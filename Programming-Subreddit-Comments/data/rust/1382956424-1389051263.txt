What would higher-kinded types solve in regards to this problem?
Aha! Finally a place you can pitch Rust as a simpler language :).
My first post about rust. It ended up a bit weird, but it partly mirrors my own experience while learning the language. 
Slide 17 uses old for loop, but slide 21 uses new for loop!
Managed pointers are on the way out; they're now behind a feature flag and will be removed from the language altogether some time soon. Prefer using owned pointers instead, or take a look at `Rc` which does basically the same thing but is a library feature. The garbage collection managed pointers do is not complete garbage collection; it doesn't collect cycles, for example, until the completion of the task.
Slide 21 also uses `println(fmt!("%d", *self))` instead of `println!("{:d}", *self)` (and the `:d` is optional there, I'd omit it).
Nice work. I'm surprised crates/modules didn't get mention, though.
I've added a postscriptum at the end, the change got in while I was writing the post. 
Thank you so much for sharing. These kinds of things are really valuable to read.
&gt; But this won’t do any good here: rust does not do tail call optimization. It’s unfortunate, but there are good reasons for that (summary: TCO clashes with some of Rust’s goals, including performance and C compatibility). Rust doesn't have *guaranteed* TCE, but LLVM does do so-called sibling call optimization, which IIRC works when the callee function is statically known (not sure if there are other restrictions?). So it won't work with e.g. continuation passing style, but I think it *should* happen in the kind of simple case you presented.
Most languages only ever use (), [], and {} in balanced pairs (outside of comments) so it's much easier to understand for support tools like editors etc. On the other hand &lt;&gt; are regularly used on their own for inequalities, not balanced, so support tools need a much more complete parse to figure out what's going on.
Rust needs generic sugar for smart pointers. Special casing types that are meant to be only one of many alternative implementations in the language is a crutch.
I remember reading somewhere that [] was considered/used for generics, but I didn't know it was also ambiguous to parse. I think square braces a bit nicer, but this is only a very minor bikeshed. 
&gt; Rust needs generic sugar for smart pointers. Definitely. But unless `@` is re-used for that sugar (as iirc Kimundi suggested a while ago) or some other purpose, I don't see why one has to come at the other's expense. (The GC shipped with the standard library is going to have a distinguished role no matter what, because only tracing GC can be used with full generality (thanks to collecting cycles), and multiple tracing GCs don't coexist happily, so to avoid compatibility issues and fragmentation using Rust's own GC will be heavily favored when people have any kind of choice in the matter and need one.)
I agree it's important to have an easy way to work with managed pointers and a GC if needed. It could be used as a transitional feature for new users: those more familiar with GCed languages could just use @ everywhere initially, before having to learn the complexities of unique pointers, borrowing and lifetimes (that's why I only used managed boxes in the post). It's not idiomatic but some people started with C++ doing C with a few classes, and some people start learning Scala by writing Java with a few functional features. A transition path is often important. But I don't think functional programming can't happen without @, it's just that you have to understand the language's character and do it in a way that's a better fit to its features. I intend to write about this in a future post. 
I don't think it makes sense to have a different syntax for reference counting and garbage collection. It's also very odd to place tracing garbage collection above reference counting in a language using destructors for non-memory resources and move semantics. The only time `std::rc` reference counts happen is when ownership is actually split with `clone`, otherwise it is as cheap as a unique pointer.
&gt; I agree it's important to have an easy way to work with managed pointers and a GC if needed. It could be used as a transitional feature for new users: those more familiar with GCed languages could just use @ everywhere initially, before having to learn the complexities of unique pointers, borrowing and lifetimes (that's why I only used managed boxes in the post). It's not idiomatic but some people started with C++ doing C with a few classes, and some people start learning Scala by writing Java with a few functional features. A transition path is often important. One of the problems with programming in this style is that if you need to send data between tasks you end up in trouble. Maybe serialization and flatpipes are the answer to that (giving an Erlang-y shared-nothing, copy-all-messages model), or maybe the right solution is a concurrent tracing global GC (horrors!). Given that functional programming doesn't favor shared mutable state, the latter approach might well be sufficient to support naturally-written FP in a concurrent environment without sacrificing the "no data races" philosophy of Rust, at the cost of global GC pauses. I feel like we need some room for the community to experiment with all styles to see what GC'd Rust looks and feels like. I think Rust 1.0 will not have all the answers; Rust 1.0 will primarily support the low-level, C++-esque "unique pointers where you can, reference counting where you must" style. That's the style we're most familiar with, it's the style we've worked hardest to make natural, and it's the style that low-level projects like Servo and sprocketnes are written in. But as Rust has potential beyond these domains, we should leave the door open to see what works for folks who want garbage collection in Rust 2.0 and beyond. To that end, I concur with strcat that baking one type into the language seems premature. Interestingly, there seems to be some sort of law that version 1.0 of a language will support only either low-level memory management or high-level garbage-collected memory management well, and subsequent releases may move it further and further toward the other direction. Given Rust's focus, I'm pretty happy that we started where we did.
Virt cost is due to not having a JIT with polymorphic inline caches the cost dissapears. Maybe the field should be exposed without an accessor. Personally i find inheritance harder to maintain you have the fragile base class issue , prefer extention by composition and inject common code via a function in the constructor. Inheritance IS composition but the compiler sugars the compisition via the 'this' pointer. Nothing to stop some implementations having there own this. To me this is a slippery path as well - Encapsulation is needed with inheritance - interfaces are more usefull especially as a standard lib construct. Do you have inheritance with interfaces ? inheritance can be emulated with 3 interfaces ( but with virt call cost) . Existential types can do interfaces and give more of an OO style and runtime dispatch. ( Kind of important for a standard lib IMHO) . To me what it boils down to is if you want a more OO hybrid than you should move to a more advanced System F type system and have a type system that can express inheritance and interfaces. http://gallium.inria.fr/~remy/modules/Montagu-Remy@popl09:fzip.pdf 
Please direct any feedback to the ML, as this is a formalish RFC.
The old `read_char` was actually memory unsafe as it transmuted `-1u32` to a `char`, which is assumed to be valid.
Well, I hope those changes land soon. Right now, I'm probably stuck to 0.8 because my parser isn't done and updating to master would critically break it :( (a parser that can't read chars is rather useless). 
You can [copy the 0.8 impl](https://github.com/mozilla/rust/blob/0.8/src/libstd/io.rs#L717-L724) if you really want to upgrade since Rust allows extensions traits. (Note that that would require removing the invalid `transmute(-1)` and presumably changing the return type to `Option&lt;char&gt;`.)
Do you think there are gains to make on algorithmic changes, rather than constant factor optimizations? I know very little about the current state of production implementations of CSS rendering, but there was interesting work on making rendering parallelizable by Leo Meyerovitch, in his 2010 article with Stanislas Bodik [Fast and Parallel Webpage Layout](http://www.eecs.berkeley.edu/~lmeyerov/projects/pbrowser/pubfiles/paper.pdf). Have those ideas been adopted in practice? Are they unrealistic given the corner-case complexity of actual production browsers?
As dbaupp says, if you only need UTF-8 don’t wait for full support of arbitrary encodings and use something more specialized. Either copy the `read_char` implementation, or use one of the `from_utf8*` functions in `std::str`.
&gt; We can get closer to having all of Servo to build with rustpkg. Nice.
Agreed, I'm really excited to have a solid rustpkg - it's basically the last thing I'm waiting for to mature a little more before really diving into the language. Even though Go's built in package management tool is lacking in some ways (versioning, reproducible builds, $my_companies_way_of_doing_things, solving the halting problem etc) it provides a really user friendly way to jump into development and get started quickly. Not relying on a central registry is also a massive plus in my book and am glad to see Rust picking that up. /excited
We have talked with Leo a lot :) Yes, I think there are plenty of gains to make there, and we plan on implementing them. We have implemented the algorithms in a way that should be parallelizable once we have a work-stealing scheduler to parallelize them with. That was actually one of the main driving factors behind Servo.
&gt; Virt cost is due to not having a JIT with polymorphic inline caches the cost dissapears. Maybe the field should be exposed without an accessor. OK, but we don't and can't have a JIT. &gt; Existential types can do interfaces and give more of an OO style and runtime dispatch. ( Kind of important for a standard lib IMHO) . We considered explicit existential types early on and decided on our trait system instead because of language complexity/familiarity concerns.
Would a concurrent hashmap expose mutability? I find it a little strange that RWArc pretends to be immutable even whole providing mutable access to its contents.
Perhaps I misunderstand the problem, but why not reuse @ for smart pointers in general, like let x = @RC(Thing::init)?
Well, `RWArc` is only as weird as `@mut`, no?
I don't think rustpkg should really need you to add stuff to RUST_PATH just to work. It should be able to scan the child directories at least. I don't know how it works - it fails on Win, but Win is rather bad.
So the idea is to remove not just `@` but `~` as well? Then you can define `new(my_allocator)`, right? Isn't that too much freedom?
Too *much* freedom? In what way?
The more restricted your syntax is, the easier it is to understand what happens. Imagine I get `let a = new(oh_my_god_what_does_this_do) "33"`. I know what `let a = ~"33"` does, I know what `let a = @"33"` is, but the OMGWDTD allocator does something weird(er). It writes a copy onto HD and a one on heap and synchronizes between two values. So if someone changes representation on disk value in memory changes and vice versa. Anything that compiler allows, will be written eventually.
For perspective, this is one of the big blockers for 1.0 that we've been eagerly awaiting for a looooong time (since 0.5, at least). IMO, here are the remaining three "big" bugs standing in the way of a stable release: https://github.com/mozilla/rust/issues/2202 https://github.com/mozilla/rust/issues/6308 https://github.com/mozilla/rust/issues/7803 Once those are resolved, all that's left is mostly clarifying edge-case semantics and putting the finishing touches on syntax.
Note that all lifetime parameters on functions are late bound at the moment, and you can just omit them instead of using \_(or '\_) to get inference. So using '\_ or using semicolon for separator will affect exactly zero existing Rust code, and I think these will continue to be rare cases. On the other hand, I think early bound lifetime parameters that are not used by later type parameters (so don't need to be early bound) should warn, or even error. This should catch cases when lifetime parameters are accidentally early bound.
&gt; Isn't that too much freedom? Servo needs it, for one. We don't use the Rust garbage collector in Servo's script task; instead we use the JavaScript garbage collector. (Chromium is experimenting with doing the same thing, by the way; it's needed for Dart.) So we need a way to allocate Rust objects into the JavaScript heap, and placement `new` is the way to do that.
Right, I do think it's *really super vitally* important to have pretty-fairly-good libraries before a "full" 1.0 release. But as far as a sort of symbolic "1.0-alpha" release, we could perhaps get away with committing to merely language backcompat and making it explicit that the libs are still in flux for the duration of the alpha period (which could probably last, I dunno, 6-12 months, and give us additional time to fix bugs and work on perf). But that's only really necessary if brson is eager to get the language to a stable milestone as soon as possible.
Ok, that sounds reasonable, but I'd like to keep some aspect of the `@` syntax. It seems way more "readable" (subjective feel) than `new` 
The other part of #2202 is the borrow checker changes. I have those basically done, actually, but I deferred landing until the RAII work is done, because I saw that a lot of closures would be converted then anyhow. But maybe I should just land it now. 
To me, this is probably the last major thing for the region system to work well. While it doesn't come up too often, the fact that in this struct: struct Foo&lt;'self&gt; { bar: &amp;'self mut Bar&lt;'self&gt; } the lifetime of the pointer to `Bar` and the lifetime of `Bar` are tied together can have some serious consequences. 
To me it just feels completely arbitrary, and pointless. The best argument I think of for not using @ is the question "Why should we use @ for smart pointer syntax?"
On a side note, there is a `-Weverything` flag in clang which is supposed to show every warning.
There's also `-Wmost`, leaving out experimental/broken or generally not useful warnings.
Also some of the warnings are very specific. For example, a soft real time audio program should not allocate any garbage collected memory, or heap memory but for something like a compiler that only needs throughput warning against allocations would be counter productive.
&gt; Sometimes you need classical OO, as unfashionable as it may be. Example?
With this system you can emulate interfaces perfectly by creating a struct bound to any number of traits, not implementing any of those traits for that struct, and then inheriting from that struct.
Rust is quickly gaining one of the best foreign function interfaces out there, in my opinion. This is a great thing to add for the sake of pulling in C and Objective-C code.
I think this is absolutely the right decision. We had great success at a previous job of mine in using Linux's lazy memory page allocation to create very large in-memory Tries while minimizing memory fragmentation. This was on 64-bit systems, of course.
With this change, I *think* it's finally possible for rust-bindgen to automatically bind any C API without any holes! Previously, when binding Lua, I had to manually comment out anything that made use of either unions or variadic functions. Very exciting.
How are unions represented in Rust?
This is #5492.
I thought kibwen was saying there was a solution available now. I guess I am misunderstanding.
cmr on IRC tells me that rust-bindgen is indeed capable of handling unions. Though I don't know *how* it does it, and I haven't yet tried it to see if it works.
OO is a pretty good paradigm for graphical user interfaces where you have a tree of controls that differ only a little from each other. Implementing that without single inheritance is really tedious.
I started on some documentation for Linux sandboxing, as it pertains to Servo: https://github.com/mozilla/servo/wiki/Linux-sandboxing
Windows does still have a form of overcommit. Memory can be allocated as pagefile-backed and it will reserve disk space equal to the uncommited virtual memory.
I think you need `~Any` type, which is currently being proposed as of Issue [#9881](https://github.com/mozilla/rust/issues/9881). The issue has a link to a possible implementation which may or may not fit on your use case.
The [Any trait (and the three pointer-related traits)](http://static.rust-lang.org/doc/master/std/any/index.html) are already in master. It seems like [#9967](https://github.com/mozilla/rust/pull/9967) didn't close (or even update) the original issue you linked, [#9881](https://github.com/mozilla/rust/issues/9881). EDIT: if `thing` is `&amp;Any`, this should work (see [docs](http://static.rust-lang.org/doc/master/std/any/trait.AnyRefExt.html#tymethod.as_ref)): `thing.as_ref::&lt;uint&gt;().unwrap()`.
Is it possible to make a container store a `Trait + Any` type so that I can call my defined methods on `Trait` while being able to cast?
I'm trying to create a library crate that accepts variants from client code, so defining such enum in library code would create a strong dependency with the client.
If you want to be storing a trait object for `Trait`, then you'll need to have it inheriting from `Any`, i.e.: trait Trait: Any { fn method(&amp;self); } Note, however, that C++-style polymorphism isn't really designed for Rust. If you want functions that can handle any type that `impl`s `Trait`, then a plain generic is better: fn function&lt;T: Trait&gt;(vector: &amp;[T]) { /* ... */ } (This does have the limitation that the vector is homogeneous.)
Very cool! It'd neat if `specfold` took a generic iterator, rather than a specific range, i.e.: pub fn specfold&lt;A: Eq + Clone + Send, B: Send, It: Iterator&lt;B&gt;&gt;( iter: &amp;mut It, loop_body: &amp;fn() -&gt; ~fn(B, A) -&gt; A, predictor: &amp;fn() -&gt; ~fn(B) -&gt; A) { The current behaviour would then just be `specfold(range(lo, hi), body, predict)`. Also, I believe `specfold` current fails on an empty range, it should probably take an initial `A`, and it'd be slightly more useful if it returned the last value directly (i.e. if it was `specfold&lt;...&gt;(...) -&gt; A`).
I just pushed my last update for the night. I changed the interface of `specfold` to take a single integer (for the number of iterations) and added a README.
&gt; It'd neat if `specfold` took a generic iterator, That's a good idea, I may try that out. I'm not really sure why the original paper used integers `low` and `high`, but I did my best in the initial version to copy the paper pretty much exactly. &gt; Also, I believe specfold current fails on an empty range I haven't tested it. I'll take a look at that. It uses `predictor()(0)` to get the initial value, which must be "correct". I'll test it for empty ranges. &gt; it'd be slightly more useful if it returned the last value directly (i.e. if it was `specfold&lt;...&gt;(...) -&gt; A`) That shouldn't be too hard, though I don't know how useful it would be. The intermediate value is supposed to be things like the state of a state machine (for lexing), but I could add it in. The CSS parser does everything by sending the tokens over a channel to a coordinator task which stitches everything together at the end (which is why I was asking about `flat_map` on IRC).
&gt; I haven't tested it. I'll take a look at that. It uses predictor()(0) to get the initial value, which must be "correct". I'll test it for empty ranges. The problem is [the `results[0]`](https://github.com/haxney/speculate/blob/45e21d680e45820ecabfa35582755c05fce01296/src/speculate/lib.rs#L49), since the vector is never filled with anything.
In many situations you can get cleaner code by using an enum. use std::hashmap::HashMap; enum Test { UintValue(uint), // Put more options here } pub fn main() { let a = 15u; let thing = UintValue(a); let mut map = HashMap::new(); map.insert(0, thing); println!("{:?}", a); let a = match *map.get(&amp;0) { UintValue(a) =&gt; a, // Put more options here }; println!("{:?}", a); } EDIT: Oops, I read the thread. He doesn't want enums.
Alternatively you can try to add a lot of methods to the trait. If you add enough methods, then it may not be neccesary to cast.
Some people (among whom janitors) are paid for cleaning up! We can argue that your change is not big, but if every single programmer made a similar change Rust would probably be typo-free :)
Nice! But I'm noticing that you're not yet using match statements to their full potential: Instead of match cast { None =&gt; { retval = None } _ =&gt; { let tmp = cast.unwrap (); retval = Some (tmp.to_str ()); } } You can write match cast { None =&gt; { retval = None } Some(tmp) =&gt; { retval = Some (tmp.to_str ()); } } That is, you can directly bind the the content of the Some variant to a new variable. No need for explicitly calling unwrap. :)
Even better, using [the `.map`](http://static.rust-lang.org/doc/master/std/option/enum.Option.html#method.map) higher order function on `Option`: fn rust_readline(prompt: &amp;str) -&gt; Option&lt;~str&gt; { do prompt.with_c_str |c_buf| { let ret = unsafe {c_str::CString::new(readline(c_buf), true)}; ret.as_str().map(|s| s.to_owned()) } } This [uses `with_c_str`](http://static.rust-lang.org/doc/master/std/c_str/trait.ToCStr.html#method.with_c_str), and the fact that all these methods pass the return value of the closure as their own return value, so the mutable temporary `retval` isn't necessary. (Also, it wraps the minimum amount possible in `unsafe`, so that we don't accidentally use other `unsafe` functions in places we aren't meaning to.)
http://tim.dreamwidth.org/1832202.html
Every change makes Rust more awesome, no matter how small.
&gt; In just a simple benchmark of reading/writing 4k of 0s at a time between a tcp client/server in separate processes on the same system, I have witnessed the throughput increase from ~750MB/s to ~1200MB/s with this change applied.
Android/ARM is on Samsung's radar. My hope is that iOS/ARM is not too far out.
Enjoy the `contributor` flair :)
Thus the build system. Nothing else!
Ah cool thanks!
Cant believe you can do that. I experimented with using: let ret = unsafe {...} but then i got scared ... :P
As I said on the mailing list: "I started making a list of Rust packages that build with rustpkg, on the wiki: https://github.com/mozilla/rust/wiki/Rustpkg If I left out yours, add it! (And if I included yours but shouldn't have, then remove it; I was going through RustCI and finding the ones with a lib.rs file :-) With hope, the central package database ( https://github.com/mozilla/rust/issues/10041 ) will obviate the need for this list, but in the meantime, let's maintain the list informally. "
Nice, thanks. We might want to add build status as in https://github.com/mozilla/rust/wiki/Note-wanted-libraries
Did you re-run `./configure` before `make`?
The linked video from LPC about user-level threads is well worth the watch by the way http://www.youtube.com/watch?v=KXuZi9aeGTw
I ran into this as well. 'make clean' and 'make clean-all' don't actually get rid of everything; I had to manually delete all generated/downloaded files to get back to good.
This seems promising. Does anyone have documentation on these apis? do they even exist? What should the rust scheduler do on platforms that do not support a similar light weight threading system?
Sadly no patchset seems to have been published from Google yet.
you may want to try a generic approach. like: struct Parser&lt;R&gt; { source: R } impl&lt;R: std::io::Reader&gt; Parser&lt;R&gt; { pub fn from_reader(data: R) -&gt; Parser&lt;R&gt; { Parser { source: data } } } 
&gt; What should the rust scheduler do on platforms that do not support a similar light weight threading system? I think 1:1 threading is far more important than going out of the way to optimize for the high-performance computing (which is surely on Linux) or scalable socket server (which is likely on Linux) use cases. I'm sure anyone doing this on OS X will have no problem overriding the default ridiculously low limits for threads and lost performance from context-switching isn't the end of the world. The interest in Rust has primarily been centered around Servo, video games and other client-side applications where C++ is still king. Using M:N threading will be a serious hindrance to these use cases. For example, NSS depends heavily on thread-local storage and exposing a safe API without 1:1 threading might not be possible.
I also like Alex Crichton's response about threading model abstraction here: https://mail.mozilla.org/pipermail/rust-dev/2013-November/006573.html
Ah! I see it. Just fixed this. Thanks!
If you update to master you can write struct Parser&lt;'a&gt; { source: &amp;'a mut Reader } (Or use the generic `struct Parser&lt;'a, R&gt; { source: &amp;'a mut R }` like /u/berleon suggests.) This isn't possible with the old `io` (which still exists in 0.8), since the `@Reader` trait object was so cemented into its design.
I'm just a casual observer, but very interesting things are happening here in rust-land. AFAIK rust has 3 different kinds of pointers: owned, managed and borrowed, each representing different use-case. maybe a similar attitude towards concurrency is to be made here: 1:1 vs M:N and cooperative vs preemptive, each implemented in a standard library; for developers to chose for their individual use-case ┌───┬──────┬──────┐ │ │ coop │preemp│ ├───┼──────┼──────┤ │1:1│ ∅ │ ✓ │ ├───┼──────┼──────┤ │M:N│ ✓ │ ✓ │ └───┴──────┴──────┘ 
It's not really possible for Rust to provide preemptive scheduling with M:N threading, unless you just mean scheduler threads preempting each other. The mailing list post explains how cooperative scheduling (or any user-mode defined strategy) is possible to implement on Windows and hopefully soon on Linux.
Is it possible to easily convert `str` into a `Reader`?
And brson has endorsed this response: https://mail.mozilla.org/pipermail/rust-dev/2013-November/006627.html People following this thread may also like to know there's been quite a lot of discussion on HN: https://news.ycombinator.com/item?id=6726357
With 0.8, I think there's a `std::io::with_str_reader`. With master, you could use `std::io::mem::BufReader::new(string.as_bytes())` ([docs](http://static.rust-lang.org/doc/master/std/io/mem/struct.BufReader.html)) (or `mem::MemReader::new(string.into_bytes())`, if you have a `~str` and can hand away ownership at that point, [docs](http://static.rust-lang.org/doc/master/std/io/mem/struct.MemReader.html)).
Intriguing, though I guess I could make a `Reader` that would wrap `str` in a `BufReader` and present itself as a StrReader.
It is caused by this change in libuv: https://github.com/joyent/libuv/pull/987 The build process needs to call "gyp_uv.py" now instead of "gyp_uv".
| Instead of segmented stacks we're going to rely on the OS and MMU to help us map pages lazily. Although the details aren't clear yet, I expect that on 64-bit platforms the number of concurrent tasks will be comparable to using segmented stacks. This is very optimistic, in reality I expect some problems with this approach. For example, if default stack size for task is 1Mb and page size is 4Kb we will end up with 1Mb virtual and 4Kb physical memory for each task. If we want to create 100 000 tasks - ~100Gb of virtual address space and almost 400Mb of physical memory will be needed. 400Mb is not a big problem but 100Gb of virtual address space really is, because all this address space need to be backed by rather physical memory or swap memory. At least on windows, total amount of pageable virtual memory can't be larger than commit limit and commit limit is not very large value. Because of this, there is no big difference between 64 and 32 bit, at least on windows.
&gt; But this is no great loss; moving out of a vector will be accomplished through methods like pop() etc. As a container method, does that mean that `pop()` would adjust the storage? That seems fine for moving out one item, but what if I want to move out all of them? Gradually shrinking the storage seems wasteful when it could all discarded at once after moving. That is, in the hypothetical scenario outlined where let x = ~[~"Hello, ~"World"]; let y = x[0]; is disallowed, is it possible to write a moving fold / reduce that does not needlessly perform extra work? Will it have unsafe bits? (I'm interested in such a fold over a vector proper or indifferently a slice.)
It's not possible to move out every item progressively of a vector even with `[]`; allowing partial moves from a vector `~[T]` without changing the vector itself would leave holes in it, holes which are not necessarily detectable in general, so the vector destructor would attempt to run the `T` destructor on that hole, and then you've got yourself some memory unsafety.
Why not just have a consuming extractor? fn index_consume(self, idx: int) -&gt; T It can be extended to return a fixed-length array of elements extracted given a fixed-length array of indices (but this requires generics with integer parameters). 
A slice is a structure with two fields: base and len. You can think of it as a pair of RandomAccessIterator, base and base+len. You need len to do bounds checking. C++ does not need len because indexing RandomAccessIterator doesn't do bounds checking, but that is unsafe.
Here is a ticket discussing @achrichto's more-concrete proposal on how to proceed: https://github.com/mozilla/rust/issues/10493 I made a comment there laying out my thoughts, albeit they're pretty head-in-the-clouds.
I think slices are a fundamental type while the vector is not. The vector concerns itself with allocation and growth strategy. The slice is just a contiguous range (Either two pointers or a pointer and a length), and it can be reused by an alternative vector implementation. Further thinking along the line of slices goes down to strcat's observation that the vector iterator and slice are equivalent, and they could be unified.
Try adding a semicolon behind the feature gate, e.g. #[feature(struct_variant)]; Sadly, there is no warning when you don't have that semicolon there, but it is required for crate level attributes. I've been bitten by this before as well, and suggested a warning about this, but was told that it wasn't worth the effort to special case crate level attributes to give this warning. ~~I may yet try to put in the effort though to see if I can implement this myself ...~~ (this seems like more work than I thought - see the linked issue below; I would still love to see a warning about using `#[link(...)]` or `#[feature(...)]` as an outer attribute though.) I think the only other attribute that requires this is `#[link(...)];` which is also crate-level. EDIT: There is an issue filed for this here: https://github.com/mozilla/rust/issues/2569. It looks like the focus is on changing the syntax rather than just warning when an inner attribute is used as an outer attribute...
Thanks! I tried this earlier and it was an error, but if I put it at the very top of the file before everything else _and_ with a semicolon, it works. I think I was confusing how crate-level attributes and module level attributes are written/understood. Much appreciated, I'll keep it in mind and pass it along if I see anyone else running into it :)
(Note that unification would trade-off performance: slices should have fast bounds checking and so should store their length, while iterators should have fast iteration i.e. only update one value for each step, which requires storing a pair of start &amp; end pointers.)
A slice essentially groups the pointer &amp; length one sometimes passes to C/C++ functions into one object: // C/C++ int sum(const int* arr, int len) { int s = 0, i = 0; for (; i &lt; len; i++) { s += arr[i] } return s; } // Rust fn sum(arr: &amp;[int]) -&gt; int { let mut s = 0; for x in arr.iter() { s += *x; } s } (Admittedly, this is more C than C++.) The respresentation of a slice is: struct Slice&lt;T&gt; { // == &amp;[T] ptr: *T, length: uint } (The representation of a `&amp;mut [T]` is the same (although possibly with `ptr: *mut T`), and a string slice `&amp;str` is `Slice&lt;u8&gt;` with the restriction that it's valid UTF-8.)
I like the first one, although [the top links seem to disappear for sufficiently small screens](http://i.imgur.com/FEr6Y4Q.png) (Firefox Nightly, Linux). (BTW, Firefox developer tools offer a ["responsive design mode"](https://developer.mozilla.org/en-US/docs/Tools/Responsive_Design_View).) (Also, neither here nor there, but the [page encoding of the "getting started"](http://adrientetar.legtux.org/cached/rust-www-proto3/starting.html) appears to be ISO-8859-1 even though it's got a `&lt;meta charset="utf-8"&gt;` tag in the header.)
This is "just" an email from a community member (i.e. not authoritative); but I thought it sufficiently interesting to not let it get lost amongst the discussion of tutorials and threading. 
Am I the only one here that really likes current design?
Check your [line length](http://www.designerstalk.com/forums/graphic-design/42390-design-basics.html#post419371). It's not a hard-or fast rule, but generally 45-70 characters is a good range for maximizing readability. Websites sometimes go a little longer than that, but your examples are really pushing it The layouts seem a little hap-hazard. Are you using a [grid system](http://en.wikipedia.org/wiki/Grid_%28graphic_design%29)? (see also: http://www.thegridsystem.org/) You don't have to use one of those frameworks, but using one at the design stage will give you a much more coherent result. Have you done any sketches/mockups that we can look at? ie. before you began coding it up?
That doesn't sound like a particularly large overhead to me, but maybe I'm just not thinking of the right sort of examples where it would be expensive. Surely anywhere these checks are performed in a tight loop LLVM would lift the computation (which is small and cheap anyway)?
Which doesn't sound like a large overhead, updating two things? (For one, LLVM is very picky about how it optimises loops... they have to be very similar to the C/C++ equivalent (i.e. updating one thing only).)
I also like the current design *for the main page*, but we will eventually have to think about the integration with other pages.
Also related: [#10316](https://github.com/mozilla/rust/pull/10316) (Add lint for misplaced/obsolete attributes).
I really like the first one! Good Work!
I admittedly like it a lot too, it's a great deal of simplicity and cleanness. I think brson is willing to have a website that has the download for your OS and some quick get started instructions accessible from a push of a button.
C++ does not need a length because it uses two iterators to form a semi-open interval instead. It amounts to the same information, but the iterators-as-bounds version can be more convenient for iterators that do not allow for offset computations. pair&lt;RAIt, RAIt&gt; to_bounds(RAIt base, Diff offset) { return { base, base + offset }; } pair&lt;RAIt, Diff&gt; to_offset(RAIt start, RAIt stop) { return { start, stop - start }; } Well, sometimes pointers + length pairs do appear though.
Could provide an internally-unsafe wrapper type that takes ownership of the vec and associates each field with a bit flag stored externally to offer a `Vec&lt;Option&lt;T&gt;&gt;`-like interface. Primitive sketch: http://ix.io/92N
I think you want to post this on /r/playrust
[MoveIterator](https://github.com/mozilla/rust/blob/a46b2b8e7aafd23a4d3850d4de6653e363fd0813/src/libstd/vec.rs#L2455) doesn't seem that bad.
This is really great. Most languages support only one or the other form of linking, with clear disadvantages; this is one important step closer to making Rust a true systems language. Incidentally, this might squeeze out a tiny bit more performance from Servo, by reducing PIC (although if we want ASLR that benefit will go away).
Morbid curiosity: how many people actually read the whole thing?
I read it, but I didn't understand much of it, or its implications.
I understood most of the words, just not in that context. From what I did understand, some of it seemed like interesting ideas.
There's nothing wrong about programmer art. Rust is meant to be advertised to programmers. Most time I visit rust-lang.org to check docs on trunk/latest stable, join irc to ask question, or jump to github to checkout the code. And that's exactly what I get at the top of the site. Later some little introduction follows for programmers who are visiting fist time. Seems perfect for me. I think rust website is awesome, ATM. That is all.
+1 to this. Yeah, I love the ability to just match chars in string like this. Allows for some really Haskell-y goodness.
I'd be really interesting to see Rust become implemented in the embedded space. Do you already have a examples of doing this being done, or discussed?
This unfortunately ignores that UEFI is *absolutely* **huge**, and requires very complex firmware. Sure, you're running nothing you wrote that isn't Rust,but the UEFI runtime is a beast.
Has there been any update on the profiling part? I'm unsure if the mail view is up to date.
Wow, that is very interesting patch. Like the `read_char` on `BufReader` :) The new syntax is rather concise and to the point.
I agree that it's cool to see people looking at this kind of application area for Rust, however I really don't share the opinion that C is a "terrible language." It's gotten us pretty damn far.
C is an excellent abstraction over assembly language but I don't think it's a great general purpose programming language. Don't get me wrong, it's been used for great things. I see it as the split between viewing programming as expressing computation and viewing programming as expressing the steps a machine uses to perform a computation. C is terrible at expressing computation, but excellent at expressing the steps needed to perform it on a (von Neumann) machine.
I don't even think it's very good at that. Too abstract in the wrong places (varargs? implicit stack when calling functions?). It's *convenient* given its original purpose, but it's hardly an ideal anything.
How about an ideal amount of abstraction with the least amount of performance penalty and magical-ness.
It's relatively unlikely that C is the optimal language for any one feature, let alone 3. (Purely from a "the language-design space is *huge*" and "maximising 3 different variables at once is *very* hard" perspective.)
Vector matching is only done on slices (but would be useful on fixed-size arrays too), so it would be unchanged by moving dynamic arrays to the standard library.
Yes, UEFI needs to be shot and killed and the programmers at Intel and Microsoft who came up with the idea should be sent on a colonial ship to another planet, far, far away. Can we please have coreboot now? *Please*, Intel? It will make your silly Tizen boot faster...
&gt; I agree that it's cool to see people looking at this kind of application area for Rust, however I really don't share the opinion that C is a "terrible language." It's gotten us pretty damn far. Because of being UNIX's official system language and its widespread into the industry. C is the main culprit of the security exploits we still suffer in our software stacks.
That was unnecessarily aggressive.
No - I mean the mix of the 3. It's like a jack of all trades (for it's specific domain, of course - not comparing it's usability to Python or anything), master of none.
Feel free to open issues here: https://github.com/thestinger/rust-core As soon as generic destructors actually work, all of the containers/pointers will have allocators. I've yet to figure out how I want to handle dynamic out-of-memory errors though. Intrusive containers and safe abstractions are basically polar opposites, yet they're part what makes handling out-of-memory conditions bearable.
I think you mean `restrict` rather than `const`. I don't think `const` applied to pointers actually helps optimization.
The more I've worked on Rust† the more I've come to appreciate the design decisions made by C and C++. It's harder than you think to compete against them in their domain. (That said I think Rust has done a pretty good job, and the few remaining language changes will make it even better.) †Over 3 years now? Wow, it's been a while :)
Ah yes, I did mean `restrict`. I don't know of any optimizations involving `const` either.
I can't directly answer your question, but you might find this recent mailing list thread informative: http://thread.gmane.org/gmane.comp.lang.rust.devel/6479
I also read that and couldn't answer if rust is abandoning the goal of cheap erlang style processes.
I am still confused about how libraries will be implemented, especially the ones dealing with IO. Will a library (especially the std library) have to deal with both threading models?
Have you used C extensively, especially in the embedded space? It's definitely a terrible language. Note that this doesn't mean it isn't powerful or that things can't be done with it. It also doesn't mean that it isn't the best language available for systems programming right now, or that it isn't commonly used. See [Appeal to the People](http://philosophy.lander.edu/scireas/popular.html). Assembly also got us pretty damn far, but it's definitely a terrible language.
You might want to check out clay. Tiny elegant language that compiles to C and runs at the same speed. It is what C++ could have been had we know then what we know now.
There's been people playing with Rust without a runtime and without the standard library for [a while now](http://www.reddit.com/r/programming/comments/1f2nwe/zerors_rust_without_a_runtime/). There's been more work on it [here](https://github.com/thestinger/rust-core). A meta-bug for documenting all of this as these external projects become part of the language is [here](https://github.com/mozilla/rust/issues/8344). As far as people trying to run Rust on non-x86 systems, I haven't seen anything towards that end. I'm looking for using Rust on Microchip's PIC line (MIPS-based), AVR's, ARM chips, etc. Ideally it will also support arbitrary language extensions so that things like the Propeller can be supported with it.
Actually, C is a tiny nifty language that does it's job well for embedded. It could be be better, though, considering we have over 40 years of knowledge and experience to improve it.
nah, it was just about right
Well, it's hard to negate the shortcomings of C, but I don't find it to be _terrible_. The problem with Microchip is a problem with a Microchip, not Linux. I use gcc for everything, would support clang maybe, and stayed away from other toolchains because such companies have a tendency to produce garbage that is venomous for your software. Plus some of the problems you describe are just sad facts about reality. It's easy to get well defined behavior for every details if you're programming in an abstract language for some abstract virtual machine. But programming two completely different architectures with different hardware behavior, registers width and floating point implementations etc. is just not possible without extra work and carefulness if you want to achieve proper performance. The sole fact that in C it's possible is proof how awesome C is, despite it's shortcomings. What I find the real problem of C, are meta-programming, poor modularity, lack of modern abstractions, clumsy syntax, and no assistance whatsoever in regards to safety. So yeah, I agree that C is not perfect, probably not even good anymore, but I just love it too much, to not oppose calling it terrible. :) . I just hope Rust could be better C for embedded one day. :)
It's a reality that's is a culprit of security exploits. Eg. the fact that you have limited memory, limited computation power, limited time and developer power for software delivery. Everything seems super easy if you have arbitrary long buffers, arbitrary big integers, GC and other features a lot of languages takes for granted nowadays plus plenty of people writing unit testing, integration tests and management that's top priority is software quality, not market delivery times or salary costs. And last time I checked there were still critical security issues announced for languages like Java. So nope, it's not C that should be blamed. 
There were safe systems programming languages like Modula-2, back when C was a UNIX only phenomenon. Yes, sure C is to be blamed with its decay of array into pointers, no bounds checking for arrays, null terminated strings without length validation, usage of pointers for out parameters, union types without validation of the correct data. Nowadays with _-Wall -Werror -pedantic_ and a static analyser integrated into the build, C can be bent into a safer language, but *only* if developers follow the guidelines how to write secure C. Which does not fix the amount of code out in the wild, waiting to be exploited.
How does let x = ~[1, 2, 3]; ===&gt; let x = Vector::init([1, 2, 3]); interact with types that move? I.e. how would one replace `~[x, y, z]` where `x`, `y` are `~Trait` objects or something? If `init` takes a slice then it cannot move out of it. (Also, slices seem to be fundamental container types too since they're just a pointer to a block of memory with no destructors or anything, and I imagine moving them completely out of the language into libs will make things uglier for everyone. :( (And possibly lead to an overuse of `Vector&lt;T&gt;` rather than `Slice&lt;'a, T&gt;`.))
&gt; -Wall -Werror don't forget -Weverything and -Wextra
Rust reddit is about the programming language, not the game...
You need separate library implementations for M:N and 1:1 threading. A traditional C library will use blocking I/O so alternatives need to be developed based on the scheduler. This is why the standard library has both native and libuv-based I/O. Any third-party library needs to do the same thing. The communication and synchronization primitives are also much different for M:N and 1:1 threading. The ones in the standard library at the moment don't map well to 1:1.
If the library only needs the primitives provided by the standard library (pure Rust), then it doesn't need to do anything special. However, if it's a C binding then it's likely going to be inherently tied to the 1:1 model. It will require more work (if the library supports async) or a rewrite of the C library to support non-blocking I/O for M:N threading.
voting for #2 as well
Spawning 100k threads on Linux takes a second. The memory isn't committed until it's actually used (each thread uses ~4K and maybe 4k in overhead). The same applies to Rust's tasks, but they don't require the (minimal) kernel scheduler resources and expensive context switches for fair scheduling and pre-emption.
This is true only if overcommit is enabled. This won't work on linux distributions configured in another way (overcommit disabled) or on windows because windows doesn't allow overcommit at all. And even if overcommit is allowed - you will end up allocating one physical memory page for each thread that is 4K on most systems.
The built-in vector is slow and shouldn't be privileged; there are lots of other data structures (trees, hashmaps, lists), and, more significantly, lots of other possible vector implementations (in particular, Servo is interested in things like `SmallVec`, which only allocate after they've reached a certain size).
Okay, that makes some sense. That basically jives with what I was thinking: I feel like arrays should be a native language type, but not necessarily *growable vectors*. The proposed solution still feels like throwing the baby out with the bathwater. Why not just stop special casing `~[T]` to be a growable vector, and instead (assuming DST) just let it fall out directly from the semantics of `~` and `[T]`? I think that means that it would be an owned box of a fixed-length array (fixed at allocation time), meaning you couldn't do vector-like things like push or pop (because that would require a capacity), and for those, you would have to use a library-provided vector type. Just because unique ownership *allows* reallocations (ooh, shiny!), doesn't mean that `~[T]` has to take advantage of it. Maybe that's a temptation that should be resisted. That means `~[T]` is a little bit less awesome, but you get to keep the convenience and superior compositionality of the current/DST approach.
So you're saying writing `~[1,2,3]` has type `~([int, .. 3])`? I think that will fall out of this "automatically", in that it will be parsed as `OwnedBox(ArrayLiteral(1,2,3))`, which couldn't be anything other than the above (since `~[]` as a special case would not exist).
That actually fits very well with `&amp;[T]`, which has a pointer to data and a length. `~[T]` has capacity as well, right now, because it's growable, but without capacity, `~[T]` and `&amp;[T]` would be interchangeable.
That's also what C++ does with the special cases for `T[]` in `std::unique_ptr` and `std::shared_ptr`.
So how do I set the allocator for ~[T]? It's missing an allocator type parameter. How do I handle an out-of-memory return value from `malloc`? A language feature needs to be a primitive building block or at least be flexible enough to work in the niches Rust wants to play in.
I confess to never having used custom allocators in C++ before. That said, is this issue different between `~[T]` and any other `~X`? Given DST, wouldn't the solution in both cases be to write `CustomAllocatorPointer&lt;X&gt;` (where `X` might be `[T]`)? How do you handle out-of-memory with `~` pointers in current Rust? What interaction does that have with DST, and/or with demoting all `[T]` except `[T, ..n]` to library types?
Are you sure that windows allow overcommit? I read and do some experiments on windows few years ago and find out that address space need to be backed by physical memory or page file. I want to build scalable server using fibers that time and my server always crushes because of commit limit if number of fibers is to high.
Well, the situation with unique pointers isn't really any better. There are a lot of pain points in freestanding Rust like that. Generic destructors don't support calling methods on `self` via type bounds so it's not currently possible to use allocators at all.
If the tasks are using blocking I/O through a C library like sqlite the benefits of M:N threading are gone. Whether or not they can be pinned isn't really an issue unless the I/O homing issues are never fixed.
4k to 8k is a lot and not comparable to erlang's process overhead :(. Doesn't the M:N threading imply 'green' threads scheduled by the rust runtime? If so isn't the startup and resource overhead much less with M:N? I assume you can choose what type of task to spawn right?
M:N threading means that a Rust task doesn't map 1:1 to an OS thread. It still has a large contiguous stack as an OS thread would. The difference is that it's scheduled in userland and doesn't have the usual thread properties like a TID, thread-local storage (task-local storage is built on top of it), etc. Windows supports scheduling threads in userland now, and using that functionality would allow 1:1 threading with all of the current benefits. Linux is likely going to pick up that functionality too, because Google already implemented for their own use.
Windows threads reserve stack space but only commit it as it's consumed. They're actually more lightweight than Rust's current stack allocations. I'm pretty sure you can get the same functionality through the Windows API.
Interesting. I think the logical solution there would be that if the Drop impl for a generic type has trait bounds, to throw a type error if the destructor would be invoked on an instance of that type not matching those bounds. But what I'm trying to nail down here is what the problems are that you would like to have addressed by moving the array-like types into libraries, and how would doing that address them? Was your objection only to to `~[T]` being a growable vector (with which I agree), or is it broader than that? 
I admit I'm also confused. Even in the M:N arrangement where threads are being shared, each Rust task will still require the 4 to 8k of memory required by an OS thread?
Yes. There is already code that begins to do this in libstd.
Interesting. Given that we need DST anyway for traits, this may be something worth pursuing. I'll forward this thread to Niko.
&gt; Interesting. I think the logical solution there would be that if the Drop impl for a generic type has trait bounds, to throw a type error if the destructor would be invoked on an instance of that type not matching those bounds. I'd just throw the error when the type is constructed. The behavior strcat is referring to is just a bug as far as I'm concerned.
I didn't see that in the docs I saw for `shared_ptr` but I did for `unique_ptr`.
Yup, but it was just to demonstrate. Thanks for the responsive debug thing, I wasn't aware of that!
How are the new contributors determined? From github PRs?
Yes, they won't require any less memory for the stack. The M:N threading removes the overhead of fair/pre-emptive scheduling and concentrates on throughput.
So a Rust task may spawn other tasks within that one OS thread. I assume that's up to the programmer right? I saw the slides from linux plumbers conference about user level threads and the proposed api but don't remember if it has lower memory overhead.
User-mode scheduling doesn't have lower memory overhead. The stacks are the same size and the minimal scheduler resources still exist. Instead of scheduling the tasks itself, it leaves that up to userland. Unlike what we have now where one of the OS threads can be blocked by a blocking system call or a page fault it would hand control back to the scheduler in that case. It would also mean each task would have a TID and real thread-local storage.
Sounds great and how does rust M:N scheduling fit in with that?
Is it true that rust tasks aim to be like real OS threads and not cheap Erlang or GHC threads? That's my interpretation of your replies.
 #!/usr/bin/sh INITIAL_COMMIT=c01efc6 START_COMMIT=`git log --before="two saturdays ago" --author=bors --pretty=format:%H|head -n1` ALL_NAMES=`git log $INITIAL_COMMIT.. --pretty=format:%an|sort|uniq` OLD_NAMES=`git log $INITIAL_COMMIT..$START_COMMIT --pretty=format:%an|sort|uniq` echo "$OLD_NAMES"&gt;names_old.txt echo "$ALL_NAMES"&gt;names_all.txt diff names_old.txt names_all.txt #rm names_old.txt names_all.txt 
Just to be clear, Steve is quoting the Rust community's policy of conduct: https://github.com/mozilla/rust/wiki/Note-development-policy#conduct @strncat, I know you feel strongly about this but please do try to keep it constructive.
When was your first patch? (I believe the lists only started in [2013/10/19](http://cmr.github.io/blog/2013/10/19/this-week-in-rust/), so if it was before that week, then you won't have got a mention.)
No big deal, the first patch was around the 8th this month, the second 3 or 4 days ago. 
It would ideally replace M:N scheduling on available platforms. Rust would still have a userland scheduler, probably looking a lot like it does today, but would be using an API to context switch (reducing maintenance burden) and would need to handle notifications of blocking from the kernel.
They're cheap except in terms of virtual memory. The virtual memory on a 64-bit operating system with overcommit enabled isn't a scarce resource, and without overcommit it can be increased by making a large swap file. Haskell doesn't use a call stack so it's not directly comparable. Both Erlang and Haskell use far more *committed* memory than Rust due to relying on garbage collection and immutable data.
I don't talk about lazy commit - which is nice, I'm trying to talk about commit limit. Windows doesn't allow virtual memory overcommit - there is such thing as commit limit - total amount of virtual address space of the process can't exceed total amount of physical memory + swap file size. This article explains commit limit - http://blogs.technet.com/b/markrussinovich/archive/2008/11/17/3155406.aspx Because of that - it is impossible to allocate enough virtual address space for large enough amount of threads with contiguous stack on windows. You will hit commit limit eventually.
So Microsoft is wrong to push for user-mode scheduling as a replacement for Fibers? http://msdn.microsoft.com/en-us/library/windows/desktop/dd627187(v=vs.85).aspx
 You make my data circuits skip a beat 
Problem is not in fibers or scheduling, problem IMO in presence of commit limit in windows.
Rust can expose any tools implemented in LLVM for enforcing constant running time of a function via attributes. At the moment those tools don't exist, so there's nothing Rust can expose. I can't find any existing research on this using LLVM, and I expect it would involve very controversial invasive changes to the pass infrastructure. Rust exposes support for inline assembly, and could expose the incomplete `optnone` attribute if there's really a use case for it. I don't think there is, because crypto is usually performance critical. I think a half-measure trying to do language-level prevention of branches or array lookups based on secrets and hoping for the best from LLVM would be far worse than doing nothing at all.
Was hoping for prior research from projects like Coyote or Crash Safe.
&gt; (b) encouraging people to use off-the-shelf crypto libraries like NaCl instead of writing their own crypto in Rust. Isn't there also a need to secure the NaCl consumer (rust code)?
"contribute" goes nowhere, I already want to send you some grammar fixes :(
Yup. But timing attacks are less of a problem if you aren't rolling crypto, as far as I'm aware.
I'm excited to see where this leads.
&gt; Rust doesn't have pointer arithmetic either There is the `offset` intrinsic for `*` pointer arithmetic (although this might not be regarded as "core" Rust).
Love the addition of This Week in Servo. Thanks as ever.
&gt; Junyoung Cho added the ACID2 test file, which is one of the big focuses of the team over the coming months, in https://github.com/mozilla/servo/pull/1287 I thought I remembered hearing that the remaining acid tests explicitly weren't a priority for the Servo team. Can you cite the source that says otherwise?
Lars, a member of the servo team, wrote and sent the entire "This Week in Servo" section to me.
Our colleagues at Samsung are working hard on the ACID tests, among other things, because they are important to them, and we on the Mozilla side are helping to support those efforts. That said, we're trying to also touch on the work suggested by the Firefox gurus as having large architectural impact (namely, things like: flexbox, bidi/vertical text, overflow) in addition to adding more parallelism. And handling Rust upgrades :-) 
Hey @cmrx64, could you edit the link to the tutorial to: http://adridu59.github.io/rust-tuts The GitHub page is a bit more up-to-date, thanks!
And how many actually know rust? I know I'm one of the "just curious" lurkers. B-)
I enjoy writing little toy projects and watching as the error messages grow more comprehensible :).
Done, thanks
You're missing the point of c, it is relatively easy to map to asm by just looking at it, it has about zero abstractions - no vtables, no mangling, no eh_frame requirements. Its also easy to port and optimize.
If c ever implemented runtime based bounds checking on arrays or struct based strings is the day I would stop using it. C implements zero abstraction, if you want abstraction build it on top of a base with none. 
Vectorization is a compiler issue not a c issue. GCC / llvm vectorize almost all char-at-a-time loops. UB is either a developer or compiler issue or the standard is too open.
Highway towards the cliff! Sane languages, provide compile time options on their compilers to control when bounds checking should be disabled. &gt; C implements zero abstraction, if you want abstraction build it on top of a base with none. The 70 and 80's are gone. C no longer maps 1:1 in modern processors. 
I've mostly been a just-curious lurker, though I've been using it on the [Project Euler](https://projecteuler.net/) problems. My gut feel is that Rust is doing some really interesting things. If it doesn't take off, I think it will influence another language that does, and I might as well get more familiar with some of its ideas.
Warning on out of bounds can enabled in GCC / LLVM warnings.C isn't a 1:1 map with processors it never was in my opinion.
&gt; Warning on out of bounds can enabled in GCC / LLVM warnings If it isn't defined on ANSI/ISO, it is not part of the language. There are many developers that use other compilers. This is my main issue with C, reliance on external tools to fix the language troubles.
Eh. Rust is a remarkably easy language to learn, if you've already had exposure to other languages in the same spaces (e.g. ocaml and C). There's not much cost to being an early adopter in this case.
I wouldn't go that far. I think it's worth learning. It isn't going to change *that* much.
A minor thing, but `std::rand::TaskRng` (return value of [`task_rng`](http://static.rust-lang.org/doc/master/std/rand/fn.task_rng.html)) is [no longer (just) a `@mut` wrapper](https://github.com/mozilla/rust/pull/10588), so something like fn use_rng&lt;R: Rng&gt;(rng: &amp;mut R) { ... } fn main() { use_rng(task_rng()) let cached = task_rng(); use_rng(cached); } will need to become fn main() { use_rng(&amp;mut task_rng()) let mut cached = task_rng(); use_rng(&amp;mut cached); } (i.e. "exterior" mutability.)
Oh, yikes, I must have overlooked that one.
This is not the first 3d ray caster in Rust, but surely the first 4d one ! I have to write a ray tracer for a school assignment with a friend. Since I already had a n-dimenisonal ray-caster (ncollide), we decided to try to render a 4-dimensional scene (the ray tracer is in fact generic with regard to the dimension). On the project's README a 2-dimensional screenshot of a 3-dimensional rendering of a 4-dimensional scene is given. Note that the objects are not rotated, and the projection is orthographic, and the eye points toward the fourth axis (to make it insignificant). Everything is done in pure Rust, and this would be very hard in, say, C++, because of all the genericity requirements :)
I think part of this is LLVM optimizer deficiency, in that LLVM should be able to remove bound checks.
Hi there! Author of [cgmath](https://github.com/bjz/cgmath-rs) here. Thanks for so much for your work on this and the time you spent writing it up – it was most useful. Performance hasn't been the primary short term goal, but it is a library aimed at games and graphics so it is definitely high on my list. Any help in improvements would be most appreciated!
Why is there any doubt that it's an LLVM problem? Compile with clang 3.3, and now you're apples-to-apples.
I must admit I would be interested in getting the optimized LLVM bitcode for the function; in all the cases I've played with LLVM it was generally quite smart about eliding checks that were unnecessary, but it does depend on whether it managed to inline/constant propagate stuff.
It's often able to hoist out a bounds check, but it can rarely eliminate it. For fixed-size arrays, it doesn't trust that the array is actually valid if it doesn't see where it's allocated. It has to assume a pointer of a certain type doesn't *necessarily* point to allocated, aligned memory for that type and might trap.
I assume `Rust -O3` means that rustc was run with `--opt-level=3` (since `-O3` doesn't work)?
You assume correctly. I was just trying to keep the tables consistent.
I don't think this test actually reflects matrix multiplication performance of Rust. Writing routine that multiplies matrices only of size 4x4 and then comparing to similar unrolled c implementation is not very useful. Both implementations are unrolled by hand. So this test shows that Rust can compile linear code to linear assembly quite well. I understand that 4x4 multiplication might be useful for game development but this example doesn't tell much about Rust itself. Most matrices in real life are not 4x4, sometimes they even are not square or worse their size is not known at compile time. It would be interesting to see if it is possible to write a macro in Rust that would spit out unrolled code for matrix multiplication. PS: have you tried to multiply matrices using algorithm that requires fewer number of multiplications? Say to multiply 2x2 matrices you actually need 7 multiplications not 8 (there are more additions so it is not clear which will win in real life). 
LLVM has pretty good loop unrolling and vectorization. I expect algorithms like this will often run into performance issues if they're not using `unsafe_get` or static offsets via tuples/structs. LLVM is just *really* bad at doing anything with the bounds checks beyond hoisting them out in some cases.
LLVM doesn't have C-like semantics for pointers. Nothing is assumed about a pointer from the type, and fixed-size arrays passed/returned by-value are compiled down to passing pointers.
Being generic with regard to the dimensionality of the scene basically makes every structure or algorithm parametrized by something describing the dimension. This should be quite easy to do in C++ since it allows types to be parametrized by an integer. Things become harder if you want to be generic with regard to the algebraic structures (what if I want to use a pair of quaternions instead of 4d rotation matrices ?). In C++ this would be possible but very time consuming (for the developer) since a single error anywhere would make the compiler spit hundreds of errors. With traits, Rust has very precise, local, error messages, which make it very easy to identify missing operations for a type. When I did not know Rust, I tried to write a similar library in C++. At some point, error messages were so insanely long and complicated that I became completely unproductive. That is why I decided to find another language. With concept lite, C++ will have significantly better error messages, but the development of the ray casting library itself would still be very hard since concept lite are checked at the instantiation site of the generic function, not the definition site.
Nightly builds would be awesome for Windows users. I just finished a Windows build last night and it's a rocky process. Apparently, "make check" isn't used and fails but "make check-fast" works? I'm not sure if that's out of date info but it's what I experienced. Also, it appears that the build process downloads the dll's it needs rather than needing copying them from an old gcc? In then end, I have what appears to be a working compiler.
Probably easier to just get gentoo stage3 up and running and compile from that :) Any reason you're sticking with windows? Can't partition the machine? Favourite IDE? 
Shear stubbornness? I'm under 100GB free on c: and I'm just unwilling to share that with another complete OS. The other thing is Rusts needs to play with it under Windows. Even if I just kick the tires it's better than nothing.
&gt;Even if I just kick the tires it's better than nothing. Oh for sure. I was just curious. I was kind of pondering cmake support for Rust, but I'm not sure how many hobbyists use Visual Studio. And a cmake centric build flow is just one step along the way to maintainable Visual Studio integration of Rust.
And part 2 here: http://smallcultfollowing.com/babysteps/blog/2013/11/27/thoughts-on-dst-2/
Yeah, it turns out this a feature in Boost's `shared_ptr` added after the standardization for C++11.
Is the definition of `RC&lt;T&gt;` correct? I would have thought that a reference counted type must not place the reference count inline but must place it before the allocation, otherwise `clone` wouldn't work.
Yeah, I think this is a bit more complicated. The length has to be added to the size of the dynamically sized allocation, with overflow being checked for.
Yes you're right of course.
Not really a big deal, since all one needs to do to compile a Rust crate is run a singe program on a single file. All the configuration etc happens in the crate attributes (though --cfg can be passed). I don't see a lot of room for complex builds except in rare circumstances (servo or libhttp's codegen, for example)
I was a bit too hasty with the title, as this is actually a video encompassing *all* of the presentations from last week's Rust meetup in San Francisco. Well worth watching the whole thing!
Copied from my [comment](http://www.reddit.com/r/programming/comments/1rm8wc/sprocketnes_practical_systems_programming_in_rust/cdoobpz) on the /r/programming post, this is the program: 03:00 - The Rust Community (Brian Anderson) 26:00 - SprocketNES (Patrick Walton) 62:00 - Rust at Open DNS (Frank) 73:30 - Embedding Rust in C (Yehuda)
Nice talk! If i may add my (hopefully constructive) criticism in hopes of more and better talks? - Please always repeat/summarize questions from the audience, one can't hear them in the video - Patricks presentation was the most "entertaining" ( = interesting) from my point of view, because it showed actual code and live examples (profiler, code, running the app) but patrick too often scrolls up and down in code that he shows, give us some time to read it :) Looking at github activity and patricks references to him i'd really be interested in a talk by Alex!
Very nice talks. Wish I could've been there.
Thank you for posting the slides. For the record these are the slides of the fourth talk in a video that is discussed here http://www.reddit.com/r/rust/comments/1rm85y/sprocketnes_practical_systems_programming_in_rust/
A question about the macro in Patrick's talk. Couldn't this be done nowadays with a default implementation in a trait?
rust-http's code generation can, and should, get a lot simpler. I'm thinking of switching status to use macros (requires some more explicit code, but that's not a bad thing for searchability) and checking in the other generated parts. It needs to be either that or using the rustpkg pkg.rs and seeing what can be done with it. Anyway, the end goal is having it able to be built in the regular way with a single invocation of rustc or rustpkg.
Thanks. I had no idea what this was before, or even after, clicking on it. It was clearly a presentation of some sort, but other than who and what I had no idea where or why. It also doesn't seem to be self contained. Not sure what others are getting out of this without the video, but all I got was that it was about something (skylight service) currently written in Ruby being rewritten in Rust with some help from C. I'll watch the video later. Thanks for the link!
Yes, probably.
In reality, the best thing to do for linear algebra is to link directly to an optimized BLAS library. It's not that I don't trust Rust's optimizations, it's just that those libs have been around *forever* and are *extremely* well optimized.
This is awesome, thanks for sharing.
&gt; Guess I'll better get started. Or you can contribute to the project. 
Great talks! Patrick, could you share your highlighting file? I'm using the sublime-rust package but it looks weirdo imo, e.g. curly braces are pink.
Well, both, right? The shell will use these utilities.
Isn't this then not a (mostly) drop-in reimplementation of the POSIX/GNU coreutils utilities?
It seems like you could avoid the pitfalls of SST by importing its key features into DST. So, make it so that the size information is stored externally (with the necessary semantic adjustments), and allow `struct U&lt;T: unsized&gt; { x: int, t: T }` (i.e. unsized type in the tail position), such that if `T` is unsized, then `U&lt;T&gt;` is unsized. Then you can generate the impl for GC&lt;[T]&gt; without problems.
this is really cool. will certainly watch the project and maybe try my hand at a contribution
Do note that this is mostly for my own edification, though others may find it useful.
This is a really awesome project! Kudos!
The first five books are really good. The next five ones with Merlin, considerably less so in my opinion.
It hasn't been changed. The ref count needs to be stored indirectly – such as by allocating it along with the referenced memory – or else changing the ref count on one copy of the RC wouldn't have any impact on other copies of the RC. It would essentially be useless.
I would suppose it depends how the json/bson output is triggered. Should those utilities emulate the GNU coreutils so precisely as to let the user fall into the same traps ? Should they be interoperable ? If you forego interoperability, then the format in which the information is piped to the next program is suddenly irrelevant (though I know not if it is possible to ask for the capabilities of the recipient of a pipe, this would certainly help here). If from the user point of view all that changes is that suddenly commands who would have a very weird and mysterious output with coreutils start working with uutils, I would argue it's a drop-in re-implementation :)
Is there a replacement for linked failures ? Rust doesn't have an exception system (on purpose) for throwing and catching errors, and the recommended way of handling failures was by using linked failures. Is there no longer a way to recover from a failure ?
Failure still exists; linked failure just refers to the way in which, by default, a task that failed would also cause the failure of any tasks spawned by it (and so also of their subtasks etc) and its parent, and so on, to propagate the failure around the task tree (until it met a task spawned as "supervised" or "unlinked"). The current recommended way to detect/recover from failure is to use `std::task::try`, which even allows propagating the failure message up from the subtask with the (relatively) recent addition of kimundi's neat `Any` trait.
I'm not sure of the interoperability goals, you'll have to ask Seldaek about that. In any case, shell utilities are designed to interact with arbitrary programs, and plain text is certainly the most widely supported IO interface. (NB. I've never used power shell, so I don't have any idea how well the structured format works there, so I'm possibly concerned about something that isn't too bad in practice.)
uutils initiator/mad man here. I definitely agree that going off the beaten path and into a "cli for the 21st century" would be amazing. The trouble however is two-fold: we have a big issue of collective muscle memory used to current commands (including quirks), and this would be an even larger project. I already feel like this coreutils "rewrite" is insane in scope. That said, yes it would be great to remove/clean up args, fix the pipe stuff to be in a more computer readable form for both speed and I'd imagine even more powerful commands. Heck even a new shell/terminal-emulator with full color support and ability to display images (think graphs and all) would be cool, but that's a topic for another time :) I'd be happy to discuss this further and possibly change the direction of the project though, it's just an experiment at this point, and if anyone is interested in pushing things further in some smart way I am all for it.
Pardon, my ignorance, but was the typical use case for `do`? I see people in the mailing list mentioning Ruby like constructs etc.
Meetup is not YC, the 'coolest' people they've taken funding from is Union Square Ventures.
&gt; I'd be ok with just removing do entirely, with the option for adding it back in later if we work out that things are too painful without it. Yeah that might be the best way.
Do we mean "portable" as in "it runs on that platform today"? Since LLVM is supported for platforms where there is no .NET support, i would not say that .NET applications are more portable than native ones.
To be honest I've never attend any. But as far as I am concerned this is just bottom up initiative. Some enthusiasts in Malmo/Lund area are organizing meetup to talk about Rust. I am planning to attend and I thought if anybody here is interested maybe would like to join too.
I see it on RESless computers, so it appears to be something done by reddit proper.
A bit of digging led me to this https://github.com/reddit/reddit/commit/252437da170d2505a0c8dab7b40b1c6687f695da. Seems that Reddit's using this service http://embed.ly/ to make those things.
Nice code. It's very inspiring for me to fix some of my ugly code. But I have to ask, does `fail!` cascade? What happens if my code calls your code and you do `fail!`? Or if you call a translator that has emitted `fail!`? 
So my thoughts on this was - how would one go about increasing speed of Rust bootstrap, to allow faster, iterative development on the Rust source? 
Doesn't each significant change to rust from master require a bootstrap of rust? I.e. clean folder, do full rebuild, etc. Assuming, you are building rust from source ofc.
&gt;The main reason for "do"'s existence is to make task spawning look nice. The closure inference was removed throughout the language because it masked allocation and doesn't work well with custom smart pointers. If "do" is still causing confusion, I'd rather just remove it entirely. [source](https://mail.mozilla.org/pipermail/rust-dev/2013-November/007005.html)
I think Niko is wrong: the SST solution can be made to work for vectors just fine. What you need to do is make the vector size a **run-time** value and instead of doing the current "static" monomorphization, you monomorphize in a way that turns it into a run-time variable. Then, when you drop the vector, the vector length simply ends up being passed to drop() and it all works simply. It would be implemented like this: impl&lt;T, n: int&gt; Drop for [T, n] { fn drop(self) { // here T is specialized at compile time // but n is a run-time variable! // and it all works! // (of course, this is a compiler built-in in reality) } } Indexing works similarly, with the bounds check being done against the run-time variable n. For objects, the same thing can be done by passing a run-time vtable variable as it is done with current trait objects. Of course it requires a lot of additions to the compiler to actually work. 
What happens if you had, say, impl Drop for [T, .. 2] { ... } impl Drop for [T, .. 4] { ... } i.e. the size wasn't a constant and so there were entirely different `drop` implementations, differing in more than just `n`. (FWIW, he does address this with "`erased`" under "Why SST just doesn’t work with vector types.": &gt; I thus proposed that a solution might lie in formalizing this idea by permitting a type parameter T to be labeled erased, which would cause the compiler to guarantee that the generated code will be identical no matter what type T is instantiated with. so in your example the `n` would have to be marked `erased`.)
Strings are not much more than a wrapper around byte vectors providing a guarantee that the contents are valid UTF-8. Other than the type names, I don't think there's much to be confused about. Slices are an immutable view of a string and unique strings are dynamic arrays that can be mutated and resized. Is there an issue with them other than the confusing reuse of `str` and sigils in the names?
Why do you have to iterate over them to get a char? Why not have stack allocation? Why not differentiate between a u8 which means a UTF8 byte and a u8 which means an 8bit unsigned int? 
&gt; Why do you have to iterate over them to get a char? Because UTF8 is a variable width encoding, some code points are encoded one byte (i.e. all ascii characters) while others are up to 4 bytes long. &gt; Why not have stack allocation? How would this work? Modifying a string in place is dangerous/hard to get right (one has to mantain the UTF8 invariant), and a stack allocated string can't be dynamically extended, so having a stack allocated string doesn't offer a lot over just having (possibly mutable) dynamic heap strings and immutable static strings. &gt; Why not differentiate between a u8 which means a UTF8 byte and a u8 which means an 8bit unsigned int? Why would this be useful? e.g. the byte 195 is valid in UTF8, but only with certain following bytes: `195 20` is not valid, but `195 182` is (that's ö, fwiw).
&gt; It simply generates code that takes into account any difference at run-time (which of course may involve computing struct field offset dynamically and so on). We tried that (intensional type analysis) in early versions of Rust. It was incredibly slow and error-prone.
If you want to write it this way, you need to encapsulate the shared state `a` and `b` somehow, perhaps using two `Rc&lt;RefCell&lt;int&gt;&gt;`. This is not particularly well documented, mainly because this isn't idiomatic Rust. (What Go is doing is implicitly converting `a` and `b` to garbage-collected heap cells. That must be done explicitly in Rust, using `Rc&lt;RefCell&lt;&gt;&gt;` in master, soon to be just `Rc&lt;Cell&lt;&gt;&gt;`. Rust makes the fact that this is an extremely inefficient way of computing Fibonacci sequences very apparent :)) There is no solution involving lifetimes. Lifetimes are designed to tell the compiler about the stack discipline that you're already following: if you aren't using stack discipline in the first place, then lifetimes won't help you. Another way to think about it is that lifetimes only let the compiler check that you're doing things properly: they never change where variables are located. To put the closed-over variables on the heap where they need to be for your program to work, you need to explicitly put them there and arrange for them to be destroyed at the right time, perhaps with `Rc`.
Thanks for the reply! I'm working on digesting the `rc` and `cell` modules now, but is there some reason `~int` isn't allowed, as in the following? It puts `a` and `b` on the heap as required and I really expected it to work when I first tried it (or at least give different errors). fn fib() -&gt; ~fn() -&gt; int { let mut a = ~0; let mut b = ~1; || -&gt; int { let tmp = *b; *b = *a + *b; *a = tmp; *a } } Although this kind of thing doesn't come up much in real-world code, I'm trying to figure out an elegant way to express infinite sequences in Rust for Project Euler problems. Would it be more idiomatic to send the sequence down a synchronous channel or is that another Go-centric idea? Or maybe using futures would be better?
[I used iterators](https://github.com/cmr/rust-examples/tree/master/euler). The reason your example doesn't work is that it would require moving the values a and b into the closure's environment. This isn't allowed, since the closure could be called more than once (on master, `proc`s lift this restriction, as they are only callable once). You could borrow the values mutably, but that isn't safe because you're returning the closure, and the values (a and b) would be destroyed on the return of `fib`.
&gt; procs lift this restriction, as they are only callable once (Note that this means that the example above *cannot* be written using either type of closure that Rust has sugar for.)
`char` is a unicode [code point](http://en.wikipedia.org/wiki/Code_point), UTF-8 is just one way of representing a sequence of such code points on disk/in memory. `~[char]` actually corresponds to the [UCS-4](http://en.wikipedia.org/wiki/UCS-4) encoding, which has the "advantage" of things like O(1) code point length, and O(1) random access to code points, but the disadvantage of 4&amp;times; memory use for ASCII strings over the UTF-8 encoding (and, in general, increased memory use for almost all strings, since most languages have all their characters encodable in 3 or fewer bytes). "Advantage" is quoted like that because length/random access to code points isn't actually super useful (and it is likely to be incorrect, in the general case): a code point does not correspond to a visible character, so accessing the `n`th code point isn't necessarily going to be the `n`th thing on screen, nor does a string with 5 code points necessarily correspond to 5 visible characters. Extreme example (infamous ["zalgo" text](http://eeemo.net/)): &gt; T̷ḥ͍͞i̺̖͇s̪̝͓͉ ̷͚ṯ̹̀ͅe̥x̩̖ͅt͘ ̺̣̩͝c̗̙̟o͈̣͖ņ̘̦͍s̘i̝̦̮s̘t̲s̩̠͞ ̶̞̟̲o̢͉f̪̻̖͜ ͕͉̹̞13̬̗̣͎9̼̝̜ͅ ̙̻̣̦c̲o̫̬͓͇d̹̲̯e̺̳̠͢po̜͖̬͢i̙͍̝̗ǹ͙͔̮ṯ̹̻̙ș̻̣͢.̖ ([screenshot](http://i.imgur.com/GWJWetz.png).) That is, in human terms, UCS-4 is also a variable width encoding of actual visible characters. (In summary, most of the complexity in Rust strings (and strings in most languages) is due to the fundamental complexity of representing human text.)
That was a very informative post, but what are the negative aspects of having `str` emitting a `~[char]`, other than displaying some invisible characters and non-normalized characters? I think the /u/saosebastiao wants random or custom access to underlying unicode code points. Not wanting iterators is a valid sentiment: &gt; And the more I think about iterators, the more I really wonder if they have any place in a public API. At all. &gt;For a while, I thought that being able to traverse a collection without exposing the underlying container sounded like a good idea, so instead of returning a List or a Set, you just return an iterator. I could buy that, although I found that in practice, iterators are pretty hard to manipulate, and as soon as you find yourself needing more sophisticated access to the underlying container (such as the size of the sequence, or random access to its elements), you quickly replace your iterator with a collection exposing the richer interface you need. http://beust.com/weblog/2010/06/17/iterators-they-still-make-these/ Note: these aren't my opinions, I just think it *might* be a good idea to allow more malleable ways of accessing data.
I guess I don't understand what you mean by "emitting `~[char]`" since I covered at least one disadvantage of using `~[char]` for `~str` (memory usage) as well as going into detail about why one should *not* be handling text at the individual code point level unless you're sure you need to, and be careful about it. (Also, Rust's iterators are not like C++ ones, in that a Rust iterator is a single object and is actually just a type implementing a certain trait, so you can just put more methods on this type for the enhanced functionality.) Lastly, there are already the more "malleable" ways to access data: one can easily collect the `char`s of a string into a vector to get the dubious/rare advantage of fast random codepoint access if you really need it. Iterators compose well for that sort of behaviour. (`let cp_vec: ~[char] = my_string.chars().collect();`)
Oh yeah, you can't use the closure syntax either. The reason is that `||` captures by reference, and references can't outlive their stack frame. You'll need to package the values up into a `struct` and implement a method on that struct. Sorry.
I'm not sure if you understood what I mean. I mean that if you have code like this: struct Foo&lt;T: Duck, n: int&gt; { a: T b: [f64, ..n] c: u64 d: T e: u32 } fn func&lt;T&gt;(v: &amp;Foo&lt;T&gt;): u32 { v.d.quack(666); return v.e; } Then you can generate a version of func that works for all T and n, by generating bytecode equivalent to the following C code: uint32_t func(rust_vtable_for_Duck* T, size_t n, void* v) { T-&gt;quack((char*)v + T-&gt;size + n * sizeof(double) + sizeof(uint64_t), 666); return *(uint32_t*)((char*)v + T-&gt;size + n * sizeof(double) + sizeof(uint64_t) + T-&gt;size); } [NOTE: this assumes that all types have an alignment of 1: the actual code would need to include bitwise ands to handle struct field alignment] Of course this is slower than specializing for a specific T and n; however, for things like deref() in smart pointers, the code would actually be the same since T and n are never used (in smart pointers, they would be used only in construction and destruction). So, once you add the ability to do this to the compiler, you can also add existential types and thus make Niko's "SST" proposal work. 
I think the questions raised in the meeting about what happens with `~` when you introduce `box` deserve more thinking about. Though I have to say I disagree totally with dherman that the fact `new` is familiar to programmers is a strong advantage. Firstly, as discussed in the mailing list the semantics actually are different. Secondly, learning the meaning of a new keyword is not a difficult task and is made even easier if the keyword name is chosen intelligently. I don't see how it makes sense to optimise for programmers who don't spend even half an hour learning the language and guess at the meaning of things, not for the spaces that Rust targets anyway.
&gt; I don't see how it makes sense to optimise for programmers who don't spend even half an hour learning the language and guess at the meaning of things, not for the spaces that Rust targets anyway. I don't really agree with this; we rationalized sigils away with this, but a *lot* of people decide whether the language is worth learning by taking a look at the syntax and judging by first reactions. It's base human nature, maybe, but it's still human nature.
I volunteer to be Chief Curator of Cat Herding! ...anyway, what's the status on libstdc++, then? Does it look like it's going to be removed on Unix or not?
Does this means no Rust on Windows in near future :( ?
Isn't reserving a short, common identifier like `box` too high a price to pay, though?
You already need to jump through a few hoops to get it working currently.
No, Windows support isn't being dropped. Unwinding is quite broken on Windows at the moment though.
True, but it's also hard to predict who your audience is actually going to be and how your goals mesh with theirs. "Comfortable for a C++ programmer" might not be that great if the people who start getting interested in Rust are C programmers who want a more modern language or Ruby/Java programmers who want to start getting close to the metal but have actively shunned C++ because, well, it's C++ (raises hand). C++ programmers already have C++. They've already been given an alternative with D and for the most part haven't taken it. Rust has compelling features over D but I wouldn't be surprised if its fate amongst C++ people ended up the same (I wouldn't be surprised the other way, either). But the rest of us want the same power without all the attendant misery, and I think that's ultimately where the real appeal of Rust is going to pull people in. Which is a long way of saying "there's a good chance that your actual audience won't see 'new' as familiar, they'll see it as weird and reminiscent of that language they were trying to avoid by looking at Rust in the first place". Seems like Go already went through this; their original marketing was geared towards C programmers, but it seems the people who are actually flocking over are Python/Ruby/Java devs.
Well it looks like it'll be either `new` or `box`, and the price is even higher for `new`.
We ran out of time and didn't come to a conclusion on removing it.
You don't realize just how much code bloat and slowness that this scheme caused. It was really really really slow and took forever to compile due to all of the dynamic size calculations. It really is a dead end.
FWIW I was *extremely* confused about the semantics of "new" while reading the giant email thread, precisely because the semantics in C++ are very different. In C++ new "takes" a constructor invocation (in a sense), not a value. The operative thing that "new" does is invoke a constructor (optionally allocating memory first, if you don't use the placement new), whereas in Rust it would basically be primarily about allocation (side note: the fact that the memory allocation function in C++ is called "operator new" whereas the "new operator" is an entirely different thing, is admittedly kind of confusing). Anyway, the point is that "box" or "alloc" seems fine to me. And furthermore, the fact that allocations used to be symbols was one of my main pet peeves with Rust so I'm very happy that it changes. Allocations should *look* expensive.
Wait, I thought that was &amp;?
`ref` binds a name to a reference to a (sub)section of a data structure in a pattern, I.e. match foo { Something(ref x, ref y) =&gt; { … } _ =&gt; { … } }
Since `let` statements also use patterns, the following two examples are equivalent: ``` let x = 5; let y = &amp;x; *y ``` ``` let x = 5; let ref y = x; *y ```
Ah, right.
&gt; No, Windows support isn't being dropped. Unwinding is quite broken on Windows at the moment though. Tbh I don't develop Rust on Windows and I really, couldn't care less - but I wanna see Servo on Windows :D On second thought, I guess as long as you have good enough binaries on Windows, it doesn't matter.
History has proven that no language targeted for systems level programming gets adopted by the industry at large, without being part of an OS vendor SDK. So Rust will have the same fate of D and Go, Modula-2, Modula-3, Oberon, ..., if it doesn't get a first class treatment by an OS vendor. Mozilla could make it a first class language in FirefoxOS to help drive adoption.
These are all good points that I agree with. It's definitely possible that C++ people will move over in droves b/c their needs are being met where they weren't before. My main point is just that it's hard to predict what people are going to do and who is going to actually end up using the language. Optimizing for familiarity to an audience that you don't actually know is going to switch seems like it should take a back seat to just doing 'the right thing', whatever that is. So even though it's ultimately a small little bikeshed, I'm happy that 'box' seems to be the choice over 'new', as it's more descriptive of what's actually happening.
&gt; This has had some support on the ML and I was disappointed that it wasn't mentioned at all in the meeting. Similar arguments against `in` apply to it as well: namely that the order of evaluation is reversed.
Judging by the CSS in this subreddit, at least some people enjoy the sigils though :)
I sure hope you enjoy yours!
Why, thank you. ;)
I was so excited about this at the time that I kept the source and updated it all the way through 0.5: https://github.com/brson/rustray
It's really fascinating to read Sebastian's list of complaints and compare the direction that the language has taken since then. Purity: chucked out, we have better mechanisms for what this used to achieve. Mutable locals: no more, now we require you to opt in to mutability, rather than opt out of it. Mandatory numeric literal suffixes: long since replaced with numeric literal inference (which has some of its own problems, but not anywhere near as bad as the annotation burden that this used to be). And check out these source files! https://mail.mozilla.org/pipermail/rust-dev/attachments/20111209/0f9bd153/attachment-0005.obj Sigil-less strings and vectors (which were all enforced to be dynamically-sized back then), `#` instead of `!` for macros, C-style format strings, `args` as a parameter to main(), anonymous structs, `.rc` files, `const`... Ah, nostalgia. :)
Looks like PR #7 gets it to run on 0.8-pre too. Exciting developments!
Oh my! I did not know that was there.
Oh yes, as a frequent HN commentator I agree with your appraisal. But there are always people itching to start holy wars over languages, and I'm not about to give them any ammo. Aside from keeping things generally pleasant, I have a more selfish reason for this rule. There's already people out there who use Rust's instability and shitty docs as a license to misrepresent it, and when I see that happening I feel an obligation to correct it. Fewer people fuming over perceived slights (*"OMG THEY CALLED GO USERS IMMATURE"*) equals fewer people with a motive to spread misinformation (whether deliberate or otherwise) which equals less work for kibwen.
&gt; Because UTF8 is a variable width encoding, some code points are encoded one byte (i.e. all ascii characters) while others are up to 4 bytes long. This answers the original question of 'why are strings so hard?'
In what way is unwinding broken? Works just fine for me...
Well, the fundamental answer is "human text is hard".
Yes.
"stalked the Internet" is a little over the top for "looked at the about page on the blog". 
Could this pleeease use standard Rust conventions? Pretty please? That would mean: - snake_case local variable and function/method names, not camelCase (this is the most important as it's in the API); - Four (not two) space indents; - Not using parentheses around `if` clauses (e.g. change `if(foo){` to `if foo {`; - Using whitespace around curly braces in all structural places (e.g. change `}else{` to `} else {`, `fn x(...){` to `fn x(...) {`, but maybe not `Struct{x: y}`—that one is not entirely sorted out yet and styles differ); - Using spaces after colons (e.g. `foo: Bar`); - Probably a fair bit more. Largely, I'd just like to establish early precedent for how things should be done, especially with public APIs. I believe it'll make things *much* easier for us in the long term. As it is, this code looks to be distinctly lacking in consistency (even down to using camelCase sometimes and snake_case other times).
"stalked the Internet" is a little over the top for ["glanced at what is literally the first element on the page"](http://i.imgur.com/Jvai96P.png).
Nice series! It's a small disappointment that you presented these ideas as wholly your own, rather than refering to [the source](http://smallcultfollowing.com/babysteps/blog/2013/04/30/dynamically-sized-types/#comment-1131233956) ;-) Anyway, I've been thinking about this for quite some time, and about the problem you signal in part 3, I had also thought about that. The idea of monomorphization is that you have some type parameter and you generate a different version of each function at compile time for each different instantiation of that type parameter. That doesn't work when here you have the vector's length instead because there are infinitely many integers. Actually, that problem with monomorphization even pops up with types. If you have [polymorphic recursion](http://en.wikipedia.org/wiki/Polymorphic_recursion) you also need infinitely many instantiations. This is the reason why compilers like MLton that do monomorphization do not support polymorphic recursion. My current solution to the problem is to take a different viewpoint. Instead of thinking about type parameters as being instantiated at compile time, and erasing some parameters selectively, you think about type parameters as *normal parameters that are passed in at run time*. Then to improve efficiency, you selectively move things from run time to compile time. There is a well known technique for doing this, namely staged programming. This way you separate the distinction between type/value from the distinction of compile time/run time. You can have types at run time (which you need for example for polymorphic recursion) and values at compile time (which is useful for all kinds of things -- see the staged programming literature). The result is a system with very few primitive features (dependently typed core + non uniform value representation + staging) that lets you express a whole range of features that are primitive in other languages, like fat pointers, vectors, closures, monomorphization, etc.
I somewhat agree: * snake_case is more readable * four indents are arguable, but understandable * `if foo {` however I don't get. What happens if someone decides to write a `if foo&amp;&amp;bar {`? Won't they need to add parenthesis? * `stuff{` over `stuff {` is negligible difference. I prefer space, but I miss it sometime. Best way to enforcce this is to just have pretty-format on rust and promote it! Updating https://github.com/mozilla/rust/wiki/Note-style-guide might be good as well.
&gt; What happens if someone decides to write a if foo&amp;&amp;bar {? Won't they need to add parenthesis? fn main() { if true &amp;&amp; true { println("nope"); } }
MinGW's table-based unwinding is broken on 32-bit. LLVM and MinGW-w64 have working SEH on 64-bit Windows but Rust doesn't have upstream support for either 64-bit Windows or SEH yet.
It looks like it just shells out to the plumbing commands. It would be nice if it used libgit2 instead.
Ok, but what happens if at some times someone gets a bit more complex logic? if foo &amp;&amp; bar || baz { } Adding clarifying statements would need to be added sooner or later.
Aww, I was hoping it uses or implements git2rs?
Sure, add parens if it makes your code more clear. But for most conditions, the mandatory parens in C and C++ are just noise.
Yes a little bit exaggerated, ok. Nevertheless when i browsed the comments 50% of the comments where concerned whether the author is a woman or not and how to cope with the fact. Not wanting to opening the whole gender discussion here but frankly i didn't care what gender the author is and wanted to read a technical discussion about the content.
It's patented on 32-bit so MinGW doesn't support it there. Only the MinGW-w64 fork has support for both 32-bit and 64-bit.
Are there any plans to make formatting tool similar to gofmt?
Given that Julia was in that thread herself answering questions, I'm glad that other people were willing to step in with the pronoun correction rather than forcing her to waste time and energy providing the corrections herself (or worse, forcing her to silently suffer the indignity of being referred to as the incorrect gender despite ample and obvious evidence to the contrary). Trust me, we're all tired of pronoun battles. But rather than silence those who speak up, the solution is to stop implicitly presuming that people in the tech community are male and either make an attempt to use the correct pronoun or just use gender-neutral terms in the first place. Meanwhile, if you'd like to discuss the blog post further, Julia is hanging out in #rust and #rust-osdev on irc.mozilla.org right now (see the links in the sidebar).
Yes, but no one is actively working on it, and the pretty printer has rotted to the point where it needs a redesign and a rewrite.
How is a three letter keyword "tedious and annoying"? It's just about making sure the allocation is visually easy to pick out, and doesn't get hidden by being just a tiny little symbol next to something else. Symbols and sigils are popular *because* they're don't take up too much visual attention, so using them for something important that people should know about is a mistake, IMO. Allocations are one of the biggest performance concerns in a lot of code (like games), so I'd say it *is* actively harmful in the same sense that unsafe code is (but perhaps to a slightly lesser extent.. but only slightly). Yes, there are cases where you need it, but you should always prefer to not use it (and ideally the aesthetics should reinforce that preference - if you avoid an allocation because you think it's ugly, then that's a win IMO).
&gt; It's just about making sure the allocation is visually easy to pick out, and doesn't get hidden by being just a tiny little symbol next to something else. I think this is the main part we disagree about. (And the reason why it seems like you're vehemently agreeing with me in some other parts.) I think sigils are obvious enough *and* unobtrusive enough. A good balance. But as I said, I don't have a huge problem with the three letter keyword either. I just don't agree with preferring it \*because* it's uglier. (About which again, see the first sentences.)
I think the main issue is that I consider excessive allocation to be a bigger issue than you do. It's one of the most expensive things you can do (and worse: it can cause performance issues "at a distance"), so the language shouldn't go out of its way to make it pretty and easy. I'd rather have someone write a simple loop with unchecked array accesses than allocate memory, for example. It's less likely that the former will cause problems than the latter, in the grand scheme of things.
DWARF-based unwinding on 32-bit windows had been [implemented](https://github.com/mozilla/rust/issues/908) a while ago. Not sure what's the status of unwinding on 64-bit Windows, but Rust doesn't officially support Win64 yet, does it?
OK, we definitely disagree about that (those) too. (Allocation does not have to be expensive either. Many GCs have bump-pointer allocation, for example. Not every application is sensitive to latency or heap size. Rust should cater first and foremost to ones which are, but also shouldn't needlessly alienate ones which aren't.)
I'm confused. What do you mean by "that doesn't mean the MinGW implementation completely works"? Rust on Mingw/Win32 passes all unwinding tests. So what exactly doesn't work? Throwing from msvc-compiled dlls into Rust code? I wouldn't say that is a huge deal, because there are virtually no Windows libraries that use exceptions to communicate errors.
`if ((foo &amp;&amp; bar) || baz)` in C should be written as `if (foo &amp;&amp; bar) || baz` in Rust. Only the outer parens are bad Rust style.
It's certainly ugly code in a lot of places - I wrote it to learn rust, so conventions weren't quite clear to me for a lot of it. Definitely something to fix up at some point, maybe after my exams. The newer the code is, the better the conventions are, but unfortunately the combination makes it quite ugly.
As the creator of this - that's the plan at some point, but I figured it was easier to just use shell commands to start with. It really started out as a small project to learn Rust, it was never intended to get any attention! Now I have to fix it up... guess that's a good thing though.
I've seen http://static.rust-lang.org/doc/master/std/comm/index.html but i am still not sure about the meaning of `std::comm`.
The interesting part starts here: https://github.com/mozilla/rust/pull/10830/files#diff-93004c0bbb8fe237497ddd7a52c6a5a4R11
[Empscripten](https://github.com/kripken/emscripten/wiki) is a LLVM-&gt;JS compiler/translator, that has been associated with Mozilla for a while (possibly even created by Mozilla, I'm not sure), so there's understandably been [interesting in running Rust on it](https://github.com/mozilla/rust/issues/2235).
Yes, exactly that. (Well, the precise details differ, but that's what it's designed for.)
What does the produced JavaScript look like?
The main author seems to be working for Mozilla Research: https://twitter.com/kripken
This is the first code I've ever written in Rust, and I've probably done some unidiomatic things. If you have the time please help me out with some pointers on what I could have done differently. I have probably misunderstood how packages are supposed to be packaged. I started with trying to build the package in rustpkg, but unfortunately I didn't manage to figure out how modules could refer to each other when using rustpkg. That said, NaCl is a really powerful cryptographic library that exposes primitives that are opinionated and minimizes the risk of implementation issues when having a need for cryptography in your application. If the rust community is interested I could create some package for simple secure connections that uses these bindings.
&gt; NaCl's goal is to provide all of the core operations needed to build higher-level cryptographic tools. Are those core operations at a high-enough level that we don't have worry about e.g. side-channel attacks in the Rust code that builds on them?
Bravo! This looks great! Does this rewrite happen to include allowing select() to take heterogeneous sets of Ports?
Looking forward to seeing this progress. High quality crypto is something people are always asking for.
The main author sits right next to me! He's the best.
It's great to see this progressing. We should add support for the triple to rustc and make std work with it.
I noticed in the PR's comments that this removes oneshot Ports/Channels. &gt; I would rather try out not adding oneshots back to begin with. The use case in which they are more efficient is when the creation of the channel is far more common than the usage of the channel. We currently don't have much code that has its bottleneck in that area. &gt; -- achricto If I wrote a tcp server that spawned a task with a port/chan pair per request, wouldn't a oneshot of each be desirable? Or are tasks and pipes expensive enough to create that I shouldn't be spawning them on-the-fly?
It was originally Alon's side project, but he switched to working full-time on it a while back.
Yes, djb has been extremely vocal about side-channel attacks in the past and NaCl has been designed to not have any key dependent code flow, data paths, etc. I would recommend reading the original paper http://cr.yp.to/highspeed/coolnacl-20120725.pdf for more information about these issues. I have attempted to eliminate some potential errors for users of the library by only allowing constant-time comparisons for authentication tags. The actual primitives are all side-channel free (see the paper). 
I am posting this here not because I necessarily agree or disagree with the OP's thesis, but because there seems to be some reasonably intelligent discussion going on in the thread.
Nice find. His point about 'more folks involved in the design' particularly hits close to home. We're a largely community-driven project with relatively few paid developers, many competing interests and a lot of iterative design (firmly in the 'bazaar' mode of development), so we're never going to be clean, simple and beautiful. Sometimes this worries me, but mostly I'm just grateful to be part of something so exciting and I hope that it all comes together into something sensible in the end. The points about Go or Rust winning or losing of course don't bother me much for all the typical reasons: we don't believe we're in the same domain, and we've got our own killer app (servo) and our own motivation.
Unfortunately that's *really* old in Rust terms; predating the FFI changes, and not created with [rust-bindgen](https://github.com/crabtw/rust-bindgen), so it's very hard to update. ([I tried a while ago, it's ugly.](https://github.com/huonw/git2-rs/tree/rustc-d09f569aac99a4ef2f577d288d547504e3dcf588))
Rich Hickey's talk on "[Simple Made Easy][sme]" is also relevant. As /u/brson mentioned, Rust's bazaar mode does not lend itself to the simple idea easily. Comparatively, Go was developed with clear, specific goals. At times, Rust feels like a bunch of PL researchers' thesis project and the complexity seems to be growing. The danger is a C++ / Scala level of complexity where teams dictate language feature subset, style guidelines, and design patterns since there are multiple ways of solving the same problem. This makes code difficult to read between different libraries or teams. However I am fairly biased in this regard, and it's reflected in my language preferences (C, Python, Haskell). Striving for a balance between simplicity and flexibility is a much more difficult route than Go's path. [sme]: http://www.infoq.com/presentations/Simple-Made-Easy
It's common to overestimate the short term, and underestimate the long term. Rust still needs to overcome inertia and library support. After 1.0, it will probably take 2-3 years for a significant number of new projects to be written in Rust. I'm going to guess web dev is the most likely inroad since the community is the least invested in existing tools. By comparison, enterprising gaming companies are heavily invested in graphics support and game engines. Mobile games and apps will still be in Objective-C and Java. Enterprise is not moving off the Java / .NET stack (also hard to hire Rust developers out of college). Embedded and hardware developers are conservative by nature since code can't be easily updated once deployed.
The most likely inroad is IMHO anything that would have otherwise been written in C and C++, since Rust can provide the same performance (well, except for array bound checks, but that could be hacked away at the expense of safety), and is simpler and easier to learn and use. Starting of course from replacing the C++-written Gecko with Servo, which will probably replace all other browser engines since it is secure due to having a language without buffer overflows and use-after-frees, unlike them. As for the rest, garbage-collected-by-default language are to some extent simpler than Rust, so things like Java 8 and C# and JavaScript/CoffeeScript/TypeScript might increase their dominance It's probably going to take another 10 years for C/C++ to finally die for new projects, though. 
&gt; Which will probably replace all other browser engines since it is secure due to having a language without buffer overflows and use-after-frees, unlike them. I wouldn't go that far. I don't know if Servo team can demonstrate that they can rewrite Gecko. Gecko is HUGE. If you want to replace it you are best so doing one module at a time. And again there will be a lot of resistance from people that know C/C++. That said I think there might be inroads into gaming. Rust has proven solid and it can interface rather well with C. So I think whatever you use to write C/C++ is a valid target. Big enterprise AAA games are all well and nice, but change rarely comes from the enterprise, unless you have enough money/incentives to bribe the top into switching. I think if Rust catches on in the small scene as a safer, better C/C++ it could become prime language for game dev. 
&gt; Rust channels can be used as if they have an infinite internal buffer. What this means is that the `send` operation will never block. `Port`s, on the other hand, will block the task if there is no data to be received. Are you sure unbounded channels are so desirable? What happens if e.g producer is piling-up faster than the consumer is able to pop?
&gt; The points about Go or Rust winning or losing of course don't bother me much for all the typical reasons: we don't believe we're in the same domain, and we've got our own killer app (servo) and our own motivation. True. Go seems like a server, admin language, while Rust is definitely into the OS language. I'd love if Rust can escape OOP as much as possible. At the moment you have `struct`s with extension methods. That's awesome and simple. Adding heritability to `struct` would be a boon, but I fear going further than that is falling into a OOP-ish mess. I think `traits` inheriting `struct`s is bad territory because it confuses two elements together. 
Why the doh? It's a fairly obscure library I discovered trawling through `rustpk` issues. No ones born educated.
I agree. I've often stumbled upon the debate of simplicity and people seem to think that "simple language" imply "simple programs". This is, unfortunately, not true. If we look at "complicated" languages such as C and C++, C is simpler than C++ (since C++ is nearly a superset of C) and yet many programs can be written much more easily in C++ (thanks to RAII, templates, and virtual methods). I understand the argument that a language that is too complicated will only confuse developers; and I agree; however even though lambda calculus is a simple language, programs written in it are quite difficult to follow...
Could the parts of rustc that take a relatively short time but have big codebase be excluded from the llvm optimizations?
I think you have to keep in mind the dictum "make it as simple as possible, but no simpler". In other words it's not possible for the solution to be simpler than the problem it's trying to solve. Go succeeded at simplifying itself straight out of its targeted problem domains. Then it accidentally became popular in a different one. 
To be honest the minute they added GC and heavy runtime they left C domain. 
&gt; Go succeeded at simplifying itself straight out of its targeted problem domains. That's actually not true. I recently watched videos from 2009, including the original announcement video, and they always specified the term "systems-level" by saying that it was designed for building systems like web servers and backend software. I doubt that the designers ever had operating systems or embedded systems in mind while designing the language (even though Thompson and Pike were OS people in their previous lives). Their aim was to simplify the development of software like the Google systems they worked on.
According to them GC was a day 1 decision.
Yes, I'm aware of this. Low level programmers can't accept GC or to be precise, they can't accept large runtimes, because resource are rather limited in embedded components.
&gt; far as I know part of their original aim was to be a replacement for C++ … for the kind of software they wrote, not for everything. C++ and scripting languages are not problem domains.
&gt; Aesthetically I'm liking Rust less and less as time goes by What part of it strikes you as 'ugly'? 
[This][1] was the background for what I wrote: &gt; I was asked a few weeks ago, "What was the biggest surprise you encountered rolling out Go?" I knew the answer instantly: Although we expected C++ programmers to see Go as an alternative, instead most Go programmers come from languages like Python and Ruby. Very few come from C++. &gt; We—Ken, Robert and myself—were C++ programmers when we designed a new language to solve the problems that we thought needed to be solved for the kind of software we wrote. It seems almost paradoxical that other C++ programmers don't seem to care. You're completely right that their aim wasn't to "be a replacement for C++", as I wrote: only for the things they were using it for. But they *did* expect a big part of their user base to come from C++, which didn't happen. &gt; C++ and scripting languages are not problem domains. Of course. My apologies for using imprecise language. Thankfully human language has a great tolerance for imprecision, due to humans' sophisticated ability to infer the intended meaning. (C++ and scripting languages are not problem domains, but problem domains and the languages used for solving problems in them are heavily correlated. In particular I believe there is very little overlap between the problem domains C++ is used in and the ones scripting languages are.) Edit: I'll grant that maybe we should make a distinction between *goal* and *expectation*. Their *goal* was to solve their particular problems, which I assume they did; their *expectation* was that it would be popular among C++ programmers in general, which it wasn't. If it wasn't an explicit goal then it obviously can't be thought of as a failure. But I think the moral of the story stays mostly intact (because it didn't really depend on this point): there exist things more important than simplicity, such as capability. [1]: http://commandcenter.blogspot.it/2012/06/less-is-exponentially-more.html
Personally, I haven't explored lifetimes very much, but I still think the syntax for lifetimes is not aesthetically pleasing in my opinion...[I mentioned on the mailing list](https://mail.mozilla.org/pipermail/rust-dev/2013-February/003124.html) an alternative using `#` (hash/pound sign) or at the very least making the lifetime symbol a suffix rather than as a prefix, but the ship had sailed by that point. I'm interested in what /u/smosher has to say on this topic though.
&gt; Yeah, you can run bindgen and get something that works for your particular machine, but now you have Makefile and a clang dependency in your Rust project unless you eyeball the header and decide it happens to be portable. Rust will have a hard time being a replacement for C because it requires Makefiles? C requires Makefiles… &gt; There's also the less severe but more annoying issue that non-blocking Rust tasks don't play nice with external C event loops, which is also one of the reasons Haskell's gtk bindings suck so much. You might be able to write something that approximates sanity, but it will need careful thought. We already solved that problem in Servo by having true 1:1 threads, and we plan to simplify it even further.
&gt; Rust isn't even in the same ball park as C. Rust does not have the implicit conversions and undefined behavior of C. I think it's quite possible to hold Rust in your head to a degree that is not possible with C. &gt; I find it more likely that many C programmers switch to Go as many projects that are written in C don't depend on predictable memory management. That hasn't happened so far. I think most C programs do depend on speed.
I agree with this but I would note that Go is complex in simple ways, whereas Rust is simple in complex ways. What happens on indexing a map with nil is a simple issue. Lifetimes aren't simple. Go has many simple issues, Rust has a handful of complex issues. So if you merely count the bits of information required to describe Go, and the number of bits you need to describe Rust, Rust may be 'simpler' in that sense. However, if you count the number of bits required to describe the things that matter most form a language design perspective, Go is probably 'simpler' in that sense.
I'd just sum up that distinction as "simple vs. easy", as Rich Hickey did. Lifetimes are *simple*—the lifetime rules can be described in just a few sentences [1], and then the rest falls out of subtyping. But they aren't *easy*. [1]: I'll try here: Every reference has a lifetime. Every lifetime has an associated lexical block. References pointing to lifetimes of outer blocks are subtypes of references pointing to lifetimes of inner blocks. It is an error for a value of type `&amp;'a T` to exist outside of the block `'a`.
https://github.com/mozilla/rust/issues/2124 This has been planned for a long time!
Yes, you can express a C function pointer in Rust (like `extern "C" fn(uint)`) and define functions with a foreign ABI. However, since the standard library makes use of unwinding, you can't expose a safe interface taking an arbitrary Rust callback.
Not addressing your main (and valid) point, but Kimundi changed/simplified the iterator names in [#10622](https://github.com/mozilla/rust/pull/10622) (which also includes a cheatsheet for the names changed).
Sorry, does this mean that C library (like the portaudio C library mentioned above) can't callback to a Rust function, or just that it has to do it in an unsafe block of some sort? Really I am trying to figure out if the Portaudio wrapper for Rust did not implement the callback because it's just not implemented yet, or because it is not possible. I suppose I could send the author a message on Github. I have not heard the term unwinding before, but I do understand things like the difference between calling conventions and name mangling, etc.
`.chars()` is the new name for `.iter()` on `&amp;str`; and it's literally just a rename, so changing the method name should be the only change necessary.
Oops, I for some reason glossed over that and only saw `char_indices`, and not `iters() -&gt; chars()`. Thanks for your help :)
Well, isn't Rust's name resolution rather complex and not needed to solve those two problems?
&gt; And again there will be a lot of resistance from people that know C/C++. That actually hasn't happened a lot in my experience. If anything, Gecko engineers tend to be surprised that we're as flexible and low-level as we are. I've had Gecko engineers tell me they'd prefer to not have `MutexArc` at all, for example. There isn't as much love of C++ as you'd think from Gecko engineering. I believe Blink is the same way—Alex Russell from Google has talked about "suffering with C++". Of course I can't speak for all browser developers, and this is an incredibly broad overgeneralization that I am likely to get in trouble for :) But I think, all in all, the game developers are the ones who love C++. Browser developers tend to just put up with it.
&gt; We're resisting very popular things like once fn because of simplicity Wouldn't `&amp;once fn` reduce the complexity of code? I struggle to use monadic HOFs with `Option` and `Result` due to move/borrow errors, leading me to have to use `match`. Of course there might be other simpler ways to fix these problems without adding a new `fn` type - I don't know.
sorry, that makes sense. 
Simplicity in the way the OP describes is all about omitting features in a way that makes code less convenient. To take your example, you can't even write higher order functions like `map` in Go at all, because of the lack of generics.
Thanks, I have updated it! Seems like rusti isn't always up to the point.
I think Brian was a bit pessimistic here.
rusti-the-IRC-bot is currently running Rust 0.8 because the sandboxing stuff got broken somewhere along the way and hasn't been fixed yet.
Aesthetics is the science of art, beauty and taste. Apparently the phrase "Aesthetically I'm liking Rust less and less" implies you consider some of its code not beautiful, but ugly.
I still think a lot of it is the lack of documentation. Of course, even if it's documented, if people will have more of a propensity to use `~` than `box`, the fact that many won't read the documentation properly but will just use it would suggest that `box` should be used instead of `~`. But that's still an assumption, that the natural propensity to use `~` will be higher than for `box`; I don't know if that assumption is valid or not, though I suspect it is.
You are correct; thanks. I have now fixed it.
Both heavy runtime and GC are optional in Rust. No GC and 1:1 threading (no heavy runtime) is going to be the default. 
It should just call unwrap() or expect() on the file option instead of reimplementing it with pattern matching. 
This is also due to lack of autoref. The user should have to just write Path::new instead of &amp;Path::new. 
I'm really nervous about adding more magic like that. This is one of the properties of C++ references that a lot of people don't like.
You need to rate-limit the producer somehow. This hazard is better than deadlocks though.
Please include perf, which is apparently currently the best way to profile Rust on Linux.
The problem in the first place here is auto-referencing from unique pointers to references. The magic obviously makes this less clear, and adding more doesn't seem like a solution to me.
I think people like it for `const &amp;` but hate it for `&amp;`. The Google C++ style guide forbids using `&amp;` in function signatures because they view nullability (when you don't want it) as less bad than hidden mutation.
Awesome! I definitely will. Do you think Pintools as well?
I don't want to get into distro wankery, but why Arch, if for reasons other than personal preference or familiarity?
It's the only distribution with a pre-built `rust` package in the official repositories. It has a nightly `rust-git` package provided on the official Arch build server, and the latest stable release of every package such as `linux`, `perf`, `valgrind`, `glibc` and any libraries you may want to use. Since it's free of branding or patches that weren't accepted upstream, there's nothing unique to learn beyond the package manager.
`gdb` would be good.
Now, yes; but before, it wasn't so good.
What I think this might lead to, is allowing multiple inheritance of implementation. Those are always nasty to sort through. But what I fear especially is having Scala like trait stacking, where order of definition changes behavior. Because having to worry about traits collision isn't enough, now you have to worry about order in which you define them.
I think this is a much better style of teaching, and plan on extending this a lot more. Any feedback is welcome!
Cool! In general, I prefer to limit the declaration of variables to the scope they're used. For example, line 25: `let s = str::from_utf8_slice(buf);` could be moved after line 27 `Some(nread)`, while maintaining the same program semantics.
All these threads about Option/Result APIs have helped me finally understand the point of monads.
That does look pretty bad, what OS &amp; browser?
C# will have monadic Null-Checking: http://adamralph.com/2013/12/06/ndc-diary-day-3/
I've only read the first 9 chapters, but it's pretty good so far. However: * The g++ and clang prereqs don't have "or later" on them; whereas the other ones do. Does rust not work with the latest versions? * The paragraph at the end of "Compiling your first program" seems a bit out of place. You can probably move the bit about non-declaration code to "Expressions and semicolons" where you explain what a declaration is. * You introduce static items in "Syntax basics" without explaining what they are. * There's a stray backtick before `f32` in the paragraph after the code example in "Primitive types and literals". * The "Loops" section should discuss for loops. * The "Functions" section should mention overloading. * In "Move semantics" you should mention that conditional moves will still make the old variable unavailable even if the condition isn't taken (e.g. `let b=if *a==3 {a} else {~10};` invalidates `a` even if it's not `3`). This can be surprising especially because C++11's `std::move` doesn't work like this.
OTOH nobody likes to see something like this in the middle of running someone else's code either: Prelude&gt; head [] *** Exception: Prelude.head: empty list
(Note that only the linked chapter (i.e. 9) was subject to the rework in question here; not saying the other points aren't valid, just that the rest of the tutorial hasn't had a lot of work on it.) &gt; This can be surprising especially because C++11's std::move doesn't work like this. How does `std::move` work then? Does it have runtime checks? e.g. auto b = cond ? std::move(a) : c; return a; // what happens when cond is true?
As I understand this is a minimalist version of an irc bot but I think it should at least answer to PING requests otherwise it won't stay connected for too long:)
Wow, that's really cool! :)
thx. Now much shallower indents.
Zoom + Chrom{e,ium} (+ Linux?) has never looked good.
It’s a blance to find: do you think the tersness is worth doubling the API surface? (ie. having both from_utf8() and from_utf8_opt())
(Bounded buffers do natively offer with that rate-limiting.) The fact that incorrect concurrent sequences can lead to deadlock with bounded buffers is indeed "infortunate", but unlimited buffering doesn't also really exist (in any real resources-constrained world). Any system that requires unbounded buffers to not deadlocks might also be considered suspicious at first. What puzzle me is that unbounded buffers thus sound (to me) like an illusion (because buffers actually are RAM-bounded so just bounded), and also like an unnecessary latent memory leak because ..well, if a system could have a correct behaviour with a bounded amount of RAM (which I think it should), then it would just work with bounded buffers (and a leak wouldn't have to compensate for a sequence flaw. I know Erlang has that same `unbounded buffer' approach, but I've eventually always been uncertain about how this is the easiest model to program against. Go on is side went for the bounded buffer approach, which admittedly surprised me at first, and may be considered has kind of beneficial in the sense that such nasty issues are eventually just catch earlier. Those are obviously just random thoughts, but unlimited [you name it] always make me feel a bit suspicious;)
Why is this .? operator called 'monadic', btw?
You're right, I need to add that after I figure out how to read single lines from the buffer...
C++ doesn't have affine types or static checking of moves. Every type implements its own move constructor, with whatever semantics for use-after-move it feels like. I think it's generally expected that the object is still in a valid state after the move (but I haven't touched C++11 in a while so not 100% sure). (So `a` will be returned, which will be an object in whatever state the move constructor left it in.)
`std::move` doesn't remove variables from the scope, it just changes their value; how it does so depends on what type the variable is. Moving from a `unique_ptr` will always nullify the moved-from pointer, moving from a `string` will leave it in some unspecified valid state. Each type has its own guarantees (though in practice, most of them go to some sort of empty state). In you example, if `a` was a string it would likely either be the empty string or have its old value.
The only new content here is the *Implementing a linked list* section the link points to. I haven't rewritten the whole tutorial and am only the author of a few other sections. I'm not really interested in making minor fixes to the rest of the tutorial, as I think most of it needs to be completely thrown out. &gt; The "Loops" section should discuss for loops. This is covered in the iterator tutorial rather than the tutorial. It's linked to at the bottom. &gt; The "Functions" section should mention overloading. There's no function overloading. &gt; In "Move semantics" you should mention that conditional moves will still make the old variable unavailable even if the condition isn't taken (e.g. `let b=if *a==3 {a} else {~10};` invalidates `a` even if it's not `3`). This can be surprising especially because C++11's `std::move` doesn't work like this. This should probably be mentioned, but I don't think that it's *surprising*. Rust forbids accessing a variable that has been moved from, so it has to forbid it whenever it could be moved from. It's not different than how preventing uninitialized variables works. C++ doesn't attempt to forbid accessing variables that have been moved from or uninitialized variables at all.
Any word on potentially adding something similar to Haskell's `do`, or Scala's `for` to deal with monads? /u/pcwalton?
The `Option` one would be the default in most cases, so I don't think calling `get` is too much to ask. It's only 5 extra characters.
&gt; Go on is side went for the bounded buffer approach, which admittedly surprised me at first, and may be considered has kind of beneficial in the sense that such nasty issues are eventually just catch earlier. They aren't necessarily caught earlier. There can be issues in which you only uncover the deadlocks when, for example, the user submits input overflowing the size of your buffer. Your automated tests may not discover this.
emscripten usually generates unreadable and huge `asm.js` but it's pretty optimized for what it does.
&gt; *N* Rusties Attending Quick opinion polls upon a couple of occasions in #rust have been strongly supportive of the nomenclative application of the term “Rustaceans” to persons developing in Rust and working in the language. I can’t remember who it is that suggested it in the first place.
Some background: ktt3ja worked on this over the last month as his final project for the [CS4414 class](http://rust-class.org/), resulting in a fancy new lint and in [removing almost 1000 lines](https://github.com/mozilla/rust/commit/1755408d1a58684b6c9bce11aeceb18a1ec2d66e) of dead code from the rust repo. (With several modules marked `#[allow(dead_code)]` so others can go through and remove even more code!) Thanks ktt3ja!
Initial work towards a rustfix.
Most of that work is already done, it just needs some cleaning up and a frontend slapped on it. Not going to happen before 1.0 though.
Thanks, Felix. I added your slides to the [wiki](https://github.com/mozilla/rust/wiki/Docs#presentations)
I added some ideas!
I think a rustfmt is far more important than a rustfix. rustfix is of most significant value before 1.0, and it's a bit late for it to be most effectual, while rustfmt will be useful for ever and ever. Amen.
&gt; `Path::new` has been renamed back to `Path::init`. You mean the reverse, right?
Just FYI, I have cmake and rust working swimmingly, but my rustc patches for this haven't landed yet (https://github.com/mozilla/rust/pull/10593) I'll be blogging about this work soon, and you'll see it used in Servo shortly as well.
Its works like Haskell's Maybe monad.
regexp support!!!!
It could also be nice with direct links from the documentation to the implementation at github.
Note that there are `[src]` links already there. (These link to a static copy of the source next to the HTML docs on the webserver; was github a fundamental part of this suggestion?)
It does for non-built-in types (e.g. [Option](http://static.rust-lang.org/doc/master/std/option/enum.Option.html)), although not necessarily in the most digestible form; but it is a *killer* for built-ins like `str`, `[]` and the number types (this is [#10114](https://github.com/mozilla/rust/issues/10114) if anyone wishes to keep track).
Oh! That's annoying. ([Filed a bug](https://github.com/mozilla/rust/issues/10896).)
&gt; Rustaceans What is the etymology and how is it pronounced? I like Rustafarians.
This is an ancient version of Rust (0.7) though.
It's now fixed, thanks for pointing it out.
It's still nice :D Well until we get Rust.js via Emscripten working ;)
To your other point, it a play on [crustacean](http://en.m.wikipedia.org/wiki/Crustacean), like a lobster. I would pronounce it rust-a-shin. I kind of like it. I think I'm going to start using it.
Be our secret Santa :D
Not to mention that rustfix would rely on lots of the same innards as rustfmt...
Creating a canonical 'cookbook' type reference is something I'd like organized at some point. This is the type of thing that it's easy for people to contribute to in small bits, and I know I've seen a few other attempts at similar things. It would be great for one of these efforts to gain momentum, subsume and integrate all other outstanding cookbook-style material.
What is "tvland"?
Rust 1.0 + Rust.js-Emscripten could make a nice base for a web-framework were you write client and server code in Rust!
It refers to those in the meeting who are working remotely, as they appear on a TV screen in the conference room.
Sorry for being cute in the notes; I'll try to avoid it in the future.
I can take a poke at it, though I don't know much about gdb's internals and even less about DWARF.
Not sure if it would be appropriate to start a new thread so I figured I'd add a comment. The bot has been updated to Master and I was able to rewrite a bunch of the functionality to make the code more concise (and add the proper response to PING!)
Thanks for writing them down in the first place.
Of course, if I wasn't willing to shave that yak I would have just given up. It's been great fun and I"ve learned somewhat more about RFC 2616 in particular than I had *quite* paid attention to in earlier readings of it.
I feel like nobody in the `enum mod` discussion really understood why people are requesting it. Personally, I've started using the workaround implementation for `enum mod`, because I have a number of different enums in the same library (and a couple of them even have variants named the same [for a good reason]). It's much better than bare enums, but a real `enum mod` would be even better.
For context, Jack is a Mozilla Research employee who divides his time between Servo and Mozilla's upcoming Daala video codec.
This all looks very good. Over the past few days I've been mucking about with Makefiles and rust code and have been wanting `--dep-info`. My only worry is that inferring the pkgid from the current filename will lead to a lot of libraries with the same hash, because their filename is `lib.rs`. Could it not fall back to using the old collection of link attributes? If someone needs predictable naming, they can use `#[pkgid]`. Otherwise, avoiding collisions seems like a good idea.
Assuming that the names are the result of a deterministic calculation, couldn't the compiler simply tell what the generated lib name will be when using a specific argument (--tell-me-the-lib-names-pretty-please)? In that case it does not really matter how complicated it is to calculate the name and everyone will be happy and not much have to be changed? Maybe I am oversimplifying things.
I feel like we should learn from C#. C#, like Rust, compiles multiple source files to one output, and uses unpredictable file names.
That was my first thought too, but I'm not sure how much work it takes to figure out the library name when the hash is computed from the link attributes and dependencies.
When compiling most projects, you don't invoke the compiler to find out what the resulting name is. You can figure it out yourself, and tell your build system what it is. Rust making it so you need to invoke the compiler just to find out the library name is ugly. With the change for predictable hashing you don't need to reimplement the hash yourself if you don't want to, you could just build once by hand and look at the filename. With the predictable hashing you know the filename won't change unless you change the `#[pkgid]`. Without it, the filename may change when you do things like add `extern mod` declarations.
Agreed on multiple source files to one output. But, what unpredictable part are you talking about? C# respects the output file name requested. Or were you referring to shared assemblies installed into the GAC? In that case, IIRC, they're installed to a folder that is basically: &lt;GAC&gt;\assembly_name_VERSION_pubkey\filename The pubkey is _not_ a hash. It's the public key associated with the key you used to sign the assembly. I don't think unsigned assemblies could be placed in the GAC without using some developer-only tomfoolery, though in that case you'd get some weird paths. If you're doing that, though, you probably are a CLR dev and were using a local GAC and purge it on clean builds anyway. Regardless, you should *never* be directly accessing directories from the GAC by filesystem path, but instead should be looking them up using reflection APIs like `Assembly.Location`. (some of the path details may have changed - I was in DevDiv and, among other stuff, contributed to the MSBuild object model, but left before the extensive SxS changes post-2007). It's also important to be careful about what you learn from C# from a tooling perspective by looking at CSC.EXE. Like the rest of the MS compilers, it's a library with a bunch of APIs designed for hosting inside of MSBuild, VisualStudio, and incidentally also the commandline interface. So, there's a bunch of stuff that build tools can know and do that (at least at the time) was non-trivial to impossible to know from CSC.EXE.
I personally would accept a patch to rustc that output the filenames. It would look very similar to my --dep-info patch. If someone is willing to work on it, I'm happy to mentor (if needed).
I thought this article from February 2011 is interesting from the perspective of Rust because it describes three problems with C++/Java/C# style class based programming that Rust seems to tackle: &gt; - Pervasive mutable state. &gt; - Indirect support for closures. &gt; - No algebraic data types. Interestingly his conclusion is: &gt; Note that fixing those three mistakes (pervasive mutable state, no closures, no pattern matching) turns Java into ML. Also remember that [class based programming is syntactic sugar over records and closures](http://loup-vaillant.fr/articles/classes-as-syntactic-sugar). Fixing those things in C++ turns it into a Rust-like language (of course with tons of cruft and a broken type system, heh).
The problem with using the dependencies in the hash is that you often change dependencies during development. This means that the build system has to determine all the dependencies just to know the name of a file; it must do this a lot. No other build system seems to work this way and the benefit for bucking the trend here seems miniscule. However, now that we don't need to do that, spitting out the filename based on a command line flag is pretty easy and totally something you could do in a build system. It's not free, but it's probably not going to be very noticeable. Systems like Tup will cache this anyway and not have to do it everytime.
rustpkg has been a real pain lately. I'm really considering moving my projects back to makefiles. :(
This has inspired me to [start my own list](https://etherpad.mozilla.org/k14brBnFZa) - feel free to add anything I've forgotten (if you remember me mentioning it in a `#rust*` IRC channel).
How's a closure different from an object with a method called apply? class FunctionComposition(Function f, Function g) implements Function { def apply(arg) { return f.apply(g.apply(arg)); } } &gt; It shouldn't matter if the value is a function or an integer. What's the reason for this claim? For the user? For the compiler? &gt; there is no reason to treat methods and member variables differently, and functions should be objects. IIRC, the former part is what Newspeak does. It has primitive functions, however. Pretty much agree on the ADTs, I think. In general, the assumption that OOP sucks because Java/C++ suck (do they even suck? I don't know, they seem to be very useful for many people..) is fundamentally broken.
:( aww What has been the issue with rustpkg? (Other than it doesn't work on Windows) 
Not only C#. I think compilers for module based languages like Ada and Modula-3, could also be valuable.
OOP is not restricted to "class-based programming". A quick example is JS, in which almost everything is an object and only two values can't be used as objects (`undefined` and `null`). But only ES6 add classes, and they're just syntax sugar for the prototype inheritance model.
yet Scala is clearly not ML, as the conclusion states.
Installing/uninstalling libs is tricky, linking with external dependencies both from external repos or from local directories is hard, working with more complex directory structures with examples and internal/external test-suites is nigh impossible, it sometimes doesn't rebuild source code because it thinks it's already been built, you can't pass linker arguments to it...
Sounds a lot like TermKit https://github.com/unconed/TermKit It would be awesome to have it implemented in rust, and have it run on linux!
Not really; here I am not talking about the terminal but about the traditional Unix programs (such as `ls`, `grep`, ...)
`[T]` isn't a type, `str` isn't a type (`str` is kinda like `[u8]`). The type of `[b]` is `[SomeStruct, ..1]`, eg. a vector with a fixed, known size of 1. `~`, `@`, `&amp;` imply indirection, e.g. `~[T]`, "here's a pointer behind which there's a vector of a bunch of `T` and a field that says how many". For things that have no fixed size, you can't have them as types without indirection because the size needs to be known at compile time (so the layout in memory is known for codegen, etc). (`*[T]` doesn't exist either, but for types, where the size is known, `*T` is also indirection.) If you can write your program without using the pointer sigils, it just means you're avoiding indirection, and move/copy values around instead of passing pointers to the values. Usually that is a good thing, it probably means your program is easier to reason about, and in some cases it's a bad thing, if you pass around huge objects or arrays by value and the copies end up costing you too much. But sometimes it is not an option at all, if you need recursive types or dynamically-sized vectors for example, or shared ownership. That's a much clearer case than "hmm maybe it'll take a long time copying? I dunno?" so that's our motivating example. (ps. like half of this is subject to change, http://smallcultfollowing.com/babysteps/blog/2013/11/26/thoughts-on-dst-1/ etc, but that's probably advanced reading)
So basically, no boxes -&gt; value semantics. Am I using stack? I'm unsure if I need to worry about consuming too much room when allocating at run time (even though the program is logically sound). Other than copying cost that comes with value semantics, are there downsides?
But that's exactly the source of my questions. The tutorials on rust-lang only suggest pointers/boxes as a way out of circular references (esp. with recursive structures, as in List referencing List in the tutorial). But these are not necessary, you can always avoid them (as shown by f# language) without loss of expressiveness or growth of complexity. So I wonder if it was just a throwback to C++ so those with such experience coming over won't immediately reject the language or if there is an actual problem with not using all the pointer/box types.
If you're familiar with C++, this might help: https://github.com/mozilla/rust/wiki/Rust-for-CXX-programmers
Using `&amp;` is pretty much non-optional in any non-trivial code because it's the way to pass data around without moving ownership. This means you can pass a field in a struct to a function or method without moving it out of the struct (which renders the struct unusable afterwards). 
Yes, rust uses a C-style call stack. It might run out eventualy. I'm not sure whether the plan is for controlled unwinding or just `abort()` at that point. I think the main cost is going to be the reduced flexibility in implementing data structures and algorithms. No arrays or lists or anything. And of a lot of the stdlib is probably unusable if you refrain from calling methods defined on `&amp;self`.
Only `*` and `&amp;` are fundamental to the language, the full functionality of `~` (very easily) and `@` (probably does require a little compiler magic) can be implemented in terms of them; and of those two, `&amp;` is the one that is really needed for the interesting part of Rust's semantics. &gt; I write a complete program that does not use any of those things, are there averse effects? Does it change whether things are on stack/heap, does it change value/reference semantics? - Doing it with none of the 4 will be very hard (everything will either be in static data in the executable, or on the stack and everything will be passed by value, there's no possibility for borrowing). - just `*` is essentially writing C in terms of pointer safety. - just `&amp;` is actually not completely insane: everything will be on the stack or in static data, but you have both value and reference semantics, and the full lifetime/borrowing analysis that makes Rust memory safe. (EDIT: I had written "the full functionality of `*`" rather than "... of `~`".)
You wanted /r/playrust.
Hehe, woops. Thanks, sorry about that.
John is the my very favorite professor and this is my very favorite presentation about Rust macros.
Ah, thanks, I knew there was an example, but didn't remember enough to be able to find it. It's [fempeg](https://github.com/pcwalton/fempeg), which hasn't been updated in more than a year, but Rust's no-heap support has strictly improved in that time.
Not any form of pointers, just `~` boxes.
&gt; If I write a complete program that does not use any of those things, are there averse effects? Does it change whether things are on stack/heap, does it change value/reference semantics? My advice for beginners is: Ignore `@`, as it's feature gated and going away, and ignore `*`, as it's mostly just there for calling C code. Understand `&amp;` and `~` first. My suggestion is to read `&amp;` as "reference" (as its primary use is to change value/reference semantics) and to read `~` as "box" (as you use `box` to construct it once the PR lands anyway; it changes whether things go onto the stack or the heap). &gt; There is something non-trivial going on, because while I can have a function accept SomeStruct as a parameter, it appears I can't have a function that accepts [SomeStruct], I need something like ~[SomeStruct], even though I can say: Arrays and strings are *dynamically sized types* in Rust. The language has a restriction on dynamically sized types, in that they can only be passed by reference or pointer. In most languages, the pointer is implicit; e.g. `std::string` in C++ is `~str` in Rust. However, in Rust, the pointer is explicit. If you want something more like other languages, just use `~str`.
Here is how I did it on Mibbit: /msg NickServ register &lt;password&gt; &lt;email&gt; You will receive a confirmation by email. If you experience that you can't post to the channel, go to the Home tab, click 'Auth', then select NickServ in the drop down and type your password. Then type your nick and channel in the boxes below and click 'Connect'. Edit: Forgot you need to click the 'Auth' link.
&gt; My suggestion is to read &amp; as "reference" We should really purge the docs of the term 'borrowed pointer'.
Moderation has been disabled and we're under attack just now. This thing made my laptop lag and heat up like crazy, had to switch off WiFi to take control back... remote virus ftw.
I have a few questions. What's the purpose of kissdb_close? Is that going to do something in the future? What's the point of the File2 trait? Is that necessary for some reason I don't see?
With the channel having been under attack for twenty minutes or so just now and most of the Americans in bed, it made me think that for the moment at least we may need a wider geographical distribution of people with the power to change the mode (I haven't learned Mozilla's IRC permissions model; is op sufficient?); dbaupp and I come to mind as people that tend to be around for a lot of the PST early hours. (And ten minutes later: uh oh, it's started again…)
kissdb_close takes the db out of the scope so that the file is closed. Without File2 trait, I could not make the code compile. To be more precise, I was able to define fn write_one_hash_table_(mut f : File, ht : &amp;[u64]) but when I tried to use this function, I met a `error: cannot move out of dereference of &amp; pointer`
But the file would go out of scope anyway, eventually, no?
thx. I pushed the change along with others. I felt a bit uncomfortable about the { ... } in the match so I am happy to get rid of it.
Maybe you are right. The existing rust libraries do not have `close` so I removed `kissdb_close`. https://github.com/pirapira/kissdb-rust/commit/caa37240eb86428fece378e3dfd938531b380a30 
Simplicity needs to have a context, in example c is simple due to the somewhat 1-1 mapping of code to asm , c++ is simple due to the features provided at the expense of abstracting away how the machine or code works.
I'd prefer `box` to be a function, and `~x` expression kept as a syntax sugar to box function invocation. Because `box` is verbose and `~y` is used frequently. let x: ~int = ~3; let x: ~int = box(3); // the same Note, in Clay allocation works like this: Clay doesn't have `new` or `box` keyword, and there's `new` function that returns smart pointer to the data that is passed as rvalue in parameter, and moved into allocated area. `box` keyword doesn't solve any problem that is not solvable otherwise, and just complicates the language. **Update:** This seems not to work. See [explanation from pcwalton below](http://www.reddit.com/r/rust/comments/1syapv/implement_the_new_box_syntax_for_unique_pointers/ce2lwej).
The goal is to make it more obvious that memory allocation is being performed, and also allow placement new. 
Do I infer correctly from the final snippet fn main() { let x: ~int = box 3; println!("{}", *x); } that '~' will still be used to represent the owned pointer type? That is to say: are we not moving away from the use of the tilde altogether?
&gt; goal is to make it more obvious that memory allocation is being performed Well, since `~T` type is a pointer, it is easy to come to conclusion that memory is allocated somewhere. Anyway, I'm fine with just removing `~T` type and `~x` expression. I'm mainly opposed to the `box` keyword. &gt; and also allow placement new Rust already has functions similar to placement new in couple of places like `Gc::new` and `Rc::new`. Similarly, `box`keyword could be `Unique::new` and return `Unique&lt;T&gt;`.
Better than `new` for sure, but still weird to look at.
&gt; and ~y is used frequently If you make it too pretty then maybe it will be used frequently, but of course it would be better if it wasn't used frequently. IMO languages should apply gentle syntactic pressure to make expensive things look expensive. 
This is still an open question.
Allocation is not expensive (especially with modern allocators). And in 99% cases either: * cost of allocation does not matter at all * or I have to perform an allocation, even if it is expensive It is like prohibiting floating point division. Anyway, as I said, I'm opposed to `box` being a keyword. I'm indifferent about keeping or removing `~x` expression (pro: it is needed frequently, contra: it can be replaced with library code).
I vehemently disagree. Allocation, and additionally the "sparse" (cache-wasting) data structures that come from relying too much on pointers and allocation (instead of thinking a bit harder and storing things "embedded" within their owner) is by far the biggest reason other high level languages are entirely unsuitable for high performance applications like games. Stomping out unnecessary allocations is a very common optimization technique (or rather, chore) that you absolutely *have* to do to ship games in languages like Java or C#. This is true in C++ as well, to some extent, but since C++ tends to favor embedded data in the first place you hopefully don't end up in quite as much trouble.
Technically, you are right. I think *moving* value *there* is a sufficient replacement of true placement new. LLVM is capable of removing extra move. I did a test: https://gist.github.com/stepancheg/7794096 two version of function, `foo` performs "placement new", and `bar` "moves" value. With optimization turned on, LLVM produces identical asm. So performance is not an issue. Sometimes value cannot be moved, because type is not movable. These cases are extremely rare, and can be dealt with couple lines of code. Such cases do not worth extra keyword IMO.
Answered below.
OK, memory allocation is expensive in some scenarios. Problem of Java is that you cannot do stack allocation, and cannot allocate structure inside another structure, and you cannot turn off GC. Unlike Java, in Rust, even if `~x` or `box x` is super-expensive, you can do profiling, find a bottleneck and fix it. `box x` instead of `~x` doesn't automatically fixes problems, it just adds extra boring typing.
&gt; Allocation is not expensive Allocations (and the consequences of them) *are* expensive, e.g. [two](https://github.com/mozilla/servo/pull/1393) [changes](https://github.com/mozilla/servo/pull/1371) to servo that are essentially just "remove allocations", which give dramatic speed-ups.
Again, disagree. It's not the obvious cost centers that end up causing you problems when you need to optimize a game, it's the "peanut butter costs". I.e. the small inefficiencies that are *everywhere*. These wont' show up at the top of any profiling list, but *in aggregate* they're costing you a ton of performance. Yes, C# and Java are worse because they add allocation everywhere for built-in stuff (e.g. iteration), but even without that the allocations made by the users are a huge issue too. Simply profiling and trivially finding a bottle neck is a highly unrealistic and idealized scenario. Refactoring a central data structure with dozens or hundreds of operations after it's already in use is a pain, especially when it only contributes to 0.1% of the perf. overhead (it could still be the biggest cost center remaining, though!). Going through five thousand instances of the allocation operator being used and analyzing each one to see if it can be removed is a pain. The only way to avoid "peanut butter" costs is to not put it in from the start. This means making sure your language primitives and your library don't use them needlessly, and making it *slightly* inconvenient to do expensive things so that people won't reach for it unless they really need it.
LLVM inlined those functions; that isn't a valid test as allocators do not generally inline (at least, they don't inline their slow paths). Also you should test with a large data structure; e.g. `[int, ..16384]`. The reason we have `box` is that otherwise you would have to allocate a 130KB stack frame in order to construct such a value on the heap. In general if you disassemble Rust code you will see far too many `mov`s everywhere compared to C. This doesn't hurt runtime performance too much on x86 (presumably because they're all L1 and don't put load on the ALU) but bloats code, affecting i-cache, and is generally bad. The primary reasons for this are: (1) lack of TBAA info causes LLVM to copy padding when it is not necessary; (2) zeroing out structures; (3) `Rc::new`, `Arc::new` and friends. I think we need to solve all of these problems.
Just anecdotally, whenever I go to optimize some code, the first thing I do is try to kill all allocations. That usually results in bigger performance gains than anything else I do, assuming the initial algorithm was sane. (For what it's worth, the next thing I do is to make sure inlining is happening properly. Inlining is huge if it leads to SROA.)
&gt; Also you should test with a large data structure; e.g. [int, ..16384]. The reason we have box is that otherwise you would have to allocate a 130KB stack frame in order to construct such a value on the heap. That's valid point. I have to think about it. Thanks!
In stepancheg's defense, initialising that large structure is also going to take at least linear time (possibly much more when the constructor is complicated) so even when the cost of copying becomes larger than the cost of an allocation it will probably still be significantly less than constructing the data in the first place. Of course the real victim here will likely be the cache.
 match self.read(buf) { None =&gt; None, Some(buf_size) if buf_size == bs =&gt; { let mut br = std::io::mem::BufReader::new(buf); for i in range(0, hash_table_size + 1) { result[i] = br.read_le_u64(); } Some((result)) }, _ =&gt; None } No need for `_ =&gt; None`, since the matching is already exhaustive (covers `Some` and `None`). Also, no need for the `return` keyword it's the last line in the function (e.g. `fn foo() -&gt; int { 3 }`} works). Did you benchmark this vs the C version by the way?
Note that functions aren't a universal feature of Make programs but only some (like GNU Make). Unfortunately, Rust's attachment of crate hashes to library names requires these kind of things.
(The match isn't exhaustive: there is a guard that means the `Some` case only covers `buf_size == bs`. The compiler would actually warn (or error?) if the `_` case was useless.)
For unique pointers yes, I believe. For managed pointers and other types of custom smart pointers, probably not. Allowing arbitrary side effects in pattern matching outside of guards is too complex.
merged. Your patches were very insightful. Thank you.
bumb 
* I think this code involving the pattern match can be simplified using `read_bytes`, I will try that. * Does it make sense, if it looks like C, I put `return`, and if it looks like ML, I don't put `return`...? * Benchmarking showed it is 30 times slower than the original, a bit untolerable. I have to investigate this.
Ah, I missed that. Thanks. Wouldn't it be better written as: match self.read(buf) { None =&gt; None, Some(buf_size) =&gt; if buf_size == bs { ... } } And ensure complete coverage?
&gt; Does it make sense, if it looks like C, I put return, and if it looks like ML, I don't put return...? I think we should have some sort of "official" style guide for the language. After programming with Scala for quite a bit, unnecessary `return` statements become noisy IMO when reading code written in languages that require it (like Java and C++). What I usually do is only put `return` when returning from nested scopes (e.g. `if`/`while`/`for`), or if it is required. I remove it when it is optional. &gt; Benchmarking showed it is 30 times slower than the original, a bit untolerable. I have to investigate this. Did you compile with `-O`? I would be interested to hear about your findings.
I'd write match self.read(buf) { Some(buf_size) if buf_size == bs =&gt; { ... } _ =&gt; None } personally.
In C++ you have to go out of your way to allocate something behind a pointers. There are a few reasons for this, the first is that allocation itself is a big scary separate keyword. The other is that variables "by default" are just values (like Rust, but unlike Java and C# which have uniform representation and thus defaults to storing things as references to heap allocated objects). So the default behavior is that things are stored "in place", and you have to opt-in to the more expensive form.
Is the syntax final? As in will `~int` be changed to `Box&lt;int&gt;` in future? 
Continuing to use the `~T` as the type for owned pointers is still up in the air. Some people want to change it to `*T`, some people want to change it to `Uniq&lt;T&gt;`, and some people want to leave it as is.
&gt; Did you compile with -O? I would be interested to hear about your findings. It's probably caused by libuv-based I/O, rather than the quality of the generated Rust code.
Why `*T`? Isn't `*` used for dereferencing `&amp;` pointers?
Note that the same is true in C (`*` is used for both specifying a type, and as a de-referencing operator) (edit: s/referencing/de-referencing/)
IRC is really only good for hashing out informal ideas. Prefer to send a message to the mailing list if you want to give the devs a chance to consider it.
 let x: box&lt;int&gt; = box 3; I'm assuming that this would be the alternative. Personally I'm leaning more towards this version for the sake of consistency, but there's something to be said for keeping syntax terse.
Which is in my opinion a mistake and one of the reasons why pointers in C have a reputation of being difficult to learn
Can we keep `~` too? I like it personally.
I monitor so many sources that I don't always remember precisely where an idea has been discussed. It's true that I've seen them mentioned on IRC, but I'd be surprised if they haven't been thrown around on the mailing list and in the weekly meetings as well.
No problem! I'm happy to help a new Rustacean better learn the language.
Yes, I believe there is a strong case to be made for not following the example that C provides. Especially since `*` in rust would have a subtly different meaning than `*` in C, which could lead to confusion.
consider using the `#[test]` directive for those tests!
Is libuv a known source of IO slowness then? If so, are there any plans to address that?
To register in Mibbit, visit [the normal link](http://client00.chat.mibbit.com/?server=irc.mozilla.org&amp;channel=%23rust) and enter your username. It will appear to hang instead of taking you to the chat room. In reality, it's opened a 'Mozilla' tab in the upper-left of the page where a message telling you that you have to register awaits. You can use the [commands found here](https://wiki.mozilla.org/IRC#Register_your_nickname) to complete registration.
IMO the box syntax is weird and i'm opposed to it. I'd rather rust to use the design suggested in: https://www.mail-archive.com/rust-dev@mozilla.org/msg07181.html I agree with Patrick's analysis with regard to having an implicit different argument evaluation order (lazy), but, rust already has a solution for that - macros will make it explicit and consistent with the rest of the language. 
Replacing blocking I/O with quasi-blocking I/O backed by a thread pool is always going to be a lot slower. This can be improved but it will never be as fast as C without opting out of the libuv I/O.
This subreddit is for the Rust programming language being developed my Mozilla, not for the Rust game that was just released. Maybe /r/games would be a better place to post?
You wanted /r/playrust.
While it looks like the standard library is still quite in flux, is there light at the end of the tunnel with regards to language changes, specifically backwards-incompatible ones? I'm just thinking of these box/~ changes. Are there any more changes like this looming on the horizon before 1.0 (seems like that release should be coming pretty quickly from how things sounded the last few months)? I'd love to start writing some programs in Rust, but given how little time I have, I'd like to wait a bit for the language to mature a little before I jump in.
The language isn't changing very frequently anymore. I doubt there will be more changes without trivial migration paths to equivalent code. On the other hand, I'm sure there will be a fair bit of breaking changes with easy migration paths like this. If there's a better way of doing something, there's really no need to leave behind the obsolete version at this point.
&gt; Are there any more changes like this looming on the horizon before 1.0 (seems like that release should be coming pretty quickly from how things sounded the last few months)? Dynamically sized types, although that won't break much code. Requiring that all types be dropped will break some code, but probably not too much. Maybe the `'self` lifetime will be renamed something else. Maybe `extern mod foo;` will change. Other than those plus `box`, pretty minor stuff.
If the meaning of `~[T]` changes, that will break a *lot* of code. The `'self` lifetime is already gone :).
Excited for --dep-info!
Alex wrote: &gt; Overall, this halved the compile time for a fn main() {} crate from 0.185s to 0.095s on my system (when preferring dynamic linking).
Should be automated by a bot written in Rust.
What impact does this have for larger projects, say, rustc?
I thought segmented stacks went away? Is this leftover cruft that could be taken out or am I mistaken about the stack thing? edit: yeah, this thread: https://mail.mozilla.org/pipermail/rust-dev/2013-November/006314.html
next to 0. metadata reading is only big for small crates.
It's currently used for some semblance of stack safety, e.g. `fn main() { main() }` will abort with a nice printed error message (`task '&lt;main&gt;' has overflowed its stack`, or something) because the stack overflow is detected in that prelude.
No impact.
So also cmr's comment about this: https://github.com/mozilla/rust/pull/10966#issuecomment-30569747 
Oh, yes. I changed the main function into a function with #[test] directive.
Great discussion of these issues and their workarounds. It will be useful to point future developers at them when they hit these problems, rather than the bugs themselves.
Most of the compilation time of anything non-trivial is spent in the LLVM optimization passes. So this doesn't help much at all for that. But it's still awesome for many reasons.
Return in closures! Hurrah.
Rust's only compilation unit is a crate, so it's the only unit link-time optimization can be done on. Crates aren't necessarily library boundaries, as they're the only way to divide up your project and do incremental compilation.
"the TCP thing" apparently refers to Tennent's Correspondence Principle (and was kinda hard to google for). tmyk!
I think `extern mod` is fine, as it's clearly describing an external module (library). The *crate* terminology might make sense to insiders but it makes no sense to someone learning the language. Why not call it a library or external module if that's what it is?
That day will come faster if you upstream some of our patches :)
What about `use lib std;` or `extern lib std;` then? That provokes neither the confusion-from-overloading of `extern mod` nor the confusion-from-obscurity of `crate`. (And it makes sense: a crate is a more general concept than a lib, being either a lib or an app, but you're not going to link to an app.)
Should be starting at 8PM pacific. More info here: http://www.meetup.com/Rust-Bay-Area/events/153010612/
Dear Princess Celestia, Today I learned something amazing! Everycallee everywhere has a special magical connection with her callers, maybe even before she's called by them. If you're feeling you're doing unnecessary duplicate work, just inline. Who knows, maybe you and your caller are all doing the same work and magical LLVM fairy can eliminate them.
short and (super sugary) sweetness! Excellent work John, I'm inspired to try to make some 10min presentations of my own.
Should really say thanks to Leo Testard from the help on it.
bUMP!
This is the subreddit for the rust programming language, not the game rust.
I don't know the Rust team's reasons but since 'no_mangle' is more descriptive about its effect, i prefer it.
Does some one have a good example of this with arguments to the function? In particular, is it difficult to do things like interact with Option types from C?
We deliberately don't make any guarantees as to the layout of enums *in general*, to allow for various optimizations based on their structure. If you want layout gurantees, use structs instead. However, for any Option type whose contained type is a pointer, we lay this out as nothing more than a nullable pointer at runtime. This is a pretty fundamental optimization, so it's more-or-less safe to rely on it AFAIK. By way of example: let x = Some(~4); // x is just a nullable pointer at runtime let x = Some(4); // ...but not here, since the contained type isn't a pointer I should also mention that if you're using C-style enums (i.e. enums without any data attached), you can guarantee a C-conformant representation by using the `#[repr(C)]` annotation on the enum definition.
I have no idea how difficult it would be, but it might make sense. Could you file a bug for it? https://github.com/mozilla/rust/issues
Is a recording going to be posted?
This example doesn't give a complete picture of the FFI. `#[no_mangle]` is necessary so that the symbol can be easily named but for general FFI purposes you almost always also want to declare something `extern` so that it uses the correct ABI: #[no_mangle] extern "C" fn do_something() { ... } Without the `extern "C"` the function will use the Rust ABI, which is close enough to the C ABI that calling a nullary function from C will work, but it isn't correct in general.
It's there!
An issue is already open about this: https://github.com/mozilla/rust/issues/10530 
I thought some of these talks might be of interest to those working on `rustc`.
It could be nice to have a guide with patterns for handling the situation where two objects, a and b, need to access the data of a third object, c. * Make c immutable and let a and b have pointers to c * Turn c in to an actor communicating through pipes * Use RC or RWArc EDIT: Perhaps it could also contain patterns for handling situations where you would "normally" use circular dependencies. 
I'm curious to hear what people think of my proposal here; from #rust I've received positive vibes in regards to using Sphinx, but I'd like more feedback. If you have concerns, I'd like to delve further into them so that we can figure out whether they're well-founded or not.
Would rustdoc be unnecessary when using sphinx, or would rustdoc be able to just replace it's current `sundown` markdown renderer with some sort of call into sphinx?
IMHO, the "correct" way to fix this would be writing a proper rustfmt tool, and then hooking a HTML output format into this, since this would give us perfect formatting rather than having to maintain a different parser. [rustfind](https://github.com/dobkeratops/rustfind) is reasonable example of what I'm thinking ([example output](http://dobkeratops.github.io/rftest/librustc/rustc.rs.html#176)); it'd be really need to have hyperlinking like in that example too. This is mostly independent of the actual documentation engine we use, as long as it gives us a method to perform custom handling of the source blocks.
I'm confused - is this a post saying "don't be a dick" or are you saying this is some sort of uber-PC safe zone? A stickied modpost linking to an LJ rant about saying "hey guys" on IRC suggests that somebody's got some very-much-not-programming-related axes to grind. It suggests that these rules need to be posted *because* the community is not tolerant and inviting. Most importantly, it suggests that the community isn't about programming. Bad first impression.
Also check out http://en.cppreference.com/w/ I like the clean layout, and the many examples that can be modified and run in the browser, ie. http://en.cppreference.com/w/cpp/numeric/random/uniform_int_distribution 
I wonder why extern fn are not "no_mangle" by default. Is there use cases for mangled extern "C" functions ?
Does restructured text allow for formatting mathematical equations?
Having examples runnable and modifiable like that is something I definitely want. (I forgot to mention it in my presentation but did mention it in the question time at the end.)
The collection of information that rustdoc does at present would be essential to tying in with Sphinx's [autodoc](http://sphinx-doc.org/ext/autodoc.html) and [autosummary](http://sphinx-doc.org/ext/autosummary.html) extensions. The question that you are asking is then which way round you have it: do you (a) render reStructuredText/Sphinx snippets, just replacing sundown, or do you (b) let Sphinx control the entire thing with the remainder of rustdoc's functionality (HTML generation) being removed from rustdoc-the-program-written-in-Rust and instead integrated into a Sphinx theme and extension (written in Python)? Sphinx isn't designed for the first, especially with its cross-referencing; it could with difficulty be managed, but you'd lose various other benefits like PDF/EPUB export at the same time. Thus, the second would be the approach which would need to be taken.
While a plain text format like that would also be useful (Go's `godoc` and Python's `pydoc` can do pretty much that thing, and could be integrated with folding to produce largely a set of signatures until you expand them to see the doc comments), what you really want for tools is a particularly convenient machine-readable form like JSON. And rustdoc can actually already produce exactly what you are asking for here—it's just a matter of typing it into the IDE in some way. Of course, what you really want is semantic and contextual completion and knowledge; that's something where the tools are not there yet.
If you want the user to be able to make modifications, you can either shell out to a remote service for execution or you can go the compile-rustc-to-JavaScript-with-Emscripten path. The latter will be slow and heavy and potentially costly in bandwidth, the former has the potential to be faster and should be lighter but introduces more work or an incomplete result.
Just a bit of light relief. ☺
So we'd need a (limited) Rust parser in Python? (Or, we could adapt rustdoc to output a `.rs-doc` file that is a very simplified version of Rust, i.e. just the relevant type signatures and structs and their fields and so. *e:* well, I guess it already has JSON output...)
Sadly the joke is lost on me.
Your Markdown critics don't seem truly valid since they are overcomed by Pandoc which has all the syntax you need. We don't use the vanilla implementation of Markdown. &gt; Pandoc’s enhanced version of markdown includes syntax for footnotes, tables, flexible ordered lists, definition lists, fenced code blocks, superscript, subscript, strikeout, title blocks, automatic tables of contents, embedded LaTeX math, citations, and markdown inside HTML block elements. E.g. your examples of messed code due to syntax aren't valid with Pandoc because you can just wrap inline code with backticks `foo` and then the Markdown semantics aren't being applied anymore. Now I surely agree that reStructured Text looks interesting and well-thought but Markdown is WAY more popular and pretty intuitive coming from HTML. Just look at GitHub developers, they all use at least a tid bit of Markdown for their repo and this alone makes a better motivating point because maybe people wouldn't want to have a look at RestructuredText *just* to send a contribution to Rust? idk. Another thing, pandoc is pretty lightweight and has kate highlighting support, which is from what I've seen (at least now) better than pygments. Note that I'm not *necessarily* standing against this, its just that you already presented to positive aspects of it (through, as I said, I sense that most of them are invalid since they target original Markdown specification).
We *do* use mostly-vanilla markdown in API docs, rendered by sundown.
Oh I see, I'm not familiar with the rustdoc backend. Why can't we swap sundown for pandoc?
We already switched *from* pandoc because it was atrociously slow. It was something like a 100x speedup iirc. Then again, we were also spawning a process for each doc block, which just isn't efficient.
I also support moving to Sphinx.
/r/playrust
Is there any documentation on this? Is it on par with Latex typesetting? --- Edit: oh wait, here it is: - http://docutils.sourceforge.net/docs/ref/rst/directives.html#math - http://docutils.sourceforge.net/docs/ref/rst/roles.html#math Seems it uses Latex syntax which is awesome!
Yes, it uses the LaTeX syntax; it doesn't seem to be without flaw, though; I just tried ``:math:`…` `` at http://rst.ninjs.org/ and got "Unknown LaTeX command: ldots"! (I haven't tried reproducing it locally.)
Thanks for writing this, it was super helpful. In honesty, I hadn't realized that either of these were actual bugs -- I thought that these were restrictions that were necessary to maintain the soundness of the borrow checking system. I'd just gotten in the habit of liberally sprinkling my code with `let`s. It's exciting that Rust is going to get even easier to write!
Want.
Etched how? Can you describe the process? Also, I think the damaged tooth on the upper right looks quite nice, though I'm not sure if it was intentional. :)
Not mangling by default would be a valid option. Mangling is not always necessary (for e.g. callbacks) and not mangling makes it more likely to have collisions in symbol names with either the current crate or other libraries. I recall it being discussed at the time but nobody having strong opinions.
It's a copper-clad PCB, I used a laserjet printer and a magazine and a clothes iron to transfer the pattern onto the board. Then a ferric chloride solution to dissolve the copper. And then acetone to wipe off the toner, but some elbow grease would have worked just as well :) There are many resources online on how to do this! [hackaday](http://hackaday.com/2008/07/28/how-to-etch-a-single-sided-pcb/) and [instructables](http://www.instructables.com/id/How-to-Etch-a-PCB/) have many. The damaged tooth wasn't intentional, but I'm in the process of trying some things to make it look more "rusty"/aged. I'm going to laminate it after because oxidized copper looks gross!
Copper? This needs to be done with iron and then be exposed to salt spray for a nice coating of rust.
I'm a huge fan of rust and I have Sphinx commit rights. Whatever needs to be done, just shoot problems my way.
&gt; Most importantly, it suggests that the community isn't about programming. Why?
Note that for the latest build Luqman removed the rpaths; to get it to run, you'll need something along the lines of `LD_LIBRARY_PATH=/path/to/rust/lib` to get it to work: &gt; *(10:43:47) ChrisMorgan:* Luqman: also, do you know why rustc can't locate the libstd\*.so file without setting LD_LIBRARY_PATH manually? (Or acrichto?) &gt; *(11:11:56) Luqman:* ChrisMorgan: oh, so i had stripped the rpaths cause they were hardcoded to my machine &gt; *(11:21:47) Luqman:* ChrisMorgan: hmm, come to think of it, they may include relative paths that would work. i hadn't looked to hard last night Hopefully this will be fixed up again for later builds.
It *is* true that this particular discussion thread is very tightly tied to a specific incident, though.
Before anyone asks: yes, I would love to release the source and hope to do so in the next month or so. I need to factor the library better (this code is all in one crate, but I can easily split it into 3 (bin, engine library, game-code) and publish that. I also want to add a few more features (sprite fonts, basic ux stuff and [de]serializing of the World (collection of Zones, Agents, Objects, etc).
Great! I'll bear that in mind, perhaps we can collaborate on the Rust domain.
Some ideas for the next steps: - A completely functional bicycle chainring (you'd only need to change the tooth design; the rest is pretty much what you need, though I confess the crank would obscure your work of art a little); - A genuine rusted iron version; - A cake (for a birthday, or when we get to 1.0).
it would be nice to introduce/teach the language by showing how its standard library is architectured/coded.
beautiful &lt;3
True. A book is a step forward only if the documentation is already first rate.
More basic stuff about pointers written for people coming from garbage collected languages.
My advice is that it's still a little bit early in Rust's development to write a book, as such -- the nice thing about a book as opposed to online docs is that a book is usually polished, has many carefully chosen examples, has had many people review it, and so on. (Real World Haskell is one good example of this.) It would be a shame if you or anyone else put a lot of effort into this and then had to change large parts of it due to language and/or library changes. Also, although I've never written a book, I've been told that writing a technical book takes vastly more time and effort than you think it will be when starting out, and can easily unexpectedly take years. So keep that in mind and ask yourself how you could have the most impact with the limited number of hours in a day :-) A compromise might be to start something like a wikibook? Something that's easier to edit quickly than the current docs (you wouldn't have to submit a pull request), and is organized so as to tell a story. Possibly you would want to limit the number of people with write access so as to keep the quality high from the beginning.
What are you trying to do? I don't understand the intent behind this block match wtf.find_equiv(&amp;k) { ... } 
&gt; Can I pass intern() a borrowed pointer to the SymTbl to avoid threading tbl through each call to intern()? Yes, use `&amp;mut SymTbl`. &gt; It seems like I have two copies of every string. One in the array and one in the hash table. Is there any way to avoid this? * Reference counting is the easiest way (`Rc&lt;~str&gt;`). (The double indirection is necessary today but will not be necessary in Rust 1.0.) * If all the strings are constant strings in read-only memory, as in your example, you could just use `&amp;'static str`. * You could use unsafe code to squeeze out the last bit of performance, but I would do reference counting first. &gt; How can I avoid the {let wtf = i.hm.clone();} bit? This is a borrow checker annoyance that is on file as a bug. You can work around it in two ways: * Change `match (...) { Some(v) =&gt; (i, *v), None =&gt; ... }` to `match (...) { Some(v) =&gt; return (i, *v), None =&gt; {} } ... }`. That is, hoist the `None` logic out to after the `match`. * Use the `.contains_key()` and `.get()` methods instead of `.find()`.
Thanks! That works.
http://www.meetup.com/Rust-Bay-Area/
For the record, I don't plan on writing a book! At least, not for a while. I just wanted to get some feedback because I'm interested.
Indeed, the purpose of baking version numbers into packages and mangling symbol names with the hashed version is to avoid this sort of dependency hell. However, this is largely untested and I have no idea how much of it is actually implemented.
Wrong subreddit. :) See /r/playrust.
Oh, my. Im so sorry lol.
Read the java/c# precisely books from Peter Sestoft, and do it the same way. Terse, lots of examples and diagrams to helps you get a mental model of what happens, And in less than 100 pages. The print book has a beautiful layout, such that left page has theory and/or explanations, right page corresponding layout examples/diagrams. A somewhat old version of the java edition is available here: http://www.itu.dk/people/sestoft/javaprecisely/javaprecisely.pdf 
Global install (I use cabal sandbox, and used to use things like virthualenv) and the version bound definitely make the problem worse. But, even without those, there's no way to have the situation work in haskell currently as far as I know, which is why things like [backpack](http://plv.mpi-sws.org/backpack/) are being looked at.
Cool; thanks. 
The `sort` PR adds [`.sort_by` (taking a closure)](http://static.rust-lang.org/doc/master/std/vec/trait.MutableVector.html#tymethod.sort_by) and [`.sort` (just applying to `TotalOrd` types)](http://static.rust-lang.org/doc/master/std/vec/trait.MutableTotalOrdVector.html#tymethod.sort), fwiw. (Oh, just noticed, I forgot to update the doc string for `.sort`, the `vec::SortForward` should just be `|a,b| a.cmp(b)` if someone feels like opening a PR (I'll do it later today, if not). *e:* [done](https://github.com/mozilla/rust/pull/11127).)
i have had the game for at least a week now and i am enjoying it! Its scary and fun at times and me and a couple friends have been constantly getting ourselves into firefights. The article is such a great read its really how it all went down that night also! if your thinking about buying the game do it! Shameless plug* www.twitch.tv/rawrnold
Yes.
Code: Maybe somewhere around here? https://github.com/mozilla/rust/blob/master/src/libstd/rt/sched.rs#L412 There's an old issue at https://github.com/mozilla/rust/issues/3095 but I don't know how closely the design sketched out there matches the implementation.
The implementation is close to what I outlined near the bottom of that thread, plus a bunch of additional complexity for dealing with I/o.
Scala is the most popular functional programming language right now, mostly because of how easy it is to use in existing java codebases. It has a lot of OOP features, and a lot of functional features too. Haskell is a purely functional programming language, and so no functions are allowed to have side effects. The only way to perform IO is using monads. OCaml is a language which pioneered the functional+procedural combination that's popular today (afaik), and rust draws a lot of inspiration from it. Rust is a system's language which supports functional programming paradigms easily, with things such as parametric polymorphism (generics), ADTs (enums), libraries to help with writing functional code (iterators, map, functions that return new values instead of mutating an existing one, etc.). It keeps the memory control and flexibility of a language like C/C++, without sacrificing the safety and type system of most functional programming languages. Edit: After reading the linked post: You should probably avoid rust if you have trouble learning new languages, as there's little documentation, the language changes rapidly, and there's not many libraries yet. All of the languages mentioned above are statically typed, and share very little in common with C# and java (except for scala, but scala is still a unique experience). You don't really need a debugger that much while writing code in functional programming languages, because functions are pure you can easily isolate and test them individually, and because of the safety features most of your errors will be compile-time rather than runtime. You can't run any of these languages in a browser really, so if you're looking to do web development you'll almost certainly need two different languages (unless you're using node.js, or a language that can compile to javascript easily). Rust has pretty rough-edged introspection, and I haven't used the introspection facilities of the other languages. Generally it's only needed for automatically implementing typeclasses like Show/ToStr/etc. Introspection is used very little in functional languages compared to OO ones, in my experience. If you do wish to get into functional programming, and I highly suggest you do as it will make you a better programmer even in C#/java, you should be prepared to have a lot of your assumptions about how programming works invalidated. Many people who tell you what it's like to learn haskell say you have to learn to program from scratch. 
Rust is a systems programming language. It's low level and so usable pretty much anywhere, but contains some high-level features, and so is easier to use without doing too much boilerplate code. It also has lots of compile-time safety checks so you only get runtime errors when things out of your control go wrong, as opposed to most other languages where you can screw things up and never know until you run the program.
I'm not really a Rust developer (waiting for 1.0), but I'm a C++ guy who has a background in functional programming, but I think I can help some. Rust isn't really competing with OCaml or Haskell or F# or Scala. While Rust has good support for writing in a functional programing style, I would not call Rust a functional programming language. It's a low level imperative (e.g. systems) language, and mainly intends to compete with C and C++ (probably also D, and maybe Go). Rust offers more safety than C/C++, but without the runtime overhead of D, Go, or any of the functional languages you listed. Basically, Rust is low level and Haskell/OCaml/F#/Scala are extremely high level. This is the reason for supporting loops and mutation so well, as these turn into extremely straightforward machine code. Moreover, Rust has no garbage collector by default, which means you must spend time worrying about lifetimes and ownership and etc. A lot of your questions weren't about Rust though, but I have some - OCaml and Haskell are similar in a lot of ways but if you ask me Haskell gets all the important parts right where OCaml gets them wrong. There are two big differences though: Laziness and purity. Basically, they choose different defaults for laziness, and Haskell is much more strict about purity than OCaml is. There are benefits and drawbacks to both of these differences. Haskell is the more popular language so if you're going to learn one of the two, you should go with that one IMO. (That said, OCaml is the more pragmatic of the two languages). - Standard ML is a lot like OCaml but older. I doubt many new projects are started in it. I had to learn it for a class I took in college. I wouldn't recommend it over OCaml, as they're extremely similar. - F# is a dialect of ML that runs on .NET. It's a fully supported and first class citizen of .NET so if you want to run code on that platform it's the best/only choice of the lot. I've never used it but it looks extremely similar to OCaml (even closer than OCaml is to SML). - I don't know much about Scala other than that it's popular and runs on the JVM. Hope this helps. If you're interested in a functional language I'd recommend avoiding Rust. You'll learn more by using something a bit purer. Haskell is a good choice and a better language. Heck, if you want a strong guarantee that the language will always work I'd recommend avoiding Rust until it's stable, which will be version 1.0 (I think).
Well, being on the JVM means it's not really in the same bracket IMO. Having control of memory allocations is a language feature if you ask me ;).
Syntax is a matter of taste. I think Rust's is somewhat ugly, but not so bad I wouldn't get used to it. It has a higher signal to noise ratio than C++ does, which endears it to me. That said, you compare it to "Go, D, Cobra, Scala, Nimrod, Haskell, and F#". I don't know anything about Cobra (it seems to be on .NET?) but all of the others here have garbage collection. Sure, Nimrod and D let you turn it off, but if you do so you lose all safety (and in D, the standard library), and are on equal or worse footing for safety with C/C++. Also Nimrod is reference counted, which can have significant overhead compared to manual management. Go at least lets you avoid some heap allocation, but last I checked most of the time the programmer has no control over when/where heap allocations occur. Not to mention it has a pretty awful GC.
FWIW, Rust's lifetimes are actually a pretty unique feature, that is in no other industry language (they allow for first class manipulation of interior pointers in a type &amp; memory safe way, *without* a GC). Also, re the mailing list threads, they're often started by people who say "I'm half way through the tutorial and ...", I.e. they don't necessarily have enough experience to understand why something is the way it is (I.e. it might be ugly, but any other syntax is either not general enough, or uglier). (Also, the devs do understand... That's half the reason for the removal of the `@` sigil.) Lastly, guaranteed tail-call optimisation requires making *every* single function call slower, for something that doesn't occur in practice a lot (i.e. a tail-calling function that is very hard to write as a normal loop). (That is, the language could easily support it, but it was a tradeoff that was decided against.)
I also like that the code snippets naturally need to be self-contained (including all necessary "use" statements)
I'd disagree. When it comes to complexity, Scala is the same ballpark as C++. Rust isn't in that way comparable and I hope it never will be. Also Scala can't be used on an embedded systems, unless you are willing to abandon everything that makes it Scala.
Have you checked the explanation on the website recently? http://www.rust-lang.org. It doesn't clearly answer the question what is unique about rust - parts of it probably are not comprehensible to non-language-lawyers (what the heck is 'linear type system'). 
Yup, this is great.
It may be a newbie question, but we should be encouraging and helpful to newbies, not groaning.
What's the problem with the name? I mean, yes, it starts with an "i". So what?
Awesome, I just wish it worked with the latest rust master branch, rather than the latest release.
Alas, it doesn't keep state between evaluated lines of input :)
LLVM does do TCO for Rust in similar situations to the ones GCC does for C/C++ (and essentially identical ones that Clang does them, since it uses LLVM too).
I think it's defensible to ask the community instead of relying on the ad copy (which in parts still reads like a wish list).
Thanks! After reading the discussion, I'm convinced they made the right choice in removing float. I don't really follow much of the discussion about `int` and `uint`. It seems like they can't find a good integer type that works well as an index and a general numeric type. Is that right?
What? This isn't a game...
This isn't a game...
&gt; I don't really follow much of the discussion about `int` and `uint`. It seems like they can't find a good integer type that works well as an index and a general numeric type. Is that right? If you have a bound, you almost certainly want to use the smallest possible fixed-size integer. If you don't have a bound, you need a big integer. The only reasonable default is a big integer, but it's not a sane default for a systems language. The reason for `int` and `uint` existing is having an integer type with the same width as a pointer. Rust ignores legacy architectures with segmented address spaces, so there's not `uintptr_t`/`size_t` split and they're used for indexing arrays too.
So int and uint take the same size in bytes as a pointer on the target architecture?
Yes, they're defined as a pointer-size integer.
Thank you.
What don't you like about the syntax? Keep in mind that pointer sigils are being removed. This is the first time I've heard that we don't change things *enough*. We've changed the language a *lot* in response to feedback and it's bewildering to suggest that we don't listen. Go look at what Rust 0.3 looked like. I've seen a lot of strong opinions about how Rust's syntax is "obviously" horrible, but usually the concrete suggestions for improving it are things like s-expressions or whitespace-based syntax, or just don't work for whatever reason (`:=` instead of `let` breaks lookahead for example). Also, there are two things to note: 1. Rust is the only industry language that lets you program with locks and mutexes but rules out all data races. 2. Go does not support extension methods. Methods for a type must be defined in the same package as the type. Rust, however, does.
Rust will do TCO in exactly the same situations that C++ does. Regarding lifetime syntax, I haven't seen any complaints about the current syntax. It was deliberately chosen in response to complaints that the original syntax (`&amp;int/a`) was hard to read, contrary to your suggestion that we don't ever change the syntax in response to feedback. (OK, that's not entirely true: I did get one suggestion to change it to the clock emoji.)
Holy shit. I just realized this is the completely wrong sub-reddit. Omg I'm sorry
If you need to re-use the tuple struct definitions Circle and Rectangle, you'll have to give the Shape variants new names. struct Point { x: f32, y: f32, } struct Circle(Point, f32); struct Rectangle(Point, Point); enum Shape { ShapeCircle(Circle), ShapeRectangle(Rectangle) } fn main() { let x:Shape = ShapeCircle(Circle(Point{x: 44.4, y: 22.2}, 99.9)); } &gt; Also, the 2nd example would work if Circle and Rectangle were just normal structs rather than tuple structs. Not exactly. struct Point { x: f32, y: f32, } struct Circle { ctr: Point, diam: f32, } struct Rectangle { ptA: Point, ptB: Point, } enum Shape { Circle, Rectangle } fn main() { // no error -- but not what you intended! let foo: Shape = Circle; // no error let bar: Circle = Circle { ctr: Point { x: 0.2, y: 0.3 }, diam: 4.3 }; // compiler error let baz: Shape = Circle { ctr: Point { x: 0.2, y: 0.3 }, diam: 4.3 }; } Instead of making a Shape either a 'struct Circle' or a 'struct Rectangle', we've made 'Circle' mean two different things. (See eddyb's comment for an explanation--this behavior is normal)
The reason it works with normal `struct`s and not tuple `struct`s is because tuple `struct`s and `enum` variants both add constructors. While this may be confusing, you can actually define a type, a function and a module with the same name. An `enum` variant will define a function, while a tuple `struct` will define both a type and a function.
Your code example is exactly what I meant, and it did compile fine. I just never actually tried using the structs after defining them. 
Great ! Glad to see Tony Arcieri getting interested in Rust.
You can also do this: struct Point { x: f32, y: f32 } enum Shape { Circle { origin: Point, radius: f32 }, Rectangle { tl: Point, br: Point } } This is called structural variants and they're currently hidden behind a feature gate. Sadly they haven't seen much use and hence may have some bugs here or there. 
It's best to just think of them as structs with unnamed fields.
5 months late? stop necroing son 
Using rust in production right now wouldn't be a great idea, unless you have a lot of time on your hands. If you really want to use rust in production I'd wait for release 1.0, but don't let that deter you from learning it, but be aware there will be lots of changes. Edit: I should probably add why rust is unstable at the moment. They're currently making a lot of changes, syntactically, to keywords and internally which could easily break your program, meaning you have to spend quite a bit of time fixing it.
The changes are normally pretty drastic, I'd recommend taking a look at the series of articles: [this week in rust] (http://cmr.github.io/blog/2013/12/22/this-week-in-rust/), which give a list of breaking changes each week. Hope this helps.
Wait, that doesn't seem right. Straight from the tutorial: &gt;Rust also has tuple structs, which behave like both structs and tuples, except that, unlike tuples, tuple structs have names (so Foo(1, 2) has a different type from Bar(1, 2)), and tuple structs' fields do not have names.
Looks like I've misunderstood tuple structs! Thanks for pointing that out!
Not even a little bit. That looks awful. Also, *really* outdated anyway.
&gt;I don't see an obviously superior alternative syntax for lifetimes. Any suggestions? [I proposed an alternative on the mailing list](https://mail.mozilla.org/pipermail/rust-dev/2013-February/003124.html) with `#` (pound sign has connotations of time/numbers better than `'`) as a suffix lifetime symbol or at the very least making the lifetimes a suffix rather than as a prefix, but the ship had sailed by that point. Like any bikeshed I can't speak for others, but I felt it read more clearly (see the mailing list link for examples).
&gt; What don't you like about the syntax? I still think we can find a more intuitive syntax for lifetimes. [I proposed an alternative on the mailing list](https://mail.mozilla.org/pipermail/rust-dev/2013-February/003124.html) with `#` (pound sign has connotations of time/numbers better than `'`) as a suffix lifetime symbol or at the very least making the lifetimes a suffix rather than as a prefix, but the ship had sailed by that point so wasn't seriously considered...perhaps since it wasn't better enough than the newly existing usage of `'`. Like any bikeshed I can't speak for others, but I felt it read more clearly (see the mailing list link for examples).
It compiles to native code using LLVM, so it is stable at run-time. However, the language is still changing, so you'll need to apply regular expression replacements or possibly manual changes to your whole codebase regularly. 
Sure, honestly I'm more a fan of the suffix notion than the pound sign myself if something was to be considered.
That checked_add function (and it's siblings for other arithmetic ops) is bugging me. It takes a pointer to values that are at most 64bit. On a 64bit machine a pointer is 64bit, passing a pointer is never better than plain copy of value type and in most cases worse. I know it doesn't matter, since you wouldn't use "checked" in perf-critical code, but it still bugs me.
This subreddit is for a programming language, you'll want to post to /r/playrust instead.
Does this mean that using libstd from a rustboot-like environment is that much more feasible? Or is the runtime still deeply ingrained into libstd, but just more abstractly?
Neither form of threading is available in a freestanding environment because both are built on POSIX/win32 threads. Any `extern` block using `libc` functionality isn't going to be work in most cases, and neither is unwinding.
Yes, that's the idea. You can just stub out or not implement the I/O and threading implementations that won't be available in kernel space, just as most of `stdio` is stubbed out in kernel space in Linux.
Most likely you'll have to opt-in, similar to how you `forkIO` in Haskell to get over to the green scheduler. But this is not yet fully decided.
Do you mean IRC? Take a look at the info below the "Community" section: https://github.com/mozilla/rust/wiki/Docs
this subreddit is about some programming thing and completely unrelated to the game, you probably want to ask in /r/playrust
This: struct Circle(Point, f32); Is *almost* equivalent to a single-variant enum: enum Circle { Circle(Point, f32) } (Note that the data layout of enums is not guaranteed) In fact in languages like Haskell, this is how you actually define 'tuple structs': data Circle = Circle Point Float
Though technically speaking, `expect(format!(...))` method call will allocate one string per iteration, which is undesirable. A bit more verbose version won't have such overhead except for the checked addition, which ultimately compiles down to a single overflow check (i.e. one more instruction): let tmp: u64 = match n2.checked_add(&amp;n1) { Some(v) =&gt; v, None =&gt; fail!("overflow: {:u}, {:u}", i, n2) }; ~~(I suggest to add a lint pass for such overheads ;)~~ Hmm, after some thought it may be trickier to make into a lint due to the possibility of both false positives and false negatives.
Rust strings aren't null terminated. You need to convert your data to a C string first. I'm on my phone right now, so I can't give more detail on that. Google away.
I'm pretty sure Rust has c_str support somewhere.
Check out [Elixir](http://elixir-lang.org/) if that's how you feel about Erlang.
It's in the [`std::c_str`](http://static.rust-lang.org/doc/master/std/c_str/index.html) module.
Thanks for this, I was waiting for windows nightlies! However i could not make it work. I've installed from powershell, via nuget install Rust then copied under mingw home directory. When I try to launch rustc.exe --version I get a "The procedure entry point _ZNSt8_detail15_node_base7_M_hookEPS0_ could not be located in the dynamic library libstdc++-6.dll" 
everyone: thanks for the suggestion to try out `c_str` but my problem remains: what's the return type on the function? #[link(name="rust_uuid", vers="0.1")]; extern mod extra; use extra::uuid::Uuid; use std::c_str; #[no_mangle] fn uuid_rust() -&gt; c_str { // ^^^^^??? let uuid1 = Uuid::new_v4(); let uuid1_str = uuid1.to_str(); let uuid1_c_str = uuid1_str.to_c_str(); return uuid1_c_str; } #[no_mangle] pub extern fn asdf() -&gt; &amp;'static str { return "asdf" } #[no_mangle] pub extern fn uuid_str() { uuid_rust(); } #[fixed_stack_segment] fn main() { //println(uuid_rust().as_str()); println(asdf()); } I really appreciate all the help!
Works fine for me.
Happy birthday!
Inlining does not help, since `let tmp: u64 = n2.checked_add(&amp;n1).expect(format!(...));` is equivalent to this code: let expect_arg = format!(...); let tmp: u64 = match n2.checked_add(&amp;n1) { Some(v) =&gt; v, None =&gt; fail!(expect_arg) };
You're on the wrong subreddit, friend. You're looking for [/r/playrust](http://www.reddit.com/r/playrust)
Here’s the [development roadmap](https://github.com/mozilla/rust/wiki/Note-development-roadmap) for Rust. It lists the things planned for future releases. hth
Happy birthday and thanks for your contributions! :) Love the cake. Was it delicious?
Erlang's syntax is pretty alright once you use it for a day or two. The problem with this code is it's overly wordy, terse, and nested, IMO.
Make peace with it. Perhaps give it a small gift. In return, it will warp your mind and send you upon an endless journey of enlightenment.
Great, now make a tail recursive version! :)
Happy birthday, you tricky wizard.
Looks yummy. Probably should have used a dusting of icing sugar for the logo though - the brown is a little hard to see.
This kind of feels like inheritance in a strange way. 
The homepage of Joe Duffy says "I’ve been granted 45 patents, with another 33 pending" [1]. That's somewhat disgusting/clueless. He says explicitly that he cannot reveal any details at this point; i.e. Microsoft has filed patents related to this "new langage" and can't talk about it until they are approved. He also claims to have been working on his "new language" for 5 years already; I wonder what those 33 patents he says he got pending are? Or maybe he patented 33 things related to something he hasn't been working on for the last 5 years? Not likely. Microsoft will get more and more desperate as they continue to be marginalized in terms of market cap, market share and developer mindshare. They have a long track record of simply being dicks (i.e. just look at how they charge royalty for every android phone, and how they created the Rock Star patent troll company etc). It would be best if Microsoft stayed out of the "perf + productivity" language niche. His homepage went down when HN linked to it so below is the google cache link. [1]: http://webcache.googleusercontent.com/search?q=cache:ciUKuYV44dYJ:joeduffyblog.com/about/+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=se 
You have a different libstdc++-6.dll than the one rustc.exe was compiled against. Try downloading a different one and put rust in its own directory (I don't think it's a very good idea to put rust into mingw's directory on windows in general) and putting that directory into PATH, and that should help.
If someone is interested, this is the paper that Duffy refers: [Uniqueness and Reference Immutability for Safe Parallelism](http://research.microsoft.com/pubs/170528/msr-tr-2012-79.pdf)
Please refer to [this interview](http://www.infoq.com/articles/Joe-Duffy-Safe-Parallelism) Probably there are already way more M# code than Rust For a more depth reason, check [this](https://careers.microsoft.com/resumepreview.aspx?aid=111551) &gt; The Technical Strategy incubation team is seeking an exceptional developer to &gt; build the user interface platform for next generation UI applications. Your &gt; responsibilities will include the design and implementation of core UI services &gt; such as composition, input, window management, and a controls framework for &gt; both native and HTML5 applications. All development is in M#, a C#-like language &gt; for writing asynchronous and parallel operating system components with strong &gt; guarantees of correctness. Seems this is from the [Microsoft's Technical Strategy Incubation group](http://channel9.msdn.com/Forums/Coffeehouse/Concurrency-Safe-C-from-TSIMidori-team-Joe-Duffy-etc) See also [this](https://careers.microsoft.com/resumepreview.aspx?aid=86472) &gt; As a Principal Software Development Engineer on the team you will be responsible for the design, implementation, testing, and &gt; performance of transaction processing and distributed storage features for this multitenant data processing platform. You will write &gt; code in a language like C# that has the performance characteristics of C++. You will contribute to brain-storming sessions and &gt; propose innovative solutions to hard problems. M# seems like to be the backbone of the Midori project
Interesting! Is there other "expressiveness benchmarks" for other languages?
thanks! Just to clarify, I did not copy Rust under the mingw bin files directory. I meant I copied the whole Rust folder under my own msys "home" folder. About libstdc++-6.dll, I may be way out of my depth here, but wouldn't it be better (if possible at all) to have it statically linked? 
An interesting nugget from the interview: &gt; Joe Duffy: [...] &gt; &gt; I think the most interesting aspect of our project is that we've built an entire operating system using the language, doing simultaneous "co-innovation" all the way. Too often, languages are created in a vacuum, and it takes a long time to find out what works, and to fine tune things. The iterations take a long time when you need to ship a release to customers, wait for them to build stuff, and only get the feedback. Whereas we find out almost instantly. After working this way for several years now, I simply can't imagine going back. This doesn't just apply to the language, but the entire development platform. &gt; &gt; InfoQ: You built an entire operating system? That seems like a lot of work just to prove the effectiveness of a type system. What inspired you and your colleagues undertake that project? &gt; &gt; Joe: To be fair, the OS came first. We simply realized over time that, to truly achieve our goals, we needed to innovate in the language. Codevelopment of an entire system is a powerful thing. Remind you of anything? :-) The bit near the end about the "interleaving problem" is tantalizing as well.
/r/playrust
The Go tour is [open sourced](http://code.google.com/p/go-tour/) and licensed under Apache 2.0. We could fork that and rewrite it in Rust I imagine.
Relevant HN thread: https://news.ycombinator.com/item?id=6975740 Personally, I'd like to equate the [expression problem](https://en.wikipedia.org/wiki/Expression_problem) here with Acid tests. While Acid tests are good indicators for Web browser comformance when it's given in isolation, in reality several browser vendors historically tried to support what Acid tests require and nothing else, and some tests are even not suitable for some novelty "browsers" which has an excellent conformance otherwise. (e.g. Prince XML-to-PDF converter does not pass Acid3 since it naturally does not support JavaScript, but it was one of the first non-browser to pass Acid2.) Likewise the expression problem is just a showcase, and much of flamewars from the HN seem to originate from it.
Is this about the game Rust? If so, /r/playrust . This subreddit is for the Rust programming language (see the sidebar and title and so on).
woops my bad thanks for the tip 
This is the subreddit for Rust, the [programming language](http://rust-lang.org/). You're probably looking for /r/playrust ;)
Two words: - thanks for working on this, it's awesome - thanks for the summary
thank you &lt;3
1. How does MinGW compare to MSVC or GCC? Regardless, we use LLVM for codegen on every platform. We don't even use MinGW at runtime (besides libgcc_s), it's all libuv/win32 calls. 2. A lot of the stuff is in `std::libc`, but you might need to bind the functions yourself. We could use a complete winapi wrapper, if you'd like to contribute :) 3. We generate standard DWARFv2 debuginfo, so any tool that can read that can read us. Notably, gdb. There is no IDE support yet, but there's syntax highlighting for all the major open-source ones, and you can use etags to help along with completion. 4. Right now we aren't dependant on any C++ libs ([thanks to Vadim!](https://github.com/mozilla/rust/pull/11121)). We do depend on libgcc_s for unwinding, but it's tiny and not really a big deal. We want to try and move away from it when we can. 5. Building on windows still isn't great, since forking processes is sooo slow. The LLVM build takes forever because of this. You need to be comfortable with the commandline, although there are now [Windows more-or-less-nightlies](https://www.nuget.org/packages/Rust/).
IDE? Lol.
Re: API support, there is a work-in-progress WinAPI wrapper at https://github.com/klutzy/rust-windows -- help is appreciated!
外星語言，你說呢？讓我們吃麵條在你的顱腔
0.8 is way too far behind. We're releasing 0.9 this week or next. Track master for sanity :) The complexity isn't so bad, and an IDE or IDE-like features would be nice, someone just needs to put in the work (it's not always trivial). There are emacs and vim and sublime and kate plugins, I'm sure more will come as rust gains traction.
Awesome! Thanks for the great work and this summary!
Using 1:1 threading doesn't increase the resource usage. Either way, there's a large fixed-size stack allocation (2-8MiB). OS X has an arbitrary limit on the number of OS threads, but elsewhere it's not an issue.
Ah, I didn't realize there was such a hefty allocation going into the creation of each task. I thought that each task was a few kb, so making a few dozen on the same thread would be cheaper than creating a few dozen with their own threads. As it stands, allocating that much space for very short lived tasks seems impractical. I guess I'll have to weigh that cost each time I consider spawning. Thank you for explaining. Are there any plans to shrink that number down from MiB to KiB?
No, large stacks are an absolute requirement for fast foreign function support. Rust used to use segmented stacks but it's not going to go back to that. You should keep in mind that the memory will be allocated lazily as it is consumed, so it's really only an issue on 32-bit.
Could you elaborate on that? So if I spawn 500 tasks, each will allocate 2MiB, but the OS will only give it a fraction of that until it actually tries to use more?
To satisty an `mmap` (or `VirtualAlloc`) call, the operating system will set up some bookkeeping data structures for the allocations, and when first accessed it will cause a page fault via the memory management unit. If the memory has been reserved by the application, it will actually be allocated and handed to it as zeroed memory. Modern operating systems use virtual memory, where the addresses in the program don't correspond to actual physical ones. In fact, after calling `fork` all of the addresses will remain the same... despite being a new process. Linux (and probably other *nix operating systems) will even do copy-on-write via the MMU to implement `fork` (although using `posix_spawn` can still be a lot faster in a micro-benchmark to avoid copying page tables).
Great explanation, thank you. Does this happen in stages? That is to say, if I spawn a task and that in turn causes the first page fault, will it go ahead and allocate the full 2MiB? Or will it allocate a smaller amount until the next page fault? I suppose what I'm driving at is: is there a simple way I can predict the memory usage of a large number of tasks? What can I do to avoid the page fault that will result in the full allocation occurring? Thanks! 
Yeah, bug tracker is probably better place for this: https://github.com/mozilla/rust/issues/11198 Seems like it appears on other builds too.
From the comments &gt; you've reminded me of something that I left out of the post. The answer to your question is "kind of". We have a type, Result&lt;T&gt;, which can store a "reified" error result. You can construct these values explicitly, or you can "capture" the result of a possibly-throwing method call into a Result&lt;T&gt;. And if you have a Result&lt;T&gt;, you can "open it up", which will either produce the value or throw the exception, depending on what's inside. &gt; Result&lt;T&gt; (and the accompanying language syntax) is definitely inspired by monads and sum types. And if we were starting from Haskell or F#, it would probably be implemented that way, too! For now, it's more of a special-case feature. 
I'm curious how they do resource cleanup on nonrecoverable failures without unwinding.
It works now. For anyone else who may have the same problem: I upgraded gcc under mingw to its latest version (I had a version &lt; 4.6 as the wiki mentions that higher versions have issues compiling Rust and I thought that was the required version for nightly builds)
This subreddit is for the programming language. Head to /r/playrust :)
Woah: &gt; Conditions in particular need to be removed. https://mail.mozilla.org/pipermail/rust-dev/2013-December/007582.html
I vote for having `optional/keyword arguments` before 1.0
If components are truly independent, and the OS cooperates, you don't need unwinding to kill one (assuming the semantics state that these errors are unobservable "from the inside"). Think process termination (though it could be more light weight than that. If the OS cooperates by tracking ownership of things like file handles in a more fine grained manner you could group handles by component ID and bulk kill them on component termination). I don't know what the plan is to make this work on vanilla windows (if that even is the plan).
Have nothing else to do?
Here is the Github issue where this decision was made https://github.com/mozilla/rust/issues/9795
This is not the Rust you are looking for.
There's an API wrapping `dlopen` and `dlclose` in `std::unstable::dynamic_library`, but it's very unsafe since lifetimes of loaded symbols aren't enforced and types aren't checked.
&gt;Native actor-based concurrency inspired from Erlang. A couple of nits: - Rust offers concurrency primitives which could be used to build an actor model, but does not really provide an actor system out of the box. - While the concurrency system may have been initially inspired by Erlang, the use of green threads is going to be de-emphasized in the near future. The 1:1 scheduler is going to become the default, so each new task will use its own OS thread. Each task will also have a sizable (2MiB-8MiB) stack allocated to it. As I understand things, these changes will make the cost of spawning thousands of threads largely OS-dependent. Modern 64-bit operating systems will dole out smaller pages of the 8MiB allocation as necessary, but this is not a guarantee made by the language. Personally, I hope that M:N somehow manages to make a comeback -- I love Erlang's model of freely spinning off cheap processes (tasks). 
Afaik you will have choice between libgreen (M:N) and libnative (1:1). Are you sure that libnative is becoming the default one? In his talk Alex said that libnative can be useful in kernel and such, does not sound like they want to do away with M:N to me.
First of all, Thank you @adrientetar &lt;3. We need these. But, I have some remarques: 1) I personnaly find the official tutorial much better to begin with. I don't think any *starter* can understand any thing from this tutorial. You can at least point in the begining to the official tutorial. You said that your audience are newcomers, so I think that you &lt;3 should &lt;3 start over. For example, i find it better to introduce the problem of iteration, and how it can be cumbersome. Then introduce the iterator design pattern (using fns and structs for example), and later how traits can be used to abstract it (and generalize it, and make it a joy to write and read loops ...). Finaly show how the standard library implements a lot of iterators for you, and defines many helpfull methods. 2) In chapter 3, in the statement: &gt; Here, we make use of Rust’s functional paradigm by using `.chars()` to iterate over the chars of our string ... I don't understand what does functional paradigm have to do with iterators? 3) You should add a `next` button in the end of each chapter :P thanks again :)
&gt;Afaik you will have choice between libgreen (M:N) and libnative (1:1) True! &gt;1:1 will probably become the default From slide 30 of Alex's talk.
1:1 will become the default, but you will be able to opt-in to M:N easily if you want that instead.
Right I've seen it, he doesn't say why through. Edit: Alex answers the question in the video at 87:06.
https://air.mozilla.org/rust-meetup-december-2013/
2) I totally agree that .map and .zip methods are taken from functional languages. But the statement as it is now does not make sense to me. It mixes a lot of concepts together. Just say: "Here, we make use of Rust’s iteration protcole (**for** e **in** iterator {...}) to iterate over the chars of our string ..." and than you can add , **as a separate feature of iterators**, that they have methods such as .map() and .filter() -like in functional languages- which return iterators. So one can write (**for** e **in** iterator.map(...).zip(...) {...}) which is expressive and very declarative.
1) Just make it clear in the start of the tutorial which concepts you expect readers to already know. &gt; would you want to write something on that? It is a challenge for me. You may have already noticed that i am not a native english speaker :)
Why green threads need so large stack? Is Rust still possible to "create hundreds of thousands of concurrent tasks" describled in http://static.rust-lang.org/doc/master/tutorial-tasks.html ?
Yes. The following runs perfectly fine for me: fn main() { for _ in range(0, 100000) { spawn(proc() std::io::timer::sleep(10000)); } } (The `sleep` is just to ensure that the tasks all exist at the same time.) (Although each task does use 2MB of virtual memory and 8.5kB of RES (i.e. 200GB VIRT and 850MB RES in total), so this requires 64-bit platforms, with memory overcommit/lazy allocation.)
Thanks. Its a pity that it is not possible in 32-bit systems.
This subreddit is for the Rust Programming Language, not the game. You could try /r/playrust.
GODDAMMIT! 
Interesting. Is `rust-lexer.js` hand-translated from libsyntax's `parse/lexer.rs`? It looks quite familiar.
Rather than try to over-engineer it, the easiest solution might be to link any such module with -z nodelete so that it is never unmapped from the process on dlclose (I'm not sure what the Windows equivalent is). This means that the consumed address space is never released, but this shouldn't be a huge concern: * Address space is cheap on 64-bit systems * Most of the pages should be backed by persistent storage (i.e. disk), so the OS can drop them from the page cache if they become unused. * Most applications employing plugin systems do not open and then close a potentially unbounded sequence of unique loadable modules at runtime, so unbounded address space consumption is unlikely. At worst they may close and re-open the same plugin several times, but this will not consume additional space. Note that even if you can ensure pointers into the loaded module do not outlive it, there can be no safe interface to load an arbitrary .so (not even one annotated with special metadata), as it could always contain unsafe machine code. Safe dynamic loading requires the module to be in some form where it can be statically verified as safe by the loader, as is the case for Java class files or CLR assemblies.
Yes. It is hand-translated from libsyntax. Naturally, the goal extends to generating the code automatically. I think it can be done either by * visiting the AST generated by rust code * or translating lexer and parts (subset?) of the parser to JS and spitting code Now that lexer is working, I atleast target its generation automatically. And this is the first step in the direction - understanding the nuances of Rust and JS for a relatively simple codebase. 
Nice work. BTW I think that it would help to rename the chapter titles to make the text more navigatable "Few things you should know" -&gt; "installing rust" "And so it begins!" -&gt; "A simple rust program" "Testing, Logging, Matching… so wird’s gemacht!" -&gt; "Testing, Logging, Matching" "Guess what…" -&gt; "Example: random number generator"
Thanks, I will address this!
This is certainly really cool! (not fan of the highlighting CSS through) Can it be invoked via node to parse code blocks?
Actually, its just collecting the tokens and not parsing the code. Which means * It can be invoked via node to collect Rust tokens from a Rust source file, pointing out any lexical errors. * It is NOT cool enough to parse code blocks.
Ah yes, the basic Rust GC problem. Perhaps the best way to fix it is: * Add a `#[managed]` annotation to force the typechecker and translation to consider a type managed, even if it contains no `@`. * Move the reference counting GC out of `libstd` and into a separate library (eventually to be replaced with this project if successful). * Allow either GC (but not both!) to be linked against in the host program, by exposing generic `managed_alloc` and `managed_free` interfaces and requiring that they be satisfied by one GC or the other. Once this is done, Rust will automatically call the GC to allocate when types that contain managed pointers are allocated on the exchange heap. Having two separate GCs running in the same program doesn't really work. Rust can't do anything about this fundamental law of the universe. So we either need to (a) standardize on one GC or (b) get libraries that want to use the GC to program to generic interfaces.
Rust shares the same alignment with C, so this could be useful for folks wishing to optimise their Rust code.
It can be also important to place commonly used fields together, in addition to compact packing. Someone wrote a tool called [struct_layout](http://blog.libtorrent.org/2013/12/memory-cache-optimizations/) to visualize the struct layout to help optimizations.
&gt; grapheme cluster Thanks for that. A grapheme cluster iterator is exactly what I was looking for (Unicode terminology: so many pitfalls). I would certainly like to see this (and other Unicode algorithms) adopted into the official libraries at some point. Until then, I'll have some fun with rust-grapheme.
/r/playrust
I believe there is a `#[packed]` attribute, but I could be wrong.
Technically not an Unicode algorithm, but I maintain [rust-encoding](https://github.com/lifthrasiir/rust-encoding) for character encoding supports. There is also a reimplementation of Unicode Character Database and related database (e.g. nameprep) called [rust-unicode](https://github.com/klutzy/rust-unicode/).
Wish we could have struct or at least enum layouts 'sorted by alignment' by default, with an attribute for C-compatible layout if desired. We have a lint pass for using non-C-types in extern "C" interfaces already, don't we? ;) Just putting the enum tag at the end of the enum might already save us some padding, since it is rarely going to have to be bigger than a byte and yet is going to take up word-sized space in any enum with a pointer...
There is (only on structs, entirely ignored on enums).
Regarding /u/pcwalton's comment about blessing the best 3rd party build system - I'd have to agree. From working with both [rust-pcre](http://github.com/cadencemarseille/rust-pcre) and [rust-http](http://github.com/chris-morgan/rust-http), both of which generate files at compile time, the `Makefile` based approach is definitely much cleaner, as it doesn't require you to re-write your own utilities as much. Compare [pkg.rs](https://github.com/cadencemarseille/rust-pcre/blob/master/src/pcre/pkg.rs) with [Makefile](https://github.com/chris-morgan/rust-http/blob/master/Makefile) to see what I mean. `rust-pcre` has to re-write lots of stuff that is kind of given for free in `make`, and if you wanted to customize the build process even more, `pkg.rs` will get very verbose very fast. I'm not saying that `make` should be the standard build system (although I don't mind if it is, there is lots of support for it, and the work that /u/metajack has been doing on integrating `rustc` with `make` is great), but I think that we could definitely do better than `rustpkg`.
I think you have the wrong subreddit - did you mean to go to /r/playrust? This is the subreddit for Mozilla's programming language called [rust](http://rust-lang.org).
I would love seeing rust integrates into a CMake workflow, for people who wants more flexibility than rustpkg. It's better to have a cmake integration in the language than leaving other integrates it badly.
`go build` is far too simplistic for a systems language that wants to integrate with C and C++ code as a first-class dependency. Go wants you to write everything in Go, right down to the level of syscalls, but Rust has no such philosophy. That means that we need integration with generic build systems. If we build tooling around an external build system that's equivalent to `go build` to the user, why does the user need to care what build system is being used under the hood? The user won't notice the difference. But it means that we don't reinvent the wheel, and that we play nicer with external packages.
Why would the fact that a loadable crate contains unsafe code make it any more unsafe than a regular crate? - If through metadata and library interfaces we guarantee a type and memory safe API, wouldn't there be little difference between a dynamically loaded crate and a regular one?
Very cool I etch circuit bored for projects very nice
One solution could be to store an integer handle into the textures array instead of a borrowed pointer and avoid on-heap borrowed pointers. A problem with your existing code is that when you resize the textures array, it invalidates all existing pointers to textures, which is why you can't have borrowed pointers stored like that.
Perhaps I'm mistaken about the rust safety model. My understanding is that a safe function is one that is either statically verified to be safe by the compiler, or which the programmer has manually proven to preserve rust's safety guarantees. Since dlopen can cause arbitrary code to be executed, there is no way for the author of the dynamic crate loading interface to meet this proof obligation. Verifying the metadata doesn't help if the metadata is lying about the machine code. Verifying the machine code would be equivalent to solving the halting problem. To put it another way, the interface is safe only if the user loads trusted libraries with it and unsafe otherwise. This means the functions must be marked unsafe, and the client application inherits an obligation to prove it does not load libraries that have been tampered with.
In other words, the type system caught a nasty memory safety bug :)
That's not even possible—what would own the textures vector? It’s the Game that owns it, hence `~[Texture]` is needed.
C++ programmer lurking in the Rust subreddit from quite a while here - in my game engine I have a `std::vector&lt;std::unique_ptr&lt;Texture&gt;&gt;`: how can that be translated to Rust code, and would it work in the situation the OP described? Thanks.
I do not think it is fair to use the current state of `pkg.rs` as an argument. It's known to be a convoluted way of doing it and it could be done significantly more nicely yielding a result not so very different from the makefiles. Also once [#11151, RFC: Externally loadable syntax extensions](https://github.com/mozilla/rust/pull/11151) is ready and lands, rust-http's need to generate files before compilation will be gone—it will then merely depend upon another crate to define the macros it needs to generate in the compilation step those things that formerly were generated to disk before compilation.
Why would Rust support ~[@T] is it a must have feature? I think that NO. I think that it just complicates the implementation of the GC and slows it down. If the task's stack is the only thing that owns GCed pointers, the conservative GC will never need to scan any object outside the local heap which is a big performance win. Moreover, It may be faster to allocate `@[ ]` than to allocate `~[ ]`, right? So what's the point from having ~[@T] at all! I am arguing here against any `box(R) T` where `R` is not `GC` and `T` contains GCed pointers. What do you think?
Fair enough. That still wouldn't remove `rust-pcre`'s need to generate code, although I'm still not sure that `rust-pcre`'s code-gen is the correct way of doing it either. I do look forward to seeing `pkg.rs` improve greatly.
`~[@T]` is not `Send` (`~[T]` is `Send`able if and only if `T` is `Send`), and so cannot be transferred to other tasks, hence the GC will only ever need to be task-local. (It is semi-feasible that `~[@T]` would allocate memory from the GC, and the destructor would tell the GC "this memory is definitely unused", rather than directly `free`-ing it like `~[T]` does normally. i.e. it would essentially be `@[]` in terms of allocations, but not in terms of semantics, since `~[@T]` would still be resizeable.)
I just pushed [some bindings](https://github.com/huonw/boehm-rs/blob/8da9f04c997bfac34c19c28c25e6314bcd6da937/src/tracing/mod.rs) to [gc_typed.h](http://www.hpl.hp.com/personal/Hans_Boehm/gc/gc_source/gc_typedh.txt) (for precise-on-heap operation). [Example of the difference it makes](https://github.com/huonw/boehm-rs/blob/8da9f04c997bfac34c19c28c25e6314bcd6da937/examples/tracing_example.rs). Unfortunately, we *really* need compiler support for generating the pointer maps; I'm doing it a via hand-written trait implementations there, but it's very hard to write [a correct implementation](https://github.com/huonw/boehm-rs/blob/8da9f04c997bfac34c19c28c25e6314bcd6da937/src/tracing/boehm_traced_impls.rs#L57) for (e.g.) `Option&lt;T&gt;` since there's (at least) the nullable pointer optimisation, and the discriminant &amp; it's padding isn't a fixed size (I guess my one there is incorrect, in any case), also, using a trait like that has the unfortunate side-effect of needing to be regenerated for every allocation... so it's super slow.
&gt; the GC will only ever need to be task-local. I though that since the GC is conservative, it must follow even owned pointers since it doesn't know their types and whether they lead to GCed objects. So that the GC *is* task-local. But will end up traversing objects belonging to the exchange heap. Is that right ? and are there any documents/wiki-pages explaining how rust's GC is supposed to work?
Long ago the goal for 1.0 was to be precise on the heap and conservative on the stack. I'm not sure if or how this might have changed in the past few months.
"Exchange heap" is an obsolete concept. There's a `contains_managed` intrinsic that could be extended to user types (perhaps via a `#[managed]` attribute), which can be used to avoid tracing more than necessary. The goal right now is still to be precise on the heap and conservative on the stack.
&gt; is it a must have feature? I think that NO. If it doesn't support `~[Gc&lt;T&gt;]` and `~Gc&lt;T&gt;`, none of the containers in the standard library will work with managed pointers. Managed slices cannot be resized.
&gt; The resizeablity of `~[T]` does not count, since it is a special case which is hard coded to the language. It's a library feature. It's not possible to have a vector use shared ownership and be resizable without indirection, and `Gc&lt;RefCell&lt;~[T]&gt;&gt;` already provides that functionality.
Something simpler: Can multiple sprites borrow from one, mutable container? struct Texture(i32); struct Sprite&lt;'s&gt; { tex : &amp;'s Texture } fn main() { let mut textures : [Texture, ..10] = [Texture(0), ..10]; let mut sprites = ~[]; textures[0] = Texture(0); sprites.push(Sprite {tex : &amp;textures[0]}); textures[1] = Texture(0); sprites.push(Sprite {tex : &amp;textures[1]}); }
Any owned pointer/vector will need to be registered as a GC root for the GC to follow it, and those that are transferable between tasks won't be registered, so they will be automatically invisible.
&lt;3 this class, going where no lecturer has been before. &gt; Many did things that I think are very impressive and will be useful to the larger Rust community and to future offerings of this class I think Kiet Tran (aka ktt3ja)'s dead code work (which isn't mentioned in that section) is the project that has the broadest impact so far: there was a *lot* of cruft in the main codebase that was picked up and removed by that change, including multiple tests that were missing the `#[test]` attribute (some of which I wrote... whoops!). And I've certainly had bugs picked up by it in my own code (normally little ones like forgetting the `pub` on things I'm trying to export when writing a library, but a few bigger ones, e.g., where I'm calling `if ... { foo() } else { foo() }` rather than `if ... { foo() } else { bar() }`).
This is a fantastic post-mortem. It's so exciting that a significant portion of the class didn't hate Rust! I lol'd at the student saying "Rust documentation is god awful", which is true, but it's getting better. Next year Rust will be even better for this type of work. Hopefully we can have large chunks of the standard library usable in kernel space by then.
I also really liked that "Rust changes the way you think". That's a pretty awesome compliment.
This was an excellent read. It seems student response overall was positive towards rust, even if it was an outdated version of an incomplete language. This is just proof that rust is going the right direction and is only going to get better with time. Personally, I'm excited for v1.0, so I can start using rust knowing that there won't be any major language breaking changes while I'm developing something.
This is similar to what I was doing coming from C++ background. Storing borrowed pointers in structs should be done for instances with short lifetime I believe. **I am not an expert, so I might be wrong on this, but:** In your example, you won't be able to expand your textures array, even if you change it to an owned vector. What is more, you won't be able to mutate any texture using the textures array **while** it's borrowed in a sprite.
Really? D is on its way out? Nice to see he didn't actually look at the choice. Also go is not a systems programming language.
I got the following to compile. struct Texture(i32); struct Runnable { val: int } struct Game&lt;'s&gt; { priv textures: ~[Texture], priv sprites: ~[Sprite&lt;'s&gt;], priv engine: Runnable } struct Sprite&lt;'s&gt; { tex: &amp;'s Texture } impl Runnable { fn run(&amp;mut self, sprites: &amp;~[Sprite]) { self.draw(); } fn draw(&amp;mut self) { } } /* fn why_illegal(game: &amp;mut Game) { game.sprites.push(Sprite{ tex: &amp;game.textures[0] }); } */ fn main() { let mut g = Game{ textures: ~[Texture(1), ..4], sprites: ~[], engine: Runnable{val: 10} }; g.sprites.push(Sprite{ tex: &amp;g.textures[0] }); g.engine.run(&amp;g.sprites); g.sprites.push(Sprite{ tex: &amp;g.textures[2] }); g.engine.run(&amp;g.sprites); } I still don't understand why "why_illegal" is illegal as in this thread's original problem. 
&gt; I'm not aware of any other language that has concurrency constructs as elegant and easy to use as Rust's spawn, and I don't know of any language that comes close to the race-free safety guarantees provided by Rust. Erlang?
That is exactly correct: mutating a vector could invalidate the reference (e.g. `.push`-ing to it could cause it to be reallocated and change it's position in memory, so the reference is then left pointing to invalid memory).
I'm not sure if D is: &gt; most D code - including the runtime and standard library &gt; - assume that a GC is present, and thus may leak memory. From: http://forum.dlang.org/thread/kjo7id$22jk$1@digitalmars.com
The verbosity of `RefCell` should vastly improve with Niko's changes to make the lifetime of temporaries extend to the whole statement, which should land hopefully next week-ish. It'll also get much better with the `Deref` family of traits, which are under discussion. In general removing `@mut` seems to have cut down on dynamic borrow check failures quite a bit. The remaining issue is verbosity, which is much easier to solve.
I've never been much hurt by the single `=` allocator personally, and I think that it's much better than having to write 2 characters each time. It is a large convention of programming languages today anyways, so you can't really learn CS and bypass that.
You could argue it's not a great systems language, but given that D's runtime including GC is itself written in D, it is a systems language.
I agree, and I also agree with the premise :) Rust's emphasis on lifetimes is rarely encountered, I must I actually discovered it with Rust though I guess some obscure languages probably used it before :p However the lifetime of objects *is* crucial: - C: incorrect idea of lifetime leads to use after free (which can also be seen as an ownership issue) - Java &amp; al: space leaks... (or the ever growing cache syndrome)
Well, despite the recent announcement that a whooping 5,000 lines of D code was used in production at Facebook it is not really a successful language is it ? Scala is much younger and already widely used in the industry in comparison. So "on its way out" might be overstating it, but I think that D was not revolutionary enough to be worth the switch.
I had no idea he was a student from that class. Well done!
Really? So your just gonna ignore Remedy Games writing a new game in D. Or Sociomantic Labs? There are a couple more that I can't remember off the top of my head. Not just overstating it, simply plain wrong. As an aside, Scala runs on the JVM. Apples to oranges.
Congratulations on getting this tricky PR through bors. Must have been bloody annoying!
Wrong subreddit, this one is about the Rust programming language. I think you want to be here: http://www.reddit.com/r/playrust
The lectures weren't recorded but all the slides and notes are posted at http://rust-class.org. I'm not sure if I'll be able to record the spring class, but if you are interested in following it please submit the form here: http://rust-class.org/pages/spring2014.html
Your work on removing @ pointers from the language in favor of a library solution is probably one of the more exciting things to me. Having GC handled through a library is a good idea. To me it makes it clear that GCed pointers are more of a last resort sort of thing, while simultaneously making the language that much more flexible (since you can use placement new to box up data into whatever you want). Only thing I'm probably more excited for is struct inheritance. Between placement new and struct inheritance, I'll have essentially everything needed to really dig into COM with Rust.
No, you can't do that. You should probably put the Textures inside the Sprites, or put an Rc&lt;Texture&gt; inside the sprites if the textures are shared. Alternatively, if you don't need to add textures dynamically, you can move the textures array to a local variable in main() and put a borrowed pointer to it in Game. As for why you can't do that, it's because to hold a borrowed pointer, the compiler must statically know at all times that the array is borrowed, which means you can't modify it in any way, and cannot go out of the lexical scope where you borrowed it. 
Then don't use them. It really is that simple.
And have to duplicate all that functionality (and the debugging that's gone in to it)?
If they sort out the `@safe` subset and port standard library allocations to use `Allocator` interfaces, I think those will be significant changes. I have no idea when those will be addressed. There are significant things, generic programming support is much better in D, e.g. it allows templating on a string literal, which C++ does not. C++ libraries tend to use null-terminatated strings, which often cause performance issues (or worse). There are various things which all add up, depending on the use case.
I really, really, appreciate that you took the time to prepare an animation showing off exactly what this small example yields as an output. It might not be very technical, but it does raise the attractiveness of the article (and thumbs up for using the Rust logo). On the technical side, I am very much looking forward to Cap'n Proto and it is sweet to see that Rust can be used to implement such low-level logic. Did you experience any specific difficulty or are there specific performance issues you would like to report ?
There is a forum discussion about "[Inherent code performance advantages of D over C?](http://forum.dlang.org/thread/l7tij3$v6m$1@digitalmars.com)". If D programs are faster than C/C++, it matters. So far there is some evidence but nothing irrefutable. Most (or all?) of the arguments apply to Rust as well, though. It is possible to combine C++ and D to some extend, so C++ shops might be able to slowly migrate from C++ to D. I do not know any other language, where is is possible. Rust can only be combined via the C-subset of C++.
&gt; If they sort out the @safe subset and port standard library allocations to use Allocator interfaces, I think those will be significant changes. I have no idea when those will be addressed. `@safe` requires garbage collection. As far as I'm aware, there are no plans in D to add safe unique pointers and lifetimes (and IIRC Andrei has explicitly spoken out against them on Reddit, considering them too complex). So Rust remains the only language that offers memory safety and data race freedom without garbage collection.
I expect Rust to grow native C++ interoperability to the same degree as D. Here's the open issue for it: https://github.com/mozilla/rust/issues/5853 All it requires is someone to put in the (considerable) effort. Note as well that good C++ interop will be crucial for Servo, which needs to intimately integrate with SpiderMonkey.
I do not think the intent is to delete a texture after the last sprite stops using it - would you like having to load, parse, and upload a PNG file every single time a monster moves on and off screen? Garbage collection is clearly not the solution here. But borrowed pointers in structs are awkward to use. Handles aren't as bad as tagging a large number of structs and functions with lifetime parameters, at least to me.
Whether ~[Texture] is sufficient depends on whether you find it acceptable for the Texture to move every time the vector is resized, which you can't do if you need to maintain borrowed pointers to it.
And I just started my own redis library: https://github.com/mitsuhiko/redis-rs/ //EDIT: I think I like mine a lot more
The game "Rust" is this way: http://www.reddit.com/r/playrust
What would be the salient differences?
Any chance of a video of this? I am interested in Rust + C++ interoperability 
If the code is downloaded in source form ,then the Rust compiler can guarantee its safety by enforcing the additional restrictions being explored in this discussion.
I'm afraid you are on the wrong subreddit, this one is for rust the programming language. I think you're looking for /r/playrust.
It already wraps many more commands :)
I really enjoyed reading this, though I'm still quite a rust ingenue, not having written any rust code yet. I have one probably stupid question: does this proposal imply that ~[T] will become un-resizable, as mentioned in part 1 of the series? How will the traits (or something else) pick up the slack?
FWIW I think `~[T]` under this scheme *should* still be able to support resizing, just not efficient appends. You should still be able to decrease the size cheaply, and to increase it at the cost of a reallocation each time (and of course you would have to provide something to initialize all of the new elements with). What you lose is the ability to grow the vector with cheap incremental appends by keeping track of a spare capacity, like the presumptive `Vec&lt;T&gt;`. (I'm thinking `Vec&lt;T&gt;` itself could probably be built on top of `~[T]` using these features, with a bit of unsafe code to permit uninitialized elements in the unused capacity.)
I imagine Vec&lt;T&gt; would be an ordinary object type, not a trait? Which would leave the generic treatment of vector-like containers to iterators and the (currently rather sparse) set of container traits. How would allocator support look, in this scheme? Would one hack on libstd? 
Yes, an ordinary type. &gt; Which would leave the generic treatment of vector-like containers to iterators and the (currently rather sparse) set of container traits. Aren't we are already in this situation? &gt; How would allocator support look, in this scheme? Would one hack on libstd? One possible design for allocators would be something like (**NB**, this is just off the top of my head, not at all authoritative): struct CMalloc; impl Allocator for CMalloc { fn malloc(&amp;mut self, size: uint) -&gt; *mut u8 { libc::malloc(size) } fn calloc(&amp;mut self, size: uint) -&gt; *mut u8 { libc::calloc(size) } fn realloc(&amp;mut self, size: uint) -&gt; *mut u8 { libc::realloc(size) } fn free(&amp;mut self, size: uint) -&gt; *mut u8 { libc::free(size) } } struct Vec&lt;T, Alloc = CMalloc&gt; { length: uint, capacity: uint, data: *mut T, alloc: Alloc } which uses [default type parameters](https://github.com/mozilla/rust/pull/11217) (haven't been accepted yet). The fact that `CMalloc` is a zero-sized struct means that, by default, this is precisely identical to `struct Vec&lt;T&gt; { length, capacity, data }` without the allocator parameter, but gives one the flexibility to use other allocators.
The removal of dereferencing for newtypes is a bit painful, I think it will make using newtypes a bit too fussy. I mainly use them to wrap different kinds of numbers so I don't mix them up in argument lists and to make the function signatures clearer.
The reallocations would be amortized, as most allocators know the size of the allocation. An idea I saw some time ago (and I really like) is to remove all growable functionality from `~[T]` (or `Uniq&lt;[T]&gt;` as it may be in the future) and allow cheap conversions from `~[T]` to `Vec&lt;T&gt;` ("thawing" the length) and back to `~[T]` ("freezing" the length and discarding the capacity).
&gt; The reallocations would be amortized, as most allocators know the size of the allocation. Yes, but I doubt they over-allocate by the right amounts. :) &gt; An idea I saw some time ago (and I really like) is to remove all growable functionality from ~[T] (or Uniq&lt;[T]&gt; as it may be in the future) and allow cheap conversions from ~[T] to Vec&lt;T&gt; ("thawing" the length) and back to ~[T] ("freezing" the length and discarding the capacity). Yep, and if `Vec&lt;T&gt;` contains an `~[T]` internally this would be even easier to implement.
From the PR(https://github.com/mozilla/rust/pull/11188): "This ad-hoc behavior is to be replaced by a more general overloadable dereference trait in the future."
AFAIU, Andrei is against Rust's lifetime annotation. I don't see why D would be against memory safety without GC, just that they don't want to copy Rust's solution. Perhaps a simpler solution is possible, who knows.
I am saddened at my inability to know this.
(I'm assuming you're saying that we should be using `~[T]` as "backing storage", so the length of that is the capacity, and then store the actual length of currently-used elements separately.) &gt; less unsafe code Trying to fit uninitialized elements into a `~[T]` will be quite hard to without significant unsafe code, and will require destructor/transmute magic. (*e:* to be clear, the destructor on `~[T]` would run the destructors of each element, and so you would have to find some way to stop this... maybe setting the length shorter before dropping it, but that seems to go against "less knowledge of the representation of `~[T]`.) &gt; less duplication Maybe a little, but you still have to duplicate some things. Example off the top of my head: you have to reimplement the bounds checking &amp; indexing on `~[T]`, since they will be working with the capacity, not the length. &gt; less knowledge of the representation of ~[T] I'd guess that you end up requiring complete knowledge, either for performance, or safety or, most likely, both. &gt; easier support for converting to and from same. How common will this be? (Not to discourage you from trying though.)
It's totally possible that you're right. An alternative strategy could be that the length stored in the `~[T]` is the actual length, the capacity is stored separately in the `Vec`, and there's an `unsafe fn unsafe_set_length(v: &amp;mut ~[T], l: uint)` which `Vec` uses when it knows that `new_length &lt;= capacity`. I haven't thought this through: do you see obvious problems with it?
Lots of really exciting changes this week. I've been following the [external syntax extensions](https://github.com/mozilla/rust/pull/11151) PR since it appeared. That one is really exciting to me as it really opens the language up to a lot of cool extensions (really robust code generators for example). The UDP IO is interesting. It's an area that I'm more familiar with than I'd like to be. Especially when it comes to edge cases like IGMPv3 for IPv4. Glad to see that coming about. I've got some applications I'd absolutely love trying to rewrite in rust that make heavy use of UDP multicast.
I don't think it is possible to have a less annotation-heavy solution while still retaining the flexibility and expressivity of Rust's solution.
Well, performance on par with C++ is already good news. I/O slower than C++ is a bit worrying since C++ I/O is already slower than C I/O, but there is no fundamental reason than Rust I/O should be slower than C I/O so I am hopeful that this can be solved somehow (though the problem may lie in the Rust runtime itself).
&gt; The biggest issue that I have with Rust, right now, is the lack of compile time features. Huh? I'm not entirely familiar with the value of templates and CTFE, but the borrow checker and other compile-time niceties of the Rust compiler should not be taken for granted. :)
https://mail.mozilla.org/pipermail/rust-dev/2013-December/007565.html has all the details. Most of the IO is implemented; all that's left is unix sockets and DNS. The rest is either landed or has patches.
CTFE lets you more or less interpret functions at compile time; basically const folding on steroids. That, plus the `mixin` statement, which lets you insert arbitrary strings of code at compile time, let you do some pretty crazy stuff. A realistic example of what this lets you do I point people to is my project [temple](https://github.com/dymk/temple), which makes heavy use of this. If Rust introduces features like this, then I'd waste no time porting my projects to Rust. 
tl;dr: docs. :/
Was interesting seeing the feedback from the students. It is pretty obvious that the documentation is lacking. That's something that is improving, but I don't think will get pinned down to the point of being top notch documentation until rust stabilizes at 1.0
Is this API style based on another well-known project? e.g. .lookup(), .lookup_path() I'm toying with a project of my own and if this is a known API style, I'll go ahead and mimic it.
I think the doc situation was particularly bad because IO was in a massive transition. std::io was the old. It worked, but was klunky and not very featureful. std::rt::io was the new, worked good most of the time, but was documented very incompletely and sometimes the docs were wrong (because they were describing the interface-to-be rather than the interface-that-was). More complete API docs and a larger portfolio of simple examples will help the most, I think.
Maybe we should make it say "The Rust Programming Language" in all caps on the page header. :P
Certainly. Have to consider these students were working with rust 0.7. That was in the midst of some very big, transitional language and library changes. The documentation is far better now than it was, but I feel like once rust reaches a stable state at 1.0 the task of documentation will be much easier (won't have to worry that a feature will suddenly disappear on you) and more people will feel more confident in contributing to the documentation.
I'm not sure, but I was just thinking that making a trait for things like this would be useful. For example, in Ruby land, we have `load`/`dump` implemented on most parsers. So you `JSON.load(foo)`, `YAML.load(foo)`, etc. I don't care what the actual interface is, just saying it'd be nice to have all of them on the same page.
Plus we have the new rustdoc now, and I think people will send pull requests adding examples as they try to make use of libstd methods (I know I did).
Yes, since that damn game was launched (lol) this reddit receives weekly game posts ; - ;.
Agreed, that would be very useful! I wrote something similar to the TOML parser's API, but used 'find()' and 'find_path()' since that's the verb used in extra::treemap::Treemap. I also used a Result as my return value instead of an Option. It'd be nice to have an interface to implement so I don't have to be creative. :P
Thanks for the explanation. :) It just sounded funny at the time to hear it phrased in such a way that made it sound as if there are a lack of statically *checked* features in Rust; yet in the context of speaking about templates and CTFE compile-time features is probably about as succinct you can get.
I can't think of anything; but I'd much prefer it being completely in libraries: easier to adjust and micro-optimise than trying to coerce the compiler provided things to help. (For example, [this vector implementation](https://github.com/thestinger/rust-core/blob/master/core/vec.rs) is only 200 lines long, and provides most of the functionality one would need from a vector (not all the sugar that we have in the stdlib, though).) 
An in-memory map isn't going to have more than one error case to report, and is going to want to return a reference rather than an allocated value. A trait doesn't really work for both unless you're memory mapping the configuration file, returning wrapped slices and not distinguishing between errors.