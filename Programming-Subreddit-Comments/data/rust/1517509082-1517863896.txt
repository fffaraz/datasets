Yep, these are the same problems that GC integration ran into.
bad bot
Thank you for feedback, really glad it helped!
Ahh, so similar to Lokathor's comment just a different paradigm. In certain places would this allow casting? `custom_enum as bool`?
&gt; With the introduction of L0 That's what came into my mind too. I'll remove it and make it like it was before. &gt; If you are trying to find out the distribution of the brackets in the final layer for something, Yes, that's what I wanted to do, but I don't want to use a simple fn.There are two reasons for that. There is a small Mall where I live and for children the have setup a few "Experience Math" stands. One of them had a [Galton Board](http://physlab.org/wp-content/uploads/2016/03/Galton_Board_5.jpeg) similar to the picture but bigger. I wanted to rebuild that in Rust. :) Second reason is that I just enrolled for the Coursera course "Model Thinking" by the UMich and to fully grasp all the concepts I want to do as much low level stuff as possible instead of just google and use a standard deviation calculator or six sigma calculator or a rust fn :) thank you for your help.
`as` casts are different from using `From`/`Into`. `as` is reserved for primitives such as integers.
&gt; You can put everything behind Rc's/Arc's but that has a huge performance cost compared to a generational gc. Citation needed. ;) Please correct me if I'm wrong, but the only that is expensive there is atomic increments/decrements and (less so) pointer dereference. Point dereference is the same in GC and non-GC case. Atomic operations might actually not be that common. It depends on number of aliases. One would have to compare that to cost of GC scans, etc. My intuition tells me Arc/Rc should be usually much faster, and the only big problem with them is possible cycles, which can be a huge PITA.
Ok! Thanks for the clarification!
This is possible in Rust üòâ use std::ops::Not; impl Not for CustomEnum { type Output = bool; fn not(self) -&gt; bool { match self { CustomEnum::True =&gt; false, CustomEnum::False =&gt; true, } } } let x = CustomEnum::True; if !!x { /* ... */ }
*Darn it* vitiral, I am not a bad *darn* bot... :c *Beep boop*, I am actually a sweet bot. *** ^^Darn ^^Counter: ^^57510
Having implemented a double-ended vector in C++, I still have nightmares about the shuffle routines. When move can throw on a per-element basis, it's really hard to shuffle elements in an array. It's definitely NOT an advantage I'd toss away.
For some reason my reply is invisible: https://www.reddit.com/r/rust/comments/7tod2a/hey_rustaceans_got_an_easy_question_ask_here_52018/dtkzwr2/
I mean, that's nice, but it has 1 contributor and 27 commits. It doesn't exactly seem like a tool people are really using. More importantly, I can't find any examples of how it would be used. Their docs are about as descriptive as that simple link.
Since you asked; no, the documentation still does not work for me, I'm sorry. I'm not sure how much weight you should put on just my feedback, though. I asked for a motivating example [on module level](https://docs.rs/taken/0.1.1/taken/). I think this would be helpful as a softer introduction than [the gory details of the macro](https://docs.rs/taken/0.1.1/taken/macro.take.html). The macro documentation appropriately starts by describing what is specifically does. But this seems premature for me, I have no motivation for doing that thing quite yet. Similarly with your second example of the macro, "It also allows you to _change_ the mutability of variables more concisely." I still have no idea of why I want to do the _basic_ thing, I think it is premature to explain the advanced thing. The examples listed under "Examples" do not show the alternatives. I tried to explain what I think I need: 1. What the code one typically initially would write would look like. This would contain a compiler error 2. How to make the code work without `take!` 3. How it would look with `take!` So, that's my two cents for improving the documentation. Take it for what it's worth :)
Not everyone can pick their distro. For example, for work environments, I'm banned from using rolling distros.
It would be nice if what Niko developped could be used in rpds.
It works now. I crossed checked with an online calculator and it gives out the same values. woohoo, finally something useful I did with rust :)
I wrote a tool for my job that includes a feature like this. I can't publish the tool, but I did publish a crate I wrote for the fuzzy text matching I use: [ngrammatic](https://crates.io/crates/ngrammatic). Basically, I iterate over a folder full of known licenses' text, add the contents of each license to the ngram corpus. I think I used trigrams, with two-space padding. At least, I'm pretty sure that's what I set the default to be in ngrammatic.
xi uses a rope based on arc, and get_mut to do mutation when things have a refcount of one, which is an interesting take on this
such is reddit; it's certainly not a thing run by /r/rust directly. i find these bots really annoying, personally.
&gt; and the lack of generics and scheduler control means you can't really build abstractions on top of them. I mainly pointed to this to show that it is possible to build abstractions op top of them. 
I've also looked at harvesting the text from more file types than just plaintext - rtf and pdf. I ran into a whole bunch of very immature crates (a file type detection crate that gave wildly, obviously wrong results in very simple situations, a pdf parsing crate that really only parsed out images, xml dom parsing crates that traded correctness for speed, etc). I wound up farming out a bunch of functionality to external tools (unrtf, pdftotext) and libraries (libmagic), as a result.
/r/playrust
Would you be willing to provide this "equivalent code in C" that you're referring to? It's really hard to draw comparisons otherwise.
True, thinking more about it it probably would come down to usage patterns. Doing a chain of transformations on an immutable tree without fusion produces a ton of short lived garbage that's almost free for generational gc's. But it is possible to use things like zippers to trade that garbage for mild amounts of extra work. Iirc a lock prefix costs a cash miss which isn't great but probably won't matter outside a loop. 
I will note a few small things: let mut vec : Vec&lt;Vec&lt;i32&gt;&gt; = Vec::new(); should probably be: let mut vec: Vec&lt;Vec&lt;i32&gt;&gt; = Vec::with_capacity(x); and then let mut entry : Vec&lt;i32&gt; = vec![0; len]; this line is initializing the entry `Vec` to `0`... every single element. Then you follow up by doing for k in 0..len { entry[k] = kval; which will _probably_ have the bounds checks eliminated, but there's a chance they aren't. a better way to write that code if we're going this route would be as such: for k in &amp;mut entry { *k = kval; kval += 1; } then it's getting a mutable reference to each element and assigning the value. there should be no bounds checking here, and there's less room for mistakes. But, the more idiomatic way to write this code from the beginning would have been something like this: let mut entry = Vec::with_capacity(len); for kval in 0..len { entry.push(kval); }
Sure, I'm actually in the same boat.
askalono employs a similar strategy; it preprocesses texts into bigrams (stored as 2-tuples of words). I experimented with trigrams and even single-word-as-a-grams but didn't find a noticeable improvement. But I'm not a statistician, so it's entirely possible that could perform more accurately when weighted appropriately. Looking at the code now, I left that in; there are a few unused functions ending in `_three` and some commented-out logic to combine 3 types of ngrams. I should probably just remove that at this point.
&gt; The basic rule of thumb is, if you can call C code from it, you can call Rust from it. You can call C from Java, but you can only pass a small set of primitives as parameters or return values. You can't pass structs or objects. You can't even pass pointers, really. You can send a pointer from Java, but it turns into an opaque handle on the C side. There is then a C API for querying Java objects using those handles. There are a few special Java classes which have slightly richer interfaces on the C side. There is no general way to convert a blob of bytes into an object or vice versa, nor to convert a pointer to a blob of bytes into a pointer to an object or vice versa. Perhaps the most relevant special class is ByteBuffer, which you can convert to or from from a pair of a pointer and a length in C, and access somewhat like an array in Java. You could use that to pass a pointer to a Rust struct into Java, which could then see its raw bytes. However, to make sense of those raw bytes, you would need to know the exact layout of the struct - the offsets and sizes of the fields. With that information, you could translate the bytes into a fresh Java object, or write a proxy that exposed the fields through method calls. This is all absolutely possible - and i've handrolled stuff like this myself - but to do it automatically takes a little bit more information that is currently available in the generator script. I sense we may be talking at cross purposes here - apologies if the above is irrelevant or obvious. 
Absolutely. I have included it in this comment, but if you think it is more appropriate to include it in the body of the post please let me know and I will move it. Thank you very much for the helpful notes in your other comment! #include &lt;stdlib.h&gt; #include &lt;stdio.h&gt; #include &lt;math.h&gt; #include &lt;time.h&gt; #include "kvec.h" int main(){ // Declare the sizes: int N, len, j, k ; N = 1000 ; len = 10000 ; // Declare the vector of arrays: kvec_t(int*) vec ; kv_init(vec) ; clock_t start = clock() ; // Populate each of them: for(j=0; j&lt;N; ++j){ int* newar = malloc(len*sizeof(int)); for(k=0; k&lt;N; ++k){ newar[k] = k ; } kv_push(int*, vec, newar) ; } clock_t stop = clock() ; // Print and free: for(j=0; j&lt;N; ++j){ printf("The third value in the array was: %d \n", kv_A(vec, j)[2]) ; kv_A(vec, j)[2] = 10 ; printf("I just changed it to ten. Here it is now: %d \n", kv_A(vec, j)[2]) ; free(kv_A(vec, j)) ; } kv_destroy(vec) ; printf("It took %f seconds to do this. \n", (double)(stop-start)/CLOCKS_PER_SEC) ; }
The biggest difference, based on your description, is that your bigrams are composed of two _words_, mine are composed of two _characters_. My approach uses a ton more memory, for essentially no improvement in accuracy, but this just happens to be one of a lot of applications for fuzzy text matching in my tool, and the only one that suffers from character-level ngrams.
Okay... so, I tested this on my computer, and I know exactly what you did, with a high degree of confidence. You compiled the Rust code in debug mode. Using your code: | Rust | C |----|- Debug | 0.557 | 0.008 Release | 0.004 | 0.007 For some reason, the C code in your example is not really affected by optimizations, but the Rust code absolutely is. For performance comparisons, always compile in release mode. If you're just compiling the Rust file directly: rustc -O test.rs or if you're using `cargo` (which you really should be) cargo build --release
One thing to note is that even your current version will run in 0.02 seconds if you build it with the --release flag. As for collecting the vectors more idiomatically, there are a few ways you can do it. You can replace this whole block: for _j in 0..x { let mut entry : Vec&lt;i32&gt; = vec![0; len] ; let mut kval:i32 = 0; for k in 0..len { entry[k] = kval ; kval += 1 ; } vec.push(entry) ; } with this: for _ in 0..x { vec.push((0..len).map(|x| x as i32).collect()); } or even with this if you're so inclined: let mut vec: Vec&lt;Vec&lt;i32&gt;&gt; = (0..x) .map(|_| ((0..len).map(|x| x as i32).collect())) .collect();
Thank you very much for the feedback! You were dead on about my incorrect compilation options. I should have been more clear about this in the body of my post, but filling in the values of the inner vector (entry) will be covered by some form of obtaining matrix elements---so I probably can't use map in as slick a way as you do. But between your feedback and others I've gotten, I definitely have a better impression about how to do so idiomatically. Thank you again.
but, to answer your question, there is no way. The `Vec` itself is allocated on the stack, and that same piece of the stack is getting reused with every loop iteration. if you could push a reference to it, then every reference in `vec` would be the same pointer, and that's obviously undesirable. The `Vec` is stack allocated, but the `Vec`'s element storage is allocated remotely on the heap, as you would expect.
Wow, so even when I push entry : Vec&lt;i32&gt; onto my vec : Vec&lt;Vec&lt;i32&gt;&gt;, it is actually just creating a new pointer to the piece of memory (which is 10000 int32s) and putting that on vec? I would have thought that calling vec.push(entry) would copy the 10000 int32s onto a new piece of memory and then provided a pointer to that memory to vec. That certainly makes me feel less confident about when things are getting copied versus passed by pointer/reference. Or am I misunderstanding something?
The `push` function *moves* its argument, which is equivalent to a `memcpy` where you can't access the original afterwards. Let's try to access `entry` after it gets pushed: for _j in 0..x { let mut entry: Vec&lt;i32&gt; = vec![0; len]; let mut kval: i32 = 0; for k in 0..len { entry[k] = kval; kval += 1; } vec.push(entry); let z = entry[0]; } when we go to compile it, we will get this error: error[E0382]: use of moved value: `entry` --&gt; src/main.rs:17:17 | 16 | vec.push(entry); | ----- value moved here 17 | let z = entry[0]; | ^^^^^ value used here after move | = note: move occurs because `entry` has type `std::vec::Vec&lt;i32&gt;`, which does not implement the `Copy` trait So, the value gets *moved*. The compiler might optimize the `memcpy` away entirely, but at most it will be `memcpy`-ing the 24 bytes that the `Vec` consists of. (possibly 32 bytes, depending on if there is any padding for alignment, which I'm not sure if there is.)
Another interesting article on this: https://blog.plan99.net/modern-garbage-collection-911ef4f8bd8e 
&gt; That certainly makes me feel less confident about when things are getting copied versus passed by pointer/reference. If you pass something in Rust, it is passed by-value, unless you explicitly take a reference to it. But, the confusion here lies in the data structure itself. Rust won't do expensive copies unless you explicitly tell it to, like saying `entry.clone()`. If you haven't used `clone()` or some other similar method on an object, you should feel confident that what you're doing is not going to create an expensive copy operation.
I'd use a template like https://github.com/japaric/trust/: this uses appveyor &amp; travis CI to make Linux, Mac and Windows binaries. You can then release using a git tag (`git tag -a v0.1.1 &amp;&amp; git push --tags`), and trust should build binaries and upload them under "Github Releases".
&gt; Can you clarify what relationship this has with SWIG? Relationship is in the abbreviation([The Simplified Wrapper and Interface Generator](http://www.swig.org/)) and in the global idea to simplify usage of one language from many others. That's all. Because of a different language (Rust vs C++ in the original), a whole different infrasturture and possible solution based on avaible technologies they are completly different projects.
I appreciate the discussion :) Maybe it's better to say that you could generate Java classes that match the rust structs, but that wouldn't necessarily help you decode the struct in Java?
Wow. Thank you for such detailed and informative answers. I clearly do need to spend some more time with the book. Thank you again for your time!
I wrote a macro to do this, but first it converted to rpn. It turned into a huge mess, so I ended up generating it with a build script. Here's a link, if anyone's interested (or has suggestions for cleaning it up!): https://github.com/paholg/typenum/blob/master/build/op.rs
Strange! I see it in my messages, but not in the thread. For the https://doc.rust-lang.org/error-index.html#E0038 entry, I think those are just stored in the rust source code (https://github.com/rust-lang/rust/blob/fdecb0564b86f6876124903a05e590e929532039/src/librustc/diagnostics.rs#L30). I'm not sure what the best way to say this in an issue is, but I agree that it'd be good to fix. If you (or anyone else) have the time, I think it could just be reported as a documentation error in the rust-lang/rust repository?
I doubt this will happen for Debian?
A build script? [https://doc.rust-lang.org/cargo/reference/build-scripts.html](https://doc.rust-lang.org/cargo/reference/build-scripts.html) A include macro? [https://doc.rust-lang.org/1.1.0/std/macro.include!.html](https://doc.rust-lang.org/1.1.0/std/macro.include!.html)
Does a generational GC have better cache locality because the nursery heap is smaller, keeping locations in the nursery in cache? (Similar to arguments in favor of the stack.) I don't know if it does or not, but it seems plausible that it would.
&gt; why is the JavaScript still not tiny [...] But in the future perhaps those could be made optional Yup, or maybe employ some other packaging tool to help here. It would also be nice if the JS layers were a bit more pluggable.
I might be wrong, but stack cache locality matters because you constantly rotate the most used data in a tight, hot cache, effectively reusing hot memory, compacting things in shared cachelines. For heap, it's the access pattern matters, and this is quite similiar with or without a GC. Compacting is something for allocator to take care of. I personally don't believe in any GC-super-performance claims. It's a lot of wishful thinking. "We are going to do a lot of expensive GC operations, and that will make everything faster". Sure. Yet any time I run any IDE written in Java, I immediately feel slowdowns, even though Java GC is said to be the best. And on the server side it will run fast, but eat all the memory. While with Rust I'll get top-notch perf with minimum memory usage. 
&gt; they are completly different projects It is weird and rude to use the same name for a "competing" effort. That is, code that does similar things, but isn't part of the original project.
Yes, I too would like very much to have an ability to be able to indicate minimum Rust version in `Cargo.toml` and judging by several issues it's a long requested feature. (see this [link](https://github.com/rust-lang/rfcs/pull/1953#issuecomment-360623327) for recent discussion) Quite unfortunately this feature got lost in the mix-up with Cargo schema discussion... As for temporary solution you can use `[replace]` section to patch your dependency with the local fork: [replace] needle:0.1.1 = { path = "your/fork/" }
I intentionally chose to avoid putting the meat of the documentation at the module level since I plan on exporting this macro in other crates. It is _really_ annoying that it includes all the gory details in the docs. I'll think about your other comments as well. Thanks again for the feedback.
&gt; for a "competing" effort Yes, I am not good in naming. But It is not "competing" effort. You can not use tool for `c++` for `rust`, and you can not use tool for `rust` for `c++`. They are live in different, not intersecting worlds.
Feel free to send us an application and write some sentences how you'd like to save the world with rust ;-)
Rocket is flashy, but I find that Rouille is a great, simple framework that just works, and it works on stable. I'm not going to use something that depends on nightly for more than just a quick experiment. 
Thanks, I'll check it out.
After some time off, I have started working on [FUSS](https://github.com/jsdw/fuss) again, my CSS preprocessor. It's written in rust and aims to be a simpler, functionally inspired, harder-to-shoot-yourself-in-the-foot alternative to SASS (and of course, it's written in Rust). Things mostly work pretty well now, so my main job is tidying up and improving the error output. Next, I'll probably have a pass over the parser and add more native functions to work with colours. 
Reported. I sometimes contribute to rust-lang/rust so I might as well fix it. But what about my shadow comment? Maybe it was caught by the spam filter? If so the mods should have approved it already. Maybe it's because I pressed F5 shortly after submitting it, but I can't see how that would leave the comment in a half-submitted state for such a long time.
I'd hope so! let's report it, and see
You haven't mentioned `forget()`ing the array before. For some reason I just assumed it lived higher on the stack. I presume now that it's on the heap, right? (Leaking an array on the stack won't prevent it from being possibly overwritten)
I'm pretty sure `start_send` and `unbounded_send` will be 100% the same in behavior because sends are always allowed, but `start_send` must be compatible with `Sink` so it could *technically* return the result "not yet sendable". The distinction lets you call `unbounded_send` with type system assurance the send is complete. I don't think either relate to `poll_complete`. The typical use of a Sink would be the `.send()` method, which returns a future and will automatically call the underlying `start_send` multiple times until it returns "ready", and then it will block on poll_complete. The right ones to use as a consumer are `unbounded_send()` or `.send()`. Use `unbounded_send()` if you aren't sure which of these you need. `.send_all()` can also be used, but you won't typically need to. it's useful if you have a separate `Stream` and you just want to feed everything from it into your `Sink` automatically.
(extremely cƒÅche voice) Sir Dee
I second your parent, but also have been meaning to give Gotham a go as well.
&gt; Does a generational GC have better cache locality because the nursery heap is smaller, keeping locations in the nursery in cache? That certainly helps, but it's not the most important reason. Take a look at this simple benchmark in Java: https://gist.github.com/stjepang/9ec32aadd888e5a7f38c9fc64f822cbd The benchmark inserts one million integers into a `TreeSet&lt;Integer&gt;` and then measures the time needed to iterate the whole tree. Running it my machine results in "time: 100 ms". But if I uncomment the call to `System.gc()` to flush the nursery before iteration, it prints out "time: 20 ms" - which is a huge improvement! And the reason is that the GC copies objects from the nursery into the main heap so that linked objects are laid out in memory as closely as possible.
You can't `impl Display for Vec&lt;MyStruct&gt;, but you can do something like this. (I just typed this out so there might be errors, but I've done this a few times so I know it works). struct Nice&lt;T&gt;(T); impl&lt;'a, T&gt; Display for Nice&lt;&amp; 'a Vec&lt;T&gt;&gt; where T : Display, { fn fmt(&amp;self, f: &amp;mut Formatter) { write!("[ ")?; for v in self.0.iter() { write!("{}, ", v); } write!("}"); } } Then you can use it like: let v : Vec&lt;MyStruct&gt; = ....; println!("{}", Nice(&amp;v)); 
Shockingly valgrind doesn't only not show my program leaking memory, it shows it using only about 16 bytes of memory... even when I compile with the system allocator. Or that was the case when I was trying to debug a slight issue of a double free decrementing (literally subtracting 1 from) the next_ptr in my free list before. Pretty sure something is broken there... but since valgrind doesn't really support rust anyways I didn't worry about it.
BigInt implements `Num` and `FromStr`, so you can use ``BigInt::from_str(&amp;str)` or `BigInt::from_str_radix(&amp;str, radix: usize)`
Gotham's BorrowBag is scary.
I thought about and started writing something like this in Python. However, some licenses are modified from a well-known license - for example, GPL plus a brief attribution clause. I believe that with legal licenses, language model similarity is not good enough to base legal decisions on. For many applications you would need to prove that the license text is isomorphic to a known license or otherwise flag it for legal review.
You can try [actix](https://github.com/actix/actix-web) web framework. It compiles on stable, it support http/1, http/2, websockets and it is fast!
Is there a way to set the color of text being inputted into the app. Like std::io?
It's competing in the "C++ wrapper generator named SWIG" sense. And since it's the first result for "rust swig" it's very misleading. Please change the name.
Maybe crate authors should start adding ad-hoc badges? Something like: https://img.shields.io/badge/rustc-1.20+-red.svg
I used to always want stable, but my latest crate has a minimum stable version of 1.24 :(
maybe name it `cradle` since it helps foster rust to exist alongside its (programming language) siblings. Also cradle rhymes with gradle.
Batman?! you stand in opposition to Gotham? I would expect you, of all people, to be defending Gotham.
I'm mainly making a joke about your name... and Gotham city, which is where Batman lives and it's the city he defends.
Persistent data structure would allow for implementing something like Redux(popular state management from JS land popular with React) in Rust? I really liked it for managing state with UI and how when data changed, it chained through the relevant reducers to update the data structure(big nested collection of objects/structs) where the React UIs could then all automatically update upon knowing the data changed, data was always flowing one way instead of bi-directional where it's been frustrating with past UI development for me. Then you had all the third-party middleware allowing for things like memoization. IIRC Rust doesn't compose functions well enough at present to mimic how all this works? And the data structure, I'm not sure how to go about, is the strong typing and compile time checking going to get in the way of those benefits that the JS implementation?(Redux was released at only 100 lines of code roughly iirc)
&gt; a file type detection crate that gave wildly, obviously wrong results in very simple situations Was it one of the crates that uses mime-types for detection? There is a few, one uses libmagic, one tries to be similar where it's much faster but doesn't support as many types, and a few others. Did you raise an issue on the crates issue tracker?
If you *know* that your graph is really small and short lived, you can use the same approach in Rust too - just create an arena, allocate inside it without bothering to free anything, and deallocate the whole thing when you're done. Very common approach in game programming and the like. The issue only comes up in the first place with bigger and longer-lived graphs, and there GC will *always* add some cost in terms of latency, jitter (i.e. worst case latency), memory use (which of course causes all sorts of further performance trouble due to interaction with caches and the OS!), computation cost, or some combination of these. TANSTAAFL, and reference counting is actually an excellent all-around solution when the conditions for its use are met.
dont worry buddy, I got the joke
Unfortunately [Make Cargo aware of standard library dependencies #1133](https://github.com/rust-lang/rfcs/pull/1133) has been outstanding for quite a while.
I personally use stable all the time. My only deviation from this is rustfmt, and that's going to be on the stable channel next release.
Same here. Nightly *tools* are mostly okay, like rustfmt or rls, but all my actual code must work on stable.
Redux doesn‚Äôt require persistent data structures‚Äîwhile it is often used with them (Immutable.js), it is possible but awkward to do so without. Same applies to Rust, I think. 
/u/myrrlyn it's cach√©
Yup I hear ya. This is why I've been on Arch since 2009. :-)
There is a rust discord channel?
I use stable all the time, and rustfmt sounds like it'll be cool, but I've gotten by without it just fine.
Is there something preventing it being implemented well on Rust? I remember a Redux implementation a couple years ago that had difficulty porting to Rust(might have been due to language differences or lack of some feature at the time), as well as a few Reactive Extension projects(I think Async support was an issue for them at the time). There was also transducers which was a clojure thing for compositing function operations in various ways that iirc didn't quite pan out as well with the Rust port. I guess by end of 2018, these all might be more viable? Would be neat to use Redux like state management with a UI framework(or Qt)
Ah that was the less supported types but more performant than libmagic one I mentioned :) Thanks for raising the issues, hopefully they'll resolve them as that seemed like a pretty interesting crate.
Normally I would too, but working in a shared repository doesn't really permit that :P
In a workplace you need linting and format to shut down pointless discussions, and to protect against issues. I really couldn‚Äôt use it at work without them.
Is the goal of Chalk to provide a more advance "Type System" for Rust? For example, to be better able to support things like Constant Generics and Higher Kinded Types, or am I missing the point? (Sorry, but, you seem to be at a sophistication level a little above my pay-grade. I want to make sure I at least understand the "point").
You know you don't have to ping me when you're replying to me, right :p
&gt; We need to be able to develop and run Rust 100% on stable. I *do*.
I believe that build script is what I am looking for, basically my build script would build the main.rs file before compiling
Rustfmt, clippy, and RLS. 
`r` is route definition and you can configure routes with complex rules for example: .resource("/{name}", |r| r.p(Any(Get()).or(Post()).and(Header("CONTENT_TYPE", "text/plain")).f(index))
OP's thread is about having to switch to stable to get RLS to work, isn't it? which kinda contradicts your point. But, I'm not opposed to installing *convenience tools* like `rustfmt` or `clippy` with nightly. The tools could be written in OCaml, Perl, or even Visual Basic for all it matters, as long as they work well. My programs compile against stable, and that's what matters. I don't want my code having spurious compiler bugs in production, and I don't want my code to stop compiling on a whim as nightly features come and go.
Not OP, but it's kind of unfortunate when a lot of the fun stuff is nightly only (e.g. Rocket). It's certainly getting better (Diesel moved to stable around Rust 1.15 and is now 1.0), but there are still quite a few compelling libraries using nightly features. Having a way to distinguish them would really help in developing on stable.
&gt; Having a way to distinguish them would really help in developing on stable. I agree completely with this.
&gt; Persistent data structure would allow for implementing something like Redux Redux is a javascript translation of the Elm architecture. Someone might have come up with the pattern before Elm but that's what popularized it. There are a number of TEA implementations in Rust, for [custom widgets](https://github.com/christolliday/limn), [gtk](http://relm.ml/relm-intro) and [web](https://github.com/DenisKolodin/yew). They're all kind of prototype / in development but people know about the pattern. Redux specifics like HoC to wire up state may not translate directly (I haven't thought about the types) but if they don't, they should after `impl Trait` lands.
Interesting, I hadn't heard about that project! I've been a little unhappy with iron, and Rocket doesn't run on stable (and is missing some features), so I'll have to play with this.
[Rouille](https://github.com/tomaka/rouille) is 1.0, and has been for awhile now, by Rust standards. I understand that it's the route definition, but the *common case* seems to be just handing off to a function. Having a more advanced way to do things is good, but the syntax should be centered around the most common case, right? and using one letter identifiers like `r`, `f`, and `p` is not my favorite either. I definitely appreciate Actix going all-in on HTTP/2 and websockets, I'm just giving you my feedback on the design!
I use both. Stable for projects that matter, nightly for hobby stuff. If we can have a way to know if something works on stable *and* if a few other tools land on stable (e.g. the new rustfmt), then developing on stable will be so much nicer.
thanks for suggestions. regarding Rouille, I don't really see use use for it. According to [TechEmpower benchmarks](https://www.techempower.com/benchmarks/previews/round15/#section=data-r15&amp;hw=ph&amp;test=plaintext), it seems slower than most of other frameworks.
Awesome. I saw "session support", but I wasn't sure if that meant database backed, signed, or just some primitives to do it yourself. The examples were all pretty simple. Thanks, this may just be a winner for my project!
great. if you will have any question regarding actix, just ask me directly.
Awesome. I'll probably get some time to play with it this weekend.
Don't use someone else's branding for your project. Change the name.
Thanks so much for all the input. I ended up liking Reverse() inside of sort_by_key. An equally lazy way of doing it would work with letting two variables and then just calling .rev() on the vector.
I switched my server to pure hyper this week (was using rocket) because I really didn't feel well shipping something that may break the next day... You know there are not many rust developer to fix that when it happens
Do you have a link to your impl?
Fixed! Thanks!
XInput: https://github.com/Lokathor/rusty-gamepads Handmade Hero: https://github.com/Lokathor/handmade-rust (only visible to people in the Handmade Hero github development group because they pre-ordered the game. I'm not allowed to make it public domain until the game itself is public domain 2 years after the actual launch).
for anyone reading this, I don't see any `unsafe` in the BorrowBag code, so this just seems like fear mongering unless you would like to explain further **why** you think it is scary.
Maybe `cargo test -- --nocapture` ?
last time I implemented db middleware for gotham it's very long just for describing the return type. but it's because I used r2d2's ManageConnection + Diesel + PgConnection, wrapped in BorrowBag which is a type for other type. even with type alias it's cumbersome. it's not unsafe or anything.
ok, I could see that
I don't think `cargo test` links any kind of logging framework into the test binary, at least by default. Setting `RUST_LOG=debug` shows me all kinds of debug output from cargo itself, but not from my tests.
If only Rust did protect against deadlocks... The clang/gcc C++ lock ordering annotations are often handy for that.
&gt; regarding Rouille, I don't really see use use for it. The vast majority of the world runs php, ruby and python. Don't be silly.
I wish we had something like C++ immer library in Rust: https://github.com/arximboldi/immer
&gt; Redux specifics like HoC to wire up state may not translate directly (I haven't thought about the types) but if they don't, they should after impl Trait lands. Ah sweet. So once impl Trait arrives, I should be able to get a similar state management experience and the linked UI crates may be at a better progress to integrate/use? **EDIT:** Had a look at those crate links, yew sounds really good! Relm too :) Thanks!
Any type breaking the assumption that "moves are free" when combined with an invariant that doesn't require to move the whole type in some cases: * Example 1: `enum { A, B([i64; 256]) }` when the active variant is `A`. That requires moving only 1-8 bytes (for the enum tag only), but the current model moves the whole type always (that's 2048 bytes + 1-8 for the variant). This is 2000x more expensive than the same operation in C++ (`variant&lt;empty_type, array&lt;long, 256&gt;&gt;`). Supposing we fix Example 1 with better heuristics for how to emit memcpys, which might or might not be possible (idk), it is easy to come up with examples in which things are still pretty bad by using invariants that the compiler doesn't understand (the compiler understands `enums` pretty good): * Example 2: `SmallVec&lt;[i64; 256]&gt;` when the vector has a `len &lt; 256`. That is, the active variant of the enum in the `SmallVec` is the `[u64; 256]` one. Even then, `memcpy` doesn't need to copy the whole variant on move, because if `len == 1`, one only needs to move the first element (so that's a ~8x3 bytes memcpy for 1x u64 + len + tag fields). So even if we fix Example 1 to move only the appropriate variant, in this case that's not enough because the `SmallVec` uses unsafe code to make sure that only the elements at `i &lt; len` behind the array can actually be accessed by its users, but the compiler doesn't know that. One could work around that in `SmallVec` by using a recursive implementation where the enum contains all arrays between `[i64; 0]` and `[i64; 256]` but then it is trivial to construct similar cases for structs with uninitialized fields where the type invariants prevent them from being accessed while uninitialized, but moves will always move them.
Interesting. I'm curious how often these situations come up- I suspect far less than things like `Vec` resizing, but still often enough that it's probably worth coming up with at least a workaround. You could of course use `mem::forget` and write the partial memcpys yourself in specific cases but I don't know how possible that would be to wrap up in a function. It's certainly not as ergonomic as a move constructor.
Eh, not every situation requires `#[repr(C)]`, and I'd sooner try a different operational approach than give up on the language entirely if it was *that* big of a problem.
I was mostly only curious about the cases where the current Coroutines TS is broken. I also feel that its to magical for my tastes, but I've encounter many people whose only answer to critiques is "show me an example where the current beta Coroutines TS implementations cannot optimize this away or shut up; you won't find any".
Ah, something like IncludeOS? Very nice, I've been waiting for something like this!
Yeah, that's about what I had to do
Rouille use standard threads to dispatch requests. It will always be slower than any async based solution. However it is a very well crafted piece of software and rock solid. The author (rightly) consider Rust's async story a bit too much in flux and doesn't rule out using tokio etc once the dust settles. So the question is whether you need that extra edge async gives you. For my current project, good ol' threads are fine, and I'm happy with Rouille.
I don't think "nightly is the default" is true. I see most folks running on stable these days, and almost the entire ecosystem is stable. Firefox uses stable Rust. Sure, some tools like RLS and clippy are on nightly but that's because they're still in alpha. They're on track to stabilize through rustup this year. I'm not sure what more can be done to fix this; folks are aware of the issues and working on it. There will _always_ be shiny new things that only exist on nightly.
We are working with recruiting firms but are also open to direct applications: careers@maidsafe.net
I'm on mobile, so please allow me to ask what you use `#[feature(test)]` for?
I (the OP) am not using it - it's in the needle crate I was trying to use. I don't know what it is for.
Wait for nicholas's next post.
Thanks for the suggestion daboross. I have forked it and will see if I can fix it tonight.
So wrapping my vec? I hate that now I would need to either add methods to this new struct to call like `my_list.push` or would need to `my_list.inner.push` and that is only driven because I want to print properly which seems a different matter.
Have you tried specifying both `RUST_LOG=` and `--no-capture`?
Maybe it's for some benchmarks? In that case, putting the code in question into a `benches/` subdirectory or using the [bencher](https://crates.io/crates/bencher) crate can alleviate the issue. I'll look into it when I find the time.
While it may be appealing when coming from different languages, Rust specifically prefers to not coerce types to bools. This way, the code is much more readable. I'd suggest getting inspiration from `Option` (`.is_some()`, `.is_none()`), although if you also need to do pattern matching, it's anti-pattern.
[num_traits::pow::checked_pow](https://docs.rs/num-traits/0.1.42/num_traits/pow/fn.checked_pow.html)
The history is probably strongly linked with the design of Unix. Without knowing much about it, I would imagine that program arguments posed the question of "where do I put this variable-sized block of data so that the program can find it?", and "the stack, in the manner of function arguments to the entry function" was the simplest answer.
But isn't a segfault in C just as "safe", since it can also be catched (SIGSEGV handler)?
[I agree](https://deterministic.space/rust-2018.html#aim-for-long-term-stability-of-the-library-ecosystem) :)
'We got a good handle on this' may be true, but it's not a good starting point for discussion. What is good about our docs? Where can we double down? Should we e.g. announce a 'docs week' where everyone is supposed to document all the things? Or seek out great documentation examples and blog about what makes them so great so that others can learn from and emulate them? Or should we extend This Week in Rust to include the best docs of the week? Same thing with examples; I think we can do a lot more in that area. Perhaps there should be a way to include examples into the docs (via link, perhaps)?
why did it fall through?
&gt; Please correct me if I'm wrong, but the only that is expensive there is atomic increments/decrements and (less so) pointer dereference. Allocation and deallocation of an Rc uses the normal allocator, advanced GCs have more tuned allocators and can have pretty ridiculous throughput. This is important for persistent collections as even with sharing you're creating and destroying a number of nodes on every structure updates. IIRC the JVM takes ~11 cycles to allocate an object on average (ignoring cases where escape analysis means no allocation even happens).
Thanks for your reply! I just noticed that `send` and `send_all` consuming the sink what leads to problems in my case. `unbounded send` takes `&amp;mut self` that suits for me but is only available for `mpsc` not for other stream sinks. So `start_send` + `poll_complete` seems the way to go if I don't want to consume the stream but like to flush?
It's nice, but it'd be better if we had something like that in the std, I guess.
I don't think that in this case the lack of generics has a performance impact. The library has to do type-casting, but doesn't use the meta-facilities. It does have an impact on type safety, and the type-cast are annoying. It's also not very easy to come up with a dense syntax for something like this in Go, which is also annoying. But I do think it is still a *useful abstraction*.
Here is my personal experience: I went to Rust meetup for a long time and I never met any white men, none at all. Finally, fitzgen came to Korea to be the first white men I met at Rust meetup I went to. If the above sounds like non sequitur, (and I somewhat expect it to be) consider your personal experience may sound non sequitur too.
So are you blaming trans people, POCs and women to be too lazy to work on Rust? Just another instance where white males have to do all the innovative and hard work? ;-)
If you're worried about that, you can write it yourself or copy the function you need from an open source project after reviewing it. "I'll have to use a library" still sounds like a bad reason to add features to the standard library. Besides, the library is authored by the Rust Project Developers. 
That's a fair point! Something that's really great about our docs is the fact that they exist. Everything on crates.io is also on docs.rs, even when it's just the otherwise undocumented API. I forget how great that is sometimes until I have to work in an ecosystem where it isn't the norm and tracking down information becomes much harder. Integrating more fully-fledged examples into docs, even as links, could be a good complement to more guide-focused content. I think there are two things we need to double down on in docs. Firstly, I think we should have more guidance around how you can make the most of rustdoc. What kinds of things should I put in my crate root docs? Introductory prose and motivating examples? What about submodules? Should we try add general examples to structures that might be repeated on methods? Are examples better if they include `use` statements, or should we try reduce noise? There are lots of questions with probably lots of right answers, but we should have guidelines discussing the virtues of different approaches. Secondly I think we need more guide-level docs. We probably need more of them because they're a lot of work to put together, even though they're very useful. Would a docs week be helpful to bootstrap guides? I think it could.
&gt; So it gives more flexibility to the developer. Well, except that a Rust developer can't choose to use GC while also using Rust, even when they are prepared to pay for it.
How about "It would make sense that, if only one operation is included in the standard library, it should be the one which can be used to build the other"? (As is, it feels like having `print!` in the standard library, but not string-formatting functionality that can output to a variable. Sooner or later, you're going to get people doing crazy stuff like temporarily redirecting `stdout`.)
It‚Äôll work fine.
&gt; The community has a lot of white men. &gt; This isn‚Äôt a bad thing on its own, but it also has a somewhat chilling effect on getting non-white-men involved. I had the personal experience of going to a rust meetup and being (unfortunately) unsurprised to find pretty much a room of men (from what I could tell, if there were other trans people there they weren‚Äôt flagging enough for me to tell). The meetup was fine, but I personally don‚Äôt think I could ‚Äúsell‚Äù a rust meetup to a number of my friends. ‚ÄúWhy should I subject myself to an hour of confident men when I could do literally anything else?‚Äù Honest question, are there any meetups about programming languages where the significant majority of attendees are not white men?
Yes. Come to South Korea.
&gt; The community has a lot of white men. &gt; This isn‚Äôt a bad thing on its own, but it also has a somewhat chilling effect on getting non-white-men involved. I had the personal experience of going to a rust meetup and being (unfortunately) unsurprised to find pretty much a room of men (from what I could tell, if there were other trans people there they weren‚Äôt flagging enough for me to tell). The meetup was fine, but I personally don‚Äôt think I could ‚Äúsell‚Äù a rust meetup to a number of my friends. ‚ÄúWhy should I subject myself to an hour of confident men when I could do literally anything else?‚Äù The fact you don't feel confident to "sell" rust meetup to your friends because you feel there are too many white male *really* scares me. Just swap "white male" by any "minorities" and you will get the idea. Seriously, Rust is a tool and it does not care whose human is using it. We are building tools for all human beings. Stop to bring division where there is none.
&gt;Stop to bring division where there is none. Fully agree!
Also a local mirror that can be shared on LAN is a must if you have more than a couple machines or want CI availability.
Ideally, it should also be able to show that a crate is nightly-only, or has nightly-only features. 
&gt; I don‚Äôt know if it‚Äôs possible to make ‚Äúroogle‚Äù (AKA hoogle but for rust), but I believe that the preconditions are pretty good We already have some Hoogle functionality in rustdoc (press `?`), but it seems somewhat broken at the moment. One of the official examples, `vec -&gt; usize`, does not seem to work.
why? :D
The `num` crate on crates.io is maintained by the Rust team as well. There are a lot of crates like this: https://docs.rs/releases/the-rust-project-developers
last year's survey showed stable users now make up 77.9% of Rust users, and nightly 51.6%. For me personally, once the next release brings rustfmt, I'll be on stable for all but one project.
&gt; Seems there is still no path to get that moved onto stable. It will follow the exact same path as rustfmt and the rls, given that it has the exact same problem.
&gt; IIUC, it's actually impossible in Rust. Rust doesn't guarantee that you won't accidentally share state via channel (e.g. using `Arc&lt;T&gt;`), but it will make sure if you do, it's safe to share.
I did not know about `hoogle`. Looks pretty neat. &gt; Take, for example, the three most-downloaded crates as of the time of this writing ‚Äî libc, bitflags, and serde. Of these three, only bitflags and serde have something that resembles a user guide. What? glibc, musl, and friends have reference documentation, user guides, man pages, and... a gazillion amount of books that explain how to use them. Like, how many books explain how to use glibc? 100s or 1000s at least :/ Or what am I missing? Libc's documentation says: &gt; A Rust library with native bindings to the types and functions commonly found on various systems, including **libc**.
I am trying to create a default implementation to get the json representation of all my data types. I created a trait Data with the as_json() method. I also have ~5 structs that implement data, all with the exact same implementation. Currently my trait looks like this: pub trait Data { fn as_json(&amp;self) -&gt; String; } All structs have a copy-pasta implementation for this method. But since this is bad practice, I would like to have it look like this: trait Data { fn as_json(&amp;self) -&gt; String { match serde_json::to_string(self) { Ok(string) =&gt; string, Err(error) =&gt; { // } } } } struct Struct1 {} impl Data for Struct1{} struct Stuct 2 {} impl Data for Struct2{} But that doesn't work. The compiler keeps telling me the this: trait `Data` cannot be made into an object 
a lot more people have access to std than do num-traits. (I'd make the argument on trustworthiness, not number)
Maybe cargo should support specifying a minimum rust version for a crate ? Which is something that has been requested a gazillion times, and to which the answer is "just upgrade to a newer Rust version". 
/r/playrust
&gt; Firefox uses stable Rust. Sure. How does Firefox modifies Rust system allocator again? Ah yes, that's stable, but oh.. yuck!
If you want to compete with php, that is fine 
What is your main struggle with `Failure`?
Yeah it‚Äòs https://discord.me/rust-lang
That eye symbol though...
True... which is probably part of the reason all other similar panicking operations have checked counterparts.
By the way, there already exists implementations of this: http://nalgebra.org/rustdoc/nalgebra/linalg/struct.QR.html https://docs.rs/ndarray-linalg/0.7.0/ndarray_linalg/qr/trait.QR.html It might be also useful to check how they do it and also if you insist if reimplementing for sake of learning, I would do it on top of ndarray of nalgebra data structures.
Guess you can use it with a cpupool?
Try [turtle](http://turtle.rs/).
You can, but then I‚Äôd like to see something like, ‚Äúuse only with cpupool‚Äù
I've noticed this happening a few times too. Sometimes RLS will just go nuts and start hammering the CPU. I've had this happen a few times in both Linux and Windows, and the solution has just been to "killall rls" and let it restart itself, or kill it via task manager in Windows.
One tradeoffs we could make is to have separate domains for nightly and stable * stable.crates.io only listing stable crates * nightly.crates.io lists all crates * crates.io aliasing to stable.crates.io Just a thought...
Here is a connection pool that can be shared across threads: https://github.com/sfackler/r2d2-postgres
I think your problem is not unique to rust. You should inject server and client as dependencies and in test use some mocks that will not block and will not require network connection. For example the function that currently accepts `server` and `client` should instead accept `TServer where T: TServer` and `TClient where T: TClient` and your `Server` and `Client` should implement those traites (`TServer` and `TClient`). In tests, you should provide your own (mocked) implementation of those traits that do what you want
Could you have a `FixUp` trait that is implemented by the compiler for safe code (recursively for members) and manually otherwise?
https://github.com/emoon/minifb looks like a perfect fit!
Thank you for the reference! I definitely have looked at that source code (although it is sufficiently sophisticated and I am sufficiently new to the language that it is kind of challenging to understand). What I have in mind, though, is more for an application of low-rank approximation. So I will collect and modify columns and then terminate that process early. But if I end up developing the proficiency to write some code for a decent low-rank approximation, I will definitely try to use existing codebases and write it in a way that it could be contributed to nalgebra (if they want it).
Yeah, that sucks!, I want to use the new features from relm and use VSCode at the same time, but that's not possible at the moment.
/u/matklad ah thanks. I will check them out. 
I'm doing something similar with a Rust dialect, in a project where I want to write parts of the app in that dialect I have a build.rs like this: extern crate dogerust; use std::env; use dogerust::*; fn main() { transpile("src", env::var("OUT_DIR").unwrap()).expect("transpiling failed"); } Then in my lib.rs I have `dg_mod!(pub widget);` and in `widget.dg.rs` I write the code in my dialect.. Btw, the `dg_mod` macro looks like this: #[macro_export] macro_rules! dg_include { ($p:ident) =&gt; ( dg_include!(__impl concat!("/", stringify!($p), ".rs")); ); (__impl $p:expr) =&gt; ( include!(concat!(env!("OUT_DIR"), $p)); ); } #[macro_export] macro_rules! dg_mod { (pub $p:ident) =&gt; ( pub mod $p { dg_include!($p); } ); ($p:ident) =&gt; ( mod $p { dg_include!($p); } ) } 
It's a really small project - that's the thing. The debug build takes about 7 seconds to complete, so it's really weird that RLS can hang for minutes at a time. Cargo check takes even less - just under 2 seconds.
ah gotcha, that definitely sounds suspicious, then.
Recursion in struckt normally means boxing. I am currently on mobule and cant view the playground.
you're not going to be able to. why are you reinventing the wheel instead of using the standard library or a crate from crates.io? but, if you're going to, it makes a lot more sense for each Node to have a Box of T inside it rather than a reference to something contained within the same parent struct... a self referential structure. Rust doesn't support self referential designs, unless you use a hack from crates.io like "rental", and even then it's only okay.
the other solution which you could consider is just storing the numeric indices in Node. the start and end values.
Say I have the following folder structure somewhere in my project routes/ user/ get.rs post.rs put.rs event/ get.rs post.rs I am doing this for organization. And so that I don't have to add the path of the file to `main.rs` as well since that is an extra step I would like to be able to have it so that cargo will automatically include those files into my program and create routes for them and what not based upon the folder path and other things instead of having to write it out myself. I know believe that with the build.rs I can write a `main_template.rs` file which is used as a base for the `main.rs` and is thus constructed before any compile.
&gt; why are you reinventing the wheel anyways instead of using the standard library or a crate from crates.io? I'm not. Is there are any good tree containers? A don't know about them. There is `ego-tree` which doesn't support node's removing and `petgraph` which isn't a tree. &gt; then it makes a lot more sense for each Node to own a Box of T inside it rather than a reference I think it's easier to store just a range or share the data via Rc. But it will not be checked at compile-time. And this is what I want.
what you described doesn't actually seem to be a tree, which is part of my confusion.
good
&gt; but the stdlib has some great trees Really? I need something like [rctree](https://github.com/SimonSapin/rust-forest/tree/master/rctree)/dom.
Are you allowed Fedora? Their Rust packages update throughout the 6-month release cycle. 
So what happens when 60 ESR comes out and depends heavily on Rust? Is Debian going to drop Firefox? Stick with unsupported 52 ESR? I'm really unclear on how that's going to work. 
Sure, but you can't reasonably write a garbage collector in Rust *for Rust*, without building it into the compiler. And `unsafe` code that currently exists might store pointers in ways that the compiler wouldn't be able to detect (e.g. when scanning something silly like a xor-linked list).
Setting up float traps would probably be more efficient that `checked_pow`, unfortunately this is not supported by LLVM. :(
Debian is going to ship the Rust you need for building that ESR. Also, the important moment is the one where a new Debian release ships, shipping a new ESR. Given that the Debian maintainers of Firefox (and a couple of others) are actually employed at Mozilla, I wouldn't expect any problem.
If you want something *like* rctree, that could be [accomplished like this.](https://play.rust-lang.org/?gist=9a21e2f14ceaf787ea1bd0e0fa492ce6&amp;version=stable) But, a tree has multiple levels. Your "tree" is a set of values, and then another set of values that references groups of the first values. I don't see how that's a tree... I'm also not sure what the use-case is for this structure.
We're using Fedora, yes. Most companies with those issues use RHEL anyways, so they don't have too much ground to cover there.
The first thing I noticed in the README example was that you are passing the HTTP method by reference, then in the `add_route` method you immediately call `.to_owned` on it. You could probably just move the Method type into `add_route` and be able to avoid the `.to_owned()` call pub fn add_route&lt;F: 'static, S: Into&lt;String&gt;&gt;(&amp;mut self, method: Method, path: S, func: F) -&gt; &amp;mut Self where F: Fn(D::M) -&gt; Response { let route = Route { method: method, path: path.into(), func: Arc::new(func), }; self.routes.push(route); self }
So you want to do this? https://github.com/scikit-learn/scikit-learn/blob/a24c8b464d094d2c468a16ea9f8bf8d42d949f84/sklearn/utils/extmath.py#L228
This is obviously true, but post-processing binaries isn't all too unusual.
It's just an example. The idea is that I want to store some data in the tree/root node and all other nodes only has a reference to it. So I have one allocation instead of multiple. I thought it can be possible with lifetimes. &gt;Why can't you just use rctree then? That's what I'm doing right now. But it has runtime checks instead of compile-time. Also, there is a problem with circular references.
Programs aren't cars; crashing is a very safe thing for them to do;)
The argument is Rust allows the engineering of more robust software. RLS' continual flakiness throws a spanner into these claims. 
(pulls a blanket over code written before I knew about format!) Hahaha crazy who would do something like that
What you need to do here is take a huge step back. No matter how much Rust might want to hide it from you, you're dealing with a high level systems programming language. Consider the following snippet. use std::mem; fn main() { let mut string_a = String::new(); { let ref_a = &amp;string_a; let _string_b = string_a; // ILLEGAL string_a.push('H'); // ILLEGAL mem::drop(string_a); // ILLEGAL } string_a.push('H'); // LEGAL mem::drop(string_a); } [Playground](https://play.rust-lang.org/?gist=817d55988d9ef6002f57daaba25c9e80&amp;version=stable) Lifetimes here guarantee that you can't move, modify, or destroy `string_a` unless you have destroyed all references to `string_a`. To perform a mutable action on `string_a`, you first need to perform a mutable action (in this case, destruction) on `ref_a`. Now, consider a self-referential struct. In order to move, modify or destroy this struct you first need to destroy all references to that structure. However, one of the references is inside the struct itself, so you need to destroy that first. However, to destroy it, you need to modify the struct around it. However, to destroy that... You're stuck in an infinite loop. References inside a structure have its use, if they point to something outside. They can be used in some cases, like: * Custom borrowing (`Iter&lt;'a, T&gt;`) * Generics (`HashMap&lt;&amp;'a str, u64&gt;`) But in general, if your struct contains a &lt;'a&gt; and it's not a wrapper around an other struct, you need to rethink your program. I noticed that you only have a single layer of children, and a single vector that provides all the data. Why don't you just define your tree as a wrapper around the vector? struct Tree&lt;'a, T : 'a&gt; { children: Vec&lt;Node&lt;'a, T&gt;&gt; } [Playground](https://play.rust-lang.org/?gist=20fea9dd313e5c85a0bfcbb809a56d8c&amp;version=stable) Or, you could use late binding, which just says... struct Node { slice_start : usize, slice_end : usize } [Playground](https://play.rust-lang.org/?gist=51b591ba64473b3b749a99018485dd37&amp;version=stable)
A lazy_static! block that sets up the log sink might be workable but I'll have to play with that before I talk further
are you on Linux? run "perf top" and file an issue with the results
I think this information is better in rustdoc than on crates.io. focuses is much better at showing versioned information, and the rust version requirement depends on the version of the crate.
The Rust mindset is move-by-default, rather than clone-by-default like in C++. let x = vec![0; 10000]; let y = x; let a = y[0]; // this is OK let b = x[0]; // this is a compiler error, because `x` does not exist anymore as its value was moved When you assign `y = x`, the Vec object is moved. This means that it does not exist at `x` anymore and you cannot access it using `x`. Because of this transfer of ownership, Rust only needs to copy the stack data (pointer and metadata), not the 10000 values on the heap. If you want to access it from multiple places, you can use references: `let y = &amp;x;`. If you want to make two Vecs by copying all the 10000 data values, you can clone it: `let y = x.clone();`. Types which are trivial to clone without a performance hit are called `Copy` types. Examples of such types are the primitive types (integers, etc.). These are the only types that will be copied implicitly, instead of being moved: let x = 7; let y = x; println!("{}", y); // OK println!("{}", y); // also OK, since i32 is Copy In Rust, expensive operations are always explicit, unlike in C++ where they can happen implicitly. You have to ask for them. This is a good thing, because it is always clear to you where potentially-expensive operations can happen.+
I think you are *vastly* underestimating the effort that would be required for this little exercise. Would this hypothetical GC be able to detect pointers to GC managed objects inside a `Box`? Inside a closure? Inside an enum? The whole point of a GC is not having to think about this kind of stuff, but for it all to just work.
I wonder whether anyone has this using another front-end, apart from VSCode. I, myself, haven't had troubles yet on vim (with asyncomplete-lsp), but I don't run large projects yet. I'll keep an eye out.
Some crates are mixed, with unstable opt ins.
Thanks for detailed answer. &gt;I noticed that you only have a single layer of children Only in example. &gt;Or, you could use late binding, which just says... No static garanties, sadly.
Thank you I was looking for this yesterday!
I'm afraid it's not very polished, but you could look at [Entmut](https://github.com/dstu/entmut) to see a few different methods for implementing trees. There are rustdocs but not enough tests, benchmarks, or or high-level documentation.
Not quite. Certainly the SVD is a different decomposition, for one, but more importantly the randomized strategy for low-rank factorizations is quite different than one that works on individual columns at a time. Specifically, randomized methods are most useful when you have a fast matrix*vector operation, which is not required for a partial QR. I don't really think that what I'm describing is the most performant options for many applications. It is just a very easy algorithm to implement to get my feet wet. 
&gt; RLS' continual flakiness throws a spanner into these claims. This is orthogonal to the safety guarantees.
Rust is discouraging for women and POCs because the borrow checker is racist, we need affirmative action to increase the quotas, and allow minorities to alias mutable references! Down with the static typiarchy, it's too strong!
No, circular references aren't possible with lifetimes. If you are all in for performance, you could use [id-tree](https://github.com/SimonSapin/rust-forest/tree/master/arena-tree), copy the file and replace all the `.get()` by `unsafe { .get_unchecked() }` to get around the runtime-checks. This of course has it's disadvantages - you have to make sure that the IDs you give it are correct / in the range of the allocated arena of nodes. But it's good if you want to have only one allocation. You can further swap out the `Option&lt;usize&gt;` with an `Option&lt;NonZero&gt;` if you are on nightly, to save space. This should be the fastest version. id-tree is jus 450 LOC and very easily understandable. You have a `Vec` of nodes and an ID for each one, which makes circular references possible. So your other nodes would just store the ID `0` for the root node. Since a pointer is also just an offset into a memory region, it should be roughly equally fast as if you are using a reference. 
Aren't all generationnal GC compacting ?
About your IDE experience, I doubt you'd be able to see a speed difference but your are most likely seeing an increased latency, which is a classical drawback for GCs ‚Ä¶ Processing everything twice as fast but with regular latency spikes above 200ms is a terrible user experience when it comes to UI, but it's not for data crunching. 
I agree with this; we should try to reduce the friction of writing robust code as much as feasible.
What if the program is controlling a car?
No, being a compacting GC and being a generational GC are completely unrelated to each other.
*As I understand it...* The first goal of Chalk is to provide a better way to check types. The current algorithm has some short-comings, such as inferring the type from first use and then complaining that the next use doesn't match... with sometimes cryptic error messages. The second goal is to then be able to enhance the type system, notably for "negative reasoning".
I tried to implement ID tree by myself, as exercise, so I know how it works. But again, no static checks, no remove support. &gt;all in for performance I'm not. But if I have hundreds of nodes and all of theme allocates - it's just bad.
I'm not sure about automatically intercepting stderr to write it out to a file (depending on how you're running your program, normally this is done via `./my_program 2&gt; some_file` on the command line), but you might want to check out the log crate: https://crates.io/crates/log
What runtime checks? Incrementing and decrementing an integer as you add/remove nodes is not expensive by any means.
To be honest, I find those numbers meaningless. As a tinkerer, I like to toy with the new and shiny, so I'll always use nightly for pet projects and POCs, just to see how far I can push a feature. This makes me a nightly user. **However, I don't need nightly. I just toy with it.** Therefore, when I read that 51.6% of users use nightly, I can only wonder how many *are stuck* with nightly and how many *just toy with it*. And this significant difference in usecase may artificially blow up the number of nightly users (and of course push down the number of stable users) in the statistics, and increase the skittishness of would-be adopters. Taken at face-value, those numbers are scary, even though in practice it's unclear what they really mean :(
I mean, you *can* use start_send and poll_complete, but you have to use them correctly. `start_send` is never guaranteed to actually send anything, so if it returns `AsyncSink::NotReady(T)` you *must* take back that T and try to re-send it again later. `send` consumes it, yes, but it also returns the sink again as part of the result. If you have a general thing you need to do with `Sink`s, I would recommend using `send`, and then re-capturing the sink again in an `and_then` combinator. If all you're sending to is an `mpsc` stream, use `unbounded_send`. `mpsc` streams are, well, simpler than the `Sink`s can be, so `unbounded_send` represents this simplicity. This is why it only takes `&amp;mut self`.
Might as well have both!
Nobody claimed that Rust prevents software from having bugs.
Agh, sorry, yeah. I misunderstood your question, I thought you were already wrapping the vec. If you *aren't* already wrapping it, I wouldn't recommend doing that. Instead, I would just create a `struct DisplayVec&lt;'a&gt;(pub &amp;'a [X])` wrapper which could be easily created on demand around any vector (like `println!("hello, {}", DisplayVec(&amp;the_vec));`).
The author doesn't feel comfortable in spaces occupied by a lot of white men. As a PoC, I understand this feeling. It doesn't mean white men are bad, and it doesn't mean the author is a racist. Nor is the author trying to sow division. The author is expressing how they feel and honestly how many people who are not white males feel. I think this is an opportunity to explore why the author feels this way. This is an incredibly difficult subject to explore, but based on what I have seen from the Rust community, I would expect this group to at least approach it with an open mind. Why does the author feel this way?
UI latency is one thing, the other is rest of the system. GC works by overallocating memory, and then doing scans, and you are able to tell, because everything else seems to get slower too. Other apps gets to keep less hot caches, your oS can use less memory of FS caching etc. Another thing is that in Java almost everything is referenced through a pointer, or even a vtable, which is costly too. Probably a run-time optimizer can help, etc. But that's just another cost that is running in a background. So I fully agree. If you were to do data crunching, on a non-interactive machine, than GC will be OK. Having said that - I still think `Arc` would be faster in most applications, especially in a language that doesn't have to needlessly clone pointers everywhere.
You blame it on a piece of the floor padding getting between the pedals. 
I really like this answer :) I also think that the [Rust Roadshow Brazil events](https://discourse.mozilla.org/t/2018-rust-roadshow-brazil/24015) will have a much lower number of white men.
A better question would be, "How can we make this person feel more comfortable in our community?"
Totally! Unfortunately, they're the best numbers that we have. If you have ideas on how to better collect this data, I'm sure the community team would be interested; we do change the survey slightly each year.
It was an error, not a crash, but what about Therac-25? Lethal dosages of radiation due to bugs.
Fair enough. Although my question still stands in general, what about two meetups on different languages held in the same area? It's just that I would find it very surprising if rust, or any other technology for that matter, attracted in any way a different demographic compared to similar technologies. I just see no reason why it would.
Doesn't matter. You're not considering how it will be perceived.
Unfortunately, I'm running on Windows, and somewhat more fortunately, the issue seems to have mitigated itself after a while (admittedly I did update a few times and did some other arcane crap), so I can't reliably reproduce it at the moment.
If your definition of safety doesn't help people to build more robust software, then such kind of safety is not very useful. I hope that Rust's "safety" is not just equal to security, because security does not provide any value by itself. It's better to have a program that works but has vulnerabilities, compared to a program that is secure but doesn't work. Good kind of safety should help you make less bugs in your code. And that means less vulnerabilities too, because they are caused by bugs in the first place.
It uses the XScreenSaver API (maybe there is a different name), through the X11 crate. In the docs at http://www.x.org/pub/X11R7.6-RC1/doc/man/man3/Xss.3.xhtml it states "The idle field specifies the number of milliseconds since the last input was received from the user on **any of the input devices**." So yes usually this will be keyboard and mouse but also trackpads, joysticks, touchscreens etc.
I'm not talking about a runtime cost. I'm talking about "correctness" checks. When using lifetimes the compiler hold by back, but with Rc it's only a runtime (application will panic on double mutable borrow).
Judging by the author's post linked from the Rust post, the author does seem to have a general distaste for what they describe as "silicon valley bro" types. But, for the rust community to really be inclusive (which I think our leaders are actually doing a good job with), we can't just dismiss people who tell us they don't feel comfortable in our community because they cite "white men" as part of the reason or because we can't think of any reason for them to be uncomfortable. When someone says, "I don't feel comfortable here" and we don't know why, that's a learning opportunity.
I think it would be important to distinguish usages, I just don't know how best to format it. Maybe it would be as simple as restricting the question to *production usage* (or *intended* usage), and make it clear that "fun"/"individual" projects are not to be taken into account. Maybe it would be important to distinguish between current/intended production usage and "pending stable" production usage? &gt; La critique est ais√©e, et l'art est difficile. *In English: Criticism is easy, and art is difficult.*
Rc doesn't support mutability. that would be a Cell of some kind. If you're worried about a RefCell panicking, then there's *no way* you could get within a mile of a design that the borrow checker would be able to enforce at compile time.
Yeah, I mean, being straightforward about it is probably best. &gt; La critique est ais√©e, et l'art est difficile. :)
That's somewhat historical. The crate originated from libstd, but has been maintained independently for a while now. I just left the `authors` field as-is so I don't take undue credit. Additions since then have been from a number of contributors, [including`checked_pow`](https://github.com/rust-num/num/pull/162). (Though I suppose I am part of the Rust team now, as I volunteered for the rust-lang/release team.)
How does such a crate build with the stable compiler?
Presumably, the claim is that Rust's properties make these crashes easier to track down and fix, not that they shouldn't be happening in the first place. That is, they're not caused by memory corruption! As someone who deals with those kinds of bug reports in a C++ codebase... thank god. I'd take an RLS crash bug any day.
If you want to keep things simple you can just use the high level failure::Error type. with_context is the rough equivalent to the chain_err call. There's the macro's bail! macro does the same thing as chain_err. Note failure::Error has a small cost when error's are returned, so it's not great for a tight loop that creates a lot of errors. use failure::{Error,ResultExt} fn test() -&gt; Result&lt;(), Error&gt; { .... let file = File::open("bad name").with_context(|_| "open test file")?; //Or let file = File::open("bad name").context("open test file")?; if bad_thing { bail!("Bad thing happend"); } Ok(()) } If your using a #[derive(Fail)] for your error type and io::error Can be handled like #[derive(Debug, Fail)] pub enum MyError { ... #[fail(display = "IO Error: {}", io_error)] IoError { #[cause] io_error: std::io::Error, }, ... } impl From&lt;std::io::Error&gt; for MyError { fn from(io_error: std::io::Error) -&gt; Self { Self::IoError { io_error } } } 
I want to implement the tsqr algorithm, which uses householder reflections, and from there some blocked Gram Schmidt algorithms. So far I was using ndarray for me matrices, which I'm really happy with. Maybe you can get some inspiration from my Gram Schmidt crate for how to write these things in rust? The classical gram schmidt functions are mainly blas, but the modified one is mostly rust. https://github.com/SuperFluffy/gramschmidt-rs
I'm trying to access an Option&lt;Hashmap's&gt; .contains_key() method, yet I keep getting this error: error[E0599]: no method named `contains_key` found for type `std::option::Option&lt;std::collections::HashMap&lt;std::string::String, dbus::arg::Variant&lt;std::boxed::Box&lt;dbus::arg::RefArg&gt;&gt;&gt;&gt;` in the current scope
Sometimes it's easy -- library items can just be conditionally compiled. Like `#[cfg(feature = "nightly-only")] pub fn foo() { std::unstable_function() }` The stable compiler will do that file. If it's unstable syntax, like `const fn`, you can conditionally compile that too. If it's syntax that is both new and the stable compiler finds it completely outlandish (= it won't compile it), you can hide it in a macro, and conditionally expand the macro (stable Rust knows how to do that).
Fantastic! As a markdown enthusiast, I get the history of why "Reddit Markdown" is a thing; any thoughts on eventually changing over to a more standard-y implementation? GitHub is currently going through a translation of GFM -&gt; CommonMark + Extensions: https://github.com/blog/2333-a-formal-spec-for-github-flavored-markdown I can also totally see why you wouldn't do this, just curious! I sometimes get tripped up when writing comments by the reddit-specific bits.
This is really cool. I don't have anything better to contribute than that.
Yeah, github also has much more man-power and resources to put on this problem. We really hope to be there someday!
Who the fuck would work for this piece of shit company?
There is no method `contains_key` because you are calling on an Option&lt;HashMap&lt;_&gt;&gt;, not a `HashMap&lt;_&gt;`. Think about what your program should do if you have an `Option::None` vs `Option::Some(HashMap&lt;_&gt;)`. One potential course of action is to quit the program with a panic when you have a `None`. You can do this by calling `unwrap()` on your `Option&lt;HashMap&lt;_&gt;&gt;` to yield a `HashMap&lt;_&gt;`
Your opinion is contradicted by continuing to use the site.
That's what I figured, thanks!
I agree. Wish I had more (any?) Rust experience. Compilers and programming languages definitely pique my interest, being a large portion of my current course work. Maybe you all could use a software engineer intern assisting on this project? *hint hint* I just applied [here](https://boards.greenhouse.io/reddit/jobs/891967), if so. :)
Maybe that was ironic. I for one would happily apply for that job of it wasn't so far away from home.
Glad to see more blog posts about rust coming up! Ill check it out.
You can dislike a company while still using their products.
(I'm still very curious just HOW much slower it is...)
That's totally true. I bet stdin stdout with json would be pretty easy...
Snudown forked from Sundown back in 2011. What was the rationale behind the fork in the first place? Have you ever had discovered memory safety vulnerabilities in it (I'd love to see a torturous test case)? Why decide to port it to Rust? Are there any other internal libraries that might also be candidates for porting if this goes well?
There's the [transpose](https://docs.rs/nalgebra/0.13.1/nalgebra/core/struct.Matrix.html#method.transpose) method on `Matrix` (which `Vector` is just an alias for).
This is great! I don't have such amount of experience, but it's good to see more companies open to port/optimize their software. Just one thing.. when you open the position, please put something like "7 years of Rust experience" :)
&gt; We are porting Reddit-flavored Markdown parser from our open sourced C implementation to Rust and need someone to lead this project. Can someone give me a response that explains the motivation here? I want to understand why Rust was chosen to replace something that _is_ working in C (so that in the future I have ammo for when I want to do the same thing...).
I'm great with Rust. A little CLR, and I can get it off of anything. When do I start?
Safety in Rust is rather narrowly defined as the absence of ["undefined behavior"](https://en.wikipedia.org/wiki/Undefined_behavior). It definitely helps building robust software, but of course it does not guarantee the absence of bugs. &gt; It's better to have a program that works but has vulnerabilities, compared to a program that is secure but doesn't work. Depending on the circumstances, having vulnerabilities means it does not work. And I can certainly think of scenarios where a vulnerable program is worse than no program. &gt; Good kind of safety should help you make less bugs in your code. Again, this is not what is meant with "safety" in this context.
**Undefined behavior** In computer programming, undefined behavior (UB) is the result of executing computer code whose behavior is not prescribed by the language specification to which the code adheres, for the current state of the program. This happens when the translator of the source code makes certain assumptions, but these assumptions are not satisfied during execution. The behavior of some programming languages‚Äîmost famously C and C++‚Äîis undefined in some cases. In the standards for these languages the semantics of certain operations is described as undefined. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Really cool that such a big company want to give Rust a try! While I'm unable to apply for this (too young, lives outside of the US), I would love to help in any other way possible! A few questions: * What made you choose Rust for this project? * Will the new parser be available for public use? * What is currently wrong with the current parser that needs to be fixed? (Too slow, SEGFAULTs, etc.) 
Thank you! I can't believe I totally forgot about unwrap.
If someone thinks that Rust's safety guarantees imply it's impossible to have bugs, I can only tell them that this is not what is meant with safety.
I've seen something that I _think_ is the same thing happen several times using NeoVim + nvim-completion-manager. It hasn't happened consistently enough (and I haven't been disciplined enough) to suggest reliable steps to replicate it. I generally just run `pkill` + possibly close-out/re-open NeoVim until I'm back to normal.
Did you mean to respond to lynx-df?
Rustup installs it for you...
It's exposed to the web, so it is probably nice to minimize unsafe code.
The error message is saying that `Data` has a `serialize` method, which your code sample does not show. I think that is important context. Can you show the code that actually produces the error?
Rust's marketing stresses reliability.
Why are you using an `Option&lt;HashMap&lt;..&gt;` at all? Is there a semantic difference between `None` and an empty map?
Right. My bad.
&gt; Safe (or not) has much less to do with language and more to do with implementation. I think you missed the `&lt;/sarcasm&gt;` tag somewhere :)
I respect and I do not try to undermine the author's feeling, neither yours. But, as you said, this is all about feelings here and I think you are the only one that can help you to fix it, and be more comfortable. People will help you spontaneously to make yourself comfortable, but do not ask them to do it *because* you are a PoC. This is terrible. Besides, this kind of feelings can be really restricted in time and space, and it seems difficult to me that this should be tackled by all the Rust community. If you have racial issue within a particular meetup, I am sure people here will be glad to help you. For example, I just discovered that we have [Kenyan Rustacean](https://twitter.com/Africastalking/status/957171013921525760) that organizing some meetups: do they really need to face this kind of PoC feeling issue ? 
Reddit has a large history of open sourcing projects including the primary monolith codebase but we've changed that policy to be more focused on frameworks and libraries. Since this parser is primarily a library there's a strong possibility we can open source it. It really depends if the person we hire is comfortable taking on community and pull request management duties as well.
The fork was just to add reddit-specific features on top (e.g. r/subreddit and u/username autolinking). We otherwise kept pretty close to mainline and upstreamed anything non-reddit-specific back. I did a bunch of testing before we switched over and we did find some interesting bugs. Most were about letting funky HTML through rather than memory issues, but there was a segfault and a really fun one with varargs that u/slyf fixed. Here are the patches we upstreamed which will include these issues: * https://github.com/vmg/sundown/commits?author=spladug * https://github.com/vmg/sundown/commits?author=andre-d
Thanks!
u/wting gave some motivation [here](https://www.reddit.com/r/rust/comments/7utj4t/reddit_is_hiring_a_senior_rust_engineer/dtn47t1/) if you didn't see it yet. Sounds like primarily this reason: &gt; Also the C version of the parser is mostly maintained by our security team. It means that it's pretty safe, but **feature velocity** is quite detrimental as they typically have higher priorities on their plate.
"Fun"
... and then magically drops it after a toolchain update.
Having built and programmed an autonomous vehicle, I feel confident saying that the failure handling and entire program structure for these machines is quite different than that found on the desktop
I'm a newbie in Rust, but isn't the whole premise behind it is that it simply eliminates a whole category of bugs if your (non-unsafe) code compiles?
&gt; rustc is designed around several phases. At a high level, first we parse, then we typecheck, then we borrowcheck, then we lower to LLVM‚Äôs representation. This property of immovability is a property of the value‚Äôs type, basing type information on the results of borrowcheck would be out of order. &gt; &gt; In the limit, this may just not be possible - you may have a cyclic dependency, where borrowchecking needs to know if this type is immovable, but we don‚Äôt know if its immovable until we‚Äôve finished borrowchecking. Of course this is a very high level picture with a lot of detail hiding underneath, so this is probably more of "why couldn't this work" question, but: Given that (as I understand it) typechecking doesn't need to know about immovability, and the shape of the situation is just that borrowck both needs it as an input and would be the one producing it as an output, could this be resolved by running borrowck twice, once assuming that all types are movable, and then a second time knowing which ones aren't? (Or if there aren't any interesting interactions, just a simpler moveck phase; on the flip side of the coin, if there are interactions in both directions, running it to a fixpoint instead of just twice...) (There are potential performance issues here; I'm just wondering if it could work in principle.)
Unfortunately, what you're doing is not something representable in the borrow checker. The [rental](https://github.com/jpernst/rental) crate will let you do one level of self-referential borrows, but it's very strict about mutability, and that's not likely what you want. Implementing collections like this will need to be done in unsafe rust, if you want both mutability and performance. This isn't necessarily a bad thing though! If you do want to implement this structure from scratch, I would recommend reading [the rust nomicon](https://doc.rust-lang.org/nomicon/). It's a book on writing sound unsafe rust, and will be a good guide on making things like this in a sound way which can be used from safe code.
&gt; serde_json::to_string(self) There it is, in line 3. 
I think your points all hit the mark. "Maintainership" is a harder gal to achieve than the others, but Dependable API, Examples and Documentation are pretty much the mantra of the [ergo ecosystem](http://github.com/rust-crates/ergo) (which I see you linked, thanks!) One of the goals of ergo is to provide "a standardized API for disparate types/approaches, allowing library authors to develop simple libraries of high quality, which can then be combined into an ecosystem with a unified API and excellent ergonomics." It does this by importing the "best" crates for a domain and providing wrapper types around them to unify their API (among other strategies). In my opinion this is the best strategy for supporting both producers _and_ consumers.
With C and C++, the unsafety have a lot to do with the language (that don't know when you are screwing up your memory handling)
Just to clarify, rental supports up to 32 layers of self-borrowing as of now, but that's jut a constant that can be increased if need be. It is true though that for mutable self-borrows, only the last field is actually accessible once the struct is made, since all previous fields are considered mutably borrowed and thus locked out.
Over the past several months that I have used rls, I have encountered all kinds of crashes which seem to fix themselves next week. In the past week I finally figured out with the task manager that my McAfee real time scanner was using up a ton of cpu resources every time rls would run or if I compiled something. I removed it and now my build time is much faster than it was. I wonder if anyone else is having this problem and they do not know it
Oh wow I really wish I had the experience and knowledge for this!
not anymore, as nightlies are no longer produced without an rls.
There are a few approaches you could consider: - You could have the GUI program print everything it's reading as it's reading it, before it does any other processing. This is probably the easiest, but maybe you don't control the GUI. - You could replace your program with a shell script, which inside calls `tee stdin.log | your_original_program.exe | tee stdout.log`. This might be the most convenient thing if you don't control the GUI. - You could have your program fork off two `tee` child processes, one with your stdin and one with your stdout, and then use some `libc::dup2` magic to have all reading and printing talk to those instead of the usual pipes. This is tricky and time consuming, but it's a fun science experiment for getting a sense of how all the pipes work under the covers. The [`os_pipe`](https://crates.io/crates/os_pipe) crate can help with this if you want to try it.
Ah, thank you! I didn't do the right research as to the extent `rental` supports that.
Really nice to see a Rust-oriented position open up in such a high profile company :). Good luck finding someone!
I was just fighting with xautolock literally last week. Thank you!
Their tone was well beyond "dislike", but oh well, it's deleted now.
Can't work as I'm too young, but if you're looking for interns, I would love to be one! I'm currently learning Rust and I'm in the Bay Area.
Indeed, and with C it's easy to conclude that your code wasn't safe after all once it's been exploited, whereas with Rust it's easy to conclude it may not have been safe once the compiler (borrow checker) refuses to proceed. And no, I'm not claiming all Rust code is secure. Just that it catches some vulnerabilities before they exist.
Right. But there's no `serialize` method, which means the error message is pointing at code you didn't show me. In fact your posted code has some typos in it (`Stuct 2`) which means it definitely wasn't copy/pasted from the editor where you got an error. I'm not trying to needle you -- often, seemingly irrelevant details are actually important and the best way to get help is to give the situation _exactly_ (reducing the length of the code is good, but make sure it still gets the same error from rustc). All that said, I am guessing your real code is something like this (which [gets the error you describe](https://play.rust-lang.org/?gist=b6134c3837ba90fe3fa0693cdc17c17e&amp;version=stable)): trait Data: serde::Serialize { fn as_json(&amp;self) -&gt; String { match serde_json::to_string(self) { Ok(string) =&gt; string, Err(error) =&gt; { panic!() } } } } #[derive(Serialize)] struct Struct1 {} impl Data for Struct1 {} fn foo() -&gt; Box&lt;Data&gt; { unimplemented!() } // error here So, the issue is that `Box&lt;Data&gt;` is a boxed trait object, and you can't make a trait object out of a trait with a generic method. Here, the generic method is not actually in `Data` but rather in `Serialize`, its "supertrait". There's an explanation [on this blog](http://huonw.github.io/blog/2015/01/object-safety/#generic-method) of why it just doesn't really make sense to box a trait with a generic method. To solve the problem, you could maybe look at [`erased-serde`](https://crates.io/crates/erased-serde) which has similar traits but without the generic methods. Or you can refactor the code to not use `Box&lt;Data&gt;`. Without more details on what you're doing with the boxed traits, it's hard to give more specific advice.
I'd write a web frontend and communicate via websockets with ws-rs.
Using it in Atom, I faintly remember big performance spikes in previous versions of the integration but not in more recent version. When they disappeared after a while, I blamed them on me not removing the cargo integration and running both pipelines ‚Äì with error report and all ‚Äì simultaneously. I didn't actively monitor my usage recently, though.
It‚Äôs the correct term!
Cool!
The joys of sharing codegen infrastructure üòÅ
I'm loading a rust library into my rust application with [`libloading`](https://crates.io/crates/libloading) and calling a function in it. That function allocates a box and returns it. Eventually the box gets dropped, application-side. How is this handled? It's not crashing so I presume things are fine but I'm wondering what exactly happens. Does the dylib somehow use jemalloc along with the rest of the application or does it use the system allocator (because it's built as a library target) and when the pointer is freed jemalloc realizes it doesn't own that memory and passes it up the chain to the system allocator?
I compiled this last night and it didn‚Äôt recognize any keyboard commands at all. Anybody else have this issue?
This is a very common speed bump that people run into when learning the lifetime system. Self-referential lifetimes are pretty much impossible in safe rust. There are a number of reasons why. In this particular case, it would be very unsafe to call `push` on a vector when you have outstanding `&amp;[T]` slices into it, because `push` can cause the vector to reallocate and turn all of those slices into dangling pointers. The most direct fix would be to hold something like an `Rc&lt;RefCell&lt;Vec&lt;T&gt;&gt;&gt;` (one thread) or an `Arc&lt;Mutex&lt;Vec&lt;T&gt;&gt;&gt;` (multithreaded) instead of a `&amp;[T]`. A more idiomatic fix might be to use integer indices into your vectors of nodes and values, rather than using actual references.
As a primarily JS shop you'd think the reddit mobile app would better /snark. It's slow and has really horrible UX - post a comment not logged in - "Something went wrong" not "You aren't logged in", go to login and it loses your place. I get the apps are your likely focus but if so why put out a mobile client at all.
Short form. &lt;?php I say this as someone who sadly works full time with PHP.
help a programming newb out, why can't they be in stable?
Ah, I didn't think about the derives ^^ I can't really copy paste my entire code as its *a lot*. I use Boxes because they worked^tm and returning Data did not :/ Guess I will have to find out how I'll get this to work :P Thanks for now. When I get back to coding, I might come back to ask another question :P
Too bad it's on-site...
https://github.com/archer884/needle &lt;-- No features.
They use the guts of the compiler to do their job, and the guts of the compiler is not stable. The solution is to ship them with the compiler, so that everything lines up correctly.
I‚Äôm at FOSDEM and I‚Äôll probably be hanging around the Rust devroom most of Sunday. Bit late for a drink now though!
Since you're here talking about markdown I'd just like to say that to have a way to enter code blocks other than using four spaces of indentation in an entry window that doesn't support tab. :-)
Yup, that bothers me all the time too. Often I end up writing repies in vim before copy/pasting into the comment box. One of the longterm goals of this project is to make it easier to add and extend new features. :)
As an avid Reddit fan and Rust programmer, I'm very tempted to apply to this. Too bad I still 2 years to go in my PhD...
You forgot `extern crate herpes;`
Oh god, /r/programmingcirclejerk will have a stroke hearing this.
By the way RES has code feature in the editor that basically just indents a block of code by 4 characters which might be useful. Kind of surprised Reddit hasn't stolen that already.
Does it still have that cost for creating the Error, now that stacktraces aren't generated by default?
Are you saying herpes is implied? That's one funky universe...
Great, thanks.
I think this problem isn't usually solved at the web server level. What I would suggest is a middle service between your database clients and your database server. An example of this for Postgres is PgPool. The middle server emulates a database connection so your web server doesn't have to be aware of the multiple database servers. (You just connect to the middle as if it were a single database). It also takes care of the load balancing between the slaves.
I program in Rust, I applied at github and .... got reject at the resume screening phase! BOUH!
I'm interested in getting into dependently typed languages like Idris, can you recommend any resources to get into that? (I think Idris is more interesting than Coq because you can do systems programming with it.)
Video courses? I only know this [German one](https://www.youtube.com/watch?v=lQ36K1htRDY&amp;list=PL0Ur-09iGhpwMbNiVTBeHmIjs0GuIXhNg). Looks like someone translated the [book to spanish](https://www.reddit.com/r/rust/comments/51shfg/es_libro_de_rust_en_espa%C3%B1ol/) though..
something something there's a time and place
You jest, but there is a comp sci paper actually related to that, specifically about communication. I'll have to see if I can dig it up.
Hola! Te dejo algunos recursos adicionales a los que ya te han compartido desde el canal oficial de videos del proyecto Rust: - https://www.youtube.com/watch?v=Wq_Mlv1-mSI&amp;list=PL85XCvVPmGQiOmuK6ogZH_wyNxp8pz4TJ (a partir del segundo video) - https://www.youtube.com/watch?v=Y5apkLSkJaI&amp;list=PL85XCvVPmGQiRhpkQJEENbDd2gVRUPbNh - https://www.youtube.com/watch?v=xx8qiGMaLzo Igualmente, la traducci√≥n de la segunda edici√≥n, muy mejorada, del libro oficial de Rust, se ha estado llevando, aunque a ritmo lento, en https://github.com/thecodix/book/ Dependiendo de donde te encuentres, puedes encontrar tambi√©n un grupo cercano de reuniones de Rust en: https://www.rust-lang.org/en-US/user-groups.html Por pura curiosidad, qu√© esperar√≠as encontrar en un videocurso de Rust? Estamos muy interesados en generar contenidos en varios idiomas para quienes quieran aprender el lenguaje.
For every logging sink which hooks into the `log` crate, the behavior of multiple instillations is "the second time you try, it returns an error". `log` handles the actual global instance, and that's it's behavior - the only way you'd get something different is with a totally different framework (like slog).
That's great and all, but they'll never get back to you.
If you ever need someone to do a bunch of rust FFI work, let me know :)
I just read about futures but didn't realize m problem was a perfect use case. Sounds less laborious than the trait schema. Thanks a lot!
That's a charitable way of looking at it. Props for switching to a modern (albeit unproven) technology but you could equally argue that their choice of the previous technology is questionable. 
failure::Error still has a small overhead, that might be a concern in tight inner loops that produce lots of errors. A derive fail enum should be quite fast, as long as it's size is small. This comment (https://www.reddit.com/r/rust/comments/7te8si/personal_experience_can_cause_hard_to_notice/dtc18um/) and the rest of that reddit post provide some numbers and discussion.
It's not 'questionable', it's just 'prototype-grade'. I mean the website itself is written in Python, ffs (or was when this sort of stuff was routinely being discussed in the open, for all we know this may be a misleading description nowadays). And I'm not going to comment on the other languages that OP has mentioned here, you can see that there's been some improvement but the 'prototyping', 'iterate quickly', 'move fast and you-know-the-deal' etc. use case is very much the one that's being optimized for. And I know that the Web evolves quickly and some of this can't be avoided, but this stuff is so much more mature today than it was 10 years ago.
Well, there's a lot more to writing a robust parser than just memory safety. If it was my decision to make, I'd still want the Rust version to be maintained by the security folks, and I wouldn't want any interns committing features with no proper review either! This doesn't mean that there's *no* advantage in being memory safe, but Java is memory safe too and abuse of hand-rolled parsers for things they weren't supposed to do is absolutely rampant there.
"hahaha" \- nobody
There's a significant cost to porting a code base from one language to another. And type safety is something that should _already be handled_ in a production code base that's years in the making. So I wanted to understand the motivation for moving. It sounds like feature velocity is one of the considerations. And I can appreciate that, though I am of the opinion that it's a weak argument for a critical move like that.
Sorry, I'm having a bit of trouble telling: is this sarcastic or is that a legitimately good error message? It seems pretty confusing to me, but maybe it makes a lot more sense knowing the surrounding code.
I *was* talking about programs in general. Embedded, crash-less, FSM type programs are hugely niche. Crashing is also safe and possibly even preferable for server processes, kernels, and non-safety-critical embedded devices. A crash and resumption is a great way to recover with known good state, which is one reason why Erlang tasks and the NT/Linux kernels do it. There's a very small set of cases where crashing is unsafe; for the majority of programs, it's a perfectly valid behavior choice when a failed attend occurs.
Do y'all _currently_ have rust in production? (It sounds like you do) If so, would you like to be on the https://www.rust-lang.org/en-US/friends.html page? There are instructions for adding your company at the bottom but you can also email community-team@rust-lang.org with a logo and some background and we can add it.
Holy shit this is pretty amazing!
Thanks! I can read English, the official guidebooks are really good, but videos are a must for me... thanks again! :)
Thanks dude!
I compile on stable, but as part of the build process, I use night for rustfmt.
do you need a gui or just a canvas to draw? mini_fb is cool but SDL2 works also great. 
You just took a single line out of context. If you read message from top to bottom -- it literally hand-holds you as to what is coming where from and what it probably should be. The line you mention just states in terms of types the compiler found what it was expecting (i.e. no need to chase &amp;&amp;&amp; and *** ref/deref stuff). It actually makes it even easier to focus on the real issue... I think it is pretty awesome. I am so spoiled by nice, detailed compiler error messages in Rust that my tolerance to cryptic output of all the other compilers went to virtual zero. Keep it up Rust team!
I know Rust but I live all the way on the east coast. When do I start?
Isn't that a response to anything that improves?
15 years or go home
We do but it's not a lot. I'd be more confident extolling the praises when we have something substantial to point at, otherwise it feels like damning with faint praise :)
Hard to say it's unproven when it's a chunk of Firefox.
Just thought I'd throw out that I'd love if it was FOSS. I've created a site that relies on reddit to render the markdown before it's shown to the end user (it's a reddit post, I'm not abusing your servers). If it was FOSS, I would likely compile to wasm or run the code on my server, instead.
It's used in the one product it was designed to be used in, how is that surprising? Rust is promising but still very young. It takes a lot of efforts and time to see if a language will become mainstream. We'll probably have a better idea in five years or so. 
From a quick look through it pretty good. The only thing I seen was you didn't explain how to install it on windows. If you go to the rustup.rs website it will give you a rustup-init binnary to install it. Plus you have to install the Microsoft build tools to use msvc. 
I know that [`termion`](https://github.com/ticki/termion) has the [`async_stdin`[(https://docs.rs/termion/1.5.1/termion/fn.async_stdin.html) method, which uses an `mpsc` stream as /u/daboross suggests. Would that fit your needs?
Context?
So, curses lets you set the timeout on getch to 0, and then it will immediately return with ERR if no input is ready. You can also set it to a negative number and then getch will block forever waiting for input, or a positive number and it'll wait up to that many milliseconds before timing out with ERR. There's layers of stuff built on top of curses, but that's the basic interface. I don't know enough to say how you'd hook that into tokio, but maybe that explanation will help someone see how to do it.
Hear, hear! The Rust compiler diagnostics are some of the best, clearest ever. They make a huge difference in my quality of life.
&gt;markdown I say this every year, but single newlines need to actually create single newlines, backwards compatibility be dammed. This catches just about every single new user.
Alternatively, every other dialect has \```lang or ~~~lang ;) 
Yeah - I mean I can make sense of the whole error. The OP just seemed, well, maybe I'm just bad at seeing sarcasm. It is in whole a pretty nice error message!
Has someone who knows what they're doing (not me) filed a feature request on LLVM for them?
if everyone waits to see if something becomes mainstream, then it cannot become mainstream... People need to pick up the ball and move it forward and there is an element of risk involved but you can't win the game otherwise.
6 monies.
Oh - thanks very much. I‚Äôll be sure to include that in the next tutorial
&gt; the Reddit parser is a fork of comrak. Glad to see that more people are using comrak. Although pulldown is more popular, comrak has a better support for CommonMark, and the generated AST is quite handy.
I‚Äôll most likely be there as well :-) I guess I‚Äôll just have to ask earlier next year (^^,)
TIL
Link?
[This](https://github.com/rust-lang/rust/blame/6c15dffc43d86c316e3d6bf9f9ffd48d8b5f4a3e/src/librustc/infer/error_reporting/mod.rs#L1160) could help finding the "one" it think its necessary to dig more into the history but it looks like ‚Äì from the first gimps ‚Äì at least 9 individuals are involved. 
You want /r/playrust
Underneath Tokio, mio is used to handle asynchronous event loops and stuff. There attitude towards asynchronous events involving stdin ‚Äî the terminal input ‚Äî are described here: https://github.com/carllerche/mio/issues/321 
Why is `T` a different type from `(T,)`? What's the point of having a separate type for 1-ary tuples at all?
Sounds workable even if far from ideal. Do you have a repo for me to peek at ?
They are occasionally useful when defining macros over a variable number of arguments. Having to special-case one-element variants would be quite frustrating.
Mixed feelings. Reddit is one of the biggest vehicles for propaganda on the net and their original values such as allowing free speech no longer exist. I would not go after this position. If programmers displayed some ethical awareness in their choice of work, the internet wouldn't have become such a crappy place.
Wow that‚Äôs bizarre. I was literally in the process of doing the same thing. I started however using Go and was then going to rewrite in Rust. You can find my code here https://github.com/boyter/lc I am still in the process of ironing out some of the issues with SPDX generation. Seems that identifying licences has become a good test of command line tool programming, similar to how building a blog was the test of web frameworks for a while there.
Background: I have a loop that I only want to run when data is available so I want it to block to save cpu cycles. My idea is to basically use a channel as a counter, since it 
Problem: I want to run a loop only when data to process is available. This data comes from other threads. I want to signal the thread from another one whether there is data to process. My idea is to use a channel that basically acts as a counter for the iterations that still need to be run. It should work like I want, since the receiver.recv() blocks when empty. Would this work? I also want to ask if there is a more elegant way to do this. Maybe blocking only if an atomic u32 is 0. The problem I have is that it doesn't look very sane to use a channel for this, since I don't want the message functionality but only the blocking functionality.
Yes, I think this diagnostic is the culmination of the effort of multiple individuals over a long period of time, each further polishing the message.
thank you.
That's what I do. I have a python script to do this because I got tired of doing this manually.
What I would like to see is a benchmark of how long it takes developers to solve a problem using these different approaches.
Nothing about the builder pattern inherently imposes that limitation, though some implementations of it might. The builder pattern is simply about using `func(1, 2, 3).optionalA(4).build()` as a substitute for `func(1, 2, 3, optionalA=4)` where `func` could theoretically have two dozen optional arguments.
I'll counter: 5.5 monies and I get to wear sandals with socks.
2 and a half shmeckles and ponchos and mandatory. that's my final offer. 
I have a `BufRead` and I need the ability to read more than one `buffer width` at a time without calling `consume()` in between. [You can see that I had a discussion with myself](https://github.com/hxtk/Rust-Scanner/issues/4) in which I concluded that I should implement the `BufRead` trait on my own object and use a variable-length buffer, but I thought I'd ask here first: 1. Is there a simpler way? 1. Does a variable-length buffer inherently break any promises made by the BufRead trait? Then as a second question, you might note in the discussion that I'm looking for a way to match the language of all prefixes to the language of a regular expression. In mathematical terms, I want to know whether the DFA for the original language is in a dead state after consuming the last byte of the input. If someone knows how to do that without implementing my own Regex engine, that'd be grand.
Great work. Github link: https://github.com/vorner/vorner.github.io/blob/master/async-bench.md If you think the text is too bright. 
That's an encouraging pull request number. :)
Noooooooooooooope 6 parts shame, 4 parts I promptly refactored
&gt; because it can‚Äôt have stack-full coroutines and work-stealing between threads at the same time and still stay being Rust Isn't that exactly the premise of Rayon? Although Rayon is not an async framework, but rather one for static workloads.
Try [this one](https://github.com/actix/actix-web)
It's nice that people are trying to use numbers for comparisons, but to be perfectly honest this benchmark is not very helpful. All this benches is how fast syscalls are. The code being benched does virtually nothing except call syscalls and syscalls aren't cheap (especially post meltdown). To compare different strategies, you really have to do something real. Actual computations, protocol handling, app logic, many tasks that are interrelated, etc...
Strictly speaking, isn't a[b] desugared to deref(sum(a, mul(b, sizeof(typeof(a)))))? Your fetch function shouldn't deref NULL; it should be performing collapsible arithmetic on it -- add(NULL, sub(addrof(c), NULL)) -- which just evaluates to addrof(c) before the deref occurs.
This is really cool. Have you looked at XDP, and how eBPF might be used write things like custom load balancers? This is from the [iovisor](https://www.iovisor.org/technology/xdp): Use cases for XDP include the following: - Pre-stack processing like filtering to support DDoS mitigation - Forwarding and load balancing - Batching techniques such as in Generic Receive Offload - Flow sampling, monitoring - ULP processing (i.e. message delineation)
It's a deal. I'll start on February 31st.
This [modification](https://play.rust-lang.org/?gist=0e98bbbe7281af66366a4a723caca58e&amp;version=stable) will work. You also can take [`Chunks`](https://doc.rust-lang.org/src/core/slice/mod.rs.html#2127-2130) as a reference. As for giving references to data owned by iterator AFAIK it's currently impossible.
More and more, I think that the best languages are **boring**. As a counter-example, JavaScript is full of excitement: &gt; [0, -1, -2].sort() // [-1, -2, 0] WAT? I don't want a language full of excitement, I want a language built on the [Principle of Least Astonishment](https://en.wikipedia.org/wiki/Principle_of_least_astonishment), a language whose semantics and performance are roughly predictable. No surprise, just **plain boring**. And I'll use it to build boring services and applications, which just churn along quietly.
It's on my to do list to. There is a WIP implementation of libp2p which is quite active, so hopefully it will soon be not too difficult to write a Rust ipfs node...
Sure! The codebase isn't exactly a small example, but I'll link it. https://github.com/daboross/screeps-rs/tree/master/network/src/tokio is the heart of the tokio thread &lt;-&gt; graphics thread interaction, as well as my code to network using tokio. The ui/ crate in that repository handles the GUI.
I think you should take at least a little bit of credit. It's easy to write unreliable code in Rust. Rust just taps you on the shoulder and says "you know that can fail, right?"
Thanks!
That's a pretty poor example IMO. That's only bad language design because of the poor default behaviour of the sort method there, not because you can instantiate an array and sort it that succinctly/dynamically.
I'm running into some trouble trying to make a REST API where a number of functions manipulate a shared resource. I wrote a toy example that has the same problem as my real program. I think the easiest way to explain my problem is with a comment in the code :) #[macro_use] extern crate nickel; use nickel::Nickel; use std::sync::{Arc, Mutex}; use std::time::Duration; struct HonkManager { honk_counter: u32, } impl HonkManager { pub fn new() -&gt; Self { HonkManager { honk_counter: 0, } } pub fn honk(&amp;mut self) { self.honk_counter += 1; println!("honked {} times", self.honk_counter); } } fn main() { let thing_manager = Arc::new(Mutex::new(HonkManager::new())); // How do I get rid of this unwanted clone? let unwanted_clone = thing_manager.clone(); let mut server = Nickel::new(); server.keep_alive_timeout(Some(Duration::from_millis(100))); server.utilize(router! { get "/honk" =&gt; |_req, _res| { thing_manager.lock().unwrap().honk(); "honk!" } get "/also_honk" =&gt; |_req, _res| { // How do I get rid of this unwanted clone? unwanted_clone.lock().unwrap().honk(); // If I use thing_manager here instead of unwanted_clone, I get this message. // The problem is that I don't exactly know what's expected of me. // It doesn't seem right that I should implement the copy trait on this type // error[E0382]: capture of moved value: `thing_manager` // --&gt; src/main.rs:45:13 // | // 37 | server.utilize(router! { // | ____________________- // 38 | | // 39 | | get "/honk" =&gt; |_req, _res| { // 40 | | thing_manager.lock().unwrap().honk(); // ... | // 45 | | thing_manager.lock().unwrap().honk(); // HELP: How do I get rid of this unwanted clone? // | | ^^^^^^^^^^^^^ value captured here after move // ... | // 48 | | // 49 | | }); // | |_____- value moved (into closure) here // | // = note: move occurs because `thing_manager` has type `std::sync::Arc&lt;std::sync::Mutex&lt;HonkManager&gt;&gt;`, which does not implement the `Copy` trait // = note: this error originates in a macro outside of the current crate "honk honk!" } }); server.listen("0.0.0.0:6767").expect("Blargh!"); } 
k
&gt; [0, -1, -2].sort() // [-1, -2, 0] Why would this be javascript's fault?
`?` is shorter than `.unwrap()`. So not only does Rust warn you when your code is unreliable, it's also more cumbersome to let an error slip than to just handle it. 
I'm using serde_json and I'd like to derive a struct. The example from the documentation goes like this: ``` #[derive(Serialize, Deserialize)] struct Address { street: String, city: String, } ``` My question is, how do you do this when the key for a field is a reserved keyword in Rust? The API I'm using has a key "type" and so this struct won't compile: ``` #[derive(Serialize, Deserialize)] struct Info { data: String, type: u32, } ```
You just discovered the most beautiful thing about Rust: if you eventually manage to prototype a piece of software in Rust, it keeps working in all types of situations. In most languages, if you manage to write a data processing function, and you want to allow it to use multiple cores, you suddenly have to be extremely careful not to introduce race conditions, causing a large rewrite, lots of data race debugging, and so on. In Rust, rewriting your code to take advantage of 40 cores instead of 1 takes under five minutes, and a single `extern crate rayon;`. Just one of my thousands of "holy shit, that's awesome" encounters with Rust.
Yep, my recent favourite thing was discovery, that you can collect iterator over `Result` into `Result&lt;Vec&lt;_&gt;, _&gt;`. (http://xion.io/post/code/rust-iter-patterns.html)
I know adding the question mark operator was contentious at the time, but I think it was a great decision in retrospect for this reason. Writing safe code is just so much less typing!
Because any sane language will sort a list of integers in proper numeric order, like Python does? &gt;&gt;&gt; a = [0, -1, -2] &gt;&gt;&gt; a.sort() &gt;&gt;&gt; a [-2, -1, 0] Javascript's approach is equivalent to this Python code: &gt;&gt;&gt; a = [0, -1, -2] &gt;&gt;&gt; a.sort(key=lambda x: str(x)) &gt;&gt;&gt; a [-1, -2, 0] I confirmed it by double-checking Javascript's approach on a longer array: [0, -1, -2, -10, 1, 2, 10].sort() // [-1, -10, -2, 0, 1, 10, 2]
std::array is a wrapper around the plain C arrays; same size etc, only you have all the std functions and helpers you know from std::vector.
Sure, we can ascribe many words to the issue. "Surprising" is another good one. It's not even a dig at dynamic typing/coercion. It's a dig at any kind of "bad surprise". For another example, consider a HashMap which under certain conditions would have O(n) insertion/deletion^1 . The output is correct, the performance is surprising, the sort of surprises that causes a service to timeout from time to time, for no discernible reason. ^1 *An example is [Hash collision security issue](https://bugs.python.org/issue13703), which plagued Python and Ruby a long time ago, and of which even Rust suffered in some corner-cases.*
I should have looked at it more closely, that's ridiculous
&gt; There is a WIP implementation of libp2p which is quite active, Which is that? The only one I know of seems to have stagnated
I haven't tested this properly, but [according to this](https://serde.rs/variant-attrs.html), it would seem that the answer should be #[derive(Serialize, Deserialize)] struct Info { data: String, #[serde(rename = "type")] // This! formerly_known_as_type: u32, } 
how does it compare to Go(routines)?
Python has certainly found itself an interesting niche in science applications. I tend to think pretty similarly, that most scripting languages shouldn't be used for anything nontrivial. And yet the industry is in a situation where data science is becoming all the rage, while most scientists are not typically trained that extensively in programming. So here we are with Python being the de facto language of choice for so many production systems.
Ambiguous comment, but I'm giving you the benefit of the doubt and saying you agree with me. 
I may or may not agree with you, I'm just saying this is probably not the best place to say it. If you're not interested, **don't post**. If you want to use better places than reddit, **stop using reddit**.
If you keep indexing out of bounds like that, you're going to cause a panic.
To be fair, I think everybody agrees that JS has its warts but the language standard authors are unable to fix them as it'd break backwards compatibility. I hope with WebAssembly we can have a "JS 2.0" in a sense.
One of the things that I found cool is that you can't search a string starting from the back, because that's not how Unicode works. You can only iterate from front-to-back and then yield the found results in reverse order. It prevents you from ignoring that UTF-8 variable-width encoding works front-to-back. If I hit a bug that I can't debug in 10 minutes, I create a condensed example of the bug in [this repo](https://github.com/fschutt/errors) (after I fixed the bug), to remind myself if I ever get into a similar situation again. So far there are only two bugs and I've been writing Rust full time for roughly a year now. 
Thank you!
&gt; but to be perfectly honest this benchmark is not very helpful. I never said it was. I tried to even hint that it isn't. I meant it more like finger-in-the-air estimation. &gt; All this benches is how fast syscalls are. The code being benched does virtually nothing except call syscalls and syscalls aren't cheap (especially post meltdown). I would disagree a bit here. This benchmark measures syscalls + *task switching costs*. As all the implementations do the *same* syscalls, the difference should be on the task switching ‚Äí which is what I tried to measure. (Furthermore, this is AMD processor that doesn't have meltdown and the kernel version not yet patched for either meltdown or spectre)
I have a similar story. I coded up a simple rust web app in the pre-1.0 days. All it did was query my city's bus data api and served up a page showing me the next few buses coming to my most frequently used bus stops. After a while I stopped taking the bus and forgot about the app. I noticed it was still running, happily serving up pages, and at completely level memory usage over a year later! Not bad in my opinion.
https://github.com/libp2p/rust-libp2p
I don't have an idea. I didn't have enough motivation to learn that language and to do something remotely fair, I would have to go the harder way with separate client and somehow orchestrating starting and stopping all the separate server implementations. But if you want to do that, you can of course reuse the benchmark code of the servers here :-).
No probs. I actually meant to link this: https://serde.rs/field-attrs.html Mainly because the help text was a little clearer: &gt; #[serde(rename = "name")] &gt; Serialize and deserialize this field with the given name instead of its Rust name. This is useful for serializing fields as camelCase or serializing fields with names that are reserved Rust keywords.
That sounds like something *very* subjective. How would you want to measure that in a fair way? How do you find a person that knows the approaches to the same level? Do you measure it with experienced programmer (then probably the one with shortest solution wins) or one that has to learn it (then the learning time dominates)? Furthermore, different people think in different ways, therefore find different approaches convenient. You probably could choose some task and set the code for each approach side by side and let people pick.
I didn't really mean to imply that the system used for the benchmarks had the meltdown patch applied. I only meant that this type of benchmark is even less meaningful post meltdown. &gt; This benchmark measures syscalls + task switching costs. Right, but task switching costs will be dwarfed by syscalls here.
Bit late response from me too. Will be at dev room though :D
Sure, FOSDEM is the single greatest FOSS conference!
Ah, so you *are* capable of forming sentences. That's great. But please, don't tell me what to do or not do. 
Pretty involve indeed, I'll have a look. Thanks !
Is existing a way to fool Rust's compiler and make a dangling pointer? 
Yeah. Java is boring. Rust is fearless.
Only if you use unsafe and `*const T` instead of `&amp;T`.
I think WebAssembly is a huge step forward for the web. If there is one thing that is present on more computers than a JVM or CLR, it's a web browser.
If there was a way to fool the compiler (the borrow checker) into keeping a reference after the object is deallocated, then that would be a soundness hole that has to be fixed in a new version of the compiler. To my knowledge, no soundness holes like that exist. If you make raw pointers then I think it might be possible to create a dangling pointer, but then you'd also need `unsafe` to dereference the pointer. (still, `unsafe` does not give you permission to break the borrow checker's rules, it's only a way to promise the compiler that you are still following its rules even though the compiler can't verify that. If you break the borrowing rules using `unsafe` then the compiler might break your program.)
Question: why do you want to get rid of the `clone`? It doesn't seem particularly problematic to me. The reason it isn't letting you do this, is because you use `honk_manager` within the `/honk` handler. Each handler needs to own all data it uses, but only one can own each `Arc` handle. Using a clone lets you have both own copies of it. `Arc::clone()` isn't particularly expensive, however, so I'm not sure why you want to avoid it. It's literally increasing an atomic reference counter, and making a copy of the pointer. I assume the whole reason you have this structure wrapped in an `Arc` is _so that you can clone it_, right?
The reason why I want to avoid it is because when I add a third and fourth clone, it's going to get pretty messy. I can't imagine that idiomatic rust code would look like this: let honk_manager_clone_1 = honk_manager.clone(); let honk_manager_clone_2 = honk_manager.clone(); let honk_manager_clone_3 = honk_manager.clone(); 
This post was yesterday, though. I‚Äôm not sure if you refer to tonight? I‚Äôll be at the rust track tomorrow at the very least
See you there, I guess :-)
As a hint for the second case: struct Mm(f64); fn Mm(mm : f64) -&gt; Mm {Mm(mm)} impl Into&lt;Pt&gt; for Mm { fn into(&amp;self) -&gt; Pt { Pt(self.0 * 2.834_646_f64) } } Might save you a *lot* of trouble in the long run. It's called the newtype pattern.
To be clear, `unwrap` _is_ safe. Safe doesn't mean "never crashes".
Oh I know it's presumptive, and I'm trying to get use valgrind, etc. to see if I can get more info. I just figured someone might know. I still think if there was an allocator mismatch it would result in immediate issues, as it's similar to a double free. I also use the raw pointers and "pass-back" strategy, but would like to avoid it in this case if possible to the structure of the application.
Your definition is slightly orthogonal to mine, because you can be unsurprised at magic, and that magic will work for you, which is supposed to be the draw of Ruby.
&gt; [0, -1, -2].sort() // [-1, -2, 0] How? Why?
Hmm, I didn't have that experience with rayon in a personal project I'm working on. It reads from files that can be arbitrarily large, so I read lines at a time, but rayon basically only works for the fixed size containers in the stdlib, so to even use it, I'd have to resort to collecting chunks at a time, doing it in parallel on that, and then moving on, which is cumbersome and inefficient.
200000 USD and year of time and you have it :P
Join the discussion link is broken? :)
I had this same reaction and looked it up. Turns out JavaScript's `Array.sort` method takes a comparison method, and if one isn't given, by default, it turns every element into a string and sorts lexicographically. I cannot even begin to imagine why this decision was made.
I cannot quite follow your thoughts. I think you could mean the following two scenarios, both are handled fine by Xi design: 1) The editor should handle files larger than current RAM allows, let's say 100 TB. This already requires that the file is paged in and streamed in chunks into the editor core - the rope data structure makes this rather attractive, since it is easy to express. The additional overhead of handing chunks of your file to other plugins via RPC is not of importance here - encoding the json and passing it over IPC will be at least an order of magnitude faster than loading chunks from disk. Plugins will have the same power in this scenario as the core, they will just have the higher latency of one RPC roundtrip until they can get started. Users will not feel the difference. 2) The editor should handle only large files that still fit into memory. I think your assumption here is that the core could do bulk operations on the whole file quickly. But searching 5Gb takes a second or so and if the data is linear in memory, the editor would need to block to do this search. However, a stated goal of Xi that blocking never happens. The design will therefore search over the text in chunks (of the rope) which allows other parts of the text to still be edited while the rest is searched. Here again, the chunks can be easily streamed to the plugin interested in doing the bulk calculation and given that IO is threaded in plugin and core, the cost is again only the added latency of the first RPC roundtrip - while the second batch is streamed, the first can be processed. In general I think Xi's design works for all use cases, as long as IO+serialization time is much smaller than processing time. This is true for text search already, the simplest plugin I can think of.
I guess the main advantage Python has is the operator overloading lends itself well to translating equations into code, without much noise. However I think it does come with complications, judging by the fragility of the package management (pip) which works generally OK but to get a reasonable data science setup you need to pull in numpy and a bunch of other things 
Apparently only members could view that link. I've updated it with a public isse.
Somehow reminds me of [this](http://www.bash.org/?5273): &gt; &lt;erno&gt; hm. I've lost a machine.. literally _lost_. it responds to ping, it works completely, I just can't figure out where in my apartment it is.
What is a language but part of the implementation?
Alright, thank you so much! I've been bashing my head against this for a few days now.. :D
It was not much data, and a lot of processing. The entire data file took about 3MB, and cost thousands of CPU-hours to process. I simply loaded the entire file in RAM and started processing it afterward. If your application is IO-bound... I guess you're stuck using Hadoop-techniques, where you need multiple machines and hard disks. Simply using more CPU cores won't speed up the disk reads.
&gt; For reasons I couldn‚Äôt guess, the futures approach is somewhat slower than async, even though they both produce a state machine that is fed to tokio. Maybe the async style is easier for the optimiser to reason about or the resulting state machine is smaller. This is definitely the case today! The nested enums are still much harder to optimize (in terms of reducing memory usage and flattening the discriminant), whereas the generator state doesn't look very different from some data on the stack and the state is one integer per `async fn`.
Yeah, aliases are a lesser known feature of Cargo! There are some handy built-in ones! cargo r =&gt; cargo run cargo t =&gt; cargo test cargo b =&gt; cargo build
Simply put, yes. It's in the first bullet point of the Code of Conduct: https://www.rust-lang.org/en-US/conduct.html Our goal is to be welcoming to all, regardless of experience level. Rust is harder to learn than Python, and that might turn some people off, but our community environment should always be welcoming. Sometimes we fall short, but it's the goal we strive for. If you read docs, do your own homework, and respect the time of those that help you, you can make great contributions to Rust.
It will make a string of integer and sort like an array of string.
Note that "safe for space" means something slightly different than what's described here. In particular, it means that the maximum working set size doesn't grow (asymptotically) more than it "needs" to. That is, memory that could be freed isn't held on much longer than it should be (for precise values of "could be" and "much"). The post only says "eventually" deallocated, which isn't quite the same.
I used this trick to collect a paycheck for 3 years without ever working.
/r/playrust
[removed]
It's [mdBook](https://crates.io/crates/mdbook)
 Talking to (non-computer) scientists, I'm happy as long as they aren't using Matlab or FORTRAN on some level. Thinking about it, what is a good programing languge for scientists? As much as I love rust it requires you to learn a bunch of theory up front which makes it hard to convince them to use it as for scientists the interesting stuff is done outside of programing and programing is just the boring tool to crunch numbers to them. I think Python is aproachable enough to gain traction within the science community while being sane enough to not actively piss off programmers (for the most part)
Rust certainly has a niche that it targets, so it may simply not be what you need, and that's fine. That said, Rust's niche (robust, high performance, detailed control over hardware) could also easily be where your "script that makes your life easier" or "way to earn a living" fits! Which is why it does strive to be accessible to everyone.
You could probably CFG it and register stdin directly as a raw fd on nix systems if you wanted to at least? 
Thanks!
This...this is mind-blowing! Does this already have a Rust Cookbook entry?
Why would you not "get started" if you know NLL is on its way?
What do you mean? I'm learning the Windows Console API to build some Windows TUI logic, and an interested in hearing why. It's annoying to convert UTF-16, but I haven't seen anything that I would say is "broken"...
Rust is really usable as is, NLL mainly fixes a few papercuts. If you don't want to deal with the borrow checker, you can always just avoid borrowing things in complicated ways.
Omg, this will be incredibly useful. I can finally move away from makefiles!
NLL will remove some borrow checker issues, but ultimately you'll still need to internalize the borrow checker at some point regardless of NLL.
Often with the functionals, achieving speed means doing things in very particular ways, and it's an art because the performance qualms are less obvious than when using C/C++ which also have an art to performance. Speaking of C/C++ those are also static, albeit weakly typed :(
Rust is excellent for beginners that want to do system programing (or simply want to profit from its strong points) because it protects you from a lot of potential errors you would inevitably make. If you have no use for rust strong points (small memory footprint, short latency, speed) then no real reason to use it.
Already there in nightly https://santiagopastorino.com/how-to-use-rust-non-lexical-lifetimes-on-nightly/
Look at the table for the == It's bad all the way down.
What (if any) Scala libraries did you use for your service? Performance definitely isn't always the best but I find it very easy to write highly reliable services using Akka (a few obnoxious JVM idiosyncrasies aside). I find I'm having a hard time being as productive in Rust as I've been in Scala but I love the language and it's only getting better. 
Yep, this one.
I'd love to know as much detail as you can give. I'm working on a system that uses Rust in an on-premises app as a wrapping around a Java app that pushes data to a cloud service. We're implementing that cloud service as a single digit number of microservices written in Scala. I'm interested in moving some of the smaller ones to Rust eventually, mostly once AWS Lambda supports Rust first-class.
Could you show some code or example for me ?
&gt; Rust tests the programmer's knowledge on a subject they probably haven't studied yet. If you are coming from a C or C++ background (i.e. the things closest to Rust without Rust's USPs) you not only should have studied this, you should be able to consistently get it right in most cases, because getting it wrong means your program's doing something undefined. The only (although IMO its vast) improvement Rust makes here is that it doesn't let you get away with getting it wrong, even in benign ways. (Maybe you've been lucky enough that your thread finished before the non-`'static` thing you passed to `spawn` got deallocated) You're right though - all NLL does is change the syntatic rules to allow some constructions that conceptually work but are currently disallowed because the compiler's notion of when lifetimes end isn't as sophisticated as it could be. It's not going to help the OP understand the semantics of how long his objects and references last in relation to each other and how to arrange his ownership graph so that all the lifetimes check out. 
Just put a lot of people to write a server using async crates and measure every people time with each crate and divide the sum of the times by the number of people. It doesnt need to be one guy ;)
To add to this, I can only think of one or two places I worked around the lack of NLL. Granted, this might be application / API specific. Now, more complex borrows and moves I've worked around some but aren't too worried about it. I sometimes have this concern that as Rust evolves there will be some roadblock that prevents its future growth in an essential language design areas. I see self-referential structs being one of those. We've got a work around (rental crate), there is talk of a work around for generators (immovable types), and I have seen some pushing for move constructors. I feel the latter is essential and hope a viable solution gets agreed upon and implemented.
I'd like to use rust more and contribute to a project. Where to find those project suggestions? 
https://github.com/aep/elfkit is probably the closest that exists.
Depends on what you mean, but there is this: https://www.reddit.com/r/rust/comments/7muwwp/elfkit_elf_linker_written_in_rust_can_now_link/
Doesn't compile as given. You'll need to work out an appropriate prelude, which on current nightly seems to be #![feature(alloc, allocator_api)] extern crate alloc; use std::slice; use std::heap::{Heap, Alloc}; use alloc::allocator::Layout; Having done this, you'll then find that running it produces a plain ol' segfault, because it fails in the unsafe block. So no fancy error message. If you fix the handling of `capacity` in push, you will find that things work. Note that building in "release" mode with `-O` will not get rid of the bounds checks. This is good: you wanted those. Using the struct `impl` is good Rust style, but cheating a bit when imitating C code. Both `new()` and `push()` can easily be lifted out to standalone functions. Here's a [working version](https://gist.github.com/BartMassey/d2a93f81f4f3d22587bff1a846e73c3a). Using `Box` in the Rust version is kind of cheating. I'm working on replacing it with a raw pointer in the spirit of C, but it's slow going. Getting rid of the slice would also be nice, but would require implementing `Index` and `IndexMut` and I don't think I'm that ambitious.
If you control all of the source streams, you could build them using an external implementation of streams which supports select. For example, with [chan](https://crates.io/crates/chan), you can `chan_select!()` and wait on any number of multiple streams with different code paths for each result. I'm not sure what the performance aspect of this would be vs. separate mpsc streams &amp; and condvar, but there shouldn't be too much difference.
I've got a variable-length `BufReader` clone in [buf_redux](https://crates.io/crates/buf_redux), let me know if that fits your needs.
I would argue that not even then can you "fool" the compiler. When you use `unsafe`, the compiler *assumes* that none of your pointers are dangling, and if they are, then the program is not defined, and it's entirely your fault.
This is very cool! I'm going to keep my eye on how this develops
Alright guys, we gotta upvote this. This could easily become an unofficial standard. Let's do it!
To be fair, much of this is python providing a friendly interface to fast scientific code written in lower level languages (numpy, scipy, opencv, tensorflow/theano, pytorch, etc.. ). It's really easy to quickly parse a data file, which scripting languages are good at, and munge the output however you want. Plus the code doesn't have to be robust, it just has to work well enough to get results. I'm happy to let python do that glue work, but I'd be happier with those lower level libraries written in rust instead of C++. 
I find it useful sometimes in rust to take a step back and look at other popular languages for these types of things. As I frantically try to avoid all copying and dynamic dispatch, I remember that I used to write a lot of C# in my free time, where I woudn't have batted an eye at everything being heap allocated and dynamically dispatched. The change in perspective makes it so that the `Box&lt;T&gt;`, and `.clone()`'s don't seem so bad anymore, and if the make the code easier to read and understand, then they might even be worth it. Even in another high-performance langauge (C++), `shared_ptr` is common, and considered to be "best practices" in some cases. This makes it so that putting something in an `Rc` more palatable.
Awesome find! Do you think this could be a fairly mechanical transformation of a codebase? It would be interesting to see how it affects compile times of other projects.
While I agree with you on the fact that dynamic dispatch isn't as bad as people here think it is - I strongly against choosing developer comfort over real-life performance. That's how we ended up with JSON everywhere. 
The functionality appears to be perfect for my use case. Making it fit where I had previously used `trait BufRead` took some doing, but I got it all in there.
Yeah, the actual change is very simple. You could probably write something to automatically change impl traits to box traits. It just involves putting Box::new() around the value that is returned and doing a find+replace for the return types
If that is the reason you're just looking for excuses to not make an effort.
Yup. I'm sure is relatively cheap unless you chaining tons of boxed futures together.
So from looking around, it sounds like this is a spin on the stdx/platform idea with the differences being that it is focused on a single topic and tries to do some API bridging? When I saw that `ergo` was for ergonomics, it made me think of another project, [`easy_strings`](https://github.com/Storyyeller/easy_strings) and a [comment advocating for `Box` and friends on another thread](https://www.reddit.com/r/rust/comments/7v4kfj/impl_trait_vs_boxtrait_or_how_i_learned_to_stop/dtphtjo/?st=jd8d5enh&amp;sh=abc2c2a2) Might be out of scope for you all to take on, but I think it'd be valuable to have a coherent ecosystem of crates that prioritize usability over performance. This doesn't just mean discoverability but designing a simple API independent of the building blocks you use. Some examples of what this would mean for an API - Don't expose implementation details to the user - e.g. `Arc` in `ergo_fs::PathArc` would be an implementation detail - e.g. `ergo_fs`'s docs focus on what the type does over `stdlib` rather than help the user know when to use it (like error messages) - Coherent / consistent api - e.g. `ergo_fs::WalkDir` would natively use `ergo_fs` types - Avoid cognitive load on users by limiting the number of concepts you expose, and guiding the user via docs and type names. - e.g. The number of `Path` types introduced in the front page of the docs feels overwhelming - Interop with `std` for working with other crates or for inner loops I think a worth goal to have is "can we be as easy or easier than python?". How much can we reach that goal with just library support? What kind of docs and language initiatives would we need to support these "non-zero-cost abstractions"?
Thanks, but you accidentally used the LLVM tracker URL for both links. 
I'm unsure what, specifically, you're asking for an example of. Clarify, please?
If it helps, my main use for Rust is replacing Python in "small scripts" because Rust programs start much more quickly than Python scripts and a strong type system is worth a million unit tests. (Literally, if you think about combinatorial complexity.) While I haven't had time to update it to use `failure` rather than `error-chain` yet, you might want to take a look at this boilerplate I put together as a starting point for writing the kinds of tools I used to write in Python: https://github.com/ssokolow/rust-cli-boilerplate
Ephemeral typing? I have not yet encountered that terminology anywhere in the Rust community, maybe I'm not looking in the right places. Do you mean affine types?
No worries, I wasn't sure whether it was honest or sarcastic either when I first saw this. I always have trouble reading error messages like these. Usually it's the part that says "so that types are compatible". Which types? In this case, I actually can't figure it out. In the first case, are the types in question 1. the type of the return value, and 2. the return type of the function? In the second case, I have no idea... do I need more context than just what is in the error message?
shared_ptr is also Sync
Unless it's performance is mission critical, developer comfort translates to quicker development time, which is probably more important than eeking out even more performance. It really depends on the project, but I'd default to developer comfort.
It was still running in a tmux session on a dev server? Were you running it in debug mode, without compiler optimizations, like with "cargo run" or "cargo build" ? It would be so funny if you were impressed by the performance of a debug build, which I think is totally possible.
Actual measurements are king, of course. But it's also possible that reductions in binary size led to a big win in performance thanks to reduced instruction cache pressure.
Yeah, as somebody who is schooling myself in type theory, I have not really come across this language. Maybe they are talking about phantom types, or using type-level proofs that are erased at runtime. Not sure though.
Unfortunately, developer comfort is also why we have things like electron everywhere...
As u/PizzaRollExoert allures, the alternatives explored by the scientific communities are MATLAB, Fortran, R, etc. Of these, only Python has a community practice of automated testing. So yes Python can be shonky but just think of all the MATLAB code that has been used to produce results and that it almost certainly had less than 10% coverage. We can do better but Python is Ok!
Is it a particular portion of your crate that is recompiling? It may be useful to turn some of your modules into crates to avoid some of the recompilation.
&gt; I woudn't put yourself down for not being a "true" programmer (whatever that means). Imposter syndrome is a real phenomenon that we need to combat. Programming is for almost everyone like reading and writing.
Not exactly, the ref-counts are atomic but modifying the pointer is not, so there is proposal for atomic_shards_ptr for C++20
The real problem is the compile times being too slow, not `impl Trait` specifically. I wish I could help improve compile times, hopefully this Autumn :)
What I meant to say is that shared_ptr is atomic, thus even more expensive than Rc is. I guess the atomic_shards_ptr would be like AtomicPtr or an AtomicCell?
I don't like language wars, but I cannot understand why people love Scala.
Yeah, I can imagine a feature in Cargo where, when one invokes `cargo foo`, it searches for `cargo-foo` not only in `PATH`, but among the binaries of the packages from the crate's dependency graph as well.
It's specifically the tests that take forever to compile. The crate itself is not big enough to warrant splitting.
File a bug?
I think they're just giving borrow checking a name that makes sense for them. I've certainly not heard the name before... 
I'll also be spending most of the day in the Rust devroom 
In OPs case it's maybe true. I just think it shouldn't be rule of thumb. I'm just have very strong opinions about json in web and I believe we're where we're because of too many people thinking that way.
I can't live without [alias] c = "check" br = "build --release" rr = "run --release" in my `~/.cargo/config`
Jesus, do the comments on that go south quick.
My vote is for [RON](https://crates.io/crates/ron) instead of toml. Apart from that, I wholeheartedly welcome this initiative. With an 'ergonomics first / batteries included' approach like this, Rust could rival python for writing small commandline tools.
What's so bad about JSON? I thinks it's a good balance between human readable and fast parseable. In most cases like api-requests the network latency overshadows the parsing time anyways.
Yes. There are no simple principles to be followed blindly which lead to the sweet spot (developer convenience, decent performance, maintainable code). Premature monomorphism is a real thing (as C++ people have discovered) and yet it remains a most important part of our toolbox. Electron is a bit of an extreme case, where developer convenience leads to a terrible waste of end-user resources, and I'm sure we can do better than that.
For those wondering, the lambda's don't evaluate until the print statement, and so they use the last value of i, which is 2. To fix this you can use partialeq or use default values in your lambda.
&gt; ining tons of boxed futures because all other alternatives suck even more than electron.
That may be en explanation of the issue they were solving, it's not an explanation of the solution they picked. 
Also cython
https://doc.akka.io/docs/akka-http/current/implications-of-streaming-http-entity.html Having to call `discardEntityBytes` everytime I do not want to read response from server, puts akka on C level in my eyes.
Isn't that a logical property of closing over mutable references, and ubiquitous amongst boxed langages?
In Scala in particular, the things that make it slow are also the things that make it fun. I learned the hard way that `Option[T]` should never be used for more than a few objects.
I'm not using cargo install, so I don't know about that. For packaging I'm using NSIS for Windows, Flatpak for Linux and a zipped .app folder for mac.
I really liked Scala, when I started using it. Coming from C++ and Python background (and having seen Java before) it was really something good and fresh. Ease of passing functions around and operation on collections (map/filter/fold), which can be chained, made code much easier to write and read than in C++ and even Python. Compared to Java, Scala was much more concise and less tedious. But, then I discovered this wart https://doc.akka.io/docs/akka-http/current/implications-of-streaming-http-entity.html, which put Scala on par with C regarding management of resources. I also encountered implicits, which are creations of some nuts person probably. And not to mention sbt, when I wanted to create new project and configure it. I also dislike, that some language constructs can be used in like 1000 ways (think trait, you read `trait X` and do not know whether it is interface, type class, mixin or what). Also Scala is in some way comparable to C++. It is so big language, that you really need to have some style book in place, otherwise every developed who comes to your team would do something different and only thing you will see, would be disagreements. TLDR: I understand, why people like to use Scala, it is not a bad language to program in (when you get over implicits and traits).
&gt;(See, for example, the constructors exposed by the API for Python's LXML.) 
It's Slashdot, so what did you expect?
Nice find, but next time please link the original source (which would be graydon's twitter thread) instead. Thank you.
I've never understood the appeal of slashdot ... but then I barely understand the appeal of Reddit.
My expectations of humanity have a remarkable capacity to outpace the performance of it.
[criterion](https://github.com/japaric/criterion.rs)?
Looks nice. But can it be used to play microtonal music, like [med](https://github.com/suhr/med)?
TBH, the C code ain't good -- even ignoring what was noted by the author. I hope they never wrote "real" production C. Probably only ever touched the C-ish subset of some ancient C++ standard and doesn't know that C++ and C are quite different.
Thanks for stating the obvious. What a dreadfully dull conversation. 
Stable Rust only does x86 at the moment. They‚Äôre working on cross compiling and features line inline assembly, but at the moment you need to use unstable and hope that someone has written the platform support for your device (not sure whether that has been done since it‚Äôs not really my field of work)
Ahh. No, I mean the constructors for the Python API which rely on default values and named arguments to remain usable. Stuff like this: tostring(element_or_tree, encoding=None, method="xml", xml_declaration=None, pretty_print=False, with_tail=True, standalone=None, doctype=None, exclusive=False, with_comments=True, inclusive_ns_prefixes=None) 
Spare a thought for those using #[no_std].
"One Twitter user then asked him if Rust was about dragging C++ hackers halfway to machine learning" - actually one twitter used asked about dragging toward ML (as ML language, like OCaml). They even did not get this right :/
Is it a bug? I don't know much about rust, but I guessed that impl Trait generates code at compile time, while Box doesn't and relies on dynamic resolution. It could be improved, but I wonder by how much.
Unfortunately, release 0.1.2 still sometimes crashes, however this is fixed in git master.
I don't know what the code in question does, but 14 minutes for a small crate test is a long time, so it may be a good benchmark for speeding up compilation of impl trait. The feature is quite new and hasn't been thoroughly tested. So there may e.g. lurk some accidentally quadratic behavior.
Yup, `unwrap` is safe. It's just not *reliable*, in the sense that your program usually doesn't survive the call.
Stable rust does a whole lot more than x86
&gt;What's so bad about JSON? I thinks it's a good balance between human readable and fast parseable. In most cases like api-requests the network latency overshadows the parsing time anyways. You are presuming you know what the use case is there's plenty of time it's worth improving it.
I have, but not for anything near the same meaning ‚Äì in C++ "ephemeral type" is commonly used to refer to the type of an anonymous value, e.g. a lambda expression or the result of an expression template.
Anecdote: I've been working on a small console program to process log files, as a learning exercise. For reasons, the standard `lines()` iterator wouldn't work, so I hand-rolled some code which allocated a vector used `read_until` to fill it processed the line cleared the vec loop until done Note that this code only allocated 1 vector. Problem was, I had to duplicate the loop code in several places, so I decided to make my own custom Iterator for this type of file. At that point I had some problems with lifetimes trying to return a slice to the Vec that the iterator owned. Couldn't get it to work, so I gave up and simply allocated a new Vec for each line and returned that. (Working on the principle of getting something working first, optimise later). Amazingly, the version that allocates a new Vec for each line is only 1% slower than the version that allocates only a single Vec. I then went off and checked the source code for the builtin `lines()` iterator and it does exactly the same, though it allocates a new String each time. It's almost as if jemalloc was using some sort of cache to speed things up. Anyway, it's very impressive.
`impl Trait` doesn't generate extra code, generally speaking it lets you use types that couldn't otherwise be named. The drastic difference in compile time is definitely a bug.
&gt; It stands for "Millimeter" and "Point" (1/72 of an inch) I was thinking it was Millimeter, Pt for some reason didn't click though :) Thanks for that.
For real - I've written a couple of WPF apps recently, and I'll gladly ship the Chrome engine 100 times before I go back to that again.
Lol, of course, right? It's often good enough to not implement allocation reuse, since the allocator already implements that and tries its best to do that for you. The exception would be arena-like cases(?).
`impl Trait` allows writing code that is a lot more complex, with more types to type check, more generic code to instantiate and less reuse. It's not a surprise that it takes longer to compile.
For GNOME - `gtk-rs`. For everything else - none.
Link to gfx-rs [talk slides](https://github.com/kvark/slides/raw/master/GFX_PortableGraphicsAbstraction_Fosdem2018.pdf)
It's not a bug, its the result of how heavily the ecosystem relies on generics, causing most of the code in your libraries to be monomorphized every time you recompile, instead of being compiled once the first time you depend on your libraries. Its the obvious and inevitable consequence of acting like heap allocation and dynamic dispatch must be avoided at all costs and not balancing the real trade offs involved.
I'd also love to have a IPFS node in rust. That'd be really awesome for my next project idea.
That depends on how you define things. There *are* three other options depending on how you define "create a GUI for a Rust project": * Make a web UI * Use something like [conrod](https://github.com/PistonDevelopers/conrod) which produces a *non-native* GUI. * Bring in another language to act as glue. (I've been using [rust-cpython](https://github.com/dgrunwald/rust-cpython) with PyQt in one of my projects and it's quite comfortable.)
There are two problems. First, cargo uses git for crate publishing, and git has weak support for partial checkouts. Second, there are projects where non-source files are essential (precompiled dependencies, resources of some kind), and any kind of filtering would prevent publishing some of them.
At some point people will realize that the constant security bugs that happen due to the language not making them impossible are not acceptable. If you think you can be more productive by using C then by all means go for it as long as you use it in a manner that security does not matter. But when you talk about operating system components, anything that runs as root on an internet-connected device, should be running safe code.
See this internals [topic](https://internals.rust-lang.org/t/idea-on-movable-self-referential-structs/6694).
I don't think people writing a chat bot are ever going to use no_std, who'd want to do something high level like that without collections and strings
I think all of this stuff should be explicitly imported.
The problem with all of this approaches is they are immature (almost alpha).
I can't get past the pointless bomb throwing. The same problem exists on here, but it at least seems to be somewhat limited to echo chambers. That said, this morning I was told of my "retardation" [sic] and told to "eat bleach" on what I thought was an extremely minor point about tax jurisdictions. The quality of human discourse seems to have changed somewhat since, I dunno, roughly November, 2016 ... wonder what that's all about?
For sure for this particular use case, but there are a lot of useful libraries out there already that could, with a little bit of tweaking, work under #[no_std] but don't.
[removed]
There is [rocket.rs](https://rocket.rs/) that is absolutely production ready but needs rust nightly. Depending on your need there are also good alternatives (see [rust-web-framework-comparison](https://github.com/flosse/rust-web-framework-comparison)). E.g. you could directly use [hyper.rs](https://hyper.rs/).
I have looked at Lilypond! It's absolutely excellent at typesetting music, as you say. But although you can generate MIDI from it, the language itself I feel has readability issues. I feel the same about ABC notation - both have a focus on producing scores, which is great, but I wanted something solely focused on producing MIDI.
..warming up to Rust? nope,the comment of "I 'm also terrified...by Rust" terrified me. :)
I used to dump them in Elasticsearch as JSON documents and use Kibana to graph / monitor the results :)
&gt; [I‚Äôm] strongly against choosing developer comfort over real-life performance I hate to be flippant, but why not write in assembly, then? Rust is about finding the right balance of performance, developer ergonomics, and safety. It‚Äôs not about optimizing for one to the disproportionate detriment of others. 
A mixture of programmingcirclejerk and youtube comments, which is exactly what it delivered. I am satisfied.
i'm sure many use cases can tolerate the dynamic dispatch; coming from a gamedev background however I've seen horrific scenarios. it really does depend what you're doing. I've wondered if (given a safe project) Rust could be compiled during development/testing in a different way that just works semantically equivalently, i.e. turning a lot of the inlining/monomorphising *into* dynamic dispatch transparently. I think you could defeat such an idea with unsafe code though so you might need to have a load of alternate cfg implementations for that
Whats stopping it is bugs in the llvm backend causing libcore to not build for avr. The last comment on it was 18 days ago, so I'll say it's being worked on. https://github.com/rust-lang/rust/issues/44052
You can use references multiple times, so they're not necessarily affine. `&amp;mut` is `!Copy` but there's reborrow magic that sometimes makes it look that way. "Ephemeral" is new terminology; nobody else uses it yet. I'm talking about the `'a` in `MutexGuard&lt;'a&gt;. It means the compiler pays attention to *when* the `MutexGuard` can be used and whether it is allowed to escape a particular function. This limit isn't "as long as the Mutex hasn't been freed", nor "until it is dropped" - those are constraints that the compiler satisfies; they don't simply define the lifetime. On Stable the lifetime will be a particular scope. NLL looks at how the control flow gets from acquiring the MutexGuard to any other conflict (dropping it, dropping the Mutex, calling another method of the Mutex via the same variable, anything that would invalidate a reference within the Mutex, etc.) - as long as that control flow is within one function. The `'a` parameter means that the lifetime solver must do something to decide over what region of the flow control graph `Mutex::lock` borrows `self`; the resulting `MutexGuard` may not escape that region. So it is an ephemeral value. 
Either you are looking for /r/playrust or you should pronounce 'play' as 'code'. This subreddit is about the Rust programming language, not the game.
I'm much more comfortable with Rust than any language you listed.
[removed]
This wouldn't make it any harder to abuse, only more annoying to use normally.
&gt; New Rustdoc is progressing fast, now supporting almost all DefKinds, pluggable frontends, More powerful testing. The new rustdoc repo is basically dead, with almost zero activity in the last 6 months. One can say that there was little to no progress, or a bit of progress, maybe even some progress. But saying it is progressing fast is IMO borderline dishonest. 
Shouldn't `impl Trait` be as fast as writing out the type?
Related: https://internals.rust-lang.org/t/pre-rfc-automatic-generic-to-dynamic-conversion/6075
Will the talks be uploaded somewhere?
Important nuance. Thanks for pointing that out.
I'm so tired of these comments.
Sorry yes, I should have provided the full Rust gist, I excluded the headers since I wasn't intending on folks to compile the Rust version. Can you clarify what the capacity issue is? The code runs on my machine, but it's possible I avoided the segfault by chance.
Of what exactly?
I've done a little gtk-rs and it works, but I find it quite hard to find the rust specific parts; you're caught between generic gtk docs and then wondering how to deal with rustisms.
I think [here](https://video.fosdem.org/2018/?C=M&amp;O=D).
Yes, everything is recorded. Will be uploaded after the speakers review and annotate their corresponding chunks. I don't have an ETA.
I've been keeping an eye on the `gtk-rs` approach and I don't consider it particularly more mature than using `rust-cpython` to generate a compiled Python module and then importing it like I do with my Rust+PyQt-based solution. Do you know something I don't?
Improving compiler performance is definitely a priority, and this sounds like a good test case if nothing else. That said, the end conclusion might be "this can't be solved until the [trait system rewrite](https://github.com/rust-lang/rust-roadmap/issues/8)".
Improving compiler performance is definitely a priority, and this sounds like a good test case if nothing else. That said, the end conclusion might be "this can't be solved until the [trait system rewrite](https://github.com/rust-lang/rust-roadmap/issues/8)".
Fair enough :-) I did intend it to be slightly ironic. And thanks for the link, interesting reading.
&gt; I've never understood the appeal of slashdot ... A long long time ago (late 90s/early aughts), it was more or less the only non-mailing list source for general-purpose nerdery.
You require a python binding over a C++ library. That's 3 steps. Not very efficient. :-/
&gt; So from looking around, it sounds like this is a spin on the stdx/platform idea with the differences being that it is focused on a single topic and tries to do some API bridging? Other major differences inlude: - We hope to be a team of people instead of a single individual - We are split up into multiple sub-crates. `ergo_fs` is _just for filesystems`, `ergo_sync` is _just for threading/synchronization_, etc. This avoids the "kitchen sink" problem where it becomes difficult to determine if a crate belongs But yes, it is (currently) targeted towards a single use case. &gt; When I saw that ergo was for ergonomics, it made me think of another project, easy_strings and a comment advocating for Box and friends on another thread This is exactly the kind of ideas/discussion we need. Please open any issues you think we should consider! &gt; Don't expose implementation details to the user Hmm, that is _definitely_ the goal. I'm wondering in what way `Arc` was exposed to the user? Do you mean it is exposed because of the name `PathArc`? In general I have tried to keep implementation details out of the picture. &gt; e.g. ergo_fs::WalkDir would natively use ergo_fs types Haha, I tried this! It is possible but kind of annoying (as you have to wrap _every_ type). Instead I made `PathType::from_entry` which is (I think) a decent bridge. Very open to feedback/PR on this topic (and any other!). &gt; Avoid cognitive load on users by limiting the number of concepts you expose, and guiding the user via docs and type names. The docs could definitely be improved, and I am planning on getting started on the Ergo Cookbook sometime next week. &gt; Interop with std for working with other crates or for inner loops I'm not sure what you mean by this. Thanks for the feedback. The goal is indeed to be "easier than python" -- we should put that somewhere in the design goals!
As per [the Rust Forge](https://forge.rust-lang.org/platform-support.html), all Tier 1 platforms are x86
Thats not what you said. Tier 2 are also supported by stable and official builds are provided, with automatic building building set up. A lot of those platforms also support rustc and cargo, so you can build on the platform itself without cross compiling. And no, you dont need to "hope that someone has written the platform support for your device". Setting up a custom target is like 10 lines of JSON so you can build for a bunch of things that arent even tier 3 supported (I'm building for aarch64-none-eabihf myself)
It would be cool if something like https://perf.rust-lang.org would be usable for all rust projects.
&gt; You know json is not only slower to parse Slower than what?
My pre-RFC about this: https://internals.rust-lang.org/t/pre-rfc-automatic-generic-to-dynamic-conversion/6075
I don't think this should be done automatically: It would pretty much prevent any usage of Rust in embedded environment. But there could be attribute to allow it or something.
&gt; Is there a maximum crate size? Yes.
The performance drop in using a language like Python or Ruby is **way** higher than the performance drop from boxing up futures all over the place.
Remember when I mentioned on urlo that I had ideas along these lines? My idea was, search in `PATH` as well as `.`; but again, your way sounds better.
interesting, so you also imaging making it selectable.. i can see that being useful too. what i had in mind was a global override.
I think the choice between dynamic dispatch and monomorphisation should always be explicit, as it can potentially have a significant impact on performance.
I don't do anything fancy. I just [store the raw output in the repository](https://github.com/rust-lang/regex/tree/master/bench/log) and then use [`cargo benchcmp`](https://github.com/BurntSushi/cargo-benchcmp) to compare them when I need to.
&gt;We should RFC this. Would you mind championing the effort? I'll be glad to help, but my primary focus nowadays is libsyntax 2.0, which already is a yak shave :-) In other words, I am to lazy to draft the text, but I am always ready to scrutinize writings of someone else! :) 
So does inlining. The problem is, the impact on performance can be positive or negative and it's not always obvious why. For example, dynamic dispatch can be faster due to less pressure on the instruction cache. At least with inlining, compilers are better equipped at taking this decision. I could imagine that this decision is similar.
[Huh](https://github.com/steveklabnik/rustdoc/compare/e7e2c22abfd77836973a0a026cd9d600e3f66dcf...master)..?
The community code of conduct expects that people be treated with respect. When someone reduces this expectation to the caricature ‚ÄúSocial Justice Warrior‚Äù, they are vice-signaling to others that they believe there are classes of people who are not worthy of respect. 
That's why knowledgeable JS devs exclusively use the strict equality operator. Yes, that one is bad language design, but only because unlike in other languages we can't break backwards compatibility.
No less efficient than writing any other Python application which imports both a GUI (Qt, GTK+, etc.) and some other compiled module. Heck, it's more efficient than using numpy since all of the hot code paths stay inside the Rust portion.
FWIW this is what swift does (more or less).
This follows on from my #rust2018 blog post that I posted here last week. The project now has a name and a web site where I'm showing some example code and initial performance data (much more to come on that soon).
When I started writing WPF/XAML I was like "wow! It's like someone designed HTML from scratch as an application development platform, this is great!" Then, over time, you notice the little holes, and common pitfalls, and missing functionality, and realize that MS gave up on this platform and didn't bother to finish it. Here's hoping they actually see this UWP thing through, for once.
I'll see what I can do. Count me in.
&gt; Rust‚Äôs trait objects...can pose safety issues due to their interactions with lifetimes The authors only mention this once at the end, anybody know any more about what they're talking about?
Many people suggest that the Code of Conduct and the general attitude of the official Rust team are coddling minorities and women, which then implies that everybody using Rust is somehow an SJW. I somewhat see where they're coming from, as I feel most people don't actually care who made code as long as it's well made, and there's the potential for a loss in quality by enforcing SJW-like thought processes (the regressive notion that something is better simply because of diversity, rather than the diversity potentially spurring actions that result in a better outcome). That all said, the only place where the Rust team can really enforce the CoC is on official channels, and so long as they continue to only enforce it based on the activity in those channels there's really nothing too different about it from any other community. If people can't put on their adult pants long enough to make use of the official channels and be excellent to each other then that's their problem. If someone wants to have /r/assholerust and advertise it as a Rust community that doesn't enforce the CoC, they should still be allowed to post here as long as they're following the rules while they're here. tl;dr - Some people think the Code of Conduct means Rust is infested with SJW-ism, and others hear people complain about Rust's supposed SJW-isms and take it as gospel.
For those curious about the cause of this, this is actually a compiler bug (tracked in [#38528](https://github.com/rust-lang/rust/issues/38528)). Specifically, when you have deeply nested types (which you get, for example, by having functions that return an `impl Trait` call other functions that return `impl Trait`), the compile time increases nonlinearly! This should *not* be the case. So while it's true that Rust programmers often have an irrational fear of dynamic dispatch, this should not be one of the motivations for `Box`ing everything :)
Here is the link to the start of the Twitter conversation https://twitter.com/timClicks/status/958267304638169088
The biggest reason that I personally avoid Box&lt;Trait&gt; usually is that you can't make it generic over marker traits...especially `Send`. Often times with futures, you end up with something like `MyFuture&lt;T&gt;` where `T` is an inner future and `MyFuture` is `Send` when `T: Send`. If I go from `MyFuture&lt;T&gt;` -&gt; `Box&lt;Future&lt;...&gt;&gt;` I have to commit to either always `Send` or never `Send`. This matters a lot when working on libraries.
[Qt GUI with Rust slides and demo code](https://fosdem.org/2018/schedule/event/rust_qt_binding_generator/) The organization went very smooth. Beamer worked on first try and great questions afterwards. Video should be online in a few days. 
[Qt GUI with Rust slides and demo code](https://fosdem.org/2018/schedule/event/rust_qt_binding_generator/) The organization went very smooth. Beamer worked on first try and great questions afterwards. Video should be online in a few days. 
Nice catch. Thanks!
[This Stack Overflow Q&amp;A](https://stackoverflow.com/questions/19650265/is-there-a-faster-shorter-way-to-initialize-variables-in-a-rust-struct) explains the Builder trait quite well, though I'm not sure that it applies well to your use case. Having a lot of functions with a lot of default values is probably a code smell, but scanning the rest of this thread it looks like you sorted that out. :)
I can‚Äôt find a single programming job where anyone actually does half decent unit testing. Managers consider it a waste of time, and then wonder why every project becomes an unmaintainable trash fire.
`impl Trait` is new syntax in nightly. Compare these two function signatures: fn foo&lt;T: Trait&gt;(arg: T) {...} fn foo(arg: impl Trait) {...} Using `Box&lt;Trait&gt;` (or any pointer to a trait) switches from static to dynamic dispatch. [Here's](https://stackoverflow.com/questions/27567849/what-makes-something-a-trait-object#27570064) a great SO post about trait objects that you might find useful.
My first blog post about Rust. Aimed at beginners, and those who want to have a play with macros. Please give feedback!
This looks somewhat like what I had in mind. Do you have a system so you can know what benchmark corresponds to what code/commit/setting? Or do you just name them correctly and hope for the best?
No worries. Best wishes!
I know. But it shouldn't crash and restart all the time. Seems there are too many unwraps in the code base.
LLVM can monomorphize trait objects when they're used, er, monomorphically, at least in simple situations. For example, compare the assembly generated for `run_something_noinline` and `run_something_noinline_polymorphic` in this [playground](https://play.rust-lang.org/?gist=a924565f6cc98a971009bf89393b997b&amp;version=nightly&amp;mode=release).
That, and Rust is actually the much more comfortable language (compared to Python and probably Ruby) as far as I am concerned. Not having to worry about calling functions with the wrong number of arguments, or data of the wrong type, is a huge boost in developer comfort. YMMV.
It starts with you. You‚Äôre a professional. It‚Äôs on you as a developer to ensure your code works as expected, and automated tests are one way to do that. Your manager doesn‚Äôt need to know or care. Just do it as a normal part of your daily routine. 
Part of developer comfort means being comfortable with changing things without fear of it breaking, and rust is unparalleled there. Also, &gt;If you want performance and developer comfort doesn't matter then you are using the wrong language. &gt; &gt;Use assembly instead. 
this would be totally awesome
Rust Qt Binding Generator gives you access to Qt / QML. You write the GUI in Qt or QML and the logic in Rust. The communication between Qt and Rust is generated for you. [Slides, video and links](https://fosdem.org/2018/schedule/event/rust_qt_binding_generator/)
Not really. Automatic boxing would prevent usage in embedded environments, but a `f(t: &amp;Trait)` doesn't imply any boxing. The concrete values implementing `Trait` could well be allocated on stack.
I pretty much just hope for the best. If I were to track more things, I would probably just add a README to each dir saying which commit was being benchmarked and the Rust version.
Personaly I use "native tools", C++ Qt on Linux and Java on Android. And automaticaly generate bindgins for these languages to my library in Rust language.
Trotting out Electron is a red herring and a false dichotomy. It would be nice if one could use PGO to decide when to switch from dynamic dispatch to monomorphized code and do so automatically.
Cool. I won't say that I'm gonna do it right now, but I'm happy to work up a draft an dcc you on it :)
[removed]
Not just testing, of any kind, but in rigorous design. We need to be running simulations and using formal methods in the construction of our large systems, yet at the largest most professional companies it is still, "be extra careful".
I actually found out about the September 11 attacks on Slashdot. At first I mistook the post talking about the World Trade Center towers being gone as a poorly-written book review. The fact that I could do so makes me think Slashdot was always a little weirdly shitty, but yeah, it's apparently a cesspool now.
&gt;tax jurisdictions There's your problem. On Reddit we are all sovereign citizens and no authority can place us into arbitrary jurisdictions for theft. And suggesting such is rightly punishable by suicide via imbibing bleach. I think I'm getting the hang of Reddit now.
also "serialzed"
You are thinking of the former CEO, Brendan Eich, but in actual fact he quit. The constant claims by alt-right brogrammers that he was fired has apparently taken root, though.
This is a cool little project. It kinda reminds of qb64, just that you don't compile it down into an executable.
You can definitely opt into this! I've been adding a line like this to all of my library `Cargo.toml`s for a while which will exclude any files not mentioned: include = ["Cargo.toml", "src/**/*", "tests/**/*", "examples/**/*", "LICENSE", "README.md", "CONTRIBUTING.md", "CHANGELOG.md"]
One of the biggest irks for me about Spark/Hadoop/HDFS is deployment. I am really interested in hearing about how the code is pushed to nodes and then how nodes decide which data to process. Also, is this a fairly generic map/reduce implementation? Is it possible to define workers outside of the core app that speak stein/stdout, such that Python/R/etc workers can be deployed easily? 
Doesn't seem like this like is posted https://www.youtube.com/watch?v=Y9vemQmVeLI
Awesome, thanks! I've see that link before but had since lost it. My background is in build tools/automation, rpm packaging, Java rest stuff and I'm at ch 13 of TRPM. I skimmed that list and interested in rustfmt, bindgen, and rust language server + vscode support. The cookbook would help with my noob understanding of the syntax. The organization here is very helpful! I'll search a bit deeper on those projects and work an issue :D
That's best-practices for C++; mutation across threads should always occur under some sort of memory control; two separate threads that have access to the same shared_ptr (not the same as the same object being referred to by multiple shared_ptrs!) need to coordinate access to that value. Solving this problem is way out of scope for shared_ptr.
And yet somehow, lots of C++ programs end up slow, and "hand tuned assembly" ends up blazing fast.
&gt;Many people suggest ... It's always 'Many', yet they all troll the same, so for all we know it could be one and the same guy in his mom's basement. &gt; that the Code of Conduct and the general attitude of the official Rust team are coddling minorities and women... As opposed to coddling privileged jerks, as much of our field apparently does? &gt; I somewhat see where they're coming from, as I feel most people don't actually care who made code as long as it's well made... On the other hand, many Rustaceans I know see the CoC as a net win and would not want to be in a community that doesn't uphold at least most of its values. &gt; there's the potential for a loss in quality by enforcing SJW-like thought processes (...) Yet the Rust community continues to deliver high-quality code in a pace never seen before in systems programming. If there is a loss of quality, *something* certainly made up for it. Rust is an open source project. Why don't the trolls just put their money where their mouth is, fork Rust and name it some expletive and release a better language? I'd wager it's because they aren't competent to pull it off.
Even though he was officially fired to many he was forced to quit which is often viewed in a similar way. Article about it: https://www.forbes.com/sites/quora/2014/04/11/did-mozilla-ceo-brendan-eich-deserve-to-be-removed-from-his-position-due-to-his-support-for-proposition-8/#5e95d4f02158. Specifically for the phrase ‚ÄúHe came under pressure to resign and he did.‚Äù Is what I‚Äôm referring to. So whether it is the alt-right or alt-left or whoever many see being pressured to resigned then resigning as the same as being fired. Specially when talking about CEOs. You may have a different view and that is OK, just wanted to clarify my previous comment to others who may not know about the situation.
Surely it's better than most code I get from my students -- but this is no student submission but a blog post people should learn from. And things like that, imho, should at least go through codereview.stackexchange.com. Next to the changes you made, I'd also change use (of course that code is wrong anyway, but now it's wrong but neater) compound initializers: Vec* vec_new() { Vec vec = { .data = NULL, .length = 0, .capacity = 0, }; return &amp;vec; } I'd try check for overflows in the `new_capacity` calculation of course, or just use `calloc()`/`realloc()`, and not cast the return value, but that is to be argued about. `void main()` is no legal main function by the standard (or, at least, implementation-defined). The return type must be `int`. Also this way the declaration of main and `vec_new()` don't provide prototypes saying that it cannot have no parameters; to create a prototype the "correct" code would be: int main(void) {} Vec *vec_new(void) {} ie. no empty parameter-list, otherwise one could call vec_new("whatever I want", "and how much I want"); and it'd be legal, compiler-wise. But the `void main()` really enraged me as I get more and more submissions by students completely messing up `main()`! Also the empty-parameter-list problem is spreading over due to many C++ programmers thinking that C is just a subset of C++ and carrying-over C++ stuff that's wrong or bad in C.
&gt; I enjoy programming from time to time, Then you're a programmer, even if that's not your profession :)
Thats what I'm planing to do.
Cool- just wanted to make sure you knew about this option.
That's pragmatic advice, but still very sad that it's required. At many jobs you're being incentivized to cut corners and that is demoralizing. It's also demoralizing if you're the only one doing it and other developers disable or delete your tests when they fail. That lowering of morale may be common, but it is still lamentable.
Wait. ... WHAT?!
I think Reddit was generally better in the past. Especially subs like /r/programming and /r/technology. 
I think only the crates.io index is hosted via git, the actual crate sources aren't.
[Here](https://www.youtube.com/watch?v=JctBMLQ_IdA&amp;list=PL_QKjHDgmNzpckLNciogFQ79csbL4JtzN) is a YouTuve playlist
This disclaimer was limited to the intended errors. Things like `void main()` should not happen in an example code. If you want to compare (case study) C with Rust any sane reader assumes a reasonable comparison, ie. between *standard* and *modern* C with Rust. I wouldn't drag out an old rust language spec to show how overly complicated "Rust" is.
Perhaps this is about object safety? https://huonw.github.io/blog/2015/01/object-safety/
Can you describe what you're looking for in more detail?
Thank you for the feedback! Whether to name it shrinkwrap or shrinkwraprs is something I spent an embarrassingly long time agonizing about, and to be honest I'm still not sure. For now, I'm enamored enough with the pun with "shrinkwrappers" that I'll probably stick with this :) But for sure, I'll keep it in mind!
I think you forgetting that that poor iphone or android device is not powered by multicore xeon plugged into power outlet. And all 250k rpm is going to those devices. Devices on spotty LTE or worse network. Networks where every kilobyte counts. I bet you forgot about that part? 
The buggy one. The only reason I brought it up is that from your post one might expect you would get an array bounds error when you tried to reference element 0 of a 0-length slice. Instead, you'll get a mysterious segfault at implementation time. This is arguably a bug in the Rust runtime, actually. Even unsafe code should be throwing an exception rather than calling `mallocx()` with an illegal value. Should probably report it.
I think this is an ideal case for wasm.
First of all, because the assembly is the program that turns assembly language into machine codes. Real question why not program machine codes? Here is why - I doubt either of us can write code in any assembly language available that will perform as good as rust (or even ruby). And because after you ship - you start working on an update in the same code base. While with wire encoding you don't care what is on a wire after you done debugging your schemaless mess.
It'd make sense for it to be object safety but I guess we could only be sure by asking the authors. I'd guess that if they found something new they'd likely be publishing it in the future along with their work in expanding the scope of their Rust/Coq stuff
Deceptively, object safety isn't a memory safety concern.
Good catch on the missing `void` in the argument list for `vec_new()`. I missed that one. I think using named structure members is arguable. You use it if you're sure you're in a recent enough ANSI C environment to support it, you don't use it if you want to be able to compile with C89. Without named structure members, you should initialize as the author did, so that you don't screw up the order of the initializations. I had caught the `void main()` thing, but had misremembered that the ANSI standard once allowed it: it never has. The compiler and/or linker (don't remember which) will clean this up for you if you do it, so while it's bad style it's not really a disaster. Since it's not germane to the example given, I probably would clean it up explicitly. All of that said, I still don't think this C code is *too* much of a strawman for what bad C programmers actually write. Neither I nor any of my friends would have made any of the mistakes made here ‚Äî unless we did. Human error is a real thing, and greater skill only decreases probabilities. I like the capacity-zero bug because it's a semi-plausible bug Rust won't catch either, and as it turns out doesn't even handle gracefully. Claiming that using Rust will eliminate all program bugs would be a terrible idea, and it's good to remind everybody of that.
While I expected to get a reply like this, I'm really surprised that such a hostile response came from a mod. It definitely doesn't feel in spirit of sections 3 and 4 of the CoC. &gt; It's always 'Many', yet they all troll the same, so for all we know it could be one and the same guy in his mom's basement. That's a great feel-good response, but it doesn't answer the question I was answering. The perception of SJW's in Rust's community is that "many" people suggest that the CoC is unsavory regardless of their reasoning, and that perception is warped into suggestions that the community is "toxic" or whatever else. &gt; As opposed to coddling privileged jerks, as much of our field apparently does? No. A Code of Conduct should not coddle ***anybody***. It's supposed to be a statement of how anyone should act when involving themself with official parts of the entity the CoC represents. I feel the Rust CoC is rather fair about not excluding anybody. *We are committed to providing a friendly, safe and welcoming environment for all, regardless of gender, sexual orientation, disability, ethnicity, religion, or similar personal characteristic.* By that rule, nobody is allowed to create an unsafe environment for anybody, whether they're a trans disabled woman of color or a straight white cis male or whatever other identity they want to present. It's a good rule and worded well. The whole CoC is. &gt; On the other hand, many Rustaceans I know see the CoC as a net win and would not want to be in a community that doesn't uphold at least most of its values. I'm right there with them. I'd say that in general the CoC is a good thing, at least Rust's implementation of it. &gt; Yet the Rust community continues to deliver high-quality code in a pace never seen before in systems programming. If there is a loss of quality, something certainly made up for it. And I didn't suggest otherwise. I said that employing **regressive** SJW-ism is bad. Regressives will suggest that the uncontrollable traits of a person can make something better or worse. It's equally regressive to assume that a product is better *because* it was written by a woman as it is to assume it is better *because* it was written by a man. A good product is a good product. It's important to be non-exclusionary, as someone with a different viewpoint may see something that would have gone unnoticed otherwise. Non-exclusionary development is a good thing. Weighing someone's opinion because their immutable innate traits isn't.
Maybe but it‚Äôs pretty common in all trades that bad managers cut corners for short-term productivity, even when they know it‚Äôll bite them in the ass in the long-term. It happens in blue-collar jobs all the time, and we shouldn‚Äôt be surprised that software isn‚Äôt that different ‚Äî after all, the incentives are the same: the manager wants to meet their quota/objectives/deadlines. That‚Äôs how they‚Äôre primarily evaluated, and it‚Äôs highly visible in the organization. So they‚Äôll push their workers to go faster faster faster and sacrifice things that aren‚Äôt so visible to higher management.
Thank you so much for the feedback!
Ugh, fucking C
Looks really cool! A bit of a different solution to the same problem is my derive_more crate, which can derive From and Into and a lot of other stdlib traits: https://jeltef.github.io/derive_more/derive_more/
JS? I was thinking more as using wasm as a lingua franca intermediate language running on [wasmi](https://github.com/pepyakin/wasmi) or some jitting implementation that doesn't exist yet.
Who said anything about Android and iOS? The majority of my Rust use cases involving JSON has been for backend services (e.g. log processing). If you want to provide more context about the specific situation you are explaining, I'd be glad to have a discussion with you. 
Well since Rust uses LLVM it's likely that the equivalent of that code in Rust would exhibit UB as well, it's just that Rust doesn't really have a formal specification, so who can tell what is UB and what isn't? ;)
That's great to hear. Good luck!
The API seems to be quite limiting or verbose (not sure). In Spark, I can write almost any reasonable Scala function and have it distributed. It does not seem to apply here right now. 
Cool thanks for the link too 
I know a lot of this has been on your radar for a while :) I think we'll have a great opportunity once the tooling gets closer to where we want it to be (and I think it's worth reminding ourselves every now and again that our tooling around docs is already great) to put it to good use on stable/stabilising crates in the ecosystem.
Wow, I really don't know how to type apparently.
&gt; Who said anything about Android and iOS? The majority of my Rust use cases involving JSON has been for backend services (e.g. log processing). If I see one more log service that wraps messages in JSON... Log/events processing is perfect example when you can't affort wasting space. What I mean is that today, most frequent case for backend is backend for mobile app. There is no befit of using JSON there. I get it that 5 years ago JSON was blazing fast in a browser compared to everything else because parses were not written in javascript and were native. You know what the most underratted HTTP header is - Accept header. If you have well defined structure that can be converted to protobuf, it can be converted to pretty human readble json without any sweat. Make client choose what it wants. &gt; If you want to provide more context about the specific situation you are explaining, I'd be glad to have a discussion with you. Our auto-scale triggered by network-out utilization than CPU or memory. It's pretty easy to eyeball how much of that traffic is just keys for dictionary. You know how others solve this proble? Look at it: [ { "a": 26129, // Aggregate tradeId "p": "0.01633102", // Price "q": "4.70443515", // Quantity "f": 27781, // First tradeId "l": 27781, // Last tradeId "T": 1498793709153, // Timestamp "m": true, // Was the buyer the maker? "M": true // Was the trade the best price match? } ] Some actually just do something like this: [26129, "0.01633102","4.70443515",27781,27781,1498793709153,true,true] You going to tell me with a straight face that this is human readable? Oh, don't forget that browsers can't handle large integers neither, they will truncate number like nothing is wrong. This is more of a browser implementation of json though. 
I don't know that it will ever be feasible for this project to replicate Spark's behavior where closures can be dynamically serialized and sent to worker nodes. The DataFusion approach is for you to put your custom Rust code in a user-defined function i.e. implement the ScalarFunction trait and then deploy your code as a crate dependency. There will be other types of functions supported in the future too i.e. functions that operate on an entire row for map operations as well as aggregate functions. 
I think it's definitely an important part of the picture! I'm also interested to know how you've found the experience of combining the multiple disparate crates together. A big part of making consuming libraries ergonomic is the identification of _interchange types_. Those are types that are common between libraries that can be used to glue them together. Things like `futures::Future`, `http::Request`, `failure::Fail`, `bytes::BytesMut`, `std::path::Path` etc. Have you found the APIs of the underlying crates in `ergo` use consistent interchange types, or is there a lot of translating between similar types?
Everything's pretty immature at the moment, to be honest. If you're OK with non-native, I've heard good things about both [conrod](https://github.com/PistonDevelopers/conrod/) and [orbtk](https://github.com/redox-os/orbtk). I've used conrod: there's a bit of a learning curve to getting the first application set up, but it does have a really nice way of handling state. If you're targeting a specific platform, I would go with: - [native-windows-gui](https://github.com/gabdube/native-windows-gui) for windows - [gtk-rs](http://gtk-rs.org/) for Linux - not sure about mac at the moment, probably want to build GUI in a native language and bind to rust. I haven't used any Qt/QML stuff but that could also work well for a cross-platform native-ish gui. There are a number of other crates and collection posts that have been posted on this subreddit too: https://www.reddit.com/r/rust/search?q=gui+&amp;restrict_sr=on
why isn't it a good idea?
That‚Äôs nothing new just google for it.
Just google it. Movfuscator is a good keyword.
Because IPFS, at least this early, is not as reliable or as fast as something like Github.
What data formats does it support? Is it optimized to work with avro, parquet, gz/bz/xz-ed xsv files ? Also, you may wish to get benchmarks against larger datasets. 50Gb can fit in memory on a 80$/m bare metal server. How well does it do on data volumedls in the hundreds of TBs with high granularity volsand/or very wide rows and/or variable widths row ? How well does it perform when ran on a few dozen machines in parallel ? Did you benchmark against scylladb ? That database is more or less the golden standard for distributed sql queries on distributed data. 
&gt; some jitting implementation that doesn't exist yet. [Cretonne](https://github.com/stoklund/cretonne) is aiming to get there one day
Oh okay. So wasm as machine-independent byte code
ok, but assuming 5 years in the future ipfs or alternative are stable, then it would be a good idea?
The Rust team strongly disagrees with this viewpoint. One of the primary goals of Rust is to make performance available without straining developers.
I didn't mean to imply you were responding as a mod, just that I expect the mods to be the example regardless. I also didn't mean to imply that you *violated* the CoC, just that your comment felt out of spirit of the CoC. Section 3 says "Please be kind and courteous. There's no need to be mean or rude." I understand that you see a lot of trolls but I feel the context here is where you're brushing up against this. The previous poster asked what SJWs have to do with Rust and I was explaining where the connection comes from, and elaborated why. I tried to do so without being a dick. Section 4 says "Respect that people have differences of opinion and that every design or implementation choice, in any programming language, carries a trade-off and numerous costs. There is seldom a right answer." People will have differing opinions on everything, including the CoC. People are allowed to think whatever they like about the CoC, as long as they're following it in official channels they should not be disrespected per the CoC. Regressive is regressive, regardless of who is causing it. I could give examples, but I already feel this is getting too far from the original context of this thread, and that was already pushing the boundaries of what should be talked about in this subreddit.
How do you think will IPFS help here? The only advantage of this approach I can see is the potential extra reliability (assuming there are enough computers on the network and the data is replicated well enough), but that will require _a lot_ of computers. 
Sure, but how is it different from, say, storing the same thing on Github or any other storage service like Amazon S3?
This is a very new project and only CSV is supported today. I plan on supporting HDFS and Apache Kudu in the short term. Parquet would make sense but I haven't researched that yet to see what is involved. Part of the reason for announcing this is to generate interest and hopefully find more contributors to help move this project along at a faster pace and add support for more file formats. 
That dependency approach is actually good enough for most usecases I can imagine. It should be highlighted in documentation :) 
Besides the technical and cost factors? I never had the idea to store for instance my models on github to download then in rust code. To me it was always a bulk storage place, so I don't lose stuff. IPFS or alternatives gave me instantly the feeling of having it and not having it. It feels exactly like the guy from the comedy Silicon Valley tried to explain. Why drive a Porsche if a Mustang would do too. Maybe there are no differences. 
I really don't see how IPFS is fundamentally different from, say, an S3 bucket, in terms of what you're doing with it right now. It's just a file store for you, and you really don't care how or where the files are stored - what you may care about is the reliability and speed of said store, and IPFS can't really compete with hosted services on those.
ok
Also, it still feels to me like you're not quite understanding how IPFS works, so I'm sorry if this comes off wrong, but I have to ask again: you do understand where IPFS stores data, and how said data is up/downloaded, right?
Before yesterday, this project wasn't complete enough to even run a benchmark. This initial benchmark was single-node single-thread on a desktop with 16GB RAM. I'm in the process of getting a 16 node cluster running locally so I can run some more larger distributed benchmarks. I'll also be testing on EC2 once I have the benchmarks working smoothly. I think this is another area where hopefully others can help out and take this code for a spin and try out what limited use cases are supported by the current codebase.
as far as I know the data is save in the data field of a dag, together with some other information such as file name and links. Not sure about the format but looks similar as I would encode in base64. The dags are stored in chunks in the .ipfs/blocks/00- potentially distributed all across the network. Some are deleted after 18-24 hours from a node. But not sure. But I don't need an id, credit card to use it, I installed a website in 2 minutes. and that's what counts. 
My point is, the data is stored on many other people's computers, and you're basically not guaranteed anything at all - your data can get lost, the computers storing it can go offline, your firewall can block peer to peer connections, and so on. This is really bad for storing stuff like Rust crates because you _really_ want something like that available to everyone, all the time.
Do you plan on including YARN integration in the future? It would be really convenient to test out if it integrated well with our existing HDFS/Parquet/YARN setup.
[removed]
That depends entirely on how you implement matrix multiplication in both C and Rust. A naive implementation in either language will likely be quite a bit slower than something like OpenBLAS that provides hand-tuned implementations for like 20 different CPUs, most of which involve raw assembly or at least SIMD intrinsics.
invite sent!
So is the fastest implementation of matrix operations OpenBLAS?
It's extremely likely to be either OpenBLAS or Intel's MKL, depending on the exact CPU you use for benchmarks.
I see. So would you say it is unlikely that we would see a competing library in Rust?
Freedom comes with responsibility. If I have the freedom not to be reliant on big cloud services, I have to make sure that the things I want people use are available. AWS is no guarantee the things are accessible. Once in a while my internet breaks (mostly DNS). I can't do anything. Mostly. So not only on the server side but also on the clients can be problems. But if I ever write popular code, I put a ipfs daemon on a AWS EC2 and my code on a S3 with public gateway. Super safe.
Recent FOSDEM video: https://fosdem.org/2018/schedule/event/rust_qt_binding_generator/
One of the primary goals of `ergo` is to provide wrapper types that expose a uniform API, or at least simple ways of _converting_ types for all exported items. A good example of this is [`PathTmp`](https://docs.rs/ergo_fs/0.1.5/ergo_fs/struct.PathTmp.html) which is just `tempdir::TempDir` wrapped to make it look like a `PathDir` (including relevant methods, etc). This allows `tempdir` to be developed separately and doesn't put any constraints on its API, error messages etc. We can still integrate it into the ecosystem with a uniform API. So to answer your question, `ergo` has multiple strategies here: - Being opinionated on what types are supported but also making it easy to use the "standard" types. For example, `ergo_fs` uses specific path types everywhere, but it is always easy to "downgrade" to the `std::path` types. `PathDir` is `AsRef&lt;Path&gt;`. - _Don't_ be opinionated when the solution is not obvious. `crossbeam-channel` is the clear best-in-class channel solution for synchronous code, but it is unclear what the right threading model is. So `ergo_sync` does _not_ automatically provide any of `rayon`, `may` or `crossbeam_utils::scope`. In the future we may use the best one (probably `May`), but that is definitely in the future. Does that answer your question?
There is no reason something like that can't be done in Rust, but I don't think anyone is working on it, and it's very unlikely Rust will be faster - the implementations in OpenBLAS/MKL are basically hand written assembly, and it's really hard to compete against that.
Thanks! I did not realize that OpenBLAS is hand written in assembly. I am guessing that LAPACK is also written in assembly. Are their some kind of bindings to these libraries available to rust developers?
They're not exactly handwritten in assembly, but they are largely written using compiler intrinsics that map directly to assembly. There are crates for [`blas`](https://crates.io/crates/blas) and [`lapack`](https://crates.io/crates/lapack), but I'm not sure how usable/stable those are.
&gt; Oh, don't forget that browsers can't handle large integers neither, they will truncate number like nothing is wrong. This is more of a browser implementation of json though. JSON can't represent integers at all, only (a subset of) `f64`s. Any software that emits numbers not representable in `f64` is not emitting JSON, and it should be no surprise that conformant parsers have trouble with it as a result.
I really want to do that, but we are waiting for the compiler. I've been thinking about compiling to C and then to arduino, it seems to be possible with llvm, but I haven't tried.
The compiler only inlines function in the same crates. `#[inline]` allows the compiler to inline other crates functions. So it makes sense to inline those functions
This approach seems perfectly reasonable. Don't know about implementation, but was hoping for something akin to Hadoop Streaming 
Let's not imply that Rust is a silver bullet and does everything better than *&lt;insert_language&gt;*. `mypy` improved the situation a lot for python, and the async story is definitely more refined in python3 compared to Rust right now. Also, when you're doing i/o bound work, python's performance hit isn't an issue, and testing tooling is more fleshed-out. I don't know about ruby, but I'm sure it has some upside too.
side note: shared_ptr is not at all best practice - clear ownership contracts are extremely important in idiomatic C++. However, deep copies are seen as less "evil" than in Rust, definitely.
1s and 0s is theoretically optimal. Rust/C/C++ are not
&gt; "I made a prototype, then my employer threw millions of dollars at it [...] Just curious, how many millions have been thrown at Rust? 
Nice! This looks much more mature than [my BASIC in Rust implementation](https://github.com/travisbhartwell/rbasic) that I did last year as a way to learn Rust. I haven't had a chance to do much with it since starting a new job last May, but it was fun to write.
Will it support functions?
There are some early implementations around such as /u/neutralinostar's [matrixmultiply](https://github.com/bluss/matrixmultiply) and my multithreaded fork [matrixmultiply_mt](https://github.com/millardjn/matrixmultiply_mt), which are only sgemm and sgemm, rather than all of BLAS. These rely on auto-vectorisation, which tends to be brittle and occasionally regress with compiler updates. Performance isn't as good as hand written asm, but I've hit speeds of 350 Gflops in sgemm on a quad haswell machine which is about 76% of theoretical peak flops. I think this has regressed since, towards 300 ish. I think truly competitive libraries will have to wait until rust improves support for numerics. Const generics, better inline asm, simd, and other capabilities are all in the pipeline or at least being thought about.
IMHO, a lot of functions in Python with different default values is not a code smell. However, when I translate such functions into Rust, it will be code smell if I could not handle it properly. As you say, I sort them out with `impl trait`, it is great. 
For compile-time known dimensions, it's not hard to write fast matrix multiplication in C or Rust or any language with an ahead-of-time compiler and sufficient optimization. The language doesn't really matter, as long as it can expose sufficient semantics to its optimizer. For runtime-specified dimensions, beating Intel MKL or OpenBLAS is not for the faint of heart, since as was already pointed out that they use specifically tuned algorithms across various CPUs. The most promising effort in my opinion comes from the libflame people (https://www.cs.utexas.edu/~flame/web/libFLAME.html) who identified a small handful of "kernels" that you can implement higher order linear algebra primitives on top of. (See also C++'s Eigen for another fundamentally different, but nonetheless valiant effort.) Thus, instead of optimizing each algorithm for each piece of hardware, you just optimize these small kernels and get the improvements for free. If anybody was interested in writing a fast, non-LAPACK dense linear algebra library in Rust, the libflame papers are probably the best place to start. I wouldn't expect C to meaningfully outperform Rust, or vice versa, in such a hypothetical implementation, but perhaps Rust can allow an easier implementation due to its ergonomics. 
That is interesting. I am mostly curious because I do a lot of statistics at work. One of the many packages I use is Stan which requires Eigen. I think most of the heavy lifting is for LU decompositions. I was mostly curious if a Stan-like clone would run any faster if it were Rust based as opposed to C++ based. I am guessing the performance would be similar.
At last, here's the proposal. I want to emphasize that this proposal is based on the principals outlined in the 2018 roadmap: we want to make things that can be shipped. We have ideas (especially Niko does, of course) about how to typecheck the notion of immovability, but its unrealistic to imagine those coming to fruition sooner than 2020, given that NLL, GATs, and const generics are higher priority. I also want to point out something about async functions that will be relevant given recent threads here: they can solve the compile time problems with futures without giving up performance. `impl Future` results in superlinear compile times because of bad caching in trait resolution, causing highly nested types to get checked for trait impls again and again. Because an async function does not return a highly nested type, it doesn't result in this superlinearity. But its roughly the same performance profile as `impl Future`.
That sounds like a fun project. I could help you get that going for sure. The built-in SQL parser and query planner would get you a long way towards this. 
In the end I think both Rust and C++ would depend on the same base libraries.
There's nothing perfectly succinct, since modules don't exist as runtime concepts, but there are two ways I can think to do this: A. use macro_rules to make it at compile time: macro_rules! run { ($($module:tt),*) =&gt; ( $( $module :: run(); )* ); } run!(a, b, c, d); This can be done inside a function - the macro won't exist outside this one usage. B. Iterate over the functions rather than modules: for f in &amp;[a::run, b::run, c::run, d::run] { f(); } This could have a runtime cost, but it will be very easy for the compiler to optimize it out.
&gt; something like Github. To be clear, today, crates are hosted on S3. The index is on github.
Pretty sure it's not true. According to JSON spec: number = [ minus ] int [ frac ] [ exp ] digit1-9 = %x31-39 ; 1-9 int = zero / ( digit1-9 *DIGIT ) From the same spec: &gt; This specification allows implementations to set limits on the range &gt; and precision of numbers accepted. Which means representing all numbers as `f64` is up to the implementation. Therefore, software limiting numbers as `u64` and/or `i64` is perfectly valid software. The limitation comes from the fact inside javascript all numbers are `f64`.
Ok,thx.The first method seems better to me. But i still hope there will be methods working on modules level in rust .
Google prefers `gRPC` to `HTTP+JSON` and they claim exactly the same issues with `JSON` You have to understand that when your client is with shitty chindroid device with spotty 3G network he doesn't care how fast you wrote your backend and how easy it was to debug with curl, all he cares that it's taking forever to load. User is willing to wait for Facebook and snapchat. Hell, users were using snapchat on Android back when it would screenshot the screen instead of taking a picture and unless you're one of the big companies user isn't going to wait for your thing to load. Every byte counts. 
The idea of an unsafe, unstable interface exposed through safe language features and library APIs is an excellent way to get this working quickly! Thanks for writing this up, I'm excited to see the final post. :)
Wow, this post delivers. This is unarguably a *simple* and *quick* way to get going. Excited!
There are two variants: 1. You want draw resulted pdf, then you can use skia: https://github.com/servo/skia 2. You want specify pdf via template (xml, html or something?): https://crates.io/crates/wkhtmltopdf potential you can use servo instead of wkhtmltopdf, but it is not ready for this use case.
Bikeshed: `Generator` and `GeneratorMove` are a bad pair of trait names to pick. Using `Generator` is fine, but the trait that should go with it is `MovableGenerator` or `MobileGenerator` or something of the sort. Pairing it up with `GeneratorMove` is bad because while that term as a whole is still a noun, it's a kind of Move, not a kind of Generator. The "generator" part of it has become an adjective.
The analogy was `FnMut` and `FnOnce`, but I don't have very strong opinions on what these traits are called.
Slides for Siddon Tang's talk: [Using Rust to Build a Distributed Transactional Key-Value Database](https://fosdem.org/2018/schedule/event/rust_distributed_kv_store/attachments/slides/2034/export/events/attachments/rust_distributed_kv_store/slides/2034/Siddon_Tang_Use_Rust_to_Build_a_Distributed_Transactional_Key_Value_Database.pdf)
Oh another thing, I'd like to see generator also have an `anchor` method. Since we may have fn type parameter defaults soon, it could look like this: trait Generator { type Yield; type Return; unsafe fn unsafe_resume(&amp;mut self) -&gt; CoResult&lt;Self::Yield, Self::Return&gt;; fn anchor&lt;T = Box&lt;Self&gt;&gt;(self) -&gt; Anchor&lt;T&gt; where T: Deref&lt;Target = Self&gt;, Self: Into&lt;T&gt; { Anchor::new(self.into()) } } So you can do `generator().anchor()` or `generator().anchor::&lt;Arc&lt;_&gt;&gt;()`.
Hey everyone, I've written a post that will hopefully be useful to those of us that are new to the world of procedural macros. I've tried to go over what exactly a procedural macro is, and show you how to make one with a fun example. Since `proc_macro` is an unstable feature, it's a bit of a moving target to write about. If you find something out of date let me know!
It seems pretty cool, but I'm unclear which part of the Rust development cycle you want to replace with IPFS. For me, git and github are reliable, and let others collaborate easily. Once the crates are used my `cargo`, anyways, they're grabbed from the `crates.io` server, not from github. Your title states "ipfs instead of github" - but your post is all about replacing in-app resources. Do you want to replace/augment `crates.io`, `github` or something else with ipfs? -- for in-app resources, if that's your idea: I wouldn't go too far with it. I'm wary of storing resources used by a binary _anywhere_ online, in case someone needs to run it without an internet connection. It sucks when you're on a plane, or train, or anywhere without a connection and that means the programs can't run. If you're thinking of using it as a cache of sorts, that would be pretty cool, but I would be against using it (or github, or any other online service) to store critical information.
I do prefer `GeneratorMove`. AFAIK, `MovableGenerator` doesn't match any existing naming pattern in rust, which should be a top consideration.
Since you asked, in an almost accusatory manner, I'll bite. [Here are reports of CoC violations levied against a member of the Rust core team](https://www.reddit.com/r/node/comments/6whs2e/multiple_coc_violations_by_nodejs_board_member/). This occurred prior to them joining rust core, but the person in question was a leader in another community at the time, and a vocal proponent of CoCs. The point is, CoCs *have* been weaponized in a self-defeating fashion, and concerns about that happening to rust are not without merit.
Rust doesn't have any ABI compatibility except for C and maybe unofficially C++ if you match rustc and clang with each other. Why is it that the allocator is The One Thing people worry about breaking? Literally *everything else* about how Rust-specific concepts map to machine language is up in the air. And they certainly do change between compiler versions. Rust recently gained a nifty optimization for nested enumerations. Your plugins will only be compatible if the compilers are compatible. And nobody will necessarily tell you when breaking changes happen. I'm perplexed and genuinely curious what problem `libloading` solves for you.
Its unlikely that the trait would be deprecated, since there remains this fundamental difference where one is movable and one isn't. The `unsafe_resume` method would be replaced by a safe method with a signature that enforces the constraint that it can't be moved.
Thanks, I'm really glad to hear that it was accessible. :)
I imagine some long-term solutions might make one of the traits equivalent to something like `Generator + ?Move` (just in the sense of having a modifier), in which case we'd want to make it into an alias, right?
depends. but got imgui-rs working quite easily for simple uis.
If I'm reading this correctly, wouldn't this proposal be predicated on including `Future` in `std`? If the goal is to ship this abstraction as stable this year, and: &gt; We‚Äôll keep it unstable to implement either of these traits (just like the Fn traits have been kept), and some day, when we have self-referential structs, we‚Äôll deprecate the unsafe API on Generator and transition to a new and completely type-checked API. Until that time, we‚Äôll encourage users to interact with generators through these safe abstractions. Then won't Future need to be in `std` to use an unstable feature but be used on a stable compiler? It seems like the logical progression of the various goals proposed, but I'd also note that the Futures API has a proposed overhaul that may not have very much time to bake outside of std if my read is correct and the author hopes this will actually ship in stable this year.
It solves hotloading a small, fast-to-compile part of my larger, slower-to-compile application during development. I can hit save in my editor and the in-app behavior changes ~1s later. Development of this particular part of the app is basically just continuous tweaking, so this is very useful. If I were to do plugins, then yes, all the FFI rules apply.
Ah, I see! Thanks for the clarification. 
* https://docs.rs/rand/0.4.2/rand/struct.AsciiGenerator.html * https://docs.rs/rand/0.4.2/rand/trait.SeedableRng.html * https://docs.rs/rand/0.4.2/rand/struct.StdRng.html * https://doc.rust-lang.org/core/cell/struct.UnsafeCell.html * https://doc.rust-lang.org/core/sync/atomic/struct.AtomicUsize.html * https://doc.rust-lang.org/core/nonzero/trait.Zeroable.html * https://doc.rust-lang.org/std/str/struct.Utf8Error.html I'm sure we could go on and on all day. Adjective Noun is just how English kinda works.
Yeah, because you totally get an `ErrorBorrow` when you use try_borrow on your `CellRef` but it was already in use ;3
Some areas of memory are special. Basically this special memory can't be cached within a CPU register across writes to memory, or (possibly) across certain memory fences. If you write you must reread. Those rules are true for the target of a raw pointer. But once you turn it into a reference it stops being true. References to `UnsafeCell` are also handled cautiously. This makes it safe to cast `&amp;UnsafeCell&lt;T&gt;` to `*mut T` because even safe code agrees that the memory is special. Casting to that raw pointer to a reference is dangerous because downstream code no longer gives it special treatment. Unfortunately the exact details of what "special" means aren't defined very well yet. It means enough to make `RefCell` do what it should; that much can be counted on. 
`f(t: &amp;Trait)` implies v-tables though, I think? It's certainly possible that some embedded environments that might be too big a performance hit. It might not change the semantics of the program, but going from possibly no indirection to a method call to two(?) levels of indirection is some difference.
Considering Iterator and Generator are somewhat related, DoubleEndedIterator, ExactSizeIterator, etc are some counterexamples.
This is bizzare, I just wrote a small CLI tool this past weekend and my `main` and `run` functions are essentially identical down to the lines except I'm currently using Strings instead of the failure crate. StructOpt + Clap is a powerful set of tools. As a cool aside, it's very easy to write tests to make sure your CLI behaves the way you want it when passing args in certain orders and such: #[test] fn test_run_arguments() { assert_eq!( Command::Run { test_framework: None, directory: Some("target".to_string()), user: None, password: None, arguments: vec!("ps".to_string(), "-a".to_string()) }, Opt::from_clap(Opt::clap().get_matches_from(&amp;[ "your-binary", "run", "--dir", "target", "ps", "-a" ])).cmd ); }
Not quite a Rust issue. The trouble here is English itself. Many English words are both nouns and verbs, and you don't know which until you look at a particular usage. We have the same deal with adjectives and nouns too. To use an example from an old book I like, "a dog house isn't the same as a house dog". The only way you know which is which is because you know (perhaps unconsciously) that the adjective precedes the noun it modifies in the default case. This isn't an absolute rule of course, like "attorney general" and stuff. https://en.wikipedia.org/wiki/Postpositive_adjective goes way into it if you care.
There's also the [`assert_cli`](https://github.com/killercup/assert_cli) that can be used to help test your results ;)
I actually covered that in my reply in the other comment branch. Reddit is just a bad format sometimes :/
I can't wait until the Army puts stars on a JAG just to ruin your last example;)
SQLite would make a better container over Zip (Jar, Apk, etc) for packaging up and transporting WASM. 
I finally did it! 3 weeks later, I tried your advice, and it really helped me get moving in the right direction. I had to jump through the wackiest of hoops to get this code to run, but eventually it happened. The `oneshot` thing is awesome, I wish I had known about it before. It worked perfectly for the server.run_until() method. I also ended up using .and_then() on the oneshot receiver. The biggest problem I had by far was the Responses. Since they aren't cloneable, I had to write a ton of stuff expensively cloning them by hand while they were under like three different layers of Options and RefCells. I can't explain this in words at all, but in case you're curious, my code is [here](https://github.com/IntrepidPig/orca/blob/cf20d349d8cea92eab66aeb84838541e4fda29e4/src/net/auth.rs) (that's a link to a specific revision). The last two functions in the file are the ones that clone the Responses. They're pretty crappy, lol. I just realized as writing this that maybe the best thing would've been to have the user provide closures to generate responses. Maybe I'll do that another time. Thanks so much for your help!
Make the attorney general be a military General. :)
To be fair, outside of English majors, most native speakers don't pay much attention to subtleties of grammar...
*move* is not a verb. *GeneratorMovable* would be the analogon.
I would accept `Gen` and `GenMov`, but in the long form I'd strongly prefer `Generator` and `MovableGenerator`!
I think it has to do mostly with the fact that our primary types in rust are `T`, `&amp;T`, and `&amp;mut T`. If we choose to pronounce the `&amp;` as "ref" then that would be read as "Tee", "Ref tee", and "Ref mut tee". This makes a special case where the adjective "mut" is coming out of the normal order, which carries into a few other places like `FnMut` and `IterMut`. Of course, we also have `mut &amp;T`, but that's a different thing entirely (a binding to a `&amp;T` that can be re-assigned). Some future rust2 language might choose to change &amp;mut to an alternate punctuation entirely. Something like `T`, `&amp;T`, and `^T` ;P
I started using quicli which allows ? in main, and integrates failure, log and structop, this is really comfortable - at least for simple CLI.
Nice, I love how easy it is to test things in Rust.
I've been playing with the beta and this is going to be very useful: $ mrh --ignore-uncommited-repos cargo-bloat test/scratch/quick-protobuf (untracked files) test/quick-protobuf (untracked files, uncommitted changes) test/examples (uncommitted changes, untracked files) lua-patterns easy-shortcuts (untracked files, uncommitted changes) scanlex (untracked files, uncommitted changes) gentle-intro (untracked files) .... The `ignore-uncommited-repos` excludes all those little Cargo test projects that tend to litter our harddrives. 
I'm still working on the caching for layout constraints for [azul](https://github.com/maps4print/azul), my React-like GUI library. Caching constraints can make the difference between 80ms and 0.3ms for a re-layout, so getting it right is important. I hope I'll have a simple demo to show at the meetup on friday.
Doesn't internal mutability break this? Suppose you anchored a generator that has a RefCell inside it, and then invalidated the immovability constraints using perfectly safe code?
&gt; I also want to point out something about async functions that will be relevant given recent threads here: they can solve the compile time problems with futures without giving up performance. I feel like this is a dangerous red herring. The compile time blowup is a compiler bug, and masking bugs with new features is not a good precedent. The bug's still there.
[removed]
I should probably learn about crates this week for my [show](https://www.twitch.tv/mortoray). Might need to do some unit testing as well. And get swapping working on the knapsack problem.
I guess the reference to be invalidate need to be created before the invalidation, which locks the RefCell.
I just joined the ergo initiative, made a first PR to [stdsimd](https://github.com/rust-lang-nursery/stdsimd), started an experimental PR to convert [bytecount](https://github.com/llogiq/bytecount)'s benchmarks to [criterion](https://crates.io/crates/criterion) (waiting on its next release, which will very probably fix a crash for us), and of course will do TWiR.
I'm currently using `crossbeam-channels` for channels (mainly for a receive timeout). The receive seems to be busy-waiting as my CPU sits at 25% while it blocks on `chan_rx.recv()` or `chan_rx.recv_timeout(/*some duration*/)`. Should it be busy-waiting? If so, is there a channel implementation that doesn't and has a timeout option available?
I tend to divide my projects/crates into ones I want to get popular and ones I don't really care about that much. The first I spend a lot of my free dev time on, I also aim to make it easy to contribute although it usually takes a while after starting a project to get there. The later ones I just publish, and if someone needs a feature they have to do it. I'll gladly review and guide/improve any contributions. Usually I leave a TODO file or issues on GitHub detailing what yet can/has to be done. I don't really feel bad about not maintaing them properly but so far none has gotten popular yet either lol. One thing I think would be nice is a template Contributing file, detailing this decision of limited maintenance, I can put in my repos. I guess I might do that.
This seems like a weird thing to want to accomplish. What are you actually trying to do?
yes, this is something I'm planning to use, but it will be a bit trickier, since the network related kernel structures can change depending on the kernel version and the configuration options (that's why BCC requires the kernel sources to build ebpf programs)
Regarding `Anchor`: I could use a mechanism that forbids calls to `mem::swap`, for a similar self-referential-struct situation. I sketched out an idea for a primitive for self-referential structs: https://play.rust-lang.org/?gist=cb7907ea16bfd408b73ff48a9cc1a679&amp;version=stable I know `[rental](https://crates.io/crates/rental)` &amp; friends already exist; this one uses a different technique. Is there anything like it on crates.io?
We can also have non-allocating escape hatch: // Prevents calling mem::replace() on &amp;mut G struct ResumeHandle&lt;'a, G: 'a + Generator&gt; { generator: &amp;'a mut G, } impl&lt;'a, G: 'a + Generator&gt; ResumeHandle&lt;'a, G&gt; { unsafe fn new(generator: &amp;'a mut G) -&gt; Self { ResumeHandle { generator, } } fn resume(&amp;mut self) -&gt; CoResult&lt;G::Yield, G::Return&gt; { unsafe { self.generator.unsafe_resume() } } } trait Generator { // All things already mentioned, plus this method: begin&lt;F, R&gt;(self, f: F) -&gt; R where for&lt;'a&gt; F: FnOnce(ResumeHandle&lt;'a, Self&gt;) -&gt; R { let mut generator = self; f(ResumeHandle::new(&amp;mut generator)) } One could use it like this: generator.begin(|handle| { foo(handle.resume()) // With language support or impl Iterator for ResultHandle&lt;Return=()&gt;: for x in handle { bar(x) } })
Can you please comment on why you chose Generator and GeneratorMove for trait names and not, say, ProtoGenerator and Generator? Wouldn't it be more logical to give the name "Generator" to an object that you can actually call resume() on?
You are missing the fact that one is allowed to nest multiple generators within each others, and only then box them, in which case they don't end up separately boxed. This is because you _are_ allowed to move them before you call resume for the first time.
`#[no_std]` can be very painful if floats are involved. You lose a lot of math functions, and even the simple ones like `is_finite` are not exposed on stable.
If the line iterator had something like `slice.chunks()` that would probably help.
In terms of names, `PinnedGenerator` and `Pin` / `.pin()` (instead of `Anchor` / `.anchor()`) might also make sense (and correspond to GC "rooting" terminology, whereas I've only seen "anchor" in a technology context to refer to the `&lt;a&gt;` tag in HTML). If nothing else, "pin" is shorter. &gt; We‚Äôll keep it unstable to implement either of these traits (just like the Fn traits have been kept), and some day, when we have self-referential structs, we‚Äôll deprecate the unsafe API on Generator and transition to a new and completely type-checked API. So this is good, but I'm wondering if we can go much further and avoid issues similar to "we can't easily phase out `Iterator` in favor of `GeneratorMove` because of backwards-compatibly and/or coherence", once we do get safe self-referential structs. What *might* the final API look like? 1. `Move` / `!Move` property of each type: * `Generator + Move` could imply `GeneratorMove` (via a blanket impl), such that you wouldn't need to deal with the latter directly * However, `Generator` *implies/requires* `Move` today (as in, everything requires `Move` because `!Move` doesn't exist yet), and relaxing `Generator` to allow `?Move` would be a breaking change, wouldn't it? * Could we keep enough of that unstable? I don't think so, because we need users to be able to write `-&gt; impl Generator` for immovable generators and thus async fn 2. perma-borrow on calls to a safe version of `unsafe_resume`, but not `GeneratorMove::resume`: * We can do it today by e.g. adding a special perma-unstable attribute to the compiler * Would only be safe when the borrow is on a local variable or field thereof, *not* through any indirection (since the type wouldn't prevent *other functions* from moving) and *even then* you might still have the `swap` problem 3. using `Anchor` / `Pin` (or a slightly different type) somehow in the type of `unsafe_resume` * We know how to make wrappers that perma-borrow, by having a phantom lifetime parameter and then using the lifetime in an invariant context e.g. `&amp;'a mut PinFor&lt;'a, T&gt;` * We can make creating `Pin&lt;&amp;mut T&gt;` unsafe in general (because of reborrows), while `&amp;'a mut PinFor&lt;'a, T&gt; -&gt; Pin&lt;&amp;'a mut T&gt;` can be safe (underlying data is perma-borrowed and the `Pin` contains the only reference that can ever exist to the data) * `unsafe_resume` could be safe by taking `self: Pin&lt;&amp;mut Self&gt;`, while `Pin`-based `resume` impls would do an unsafe conversion from e.g. `&amp;mut Pin&lt;Box&lt;T&gt;&gt;` to `Pin&lt;&amp;mut T&gt;` I like option 3. most, I think, but it's really not the `unsafe` that I'd like to avoid as much as stable-facing eventually deprecated APIs.
Unlikely.. unless perhaps you could think of some way to increase cache friendliness and/or smartly compress input in Rust that is unwieldy in C.
Depends what you mean by functions. Right now I'm working on supporting parts that can be "called" anywhere in the piece. But at the moment I have no plans for anything more complex than that (function arguments or whatever). Did you have something else in mind?
I would also like to know this. From what I've seen rust support for OAuth is a bit barebones.
It doesn't concern what i will do, i only hope rustc to support something at module level,suchas attributes of modules etc.
Nice! I am not an expert on the topic. How far is it from Visual Basic?
What is the name of the monospace font?
I was disappointed by `BufRead` so I decided to more or less clone `java.util.Scanner`. I'm kinda stuck on bug fixing until I or someone else writes a regex engine that supports partial matching, but the `Scanner.has_*` methods should be out soon. https://github.com/hxtk/Rust-Scanner https://crates.io/crates/file_scanner It's my first crate, so constructive criticism is welcome.
That's not as convenient, because you have to copy-and-paste the dependencies of your function as well, which might be non-trivial.
There was discussion in the post about a wrapper type that would make it unsafe to get a mutable reference to the inner types. You could still do it, but you explicitly consent not to move the inner type.
This wasn't covered explicitly, but presumably we could have an implementation of `GeneratorMove` for `Anchor&lt;T&gt; where T: DerefMut, &lt;T as DerefMut&gt;::Target: Generator`? This would allow using self-referential generators entirely from safe code.
If the target is a Spark-alike wouldn't forking, serialising all the data to stdin and reading data from stdout for each function call place a really nasty bottleneck on the system that otherwise wants do keep everything in memory? That said, it would certainly be a good way to get value now so it's in the hands of users - and then contributors can iterate on it.
&gt; This is bizzare, I just wrote a small CLI tool this past weekend and my main and run functions are essentially identical down to the lines except I'm currently using Strings instead of the failure crate. I've taken to using a main that's basically the same, too: fn main() { use std::process::exit; match run() { Ok(_) =&gt; exit(0), Err(e) =&gt; { eprintln!("Error: {}", e); for e in e.causes().skip(1) { eprintln!("Caused by: {}", e); } exit(1); } } } I then make use of `context` and `with_context` to build a chain of failure causes, in a similar style to error_chain.
I take it none of the Rust code in Firefox has reached the GUI layer very much yet?
Github link to changelog with all updates: https://github.com/exonum/exonum/releases/tag/v0.5
In the editor it‚Äôs Operator Mono
Just [released](https://bheisler.github.io/post/criterion-rs-0-2/) v0.2.0 of [Criterion.rs](https://github.com/japaric/criterion.rs), a statistics-driven benchmarking library. Not entirely sure what should come next - there's still some work to do to expand the HTML reports, especially to show the performance differences between multiple functions and/or multiple parameters. Alternately, I could work on hooking into jemalloc to measure the memory allocated by each iteration of the benchmark. What do you folks think?
My [client library for Path of Exile API](https://github.com/Xion/ezomyte) is presentable now, but I'm not yet happy enough with its reliability to release a 0.1. Turns out that when the data (here, the API responses) you're working with is very irregular, trying to come up with a salient type model is rather challenging. I can absolutely see the appeal of dynamic languages for this kind of use case (or at least dynamic types a'la C#). Still, hopefully by the end of this week I should finally land something on crates.io :)
It's tricky though. I'm a huge fan of algebraic effects, but I'm not sure how they could be implemented in a low-to-zero overhead way. They also lack much real-world battle-testing, apart from Purescript's foray (half-baked and regrettable, alas). Perhaps we *should* wait for OCaml to make the jump first, but I just worry that it will be even harder to retrofit later on if we haven't put any planning into how it could work later on. Perhaps I would feel more comfortable if the async/await proposals also addressed the possibility of moving to a more general, powerful solution in the future that could also cover other effects, like internal mutability and panics. At the moment it seems like a big blind spot.
More importantly, they're pretty well supported and there's not a lot of incentive to RIIR when you can just add bindings to them, which I believe has already happened. You can do blas in Rust by just hooking into the library that exists.
I can recommend wkhtmltopdf, I have used it both in personal and professional applications with great results. In my case I have only used it as a sub-process, not as a shared library. If you choose this route I would recommend reading the documentation on the available command line parameters carefully, there are quite a few and knowing what options exists can save you form re-implementing existing features, for example automatic page numbering.
Took a break from working on [relm](https://github.com/antoyo/relm) to publish the first blog post that I‚Äôm sharing with the Rust community: * [Introduction to Procedural Macros](https://tinkering.xyz/posts/introduction-to-proc-macros/) I was going to publish it earlier, but I got a message that water was raining from the ceiling in my lab, so I had to go save my PhD. I think half of the trash cans from that floor of the physics building ended up in my lab to catch water üôÑ. Here‚Äôs what it looked like: https://i.imgur.com/1GjOi3m.jpg
I suspect this is caused by `rustc` being invoked with multiple parameters in the filename position. This is what happens if you try this on a command line: $ rustc foo.rs bar.rs error: multiple input filenames provided Maybe your Atom Rust IDE is improperly configured and/or buggy, and tries to invoke rustc in an invalid way. Until you can get it fixed, I would suggest just invoking cargo/rustc manually from the command line. I believe Atom has packages for built-in terminals, where you can comfortably do this from within the IDE. 
(then there would be an attorney, who is also a general)
Sub-process is certainly the way to go. That way you can shoot the process when it hangs and it's much easier to work around some of its other flaws as well.
Yes, I actually have an issue open for that. 
Do you specifically need it **per function** or do you want to know how to get ASM/IR output? The latter is done with `cargo rustc -- --emit=asm` or `--emit=llvm-ir`, or with `rustc --emit=asm ...` if you're compiling things manually. It doesn't demangle symbol names, though. You can also try [Rust's playground](http://play.rust-lang.org/), it lets you use most popular crates and does demangling.
I'm preparing some bindings of `usrsctp` for release, and one of the things that I wanted to figure out before hand was how I could take a `std::net::SocketAddr` and get the underlying `libc::sockaddr_in` or `libc::sockaddr_in6` out of it. I didn't see anything in the `std::net::*` or `libc` docs? 
The X/Y problem is a common enough occurrence that information about the desired end state is desirable, regardless of thoughts on the journey to get there.
Firefox is also GTK, if I remember correctly
Thanks, it looks quite interesting.
Comparing with C++ I read, "Their solution has been to ‚Äúanchor‚Äù every generator by heap allocating them every time.". What does 'every time' mean in this context? Two options(?): heap allocate the yield result every time resume() is called - or heap allocate the yield result once (during Generator creation) and reuse it on every resume() ? I think I need to write an await server so I can update my mental model. 
Yes, I meant per function. As an alternative to the playground, I can recommend https://rust.godbolt.org. It's great for looking at the emitted ASM. It works nice if your code is self-contained enough to copy-and-paste it.
I've starred both repo for future use, but I would most likely use oauth2 since it is written by alexcrichton who is very active in the rust community.
The full quote from that article was: &gt; First, though, there's a matter that we should all be clear about: Brendan Eich was not fired. After his appointment, there was backlash from the Mozilla Community. He came under pressure to resign and he did. The Mozilla Board that appointed him knew about his donation; they did not "remove him because of his views." If that alone was the issue, they simply wouldn't have given him the job in the first place. Resignation (after only 11 days in the CEO role) became the only viable path forward when a sizable portion of the Mozilla Community refused to follow the person that the Board designated to lead the organization. That wide refusal and rejection fomented the issue, and Eich's decision to maintain his public stance on gay marriage -- as is his right -- created an impasse. It is incorrect to say that he was fired or removed; it is fair, though, to say that he was forced out. So he was forced out by ***community*** backlash because of actions he'd taken against marriage equality. He wasn't fired and the pressure wasn't (based on all evidence I've seen) from the board, the people who would have fired him. There is a big difference between being forced out because you can't lead (because you're being rejected by a bunch of people you're supposed to be leading) and someone with the power to fire you pushing you to resign so they don't have to.
You can also get to the videos from here and the added advantage is that you can also find the slides and attachments like demo source code. https://fosdem.org/2018/schedule/track/rust/
I spent a good amount of time this weekend getting Tor to be statically compiled and callable from in Rust in Windows [here](https://github.com/cretz/rtsw-poc). It uses the new "api" (which is just a way to invoke main programmatically) that the Tor guys have been working on. I really need to trim the exe size though, probably by config options to openssl. Now I need to apply it. I think the first thing may be a Rust-friendly wrapper around the raw args. Like maybe even easy Tokio pluggability. At first the API might have to spawn different processes of the same exe due some bugs mentioned in [tor_api.h](https://github.com/torproject/tor/blob/953c769a867415f81dc016f30575dee6c0b2cb43/src/or/tor_api.h). I have a few ideas after that because who couldn't come up with several ideas when you can easily generate/start onion services and get built-in nat busting and anonymity?
As I can't find a comments section in the blog post, I post here some improvement on the structopt usage: extern crate structopt; #[macro_use] extern crate structopt_derive; use std::path::PathBuf; use structopt::StructOpt; /// Benchmarking utility for librsvg. #[derive(StructOpt, Debug)] #[structopt(name = "rsvg-bench")] struct Opt { /// Number of seconds to sleep before starting to process SVGs. #[structopt(short = "s", long = "sleep", default_value = "0")] sleep_secs: usize, /// Number of times to parse each file. #[structopt(short = "p", long = "num-parse", default_value = "100")] num_parse: usize, /// Number of times to render each file. #[structopt(short = "r", long = "num-render", default_value = "100")] num_render: usize, /// Render to a GdkPixbuf instead of a Cairo image surface. #[structopt(long = "pixbuf")] render_to_pixbuf: bool, /// Input files or directories. #[structopt(required_raw = "true", parse(from_os_str))] inputs: Vec&lt;PathBuf&gt; } fn main() { let opt = Opt::from_args(); println!("{:?}", opt); }
&gt; but the spacing between characters is just off I used rusttype before, and can thing I can point you to the problem: in `rusttype`, height is measured as `ascent`, while in PDF it's `ascent - descent` (where `descent` is usually negative). Or maybe it's the other way around. But to calculate the with of a text in PDF, you need to do something like let vm = font.v_metrics(rusttype::Scale::uniform(1.0)); let pdf_width = rusttype_width * (vm.ascent - vm.descent) / vm.ascent;
Are procedural macros the same as macros 2.0 or are with they something else?
Just as it is outside scope for `Arc`. You still need something to synchronize accesses, like `RwLock`.
They are something else. It's my understanding that macros 2.0 will revamp both declarative macros and procedural macros. It's important to realize that procedural macros aren't the next step after declarative macros, they're just another type of macro.
Is there a way to do the same for modules of the format prefix_x, where x is some u8? Basically, can you operate on module names in macros, and call a function of that module afterwards?
I think it's funny that naming has become the largest comment thread in this post :)
Not all embedded devices has a floating point unit.
 let schema = Schema::new(vec![ Field::new("city", DataType::String, false), Field::new("lat", DataType::Double, false), Field::new("lng", DataType::Double, false)]); you should just use the builder pattern and move out of self: let schema = Schema::new() .field("city", DataType::String, false), .field("lat", DataType::Double, false), .field("lng", DataType::Double, false); also prefer a descriptive enum to raw true/false
Why would anyone use a "private blockchain" instead of an uhhhhh‚Ä¶ database
I doubt that the solution is that "simple" - I already tried all sorts of variations. In PDF, the font is seperate from the actual text you write. You first embed the raw font file, then you need to embed the **unscaled** widths of the characters of the font into the descriptor, and these are tricky to calculate. [This](https://github.com/fschutt/printpdf/blob/master/src/types/plugins/graphics/two_dimensional/font.rs#L226-L228) is how I currently get the font - I take the height of the literal "space" character (U+0020). It works, but I don't know why. Then I multiply the widths [here](https://github.com/fschutt/printpdf/blob/master/src/types/plugins/graphics/two_dimensional/font.rs#L294-L307). I already made [a patch for rusttype that can get you the unscaled v_metrics](https://github.com/redox-os/rusttype/commit/c453ec2b904a856989a1ed485561cf75c137d524) and [another one](https://github.com/redox-os/stb_truetype-rs/pull/9) because I thought that it was parsing the font file incorrectly. These patches makes rusttype work for printpdf, but breaks everything else, so it can't be merged. If you are really sure that your version fixes the spacing problems, I'd be really happy about a PR, in order to get away from freetype and improve the Windows installation process. But I've ripped out my hair for days over this "character width" problem and tried all sorts of combinations / divisions / multiplications. I'm not denying that it could be that simple, it's just that I'm tired of trying.
&gt;I wasn't being accusatory, I was terse I apologize, especially as someone who appreciates terseness. &gt;the linked posts (assuming they're real) don't seem sexist, just stupid. It's an interesting point, because it brings into question what it mean to be sexist/whatever-ist. As a society we're quick to put these labels on people for superficial reasons. Personally, I think true racism/sexism/*ism comes down to intent versus simply uttering words. Some people may have a crass sense of humor, for example, and say things that are considered insensitive while never having any real ill intent. On the flip side, some people may be outwardly virtuous, but may be entirely self-serving and not representative of their true actions. When it comes to the things AW said, I think it's only appropriate to levy the same definition of racism/sexism against her that she has subscribed to herself. After all, she was the one who advocated a CoC and slapped these labels on others with reckless abandon. I'm not offended by what she said, but I find the hypocrisy incredibly distasteful, and disqualifying of any position that enforces a CoC. &gt;BTW - should CoCs work backwards? Another interesting point, and one I've thought about quite a bit. A CoC is founded on principle--It shouldn't matter the circumstances of ones life, because a CoC should be applied equally regardless. So much of the backlash against CoCs is a result of certain communities (ahem, node) claiming outright that a CoC *isn't* a principled document, rather something that is and should be enforced differently based on entirely superficial aspects of ones being. &gt;I still, due to a shortage of time, haven't verified the sources and fully built my opinion about that person. When I need one, I'll spend some time carefully researching the topic. As you should. And I want to sincerely thank you for engaging me in a meaningful conversation. :)
You are probably right. But i will still try to do something with it, since I do want to use your library in the future. 
Well, pragmata pro is ‚Ç¨200 as well and people definitely buy that one...
Would the proposed keeping-`Generator`-traits-unstable-but-allow-using-them-stably allow for backwards compatibly extending them to take arguments when resuming? I've seen multiple people go "ah, Rust has generators, perfect for my use case!" then two minutes later "oh wait, but they don't accept resume arguments, nevermind then..." recently. (or is this one of the things that will be determined in the actual (no longer e-) RFC for generators that will be submitted at some point, and you were just sketching something as illustration)
Have been keeping an eye on this project exactly because I want to steal* the actor framework it uses (which is not up on `crates.io`). Was concerned that development had stalled since December but it [seems to have resumed](https://www.patreon.com/posts/how-i-spent-and-16804910) again. # actually, it is AGPL licensed so not terribly useful as a library
If you want to try it, there is already a [rusttype branch](https://github.com/fschutt/printpdf/tree/rusttype), just wanted to make you aware. 
&gt; Nevertheless, ŒªRustis realistic enough that studying it led us to uncover a previously unknown soundness bug in Rust itself [Jung 2017]. anyone know what this was? assume it has been fixed?
That looks awesome, I look forward to trying it out!
It's probably at least a little tricky to do since LLVM does a lot of inlining and such when optimizations are turned on, and probably even more when LTO is turned on. "An individual function" may well transform or vanish unless you take care to ensure it doesn't, at which point you're not actually looking at the code the compiler wants to generate. On the other side, an individual generic function may expand out to have many concrete implementations. It's certainly not impossible, just a bit trickier than it first looks.
Updated my [gfx-rs tutorial](https://wiki.alopex.li/LearningGfx) to work with gfx 0.17. Going to be trying to work on documentation for gfx-rs more in the coming weeks.
I'm curious how receptive crate authors would be to switch from `libtest` to Criterion. I know there is the whole mantra of "if it ain't broke don't fix it", but there are a host of things to like about Criterion (benchmarking on stable and the increase in statistical rigor ). bheisler has also done a fantastic job of continuing development, writing documentation, and answering questions. Congrats on the release!
I knocked off a couple easy issues in [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis) last week and I'm deciding if I want to release v0.17.0 as-is or implement `ops` traits (`Add`, `Sub`, ...) for references first.
yup-oauth2 is very nice at it also handles refreshing and storing of tokens. But, it seems kind of almost abandoned at this point. There is still some commits sparingly but it still uses these rather old crates: hyper = "0.10.2" hyper-rustls = "0.6.1" rustls = "0.9.0" And upgrading them is a non-trivial, as a dependency on ring means you need to stay on hyper 0.10 as only one version of ring can be linked. I tried doing the update at some point but lost track of it by being stumped somewhere.
Maybe ["unsoundness relating to WF requirements on trait object types"](https://github.com/rust-lang/rust/issues/44454), which appears to be the same as ["object-safe traits can have associated types with unchecked bounds"](https://github.com/rust-lang/rust/issues/27675)? /u/ralfj, any comments on this? Also, curious about what the next steps for the RustBelt project are going to be. Expanding the analysis to cover some of these things listed as not yet covered (atomics, trait objects, automatic destruction, etc), working on the Rust memory model, making it easier to translate from real Rust to Lambda-Rust to be able to expand the number of libraries this analysis can be applied to, or something else?
Could you link me a png of what you think is the best version of it so far? I'll try to just stick that onto the shirts :)
Got tired of recompiling my entire application for small tweaks, so I'm messing around with hotloading: https://gfycat.com/OpulentScratchyEmperorshrimp
But many do, and for those that don't there is softfp.
How would I benchmark three versions of the same function against each other over a set of input sizes using the new API?
[relevent issue](https://github.com/citybound/citybound/issues/209)
AFAIU, async/await is planned/prototyped as thin syntax sugar on top of futures-as-generators implemented as macros. I don't mind as it will not make any fundamental change to the language and so will not close the door for future improvements as the generalized algebraic effects if/when they became available.
Sublime + Rust Enhanced It works quite well, yet it could be a bit user-friendlier. This however is more of a Sublime problem than a plugin problem.
**Awesome** I don't code in Java often, but when I do I really appreciate IntelliJ showing me ways to simplify the code and just fixing it for me with a simple ALT+Enter.
I tried it, but I missed refactoring tools, a good integrated terminal, and type on hover compared to VSCode.
I've used both vim with the rust.vim plugin and Intellij with it's Rust plugin. Intellij has the most complete ide experience I've tried and the best completions but I still prefer vim. I'd recommend trying the setups mentioned on https://areweideyet.com/ and seeing what works best for you. 
Without going into too much detail, at a company I have worked for we were experimenting with using a private proof of stake blockchain. The reason we went with a blockchain implementation instead of a database is because the hope was other companies would utilize the blockchain to store and keep a record of very sensitive financial data (the type of data you probably heard about in a breach last year) and we wanted a consensus protocol to decide what was committed so that control can be shared amongst some chosen members. There are various reasons why we didn't consider a different solution. Ultimately it wasn't made, since the project manager didn't really know what he was building that well, but this is a scenario where a private blockchain (or some other kind of private, yet decentralized) network can be useful.
I was wondering if something like "expression-template" could be leveraged in Rust. The basic idea would be to defer the computation as long as possible, embedding the computation to be as an AST, and then perform high-level optimizations on the AST, for example using FMA instead of multiply-then-add. AKA: Eigen in Rust :)
This RFC has gotten surprisingly little attention from the community, but in the past *many* people have expressed a desire for this change. If you have an opinion here, please jump onto the RFC thread!
I can give a more detailed example when I get home, but the short version is something like this (on mobile, please forgive any compiler errors): ParameterizedBenchmark::new("func1", function_1, &amp;sizes) .with_function("func2", function_2) .with_function("func3", function_3) The functions can of course be lambdas that accept the Bencher and call some timing loop, as usual.
This is something I have personally done a lot, to investigate compiler optimisations. I hope I can help you. First of all, keep in mind that, when optimisations are turned on (release mode), a lot of functions get inlined. Many of your functions (especially smaller ones and ones that only get called from very few places) might not even exist in the final binary, because they would be inlined into all of their call sites. Hence, you might need to disassemble one of the functions that calls your function of interest, instead of the actual function. First, you need to find out the mangled symbol name for the function you care about. To do this, run: `nm target/release/your-binary | grep your_function` to search for a symbol containing the string `your_function` in the binary `target/release/your-binary`. Try your function of interest first. If you cannot find it (i.e it is inlined), try searching for some function that calls it. Due to Rust name mangling, the actual symbol will probably look something like `_ZN5lfsr311print_stats17h57fa88e219ebf599E` (I got this for a function called `print_stats` in a binary crate called `lfsr3`; you can see these strings in there. In your case, it would contain the names of your function and crate.). This is what you should use in the next command bellow. Once you have found out the symbol name of the function you want to view the disassembly of, you can disassemble it using gdb: `gdb -batch -ex 'file target/release/lfsr3' -ex 'disassemble _ZN5lfsr311print_stats17h57fa88e219ebf599E'` gdb will then spit out the disassembly for the function. This is much simpler for C FFI functions marked with the `#[no_mangle]` attribute, since their names wouldn't be mangled and you can just use the actual name of the function, without having to first go through `nm` to search for it. `nm` also has a `--demangle` option, which tries to apply C++ name demangling rules (which Rust's rules are based on) to the symbols. This can make the output more readable, but I have found it to be unreliable (cannot demangle all Rust symbols) and gdb does not seem to always accept the demangled names for the disassemble command. That said, I don't currently have access to the latest version of gdb. Maybe they fixed it. Idk. I have to use the mangled symbols on my system. Good luck with your disassembly explorations!
I had the same experience.
That's a good point. There isn't a lot of space on the small plots in the report for a legend, but I could add some explanation to the end of the file and provide a link to the documentation. In the meantime, if you click on the small plots you can see a larger one with the legend.
Cunning. That would be an ambitious and hopefully very rewarding research project, but I don't think it exists yet.
Please voice this sentiment on the RFC thread, if you could!
The extension of the file can be spoofed, it would be more secure to check the file itself. A quick google search finds this: https://github.com/hyperium/mime
The generator itself is boxed in C++. Here is a talk from Gor Nishanov at [CppCon 2015](https://www.youtube.com/watch?v=_fu0gx-xseY&amp;feature=youtu.be) presenting his work on the topic, and there are [the slides](https://github.com/CppCon/CppCon2015/blob/master/Presentations/C%2B%2B%20Coroutines/C%2B%2B%20Coroutines%20-%20Gor%20Nishanov%20-%20CppCon%202015.pdf). The idea of Gor is: - allocate to make it easy, - let the compiler optimize the allocation out.
Video linked by /u/matthieum: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [CppCon 2015: Gor Nishanov ‚ÄúC++ Coroutines - a negative overhead abstraction"](https://youtube.com/watch?v=_fu0gx-xseY&amp;feature=youtu.be)|CppCon|2015-10-17|0:58:23|252+ (97%)|24,758 &gt; http://www.Cppcon.org ‚Äî Presentation Slides, PDFs, Source... --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/matthieum ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=dts3rue\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v2.0.0
Yes that should have a `where Self: Sized` bound on it.
Probably this will be decided up front, since the args would presumably be part of the trait signature.
No, because generators are all opaque types that don't let you access their internals.
https://github.com/rust-lang/rust/issues/41622
These do radically different things. In the first case, you are consuming the reader by passing by value - it will become owned by your function, nothing in the caller will be able to access it afterwards, and it will be dropped when your function ends unless it's part of the return value. If you write your signature the first way, you can't actually call it with a `&amp;mut reader`, you need ownership of the `reader` in the caller, and also that there's no `&amp;reader` (mut or not) elsewhere. In the second case, you are passing by reference, which means that you do not have to own the reader and once your function ends, the reader will still be around in the same place, albeit possibly with a different value.
Was this posted already?
CLion, since I have a .edu address through work;)
I am deterred, honestly. But I think what needs to happen to fix it is beyond the scope of the project, so hopefully it can still be useful for most use cases. And if it's performance issues that actually can be worked out, and it's just my ignorance, then the community could potentially help out with that as well.
If the choice is between R being a reference type to a concrete reader, and a concrete type itself, I'd definitely go with the latter. As my misunderstanding shows, the former's more confusing than the latter. 
Maybe open a PR on the utility instead? https://gitlab.gnome.org/federico/rsvg-bench
FYI, oauth2 is used by crates.io
By not hard, I mean writing an implementation that is competitive or out-performs LAPACK. This is because the optimizer can figure out the memory access patterns and caching. At these small dimensions, the naive algorithms are probably faster than the fancy ones.
I use Intellij with the Rust plugin. I'm already using Jetbrains IDEs a lot for uni work, so it made sense to stick to that.
IDEA
Ah, I assumed that was a constraint on `Anchor` itself. What if this is combined with: https://docs.rs/stable_deref_trait/1.0.0/stable_deref_trait/ If that trait is pulled into libcore, then the generic implementation would be possible?
I don't know how much you could uee this, but [bytecount](https://github.com/llogiq/bytecount) is very fast at counting byte occurrences in a byte slice, especially for larger slices.
I use sublime + LSP (for rls) right now. It's working nicely.
Oh. Why am I yet not contributing to grin? 
That is awesome! I love the new API. Thank you so much!
Neat! Have you done any profiling to see where the bottle necks are, or if they are in your crate or a dep?
Yes we could add an unsafe trait.
I use VSCode with the official plugin. There have been difficulties in the past, but the plugin and rls have recently become good enough that it mostly 'just works'. The only consideration is that rls isn't on stable yet, and you should check https://rust-lang-nursery.github.io/rust-toolstate/ before updating to make sure your nightly has rls.
&gt; makes the whole API harder to understand Could you clarify this statement? From what POV does it make the API harder to understand? My assumption is that you are coming from a point of view of looking at the trait without any context. The primary issue with a `&amp;mut Context` argument is that in almost *all* implementations of `Future`, you would do nothing with it except pass it along to another function. Libraries like h2 (https://github.com/carllerche/h2) would need to add that `&amp;mut Context` argument to virtually all functions just to pass it along. IMO this is not a trivial loss of ergonomics.
The good news is you can refer to it as `task::Context`, which seems like a fair comprise and doesn't result in redundancy with the namespace and name
[relevant comment](https://github.com/citybound/citybound/issues/204#issuecomment-337619116) For those that don't want to click: separating the actor crates into split repos is considered, but not to publish them on crates.io, as that would imply support for anything but citybound.
That was a nail-biter in the first demo, waiting for all of the automobiles to load, but what a great moment when they did!
I don't know much about licenses, and I put my own crates under MIT because that's what the Rust community seems to consider to be the "good practice". But if I understand correctly, MIT would allow any company to use the source code in their own software without any counterpart (by counterpart I mean giving me or a charity/non-profit of my choice money, or open-sourcing their software for example). Is that right? If so, I don't really like it. I like the idea of sharing, but not much the idea of free labor for coporations. What kind of license defends this position?
True, I was only looking at the trait and thinking about how I'd implement an IO future. I also must admit that I have little experience in implementing futures at all. As I wrote on the RFC thread, perhaps we can have both low- and high-level interfaces with a wrapper type to bridge between them? This would allow both kinds of implementations to coexist and give us the best of both worlds.
Idea with Rust and Toml plugins.
Yeah, the vast majority of the time is in the iterators in `unicode-segmentation`, particularly in iterating over the grapheme clusters. It's made worse by the fact that it's necessary to do these iterations several times over the same line. The lib only exposes its functionality through these iterators, so it's difficult to count, for example, words and grapheme clusters, in a single pass.
I think I understand the strategy. Might be worth investigating how the Julia and Numba JITs optimize these operations. The Julia community in particular has a lot of experience optimizing hot loops in numerical code
On Mac, I use `VSCode + rusty-code` or whatever it's called, but that doesn't work on FreeBSD. On FreeBSD, I use`NeoVim + neomake + nvim-completion-manager + rls` (might change soon, for it's misbehaving) Really want to switch back to intellij-rust if [this](https://github.com/intellij-rust/intellij-rust/issues/2132) ever get fixed. Tired of killing RLS at 9Gb. If it were giving more or less stable results it would be okay-ish, but it doesn't.
&gt; the Eclipse project may make one, it's currently being discussed. Link?
Are you looking for client or server side OAuth? Because I'm trying to develop a pure server side library more extensive than `oauth2`. It has been a bit stale over the course of January but I'm picking it up again by implementing `pkce`, a method of ensuring the identity of public clients. It's called [oxide-auth](https://crates.io/crates/oxide-auth), any feedback welcome.
Cretonne! It's nearly there!
I cede my argument.
I'm not sure if it actually counts as an IDE, but Emacs + rust-mode + a tty for cargo &amp; gdb for me.
I've also noticed `wc` and `uwc` have differnt definitions of "words" (IMO `uwc` is correct, whereas `wc` uses a naive solution). $ cat rustfmt.toml format_strings = false chain_overflow_last = false same_line_if_else = true fn_single_line = true $ wc rustfmt.toml 4 12 98 rustfmt.toml $ uwc rustfmt.toml lines words bytes filename 4 8 98 rustfmt.toml Notice `wc` counts `=` as a word.
From Julia's [https://docs.julialang.org/en/stable/stdlib/linalg/](linear algebra documentation): "Linear algebra functions in Julia are largely implemented by calling functions from LAPACK." Scipy, which Numba bundles, is also just wrappers around ancient, battle-tested linear algebra codes. (Just like Matlab!) All the JIT-ing in the world is still going to run into the hard limits that existing implementations have mostly reached -- very little point in rewriting everything in Julia. Or rather, a somewhat depressing observation: we can't beat existing single core algorithms by being more clever. Another even more depressing claim, but at least possibly wrong: we can't beat existing multi-threaded implementations (multiple cores, but same discrete node). Even pre-existing codes that scale across clusters with MPI are fairly mature and well-optimized. Projects like libflame more or less just make it easier to achieve state-of-the-art and reduce the burden of maintenance when new CPU's come out. Where you might be able to meaningfully beat state-of-the-art is on heterogeneous compute nodes, but even there Intel has full-time employees on MKL and nVidia on cublas, precisely because numerical linear algebra is so fundamental to all of scientific computing. What's interesting is their efforts, just like traditional BLAS and LAPACK implementations, are language-agnostic -- as long as your favorite language has a C FFI, you'll be able to use their super-optimized linear algebra primitives. I remember the first-time I took my single-threaded BLAS code and recompiled it with AMD's (now-defunct) multi-threaded acml library and, changing nothing at all in my Fortran, and got 100% utilization across all 8 cores! I also remember recompiling it against their clBLAS library, and again changing nothing at all, got to start heating up my GPUs. Empirically, it seems the separate, black-box linear algebra implementation is the correct abstraction, even if it remains fun to think about rewriting it in Rust, Julia, whatever.
Well, at least on my computer, it doesn't underline errors or warnings.
&gt; That could either mean compiling the worker nodes statically with those dependencies or having the worker nodes pull the crates from a repo and dynamically loading them. Why not just make the tasks into self-contained binaries that statically bundle all their dependencies and custom code? Tying custom code to infrastructure like that is just going to create difficulties for users: "All I wanted to do is run a little bit of custom code, and now I have to ask the infrastructure team to deploy this crate to all nodes/set up a repo that all the worker nodes can access!" It doesn't have to be a binary, it could be an archive that contains multiple binaries and linked libraries, but there should be one artifact that is "the job." More generally, I'd argue in favor of putting as much of the functionality of the system not into worker daemons that run at the nodes, but rather into libraries that user's applications embed independently. I've had too many situations that go something like "Joe wants to use a Hadoop 2.7.x feature in his MapReduce job but our cluster is still on 2.5.x."
I use Atom with these plugins (`apm list | grep rust | grep -v disabled`): ‚îú‚îÄ‚îÄ language-rust@0.4.12 ‚îú‚îÄ‚îÄ linter-rust@0.8.4 ‚îú‚îÄ‚îÄ rustsym@0.4.1 It works reasonably well, although I would rather be using emacs.
Yup, I totally agree with `TaskContext`, which is why it's in the `task` module. This allows you to use it like `task::Context` but will also allow for shorter function signatures in areas where it's prevalent without users having to introduce their own ad-hoc aliases.
Have you tried it in the past few days? There was a bug that was preventing RLS from working on my machine that was recently fixed. I agree though, the flakiness of RLS is very discouraging, especially considering the deficiency in IntelliJ plugin.
Yup! During this project, I've been finding lots of these weird cases where `wc` isn't quite right, particularly odd cases like NFC vs. NFD. ``` ‚ûú uwc git:(develop) ‚úó cat tests/fixtures/i_can_eat_glass_multi/input_vietnamese_nfc T√¥i c√≥ th·ªÉ ƒÉn th·ªßy tinh m√† kh√¥ng h·∫°i g√¨. ‚ûú uwc git:(develop) ‚úó wc -m tests/fixtures/i_can_eat_glass_multi/input_vietnamese_nfc 41 tests/fixtures/i_can_eat_glass_multi/input_vietnamese_nfc ‚ûú uwc git:(develop) ‚úó uwc -c tests/fixtures/i_can_eat_glass_multi/input_vietnamese_nfc graphemes filename 41 tests/fixtures/i_can_eat_glass_multi/input_vietnamese_nfc ‚ûú uwc git:(develop) ‚úó ‚ûú uwc git:(develop) ‚úó ‚ûú uwc git:(develop) ‚úó cat tests/fixtures/i_can_eat_glass_multi/input_vietnamese_nfd ToÃÇi coÃÅ theÃÇÃâ aÃÜn thuÃây tinh maÃÄ khoÃÇng haÃ£i giÃÄ. ‚ûú uwc git:(develop) ‚úó wc -m tests/fixtures/i_can_eat_glass_multi/input_vietnamese_nfd 51 tests/fixtures/i_can_eat_glass_multi/input_vietnamese_nfd ‚ûú uwc git:(develop) ‚úó uwc -c tests/fixtures/i_can_eat_glass_multi/input_vietnamese_nfd graphemes filename 41 tests/fixtures/i_can_eat_glass_multi/input_vietnamese_nfd ``` This case could just be a matter of semantics, though. I'm going to guess that `wc` is defining "character" as "unicode code point."
Very cool that they are about to change their name.
I think it was. Definitely one of highlights I'd select from that RustFest.
&gt; I like the idea of sharing, but not much the idea of free labor for coporations. We all benefit from an open source ecosystem. The time saved by others by being able to use your code leaves them more time to write other code, some of which they themselves might or might not choose to share back with the community. That's my view on it anyhow.
Works for me! Here are some things to troubleshoot: 1. Are you using the official plugin `rust-lang.rust`? 2. Are you using a recent nightly with the `rls-preview` component enabled? 3. Do you have any preferences that change what channel or rls the plugin uses? Otherwise... it'll get fixed eventually, I'm sure ¬Ø\\\_(„ÉÑ)_/¬Ø