As u/lelarentaka mentioned however, the filter method is directly on Scalaâ€™s Option class. Actually, itâ€™s really nice in Scala to think of Options as single-element collections. 
We're basically drama free at this point. We have a lot more focus on what provides a great user experience, for both buyers and sellers, and it's really paying off :)
It's on the road map. One of the short term goals is actually building out a JVM integration over the JNI such that we can embed it directly into the language.
The child process would still be running safe Rust code, and it would have undefined behavior through potentially corrupted values. The parent would be fine, but that's not enough.
I'm trying to write a scanner with the following code: use std::str::Chars; mod token; pub struct Scanner &lt;'a&gt; { chars: &amp;'a mut Chars&lt;'a&gt;, } impl&lt;'a&gt; Scanner &lt;'a&gt; { pub fn next(&amp;self) -&gt; token::Token { let (literal, t) = match self.chars.next() { Some('+') =&gt; { (String::from("+"), token::Type::Plus) } ... snip ... }; let literal = &amp;literal; token::Token{ literal, t, location: token::Location{ line: 1, column: 1, } } } } Where _Token_ is defined like: #[derive(Debug)] pub struct Location { pub line: usize, pub column: usize, } #[derive(Debug)] pub struct Token &lt;'a&gt; { pub t: Type, pub literal: &amp;'a String, pub location: Location, } However, when I try to compile this, it tells me on the line _match self.chars.next()_ I'm assigning into an immutable reference, and on the line _let literal = &amp;literal_ that _&amp;literal_ doesn't live long enough. Any ideas?
[The RFC was already written](https://github.com/rust-lang/rfcs/blob/master/text/1937-ques-in-main.md), [discussed](https://github.com/rust-lang/rfcs/pull/1937) and [accepted](https://github.com/rust-lang/rust/issues/43301). It's more robust than /u/Furyhunter describes - it changes `main`'s signature to return a type which implements the `Termination` trait. This includes `()` (for backwards compatibility), `!` (so programs which run forever are more self-documenting) and `Result&lt;T, E&gt;` where T implements `Termination` and E implements `Display` (to make `?` work).
I'd like to know if my repo/docs/readme is set up correctly. I hate having yo publish a new version because I forgot `.md` in my readme, or messed up some links. There's probably a way to do that now, but if a tool could tell me that links were broken or files not found, that would be great.
&gt; Never type implements all traits No it does not, [rfc 1637](https://github.com/rust-lang/rfcs/pull/1637) was closed.
Tokens can be invalidated. But binary files continue to add to bloat no matter what and make mirroring crates.io harder. So checking for binary files would be a great thing.
This is a great idea, thank you for making it! It's wonderful to have a pre-flight checker to prevent committing things like private keys. Catch things before they are published, which I refer to as a leading check. Does anyone know of plans for crates.io do to trailing checks? EG: every time a crate is published, check it for various API keys that may be checked in and email the package owner. AWS does this with the GitHub activity firehose (or via [GitHub Archive](https://www.githubarchive.org/), I am under the impression the firehose has been deprecated): if someone checks their AWS keys into a public GitHub repo, AWS sends the account owner an email.
Files that are beyond a configured size are reported, so are packages that are beyond such a size. Anything that is not UTF-8 is reported as such - this is a bit harsh, yet the reality on crates.io is that files are either text (then they are utf-8) or binary (then they are not).
That would make implementing e.g. `Clone` for some struct inside a library crate a breaking change.
AWS, SSH and RSA keys are detected and reported, so are common private key chains (think `id_rsa`).
I lost count of how many times in my career I've answered my own questions and the questions of others by reading the source.
While `chars` is a mutable reference, `self` is an immutable one, so you're trying to mutate `self.chars` through an immutable reference, which is disallowed. You'll need to have `fn next(&amp;mut self)` or use one of the `Cell` types which enable mutating through an immutable reference.
yep, Scala still doesn't allow you to have fine-grained control of memory in this situation, nor does it support the affine types concept of `into_iter`, which are the two types of additional control being granted here, neither of which are as useful when dealing with an integer as they can be with larger objects. Which is not to say that one approach is universally better than the other, of course. Someone writing Python code is usually very happy not to have to make decisions of such a fine-grained, low level nature, and I would imagine Scala users feel similarly.
I agree with you on the bors image. There is a difference between pixelated art, and low res images: https://duckduckgo.com/?q=pixelated+art&amp;t=ffab&amp;iax=images&amp;ia=images It could still be intentional though.
I'm actually the one who gave Bors its current avatar (also [rust-highfive](https://github.com/rust-highfive))! Here's the story as I remember it: in the long-long-ago, Rust was young and Bors--at the time, its only bot--was without an avatar. I remedied this with a lovely full-size image of the Rust logo superimposed on HAL 9000's eye. However, Github's avatar support at the time completely sucked. I forget if they were outsourcing this to Gravatar back then, but their downscaling was just dreadful and the resulting tiny-scale logo was unrecognizable. Given that Bors' avatar is seen far more often in tiny form (in commit/merge bylines on PRs) than in large form (on its profile page), I replaced it with a low-resolution version of the avatar that was optimized for the former. And it looked great! ...For a while, anyway, until Github slightly increased the avatar resolution used beside one's name in pull requests (from something like 32x32 to 40x40), making it look a bit blurry. And *then* we rewrote Bors to now leave comments on pull requests, which uses an 88x88 version of the avatar, which I had not anticipated. :P I could probably dig up the old full-size logo and ask whoever's wrangling the bots these days to update it... if people aren't too attached to the retro-pixel look, that is. :)
You're on the stable toolchain. Try switching to nightly.
 rustup install nightly &amp;&amp; rustup default nightly Anything marked as `#![feature(...)]` requires the nightly version of the compiler.
Doing it right now :\ Lets hope all goes well...
Doing it as you said this... pls help me if it doesnt work T_T
This project transitively depends on `rust-phf`, which can only be built with a nightly version of rust. So you'll need to use nightly: `cargo +nightly build`
The error is that you are running a stable release of the compiler, but in your code you are trying to use an unstable feature, which only works on the nightly releases of the compiler. If it's truly urgent, then the expedient fix is to use the nightly release to compile this code (if you're using rustup, run `rustup install nightly &amp;&amp; rustup default nightly`to get it and have Cargo use nightly). But in the long run, if you intend to maintain this project for a long time, then you probably want to avoid using unstable features so that you can compile with the stable release. (However, if this code isn't intended to be used long-term, then it may not particularly matter.)
New strange errors: error[E0061]: this function takes 3 parameters but 2 parameters were supplied --&gt; /home/hcking/.cargo/registry/src/github.com-1ecc6299db9ec823/regex_macros-0.2.0/src/lib.rs:487:21 | 487 | quote_expr!(self.cx, $start), quote_expr!(self.cx, $end))); | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected 3 parameters error[E0063]: missing field `beginning_vert` in initializer of `syntax::ast::Arm` --&gt; /home/hcking/.cargo/registry/src/github.com-1ecc6299db9ec823/regex_macros-0.2.0/src/lib.rs:542:9 | 542 | ast::Arm { | ^^^^^^^^ missing `beginning_vert` error: aborting due to 2 previous errors error: Could not compile `regex_macros`. warning: build failed, waiting for other jobs to finish... error: build failed 
New strange errors: error[E0061]: this function takes 3 parameters but 2 parameters were supplied --&gt; /home/hcking/.cargo/registry/src/github.com-1ecc6299db9ec823/regex_macros-0.2.0/src/lib.rs:487:21 | 487 | quote_expr!(self.cx, $start), quote_expr!(self.cx, $end))); | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected 3 parameters error[E0063]: missing field `beginning_vert` in initializer of `syntax::ast::Arm` --&gt; /home/hcking/.cargo/registry/src/github.com-1ecc6299db9ec823/regex_macros-0.2.0/src/lib.rs:542:9 | 542 | ast::Arm { | ^^^^^^^^ missing `beginning_vert` error: aborting due to 2 previous errors error: Could not compile `regex_macros`. warning: build failed, waiting for other jobs to finish... error: build failed 
I did that, strange errors came now: error[E0061]: this function takes 3 parameters but 2 parameters were supplied --&gt; /home/hcking/.cargo/registry/src/github.com-1ecc6299db9ec823/regex_macros-0.2.0/src/lib.rs:487:21 | 487 | quote_expr!(self.cx, $start), quote_expr!(self.cx, $end))); | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected 3 parameters error[E0063]: missing field `beginning_vert` in initializer of `syntax::ast::Arm` --&gt; /home/hcking/.cargo/registry/src/github.com-1ecc6299db9ec823/regex_macros-0.2.0/src/lib.rs:542:9 | 542 | ast::Arm { | ^^^^^^^^ missing `beginning_vert` error: aborting due to 2 previous errors error: Could not compile `regex_macros`. warning: build failed, waiting for other jobs to finish... error: build failed 
From the documentation for regex_macros: &gt; An implementation of statically compiled regular expressions for Rust. Unless you specifically need compile time regular expressions or a matching engine that is guaranteed not to allocate, you should temporarily prefer using the plain regex crate (since it is almost always faster). Is there a reason you can't simply use the regex crate?
I dont know, but some kind of issue is creeping up. And at this momenet, especially post midnight, i dont like it.
Also don't forget that a slice is 2 pointers, which is quite larger than a few utf8 chars. The borrowed type maybe a mistake here.
Well, the issue is that something in regex_macros no longer works with the latest nightly (that's why nightly features are considered unstable). If you aren't using regex_macros directly, try using 'cargo tree' to determine which dependency is, and potentially remove it. Or, if you are directly using regex_macros, don't, and use regular regex. Alternatively, you may have luck rolling back to another nightly version ie: going back a month and trying that nightly version. Based on your project it looks like you're relying on regex_macros in your spell_core crate. It doesn't actually look like you need to at all - simply remove the 'regex_macros' dependency sa you don't actually seem to utilize the feature.
Im trying to roll back to Oct '15 nightly, will tell. Hope everything goes okay. I just want the damn working code for tomorrow.
Yeah, I think the easiest solution is to honestly just delete the line of code that mentions the feature and remove the dependency. I don't see the feature used anywhere.
`Option` can be considered a single-element collection in Rust as well, which is why `.iter()` is defined on it in the first place. The difference is that Rust historically prefers to define iterator adaptors as methods on iterators rather than as methods on collections.
Maybe. Although by using Rust as the language to describe the rules, we can leverage existing tools. For example of you edit the rules file in an IDE, it can type check the rule. Also, by using Rust, Rerast can make lots of use of the Rust compiler and doesn't have to reimplemented lots of stuff.
What was the drama?
Big layoffs back in June: https://techcrunch.com/2017/06/21/etsy-will-cut-15-percent-of-its-workforce-in-a-new-round-of-layoffs/
It's worth mentioning that this tool doesn't actually transform the HIR. It matches HIR, then transforms source code by making use of the spans on the HIR nodes. If it tried to transform then pretty print the HIR, all sorts of stuff would be lost, like comments, formatting, macros etc.
Cool! I might try automating my weekly nags...
The main things Rerast needs are a way to "inject" the rules into the crate being transformed, then get access to the resulting HIR. The rules could maybe be compiled as a separate crate, but then they wouldn't be able to refer to private items in the crate which would be a shame.
It sounds like you might be checking for this already, but it's really important that .env files aren't committed since that's usually where API keys and stuff go. 
I really dont know what to do at this point... I'm trying... But I picked up this project in Rust and I've yet to fully learn Rust...
Oh, this is news to me. Thanks.
OK I think that you're going to run into a lot of compiler errors unrelated to the original one. However, I've solved your nightly issue by doing what I'd suggested earlier - I removed 'regex_macros = "*"' from Cargo.toml I removed the first two lines of lib.rs: #![feature(plugin)] #![plugin(regex_macros)] From here on out the errors are that you call methods on types where the methods don't appear to exist. The first was 'cap.at(0).expect(...)' I replaced that with '&amp;cap[0]'. Then I get compiler errors like syntax errors: error[E0615]: attempted to take value of method `path` on type `iron::Url` --&gt; src/main.rs:13:60 | 13 | println!("Running ping handler, URL path: {}", req.url.path.join("/")); | ^^^^ | = help: maybe a `()` to call it is missing? I think maybe you can handle it from here?
I would definitely prefer a high(er) resolution image for rfcbot. I do get the appeal of the pixelated bors image, but would probably prefer a high-res one there as well.
Which date is your nightly version?
With my changes I don't believe nightly is necessary. I get the same errors on stable as I do on nightly. That said my nightly version is: cargo 0.24.0-nightly (e5562ddb0 2017-10-26) But, again, this shouldn't be necessary as I've removed the only features that relied on nightly (the regex-macros crate and the two lines in lib.rs)
I'd go with `Vec&lt;String&gt;` without blinking. The implementation will be much easier to write and unserstand. Unless you plan to instantiate millions of `Generator` values at once, the performance should be fine. The standard library uses `Vec` and `String` in many places.
Also just released on Youtube: [RustFest ZÃ¼rich 2017 - Impractical Macros by Alex Burka](https://www.youtube.com/watch?v=ApOUBBOvZDo&amp;index=4&amp;list=PL85XCvVPmGQj9mqbJizw-zi-EhcpS5jTP)
I've reached a new zenith of errors... hcking@hcking-ThinkPad-L470:~/projects/spellcorrector-master$ cargo build Compiling spell_corrector v0.0.1 (file:///home/hcking/projects/spellcorrector-master) error[E0615]: attempted to take value of method `path` on type `iron::Url` --&gt; src/main.rs:13:60 | 13 | println!("Running ping handler, URL path: {}", req.url.path.join("/")); | ^^^^ | = help: maybe a `()` to call it is missing? error[E0061]: this function takes 3 parameters but 2 parameters were supplied --&gt; src/main.rs:28:16 | 28 | router.get("/ping", say_pong); | ^^^^^^^^^^^^^^^^^ expected 3 parameters error[E0061]: this function takes 3 parameters but 2 parameters were supplied --&gt; src/main.rs:29:17 | 29 | router.post("/correct", | ^^^^^^^^^^ expected 3 parameters error[E0277]: the trait bound `for&lt;'r, 's, 't0&gt; router::Router: std::ops::Fn&lt;(&amp;'r mut iron::Request&lt;'s, 't0&gt;,)&gt;` is not satisfied --&gt; src/main.rs:33:5 | 33 | Iron::new(router).http("127.0.0.1:3000").unwrap(); | ^^^^^^^^^ the trait `for&lt;'r, 's, 't0&gt; std::ops::Fn&lt;(&amp;'r mut iron::Request&lt;'s, 't0&gt;,)&gt;` is not implemented for `router::Router` | = note: required because of the requirements on the impl of `iron::Handler` for `router::Router` = note: required by `&lt;iron::Iron&lt;H&gt;&gt;::new` error[E0599]: no method named `http` found for type `iron::Iron&lt;router::Router&gt;` in the current scope --&gt; src/main.rs:33:23 | 33 | Iron::new(router).http("127.0.0.1:3000").unwrap(); | ^^^^ | = note: the method `http` exists but the following trait bounds were not satisfied: `router::Router : iron::Handler` error: aborting due to 5 previous errors error: Could not compile `spell_corrector`. 
Yes, these seem more standard. For these errors I'd suggest trying the suggestions in the errors. For example the 'path' error it look slike you just want to add () to 'path' ex: '.path()'. For the rest I'd try IRC if you can't figure them out. Most of these errors look pretty simple - you aren't passing enough parameters, so check the documentation for those functions/ methods and look at what parameter is missing.
The previous one was simpler with () for path. Then I come to Iron framework... I'm trying using tjis (https://github.com/iron/router) documentation... and call me dumb but these errors are really stupid and I'm going crazy trying to understand thhem. At tis point I just feel like sleeping away.... 
Here it took C++ like 2 decades to get a Turing complete macro system, and Rust has had it since day 1.
Oh man that would be so cool! I hope to get it mature enough for stuff like that soon! (I'll need to add support for stickying things.)
You're definitely allowed to have an opinion! Nothing prevents you from filling out whichever answers you want to. I would be happy to receive submissions that answered all the questions but also indicated that they don't use Haskell anymore (or ever). 
Thanks for the feedback! Every question is optional, so you can answer only the ones you have an opinion about. If you have any suggestions for questions you would have liked to see, I'm all ears! 
Nothing prevents you, but the survey specifically says to skip over them.
That's true. It's meant to be a suggestion, but it's not worded as such. The intent is to avoid wasting people's time by forcing them to scroll through a bunch of irrelevant questions. 
it would be a tradeoff. In this scenario, you required functionality in the crate that wasn't available. You have no choice but to enter debate with that crates community.
I always screw up the symver on dependent packages. Could you check that?
I should care why?
I read that as izma compress (with a capital i), which made me think of this: http://1.bp.blogspot.com/-MShRkDYCdwM/TXJU-ag3gTI/AAAAAAAABmQ/R5jeYSh-noU/s1600/yzma_by_senoremi-d312koq.jpg
Basically OP, if you want a less-verbose language that compiles to safe native code with extremely easy C interop and has a *relatively*-nice type system, look at D. It doesn't have linear types and uses a GC, but besides that it fits in a lot of the same places that Java does.
100% the wrong attitude to have.
So happy to see Jorge Aparicio talking about his work with Rust in the embedded world. I absolutely believe this is a game changer for IoT in every dimension.
/u/acratchett's video explaining how futures work was very informative, so as not to be too afraid to try them if I have an opportunity to try.
...ever tried [structopt](https://GitHub.com/texitoi/structopt)? :P
Nope, hadn't heard of it until now. Looks neat but I'm not sure how much it would have helped me since my arguments are just strings. I could have used serede for parsing the key value file though
It'd do what clap is doing for you now, but reduced boilerplate code, and a little cleaner since it does all the args parsing stuff for you! :D
ALL HAIL THE TURBOFISH.
Well languages that aren't statically typed aren't *real* languages.
It's not bad. You just need to be aware of what the trade-offs are. What's bad are people using `Box&lt;Trait&gt;` to try and write C#/Java code in Rust. It's a tool, not a cudgel.
wonderful work.
https://github.com/ggez/ggez/blob/master/RELEASE_PROCEDURES.md is my reference list. Checking for API keys and such is a great idea, though not applicable for that particular problem.
What do you mean by "carry around all that extra type information"?
 struct MyStruct&lt;T&gt; where T: MyTrait { foo: i32, bar: T } fn myFunc(something: MyStruct&lt;T&gt;) { ... } Having to write `&lt;T&gt;` and such everywhere, mainly. It gets excessive once you have more values.
You need to calm down... The compiler tells you everything error[E0061]: this function takes 3 parameters but 2 parameters were supplied After reading the example from your link, it is obvious you missed the last argument in `router.get` function... router.get("/", handler, "index"); I believe the following error is caused by this error.
Ermergherd, someone did a presentation on ggez. Someone I don't even know(?)! And she did a kickass job! Yes, ggez 0.4 will break everything... but mostly in small ways, I promise! Honest. (I should get my butt in gear to work on that... these things won't break themselves!) Also ye gods yes, live coding is hard as heck. I did a little bit in my Toronto talk and it was way more difficult than I expected. Oh, she says "it just works" at one point. The highest praise a library writer can hear...
`lazy_static! { static ref MyThing: Arc&lt;Mutex&lt;YourType&gt;&gt; = Arc::new(Mutex::new(YourType::default())); }` If you use `lazy_static` crate.
No. `Box&lt;Trait&gt;` is just like Java's `Interface` it is a good way to separate a contract from an implementation. Also `Arc&lt;Trait&gt;` is nice if you want to move/clone the `""Interface""` around. 
Keep in mind that `Box&lt;Trait&gt;` allows using `&amp;mut` methods whereas `Arc&lt;Trait&gt;` requires a ref count of 1 to do so.
I changed the router and iron versions and everything works fine.
Why does this need to be an Arc?
I gonna admit that I tried to read that codes, and my brain is fucked... 
I consider it preferable to try your hardest to design around needing this, as the performance costs can be harsh if this is used very frequently. That being said, sometimes it really just is the right tool for the job. One good example of this is when you have to provide arbitrary closures to be stored in a data structure. There just isn't a better way to do that.
I don't think you understand the scope of the problem here. The unsafety is not in the parent but in the child, the child is saved. The problem is generated by an awkward combination in POSIX of multi-threaded proceseses and forks; essentially if you fork a multi-threaded processes only the thread that calls fork gets copied into the new process. Copying all-threads is possible on some Unixen via some nonportable extensions but this approach has its own problems. This results into the situation that if you fork at the moment a mutex is held by another thread that mutex wil never be released in the child process because the other thread does not exist in the child process to release it. To deal with this POSIX specifies in its libc spec that certain functions must be "async-safe"; this is a really fancy definition for what in practice means "do not use mutexes and rely on the kernel to do them atomically". The result is that POSIX says that calling any function that is _not_ async safe after a fork from a multithreaded program is "undefined behaviour" because it likes to throw that strong word around very liberally towards anything you just shouldn't do. In practice in (virtually) all implementations the behaviour is "may lock up because you're waiting on a mutex that will never be released". But the point is that because POSIX says undefined behaviour then conformant implementations are indeed permitted to generate ridiculous memory errors in this case. malloc is one of those functions which is not async safe. In theory malloc is free to assume that calling it after a fork from a multi-threaded program will never happen and not validate for that and when it happens return something like a pointer to memory that the process is not permitted to write to or just hand it to other processes before it is freed. As such in theory before_exec is unsafe and the unsafety manifests in the child process onlyâ€”in practice though all it does is potentially deadlock.
I don't think it has to be one. The `Mutex` would have a `'static` lifetime anyway, so it's useless indirection.
You don't need to put `#[inline(always)]` in your trait definition like you do [here](https://github.com/AdamNiederer/faster/blob/master/src/intrin.rs#L12-L33). The inlining only matters where the trait functions are being implemented.
Hi guys! I've been posting about Indigo in the "What are you working on this week" threads for a few weeks now. This is my take on a UI framework in Rust. I've been hacking away at this for a while now and after some gentle prodding by others, I took the step of open sourcing my work so far. It is highly experimental, incomplete, and intended to foster a discusion around potential approaches to designing a UI framework in Rust. I'd love to hear what you all think of it :).
This is simultaneously horrific and beautiful. I love it!
Posting this to gauge interest. Examples are in main.rs. This project has existed for less than 24 hours so it's a little light on documentation and style at the moment, but I'm super excited with how pretty I was able to get it in so little time! 
Maybe your firewall is blocking it?
You might enjoy Rossberg et. al.'s work on [1ML](https://people.mpi-sws.org/~rossberg/1ml/), a variation on ML that unifies the "core" with the module system, and has some very well-thought-out handling of the use cases of type classes. You may also find Wadler's [Implicit Calculus](http://homepages.inf.ed.ac.uk/wadler/topics/type-classes.html#implicits) useful - not just for what it directly describes the design of (though that is very relevant), but also for its explanation of how it compares to type classes. Another nice feature of implicits, (which 1ML also uses) is that you can start with a simple "explicit dictionary passing" approach, and then add implicits. This may help make the steps of the implementation process simpler and more evident.
Sheesh!
Shouldn't rustc warn about that?
I think something like this will work for me, but I was hoping maybe there was something like ONCE_INIT and I was just too dumb to see it. Should I put an issue against the std::Sync::Mutex documentation in this case?
Why not just use '/' in path configs everywhere? It worked for me so far. So if `path` is "foo/bar", why not just do `Path::new(path)`? It works on all platforms, doesn't it? &gt; Character restrictions are still a problem. At some point we might want to incorporate replacement procedures, or APIs that return Resultâ€™s to flag for non-portable characters. Yes, I think that would be very useful. I've found myself writing code that replaces invalid (Windows) path chars when saving files to disk...
Looks fantastic. It may be worth mentioning to people that `splat()` is transforming a scalar to a vector-ish variable. On second thoughts, I guess that's probably obvious to people playing with SIMD code. Do you need to explicitly enable any target features in Cargo.toml in downstream code for the faster crate to work, or will it "just work"?
I don't know much about simd but I keep reading that the benches from thebenchmarkgame are missing simd support to be on par with c/c++. Would it be possible to show how faster would help?
Nice work /u/ncarrillo. I recommend adding some indications about which targets are known to work out of the box. Even though it's alpha software, it might still be good to know what people should expect.
OK I managed to find the commit that removed these things and the comment itself says to use the lazy_static crate. Thank you for the help!
It would make them... ... faster
`type SpecializedStruct = MyStruct&lt;T, U, V&gt;;` with T, U and V replaced with concrete types can sometimes help to reduce with type noise
I encourage you to make a PR for the docs. Surely you won't be the last person to wonder this if it's left as is.
Simd lets you perform certain small batch operations in parallel across 128-bit (or larger) registers. It's used differently than how you'd use normal 64-bit registers.
Or there should be a clippy lint.
Adding to this, you may want to also have tests that are automated with Travis CI or another service.
Not sure checking for bad characters is enough. Windows paths are a trash fire. For example, you can't have a file named "NUL" because of compatibility with a version of DOS that was so old that it didn't support directories. 
I feel like using Box&lt;Trait&gt; ought to be more common than it is in idiomatic rust, tbh. In some situations, the miniscule perf penalty may even be outweighed by the reduced code bloat anyway. I reckon you should use it wherever it makes sense, and don't worry about the perf until the profiler tells you you have to
What do you mean?
Yes - find any place where you have many primitives of the same type having the same operation applied to them. For example, if you had a for-loop that was iterating through an array of u32's and incrementing each by 1, you could rewrite this as a 256-bit SIMD operation by packing 8 x u32 in that register, and then another 256-bit SIMD value but with each of the packed u32's having the value of 1. When you perform addition between these two 256-bit-wide values, it will effectively perform 8x that operation simultaneously, in a single instruction.
Looks really cool. The name seems a bit too general, though.
Was very close to submitting my first bug report to Rust, but thankfully clippy saved me from embarrasing myself. So thanks to /u/llogiq and everyone who has submitted lints. For the curious, I ["discovered" some code](https://play.rust-lang.org/?gist=e5d369eb00c642162563791d3741b229&amp;version=stable) that produced the following weird result: -1^0 = -1 -1^0 = 1 -1^0 = -1 -1^0 = 1 Turns out though, Rust isn't broken. And now I'll be running clippy pretty much constantly. Thanks again :)
What license do you intend to use? I saw AGPL-3.0 listed in Cargo.toml, but I'm not sure that's intentional, seeing that there is no license file and the source files have no license headers. Whatever license you choose, I don't think a field in Cargo.toml is sufficient, and you should really include a license file. And if you intend to use the AGPL or any *GPL, you should include the comment headers in all source files as well.
it really seems to me that Vec and String are infinitely more useful when raw performance isn't a concern
I'm getting a lot of conflicting advice
What did clippy say?
Looks neat. I will need to use simd instructions for optimising rendering/game code soon, and this seems a lot more friendly than other simd approaches. It would be great if this was licensed under a permissive license (e.g., MIT, BSD, Apache 2.0) to ease integration into applications.
It's your package, your law, but... Please don't use (A)GPL, it will limits the use of your library and encourage a concurrent solution to emerge, thus fragmenting the rust numerical community.
It is possible to use it with Rayon? I would love to have automatic SIMD + automatic parallel computations
Wait, is everything in the git repository packaged and uploaded? Even if the code doesn't touch it?
It's possible to recreate the original by clicking "Clippy" in the playground link, but this error message is what was produced: help: consider adding parentheses to clarify your intent: `-(1.0_f32.powf(0.0))` 
FWIW, indigo builds on Windows just fine
This might be a silly question - does the compiler perform no SIMD optimisation? New Rust user so forgive me for my lack of knowledge.
This one was not specific to Rust. In C you also would just duplicate a few chars instead of pointing to them. I guess.
It is.
Interesting, thank you for the information! :) I'd prefer the high-res avatar over the pixelated one. I think neither Rust nor HAL 9000 are somehow connected to "pixel art", so it's not really fitting. But then again, HAL might not be perfectly fitting to the bot itself (in particular because the name "bors" come from another universe). I thought about something: maybe we can have an avatar contest for the two bot accounts. I'm sure there are plenty of awesome artists in the Rust community. Right now I'm dreaming about two nice characters in the style of [the Ferris on the new book](http://www.rustacean.net/more-crabby-things/dancing-ferris.gif). The grumpy, but still nice bors, and the super enthusiastic highfive \^_^ I think I will open an issue on the rfcs repo (or somewhere else?) to discuss this with some of the people in charge. A small reddit thread is probably not the best place :P
This looks great so far! SIMD seems a little lacking in Rust currently, which is unfortunate. The crates with SIMD have a decent amount of operations, but are lacking in a few essential ones. Specifically, operations concerning the entire vector, such as BSF (Counting the number of trailing zeros) or LSB (Least Significant bit of a vector). Adding some of those operations that the `simd` crate doesn't have could make this library very appealing! At least for my personal use-case :)
At the very least! Not just that `#[inline(always)]` doesn't have an effect on trait functions but that it should be moved to the impl's functions.
on the other hand, please use (A)GPL, because it guarantees that the contributions you make in your free time for a good cause are never stolen by greedy people just trying to make money of off your work.
While not really Turing complete, a functional Brainfuck interpreter can be implemented with the C preprocessor: https://github.com/orangeduck/CPP_COMPLETE Also, a similar thing can be implemented with templates: https://github.com/knome/metabrainfuck/blob/master/bf.cpp While C++11 provides variadics, in C++03 it is possible to simulate that up to a certain amount. With C++14, you can *compile* Brainfuck at compile-time! https://gist.github.com/bolero-MURAKAMI/7af16aced449acfe4090
Oh, that's the error. Being able to use methods on numbers can be a bit tricky.
I did this (it doesn't check for names like "NUL", "CON" or "PRN" though): // make it a valid windows file name let filename = filename.replace(&amp;(0u8..31).map(|i| i as char).chain(r#""*/:&lt;&gt;?\|"#.chars()).collect::&lt;Vec&lt;_&gt;&gt;()[..], "_");
[I see what you did there](https://github.com/mleise/fast). 
If i've understood correctly, contrast the implementation with ownership, where a factory method can easily return a value: #[derive(Debug)] struct Bar(usize); #[derive(Debug)] struct Foo(Vec&lt;Bar&gt;); fn pair_foo(first: usize, second: usize) -&gt; Foo { Foo(vec![Bar(first), Bar(second)]) } pub fn main() { println!("{:?}", pair_foo(17, 23)); } To the implementation with borrowing, where it can't: #[derive(Debug)] struct Bar(usize); #[derive(Debug)] struct Foo&lt;'a&gt;(&amp;'a [Bar]); fn pair_foo&lt;'a&gt;(first: usize, second: usize) -&gt; Foo&lt;'a&gt; { Foo(&amp;[Bar(first), Bar(second)]) // error[E0597]: borrowed value does not live long enough } pub fn main() { println!("{:?}", pair_foo(17, 23)); } For this to work, the factory method pair_foo would have to receive a reference to the already-constructed vector, making it pointless.
I'm working on a patch for Rust's libtest that will add JSON output for easier machine parsing. So far I've managed to refactor the lib in order to enable this, all that's left is to actually use serde, and make sure I haven't caused any regression.
Is Rust being used here because it has particular strengths? Or is Rust playing the classic role of an obscure but cool language that lets you attract better people than you would with a more conventional tech stack? 
The Implicit Calculus paper contains an interesting comparison between type classes a la Haskell and implicits a la Scala. On weakness of the implicit parameters approach is that there is no way to guarantee that you use the same instance in for example two sets you want take the union of (a consequence of the orphan instances, which are disallowed in Rust). I propose [one solution using phantom types](http://jnordenberg.blogspot.se/2014/09/type-classes-implicit-parameters-and.html) to adress this. Basically you include the type of module where the instance is defined and types of all its implicit parameters in the type of the instance. This way each instance gets a unique type which can be used as instance identifier. However without proper compiler support it's easy to "cheat" and construct fake identity types.
Oops. Well, then I have uploaded 100k sudokus. And my next release would have added another 100k. I've got some repository rewriting to do.
Everything that is not in `.gitignore`. If you don't want this behavior, you have to list the files you want to be included explicitly.
Again, it's the author's choice, but I would go with LGPL in this case. The [GNU recommendations](https://www.gnu.org/licenses/license-recommendations.html#libraries) section on Libraries distinguishes three cases, and I believe `faster` falls into the second one: libraries that provide some non-specialized functionality that already has established alternatives. This way, evil corporations can use your crate, but if they want to make changes to it and distribute the modified version, they have to publish the changes. 
&gt; The unsafety is not in the parent but in the child; the parent is always safe. Which does, to me, support this method itself being safe. You're quite right that it can lead to unsafety in the child process, and it does feel like that should be marked somehow. But then, even spawn can lead to unsafety in the child process, because you can use it to run a program written in C. The safety of the forked child feels like a gray area - perhaps it is not really Rust's concern?
&gt; Which does, to me, support this method itself being safe. The child is also written in Rust code. The safety guarantees talk about things written in Rust code. If the safety guarantees do not cover anything that happens after a fork then they should explicitly disown that because right now the intuitive implication of the guarantees is definitely that safety survives a fork. If the guarantees can go out of their way to mention that they don't cover deadlocks and memory leaks they should certainly go out of their way to mention that they don't cover forks. &gt; But then, even spawn can lead to unsafety in the child process, because you can use it to run a program written in C. The safety of the forked child feels like a gray area - perhaps it is not really Rust's concern? You can also always exec the current process into a program written in C so I don't feel this logic. It's about that the offending code that leads to the unsafety was written in safe rust. I still feel the best solution is a `marker::AsyncSafe` trait because this in general needs to be marked as running any function that is not async-safe from a signal handler is also undefined behaviour. A function or closure should automatically derive AsyncSafe if all their calls are AsyncSafe and certain things should just require AsyncSafe. Of course the problem is that you then have to stablize async-safety.
LLVM can indeed autovectorize certain operations. However, there are many cases where you know more than the compiler regarding what you're specifically trying to accomplish. This is where having explicit SIMD is necessary.
Finally, I have finished the demo page of juggernaut.rs Using this demo page, you can train and evaluate a neural network in your web browser. There is no JavaScript involved to train the model, everything is Rust. This is the demo: https://juggernaut.rs/demo/
It does not: https://play.rust-lang.org/?gist=0b877f78bf644844aa1bef7bd8134002&amp;version=stable
Once `const fn` gets more powerful/in stable, you won't need the `lazy_static`.
What's also great: Lisa basically gave the same talk at the RustFest before but in an "this is all the piston stuff you need to get started with something small". So ggez basically turned that into "hey, here's a lib for that". That's great progress in 6 months! :)
true, but that's potentially unsafe, no?
There was an issue with building on Mac OS that I just fixed, I don't have a Mac to test with. I test on Windows/Linux. Having automated tests and CI is something I am looking into. Layout would benefit immensely from such tests. I need to make some architectural changes to allow asserting on things like the calculated available size, in order to properly test the `Measure` pass. I'll make this something I work on this week. 
No it just causes multiple competing products that do identical things are created and you guarantee a low adoption rate by stonewalling many other would-be contributors.
&gt; Again, it's the author's choice, but I would go with LGPL in this case. Dealing with the LGPL's linking conditions is a pain on many platforms. Fuck that license. Just go with MIT/BSD/Apache 2 if the lib is meant to be open and accessible to everyone.
If you want to look for additional ideas, you can also have a look at Intel's ISPC compiler ( http://ispc.github.io/documentation.html), where you write your code in a shader-esque C-like language with semantics specifically tailored for SIMD and the compiler outputs efficient (at least in theory) assembly. Also, ISPC is available on https://ispc.godbolt.org (which means you don't need to install it if you can't be bothered to).
CNTK (neural network toolkit) bindings. Almost there.
Apart from what you mentioned, using strings have a number of disadvantages in my opinion. It doesn't fail equally on all platforms. A Windows developer wouldn't notice anything wrong until they hand the configuration over to their Linux friends. Due to character restrictions and the possibility to use backslashes in components, this is not entirely true for relative-path either. But I aim to get there. String replacing would be lossy (a common technique I saw to work around this). The stored data structure doesn't exactly represent the input. This pushes you to use stringly typed APIs more. Which can be hard to write correct portable code in. Safer to use codified guarantees IMO.
Isn't static linking problematic with the LGPL?
You're welcome &amp; thanks for the kind words. Perhaps you want to contribute to clippy so I (or another maintainer) can personally mentor you to avoid any embarrassment. ðŸ˜Ž
The rustup executables in your path are just frontends that call the corresponding tool from one of installed toolchains, i.e. that "rustc.exe" is not the compiler, but a wrapper that will call the actual compiler. Same for cargo etc. I guess that the wrapper changes behaviour based on the name by which it is called. That means that rustc.exe, cargo.exe etc. are all the same file, they just behave differently based on their name. Unfortunately, I don't know where rustup installs the actual toolchains on Windows, so I can't tell you where to look for the actual compiler rustc.exe to check its size.
Neat! I'm going to play with it to see if I can make my [edge detector](https://github.com/polyfloyd/edge-detection-rs) a bit faster.
&gt; I don't know where rustup installs the actual toolchains on Windows, ... Sadly, not where it should. They're installed to `%USERPROFILE%\.multirust\toolchains`. The `rustc` I have for stable is ~87KB in a directory with ~74MB of DLLs.
I hope I can get my PRs for the rust-vobject crate ready, although I should work on my masters thesis. I also hope to get the Kairos parser implemented, though that is even less likely. :'-(
Is it possible to use the same approach for GPGPU code?
Nice work! It's exciting to see what can come from `stdsimd`. One immediate issue that pops out at me (because I've been thinking about this a lot) is your [`PackedTransmute`](https://docs.rs/faster/0.1.3/faster/trait.PackedTransmute.html) trait. In particular: 1. You name your methods `as`, but they are actually implemented as bitcasts. This is inconsistent with Rust's `as` operation, which is a cast, *not* a bitcast. So that's a bit confusing. 2. The same trait also provides a *safe* method for bitcasting from an integer to a float. There is some fogginess over whether this can provoke UB if the integer you're bitcasting from corresponds to a bit pattern for a signaling NaN. In the standard library, we made this safe by translating signaling NaNs into quiet NaNs: https://doc.rust-lang.org/std/primitive.f64.html#method.from_bits
I got a lot done on [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis) last week. I'm working to support all types that implement `Num` and finally have all tests passing for `f32` and `f64`. This week I'm working to extend those tests to all other types and make sure my changes work for everything.
I was hoping so, so much that somehow this worked on stable. Depending on nightly features is a no go for me and many others.
* `simd_iter` * `simd_dispatch` * or my personal favourite, `simdon_says`
If this is bad form, what's the "rightful" way of building collections heterogeneous/polymorphic objects ?? ( but all implementing the same traits ...) I can't see any other alternatives than `Vec&lt;Box&lt;Trait&gt;&gt;` (replace Vec by your collection of choice and Box by (A)Rc according to your ownership needs )
If this is bad form, what's the "rightful" way of building collections heterogeneous/polymorphic objects ?? ( but all implementing the same traits ...) I can't see any other alternatives than `Vec&lt;Box&lt;Trait&gt;&gt;` (replace Vec by your collection of choice and Box by (A)Rc according to your ownership needs ) 
We're working on it. Come join. :-) https://github.com/rust-lang-nursery/stdsimd
I intend to switch to LGPL-3.0 (headers, included copy, and all) once it has a test suite and I can vouch for it not breaking anything (by 0.2.0 at least) I usually use AGPL-3.0 to make sure nobody accidentally links it. Wouldn't want a buggy SIMD wrapper with a ton of unchecked unsafe code finding its way into somebody's system because "it's rust, so it's safe".
I fully intend to make this work on stable as soon as cfg(target_feature) lands and stdsimd builds on stable. IIRC the rust core team intends to do that in the not-very-far future, so we could have this on stable fairly soon.
It "just works". The closure in the iterator is being passed an `f32s` in the example, which is typedeffed to the largest SIMD type available on your system. So, if your system supports AVX2, everything in that closure is an f32x8. A NEON rig would see that as an f32x4. The idea is to provide generic wrappers for everything so you can write it once and run it anywhere.
How much is the Antimony engine battle tested?
It will be licensed as LGPL-3.0 as soon as I can get a test suite going for it and ensure it doesn't set anything on fire. (by 0.2.0 at least)
faster doesn't intend to make your explicit simd code faster, but it does make it much prettier to write. For example, I had to spend a few hours accelerating the codec for base100: https://github.com/AdamNiederer/base100/blob/master/src/lib.rs#L35 With faster, I could probably do the same thing in a few minutes. Of course, compared to scalar code, it's 5-10x faster usually.
I'm not too familiar, but doesn't the LGPL have permissions for dynamic linking only? How does that fit into rust's compilation model?
I was under the impression that `lazy_static` `Deref`s into a `'static`.
I believe that C and C++ compilers have / are getting support for selecting between different implementations of a function when the binary is loaded (patching calls to the function to the one matching your platform best). Are there any plans for doing similar on rust? It's nice being able to use this to statically compile stuff, but being able to create a single binary that optimizes as much as possible for the user's machine at runtime would be a great feature too
Thank you. I will use Event::Key as per your suggestion.
Hello! Iâ€™ve been working on a blog post about cross-compiling Rust code on macOS and I wanted to make sure I wasnâ€™t breaking any rules if I posted it here. Are there any explicit guidelines on linking to oneâ€™s blog?
What's the best way to use futures_cpupool crate to run expensive functions in parallel? When i run multiple `spawn` functions , the closures seems to run in sequence/blocking manner.
What you are looking for is [`std::mem::replace_with`](https://github.com/rust-lang/rfcs/pull/1736) but unfortunately the rfc is closed due to the complexity handling panick inside the closure ðŸ˜‚ðŸ˜‚ðŸ˜‚. If you don't care that, you could grab an implementation mentioned in the thread, or do something like [this](https://play.rust-lang.org/?gist=b88421cb4cbbf3a8c47d82093758f61e&amp;version=stable) Also if you are working with `Option` you could use the `take` or `iter` method... something like this 
You can create such files using unc-paths. But you can't delete them using explorer, so it just adds to the trash fire :D
May I get an answer to the question "why LGPL"? What does it provide you that you want but MIT and Apache-2.0 can't? The one thing I can think of is enforcing the crate developer to provide its users with the option to use an API-compatible implementation of `faster` instead of your own. For closed source software, like a commercial video game, that means that `faster` has to be linked as a DLL/SO, and we all know how much than that is at the moment. Effectively, that would force all Rust projects using `faster` to be open source, even if `faster` is a dependency of a dependency of an other dependency. The alternative to open sourcing would be to also ship linker artifacts together with link instructions. Not much fun, either. If that's what you want, then good for you, but I'm no longer interested. In case that's not what you want, LGPL might not be the best license to pick.
Man, replace_with would have been great. I tried using take, but it doesn't really work. I can store the option outside the struct, but I can't have a ref to the data inside the option in the same scope that changes the option to None, even if that ref is not used after setting to None, or even if that ref is dropped. 
This is a super cool demo, but I'm not sure your neural network is sophisticated enough to be able to capture those sorts of distributions... k-means would probably work much better, at least on datasets 1 and 2. ;-)
Thanks! That's very true. I just wanted to demonstrate the neural network itself and for that amount of data and records, something like k-means would have a better performance. I hope to spend more time on the neural network itself and add more options for smaller datasets. 
What is SIMD? Iâ€™ve been developing for the web for years, and Iâ€™m new to Rust. Reading through these comments, I really feel like a novice.
Shoot, I forgot that rustc's linking is static. I do want something which requires release of the source code of this library and is compatible with GPL3+/Apache2, but I'm not interested in strong-arming people into releasing the code of their applications. Any suggestions?
Just curious, doesn't self.variant = self.variant.take().and_then(|data| { if data.work() { None } else { Some(data) } }); work for you? assuming that `A` is `Some`.
I wonder if there may be a bug in your visualization? The training on the "three blob" seems to reliably converge with the frontier between green and blue in the middle of the green blob, which seems silly, I'd expect such a network to easily learn to separate that easy dataset. Very cool nonetheless! =)
Ah, yeah! To be honest with you I tried to find the issue but was not able to figure out what is going on. I will take a look. Thanks!
I'm no expert, but the general recommendation for Rust crates is dual-licensing unter `MIT/Apache-2.0`. You could try the [tl;dr Legal Reverse Lookup](https://tldrlegal.com/search?reverse=true) page to find licenses fitting your needs.
You likely want the Mozilla Public License 2, which is like the GPL but has it's boundaries defined at the file level instead of at the executable binary level. It's what I use for all my Rust code.
I would recommend you to focus on supporting RNNs and other complicated architectures, than on pointless demos with browser ;)
Sure, will do! Just being curious, why do you think it's "pointless"? 
I'm changing internet providers, so I might be semi-offline during the next two weeks â€“ hopefully not longer. Since I'm unsure if I can keep up with current development, I'll probably just do TWiR.
I thought the demos were a very approachable demonstration of neural network learning.
I notice you throw a compile error for CPUs which don't support SIMD. Would it be better to just throw a warning, and revert to generating standard code under today circumstances? Or maybe users of your create could swap between the behaviors based on a feature flag.
Looks good. Thanks for contributing. This looks like it will be useful. I second /u/ErichDonGubler 's recommendation, structoptt (which uses clap) might reduce your lines of code by a bit, and it wouldn't hurt to actually have a struct which represents the state of commands. This would make it easier to combine commands (like update + run, or whatever) maybe that would never be required. Your chain of `if/else if` blocks would change to a string of `if let Some(cmd) = mystruct.cmd` so not a big change there, except that it would be a bit more flexible in the face of change. Regarding the install step, when you deploy to cargo, I expect people would want to take advantage of `cargo install` so that means the install step would require some bit of code generated by the `ma` binary itself. I am rather partial to the approach used by docker machine, which is to `eval $(docker-machine env)` . Maybe convert your `install.sh` script to something that can be emitted by a `ma install` or `ma env` command. 
If you know ahead of time what the possible types in your collection are going to be, you can use an enum, and have it implement the trait (although that is a bit boilerplate-y). If not, using trait objects makes perfect sense, e.g. when you're writing a library and the trait is public. 
Often, you don't actually need a heterogenous list if you design differently. In games, for example, you will often use use an entity-component-system, which splits objects amongst many homogenous arrays representing a single aspect each. Or maybe you can use HLists of some kind, which don't erase type information, and can store many types at once explicity. But if you need a heterogenous list, then there is nothing wrong with using boxed traits. It's in the language so you can use it, exactly as you describe.
`/` doesn't work in all Windows paths, particularly ones that have disabled canonicalization to get around the 260 length limit. For more information on just how wacky (and insecure!) this can get: https://googleprojectzero.blogspot.com/2016/02/the-definitive-guide-on-win32-to-nt.html?m=1
Planning on working on WebRTC impl as a way to learn Rust/Tokio better (I know, I always choose daunting projects, and I even finish them sometimes). My goal is to start by reaching feature parity with [coturn](https://github.com/coturn/coturn) because that has awesome uses even on its own and then work on the WebRTC side. No real repo yet, but we'll see how it goes. Starting w/ STUN because it's the easiest.
The most obvious things I can think of are - make sure you have more than one worker thread (`CpuPool::new`) - use `futures::future::Lazy` to wrap your closures (docs for `CpuPool::spawn` say so) - be careful about blocking or synchronizing in the tasks. Don't use `stdout`, for example. (`println!` should be alright. It does synchronize, but in a fine-grained way.)
YEEAAAHHH! ^(Sorry, I'll see myself out.)
It requires special consideration but isn't impossible: http://www.gnu.org/licenses/gpl-faq.html#LGPLStaticVsDynamic
Could try honestly, it looks better than what I have. Also what does the iter thing does on an Option ?
http://www.gnu.org/licenses/gpl-faq.html#LGPLStaticVsDynamic and http://eigen.tuxfamily.org/index.php?title=Licensing_FAQ#But_doesn.27t_the_LGPL_have_issues_with_code_that_is_in_header_files.2C_and_template_libraries.3F discuss similar scenarios.
Do you let the result (a `JoinHandle`) of `spawn` go out of scope before spawning the next thread?
It's a neat demo and I thought the visualization was rad. There's been a weird trend in /r/rust of just lots of negativity lately. I wouldn't worry about it.
Well, I was a bit confused, that's why I asked for explanation. I did mention that this is an experiment rather than something that is going to be useful in real world. Maybe that's why osamc thought it is "pointless". 
Minor point: the vectors are typedefed to the largest SIMD type known to be available for the compilation target, which isn't (necessarily) the same as the system the binary is running on, or even as the system it is being compiled on. A platform like x86-64 will require extra flags (e.g. `--target=native`) to get anything beyond SSE2. A hard part of SIMD is getting dynamic switches to work, meaning the binary has multiple copies of inner loops, using different SIMD widths, and chooses between them at run time. Unfortunately I don't think this sort of erased/uniform-vector-width approach works very well for it, unless it was used as a sort of expression template style pattern, to do the creation of the multiple loops.
See also the crate hetseq for if it's possible to know the types needed in your collection at compile time.
Correct; I'm not shooting for dynamic detection of SIMD capabilities quite yet. It still has value in that making your SIMD code work on an AVX or ARM (in the future) machine is as simple as settings `RUSTFLAGS`. It should, however, be possible to do without enormous amounts of overhead. That's probably best left to user option, however (afaik it needs one branch per `simd_iter` and a few hundred cycles at the start of the program)
Yes; the goal, eventually, is to make `f32s` and related vector types and traits work on scalar machines as well (falling back to scalar operations in the standard library, or doing some iterator shuffling in the case of swizzling operations). I'm not sure whether I want to warn about this, because the correctness of the program shouldn't be affected.
...this actually looks like this could let me dip my toes into using a GPU, having never done it before. I haven't had a strong reason to hit the learning curve for GPU programming before, but maybe this will let me transition into it! :D
You are looking for /r/playrust
Thanks for the feedback; I hadn't considered the signalling NaN case. That's definitely something I'd like to avoid, so I'll take a look at vectorizing a signaling -&gt; quiet NaN translation in those functions. In the worst case, I can mark them as unsafe.
If I understand this correctly, static linking is fine if your code has any of the typical licenses.
Are you in the wrong subreddit?
Solid cynicism but also a fair question. We're using Rust precisely where it makes sense: we needed a language with zero runtime, has very high performance, embeddable, and parallel. One specific use case is feature quantization: taking structured data and converting it into feature vectors, when you need to compute it over tens to hundreds of billions of records. We have a polyglot stack (JVM, Python, Php, etc) and we don't want to rewrite the feature processor code multiple times, so compiling it to a native library and writing bindings into each language is a real win and boost for productivity. That leaves C/C++ as the only real competitor in this space and for us it came down to wanting modern features: since we'll be embedding it in runtimes in the critical path, we want to minimize data races, UB, and memory leaks as much as possible. Frankly, Rust is a better choice for our needs. Happy to talk more about why it make sense!
Very informally, it's an instruction set supported by a processor that let's you perform operations on arrays of floats in parallel instead of operating on them one at a time. Different CPU architectures support different simd instructions, hence the need for abstractions like this library.
Isn't `.rustup` a symlink to `.multirust`, or the other way around?
Perhaps the intent of putting it in the trait is that it should be automatically put in every impl of the trait?
Thanks! (and sorry for the late reply)
Awesome!
I guess if I don't know what is SMID it's not for me
Really interesting link. And it will help me improve future versions of the lib. Thank you!
You're confused, this is for CPU programming with SIMD aka pretty much only x86.
Would you like to know? It could be for you :)
Am I the only one reading &gt; expect(3).to.be.a(i32); Aloud in their head thinking it should be an(i32) 
Possibly, but the inline annotation is not part of the API, so it's not really visible to users. If one wanted to express that intent, I'd just put it in the docs.
heh! yeah my bad sorry, I have implemented `a` and `an`. it must be `an(i32)` and `a(f32)`.
Right, I was suggesting though, that if trait has that annotation, it should be automatically copied by the compiler for every impl of the trait (unless the impl overrides it to a different setting)
In C++ this can be done using expression templates to define a program and then compiling qnd running when consumed (collect or get). I am actually researching this at the moment. I think the she should theoretically be achievable in Rust. 
This library posted doesn't support it, but this is planned, yes: https://docs.rs/stdsimd/0.0.3/stdsimd/#portability is something you can use on nightly right now. &gt; This macro will detect at runtime whether the specified feature is available or not, returning true or false depending on the current CPU.
Oh I see, I didn't realize you were requesting a feature so much as suggestion a convention. I suspect I'd be against that feature based on the fact that inlining is very easy to abuse, but YMMV. :-)
LOL, I was just being pedantic! I didn't realize you had implemented both and didn't expect you to have either.
It would be nice if they implemented std::ops::Div for Path so you could chain them like this: `base / "foo" / "bar"`
I just added http/2 support to [actix web](https://github.com/actix/actix-web). upgrade to http/2 over tls connection works, but now I'd like to add `upgrade: h2c` over clear text connection
Lets put it this way. I have seed many demos/playground like this (most famous is this one http://playground.tensorflow.org/). I have not seen any library in Rust, which allows you to train recurrent neural network or automatically calculate gradient of some complicated architecture like tensorflow, cntk or theano does. 
That's true but the point here is that I have not used JavaScript and it is a Rust code on the web browser. What you are saying about RNNs is correct but these are just two different things IMO.
I'm against this; there's a reason we named the operators `Div`, `Add`, `Mul` etc rather than `/`, `+`, `*`... it reinforces that an overloaded operator should have similar intent to a standard operator, and implicitly discourages things like overloading the left shift operator for printing. :P
But it looks like you are only causing a detour for calling `createmove_hook()`, not for calling the actual function in the DLL at address `0x10111790`. When the game calls the DLL function, it won't call your `closure_for_createmove`, right? Wouldn't you have to write `CreateMoveDetour.initialize(fn_ptrs.addy, closure_for_createmove)` to cause a detour for calling the DLL function? I'm asking because what I want to do is: Hook a DLL function such that when another program calls it, it calls my detour function, which should log the arguments it's called with, and then call the original DLL function. How can I do that with detour-rs?
Is this possible with detour-rs?: Hook a DLL function such that when another program calls it, it calls my detour function, (which should log the arguments it's called with), and then call the original DLL function. How can I do that with detour-rs?
I wanted to ask (not specific to SIMD, but close): Intel has [dpps](http://www.felixcloutier.com/x86/DPPS.html) and [dppd](https://software.intel.com/en-us/node/524199) instructions to calculate a dot product for two vectors in a single instruction (using SSE4). This is very useful for any graphics / game work. Is there any way to get this instruction to work on nightly rust?
As long as it's related to Rust it's not a problem at all.
...d'oh! Yeah, I guess that that should only reveal how much of a newbie I am when it comes to programming closer to the machine. TIL, thanks!
I think the general Reddit guidelines apply: https://www.reddit.com/wiki/selfpromotion
Super smart idea. Now I just need to find an excuse to incorporate SIMD into my code
Would probably be very useful for me to learn Rust more deeply. Not sure that I have lots of time to commit, but will certainly dig into the source code and look through the issues list etc
Morq looks neat. Perhaps alias close_to to close and equal_to to equal like you have done with a/an
/me feels bad for overriding &gt;&gt; to perform piping operations...
If you wanted to mess around with GPU programming in rust there are OpenCL and Vulkan bindings that you could try. I There is even a higher level Vulkan crate called Vulkano.
Inlining feels like a concept better applied to implementations - it seems like a Trait is the wrong place to dictate something like inlining.
Last week I did a little on [tarpaulin](https://github.com/xd009642/tarpaulin), trying to get tarpaulin running on tarpaulin but I got stuck with difficult ptrace things. This week I think I'm going to take a break from it and work on some other features/issues and wait for a flash of genius. I might get round to starting the design/implementation of branch coverage!
I don't know a lot about neural networks but I wonder what the performance comparison would be with a similar library purely written in JS. My intuition tells me that this should be an area that Web assembly shines, but numbers are always cool!
This deserves a mention: https://antimony.rs/
ARM NEON, PowerPC Altivec, SPARC VIS, MIPS MDMX... itâ€™s actually hard to find an architecture that doesnâ€™t have SIMD at some level these days.
SIMD (Single Instruction Multiple Data) is a feature of modern CPUs which allows doing the same operation on multiple values at once, with a single instruction, on a single core / thread. This means that it can be used to greatly speed up working with arrays of values, especially with a lot of data, as the CPU can effectively process 2, 4, or even 8 numbers at once without any multithreading. Many compilers (LLVM especially, and hence Rust) can automatically detect some common cases when you are working with arrays and optimise them by generating the appropriate machine code instructions for the CPU to make use of SIMD, speeding up your loops/iterators. However, compilers are not smart enough and often miss out on many such opportunities. Also, in many cases, you as a human programmer just know better what exactly you are trying to do. Hence, explicit SIMD is useful (being able to explicitly create say "do this SIMD operation on these multiple values"). Explicit SIMD has many applications. It is used to write performance-optimised multimedia codecs, matrix algebra/math for scientific computations or even game engines, amongst other things. Different CPU architectures each offer different SIMD features that work somewhat-differently. x86 has SSE/AVX, ARM has NEON/SVE, PPC has AltiVec. They all offer similar ideas, but differ significantly in how they work and offer different features. Explicit SIMD is usually done either by manually writing assembly code (which only works on a specific processor ofc) or by using compiler intrinsics (special compiler built-in functions that represent the CPU SIMD instructions), which are also architecture-specific. Some languages offer special types that allow you to represent, say 4 floating point numbers, as a single variable and then do regular arithmetic operations on them. Then, the compiler treats it as a single unit and emits the appropriate SIMD instructions. Both the intrinsics way and the special types way are currently WIP for Rust, and partially usable on nightly. People are excited about them, because it will allow writing things such as fast video encoders in Rust, which simply require explicit SIMD, so are not currently possible in stable Rust. There exist libraries that try to abstract over the differences between the different CPU architectures (also falling back to just doing the maths one number at a time for CPU architectures that do not support SIMD), to make it possible to write portable code that compiles for any CPU, while making use of the respective SIMD features of the various CPUs whenever possible. From a quick glance at the code, OP's library seems to be x86-only (it is still a useful library, as it provides more idiomatic Rust-y ways of working with SIMD, which are higher-level than what the compiler offers directly). Honestly, I don't expect much better, considering the current state of SIMD support in Rust. Some more work needs to be done to enable the Rust compiler to do explicit SIMD on various CPU architectures. OFC, for the implicit case, LLVM is already fairly capable of auto-optimising and generating some SIMD on its own, when you are building your Rust crate in release mode. It is one of the many performance optimisations that LLVM does. 
I am working on a rust implementation of `dd` that provides status information. [current state](https://github.com/FreeMasen/dd_stat) last week to support this I put together these projects I rolled my own status string generator [here](https://crates.io/crates/progress_string) I also put together a text file generator for testing [here](https://github.com/FreeMasen/tallocate) which resulted in my first published [crate](https://crates.io/crates/blobber) This week I am hoping to implement a true blob generation function to Blobber that returns `&amp;[u8]` and update the implementation to reach an exact size instead of a minimum size. I want to implement a `current_progress/total` display to the progress_string options. Lastly I am hoping to start in on some of the other features of dd like `conv`, `skip`, `seek`.
I'm writing a plex-like application in Rust and am using Tokio for sending and receiving data over TCP. When I try to send a large amount of data (that is, more than ~1400 bytes of data, which I assume is related to the maximum amount of data a packet can hold), I receive data which is invalid. Am I simply being stupid and should I limit the length of each message to be at most 1200 bytes or so, or am I making another mistake causing my message to be sent or reassembled improperly?
If it's done inside a macro then it might be a decent compromise. A `path!(base / "dir")` kinda thing.
No worries. When in doubt, just ask. We can split the work into bite-sized chunks if that helps.
No, it's that way.
This library only supports SSE or AVX though. So x86.
I added a bash/Docker wrapper to pq for convenience: https://github.com/sevagh/pq/tree/docker_wrapper#pq_docker-usage Seems to be a hot thing now to run things in Docker containers. This way you can avoid needing to install `protoc`.
also have a look at https://air.mozilla.org/bay-area-rust-meetup-november-2017/ where boats talked about this
Raising a `BigRational` `x` by a fractional power `a/b` is the same as exponentiating by `a` and then taking the `b`^th root. But taking the root will not return a rational number, generally speaking, so that's probably why it isn't supported? 
They are actually part of SSE4.1, but yes, they are exposed in the `stdsimd` crate, which does indeed require nightly Rust: https://docs.rs/stdsimd/0.0.3/stdsimd/vendor/fn._mm_dp_ps.html and https://docs.rs/stdsimd/0.0.3/stdsimd/vendor/fn._mm_dp_pd.html (Note that `stdsimd` is available on crates.io for experimentation. The plan is to eventually bring it into `std`/`core`.)
Having used error-chain in the past, which was a great library, this looks like a huge improvement. The ergonomics look a lot better, especially since it utilizes custom derive to make creating new error types easier.
oh, probably... is there any way to approximate it better than f64?
Do you have a link to where the work on the tool is happening, so people can follow along as it progresses?
Things I like - Feels lighter than error-chain - Feels less opaque than error-chain - Feels more composable than error-chain Things I dislike - Errors are boxed, both in a library's exposed API and in the error's `cause` &gt; To emphasize: Error is intended for use cases where the error case is considered relatively uncommon. This optimization makes the overhead of an error less than it otherwise would be for the Ok branch. In cases where errors are going to be returned extremely frequently, returning this Error type is probably not appropriate, but you should benchmark in those cases. &gt; (As a rule of thumb: if you're not sure if you can afford to have a trait object, you probably can afford it. Heap allocations are not nearly as cheap as stack allocations, but they're cheap enough that you can almost always afford them.) https://boats.gitlab.io/failure/error.html#implementation-details It looks like you can allocate `cause` manually, so maybe the boxing for that can be avoided (just want a helper macro for supporting multiple causes) I've not looked closer to see if you can `Result&lt;_, Error&gt;` rather than `Result&lt;_, Fail&gt;` to avoid the boxing. (or maybe I should abandon my obsession with avoiding `Box` :) ).
Square roots are irrational (in general) so at that point only symbolic computation will save you from loss of precision. There is a `bigdecimal` crate, so that you can get arbitrary precision, but I cannot vouch for it, having never used it.
The `rug` crate does provide arbitrary-precision floating-point numbers. use rug::Float; use rug::ops::Pow; // 100 bits of precision let f = Float::with_val(100, 1.5); println!("{} to the power of {} is:", f, 0.5); let p = f.pow(0.5); println!("{}", p); The power can be another arbitrary precision `Float` instead of 0.5, or it could be an arbitrary precision `Integer`. It cannot be a `Rational` directly, but you could convert a `Rational` to a `Float` and use that: use rug::{Float, Rational}; use rug::ops::Pow; let f = Float::with_val(100, 1.5); // r = 1/2 let exp_r = Rational::from((1, 2)); let exp_f = Float::with_val(100, &amp;exp_r); println!("{} to the power of {} is:", f, exp_f); let p = f.pow(&amp;exp_f); println!("{}", p);
It's not like i care about loss of precision,it's just that I need a bit more, the algos i'm running fail sometimes with certain parameters, and I'd rather not just `assert!(x == 0)` Checked it out, but now powf() functoin or anything similar:(
This is exaaaaactly what I was after, thank you!
Starts at 1:17:30
In theory there will be a blog post about this by tomorrow. :)
In Rust Option is an enum of `Some(T)` or None, but then again you could think of it as a list of either one or zero elements. In the latter case `.iter()` makes sense: The first `.next()` call will return the first element of the list, or `None` if there is no such element.
&gt; Errors are boxed, both in a library's exposed API and in the error's cause That's not correct about cause. cause returns an `Option&lt;&amp;Fail&gt;`, a normal implementation would not need to allocate (you can cast an `&amp;T: Fail` to an `&amp;Fail`). However, if you use the `Error` type, that does box. In my opinion, this is not a downside in the *vast* majority of use cases. The Rust community is too afraid of allocations. What really matters for errors in most cases is that the Err type is not too large, because that negatively impacts the happy path by making the `Result` larger. That's why `Error` already uses a custom DST to ensure that `Error` is only 2 words. And its why dtolnay has proposed, based on his experience benchmarking serde, boxing twice inside of `Error` to make it only 1 word. --- Its true that moving to this new system is a breaking change, which is why I advocate applications move to it immediately and libraries be a little more cautious (libraries on the current system can be plugged into applications that have moved to the new system without special glue code).
But that's kinda what the vtable is doing, right ? 
Indeed, even the `csv` crate boxes its error internally: https://github.com/BurntSushi/rust-csv/blob/11e45d853887afe0e7e88b517fb2dc7f07fa4f6f/src/error.rs#L28 The unboxed error type on its own is 88 bytes(!) on x86_64.
Hm, good point. One difference is that there are no pointers if you use an enum, and the address of the method to use is known statically, whereas with vtables you always need to look up a function pointer IIRC. Also, the compiler might optimize code using enums better.
I want to mention that I feel I came off too negatively about the existing solutions in this talk. Partly this was because jokes &amp; partly this was because I hadn't prepared sufficient notes. The Error trait is flawed, but this is because it didn't get enough attention in the lead up to 1.0. Honestly the fact that the Error trait is the worst API in std is a testament to how good we did in that period. error-chain is pretty much exactly what I would've done at the same time that error-chain was first released. It was the best solution given the context. But now we have custom derive, and we've also learned important lessons from the experience with error-chain that weren't obvious at the time. So I want to be emphatic: the existing solutions are not *bad*, we're just going to keep trying to make better things until we are all dead.
Re: breakage, `failure` certainly isn't a drop-in replacement for `error-chain`, but that's not quite so bad; the whole reason we encourage experimentation outside of the stdlib like this is to let good solutions evolve over time while also allowing people to manage breakage on their own schedule. `error-chain` isn't going to break or go away for those who decide to continue using it, and if it ever falls out of use it will be because the community chose to stop using it, rather than the Rust developers forcing anyone.
Another thing I like: I suspect this will be easier to reason about API compatibility. Sometimes the error you convert `From` is part of your API and sometimes its an implementation detail. I'm still not sure the best way to handle this but with `Failure` being less opaque, its more obvious what your API definition looks like.
&gt; Its true that moving to this new system is a breaking change, which is why I advocate applications move to it immediately and libraries be a little more cautious (libraries on the current system can be plugged into applications that have moved to the new system without special glue code). `Error` is such fundamental part of the ecosystem, especially with `std` using it and during/after such a hard push to get libraries to 1.0. What do you see as the long term path for this?
Is it possible to derive the `Fail` trait for enums? One of the things I really like about `error-chain` is that you can really easily match on errors, even going so far as to match multiple levels deep. Downcasting is really un-ergonomic, and you lose the exhaustiveness checking that the compiler provides automatically for enums. This is a huge deal for me: if a library function can error in several ways, and I want to handle those error cases, I really want the compiler to tell me if I'm not handling one of the variations! There's a lot of great things about this new error handling story, but I'm really afraid it will just encourage returning generic `Error` types everywhere, and if that happens we may as well have just used exceptions...
boats has a face! (good face boats &lt;3)
&gt; now we have custom derive Just to point out that [derive-error-chain](https://crates.io/crates/derive-error-chain) exists. Of course it doesn't solve any of the other problems you've identified.
If this is popular and widely used, we would consider moving `failure::Fail` and `failure::Error` into libstd and deprecating `std::error::Error`. For now, anything that implements `std::error::Error` also implements `Fail`, so there's an automatic compatibility in the direction of library to application. This is why I said applications that appreciate the API differences should move immediately - there should be no cost to them. For libraries, if you make breaking changes, IMO you should bundle this up into your next breaking change. There is a story for converting from a `Fail` to an `std::error::Error`, which is not quite as nice but is still not painful. For libraries that don't make breaking changes, the backcompat story we already have will allow people to keep using those libraries seamlessly after moving to failure, as I mentioned before.
I've seen better ;)
&gt; However, if you use the Error type, that does box. In your talk you mention how this lib is friendly to no_std, how does that work in the face of this?
For an example of where `Box&lt;Trait&gt;` is better, see [burntsushi's comment](https://www.reddit.com/r/rust/comments/7b88qp/failure_a_new_error_management_story/dpg4vr9/?st=j9owane8&amp;sh=24791089)
The Error type is not included if you compile it in no_std mode. The Fail trait is no_std compatible.
TCP is responsible to receive the data in the correct order, so you don't need to worry about that. The issue may be in the way that you are reading or writing data to the socket. Can you post the code that is reading/writing the data? 
I left the first example training for too long and... [something went wrong](http://www.seas.upenn.edu/~aburka/tmp/Screen%20Shot%202017-11-06%20at%207.56.51%20PM.png).
&gt;Just go with MIT/BSD/Apache 2 if the lib is meant to be open and accessible to everyone. Except end-users who need to fix that lib when the vendor wont or cant. Fuck permissive licenses. 
(A/L)GPL also allows end users to fix your code to fit their needs. To me, that's the primary benefit of these license, and a very important one. 
Please continue using GPL-family licenses for your project. These licenses guarantee that end-users have the right to edit and fix your code when a vendor does not. If you want to support propritary software, consider using LGPL which allows authors to keep their code close. A good example of a library licensed under the LGPL and used by many proprietary software is the qt GUI library.
I. love. this. This looks so much better than error-chain, and is exactly what Rust error handling needs. This needs to be in std! I really hope it eventually ends up there. My only question: I assume there is a reason for not bounding Fail on Any?
For me, .multirust is a junction to `\??\C:\Users\me\.rustup`.
There's [a blanket impl of `Any` for `T: 'static + ?Sized`](https://doc.rust-lang.org/src/core/any.rs.html#113), and [`Fail` types must be `'static`](https://github.com/withoutboats/failure/blob/master/src/lib.rs#L70).
Oh sorry I was actually talking about the Error struct, because it has downcast_ref and downcast_must implementations but not in `impl Any`, but now I just saw that they both require the target type to be "T: Fail" which of course makes sense.
Has GPL ever forced a project to be open sourced except when accidentally included? To my knowledge every company that wants to do a non-open sourced product simply bans anything GPL. If you think that free software is important that is your perogative but don't paint it as an accessibility thing, either related code will be open or it will not, how you license your code only affects whether your project will be used not how that decision is made.
Hm... That doesn't feel as different from [derive-error](https://crates.io/crates/derive-error) as I'd like it to be. Any obvious advantages that could prompt me to go from derive-error to failure?
Is there any plan to add it also behind a alloc feature flag that enables Error when using feature(alloc)?
structopt uses clap internally and is a custom_derive wrapper around clap. So the two can actually be used totally in conjunction and are in no way mutually exclusive ;) I.e. you can use structopt to build an initial `clap::App` struct and add any additional settings not available in pure structopt prior to parsing.
So is part of the idea that you would move to a more 'dynamically typed' error strategy? Kind or wish Rust have open unions for this kind of thing so that one could maintain type-safety and good documentation while also allowing for extensibility/composability.
My reply isn't a plea to force companies to open their software. My comment is a reply to i-eat-kittens's assertion that MIT/BSD/Apache2 should be used if software is meant to be open and accessible to everyone. I've painfully experienced first-hand how false that statement is. Free software is an accesibility thing. A users ability to modify the software he or she uses is a core guiding principle for the GPL. Finally, If a company doesn't want to open source their software, they wont - as you stated. Faster's license whether GPL or MIT won't change that fact. It will only insure its end-users right to modify the software they use. 
Incompatibility with the stdlib concerns me. I'm worried this will just cause a fractured ecosystem. Some libs will use `std::error:: Error` and some will use `Fail`, and then we end up in an even worse situation than when we started.
I look forward to the day when [steed](https://github.com/japaric/steed) and [rustls](https://github.com/ctz/rustls) are mature and we no longer need to do anything more than `rustup target add $target` and `cargo build --target $target`. This is one area where Go currently blows Rust out of the water, cause Go programs rarely rely on libc or OpenSSL.
Thanks for putting those two libraries on my radar. That's sort of what inspired my post; I wanted to be able to run those two commands with no other dependencies. When that didn't work, I went off to find the next best thing for the time being.
Thanks! I ended up wrapping them in lazy futures and `joined_all`. I have 10 workers on `CpuPool`, is that a lot?
Well that is I guess because `Foo&lt;Bar&gt;` and `Foo&lt;Baz&gt;` are legitimately different types in every sense of the word and it's truly possible for a function to be able to accept one and reject the other. In the case of `Box&lt;Trait&gt;` it is one and the same type and there is no way to observe which implementor of `Trait` is used at compile time at any point I will say though that Rust's spelling out type info can indeed get super verbose. I rather like how Haskell just makes all type names capitalized and says that in signatures every lowercase name is a a universally quantified bound variable.
That's impressive!
I watched your presentation a couple nights ago. For the record, I don't think you came off negatively. It was all perfectly fair and reasonable.
An RFC for annotating enums with `#[non_exhaustive]` has been accepted. That'll solve the enum extensibility problem.
Not really. What I mean is having row-typed polymorphic variants like OCaml. Although that brings up issues of memory layout that Rust uniquely has to care about :/ - http://caml.inria.fr/pub/docs/manual-ocaml-400/manual006.html#toc36 - https://realworldocaml.org/v1/en/html/variants.html#polymorphic-variants - https://hackage.haskell.org/package/open-union-0.2.0.0
I'm trying to create a closure in a function and store it in a Vec of closures. I get lifetime issues even when Boxing it up. Is there a good way to solve this?
&gt; failure is no_std compatible YES! &gt; though some aspects of it (primarily the Error type) will not be available in no_std mode. Huh... gonna check the sources. Okay, fount two reasons: - No `impl`s for `std::error::Error`, that's okay. - No `Error` because of `Box`. Well, that's kinda meh. Why not add an other `feature = "alloc"`, which pulls in the `extern crate alloc;` for `no_std` users? In that case `Error` will just work.
Corrode supports just C code. It has no support for C++.
Open source developers work for free on the things that interest them, and we are all lucky that they share their work freely. If you want something, you should consider building it yourself. In any case, I think that it is rude and counterproductive to tell someone that something they made is less worthy because it doesn't satisfy your personal wants or needs.
&gt; If the safety guarantees do not cover anything that happens after a fork then they should explicitly disown that Agreed! The post-fork execution should either be safe, or fork should be clearly documented as leading to unsafe execution. Pragmatically, i would suggest we start with the latter, and introduce the former if it becomes possible. I still don't think that requires marking before_exec as unsafe. &gt; I still feel the best solution is a marker::AsyncSafe trait [...] A function or closure should automatically derive AsyncSafe if all their calls are AsyncSafe Functions can't have traits (can they?). This would have to be an attribute, and i'm not sure there's existing machinery for deriving attributes like that. Indeed, i think that would require an [effect system](http://smallcultfollowing.com/babysteps/blog/2012/05/29/simple-effect-system/), which Rust [currently looks unlikely to get](https://github.com/rust-lang/rfcs/pull/73#issuecomment-43698004). 
&gt; Agreed! The post-fork execution should either be safe, or fork should be clearly documented as leading to unsafe execution. Pragmatically, i would suggest we start with the latter, and introduce the former if it becomes possible. I still don't think that requires marking before_exec as unsafe. Well it should be done quickly because right now the documentation definitely implies that a fork is caught by safety guarantees and what's more Rust does not seem to define a notion of "fork". It's pretty obvious that `before_exec` maps to fork for anyone who knows what fork is but that's where it ends. &gt; Functions can't have traits (can they?). Sure they can. A function pointer has a _type_ like `fn(int) -&gt; int`; this type will always at the very least implement the _trait_ `FnOnce(int) -&gt; int` and may also implement `FnMut(int) -&gt; int` and `Fn(int) -&gt; int`. Apart from that many things that call functions have further trait bounds and a lot are automatically derived in a similar way. For instance: https://doc.rust-lang.org/std/panic/fn.catch_unwind.html Which requires that a function pointer or closure implement UnwindSafe which is automatically derived and added to the function or closure when it internally only calls functions that are UnwindSafe; I see no reason why `AsyncSafe` could not do the same.
Not every `no_std` situation supports `alloc`.
Is returning `Error` instead of a specific error type, for a function like `read_toolchains`, not considered an anti-pattern, since it erases all useful type information abou how the function could fail?
&gt; Why not add an other feature = "alloc", which pulls in the extern crate alloc; for no_std users? In that case Error will just work. Because allocators aren't an option on many (if not most) no_std platforms for most people.
What I'd find appealing if one could see from a function's signature what errors exactly it can return, rather than a superset of it. As far as I can see, this makes you always return `Error`, which boxes up the set of all possible errors. Is there a good remedy for that problem? I've like `error_chain` so far, but I don't see how failure would facilitate finer-grained error definitions.
I could be entirely wrong but what i understand is that any library error that implements ```std::error::Error``` also implements ```failure::Fail``` so as a library user there should be no problem if i migrated to `Fail`. Writing my own errors in my application is obviously no problem
I sort of get why you snipped away the long block of error messages, but I wish you didn't. It makes it that much harder to find your post when Googling for errors.
Is everyone oblivious to the fact that the example on the README doesn't even build? &gt; #[macro_use] extern crate derive_fail;
Which is why I requested that additional `feature = "alloc"`. If you support it, use it, if not, then don't.
See my reply to Steve.
&gt; Also what does the iter thing does on an Option ? It treats the Option as a collection of 0..1 items (None = 0, Some = 1) then iterates on that. Basically, when you iter it `None` ~ `vec![]` and `Some(v)` ~ `vec![v]`.
Perhaps I should have ended my post after "fuck that license", as pushing a permissive license wasn't what I was trying to do. My point is that the LGPL is horrible, and as a Rust user you should be aware of why.. You argue about users fixing their closed source software by upgrading libs, but that just doesn't happen. If someone must choose a non-permissive license, there are alternatives without LGPL's bullshit linking terms. The author seems to be leaning towards one of said alternatives.
No current plan, but I'm supportive in theory. Depending on what libbacktrace requires, the std feature flag might be alloc compatible already.
In this case, use a custom error enum (that implements Fail).
What type safety do you believe has been lost? In my opinion this is how to implement an open sum type in Rust.
I am supportive.
There are certainly cases where it would be the wrong choice, but i don't think a blanket statement like "anti-pattern" is correct. Especially in the application context, you're often ultimately just throwing these errors up to some root function which prints or logs them. If you do need to recover in a particular case, that's what downcasting is for. But within the high levels of an application, it is rarely helpful to restrict the possible errors. On the other hand, there are cases where you do want to restrict the errors. This is especially common in libraries. error-chain's API encourages users to use a single error type for their entire library, providing a mirage of "restriction" to a specific set of errors, when in practice that set grows enormous over time and each function can only return a small subset of it. You don't have to use it this way, but most people do. The current system gave users the verbosity of enumeration without the benefit of restrictions. failure gives you a choice between the two.
Perhaps I should have ended my post after "fuck that license", as pushing a permissive license wasn't what I was trying to do. My point is that the LGPL is horrible, and as a Rust user you should be aware of why.. You argue about users fixing their closed source software by upgrading libs, but that just doesn't happen. If someone must choose a non-permissive license, there are alternatives without LGPL's bullshit linking terms. The author now seems to be leaning towards one of said alternatives.
There's sadly no video of the lightning talks, someone presented a lisp implemented in Rust macros.
/u/asmx8 is correct. We have considered backwards compatibility carefully. Anyone using failure can use libraries on the old system at no cost, and anyone using the old system can use a library on failure at the cost of a single method call (`.compat()`).
So in the README's example, one would just return `Result&lt;Toolchains, ToolChainError&gt;` and put those iO Errors into the ToolChainError enum? That sounds kind of painless, nice! Now I see arguments pro-boxing coming up, and a feature of using `Error` as return type error (as in the readme) is that failure makes this a box transparently. Can this be had with custom enums as well? 
Was inprecise in my speaking. More that you don't get exhaustiveness checking and the documentation that goes with enums in Rust when you get to downcasting to concrete error types. It's nice to know what the failure cases are for a library function, otherwise it becomes as opaque as a `panic!`, albeit with the ability to catch the error within a thread. Granted, for libraries that might be a good thing - to have the ability to change their APIs without breaking backwards compatibility - but that could be solved by returning an opaque row parameter. Something like: ``` type ReplError&lt;E&gt; = ParseError | TypeError | io::Error | E; fn run_repl&lt;W: io::Write, R&gt;(w: &amp;mut W, src: &amp;str) -&gt; Result&lt;(), ReplError&lt;E&gt;&gt; { let expr = src.parse()?; let (val, ty) = eval(exor)?: writeln!(w, "{} : {}", val, ty)?; Ok(()) } ```
&gt; I want to mention that I feel I came off too negatively [â€¦] &gt; we're just going to keep trying to make better things until we are all dead. That gave me mood whiplash. :)
Nice! Tried that from Linux and I could not make it work. Then I found rust-cross: https://github.com/japaric/rust-cross Have you checked this? It's awesome!
 Its true that you can't specify a subset without creating a new enum type. (The code you wrote isn't quite right because you want `E` to be an existential, but I get your meaning).
We can't change the representation of an enum to use a box, no. :-\
The article is not quite correct on this part: the need for a cross compiling C toolchain is not really to do with libc/openssl, it's because rustc needs a linker. As soon as the LLVM linker matures enough, it would be possible to drop the dependency on a cross-compiling C toolchain, unless your crate depends on the `gcc` crate.
&gt; The Rust community is too afraid of allocations. What really matters for errors in most cases is that the Err type is not too large (in its stack representation), because that negatively impacts the happy path by making the `Result` larger. Good advice! Would it be possible to have a typed version of `Error` that can be cheaply converted to the opaque `Error`? For those who want to document what errors their APIs produce?
I'm having trouble with `rust.vim`, getting errors to show up in the quickfix window. I'm using neovim 0.2.0, run `:compiler cargo` and `:make build`, see the errors, but my quickfix is still empty afterwards. should I give up and use ALE instead?
Note: you could easily alias `type BoxResult&lt;T, E&gt; = Result&lt;T, Box&lt;E&gt;&gt;` and use that.
It won't build with the `failure` crate from crates.io too - you need the latest version from GitHub.
&gt; EDIT2: And derive-fail is not on crates.io Both aren't really on crates.io yet; you need to use them from github. They'll be up there after this initial round of showing it off and presenting it to people.
The `Display` deriving seems generally useful, is it intended only for `Fail` or for deriving `Display` for any type?
Things like this make me wander if there should be an api that accepts an Into as a parameter. insert_from&lt;U: Into&lt;K&gt;, V: Into&lt;T&gt;&gt;(&amp;mut self, key: U, value: V)
This RFC is available as [take](https://crates.io/crates/take) crate by the way.
That would be [`take_mut` crate](https://crates.io/crates/take_mut).
I've been wondering that as well. In fact I've been wondering why this isn't already part of the standard library. I can see how a type's `Display` is much more type-specific than its `Debug` but stillâ€¦
Thank /u/ncarrillo I just have a simple, and quite trivial question. What are the dependencies of Indigo? Will I be able to just compile a project down to a single executable that does not require several external dependencies to work in the major platform? (Linux, OSx and Windows) Thanks :)
That's pretty fucking neat
I can think of a couple of examples where an application might care about specific error types at a high level: 1. In CLI applications, you often want to gracefully quit after observing a broken pipe error. It is convenient to handle this at the topmost level of the application. 2. In a web server, for example, it might be convenient to extract/infer HTTP status codes from your error. To do that, you need to know the error type. (I provide these as examples---not as counterpoints---since it seems like downcasting would still work fine in this context.)
The reasoning is that you're supposed to think about how you want to display your type, `Debug` is if don't want to think. The macro would be an explicit but more ergonomic way of implementing `Display`.
Hah. Turns out I also [doubly box the record types](https://github.com/BurntSushi/rust-csv/blob/11e45d853887afe0e7e88b517fb2dc7f07fa4f6f/src/byte_record.rs#L102) as well, so that a `Result&lt;csv::StringRecord, csv::Error&gt;` should only be two words I think.
One can think of collect::&lt;HashMap&gt; and collect::&lt;Vec&gt; as separate functions.
&gt; I've been wondering why a blanket Display isn't already part of the standard library. Display is for end-user presentation. There's no way to tell ahead of time what type of thing you're building, let alone what you intend to show to your users.
Hey, just went through your codebase for a whole 10 minutes or so... I saw you were creating a parser, I suppose to parse files that would later compose the UI. My point is : why are you doing this by yourself and not using a crate that is meant to do just that - of course, I'm talking about [nom](https://github.com/Geal/nom) ? Anyway, good luck developing this :) 
&gt; The Error trait is flawed, but this is because it didn't get enough attention in the lead up to 1.0. Honestly the fact that the Error trait is the worst API in std is a testament to how good we did in that period. I feel like this does not *really* solve the biggest issues I have with the error trait though which is the complete inability of working with the error itself. In particular what I started to realize is that what I would actually want (if I were to design an error system from scratch) is: * a stable error kind ID (maybe a UUID) that I can test against * break formatting of an error into "name of error" and "short description of error" as well as optionally a "longer description of the error". * being able to at least assist in translating error messages to users eventually (how? unclear but maybe by letting applications map error kinds to translation strings). Right now in a few cases I actually parse the stringification of an error to figure out if I should handle it or not which is absurd. Also for the errors I send via a C bridge to Python I manually assign error codes to all errors so I can restore them on the other side. Not exactly a very enjoyable process.
You can use a newtype for things like this: pub struct Arg(u32); pub const ARG_YELLOW: Arg = Arg(0); pub const ARG_QUICK: Arg = Arg(1); pub const ARG_WET: Arg = Arg(2); impl Arg { fn other(arg: u32) { assert!(arg &gt; 2 &amp;&amp; arg &lt; 100); // custom validation Arg(arg) } } This allows you to restrict the range of values with which an `Arg` can be constructed. You can provide a `From` implementation to convert back to an integer if needed.
Sounds like you want [`bitflags`](https://crates.io/crates/bitflags)
If you implement `Eq`, this allows `arg == ARG_YELLOW` and `match arg { ARG_YELLOW =&gt; (), _ =&gt; () }` as well. You can also consider using associated constants, so that itâ€™s `Arg::Yellow` still, as with an enum. Provided you implement `Eq`, pattern matching works on the simple variants, though not on your custom ones (which are a function call). You might want to implement `Debug` manually too for best output. All up, itâ€™s like this: use std::fmt; #[derive(PartialEq, Eq)] pub struct Arg(u32); #[allow(non_upper_case_globals)] impl Arg { pub const Yellow: Arg = Arg(0); pub const Quick: Arg = Arg(1); pub const Wet: Arg = Arg(2); } impl Arg { pub fn other(arg: u32) -&gt; Arg { assert!(arg &gt; 2 &amp;&amp; arg &lt; 100); // custom validation Arg(arg) } } impl fmt::Debug for Arg { fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result { match self.0 { 0 =&gt; f.write_str("Arg::Yellow"), 1 =&gt; f.write_str("Arg::Quick"), 2 =&gt; f.write_str("Arg::Wet"), n =&gt; f.debug_tuple("Arg").field(&amp;n).finish(), } } } fn main() { println!("{:?}", Arg::Yellow); println!("{:?}", Arg::Quick); println!("{:?}", Arg::Wet); println!("{:?}", Arg::other(42)); println!("{:?}", Arg::Wet == Arg::Wet); println!("{:?}", match Arg::Wet { Arg::Wet =&gt; true, _ =&gt; false }); } With this output: Arg::Yellow Arg::Quick Arg::Wet Arg(42) true true
&gt; In a web server, for example, it might be convenient to extract/infer HTTP status codes from your error. To do that, you need to know the error type. This is something I've run into frequently. I'll take it a step further though. I usually want to be able to handle categories of errors at the top level. For instance, I don't really care if it was a `sql::ErrNoRows` or a `http::NotFound` from a down stream service: the end result is the same I'd like a 404 presented to the user. I haven't found a great way to express this in Rust without either making the top level error handler know about all the low level errors (I wish we had something like `match` for downcasting) or having the lower level clients know about how they're used in the application.
I'm not sure I understand why. My values are sequential, they are not powers of two. It seems to me `bitflags` is only for powers of two.
If the work is CPU-bound the rule of thumb is to use as many workers as hardware threads but no more.
That looks nice ! Thanks (There should be a crate for that)
Note: to use with pattern-matching, you need `#[derive(PartialEq, Eq)]`, you can't have custom impls.
What did you post? Neither of your comments are rendering on my phone and nothing shows up when I tried to copy/paste it.
Like our `inline_always` lint, perhaps? Or does it fail to catch those?
Oh, I don't see `compat` in the docs. What type implements it? Also, what about libs that use `error-chain` or `derive-error`? Can they just add another error variant that `: Fail`?
It was Alex Burka as well: https://github.com/durka/macrolisp 
Is it possible to completely avoid Boxing ?
I'll share it as soon as I get home. The client is written in Java (because android), but I'll include the relevant code) 
Great! That makes integration easy (especially with Rust's static linking) but still ensures that changes have to be open sourced and could be contributed back. Looking forward to it :)
Saturn devouring his son 
`impl Trait` doesn't solve the problem boxing solves. The idea is that most of the time getting an `Err` is the exceptional case. However, many error types are freakin' huge, and moving huge data around is costly. With boxing, the unlikely error value is just 1 to 2 pointers big. This optimisation does result in measurable and noticeable performance gains.
Faktory was announced here: http://www.mikeperham.com/2017/10/24/introducing-faktory/ (HN: https://news.ycombinator.com/item?id=15541504)
I think you van do this: #[repr(i32)] pub enum MyEnum { White=1, Yellow, Blue, } Am on my phone, can't test but I think I saw code like this somewhere.
Could the crate, on its first error per thread, preallocate some heap memory for storing error objects, and use that storage from that on if possible? 
How about RISC-V. No SIMD yet :(
I do have some open union code lying around: https://gist.github.com/Sgeo/ecee21895815fb2066e3 Not sure how ergonomic it would be to use this though.
As far as I can tell nom only works on bytestreams of data, whereas I'm parsing and transforming the Rust AST using a syntax plugin. The markup that I parse is actually turned into valid Rust syntax, you can even use Rust expressions as attribute values :)
I'm getting an error: cannot move out of borrowed content. Here's my code: use std::str::Chars; pub struct Test &lt;'a&gt; { pub chars: Chars&lt;'a&gt;, } impl &lt;'a&gt; Iterator for Test &lt;'a&gt; { type Item = String; fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; { match self.chars.next() { Some(c) if c.is_digit(10) =&gt; { let literal = self.chars // .clone() .take_while(|x| x.is_digit(10)) .fold(String::from(c.to_string()), |acc, x| acc + &amp;x.to_string()); Some(literal) } _ =&gt; None } } } (This is just a trivial example of what I'm _actually_ trying to do, but it's essentially the same problem). If I leave the code like that, it doesn't compile - it says I can't move _self_ out of borrowed content (on the line _let literal = self.chars_). I can fix the error by uncommenting _.clone()_, but then it takes characters from a clone of the character stream, not the actual one, so it only advances one character per _.next()_ call on _Test_, i.e. for the characters of '12345' it returns '12345', then '1234', then '123', ... and so on. I also tried, on the line after _.fold(...)_ skipping the iterator by the length of the literal - 1, but that gives the same error as I get without _.clone()_. Does anyone know how to get round this problem?
As of right now, that's the goal or at least being as close to it as possible. How practical that remains as the framework is fleshed out remains to be seen. For pure Rust dependencies, they can be statically linked to the executable and you end up with just one. AFAIK I use `font-loader` on macOS/Linux which behind the scenes uses `fontconfig` (at least on Linux, I believe it uses CoreText on a Mac) which is a native dep which implies it'll likely be dynamically linked.
If I wrap I'm back to square one: the enum size is twice as big as needed.
 let server = listener.incoming() .for_each(|(client, _addr)| { // process `client` by spawning a new task ... let s = || Ok(TcpService { sender: distributor_tx.clone() }); let (w, r) = client.framed(TcpCodec).split(); let service = s.new_service().expect("Cannot create service"); let responses = r.and_then(move |req| service.call(req)); let server = w.send_all(responses) .then(|_| Ok(())); handle.spawn(server); Ok(()) // keep accepting connections }); The service is defined as follows: struct TcpService { sender: Sender&lt;DistributorMessage&gt; } impl Service for TcpService { // These types must match the corresponding protocol types: type Request = TcpMessage; type Response = TcpMessage; // For non-streaming protocols, service errors are always io::Error type Error = io::Error; // The future for computing the response; box it for simplicity. type Future = BoxFuture&lt;Self::Response, Self::Error&gt;; // Produce a future for computing a response from a request. fn call(&amp;self, req: Self::Request) -&gt; Self::Future { let (tx, rx) = oneshot::channel(); let msg = DistributorMessage::Request(tx,req.clone()); self.sender.send(msg).unwrap(); rx.and_then(|msg| future::ok(msg)) .or_else(|_| future::ok(req)) .boxed() } } A `TcpMessage` is a wrapper that contains a one-byte opcode and the message payload (`Vec&lt;u8&gt;`), `DistributorMessage`s are sent to the main thread to do some work (e.g. serializing and compressing the media library). Finally, I use the following code to read the socket's input stream in Java. `RAW_BUFFER_SIZE` is 1024: private void fromStream(InputStream stream) throws IOException { ByteArrayOutputStream baos = new ByteArrayOutputStream(); // Read opcode int offset = 0; byte[] rawBuffer = new byte[RAW_BUFFER_SIZE]; stream.read(rawBuffer, offset, 1); // Read length do { ++offset; stream.read(rawBuffer, offset, 1); } while((rawBuffer[offset] &amp; (byte) 128) != 0); ++offset; // Decode length int length = 0; for (int i = 1; i &lt; offset; i++) { length = (length &lt;&lt; 7) | (rawBuffer[i] &amp; 0b01111111); } size = length + offset; // Read rest if (size &lt;= RAW_BUFFER_SIZE) { stream.read(rawBuffer, offset, length); baos.write(rawBuffer, 0, size); } else { baos.write(rawBuffer, 0, offset); do { stream.read(rawBuffer, 0, RAW_BUFFER_SIZE); baos.write(rawBuffer); length -= RAW_BUFFER_SIZE; } while(length &gt; RAW_BUFFER_SIZE); stream.read(rawBuffer, 0, length); baos.write(rawBuffer, 0, length); } buffer = new ByteArrayInputStream(baos.toByteArray()); }
Yeah, but I'm not sure what you expect... you want to store a value + an enum in one structure, it's at least going to take two words (id of the variant + actual value) no matter the language. Could you write equivalent C or C++ code that shows how you'd do this in one word? Rust also has unions, but they don't seem applicable in your case.
FML I should not have missed this meetup, looks like there were some awesome talks.
If you want type safety, use an enum and accept that it's two words. If you don't need type safety, use `const YELLOW: u32 = 1;` (which is equivalent to `#define`), but accept that anyone can pass any random number to the function. Or use an enum, but split your `Other` into the appropriate values. Then you have type safety, but you neednto explicitly enumerate ehat values those "Other" variants have.
If you take a look at the definition of `take_while`, you'll find: fn take_while&lt;P&gt;(self, predicate: P) -&gt; TakeWhile&lt;Self, P&gt; ... It takes `self` by value, so that's why you can't use it on `self.chars` - because it is borrowed and non-copy, so you can't move it out. That's why using `.clone()` works - it produces a new iterator that `take_while` then consumes. To make this work you can make use of the impl impl&lt;'a, I&gt; Iterator for &amp;'a mut I where I: Iterator + ?Sized A mutable reference to an iterator is also an iterator. So you can use `(&amp;mut self.chars)` instead of `self.chars` - it borrows `self.chars`, and then you can give away that mutable reference to `take_while`. let literal = (&amp;mut self.chars) .take_while(|x| x.is_digit(10)) .fold(String::from(c.to_string()), |acc, x| acc + &amp;x.to_string()); Side note: `String::from(c.to_string())` could be simplified to `c.to_string()`. Also, you closure creates a new string from a char just to append it to another string. You can rewrite the closure to `|mut acc, x| { acc.push(x); acc }` to save yourself an allocation.
&gt; a stable error kind ID (maybe a UUID) that I can test against This is sort of what the vtable pointer is. You can use `downcast_ref` to test it. I do agree with you, though, that there should be an easier way to create a one-off error that you can check for later in your program, without adding all of them to some global enum. One option is to create ZSTs for each error (e.g. `struct MyErrorOne;`) and use `downcast_ref`, while another approach is to represent each error with a `&amp;'static str` stored in a const that you bubble up using [error_msg](https://github.com/withoutboats/failure/blob/master/src/error_message.rs#L10). I think part of the problem is that there really are so many different ways to do this, so they don't really interoperate well to the point where there's a simple answer to "how do I check if this error is the same kind of error as this other error".
[That isn't wrapping](https://play.rust-lang.org/?gist=f78c718b9fa33e3f82bfde4199601134&amp;version=stable).
It worked - thanks! The ?Sized was a bit confusing so I used (&amp;mut self.chars)
What's with your github [avatar](https://en.wikipedia.org/wiki/Saturn_Devouring_His_Son)?
Wonderful! Thanks for the clarification! :) 
Doesn't that essentially mean that you could/would have a separate error type for each function?
&gt; cause Go programs rarely rely on libc or OpenSSL They actually do. They just statically link both of these. `OpenSSL` being statically linked opens up a big can of worms because then _what go compiler version_ built your service determines if it is vulnerable to certain attacks or note. Furthermore Go's TLS implementation isn't constant time on any platform that is not x86/64. So if you deploy Go w/ TLS on ARM your sessions keys can be snooped.
I think those are all excellent use cases for downcasting rather than requiring you to enumerate all possible errors.
If you want that level of control.
That would be replicating the function of the allocator and I doubt it would be beneficial. 
It is my favorite painting.
/r/playrust
This is a strange way to handle the creation of an UI, I'm curious about that :) Keep the sub updated !
What for? Heap allocation is fast. Only if you overdo it, then the overhead of managing allocation meta data becomes noticeable.
Those create types that implement `std::error::Error`.
Heap allocation can fail. I'd rather not need error handling code for my error handling code. ;-]
I think that's potentially the right way to go, although it's obviously more difficult in rust currently. Consider checked exceptions in Java, for example. I can easily declare a method to throw any combination of checked exceptions and the compiler checks that they're handled. It would be nice to get that kind of ease of use for errors in rust.
I was so relieved when I searched in the workshop and found out I was the first to do this! If you happen to really like it, here's the link: http://steamcommunity.com/sharedfiles/filedetails/?id=1194592459 Criticism WELCOME! I won't learn to make a good skin without hearing what I can do to improve!
/r/playrust
Looks cool, but I think you meant to post this to /r/playrust, this subreddit is for discussion of the Rust programming language :-).
I'm sorry, I feel like a complete dope
Sorry :( I didn't notice. Thank you so much!
Isn't faktory just sidekiq with stable API? You could have written workers in any languages that can connect to redis before... 
Is it possible to write a nonrecursive function to get a mutable partition (of mutable refs) of a slice. For example if I have the slice `[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]` then a partition might be `[[0, 1, 2, 3, 4], [5, 6], [7, 8, 9]]: Vec&lt;&amp;'a mut [i64]&gt;` Here is an example of recursive code that does what I need ([playground](https://play.rust-lang.org/?gist=a5440419d71826aa1bcc5957e8cd6a5a&amp;version=stable)): fn split_buffer_rec&lt;'a&gt;(buffer: &amp;'a mut [i64], indices: &amp;[usize], ret: &amp;mut Vec&lt;&amp;'a mut [i64]&gt;) { if indices.len() == 0 { ret.push(buffer); return; } let (left, right) = buffer.split_at_mut(indices[0]); ret.push(left); split_buffer_rec(right, &amp;indices[1..], ret); } Unfortunately rust doesn't have [tail call elimination](https://github.com/rust-lang/rfcs/issues/271) yet, so this approach risks stack overflow for large numbers of indices. Here is an iterative version I tried: fn split_buffer&lt;'a&gt;(buffer: &amp;'a mut [i64], indices: &amp;[usize]) -&gt; Vec&lt;&amp;'a mut [i64]&gt; { let mut ret = Vec::with_capacity(indices.len()); let mut remainder = buffer; for index in indices { let (left, right) = remainder.split_at_mut(*index); ret.push(left); remainder = right; } ret } But the borrow checker doesn't like the reborrow of remainder in the loop. Is there any way to do this without using `unsafe`?
First impression: Awesome. Then unfortunally, I read this: https://github.com/contribsys/faktory/issues/21 Basically system is great, until your master crashes ;)
That's a work by Goya right? Or Caravaggio... I always confuse them because I was a bad art student :)
Funnily enough, the only change you need is wrapping `remainder` in curly braces: fn split_buffer&lt;'a&gt;(buffer: &amp;'a mut [i64], indices: &amp;[usize]) -&gt; Vec&lt;&amp;'a mut [i64]&gt; { let mut ret = Vec::with_capacity(indices.len()); let mut remainder = buffer; for index in indices { let (left, right) = {remainder}.split_at_mut(*index); ret.push(left); remainder = right; } ret } When you call `split_at_mut` it reborrows `remainder` instead of moving it (`remainder` is a mutable reference that you could move). Because it is borrowed you cannot assign it later. Wrapping usage of a mutable reference in curly braces forces to move that reference, so it is not borrowed anymore afterwards.
Wow, that's fascinating. I would not have guessed. Thank you! So to be clear, the *borrow* itself is getting **moved**?
Within the error-chain ecosystem I typically implement `From` for my custom top-level error types, then everything is just an into away, and I've also got various custom responses/handlers for my error type. `Fail` send like it will support that pretty well. Some sort of `downcast_match!` macro seems pretty straightforward to implement? ... Yup, [this exists](https://crates.io/crates/match-downcast). (I haven't looked at that at all.)
Convenience link to the LLVM bug with more context and the original example in C: https://bugs.llvm.org/show_bug.cgi?id=35229
Isn't `const fn` for computing things at compile time, like C++'s `constexpr`? That doesn't sound like it would work for the `Mutex` constructor, which needs to actually create the mutex at run-time (by calling `pthread_mutex_init` or equivalent).
It catches them, but it just says "never use `#[inline(always)]`" and doesn't say why (in this case because it has no effect, whether or not it's a bad idea).
The lower_bound and upper_bound APIs return the zeroth and last element regardless if the element at those locations adheres to the contract stated by the function's documentation. Shouldn't the return type be an Option&lt;usize&gt; instead to allow this to be indicated?
Has anyone been able to parse a csv into a matrix in Rust? I'm looking at using [`csv`](https://docs.rs/csv/1.0.0-beta.5/csv/) and [`nalgebra`](http://nalgebra.org/rustdoc/nalgebra/index.html) to read csv-formatted data into a Matrix shaped at runtime, but I'm having difficulties with basically every step of the process and I can't seem to find any resources that have accomplished this...
This wouldn't even prevent that because this pre-allocation not guaranteed to be enough heap memory, its not guaranteed to not be occupied by unfreed data, etc. Allocators are actually very good and are doing all of the clever things you might think of doing *already for you*.
I mean, I feel like this is solely an LLVM bug. It isn't a mistake within the Rust compiler, so while it should be monitored and it should be ensured that it gets fixed, I don't think it's a sensational thing that needs great attention right now. This isn't the first bug in LLVM, and it won't be the last one.
What. Ever overrun the stack? Runs out way faster than heap, unless you have severe memory leaks in quite a big loop. That is overly paranoid.
The compiler could reduce the type signature sometimes, but not in all cases. Consider the following: expected type: Result&lt;SomeType&gt; found type: Result&lt;SomeType&gt; Now you'll think the compiler is just plain wrong, however the following would make it clear. expected type: std::io::Result&lt;SomeType&gt; found type: std::fmt::Result&lt;SomeType&gt; So it's a trade-off being explicit at the cost of being verbose.
I was thinking the best case would be to have the compiler decide when it prints the error how much it needs to be qualified to be unique.
&gt; UFCS https://en.wikipedia.org/wiki/Uniform_Function_Call_Syntax Doesn't Rust mandate type signatures in all methods? A type based diff of an API should happen at some normalized, canonical representation. I still think it is doable. Could even be a feature of Rust doc where you can generate a doc bundle from a git repro passing in a list of tags, and it will generate a delta between all the versions, ensuring that the semver of the tags matches what it found in the API surface.
That would be a nice improvement.
&gt;Is there a way to tell the compiler that I know what an Option is, so it doesn't need to prefix it with it's full path? You can add ``` use std::option::Option ``` at the beginning of the file so that it's in scope. 
I don't think this works. Here's a minimal [playgroud](https://play.rust-lang.org/?gist=d126936ab5214ab5bd59243d4ea3a728&amp;version=stable) where I put a `use std::option::Option` at the top of the file, but `rustc` still tells me that it found type `std::option::Option&lt;_&gt;`, which is the same as [this](https://play.rust-lang.org/?gist=876da765c1d063bb0e893d5c9d431cde&amp;version=stable) playground that doesn't have a `use std::option::Option`. This is of course on stable rust, maybe beta or nightly is different.
IMHO, letting having `p = (&amp;y as *const _).wrapping_offset(1)` as safe and then expecting `q as *const _ == p` to have a defined behaviour is a bit dangerous. This can probably be fixed on LLVM's side with some rule in the memory model but at what cost?
It doesn't seem to be getting sensationalized at all. Should we ignore bugs that impact Rust just because they exist in the backend of the compiler? Why would we do that when the end result is the same as if it were in the front end?
It is but it isnâ€™t. There are already Mutex implementations that have a const fn constructor that works. (Theyâ€™re spinlocks) Miri opens up a ton of stuff, even allocating at compile time, but Iâ€™ll also admit that Mutex implementations arenâ€™t my specialty.
It's not bad, and there's many cases where it's the right solution. The thing that people push about is forcing people into having to Box their traits. If my code uses your library but only instantiates 1 type it may not be cheaper to use a boxed trait. Maybe I'm in an environment were I don't want to hit the situation. Generally it's a tool and has right and wrong places. Don't build APIs that force someone else to use them because you never know if it makes sense for them to or not. Use them inside your library in abstracted and hidden away fashions if it makes sense.
I am indeed.
Both `std::io::Result` and `std::fmt::Result` are type aliases, so youâ€™d actually see `Result&lt;SomeType, Error&gt;` and `Result&lt;SomeType, Error&gt;`! Allowing it to abridge types using employed type aliases would also be nice.
What specifically ought to be undefined about it? Is the equivalent C undefined behavior?
At the very least, allowing Cargo to support C/C++ directly will allow for easier integration of parts of projects written in C/C++, instead of having to mess with a `build.rs` script and such.
Are you saying there is a documentation bug or an implementation bug? Can you give an example?
The problem with that, is it's possible that it doesn't need to disambiguate for a particular error message. But other components in your project might qualify to the same thing. So the message would no longer be consciousness towards the programmers own knowledge of the code base.
I didn't say it was being sensationalized, I said it's not some sensational thing. I'm not suggesting to ignore such bugs, but I am saying no other LLVM-based programming language community is discussing this bug, simply because it is such a non-issue.
NM, I misread lower_bound because of the negation used in the documentation, but I'd like to offer a suggestion: In time series computations, binary search is useful for one purpose, most of the time: getting an exact or nearest match from a collection of timestamped data. lower_bound and upper_bound let you get the largest match or the NEXT largest match in the increasing direction. But there's no function to let you get the smallest match or the PREVIOUS smallest match in the decreasing direction. For example, when doing time series calculations, finding the thing that happened immediately prior to an a timestamp is *very* useful. That is, say you have two vectors, one of high frequency deltas, and one of low frequency absolute measurements. If you want to know the absolute value at a high frequency delta, you take the timestamp from the delta you're interested in, use a binary search in the decreasing direction and then accumulate any deltas greater than the time of the absolute measurement.
Absolutely agree. Things like `std::result::Result`, and `std::option::Option` should be ubiquitous enough that they don't need the crate prefix.
No, `==` doesn't have undefined behaviour. (However, the ordering operators `&lt;` and `&gt;=` etc do: they essentially require the operands point to the same object.)
TF when you realize you're following since ~ week 50. 
I agree they're "ubiquitous enough". To put it precisely, those types are in the [prelude](https://doc.rust-lang.org/std/prelude/), and there's an implicit `use std::prelude::v1::*;` in every module. You generally don't have to type the full name to them. (I think the exception is if you define your own `Result` type; then yours wins out over the use declaration.) I think it'd be reasonable for the compiler to describe the type using the least qualified form that would be accepted at the site of the error. This would produce the terse form /u/YourGamerMom expected. I think this would be a big readability improvement. I guess the catch is that if there are tools that are doing something like hyperlinking to types in error messages, they'd need to be aware of the context to point to the correct type. I don't know if such tools actually exist or not, just speculating.
Itâ€™s Sidekiq minus Redis, reinvents the storage layer with RocksDB. And yeah, itâ€™s fairly similar. I have a side project that sends jobs from Python to a Rails/Sidekiq processor.
Nice, I hope that this will significantly improve the error story in Rust. Error management (not handling), as you define it, has been one of my gripes with it. One of the things I wish were better is returning more specific errors - at the moment the tendency is to have a huge type that contains everything, regardless of whether many of those errors could actually happen in that context. Ideally, the type system would help to present the exact set of possible errors in each context. Of course, it isn't expressive enough to do that without defining an unique enum type for each function call, which is a huge amount of boiler plate. If there was a way to define ad-hoc enums as a combination types (and that would be matched against types, not named variants; also note the parallel to ad-hoc product types i.e. tuples), that would help returning the exact set of errors and having the compiler help to do an exact match of them. Has there been any thoughts between the language design team about such a feature? /u/desiringmachines
This is the subreddit for the rust programming language. You're looking for /r/playrust
The pointer comparison alone was not the problem. My point was that we first created a pointer which doesn't really point to something safe with `wrapping_offset` (dereferencing it would actually require unsafe) or even very well defined and then we're using it in a comparison. I'm not sure one would want that to really be safe or have a defined behavior.
I don't think tools would be using the human-facing error output, since `rustc` can produce [json](https://github.com/rust-lang/rust/pull/35401) output formats, which would be better for a tool to read.
lul my b 
`wrapping_offset` is explicitly designed for creating such possibly-invalid pointers (in contrast to the `unsafe` `offset`), and these pointers should be fine to compare for equality and offset further with `wrapping_offset`, neither of which do any dereferencing.
So from what you're saying, and the bit of Googling I've done, rustc needs the GNU linker to properly link its own object files? I'd figured the LLVM backend did that, but now I better understand after viewing some of images posted to this page: https://users.rust-lang.org/t/the-big-picture-of-compilation-in-rust/6380/6 Thanks for enlightening me! I'll update when I get the chance.
It's not undefined in C, but only by a hair. C has a provision that obtaining a pointer one past the end of an array is legal and that non-arrays are considered as arrays of one element in this context. The program would be undefined if the used offset didn't happen to be 1. (It would be undefined even if the pointer is never dereferenced.)
You're in the wrong subreddit my dude /r/playrust 
Yeah I saw thx man
Excuse my ignorance... Miri?
It is almost like we want a license chooser that, given a set of qualities that are desirable, it gives the user a choice of compatible licenses. 
&gt; Mozilla Public License 2 I am kinda embarrassed actually. I am Freedom(tm) nerd and I just learned that the MPL 2 is righteous! https://tldrlegal.com/license/mozilla-public-license-2.0-(mpl-2)
I'm like 1 day away from cutting the 0.9.0 release of [statrs](https://github.com/boxtown/statrs). Just a mere 2 months longer than intended -.-
Hi, thanks for the awesome impression. We're working hard on features but also improvements to the storage subsystem. One thing to consider, Queues are designed to be emptied quickly so it's unlikely you'll have gigs or even megs of data persisted for too long. This isn't a terabyte-sized RDBMS. If you or others are interested in helping out, stop by and say hi. https://gitter.im/contribsys/faktory
MIR = Mid-Level Intermediate Representation Miri = MIR Interpreter Compilers like Rust and GCC take code through multiple stages, each with different strengths when it comes to running optimizers. Rust goes `Code -&gt; HIR -&gt; MIR -&gt; LLVM IR` and then lets LLVM handle generating the machine code after its own optimizers run. Miri allows bits of MIR to be executed within the compiler without having to walk all the way down the chain to machine code so that Rust can effectively support compile-time function evaluation within certain specified limits.
Be careful with the word "just". :-) You'd need to implement every Sidekiq feature in every language you want to use and keep all the languages data-compatible. This way I can push many of the features directly into Faktory, keeping the workers "dumb".
I could imagine '[fail(display = ...)]' being useful for other types than Error messages. Would it make sense to place it in a separate library named 'derive_display'? 
Why is it faster? Could the implementation replace rust standard library implementation?
I have been loosely following the MIR developments in Rust, but didn't appreciate that there would be an interpreter built to enable MIR-level optimizations. Neat. Thanks also for the gcc notes, haven't seen it laid out that clearly before
Sorry, I think I took it more as a dismissal, and that coupled with my comment being a bit rushed I think it was a bit more of an attack on your post than I'd intended. I only mean to express that I, as a rust developer, want myself and other rust developers to be aware of these potential soundness issues, and I think it would be nice if they were generally more public knowledge. This is because regardless of where these issues exist it still impacts us, and importantly it impacts the users we build software for. *If* this could lead to UB, I don't see it as a non-issue.
I don't think that's quite true: that would be C's behaviour if the Rust used `offset` instead of `wrapping_offset`, I guess the equivalent C would cast to integers and back (but that seems like it might be UB too, in the back of my mind, in which case there may not be directly equivalent C).
I think this has been brought up several times. See [[1]](https://internals.rust-lang.org/t/improving-error-messages/5892), [#19792](https://github.com/rust-lang/rust/issues/19792), [#21934](https://github.com/rust-lang/rust/issues/21934).
I understand, that dataloss will be small when queues are empty. I was more concerned about high availability scenario (which do not have, when you have single point of failure). But on the other hand, maybe I am just repeating mantras from distributed systems, and one SPOF is not a big deal in most cases.
&gt; several types that are serializable Sounds like a behavior to me. Serde's deserialize picks the type to deser to based on the return type deduction. You could do something similar, but for serialization. fn ser(respose: InternalResponse) -&gt; ExternalResponse { if response.version == "3.5" { let response: Response3_5 = serialize (InternalResponse) ... } // No ; }
Where InternalResponse is the internal data representation you actually use and Response3_5 is a struct that matches an extension response and ExternalResponse is a trait that just abstracts just common to all ExternalResponses (like construct a network packet or something).
As the type determines the constructed path into the API, what of the use case where you could get the same result 'type' information back from the REST API, but on different paths? Or would that means the API is designed poorly? I was thinking about a use case where you could limit the responses to say data that has changed since a certain timestamp encoded in the path, but maybe a POST with the timestamp would be a more natural way to request this information?
Yeah, the lint should be extended. But the gist is: use `#[inline(always)]` only if you absolutely need it. On generic methods it is usually pointless, on plain functions `#[inline]` often suffices, but of course do the measurement or look at the generated assembly if you really need the perf. More often than not, you'll be surprised.
Yeah, it's been a helluva ride so far. ðŸ˜Ž 13/10 not getting off any time soon...
Both questions are answered in the pull request: https://github.com/rust-lang/rust/pull/45333 In short: Yes they are working on integrating this into std. The binary search is faster because it avoids branches in the inner loop. It is known as "Branchless Binary Search". Here is the paper: https://arxiv.org/abs/1509.05053
&gt; lower_bound and upper_bound let you get the largest match or the NEXT largest match in the increasing direction. &gt; But there's no function to let you get the smallest match or the PREVIOUS smallest match in the decreasing direction. `lower_bound` gets you the smallest match, or the position of the next element. If you want to go backward one element instead, you can subtract one, unless I'm very confused about what you are doing. 
&gt; Heap allocation is fast Sure but you don't always have a Heap available. 
I think in cases like that it would be good if the error message had the differing part highlighted. And the type names should start from the same column so that scanning it with your eyes would be easier. So instead of expected type: std::io::Result&lt;SomeType&gt; found type: std::fmt::Result&lt;SomeType&gt; You'd have expected type: std::io::Result&lt;SomeType&gt; found type: std::fmt::Result&lt;SomeType&gt;
Perhaps you could get the short version and the details afterwards, a bit like defining a generic `T` afterwards with `where`. 
You would see different Error objects (resp. io::Error and fmt::Error) though, no?
As long as you never dereference them, comparing two pointers is not different from comparing two `usize`. Why should it be undefined ?
An async book, huh? Neat, lookin' forward to it!
What's the point you're trying to make? `alloc` is opt-in. Don't have it don't use it.
&gt; https://github.com/rust-lang/rust/pull/45333 Awesome! thanks.
I'm wondering: How likely is it to encounter this bug in a 'in-the-wild' Rust program or library? Because debugging this would be a nightmare for me. But I lack the knowledge to assess the frequency of this bug.. it makes me slightly uncomfortable because all I see are very basic operations like assignments and equality checks. 
Incidentally, this sort of thing is where Rustâ€™s expression orientation shines: you can write *one* assignment, and that guarantees that youâ€™ve *got* to write out every case. You might end up with something like this, for example: *b = match *b { b@b'A'...b'Z' =&gt; rot13_byte(b, b'A'), b@b'a'...b'z' =&gt; rot13_byte(b, b'a'), b =&gt; b, }; (Too many bees, yes. But thatâ€™s just how I chose to write it.)
Unlikely, otherwise any of the several unit / integration tests in place would have failed.
&gt;why is it necessary to supply the various camera attributes by hand? Aren't those in the RAW's TIFF structure? Not for most formats. DNG has those but most of the custom camera formats need that extra metadata to be supplied. It's quite simple to do it though. I have a script to generate the metadata files from samples. If you have a camera that's not supported I can add it easily. &gt;Also, if it's not too complicated, could you please explain in the most basic terms what steps are needed to develop a RAW file? rawloader is focused on getting the raw bayer data out of the file. So that's just the pixel intensity at each location and the metadata around it. I've also included a basic pipeline that I will be splitting out into its own crate. In basic terms you need to demosaic, adjust whitebalance, apply the color matrix to transform camera color space to some space you care about (an intermediate Lab or straight to an RGB is common) and apply a gain curve because the sensor has linear values.
I am not trying to make any points. I just would like to use `Error` when I don't have a heap. 
There could be a verbose flag for that case.
I just would like to use `Error` when I don't have a heap, and having to implement `alloc` just for that seems overkill (to me).
Having compiler-checkable error-handling like this is my single favourite feature about Rust's result/error system. Any easier-to-use system I would migrate to would definitely have to preserve that.
I didn't even get as far as trying to build it because I was trying to figure out what the missing half of the example (_handling_ errors) should look like.
The main problem with `Box&lt;Trait&gt;` is that whether that's the right solution or not is application dependent. If you have a library API and return `-&gt; impl Trait`, and for my application `-&gt; Box&lt;Trait&gt;` is a better fit, I can trivially wrap your API into one that returns `-&gt; Box&lt;Trait&gt;`. However, if the library author makes that decision for me and returns `-&gt; Box&lt;Trait&gt;` and for my application that's a no go (e.g. `Box` is not available), then I just can't use your library, period. So sure, if you are writing a final application, and feel like using `Box&lt;Trait&gt;` everywhere, go for it, that's your decision, but if you are writing a library, think it thrice before returning `Box&lt;Trait&gt;`, because then you are making a big decision for your users.
I'm guessing, but I would think that `*b = *b` is not a NO-OP and should attempt to dereference the location and explode if it is for some reason problematic. The `_ =&gt; {}` case is saying "conditionally, don't dereference the location" whereas your other cases do dereference, and the potentially observable control flow probably screws up the vectorization.
The `*b = *b` will make the rust compiler emit some code to create some temporaries at the very least, which even though it will be optimized out may influence the llvm vectorizer.
Wouldn't the first clone + adding the "move" keyword be enough?
Apparently not. Maybe because of self..
The `{}` version has a conditional write, in the `*b = *b`, the write is unconditional. From my understanding of x86 instruction set, conditional writes are probably impossible to vectorize. In theory, the compiler could transform the first version into second (by adding this dummy write), but I think all modern compilers use a rule â€œdon't emit a write where there wasn't one originallyâ€. In theory, the `&amp;mut [u8]` allow inserting that dummy write, but LLVM was written for C originally, where such optimization is not legal. Anyway, I'm not even sure it would be legal in Rust, because the memory model is still in the works, maybe somebody can chime in and comment on that. Anyway, I'd go with the u/chris-morgan version.
Author of the library here. &gt; what of the use case where you could get the same result 'type' information back from the REST API, but on different paths? In this case you could implement the `RestPath` trait with generic parameter that specifies which path should be used (e.g. enum). In the example in the Readme the path parameter is used directly in the `format!` but that does not need to be the case. You could do anything with it, e.g. use enum in a match clause to select correct path. The good thing about this approach is that the compiler enforces that proper parameters are used with get and post which hopefully reduces bugs compared to manual URL parsing. &gt; use case where you could limit the responses to say data that has changed since a certain timestamp Usually how I have seen this sort of things done is with query parameters: e.g. `?limit=100&amp;after=123456` after the actual path in the URL. This is possible with `get_with` and `post_with` functions that accept additional query parameters. Hopefully these answered your questions :) 
I'm not sure what you're talking about. Do you mean the [ErrorKind](https://doc.rust-lang.org/std/io/enum.ErrorKind.html) enum? If so, the reason that has "some variants emitted" is because it's designed to be extended if need be, and allowing you to match against each variant would mean that code would break if something was added.
Yes, thank you very much!
&gt; however in the event this function doesn't correctly identify all errors in the result&lt;&gt; channel I don't understand this part. Can you unpack it? (I don't see what's ambiguous about the docs for `read_exact`. It specifies particular behavior for some error conditions, and then specifies another blanket type of behavior for all other errors.) Can you show other examples?
&gt; Square roots are irrational (in general) so at that point only symbolic computation will save you from loss of precision. Or lazy computation, that is, computing the digits on demand. The two amounts to the same thing in the end.
I'm pretty sure I encountered this situation before and that I found a good solution. Could you write a gist on https://play.rust-lang.org/ ?
Please file bugs for anything you find, one per issue. We're very happy to clarify the docs.
My guess is that it's unlikely that you'd hit it in the wild. It almost certainly requires raw pointers, and a fairly specific combination of operations to trigger.
Result&lt;&gt; is a return type that is an Enum that can be either Ok(some) or Err() with some sort of error in it. By channel, I mean the return channel through which the Result variant is returned. Note the documentation for write_exact: &gt; If this function encounters an error of the kind ErrorKind::Interrupted then the error is ignored and the operation will continue. &gt;If this function encounters an "end of file" before completely filling the buffer, it returns an error of the kind ErrorKind::UnexpectedEof. The contents of buf are unspecified in this case. &gt;If any other read error is encountered then this function immediately returns. The contents of buf are unspecified in this case. It specifically states the behavior of the ErrorKind::Interrupted error being encountered, and explicitly states the ErrorKind::UnexpectedEof error is returned on "end of file" being encountered. However, when it discusses any other type of error, it says that the function immediately returns, however it leaves ambiguous what it returns, does it return an Ok(()) or an Err() of some sort? I would assume it returns an error, but they've worded the sentence regarding any other error being encountered so ambiguously that I can't determine the actual behavior of this function without making assumptions. 
Hmm... maybe I've just been thinking of this in terms of a particular broken API for too long. I'll test something today and get back to you about whether I'm full of it or not.
Also I don't even understand what this means really: &gt;No guarantees are provided about the contents of buf when this function is called, implementations cannot rely on any property of the contents of buf being true. It is recommended that implementations only write data to buf instead of reading its contents. What do they mean by lack of guarantees regarding the contents of buf? Or implementations not being able to rely on any property of the contents of buf being true? Can this be rephrased as; it is unknown what data will be written to buf, because the source of the information can provide arbitrary data? When they discuss implementations I presume they mean people who write implementations of read_exact themselves? Actually, I have found it easier to make sense of this documentation the second time reading it, though I still do find that it could be improved and that parts are ambiguous. To some extent perhaps this is my lack of mastery of Rust, I mean I've many hundred hours of practice now but still not as much as C, perhaps this hinders my ability to infer things from the documentation, or to reason about it as well as I could the C documentation I'd thousands of hours of experience with. 
Oh I see. Yeah for things like that I'd just submit a PR. e.g., "... immediately returns." -&gt; "... immediately returns the error."
Yeah, it'd be easy enough to detect when types have similar names and to highlight the differences at least.
OK. From your OP, it sounded like you were lodging a generic criticism across all documentation in the ecosystem, but it sounds like you're just getting tripped up over this one method. I don't think that needs an essay on reddit to fix. :-) Like Steve said, just file bugs or PRs with suggestions for re-wording.
What does `as *const _` mean?
I didn't realise you could write [an impl for a trait without reference to a particular implementation](https://github.com/withoutboats/failure/blob/d20a5ea7ec5d5b4e7e027bc8af01c0c8ca88d7f0/src/lib.rs#L129): ``` pub trait Fail: Display + Debug + Send + Sync + 'static { // ... } impl Fail { pub fn downcast_ref&lt;T: Fail&gt;(&amp;self) -&gt; Option&lt;&amp;T&gt; { // ... } } ``` Or have i misunderstood what is going on here? Is there a name for this? Is it in the language documentation anywhere? Is it different to writing methods inside the trait body? 
The only constraint on this function's return value is that it return an Ok() or an Err(), there is no constraint that each variant of ErrorKind be returned to my knowledge, only that each variant be checked for in pattern matching on the value returned in an Err(). So I believe it is ambiguous actually the wording of this documentation, in that it doesn't specify what is returned on any other error, seeing as Ok() or Err() could both potentially be. If it returns Ok() on any errors it would essentially mean that not all errors regarding it can be detected by its return value, but it doesn't explicitly state that it returns error variants if other sorts of errors are detected, but does specify that some error conditions result in specifically error values being returned. 
Ok I'm glad you saw that my complaint had some validity to it :). Are you sure it immediately returns the error? I would assume so, but alas cannot determine from the documentation. 
Yes. The alternative is wildly unreasonable. :-)
Basically something like this: (https://play.rust-lang.org/?gist=f0549861a2ef49b77f06fb24ac30994f&amp;version=stable)[working] (https://play.rust-lang.org/?gist=ca14e7e5c969965155fdd88cf4d15296&amp;version=stable)[not working]
Great to see some more modbus support in Rust :) There also is https://github.com/hirschenberger/modbus-rs (sync but easy to use) and https://github.com/slowtec/tokio-modbus (async based on tokio) :)
Nice. Rust is closing in on parity with the major Linux distros. I think the only ones Debian and Gentoo support which Rust doesn't yet are: * RISC-V (Fedora port in progress) * x32 (unofficial Debian port listed under Sid, I remember reading about progress on this front in Rust recently) * Alpha (official Gentoo and unofficial Debian) * HPPA (official Gentoo and unofficial Debian) * SH4 (unofficial Debian) * m68k (unofficial Debian)
[This](https://play.rust-lang.org/?gist=3e0ad2df0dafb0e792244115313f32fa) is more what you're looking for I think.
I would like more details on the star destroyer
&gt; https://github.com/slowtec/tokio-modbus Thank you, this wasn't on my radar &gt;&lt;
It appears to be made out of Legos, and featured prominently in some of the pictures. I'm not entirely sure what it has to do with implementing RFCs, but it looks pretty impressive.
I am fairly new to rust so I'm trying to get my feet wet with a service to show the processes on a linux server in a structured format (had tried this a year or so ago but had not been able to get far): https://github.com/abhijat/system_snapshot_server It only parses the files in /proc into structs for now, I want to expose it over http soon.
Why not separate it with commas? That would make it feel more correct: `path!(base, "foo", "bar")`
Yes; the event at RustFest Zurich had a LEGO death star, the event at Rust Belt Rust had a LEGO star destroyer. Some people worked on implementing those to take a break from implementing Rust stuff :)
It's a somewhat confusing way of saying "Implementors of Read can only assume the buffer is filled with garbage." (There's also a [comma splice](https://en.wikipedia.org/wiki/Comma_splice) in the first sentence.) I agree it should really be made clear that this is a restriction on the implementor, not the user. 
Hi, very new to Rust and very excited :-) Can anyone recommend a simple graphics library? I only need basic capabilities: to load an existing picture, draw a bunch of triangles, compare two images by computing a pixel-wise distance or similar stuff. Thanks! 
Don't block your other work while you await it.
The opposite: we went working on Rust to take a break from building something amazing!
It is an impl for the type `Fail`, which designates the trait object. So you can call `downcast_ref` on a `Box&lt;Fail&gt;`, or a `&amp;Fail`. You cannot call it on a concrete type implementing `Fail` without casting to the trait object explicitly or using UFCS, but you wouldn't need `downcast_ref` there anyway.
`&amp;mut _` is just a regular non-copy type, which can be moved. But when you call methods on it, compiler doesn't move it - instead it does something like `method(&amp;mut *thing)` which instead creates a new reference that borrows the original one. Without this you wouldn't be able to call a method twice on a mutable reference. 
In reality I passed the Arc to another function instead of accessing a field. So I did have to clone twice.
x32 is working in release mode! (there are some bugs https://github.com/rust-lang/rust/issues/45416). In debug mode it does not work: https://github.com/rust-lang/rust/issues/45416
Has this been solved? If not, **to all future readers: you need to run Xargo in *nightly* rust. This should solve your problem**
&gt; Alpha LLVM dropped support for this in 2013 :( R.I.P. first and best 64bit processor
And there is also: https://github.com/cevans01/modbus-rust which you can run against: https://github.com/stephane/libmodbus/blob/master/tests/random-test-server.c 
No. For a few reasons * C really doesn't have a good way of expressing if a pointer is read/write only. `const T *` just means you won't cast, or do pointer maths on the pointer, not never write to its contents. * An Array in C is a pointer, its length is _something else_ either explicitly known, passed in a different, call, or passed in a different argument. There was a proposal in C99 to make arrays become `struct { data *T; ssize_t len; }`, identical to Rust's slices. But this ran into a lot of ABI inter-opt head aches. * C has no primitives that understand threading. Rust's `Send`/`Sync` are funky, but extremely useful. C still kind of assumes it is 1970, there is one thread, one processor, and when not being used your whole program's RAM will get swapped to disk. * C has no `drop` or `destructor` semantics. This makes RAII difficult.
Short Answer: **No, that's why a new language is necessary.** --- Long Answer: C, like unsafe Rust code, cannot be statically checked. There may be *subsets* of C that can be fully statically checked, at the cost of annotating functions (FRAMA-C?), however as far as I know fully statically checking any C program is still an open problem. If you wish to see the state of the art in this direction, I encourage you to look into life-or-death systems such as those in rockets, military equipment or planes. You can start with MISRA-C. In recent years, Clang has pioneered code-instrumentation (ASan, MemSan, TSan, UBSan, and soon TySan); those sanitizers instrument the code produced to detect some classes of undefined behavior however: - they are each specialized for a subset of undefined behaviors, and mutually incompatible, - they do not fully cover all cases of undefined behavior, - their memory footprint and the associated slow-down can easily reach 5x/10x in the worst cases. There are more lightweight attempts, if your goal is **hardening** rather than **debugging**, which you are encouraged to use in production code. For example CFI (Control-Flow Integrity) adds less than 1% overhead, there is also SafeStack, etc... Each mitigate a number of exploits, but they are far from Rust's safety guarantees being non-total run-time checks.
ARM? Running on it, that is, not just compiling for it. At least termux doesn't have it available (yes that's android, not plain linux). I've got spacemacs, clang and lua (and of course java but who wants that) on mobile but no rust... haskell would also be nice to have, while I'm at it. (For those wondering: Bluetooth keyboard. 720p are perfectly fine for coding, after a while you forget that the screen is only 6", only condition is having your nose close enough to it).
I put together some example code, you should be able to adapt it to your needs. Let me know if you have any questions! https://play.rust-lang.org/?gist=476facf112a6f79d4f515b2be089e472&amp;version=stable (It won't actually run on the playground because they don't have the `nalgebra` crate)
&gt; So it's a trade-off being explicit at the cost of being verbose. The compiler should compare the type paths and show them only if they are different, like a human would (entropic prioritization).
I remember there was an RFC about fields in traits, maybe this is what you need: https://github.com/nikomatsakis/fields-in-traits-rfc/blob/master/0000-fields-in-traits.md
Thanks for this! 
Goya. The Black Paintings. Exceptionally brutally amazing stuff. Back then people knew how to be emo. (He bought a two story house and painted on his walls.)
The `_` is a type left to be inferred, for the compiler to figure out from context. For example, with `let g = 0` inferred to be an `i32`, then `&amp;mut g` is a `&amp;mut i32`, and `&amp;mut g as *const _` will end up as `*const i32`.
&gt;Will there ever be a way to configure gcc or LLVM to make C code as safe as rust code? There already are ways to configure it to be safe, but all of them are going to be harder than just writing Rust. [ATS](http://www.ats-lang.org/) for example gives you the freedom of C, at the cost of making you (the programmer) give various proofs to ensure safety. Code verification is hard.
There are quite a few more than just ARM which don't have checkmarks for rustc and cargo on the [platform support list](https://forge.rust-lang.org/platform-support.html).
I was able to get something barebones with the two crates. extern crate csv; extern crate nalgebra as na; fn main() { let raw = "0,1,2,3"; let mut rdr = csv::Reader::from_string(raw).has_headers(false); let numbers = rdr.records() .flat_map(|r| r.expect("read entry").into_iter()) .map(|s| s.parse().expect("is number")) ; let rows = 2; let cols = 2; let mat = na::MatrixMN::&lt;u64, na::Dynamic, na::Dynamic&gt;::from_iterator(rows, cols, numbers); println!("{:?}", mat); } 
Thank heavens! I thought it was an RFC for getting rid of dereferences (`*`) or something..
Looking at [`Context`](https://github.com/withoutboats/failure/blob/master/src/context.rs), I'm a bit surprised by its behavior. If I'm reading this correctly, it looks like there isn't a good way to report a chain of contexts. `Display` will only show the context. Debug shows a debug print of the `Failure` and a non-debug print of the context. Recently with error-chain, I've been trying to improve my error reporting by adding context. I do this by calling [`chain_err`](https://docs.rs/error-chain/0.11.0/error_chain/trait.ChainedError.html#tymethod.chain_err) up the stack following by a [`display_chain`](https://docs.rs/error-chain/0.11.0/error_chain/trait.ChainedError.html#method.display_chain) to the user. Example in assert_cli PR - [text predicate fails](https://github.com/killercup/assert_cli/pull/74/files#diff-ac5cd937cc00cb0544b06a1b6ce1ce5eR22) - [add context whether it was stdout/stderr that failed](https://github.com/killercup/assert_cli/pull/74/files#diff-ac5cd937cc00cb0544b06a1b6ce1ce5eR211) - [add context of what command failed](https://github.com/killercup/assert_cli/pull/74/files#diff-b8e1279b7e534c886db53e49d60c14a5R359) This will print a nice error something to the effect of Assertion failed with command: echo "Hello world" caused by Unexpected stdout caused by Expected to contain "Something" output="Hello world" With `Fail`, I could keep chaining but in this or similar cases, `Context` might be more appropriate but it doesn't look like there is a way to chain contexts and get a nice string back.
Nice. Regarding not having the `Error` type with `no_std`, it would be really nice if this could be solved somehow. (I see there's already a comment thread about using `alloc`, but that has it's limitations.) What it comes down to is unsized objects needing an allocator. So what if there was a pre-allocated portion of memory and support for placing trait-objects there, if they are sufficiently small? I guess it comes down to placement new support?
&gt; [...] gives you the freedom of C, at the cost of making you (the programmer) give various proofs to ensure safety. This is also true of Rust :)
This is a very good point burntsushi. We've found something similar with `rand` where we wish to have some information available uniformly for all errors (the *error kind*), but also allow capturing any type of error. https://github.com/dhardy/rand/issues/10 (We also need `no_std` support; this makes the result a bit weird.)
In thinking more about this, I realize that this us from "checked exceptions" to "unchecked exceptions". I like the middle ground that Rust provides where error types can be strict but its easy (with error chain and `?`) to convert between them as you pass them up. I worry this will make it harder for library authors to document errors. I wonder if there is a happy middle ground somewhere where libraries can return a distinct type with distinct conversions so we can control what our top level errors vs our implementation-detail `cause`s.
From now on if I ever see valid code using (*) I will now call that symbol the Star Destroyer
There is an issue requesting rust [package](https://github.com/termux/termux-packages/issues/261) for termux. There is also a issue requesting a [host build](https://github.com/rust-lang/rust/issues/42639) for android (so it can be installed by rustup, which already works on android). You can use an unofficial package: https://wiki.termux.com/wiki/Package_Management#its-pointless_.28live_the_dream.29
Nice. Looks like we're making progress entering all *nix markets :D :D :D :D
Thanks for that, i Had the exact same question.
Ah, that's the idea! So what you want is the option to directly embed error data into a `Result` in case you do not use `std` *and* you don't have `alloc`, while keeping the boxing for those who do use any of them? I thought you were talking about not using boxing and thus not having `Error` at all, even though you could box with an opt-in `alloc` feature. Sorry for that misunderstanding.
Autoderef and reborrowing are the real star destroyers.
While I'm confident in this case that it does, one of the great things about having a single implementation is you can check the source pretty quickly if you aren't.
Thank you so much for this! I do have a quick novice question, if you don't mind :) I'm not sure if this question will make sense, but in the inner `for` loop, you're borrowing `record` with `&amp;record`, right? If I remove the ampersand (for no particular reason), the compiler tells me that `record` is a `csv::StringRecord`, not an iterator, and thus I should use `record.iter()` to obtain a `csv::StringRecordIter`. I'm wondering why for item in &amp;record and for item in record.iter() accomplish the same thing, since it doesn't make sense to me that borrowing `record` would magically turn into an iterator...
I'm waiting for servo to be able to use as own engine.
As of writing, there are still places where unsafe Rust is required to squeeze out the best performance. There's a [good explanation](https://doc.rust-lang.org/book/second-edition/ch19-01-unsafe-rust.html) of the design on the unsafe Rust page. 
In the following code from the rust book, why can we reassign `f`? use std::fs::File; fn main() { let f = File::open("hello.txt"); let f = match f { Ok(file) =&gt; file, Err(error) =&gt; { panic!("There was a problem"); }, }; } https://doc.rust-lang.org/book/second-edition/ch09-02-recoverable-errors-with-result.html
I can't tell what would be the bigger feat, that, or &gt; aturon and nmatsakis maybe finding a route to sound specialization??
Well... I don't want to discourage you, but for games, LuaJIT is more widely used than JS, because Lua is specifically made to be a small (&lt; 100KB), embeddable JIT language while JS is targeted at web-browsers / servers, mainly. [Here](https://github.com/fschutt/rlua_embed_test/blob/master/src/main.rs) is a test I built using [rlua](https://github.com/chucklefish/rlua) - to prove that it's possible to call Rust functions from a lua script. rlua and [hlua](https://github.com/tomaka/hlua/) are very easy to embed. I also tried Python, but that was a failure because you have to ship the Python DLL with the executable.
I've just understood it as an idiom but by looking at the trait implementations you can get a more rigorous understanding. The right side of a `for` expression needs to implement `IntoIterator`. [`&amp;StringRecord` impementes IntoIterator](https://docs.rs/csv/1.0.0-beta.5/csv/struct.StringRecord.html#impl-IntoIterator). I think the reason this idiom came about is if `StringRecord` (or whatever) implemented `IntoIterator` directly, it would consume the `StringRecord` for no reason. This could be confusing. By implementing `IntoIter` for a reference to the object it's more clear that the ownership works like a regular reference.
&gt; (My long-term dream is for retro-computing enthusiasts to extend Rust's support to the point where it could target something like Windows 95 or classic MacOS... but I'll take the real-mode DOS support in the latest Free Pascal release and the in-development Win16 support if that's all I can get. I just want to be able to comfortably code and cross-compile for my retro-gaming PCs without having to resort to Open Watcom C/C++.) As someone who's working on a DOS game using C (which I'm cross-compiling from Mac OS X) I share this sentiment!
This fails the readability test. I'd a lot rather see root / "etc" / "x11" / "xorg.conf" Than root.join("etc").join("x11").join("xorg.conf") Otherwise people will want to do something like root.join("etc/x11/xorg.conf") And now you've lost the separation between the path components and the path separators. This introduces an implicit security risk that if somebody drops an external string in thinking it's a path component, but the string can contain slashes, the path could be redirected to something the original developer didn't expect. I legit don't know where Rust falls here but I suspect it's more like the last.
I think the API I'm used to is just kinda stupid
There is no repo yet, I'll announce when ready.
Part 1, where I explain linear hashing: https://samrat.me/posts/2017-11-04-kvstore-linear-hashing/
Thank you, this is really helpful! I hadn't really used `map()` or closures in Rust before so this hadn't occured to me, but it's quite nice and concise!
Mhm, that makes sense. Thanks again!
you can't stack allocate dynamically sized types. Your previous comment presupposed you did have a heap ("preallocate some heap memory").
There is open PR to put this implementation in the standard. it is faster mainly because it only has a single cmov in the loop instead of two. It also spans less instructions in the loop so the CPU goes crazy.
Can't you do lower_bound - 1?
Author here. FWIW, The measurement harness for the benchmark data gathering was written in Rust. It was good practice for cross-language integration and Cargo build scripts.
This is awesome! I predict RISC-V becoming the dominant architecture and it is the perfect opportunity to implement everything in Rust from the ground up. Imagine all the I/O controllers in your SoC are embedded RISC-V cores running open source firmware written in Rust. A new USB/PCIe/WiFi/etc specification is released and the firmware is updated. You audit the changes for security holes, build and flash. Existing hardware is now upgradable! The future of a completely trustworthy hardware/software stack is no longer a fever dream, it's a vision we have a realistic chance of achieving one day. 
Sweet thank you. 
For all of the scripting languages that can run natively and natively, js is an interesting choice. I think just tying in Lua , lisp or python would be way easier.
For what itâ€™s worth, Servo is now obtaining SpiderMonkey from crates.io since today: https://crates.io/crates/mozjs
I'm not sure RISC-V will really help that dream, the vendors could already provide open source firmware on other architectures. Even if they move to RISC-V there is no reason why they would open source the firmware. RISC-V isn't really any more open for the user than say, Arm, the difference is just for the hardware implementor not needing to pay royalties.
also you can just click the "src" button on the docs page to see exactly what is going on in that part of the code. Sometimes you have to go down a bit of a rabbit hole, but for most stuff you can get a really quick overview of what is going on.
&gt; `const T *` just means you won't cast, or do pointer maths on the pointer, not never write to its contents. I don't think that's right. You might be thinking of `T * const`. You can still do pointer math and casting on `const` pointers: const char *s = "hello"; printf("%s\n", s + 1); // pointer math printf("%s\n", (void *)s); // casting
If you do math on a pointer, and pass the resulting pointer to a `const` you'll get a compiler error. 
Super impressive. A bit slow in iTerm but works great in [alacritty](https://github.com/jwilm/alacritty)!
I posted in another subreddit before I saw that you (the author) were around. Are you familiar with traditional hard realtime programming practices? I haven't had time to read the paper in detail but I only see an analysis of average case run times, not worst case run times. Did any of these tests about dynamic memory allocation?
rlua and hlua are bindings to plain old Lua rather than LuaJIT, for what itâ€™s worth.
What did the most performant message serialization solutions do that set them so apart from the others? Were there any common design concepts?
This is the first project I've seen in a while that doesn't use cargo. I guess this is a great reminder of the cool stuff you can do without dipping into rust's wide ecosystem of packages :)
 I think you have const confused const T * var; //You can't modify what you point to but can modify where T * const var; //You can modify what you point to but not where const T * const var; //You can't modify either Though it's trivially easy to remove constness (even accidental if you need to cast types.) Note Rust can have similar mutability difference between the a variable with a reference and it's contents, but Rust defaults to immutable. let mut x = 1; let mut y = 2; { let mut z = &amp;mut x; *z = 3; z = &amp;mut y; *z = 4; } println!("{} {}", x, y); C11 added threading primitives. So technically the C standard was only single threaded until then. In practice most C implementations used an extended specification to handle multi threading (pthreads). These extensions/C11 only make it possible to write multithreaded code, they don't offer the safety Send/Sync give you. It's not officially C but there are extensions to GCC that add destructors, but I've never used them.
Can this be made in `tmux`'s screen lock?
Also for lower power embedded vendors don't have to pay royalties for the ARM Cortex M0/6 chips. You just have to sign contracts, register with them, and certify you'll only fab less then ~10k. Also this means you just have to pay to use any of their other IP. It is a good trap to get companies into their sales pipeline. 
Ah, sorry my bad. I thought Lua was implemented as a JIT.
Rust was designed to permit static analysis with strong guarantees. This necessitates some constraints on the language (at least the safe form). Normal C isn't constrained enough to allow static analysis to the same degree. But there are some decent static analysers that can catch potential issues. scan-build comes with clang and is free. I use coverity at work which does catch a fair bit of issues. But these cannot reach the guarantees of Rust, and both miss things that Rust wouldn't compile. There are also some runtime checks that can be used for debugging, the clang sanitizers and valgrind being the most popular. Even in Rust runtime checks can come in handy if you write non trivial unsafe Rust.
Thanks for the feedback! I have some familiarity, but am largely new to the industry on the whole. Worst-case analysis would have been a good addition, especially for consideration by direct implementors. Outside of the box plot figure that included some outlier data, means were used as a summary statistic of familiarity for the primary target audience of the whitepaper -- engineering managers and project directors that may end up setting direction on cross-component messaging technology. Yes, some of the formats in some of the tests avoided dynamic memory allocation.
Keep in mind that crossing the hosted &lt;-&gt; Rust boundary to make a native call in your script is relatively expensive because it can't be inlined and requires marshalling. It's reasonable to think that you might end up in scenarios where you might want to call a fast thing from your hosted language many times, and you might screw yourself over if you pick a language with a weak ecosystem and performance (lua). I think JS or C# is a much better choice for a hosted language in 2017 because it sidesteps both of these issues.
`Fail` fixes the problems with the `Error` trait (supports downcasting, optional backtraces).
This crate doesn't change how you handle errors, just how you define them. You should use `Result` and do the same things you've done with errors defined any other way.
With rayon, it's something like: let solution = (0..std::usize::MAX/BASE+1) .into_par_iter() .filter_map(verify_number) .find_any(|_| true); Or use `find_first` if you want the smallest solution.
http://www.lowrisc.org/ open-source SoC was one of the main reasons for RISC V, though it looks like there'll be commercial implementations too
It was an opinionated choice with the idea that the most recent context will provide the most user-relevant error message. The debug message, which prints the whole chain of causes, is intended more for logging. Context returns the error underlying it using the `.cause()` method, which also implements `Display`. (And you can iterate over the cause of the causes.)
I have ot admit I bristle at the suggestion that `Error` is anything like "unchecked exceptions." *panics* are unchecked exceptions. The "checked" part is that your function always reports that it can return an error. What you've "lost" is a specific enumeration of which kinds of errors this function can return. There are many cases where this enumeration is unhelpful or even detrimental (it is a lot of work to maintain, it can limit API evolution, and if all users are going to do is `?` it further up and eventually print something, its a total waste of time). There are cases where enumerating all errors this function can return. In that case, you should return your custom error type, and not the `Error` type. The README example shows things that do each.
Well, I use Lua as a "configuration language" for my GIS, so I can load batch jobs or load / unload layers interactively like: local map = Map(54.499, -4.065, 52.157, -10.931, 400000) map.add_layer("Forest", ["'natural' = 'wood'"]) -- add other layers map.set_style("style1.json") map.load_cartography("corrections.json") map.render() map.export_pdf("file.pdf") So I can do these things either from a REPL or from a file and batch-create a continouus map atlas with a simple for-loop. Nothing performance-intensive, but the parameters are different for each PDF, so doing it via a configuration file would be too cumbersome and doing it via command-line parameters isn't interactive. Lua can be statically compiled, which is good - you don't have to worry about if your user has installed any runtime. C# would require .NET core or Mono, which is a huge dependency. Lua has a quite mature ecosystem actually, because it's often used in (smaller) game engines, the most prominent example being [LÃ–VE2D](https://love2d.org/) and Panda3d. Ubisoft uses C++ / Lua for many of their games / engines IIRC. Of course, Lua wasn't made to be a high-performance language, but it was made for easy embedding and scripting which is I think what OP was looking for. It's definitely easier to expose fast Rust functions to Lua than to JS or Python or C#, because Lua was made for that purpose, so I don't think Lua is a bad choice. So if something is missing in Lua, just write it in Rust and expose it as a function, done. 
Hmm, this is actually slower though. Rayon will chunk the entire range, rather than striding like the blog does. Is there some mathematical fact about this problem that would make one search strategy better than the other?
I think you're going to need to give an example of the compiler errors, because I can't think of a case where arithmetic itself would be affected by `const` (`+` is just reading the pointer, not writing to the pointer itself or to the memory to which it points).
Do you remember Altavista?
 tmux set lock-command /path/to/ternimal tmux lock Please let me know if you figure out how to exit this...
It's not likely a surprise, but what the best performers tended to do was less. By this I mean fewer noncritical options supported at runtime and minimized control flow complexity. Sure, codecs tended to do better as their representation approached the classic structs-overlaid-into-a-buffer approach, but there was definitely room for implementation-specific, wire-format-independent differences. Just look at the different encoding and decoding specific scores in the table for the two Protobuf-based and the two CDR-based entries. Given that all formats under test were able to handle round-tripping to a normalized representation that included a `Vec` and nested structs, I don't believe any suffered particularly from an especial lack of representation-capability, at least for the use case at hand.
Runs fine in Cmder on Windows, though without 24bit color or a good font. Cool stuff! I'll try it on my WSL setup at work tomorrow.
As /u/SatanicBarrister pointed out, check out the lowRisc project, specifically the minion cores concept. I don't expect vendors to open source their firmware. New open source firmware can be written to perform I/O on minion cores. Initially, PHY will still be licensed commercial IP, likely foundry specific, because that is very expensive to develop. Yes, there will still be closed source implementations, RISC-V is not intended to prevent that. RISC-V enables open source implementations to be developed, where it wasn't economically feasible before. 
I could be mis-remembering, since my attitude surrounding things like `transmute` has been to stay far away from them, but, if I'm not, then you're not "binding the lifetime"... you're just forcibly suppressing the "this will unpredictably cause memory corruption, depending on optimization quirks and usage patterns" error. Lifetimes don't tell the compiler what to do, they tell it which of the things it can prove for itself is the correct interpretation.
This question breaks my heart because the best answer I've found is "beautifully simple audio-video libraries don't exist at the bare-metal level of Rust." GPU-acceleration is the one game in town. Turtle graphics, what is that? And while I'm working on a solution, I only have a few hours here and there so I can't make promises. The best libraries that currently exist are the Piston project. Give them a shot. If lifetimes annoy you, consider dropping to `unsafe` and dealing with SDL directly. Part of the problem is that modern desktop systems expect programs to share resources: you're not the only thing drawing to screen or playing sound. The usual solution on anything Unixy is to use a network-ish client-server model. When something designed to work on the Internet (a timeout being late by several ms is no problem) you might not be able to use it for local stuff (audio processing with less than 20ms latency). These problems aren't insurmountable, they're just time-consuming traps for newbies. Windows might actually be a more welcoming environment. But in any case the core problem is that the libraries to do that kind of explorational stuff are suffering from bitrot (SDL) and you're likely to run into annoying problems (animations tearing and no way to fix it) now with things becoming more broken in the future.
With `#[non_exhaustive]` recently landed in nightly, I presume that `ErrorKind` will be adjusted to use it soon, and rustdoc to be more precise about its display.
[image](https://crates.io/crates/image) for loading/saving images, and [imageproc](https://crates.io/crates/imageproc) for drawing triangles on them.
It sounds like [`image`](https://crates.io/crates/image) and [`imageproc`](https://crates.io/crates/imageproc) might be what you're looking for. [Load an image](https://github.com/PistonDevelopers/image#61-opening-and-saving-images) [Draw polygons](http://docs.piston.rs/imageproc/imageproc/drawing/fn.draw_convex_polygon.html) ([or draw in-place instead of making a copy](http://docs.piston.rs/imageproc/imageproc/drawing/fn.draw_convex_polygon_mut.html)) [Compute Difference](http://docs.piston.rs/imageproc/imageproc/utils/fn.pixel_diffs.html)
This is great work, but I'm a bit disappointed by const generics being punted on. (This is from the sprint doc). Any idea what's the status on that? 
&gt; Context returns the error underlying it using the .cause() method, which also implements Display. My concern is that a `Context` wrapping a `Context` will be inaccessible.
&gt; I have to admit I bristle at the suggestion that Error is anything like "unchecked exceptions." panics are unchecked exceptions. The "checked" part is that your function always reports that it can return an error. Yes, sorry for my inaccurate language. I mean exception-specifications. I'm used to the two going hand-in-hand and I got sloppy. Not sure that I'd want to equate panics to unchecked exceptions though. Maybe its just from seeing people less familiar with Rust equate exceptions to panics because they share some mechanism (like stack unwinding) rather than `Result` that I tend to a more black and white stance on my interpretation: `Result` is equivalent of exceptions and `panic` is equivalent of asserts. &gt; There are cases where enumerating all errors this function can return does matter. In those cases, you should return your custom error type, and not the Error type. The README example shows functions that take each strategy. Missed that; thanks for having an example of it. I feel that helps clarifying the recommendation on how you all expect this to be used. The one case I know of where I'm going to care is a command line utility where I want to make sure that I return distinct error codes for config errors, unexpected io errors, and errors for what the program is trying to test.
Author of Prost here. Nice analysis! Is the test harness available? I'd like to take a look at the decoding perf difference between prost and quick-protobuf.
Wow, crazy to see a project of mine referenced in something like this! Something that I noticed is what might be a malformed reference at the bottom of the page Varda K (2013) Bincode: A binary encoder / decoder implementation in Rust. Available at: [sic] Also, which version of bincode was used in the tests (are these tests available for me to run?). A Servo contributor landed a pretty big performance win recently (details [here](https://github.com/TyOverby/bincode/issues/206), PR [here](https://github.com/TyOverby/bincode/pull/207)) and I wonder if it would have an impact on your benchmarks? 
yeah, transmute isn't going to extend the lifetime, it just allows you to take things into your own hands. you become solely responsible for ensuring that the memory being referenced does not get dropped before the reference, and that no two mutable references exist to any single object.
&gt; they are each specialized for a subset of undefined behaviors, and mutually incompatible Wait, does that mean that one can't build with all of those enabled simultaneously?
See, for example, [this StackOverflow question](https://stackoverflow.com/questions/36971902/). Some of the sanitizers need to modify the program's heap in incompatible ways.
No workplace is without drama, but as someone who worked at Etsy until recently, I can say there are lots of great people there and this sounds like a pretty neat position. The recent changes were tough, but necessary and it seems like the business has become healthier.
As long as the randomness doesn't leak out of the abstraction, this is one of the places where using `unsafePerformIO` is acceptable. 
Nope no false positives will occur. I suspect you're confusion is on what keys are. Keys are not the result of hash functions, they are what's feed into the hash function. The result of the hash is used to determine where in the hash table to store the key (or key and value in the case of a hashmap, hashsets just have keys). So when you do a lookup against the hashset, it uses the hash to figure out where in the hash table to look, then it does a full comparison of the key at that location against the key that was passed in. As for collisions it depends on the type of hash table. Rust uses a open addressing with Robin Hood hashing. The [Rust Docs](https://doc.rust-lang.org/std/collections/struct.HashMap.html) Have some good links on the particular method it's using. There is a probabilistic data structure based on hashes called a bloom filter. That you might be confusing the hashset with. Bloom filter's allow false positives but never false negatives. One use case is as a prefilter for a normal hashset/hashmap, where the key comparisons can be expensive, and the use cases expects a lot of lookups to return not found. For that the key inserted into the hashset/hashmap is also inserted into a bloom filter. Then during lookup you check the bloom filter first and if it's not in there you can be sure it's not in the hashset and return not found.
&gt; it become difficult to reason about performance or easy to misunderstand how much work will actually be done?" This doesn't inherently hold true for functional programming languages because functional programming languages can have linear type systems. In fact, Haskell is about to get linear types a few releases from now. 
You want to look in /r/playrust unless your clan is for programming.
I don't really care about executable size, because it is not going to change much in the end. I had a look at hlua and rlua. They look really nice, but they only support the official Lua. LuaJIT doesn't have any Rust bindings. Cpython has really cool and easy bindings. I couldn't find such bindings for other languages though. 
Lua is a (relatively) very fast interpreter. But that makes it easy to embed. Just copy/paste ~30 files. 
It just turned out not to be realistic to get it fully working in 2017. In particular, it's blocked on some changes in the trait system, but the relevant folks for doing that work are tied up with higher priority items, like NLL. eddyb and his WG have done a ton of foundational work on const generics, so hopefully we'll be able to move quickly at the start of 2018.
One of the reasons to use JS is the wide ecosystem of packages available. :-) I find C#'s syntax not very adapted for scripting though. Thanks for the advice, it's definitely something I'll have to take into account. I'm going to try to make batch calls to Rust or something like that for performance-critical tasks, or I'll just do it in Rust if JS isn't fast enought. 
I didn't notice it wasn't on crates.io when I had a look at it ! I was thinking of these bindings but I read on Josephine's github page that they use nightly Rust. 
Easier... But slower. Although I think JS is pretty easy too. ;-) I also want to experiment with JS, and I definitely think it's an interesting choice! 
Well Servo also has browser components that I'm not interested in. And it doesn't have its own JS engine. Servo uses bindings to SpiderMonkey. I'm pretty sure they use mozjs.
That doesn't change the fact that it's a language with lazy execution and a pure functional language sitting on top of a fundamentally imperative machine language architecture. ...not to mention that I see the syntax as distractingly alien and concise to the point of obtuseness. Nobody disputes that part of the difficulty of learning a language like Japanese is the fact that you have to learn a new writing system at the same time.
What you're looking for is called "associated type constructors" and it solves this exact use case. See the rfc [here](https://github.com/rust-lang/rfcs/blob/master/text/1598-generic_associated_types.md) and its tracking issue [here](https://github.com/rust-lang/rust/issues/44265). As far as iterating through *disjoint* elements of something, usually unsafe code is required, yes. For instance see the mutable iterator implementation for a slice [here](https://doc.rust-lang.org/src/core/slice/mod.rs.html#1130-1228) - at its core it's using raw pointers to the data.
I've just written [flot-rs](https://github.com/stevedonovan/flot-rs) but haven't published it yet (hint: no documentation). I've always been an admirer of Flot to generate pretty plots in webpages, so `flot-rs` creates standalone HTML documents so you can render the output of your command-line programs graphically. Nothing fancy, just heavy use of the excellent `json` crate. If there's interest, I'll push the release along faster.
Maybe it wasnâ€™t there yet when you looked, this is very very recent :) Josephine is another story, but I recently removed the last few unstable `#![feature(â€¦)]` flags from the `mozjs` crate. It builds on stable.
Yes. mozjs is pretty much another name for SpiderMonkey.
But, it has the same public interface as Lua 5.1/5.2. So it remains an option.
I also had this thought, when first encountering the wall of Rust errors. The (apparent) overqualification of type names triggered some post-C++ PTSD, so the idea I had was to render errors as an HTML document. The types would be stripped of qualification, but a mouse-over would reveal the Real Type. Alternatively, would be links to the documentation.
Oh cool! I'll have a look at it. :-) 
You mentioned a couple conflicting goals you're trying to balance: * do everything from a single method, basically avoiding your caller having to examine the version map and support each version explicitly. * support the format completely changing. Here's what I would do: If Produce v6's format is completely changed from v5, then don't try to cram them both into one method. It's effectively a new API, so expose a new method for the caller to use and expose a way for them to see if it's supported or not. From skimming the docs, that hasn't happened yet. Produce v0 through v5 have only minor changes (adding one field to the request or response in each revision) so expose to callers one method, one request struct, and one response struct that support them all. One catch is that you have to think about what happens if the caller wants to pass in a `transactional_id` and the server only supports version 2. Do you silently drop it? return error? or maybe instead of just `Option` for the newly-introduced request fields you use a custom enum in the request struct so the caller makes this decision: `IfAvailable(id)` vs `Required(id)` or some such.
I wouldn't take js packages into account, most of them are for the node.js runtime, the rest is targeting browsers. Personally, I would take Lua or a [lisp](https://github.com/murarth/ketos) over the others. 
Well, lodash for example should work in any JS environment. I don't really see why I would use Lua instead of JS if I don't care about the executable size. JS may be a little harder to embed but not that much. And lisps are too slow. But that's my point of view. Did I miss something? 
I recently ran into the FIX Simple Binary Encoding repository (I think a Rust crate linked from here mentioned it, but I don't remember know which one). It might make an interesting addition to your list, since it seems to be very optimized for low latency handling. 
Your code *might* be memory-safe. Provided FaceView.edges_mut is truly the only way such an iterator can be constructed, and EdgeCirculator::next doesnâ€™t end up yielding the same edge key twice (I canâ€™t easily tell from the code), I *think* your code is memory-safe. If it is possible for the same edge to be yielded twice, then itâ€™s definitely not memory-safe. All in all, Iâ€™d want to spend a fair bit longer thinking about it to be *fairly* sure, and even then I would prefer not to trust myself.
But now I had to copy *three* commands to "install" the thing instead of one `cargo install`. What a truly terrible world :'(
I've recreated the original libmodbus tests in Rust, too. They should interchangeable, I mean you can run my random-test-client (Rust) against the libmodbus random-test-client (C) and vice versa. Please have a look at the [examples dir](https://github.com/zzeroo/libmodbus-rs/tree/master/examples) of my repo.
[Offtopic] What is the advantage of wayland over x11 from a users perspective right now? Are there any reasons why I should make the switch to wayland?
&gt; my knowledge of hash tables has left me curious how it addresses collisions, especially seeing as to my knowledge it doesn't associate the value with the key but merely stores keys. Values are irrelevant to collision resolution in hashmaps. A hashset is [literally just a hashmap with a zero-sized value](https://github.com/rust-lang/rust/blob/master/src/libstd/collections/hash/set.rs#L121), so rather than store `(h, K, V)` it stores `(h, K)`. That aside, collision resolution works the exact same way and is non-probabilistic (otherwise it'd be e.g. a bloom filter not a set). Rust's stdlib hashmap (and thus hashset) uses open-addressing and "robin-hood" hashing for collision resolution, wikipedia covers both concepts, 
Some people report better performance or it fixes tesring for them.
* security: in X11 every window know the input for other windows. X11 is really really bad for security. * Wayland provides a smoother experience, the motto is "every frame is perfect" * less use of CPU and memory and consequently it saves battery * Wayland support touch, X11 just hacks. For example you can't use touchscreen in X11 without moving the mouse cursor too. * Wayland let desktop environments implement a lot of things impossible on X11
One of the main advantages for end-user can be tearing-free video playback. (Although for me it's still not as smooth as I would like)
Is it possible to recursively generate struct fields? I'm trying to convert a JSON array into an equivalent struct. All of the fields of the JSON match up with the struct. The real problem is six or seven structs of around twelve fields, so a macro would save a ton of time. struct Test { foo: String, bar: String, qux: String, } // JSON { "foo": "A", "bar": "B", "qux": "C" }
[removed]
thanks for the heads up, will try again.
I've had nothing but trouble with ConEmu's color support. And no documentation whatsoever. I've given up since and went back to mintty as it's the only one I've found to behave in a way that makes sense to me.
Any advice on how to define/use a function that accepts either an array, slice, Vec or HashSet (or a reference to one of those types) of u32 values? The function just iterates over the values without modifying them, so I've got as far as trying: fn some_func&lt;I: IntoIterator&lt;Item=u32&gt;&gt;(x: I) { } This works for calling with e.g.: some_func(vec![1, 2, 3]); but not some_func(&amp;vec[1, 2, 3]); // compilation fails with: expected reference, found u32 This also fails if I try to pass in an array or reference to an array: some_func([1, 2, 3]); // fails with: [{integer}; 3]` is not an iterator; maybe try calling `.iter()` or a similar method (though I thought arrays implemented the `IntoIterator` trait, so I'm guessing the issue is with my function definition) 
The reason the compiler is complaining is that it might be possible for you to get two mutable references to the same location (which is disallowed in Rust). I believe it's OK to do this as long as you can prove that it will never return the same `Edge` twice. If you believe that is the case, then you should be alright, but add a comment exhaustively documenting why it would be impossible to get the same mutable reference twice.
Way to make a paper out of a benchmark! Shame you omitted the serialized data size from the results; would this not affect performance of the transport layer (in anything other than shared memory architectures)?
While I do like those suggestions for "smaller" types, I had an "expected type / found type" error message with [a very long type](https://gist.github.com/oberien/cb48a926e98472e8167dedb5a5a4c5e5) quite some time back when working with tokio and futures. Obviously I wasn't able to extract any information of that error message. Thus I'd like to have a short version of the actual differing type in the beginning. With such a long type it'll sometimes be enough to have `expected Foo, found Bar`. That will tell me to change the little `and_then`, in which I transform some data. At the same time I think that this suggestion does not always help, especially if something in the middle of the type is differing (like `Option&lt;5-tuple&gt;` instead of `Result&lt;5-tuple&gt;`.
Same for me. Wayland is a huge improvement in that regard. But video is still a pain on every machine for me. Micro stuttering is still a thing on every mayor OS especially in Browser/Youtube (we don't need to start talking about the video quality on Youtube)
&gt; Historically, multithreading has always been a double-edged sword. It saves a lot of time and resources by speeding up heavy computations (by parallelising them), but on the other hand â€” it can easily introduce countless situations of unpredictable behaviour, often difficult to reproduce, debug, or even identify before they actually bring down your application. I must admit that I am quainted out by the amount of programmers who think that multithreading is the only way to do parallel stuff forgetting that multiprocessing is the original way which lets the OS solve the synchonization for you, no advanced library needed to stop data-raises there. I had a very weird discussion about this which featured Rust on r/programming a while back which opened me up to that apparently a lot of people are not aware of the inherent problems of multithreading on Unix as well as the convenience of multiprocessing. Like they seemed weirdly unaware of the fact that two processes on Unix whether they forked from each other or not can just share a segment of memory (not sure if Windows allows this but it surely must right?). A lot of the whole modern concurrency paradigms in multithreading in languages like Go and Rust basically seemed to have copied the old multiprocessing paradigms which the OS provides you for free. The whole "share data by communicating; don't communicate by sharing data" is pretty much the standard IPC approach of multiprocessing. I also ran some test and libc's fork is two orders of magnitude cheaper than `std::thread::spawn` on modern Linux and Musl at least. Multiprocessing just seems like a better solution in every way and if you want something like channels then I'm sure a library can (and really should) be written that uses shared memory maps to do this after a handshake between two processes, no need for expensive serialization and deserialization to send it over a socket. &gt; Fortunately, itâ€™s almost impossible to write such dangerous code in Rust. Itâ€™s in the languageâ€™s motto â€” itâ€™s been constructed in a way that guarantees thread safety. I have to say that these promises are overblown; it occured to me in that very discussion that multithreaded programs are inherently unsafe in Rust in theory even though they don't say it but this is one of the problems with multithreading and all. In some multithreaded contexts in particular signal handling (not available from safe rust) and forks (avialable from safe rust) it becomes undefined behaviour to call any function that is not async-safe and safe Rust absolutely allows you to do this. Now in practice even though POSIX calls it undefined behaviour all it will do is deadlock which is allowed in Rust safe code but in theory a conformant implementation is absolutely allowed to hand you memory unsafety. 
std provides no `select` operation for channels, which reduces their usefulness in some cases. So I've been using [chan](https://github.com/BurntSushi/chan) instead.
One thing I am missing in the paper is a discussion of the resiliency of the benchmarked solutions against malicious or just accidentally malformed (e.g. flip one bit, omit one or more bytes, incomplete data) data. Perhaps that would make a good followup.
[removed]
Arrays up to size 32 implement `IntoIterator`, though there is some development to autogenerate the impl for all sizes as needed.
If it's speed you want, you lose that every time you leave rust for a script. Also I am not sure there is really a speed advantage in Js. There are plenty of high speed lisps, python is fast especially with pypy, and I imagine Lua is fast enough or it wouldn't be used in the games industry.
The *bincode* version from the Cargo.lock at the time of the test's data was 0.8.0. Hooray, tooling.
The test harness is not yet available to the public. My intent is to open source it, but the timing is uncertain, and probably on the order of a few months.
Ah, thanks, didn't know there was a difference depending on size, will do more reading on that.
There is an `impl IntoIterator for &amp;Vec&lt;T&gt; { type Item = &amp;T; .. }` in the standard library, so `(&amp;vec![1u8]).into_iter()` is an Iterator over `&amp;u8`, not `u8`. Arrays implement `IntoIterator` only for `&amp;[T; (0 to 32)]` (note the `&amp;`) which yields a Iterator over `&amp;T`. There is [an open issue about implementing it for `[T; _]`]( https://github.com/rust-lang/rust/issues/25725). An workaround is to do `some_func([1, 2, 3].iter().cloned())` (copying `u8` is free). If you have a fixed number of values that you'd avoid callng `.cloned()` on it for performance reason, you can use [`ArrayVec`](https://docs.rs/arrayvec/0.4.6/arrayvec/struct.ArrayVec.html#impl-IntoIterator-2) from `arrayvec` crate.
Slices and arrays implement `IntoIterator&lt;Item=&amp;T&gt;`, not `_&lt;Item=T&gt;`. You might try: fn some_func&lt;I: IntoIterator&gt;(x: I) where I::Item: Borrow&lt;u32&gt; {} Which accepts an iterator returning references or owned values.
I like that. On Windows the result varies a lot depending of the terminal. It works great on Git bash, OK on Cmder and completey broken on cmd.
I would just take the token, change its fields and return it. Since your API takes ownership of the token and returns new token, it looks immutable from the outside perspective, which is fine. Just remember, that immutability is not the holy grail, just a good rule, and you have to know when to make exceptions.
Here's one thing that should work (untested): ```rust pub fn flag_as(self, field_to_update: &amp;'static str) -&gt; Token { let Token { value, is_digit, is_punctuation, is_stopword } = self; // mutate one of the local variables here Token { value, is_digit, is_punctuation, is_stopword } } ``` Note that, with bare `self` as the method argument, this consumes the old token. This might not be what you want, in which case you'd take `&amp;self` instead; in that case, destructuring the struct as I did here probably doesn't work, but you can just instantiate a new `Token` that explicitly passes values from the old one.
I exclusively use Solus with Budgie (which runs on X11) on all my machines and haven't experienced any stuttering issues on YouTube. Maybe I just don't notice stuff like this :/.
I have to say i if i read your name anywhere i immediately think: "mhhh tasty performance wins!". Keep up the good work!
yeah, i am over exaggerating here. it is very minor indeed â€“ but its just something you can't unsee once you noticed it. it is also very dependent on the content. On very fast and shaky camera movements its unnoticeable. But it really strikes on slow to mid fast constant camera movements. Try this video https://www.youtube.com/watch?v=0RvIbVmCOxg i have yet to see a computer without micro stutter on the slow moving parts. 
Author of quick-protobuf. I would love knowing the difference as well. I haven't spent lot of time trying to optimize the encoding part (wasn't critical for my projects) but being more than twice slower is a surprise.
I feel the same! When I start reading I was wondering how quick-protobuf would fare .... Until I saw that it is tested! Open source is really nice! Thanks to the author
Ha, seriously. Academics, take note: this is how you pad out a CV.
Thank you for the helpful answers :-)
You would use discriminated enums for the flags provided that they are mutually exclusive. Here is a link to [a playground demo](https://play.rust-lang.org/?gist=cd3afdd62c59cb4560c598c763b24b15&amp;version=stable) 
Maybe that should be his flair ðŸ¤”
I can definitively see that now, thanks.
Yes, that makes sense (although that , might only hold true for a few of them)
Well, I guess that makes it conceptually more simple, if anything. And while I have understood the concept of ownership intellectually (to a reasonably degree, at least) I'm far from understanding it practically.
Relevant : https://stjepang.github.io/2017/08/13/designing-a-channel.html
sorry for that ... you will never unsee it now :/
Yeah, I am thinking this may be the only way to go for now. A third option I thought of is sort of doing what the official Java clients do and having a different version annotated by the target Kafka server version and using conditional compilation with features to choose which struct versions to compile. This would get the resulting binary correct, but it would also complicate the build process, and make the code very tedious and hard to follow. `Option`s may be the best compromise right now. Thanks for your input!
I was always wondering why Sender and Receiver both are structs and not traits. With traits we wouldn't be dependent on standard implementation and anyone can create its own one.
Looks good. Also, I like the name Ternimal, it's pretty clever.
Instead of using `Option`, shouldn't the no-modifier be one of the enum branches?
Are you also familiar with / could lessons also be taken from [this](https://wingolog.org/archives/2016/09/20/concurrent-ml-versus-go)?
One thing with the solution you posted: for each value of Modifier I would need to define a function. How can I parse a string (well, &amp;str) into an Enum value?
Thanks, Iâ€™d be interested in seeing it. In the meantime, what versions of prost and quick-protobuf were used?
Before we look into your code, make sure to format it â€“ prepending 4 spaces to each line of code will make sure the formatting is respected in reddit's flavor of markdown. Otherwise it's really hard to follow.
Prost 0.2.1 and Quick-Protobuf 0.5.0
Yeah I agree. For this test, Iâ€™d expect prost and quick-protobuf to have essentially the same performance for encoding and decoding. Quick-protobuf can currently be much faster than prost at decoding long string or bytes fields, but I donâ€™t think that the test included that, if I understood the paper correctly.
I still canâ€™t get over the select design. I know itâ€™s performant, and every other part of the library is great, but the conditions seems way too easy to mess up - no other code I know in any language forces you to break a loop for it to work. Rust is usually very good with statically not letting you do stuff in the wrong order, but here you donâ€™t even get a runtime error, just maybe a deadlock. I also donâ€™t like the global state with the threadlocal variable, why canâ€™t it be a struct with methods? 
It applies to arrays and tuples right now; eventually this restriction will be lifeted.
If you're not keeping a reference, you should generalize it over all lifetimes. pub fn flag_as&lt;'a&gt;(self, field_to_update: &amp;'a str) -&gt; Token { /* ... */ }
Yep, data size was gathered, though transport layer effects discussion was ultimately omitted in the name of focus. I'll see if I can release it today, for the curious.
That's good to hear, thanks =)
Rust proposes that there is a problem with shared mutability, not all mutability. Avoiding shared mutability avoids classes of bugs. Many other languages don't have the concepts like ownership that allow one to ensure or enforce non-sharing.
Thanks that clarified everything for me, I thought the key was the bucket number produced by hashing the value, so knowing this was incorrect completely cleared everything else up. 
&gt; but the conditions seems way too easy to mess up I imagine it would be pretty easy to wrap selection in a macro that looks a lot like `match` and removes some of these caveats. That said, I'm impressed to see select get this far without using macros or special language features at all!
[Here you go.](https://imgur.com/IdHxdQs) Not the prettiest chart, but should be basically readable with a little zoom. 
&gt; lua vs js and slow lisps (mobile app doesn't let me select text) It really depends on what you are going to use it for. I wouldn't use the embedded program for heavy computation, that's a job for the host. Another thing you will want to take into account is the interop and marshal/unmarshal operations you are going to perform between the host and the client. The more data you are going to move the worse the performance will be. And finally, with size it also comes complexity, you can't really compare a scheme, lisp or lua runtime to any of the current *fast* JavaScript engines out there. I don't think it would be a pleasant journey. On the other hand lua's interpreter is pretty small and you can implement a scheme in a small amount of code. I would, now, write a small list of all that's wrong with JavaScript (the language) but I don't want to start a fire here. I'll simply leave this: JavaScript is complected and complex. Lua, scheme and lisps are only complex.
Is there a nice example one could use to understand how to use mozjs? It seems to be decently documented but I'm not seeing any examples.
So, what you are saying is that multiprocessing is unsafe in rust ,while multithreading is safer.
This one? https://github.com/real-logic/simple-binary-encoding/pull/481 Note the author :-)
Traits aren't sized, so you'd need to rely on heap allocations to own one. That's at least one downside.
Not really, you need both to trigger the unsafety. Fork from a multithreaded program on Unix puts a lot of limits on what you can do in the child to not trigger undefined behaviour (immediate exec is one of the things that is perfectly safe) and Rust's type system currently does not guard against that. If the parent was single-threaded you can do anything and be safe and if you don't fork from a multi-threaded process you can also do anything and be safe but throw both together and you got a recepi for undefined behaviour that Rust's type system does not catch. That could be fixed by either marking `before_exec` as unsafe or adding an `AsyncSafe` marker trait to the language but that still doesn't solve most of the problems with multithreading, just makes it safe in a rust world.
This is only 2 allocations. Is it so critical? Also with **impl Trait** it should not be a problem.
`impl Trait` doesn't work, because you can only return a single type from that function. Two allocations may or may not be critical, it depends on what you're doing.
That's certainly a relevant topic. Several solutions include some degree of protection, but it's definitely uneven across the options.
&gt; impl Trait doesn't work, because you can only return a single type from that function. trait Sender { ... } trait Receiver { ... } trait Channel { fn sender() -&gt; impl Sender; fn receiver() -&gt; impl Receiver; } fn unbounded&lt;T&gt;() -&gt; impl Channel; fn bounded&lt;T&gt;(cap: usize) -&gt; impl Channel; Will this work?
That works only if all channels you try to group together return the same concrete `impl Sender` or `impl Receiver`.
So, not literally, as you can't directly do `impl Trait` in the return type of a trait. IIRC with the latest changes you could set the `Sender`/`Receiver` as an associated type on the `Channel`, and return that. So like, two years after 1.0, you still can't write this on nightly, even if it will work someday :) What you can't do is implement the `sender()` or `receiver()` methods here to return different types of `Sender`/`Receiver`; I mean, if you had implemented `Channel` on two different types, those ones could, but within a single impl, you can't.
Of course! In that case use the `From` trait! I had some issues with `FromStr` as you can't specify a lifetime in FromStr so you can't store a ref to the `&amp;str` you are given. Here is the [updated playground](https://play.rust-lang.org/?gist=9061060a870cc034670413e0fd9e25bf&amp;version=stable) 
Thanks for the response! The serialization part does actually have a trait, though, and that's not where the problem lies. The problem is at the call site, where I need to pick the right struct type to de/serialize based on the broker's supported API versions.
wrong sub, dude
/r/playrust 
Thatâ€™s something I considered as well but `Option` gives us access to `map` and other cute functions. 
Building off of the relatively mature browser-based charting libs is such a good idea. I could see a bright future of something like this combined with an embeddable version of servo, rather than needing to reinvent rust-based charting from the ground up.
It'd be interesting to see a design of multiprocessing for rust that takes into account most multithreading abstractions(in rust),and provides examples of equivalent functionality in multiprocessing scenarios.
Yes, but it's not great: https://docs.rs/chan/0.1.19/chan/macro.chan_select.html
The return type is a boxed trait. Each of the versioned structs implement some way of creating a network packet to send (which is uniform across the trait).
&gt; completely broken on cmd And nothing of value was lost. 
No reason it can't be built using shared memory. There are in fact libraries which copy the MPSC interface using serde but naturally that requires expensive serialization. With shared memory it is as efficient as inside of a thread. I in fact ran some tests where I used unsafe hacks together with a pipe between processes to just dump the internal representation of `Copy` types into the pipe and read them out again on the other end and making a 10_000 forks with each sending an integer across over a pipe (as in 8 characters) to the original process was done in 1ms while making 10_000 threads and doing the same over a channel took like 120ms and then I did some further test and found out that merely spawning 10_000 threads on Rust with thread_spawn which were all empty functions that did nothing took 70ms whereas 10_000 forks which did nothing and died and just were waited on by the main program again were 1ms. So yeah, fork is fast.
I realize this thread is 3 months old so you may have figured this out already, but: Yes, your more-sophisticated version is called "priority inheritance." It's available on Linux via [PI-futexes](https://www.kernel.org/doc/Documentation/pi-futex.txt), supported in the kernel with [`rt_mutex`](https://www.kernel.org/doc/Documentation/locking/rt-mutex.txt), and exposed in pthreads as the [`PTHREAD_PRIO_INHERIT`](http://pubs.opengroup.org/onlinepubs/009695399/functions/pthread_mutexattr_getprotocol.html) value for the mutex protocol attribute. On Windows the problem is instead addressed by [randomly boosting un-blocked threads](https://msdn.microsoft.com/en-us/library/windows/desktop/ms684831(v=vs.85).aspx), which fits your more general version. I'm not super-familiar with priority inheritance's effect on fairness but the term should at least give you a direction to go looking if you want more. :)
but is it actually worse than not using a macro? If it's "not great", we should find a way to make it great, but statically enforcing things at compile time is my preference, at least.
I'm providing data. That macro has existed for years and hasn't improved one bit. Others are welcome to try. :-)
&gt; but the conditions seems way too easy to mess up - no other code I know in any language forces you to break a loop for it to work. Eh, I know, but it is what it is. Really wish I knew how to do selection better. But whatever I try, selection always ends up being imperfect. :( We could have a macro for static selection that declares the loop behind the scenes and automatically breaks from it. But macros can look kinda ugly, cause poor compilation error messages, and usually have annoying warts like the one in `select!` that was mentioned in the RFC. &gt; I also donâ€™t like the global state with the threadlocal variable, why canâ€™t it be a struct with methods? It can be - in fact, that's how selection worked a few months ago. But, in the end, I felt explicit struct declarations didn't bring a lot of value to the table. You can still run into deadlocks and all that. However, an explicit struct could help with debugging. Instead of causing a deadlock when you forget to break from the loop, it could cause a panic. For example: let select = Select::new(); loop { if let Ok(peer) = select.recv(rx) { println!("{} received a message from {}.", name, peer); // OOPS, forgot to break here! Fortunately, the next call to `select.send` will panic. } if let Ok(()) = select.send(tx, name) { // Wait for someone to receive my message. break; } } Apart from this (and perhaps small performance improvements), am I missing any other advantages of explicit structs? Here's another idea. We could have a `select_loop!` macro, so that the following code: select_loop! { if let Ok(peer) = select::recv(rx) { println!("{} received a message from {}.", name, peer); // OOPS, forgot to break here! Fortunately, the next call to `select::send` will panic. } if let Ok(()) = select::send(tx, name) { // Wait for someone to receive my message. break; } } Expands to: // This is an internal function. // It asserts that the state machine is uninitialized. select::begin(); let res = 'select: loop { // This is an internal function. // It panics if cases appeared in the wrong order (by computing a hash as we // fire cases in each iteration of the loop), or there were too many, // or some were missing, or some cases were duplicates. select::tick(); if let Ok(peer) = select::recv(rx) { println!("{} received a message from {}.", name, peer); // OOPS, forgot to break here! // Fortunately, the next call to `select.send` will panic because we haven't // called `select::end()` yet. } if let Ok(()) = select::send(tx, name) { // Wait for someone to receive my message. break; } }; // This is an internal function. // It asserts that the state machine is uninitialized (panics if we have // prematurely broken the loop). select::end(); res Some of these checks could already be added to the current implementation, without any additional macros or structs. For example, we could compute a hash of all cases as we fire them in order and panic as soon as something starts looking fishy. I believe that would turn most (maybe even practically all) potential deadlocks into panics.
I recently started working on a project idea of mine, part of which involves a headless wayland compositor (yes, there is actually a use for that). Pretty much all the current libraries assume that you are gonna be writing an actual interactive compositor that will manage input devices and displays, get input from the user and draw things on the user's screen, none of which my compositor will do. Hence, I might need to write my own wayland thing at a much lower level than existing compositor libraries. I want to write it in Rust. Do you have any ideas/pointers as to what resources/libraries/documentation would be most suitable for something like that? I don't really know much about what wayland-related Rust crates exist at the moment. I pretty much only know about your compositor :) . (which is clearly not very useful in my case :) ) (also it is great that you are switching to wlroots btw) Also, I remember hearing at some point that someone was doing pure-rust replacements of some wayland C libraries? . I want to write some code first to play around and to make sure I actually want to keep going with this idea and that it would actually make sense, before I reveal any more details. Once I have some basic stuff working, I'll happily write about it and share it on this subreddit. 
Nice. Will switch `slog-async` (mpsc) and `rdedup` (mpmc) to use it and see what happens. :)
Maybe, but I think the article (a great one, by the way) is a bit out of the scope of this endeavor. It specifically focuses on zero-capacity (*rendezvous*) channels, asynchronous operations, lightweight tasks, composition, etc. This is the realm of tokio and futures. But as far as `crossbeam-channel` is concerned (and most programs in Rust today), zero-capacity channels are pretty uninteresting. We typically care more about unbounded channels and raw performance (e.g. look at Servo).
(copy pasting part of [my comment in an other thread](https://www.reddit.com/r/rust/comments/79oq6n/im_a_compiledlanguagenoob_and_im_considering_rust/dp53lef/): - WLC is pretty high-level, making it quite easy to get something to work (but is being abandonned) - libweston is quite high-level too, but I'm not sure about what's the status of its extraction from weston - wlroots is a little lower level than WLC, as apparently WLC was not flexible enough for the needs of sway, and afaik it is very near to being usable to make a compositor - smithay aims to remain very low-level at first, and thus being very flexible, and keeps open the possibility to integrate higher-level abstraction in the future, once the bases are solid. It is still very WIP, see the 0.1 release notes if you want more details. I don't know about libwlb, but given it's github does not seem to have been updated for 4 years, it looks like it's pretty dead and probably severely outdated given the pace at which wayland evolves.
This does actually sounds like a fine use-case for [smithay](https://github.com/Smithay/smithay) (yes, shamelessly advertizing my own project): it does expose low-level primitives, and notably, the "handling wayland clients" part is completely decoupled from the "backend/screen/input/whatever" part, so you can absolutely use it for a headless compositor!
Especially if interaction is needed - Flot has a good story there. But the current itch is simply to plot out data without having to involve external tools like gnu plot or big gui frameworks 
[removed]
Thanks a bunch! I hadn't thought about it since then so I was pleasantly surprised to get answer after all this time :) That said those things seem similar but not quite the same as what I was thinking of? They're all to do with the interactions of threads having different priorities, while the question was about preemption of lock-holding threads in general, regardless of priorities.
It's kind of hard to justify rewriting a JIT into Rust though. JITs are complicated memory unsafe things, and there's nothing rustc can do to make you avoid being unsafe in asm! blocks. If you're writing a new one, sure write it in Rust. But the work required to rewrite SpiderMonkey, V8, or Chakra into Rust just isn't worth it.
&gt;Apart from this (and perhaps small performance improvements), am I missing any other advantages of explicit structs? I just don't like state I can't see. Usually when I call a free function with an argument the only thing I expect to modify is that argument. But here the function doesn't even take a mutable reference and it modified a hidden state that I can't even access. I feel that it's more rustic to go with the explicit option by default, and I don't see why not have it here. The select_loop! macro is a really cool idea, but if just having a struct will give you the same guarantees I'd still go with the struct personally. And I do think that the idea of having a macro for simple static selects should be a thing since it's probably the most common use, and if it won't be on the crate there would probably be 8 different versions of it buried inside other projects. 
Haha, thank you! :) Have a great [Sagan day](https://www.youtube.com/watch?v=iR-mFcEhQXQ)! 
Or just omit the lifetime and let Rust elide it: pub fn flag_as(self, field_to_update: &amp;str) -&gt; Token { /* ... */ }
Sure! It can seem super confusing, and that the compositors are re-inventing the wheel (and to a _certain_ extent that's true, but it's complicated). libweston is as you probably know the offering from the Wayland team. It's basically the library version of Weston, their reference Wayland compositor. The goal of libweston is to make it easier to write _extensions_ to the Weston shell. This is important, because that means you have far less options available to you. I admit to not knowing much about the implementation (except that it would be hard to wrap in Rust), so here's SirCmpwn's take on it from [this highly relevant thread](https://github.com/way-cooler/way-cooler/issues/248): * The codebase is generally pretty bad. It's has good performance but the actual code is pretty terrible. * It has a lot of questionable opinions like desktop-shell.xml that you will inherit with it * Weston design choices bubble up to libweston too, like the config parser, keybindings, etc. It does too much. * The API is poorly designed and basically just exposes internal weston headers to libweston users and hopes they'll read around the implementation details * Working on libweston involves collaborating with weston developers, which is... not something I would look forward to wlc is the library Sway, Way Cooler, and Fireplace uses currently. It was made as a small hobby project by Cloudef, and made to make it as easy as possible to make a compositor. Instead of messing with Wayland internals, it wraps everything in a series of callbacks. The only interaction you can do is in these is during a callback, so there's way less you can do (e.g rendering borders is very inefficient and very cumbersome). wlroots fixes a lot of the issues in wlc by exposing more wayland stuff. It means the compositor implementation (e.g Way Cooler, Sway) needs to do a lot more work, but it allows greater flexibility.
The mechanisms work in general- the Windows approach doesn't care about priorities, and the PI approach *can* be applied in the other direction (though I don't know how often it is, and I'm not sure it would actually change the outcome).
Hmm, there's not much details here (if you could expand on what capabilities are necessary that can help a lot. Are you just trying to talk to clients and have them talk to you? Or is there more you want to do) As levansfg pointed out, smithay might be good for that as they deattach from the backend. Note that wlroots also does this; the only qualification I would make for that is the safe bindings I'm making assume you'll have a backend enabled. You could hypothetically use my bindings / the unsafe bindings to make a headless compositor though. I suggest using `wayland-rs` (specifically `wayland-sys` if the wayland server is too opinionated for you) as that's a direct translation of the C library. However, you'll find it to be totally unsafe Rust code (defeating the purpose somewhat) and less ergonomic (unsafe Rust is very unergonomic compared to C, something I think Rust can definitely improve upon). The wayland re-write in Rust seems to have stalled, or at least I haven't heard anymore about it ([here is the project](https://github.com/perceptia/skylane)). It's probably too difficult to do in Rust, which is why it hasn't been worked on (and why `wayland-rs` is the go-to crate I suggest).
Your argument is pretty convincing so I wrote a [comment](https://github.com/crossbeam-rs/rfcs/pull/22#issuecomment-343270450) on the pull request. Having spent so much time fiddling with all this, I can be a bit biased when it comes to judging which API feels clearer and more natural. :)
This thread makes me so happy.
OK, fine, I'll share more details. :D I want to try to eventually turn this into a remote-desktop kind of network thing, but not for a whole "virtual display" but for individual apps/windows. Think something in between what RDP/VNC/X11 already do. Basically, there is a headless wayland server on the remote machine. Wayland apps connect to it. When they want wayland surfaces, the server creates the framebuffers and notifies the client running on the local machine. The client then opens an SDL window. The server sends the pixels that wayland apps try to draw, over the network. The local machine then renders them to the SDL window. The local machine also sends input events over the network, which the headless wayland compositor receives and passes on to the currently-focused wayland app. This is my vision at least. For now I am just playing around. :)
wish: a file with lots of configurations and it keeps changing between them from time to time, screensaver-like. otherwise, very nice!
&gt;Rust proposes that there is a problem with shared mutability, not all mutability. Shared mutability is, in fact [the root of all evil](http://henrikeichenhardt.blogspot.com/2013/06/why-shared-mutable-state-is-root-of-all.html)
Made it a screensaver in zsh using zsh-morpho https://github.com/jedahan/dotfiles/commit/294a7674c30a9d33cadaeffc36a66cec6eeec34f 
For those reading this, don't just click the link above, check out the graphs, and then wander away. Click the "Rendered" link to read the RFC. It's one of the best I've ever seen.
Had a feeling it was something like this :) Haven't used SDL before, but you can just use a wayland surface to display the contents from the server (assuming the client application runs in a wayland compostor. If you want to target X11 compositors running in the client too then SDL might be a better choice). I believe there's some work being done to add something like this, I remember hearing about it on /r/linux. You'll have to give it a looksie. Sounds like wayland-sys is the best option for this, though do check out smithay and wlroots. They might be good enough for your case. Have you considered making this a wayland protocol so that you can run this in a headless or headed environment? (e.g computer running Way Cooler at home, can connect and get GUIs from it using this application + the implementation of the protocol in Way Cooler)
One option worth considering is reversing the dependency -- drive the code with node.js using rust extensions written in [neon](https://github.com/neon-bindings/neon) for the parts that need to go fast or interact with native APIs. This might be simpler, and you could use all existing node packages. 
Works! (with a couple of easy wibbles) But damnit my phone really doesn't like muliple CPU cores running at full load for longer times, they're getting hot and then clocking down... combined barely faster than a single one. But then it's not like I was planning on compiling servo and/or rustc on it.
Ah I see. It seemed potentially relevant to the design of select and stuff.
C does not have an equivalent to `wrapping_offset`. If you change the C example to cast to integer, do arithmetic, and cast back, the miscompilation goes way -- LLVM considers the pointer to be leaked by the `==` because you are comparing with a pointer obtained from an integer. C pointer arithmetic compiles to LLVM `getelementptr inbounds`, just like `offset`. However, `wrapping_offset` compiles to `getelementptr` *without* `inbounds`, which -- as far as I know -- is not expressible in C.
Unfortunately, that view is wrong, and this is what the code here demonstrates. Pointers are complicated. If you compare two `usize` for equality, say `if x == y`, then it is okay for the compiler to replace `x` by `y` in the then-branch. If you do the same with pointers, you have a bug -- that's exactly what this bug here is about. The reason for this is that pointers, in C and LLVM, have a "provenance". If you do ``` int *x = (int*)malloc(4); int *y = (int*) malloc(4); if (x + 4 == y) { ... } ``` then LLVM will optimize the comparison away to `false` -- even though this program has defined behavior and the result could be `true` on the machine! The reason this optimization is okay for LLVM is that `x+4` retains the information that "this pointer was derived from `x`, which is a fresh pointer obtained via `malloc`, so the derived results can only access `x`". At the same time, it also knows that `y` does *not* point into the same object as `x`. Even though the two pointers may have the same bit pattern, LLVM considers them to be different pointers. In other words, two pointers having the same bits does not mean that they are the same pointer. The fact that Rust allows `==` (and even `&lt;=`!) on raw pointers in safe code is problematic; I have a bug report planned about that but I still need to get a nice convincing counter-example and &lt;https://github.com/rust-lang/rust/issues/45831&gt; is getting in my way. :/
Notice that the miscompilation still happens if you cast the pointers to integers before comparing them. However, that's due to another, related, LLVM bug: https://bugs.llvm.org/show_bug.cgi?id=34548. Essentially, turning `(int*)(int)x` into `x` is not a legal optimization.
The name "select" feels really opaque to me (as someone with little experience using channels). Is it an operation that allows you to send and/or receive data on a channel at the same time? And might there be a better name for it?
"Weâ€™re giving a tutorial today, November 5th, at SenSys 2017 in Delft, The Netherlands." might need to be updated? :p
But what does the second half of the `Result` behave like? I can sort of gather from context that unpacking it into the original component errors is only done at runtime, but I'm not entirely clear about it.
&gt; Haven't used SDL before, but you can just use a wayland surface to display the contents from the server (assuming the client application runs in a wayland compostor. If you want to target X11 compositors running in the client too then SDL might be a better choice). And I have used SDL plenty. :) (actually some of my first non-trivial programming projects when I was a kid were simple 2D games in C++ and SDL) It's awesome for cross-platform compatibility and I think it would work great for this. &gt; I believe there's some work being done to add something like this, I remember hearing about it on /r/linux. You'll have to give it a looksie. Hmm, I wonder what it is and how to find it. Haven't heard of it. I'll try searching for some relevant keywords. &gt; Have you considered making this a wayland protocol so that you can run this in a headless or headed environment? (e.g computer running Way Cooler at home, can connect and get GUIs from it using this application + the implementation of the protocol in Way Cooler) My idea is that I want the protocol to not be tied to any window system. Even not limited to wayland on the server side. I just want to start with wayland, as it is more modern, simpler, cleaner, and I know it better than x11. I don't want to build x11-like networking for wayland. I want to make a modern protocol for remote gui apps, a remote session/app manager if you will, that is window-system-agnostic. I've briefly thought about how it would work with x11 as well, but I am not very familiar with x11. It would probably be some VirtualGL-like contraption with a xorg server running as a separate process and my server managing it somehow, or something like Xvnc / vnc servers. Don't know yet. I'd rather not think about it yet; X11 is ugly. Also, after I get the basics working (hopefully, if i don't give up by then, that is), I want to try to play around with using different codecs for every window/surface, so that most normal gui apps use a tightvnc-style compressed pixel codec, while multimedia apps (media players, CAD/Blender, games, etc) use a video codec like vp9. This should make it possible to remotely stream such apps, which is not possible with VNC and such. This kind of functionality is really what my main motivation/inspiration is. AFAIK there is currently no good way to do something like this. OFC, this whole set of ideas is super ambitious. I may or may not actually end up accomplishing any of this. I have a lot of free time now and in the near future, though, and interested friends who want to help. :) Maybe after I get some stuff working, there might be an interest from people in the Rust community as well, who knows. :)
I'm working on k8s compatible runtime for freebsd jails. (Un)fortunately it involves making wrappers for tons of FreeBSD libraries. Which isn't an easy task given that there is 0 hosted CI support for FreeBSD...
Link to github repo on https://morq.rs leads to 404. 
Iâ€™m rolling out a new version of `luminance` that will have a better *render state* interface and will come with face culling embedded (such an easy change, Iâ€™m still wondering why I havenâ€™t done that earlier haha). Also, Iâ€™m rolling out `warmy`, my resource system for hot-reloading cached resource Iâ€™ve built in `spectra`, my demoscene crate, as it was asked on IRC. Iâ€™ll write a blog post about it and will be looking forward to feedback!
`to.be.or.not.to.be`.
Interesting! In my case, I am iterating through disjoint elements (which I would like to persist beyond calls to `next` so that, for example, they can be collected). It seems I may be stuck with unsafe code for the time being.
Apparently it's named after a function in Go, which it's emulating.
Yes, `next` should only ever yield unique mutable data. Moreover, that data should never alias any other data yielded by `next` (it should not be possible to use some data to reach some other data). As far as the lifetimes are concerned, getting an `EdgeCirculator` requires a mutable reference to the source of the data with a lifetime `'a` (held by the circulator). Since the circulator will only ever yield each disjoint piece of mutable data once, I reasoned that it was okay to `transmute` the references to the mutable data to use lifetime `'a` instead of the narrower local lifetime from `get_mut`. The reference held by the circulator means the data should remain alive and it does not allow it to mutate outside of the references it yields from iteration. Hopefully this is correct. :-)
Maybe jumping the gun a bit here, but is it possible to make this select work with fd's too?
It allows you to declare a set of send/receive operations on channels and then block until one of those succeeds. Usually, you can also specify a timeout, or what to do if all channels are disconnected, or choose to do something else if all send/receive operations would block. Note that always at most one operation in a select succeeds - never two or more. The term *select* is actually pretty common: in [Go](https://gobyexample.com/select), [Rust](https://doc.rust-lang.org/nightly/std/macro.select.html), [futures](https://docs.rs/futures/0.1.17/futures/future/trait.Future.html#method.select), [Linux](http://man7.org/linux/man-pages/man2/select.2.html), and so on.
Ah, the software I was thinking of is called pipewire. And it's only for gnome, so never mind (from [here](https://www.reddit.com/r/linux/comments/7bm9az/what_cant_be_done_on_wayland_still/)). Your project sounds super interesting. I don't know much anything about codecs/sdl and only the minimal about graphics (you surprisingly need very little to implement a compositor, since the clients do most of the heavy lifting). If you end up working on it, be sure to post it here or at least ping me. I'd like to have something like this for Wayland, as it's the last thing I miss from X11 that I can't see in the near future without considerable effort. Plus I think I can find some free time somewhere to contribute :)
&gt;The name "select" feels really opaque to me (as someone with little experience using channels). Is it an operation that allows you to send and/or receive data on a channel at the same time? It is used to detect when a message is available in a set of different channels. I guess that the name comes from Go. &gt; And might there be a better name for it? Erlang uses `receive` to define a handler for receiving messages. Not the same thing, but very similar. 
How is `TcpCodec` implemented?
The fact that thereâ€™s a link to the source of the implementation ameliorates the problem, but showing what the default value is like that is a pretty cool trick.
CC /u/kibwen
Do you mean to say the API does not look great? Or the underlying implementation of that particular macro is not great? To clarify, I meant to say that I imagine it would be easy to write a macro that wrapped the `select` functionality of the new crossbeam-channel that stjepang is proposing, rather than "in general". I have no idea how `chan_select!` is implemented under the hood, but it sounds like the select approach of this new proposal solves a lot of existing problems? I personally feel that that `chan_select!` API *looks* quite nice and close to what I was imagining as a wrapper around this new select API, though I haven't personally used it so can't speak from experience.
&gt; I guess that the name comes from Go. `select` has been a thing in C/Unix for a lot longer than go existed, it [looks like](https://idea.popcount.org/2016-11-01-a-brief-history-of-select2/) it was invented in 1983 with sockets.
Check out the docs for the macro. I wrote some downsides. :)
&gt; I guess that the name comes from Go. `select` has been a thing in C/Unix for a lot longer than go existed, it [looks like](https://idea.popcount.org/2016-11-01-a-brief-history-of-select2/) it was invented in 1983 with sockets.
ATS gives you more freedom and more responsibility, it is arguably much harder to program in ATS than Rust. It also gives better guarantees. There was an excellent talk on it at Strangeloop 2017.
So a given binary only works with a particular server version? That seems limiting to me, but I don't know your intended deployment model.
Am I able to have functions give generic types of types that implement a given trait? Something like: trait SomeTrait; struct A; struct B; struct C; impl SomeTrait for A { ... }; impl SomeTrait for B { ... }; impl SomeTrait for C { ... }; fn some_func&lt;T&gt; (s: String) -&gt; T where T: SomeTrait { match s { "a" =&gt; A, "b" =&gt; B, - =&gt; C, } } Using an enum would probably get me what I want, but then (afaik) I can't implement `SomeTrait` differently for each enum.
If I were to go the conditional compilation route, I think it would work with a minimum version. So for example, if a downstream application specified the `kafka_version` feature as `0.9`, it would compile the structs with the API version format supported by the 0.9 brokers, and since brokers support older API versions, the resulting application binary would be able to talk to a broker of version 0.9, 0.10, and up, but not a 0.8 broker.
Yes, it's a new feature called "abstract return type". Syntax is `fn some_func(s: String) -&gt; impl SomeTrait`
Looks like it's still nightly, and doesn't work the way I want it to anyway. The error is now `expected type A, found type B`. Seems like it still has to return a single possible type, it's just more flexible in what type that might be.
&gt; Seems like it still has to return a single possible type. Try returning `Box&lt;SomeTrait&gt;` then.
select is a lot older than go http://man7.org/linux/man-pages/man2/select.2.html
You definitely need some unified internal representation to limit this versioned nastiness to the step just adjacent to the network. You do have that, right?
Esp8266/esp32 support?
If you want to override a lifetime you can just cast to a raw pointer and then `&amp;*foo` or `&amp;mut *foo` deref-reref it. But it seems like that's not the actual problem here.
https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.min shows this example code: let a = [1, 2, 3]; let b: Vec&lt;u32&gt; = Vec::new(); assert_eq!(a.iter().min(), Some(&amp;1)); assert_eq!(b.iter().min(), None); Why is the value min() returns an Option(&amp;whatever)?
Results in some messy code, but it works. Thanks.
I'm not 100% sure about TockOS, but I highly doubt it. Both of those have a microprocessor with Xtensa architecture and there is no LLVM backend for that as far as I know. I use the esp8266/32 for a lot of projects and would love to be doing all of those with Rust. I've thought about trying to write a backend, but I'm not sure I know enough to even get started.
whats that
I've done enough flair vandalism recently, I think. :P
It returns `Option` because what you are iterating may be empty, in which case there is no minimum and you get `None`. It returns the minimum value of whatever type the iterator yields. In the example `a.iter()` yields `&amp;i32`, so you get `&amp;1`. If it yielded `i32` instead you would get `Some(1)`. Try it with `a.iter().cloned().min()`.
well you probably know more than I do. I barely know what LLVM is. How hard is this do you think? Are all the tricky optimizations already done before the LLVM code is generated? Is it as simple as translating one or more LLVM instructions into the equivalent native instruction(s) and mapping registers or something?
0.8.0 does not include the performance win from that PR. It would indeed be interesting to see the new numbers. FWIW, In WebRender we've gotten some pretty significant performance improvements when using bincode with the addition of some unsafe code: https://github.com/servo/webrender/blob/f58ed651b47f47382b63dd2bce6e4ed10ee18c78/webrender_api/src/display_list.rs#L460. Even with these hacks, we still don't have the deserialization performance that we're looking for, so we have more performance improvements planned. 
Two different microcontrollers with wifi or wifi+Bluetooth built in. Designed for "internet of things" (which I prefer to call "internet of random crap that will all get hacked and dos attack you") devices. If you want to connect your toaster and blender to the Internet this is what you use.
i have a toy car with a controller i play with
Currently, I would say the struct representations are less of a "unified representation" than just single versions that represents older API formats. There are some places that specify newer API versions in some circumstances, but presently it's very ad hoc. I'm trying to figure out how to support the new versions and keep the code sane. A "unified version" is what I was trying to avoid, since that will mean basically having a lot of `Option` fields. I don't know if that's avoidable though.
Give me some examples of optional fields, please. I want to see that they're truly unifiable. Or an example of two very different/distant versions of messages.
ha. I may have accidentally given you the impression that I know what I'm talking about. :) Sometime last year I read the LLVM docs on how to write a backend, it was way over my head at the time. I think I'd probably get a lot further with it if I reread them now, but I haven't had the time nor motivation. There are lots of examples of people writing backends out there, but I just don't quite understand enough to dive in. I believe you're correct that it is just 'as simple as translating' the instructions, but simple is a relative term. I think mapping registers and all of that would be a layer above the LLVM stuff, that would most likely take place in a kernel-ish type abstraction I believe. After getting asked a lot of questions at Rust Belt Rust, I did a lightning talk about getting started with embedded development in Rust. I was hoping to dispel the idea that I was an authority rather than someone who has tinkered a lot and read everything /u/japaric has written. I also thought I might be able to find someone to give me a little guidance/mentor me, but I haven't had much luck yet. Maybe if there is more than just me interested in this, it might be enough to motivate me to jump back into the docs....heck if there is more than one of us we've almost got enough for a working group!
What's the general problem you're trying to solve? Boxed trait objects are pretty rare in Rust; using them as keys to a hash map even more so.
[removed]
You can take a look at the link to the Kafka docs in the OP. In particular, there are several time stamps added across the Produce Response versions that would all be to be `Option`s if I tried to represent `ProduceResponse` in a single struct.
&gt; I've never seen it referred to as probabilistic, and therefore assume it isn't, The default is a "universal hashing" algorithm, meaning the hash function hashes both bytes from the key and a randomly selected "seed." So a key will consistently have the same hash *for a specific hash table*, but if you restart the program or create a different table, the hashes will be completely different. This makes it difficult to accidentally or intentionally create collisions. Collisions of the full hash. Only part of the hash is used as an index. (How much is used depends on the current size of the table.) These smaller collisions are common and are handled by saying "if the key 'should be' at row 236, start at 236, then check 237, 238... up to some small number of potential locations all next to each other." The mechanics of how that works is "robin-hood hashing." 
I'm trying to do a little RPG project. In particular, I'm trying to abstract away the exact concrete type of a member in a battle so that they can be implemented many different ways. I've created a trait that can be used to describe a combatant in a battle. This trait can then be implemented by multiple structs. trait Combatant {...} struct PartyMember {...} impl Combatant for PartyMember {...} struct Enemy{...} impl Combatant for Enemy {...} I can see how this could be implemented using enums, but something about that would seem a bit backwards. I'm not sure I see how this could be done with generics. Now that I think about it, this would be a really weird thing to want. I'm thinking of them as value types, so I would like to I would like to be able to use them in a hash map. That could be potentially dangerous; I'm not sure you can guarantee the conditions for hashing will always hold with two objects implementing the same trait.
Finally, [I found motivation.](https://github.com/BurntSushi/chan/pull/23)
Unless I'm missing something big, it looks like each version up is a strict superset of the previous. So use the highest version internally, "upsample" when you parse a request (yes, maybe using options in some places) and "downsample" when you're ready to respond. When you downsample assert in some way (i.e. unwrap()) that all the fields you need are there. I think in the cases where something _has_ to be an option, it's okay for it to be an option. There is clearly a sensible way to treat the lack of data there, otherwise it would've existed in v0. Do the v0 behavior when None.
Bit confused about the `&amp;` operator. fn take_and_return_ref(S: &amp;String) -&gt; &amp;String { //.. &amp;S //&amp;object is not returning address! } So as far as I understand: | C++ | Rust ---|---|-- Reference of | type&amp; | &amp;type Address of | &amp;object | ?? [what is this?] Dereference | *object | *object How do I get an address of an object? I guess my question is how do references work when compared to C++.
Yeah, this may be the best approach, given the existing language features. I was just kind of hoping to avoid this kind of mess. ðŸ˜©
Wow, I've only switched to linux desktop a few days ago (ubuntu 17.10 with wayland and xorg) and had to switch back to x11 for some programs that didn't start in wayland. I was getting annoyed, subliminally, with the somewhat choppy animations. Just reactivated wayland and it's great (again). I guess productivity wise this is minor but subjectively, well, if you could see the grin on my face right now. You're right though on the video, still not perfect.
This looks a lot like an OOP design shoehorned into a trait.. Hm.
Curious: What language do you come from that gives you the idea this is messy? How would you like to do it, if you could magically write (or have written by someone else) the Rust You Want(tm) overnight?
Let me be a bit of an ass, but I just need an answer: why "LOL"? I imagine you know what that means. And all in caps also. I mean, why man
That's obv false.
It's messy because it requires special case code everywhere that would use this data. If this field is here, do this, if not do that instead, times the number of optional fields. It's very tedious, and makes the code hard to reason about because you have to have n different branches in your head. To my knowledge, this isn't cleanly solvable in any language. Maintaining compatibility across different software versions is just a tedious business. Most of my professional experience is in Java, where one would probably do this with a class hierarchy. In this case, the different versions are a little cleaner from a type perspective (each class only has its own fields and nothing more), but practically you're just doing `instanceof` everywhere instead of `if let Some`. I'm just trying to find out what the least bad approach is.
A hash map is definitely a very strange choice here.
Treat your types like data definitions instead of classes modeling scenarios. Your game logic is transformations on that data, not interactions between the classes. Traits aren't meant to be used like interfaces or abstract classes; a trait is applied to a constraint on types which describe operations over their data, not naming common behaviors. If you follow this approach, you'll quickly run into scenarios where you need more and more data common between each distinct type that you have to provide getters and setters over in the trait, which is very painful to maintain. Your best bet, and the most common approach in Rust game dev right now, is to use an ECS and describe this data as components of entities. See [specs](https://slide-rs.github.io/specs-website/docs/book/0.9/01_intro.html)
I read over the LLVM backend docs and I guess it's somewhat like what I expected but more complicated as you still have to worry about stuff like lowering and late stage optimizations. (I'm really not a compiler person.) This suggests some work has been done on xtensa https://esp32.com/viewtopic.php?f=2&amp;p=8760 but not enough. Perhaps it's at least good enough to provide a skeleton for further progress, but I'm not sure what the major challenges are. (Are there problems with the LLVM IR not mapping well to the architecture? Etc)
Lol because I legitimately laughed when I read that he had implemented both 'a' and 'an'. As for all caps, I think that's just habit. Way back when in the early days of instant message, message boards, et al, it was usually written all caps. I just never dropped that early habit.
Rust references are very similar to C++ pointers except they have additional lifetime and mutability metadata used by the borrow checker. In your example function, `S` is already a reference so you can return it as-is. There is no auto-ref currently, so if you had some rvalue `string: String` you wanted to pass to this function, you would call it with `&amp;string` (ignoring string slices and deref coercions).
If you want to do OOP then you should use an OOP language. Rust is not for you...
I can't speak for the rustfmt team, but my general rule of thumb is this: Rustfmt is considered stable once you can get it with rustup. Oh, and when there's a huge announcement ;) So, no, it hasn't reached *that* level of stability yet. A lot of projects are using it, though, and I'd encourage you to use it as well. A lot of style bikeshedding has settled down, and in recent releases (make sure to install rustfmt-nightly) the style is pretty stable. Also, if you care about this cool, this is your opportunity to report bugs and help fix existing ones! To underline how much I trust its stability: I have a CI pass in my recent projects that runs rustfmt and breaks when there is a diff between what it writes and the current code base. 
I once introduced a new trait: AnyHash: trait AnyHash { fn hash(&amp;self, h: &amp;mut Hasher) } It gets rid of the generic. You can then implenent Hash for Box&lt;AnyHash&gt;. I really can't remember but somehow I needed Any also, can't see why anymore. I'll look it up when I reach a real computer.
&gt; Clang has pioneered code-instrumentation Not really, developers were just not paying for them, lint for C exists since 1979. &gt; Although the first edition of K&amp;R described most of the rules that brought Câ€™s type structure to its present form, many programs written in the older, more relaxed style persisted, and so did compilers that tolerated it. To encourage people to pay more attention to the official language rules, to detect legal but suspicious constructions, and to help find interface mismatches undetectable with simple mechanisms for separate compilation, Steve Johnson adapted his pcc compiler to produce lint [Johnson 79b], which scanned a set of files and remarked on dubious constructions. https://www.bell-labs.com/usr/dmr/www/chist.pdf The only thing that clang made, what making such quality tools available for free (gratis).
Not at all. Also given the constraints of some of them, you can only use them in specialized test builds.
Clever!
Wouldn't it be better to just have rust doc automatically inline this value for default instead of having to duplicate it
Wait, don't they run on their own and you just interact with them which you can do even from rpi?
It should solve a lot of tearing issues people face right now, and it requires less resources than Xorg, there's no such thing as a separate display server like in Xorg, so the DE/WM &amp; the actual display part are one binary, which should result in less resource usage. As far as a desktop user's perspective goes, gnome &amp; sway are one of the only few wayland compositors that are actually complete and stable. It also lacks a lot of functionality that you might miss, things like OBS, redshift, and other things just won't work, and most games will run under Xwayland
Depends, if supporting mainframes is a goal or not.
I had a look around recently for Cortex M systems that would match up to the ESP32 and the best I've found is the [LinkIt 7697](https://m.seeedstudio.com/productDetail/2818), I just got mine the other day, I haven't had time to try it out with Rust yet, but its on my to do list.
I don't really understand what your goal here is (i havn't seen the video yet). If you want something that explains Rust to an audience not familiar with programming â€“ than i don't think something like that exists for Rust (yet) If you want to show some key concepts of Rust to an audience familiar with programming like C or C++ than i would recommend [intorust.com](http://intorust.com/)
The only problem is that it force the type to implement `Eq`
Seems like you could slightly get around that with `assert_eq!(a.field1, Aaa::default().field1);` for each field.
I'd leave the assert visible. It's usually the best part of the documentation. Kudos!
Yup, but this way it will be possible to forget to update the comments when adding new fields.
I might write an RFC for that, yeah.
Not sure why this has not been mentioned yet, but you can create a new struct instance from an incomplete list of fields + an existing instance, like this: let tok1 = Token::new("..."); let tok2 = Token { is_digit: true, ..tok1 }; Not sure if this is what you need in this specific situation, but it is often useful when wanting to return updated copies of immutable structs.
In that case, you can use pattern matching to make sure all fields are mentioned. # if let Aaa { field1: 3, field2: 5, } # = Default::default() { # } else { # panic!("Mismatching documentation and implementation for Default."); # } This will fail if values are changed, and if fields are added, removed, or renamed. 
Somebody should write a procedural macro verifying a/an use.
And this way the problem is that all the fields need to be public, but thatâ€™s a good hack too !
This succession can't be understated as an excellent approach, arguably the best when applicable.
There's also Mir now! Or, rather, soon ðŸ˜€
Hi, I'm learning rust having not delved into much low level stuff before. I want to do something quite simple but I'm not sure how I can do it with respect to ownership/borrowing. I create an instance of a struct and make some changes to it using mutable references, however, after passing these mutable references, with the hope that the underlying variable has changed, I want to run an assertion against the underlying variable. How do I do this? Code below: #[test] fn cracker_select_in_three_from_single_column_table() { let mut table = new_table(); assert_eq!(table.a.crk.len(), 0); standard_insert(&amp;mut table, &amp;mut vec![13, 16, 4, 9, 2, 12, 7, 1, 19, 3, 14, 11, 8, 6]); // ^^^^mutable reference 1 let pos_h = (table.count - 1) as usize; let selection = cracker_select_in_three(&amp;mut table, 0, pos_h, 10, 14); // ^^^^mutable reference 2 // assert_eq!(table.a.crk, vec![4, 9, 2, 7, 1, 3, 8, 6, 13, 12, 11, 16, 19, 14]); // ^^^^compiler error "cannot borrow `table.a.crk` as immutable because `table` is also borrowed as mutable" assert_eq!(*selection, [11, 12, 13]); } I tried using "unsafe" as: unsafe { assert_eq!(table.a.crk, vec![4, 9, 2, 7, 1, 3, 8, 6, 13, 12, 11, 16, 19, 14]); assert_eq!(*selection, [11, 12, 13]); } but it gave me the same compiler error.
From my experience (16, little formal C's eduction) traits were really easy to grasp. Trait objects, lifetimes, and complicated generic + lifetime situations are only places I've struggled. That said I haven't touched married yet.
Rustfmt is not yet stable in either sense, we are aiming for early next year for a 1.0 release which should be 'stable'. Obviously gofmt has been around for a few years, so it will take a little while longer until rustfmt is *that* stable. However, rustfmt is pretty good! I do think it is stable enough for most users. Bugs and changes in formatting both tend to be small, subtle, and infrequent. I would avoid it if you are in a strict enterprise environment or something, but otherwise, give it a go!
Okay, I think I get it now. History aside, I would still say the name is opaque though. Since the `crossbeam` version only waits for the first operation, I think the name would be significantly improved by being something like `select_first` instead.
Just to be sure, OBS redshift etc also don't work with XWayland?
They do out of the box, but only because they already have some software preloaded. It's also possible to replace this with your own software, but it's not currently possible to do this in Rust as LLVM doesn't support the architecture.
&gt; Since the `crossbeam` version only waits for the first operation, I think the name would be significantly improved by being something like `select_first` instead. `crossbeam-channel` doesn't wait for the first operation only - it waits until *any* operation can succeed. And if more than one operation can succeed at the same time, then a random one is chosen.
Redshift does something with the display I don't exactly know what, but no you can't do that in xwayland. Also I don't think OBS works in Xwayland but even if it did it could only capture Xwayland windows, nothing else. I had some luck running gnome-pie on xwayland but it was confined to the gtk window and the window had to be focused for me to activate the shortcut. And the wayland developers refuse to add functionality allowing this into the main wayland protocol, so that's just gonna fragment things since different compositors will have different ways to do things such as screen recording.
Also need nightly. For Debian, apt-get install libwebkitgtk-3.0-dev libwebkit2gtk-4.0-dev I also had to add #![feature(iterator_for_each)] to the start of `src/bin/mod.rs` to get it to compile. Having done these things, seems to work fine! Would be nice to be able to expand the names pane to be able to fit all the names without scrolling. Left-justified would probably be better than centered here. Also, render the font names in the font optionally for quick sans. Thanks for sharing!
I have absolutely no idea what you're asking.
The jittering definitely happens. Just recently I updated my nightly installation and rustfmt and it moved some of my inline comments to a new line for some reason.
`select_any` or `select_any_ready` maybe? I know it's more verbose than just `select`, but `select` only makes sense if you know about it from somewhere else (like Unix syscalls). And even then, it seems there are slightly different semantics in the examples you gave; the Go version `select`s all messages (not just one), and the futures version takes the first one that is ready (so no randomizing). This speaks (in my mind) for a name that more accurately describes what `select` actually does.
After some googling and experimenting, the solution was to introduce an artificial scope to make it clear to the compiler where the mutable borrows were taking place. It's actually quite nice how the compiler makes you clarify where state changing interactions take place, the partition of the code into different scopes is quite neat. #[test] fn cracker_select_in_three_from_single_column_table() { let mut table = new_table(); { { standard_insert(&amp;mut table, &amp;mut vec![13, 16, 4, 9, 2, 12, 7, 1, 19, 3, 14, 11, 8, 6]); } // Leave scope, destroys the mutable reference to table. assert_eq!(table.a.v, vec![13, 16, 4, 9, 2, 12, 7, 1, 19, 3, 14, 11, 8, 6]); assert_eq!(table.a.crk.len(), 0); let pos_h = (table.count - 1) as usize; let selection = cracker_select_in_three(&amp;mut table, 0, pos_h, 10, 14); assert_eq!(*selection, [11, 12, 13]); } // Again, leaving this scope destroys the mutable reference to table. assert_eq!(table.a.crk, vec![4, 9, 2, 7, 1, 3, 8, 6, 13, 12, 11, 16, 19, 14]); } 
I'm not too experienced in Rust myself. Anyway, let me pick out just one part: pub fn has_between_range(&amp;self, hue: &amp;i32) -&gt; bool { if hue &gt;= &amp;self.range[0] &amp;&amp; hue &lt;= &amp;self.range[1] { (true) } else { (false) } } The result of a comparison is already boolean. I don't see why you need to write it more explicit than: pub fn has_between_range(&amp;self, hue: &amp;i32) -&gt; bool { hue &gt;= &amp;self.range[0] &amp;&amp; hue &lt;= &amp;self.range[1] } 
rustfmt is still missing major features: - it doesn't handle reflowing of comments well, or at all - it doesn't handle long URLs in comments well, or at all (and splitting them in such a way that rustdoc can still link them doesn't work) - it is not shipped with rustup - it still has lots of bugs
You can easily do that without any clones at all, using but a single `Vec&lt;(K, V)&gt;` allocation. [Here you go](https://play.rust-lang.org/?gist=97c5776b55dca4b920ceba0a7918447a), good luck! :)
Nice catch, that was from some time ago so I don't kniw what Iw as thinking but you are totally right!
[removed]
There are crates for [rgb](https://crates.io/crates/rgb) and [hsl](https://crates.io/crates/hsl) formats, perhaps it would make sense to use those for your rgb and hsl outputs, respectively. This would increase interop between crates.
The way it is designed (as a compiler plugin) also means it's not really possible to give rustfmt a snippet and ask for the formatted version. It has to be a proper program that the compiler can parse. This is one of the things preventing formatting examples in documentation or Rust code snippets in a markdown document.
Well, since you asked for it: you spelled "colour" wrong. Some significantly less important problems: What's with all the stringly-typed data? If you've only got a small set of valid values, you should be using `enum`s. If you want to be able to load from a string, you should have an implementation of `FromStr`. You seem to be using by-value methods a lot when you don't need to. If you can use `&amp;self` instead of `self` on a method, you should. That said, there's no point in ever taking `&amp;i32`. I'm not aware of any situation in which it will be faster than taking an `i32` directly... unless you're targeting 16-bit platforms. Also, I'm not sure why `ColorDictionary` is a structure with fields; you don't look like you ever change them. It looks like it could be some free functions and some constants. You probably shouldn't use `thread_rng` directly. What I mean is that you should let the caller choose the random number generator. You can always provide convenience methods that use some default automatically. Looking at some of the code for hsv-&gt;rgb conversion, I'm wondering how robust this code is to things like negative or over-sized values. The `if hue == 0 { hue = 1; }` bit in particular sets off alarm bells. Good to see tests.
Definitely a good idea, going to write that on the roadmap!
[removed]
&gt; the Go version selects all messages (not just one), No, it selects just one - only one operation in a select is actually performed. &gt; the futures version takes the first one that is ready (so no randomizing) It is true that if both futures are ready, it will return the result of the first one. The futures version of select is a bit different in that you have two *existing* futures and then create a third one that completes as soon as at least one of the first two completes. But, in the end, both of them should complete. Selection over channels declares a set of *potential* operations and waits until any of them can proceed. As soon as that moment comes, only one operation is actually executed. &gt; `select_any` or `select_any_ready` maybe? Maybe. I guess this is one of those issues on which people will simply have to disagree. :) My opinion is that `select` will suffice since there is already a strong precedent from Go and Rust's standard library (see [`select!`](https://doc.rust-lang.org/std/macro.select.html)). If you still feel strongly about choosing a different name for `select`, I'd suggest commenting on the pull request so we can hear more opinions.
&gt; No, it selects just one - only one operation in a select is actually performed. Oh yeah, it's the loop that makes it do both. Never mind that example then! &gt; Maybe. I guess this is one of those issues on which people will simply have to disagree. :) Which is completely fair :) My reasoning is that the name is not that easy to grasp for anyone not familiar with that precedent (which could be a big portion of Rust's users, coming from interpreted languages). I'll take it to the PR though :)
I'm pretty confident in the code for `CircularBuffer`, but I know that `Drop` impls can be tricky and I want to know that `OwnedSlice` is sound. I feel certain that it's not possible to access dropped data, but I'm wondering if anyone with more experience could lend a hand.
Just want to make sure you've taken a look at [specs](https://github.com/slide-rs/specs)
Have you completed it to the one in std? https://doc.rust-lang.org/std/collections/struct.VecDeque.html
Sorry for late answer, currently at work now. &gt;Well, since you asked for it: you spelled "colour" wrong. Will have to [disagree](http://grammarist.com/spelling/color-colour/) on that haha :) &gt;What's with all the stringly-typed data? If you've only got a small set of valid values, you should be using `enum`s. If you want to be able to load from a string, you should have an implementation of `FromStr`. You mean thinks like hue and luminosity, right? &gt;You seem to be using by-value methods a lot when you don't need to. If you can use `&amp;self` instead of `self` on a method, you should. Definitely need to improve this. &gt;That said, there's no point in ever taking `&amp;i32`. I'm not aware of any situation in which it will be faster than taking an `i32` directly... unless you're targeting 16-bit platforms. &gt;Also, I'm not sure why `ColorDictionary` is a structure with fields; you don't look like you ever change them. It looks like it could be some free functions and some constants. Again, seems like you are totally right, I need to rewrite color_dictionary. If you have any tips I'd like to hear them! You probably shouldn't use `thread_rng` directly. What I mean is that you should let the caller choose the random number generator. You can always provide convenience methods that use some default automatically. I'd **love** to do something like that, mind expanding a little bit more? Don't really know how to start with that :) &gt;Looking at some of the code for hsv-&gt;rgb conversion, I'm wondering how robust this code is to things like negative or over-sized values. The `if hue == 0 { hue = 1; }` bit in particular sets off alarm bells. Hmmm, all the math is the same as the original library so I didn't give it a second look, but I'll check that. &gt;Good to see tests. Yay! Thanks :) 
I think you got the semantics of `const T*` vs `T *const` mixed up. And seriously, who could blame you, in typical C gotcha fashion: void foo( const int *p, // a mutable pointer to constant value int *const q, // a const pointer to a mutable value const int *const r // a const pointer to a csont value ) { p += 1; // OK *p += 1; // ERROR q += 1; // ERROR *q += 1; // OK r += 1; // ERROR *r += 1; // ERROR } void main() {} 
Wow, the buzzwords alone on that thing merit a few millions of VC funding! (Still not sure why it's so important for a signal generator to be network-connected)
You could use the `Scanner` struct from https://github.com/EbTech/rust-algorithms.
If you don't mind reading one line at a time, you can easily do something like let mut line = String::new(); std::io::stdin().read_line(&amp;mut line).expect("input"); let nums = line.trim().split(' ').flat_map(str::parse::&lt;i32&gt;).collect::&lt;Vec&lt;_&gt;&gt;(); for num in nums { println!("{}", num); } Of course the above code will silently skip inputs that aren't a number, but it shouldn't be hard to change that if you prefer to report errors or something.
This is great. Thank you!
Trust me, they were returning *many* errors while I was trying to get them working. Thank you for this!
&gt; You mean thinks like hue and luminosity, right? Yes. &gt; Don't really know how to start with that :) You want to call [`Rng::gen_range`](https://docs.rs/rand/0.3.18/rand/trait.Rng.html#method.gen_range). It requires `&amp;mut self`. So you want a function with a signature that looks something like `fn pick_brightness&lt;R: Rng&gt;(&amp;self, rng: &amp;mut R, ...)`. Then you can call `rng.gen_range` instead.
Perfect. Thank you very much!
It seems odd to do something like this with a colourspace which isn't perceptually uniform. Something like Lab colour seems like a better tool. That said, I'm on mobile so haven't had more than a cursory glance.
I'm trying to modify (help with) a third party crate, which maybe is not good idea because I'm such novice but well... And they/I have this: pub struct DataFrameBuilder&lt;I, C&gt; where I: Clone + Hash, C: Clone + Hash { pub index: Indexer&lt;I&gt;, pub columns: Indexer&lt;C&gt;, } impl&lt;T: Clone + Eq + Hash&gt; From&lt;Vec&lt;T&gt;&gt; for Indexer&lt;T&gt; { fn from(values: Vec&lt;T&gt;) -&gt; Self { Indexer::new(values) } } And I'm trying to do something simple like: let vector : Vec&lt;i32&gt; = vec![1]; DataFrameBuilder { index: vector.into(), columns: vector.into(), } In my mind this should work, not sure where to search for that but I'm quite sure i32 is Clone, Eq and Hash But I get the trait `std::convert::From&lt;std::vec::Vec&lt;i32&gt;&gt;` is not implemented for `brassfibre::prelude::Indexer&lt;I&gt;` I know, really basic question but any idea what's going on?
For my use cases, it shouldn't be too hard to do batch calls between Rust and JS when necessary. And in the other cases, performance doesn't matter that much. The thing is, I want that game to be moddable and so I cannot have Rust do all the hard stuff. If the server has any bottleneck (and this will happen at some point), it is probably going to be the scripts. And that's why they have to be fast. JavaScript has its quirks but so does Lua too (1-based arrays are error-prone, arr[3] = nil is undefined behavior, ...). And 'use strict' can help avoiding common problems with dynamic languages. 
Only two boards supported and they are $60 and $100? For a cortex M!
That's why you do batch calls. For the rest you rely on the scripting language. Another reason for it to be fast... There is a clear speed advantage in JS. Just have a look at the benchmarks, or roll your own. Saying that Lua is as fast as a JS JIT engine is like saying that Lua and LuaJIT have equivalent performance . It's just not true. I completely agree that Lua (or pypy, or lisp) is fast enough when it's not the bottleneck. But for my use case that doesn't work. LuaJIT would be a viable alternative but it's not much simpler than using mozjs. And pypy is hard to embed. And not that fast. I have I believe good reasons for choosing JS, and I'm not going to use Lua anytime soon. You can disagree with this but... that's just your opinion, man. 
I don't know what's going on, but I can tell you that using `From` or `Into` *consumes* the value it's given, so even if you didn't have that error you still wouldn't be able to say: index: vector.into(), columns: vector.into(), Because the first `into` consumes `vector`, leaving it unavailable for the second `into`.
I tweaked the code to make it shorter, I have two different vectors 
Nightly is not needed. It compiles fine on stable.
&gt; And lisps are too slow. Don't conflate first year CS students' code quality with capability of the language. Lisps, even ones like Racket that are wrongfully though of as 'toy' languages by many, regularly [outperform Lua](https://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=lua&amp;lang2=racket) and [Python](https://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=python3&amp;lang2=racket), and are [worse than JavaScript about as often as they are better than JavaScript](https://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=node&amp;lang2=racket).
Nope, just duplicating data is perfectly safe. The only downside is you consume memory if data is big.
Is there an built in way to turn 2 bytes into a `u16`, or the `[u8]` representation to any numeric type? ``` fn from_bytes(big_end: u8, little_end: u8) -&gt; u16 { (big_end as u16) &lt;&lt; 8 | little_end as u16 } ```
Okay. So what error message do you get when you replace `vector.into()` with `Indexer::new(vector)`?
Perhaps the [byteorder crate](https://crates.io/crates/byteorder) may be of interest to you.
&gt; unless you're targeting 16-bit platforms Even then, the additional indirection would make it slower.
Aah, but only if you *dereference* the pointer. \**taps side of head while nodding*\*
True, it's faster if you don't ever use the value!
I have not. I'll give it a look. Thanks!
I definitely see where you're coming from. This approach is going to require more and more boilerplate and hacks as it develops. I'll look into other approaches. Thanks for the advice!
I didn't really see any alternative to OOP here. enum still seems like a rough way to handle this. In any case I'll look into look into it. Thanks for taking the time to respond.
If there are private fields, those should probably not be mentioned in the docs either. # if let Aaa { field1: 3, field2: 5, .. /* fields omitted */ } # = Default::default() { ... 
Just pushed a workaround that fixes the justification issue: // Create the inner label of the row that contains the family in bold. let label = Label::new(""); label.set_markup(&amp;["&lt;b&gt;", family.as_str(), "&lt;/b&gt;"].concat()); label.set_justify(Justification::Left); // Workaround to get the labels to be left justified. let lbox = Box::new(Orientation::Horizontal, 0); lbox.pack_start(&amp;label, false, false, 0); lbox.pack_start(&amp;Layout::new(None, None), true, true, 0); // Store the label within the list box row. let container = ListBoxRow::new(); container.add(&amp;lbox); FontRow { container, category, family, }
If you're okay with making a safe use of unsafe and want to avoid superfluous moving-around-of-objects, you can do [this](https://play.rust-lang.org/?gist=c5a7e40095264e48e133e2a68218f59b&amp;version=stable). It'd be nice to condense the 3 calls of mem::replace down to one call to mem::swap, but for some reason the borrow-checker doesn't let you have simultaneous mut borrows into HashMaps, even when the die within an unsafe block.
[removed]
Wow thanks for the information. I'll have a look at Scheme too. I didn't know it could be that fast. :-) 
Yup, it's possible and its primary use case. You can find a pretty concrete example here: https://github.com/Verideth/dll_hook-rs
Ahhhhhhh so that's what Alex was making wasm-gc for! Nice! Can't wait for this to get better! Still my only hindrance with web assembly now is that the DOM can only be manipulated through JS. :/ Not much the Rust team can do about that unfortunately.
You can use a [range](https://doc.rust-lang.org/std/ops/struct.Range.html) to represent a range; -&gt; `&amp;self.range.contains(hue)`
Well it would require the user to install node. At this point, I could use Rust crates as plugins with a custom build.rs file to automagically link them to the main executable. And I don't need the networking capabilities of the node runtime.
I've only looked at `OwnedSlice`. Since you're using a tuple struct, the reference inside will be public, and anyone can replace it with another reference. This can lead to memory corruption in something like: let mut y = /* some CircularBuffer with elements */ let mut a = [/* ... */]; let mut x = y.pop_slice().unwrap(); mem::replace(x.0, &amp;a[..]); // Elements popped from y will be leaked. // Elements of a will be dropped twice. I think it would be better to: pub struct OwnedSlice&lt;'a, T: 'a&gt; { inner: &amp;'a mut [T], }
[removed]
You can still call into that JS though. It's not the fastest thing, but I don't actually think it matters that much; there's tons of stuff you can do without needing to worry about the DOM.
Did a post ever materialize?
That is simply not true. You can't access the private fields of a tuple struct. mod foo { #[derive(Eq, PartialEq)] pub struct Foo&lt;'a, T: 'a&gt;(&amp;'a mut [T]); impl&lt;'a, T: 'a&gt; Foo&lt;'a, T&gt; { pub fn new(inner: &amp;'a mut [T]) -&gt; Self { Foo(inner) } } } fn main() { use foo::Foo; let slice = [5, 4, 3, 2, 1]; let bar = Foo::new(&amp;mut [1, 2, 3, 4, 5]); bar.0 = &amp;mut slice; } This throws the following error: error[E0611]: field `0` of tuple-struct `foo::Foo` is private --&gt; src/main.rs:17:5 | 17 | bar.0 = &amp;mut slice; | ^^^^^ 
Members of tuple structs are not automatically `pub`. You're probably confusing this with enum variants.
is there a way to make that work with SDL2 yet ?
I'm not totally sure about this target, the emscripten one would have support though https://kripken.github.io/emscripten-site/docs/porting/multimedia_and_graphics/OpenGL-support.html
Yeah totally! I just want to do it all in Rust because I think that would be more fun. Especially having a pure Rust stack.
Is there any reason to use mpsc if crossbeam-channel is superior in pretty much every department?
Rust becomes way cooler when you realize this. Languages like ML and Haskell control the "mutability" part, Rust controls the "shared" part.
I'm sorry, but I fail to see the connection. For me, and as far as the quote mentions, lints are static analyses, whereas I was talking here about *code instrumentation* which is the emission of runtime code in the produced binary.
&gt; Wait, does that mean that one can't build with all of those enabled simultaneously? Unfortunately, no. Also, the cumulative slow-down would probably be worse than using `valgrind`.
Is there a source I can look at for calling into the DOM from WASM?
There are also a lot of DOM manipulation that doesn't have to be super fast. Just fast enough to not be noticable slow. I have done some experimenting and the perceived performance of adding, changing and removing a few nodes after a button press is good enough for a basic UI. At least in my example.
I couldn't find a way to expand the pane. I shall try harder. Thanks for the other fix! Neat software.
Or even better, CIECAM02 :3 The main issue with these color spaces is that near the boundaries you'll get weirdly shaped regions that are difficult to sample uniformly. 
There are several particular cases where `mpsc` might still be a better choice than `crossbeam-channel`. For example, if you're using an unbounded channel with a single sender and a single receiver (SPSC mode), then `mpsc` will have better performance. Likewise, if you want to send just a few messages through the channel, `mpsc` will be again a bit faster (and allocate less memory). Although, since you're sending so few messages, the difference in performance will probably be totally irrelevant. But other than that, `crossbeam-channel` is generally superior. I'd say it should be the first choice if you just need a channel in Rust.
This is highly exciting. I'm hoping WASM can help reduce the horrible battery usage of a lot of websites... Of course, it's likely enough that devs will just use it as an excuse to deliver even more crapware over a document delivery protocol.
* `RandomColor::hue` and `RandomColor::luminosity` are stringly typed. An [`enum` parameter would be preferred](https://rust-lang-nursery.github.io/api-guidelines/type-safety.html#arguments-convey-meaning-through-types-not-bool-or-option-c-custom-type) for type safety and predictability. * The `get_` prefixes from the methods of `ColorDictionary` are a [non-standard convention](https://rust-lang-nursery.github.io/api-guidelines/naming.html#getter-names-follow-rust-convention-c-getter). * The crate lacks doc comments throughout.
Reading your post, I just had a horrifying thought that might become possible someday: electron (or rather something akin to it) running on wasm. It's a solution to all browser incompatibility problems, but at what cost?
I wish SBE had featured in your benchmark. On regular computers it is definitely my protocol format of choice in terms of efficiency: - it lends itself to streaming encoding, obviating the need for memory allocation beyond a single (stack) buffer, - its structure makes it possible to compute the size of a message *before* encoding with a handful of additions/multiplications, - it is cast-friendly (aka zero-overhead decoding). I really wish I could have seen how it featured compared to the alternatives here. --- On a side note: #[repr(C)] pub struct LiDARPointsMsg { pub msg_info: MsgInfo, pub points: Vec&lt;LiDARPoint&gt;, } You should not use `Vec` in conjunction with `repr(C)`, a `Vec` layout is unspecified and therefore it cannot be exported to C. Also... hopefully none of the above benchmarks had to allocate memory to fill that `Vec`?
I'm posting this Eric Raymond article because it's the place I see the most definite dismissal of Rust. Not just by the author, but by so many commenters. Not sure how significant that is, but it makes me curious if they're just dismissing it out of bias or if they have some Good Reasons.
They've mentioned turning Mir into a Wayland compositor.
I published a little crate called [by_address](https://docs.rs/by_address) that makes it easy to create a HashMap or HashSet of trait objects, where instead of using the value as the key, it only uses the object's address in memory. (Note: This means it's not suitable if you have separate objects in memory that should be treated as equal.) Using it looks like this: extern crate by_address; use by_address::ByAddress; use std::collections::HashSet; trait Foo {} fn main() { let v: Vec&lt;Box&lt;Foo&gt;&gt; = Vec::new(); let s: HashSet&lt;ByAddress&lt;Box&lt;Foo&gt;&gt;&gt; = v.into_iter().map(ByAddress).collect(); } 
&gt; Selection interface is brittle - there are several rules that must be upheld by the user of the API. Go's `select` is much more robust in this regard, but that is because it has first-class support in the language. Not only it is brittle, but I must admit that even after reading the description of the mechanism several times, I am not quite clear on exactly how it works. More on brittleness, it seems, for example, that the following is a really bad idea: let mut selector = /**/; selector.recv(&amp;rx0); loop { if let Ok(_) = selector.recv(&amp;rx1) { break; } } As it would stick the `selector` in a perpetual "waiting" mode. It may be useful to provide some debugging machinery (detecting the duplicate attempt on `rx1`). At the same time though... this seems hard. --- Maybe it would be worth considering specialized operations? For example, it seems to me that the difficulty in designing a proper API is mostly due to mixing receiving and sending. For example, the receiving case could be lowered to a `match` on tuples pretty easily: let output = match selector.receive_any((&amp;rx0, &amp;rx1, &amp;rx2)) { (Some(n0), _, _) =&gt; n0, (_, Some(n1), _) =&gt; n1 * 2, (_, _, Some(n2)) =&gt; n2.parse(), _ =&gt; panic!("Timeout!!!"), }; which would hide the machinery in a fool-proof method (to be implemented for each tuple arity...). *The case of uniform receivers in a list is even easier: `let (index, output) = selector.receive_any(&amp;vec_of_rxs).expect("Not a timeout");`.* Of course, the `ReceiveAny` trait can be implemented on top of the low-level interface provided (as long as `Select` is a concrete type); still it seems it could be quite helpful in achieving a simpler API.
Can you give us a link to a place with more information on the blockers? The tracking issue for const generics at https://github.com/rust-lang/rust/issues/44580 contains links to lots of tasks, but few updates since the beginning of the impl period.
The last time an ESR article was posted here was [this time.](https://www.reddit.com/r/rust/comments/5nu1w7/rust_and_the_limits_of_swarm_design/) You might find some of that discussion useful. But, I really do think it is heavily influenced by bias. The majority of what ESR said in his blog post about [trying out Rust](http://esr.ibiblio.org/?p=7294) was a combination of bias, ignorance of Rust, and an unwillingness to learn, from my point of view. He expected Rust to be just like every other language he's ever used, something with such minor differences that he could just pick it up over a weekend, but it wasn't, and that *greatly* upset him.
&gt; Not only it is brittle, but I must admit that even after reading the description of the mechanism several times, I am not quite clear on exactly how it works. I intentionally didn't go into too much detail on the selection mechanism, but simply explained the high-level idea. Otherwise, the text would probably be twice as long. Let me know which parts you find confusing the most and I'll try to elaborate. &gt; More on brittleness, it seems, for example, that the following is a really bad idea: True. Unfortunately, I don't know of a better way to do selection. :) Also, I'm not too worried about that particular example, since it's very obviously doing something wrong. But I'll think about how to detect common errors so that we get panics instead of deadlocks and infinite loops. &gt; For example, it seems to me that the difficulty in designing a proper API is mostly due to mixing receiving and sending. Oh, absolutely. For a long time, I even believed that mixing receiving and sending would be practically impossible to design and implement. &gt; For example, the receiving case could be lowered to a match on tuples pretty easily: I don't know - this makes things brittle in a new way: you must be careful and make sure that the order of receivers in the tuple matches the order of results you're pattern-matching on.
The only major blocker I see to using Rust for large scale production projects today is there aren't enough crates available to use it in some contexts. So essentially we just need more Rust to be written.
&gt; it doesn't handle reflowing of comments well, or at all This has just landed, but is off by default and will probably remain so until after 1.0 &gt; it doesn't handle long URLs in comments well By default it doesn't touch comments (including URLs). There is no good way to split a URL and we won't format comments by default until we leave them alone. &gt; it is not shipped with rustup There's a PR in the queue to fix this &gt; it cannot reformat while you are editing code the code only needs to parse, not compile, we can probably do better with error recovery in the future &gt; it cannot reformat incrementally There is work in this direction. You can use git-fmt which formats only modules touched in the last commit (or commits). We're working on only formatting a selection from an editor and from a git diff. &gt; and in general it still has lots of open bugs There are currently 153 open issues, of which 19 are bugs (with default options), and a further 16 are formatting-only bugs (again, with default options). So not perfect, but not bad for a moderately-sized project.
This is not quite correct, it isn't a compiler plugin, it just uses one of the compiler's libraries. Rustfmt doesn't need to operate on a whole program, just a whole AST node. That could be a single statement or function. That is not user-facing yet, but we're working on it (currently the finest-grained scope is a module).
I don't think you can do away with the allocation at iterator generation without using smart pointers or unsafe, but don't quote me on that. The code looks mostly good, but I noticed two minor things: Instead of writing `nodes: nodes`, you can just write `nodes` on line 26. This is syntactic sugar you can use whenever a field and a local variable have the same name. You can do away with the `reverse`, and instead store an index which you increment on each call to `next`. If the index is greater than the length of your vector you return `None`, otherwise the element at that index. This is considerably more verbose, and I don't know if it's actually faster, but I thought it was worth mentioning.
You're doing preorder depth first traversal, and doing it with external iteration does require some amount of data storage, but you don't need to pre-traverse all nodes ever. Instead you can do the following: - Only keep the parent nodes left to visit in the tree. - So at initialization, you just put the root in there. - Then, each time `next` is called you: - Pop the last value in the vector (that's your return value). Return `None` if the array is empty. - Push the left child into the vector if it exists. - Push the right child into the vector if it exists. This has 2 advantages over your current approach: - The amount of work is always `O(1)`, and creating the iterator is very cheap. - The total number of node pointers you'll store in the vector is `O(log n)`.
Note that there exists a tool called Clippy which is intended to automatically analyze your Rust code and attempt to detect potential mistakes, common antipatterns, and unidiomatic code: https://github.com/rust-lang-nursery/rust-clippy/ . Try it out and see if you like it. :)
It's basically the logo of the Galactic Empire in fact.
How small will a simple hello world program be with this branch?
Is the canvas supposed to move with the arrow keys?
Hello! I have a chained series of enums (is that the right way to say it?) that look like the below: enum A { B(C) } enum C { D(E) } enum E { X(String), Y(u32), Z(String) } Right now, I can retrieve the values out of the enum **E** by doing something like the below: // where arg could be &amp;A::B(C::D(E::X("String value"))) if let &amp;A::B(C::D(E::X(s))) = arg { // s = String value } else if let &amp;A::B(C::D(E::Y(s))) = arg { // s = String value } ... etc Is there a cleaner way to write this so that I can avoid a long chain of else if commands? Ideally I'd like to be able to match on the A::B::C::D portion then handle the conditions for E::X, E::Y, etc. For a real-world implementation of the problem: https://github.com/UnicornHeartClub/tabletop-macro-language/blob/f88862017343ffac369edac86803343d7f517df2/src/executor.rs#L35-L117 Thank you all in advanced! This is my first time writing Rust and I am sure there is a lot I can improve on. I appreciate any help. :)
This is *exactly* what I've been wanting for rust+wasm, so I'm very excited to see it materialize, even in an experimental form! Thank you!
Compile times are also a bit of a problem, though that's supposedly going to improve very soon. 
67kb: ~/P/_/rustfix î‚° ~/Projekte/ ~/Projekte î‚° cargo new --bin hello-wasm Created binary (application) `hello-wasm` project ~/Projekte î‚° cd hello-wasm/ ~/P/hello-wasm î‚° cat src/main.rs fn main() { println!("Hello, world!"); } ~/P/hello-wasm î‚° cargo +wasm32 build --target=wasm32-unknown-unknown --release Compiling hello-wasm v0.1.0 (file:///Users/pascal/Projekte/hello-wasm) Finished release [optimized] target(s) in 1.50 secs ~/P/hello-wasm î‚° l target/wasm32-unknown-unknown/release/hello-wasm.wasm .rw-r--r-- 67k pascal staff 10 Nov 22:04 target/wasm32-unknown-unknown/release/hello-wasm.wasm ~/P/hello-wasm î‚° or 27k, after gzip: ~/P/hello-wasm î‚° l target/wasm32-unknown-unknown/release/hello-wasm.* .rw-r--r-- 135 pascal staff 10 Nov 22:07 target/wasm32-unknown-unknown/release/hello-wasm.d .rw-r--r-- 67k pascal staff 10 Nov 22:07 target/wasm32-unknown-unknown/release/hello-wasm.wasm .rw-r--r-- 27k pascal staff 10 Nov 22:04 target/wasm32-unknown-unknown/release/hello-wasm.wasm.gz 
&gt; wasm-gc Thanks! Could you also run wasm-gc (does it change anything in this case)?
Sure! Shaves off 5k on the gz'd version: .rw-r--r-- 54k pascal staff 10 Nov 22:13 target/wasm32-unknown-unknown/release/hello-wasm.gc.wasm .rw-r--r-- 22k pascal staff 10 Nov 22:13 target/wasm32-unknown-unknown/release/hello-wasm.gc.wasm.gz I have literally just built the branch from the PR, btw. I have no idea how to even run a wasm file!
&gt; Is there a source I can look at for calling into the DOM from WASM? My [stdweb](https://github.com/koute/stdweb) crate can call into the DOM and can be compiled for Rust's `wasm32-unknown-emscripten` target.
Just use [stdweb](https://github.com/koute/stdweb).
[removed]
The difficult learning curve of rust is, to my opinion, that it's really different from other programming languages. And that's difficult for an experienced developer as ESR (but that's true for a lot of others) to have a beginner level when trying rust. Think changing your keyboard to Dvorak, or giving a snowboard to a skilled skier. Now, I think that this wall is easier to cross for a non system developer that know learning a system language will be difficult. That's also easier for a skilled programmer that have played with several paradigm in a deep way (think of c++, prolog, Haskell for example) because he have learnt to think differently when changing to such different paradigm (which I think ESR is not as he's a pure imperative programmer).
Some very minor changes to show off `#![feature(match_default_bindings)]` and a slightly different usage of `split_at_mut`: https://play.rust-lang.org/?gist=787f8857243bdb373a38f7266c0a4b49&amp;version=nightly
IIRC clang-fmt straight up works on patches, would be neat if we could have that.
Did you consider doing match arg { &amp;A::B(C::D(E::X(s))) =&gt; ... &amp;A::B(C::D(E::Y(s))) =&gt; ... &amp;A::B(C::D(E::Z(s))) =&gt; ... } You could use two nested matches if you want the first one to strip off the outer layers too?
Was there some guidance from the libz blitz about the right way to expose `std`/`no_std` as a Cargo feature? Which one should be the default, etc.
Thatâ€™s a bit harsh. It is true that Rust requires developers to structure their code in unfamiliar ways, and some of ESRâ€™s issues seemed to arise from the fact that he thought of Rust as C with memory management when really itâ€™s an ML with C syntax, and he never really managed to adjust his thinking. However some of his other points were true 1. The standard library is light, and there are several crates for every possible use case, making it hard to pick the right one 2. Strings are harder in Rust than in any other language, and the compiler version available to him at the time gave extremely unhelpful hints when he tried to write a = b + c. There has been some progress on both of these, but the crate visibility issue is still an issue. You wouldnâ€™t immediately think to search for â€œparking lotâ€ if you were looking for concurrency primitives for instance. 
 This index: Indexer::new(vector), ^^^^^^ expected type parameter, found i32 = note: expected type `std::vec::Vec&lt;I&gt;` found type `std::vec::Vec&lt;i32&gt;` 