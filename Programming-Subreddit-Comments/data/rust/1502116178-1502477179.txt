It's not a rust specific thing but you are building the text representation of each disc from scratch with every call to render. You could build them once as part of program initialization and then store them in a vector or array to be referenced from the render method.
Indeed, it's not. The issue is considerably subtle, but there are at least two other main factors I'm aware of: * Whether everything you need is already in the file system cache. (In my own experience, this isn't terribly common when using `du`, but it can be if you're trying to drill down into a directory.) * I/O scheduling. If you make a bunch of simultaneous requests for I/O, it's possible for it to schedule access in a more efficient way. There's actually been some threads on that topic in this subreddit.
Is it possible to request the children of a directories and the size of files asynchronously?
when?
how did you measure that exactly?
Been trying to work on a Rust port of a decoder for [FLIF](http://flif.info/). Unfortunately, the specification isn't entirely done and the C++ code isn't well documented, so it's quite the challenge to understand it all, especially with my lack of experience in the area. I'm currently up to the point of reading transformations.
Iron not?
`wrk --latency -t2 -c100` and variations. My benchmarking wasn't especially rigorous, and my point wasn't that Rocket is slow or their benchmarks necessarily invalid. I just wanted to share that 1) my personal experience was in line with the benchmark you mentioned and 2) that it would be nice to see how the Rocket benchmarking was performed.
Have a look at the recent issues of &lt;https://this-week-in-rust.org&gt;, the have a Call for Participation section.
[I've uploaded it to a new public repository on GitHub :)](https://github.com/denis-golubev/camera_thread_gfx) I reused my old lock and toml files, so the library dependencies might be a bit out of date.
Dunno. Everything I've heard about asynchronous file I/O (on Linux at least) is that it's bad, but I don't actually understand the fundamental issues!
Have a look at &lt;https://github.com/panicbit/flif-rs&gt;. It's unfinished but maybe helpful as inspiration or something to contribute to.
Indeed. This allows things like `impl Foo for Vec&lt;String&gt;` to work as expected (this is an impl for a vector of strings). I like to read `impl&lt;T&gt; Foo for Bar&lt;T&gt;` as "for each type T, impl Foo for Bar parameterized by T". (DO NOT READ THIS IF YOU ARE STILL CONFUSED! Beware that this syntax can also actively shadow valid type names: `impl&lt;i32&gt; Foo for Vec&lt;i32&gt;` is _not_ talking about a vector of integers!)
This is a very nice talk.
&gt; What is _it_? The type parameter `T`, i.e. the placeholder that is used to say "some type name" in the definition of `Point&lt;T&gt;`. &gt; When would impl&lt;T&gt;'s T not be the same as the Point&lt;T&gt;'s T? In `impl&lt;T&gt; Foo for Point&lt;T&gt;`, the `T` is the resolved to the same type in both instances. When you write `impl&lt;T&gt;`, you are basically saying "lets use `T` as a placeholder for this one type I want to be generic over _in this whole `impl` block_". You can't omit it though, because, as discussed below, in `impl Foo for Point&lt;T&gt;` Rust sees `T` as a concrete type. This is like `impl Foo for Point&lt;i32&gt;`. `i32` should not be a placeholder here.
I don't think it's I/O bound. The information it needs is in the filesystem data structures (see `man 2 stat`). It's not actually reading in files to count bytes.
well, thanks for your reply. But IMO, your solution may generate a lot of boilerplate code. Now I am rewriting my blog with Rust, so there are some pages to show post,which logged in user is not needed. But for admin page, it needs a logged in user, and If I have a lof of functions in admin page, I would have a lot of boilerplate code: #[get("/admin/some_path")] fn foo(user: Option&lt;User&gt;) -&gt; Template { if let Some(user) = user { /* do something r */ } else { /* redirect to login page*/ } } So, I am just curious is there an elegent solution to do this. In spring, I could add some filter rules correspond to request url, so if a url is login-required, it will be filtered before it reaches controller.
At ironframework.io, it's expressly written, "Iron tracks rust-nightly".
deleted ^^^^^^^^^^^^^^^^0.6063 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/02631)
[hi there](https://user-images.githubusercontent.com/94035/28827091-1d753026-76d5-11e7-971f-b5d256566687.png) 
Hi, I'm attempting to build to android for rust using cargo, but I can't seem to do this correctly - it refuses to see the Gradle directory (currently E:\rustprojects\Gradle\bin). Whether its the one installed with Android Studio or the one I manually installed and mapped, cargo still can't see it. Need a little help to get this working. Output as follows to show cargo can't see gradle, but gradle can be manually called: E:\rustprojects\helloworld2&gt;cargo apk install error: Could not execute `gradle`. Did you install it? E:\rustprojects\helloworld2&gt;gradle Starting a Gradle Daemon (subsequent builds will be faster) 
deleted ^^^^^^^^^^^^^^^^0.8848 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/13824)
Magic ✨
Hmm, not that I know of. You could make an `AdminUser` object and implement the permission checking in it's `FromRequest` impl so that only users with admin privileges could access the route, but I don't know of a way to completely bypass the `FromRequest` step for a specific user-permission-level
I just converted a couple projects to it and it's nice, though I feel I'm losing some information since I essentially gave up my enum of error types (it's so easy to just `.chain_err(|| "...")` instead of coming up with a set of good error types that'll be ignored most of the time anyway. I know I can still do that, but laziness wins most of the time in a pre-1.0 thing.
You can easily create new types with the macro actually. It's not a well documented feature. Here's an [example](https://github.com/steveklabnik/rustdoc/blob/98a323b88573733b8796df804eb512d5d187f89a/src/error.rs) from some of the work on the new rustdoc. Now you don't need to use `chain_err` everywhere!
Looking at the repo behind it, I guess that is an outdated notice, so I create [a PR for it](https://github.com/iron/iron.github.io). If you are looking for a web framework to use on Rust stable now, I can recommend Iron. I still think there is a lot to come for web frameworks in Rust, but Iron works now, and is pretty unopinionated, so transitioning it to another framework in the future shouldn't be too hard.
`walkdir` is a standard recursive directory iterator. `ignore` is a crate designed to traverse a directory as quickly as possible while respecting various glob/gitignore/ignore rules. The APIs are quite different. For example, `walkdir` provides an iterator where as `ignore` does not. Parallelism and order are often at odds. So if you want to, say, traverse a directory tree in an order roughly consistent with what `fts.h` might do or what `find` does, then you probably want `walkdir`. See the docs for more info: https://docs.rs/ignore
Thanks. I'll start with Iron.
I didn't even realize "locking" file paths in Linux was a thing. I know there is advisory locking, but *everyone* needs to cooperate in that instance.
It definitely *can* be I/O bound, because the data in the `stat` data structures is ultimately stored on disk. This is primarily why running `find` on a large directory with a cold cache will be slower than with a hot cache.
Putting stanzas in the `errors` section gets rid of stringly typed errors, but you still need `chain_err` to construct the error, don't you? Or am I [doing it wrong](https://github.com/durka/blog/blob/master/_posts/du-evolution/code/du/src/bin/v1.rs#L45)?
Thanks! I just saw this, and already had it working with someone else's code I found. It's now running at a great speed. I used piston_window as you suggested, though. Link to the file: https://github.com/sebasgarcep/rust-neural-networks-and-deep-learning/blob/master/adaboost-stump/src/main.rs Thanks to everyone for their help! Really proud of the Rust community.
0_o
Working on an [incentivized mesh network](http://www.altheamesh.com) (routers paying each other to form a sort of decentralized last-mile network). We originally wanted to use Go because of its convenient concurrency and batteries-included approach, but found that the binaries are just too big for our use case. So we chose Rust instead, over Java, Lua, and C. It's been a steep learning curve for the team, but we're now starting on some actual code. We'd love to have anyone here to get in [our chat](https://riot.im/app/#/room/#althea:matrix.org) to give us tips and maybe code reviews etc. 
I admire your tenacity. You gave it way more of a shot than I. 
Yay! I actually knew about it, but in many cases, laziness wins out since much of the time I just print out the error message and move on. I currently don't have any crates published, but when I do, I'll probably do that. For now, laziness wins.
Once Diesel gets an async backend, we will look back to these easy to read, straightforward types.
Really hope we get `impl Trait` and `impl Trait` type aliases by that time
tll;dr async programming is hard, the futures crate needs wayyyy more help from the compiler, and tokio needs better documentation of its internals as well as its API design decisions. To the extent the author believes there's room for improvement, I'm definitely interested to see it. I don't think I share a ton of their concerns, but one place I'd like to see a better story is multicore event loops. I think right now the guidance is to bind one server per core, which can potentially run into problems with unbalanced work loads: if one core ends up with many long-lived clients, there's no way to load balance across the other cores.
The way i visualise this is to see the borrow contracting to fit as tightly round its use as possible. So, tight-fitting borrows? Snug borrows? Lycra borrows?
&gt; tll;dr async programming is hard, the futures crate needs wayyyy more help from the compiler, and tokio needs better documentation of its internals as well as its API design decisions. A very optimistic interpretation. &gt; there's no way to load balance across the other cores This is a very hard problem and solving it in any way has lots of associated costs with thread synchronization. 
I personally would use `struct Tower { discs: Vec&lt;u8&gt; }` to make it more readable inside `Tower`'s methods too, by writing `self.discs.push(slab);` instead of`self.0.push(slab);`.
If you plan to express them as a bunch of random raw pointers, it's bad. If you are going with saner approach, it will be very similiar in C++ and Rust. Having said that I'm looking forward to some graph-smart-pointers implementations like I saw in one of the talks from C++ conference.
Still learning Rust. And as I'm going have a lecture about the construction of parsers and compilers next semester I thought it would be a nice exercise to write a interpreter or compiler for the original old school BASIC. So currently writing the lexer and parser. 
Wow, so I just rewrote to use `ignore::WalkParallel` and it is way faster (40% faster than v3, 37% faster than `du -sb`). [The code](https://github.com/durka/blog/blob/master/_posts/du-evolution/code/du/src/bin/v5.rs#L17) is fairly ugly though, with atomics and mutexes strewn around, not quite fulfilling /u/0b_0101_001_1010's prophecy. Looks like a postscript is in order! BTW, it looks like [fixing this API issue](https://github.com/BurntSushi/ripgrep/issues/469) would make the code nicer and possibly even faster. Without a finalizer callback, I have to use atomic operations for every addition, which seems like it ought to slow things down.
I think you use the `chain_err` when you want to give a reason for stuff having gone wrong in a [whole chain](https://docs.rs/error-chain/0.11.0-rc.2/error_chain/trait.ChainedError.html#tymethod.chain_err). Good if you want to pass what failure caused the failure of other methods all the way up to the top.
I totally get that. Not as big a deal for side projects!
Thanks for the long explanation but I'm a little confused still about the first comment. All those examples seem reasonable to me so I'm not sure how the terminology is confusing. Edit: and yes, some of the const examples are swapped. In C read your type declarations right to left. So, const A* c, is a pointer to an A that is immutable.
Thanks for catching that - The option was a relic of the first implementation that only cached the first call using the cacher - I needed a way to represent no value if the function was not called yet. I think I attempted to use the entry api, but since I was trying to do it with an option it was getting ugly, I will try it again without option in the HashMap! 
Right, but I don't see how adding something under `errors { }` actually replaces a `.chain_err(|| "missing quux")`. Either you simply add the underlying error to `foreign_links { }` and forgo the message, or you still need `.chain_err(|| ErrorKind::QuuxMissing)`.
This week I will continue going through the rust book and probably revisit some chapters (Generics/lifetimes, ownership) just to make sure I am on top of them. Then I will dive into rust game development with Piston - get ready Pong, you are about to be remade again!
Keep in mind that every single path is sent on a queue internally, which itself is executed at least some number of atomic ops. A small number of atomic ops in addition to that---especially simple adds---should be fine. Working on a better API would be great. I don't think I'll be working on it any time soon though.
I'd be curious to hear the opinion of the author about [rotor](https://github.com/tailhook/rotor) which is not maintained anymore.
While I agree with the author that the current state of Futures and Tokio is not very usable, there is another side of async IO that the author hints at but doesn't fully go into - event loops. In my experience, writing event loops on top of mio and other polling libraries is actually a fairly pleasant experience. The main benefits are similar to what's described in the section of the "unrolled" future: * Enums make state easy to reason about * Compilation times and errors become sane again * Shared state becomes simple The latter point has been the most significant for me so far. Writing any sort of reasonably complicated async service is going to require some shared state, and as soon as that state needs to be shared in a more granular way, I can't really begin to imagine how to cleanly handle things in an efficient way with futures. In contrast just writing event loops (admittedly single threaded) this is trivial. Of course, I'm not saying that event loops are perfect. It's difficult for instance to nicely compose them compared to a Future type. It also requires writing a large amount of state machines which involves some boilerplate. However, the combination of algebraic enums and other general safeties provided by the compiler makes writing hand rolled event loops much more convenient than in a language like C. I hope more people look into alternatives like [mio] (https://github.com/carllerche/mio) and [amy] (https://github.com/andrewjstone/amy) rather than seeing the state of Tokio and assuming async IO in rust is still a no go.
I struggle to understand why the author hates Arc/Rc so much. The performance overhead of one Rc increment for each new connection would be trivial compared to the other overheads (syscalls, heap allocations, protocol overhead etc). It's the Rust equivalent of *variable assignment* in other languages with GC.
While we are on the topic, and since there is no real proper place to write this, I spent the last weekend on a thought experiment - I'm writing a Rocket based wep app for funsies, and am currently using inth-oauth and a bit of glue on top to support openid. I figured with the imminence of generators I'd see what it would be like to port inth to hyper 0.11. This is the rabbit hole that lead me to: First, just flip the hyper version to 0.11 and fix all the compiler errors. This means (generically) any function a sync api has now must now return futures for clients to run on their own event loops to eventually get their data back. The practicality of that is in question - thinking about it, I can't imagine anyone using a web framework and consuming an async api returning futures. It would involve getting futures, and then adding more and more and_then's to them to finish processing them when they are done. You know, like you wanted. Even with generators, you are just delegating this problem up the stack - eventually you have a main() that just has an async block and every function everywhere must be async to be able to await. Except you are using tokio, so its not threaded, so you then need to wrap your async blocks in num_cpus threads and *somehow* delegate that work. I haven't even fathomed trying to do that. [Just reading trying to mix cpupools in is painful.](https://tokio.rs/docs/going-deeper-futures/tasks/) Maybe you consider trying to make it sync, then you go try to grok at how reqwest does it, and realize you have been writing software for 10 years and know absolutely nothing about writing software. Like, I don't even know what kind of monk training you need to get your brain able to hold all that together. In simplest terms its just dumping the event loop in a separate thread and using channels to run it (thus allowing you to block the main thread while the event loop polls), but those simplest terms hide the arcane rituals, living sacrifices, and extraordinary genius needed to make it actually work. So here is a question - is there an idiomatic way to write an async api right now, that doesn't make the dev feel like they are condemning the user to torture and suffering for being given futures they have to somehow manage to run on their own? The only salvation is that perhaps the pain will be lessened if they can just await!() the data when generators arrive (because asking someone to consume foreign futures with and_then chains is probably illegal in some countries) but then the callers functions are all async in a non-threaded async world. Even then, you don't get a way to express the idea of "dump this operation on the event loop over there, and give me a thing to await on for its return type" since spawn and execute consume the futures. You are stuck in the callback soup no matter how you struggle, and you always have to push the burden of handling the async pain points off to the user because there is no global way to just grab the event loop, block it, and spare them. I can see where this will eventually be great - frameworks like Rocket can automagically hide all the bad guys from you, your route handlers are just always async, and you get to enjoy the fun of just await!()ing all your io while having dozens of threads worth of request handlers. I just worry for the sanity of whoever has to implement that magic.
You just summed up most of all I've complained about async in Rust. Well done!
I'm sure most of the requests are from an army of google bots that are analyzing how languages with generics evolve.
Having brought myself up to speed somewhat recently on Tokio ([and posted a question about its future](https://www.reddit.com/r/rust/comments/6rf37g/tokio_development_pace/)), I understand the author's frustration. But I also think there is solid bedrock here. What helped me was to evaluate these libraries as each building on each other, with the lower layers being the more stable Rust async I/O story: * Futures * Tokio Core * Tokio I/O * Tokio Proto * Tokio Service Through the Tokio I/O level, things are very good. But Proto and Service seem more raw (and more confusing), and I could definitely see them being reworked somehow.
Yeah now that you mention it, it only removes the need for it if you don't plan on chaining errors to one another. If you don't it just lets you use try!() or ? Without the extra function call.
If Tokio's error messages are any indication, then I'm afraid that the only answer they'll come up with is "slowly, laboriously, and by becoming *ever more generic*". :P
&gt; If you plan to express them as a bunch of random raw pointers, it's bad You're totally right. I avoid using raw pointers in the code I write. &gt; graph-smart-pointers implementations Conceptually, tree node will remain a recursive data structure even if smart pointer is used instead of raw pointer. BTW is this talk uploaded to YouTube?
I currently maintain a production system built on mio. I agree, it is a very strong library. But, where it started to get really complicated was with dealing with all the other things that go along with the handling of connections - connection timeouts, rate limiting, communicating with other asynchronous actions like loading a file from disk into memory. I think there's a lot of potential in the futures + tokio solution for helping with that. Right now though, I'm probably going to stick with only using futures, tokio-core, and tokio-io (and maybe pieces of tokio-proto). That gives me lots of benefits while letting the higher layers settle out a bit more.
Okay, good point - perhaps the actual impact isn't that bad. (With Arc, though, it might be worse - don't Arc's atomic operations use SeqCst ordering, which requires emitting memory fences? I'm probably wrong though, haven't read the code.) However, I'm a bit disappointed when the tokio guys claim "zero-cost abstractions" and then hand-wave over things like this. If they had said "yeah, clone your client, because *[reasons]*, and we know about perf, but it's alright, because *[more reasons]*" I might be inclined to agree with them, but just incorporating this random pothole for no reason tends to get me a bit riled up ;P
Can you explain "impl Trait" please? I couldn't find a useful source.
I am probably one of the data points here, since I happened to get back into writing Rust in late April after a year of inactivity. As for reasons, they are unknown even to myself. A lot of things have certainly improved since when I was last here: the error messages, the introduction of rustup, the second edition of the book, `?` syntax, etc. But I don't recall any of those being a particular hassle, so maybe it was the combination of these things that made me come back.
The state transitions in the enum example code go only in one direction. Having a separate poll function for each state would be more clear. The reduced number of options in the one-poll-per-state would increase performance.
&gt; is there an idiomatic way to write an async api right now, that doesn't make the dev feel like they are condemning the user to torture and suffering for being given futures they have to somehow manage to run on their own? I don't know, and honestly that was one of my main motivations for writing this: I recently made [glitch-in-the-matrix](https://github.com/eeeeeta/glitch-in-the-matrix) async using the latest version of `hyper`, and it seemed alright for me as a library author, but I found it quite annoying to deal with when I had to actually write a library usage example... I particularly don't like this "give your futures up to the gaping hole of the event loop" business (`spawn()` and friends). Especially when you want to write a future that borrows from `self`, the `'static` bound on event loop futures can be a real pain. You can, however, just `Core::run()`ning the futures, which essentially makes your async thing into a sync thing. ([[example]](https://github.com/eeeeeta/glitch-in-the-matrix/blob/master/examples/echo.rs#L27)) Not sure whether this solves the lifetime issue though.
Shame is that Iron seems pretty dead. No release in 8 months or so, very little activity on the repo, lots of the documentation is outdated.
It allows developers to vastly simplify certain return types. For example: fn return_futures() -&gt; FutureType&lt;FutureType&lt;FutureType&lt;FutureType&lt;.....&lt;usize&gt;....&gt;&gt;&gt;&gt; could become fn return_futures() -&gt; impl Future&lt;usize&gt; As long as what return_futures returns implements the Future trait, it'll work like magic. You can ready the RFC [here](https://github.com/rust-lang/rfcs/pull/1522)
Alternatively I made a crate for NaN-boxing https://crates.io/crates/nanbox. Haven't taken the time to integrate in my own interpreter yet however.
That's the power of Zero Cost Abstractions + Memory Safety
https://www.youtube.com/watch?v=JfmTagWcqoE&amp;feature=youtu.be&amp;t=59m29s
I remember not long ago we had just passed 10k subscribers. What happened? We have almost 27k now.
impl Trait means "This function returns a specific statically known type, but we won't tell you that type, and only tell you that it implements this traits." Where generics allow the caller to specify a type inside the function, impl trait allows the function to specify a type in the caller.
We passed 10k in May 2015, mere days before 1.0. It was a big milestone at the time. :) How time flies!
Good idea!
Holy cow, I must be confusing this sub with another one then. It looked like we surged to 27k.
No, not yet. I guess bascule took a look at it, but I am not sure if we can call it a "peer review". While I understand your point, AFAIK even ring was not properly audited (yes, I know that it's largely based on BoringSSL, but nevertheless) and Brian is interested in its formal verification, but nothing to show yet. From my side I did everything I could: fully tested all methods including fuzzing and in my ability checked generated assembly. So I guess my point is: if we have nothing to show there is nothing to audit and, well, nothing to use in the first place. But if you know someone who are ready to check someone else's crypto code I will be happy to contact them!
Cool! What language are you writing an interpreter for? Perhaps you and the creator of the tagged_ptr crate can join forces and make a single crate with cool stuff like this? :)
Matrix bindings in Rust are super cool. Matrix itself is awesome, and we just need good native implementations to make it speedy. Keep fighting the good fight!
I believe /u/mrmekon has done a fork of sysbar that adds in Windows-related functionality. See the discussion in [this Reddit thread](https://www.reddit.com/r/rust/comments/6qo5p4/hacker_news_feed_for_the_mac_touch_bar_in_rust/) for more details.
I'm looking into game development, at the stage of "what tools could I even use". I like Amethyst so far, but how do I GUI? Can it be combined with Conrod? Is it a good idea to do so?
You can get some ideas from the Rust parser: https://github.com/rust-lang/rust/blob/master/src/libsyntax/parse/parser.rs .
Great article!
Trying not to spam this sub with posts about [statrs](https://github.com/boxtown/statrs) anymore but just released v0.8.0 on Sunday (does that count as this week?)
Could not agree more! Mio is a great way to write event driven programs. Personally the domain I work in doesn't have chains of request response pairs, which seems to be the point of Tokio + futures. If you don't have that requirement, I think all the abstraction is much worse than writing out the state transitions you want (not to mention slower.) However, for web apps that are largely about executing long chains of request response that don't share state, I guess it's a convenient way to generate a bunch of boilerplate. 
Having had to deal with all of those problems you've described I agree that they can be painful. Every event loop I write more or less requires a timeout job, and handling things like rate limiting I've had to use things like Rc'd token buckets. Additionally, doing things like file reading/CPU intensive tasks requires channels and worker threads. However, doing this sort of thing with Futures requires a similar sort of approach either way(having to use a CPU Future to read a file for instance). What would actually be cool is a way to expose Futures such that they could be directly integrated into an existing event loop(via an eventfd notification perhaps). This way you could still use mio, but also get the benefits of hooking into the Futures ecosystem with ease. Would anyone else see this sort of library as potentially useful?
From a cursory glance: Interesting alternative to futures (although perhaps a bit complex); I especially like the Context parameter stuff that seems to help with state. I'll have a more in-depth look at this later!
Yeah, I think the `Future` trait itself is a nice, composable building block that's probably here to stay. However, everything above it... ;)
Your point about stateless Request/Response pairs really hits the nail on the head. As soon as you begin introducing complex events like global timers, and cross socket notifications, the entire model that Tokio is built on top of starts to break down; I encountered exactly this, which is why I dropped it in favor of a direct event loop.
Thats great. Gonna take a look at that. Thank you! 
This is cool. I just ran into a use case for it yesterday: I ended up calling `take` on an option but this is much more elegant!
I check in on this every day, I am super ready. Incidentally, do you have a recommendation for a MPSC? Just std?
Very much this. Luckily , my path to becoming familiar with tokio was by first becoming familiar with mio , then futures , then tokio core/io. And it was pretty tough. I believe they are solid abstractions that i see myself using for quite a while, but i would love to see a competitor get at least a little traction . What i do want to say is that i have come to despiseTokio Service. Because it lures you into a false sense of security where you think it might solve your problem. It won't. ( In my case ). 
https://github.com/gluon-lang/gluon :). Perhaps, the concepts are related enough that I think they could both be implemented with just a trait and two marker types which implement it (`trait Packed` + `impl Packed for NanBox` + `impl Packed for TaggedPtr`. I need to make some time to encapsulate the value handling in the vm first though, to pave the way for trying to actually integrating it.
I think this article has a point about tokio being confusing. But I want to address the part about copying. Counterintuitively, creating a "new" service every time is usually the right thing to do. That's because: 1. If we reused the same one we'd have to synchronize among multiple threads using it. 2. Stateless services aren't copied at all, because they're ZST. This means loads/stores/copies are eliminated by the compiler. 3. If you *do* need a stateful service, you have to synchronize it yourself, which is what should be required. (Otherwise hyper would have to make synchronization choices for you, which could lead to inefficiencies.) 
Having each future manage its own state is essential to make combinators such as map()/and_then() etc work, and is also essential for the new async/await stuff. So i wouldn't call that "random pothole for no reason", especially without a benchmark showing that it actually has any observable impact on performance whatsoever.
&gt; compile speed and lack of resources have made it a little bit less productive This is especially for me coming from Go. However, I find that I spend a bit less time debugging (e.g. nil pointer deference), so it's mostly a wash, especially when I use `cargo check`.
I had to use the systray on linux recently, and using the binding for libappindicator and gtk (kindly provided by the http://gtk-rs.org/ team), it was not too bad or difficult. Note that there doesn't seem to be a cross-desktop way of displaying a label next to the icon, so in Linux (and probably in Windows too) you'll have to make do with just the icon. A friend of mine did a similar app using electron and react native, and it had the same problem on LInux.
It is "random pothole for no reason" if the reasons aren't documented anywhere. Which seems to be a recurring theme with tokio : it's complicated, underdocumented, and the impl is hard to understand. I understand that tokio isn't 1.0 yet, but it's still a bit frustrating
For me, I feel like my code is more likely to be correct when it compiles with Rust than other languages because the compiler catches entire classes of errors, such as null pointer deference and unexpected exceptions. However, it *does* take longer to get it to compile. Obviously the compiler can't help you with logic errors, but it's nice to know that entire classes of bugs are impossible.
Yes, something similar in https://github.com/mrmekon/connectr But the world is more complicated than that :) sysbar is based on barfly... I reimplemented my own equivalent of barfly (thinking I could do it cleaner, but it ended up being almost exactly the same) and forked systray-rs to make its API match. I never split mine out into a library and it's really dirty, since it was literally the first thing I wrote in Rust. It is, however, quite stable and does all of the things I need. Now I'm not sure if I even should split it out. Do we need a bunch of competing partially-completed systray crates? systray-rs is windows+linux (but which "linux"?), barfly/sysbar is macOS, connectr is macOS+windows. *sigh* 
&gt; You could store the absolute path to the directory, and write the files one-by-one, but if the user now renames/switches/... the directory, anything might happen. You can use [`openat`](https://linux.die.net/man/2/openat) to open files using a directory file descriptor.
Just use the sane dbus way qt uses and boom, it works on gnome and plasma. Why imitate the gnome way that only works in gnome when you can imitate the qt way that works in both environments?
&gt; &gt; However, for web apps that are largely about executing long chains of request response that don't share state, I guess it's a convenient way to generate a bunch of boilerplate. I dunno, I recently wrote two dinky apps using async Hyper, and wanted to put some state in the server: structs holding routing logic for incoming requests, and a few other config-type things, etc. The server struct seemed like a pretty natural place for it—but it struck me as incredibly stupid that I had to clone them *on each request*. Maybe there's no way around that; I wouldn't know—but it was definitely a puzzling thing, and I can easily see how in a real app, with more complicated state, it could get out of hand.
When using serde to deserialize a struct, is there no way to default a simple field (say an int) to a specific value? This won't work (see docs https://serde.rs/field-attrs.html), it complains that defaults must be inside double quotes: #[serde(default = 10)] num_mru_items: u32 Putting the 10 in double quotes makes it look for a function called "10", which is not what I intended at all, obviously. 
Well, you could have a function that returns 10? like fn get_num_mru_items() -&gt; u32 { 10 } not very pretty though
There is [default value support](https://serde.rs/attr-default.html). You have to write and name a function to do it. #[serde(default = "default_mru_items")] num_mru_items: u32 // elsewhere fn default_mru_items() -&gt; u32 { 10 }
Thanks for writing this article. This kind of feedback can be hard to hear, but it's invaluable. I think there are a lot of fair points here, though the point about `NewService` is just that you often want some connection-specific state. A `Service` in Tokio is ultimately something that's hooked up to a *single* client. So I think the issue here probably boils down to the names having misleading connotations. As to the wider issues: as a member of the Tokio team, I'm very concerned about how impenetrable people are finding this space, and have been working with others to improve things. Alex Crichton has done a ton of important work laying the foundation for `async`/`await` (https://github.com/rust-lang/rfcs/pull/2033), which will help significantly. As to Tokio specifically, one of the things we hope to do this year is greatly de-emphasize tokio-proto, revamp the docs on that basis, and provide simpler entry points for writing servers. My hope is that by 2018, very little of the concerns of this blog post will remain. We'll be talking more about our plans as they become more concrete (heading into the impl period, https://internals.rust-lang.org/t/announcing-the-impl-period-sep-18-dec-17/5676).
Yes, I understand that. Maybe I was not clear enough - that is IMHO far too much boilerplate just to specify a default for a piece of plain old data.
&gt; systray-rs is windows+linux (but which "linux"?) &gt; connectr is macOS+windows oh wow, didn't know these crates existed, though doesn't look like systray-rs is published on crates.io. in any case, i'm willing to merge efforts somehow.
When I tried do put data in my Hyper server, it wasn't an `Rc`, it was an `Arc`, and it wasn't an `Arc`, it was an `Arc&lt;Mutex&lt;…&gt;&gt;`, meaning that access required locking, even though it was only ever read-only, which, per my understanding, is not great for concurrency. Perhaps there was a better way, but it wasn't even *touched* on in the Hyper docs as something you might encounter and deal with in such-and-such a way.
Hey everyone, I worked on a crate, Matrixnum, which is basically a part of Juggernaut (www.juggernaut.rs). Now, it's a separate crate: https://github.com/afshinm/matrixnum Matrixnum makes it easier to work with matrices in Rust. So, operations like transpose or multiplication are just one call: `matrix.transpose()` or `BasicMatrix::generate(2, 2, &amp;|m,n| 0f64)`. I couldn't work much on Juggernaut last week because I was basically busy with planning for the demo page and further versions. I will spend most of my time working on Juggernaut this week.
What I want to do is generating a dependencies hierarchy of a project. So, if I have: *main.rs* use boo::test; // fn main() ... *boo.rs* use serde::boo::foo; // ... the output should be something like: - `main.rs` -&gt; `boo::test` - `boo.rs` -&gt; `serde::boo::foo` Format of output is not important, what I want do to is generating the hierarchy. Is there any tools to generate this structure?
Can't you just do let cmd = self.requests.lock().unwrap().pop_front(); if let Some(cmd) = cmd { self.handle_cmd(cmd); } I can't test it right now against the borrow checker but I would think that would work. This also should be something that will be fixed by non-lexical lifetimes I think.
Will be ready soon, I promise. \^\^ &gt; Incidentally, do you have a recommendation for a MPSC? Just std? I think `std::sync::mpsc` will be your best for the moment. There's also [magnetic](https://docs.rs/magnetic/2.0.0/magnetic/index.html) - I haven't tried it, but looks promising.
Making a gameboy emulator in rust. Though so far, mostly just setting up my dev environment since I just switched to vs code.
Awesome, yeah I've seen you committing every day just about :P I'm hyped. I'll check magnetic out too, thanks.
Regarding the Photon-- it's based on a WiFi+MCU module from Cypress, which Cypress acquired from Broadcom. Broadcom was trying to make a play in the IoT market, and they created a platform called "WICED" based on their WiFi and BT radio chips and some ARM Cortex M MCUs. I did some work on the same WICED platform radio+MCU that the Photon is based on, so I spent a bit of time digging into how the software bit of the platform works. The upshot for someone wanting to use Rust on it is that although Particle has developed an extensive software framework, they rely on the much smaller base WICED platform library for WiFi support. And the base WICED platform library is designed to be OS-agnostic (it supports several free and commercial RTOS varieties as well as a bare-metal mode) and is entirely written in C. I have not looked at it in depth yet, but I'd bet with a bit of work you could extract the code to interact with the wireless chip and either port it to Rust or make it friendly to having Rust bindings that could work with rtfm. If you download the WICED SDK from Cypress, you'll get all the C source for the MCU code, and if you search for files with "wwd" in the name you'll find the stuff relevant to communicating with the WiFi radio's processor.
Ugghhh why does rust do this to meeee? &amp;nbsp; ^(jk i love rust im just dumb)
Nah, it's not you, it's the borrow checker.
I wouldn't worry so much about c++, just focus on Rust. Some things to avoid early on so you can a working app out quickly: 1. Don't build OO abstractions, just use structs as data and operate on it with free functions. 2. Don't be afraid of long argument lists with lots of references, where the last one is possibly mutable, C-style 3. If something needs e.g. 2 different structs as inputs and mutates a third one, make it a free function, don't impl it on any of the structs. 4. Don't overdo it trying to use the functional idioms for options and results like and_then or_else etc. Just use match and eventually it will be obvious where those fit. 5. Don't worry too much about error handling, just use expect and explicit panics 6. Don't implement your own data structures, compose the std lib ones 7. Get good at using match and enums to represent state and transitions Once you've got some more experience and you want to try to write more elegant code, you will run into ownership issues. 1. Use guard types. Basically a struct that owns a pointer into some larger data. Write a lot of these with useful utilities for manipulating that data 2. Use guard types for mutating data as well. I tend to have a type which is a big bag of data (often carefully laid out in memory for performance), and then separate types whose only purpose is to contain references to e.g. 2 or 3 different pieces of data that need to be simultaneously used. That type allows you to do whatever that operation is. This saves a lot of borrow checker fighting. 3. Think in a data centric way. What data do you need? What operations need to be performed? Then design your ownership hierarchy such that that can happen. Finally you will run into frustration structuring large projects. 1. Use cargo workspaces. Isolate self contained chunks of functionality into crates. 2. Implement stdlib traits like Iterator, From, Into 3. You can use associated types to do statically checked dependency injection. In combination with default trait implementations it's a decent way. 4. Use free functions liberally inside modules, but export mostly traits, data structs, and operation structs. 5. Use rustdoc comments in your code and refer to them. A lot of the above is opinion and might not work for everyone. I submit that it's "a path" of many for getting productive quickly and then scaling up to writing larger systems.
The problem is that anything other than generics exist, really. 
Most likely there is buffering in your capture hardware - if its transport is USB, network or uses any kind of mpeg/H26x compression it's almost guaranteed that there will be a big buffer in the driver to prevent stuttering or allow the encoding to do its job. The V4l stack above the driver is pretty low-latency - I have twin PCI PAL video capture cards that can spit out frames over V4L a millisecond or two after the hardware capture and transfer over the PCI bus. So if you can, fool about with video formats being sent from the camera - there might be one that buffers less.
Wouldn't `Arc&lt;RwLock&lt;...&gt;&gt;` work better for read-only? `RwLock` assumes its contents are safe for concurrent access, whereas `Mutex` must make them so, which I assume adds some kind of overhead.
"Honey, it's not you, it's &amp;mut me." 
No problem, have fun C:
Yeah … I can't remember if I tried that and some kind of constraint failed, or if it just didn't occur to me (I'm far from a Rust expert, here).
also https://crates.io/crates/hyper-native-tls if you want to use the platform default TLS impl. (rustls will generally be a great option though!)
RwLock doesn't assume the contents are safe for concurrent access - that would be unsafe. It's just a Mutex optimized on some operating systems for read-heavy workloads, as far as I know. Someone else should confirm.
Well, there is no lower cost abstraction to share the data across threads safely - except perhaps something similar to scoped threads. What would you propose as an alternative for sharing data across threads?
I can't deny the Rust itch any longer. I'm thinking of hacking around with a *nix TTY interface, maybe writing a roguelike. Circumstances say I need to keep using Windows as my host OS and virtualize. I don't have a ton of disk space either (old SSDs, grr Windows) so could someone recommend a BSD or GNU/Linux distro that can fit into a GB or two and where Rust just works? Maybe Arch? 
Concurrent Reads can all hold a lock simultaneously without blocking each other. Write locks will block all other accesses until released. The docs specify that the priority order of Reads vs. Writes differs by OS. meaning new reads or new writes may win... in heavily loaded read environments that means that write locks could be starved.
The nonlexical scoping changes that just got RFC'd will allow the original code, right? (Edit: /u/arielby points out that it won't, because a MutexGuard destructor is involved, if I understand correctly.)
Serde offers the most flexible option that was simple to implement given the current state of compiler-plugins/macros. What you're suggesting would be trivial in an interpreted, duck typed language.
What do you mean by, de-emphasize tokio-proto? I'm curious, because I wrote much of my tokio implementations directly over tokio-core, which I like. I've considered moving to tokio-proto, but haven't had a need to do so... It would require a decent reworking of some other code, and nobody has yet asked for it. Also, it's not clear that it would offer much in terms of compatibility with other libraries. I'm super excited for the future of Tokio! You guys are heroes for trying to make this complex subject simpler to utilize in code!
tokio-proto was only intended to be a utility to implement `Service`. There isn't anything special about it.
I think so.
You probably know better than I. I've only spent several minutes trying to figure out what benefits RwLock provides, and didn't get very far, to be honest. So I'm operating only on plausible assumptions.
I haven't been following along all that closely, but I feel like I've heard people saying that for a long time now. When is `impl Trait` likely to land? Or is it more a question of "if" than "when"?
Yes, I tried to use tokio recently and gave up and used mio instead. Maybe it was just the lack of good documentation, but I found tokio very hard to understand.
Read-write lock perform better under read-only workloads but they can cause starvation during some mixed workloads. Additionally Rust's `RwLock` makes no guarantee of the priority (i.e. if you risk writer starvation, reader starvation, or if it tries to do something clever which probably is expensive) and leaves that to the OS. Personally I think that makes `RwLock` rather useless in cross platform code.
That seems like it would reduce memory usage, but does it have any other advantages over a simple enum?
"You can borrow me, and you can change me, but you can't own me."
You may be looking for /r/playrust 
You should post in the correct subreddit for starters :)
it's just a generic with trait bound for return types?
I was curious so I looked: https://doc.rust-lang.org/src/alloc/arc.rs.html Arc only uses SeqCst ordering for strong_count() and weak_count(). Some operations use Acquire/Release, and the rest use Relaxed.
It took me a few times reading that second paragraph, but I think I understand. In that case, using `impl Vec&lt;T&gt;` without a concrete type T wouldn't compile, right?
MSYS2 or the Windows Subsystem for Linux might work for your usecase. Otherwise, I'd probably just use Ubuntu server. It's the default option nowadays so e.g. READMEs for packages with C-dependencies will usually have apt instructions. Rust should Just Work^TM with any linux distro, though. The only distros I see showing up on the Rust issue tracker often are musl-based ones like Alpine Linux. There is a PR in the works which should help with the musl issues though.
My army of Rust bots are having an effect!
The tokio-proto library was an early attempt to abstract out common behaviors for servers over a wide range of protocols. But I think that in practice, most people are either doing HTTP and should use something like Hyper (or a framework above it), or else are probably better off using tokio-core directly. In any case, the current documentation starts off directly with tokio-proto, and I think that's serving the narrowest audience. Part of what we're hoping to do is revamp the docs to focus more on the tokio-core level of abstraction, and give tons more examples at that level. It's an open question what the story will be with tokio-proto in the long run. The Tokio and Hyper teams are hoping to meet up around RustConf and hash out at least some of the roadmap, and I hope I'll be able to write more about that soon.
I think this post accurately conveys a lot of the problems I had trying to learn Tokio; though I didn't get as far as the author. Individually, the types/traits largely make sense, but then I try to get them to work together and that understanding completely vanishes. Not to mention chasing types seems to be an exercise in futility for me. On that note, I see several people are hoping that `impl trait` will less the type-soup we see with Futures, but do we have some idea when we might see it land in stable?
I thought I'd give my opinion, having written a small service with tokio that we run in production. There definitely is a learning curve to it. While there is room for improvement in the documentation, I think there is an incompressible difficulty to 0-cost futures - the thing with Service and NewService is typically that: you have to manage synchronization of your shared state yourself, and this is completely in line with Rust's principles. I personally really like the functional combinators on futures and streams, and I think futures and tokio (core and io at least) are the right abstractions. I also think the situation is going to get much better in the coming months: - impl trait is the biggest thing imo, especially with the new RFC and impl trait in type aliases, so we can write `type HttpService = impl Service&lt;...&gt;` and remove a lot of boilerplate. - even though I like the current combinators, async/await in combination with `?` for error handling is going to be nice - finer grained lifetimes management with ATCs (hopefully) - the ecosystem is going to stabilize around async abstractions - there is no async multipart library at the moment for example As a final remark, not everything has to be on an event loop, threads *are* often a very reasonable and fast enough solution, and you can combine both. I think the futures and tokio team did a fantastic job already and with a bit more time and effort Rust will be great for writing async servers. The main question is going to be the ecosystem - mainly whether many libraries will start exposing sync and async interfaces.
I agree. One should think very hard if they are better off just using mio. You have the basic building block and full control in how you structure your code. Tokio complexity is very clearly not worth it atm.
It's for rust shit, just rust the programming language not rust the game.
An absolutely fantastic parser library, I've had a great time using it. Highly recommended and very approachable, keep up the great work!
Remember that the only reason we know you and me are different is the borrow checker.
&gt; first becoming familiar with mio , then futures , then tokio core/io I think this is the proper path to understanding Futures/Tokio, and you can honestly stop at that point and write useful things with that knowledge. I mean, you can write useful things with mio, but you're going to be juggling a lot more state yourself. For example, I wrote a [websocket server](https://gist.github.com/bschwind/05cc58d77af845c6529007bb826838be) which watches for file changes in a particular directory and broadcasts the changes to all connected clients. It could absolutely be more ergonomic but if you work at the level of sinks and streams over framed protocols, it's not too bad. But if you want to write a server that performs well and has easy-to-use concurrency, I would definitely reach for Go over Tokio.
[Here is a recipe to debug using Jetbrains Clion](https://github.com/intellij-rust/intellij-rust/issues/535#issuecomment-320866757) It does not work as today Aug 7th, 2017 with any other Jetbrains IDE. When it does, please report :)
Agree. Lot of things like this are scattered in libraries. Rust wanted to keep the std lib thin. But at the moment lot it is lacking a lot of basic support. The ecosystem is becoming like node's, not that it is too bad, but you never know about the 100 crates you are pulling
I've also been wondering about `impl trait`, since it has been 'next Rust stable' for a while ;) It's also _very_ useful for doing higher-order function stuff.
You could, but doing so would prevent changing the internal representation in the future. I'd keep it as a custom struct.
you came to the wrong neighborhood...
You should make commit and push it to github.
Ideally it reduces memory usage for a very common case, which would result in better cache usage, which in turn would speed up the interpreter. Of course there's a lot of assumptions there, so whether it will always have a great effect is hard to tell ahead of time. 
Exactly, you've got it!
yeah it would be nice to have a crate that provides a simple interface, with multiple implementations for the three main platforms.
Yes, I work with USB 3.0 camera, but I do not use any encoding and work with raw RGGB stream. I thought camera should work with USB in isochronous mode, so latency should not be that high.
Do you have any pointer on official docs or tutorial? I've been hunting for the correct dbus interface to use, but I confess I got a bit lost...
Was this written by a human?
I feel this way too. Every time async Rust is criticized we hear "yeah, but impl Trait will improve it," but it never actually arrives. That said, it is making very slow but sure progress. Here is the latest related RFC: https://github.com/rust-lang/rfcs/pull/2071
Datapoint here. Working a lot with Go (like) and Scala (like more) lately, and decided to check Rust, not sure 100% why. Now that I checked, looks like I may like it (a lot). Still trying to find time to play a bit with the language aside from a hello world and reading a bit of the documentation, though
No, it's a type hint inferred by intellij-rust
Something like https://github.com/jbcayrou/ethRE (disclaimer: never used it myself)
Not sure about module-level dependencies, but for crate deps there is https://github.com/kbknapp/cargo-graph
I'll be sure to check that out!
I never did something with it, but here's something anyway. I think it depends on if you want to link to dbus directly or use a library. [The freedesktop site](https://dbus.freedesktop.org/doc/api/html/index.html) says there's a C API for dbus, but that it's very low level. And then maybe look [here](https://techbase.kde.org/Development/Tutorials/D-Bus/Introduction).
I've heard that [clippy](https://github.com/rust-lang-nursery/rust-clippy/issues?q=is%3Aopen+is%3Aissue+label%3AE-easy) is a good first-contribution, and the only PR I've submitted to it was merged promptly. I would imagine [adding new commands to coreutils](https://github.com/uutils/coreutils/issues?utf8=%E2%9C%93&amp;q=is%3Aopen%20is%3Aissue%20label%3A%22I%20-%20New%20util%20claim%22%20) is a pretty good first contribution too, since the POSIX core utilities tend to be pretty small. It looks like `cp` hasn't been taken yet. You might end up checking a lot of old manuals to make sure you get bug-for-bug compatibility but it's the kind of project that doesn't require a huge amount of fighting with the borrow checker. Also yeah, [This week in Rust](https://this-week-in-rust.org/) always has a "Call for Participation" which has got even more suggestions.
It's largely a problem that most of us who are maintaining can't actually publish new releases. :(
Thanks for the kind words! :D
No, Rust generics are universally quantified, meaning that the function works with _every_ type satisfying the constraints. `impl Trait` is existentially quantified, meaning that the function works with _some_ type satisfying the constraints. 
This uses the unstable allocator API, and so only works with a very recent nightly compiler. Also, I'm not sure about the usage of tag bits but the alternative is doubling the space overhead (I can't do any packing since the metadata has to come before the data to allow shrinking allocation).
deleted ^^^^^^^^^^^^^^^^0.7518 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/08164)
Your comment "`Fn` so that we can't mutate or drop the owning reference by moving it into this function." is incorrect. You *can* move values in to `Fn` types, and you *can* consume them within the `Fn` (by moving a `Cell&lt;Option&lt;T&gt;&gt;` at construction, and then replacing it with `None` on the initial call). This allows you to obtain a reference to a moved value, which results in undefined behaviour, making the API as it stands unsafe. 
Nowhere near the quality of rustc, but maybe you can learn a thing or two from my toy compiler's [lexer](https://github.com/TheDan64/limonite/blob/master/src/lexical/lexer.rs) and [parser](https://github.com/TheDan64/limonite/blob/master/src/syntax/parser.rs).
This is exactly what I was looking for, thanks. If I'm already using a closure for reading I can do something like set a flag when I'm reading and panic if the owner is dereferenced while doing that. I could then use a `FnMut` instead of `Fn` (and if I add the same check in `drop` I can use a `FnOnce` like I wanted to originally).
TIL there's a programing language called rust. I'll have to look into that later.
Thanks. I'd had a couple beers before posting and didn't think to look at the sub first.
thanks, looks cool but it is not exactly what I'm looking for.
FWIW, there's a trick you can use to do allocate and deallocate with stable Rust, see here: https://github.com/rust-lang/rust/issues/27700
That sealed it for me. I am using OS threads. I'll do async again in 6 months.
There was a guy that made a similar thing with a xml output. I'll come back if I find it :)
&gt; (I can't do any packing since the metadata has to come before the data to allow shrinking allocation). This requires `#[repr(C)]` as Rust is free to change the order of fields otherwise.
That *should* work; however, panicking in `drop` is generally considered a bad idea, as it can result in a double-panic, which causes the entire process to abort.
I havne't used the WSL in a bit, but when I did, it worked great for Rust dev. (I use regular Windows now but OP said they wanted NIX stuff explicitly)
&gt; You can't omit it though, because, as discussed below, in impl Foo for Point&lt;T&gt; Rust sees T as a concrete type. This is like impl Foo for Point&lt;i32&gt;. i32 should not be a placeholder here. /u/carols10cents, we should maybe add this example to the text, WDYT?
Sure, but I want to be able to shrink. One of the motivations for this crate was to allow the space used by the value to be freed safely.
I hereby relicense all past and future comments in this thread under MIT/Apache 2 or whatever other thing you happen to use in the book repo 😄
I could also just not deallocate, and then if the owner is dropped and the value hasn't been freed I can just drop it the first time that a `Weak` is dropped while the value is unheld.
Just out of curiosity, why is there a loop and a while construct? Loop seems a bit superfluous when you could just have while true instead; but presumably there's a design reason for it?
hahah &lt;3
So 'static lifetime also implies usability of owned Data, when used as a generic bound? Didn't know that
Here's a good discussion: https://users.rust-lang.org/t/why-does-thread-spawn-need-static-lifetime-for-generic-bounds/4541/2
slides.com/colinwa/rust#/ I had a solid response to this. In particular, the "documentation is part of your tests" went over really well, and enums were particularly difficult for java devs to understand.
It helps if you can reduce the problem down to the minimum code necessary: https://play.rust-lang.org/?gist=3f8bc97cf7cadd93d4f0b85d2c081903&amp;version=stable The issue here is that when you call `handle_cmd`, you're asking to borrow ALL of `self` -- but you're already borrowing `self.requests`. /u/sharazam's response gives a good summary of what you CAN do to fix this, but I haven't seen a good explanation of the borrowing principle that's being violated according to current borrowing rules. :) Just my two cents.
I think a lot of what people hear about Rust is about memory safety, but one thing that went over in a similar presentation I did was showing just how much boilerplate Rust can save you (vs., Go in particular, since it lacks generics). Or showing off how easy it is to pull in dependencies using Cargo. Many people think new languages lack in tooling, but I find Rust has many more of the important bits (dependency management, project definition &amp; build) better fleshed out than other more popular languages.
Isn't it a common pattern to pass in options that are subclasses in Java?
Control flow analysis for `loop` and `while` are different, as the compiler does not consider `while true` to be an infinite loop. For example, the following compiles: fn get_bool() -&gt; bool { loop { return true; } } But this does not: fn get_bool() -&gt; bool { while true { return true; } } As the compiler expects another return value after the `while` block, in the case that the `while` block doesn't execute.
It's because the compiler can do more aggressive optimizations if it knows the loop is supposed to be infinite until a `break` occurs. Otherwise, it'll have to check the while condition every time. Potentially the compiler could optimize `while(true)` to `loop`, but the latter seems more explicit.
Be pro-rust, not anti- other languages! Also, check out this talk which gives tips on advocating for Rust in the corporate environment. https://www.youtube.com/watch?v=GCsxYAxw3JQ 
Thanks for articulating that perspective -- FWIW, this is pretty much exactly what we've been feeling about the documentation as well.
Indeed, I'm already using `#[repr(C)]`
If you can use just mio, it works great.
could it be an effect of the rise of Rust in the Redmonk language ranking from January? http://redmonk.com/sogrady/2017/03/17/language-rankings-1-17/ 
Hmm, I was thinking you could do that by changing the Vec's capacity and then call "shrink_to_fit" but maybe that won't guarantee that the memory is not moved...
Probably the biggest thing for me is that you can go through your entire codebase and delete every instance of `if (foo == null) { // set world on fire here ...`
No, [it uses `realloc`](https://doc.rust-lang.org/nightly/src/alloc/raw_vec.rs.html#576-609). I need to ensure that the remaining allocation is static.
I'm no expert at assembly (maybe someone who is can explain more) but I gave it a shot. I compiled `a.rs` with `rustc a.rs --emit asm`. fn main() { let mut a = 0; loop { if a == 10 { break; } a = a + 1; } println!("{}", a); } Look at this snippet from `a.s` .LBB2_1: cmpl $10, 44(%rsp) jne .LBB2_3 leaq 120(%rsp), %rdi movq _ZN4core3fmt3num52_$LT$impl$u20$core..fmt..Display$u20$for$u20$i32$GT$3fmt17hedd44d3bed3208abE@GOTPCREL(%rip), %rdx leaq 44(%rsp), %rax movq _ZN1a4main15__STATIC_FMTSTR17hb34b527f1b8eddd6E(%rip), %rsi movq _ZN1a4main15__STATIC_FMTSTR17hb34b527f1b8eddd6E+8(%rip), %rcx movq %rax, 112(%rsp) movq 112(%rsp), %rax movq %rsi, 32(%rsp) movq %rax, %rsi movq %rcx, 24(%rsp) callq _ZN4core3fmt10ArgumentV13new17hb008232be618e85cE movq 120(%rsp), %rax movq 128(%rsp), %rcx movq %rax, 16(%rsp) movq %rcx, 8(%rsp) jmp .LBB2_5 .LBB2_3: movl 44(%rsp), %eax incl %eax seto %cl testb $1, %cl movl %eax, 4(%rsp) jne .LBB2_8 movl 4(%rsp), %eax movl %eax, 44(%rsp) jmp .LBB2_1 It looks like the compiler shuffled the structure around, but you can see that it first compares 10 to `a`, and if they're not equal it goes to `LBB2_3`, which is the loop. The first `jne` in `LBB2_3` is just overflow checking I believe, but notice the last instruction: it's an unconditional `jmp` back to the start of the loop. If `a` equals 10, then it goes ahead and prints it, which you can tell by all the `fmt::Display` code. Now, interestingly, I tried replacing the `loop` with `while true` and got the same behavior, so I guess the Rust compiler is smart enough to compile that out. But look at `b.rs`. fn main() { let mut a = 0; while "true".parse().unwrap() { if a == 10 { break; } a = a + 1; } println!("{}", a); } My guess is that the compiler needs to parse the string every time. And a snippet from the assembly. .LBB20_2: leaq 152(%rsp), %rdi movq _ZN4core3fmt3num52_$LT$impl$u20$core..fmt..Display$u20$for$u20$i32$GT$3fmt17hedd44d3bed3208abE@GOTPCREL(%rip), %rdx leaq 52(%rsp), %rax ... .LBB20_3: movzwl 64(%rsp), %edi callq _ZN47_$LT$core..result..Result$LT$T$C$$u20$E$GT$$GT$6unwrap17h8ad1c819db8b8615E movb %al, 15(%rsp) movb 15(%rsp), %al testb $1, %al jne .LBB20_5 jmp .LBB20_2 .LBB20_5: cmpl $10, 52(%rsp) jne .LBB20_7 jmp .LBB20_2 So you can see the `testb` line unnecessarily checks the return value of the parse and goes to different branches depending on whether it's `true` or `false`, even though it will always be true. Sometimes you the human can tell something is an infinite loop even though the compiler can't, so we can give hints to the compiler to make our program faster.
Idk. I don't do that lol but either way the syntax / concept was hard for them to grasp.
It's not really about the datatype, but about the traits you can define in terms of types with parameters. This thread talks about the issue a bit: https://www.reddit.com/r/rust/comments/2av5tv/why_does_rust_not_have_a_functor_trait/
I was just poking at this part the other day. /u/definitelynotpietro, [do these changes](https://github.com/rust-lang/book/compare/e5fe02882788d6a7d1a2170811c12235ab286523...44bf3afd93519f8b0f900f21a5f2344d36e13448#diff-ec40ac4f7d7dfc3da883521f454381c3) make this part better or worse? (also interested in (/u/steveklabnik1 and /u/killercup's thoughts)
This is my favorite explanation of why HKT's are desirable: https://github.com/withoutboats/rfcs/blob/associated_hkts/0000-friends_in_high_kindednesses.md
The urlo forum [has a talk-help section](https://users.rust-lang.org/t/announcing-the-talk-help-section/11461) which is specifically for people who are giving talks. It's private so that people can discuss upcoming talks without fear that they will be accidentally exposed to the entire internet. That means that I don't know how active it is, but it *was* created specifically for this purpose.
Continuing into week 2 of writing a Gameboy emulator. Wow its fun. I have a feeling I'll become an emulator fanatic. Anyway, my process has been "Load in the original Gameboy Tetris ROM and as I reach opcodes I don't understand, implement them". I've had LOTS of weird bugs / quirks throughout. I think they're worth a blog post that I'll put together soon. Heading into week 2, [I am able to successfully emulate Tetris up to the main menu](https://media.giphy.com/media/3o6vXMDx5rIt7cm4iA/giphy.gif). It just sits there looping as you would expect. (I literally just implemented the last required opcode to make this not crash about 5 minutes ago so I am still riding on a bit of a high at the moment :D)
Continuing into week 2 of writing a Gameboy emulator. Wow its fun. I have a feeling I'll become an emulator fanatic. Anyway, my process has been "Load in the original Gameboy Tetris ROM and as I reach opcodes I don't understand, implement them". I've had LOTS of weird bugs / quirks throughout. I think they're worth a blog post that I'll put together soon. Heading into week 2, [I am able to successfully emulate Tetris up to the main menu](https://media.giphy.com/media/3o6vXMDx5rIt7cm4iA/giphy.gif). It just sits there looping as you would expect. (I literally just implemented the last required opcode to make this not crash about 5 minutes ago so I am still riding on a bit of a high at the moment :D)
I don't agree with arguing for a major (and redundant) language change for the sake of providing superficial similarity with a wonky-as-hell-looking C++ feature.
it's just a syntactic choice, I don't think there's a ton of reasoning behind it. It is absolutely possible to write a macro to mold the syntax to your liking, but I know many community members have negative reactions to this kind of suggestion, since they believe macros hurt readability. I'm less convinced of their negative effects, but extreme use can be a bad thing.
The gold standard for explaining ATC &amp; HKT in rust [are](http://smallcultfollowing.com/babysteps/blog/2016/11/02/associated-type-constructors-part-1-basic-concepts-and-introduction/) [those](http://smallcultfollowing.com/babysteps/blog/2016/11/03/associated-type-constructors-part-2-family-traits/) [four](http://smallcultfollowing.com/babysteps/blog/2016/11/04/associated-type-constructors-part-3-what-higher-kinded-types-might-look-like/) [articles](http://smallcultfollowing.com/babysteps/blog/2016/11/09/associated-type-constructors-part-4-unifying-atc-and-hkt/) from Nicholas Matsakis. It is quite a read but it made things very clear in my opinion. 
Because it's not the `impl` that's public/private, it's the functions. Attach the qualifier to the thing it affects, not something else that happens to be higher up the syntax tree. \**changes hat*\* Ah, but you're forgetting that Rust already does this exact thing with `enum` and variants. \**changes hat*\* Apples and oranges. A public enum with private variants is just unconstructible. If you really wanted that, you could just do a newtype wrapper around a type. \**changes hat*\* Right, because no one ever does `enum Thing { ..., #[doc(hidden)] __NonExhaustive }`. \**changes hat*\* Oh please, that's an argument in favour of open enums, not an argument for privacy control over variants. Besides, do you *really* want to have to specify visibility for every variant? \**changes hat*\* You could default to whatever the outer one is. Y'know, like Rust currently does with enums. \**changes hat*\* We already got rid of the `priv` keyword. Besides, it's tolerable as a single exception. You want to add `pub` to `impl`, but what about modules? Now you've got implicit inherited state all over the damn place. You're being stupid. \**changes hat*\* No, *you're stupid.* \**puts both hats on*\* \**starts slapping himself*\*
As someone who learned C++ after learning Rust, I am thankful that Rust isn't more like C++ in this way. For example figuring out whether [this item](https://github.com/llvm-mirror/llvm/blob/8566fbfb2582f0bff46752d2ad837daea44d279d/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.h#L467) is public requires searching upward 300+ lines of code. (2-space indent makes this even worse.)
Thank you! I now realize that I cannot implement Functor in rust. I'm still not entirely convinced that it's a language limitation, rather than my own ineptitude, but this was definitely helpful!
I'm not arguing in favor of a similarity with a C++ feature; if anything, I'd say it is for readability and, especially, to avoid having to type "pub" into every function of an entire impl (especially when said block may define more than a couple functions), when it could be summarized with a single use of the keyword. But I'm not here to defend or condemn pubs, just trying to understand what was the reasoning behind this choice. 
When you said `pub impl`, I actually expected you'll be talking about public or private implementations of _traits_. Currently, Rust has no visibility for trait impls (they are all public), but if it ever added that, it would conflict with the meaning of `pub impl` you have described here.
Oh, I definitely share this belief, especially coming from C and C++. I tell you, macros are evil beings. Necessary, yes, but evil nonetheless. 
What i often do is looking through other projects and reflect on their design: What problem did they have to solve? How do the language features they employ help them / why does it work? Could one design it more ergonomic? This way, i learned about a lot of language features and how they're applied in the wild. Edit: Also, always have the playground on hand, so you can fiddle with proof of concepts for the feature you're dissecting
&gt; attach the qualifier to the thing that it affects So that when i jump to that function from somewhere else, i can quickly know almost everything i need to know about that function by scanning one line, and visibility is one of that important information. Using OP's syntax, one may need to scroll up to find that pub.
Thanks. Unfortunately the first example not work for me. I cannot yet think of lifetimes as types, and the first example of making ACT that take lifetime as parameter feel like something that would not be needed just if borrowck was improved to be smarter. The second example of making `PointerFamily` is definitely neat, and I can appreciate the elegance of the solution. This feels really helpful to understand HKT desirability, thank you!
Oddly specific thought, but this &gt; ...it returns Async::NotReady and arranges (through some ~~complex black magic~~ actually quite logical APIs) to be poll()ed when it’s next able to make progress. made me curious to know more and gives me the impression you found a good resource that explains the API quite well. If that's the case, mind sharing?
In Rust, they're hygenic, so identifiers don't 'leak' from macros or into macros, among other reasons why they're not the level of evil that C++ macros are, but yeah... my view is not as conservative on the use of macros as most people.
Here's a [list of "why you want Rust" features](https://www.reddit.com/r/rust/comments/6kkgz7/according_to_stack_overflow_rust_is_the_most/djmvslo/) that I wrote here in /r/rust/ about five weeks ago, in a nice "header, elaboration" list format.
Oh, don't worry, I got all that learning Racket and, much later, Rust. And it's not like I condemn their usage or anything, I just personally avoid writing them. That said, I'm also not a purist. I wrote a few here and there, even in C. 
I don't think that's fair, I prefer the way Rust does it but I also like how C++'s method enforces keeping the public and private methods grouped correctly. It's not a case of wanting Rust to be C++, it's just that the two approaches make different tradeoffs.
IMO Rust is even worse in this respect-- lots of things that are crate or module-private are marked `pub`, and you have to sort through several layers of reexports before you can tell for sure if something is public or not. That's actually one of the reasons I think I would *like* something like `pub impl`-- it allows you to use `pub(crate)`/`pub(super)`/`pub(in path)` more liberally without having to do quite so much typing.
I'm in a somewhat similar situation to you, but I've been lurking long enough that I had three examples to mention when I wrote [this list of reasons to love Rust](https://www.reddit.com/r/rust/comments/6kkgz7/according_to_stack_overflow_rust_is_the_most/djmvslo/) a while ago. They tend to fall into the vein of finding ways to let the compiler enforce even more invariants than the core language itself makes obvious: * Using `enum` to write a JSON serializer than will fail at compile-time rather than runtime when faced with data types JSON cannot represent. * Using Rust's combination of move semantics, type inference, and parameterized `impl` to implement a form of "session types" to have the compiler enforce correct usage of things which can be represented as state machines, like network protocols. (No more PHP-style "Headers already sent" errors) * Treating `Result&lt;T, E&gt;` as an opportunity to discover the existence of failure cases you never even knew/noticed existed in the APIs that are exposed to *every* language. (Such as not having permission to look up the current directory's path.)
I had the same feeling about the tools. Cargo is a great piece of software! I really love how the Rust language and its ecosystem try to profit from every experience made by others
The book [(TRPL v2)](https://doc.rust-lang.org/book/second-edition/) provides a strong foundation for learning the language, if you haven't worked through it I highly reccomend.
I think it makes it better, but I'd really like a small sentence calling out that this is why you need the first `&lt;T&gt;`; it disambiguate a generic param vs a concrete type `T`.
does your current company use C or C++? if so: maybe you could find some gnarly C++ bugs that you or your co-workers had to fix, and then show how rust might have prevented them. Real-world examples in your own code-base might be more compelling than contrived examples.
&gt; Be pro-rust, not anti- other languages! Seconded! This is one of the most critical things to getting people to accept the idea. When you say "Rust doesn't have null, Java does, rust is better" people shut down. When you say "Rust has an Option API just like Java's Optional, which we already love" they're way more into it. If something is strictly better, it will speak for itself without you needing to make the comparison.
That's true. We have loads of C++.
Yes! Aside from the fact that I like this style of parameterized tests, the current `#[test]` annotation in rust has not been getting much love. There is a general desire to make it modular so that the community can write some other test runners on top of it. And in order for that to be successful there need to be experts who have strong desires and who are willing to push for changes. So you making something, publishing it, and figuring out where the difficulties are will, on top of producing a crate that I'm interested in seeing, possibly help the whole community move to a better testing place. Also I want to see the code.
cool let me just add you to the repo and.... WAIT A SECOND! ;) &lt;3
You can totally do the following in C++, in encourages grouping due to minimizing repetition but does not require them to be grouped together. public: int foo(); private: void* ptr; public: int c;
Yeah, you're right. Encourages would be the right word.
The only major thing that stands out is `compare_exchange` is really only _useful_ if you have a strong/weak variant i.e.: `compare_exchange( x, y, Relaxed, SeqCst)` and your doing looping _like in a spinlock_. If both are going to be `SeqCst` and you're just doing a one off swap `compare_and_swap(x, y, SeqCst)` is a bit cleaner. &gt;I can enforce constraints on the move semantics of the allowed types to make sure it is lock free (ie. no allocations on move since that may call a kernel mutex and blow away my whole promise). Well jemalloc doesn't _always_ hit the kernel with `mmap` for new memory. Also the whole _allocating_ business is generally not discussed in lock free contexts as this form of blocking is rather uncontrolled to a large degree from a user-space perspective. 
Interesting. In what ways would you say Rust is worse? The LLVM class I linked to is private but contains "public" member functions. Rust's ["private in public"](https://doc.rust-lang.org/error-index.html#E0446) checks are a big improvement over C++ in the situation you described. Any function you call, you know the argument types and return types are accessible. class Pub { private: class Priv {}; public: // not permitted in Rust because Priv may not be accessible to caller static Priv getPriv() { return Priv(); } };
I really like this, and think it is totally worth publishing. I say go for it. 
&gt; I get the impression that Higher Kinded Types are #1 requested feature for the language. Highly doubt it. ---------- I don't think full higher kinded types are even necessary, but the associated type constructor RFC provides _enough_ of them for everyday use, letting you abstract over certain common patterns.
The stackoverflow survey was released around the end of march, advertising rust as the most-loved language for the second year in a row. I don't recall the exact date, but [this PRNewsWire article](http://www.prnewswire.com/news-releases/stack-overflow-releases-2017-developer-survey-results-300426519.html) was published March 22nd. It would be kind of crazy if that lead to an almost-doubling of our numbers by itself, though.
Yeah, once "private in public" becomes a hard error it will help this situation some. The issue is that, before `pub(restricted)`, there was no way to specify an item that was public within your crate/mod but not exported to the world. In order to deal with that, lots of crates wound up marking a bunch of items as `pub` but keeping them private by selectively re-exporting items at a higher level. When reading Rust code now, `pub` annotations are only an upper-bound on how visible an item is (and without hard errors for "private in public", they're not even that). That is, if I see `pub`, the item could be effectively `pub(super)`, `pub(in parent)`, `pub(crate)`, or `pub`-- I can't know without examining the whole chain of re-exports. At any level, items in the module could have been selectively re-exported so that only some are visible in the next layer. Some of the new module proposals are trying to change this by automatically reexporting items, removing the need for `pub mod` and `pub use` facade patterns. However, in this world, _every_ item needs to be marked with its "true" visibility-- e.g. `pub(crate)` items must _all_ be marked `pub(crate)`, where previously they could just be marked `pub` and not reexported from the crate. This is kind of a pain, which is why it might be nice to see `pub(crate) impl { ... }` or similar annotations. Quick edit: This turned into kind of a rant, and my ideas here aren't totally cohesive-- for one, I'm conflating type-privacy with function-privacy, which makes this argument fall apart a bit. I might come back to this and edit it once I've had a chance to think about it more, or I'll just delete it.
Do you have any existing python/java projects that are small enough to convert into rust? they don't need to be big. maybe at first, just do the most direct translation possible. then try to see what parts could be made more "rust-y". for example, converting a python for-loop into a rust iterator. or a java interface into a rust trait. or convert magic constant strings/ints into a rust enum. or add some new tests using rust's built-in testing tools. if you need ideas about what types of things are "rust-y", pick a chapter in the rust book. for example: "match! ok, are there existing if-statements that i can convert into a match block? some of these things seemed to be better as `match` and other things seemed to be better as `if` i wonder why...) comparing the rust version to the python/java version could be a useful way to see how the languages are different. also, there is no substitute for "just write code" in my opinion. 
Seems to be working fine for me
HKT seemed more requested early on to me, right after 1.0 in particular. What's the reason for going with ATCs instead HKTs? It seems to me HKTs are described as the "whole hog" which seems to suggest it's preferable... yet ATCs now seem the focus.
Thank you very much! This is very enlightening! It is indeed a long read, and, to be honest, I got lost near the end somewhat (I'll probably re-read it again at a later date), but this does answer all my questions!
I am not calling it gold standard for nothing ;) Niko is inspiring on so many levels :)
I probably misspoke somewhat. What I meant is more like "whenever I see someone bashing rust, the absence of HKT is almost always one of the points as to why (long compilation times being another, but that's a problem with compiler rather than language)" ATCs do indeed seem enough for most use-cases, but laymen (like me) make little distinction between them and HKT proper. Point in case: Today was the first time I've even heard the term "associated type constructor" whereas "Higher Kinded Types" has been known to me for a while now.
This is an answer I gave 9 months ago when 2.0 were released https://www.reddit.com/r/rust/comments/58nmzg/combine200_now_a_fast_parser_combinator_library/d9343n3/. Macros vs traits is the most visible difference but that is for the most part just syntax. I think traits still increase compile times to some extent but I would argue it is fairly negligible at this point (barring a regression in rustc which happened ~1 week ago in rustc https://github.com/rust-lang/rust/issues/43613). That combine uses traits used to be awkward when writing small reusable parsers, but with addition of the `parser!` macro I would argue that has been more or less completely solved (and with `impl Trait` it will be completely solved) For more qualitative differences. combine back in 1.0.0 used to be noticeably slower than nom since I aimed for it to produce good errors. That slowness was fixed almost entirely in 2.0.0 (without sacrificing any error information, modulo the bug which was fixed in 3.0.0) however with combine only being a few percent slower on the benchmarks I ran. From what I can gather, these few percents come down to combine generating more or just more complex drop glue compared to `nom`. With 3.0.0 `combine` will be able break even or overtake `nom` by a few percent (as long as nothing else changes) if one opts for cheaper/more specialized errors. Due to `combine` not focusing on fast byte level parsers immediately it used to lack conveniences for that but I think it should be pretty close now that integer parsers are added. I believe `nom` also has bit-level parsers which is something that combine do not have. `nom` has some facilities for writing state machines to feed input into the parser which combine do not have. I have never had a need for this so I didn't want to commit to a flawed and unused design. If someone needs something like that I would be interested in some discussion though! `combine` has a lot better input reading facilities since it can handle everything between `Iterator` and `std::io::Read` to already in memory inputs such as`&amp;[T]` or `&amp;str`. `nom` on the other hand only supports `&amp;[T]` (`&amp;[u8]`?) and `&amp;str`. Just because I think it is worth mentioning again, `combine`s error reporting is a lot better for the effort put in when writing parsers. In combine char('!').or(digit()).or(letter()) .parse("?")// Unexpected '?' expected '!', 'digit' or 'letter'. char('!').or(digit()).or(letter()) .expected("something") .parse("?")// Unexpected '?' expected 'something' In nom you get one or several error codes which need to be returned manually and handled separately. Though you can probably get nice errors, it is not without a lot of work. (Please correct me if I have misunderstood anything about this) https://github.com/Geal/nom/blob/master/doc/error_management.md#error-management `combine` is a lot smaller than `nom` but its tutorial(s) could be expanded (Markdown). $ tokei nom ------------------------------------------------------------------------------- Language Files Lines Code Comments Blanks --------------------------------51 2451 0 0 Rust 40 17646 13015 2934 1697 Plain Text 2 32 32 0 0 TOML 1 54 42 3 9 ------------------------------------------------------------------------------- Total 53 20183 15540 2937 1706 ------------------------------------------------------------------------------- $ tokei combine ------------------------------------------------------------------------------- Language Files Lines Code Comments Blanks ------------------------------------------------------------------------------- JSON 1 317 317 0 0 Markdown 2 271 271 0 0 Rust 16 8943 6053 2200 690 sh 1 8 6 1 1 Plain Text 1 494 494 0 0 TOML 2 53 37 1 15 ------------------------------------------------------------------------------- Total 23 10086 7178 2202 706 ------------------------------------------------------------------------------- **EDIT** `nom` has a lot of parsers already written in it which is something that should not be underestimated when deciding on a library https://github.com/Geal/nom#parsers-written-with-nom.
That's just something you'll pick up after you write more and more software in Rust. Same applies to any other language.
Interesting project No GitHub ?
&gt; As an aside, I'm not actually sure this queue is actually lock-free and I'm not sure how to determine that and if I can enforce constraints on the move semantics of the allowed types to make sure it is lock free. It's not - you've basically implemented spinlocks :) By setting `reading` to `true` you lock and by setting it back to `false` you unlock. The fact that other reader threads can't make progress while you're in this critical section is what makes the algorithm blocking. Locks usually have acquire-release semantics, so you should probably lock by using `Acquire` ordering and unlock by using `Release` ordering. Take a look at how `parking_lot` implements mutexes [here](https://github.com/Amanieu/parking_lot/blob/de8aca4485836b7fa796b806647411e96365f0b5/src/raw_mutex.rs#L77) (functions `try_lock` and `unlock`). Another problem I'm worried about is that you're comparing `read_position` and `write_position` that were retrieved using relaxed loads. There's nothing synchronizing them, so you should probably load and store them using the `SeqCst` ordering. Next problem: Think about what's going to happen when you do `drop(FixedQueue::&lt;Foo&gt;::new(7))`. First, a `FixedQueue` with 7 slots will be created. Then the queue gets dropped, which destructs 7 (possibly invalid since they're zeroed) objects of type `Foo` , even though they don't exist! This is unsafe. What you should really do is create a `Vec` with capacity 7, but length 0. To read and write elements to its internal buffer, obtain a pointer to it using `Vec::as_mut_ptr()` and write manually to memory using `std::ptr::read` and `std::ptr::write`. Also, you need to implement `Drop` for `FixedQueue` and pop all remaining elements in order to avoid leaking unpopped elements. &gt; make sure no allocation is happening inside the actual queue/eqnueue methods of the queue Don't worry, no hidden allocations are happening inside those methods. Finally, have a look at [this](https://docs.rs/mpmc/0.1.2/src/mpmc/lib.rs.html#31-232) queue implementation, which has a lot of similarities with yours. It's not strictly speaking lock-free, but it's pretty close. The only problem I see with this one is that it doesn't implement `Drop`.
&gt; whenever I see someone bashing rust, the absence of HKT is almost always one of the points as to why I think that's a skewed sample set; I don't have the same impression.
I have often thought that a great talk would simply be to live-code starting from `rustup.rs`. If you are in a room of experienced developers it would be sure to hook them. * "We're going to parse this 500MB json dump from IMDB" (or whatever) * Install rustup then install stable * `cargo new --bin my-demo` * Add `serde-json` and `error-chain` to `Cargo.toml` * Define a few structs, `#[derive(Deserialize)]` * Opening and parse the `File` using `?` for error handling * Print a few stats * Compile with --release (have some patter ready: "IT HAS NO GC, IT RUNS ON MAGIC") * Run in 5 seconds flat * Bonus points - parallelize with rayon and parse 12 files at once Could probably fit it into 45 mins if well-practiced. Don't bother talking about the borrow checker. This will make you audience feel dumb. Do keep saying "stack allocated" and "static dispatch" and "memory safe" and "statically compiled" and "type inference". This will make your audience feel clever.
It's not an "either or" situation, full HKT can be built on top of ATC. The thing is that the complete abstraction power of HKT isn't necessary for most of the Rust things; in fact, as discussed in [this podcast](https://request-for-explanation.github.io/podcast/ep4-literally-haskell/index.html), the full Monad trait is probably not even desirable in Rust. 
That's weird since it's my home network
One thing I saw come up frequently in syntax discussions pre-1.0 is the importance of greppability. Some of the language designers wanted the syntax to be friendly to evaluation using grep. So if you want to know what functions are public, you do: $ rg 'pub fn' src/foo.rs pub fn new() -&gt; Self { pub fn change(&amp;mut self) -&gt; Result&lt;()&gt; { (Yeah, I'm using rg instead of grep.) If they had made the other choice, that wouldn't be possible: $ rg 'pub impl' src/foo.rs pub impl Foo { I'm not sure if there were other reasons for this particular choice, but given that I saw this argument used in other places, it may have been relevant here as well. 
I gave one at my work. The biggest obstacle I had wasn't that people weren't interested, but that most people didn't understand the benefits. I had only one person there who was an experienced C++ developer (I thought there would be more, but I was wrong) and could directly understand the benefits of compile-time memory errors, C++-like templates (traits) instead of object oriented, and zero-cost abstraction. He had professed before that he wasn't interested in other languages, but I had him smiling and nodding along as I presented the benefits. For the record, most of our devs are either primarily Javascript or Java. To be fair, a number of people perked up when I told them about the built in package manager and testing tools (via Cargo). I guess the best thing you can do, of course, is just show them the code working. 
Happened to me for a bit. Cargo couldn't get a lock on the index. Peer chance,is your ISP Sky ? 
Mad props for the name. Edit: You should add a `--quote` option that just prints out a Gimli quote and exits. I would install it just for that.
You need to get an `AXE` method in there.
&gt; It's not - you've basically implemented spinlocks :) Can you please give a bit more details on this ? It seems that the current implementation does not force any spinlock. The way I'm testing it is enqueueing and dequeuing by spinning since I want to make sure everything gets in. However in the context where you have the option to to acquire/enqueue a value but it's not mandatory, or maybe want to try an x number of times or depending on the situation you can block and sleep between reads you aren't forced to spin to do those operations... I can't think of a situation whereby you could implement this kind of queue without either: a) A check at some point to see if the method is busy (which is what I did) b) An internal spin lock, which I would dislike, but if you actually read up on the definition of what lock-free is you will see that spinlocking can still mean the algorithm is lock free: https://en.wikipedia.org/wiki/Non-blocking_algorithm#Lock-freedom The definition of lock-free is basically that you are guaranteed at least one thread makes progress... obviously this will depend partially on the kernel implementation, but assuming POSIX thread, allocation free move ctors and no allocation inside the eqnqueue/dequeue a single thread (Either using implementation a or b) is guaranteed to make progress... since whatever thread is reading/writing can't really be suspended by the kernel (not making any syscalls). c) Using allocations... and I explained bellow point b hopefully why this means the thing is no longer lock free (If not, hopefully wikipedia does a better job). If I'm wrong, please correct me, I'm by no means an expert on the subject. &gt;Another problem I'm worried about is that you're comparing read_position and write_position I'm comparing those two in a single threaded context though and that's a guarantee... so I don't see how a mfence helps here. Is it needed ? Also as far as using Acquire and Release... I think those might actually work there, I'm not so familiar with non-seq constant memory ordering so I didn't want to bite the bullet on that one and instead went with Seq for now. &gt; Think about what's going to happen when you do drop(FixedQueue::&lt;Foo&gt;::new(7)) Completely forgot about this... In the C++ implementation the way the vector is initialized means that the destructors of it's internal always work. Here however I made the mistake of using zeroed... Is there no way to approach this similarly to C++'s move semantics and swap only the internal pointers of the objects in the vector, leaving them in a valid state to be destructed ?
**Non-blocking algorithm: Lock-freedom** Lock-freedom allows individual threads to starve but guarantees system-wide throughput. An algorithm is lock-free if, when the program threads are run for a sufficiently long time, at least one of the threads makes progress (for some sensible definition of progress). All wait-free algorithms are lock-free. In particular, if one thread is suspended, then a lock-free algorithm guarantees that the remaining threads can still make progress. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.24
I feel like this could be a presentation Kata. Don't forget to do it inside of IntelliJ, navigate into src, etc. Use `cargo doc` to browse docs locally or https://docs.rs
There's a bunch of module improvements proposed on [internals](https://internals.rust-lang.org/) (I counted at least six posts last time I looked). IIRC some address this issue.
Yep-- it's something /u/aturon and /u/desiringmachines have been working very hard on for a while.
Best thing you can do is a give a great presentation. Lots of what you cover could click later, esp the next time a data structure blows up 3 hrs into an ETL run. 
This has a ton of things I've wanted. I'm going to have to check it out!
&gt;The only major thing that stands out is compare_exchange is really only useful if you have a strong/weak variant i.e.: I'm sorry, I wasn't aware compare_and_swap was different from compare_exchange in rust. Aren't they both going to be translated to something like: cmpxchg anyway ? (Or whatever the arm equivalent is). What's the difference in terms of code generated ? Or is it just for the cleaner interface ? Also I'm not yet sure both or either should be Seq cast, I was looking into non-const seq memory ordering but life cam along and I was interrupted. &gt; Also the whole allocating business is generally not discussed in lock free Hmh, maybe I'm wrong on this one, but as far as I know the most common place for the kernel to do a ctx switch is when a thread makes a sycall... not to say the kernel can't do preemptive ctx switching (I believe it can) or an intrrerupt can't cause a ctx switch but most of the time if you are just doing 4 operations with no syscalls in a row you are basically doing "the best you can" not to cause that thread to be switched out of the scheduler... I'm quite sure that with the right kernel or settings you can even make that a guarantee. If you allocate memory, whilst you may not be guaranteed to trigger a memory allocation since w/e allocation you are using has a cache that means: a) You are relaying on the user having the same allocator as you and on the allocator's cache being mutex free b) You are incurring additional potential for the thread blocking when memory needs to be allocated c) You are increasing the time inside of the method itself (which makes the thing slower and if the user is spinning to do stuff this can result in a horrible performance penalty) d) You are depriving even a RT kernel that can make certain guarantees about the lack of ctx switching in between some points in the code of using this as lock free... since getting memory is basically I/O and I can't see any normal kernel who wouldn't ctx switch the shit out of the thread doing that. Again, as I said above, I'm not putting my life up on these statements, I'm not that familiar with lock free programming. I'd love my opinion to be challenged and changed, I'm just saying what I know and explaining my thought process when designing this.
good bot
[removed]
From Sweden, so no.
&gt; since whatever thread is reading/writing can't really be suspended by the kernel (not making any syscalls). Actually, it can. The kernel uses preemptive scheduling, which means threads simply get interrupted after a specific amount time, no matter what. Perhaps you're confusing this with cooperative scheduling, where actions of the thread determine whether it will be descheduled (e.g. by making a syscall). It is possible for your threads to get descheduled while they are in critical sections, and it *will* happen. And when that happens, other threads won't be able to make progress, at least not forever (in the sense that their enqueue/dequeue operations will keep failing). This is by definition a blocking algorithm. &gt; I can't think of a situation whereby you could implement this kind of queue without either: &gt; c) Using allocations... and I explained bellow point b hopefully why this means the thing is no longer lock free (If not, hopefully wikipedia does a better job). Well, you can just switch jemalloc for another allocator that is lock-free (they are available). But it will probably be slower than jemalloc even in highly concurrent scenarios, so... for that reason we usually just *assume* that the allocator is lock-free for the sake of simplicity and don't bother with it. :) But yes, if you want to avoid allocation, it's probably impossible to make the queue lock-free. Note that [Dmitry Vyukov's MPMC queue](http://www.1024cores.net/home/lock-free-algorithms/queues/bounded-mpmc-queue) is not lock-free either, but concurrent operations will have much smaller chances of blocking each other. I like to think of that as *blocking in theory, but almost lock-free in practice*. &gt; I'm comparing those two in a single threaded context though and that's a guarantee... If a reader thread is modifying `read_position` and a writer thread is concurrently modifying `write_position`, it's not really a single-threaded context, is it? To be completely honest, it may be all right to use `Relaxed` loads here, but I'm not sure and a proof of correctness would likely be non-trivial. &gt; Also as far as using Acquire and Release... I think those might actually work there, I'm not so familiar with non-seq constant memory ordering so I didn't want to bite the bullet on that one and instead went with Seq for now. I see. But - while you're using stronger (`SeqCst` instead of `Acquire`) orderings for locking, your orderings for unlocking are actually weaker (`Relaxed` instead of `Release`) - and that's what I wanted to point out. :) &gt; Is there no way to approach this similarly to C++'s move semantics and swap only the internal pointers of the objects in the vector, leaving them in a valid state to be destructed ? No. Well, actually... the closest equivalent of `std::move(x)` would probably be `std::mem::replace(&amp;mut x, Default::default())`. But that requires a new type bound `T: Default` and is not really an idiomatic thing to do in Rust.
that sounds more of a text editor issue to me: inbetween folded and plain views, I can imagine something that locks the outer indentation lines as you scroll (some IDEs do this by displaying the name of the current 'class' in a special bar, but I imagine generalizing that, e.g. the first N lines of the window show the first line before the first N nesting levels before you get to the current location) e.g. imagine if the editor at line 400 in a x00 line class in a namespace starting at 230 showed.. 230: namespace Foo { ... 300: class Bar { ... 330: void some_method() { 331: blah blah blah 332: blah blah blah 333: blah blah blah 334&gt; blah blah | blah 335: blah blah blah ... 400: } ... 450: } etc 
my concern with macros is they kill an IDE's ability to navigate; i've already encountered this - intellij gives jump-to-def, but when i used a macro to streamline instantiating trait objects, the indents input there are no longer navigable.
Error message will still be the same. impl Trait is needed to remove need to box futures every time you use them since there is no easy way to predict what type is going to be nor you care about what kind of type mess is returned from it. 
Yes, you can pass a `&amp;mut [u8]` as a parameter to a function. This is a mutable reference to a slice of bytes, which the callee can write to and then return the number of bytes written. However, this is a very low-level interface, and typical rust code would use existing higher-level zero-cost abstractions, such as the `io::Read` trait: on the callee side, it presents exactly this interface (the callee is passed a mutable buffer, and returns whether the operation was successful, and the number of bytes written) but on the caller's side, you can use simpler methods such as `read_to_end`, etc. according to your needs.
Is there function call to drain a vector into a slice. Basically I am looking for something like [`clone_from_slice`](https://doc.rust-lang.org/std/primitive.slice.html#method.clone_from_slice) or [`copy_from_slice`](https://doc.rust-lang.org/std/primitive.slice.html#method.copy_from_slice) that will drain a vector into my slice, because my type does not implement copy nor clone. I suppose writing the loop itself isn't horrible, but I am so used to iterators and such, I am suspicious of indexes in loops at this point :P EDIT: On that note, is there a loop free way to `copy_from_iterator` or `clone_from_iterator`? I would find these things useful for copying into buffers passed in from C. It lets me skip a "collect" step.
Yes, Rust allows this. [Here is an example I just whipped up.](https://play.rust-lang.org/?gist=7a9338231bcea3e7a0ba5750f8a201b9&amp;version=stable) Rust's slices carry a pointer and a length, so you don't need to worry about explicitly tracking the length. I didn't show it in my example, but you could get the length of `buf` with `buf.len()`.
\#216 is a broken links: pull, not pulls
IntelliJ tries to reinvent the wheel on everything. I'm surprised they do as good as they manage to, honestly, but if I remember correctly, they have some changes coming for the Rust plugin to make macros better supported. As far as I understand, the Rust Language Server understands everything, so it shouldn't be a problem for RLS. At least, once RLS hits stable.
Wait...You supposed to wrap your service in Arc/Rc? Service I wrote is 100% thread-safe (according to rust compiler) and forces user to only use thread-safe components when service is created...you telling me I still have wrap it in Arc/Rc to make sure it's created only once?
Could you show the tls certificate used for the connection?
There are a lot of important things besides allocations that are important for lock-free queues. False sharing and amount of synchronization are among them. You might wanna take look at my [old spsc queue](https://github.com/rozaliev/passenger/blob/master/src/spsc/bounded.rs). (You'll need to add some crate attributes to make it compile on today's Rust tho). There are also papers about lock-free queues, I can't remember any good ones off the top my head, but they should be pretty googlable. 
Thanks for another great write-up! You've covered a lot of detail in `elastic` and thanks for being so helpful with those issues you uncovered :) As you can probably tell it's still fairly early days for `elastic`, the bedrock is there but it's a long way up. If you read the two tutorials together it's clear that `rs-es` has a more obvious API than `elastic` that's probably familiar to users of Elasticsearch clients in other languages. In terms of surface-area `rs-es` also covers more of the Elasticsearch API. With `elastic` I'm hoping some of the design decisions that look a bit funny now (like the shape of the `RequestBuilder`) will start paying off as complexity of the requests goes up. I'm hoping to get an async client merged soon (just working on upstream support in `reqwest` at the moment), pull all the separate crates into a single repo so it's easier to contribute to and churn should start going down for a while. I'm excited to see how people interact with Elasticsearch from Rust, whether that's through `rs-es`, `elastic` or something else.
&gt; Actually, it can. Sorry, I oversimplified, gave more details on that in the answer to /u/valarauca8, quoting myself: " Hmh, maybe I'm wrong on this one, but as far as I know the most common place for the kernel to do a ctx switch is when a thread makes a sycall... not to say the kernel can't do preemptive ctx switching (I believe it can) or an intrrerupt can't cause a ctx switch but most of the time if you are just doing 4 operations with no syscalls in a row you are basically doing "the best you can" not to cause that thread to be switched out of the scheduler... I'm quite sure that with the right kernel or settings you can even make that a guarantee. " &gt;If a reader thread is modifying read_position and a writer thread is concurrently modifying write_position, it's not really a single-threaded context, is it? Ahm... ok, maybe I'm not understanding this correctly, but as far as I know for all the operations I'm doing the only effect seq ordering does is adding a mfence... basically ensuring an operation ordering if multiple thread reach the same my_atomic.operation(). In a single threaded context (which is always the case when I use Relaxed), only one thread will be doing my_atomic.operation(). ... Indeed, other threads may be doing other operations at the same time on that same atomic in another place... bu the memory ordering does not interfere with that as far as I know. So if we have two pieces of code f1() { my_atomic.operation() } f2() { my_atomic.operation() } And two threads t1 and t2, if t1 and t2 are both calling f1 and f2 the memory ordering of operation() matters... if t1 and t2 are guaranteed to be calling a separate function (e.g. either t1 or t2), the memory ordering means nothing (so why not used relaxed ?). Maybe I'm wrong on this one... I've had fundamental flaws in my understanding of atomic operations before, that's why I overused Seq in the first place. The only place where I can see more thread doing the same operation at the same time is where I already have set consistent memory orderings. &gt;No. Well, actually... the closest equivalent of std::move(x) would probably be std::mem::replace(&amp;mut x, Default::default()). But that requires a new type bound T: Default and is not really an idiomatic thing to do in Rust. Well, the thing with ::default() is that as you said, not guaranteed to be there and also can be quite costly... which is a cost I would like to avoid since I don't really care about said object. ..... Also, you have not answered my first quesiton about where exactly you saw a spinlock in my code ?
`loop { .. }`, combined with `match` and `break` is what `while let` and `for` loops ultimately desugar to. `loop` perfectly conveys its meaning. It's looping. No surprise here whatsoever. Not only is `while true { .. }` longer, it is also less natural to read (unless your mind is already warped by C). Also only `loop` allows to `break` with a value.
These are the main points of why I chose Rust over Haskell and Go to develop the implementation of my bachelor's thesis. Cargo feels like a breath of fresh air in all aspects I've encountered so far. The only thing I don't like about Rust is how redundant it feels to use `mod` and `extern crate` definitions all over the place, but this is being reworked as far as I'm aware, and it's not hard to work around it until it is done.
There are indeed A SHIT METRIC TON of papers and implementations for concurrent queues. My problem with most of them is that they are either: a) Impressive in what they can accomplish but hard to write for a normal human being ( http://webee.technion.ac.il/~idish/ftp/spaa049-gidron.pdf ) b) Over theoretical not taking into account practical concerns (e.g. iteration through continuous memory being hundreds of time faster than iterations based on pointer hoping. Relaying on GC or on various other algorithms which are good on paper but impractical in reality c) Old... granted this is mainly for C/C++ , most rust stuff is new, but there aren't as many of them implemented in RUST d) Too pedantic and strict in design in order to squeeze the last drop of performance and compatibility at the cost of easier test coverage, modularity, code clarity and flexibility (e.g. https://github.com/cameron314/concurrentqueue) e) Cluelessly bad by being either unsafe, slow or outright broken. Not that mine isn't I actually came here because it's slow and someone pointed out that it's destruction is also unsafe... but I the other version is decent and I'm hoping to correct this implementation as well and make it safe and decently fast... once I find a way to find the bottleneck that's making it act differently from the C++ implementation. I'm not saying any of a/b/d are bad. I'm just explaining my reasons for why I wrote my own (I actually wrote the C++ version after I realized I couldn't find any single w / single r queue that does exactly what I want)
Thanks, should be fixed now.
&gt; but most of the time if you are just doing 4 operations with no syscalls in a row you are basically doing "the best you can" not to cause that thread to be switched out of the scheduler... It's best to measure these things. My guess is that performance will degrade as you add more threads due to those occasional bad preemption "hiccups", but I could be wrong. By the way, if the current thread cannot make progress after several retries, it's a good idea to call `std::thread::yield_now()` in order to deschedule it and make the whole system run more smoothly. &gt; In a single threaded context (which is always the case when I use Relaxed), only one thread will be doing my_atomic.operation(). ... Indeed, other threads may be doing other operations at the same time on that same atomic in another place... bu the memory ordering does not interfere with that as far as I know. I'm worried that e.g. a reader thread will do `data.read_position.load(Relaxed)` and load a fresh value, but `self.next_pos(data.write_position.load(Relaxed))` would accidentally load a stale value. I worry that these two values might be totally out of sync and the reader might think that it's okay to read the next value, while the queue is actually empty. Sorry, I wasn't totally clear - I think the problem is even bigger than choosing the right orderings. The problem is that you're not atomically loading both values at the same time. :) Here's [another crate](https://docs.rs/two-lock-queue/0.1.0/src/two_lock_queue/lib.rs.html) that's somewhat similar to your queue. You can see how it solves that problem in [line #452](https://docs.rs/two-lock-queue/0.1.0/src/two_lock_queue/lib.rs.html#452). Basically, both `enqueue` and `dequeue` operate through `len`. They touch base through the single `len` value rather than two values `read_position` and `write_position` - that's the important bit here. &gt; Also, you have not answered my first quesiton about where exactly you saw a spinlock in my code ? Ah, sorry. To be more precise, think of `data.writing` and `data.reading` as mutexes. You attempt to enqueue/dequeue by compare-and-swapping to `true` (just like `Mutex::try_lock()`), and finish by storing `false` (just like `Mutex::unlock()`). Repeated attempts to enqueue/dequeue like the following resemble a spinlock: while ReturnCode::Done != queue.enqueue(n.to_string()) {} Oh, while we're at it: you can avoid the allocation (`n.to_string()`) here. Change the signature of `enqueue` to: pub fn enqueue(&amp;self, write: T) -&gt; Result&lt;(), T&gt; Return `Ok(())` in case of success and `Err(write)` in case of failure. Now you can enqueue like this without repeated conversions to `String`: let mut string = n.to_string(); loop { match queue.enqueue(string) { Ok(()) =&gt; break, Err(s) =&gt; string = s, } }
Is that really the only way? I have a half dozen test files and some of them have a few hundred test in them and I expect to be adding more. It would be nice if I didn't have to go through and test them one by one. Can you possibly explain to me why cargo is just randomly picking a file to run from that folder now?
No, makes no sense. You say in the OP that it's the "first" file but in your comment it's "at random", which is it? Any chance you could post the code?
Can't post the code. If I had to explain it, it's the first file alphabetically in the tests folder, but I have no idea why it would sort them alphabetically and run that file. The file structure is below. Only a.rs is run even though all of the files have test in them. src/* test/ a.rs b.rs c.rs d.rs etc...
And my haxe !
I'm sorry I was just asking a question. Not trying to make anyone upset.
Thanks, that really helped drive home the concept. I should probably start catching this podcast.
Figured it out, edit my post above. Thanks.
Oh, don't worry about it. Thanks for your help.
Awesome information thanks for chiming in! :) Maybe u/japaric might be interested in adding a binding in future with his experience developing RTFM and Photon contributions. It's a bit beyond me I think, though in future if there was a bounty/patreon or such for it I wouldn't mind contributing financially :)
Does anything need to be done to benefit from this with existing code using rust crypto aes? I presently use `aes::cbc_decryptor`.
I'd be interested in a repo and slide deck for this :o I like what u/fullouterjoin said about presentation kata, are there some like this for Rust already?
Is it possible to restrict the length of the slice at compile time and check that length at both the caller and callee's ends?
Agree with /u/carols10cents - trying to read it from the perspective of me before it was fully explained. Calling out the fact that `impl G&lt;T&gt;`'s T is a concrete type and not a generic placeholder is the crux of the confusion.
I showed how you can specify a precise length in the type, using `buf: [u8; 7]`, and you can actually take that and put it in the function signature (in this case, `&amp;mut [u8; 7]`, that way we can take a reference and mutate the contents) to restrict it to only working with stack arrays of a precise length. I would argue that if you're wanting a specific number of values, like an XYZ coordinate, you're better off with a tuple. If you don't care what specific length the array is, a slice or Vec is better. If you just care that an input and output array have the same length on a function signature, but you don't care what length that is, then that's called `const generics`, and it's a feature that is [under development.](https://internals.rust-lang.org/t/lang-team-minutes-const-generics/5090) I should also clarify: `[u8; 7]` is an array of fixed length. `&amp;[u8]` is a slice, because it doesn't *own* the memory, it just points to a part of memory with a length known at runtime. This slice could actually just be a restricted subset of the values in an array, rather than the whole array. So, a slice is a "view" into an array.
I don't see how mods and extern crates are redundant. Every language I can think of works this same way. What are you talking about, and do you have a source for plans of this being reworked?
Not really. If nullability is needed you will just have to use Option in rust but with the same boilerplate amount. Annotations can be used in Java to declare objects as non nullable like in rust. Optional exists in java as well.
Idk why that was a problem. Java has enums as well they just can't store different types of values.
There are two posts on u/aturon 's blog about this ([post](https://aturon.github.io/blog/2017/07/26/revisiting-rusts-modules/), [discussion](https://internals.rust-lang.org/t/revisiting-rusts-modules/5628) and [post](https://aturon.github.io/blog/2017/08/02/modules-part-2/), [discussion](https://internals.rust-lang.org/t/revisiting-rust-s-modules-part-2/5700)). It's still only a discussion as far as I'm aware, but I very much like the direction this is taking. Basically, instead of having multiple different ways of declaring a module, let the file system determine that, and instead of having to `extern crate &lt;crate&gt;;` AND `use &lt;module&gt;;`, you can just `from &lt;crate&gt; use &lt;module&gt;;`. Again, this is still being discussed, it's still not set in stone, but it's the gist of it. Edit: Links and wording
All the memory safety rust provides is a fad in my opinion. Null pointers in java are honestly no different than options in rust. One forces to statically check the object but I don't see that as a big benefit. To experienced c++ developers dealing with memory shouldn't be a problem and rust code sometimes takes longer to write. The reasons I like rust more than java is performance even if unnoticeable and easier interfacing with c libraries. I like it more than c++ because of cargo and the crates ecosystem. Forced null safety feels unneeded. Lack of default trait implementations seems inferior to what java has with interfaces. Macros are kind of nothing new compared with java. Spring has annotations all over the place and Lombok uses them. I don't really know if I would recommend rust to other people. Edit: match is obviously better than switch.
I mean, I agree with everything you're saying, but I'm confused why you're responding to me.
- Rust Love Poems Vol. 1, 2017
The fact that you find that issue means that you found the `--no-fail-fast` flag, right?
Yeah, it was kinda counterintuitive that that would be the problem, but at least I know what was going on now. 
I am just sharing my thoughts on why they may feel disinterested. I don't really know how to make them see rust as beneficial.
I see what you were talking about now. Thanks for the links. It looks like they want to make modules work like java packages?
this seems like a bug and might be worth reporting on GitHub. does nightly still have this issue?
It's using HTTPS, so that should be essentially impossible.
if the user has a bad root cert installed on their computer from their ISP or a piece of malware, it's very possible.
Playing on the old regex-two problem joke: A developer has a Problem. They decide to use tokio-service. They now have a Future&lt;Problem&gt;.
There is a method with almost this exact signature in the standard library: [std::io::Read::read](https://doc.rust-lang.org/std/io/trait.Read.html#tymethod.read). Rust's slices (e.g. &amp;mut [u8]) are fat pointers that combine a pointer into the array with a size, making this pattern safer and more convenient than in C.
I'm running on nightly now (`rustc 1.21.0-nightly (ba1d065ff 2017-08-06)`). Good to know that it's potentially incorrect behavior, I'll file a bug report now!
I think this is a known bug, I'm on mobile or I'd check.
That, as far as I understand, can be a valid analogy, yes. I'm just glad the module system is becoming more straightforward, because that was one of the very few gripes I had with the language.
I searched using a couple of different phrasings, but I couldn't find this bug on the Rust repo. It's very possible that I just didn't try the right phrasing though!
I started lurking/reading about that time. I'm trying to remember what it was and I think it was this post, that got picked up on HN: https://np.reddit.com/r/rust/comments/5ypodo/rusts_type_system_is_turingcomplete_an/ The issue was interesting enough, but the discussion surrounding it really impressed me, and then I got interested in the details of rust. The dialogue reminded me of what you might see in C/C++, lisp, or haskell communities, which I found really impressive.
See the documentation for the Write and Read traits. That's what it offers. let written_bytes = output.write(input)?; let read_bytes = input.read(output)?;
Isn't the index on Github anyway, or does Cargo go via crates.io to find the address to the index?
Some tips: * don't list features * gather some real world problems that pain your developers and show them how Rust helps in solving them * tell them about the openness of the community
Wow, this is a fairly big upgrade, took me a couple of hours to migrate to v0.14 from v0.13. I probably didn't look hard enough, but what was the rationale for these fairly significant API changes (e.g. Lift `Reader` trait to the forefront of most struct's generic interfaces, return `Reader`/`EndianBuf` instead of `&amp;CStr` (from `AttributeValue`), and `EndianBuf` now returns `Cow` instead of `&amp;str`, etc...)? In order to support dwarf5? Nevertheless I'm most excited about `Expression`!! The helper `struct` allows me to remove most of the hand crafted dwarf expression evaluation logic. [edit] Oops, it looks like the rationale for `Reader` and `Cow` changes was given in [#182](https://github.com/gimli-rs/gimli/issues/182).
Or event over-zealous anti-malware software.
Currently you'll have to implement CBC mode plus padding yourself. I have draft of generic block modes with the paddings, which I hope I'll be able to publish this month. (before that I need to close some bugs in hashes repo and rework BlockCipher trait) Meanwhile I would recommend to use AES-SIV implemented in the miscreant crate (see link in the OP).
Sorry about the pain. Is your code available for me to look at? I'm interested to see how people are using gimli, so that I can see if there is anything we can improve to make the API easier to use. Regarding the `Cow`, if your code sticks to using `EndianBuf` then you can avoid using `Cow` by using `str::from_utf8(endianbuf.buf())` instead (this conversion can fail of course). `Expression` is actually just a simple wrapper. Everything it does was already available (although maybe it wasn't easy to find before). Be aware though that the expression API may see some changes when we add support for the typed values on the expression stack for DWARF 5.
👍 Nothing kills my interest faster in a language than militant fan boys. 
Would there be a decent perf increase with AES-SIV vs the current AES decryption with RustCrypto? I've ported my code over to using ArrayFire for OpenCL/CUDA on the GPU, but it looks like I'll need to port AES decryption to ArrayFire as well(or read up on how to integrate existing OpenCL/CUDA kernels for AES-CBC decryption). Presumably the decryption on GPU will outperform CPU AES native instructions(It's a hash cracking utility so it's doing bulk decryption).
I am not familiar with AES on the GPUs, so I can't really tell. But pure aesni (essentially ECB with data completely in the cache) gives ~4 GB/s on my 2.50GHz CPU. More modern CPU will give a better result, plus multiply it by the number of cores. Optimally implemented AES-CTR will be a bit slower, but probably not significantly. You can run `cargo bench` for aesni on your hardware to see the numbers. Regarding AES-SIV it will be certainly slower, it has two non-parallelizable passes to provide misuse resistance. bascule wrote in #rust-crypto IRC that his AES-CTR-PMAC implementation (not yet published) gives almost 2 GB/s.
I had the same approach as you. This Talk helped me to write my Gameboy emulator: https://www.youtube.com/watch?v=HyzD8pNlpwI
What I understand from the most of answers is that Rust isn't like C++, it's more like C so that's why I had troubles with it because I shouldn't try to apply C++ programming patterns on Rust.
Neat! It's unclear what kind of editing operations this'll support based on the video, but I'm curious to see if it could potentially be useful for making maps for tabletop roleplaying :)
As always; practice! Once you've mastered the syntax for doing something you usually do in a different language, the way you would have done it in that language, read up on how to do it the 'rusty' way. And do it in a reasonable real-world project. The latter has held me up, but now I've got an idea for what to do, and that'll keep me busy for the next month (s). 😁😎
It's a known annoyance, but working as intended. It's due to when the destructor runs, which is a bit too early.
The gold standard in code quality in crypto now is probably NaCl and libsodium. There are quite a bit of uncommon precautions one need to account for in crypto, especially related to side-channel attacks, so I'd suggest, if possible, DJB for review. 
While Rust is young, it is inspired by ML which is older than C++, and has a set of academic theories regarding types for its backing, so the rust way involves quite a bit of functional programming. That said you probably shouldn't go to learn a functional language just for this. But maybe bearing this in mind can help your understanding in some situations.
Jump into an open source project and try to help out. Every time I've done that, I've been given plenty of patient assistance from existing maintainers and learned loads.
Does NLL fix this?
Actually I was going to try Haskell to get a proper view on functional languages, but starting with Rust because it's pointed to the same area as C++.
I really like this, although I'm not sure that it's a big enough ergonomics win for most of the tests that I write. You might also be interested in [quickcheck](https://github.com/BurntSushi/quickcheck), which does something similar but takes a different approach.
Wait, does this mean we might be able to get line numbers on stack traces in OSX with addr2line? #OneDay
It's working again but this is the second time this has happened, would be nice to understand why. Since it fixed itself I'm guessing my IPS was doing something stupid.
Wow, looking great. I will try this out over nom, as it looks like it's much less painful to use. Good job!
&gt; No jobs listed for this week. This sucks worse every week. Is there anything we can do other than keep working on code, blog posts, and pushing adoption of Rust at our current companies? Community team, any ideas?
The best thing for Rust would be to find a niche market to build its metaphorical stronghold in. Go was able to do this by becoming the \*ahem* go-to language to use for a specific set of networking applications. It probably couldn't have done this without the weight of Google's influence, but in my opinion Rust is a better language, so perhaps it can carve out a market without needing a massive technology giant to drive adoption forward.
I kind of disagree with &gt; To experienced c++ developers dealing with memory shouldn't be a problem While I was obviously not one of the best c++ programmers in existence, I still managed to get through without any memory leaks. **However**, this doesn't mean that there were no problems, because once I accidentally had a memory leak, it sometimes took hours to find it, which is far longer than the time I spend to satisfy the borrow checker atm.
If I understand correctly, this crate encapsulates the common pattern of iterating a bit mask, and taking some action on the set bits. So this: for i in 0..64 { if is_bit_set(mask, i) { do_something(i); } } using your crate, could become this: for i in mask { do_something(i); } This is pretty clever, although I think you could do it almost as elegantly just using filter() and map() - like this: (0..64).filter(|i: &amp;usize| is_bit_set(mask, *i)).map(|i| do_something(i)); As for your code, it looked fine to me, but I'm still just a Junior Rustacean. :) 
Oh, it's just a couple of hours, not much of a pain at all :) I have to thank you for making this fine library. It's one of the reasons that convinced me to try Rust (i.e. The API ergonomics is miles ahead of `libdwarf`). As for the code, you can find it [here](https://bitbucket.org/paradoxiology/raid/src), gimli related code is in `src/program/dwarf`. It's an extremely simple Linux and x86-64 toy debugger just for fun and giggles, not meant to be used by anybody... The front end is completely unfinished, so probably the only thing you can do now is to run `cargo test --lib` if you ever want to run it, it does contain quite a bit of integration tests though. But even then it may still be broken, as I've only tested it on my 4-year old Linux Mint distro. It's mostly just a vehicle for me to learn Rust, ELF, DWARF, ptrace, and debuggers in general. Back to gimli, I'm fairly happy with its API so far, though the interfaces to do debug_info traversal (i.e. `EntriesCursor`) and `AttributeValue` extraction (Starting from a DIE, one needs to unpack many `Result`s and `Option`s, etc... to get to the value you want) can be a little awkward to use; the documentation can be a little hard to decipher some times, but I attribute that to the inherent complexity of the dwarf standard itself... Thanks for the heads up for `Expression`, I did have some experimental code stashed elsewhere to do my own DWARF opcode evaluation, but I guess less code to maintain for me the better. Anyway, thanks again for making the library available! 
Rc is about safe sharing without dangling references and has nothing to do with thread safety. You don't *have to* wrap it in an Rc, it's just the cheapest alternative most of the time.
This reddit is vor The Programming Language Rust, you may be looking for /r/playrust. Btw, if anyone else is confused by reddit's new "report" dialog, you now gotta select "It breaks r/rust's rules", then click "next", then select "Wrong Subreddit", then you can finally click "submit" and close the dialog with another click.
No. NLL specifically *has to have* no observable runtime behavior changes. The destructors would stay *where they are right now*. To change where destructors run we'd need a way to mark `Drop` impls as non-side-effectful. Perhaps `const fn drop`?
&gt; At least it's namespaced by trait/type but still massive. .. and the name spacing doesn't always help search, you still need to know which trait/namespace to look in, the traits are an extra dimension of names to learn..
Arguably the ergonomics around it in rust are much better, since the type system was designed with sum types in mind, instead of Java, where they were bolted on decades after the languages was created
A ton of security bugs are caused by memory safety errors in code written by expert C and C++ developers. The problem with such bugs is that it takes only one of them to cause catastrophe ala Heartbleed.
That's the right move, IMO. You'll be able to focus on solving your problem instead of fighting a framework.
Rust's 'lexical' borrows currently last to the end of the statement or block, and`if let` is a block. 
I don't think anybody's trying to mess with HTTPS traffic though.
Sure. But fixing those bugs when they eventually get detected may still take less time than writing code in Rust.
But... it's not possible to do anything to alter content going through HTTPS, is it?
`impl Trait` would have been a big confidence boost for me trying to push Rust+Tokio for a web gateway project we had at work, but alas Go won out. I was definitely concerned that the error messages would not make Rust look very good. The tech lead was also concerned about the lack of other companies talking about using Rust for http stuff in blog posts, which is understandable from his perspective but frustrating. Hopefully in 6 months time the situation will look better on the http/asyncio front. Thankfully I've now found a job in Rust thanks to a meetup and an excited CEO, but it's more related to binary file decoding than more general web dev.
Generally when you call mmap the kernel doesn't even really allocate physical memory yet, the virtual pages you allocated all point to a system-wide physical memory page that contains only zeroes (and that's assuming it's even bothered to update the page tables yet). When you try to write to your mmap'ed page for the first time it will trigger a page fault and the kernel will *then* allocate a physical page and update the page tables before resuming your program. 
I agree that Rust feels nicer than Java, but so does Kotlin and Scala.
To clarify, because OP didn't, Position `fread` reads blocks of bytes from a file. So imagine `ReadValues&lt;T&gt;` like `Read` but with a `buf: [T]` parameter. 
Personally, I'm interested in using Rust as a way to move into lower-level programming, or at least applications that are more concerned with correctness, performance, and security than your run of the mill web business, so what you found sounds like a good thing! I agree with you that Rust cannot realistically compete with Go for code involving the HTTP stack for at least another 6 months. It will absolutely require async/await, fully-featured impl Trait, 1.0-level hyper/tokio/futures, and probably even a 1.0-level web framework. And all that is just to be eligible to _compete_ with what Go already has. It'll take longer than that to win any mindshare in that space.
this is my understanding: the iterator is returning each element as `&amp;T` where `T` is the type of the elements in the backing store, in this case `&amp;str`. Thus, `&amp;&amp;str`. This is because just returning `T` would require removing the element from the backing store entirely, which is usually undesirable, and not possible with a simple array like that.
Follow the docs. You're passing `&amp;["hello", "world"]` to `test`, which means `I` is `&amp;'a [&amp;'static str; 2]`. It's only constraint is that it implement `IntoIterator&lt;Item = S&gt;`. So, open the docs for [`IntoIterator`](https://doc.rust-lang.org/std/iter/trait.IntoIterator.html) and look for an appropriate implementation. There's one for `&amp;'a [T; 2]`. In this case, `T` would be `&amp;'static str`. Sadly, it doesn't list the associated types. So, follow the link to the page for [the primitive array type](https://doc.rust-lang.org/std/primitive.array.html), and look for the `IntoIterator` implementation there. Scroll down enough, and you'll find `impl&lt;'a, T&gt; IntoIterator for &amp;'a [T; 2]`. That block *does* contain the associated types. Specifically: `type Item = &amp;'a T`. Now, in the generic parameters for `foo`, you said: `I: IntoIterator&lt;Item=S&gt;`, so that means that `S` is `&amp;'a T`, where `T` is `&amp;'static str`, which means `S` is `&amp;'a &amp;'static str`... or without the lifetimes: `&amp;&amp;str`. As for the deeper why: because you can't move out of an array, so it can't be anything else.
`pure fn drop`
https://github.com/rust-lang/rust/pull/43422
&gt; impl&lt;i32&gt; Foo for Vec&lt;i32&gt; is not talking about a vector of integers! Dang, that's really hard to read correctly. I kinda wish type variable names were more strict than an identifier now. At the very least shadowing should be disabled.
[Don't worry, Clippy's got your back](https://rust-lang-nursery.github.io/rust-clippy/v0.0.150/index.html#builtin_type_shadow)
You could very easily generalize the `std::io::Read` trait so that it reads data other than `u8`. (I think that generalization should be in the standard library, but it's not there yet.) However, there are some complications with using it. You need to create your buffer somehow and in safe code that pretty much requires initialization with a known value. let mut buffer = vec![T::default(); BUF_SIZE]; This calls `clone` to create new values. When values are overwritten Rust will call `drop`. Plain data (doesn't contain pointers or handles to outside resources) will have the `Copy` trait and thus trivial `clone` and `drop`; otherwise be careful of the side effects. (Like, I dunno, opening /dev/null four thousand times.) There is work ongoing on "placement" - a generic way to handle situations where the caller allocates memory and callee initializes it. I'm not up to speed on it. 
Alright, I see. Is it still a "man in the middle" though, when the client is compromised already?
What about this? https://play.rust-lang.org/?gist=11ebc0c63312ec6f81b3605294410d46&amp;version=stable I usually think of the zip+iter_mut as the best way to copy through iterators.
But by then it's too late; your company/customers might have lost a ton of money. Better to prevent the errors right off the bat than to clean up expensive mistakes.
As for actual solutions, [take a look at this.](https://play.rust-lang.org/?gist=0b856f03ca8822f34b58c03e2e5926cf&amp;version=stable)
Somehow I expected `return x;` to be equivalent to `x`, but after some thinking I see that this would only be so when it's a statement on the outermost scope of the function, it's still rather annoying. (And if this is working as intended in rust then it's still a bug, not in the compiler but in clippy)
Fintech seems to be one thing where it is becoming appropriate...but Honestly, give it time. Rust takes a while to creep in, and Erlang didn't get much love till elixir came along either
Rust is still crazy young. Two years stable. I won't expect any kind of market for rust developers for another 5. Go is something like 10 years old now, and it's still a relatively niche language, only in the last few years (from what I've seen) getting a real market behind it. Week to week I really, really do not expect the job listing to change much. I think it's actually an incredible testament to the language that we ever get job listings.
I believe your last Version will be the same as the two above, when Compile time constant evaluation is implemented.
What is an elegant conversion between `Vec&lt;u8&gt;` and `Vec&lt;u16&gt;`? `fn u8_into_u16(bytes: &amp;[u8]) -&gt; Vec&lt;u16&gt;` should fill the last byte with zero if `bytes.len()` is odd. The other way around I'd use this: ``` pub fn u16_into_u8(words: &amp;[u16]) -&gt; Result&lt;Vec&lt;u8&gt;&gt; { let mut bytes = vec![]; for w in words { bytes.write_u16::&lt;LittleEndian&gt;(*w)?; } Ok(bytes) } ```
yay I was loosely involved in the qotw
Honestly Rust should not even have been a consideration. This is an area where Rust is far from competing with anything.
We aren't talking about places where nullability is needed; we're talking about places where people are *idiots.* :p
&gt; and Erlang didn't get much love till elixir came along either There has been more jobs available for Erlang all over the world then programmers to fill them for at least 10 years. 
[Woah](https://play.rust-lang.org/?gist=fdeeacb262f203ed3f92f677a6c63b7e&amp;version=nightly)
Know your purpose and audience. If the intent is just to make them aware of Rust, don't go on a needless diatribe. On the other hand, if you're advocating Rust's fitness for a particular purpose within your company, you have to contrast it with alternatives. I'm preparing a presentation myself, and I know "Why not Go?" is a question people are going to ask.
If we want to court industry heads, we're going to have to use their terminology. These are clearly _smart borrows_. OIBITs are _smart traits_, and generic associated types are _generic associated types_ (that's already a really good name).
Rust hasn't found a niche. The best the community team can do IMO, is expose more people to Rust in the *hope* that one of them will establish a niche, but that's an organic thing. Moreover, I suspect that subareas interested in non-garbage-collected, strict languages are magnitudes smaller than the typical webapp/fullstack/server space and more conservative to boot.
It's coming: it will show associated types in a future version. (It's at least in nightly now).
&gt; Go is something like 10 years old now, and it's still a relatively niche language, only in the last few years (from what I've seen) getting a real market behind it. What...? Go v1.0 was released in March 2012. It is a 5 year old language. &gt; Two years stable. I won't expect any kind of market for rust developers for another 5. This is so pessimistic. Rust *needs* to have a market in the next 2 years or it is unlikely to *ever* have a market. Go was able to do this in possibly 3 years from when it launched, and it is now cemented in the market. If Rust waits until it is 7 years old, everyone will have forgotten about it. Have some urgency! I think Rust is amazing, and the last thing I want is to see it die on the vine.
Wow I thought go was significantly older. Either way, I just don't expect a lot for a while. I guess another year or two.
&gt;RON is a pleasure to read and write, especially if you have 5+ years of Rust experience. :D
Cargo uses github.
It isn't really necessary to use the NRF SDK scheduler for concurrency even if you use parts of the existing SDK and soft device. For example, the FreeRTOS examples in the SDK basically substitute the FreeRTOS scheduler and tasks for all the user timer and event/call back machinery. You could check one of those examples (in the SDK/examples directories) for a model for how RTFM might hook in.
Fintech and Rust go together so well that I'm pretty surprised we haven't seen more activity in this 'space' (perhaps it is just being kept under wraps). Fintech reinvents itself every 5 years and the latest high-performance iterations have settled on a borked form of event-sourced Java where they turn off the GC and rely on with mem-mapped messaging and off-heap allocations. It's just horrible. Anyone using Rust could clean up. (Why yes, I have been thinking about this...)
Amethyst does not (yet) have GUI support, but that's something I want to work on soon. Not sure if you can use Conrod with it, because I don't think Amethyst currently exposes the gfx encoder (which Conrod needs access to). It is currently under heavy development and many parts of it have been rewritten since 0.4. So the answer is probably: I can give you my (obviously biased) recommendation for Amethyst, but not for using it right now. Let's see how far we've got in a few weeks, ;)
Are you going for cross-language usability, like JSON does? I ask because it seems like a big advantage of JSON for that is it has only arrays and hashmaps for data structures.. Whereas RON requires a host language to support maps, tuples, tuple structs, enums (real enums, not C enums), _and_ structs. P.S. If I were you I'd put a code sample in the blog post.
&gt; Aren't they both going to be translated to something like: cmpxchg anyway ? (Or whatever the arm equivalent is). What's the difference in terms of code generated ? You are correct. &gt; Or is it just for the cleaner interface ? This. &gt;Hmh, maybe I'm wrong on this one, but as far as I know the most common place for the kernel to do a ctx switch is when a thread makes a sycall Okay this is a deep rabbit hole. I'm going to skip all the pooling and thread local magic `jemalloc` does behind the scenes, it keeps per NUMA node pools of memory so small allocations don't require system calls. So `mmap` is an _extremely_ fast call. All it does it mark that your process _needs_ memory, and the address it _needs_ this memory at. And returns a pointer to that space. When first you read/write to that address your CPU enters the _exact same path_ as a `SIGSEV` for illegal memory access (on a hardware level). The kernel catches this hardware exception to see that it in fact _gave_ you permission to use that memory. So the kernel _finds_ a physical page, and updates your process's hardware TLB so the CPU doesn't throw a fault when you access that memory. The write is stored in hardware, so when execution resumes the write succeeds. The whole point of this is the vast majority of programs when you allocate you _don't immediately use all_ the memory you mapped in. Also updating the TLB requires flushing the TLB L1/L2, and the data L1/L2 (as you can only cache data you've cached its TLB entry for). This is _slow_. Also when you build a 16MiB array, that you only use _sparsely_ you may not actually need all 16MiB of physical memory, so the kernel only has to allocate maybe 2MiB of sparse pages that you've ever hit at runtime. You can change this behavior with the [`MAP_LOCKED` flag](http://man7.org/linux/man-pages/man2/mmap.2.html) on Linux which prefaults the page (ensures it is backed by physical memory before `mmap` call returns). This also lowers the priority on your memory being swapped to disk. [See this doc and attached articles](https://landley.net/writing/memory-faq.txt). That is _everything_ you've ever wanted to know about memory in Linux (literally). Generally you are only rescheduled on IO, or Futex's blocking.
Glad it uses serde. I hope it catches on. &gt; if you know a better format, tell me! Maybe not better, but have you looked at [EDN](https://github.com/edn-format/edn)? It ticks most of the boxes. 1. structs and maps are different 2. field names can be eg keywords 3. keywords instead of enums 4. commas are optional 5. comments are allowed In addition it can be extended by using tagged literals. EDIT: the example json in EDN: #myapp/Scene { :materials { :metal {:reflectivity 1.0} :plastic {:reflectivity 0.5}} :entities [#myapp/Character {:name :hero :material :metal} #myapp/Character {:name :monster :material :plastic} ] ; keywords used for the values - mimics enum }
I agree. AIUI, Erlang has existed in the telecom industry for decades, where it has served a critical role. Elixir just helps startups use it for quick, one-off prototypes, and the occasional serious application. I think it's obvious which use case I consider more critical.
I assume you can omit the `#myapp` with the right flags passed into the deserializer? That's how YAML works.
How's performance? 
Works like a charm! I can also skip the collect step by zipping an iterator rather than vector. Clever use of zip. I'm used to `zip`from python which can't be used for mutating a structure. Copying your code for posterity/searching: fn main() { let mut v = vec![1, 2, 3]; let mut v2 = vec![4, 5, 6]; { let mut slice = &amp;mut v2[..]; drain_into_slice(&amp;mut v, slice); } println!("{:?}", v2); } fn drain_into_slice&lt;T&gt;(src: &amp;mut Vec&lt;T&gt;, dst: &amp;mut [T]) { for (s, d) in src.drain(..).zip(dst.iter_mut()) { *d = s; } } 
I was talking to someone from Erricson a few months ago, they said that a lot of the Erlang code was phased out for C.
Sorry, I think that's my fault. I published some of my code and I suspect that crates.io tried to quarantine itself.
I mean, really it's like neither. Rust is more like functional languages, but it's a systems language which is where the "like C" aspect comes from. C has very few features so all systems languages are like C. But in terms of how programs are structured it's like neither.
As far as I see it, you can always ignore the semantics if it's not applicable, but you can't get new semantics where you need it. As such, if a language only knows about heterogeneous maps and lists, it can simply treat structs as maps and tuples as lists. There should be no problem here. I'm not particularly interested in conquering the world with RON. It's made for our community needs, and it's already making me happy. The world has [hundreds of formats](https://en.wikipedia.org/wiki/Comparison_of_data_serialization_formats#Syntax_comparison_of_human-readable_formats), and people can be rather opinionated about them (including myself!).
In my opinion, that's likely because it's increasingly difficult to hire Erlang programmers. People these days seem to learn C, C++, Java, Python, JavaScript, and maybe some C# and decide that's all the learning they want to do. Erlang lends itself to creating fault-tolerant, distributed, parallel systems that are relatively high performance. If you tried to write those same systems in C, it would be *really* scary. With the increasing amount of cyberwarfare going on, the last thing we need is safety-critical systems that are written for *peacetime* operation, which is what C code generally is. It's generally not hardened against a malicious attacker, but sure, it performs slightly better than Erlang would, as long as no one is attacking you. Maybe I'm wrong. I have been known to carry some interesting opinions. Personally, the Erlang syntax just happens to make every choice I dislike most, so I can't stand it. I'm sure if I worked on an Erlang project, I would learn to appreciate the syntax, but for now, I *strongly* prefer the syntax choices Haskell made, for example.
&gt; RON aims to be a superior alternative to JSON/YAML/TOML/etc, https://xkcd.com/927/ Sounds very interesting though. Thanks for sharing!
Looks like a Clojure Program Notation ;) The format is interesting. Syntax feels rather alien to me, and I don't yet understand some of the design decisions (list versus vectors, nil, white-space dependence). Thanks for the link!
This is when I had to check if I was actually in /r/rustjerk. 
Nah, I already spent that meme on [Mint](https://github.com/kvark/mint/blob/master/README.md) :P
Well, like I said, they weren't disinterested. They were definitely interested, they just didn't understand why they would use rust because they don't use low level languages. Thanks for your input, of course.
Erlang is present in Nokia, Goldman Sachs, AOL (ad platform), Amazon, bet365 (completely Erlang based), WhatsApp (before facebook completely Erlang based) and a ton of other less generally known companies. It has a diverse set of users and a healthy community. Telecom industry was just the origin of it.
It did come out of the Clojure community, AFAIK. The first time I saw it was when the Datomic database was released, but I'm not sure if it originated there or if it already existed and the datomic people just used it
You had me at "trailing commas"
Yeah, I think that was the big reason they cited. It's unfortunate.
Want to discuss partnering up via PM?:-D
[Run translation and LLVM in parallel](https://github.com/rust-lang/rust/pull/43506): Michael hard at work at making rustc faster! I wonder if the expected speed-up is noticeable?
Yeah, Hickey wrote the spec and cognitect developed it.
https://docs.rs/futures/0.1.14/futures/task/index.html is the module you'll want to look at. High-level summary, the reason you run Futures from an event loop or via wait() is that a future's execution context is augmented with the concept of a "current Task". Any Future's poll() method can then retrieve a handle to the current Task and save it in a suitable location, arranging for somebody to call Task::notify() on the handle once it's ready for the event loop to give it another try.
Apologies if it already has this, but the notion of a lowering of RON into JSON, maybe with and without the proper metadata to losslessly round-trip. 
Getting safe tools into the reversing community is great! Exploiting security analysts is a thing. Next item, a pure/safe Rust version of `strings` command.
How will https://github.com/rust-lang/rust/issues/42524 affect `tarpaulin`?
This might ease the pain: I do Elasticsearch for a living. I've used the project since version I guess I'm not telling secrets, but it's a really hyped, successful and widely used database. I'm using it production since 0.13, released in November 2010. It's been only until last year where I started seeing a substantial amount of job postings hiring or searching specifically for Elasticsearch work, a recruiter even flat-out told me that it's the first time they hear of it. The reason is quite simple: Adoption usually happens inside companies first. Then structures build, but most people know each other, so there's rarely formal job postings. Formalised postings come relatively late. Finally: all sponsors of RustFest are searching, I'm surprised the postings aren't making it here.
Rust is 2 years stable and pretty far for that. Many major players have Rust software standing around. It's used in large-scale software. Heck, Ruby found widespread adoption when it was close to a decade old, this is no reason to be bitter. Convincing people to move to whole new world (a new language) is hellish hard and Rust is doing really fine there.
I _think_ you can omit the namespace, but I'm not an expert. The developer already evaluated and rejected YAML.
&gt; This is so pessimistic. Rust needs to have a market in the next 2 years or it is unlikely to ever have a market. Go was able to do this in possibly 3 years from when it launched, and it is now cemented in the market. If Rust waits until it is 7 years old, everyone will have forgotten about it. Have some urgency! I think Rust is amazing, and the last thing I want is to see it die on the vine. I agree that a sense of urgency helps, but I don't agree with the 7 years thing. Languages chugging along in a niche for years until they get a larger platform isn't unusual.
I hunch that WASM might be a place where Rust could really sink in, with a little effort in that direction. Wasm is a greenfield, so no incumbent to try to replace, and for the next who-knows-how-long it's essentially off-limits to GC'd host languages. There might be some push to move existing C++ monoliths to it (Adobe CC and Unity come to mind as strong candidates), but there's nothing that makes *new* development in C++ wasm particularly easy. In contrast, having a strong set of crates up on crates.io would make Rust uniquely positioned for getting going quickly and that might be enough to stake out a claim in the space. On the negative side, it seems like Rust has had a rough time on the front-end. I'm assuming this has to do with Rust's weakness with OO which matches well to the domain of GUI toolkits and such. I know there was some talk of addressing this with "virtual structs" or something, but it seemed like there was a bunch of noise on that front for awhile and then it fizzled out (which surprised me, since I was under the impression that this was a big ask from Servo). Hopefully I'm just wrong on that and it's been moving ahead behind the scenes since I'm not sure how long the window of opportunity here remains open.
Well, my goal is to be thread safe there, so it's easy to clone it have multiple listeners within the same process.
Hard to say, it could be anything from being an alternative to tarpaulin to making it obsolete. However, any competition is good and I hope I can offer something that sets tarpaulin ahead in certain use cases. I've also got a lot of things planned so if I keep up momentum and motivation it shouldn't render it obsolete
I'm inclined to agree with your points on WASM. I don't think that non-OOP languages are by any means incompatible with front-end programming, but there certainly needs to be some careful thought into how we can structure ergonomic frameworks for these types of applications - especially if we have to try and win over JS programmers.
Think you'd be able to whip up an example of code that's giving you trouble on https://play.rust-lang.org/?
I don't know if you already had a look, but I started with [the Rust book](https://doc.rust-lang.org/book/second-edition/). Rust is not the kind of language I was able to pick by _just_ practicing. I had to read the book to understand some essential concepts like ownership, generics, or the trait system. You need to grasp these concepts to even be able to understand the documentation, I think. Edit: For your specific issue with Duration, can you share the code on the playground? https://play.rust-lang.org/
`.as_secs()` seems [to work for me](https://play.rust-lang.org/?gist=48f972d0aeba04f9016c4781a8d5f1fc&amp;version=stable). Perhaps you're using [`chrono::Duration`](https://docs.rs/chrono/0.3.0/chrono/struct.Duration.html) instead? In that library, the function is `.num_seconds()`.
Decided to take care of this so we don't forget even though SOME people ALSO are authors of the book HINT HINT.... wdyt of this change, /u/definitelynotpietro ? https://github.com/rust-lang/book/commit/18bd498554d37254ac037919c09ef3c826dd275a
I think references (and circular references) are another problem of JSON that is often brought up. YAML attempts to solve it, but probably it can be done better. Do you plan to support references at some point?
That's what `const fn` is. The arbitrary limitations are going away soon.
The [code](https://play.rust-lang.org/?gist=096453d13258c17689cdaab98dbbe841&amp;version=stable) from the docs works for me so can you give us an example as FenrirW0lf also suggested where your specific problems occur?
thank you, I will definately have a look at that book. I solved the problem in the meanwhile with completely re-writing it. Turned out, I only needed std:time:Instant to make it work. I'm not 100% sure, but I guess there was some mixup of code from stackoverflow which I tried, and the code from the doc.
thanks, I solved it in the meantime. See above :)
I don't know yet, we are [discussing](https://github.com/ron-rs/ron/issues/11) this.
What happened to Arena/TypedArena in the standard library? The last version I can find it listed in the documentation for it Rust v1.1.0, but I see pull requests related to arenas much more recently.
Unbounded variant is slightly slower than `mpsc::channel()` (up to 10%), which is already very fast. Bounded variant is 4 to 10 times faster than `mpsc::sync_channel(n)`, depending on how many concurrent threads are working. Of course, take these preliminary numbers with a grain of salt - this is just what I got from several simple benchmarks. :)
I've heard that fintech is very interested in crates like Crossbeam due to the focus on low-latency and highly-concurrent computing. As a Crossbeam developer, I'd be very curious to hear how we can help in this area. Is there anything in particular you wish the crate offered?
Please, don't do this. The idea sounds ok, but the code is impossible to understand, only basic usage (use &lt;member&gt; for method,method,method) is intuitive. Leave this to IDE.
Could someone explain why this is? Where exactly does the scope of `val` end and why is it too soon?
&gt; Go was able to do this in possibly 3 years from when it launched, and it is now cemented in the market. I think one major factor is that Go was pretty amazing for web/server stuff from 1.0, and there's a lot of companies doing work in that space. It's a lot harder to get market share in the niche that Rust currently excels at.
We use Haskell at work (FinTech) but I'd love to use Rust now that we're hitting performance issues when clients do things with 30 years of data -_- highly doubt that would happen though.
Still working on weld, my gui library. Still very basic, but you can now define a tree of components, interact with them and have an event handler return a new tree which is then rendered. Next up is getting this to work for partial trees so as to not rerender the entire gui :)
it's internal to the stdlib. A version users can use is published here https://crates.io/crates/typed-arena
The idea is very good, but you're not alone finding parts of the published RFC very difficult to understand. I've started refactoring it, but I need help. Don't worry, the lang team will not accept any proposal that makes code more difficult to understand. 😀
You probably should at least add a link to the original comic, even though everyone knows the author it should still give credit to him.
&gt; the lang team will not accept any proposal that makes code more difficult to understand Idk, I'm still not totally sure about some of the sigils, such as `?` and: match thing { val @ 1 .. 10 =&gt; (), _ =&gt; (), }
Nice work! Two minor points: "Porting" generally refers to converting all the source code to a new language rather than just creating bindings as you have done. &gt; UPDATE: later I figured out, that actually without #[repr(C)] Rust optimizes memory and uses 1 byte for Lang enum. So uint32_t can be replaced with uint8_t. It should work as far as number of enum variants does not exceed 256. Be careful: without a `#[repr]` attribute of some form (even one of the fixed sized ones like `#[repr(u8)]`), it is undefined behaviour to expose the enums to C. In any case, `#[repr(C)]` is designed to reproduce the behaviour of C enums in Rust, and I believe that the enum's source can be copy-pasted between languages and it will behave the same, I.e. one can write enum whatlang_lang { whatlang_aka, ... } Instead of the long series of `static const`s.
&gt; It's best to measure these things. My guess is that performance will degrade as you add more threads due to those occasional bad preemption "hiccups", but I could be wrong. By the way, if the current thread cannot make progress after several retries, it's a good idea to call std::thread::yield_now() in order to deschedule it and make the whole system run more smoothly. Again, I'm not seeing the part of the code where I could or would be allowed to do that. I'm not spinlocking. The queue's method receive a call that is either instantly rejected or allowed to do the operations needed to add/remove elements and than finished. Are you referring to the tests rather than the code itself ? Because those test, I assure you, aren't supposed to showcase and intended usecase, they are designed that way to overload the thing more easily and load it in a predictable way with predictable values so that I can more easily spot potential bugs. &gt;I'm worried that e.g. a reader thread will do data.read_position.load(Relaxed) and load a fresh value, but self.next_pos(data.write_position.load(Relaxed)) would accidentally load a stale value. OK... I've reached this point and I'm quite sure that either: a) I don't understand my code or b) You haven't read it or haven't understood it... which means I should document it better. There is not concept of the writer loading a 'stale' value in the enqueue method or the reader loading a 'stale' value in the dequeue method, or rather there is, right at the beginning, and that possibility is accounted for with the cas that kicks out any second reader/writer thread with a 'Busy' return code. Afterwards the values of the reader/writer can only be modified by A SINGLE THREAD, which means they can't really be 'stale'. The problem you are thinking of would happen when multiple threads could be modifying the same variable, which is not the case here, since both those methods are executed in a single threaded context after the initial if. Does that make sense ? Think of it this way: If I replaced all ocurances of the 'w_next' variable with 'self.next_pos(data.write_position.load(Relaxed))' the code would not change it's meaning a single bit (Would be harder to read though... hence why I use said variable, the compiler probably optimizes it out actually). It a mutlithreaded context that is not true, but the instruction generated by enqueue are guaranteed to only be executed by a single thread after this block of code: if can_write { return ReturnCode::Busy; } Does that make sense ? Is my logic flawed anywhere (I really doubt so, because if what you are saying is true I assume this thing would have broke while stress testing it)... not to mention, I see my reasoning here as logical, multi-thread code is hard to reason about, true... but the beauty of this design is exactly the fact that for the most part the blocks of code are actually single threaded and there can never be more than one thread modifying any variable other than the internal buffer. 
I am mostly interested in bounded ones for `slog-async` (where i want to offload logging records to separate thread as fast as possible). Awesome.
Was `val @ 1 .. 10` added after the lang team was formed? I thought it was in Rust 1.0...
I actually don't know, I thought it was post 1.0. It's been there for a while though. My point is that we shouldn't rely on the lang team to make those decisions since they're human and are thus liable to make mistakes.
Oh wow... I think Rob Landley might become my new Robert Love :))... thank you for the link to the article. Also, whilst the subject of allocation might still be a bit beyond me when it comes to its intricacies on various architectures and kernels... I still would like to stick to the general rule of not allocating for fixed size queues when it can be avoided. It's just a good practice in general and for this specific design I don't think allocation would help. Of course... once I get to the dynamic size of mult-writer friendly model allocation will be a must, but for now, I feel like this version is quite simple and fast (well, at least the C++ version is, I still haven't gotten any better at figuring out why this version is so slow comparatively ... :S)
&gt; Declaring `T` as a generic type after the `impl` is how Rust knows the type in the angle brackets in `Point` is a generic type rather than a concrete type. That should do it. Cheers!
"Port" is the wrong word here; porting to C would mean rewriting the library in C. You're "writing a C FFI", or "exposing to C", or "creating a C binding". So far as I'm aware, nothing guarantees how an `enum` is represented in the absence of a `repr` attribute. If you want `u8`, *tell* the compiler that: `#[repr(u8)] pub enum Lang { ... }`. At that point, you don't need `transmute`, just `lang as u8`. Oh, and *don't* use `transmute` to turn a `u8` into a `Lang`. Unlike in C, it is illegal for an enum value to ever contain a value it wasn't defined to have. Also, that `whatlang_detect` argument should be `char const *text`. And you *should not* map `struct whatlang_info *` to `&amp;mut Info`: C allows null pointers, Rust does not. The Rust side should be `*mut Info` with an explicit check for null. Really, you should write the interface to be *deeply suspicious* of any and all data coming from not-Rust. Otherwise, you can't rely on the guarantees Rust normally gives you, because no one is enforcing them. As an aside, you need to make sure you document in the binding that strings accepted by the library must be UTF-8. For `whatlang_lang_code`, instead of taking a raw `char *`, I'd recommend taking a `struct whatlang_name *` which contains a `char [30]`. That way, callers are less likely to get the size of the buffer wrong, and it's no less efficient. It's also just occurred to me, but: the reason `#[repr(C)] enum Blah { ... }` is 32 bits is because that's what an actual C `enum` is on your machine. If you use `#[repr(C)]`, you can use `enum Blah { ... }` in C directly, rather than a loose collection of constants. There's another way of returning a structure: *just return it*. You don't *have* to put it on the heap or behind a pointer. There's no easy way to do full Rust-style enums in C. The closest would be an explicit tagged union... but returning an error code with the result written through an out parameter is probably the most ergonomic for the C side of things.
I think this is a good solution: https://play.rust-lang.org/?gist=86143892526a4c15b98b157ce14607c7&amp;version=stable
React+redux with stateless components is a basically pure functional implementation of a gui. It's the best JavaScript experience I've ever had. It's modeled after the elm architecture, which *is* a pure functional implementation of a gui/FRP framework in a functional language. Writing a rust implementation of the elm architecture that targets the web via wasm seems totally doable and would be *beautiful*.
&gt; even trailing commas! be still my heart
THis is also why `[T;n]` does not implement `IntoIterator&lt;Item=T&gt;` but `&amp;[T;n]` does implement `IntoIterator&lt;Item=&amp;T&gt;` Naturally since `&amp;[T;n]` has `IntoIterator::into_iter` called on it the items must be `&amp;T`. It would be possible for `&amp;[T;n] where T: Clone` to have `IntoIterator&lt;Item=T&gt;` in theory though.
I'd also note that if you want an accurate difference between times, the `Instant` type supports the subtraction operator with other `Instant` variables, and returns a `Duration`, [as you can see from the source and in the documentation](https://doc.rust-lang.org/src/std/time/mod.rs.html#245-251). impl Sub&lt;Instant&gt; for Instant { type Output = Duration; fn sub(self, other: Instant) -&gt; Duration { self.duration_since(other) } } 
I remember it being there before 1.0, just not well documented.
Please note, this is not the final version that will be proposed and voted on. We're still working on this and would love your help in making it better. @lxrec has [drafted a new version.](https://internals.rust-lang.org/t/3-weeks-to-delegation-please-help/5742/6?u=elahn) If this RFC isn't ready within 3 weeks, it will not be "rushed through." I have no desire to make Rust code more difficult to write/read and understand.
Not sure why you'd copy a string with `libc::strcpy` before returning it's pointer. You don't have to do that. In the documentation for `CString`, there exists two key functions for managing strings across boundaries: - [from_raw()](https://doc.rust-lang.org/std/ffi/struct.CString.html#method.from_raw) - [into_raw()](https://doc.rust-lang.org/std/ffi/struct.CString.html#method.into_raw) Basically, `into_raw` will `forget()` the string, and then return a pointer that you can send across boundaries. On the caller's end, they can use `from_raw` to obtain ownership of the memory associated with that pointer, and thus avoid a memory leak. The `from_ptr()` and `into_ptr()` methods are geared for use within your library and nowhere near boundaries. But you can emulate the behavior by first creating a pointer with `string.into_ptr()`, then `forget(string)`, and returning the pointer.
Find a project and try to stick to it. That's what I'm trying. It got me as far as learning that rust can be almost as flexible as C, since I started by unsafe porting stuff I had, now I'm "rustifying" it.
Wow, that is a lot of really good information! Is that all in the Rustonomicon? I've only read it once... a while ago.
How about a good concrete number definition. IE, not "Number" is the type for numbers and instead say "We have floats and ints" Forcing the parsers to say "If it is 1.0, it is a floating type. If it is 1000000000 it is an integer type". Json's "They are all doubles" standard is annoying to work with when dealing with languages that differentiate between the two. Especially when dealing with integers that over/underflow doubles.
Like, you've written a great explanation (seriously!), but at the same time, stuff like this will doom Rust to obscurity if it's not made simpler. Passing a string iterator to a method should be easy-peasy and Just Make Sense, and yet here we are in like Type Theory Hell. Stuff like this happens way too often for common cases.
Hi, I'm currently trying to do the [nth prime problem from exercism.io](http://exercism.io/exercises/rust/nth-prime/readme) where we calculate what the nth prime number is. For example the 6th prime number is 13. I made two versions: an iterator version, and one with a for loop. I noticed the iterator code took much longer, even though I think both should compile to something similar. Wondering if someone can tell me why the iterator code is slower, since I think it is a more elegant solution than the loop. Gist: https://gist.github.com/nocduro/5da083a83fb09d03adfb31cdff997dde I included the benchmark results at the bottom of the gist.
It has been in Rust for years, well before 1.0. Here's the history of the major test, you can see that while the tests were added here, the feature already existed; the tests were mostly to check that a bug was fixed: https://github.com/rust-lang/rust/commits/master/src/test/run-pass/match-pattern-bindings.rs
&gt; Because those test, I assure you, aren't supposed to showcase and intended usecase, they are designed that way to overload the thing more easily and load it in a predictable way with predictable values so that I can more easily spot potential bugs. Yeah, that's exactly what I had in mind. That loop is technically a spinlock: while ReturnCode::Done != queue.enqueue(n.to_string()) {} But I understand what you're saying now. :) &gt; Does that make sense ? Is my logic flawed anywhere (I really doubt so, because if what you are saying is true I assume this thing would have broke while stress testing it)... Hmm, it makes sense. I might have also worded my previous answer poorly. If all atomic operations in your code were `SeqCst`, then I think it's pretty clearly correct. We do agree here. If some operations are `Relaxed`, however, then things get much more difficult to reason about. In order to make sense of code with `Relaxed` operations, I try to look for two synchronization methods: 1. Pairs of acquire/release operations that would synchronize relaxed operations after/before them. 2. Atomic RMW operations (like CAS and `fetch_add`) that synchronize threads through a single value. This is what I alluded to in my previous comment. The bottom line is: Relaxed operations don't get synchronized on their own. You also need somewhere either acquire-release operations, or single-point RMW operations in order to synchronize them. Those are the two essential tools in my mental model for reasoning about atomics. Sorry if all this sounds very handwavy. Again, I find it difficult to prove that your code is incorrect. You do have acquire-release synchronization in those `compare_exchange` operations (they acquire the old value, release the new value, and are also sequentially consistent). This might be enough to synchronize relaxed operations around them properly, but I'm not totally sure.
@ was there before 1.0. It has precedence in languages like Haskell where pattern matching is a common thing. It's nice when you want to assign an expression in a match to the value. Not a common thing to really use at all but when you do need it it's great.
I've thought about implementing something similar within Ion. Just need to work out a good syntax for the `case` keyword.
You want to use take_while instead of filter. Filter will result in all of the primes being iterated even after one has been found whose square is greater than the target number. take_while will stop iterating once it finds the first element that does not follow the predicate.
Could have called it `RusON` (Rues - ahn) since it sounds like `JSON` :p
Ahh, thank you! I just changed it and it is much faster now, basically on par with the loop.
I was a bit surprised when I looked at TWIR today. I was scrolling down and suddenly saw the quote. It took me a second to realize, "Wait a minute... I said that! That's my quote!"
Type Theory Hell? I followed some links in the documentation and substituted `T` for `&amp;str`. This is effectively just basic algebra: looking up definitions and substituting variables. I can understand someone being unfamiliar with having to think this way about types and needing a poke in the right direction, but I thoroughly reject the idea that it's somehow fundamentally harder than just programming in general.
What was the problem/solution?
This was great. Thanks for sharing! :D
hate to be anyone named ron on search engines if this hits it big :D
The most important thing is to learn from the lessons of the past and avoid the mistakes in the JSON format. See: [Parsing JSON is a Minefield](http://seriot.ch/parsing_json.php) 
Although not exactly what you asked: remove the need for llvm. Write a gcc backend. Get accepted into gcc. 
https://github.com/cramertj/domafic-rs
Wow, great read! I didn't expect Json parsing to be particularly challenging. I suppose sone of the complexity comes from the fact Json tries to be a subset of JavaScript, which is not the case for Ron.
Note for OP, to get to this result on your own: First, figure out what you expect. You expect S to be &amp;str. From the error message, you can see that the compiler thinks S is &amp;&amp;str. So, what would lead the compiler to think that? The other bound on S is the I: IntoIterator&lt;Item = S&gt; requirement. Let's look at that. Figure out what you expect. You expect I to be IntoIterator&lt;Item = String&gt;\*, and you expect &amp;[T; 2] to satisfy this. Looking at the IntoIterator implementations [here](https://doc.rust-lang.org/std/iter/trait.IntoIterator.html), you can see there is an implementation for &amp;[T; 2]. Alright, what's Item, then? Well, if you click on &amp;[T; 2] you're taken to [here](https://doc.rust-lang.org/std/primitive.array.html). Scrolling down to the trait implementations, you see an IntoIterator entry. And the Item for that entry is **&amp;T**. This is why the compiler is complaining: the item type should be &amp;String, instead of String. This means that your function definition becomes: fn test&lt;S: Into&lt;String&gt;, I: IntoIterator&lt;Item = &amp;S&gt;&gt;(iter: I) {} The compiler complains about the lifetime of Item = &amp;S, so you add one: fn test&lt;S: Into&lt;String&gt;, I: IntoIterator&lt;Item = &amp;'a S&gt;&gt;(iter: I) {} Then it complains about undeclared lifetime, so you add one: fn test&lt;'a, S: Into&lt;String&gt;, I: IntoIterator&lt;Item = &amp;'a S&gt;&gt;(iter: I) {} Then it complains that S needs 'a too, so you add it: fn test&lt;'a, S: Into&lt;String&gt; + 'a, I: IntoIterator&lt;Item = &amp;'a S&gt;&gt;(iter: I) {} And now it compiles! *Actually, to be correct, you expect it to be Iterator&lt;Item = (something convertible to String)&gt;
Oh nice! I too am into week 2 of writing a gameboy emulator! If you get stuck I guess I might be able to help given I'm literally 1 extra week ahead of you? I've managed to [emulate the original Tetris up to the main menu](https://media.giphy.com/media/3o6vXMDx5rIt7cm4iA/giphy.gif) (it crashes after a while but sits there looping for abit... I think thats because the menu has an "idle screen" and my emulator crashes as that screen is about to happen). Good luck on your journey! :)
Cool. I think I've seen a couple other attempts at implementing FRP in Rust as well. I think that wasm is still a bit early (dom or js bindings are bad/immature?) for actual *web*-apps. The kinds of things that have been succeeding are apps that do everything themselves. That is, I *think* that projects are running into the fact that there's not much point in making a blazing fast dom-diffing engine if actually calling back into JS to reach the job incurs some sort of crazy overhead compared to JS. I am in no way confident that I'm right about that. As all the speedbumps get worked out (over the next year or two?) I expect it to become easy enough to write a good FRP library that someone will do it.
Great suggestion! I filed [an RFC](https://github.com/ron-rs/ron/issues/47).
&gt; if a language only knows about heterogeneous maps and lists, it can simply treat structs as maps and tuples as lists. There should be no problem here. This makes parsing from another language easy, but not serializing. If some Rust language expects a struct (and not a map), it may be trickier to serialize the data properly from, say, python.
&gt; because you can't move out of an array, so it can't be anything else. This is all one really needs to know. The rest of that was more like a proof.
ElectronicDesign seems to be of high quality, it previously reported on Rust and SPARK. Previous discussion is [here](https://www.reddit.com/r/rust/comments/66fs74/rust_and_spark_software_reliability_for_everyone/).
Which might just mean we need better documentation explaining Type Theory concepts themselves, and then further how they play out in Rust.
Good luck with your project anyway! I'm really interested in a good tagged replacement for JSON.
I'm working on a simple API to return some movie data (json) using Rocket and Diesel. As a fairly new programmer who works on a Rails app for work, rust is pretty difficult to wrap my head around. It's nothing like Ruby lol. It's interesting for sure. I'd love to pair with anyone who has more experience than me if someone is up for it.
Does it handle partial input? That's one of the things I like about Nom.
Get a stopwatch and measure the time it takes for your coworker who's an average JavaScript or like, Python developer to understand that block of text up there - like, experienced Rust developers forget just how hard this really is
There's really nothing in the Rust type system that was overly difficult for me to learn. That's not because I'm a genius, or I had five years Rust experience before I picked up Rust for the first time, it's just because I've had experience with similar type systems over the years. Where I didn't have relevant experience, I just kept reading and experimenting until I did understand it. If someone has only used dynamic type systems in the past, then *of course* they're going to have to learn new things to cope with a statically typed language. Just like someone who hasn't programmed before is going to have to learn new things to program in any language. This isn't unique to Rust.
I've wanted const trait methods many times.
Obviously if you have no experience with type systems, you have to learn the concepts behind them. Rust is very consistent, but you have to learn its rules (which are largely just general type system concepts). If you take the time to do that, programming becomes easier, because Rust can tell you when you do things wrong that Python and JavaScript can't really hope to attempt to address.
What would be cool, would be better suggestions in `match`: - "non-exhaustive patterns: type primitive::Primitive is non-empty" should offer a fix, that you just have to click on it and it creates the missing match arms. - Not yet covered variants of enums should be immediately available as completions when starting a new match arm. - Already covered variants of enums should not be available as completions when starting a new match arm. 
What if we had RON parser named "Swanson"... ;)
Personally, I have a similiar story (excluding the Go part, because I studied D instead). Rust does indeed feel quite overwhelming for someone without years of experience with C++, or the like. I come from a mostly-Python background and I was prepared for most things, but the borrow checker, lifetimes and generics are really making my head spin. Don't get me wrong here; I love what Rust is trying to accomplish and I'd definitely prefer using it over C++, but at the moment it has a noticeable learning curve. I'd love to see some sort of a collection with good, readable and well-documented example code outside of the Rust book.
Any way to integrate the RLS into my work flow with (Neo)Vim? I already use Deoplete for code completion along with Racer, but can't easily figure out a way to replace Racer with RLS 
I struggled and still struggle with it. I'm hopeful for the future though. For instance some versions ago you needed to add 'static to static variables (or were constants?) but now the compiler just does it for you, so you can very well forget about 'static. There is also a lot of thinking going to make the module system easy. I think in many aspects Rust is too complicated but its becoming simpler. Or maybe I want to believe so. 
Do you know of [rust by example](https://rustbyexample.com/)?
That is gnome builder! Awesome. Is this experimental or will this be in upcoming versions? EDIT: is not gnome builder
Yes, it just... I don't really know how to put this, but it feels incomplete
&gt; limiting cognitive load One way to look at the core features (ownership, borrowing, and the lifetime annotations that make those work, along with the generics system) is that they're limiting a different sort of cognitive load: they're making if feasible for us finite-brained humans to reliably write safe, parallel programs without a GC. If you're not needing that level of "power", then it probably doesn't actually feel like Rust is lifting any mental load, since it isn't, but if you are needing that, then it is very helpful. &gt; Rust's fundamental MO seems to be add features and complexity infinitely until it approaches the exact coordinates of the goal Until Rust, people didn't even really think that it was possible to have an industrially-viable, memory-safe language without GC, and I'd be surprised if removing any of the main features would leave a language able to satisfy all three of those constraints. That is to say, the core features are a finite, orthogonal set of things that are the "shortest path" to the goal. &gt; My take away was that if I need it, the compiler will yell at me and I'll hunker down and figure it out then. This is an insightful comment about Rust: it's how I write it. It's true that I've internalised the compiler rules, so straight-forward code will usually work, but I still make mistakes, especially once I'm doing something more than a couple of `if` statements and a loop or two. Fortunately, the compiler yells at me when I screw up, and I hunker down and figure it out. That is, it's perfectly fine to forget rules, because the compiler doesn't. --- On a different note: &gt; a dumb person &gt; I'm an idiot &gt; idiot me This violates our code of conduct: "3. Please be kind and courteous. There's no need to be mean or rude." Jokes aside, please stop beating yourself up about it, difficulties learning something almost always aren't the learner's fault, but demonstrate that the available documentation doesn't work for everyone, and still has room for improvement. It sounds like you're particularly having trouble with the module system and ownership? My experience is that once people click, they find the rules fit together well, but also that it is a very real struggle for people to get to the "click" moment. Have you looked at [the second edition of the book](https://doc.rust-lang.org/book/second-edition/)? Many reports I've heard is that the extra few years of teaching experience combined with dedicated editing have improved it a lot for many people. E.g. [the modules chapter](https://doc.rust-lang.org/book/second-edition/ch07-00-modules.html). (But, I guess throwing more reading material at you may not the most helpful thing at the moment... :) )
First of all you sound like a perfeclty smart person to me. Secondly rust has undoubtely a steep learing curve. This was the biggest painpoint identified in the last user survey and thus lowering the learning curve is the first thing on the [agenda](https://github.com/rust-lang/rfcs/blob/master/text/1774-roadmap-2017.md) for 2017. So while it is true that rust is going to get a lot of new cool features there is also a strong focus on learnability/understanability.
For crates.io libraries, there's also [the Rust cookbook](https://rust-lang-nursery.github.io/rust-cookbook/).
Your confusion about the age of Go is understandable. My understanding (without looking it up) is that it is based in their earlier work on Plan 9 and Limbo. It's not like Go just appeared out of nowhere--there have been variants of it in development for a long time, way more than 10 years even probably. Now, use of the language is kind of a different issue...
I think your best bet is [LanguageClient-neovim](https://github.com/autozimu/LanguageClient-neovim). I haven't tried it with Rust yet (right now I prefer the IntelliJ plugin over the RLS) but it worked fine with TypeScript.
Check https://www.reddit.com/r/rust/comments/6rx634/async_autocompletion_for_vim8_and_neovim_via_rls/, it appeared here recently.
Might as well distinguish between signed and unsigned integers, unless variable-length big ints are used. E.g. `+42` is a positive signed int and `42` is a positive unsigned int.
Thanks! I'll take a look. Though this means making quote a few changes to my vim setup. I'd rather not have too many competing auto completion plug-ins 
/r/playrust
Apologies for the violation - it's sort of in jest. I say I'm dumb to take a certain position that's hard to take in a lot of programming discussions where the winners tend to be the smartest ones in the room. The second edition of the book is the one I've been reading. I've just finished the 'IO project' chapter. A pretty difficult moment for me was having finished that, then reading ahead and seeing the chapter 'Advanced Lifetimes'. I dunno, something just hit me there that was beyond discouraging. My biggest struggle is less ownership (that's admittedly pretty simple once you get it) and more the module system with regards to the filesystem and how that interacts with testing and publicity. A lot of the book is well written, but some important points are a bit opaque ([see my recent question here](https://www.reddit.com/r/rust/comments/6s3g1p/hey_rustaceans_got_an_easy_question_ask_here/dl9xi8w/)). Agree on the point that in order to have sort-of-automatic memory management with safety without a GC requires some wonky, complicated features (and a lot of them) - ownership, lifetimes, etc. are all necessary for the language to fulfill its promise. But things like macros, iterators, things of that nature are (almost) bloaty and set the precedent for just chucking stuff in. As a former Django guy, I can tell you that there is such a thing as the Paradoxical Cycle of Convenience^tm and you can go too far. In any event, I'll try not to give up. The crazy part is every time I go back to Go now, I'm like, but there's a much better way to do things! If only I understood it well!
Good to hear that there seems to be a lot of awareness on unnecessary complexity. I spent most of today practicing module system stuff, so I hope they don't change it, like, really drastically, because I finally got my tests to work...
Search for the language client plugin, the readme has an example for using RLS.
Interesting, how `rls` and `rustfmt` should integrate with each other from IDE point of view? I mean when you typing it is good if IDE reformat your code on the fly according to selecting code style, but who should be responsible for this? Editor/IDE by itself (then they should reimplement rustfmt functionality), rustfmt as daemon (two daemons (rls and rustfmt)), or rls should use rustmt as library? 
Oh, that's great. I've decided I'll main this language and the IDE.
"Rust was started by Mozilla" I stopped reading there.
Well, the way I always think about this type of code is think: 'What operations could be going on right at this very moment ?' And think about how they could affect the line of code I'm currently writing. In this case however there's an even easier way to go about thing: Imagine that for every operations I do with Relaxed I'm instead just doing operations on normal variables, nothing atomic to see there, just the values w/o the atomic wrapper. Would that code be correct on x86 -64... the answer is yes, of course it would be. Than remember that on x86 normal byte aligned variables with &lt;= 8 bytes are the same as atomic variables when Relaxed ordering is applied to the operations... and voila. I understand that CPU re-ordering of operations can seem 'random' but it does actually guarnatee something quite important, that is the fact that no matter what happens single threaded code will appear sequentially consistent to the user... and in this case we're only talking single threaded code in the context when I am using relaxed. Those variables are accessed from other threads... to be sure, but in that case even if we read the 'wrong' value our penalty can only be delaying the read/write by reporting the queue is empty/full when actually that is no longer true.
I had a look at the `Result`/`Option` handling that you're doing, and I notice that when parsing attributes you're converting all the `Results` into `Options`, and thus treating errors as absence of the attribute. This works, but I think it's making the code more complicated than it needs to be. I don't think it makes sense to try to ignore these errors. The reason is that if there is an error parsing an attribute for a DIE, you'll never be able to parse any more entries after that DIE anyway. If instead you return early using the `?` operator (and then skip that compilation unit completely when there is an error), then the code for parsing the attributes should be a little simpler.
Thanks everyone for the answers, I now understand how and why!
deleted ^^^^^^^^^^^^^^^^0.6545 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/29616)
deleted ^^^^^^^^^^^^^^^^0.8286 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/58870)
I'm using this with neovim (and vim-plug) and it works like a charm. I'd also like to point out that [LanguageClient-neovim](https://github.com/autozimu/LanguageClient-neovim) is demoed using Rust support as an example ([GIFs](https://github.com/autozimu/LanguageClient-neovim/issues/35)), unfortunately it doesn't support yet Rust-specific progress update info (is the analysis still being processed) or passing additional config to the RLS.
deleted ^^^^^^^^^^^^^^^^0.1775 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/10562)
deleted ^^^^^^^^^^^^^^^^0.0664 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/96145)
I didn't even start reading after I saw that generic stock photo with the rust logo tacked on.
Advanced Lifetimes is not something that many people will actually need. You don't need to read &amp; understand the whole book to start building cool stuff. &gt; But things like macros, iterators, things of that nature are (almost) bloaty and set the precedent for just chucking stuff in. ouch. This one really hurts. Iterators are really cool to have in a language that is this low level. I'm not sure you have seen advanced C projects and its macro system. That said, most projects don't need macro's. PS. One thing to keep in mind ( that i wish someone had told me when i started :P) . Rust is about explicit costs and safety, not about doing the impossible. In my experience when trying to build a complex multilayer structure you will want to use a Rc instead of fiddling with lifetime's 
JSON's numeric type is actually a BigDecimal, though in principle it is a double if it's interacting with JS.
Depending on the level of abstraction, it's not wrong. The article is shallow. It strings together Rust's memory safety to immutable by default to Haskell and the ability to pass immutable arguments to etc... I would say the article lacks focus, glueing together buzzwords while glossing over the actual details almost like a Markov chain. It's not technically incorrect, just very general and shallow.
Wow, such HiDPI
deleted ^^^^^^^^^^^^^^^^0.1469 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/74189)
YES YES WE KNOW. You don't have to taunt us. The community is working really hard on cross platform gui frameworks 
interesting, how does it compare with intellij (i've been using that a little) .. would it be more accurate by virtue of using the compiler ? (I gather intellij analyse the source themselves) One (expected) limitation I found was that intellij can't find identifiers that you embed in macros.. given all the possibilities with macros I'm not sure how much is theoretically possible anyway. e.g. ```new_object!(ident1=&gt;ident2)``` expanding to some expression e.g. ```Box::new($ident1::new()) as Box::new($ident2)```... if you hit 'jump to def' on ident2, could you expect it to figure out that it is a *trait*, and jump to that trait definition ... given that the ident could have been used in aribtrarily complex ways in the most general case. Ditto 'jumping to a definition' created *in* a macro, would it manage to go to the macro invocation site (that's probably easier, and you could always get the macro def itself from there). I suppose visualisation of what macros generate would also be handy to have. I suppose the RLS could also allow browsing items that are defined in macros, e.g. they could still show up in the IDE UI ... that would be rather useful
deleted ^^^^^^^^^^^^^^^^0.4534 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/48292)
it s not that you lack the smarts, it's that you lack the patience :0 once you can walk barefoot (C), it's easy to learn to walk with shoes (go) but it will take time to learn to ride a bike (rust). but once you got the stuff down, the mental load significantly diminishes. 
I think there are three parts to your story: 1. How to learn complicated topics? There are tons of strategies and methods for learning complicated topics, look on google :). But, you want two things from your method: iterative learning and chunking. e.g. Don't create modules until you actually need to -- you can pretty far with stuffing everything into a single file. 2. The Rust book seems to be making one of the most common mistakes that I see programmers teaching -- it tries to explain everything when discussing X, instead of we'll learn X in later chapters. You can take a look at [Guessing Game](https://doc.rust-lang.org/book/second-edition/ch02-00-guessing-game-tutorial.html) as a good example of it. 3. Don't worry about being able to learn Rust -- you will be able to learn it. But, the question whether to use Rust, Go, C, Clojure, Ruby, Prolog, Haskell, OCaml etc. or whatever language... is more of a question what do you intend to write, what are your constraints and what features do you actually need. Every feature in a language adds flexibility in what you can write, but this also means there are more ways that the language will be used in the ecosystem. In that sense Rust and Go diverge philosophically -- one values flexibility&amp;safety over simplicity and the other simplicity over flexibility&amp;safety. Language flexibility allows you to make better trade-offs and language simplicity allows you to pick random package and understand/modify it more easily. Ideally you want both, but it seems they will always be in conflict. Go GC has awesome stuff and is improving -- but it will never be as fast as no GC. When you use a GC, you will need to pay the price. PS: keep in mind, you probably will be eventually using multiple languages, so worry less about the language choice and more about creating awesome stuff :D.
Rust has the 1.0 compatibility promise. You'll always be able to use whatever you learn now if that's what you prefer because, otherwise, it would break existing code.
I don't know what I could be doing wrong. Only autocomplete works. Jump to definition, hover, symbols e.t.c do not work for me.
Well, maybe you are not part of the intended audience of the article. The article gives an overview of Rust to an audience that does not necessarily consist of programming language enthusiasts. And mentioning Mozilla gives a kind of anchor the intended audience may be looking for, otherwise they may see Rust as merely someone's hobby project.
Rust is a bit weird. Here's what wasn't at all like how I learned it: *Read a Rust book cover to cover attentively. Form a mental model of how Rust works. Start programming in it productively.* How it actually went down is something like picking up the language, writing simple programs and looking up example code to see how it should work. Getting yelled at a lot by the compiler and trying to fix the problems by editing code. Running into design ruts where whatever I was trying to do didn't line up with Rust's constraints and needed to be scrapped. Mumbling and pacing around for days trying to figure out a different way to do it. Over several months of constantly running into the compiler slowly developing an intuitive sense for what does and doesn't work with the language. It reminds me a bit of [Raganwald trying to learn to play Go](https://github.com/raganwald-deprecated/homoiconic/blob/master/dumping_ground/deprecated/high_anxiety.md) and the ensuing tension from not being able to jump straight in using theoretical knowledge and instead having to painfully build up a hard to explain intuitive ability to figure out good ways to approach different situations.
Please don't become another "I fixed it" thread that will leave countless future searchers shaking their fists and yelling **HOW???** Reduce internet frustration: post how.
That is still a distortion of the truth: Rust is not a Mozilla initiative. Its creator deserves some credit for taking that initiative. I hate the fact that so many articles forget to give him this. I guess it is important to mention the huge support from Mozilla, but summarizing it like this seem so disrespectful and lazy to me. It's not that hard to write "created by Graydon Hoare and now sponsored by Mozilla" instead of "started by Mozilla". edit: let's say "initiated by Graydon Hoare" :)
I don't understand - what is gnome builder? I dont see it on that screenshots. But Gnome Builder has support for the RLS since half an year.
deleted ^^^^^^^^^^^^^^^^0.2830 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/08563)
First off, lots of developers feel like they aren't that great - the fact that you spent days trying to learn an unpopular challenging language tells me that you're mistaken. Even if you found rust difficult, that says little about your capabilities as a developer - plenty of people in this sub have tried rust, failed, only to try again later and succeed. I personally struggled with rust for a while, didn't look at it for about two months, and then jumped back in later and was writing (awful) code fairly quickly, taking a few weeks to start really getting lifetimes and all that. &gt; t Rust, just by its nature, will keep piling on features and features and features To the contrary, a big focus of rust is to take what's there and simplify it. There's a ton of effort going into the book, error messages, and changes to the compiler to make the borrow checker easier to work with. I think Go is likely so much easier to learn because there is virtually nothing to learn - if you've programmed in C and Python you've basically programmed in 80% of Go. If you've programmed in C and Python you've probably only programmed in like... 50% of rust. So I tend to think that it's less "rust is so hard" and more "rust is so different". To that point, if your goal is to explore new ideas and look at code differently I would choose rust. If your goal is to be productive in a language quickly, choose Go. 
&gt; Already covered variants of enums should not be available as completions when starting a new match arm. You might have one variant covered several times if you use some `if` condition.
No special handling of partial input in 2.x though I may let parsers report how much additional input they expect in 3.x (as on optional addition, by default I think handling of partial inputs only complicates things). https://github.com/Marwes/combine/issues/116 You can of course just detect an 'unexpected end of input' error in 2.x and from that know that 'some' extra input is required, even if that does not give any information as to how much more is needed.
I still fuck up using the module system and I've been programming at least once a week (and now daily, since I do it professionally) in Rust for over 2 years. Lifetime issues become exponentially less problematic as you improve, and you learn to take some of the tricks that you used to satisfy the ownership rules in Rust over to other languages - you'll realise that single-ownership code is much cleaner than this free-love hippie bullshit that's more common in GC'd languages. When I first learnt Rust I spent a week reading the book back and forth before I wrote a single line of code, and the first few months were extremely rough. You're not an idiot, Rust is just hard. Go is hard too, but its difficulty is delayed to later down the line, once you start trying to build big, complicated software. A lot of languages optimise for beginners, so it's extremely easy to get started with but very hard to write massive software in. With Rust you have to climb a cliff to get started but from then on the difficulty stays approximately constant.
I do like reading experience reports like this one: it shows us there is room for improvements and what areas needs the most attention. I don't think there is any problem with OP's mental abilities, Rust should be learnable by everybody.
By that same logic, Internet Explorer wasn't started by Microsoft. Undoubtedly, there was one person that took the initiative and started Internet Explorer. Their name is Thomas Reardon. I bet you didn't know that. That's how virtually all corporate projects work, but people interested in history can read history. Certainly, "sponsored by Mozilla" would be a better way to say it, but splitting hairs on a simple article like this one is effort that could be better applied elsewhere.
Theres a link to the github under "code" on the top menu: https://github.com/althea-mesh
There is a lot to rust but I think the thing to remember is you won't need most of it day to day. Just learn what you need to write the code you're working on. I would suggest putting down the book and just trying to write something. Write it the way that seems obvious first. If you have problems then read up on what you need to solve that problem then continue. Rather than trying to internalise everything before you start.
[opportunity calls!](https://crates.io/search?q=swanson) 
No it wont. The lock lives for the entirety of the `match`.
I too am an idiot. Which is actually why I like Rust and the likes of Haskell. They keep my stupid safely locked up inside me and don't let it leak out to the poor unfortunate people who have to deal with the code I write. For simple applications I can usually just about manage without the aid of the benevolent idiot bat (a decent type system and compiler) beating me over the head, and in those applications I can usually just about get away with writing python or the like. The difference I find is when I go to write something that's non-trivial. Either a large application that I'm going to have to work on with people, or anything that tries to do anything that looks vaguely like computer science, ie implement a fast data structure, or parallelise a (non-embarrassingly parallel) task, or write something that has to run in a resource constrained environment (and therefore needs memory deterministic memory management). In those situation I find I just don't have the required working memory to keep all the required, relevant information in my head at once. I need something to offload that work onto. Now, I can sometimes get away with having a whole load of tests and dynamic asserts and what-have-you, but it's a poor, slow, unreliable substitute for a decent type system. So yeh, I'm not smart enough to write the kind of code I would like to write without a good crutch to lean on. Good type systems are the only crutch I've ever found capable of acting as sufficient a force multiplier to bring my otherwise struggling intellect up to the level required for the tasks I want to achieve.
I had a really hard time struggling with Rust when I was learning it, as many of us.. But it was never the module system. In my opinion, the module system is well designed and pretty straight forward. Can someone please explain me, why it is an issue for some learners?
It might be worth detecting the "all branches are free of conditionals" case regardless, it's pretty common. 
Does anyone know of a good way to use this with Sublime Text? The only LSP packages I've been able to find for it look rather experimental.
The way I usually have `rustfmt` configured at least is to run it whenever I save a file. Works quite well, until I make a syntax error and it gives me an ugly error message.
In my opinion, as someone who writes Rust for work, both with Redox OS and System76, and also has hired people to write Rust, I would need the following to push Rust further and create more Rust jobs: - Updated Rust and Cargo in Linux package repositories. The Ubuntu stable Rust is embarrassingly out of date. There is no option for nightly. dh-cargo is only available on artful. - More stable features. Most of my projects have to use nightly because features that are necessary for low level development are not stabilized. Last I checked, inline assembler was not stabilized. - Successful examples of Rust use in a for-profit context
Yes. rls is more accurate than intellij is. I don't think rls is great with macros but it does do better than intellij does.
My brain also hurts. I think coming from managed languages only there's a big jump as there's a lot of parallels with C++ smart pointers that I don't have. I think it would be great at the end of each page / chapter in the book to have a list of links to other blog posts / articles that try to describe the same thing. There isn't one right way to learn something. Many of us will have to read / attempt a concept a few different ways before we get that 'click'. Please let's have more references to others attempting to teach the same thing!
Yes, I also gave a try to this approach some time ago, but it is very inconviniet with emacs at least, see https://github.com/rust-lang/rust-mode/issues/162 . In theory this is not related to emacs. For example imagine that `rustfmt` have style to reoder `use` statements, first `std::` after that from external crates, and after crate local and you put cursor into one of use statement and press save. From user point of view would be good to preserve position on the same `use`, but how editor/ide no where rustfmt put this `use` statement?
Oh I think you're right. So maybe the original code could work under the RFC if it was just taking references, but because it's creating a temporary (MutexGuard) it won't work, as the timing of when a temporary's destructor is called isn't affected by the RFC?
Well, vscode one is also pretty buggy.
&gt; This is an insightful comment about Rust: it's how I write it. It's true that I've internalised the compiler rules, so straight-forward code will usually work, but I still make mistakes, especially once I'm doing something more than a couple of if statements and a loop or two. Fortunately, the compiler yells at me when I screw up, and I hunker down and figure it out. That is, it's perfectly fine to forget rules, because the compiler doesn't. I think this is true when your code is "mostly right" but not when your code is "very wrong". Like if you're trying to return an `&amp;str` that's not static, the compiler's errors are super duper unhelpful. There are lots of beginner lifetime problems where the answer is "you need to use String/Vec" or "you need to use Arc/Mutex" or "you need to use lazy_static" or "what you're doing is actually fundamentally impossible in safe code". I worry that following compiler errors in those situations drives people mad.
I haven't looked too deeply into it yet, but by default rust-mode uses flycheck which is unbelievably slow for Rust, every time I save the file. Any tips for mitigating that/alternate tools? Right now I just turn it off and rely on cargo check, and usually end up back in Vim for Rust projects.
Go gets by entirely on the marketing of being Google's language. It is simple, but honestly there is no reason to use it over Java. They both have gc issues, and memory differences become negligible on real projects. Rust is hard. There isn't really getting around that but if you limit yourself too small chunks of the language as you go it's manageable. Maybe it's because I've done CPP, Haskell and Scala so I'm used to more difficult languages. But you have to think about your program and work on solving it well. Rust and go are different in where they have their pain..learning and getting something up and running is faster in go. It's nice and painless. Your pain is in the future as you write an incredibly verbose language and have to constantly rewrite the same thing in slightly different use cases. Or when you get a library change and it breaks everything because you don't have version control. Or the increased bugs you'll get. Rust has more pain upfront..but fewer headaches and pain down the line, and less cost as you avoid bugs and work later.
deleted ^^^^^^^^^^^^^^^^0.2706 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/04546)
Hm - I agree the completions are good, but there's a solid 10-15 second delay every time I save the file while it checks for syntax, which also locks the file, blocking invocation of cargo from the terminal. I assume it's just running cargo build - it's a tokio/hyper project which simply does take an annoying amount of time to compile but Vim is able to provide on-the-fly syntax checking without that crazy delay. I'll keep trying stuff!
deleted ^^^^^^^^^^^^^^^^0.2191 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/86933)
Yep, spacemacs as well, default rust layer. Just started using it, haven't done a whole lot of manual config. I loaded up a simpler toy project I have and it takes much much less time to do the check-on-save (but still 2-4 seconds, longer than I'd like), so I'm assuming it's because of the fact that this project in particular takes a lot of time to compile - but my Vim plugin doesn't seem to need to do a full cargo build to provide the syntax feedback. I'd much rather use spacemacs, but disabling flycheck completely just to have a sane compile-edit-debug cycle is pretty frustrating.
deleted ^^^^^^^^^^^^^^^^0.7755 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/87286)
The way I've seen it handle that so far is it just keeps the cursor in the same place. Which is honestly not the worst thing ever; usually if you do this consistently then it doesn't actually alter the file very much.
Python has it's own dynamic language problems that Rust's compiler thankfully catches. I totally agree it's a lot to learn at once. The syntax of the language is just the surface. It's a bit like an iceberg - ownership and borrowing are simple concepts, but internalising it takes time and patience. One day it will all click. :-)
I think the above suggestion is still very useful , because the main benefit of this kind of autocomplete is to avoid *lookup* (more than just typing): if you can see an existing variant in the match body already, you already have it for reference 
deleted ^^^^^^^^^^^^^^^^0.4070 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/88187)
Cool, will do - I'm not positive this behavior is actually a problem with spacemacs. since the timing does coincide with how long cargo takes to build the project, this may in fact be expected behavior - but I'll definitely see what they say. Thanks!
Learning a new language, especially one that introduces new ways of programming, isn't ever an easy task. I believe you were drawn to Go since its aim was to be similar to C (a language you're already comfortable with). You're not an idiot by any means, but if you're serious about learning something, you need to give it more time and practice. Learning new things is always difficult. &gt; I spend 3 days reading that same god damn document. 3 days. Same here. Was it the ownership section? &gt; My worry is that Go will eventually get generics going and, with things like GC tuning, will allow for more happy-making runtime behavior, but Rust, just by its nature, will keep piling on features and features and features and adding rules until using it optimally becomes one of those Fermat's Last Theorem proofs that 8 people on earth could understand. This is an idea that (unfortunately) has been floating around the Go community, and while I guess it's up to personal opinion, I really disagree with the notion that modern programming paradigms are somehow more complicated or bad for programmers. Ages ago, you could have argued that you worried that high level languages would replace the need to know assembly code, or that they would become too complex. The reality is that most programming concepts (especially those presented in Rust) are nothing that new. Go tends to believe that "all abstraction is bad" despite the fact that (for example) generics would be incredibly useful and cut down on copy-pasting functions for each type. If you look at the language creator and lead (Rob Pike) it's no surprise seeing as he thinks things like syntax highlighting is for "babies". It's a kind of pretentious masochism I'm not really on board with... but I'm getting off topic. TL;DR, languages are hard. Languages that present new concepts are harder. Patience is a virtue.
This is awesome! Thanks.
&gt; then it doesn't actually alter the file very much I don't know, may be different expiriense, but how much `rustfmt` alter the file is not important for me, how it alter the code around cursor this is important for me. And if your editor auto indentation is not good match to `rustfmt` then after new `match` or `if` `rustfmt` change a lot around cursor, which cause a lot of inconvience for me, so I move `rustfmt` to git hooks.
Have you ever done anything with a functional language? I think the hardest part of learning Rust for me is that fixing problems usually involves completely changing the structure of my code to be more in line with how Rust works. Sometimes this can feel like a slap in the face when I'm trying to do something that's trivial in C# or Java (after years of practice). Rust design seems to lean a whole lot closer to functional design than it does to object-oriented design. Like if I write something similar to the way I'd write it in Haskell it's probably going to work, whereas if I write it the way I'd write it in Java it's probably not going to work. There are definitely some really weird pain points though. Like looping over a vector contained in a struct without cheating and making the vector public. Holy shit how is a for-loop so complicated? Once you get the hang of iterators it's really not complicated at all, but it makes you feel really dumb when you can't write a for-loop. I'm trying to keep track of things like that as a learn so that I can try to write some good tutorials for them once I progress past the learning phase.
Sounds like Russian. In Soviet Russia, the format parses you.
&gt; Apologies for the violation - it's sort of in jest. Just so you're completely aware, because sometimes it's easy to misinterpret when it's aimed at you, but I'm pretty sure the "This violates our code of conduct" is the joke being referred to in "jokes aside", since you weren't being courteous to *yourself*. You apology seemed a bit sincere for what looked to be entirely a good natured jests (for both parties). :)
Crash mostly. Its infuriating that for such a bullet proof language, apparently RLS doesn't use a lot of its features. So instead of properly handling exceptional cases, it just dies all the time because it uses so many raw unwraps. If the stability has improved I'll look at again, but I've gone back to racer for now.
Your homework: work on your self-esteem. Then revisit Rust.
Look up "transformation matrices" and learn how they work in OpenGL. It's basically a block of numbers fed into an equation that turns an arbitrary coordinate coordinate system (including an orthographic projection) into the coordinate system of your screen. It's often divided up into a couple parts; usually a "view matrix" that defines the position and facing of your camera, and a "projection matrix" that defines the box/frustrum/whatever that your camera actually observes. The linear algebra is a pain in the butt, but you don't really *need* to understand how it works on the inside, just how the pieces interact with each other. Usually the block of number for your transformation matrix is created by your program (many math libraries have [functions](https://docs.rs/cgmath/0.15.0/cgmath/fn.ortho.html) to create these easily) and [fed into your vertex shader as a uniform](https://github.com/glium/glium/blob/master/examples/teapot.rs#L133). The vertex shader then [does the math](https://github.com/glium/glium/blob/master/examples/teapot.rs#L35) to turn your world-space vertex coordinates into the points where they will be on the screen. This is nothing glium-specific, so any OpenGL docs should be applicable.
&gt; Apologies for the violation - it's sort of in jest. I'm not your parent, but they were joking as well.
Yup, it doesn't have anyone actively working on it at the moment, so that's a big part of it.
&gt; The Rust book seems to be making one of the most common mistakes that I see programmers teaching -- it tries to explain everything when discussing X, instead of we'll learn X in later chapters. You can take a look at Guessing Game as a good example of it. I'm a little confused as to what you mean; the Guessing Game is attempting to do exactly that, not get into the details. The rest of the book is, but does selectively choose to defer things to later at times.
Let's pretend you have a 2D camera struct that looks like this: struct Camera { scale: f32, position: (f32, f32), } If you already have a shader with a transformation matrix, you can just supply [[camera.scale, 0., camera.position.0], [0., camera.scale, camera.position.1], [0., 0., 1. ]] As the transformation matrix and have your shader do `gl_Position = u_Transform * vec3(a_2dPos, 1.0)`. This is on the [affine transfomations](https://en.wikipedia.org/wiki/Affine_transformation#Augmented_matrix) page on Wikipedia. OpenGL is basically 100% matrix maths, if you don't understand matrix maths (or you don't understand what a shader is or how to make one) then just comment below and I'll do what I can to help you out.
Sounds to me like learning overload. There's only so much learning a human can handle in a day; take a break and come back later. I had the same experience in some lecture courses: it's hard keeping up, but pretty soon you've been forced to use the first stuff so much that you don't have to stop and think about it any more.
Had to create a symlink on my hard drive to make go to definition for stdlib work properly. And it does crash sometimes, but it's easy to restart it so not a big deal.
Switched my vscode over to this and immediately noticed the difference (in a good way) - is there any way I can get clippy to run on save using the new rls vscode extension?
As usual, but that one seems basic enough that it should be in the compiler. Name shadowing is never a great idea.
The `T` in `Point&lt;T&gt;` means almost nothing and does not escape the `struct Point&lt;T&gt; {...}` definition. Surprisingly, you can put restrictions on `impl`s that are not on the struct definition; e.g. `impl&lt;T: Clone&gt; Point&lt;T&gt; { ... }`.
One could nitpick that it's not covered (fully) in that case ;)
Say what you will about the linked piece, but I found it interesting because it got me thinking about safety in Rust from a different perspective I'm not used to. For example, I wouldn't have otherwise looked for this: http://plv.mpi-sws.org/rustbelt/ or this paper: http://www.mpi-sws.org/~dreyer/papers/rustbelt/paper.pdf Incidentally, if I'm reading that paper right (I was really tired when I read it last) it seems to prove safety for some subset of Rust, including the unsafe blocks, under certain conditions? This paper seems important to me in writing Rust, but it's unclear to me how the results generalize or don't when the full language is considered. Does the paper suggest that if people are writing unsafe blocks that restricting their code in some way is more provably safe? Is this in the book somewhere? I haven't really looked at the unsafe book (The Rustonomicon). I apologize for asking anything stupid--the article, while kind of superficial, seemed to be pointing to a very important topic, and seemed to point to some important research on rust and how to structure rust code.
You can safely ignore many of the more advanced features of Rust while successfully creating useful programs. My ~20Kloc rust program uses very few advanced features beyond traits, structs, and basic generics.
deleted ^^^^^^^^^^^^^^^^0.4466 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/96942)
For those not in the know, [it sounds like a bunch of these features will be coming to KDevelop soon](https://perplexinglyemma.blogspot.co.uk/2017/07/keep-calm-dont-panic-and-ctrlspace.html).
Interestingly, I would somehow prefer if the RLS never modified the files. Is there a reason to implement renaming in RLS, rather than simply let the editor use the "find-usages" functionality and rename all occurrences? It seems to me that, possibly apart from reformatting, all editing functionalities could be covered by simply having RLS return the necessary information and have the editor perform the change. I don't seem to see any advantage about having RLS perform the editing actions listed instead of simply providing information to the editor. On the other hand, it seems there are several potential disadvantages: - more verbs to integrate: more validation, less re-usability across languages, - if RLS directly edits the files: loss of "Undo" on editor side, and possibly other issues (CLion forgets which sections of code where folded after invoking clang-format...), - if RLS directly edits the files: no preview/control over the modifications, it's "fire and forget", - ... Is there a rationale for this behavior?
&gt; I know, Go is not a low-level language in the way that C, C++ (and Rust??) are. But it says 'systems language' on the box and it's Google, so, fuck knows, they have good intentions, I suppose. A related historical footnote: Rob Pike was one of four members of a panel discussion at the Lang.NEXT 2014 conference on "Systems Programming in 2014 and Beyond". I forget how he phrased it, but he expressed some regret in muddying the waters by calling Go a systems language.
&gt; If you can work with C, work with C first. I'll disagree. Just today I was checking a code-review on a beginner's first project: Linked Lists. The most striking error: ~list_node() { delete next; delete prev; } Now, let said beginner understand what went wrong from the crash they'll get... In Rust, the *compiler* will error out, and therefore you'll have an error message to refer to, which will immediately point you to the portion of code that causes you trouble. Don't understand the error message? Fire up the playground, reduce the example until you do or it's minimal. Search Stack Overflow. Ask on IRC/Stack Overflow. It's so much easier to investigate/ask about a compiler error than a mysterious crash.
Just as an example: &gt; By default, Rust brings only a few types into the scope of every program in the prelude. If a type you want to use isn’t in the prelude, you have to bring that type into scope explicitly with a use statement. Using the std::io library provides you with a number of useful io-related features, including the functionality to accept user input. This could be worded as: &gt; `use std::io` makes available `io:stdin().read_line`, which allows to get input from the player. I've made a quick version of the first few paragraphs https://gist.github.com/egonelbre/c478a5068216a57034c8841904db269f. Hopefully it gets the idea across what I mean. _I did copy paste from web, because I was too lazy to find the actual source for now :D_ The words "prelude", "scope", "use statement", "library", "macro", "mutable", "immutable" are irrelevant when you try to get your first program running. Until you have the game running, these mustn't be mentioned. Treat every word as something that might confuse the user. There are also pieces such as: let foo = 5; // immutable let mut bar = 5; // mutable Here, `foo` and `bar` are both detached from the problem at hand... and this usually confuses people. Usually the first question I have gotten from students about these is "what is foo?". (not in Rust, but several other languages). Or: &gt; The :: syntax in the ::new line indicates that new is an associated function of the String type. An associated function is implemented on a type, in this case String, rather than on a particular instance of a String. Some languages call this a static method. Could be completely removed. I do agree that these are important topics to learn, but not as the first introduction to the language.
Fellow SublimeTexter here! Sounds like we should start a RLS package :) It's probably possible to write it in rust and just provide python bindings for Sublime to hook into
Rls should return a diff at the minimum that an idea can apply. Next level up would be a tree transform ation.
Yeah, there are low level concepts of safety, such as pointer safety, and high level ones such as "Does this program accurately match the spec", and "Does this program implement a mathematical proof such that we know it can't behave in some unknown way".
Its in scala too. You want to match on the internal structure, but what you actually want is the whole matched value. Super useful.
I am getting quite confused by anything I look up about this topic, given that a lot of the stuff is done for 3d rendering while I only need to draw 2d sprites onto the screen. And I just tried creating a transformation matrix with cgmath and feeding it to the vertex shaders, but the result is empty for some reason and I cannot figure out what I am doing wrong. And I also checked, the values of the resulting position vector are inbetween 1 and -1 so everything seems to be working apart from the rendering itself now.
I whole heartedly agree. Here's gold!
Any suggestions how to debug "The Rust Language Server server crashed 5 times in the last 3 minutes. The server will not be restarted." messages in VSCode?
Go is a fantastic little language to get started with. It bites you in the ass much later with a large variety of problems Rust just doesn't have. You pay the cost of comprehension upfront with Rust. You the pay the cost of debugging complex issues that occur at runtime later with Go. Sometimes one is better than the other. I prefer the upfront cost. At least then I'm not getting a phone call at midnight about the program segfaulting on a random nil ptr error or undetectable data races causing strange voodoo like behavior. 
You are right, it looked a bit like it, but it probably is another editor.
Why? I am not sure that from a duplication of effort POV it make sense for language servers to do those editing actions. For example, I would imagine renaming being carried out as: 1. IDE queries LS for declarations/definitions/usages of variable, 2. IDE offers check/preview/... about renaming, 3. IDE applies renaming. It's implemented once for all languages, and reuse the already existing LS functionalities. Rather than having each LS re-implement steps (2) and (3). What is there to gain to put this functionality in the RLS?
From what I gather the whole point of the paper was to prove the concept of "extensible safety" is actually sound, and to achieve that they proved some of the core types that implement safe abstractions through unsafe are themselves sound (and found a bug in MutexGuard in the process!). 
Nothing worse than getting your C code to compile and firing it up just to see `segmentation fault`
If associated fields get accepted [1], then it could be nice to have a macro library with the following syntax. #[derive(Delegate(DelegateFoo))] trait Foo { foo(&amp;self); } This could derive the following code. trait DelegateFoo { inner: Foo; } impl&lt;T: DelegateFoo&gt; Foo for T { foo(&amp;self) -&gt; { self.inner.foo() } } This would allow the user to write struct Bar { foo: Foo } impl DelegateFoo for Bar { inner = self.foo } [1] https://github.com/rust-lang/rfcs/pull/1546
Coming from a strong C and Python background, I find that having dealt with coding Python extensions in C has helped me a great deal in understanding what the borrow checker does. Basically, Python does the same thing when a list steals a reference from you, because whow, wtf is *that* supposed mean!? But it does make sense after a while, because the idea is basically the same, you just don't get the extra safety of the compiler being able to check it for you. If you mess up, meh poof segfault. I too have looked at Go, and it didn't really catch on because it felt just like a more clumsy Python to me. I did however instantly fall in love with their concurrency select-over-channels stuff. But Rust not only feels way more natural to me, I view getting rid of Garbage Collection as a *huge* accomplishment. That, plus Python having already taught me half of what the borrow checker does, gives me a great deal of motivation to learn Rust. I just miss the CLI. I really, really wish there was an irustc. :D Not sure if that helps you anything. But I think not struggling with learning Rust is totally impossible, because what this compiler is achieving is fucking rocket science. 
2D is just 3D with every z value being 1 or whatever. But if all you want is 2D game stuff check out [ggez](http://ggez.rs).
I actually totally agree with the foo bar thing. I think all of the examples should have meaningful variable names. If you are already trying to learn an abstract idea, having totally ambiguous variable names just makes it that much harder. I think a really good example of how to do this the right way is the example for implementing the add trait (in the docs for std::ops::Add). It uses a point struct with x and y members. It makes it really easy to understand.
Thanks! I think I get it now. I wish you had come across these earlier; the chapter is frozen now.
I have to use glium for this due to another library I am using and I do want to use glium for this myself as well. And I just noticed if I render my 4 vertices as Points I actually get a single white Pixel in the middle of the screen but thats it
3 days reading the lifetime annotation section. And ultimately it turned out not to really be a thing I needed to worry much about. At least I *really god damn know* what lifetimes are. &gt; it's no surprise seeing as he thinks things like syntax highlighting is for "babies". On a completely unrelated note, I'm pretty tired of this. Linus's rants about debuggers and 'shitty programmers', so much elitism goes around the C/C++ world. I watched Jonathan Blow shit on TDD and unit testing, both things that are super important to me. Maybe that's where my self esteem issues come from.
IMO Go and Rust are targetted completely differently; I don't think it's fair to compare them. I'm happy with the shortcut of C++ unsafely to 'lighten the load' (because I need to write tests for other reasons), but maybe eventually Rust will get more assists to lighten the learning curve (shape analysis in IDEs?) .. the issue is C,C++ have shortcuts which let you get more things done using by composing basics, whereas in Rust learning all the functional abstractions (looking up what someone else calls this pattern of operations, instead of writing it directly) for every use case is compulsory (to prove safety).
&gt; Also only loop allows to break with a value. Oh, I had no idea, that is actually really cool.
The RLS uses the LSP so its model for modifying files etc. is all dictated by that. To be clear, the RLS sends a changeset to the client and the client changes the files in its buffers - the RLS doesn't change anything and the client should only change what is in memory not disk. So basically, we do everything you want :-) I don't know why the LSP has different protocols for rename vs find all uses, but I hypothesise that it is to allow a language server to be more conservative in the rename case.
The LSP certainly expects the language server to do it. You could have multiple language servers, but that would get complicated. We found it works very well to have the RLS run Rustfmt - keeps the client simple and means you only have to install one thing.
Do you have a recommendation on what to look at to get familiar with tokio-core? I tried tokio-proto a few months ago and was pretty frustrated by the mix of approaches in the docs. I finally came back to it this week and decided to avoid tokio-proto but haven't seen a canonical example of its usage. 
It is VSCode
We'd love your help doing so. If anyone has any ideas, please get involved! 
RLS is generally more accurate and copes with more code (more complex generics, some macros, etc.) but IntelliJ has more features. However, both approaches are getting better in these ways. If you prefer a more full-featured IDE you should probably use IntelliJ. If you prefer a more lightweight editor you should probably try VSCode with RLS. The RLS can handle simple macros like `println!` and `assert!`. We're working on improving coverage.
Not yet, but it is on our radar.
You can set `rust-client.showStdErr` to true in your vscode settings, which should give you more info in the output panel (which you can see via the 'view' menu). You can also run vscode with `--verbose` too, though I have not found that so useful. If that doesn't help, ping me (nrc) in #rust-dev-tools and we'll if we can get further.
My confusion stems mostly from names and importing - specifically in complicated project structures where you're probably importing names across submodules and things like that.
To me, it sounds like you haven't found your right learning style. Perhaps jumping in with a mentored issue can give you better results.
Try Rust IRC channels. https://www.rust-lang.org/en-US/community.html . The community is very friendly. You can have private messages, which counts as solo, I guess. ;)
&gt;If you prefer a more full-featured IDE you should probably use IntelliJ. If you prefer a more lightweight editor I like both :) I would still consider using an RLS plugin for emacs
you probably want /r/playrust
&gt; And I just noticed if I render my 4 vertices as Points I actually get a single white Pixel in the middle of the screen but thats it This probably means that all your vertices end up being at the coordinate `(0, 0)`. If you draw triangles you don't see anything, since triangles whose vertices are all at the same location don't cover any pixel. But points have a certain width so you see them. In other words there's probably something wrong either with your matrix or the way you multiply.
I suppose you could still map those to c++ equivalents (manually tagged unions, tuple, just roll a struct with generically labelled fields '.a .b .c..')
Do i need to install the "msvc2015 64-bit" part of Qt if i already have MSVC 2015 installed? https://i.imgur.com/ftErnCh.png
Thanks! Do i need to install the "msvc2015 64-bit" part of Qt if i already have MSVC 2015 installed? https://i.imgur.com/ftErnCh.png
yes I just noticed that the name of my matrix was not the same as the one defined in the uniform macro .... so obviously everyhting became zero. Fixed it now and everything works properly, such a dumb mistake by me
"RSON" .. R-son .. "arson"
That's awesome to know, thanks :)
In this specific example you could move the write that's currently after the loop into the loop, before the break. Alternatively, I *think* putting the whole loop into a function / closure and returning the captures instead of breaking should work (although I haven't tested that yet).
[This](https://play.rust-lang.org/?gist=bdc57eea35feea6c87d512523dbddfe3&amp;version=stable) is one solution, but it makes a copy of the final result, rather than being zero copy. [This](https://play.rust-lang.org/?gist=0d4dd45824c2eb66120856844c23fc89&amp;version=stable) is another solution, and it is zero copy. There are probably other solutions too, but those are the two that I just threw together. If you can't use either of these, there are probably others we can look at. Sometimes solutions like these "defeat" the problem in the question, without solving the problem in the original code. and... it's not a "bug" so much as it is that the borrow checker is overly conservative. The borrow checker is still protecting you from using pointers in an unsafe manner, but it prevents some behaviors that are also safe that it can't yet prove. This will change when NLL (non-lexical lifetimes) becomes a thing, and a lot of people are excited by NLL, but to me a "bug" makes it sound like a correctness issue where it's allowing bad things. It *is* a usability bug, of course.
I'm really looking forward to the day that we can (significantly) lessen the barrier to entry of software development for satellites. 
Yes you need this, that's the precompiled qt components that correspond to the selected MSVC version. If you don't have those, then you wont be able to compile your Qt application.
I think it would greatly increase the complexity of the compiler without much gain. We already have procedural macros in the works, and custom derive already exists - I don't think we need syntax changes outside of macros on top of those two. I think more custom attributes like custom `#[derive]` but for functions or impl blocks might be nice - but I'm not sure about if these should allow arbitrary syntax differences or if they should just work on and modify code which is already valid rust, like `#[derive] ` does.
They don't, they want /r/playrustservers this kind of content is banned from /r/playrust as well!
ah, good to know, thanks!
There was some discussion of this in the talk about "epochs", the issue with this strategy is that you end up with many different dialects of the language.
I'm not sure about passing ownership of heap allocated memory between Rust and C. You'd need to be certain they were using the same allocator. If Rust allocated the string memory using jemalloc then having C free it with the system malloc would likely cause problems.
I think you are looking for /r/playrust
I'm sorry i know very little about rust.
Uh oh, my bad.
I am sorry to hear that clippy has lead you astray. I'll amend the documentation to note this problem when I get to my PC. Edit: See [#1951](https://github.com/rust-lang-nursery/rust-clippy/pull/1951).
I bet I'll do. Thank you very much for the links. :)
RLS provides introspection about the src, another tool like RLS should supply refactorings. We both agree that refactorings shouldn't be in RLS. But the refactorings should ALSO not be in the IDE. The IDE is a presentation layer between the programmer and their source. There is a missing step between 1 and 2 which is construct refactoring operation. This is non-trivial and if implemented in an IDE would have to be reimplemented across all IDEs that support Rust. While `rename` is probably 80% of refactorings, it is not all of them. Many are much more complex. Why have an IDE re-invent the refactorings? My point was that RLS, instead of modifying the src directly, should send a diff back to the editor, one the editor can apply and track in its undo buffer. Doing a complete run around the IDE destroys its state. This is an MVP level feature. To do it correctly, one would have to have encodings for operations on trees of Rust src. This would be above an MVP level feature. Editors/IDE should focus on doing navigation, editing. The external tooling should be reusable across IDEs. 
Yes, you would end up with many different dialects. My main reason for walking to talk about this was that ability to add new "syntax-like" macros. Basically something like a macro that has less rules on what is/isn't allowed in the macro but also looks like "native" code
/r/playrust
Thanks for reply, but which parts of formating `rls` can take care: some gui action `reformat region/file/project` or also smart indendation when user press `;`, `}`, `enter`? And how they cooperate, obviously they need the same information on some level (I mean both of them need AST), so `rls` and `rustfmt` parse code two times, or `rustfmt` reuse code mode from `rls`? 
i think it is a good idea! it is power. make rust more flexible 、adaptability。and make rust for everyone，Extending the language itself is very significant 。
&gt; Even with generators, you are just delegating this problem up the stack - eventually you have a main() that just has an async block and every function everywhere must be async to be able to await As an aside, this reminds me of a good read: http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/
Hi, I can just post my code here, because I can't really tell what the faulty part of the code was (as I wrote above, after hours of trying, it was a mix of code fragments from stackoverflow/google and the docs) use std::time::Instant; let start_time = Instant::now(); // do some stuff let time_elapsed = start_time.elapsed(); let time_elapsed_ms = time_elapsed.as_secs() as f64 + (time_elapsed.subsec_nanos() as f64 / 1_000_000_f64) / 1000_f64; println!("time elapsed: {:.3}s", time_elapsed_ms); I hope this helps. I'm not sure if it 100% correct, but it works at least for measurements of small time frames.
I posted my solution as a reply.
I posted my solution as a reply.
I posted my solution as a reply.
I just ran into almost the exact situation referenced in this link: https://users.rust-lang.org/t/lifetimes-on-associated-types/2728/3 which apparently would be solved by HKT (I only have a vague actual understanding of HKT to be honest; if I sit around and work through it I understand, but then I forget pretty much immediately). It arose in the context of a parser combinators library I'm writing that uses the GLL parsing algorithm behind the scenes. I've written a fair amount of rust on other projects and have never been cold-stopped by the lack of HKTs before, but this one hung me up for quite a while. I did eventually work out a way to do what I wanted, but it was quite intricate getting the lifetimes, associated types, and generic types all to play well with each other.
&gt; the issue with this strategy is that you end up with many different dialects of the language. I wonder if it would be possible to divide rust into 2 layers, much like C++ is a near superset of C (or haskell has some intermediate, '[SystemF](https://en.wikipedia.org/wiki/System_F)' I think?), which could allow code from different epochs to interoperate , or allow experimentation with dialects (that still share a large chunk of the compiler). given that rust is less syntactically chaotic than C/C++ (preprocessor/macros,context-dependant grammar) I wonder if you have an opportunity to make something more malleable.
**System F** System F, also known as the (Girard–Reynolds) polymorphic lambda calculus or the second-order lambda calculus, is a typed lambda calculus that differs from the simply typed lambda calculus by the introduction of a mechanism of universal quantification over types. System F thus formalizes the notion of parametric polymorphism in programming languages, and forms a theoretical basis for languages such as Haskell and ML. System F was discovered independently by logician Jean-Yves Girard (1972) and computer scientist John C. Reynolds (1974). Whereas simply typed lambda calculus has variables ranging over functions, and binders for them, System F additionally has variables ranging over types, and binders for them. As an example, the fact that the identity function can have any type of the form A→ A would be formalized in System F as the judgment ⊢ Λ α . *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.24
(GHC Core is based on System F, but its different.) [I think you might be looking for HIR or MIR?](https://blog.rust-lang.org/2016/04/19/MIR.html)
Not reading you problem in depth, but are you aware there is a `tokio-signal` crate?
Now I want to write a guide on how to write a bot for Rocket chat using Rocket.
Not sure tbh.
Currently we only reformat on a user action. Indentation as you type is a kind of new feature for VSCode and I need to look into how it works (format as you type is part of the LSP, but is not implemented for the RLS).
What does the canon have to say about Ferris's gender? Yes I know this a very stupid question but when I saw the plushie kickstarter, I was surprised to see the pronoun "she"; I thought Ferris was male.
Yeah it's not great. Just look at Haskell with all of it's custom syntax. It makes it hard for me to read on a daily basis -_- I'd rather not have the same thing happen to rust outside of macros.
You need to call `chan_signal::block(&amp;[/*sig_list*/])` If you don't block the signal, the signal will still execute. You _will_ be notified, but it still happens.
I wonder how much of this could be covered if the compiler attempted to infer any unimplemented trait items, and automatically used a delegated method if exactly one delegate candidate exists. If more than one candidate exists, you get a compiler error and a list of delegate candidates you could insert using the proposed `use foo for some, list, of, methods;` syntax.
That's basically MIR.
Thanks for taking the time to review it, much appreciated! My initial reasoning for converting all the `Result`s to `Option`s was to make it possible to directly return `Iterator`s (more idiomatic than `FallibleIterator`) for the debug info elements (subprograms, parameters, etc..), but eventually went a bit overboard. Agree with your assessment about the conversion and the complexity it brought on, will consider using `Result`, `?`, and `FallibleIterator`.
More power is not always better than less power.
Yea its absolutely the color problem. The thing is since async has no real compiler support it can't do anything about it. Eventually it will probably be simply to have a lint that errors the compiler if you ever use synchronous io, and some monster global macro in every file that makes all functions async. As long as you are in an async body, you can call normal functions as long as they don't block. Its just getting all running code to start in async bodies on a global event loop (preferably threaded) that is the PITA.
This is kinda off topic, so please feel free to ask me to delete it. It does somewhat cover the design of Stylo (Servo's style system), so I though folks may be interested in it. In the past I've gotten positive responses for posts mentioning Rust on /r/rust
My current, incredibly lazy bar for relevance is that if a Ctrl+F for "Rust" succeeds, it's relevant enough to let upvotes decide the rest.
&gt;Have you tried asking on IRC? Basically, a lot of easy questions whose answer is currently hard to find are answered on IRC in a couple of seconds by the people hanging on in there. This can't be stated enough. In #rustbeginners, not every question gets a good response, but it's the best IRC channel I've ever seen as far as helpfulness and respectfulness, for both lower and higher level questions.
&gt; The next strange thing is, that the worker function should return the found numbers as an u64, but that also does not work. I'm pretty sure this is because of the semicolon on the end of line 43. You can either remove the semicolon, or make it an explicit `return worker(i, max_number, threads);` instead. With the semicolon there, the result of the expression is `()`, which is basically void. I realize this is just a toy calculation, but I will note that fn calc(a: u64, b: u64) -&gt; bool { if (a + b) % 2 == 0 { true } else { false } } could just be rewritten as fn calc(a: u64, b: u64) -&gt; bool { (a + b) % 2 == 0 }
Yeah RLS is currently one of those "try every few months" things, and naked unwraps will haunt Rust programs for decades unless current attitudes change.
For what it's worth, it's better to post solutions like this as part of editing the original post (or linking your original post to here) to help folks find your solution.
hey, thanks a lot. It was indeed the semicolon. Also, I really like the optimized code for the calculation. Thanks again.
Sounds like it's a difference between the end of the match block and the end of the function block? `val` is borrowed until the end of the match where it is destructed, but it needs to be borrowed until the end of the function?. I'd think that since the end of those blocks coincide that the code would be equivalent unless there were other factors in play... But this is just a naive guess really.
Well, after removing the semicolon, everything works. Even without printing out the result. I think this is really strange, because I usually get overloaded with warnings and errors, but when code will be thrown away by the compiler, there is not even a warning?
It depends on the circumstances. If Rust's ecosystem doesn't provide a sufficiently mature equivalent for what Python offers (eg. Django, PyQt, various smaller libraries), then Python will be faster. (Though, depending on your requirements, there may still be benefits to using [rust-cpython](https://github.com/dgrunwald/rust-cpython) and [setuptools-rust](https://github.com/fafhrd91/setuptools-rust) to write part of your program in Rust and part in Python. Until you've had a some practice with Rust (or any language), your productivity is going to be lower than something you're comfortable with. (Though, I've found so far that, with The Book and the people of `#rust` helping me when I get stuck, I've gotten comfortable with the parts I actually need very quickly.) That said, when situations *are* equivalent, I find that while I do lose time on code only compiling if it meets a certain minimum standard for "complete" and "correct", I more than make that time back up on not having to find and fix runtime errors relating to `None`, exceptions, or receiving the wrong type from a function. ...and the more you care about making sure your code won't fail at an inconvenient time, the more Rust will win out. (In other words, when the libraries are there, use Rust to replace Python and Python to replace shell script. That's what I do.)
Most of the optimizations are done by LLVM, which is a compiler toolchain that sits underneath the Rust compiler. When you compile in debug mode, everything happens just as you wrote it. When you compile in release mode, LLVM looks at your code and finds ways to get the same results by executing fewer instructions. These are called optimizations. C and C++ compilers do the same thing when you turn on `-O2` or `-O3`. "Clang" is a C and C++ compiler built on LLVM as well, so Rust and Clang share many of the same optimizations. Rust and C are different languages, of course, and Rust places a much greater emphasis on correctness. As an example, if you want to multiply two numbers, you could do this: fn multiply(a: u64, mut b: u64) -&gt; u64 { let mut current = a; while b &gt; 1 { current += a; b -= 1; } current } fn main() { println!("multiplying {} and {} yields {}", 3, 4, multiply(3, 4)); } Conceptually, multiplication is just repeated addition. However, it's much faster to just let the processor use the built-in multiplication instruction, which is significantly faster than looping through and doing addition to simulate multiplication. Now, I don't know of any compiler which can optimize something this complex into a single multiply instruction automatically, but the idea is there. Optimizations take code and produce something else that is exactly the same, by all external appearances. If you write code to do a bunch of work, but you never use the result of that work, and the work doesn't *change* anything about the external behavior of the program, does it matter if that work gets done? Compilers these days are very aggressive about optimizations, across the board. Languages like Python don't have this luxury. They begin executing the code as soon as they read it into memory, and they don't have time to reason about the code or its side effects, so Python code is extremely slow. (There are more nuances than this, of course) If you're interested, [Wikipedia has more information.](https://en.wikipedia.org/wiki/Optimizing_compiler) I think that [this section](https://en.wikipedia.org/wiki/Optimizing_compiler#Specific_techniques) is particularly fun. [This StackOverflow question](https://stackoverflow.com/questions/11227809/why-is-it-faster-to-process-a-sorted-array-than-an-unsorted-array) is legendary, and definitely worth a read. In the footnotes of the top answer, there's this quote: &gt; Intel Compiler 11 does something miraculous. It interchanges the two loops, thereby hoisting the unpredictable branch to the outer loop. So not only is it immune the mispredictions, it is also twice as fast as whatever VC++ and GCC can generate! In other words, ICC took advantage of the test-loop to defeat the benchmark... which I always found fascinating. Some compilers are capable of more optimizations than others. The answer was written 5 years ago, so the 'state of the art' of compilers has certainly been progressing since then, but the information is still very useful.
**Optimizing compiler** In computing, an optimizing compiler is a compiler that tries to minimize or maximize some attributes of an executable computer program. The most common requirement is to minimize the time taken to execute a program; a less common one is to minimize the amount of memory occupied. The growth of portable computers has created a market for minimizing the power consumed by a program. Compiler optimization is generally implemented using a sequence of optimizing transformations, algorithms which take a program and transform it to produce a semantically equivalent output program that uses fewer resources. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.24
As someone who extensively uses C and Python, I'm finding Rust to be a nice compromise between the two in terms of performance and high level programming. Rust has way more "batteries included" than C, and less than Python, at least in the way of the standard library. I don't write software that other people use, so I'm allowed to be picky and do weird things like almost never using external libraries... So I can't speak too much about parsing webpages with rust. I wrote my own CSV parser and it was a great exercise. If you are doing something simple, you will likely be more productive in Python. Personally, I find that it is difficult to keep Python projects organized and maintainable once they hit a certain point (500+ LOC) - but that may just be due to the circumstances in which I use Python. Rust's build and auto-documentation system really helps once you start getting to complex projects. 
So, the basic steps are as follows: go here and install Rust: https://rustup.rs/ download VS Code: https://code.visualstudio.com/ (which it sounds like you have) open VS Code, go to the Plugins tab on the left and search for Rust. Look for the author "kalitaalexey" (which is [this plugin](https://marketplace.visualstudio.com/items?itemName=kalitaalexey.vscode-rust)) and install that one. It may ask you to "Reload" at that point, so go ahead and do that. Side note: make sure that you don't have the "Rusty Code" plugin installed. That thing is ancient and abandoned. The author vanished a long time ago, and Microsoft hasn't taken down the plugin, instead still giving it a lot of visibility. At this point, open up a terminal and go to a folder you keep your projects in, then run `cargo new --bin hello_world` and this will create a new folder called "hello_world" with the basic Rust project structure in it. You can open this project in VS Code by using `File -&gt; Open Folder...` Once the project is open, open the `src/main.rs` file in the file tree on the left (the top tab, if you're still in the plugin tab). At this point, the Rust extension you installed earlier is probably going to want to do some one-time things to improve the experience, just follow through the prompts. For debugging, I recommend you look here: https://www.reddit.com/r/rust/comments/61e7kb/can_vscode_be_used_to_debug_rust_code/ I don't use GUIs for debugging, so I feel those answers are more qualified. I prefer to use gdb/lldb directly. --------- I recommend VS Code, especially for you, because VS Code is arguably the best non-IntelliJ editor for Rust right now, and VS Code is the best Go language editor I've used. So, it should serve you well for both languages. I strongly prefer Rust to Go, of course.
I wouldn't even call it a nitpick. It's not covered
In theory, you could get to similar level for many tasks as both languages are very expressive. In practice, there is big difference, due to ecosystem maturity. Googling for any of the things you mentioned for Python will lead you straight to some blog or answered question that will tell you exactly how to do it, so its 3 seconds to type the query, 5 to read the answer, and 2 to copy-paste solution, and its done. For Rust ... often not so much. Googling will lead to a set of possible crates, than you'll have to read the docs and search for examples, then you'll need to get very familiar with the documentation because there is no repl. Also Python had 25 years of headstart, so all those libraries are mature, with Rust its often work in progress. If you have fairly small set of task you perform often and you are ok with paying high initial cost of gathering knowledge which libraries you need and how to use them, you may be productive in Rust, otherwise its far behind Python. Where Rust wins is time from "it compiles" to "its production-ready".
Right. I don't know if it will even (be guaranteed to) work if you're using alloc_system rather than jemalloc. It is probably undefined behavior. "The pointer must be returned to Rust and reconstituted using from_raw to be properly deallocated. Specifically, one should not use the standard C free function to deallocate this string." https://doc.rust-lang.org/std/ffi/struct.CString.html#method.into_raw
unwraps are fine for non-production code and are easy to ripgrep for.
Hey, no worries! I apologize that I haven't yet created a bug report on Clippy's repo for this issue, I've been meaning to! I love Clippy and have had no issues besides this one! Thanks for working on such a great tool! :)
For programs/scripts ~100 lines or less that run in a few seconds or less, Python is the clear winner for me. But for CPU-intensive work or longer programs, there are some things to consider. Rust takes time to compile, but you can use `cargo check` to just do all the type and borrow checks for a 1,000 line codebase in a fraction of a second. It's very hard to do type checking for Python code without running it. So hard that PyCharm still gets a lot of the numpy.ndarray operator overloads wrong, and I often have to disable that lint. Simple mistakes at the bottom of a long-running Python script can quickly outweigh the time cost of compilation. &gt; I don't expect anyone to be as productive in Rust as in Python for those types of tasks I agree that it's unlikely, but I'd note that those tasks are largely gated by the quality of available of libraries. When there are Rust libraries available at the level of those for Python I'm not so sure I'd reach for Python to complete such tasks.
Thanks, I got it working. Btw, do you know how to get rust-qthello to compile on linux (raspberry pi)?
&gt; I think the reason behind this is that monospace fonts tend to be wider, so the default font size (medium) is scaled so that they have similar widths, and all other keyword font sizes get shifted as well. Sort of. Monospace fonts tend to be wider, so letters that are round (like "e", "o", "g", etc.) wind up taller, so that they can stay approximately circular, and so all the other lower-case letters wind up taller to match. Typographers refer to this as the "x-height" of a font (literally the height of the lowercase letter "x") which can differ between fonts of the same `font-size`, even among proportional fonts. In prose text, composed mostly of lower-case text, mixing text of different x-heights looks like subtle and annoying changes in `font-size`. To compensate, there's a number of things you can do: - Assume which fonts will be used, and hard-code different sizes that look nice together. This seems like a bad idea, given that CSS has this whole system for selecting fallback fonts, but that's the best option we had back in 1992, so those are the defaults we're stuck with. I don't know where the magic numbers "16px" and "13px" came from, but if I had to guess, it might be what makes Times New Roman and Courier New look reasonably sized in Windows 3.1. - Specifically choose fonts that are designed to have the same x-height, like "Segoe" and "Consolas", or "SF Pro" and "SF Mono", or "Source Sans" and "Source Code", or any of the Lucida family. Unfortunately, not everybody has such a wisely chosen typographic pair on their platform of choice. - [`font-size-adjust`](https://developer.mozilla.org/en-US/docs/Web/CSS/font-size-adjust), which tells the browser to pick font-sizes based on matching x-height, rather than overall size. This is exactly the right thing, but for the longest time Gecko was the only browser engine that supported it. I guess that's yet another horrible wrinkle to add to Servo, though. :) (for a very long time, I've been opting for the second option above. I untick "Allow pages to choose their own fonts" in Firefox's advanced font settings, I pick a nice, size-matched pair of fonts, and set both proportional and monospaced variants to 14px. It's quite surprising how pleasant the Web can be once every page is using *nice* fonts)
RLS still has a long way to go. I was using it with vscode for a time, but have switched back to IntelliJ. I can think of 3 things off the top of my head that have bit me when using it: * Nightly Only * Dual Projects where you have a library and binary (Issue [#208](https://github.com/rust-lang-nursery/rls/issues/208) describes this but has been closed off..) * Proper code complete. While it will work on individual terms and symbols, there is nothing like IntelliJ's `Would you like to implement the missing fields of this struct?` style. 
about the module system. i had problems with it, dont understand it, but can use it. just add module declarations, for example "mod utils", in main file and the use "use" in another files if you need the module. https://github.com/jaroslaw-weber/rust-ox-ui here is example. maybe not best solution but easy to reason about it. im just averagr dev so i think you can learn it. lifetimes may be difficult but other things not so much. and you can copy things around sometimes ;). you can always fix it later
I also got rust-qt_cef_poc working, but when I run it, I get: &gt; [0811/034816.010:ERROR:mf_helpers.cc(12)] Error in dxva_video_decode_accelerator_win.cc on line 480 And when I enter a URL and press enter, it gets logged but the CEF widget doesn't display the site. I only see the signal/slot connection for logging the url, but shouldn't the CEF widget also show the site? Or is that not implemented yet :) It should load google.com by default, but it doesn't, it just shows an empty widget: https://i.imgur.com/HANGIIu.png Which method of the CEF widget do I need to call to display the site?
It's just such a bitch to get up there and cycle the power...
Do note, though, that signal handling across threads is particularly prone to errors. Signals work best when the main thread configures signal handling before spawning any threads. The most reliable option will be using `libc` directly.
Random words on module system woes from rust core dev: https://withoutboats.github.io/blog/rust/2017/01/04/the-rust-module-system-is-too-confusing.html You probably won't find the article very helpful to understand modules, but that's an entertaining read.
Main issue here is that you're comparing a low level systems language (Rust) with a high level non-systems language (Go). Naturally, Go will be easier to learn because the language runtime manages everything for you, for a cost. Yet, if you have already mastered Rust's lifetimes and traits concepts, then there's no gain to be made from using Go for anything. I would recommend writing down areas that you are having difficulty with, and then simply performing a review of those areas to close any gaps in your knowledge. Main difference between Rust and C/C++ here is that Rust's compiler is ensuring that your butt is covered, in regards to managing memory. But I wouldn't worry about Go displacing Rust in any area. Because Go tried to be a simple language specifically for writing simple web services at Google, Go's effectively gimped in every area. No amount of GC tuning or generics can fix that.
It's fun to that you cite _why given that I maintain this crate 😅
True. The more I dove into it the more I realized Go competes more with Java and Node than it is a descendant of C/C++. I still like it for what it is, though. If I don't need to squeeze CPU cycles out of something, it'll be there, at least.
I feel like there's a large decrease in productivity in using rust initially, but a large increase if the project lives for more than ~a month or so. If you go and work on something else, and the come back to a python script or project - there's a chance you've forgotten what each part does, or the interaction between pieces. Unless it's literally 30 lines long, it'll take looking over the whole project to get to know you aren't breaking anything in changing something. With Rust, there's going to be a lot more work initially building it, especially if you aren't familiar with the rust ecosystem - but once the project becomes 'mature', you can be very assured that your small change can't break the entire functionality, and that you won't forget to check for a None value somewhere. If the project ends up with a larger scope than you initially intended in rust, you can also trust your program to still run correctly when parallelized. With libraries like rayon, making use of all resources your computer has to parse CVS files, or do anything else, is as easy as adding a `.par_iter()` call. It can similarly easy in python, but with Rust you're completely assured you haven't introduced a data race as soon as it compiles.
[removed]
*submits many posts about rust-proofing cars*
Others have said everything I considered saying better than I could, so I'll just grab this. &gt; Maybe I'll make a personal library of things I'm shocked aren't in `std` (wrapping arithmetic types, Behold, [`Wrapping&lt;T&gt;`](https://doc.rust-lang.org/stable/std/num/struct.Wrapping.html).
&gt;Coming from assembly and C, it's so obvious to me that any reference (to a sized type) can be a len-1 slice. They're the same thing to the CPU! They are not. A reference and a slice are differently sized (and differently *typed*) things. The CPU and language thus treat them quite differently. &gt;and I don't want to introduce String before the concept of dynamic arrays because if I do the explanation is a little too much "because magic." No subject I have ever studied has ever successfully solved this problem. Learning is a process of refining mental models. Every programmer I know, good or bad, as learned how to use things before learning how they work. It's really not that big of a problem. Humans have always learned *what* is appropriate before they learn *why* it is appropriate. EDIT: Removed my sarcastic comments because they're probably not helpful. In summary: if you have a solution to your problem, use it. Don't complain that it isn't in the proper place. Many great things come from unexpected, non-standard places.
I've been learning Rust and starting working with [ggez](http://ggez.rs/) to make my clone of the Apple IIe version of Lode Runner. (I'm calling it Lode Ruster.) I have finally been able to load all 150 levels into my LevelData struct. And loading my .png sprites. And just finished my render of level 1. Doesn't look like much, but took a good bit of learning to get here. [Screen Grab](http://i.imgur.com/Nm4pD23.png). Now I need to figure out how to display part of a png for my sprite animations.... More learning to come. 
I've found this to be a great way of going about it. I was doing exercism.io in Python, then Rust for each exercise. One to think about the problem. The other to think about the implementation in a new language. I think this is easier that diving directly in only Rust at first. 
*submits many pizza crust recipes*
&gt; This is a misunderstanding of what a slice is. They're not the same thing. If you want the pain and suffering of C, with its loaded footgun, C is still there. A slice is a pointer and a length. Automatic coercion between a reference to a single element (which is just a pointer) and a slice is not "low level", it's magical, and Rust doesn't do it. It's certainly possible to have functions that make the conversion, whether in stdlib or in a separate crate. It would even be possible to do in the language itself, but going from a pointer to a pointer and a length automatically is hard to claim as "the same to a CPU". Well, this is about even the function in the stdlib being deprecated, so I find the above a bit harsh. But I have no idea if a re-inclusion RFC would make sense.
Oh.. what do you mean? Do you happen to known why the lucky stiff.. ?
What does `?` mean in your context? Is there a keyword for it in the context of Rust? Disclaimer: I am a mostly C and C++ programmer who is "Rust-curious" and has sincerely been slowly reading through [The Rust Book](https://doc.rust-lang.org/book/second-edition/) but I'm not done yet and I don't remember everything.
&gt; They are not. A reference and a slice are differently sized (and differently typed) things. The CPU and language thus treat them quite differently. However, the data they're pointing at should be the same. You can see them as different kind of views for the same data in memory. &gt; Don't complain that it isn't in the proper place. Many great things come from unexpected, non-standard places. Personally I'm very pro complaining if things are in the wrong place or missing :)
In some senses yes, and in many others, no. I'll be less cryptic when I'm not on mobile, but if you're curious in the meantime, some googling will reveal answers. EDIT: after _why quit, I picked up some of his projects and continued working on them for a few years. When he came back briefly, I was the one that collected his stuff up and published it. I never knew him personally, but feel a deep connection to his work. It's weird to pick up someone's life's work and make it your own... * http://www.slate.com/articles/technology/technology/2012/03/ruby_ruby_on_rails_and__why_the_disappearance_of_one_of_the_world_s_most_beloved_computer_programmers_.html * https://en.wikipedia.org/wiki/Why_the_lucky_stiff * https://en.wikipedia.org/wiki/Hackety_Hack#Post-Why_development * http://words.steveklabnik.com/closure * https://github.com/steveklabnik/CLOSURE * https://www.youtube.com/watch?v=MaWHVceDbFo * http://words.steveklabnik.com/why-is-a-role-not-a-person
&gt; A slice is a pointer and a length. Automatic coercion between a reference to a single element (which is just a pointer) and a slice is not "low level", it's magical, and Rust doesn't do it. I assume you've forgotten that Rust does `&amp;Type` to `&amp;Trait` coercions automatically. There absolutely is precedent for this. &gt; If you want the pain and suffering of C, with its loaded footgun, C is still there. I really don't see how constructing a `&amp;[T]` from a `&amp;T` is a foot-gun. Could you explain how this is dangerous?
The OP pointed to a discussion about removal of a function providing the conversion. If that counts as magic, everything does. I read the OP as being disappointed that the existing, perfectly fine functionality got deprecated. And really, things like the ability to go from `&amp;T` to `&amp;[T]` seem like they are exactly in Rust's core domain. I certainly see no need to tell people to go back to C over that feature.
Watchdog timers :-)
**tl;dr**: I'm wrapping up a port of ~2k LOC of python/bash automation to Rust and mostly happy with it. Personally, for &lt;200 LOC or anything heavily tied to a particular part of the python ecosystem, I'd take python. Beyond that, I find Rust incredibly "productive." **disclaimer**: I've invested in and written 10x more Rust than Python, and follow Rust pretty closely. So in general it's easier for me to make productivity comparisons with Ruby (or maybe Scala) where I consider myself equally as "advanced/studied/practiced". **background**: We have about 2k lines of infrastructure automation split between bash and python - lot of template generation, shelling out to ansible, terraform, and kubernetes, and a bunch of one-off tasks around ssh, http requests, DNS, SSL configuration, key generation, etc - a real garden variety of tasks. Being a bunch of ad-hoc scripts glued together, it lacks any coherent design. And now we have the 20/20 hindsight to know the kind of pains it has caused. I don't have the 9-5 bandwidth to do anything except for small incremental improvements, but I had an itch to scratch so I devoted some evenings to an experimental Rust port. Here's the good &amp; bad highlights: **the good**: A lot of this boils down to: if it compiles, it [usually] works. One of the big pains before was making a change, running it, finding out something wasn't plumbed through correctly, debug and fix, repeat. * [Askama](https://github.com/djc/askama) - I won't pick out every great library, but compile-time Jinja-like templates have been awesome at catching tons of issues during build. I was even able to port over most Jinja2 templates with a few `sed` one-liners so I can keep my port in sync with upstream changes. If someone adds a template variable I'm missing, I re-sync templates and get a compile error until I plumb it through. Amazing! * Type system. The Python (and Bash) stuff is plagued with null, undefined, or empty strings almost anytime you try to refactor it. And so many uses of strings are better represented as an `enum`. * Errors and Robustness. For high-level scripting replacements, Step 1: add `error_chain`, Step 2: handle errors from `main` by printing the entire error chain. Step 3: Use `?` and `.chain_err(|| "some error context")` everywhere. Most of the error handling stays out of your way, but it ends up being very robust! * rustdocs/[docs.rs](https://docs.rs/) - Most crates I reach for have great docs, and even the ones that don't, it's way easier to piece together how to use it from the full type definitions everywhere in the docs. When a pip package has mediocre docs, I often find myself reading source code to figure out how to use it. * It feels like Rust pushes me to think more about design. I'm not sure how to quantify this, but I can't imagine throwing together a dozen loosely coupled rust files and then having a single file that just drives them all. It seems I'm constantly refactoring a Rust project as it grows, where I'd rather not touch a python/bash script once it mostly works out of concern for breaking something that already worked. That said, this is also somewhat biased by the fact that this port has the hindsight of designing around the lessons learned from the original project. **the bad**: * You really need to be very comfortable with Rust to be comparably productive. So far I'm using 23 crates, 5 unstable features, and have written 3 macros just to get the productivity and ergonomics I want. That works for me because I feel comfortable reaching for these tools, but those numbers represent a significant investment (on top of the infamous learning curve) in becoming highly productive with the language and ecosystem. * Strings and lifetime annotations. I'm comfortable with the `&amp;str` vs `String` divide, but I find myself conflicted between `.to_owned()` a bunch of string literals and slices, or adding `&amp;'a` to every field of my structs (don't ask me to `Cow&lt;str&gt;`). There are a couple Pre-RFC ideas that could make this more pleasant, but for now, it's just an eye-sore for a project that really doesn't benefit from the control. I *almost* wish there was a flag to implicitly make every `String` an `Rc&lt;String&gt;` that is is auto cloned/converted everywhere (but not really). * Verbose. Type bounds are awesome, but at some point I started decorating almost every function with `P: AsRef&lt;Path&gt;` and `S: Into&lt;String&gt;` just so the callees have a more ergonomic experience. Shelling out, even with the help of great crates, also generally feels verbose. Even reading a file into a String seems to always take up 3 lines until I finally caved and wrote `pub fn read_file&lt;P: AsRef&lt;Path&gt;&gt;(path: P) -&gt; Result&lt;String&gt;`. None of these bother me too much, but they are the sort of things that add up as papercuts when working at a very high-level. * Ecosystem - I actually find the ecosystem quite good, but it has gaps. I basically started my own [kubernetes client](https://github.com/anowell/kubeclient-rs) as an extra side project to help fill a gap, but I'm shelling out to `openstack` CLI because the openstack crate is still lacking a bit more than I can chew off right now. * Team buy-in. I've successfully *snuck* Rust into production on our team, but those were lightly-maintained projects that just needed to work. This project will be very active with multiple contributors that aren't drinking the Rust Kool-Aid like me. I do have a strategy for making a compelling case for superceding the original project (delivering new features/value), but I'm uneasy about it because I fear that the rest of my team won't be as productive contributing to it, especially given the dependence on nightly and unstable features. Sadly, this might outweigh the technical perks of the port. So yeah, I do feel very productive at a high level in Rust. I can probably write greenfield Ruby about twice as fast as Rust for the first 2k LOC, but after that point Rust and Ruby development tend to be about on par for me on average (where different tasks favor different languages). But the tables start tipping toward Rust once it needs to be robust, refactored, or actively maintained beyond a couple months. (Whoa that was long. Maybe I should evolve this into a blog post once I wrap this up.)
I read this &gt; Coming from assembly and C, it's so obvious to me that any reference (to a sized type) can be a len-1 slice. They're the same thing to the CPU! &gt; So I assumed that rustc would just be okay with the coercion, or there'd be an easy method like `"string literal".as_bytes()". very differently from you apparently. Together with the context of the deprecation discussion, and that the author knows about other solutions, my view is that the presented problem is that the stdlib doesn't provide a way to do this simple thing.
Shouldn't that be `1.0 / camera.scale` and `-camera.posiotion.0,1`? EDIT: Wait, no, that would be wrong for a "scale", but usually you want a viewport *size*, and it would be one-over for those
I'm a bit lost on trait scoping at the moment. Taking the easy example of `read_to_string` implemented on `File` - you can't just *use* read_to_string if you've brought File into scope, you also have to bring in the Reader trait into scope. Why would I have to do this? In order to implement read_to_string on a File, File would have had to have itself and Reader in scope already? What am I missing here?
&gt; Look for the author "kalitaalexey" (which is this plugin) and install that one. There is also now https://marketplace.visualstudio.com/items?itemName=rust-lang.rust
Which fonts are you using?
Sure, I can see that. `&amp;T`, `&amp;[T; 1]`, and `&amp;(T,)` are all kind of the same thing, physically. But then, so are `12345u64`, `12345i64`, and `12345f64`. Type systems exist because the simple fact that things look the same in memory is not sufficient reason to conflate them. On top of that, you can't just have every unearthly conversion function anybody could conceivably want in the std library; there has to be some curation. These conversions are so trivial.. it makes it even easier to leave them out, as anybody could reproduce the conversions with hardly any effort at all. Some irrational fear of non-std crates and the `unsafe` keyword are not a reason to do anything differently.
This is super interesting, thanks! I was vaguely aware of the typographical importance of ex, but didn't know the exact details.
Today I'm using SF Pro and SF Mono, the latest macOS system fonts, but at various times I've used all the pairs I mentioned in my comment, plus things like Droid Sans/Droid Mono, or Lucida Grande (from old Mac OS X) with Lucida Console (from Windows XP). Since I'm on Linux and can actually configure these things, I generally use the sans-serif font as my standard user-interface font, and the monospaced one for terminals and text-editors, so *everything* is nice and consistent.
That is a really bad mentality to have.
deleted ^^^^^^^^^^^^^^^^0.7075 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/13408)
&gt; you can't just _use_ read_to_string if you've brought File into scope, you also have to bring in the Reader trait into scope. Why would I have to do this? It's because [`read_to_string`](https://doc.rust-lang.org/std/io/trait.Read.html#method.read_to_string) is declared by the `Read` trait, which is implemented _for_ `File`. It's not an _inherent_ method of `File`. You can use inherent methods (anything in an `impl File` block) just by bringing `File` into scope but you have to bring each individual trait into scope in order to use methods declared by that trait. &gt; In order to implement read_to_string on a File, File would have had to have itself and Reader in scope already? True! Whoever declares a struct can implement traits for that struct. But that doesn't make the use transitive. Just because `File` has an implementation for `Read` doesn't mean you want that particular implementation of `Read`. In this case both declaration of the struct and the trait are both in the standard library. In general, a third-party library could declare its own `File` and its own `Read` trait implemented for its own `File`. As a user of multiple libraries you get some degree of choice as to which structs to use with which traits. In principle you could mix the standard library's `File` with a third-party `Read` trait, or a third-party `File` with the standard library `Read` trait, provided the third-party provided such implementations for you. So because you can sort of mix and match, you have to use both the struct _and_ the trait within a particular scope to get a concrete behavior. &gt; What am I missing here? Possibly that the system is designed not only to work with the standard library but with any set of libraries, and to be able to handle conflicts among those libraries. A library you use may define a trait with a `read_to_string` method whose implementation for a struct does something totally different from what the `Read` implementation for the same struct does. How would the compiler choose between `Read::read_to_string` and `ThirdParty::read_to_string` if both are implemented? If only one of the traits is in scope, then it's unambiguous: you use the method for that trait. But if both or neither are in scope then it's unclear. Therefore you must specify by having only one trait in scope or by explicitly qualifying the call with something like `third_party::Read::read_to_string(&amp;mut file, &amp;mut s)`.
Yeah, that's normally how you'd do it but I was trying to keep it bare-bones to explain the maths. You'd probably want to scale X and Y separately to take aspect ratio into account too.
It's rust and rocket so it's very relevant.
&gt; (to people who grew up on Java and Ruby) I seriously dislike this mode of argument. It crops up _all the time_. Systems programmers coming to Rust complain about decisions being made "by them javascript programmers" and it's really not the case. Rust has a _lot_ of systems programmers designing it (as well as PL theorists. And non systems programmers.). Alex has worked on many of the low levelOS abstractions in Rust and is definitely a systems person, in this specific case. There is a _ton_ of exclusionary language in systems programming. There's a major aura of superiority projected by certain parts of these communities. I only hear such arguments in the context of systems, where someone says some decision isn't systemsy enough. Rust makes plenty of decisions for all kinds of reasons, but I never see this kind of argument in any context _other_ than systems vs non systems. This kind of argument is really toxic IMO. It grants the author additional perceived authority, and denigrates the perceived competency of the decision makers by painting them as "just" ruby (or w/e, I'm using it as a stand in) programmers, even if they are perfectly experienced in systems. It also propagates the whole "meh, that's 'just' ruby" where some fields are considered to be super easy. Even if you don't say "'just' ruby", a lot of these programmers have been hearing it often enough that it's implied. To be clear, I'm not calling you out specifically here. I'm sure you didn't mean it; there's a lot of baggage involved here that you, the writer, may be unaware of, but it may affect the reader. I just want you and others to _notice_ this kind of argument and avoid it in the future. Systems programming has been quite exclusionary for a while and one of the reasons I really like Rust is that the community cares about it being accessible to all, and this has paid off with a lot of folks starting systems programming with Rust when they were too afraid to try C or C++. This is a community full of folks from many backgrounds (systems and non systems), and I hope that continues to be the case. ----------- That decision was made for the same reason a hundred other very similar decisions have been made -- Rust wants to keep its standard library small. This has nothing to do with systemsyness; Rust has removed a ton of other APIs for the exact same reason. Now I disagree with this being removed, but I understand the argument. The default path for old pre-1.0 unstable APIs has _always_ been to just remove them. The stdlib has a lot of random bits sticking out from that part, and it makes sense to remove them (they're unstable anyway), and perhaps work on filling the void they may leave behind later. (There's a good chance they won't leave a void behind! You won't know till you remove it!) Rust in general considers "use a crate" to be a _very_ low bar for entry, which shows in the decision making. Again, not something I agree with, but this helps support the reasoning behind the removal. That issue is also two years old. Stuff has changed since then, and I think folks might be more amenable to this being added now. We've added similar helper APIs recently (there was a super interesting one about converting mutable references to Cell, IIRC). I highly recommend writing an RFC for this (or getting someone else to write one). --------- I totally get that you expected this to exist as a C programmer. I don't really have issue with the "as a C programmer I think this should exist", it's the whole "this decision was clearly made by Java/Ruby programmers" (not exactly what you probably meant to say, but again, considering how folks will read it too) that I consider to be an issue. 
That is actually not true. `chan_signal::notify` also blocks the provided signals (partly because otherwise you are not guaranteed to receive the signal via the pipe if it is consumed somewhere else). `chan_signal::block` is really just a convenience function to block signals that you do not want to subscribe to so that you do not have to pull in another crate to do that.
I don't think Ctrl+c exits the main thread which you can see if you add another `println`-statement at the end of the main function. Also, (as far as I) know child-threads are terminated when the program (i.e., the main thread) exits. I think in this case cargo is at fault. If I call `cargo run` and execute `pkill threadtests` or `pkill -INT threadtests` in another terminal, it behaves as expected. Also, if I run target/debug/threadtests directly and press Ctrl+c, it just prints out the message and does not return to the shell. From what I have observed I would assume that cargo on Ctrl+c receives the SIGINT, forwards it to target/debug/threadtests, exits and thus gives back control to the shell, which in turn prints its prompt. I'm not sure if this is expected behavior or a bug in cargo. Maybe someone else can enlighten us.
How can I determine which method to call during compile time? Consider this example: struct AA; struct BB; trait A { fn a(&amp;self) { println!("A called"); } } trait B { fn b(&amp;self) { println!("B called"); } } fn f&lt;T: A&gt;(t: A) { t.a(); } fn f&lt;T: B&gt;(t: B) { t.b(); } fn main() { let a = AA; let b = BB; f(a); f(b); } Is there any way of doing this?
&gt; Do note, though, that signal handling across threads is particularly prone to errors. I think in general `chan-signal` does a good job in avoiding errors by providing a relatively simple API, which does the right thing as long as you do not try to do anything fancy by yourself on top of that (e.g., unblocking signals using libc). However, you do have to remember (and/or just don't ignore the large and repeated warnings in the documentation) to perform all setup before spawning any threads (as you mentioned).
&gt; I'm comfortable with the &amp;str vs String divide, but I find myself conflicted between .to_owned() a bunch of string literals and slices, or adding &amp;'a to every field of my structs (don't ask me to Cow&lt;str&gt;). There are a couple Pre-RFC ideas that could make this more pleasant, but for now, it's just an eye-sore for a project that really doesn't benefit from the control. I almost wish there was a flag to implicitly make every String an Rc&lt;String&gt; that is is auto cloned/converted everywhere (but not really). Some people have suggested "foo"s String literals, and perhaps "foo"rc reference counted strings too. &gt; Even reading a file into a String seems to always take up 3 lines until I finally caved and wrote pub fn read_file Ask in Bugzilla for such simple function to be added. It's simple and useful. 
Is there a reason that methods `a` and `b` need to be defined on traits instead of the structs themselves? If not, try this: https://play.rust-lang.org/?gist=ba8413dbfa411bf47e2630d536c176df&amp;version=stable
RabbitMQ is in Erlang, and that's probably the leading open-source message broker, so it's present in an immense number of companies, particularly in the Railsy/Valleyish part of the universe.
The first question that hits me is: If I have a `usize` (or other integer) parameter in my `StateData` instance, what happens if I attempt to route to `/my-path/not-a-number`? Does it return `None`? Does `StateData` allow the surrounding struct to return a `Result` if any of the fields can fail? Otherwise: Really like the look of the interface, seems to avoid a lot of the magic that web frameworks often rely on. I checked the commit history and it looks like "Shaun" in the signature isn't [sgrif](https://github.com/sgrif), right? The "first class Diesel integration" made me think that it might be. Good work, guys!
How does this compare to rocket? Edit: also the example app is empty.
&gt; "foo"s String literals, and perhaps "foo"rc reference counted strings I do wonder if that promotes "adding overhead b/c it's easiest". But it becomes more interesting to me if it were combined with a simplified form of interpolation, e.g., `s"Hello, {name}"`. But I'm not sure the `rc` variant would be useful without auto-clone of `Rc&lt;T&gt;`. I kinda like the idea of [allowing string literals to be String](https://internals.rust-lang.org/t/pre-rfc-allowing-string-literals-to-be-either-static-str-or-string-similar-to-numeric-literals/5029/16). Combine that with [lifetime elision 1.1](https://internals.rust-lang.org/t/pre-rfc-lifetime-elision-1-1-structs-with-one-reference-field/4914) or [2.0](https://github.com/nikomatsakis/rfc-elision-2.0/blob/master/0000-elision-2.0.md) and most of that eye-sore would go away. &gt; Ask in Bugzilla for such simple [read_file] function to be added I'd kinda rather see it part of a trait (e.g. `SizedRead`: `Read` with a `len()` method and hold to the zero overhead principle), so that it becomes standard in places where the size is generally known (e.g. files, HTTP responses with content-length, etc..). But there are probably some edge cases I don't understand well (e.g. when getting length can fail, like in the case of getting file metadata).
A different Shaun (https://github.com/smangelsdorf), but equally as handsome. We're big fans of Diesel and want to make sure there is eventually a very smooth usage story between the two projects. I believe your first question relates to Extractors, the PathExtractor in particular. If the data type in the Request is not consistent with the types defined in your struct to hold extracted data, in this case a String instead of a Number, Gotham terminates the Request. You can customise what happens when this occurs. The great part about this is that your code is guaranteed to have a valid environment before it starts executing. In the case where you might not always have data coming through, as is often the case with query parameters, you simply need to use an Option&lt;T&gt; and the Request will continue on to your Handler unimpeded. Here is an example of that in action, https://github.com/gotham-rs/gotham/blob/master/examples/kitchen-sink/src/main.rs#L57, meaning you might get from 0..n values for q, without the Vec you'd get 0..1.
Both projects have had a lot of hard work put into them and we wouldn't want to make direct comparisons, there are simply different design decisions that have been made, both of which have their place in the ecosystem. I can say that we're really proud of our usage of stable Rust, our async types and the way we've implemented Pipelines and Middleware. We're also really happy with how our Handler concept has worked out. Another aspect of Gotham we really like is our Router. It is backed by a Tree data structure and can solve some very complex routing needs including delegating routing decisions to secondary Routers to allow for what we call "modular applications". I think of this as being half way between microservices and monoliths, combining the best of both. The Router will be a big focus for 0.2, leveraging macros and/or builders to make route definitions much more along the lines of what you'd see in Rails or Phoenix. We look forward to feedback from the community, I am sure there is a lot we could be doing better or haven't thought of. Edit: Ooops! Looks like a push didn't succeed and went unnoticed. All fixed up now at [https://github.com/gotham-rs/example-app](https://github.com/gotham-rs/example-app)
Actually, you're right! I stripped the example down to https://play.rust-lang.org/?gist=91e46d8b08e9b3a0c8943f32ff42952a&amp;version=stable where no threads are even involved anymore, and the same thing happens because my code just completely ignores SIGINT. When I call the binary from the target directory, ctrl+c doesn't have any effect whatsoever anymore: [13:12]mz1030@mz1030-nb111:~/tmp/threadtests# ./target/debug/threadtests ^C^C^C^CThread exiting! But if I run it through Cargo: [13:19]mz1030@mz1030-nb111:~/tmp/threadtests# cargo run Compiling threadtests v0.1.0 (file:///home/mz1030/tmp/threadtests) Finished dev [unoptimized + debuginfo] target(s) in 0.40 secs Running `target/debug/threadtests` ^C [13:19]mz1030@mz1030-nb111:~/tmp/threadtests# Thread exiting! I posted an Issue here: https://github.com/rust-lang/cargo/issues/4397
I too fully agree with you! I think it's a bit strange to sell Rust as a systems programming language and alternative to C/C++ without stable assembly (or at very least without full collection of intrinsics which cover assembly instructions for supported platforms), SIMD and type-level integers. Maybe it's worth to post your vision on users or internals forum to discuss it more broadly?
Cool! The idea that use derive plugin for adapting types for `State` is great! I will try to port handlebars to gotham as a templating middleware.
Many of us have been working on personal projects for way longer time and didn't get any money from them you know...
Do you have a custom type available that lazily constructs the parameters that can be used in place of `Vec` here? My performance spidey-sense goes off whenever I see a concrete `Vec` being passed around along with the data it's being constructed from.
the other plugin has thorough LSP support too plus other stuff. how is this better? just curious
I've been working on a pet project for 6 or 7 years, hit about 100K LOC in Go and have converted the core to Rust already over the past year or so. I haven't made a cent on it and I don't intend to. Money isn't everything.
[Rust has support for similar syntax for state machines in the works](https://github.com/alexcrichton/futures-await). A lot of patterns are expressed with hand-rolled state machines right now, having language support like Ceu, JavaScript, C#, P and suchlike would be really nice for both asynchronous programming and iterators. I've also got a dream of programming entities in games using this pattern, where you do `let (dt, context) = await tick()` in a loop and your between-frame context is stored as locals.
Congrats on this release and thank you for contributing such well designed work to the community! I'm excited to have new contenders in the web framework space to break up the Rocket monoculture that has existed since Rocket released.
This looks really great! Congrats! 
&gt; what happens if I attempt to route to `/my-path/not-a-number` ? From a web point of view, I would want that to end up responding with `400 bad request` because `not-a-number` should be a number, and optionally some text to that effect in the response body. But the second choice is `404 not found` because there's nothing valid at that url. Sometimes you want to supply custom validation logic, and fail out with a `400` response if the rules are not met.
I haven't used it, but [Cap'nProto RPC](https://github.com/capnproto/capnp-rpc-rust) is built for precisely this use-case
Both the `write()` and `read()` functions return a `Result&lt;T,E&gt;`, which can be either `Ok(T)` or `Err(E)`. This line: let written_bytes = output.write(input)?; Is logically equivalent to this: let written_bytes = match output.write(input) { Ok(val) =&gt; val, Err(e) =&gt; return Err(e.into()), }; The older way of doing it, which you may also sometimes see, is a `try!` macro, which basically expands to what I wrote there.
The choice between those two is semantic depending on the meaning of the parameter. `/add-5-to/not-a-number` is `400 bad request`, `/users-with-id/not-a-number` is `404 not found`. Apparently it's somewhat configurable, which seems to be the best situation to me, although I don't know what configuring it looks like.
You can use this: https://doc.rust-lang.org/std/panic/fn.set_hook.html To set a function to call before exiting. You can use the backtrace crate to get the backtrace: https://crates.io/crates/backtrace
I have the opposite problem — autocomplete is the only thing that doesn't work. Edit: For reference, here's my setup (I'm probably missing something): Plug 'roxma/nvim-completion-manager' Plug 'autozimu/LanguageClient-neovim', { 'do': ':UpdateRemotePlugins' } let g:LanguageClient_serverCommands = { \ 'rust': ['rustup', 'run', 'nightly', 'rls'], \ } let g:LanguageClient_autoStart = 1 " This is probably irrelevant, but I'll include it anyway Plug 'rust-lang/rust.vim' Am I supposed to still use Racer for autocompletion, maybe?
I would prefer Tera which is based on Jinja/Twig syntax https://github.com/Keats/tera 
If you use logging, you can use https://github.com/sfackler/rust-log-panics 
I'm not talking about "every earthly conversion function". I'm specifically talking about this one, memory compatible function. And I don't have an irrational fear of unsafe. Requiring users to go to unsafe for this is a damning statement of Rust's standard library. I have no idea why anyone is so angry at this one function.
I'm skeptical that putting the Rust toolchain itself in a package manager could ever be useful. Particularly on Ubuntu, where a lot of of people are on an LTS, and will therefore have tools 15-20 years out of date (or so it feels). What could be useful is putting rustup in the package manager, and making it play nicely. This is a workflow that i would be happy with, and i think would work really well in general: sudo apt install rustup mkdir piecrust cd piecrust echo 1.19.0 &gt;rust-toolchain cargo --init # this downloads and runs 1.19.0 
I don't think system programming should be an exclusive marker of social class. I do think by it's nature it's *different* from programming in general. C programmers shouldn't be listened to because they're "smarter" but because they have more experience doing the thing the Rust community says it's trying to do. The discussion I linked shows a different kind of toxicity: a representative of a governing body asks for public comment, it effectively goes into executive session, it something *completely opposite* to the few comments it receives, it doesn't explain it's rationale. By all appearances dissent wasn't considered at the meeting. I refuse to blame Alex for this, he was acting as the messenger. To put it a different way, it feels like cultural imperialism to me. There's an assembly, Algol, Fortran, PL, C... tradition and a C, Smalltalk, ... tradition and many others. Then Rust comes along and says to the system tradition "that's nice, but we're going to do what you've been doing, only smarter." Naturally that will ruffle feathers. On a lot of things, Rust is right. Refuse to generate code without necessary bounds checking or an override? *Yes please.* But when closed groups say "eh, whatever, take that out of `libstd` nobody will miss it" that feels exactly like a majority refusing to acknowledge a minority. - Here's an example from my life this week. I'm transgender and have been using a new common law name for the past two and a half years. I also have mental health difficulties that have been keeping me from working. Just recently I started an entry level job - I am literally bagging groceries and was down to my last $20 when I started. On Wednesday, my case manager and I went to petition for court recognition of my new name. The first clerk we spoke to was reluctant to let me file for fee reduction. She said "name changes are voluntary". You know, a luxury. On Thursday I didn't work, but I did go to my grocery store. My manager asked me if I had missed his call and asked why I wasn't in training then. Turns out that he had scheduled training for *a* person with a name that sounded similar to my new name and didn't make the connection to my deprecated legal name. *Ouch.* So that's my situation: I'm broke, my car's broken, and my name inconsistency is leading to hr errors at work. Fees for the entire process total about two weeks of free cash flow for me, and the probate court is half. But the clerk couldn't imagine a name change being a bona fide necessity. It's a similar feeling. I expect that name change clerks see situations like mine (poor trans people probably come up about once a month in that court, I don't know about domestic violence victims). It feels bad to have to fight to have the issue heard. ------ Thanks for your encouragement to write an RFC though. I think I actually ran across a nightly trait `Unsize` that would implement the same coercion for library-defined smart pointers.
The lack of power in the router has been my biggest sticking point with rocket.rs, so I'm really looking forward to trying gotham out. Great work!
In this context, 'low-latency' means 'absolute minimum latency', so if crossbeam is going to add even a microsecond over doing everything by hand, it's not going to get used. I suspect that any useful level of abstraction is going to be too expensive for this particular niche. 
Packaging the compiler itself is particularly important when you are building and packaging Rust applications and libraries. In your control file, you can specify a version of a build dependency, such as rustc (=1.19.0). LTS is not that out of date, and it is possible to provide brand new toolchains if the toolchain has a strong guarantee of stability, like Rust's. Packaging rustc and cargo improves the ability to do reproducible builds using only the package metadata, whereas having the Rust toolchain dependency data outside of the package metadata makes it much more difficult to manage.
The only difference is that the user of a slice must do bounds checking. Functions or locations (any coercion site) that accept a slice can always safely accept a reference to a single value. `T` is exactly one instance of a structure, `[T]` is zero or more instances. The set of values of `T` is a subset of the set of values of `[T]`. Rust performs other pointer-weakening coercions all the time, so it seems irregular to lack this one. The only difference I can see here is the difference in size between a skinny and fat pointer. If that's too heavy for a coercion, `as_slice` makes sense.
While we're talking about toxicity, I'm really disappointed in the responses OP got. A vague aura of superiority is exactly how a lot of the Rust community operates. I see where the OP is coming from, I'm very worried about Rust's direction. But that is not allowed to ever be criticized anymore apparently. Did that one comment that you dislike really warrant a giant wall of text to bash the OP over the head with? Also, I read her using Java and Ruby as a reference to higher level language where you don't deal with such things.
If I want to initialize a local variable of type u16, I can just say `let n = 0u16;` What is the Wrapping crate equivalent? Typed literals require compiler support, so `0w16` isn't possible. So the next best thing would be `let n: w16 = 0;` or `0 as w16` (put the w types in a prelude module), but `Wrapping&lt;T&gt;` doesn't implement `From&lt;T&gt;`. I'll write an RFC for that one too.
What's wrong with `let n = Wrapping(0u16);`?
One thing that kind of bothers me in the Ceu tutorial: They mention that triggering an internal event causes the caller to halt until that event is completely handled. This effectively causes nested handler invocation, which often has lots of unexpected consequences. Deferring the handling of the event seems more sensible to me (i.e. stick it on a queue for processing later), like an actor call. It's the approach I've taken in an actor-like runtime I wrote for Lua modules (at work). IMHO nested handler callbacks should be avoided if possible. (I'm not sure how this might apply to tokio -- is there an equivalent situation?)
Great news! Rocket is missing powerful routing and the author works on useless features like private cookies used by nobody. Any estimates for templates &amp; diesel? Ready to transfer my half a million per month project from php.
&gt; The discussion I linked shows a different kind of toxicity: a representative of a governing body asks for public comment, it effectively goes into executive session, it something completely opposite to the few comments it receives, it doesn't explain it's rationale. By all appearances dissent wasn't considered at the meeting. This is my big issue as well. I believe the source of the problem is that there's no formalism on concensus finding. Which is really hard to do for the final outcome, but I believe would be a lot easier for proposals themselves. For RFCs and such, you have a chance of convincing a community member that there is a concern, and it can be added and must be addressed (it's tracked by a bot) but the community has to somehow manage to get heard. I feel like I've spent the last year being the evil sideliner always yelling that explicitness sometimes has value. Watching a recent IRC language design discussion has made me think that was all for nothing.
Just asked this one on IRC, but I am impatient. So asking here again https://play.rust-lang.org/?gist=4ca1e5a2e6ceef011990bb0924702cf4&amp;version=stable assuming MyThreadSafeStruct is thread safe lockless DS. how do I make this compile? Any type of locks will defeat the purpose of the struct.
I believe there was some "construction from literals" discussion in the past, but I'm unsure where. It might be worth having a look in the issue tracker for previous discussions on how this could be realized.
As an example of the kind of foul-ups you can get with nested handler invocation, consider A notifying B of something, which causes a change of B's state to be notified back to A. So A has two calls running at the same time -- the original call that notified B, and also the state-update call from B. It's unlikely that the code in the lowermost call is expecting A's internal state to change simply as a result of notifying B of something. You can even get into loops like this. Much better to defer the handler call.
Neither of the two main Rust projects I've been working on over the past two years (an OSTN15-compliant WGS84 to OSGB36 coordinate conversion library, and rust-geo) have "earned" any money, but both are in production with third parties, one of which is a fairly large project at Stanford. 
But you are replying to the author of the handlebars crate so it seems likely he prefers handlebars :)
Our config are almost the same. The only difference is that I use `deoplete` for completion instead of `nvim-completion-manager`. I'd say your autocomplete issue is due to your completion setup. I'm still alone in this :(
&gt; Signals work best when the main thread configures signal handling before spawning any threads. That's exactly what the OP is doing.
Regardless of /u/RetraRoyale's emotional state, I think their point is that having the same data representation is not sufficient as an argument for a conversion method in the std. Now, I do agree with OP that the inclusion of such a method is appropriate, but I think citing the [number of downloads of the ref_slice crate](https://crates.io/crates/ref_slice) is more convincing as an argument.
Sure, and if the point would've been made like that, I could fully agree and bring further arguments. I just resent being called irrational. And I find the recent community drift towards "unsafe is no problem, so just use it" to be quite dangerous.
They wrote 'compiled templates', so probably something like &lt;https://github.com/djc/askama&gt;. /u/sunng, do you or anyone else you know of have any plans to write a *compiled* handlebars-compatible templating engine? Your handlebars crate seems to build an AST already, so maybe it's possible to adapt that and compile it to Rust code somehow? I'm not sure how to get a mapping between the structure of the data a template expects and an input type, though. (Askama uses specific structs and derives.)
&gt; We've added similar helper APIs recently (there was a super interesting one about converting mutable references to Cell, IIRC). FYI, this is [RFC 1789](https://github.com/rust-lang/rfcs/pull/1789).
Ten more characters, three of them shifts. Looks ugly. Maybe a better solution is a local alias of `type w16 = Wrapping&lt;u16` and then `w16(0)`.
Glad to see a new stable Rust web framework on the block, now that `iron` development seems to have slowed down. I'll probably wait until 0.2 to try it out, since you said that you want to improve the Router. Looking at the [example](https://github.com/gotham-rs/gotham/blob/e842a5ca92cebd863a146b90de5e862deff3a399/examples/kitchen-sink/src/main.rs#L109) right now, 100+ lines (if you include the `static_route`/`dnyamic_route` helpers) just for setting up 6 routes seems way too verbose. Best of luck!
Thank you! I saw it a few times and then was unable to find it ever again.
That one doesn't seem to work for me, says it has crashed 5 times in the past few minutes. Edit: Nevermind, you have to re-open the whole project folder for it to work. Reading is hard sometimes :(
Thank you for the detailed reply.
&gt; Hot reload during development What is the general idea to implement such a thing? Is there a "wrapper" executable that watches the files, runs the build when they change, then tears down the running server and starts the new one?
Great that someone is working on web framework that is working on stable! I'm not a web developer but found it super easy to start with it and build simple website, but found your framework little difficult. It is probably because I am not used to web dev terminology and only touched some flask. I think good tutorial for web dev beginners would be nice. Also I see that you have HTML in your code but as others said it would be nice to have templates. Thanks for working on the framework, I think web dev is great direction for rust :)
One of my college professors had a strong personal preference regarding the use of the `shift` key and the `-` key. He advised that I write my code like this `numofcharsrecieved` instead of like this `numOfCharsRecieved` because it was "faster to type". I've never understood the fascination with optimizing for typing speed when the 0.2 seconds saved typing is going to be outweighed by the 1 second it takes to read the variable name **every time**.
https://twitter.com/nick_r_cameron/status/886817476276703232
&gt; `/users-with-id/not-a-number` is `404 not found` Though in some cases you may want to return a `403 Forbidden` instead of a `404 not found` to prevent information disclosure of enumerable records.
Based on everything I've read around this secondary plugin, I don't believe that tweet, but I admit that I have never tried it personally. I will have to try it out and see what I discover. Personally, I would rather the Rust core team work together with the existing, excellent plugin, rather than doing their own thing, but I understand that sometimes a fresh start can be nice.
&gt; C programmers shouldn't be listened to because they're "smarter" but because they have more experience doing the thing the Rust community says it's trying to do. Again, _I totally get that_. My problem is not with saying "this is not very C like". My problem is with the whole assumption that the folks making the decision are Java/Ruby folks (i.e. non-systems) or whatever. You don't know who they are. But you immediately painted it as "oh well such a decision could only be made by a non systems programmer". (Also, I'll mention that "this is not very C like" is not in itself a very good justification. By that logic one could argue Rust should get C style for loops, for example. The equivalence of pointers and arrays is a _terrible_ design choice in C. In this specific case that equivalence is actually safe to exist in Rust in a controlled form, but given that Rust is _completely_ different from C it's reasonable to feel like such a thing might not actually be necessary. It exists in C so naturally C has APIs that use it, but does Rust often lead to such situations? It's not a question with an immediate answer.) And again, I don't think you intended to imply any of this (so don't worry about explaining your intent to me, I get it). But such words _do_ imply it for many, and I'd avoid it. Saying that "this is what I expect coming from C" would have been totally okay. People have expectations coming from languages! It's normal! Not all these expectations are ones that should be corrected for by changing the language itself, but they still exist and it's always good to be cognizant of them. But the expectations of one C programmer are not the expectations of all C programmers! Don't assume the skillset of the decision makers just because they didn't make the decision you agreed with. &gt; a representative of a governing body asks for public comment, it effectively goes into executive session, it something completely opposite to the few comments it receives, it doesn't explain it's rationale. By all appearances dissent wasn't considered at the meeting. Not that I can expect you to know that, but as I mentioned the removal of unstable pre-1.0 APIs has a _very_ low bar. This has nothing to do with dissent not being considered, an unstable pre-1.0 API usually gets removed unless there is _strong_ justification for it. Because if you want to keep it, you have to turn it into an RFC, so it's effectively the subteam deciding if they want to spend more time on it. This has to do with a general policy, not with the subteam being tyrannical or something. Rust governance is open, it's done through RFCs. This is an example of a feature added _before_ we were careful about adding things to the stdlib. So it's not an executive session trampling democracy or anything. It's the exact opposite, since features have been added to Rust without going through the community consensus process, and the default thing to do there is to remove them (or if the subteam feels like it really cares about that API, go through the effort of actually _pushing_ it through consensus via an RFC. But anyone can open one, it doesn't have to be the subteam.). Realize that it was unstable, so you can't use it on a release compiler _anyway_. It's not that it was removed fro libstd, it's that it never was in libstd in the first place, effectively. That thread was the team making the decision to _not put effort into "adding" it_ (doing an RFC, etc). &gt; It feels bad to have to fight to have the issue heard. In this case, you didn't have to. I really don't like talking about tone, but your original post was quite confrontational (even ignoring the whole Java/Ruby thing) and probably led to the majority of the response being that way. Just suggesting that we should bring it back without all the cruft would have had a pretty decent response IMO. Again, this is not to reprimand you or call you out, but to better inform future interactions. I'm sorry you had the experience of this week, and hope stuff improves.
&gt; Did that one comment that you dislike really warrant a giant wall of text to bash the OP over the head with? I _really_ tried to avoid it being a bashing over the head, but rather a rant about that kind of argument as a message to everyone to _notice_ this in their writing and avoid it in the future. I tried to make that clear in the post; I mentioned that I don't think that was anyone's intent, but just mapping out what it reads like. It wasn't just the "one comment"; the entire post was structured based on this argument. That one comment was just me quoting the case where this argument was particularly visible. And ultimately yeah, arguments which alienate whole classes of people should be pointed out, and deserve walls of text explaining exactly why they are nonconstructive. &gt; But that is not allowed to ever be criticized anymore apparently. That's untrue. I even _agree_ with the criticism; I think Rust should have gotten this API. I disagreed with the form it was presented in, a form which tends to only further alienate non systems programmers from the field. &gt; Also, I read him using Java and Ruby as a reference to higher level language where you don't deal with such things. What people read and what people intend can be different. I'm not commenting on the intent of the post, I'm commenting on its effect. 
Please don't just call folks irrational.
Where did they write that? As the author of Askama, I'd be happy to work with them the Gotham authors to facilitate Askama support. 
Very excited to see another entry in this space! I think we need a lot of exploration to figure out how best to do web dev in Rust, and this framework is nicely complementary to Rocket. I also love that you're releasing 0.1 fairly early on and iterating in an open way with feedback. I know that can be a hard road to take, but it often produces better results. I wonder if you've seen Cargonauts (https://medium.com/@withoutboats/announcing-cargonauts-db5efaaaf7d2), an experimental framework with some similar goals (in particular, is modeled somewhat after Rails). I'd wager there are some good ideas there that you might be able to use. Anyway, I hope to play with this soon, and am grateful for the thought and work that's gone into it!
&gt; And I find the recent community drift towards "unsafe is no problem, so just use it" to be quite dangerous. I am skeptical this exists. Examples? This specific case isn't even a recent issue.
Above, in the text of this post &gt; There are some important features still to be built and we hope that the community will help us define even more. Right now our roadmap includes: &gt; &gt; - … &gt; - Compiled Templates &gt; - …
What is it with this thread? Please don't call people irrational for things you disagree with.
That would be the case for `/users-with-id/not-a-known-id`, but I don't see why it would ever be necessary for the `not-a-number` case.
&gt; I would rather the Rust core team work together with the existing, excellent plugin, rather than doing their own thing I was not involved in this, but my understanding is that this *was* attempted, but it didn't work out.
Looks awesome! Well done, and thanks. Will give it a go!
&gt; I believe the source of the problem is that there's no formalism on concensus finding. No, it's that it was a stabilization issue for a pre-1.0 unstable API, and that the bar there is _very_ high. Pre-1.0 APIs didn't go through the RFC process. They just landed because someone felt like it. They never went through the formal consensus process that we have now. So with these issues the path forward is typically to make an RFC, and in this case the subteam felt it wasn't worth it (two years ago, when they had a _lot_ more pressing API things to deal with). Sometimes I think these stabilization issues do end up with an RFC-less stabilization, but that's typically for APIs that actually get used a lot and get a lot of positive response. The latter somewhat happened here, but not the former. Both of you are making the mistake of assuming "we don't want to stabilize this pre-1.0 API" to mean "we don't want this API". That is not the case. Gauging consensus is a hard problem. It's not the problem that affected this specific situation.
The problem is that the language forbids you having two `&amp;mut` to the same object existing at the same time, because this is in general unsafe. To do what you want safely, you need to have `produce` and `consume` work within the confines of what you can do with an "immutable" reference. This isn't as restrictive as it sounds, because a lot of the mutations that you'd want to do in this context don't actually require mutable references, e.g. changing the value of an `Atomic`, getting the thing inside an `UnsafeCell` both only require `&amp;Atomic` and `&amp;UnsafeCell` respectively. If that's not enough, you might be able to get away with stuffing the contents of your struct into an `UnsafeCell` and then manipulating it that way. ~~Alternatively, you could do what you're doing now, then inside the thread turn the `Arc` into a `&amp;self` and unafely transmute it into `&amp;mut self`. This will give you the result you want, but I'm not 100% sure the Book doesn't class this as UB. Even if it doesn't, you've thrown away all the synchronisation protections, so you better be *absolutely* sure you don't have data races between the two methods.~~ EDIT: Don't do that, conjuring `&amp;mut T` is undefined. (see /u/my_two_pence's post below.) Use either immutable references or wrap everything in an `UnsafeCell`. 
Transmuting `&amp;T` into `&amp;mut T` is never a good idea.
An example would be [Cargo Safety Rails](https://internals.rust-lang.org/t/pre-rfc-cargo-safety-rails/5535/31) but that's just the one where I remember how to find it. I should clarify, I'm not talking about the removal of the function, but the idea that "unsafe" is nothing to worry about specifically. In this case, I just found "there is an unsafe way to do it" not a good argument for not providing the safe abstraction.
I didn't realize that monoculture existed. I've not wanted to switch back to nightly (as required by rocket) ever since I could switch to stable w/ serde. I'm using iron in my project since I started and it'll probably stay that way unless something bad happens with iron. I've developed a few custom middlewares and it's sort of tuned to the iron ecosystem. Edit: Is there something I should know about iron becoming unmaintained?
Most Linux installs are not huge if you go for a non-graphical/minimal install. Debian and Arch both work well in my experience. Unfortunately it appears alpine is a no-go, which is a bit sad: https://github.com/rust-lang-nursery/rustup.rs/issues/354
I've got nothing against shift, but I still think punctuation needs to be used in measure. `.collect::&lt;Vec&lt;_&gt;&gt;()` is an awful lot of punctuation to type, using various modifiers depending on keyboard layout. `.collect_vec()` is better, less punctuation, less brutal stops and more reuse of that reading comprehension engine one got. (Aside, `.to_vec()` seems like the better name.)
ggez for 2d. amethyst for 3d if you want to do a lot of (fun) work making it possible for amethyst to do what you want. Roll your own otherwise. There's lots of tools that you can use *to* roll your own, like immi, Conrod, gfx-rs, etc, but you'll be doing lots of fairly low-level duct-taping regardless.
Alright, I can see where you're coming from. As I said, I've read the OP not meaning that high level developers lack the wisdom, but that some might not have the need for it. So to me the tone seems quite different. FWIW, your post would've come across a lot less blunt to me if you'd split it up into two posts. &gt; That's untrue. I even agree with the criticism; I was specifically referring to criticising Rust's direction, which tends to go over less well in my experience.
It depends. If it's going to have 500 lines of code, you're going to be the only user ever and you'll watch it as it runs, then Python is going to be the winner by far. However, if what you write will have 10k lines of code or more, be expected not to crash and the planned lifetime will be in years, it might pay off to use Rust. Python lets you slack, Rust makes you do it properly (or, more properly than Python). With Python I always get the feeling the bits of the program don't really hold together well, it feels a bit like made of jelly. Rust's code holds its own shape, in a way. Also, if you're expected to deliver a bug-free product, you need to count the debugging into the equation. You write it fast in Python, but then the bugs just keep appearing. I don't claim to make 0 bugs in Rust, but I feel more confident about the code I write there and spend less time debugging.
I love you for making Stable Rust compatibility a priority! I will use this.
In Rust they aren't the same, &amp;mut T is a mutable type reference, &amp;mut [T] is a mutable slice. One has data, one has data + length of slice. They're different for very good reasons. So you can't go willy-nilly from one to the other. In C, they HAPPEN to look the same at the low level.
&gt; As I said, I've read the OP not meaning that high level developers lack the wisdom, but that some might not have the need for it. You've missed the point. I'm totally okay with the notion that systems programming needs certain things that HLLs do not. That is pretty clearly true. That is true for any pair of programming subfields. I am _not_ okay with the flippant labeling of such decisions as _coming from non-systems people_. The "higher level developers lack wisdom" was something never explicitly said in that post, nor do I think it was intended to be. But this kind of argument comes up often enough _with_ this explicitly said that it's very easy to see the same argument implying it. I did explain this in my wall of text.
It's also not parametric; you can `.collect::&lt;Vec&lt;_&gt;&gt;()`, `.collect::&lt;BTreeSet&lt;_&gt;&gt;()` and so on - anything that implements the `FromIterator` trait is fair game. `.collect_vec()` locks you into one type of data structure and couples your iteration system to your ability to allocate heap memory, which is a bad look for a systems language. e: I could see allowing omitting inferred type parameters, though, which would reduce it to `.collect::&lt;Vec&gt;()`.
I wasn't only talking about this feature specifically, but the problem in general. The problem is that often final decision comments, summaries and such don't take everything into account. And if it was taken into account, it isn't mentioned. This isn't out of maliciousness but out of volume, which is why I mentioned procedure. The recent Deliberation Period post on i.r.o tries to counter a similar problem space. It didn't help that the decision in this case talks about deprecation. If it had said "this might be part of a larger scope API consideration that hasn't happened yet, so stabilisation is post-poned" it sends a very different message. Later in the thread it is mentioned that it can come back, but it's easy to miss because the thread kinda switches topics.
&gt; If it had said "this might be part of a larger scope API consideration that hasn't happened yet, so stabilisation is post-poned" it sends a very different message. Which has pretty much been the default for all such threads. It has always been the case that you can and should open RFCs for features you want added. Like, I don't fault y'all for not knowing this, but there's _context_ to this. Old threads have context. All threads have context, but the context for old threads is harder to see, since it's no longer the current context.
&gt; You've missed the point. I'm not sure what you're replying to. I have agreed with you, and given an explanation as to why my interpretation was different. How can I miss a point I did not counter?
Do you have a roadmap or rough list of stuff you want to add next? (I looked through the website and the git repos and did not find it) EDIT: I just found the bullet list in the original post :) tnx.
That's not what happened. But this is getting far in the weeds and is really unimportant so I'm going to drop it here.
I understand. I can't even follow the current pre-RFC module discussions fully, and they're still in the present. A postponed tag might've helped context-wise, but hindsight and all that.
More straightforward to have a catchall "not authorized or doesn't exist" response that's identical so you don't accidentally reveal implementation details. For example, the default response to a request for an arbitrary key in AWS S3 is 403 unless the object exists and you have permission to view it. The one difficulty is explaining that detail to confused developers ;)
I don't see the dissent on the safety rails proposal to be making that point. (At least, when I read it a few weeks ago, things may have changed). It seems to be saying "we don't want to overly stigmatize unsafe", which is a _very_ different point from "unsafe isn't a problem, just use it". There are legit reasons for using unsafe. We should never stigmatize unsafe so much that people fear using it in those cases. They should still be _careful_ about it, but that's a completely different axis from feeling _bad_ about writing it in the first place, if it's a legit use case. Most of the dissent seems to be of the form that this solution is really a bad proxy for the actual problem (which involves elements of trust; and ultimately involves noticing "legit" unsafe). I quite liked nrc's auditing feature since it closer matches what I would wish to use. I think really nrc's comment "I think this would both demonise unsafe code beyond what is reasonable and give a false sense of security." sums up most of the dissent pretty well -- it stigmatizes unsafe _beyond what is reasonable_, and is not really a coherent solution; and it's solving the wrong problem.
Sorry, is that better?
To clarify: it's undefined behaviour to do so. No exceptions. Even if you know that there are no other `&amp;T`s lying around, and that your newly constructed `&amp;mut T` is unique, you will *still* have invoked UB. The only way to legally transmute non-`mut` into `mut` is through `UnsafeCell`, because this type has been blessed by the compiler. 
Thank you.
Thanks for the info. Hopefully the musl work means better Posix compliance and thus portability. 
TIL, and edited the grandparent to mention that. 
It doesn't really have anything to do with POSIX, as far as I know. Just changing the build system to better support dynamically-linked musl-libc targets.
Honestly, I've been at this thread since last night and am kind of losing energy. So I'll just take one quote from the discussion that I feel summarizes my issue. &gt; Stigmatizing unsafe is based on flawed premises that code using unsafe is not trustworthy, and that code without unsafe is safe. That is the point I take issue with. Because code without `unsafe` is supposed to be at least memory safe. Requiring absolute safety is the "nothing prevents all errors" argument. And `unsafe` code that I can't audit is untrustworthy to me. I never trust `unsafe` code, I trust some of the developers and teams using it, so it's an external trust situation. I'm a high level programmer. Some of the details of unsafe programming are surprising and down-right scary to me. The fact that I fear `unsafe` doesn't seem bad to me at all, quite the opposite. I don't really see much talk about `unsafe` being bad itself (at least in the Rust community), I see talk about handling the different safety implications between safe and unsafe code. A feature like the one mentioned would be a mechanical way to audit dependencies for use of `unsafe`, which allows for excluding parts of the project from the need for memory safety audits. I find that a reasonable demonisation, if that phrase makes any sense.
Is a less generic method bad to provide? `.as_slice()` (on Vec) and `.to_vec()` (on slices) seems to say no, it's ok to have less generic and more direct methods too. (Both of those have more generic variants like `AsRef::as_ref` and `ToOwned::to_owned`.) I'd love to have `.to_vec()` on iterators. Not because it's the only method you need. But it's one you often need. 
Typically what I'd do is if you want to spawn a `Future&lt;Item=(), Error =E&gt;` you'd do: core.spawn(my_future.then(|result| { match result { Ok(()) =&gt; { /* yay! */ } Err(e) =&gt; { /* handle error here */ } } Ok(()) })); 
Continuing work on my experimental UI framework. Layout is kind of working with alignment now. Text layout is still slightly off. Also clipping isn't perfect :) I've got border support working nicely with the help of WebRender :). I'm going to try to do images next, and perhaps more complex layout containers to allow for a Grid like arrangement instead of just vertical / horizontal stacking. [here's a screenshot](http://imgur.com/a/f1FeM) 
^(Hi, I'm a bot for linking direct images of albums with only 1 image) https://i.imgur.com/vHBzLTT.png ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20dlhd1d9) 
We are in a position where we can't really release due to publishing permissions. Makes it hard to maintain when you can't release.
Do you really need a wrapper? You could use the `map_err` combinator, or `or_else`. Something like: Core::spawn(stream.for_each(func.or_else(|e| Ok(eprintln("Error: {}", e))))
I didn't say unwraps were good for RLS. Please don't judge my mentality without providing insight. Unwraps cannot "Haunt a [Rust] Codebase" in the way that exceptions and null can haunt Java.
hygenic macros that have more features than just text substitution, custom derive, and I think even the "build.rs" script being written in Rust, capable of using any of the crates in the rust ecosystem as dependencies without building them into the final application is awesome. Don't forget the great type inference engine, and numeric type suffixes (like 32u16) are nice to have. The true generic type system is also much more advanced than the templating that C++ does, although it doesn't support some features like const generics yet. Rust Strings are a pointer and a length, which is huge, because you can have interior nuls (pretty sure) and finding the length of a String is O(1) and doesn't run the risk of a buffer overflow like it does in C. Rust also handles UTF-8 correctly by default. The whole Send + Sync marker trait situation is also amazing. SDL2 is an old C library that must be operated from a single thread. I am currently [writing a library](https://github.com/coder543/sdl2_mt) to wrap SDL2 safely for multithreaded operation, and Rust is keeping me from doing anything illegal with SDL2.
https://forge.rust-lang.org/platform-support.html x86_64-sun-solaris is listed as a tier 3 platform, which means there are no guarantees and no official builds (but it should work). That chart has a check for std and rustc, but not cargo; you'd need to find someone who's actually used it to know more about what works.
Traits are a pretty neat concept.
Type safety - no null pointer exceptions! No exceptions - never wonder if this function can fail (and if it can fail, what the possible exceptions you can catch are) again! Lifetime semantics - never invalidate an iterator again! `Send` and `Sync` - never hit data races again! Traits - not only can you write generic functions, but you can write _generic implementations_ of interfaces. Also, no more `new BigNumber(54).add(new BigNumber(46))` Tagged enums - never worry about checking the index method for returning `-1` again!
Fearing unsafe is good. People are cautioning against fearing unsafe _too much_. Sure, I take issue with that comment too, but I don't see a trend as you say. I'm not asking you to prove the existence of a trend to me, just saying I doubt this trend exists :) There will always be folks making comments on either side of the extremes. Also that same person expanded on the comment later and it's more reasonable. They point out the situation is pretty nuanced, and that the proposal is blunt in conflating trust with safety too much. Which I kind of agree with.
you could publish an iron2 crate.. but that is really unfortunate.
How does one tell if one has a legitimate use case? I've seen a pile of `unsafe` code driven by misunderstandings and premature optimisation, and most times that I look at unsafe code posted here, I find something incorrect. I'm not sure of a good way to encourage people to try harder within the bounds of safe code other than aggressive code review and general fear of unsafe. TBH, the "unsafe isn't something to be feared"/"it's okay but remember to be careful" arguments, or, at least, their consequences, aren't that far off the "you're doing it wrong"/"a real *X* programmer wouldn't make that mistake" excuse for vulnerabilities in unsafe languages. In other words, I think the theory of what you say is all well and good, but it doesn't work in practice.
&gt; "why would you use Rust instead of Java/C#" I wouldn't. There are some small-to-medium things about the Rust language that are better than Java. Type inference, enums, tuples, non-nullability, Result instead of exceptions, probably others. But they're pretty modest. To get them, you have to give up the freedom to allocate and pass around objects anywhere, a giant community and ecosystem, and the best tools available. If you don't actually need the performance Rust gives you, i don't think it's a good tradeoff. I love Rust, and i wish i could do more of my work in it. But i don't. 
&gt; No exceptions - never wonder if this function can fail (and if it can fail, what the possible exceptions you can catch are) again! I'd rather have exceptions than panics. edit: I should give this context - as a Java developer working with other Java developers, panics feel incredibly weak relative to runtime exceptions. While I much prefer using Result everywhere it isn't possible - unwrap exists and will be used, and bugs will cause panics. As a Java developer I would like to be able to better understand those panics at the handling site, even if that just means "i can retry this payload" or "I can't retry this payload". Since this topic is about targeting Java developers I thought I'd throw that out there.
Yeah. I've considered a few things, but there are some really good alternatives now and iron has a synchronous model so moving to async would require a lot of ecosystem work. I'd argue we'd be better off working on alternatives or doing a ground up rewrite and just not calling it iron.
&gt; [rust] traits are a pretty neat concept. C++ concepts are a pretty neat trait.
Cool name, but you can't beat Gimli. It's top quality. Seriously though, awesome work! I might check this out.
Well, you can probably tell that I disagree that it's too blunt :) It's perfectly possible that I'm imagining that trend. I'm worried about it because if it would become more prevalent it would put a bit of a dent in my ability to some day use Rust professionally, but I reconigze that that might be specific to my situation. My perfect solution would be a fusion of the two. A blunt one to make sure no dependency sneaks in unsafe code where I'm not expecting it, and other more precise tools to ease the auditing of the unsafe code where it is used.
All the articles listed by /u/brson in his [fireflowers](https://brson.github.io/fireflowers/) blog post are good sources because all theses articles are describing _"The Rust Programming Language in the words of its practitioners"_ (quoting /u/brson blog post). On the opposite, [this post](https://graydon2.dreamwidth.org/218040.html), wrote by the author of Rust, goes the other way around and lists all the bad things that Rust doesn't have.
&gt;"why would you use Rust instead of Java/C#" You mentioned it already, but the reason *I* don't use Java(/Scala) is because `cargo` is too good. 
I would advocate *against* new syntax, to avoid splitting the ecosystem, however the other two seem definitely possible: - logical proofs could be added by using lints; an interface should be stabilized for lints, and a framework for inter-procedural analysis, however this is possible to an extent, - optimizations could be obtained by rewrite rules, also known as procedural macros; the timing with lints gets tricky (the lints should come *before* the rewrite), however it might be possible. In the absence of rewrite rules, a possibility is to use *pre-conditions*: that is, the user is responsible for using the faster alternative, however the lint system checks that the pre-conditions of said alternative hold at the call site at compilation-time.
Nor have I. After trying out Rocket for a while, I decided to give Iron a try, and ended up loving Iron. I'm very excited to try Gotham as an alternative. One of my favorite things about iron is how spectacularly well it's documented. I hope Gotham follows in those footsteps!
I'd say the package management situation for Rust is the best I've seen out of any of the languages I've used so far. The build system is also so well integrated into the language, better than anything else I've seen.
Thanks for targeting stable Rust! I realize that it likely results in a less-pretty API than Rocket, but there's plenty of us who are happy to make that trade. :) More competition is good!
Yes, essentially I feel the same way about the perfect solution, it must incorporate trust and safety as separate but related things, not under the same umbrella (but probably in the same tool)
On this specific point, I much prefer annotating the type on the variable side: `let v: Vec&lt;_&gt; = (...).collect();` I find `: Vec&lt;_&gt;` less "good luck in reading that" than `::&lt;Vec&lt;_&gt;&gt;`.
Hmm I'm not sure I see the issue with this comment. If I were to classify it in the [Graham's Hierarchy of Disagreement](https://en.wikipedia.org/wiki/File:Graham%27s_Hierarchy_of_Disagreement.svg) I'd put it in the counter argument bucket which seems like good, healthy discourse. Your comment seems to imply it's ad hominem even tho he's specifically criticizing the fear his professor had and not the professor himself. 
All in all, and it's a joy to work with.
Is there more info on this predicament? Like a GitHub issue or something?
Oh, agreed. I do think the Rust community needs to improve on this, and I think further stigmatizing unsafe code is a good step. I'm wary of stigmatizing it _too much_. Both sides are bad. When I say legit use case I generally am talking about things like rayon. And _absolutely_, people do not know what is and isn't legit. That is _precisely the point_. You know how Nightly crates are stigmatized (rightly)? The fear expressed in that thread is that the same will happen to unsafe crates; where folks will be _so_ averse to unsafe that they will be like "no, that doesn't count, if you can't implement it in safe you can't implement it at all, because people don't use crates with unsafety." The risk basically is that folks start from "unsafe=bad" and overapply the tool, trying to stay "safety clean" (much like how you try to stay 100% stable) way more than necessary. This would destroy Rust's credibility as a systems language. We already have "oh you can only do it in nightly that doesn't count" (a good thing!). If this applied that broadly to safety too we'd have a major problem. The proposal doesn't address this at all. There's a difference between the intent of a tool and how it actually gets used, and tools need to prepare for that. Awareness of what is and isn't "good/legit unsafe" within the community is not that great, and within that context it is not unlikely that people will overuse the tool. Basically there's a more fundamental problem that needs to be addressed here. I think it's a legit fear that the tool will be overused. I don't strongly believe in it but I completely see where it's coming from. I didn't perceive much of the dissent within that thread to be "let's not do this", it was "I see this bad outcome, let's do this better/differently".
That's a great point too!
&gt; Maybe it's the framework Rust deserves, but not the one it needs right now. i like what you did there \^_-
You're not alone. I share your setup and it seems to be pretty flaky at the moment. Mine was working yesterday when I added keybindings, for example, but only autocomplete works today. The only thing I've done is a `rustup update`. 
The comment was edited FWIW. People weigh tradeoffs differently. It's not constructive to say someone's weighting of a tradeoff is irrational compared to yours. It is possible for a point of disagreement to be a good counter argument and _simultaneously_ have elements that are vestigial and not constructive. 
I wouldn't call something that terminates the current executable "hot reload", because I expect a "hot reload" to preserve state. It's mighty hard, and you best not have changed your ABIs...
What sort of publishing permissions do you mean? Are the restrictions due to your current job? I only ask because I think it's a real shame that Iron isn't being maintained and improved more actively. It's a great project, for reasons many have detailed here and elsewhere.
&gt; Rust Strings are a pointer and a length Actually, no. They are (pointer, length, capacity), just like C++ `std::string` without SSO (Short String Optimization). On the other hand, Rust's Strings are guaranteed to be valid utf-8, not just any blob of data.
&gt; They are (pointer, length, capacity), Fair enough... they are effectively a wrapper around a `Vec&lt;u8&gt;`, so they do have pointer, length, and capacity. My bad.
I just want to add (also so I'm not just a grinch in this whole discussion), I believe Rust can and will make lots of headway with making `unsafe` a lot more approachable. Usually there is a language/ecosystem split (Python/C, Perl/XS, ..) but Rust's way of integrating things makes it all a lot more learnable in my opinion. It also helps that there's an awesome docs team. But the underlying danger is something I feel you can't get rid of. I'm hoping for a wide variety in tooling ideas to help everyone feel in control according to their comfort level with unsafe things.
**Move Semantics** (done right). The interesting thing about Rust is that memory safety is just a fallout of ownership + borrowing, and those concepts can be reused for *other* things. I find C++ copy constructors and move constructors **clunky**: - it's very easy to accidentally make a copy when you should have used a reference; there's no warning, and suddenly you are making a memory allocation (or a 1000s, it's a deep copy) without meaning to, - it's very easy to move from a variable and accidentally use it afterwards, - because moves run custom code, the compiler has little latitude to optimize things away. On the other hand, in Rust: - making a deep copy requires a `.clone()`, and shallow copies are only allowed for `Copy` types, - moves are tracked at compile-time, so you cannot accidentally use a moved-from variable (and puzzle over bugs at run-time), - moves are bitwise copies, which do not require zeroing the source, making the compiler happy. The latter point is about performance, but bears repeating. An idiomatic use of `Vec::insert` in Rust is *faster* than an idiomatic use of `vector::insert` in C++ when inserting before the end, because in Rust it's a `memmove` whereas in C++ it's a loop to move each and every element (and hope there's no exception). The point about compile-time tracking of ownership means that you can encode *powerful invariants* and have the compiler check them for you: I can create a state machine, with one state being represented by one type and each transition being a function consuming a state and producing another, and I'll get a compile-time guarantee that I cannot accidentally apply a transition on a state I already transitioned from. **Affine Types are awesome** like that, and I have a feeling that much like C++ template we are only touching on the possibilities they offer.
its a friday i am glad you two are keeping me awake at my desk
It's the readability and opportunities for error that matter, not the raw input time.
I have publish permissions on some of the repos, other people have publish permissions on other ones. We've tried to get it resolved a few times but it's hard. :(
great, that's a nice solution :) Thank you!
https://github.com/iron/urlencoded/issues/68 gives some background. Basically a lot of us can publish to some crates but not all. That combined with the fact that iron is so split up over different repos/crates means it's really hard to roll out updates. (I'm largely against how Iron is structured repo/crate wise)
I love the error handling. Using the crate `error_chain`, it all feels very natural. It's the first language where error handling just feels like a part of coding.
This is that I have this statement several times, which is why I'd prefer a wrapper.
Here are some summarized paraphrases from the [list](https://www.reddit.com/r/rust/comments/6kkgz7/according_to_stack_overflow_rust_is_the_most/djmvslo/) I wrote a while ago: * The ability to use enums to comfortably write things like protocol serializers which give "can't serialize this" errors at compile time rather than runtime. * An equivalent to Java's `Optional` that's used consistently throughout the standard library and nulls that are disallowed at compile time except for in the "raw pointer" type, which is confined to `unsafe` blocks and intended only for C FFI. * The ability to know you've handled all recoverable error conditions just by looking at the function signature. (I've actually learned about failure cases I'd missed in POSIX APIs from this.) * A type system powerful enough to implement a useful subset of the "session types" concept. (eg. [Hyper](https://hyper.rs/) will catch "trying to set a header after the body has started streaming" at compile time.) * Predictable memory usage with less risk of leaks than in a GCed language. ("Less than" because you need to explicitly use something like `Rc` to create a cycle and you can be more cautious when doing so.) * No data races (Dropbox [has said](https://about.sourcegraph.com/go/go-reliability-and-durability-at-dropbox-tammy-butow) that this is the most insidious type of problem they run into when coding in Go.) * Locks you can't forget to acquire or release. * Hygienic macros, as an escape hatch for those times when there really is no better option without giving up the compiler's ability to check things. Also, while not in that list directly, I quite like how Rust's enforcement of owned vs. mutable borrow vs. shared borrow has utility for writing idiot-resistant code above and beyond the variables themselves. (eg. In one of my projects, I have a wrapper for interacting with the filesystem in certain ways and I use `&amp;mut` to indicate operations which would have lasting side-effects outside the current process, such as writing/deleting a file or opening/closing a CD/DVD tray. This actually legitimately caught a mistake in a unit test once.) **EDIT:** Sorry about the transient bit of BBcode. Too much bouncing back and forth between here and forums while distracted, it seems.
I've always been a fan of some subtle details around how core things are named. * Common things are short: fn, box, let, vec, rc, u32, option, result. This matches natural language (a, as, the, me, you, him, her, ..). This lets us breeze past the common/minor things easily. * Conversely more dangerous/extreme things are longer: copy_nonoverlapping, get_unchecked, from_utf8_unchecked. Again matching language -- "stupendous" is more extreme than "great". This encourages us to pay more attention, and take it more seriously. (caveat: when overdone potentially a maintenance burden) * Similar primitives generally have equal length, and are named to avoid suggesting one is the "default": u32/u64/i32, f32/f64, usize/isize. We're biased towards the shorter/simpler names, so "float" and "int" seem more attractive than "long", "unsigned int", "double", "uint", or "int64". Unsigned integers are often neglected in other languages for this reason. Rust's names encourages the programmer to reflect on the *right* choice for the problem. * "best practice" defaults. Often languages will provide a convenient default mode for declarations, but the community's "best practices" tell you to prefer something else whenever possible. You might disagree with those best practices, but at least the language is consistent with them. * Apparently things should be immutable by default, so `let` is shorter than `let mut`. Constrast with `const` is many other languages. * Apparently things should be private by default, so `struct` is shorter than`pub struct`. Contrast with "private"/"protected" in other languages. Now, to be fair to other languages: many of these things are a result of Rust being new, and being able to benefit from experience. Backwards compatibility is a hell of a drug, so Rust is probably only going to get worse at this over time. (see: `pub(crate)`, `Trait` vs `impl Trait`, `*mut` being awful, and mooore!!)
A good point, but since that's what I have to do *now*, at least automating it so I didn't have to switch to that window would be nice ;-)
&gt; Rust BESIDES speed/memory safety? &gt; "why would you use Rust instead of Java/C#". ... aren't there languages on the JVM and CLR that have those additional features (pattern matching etc) - F# etc. Rust incurs costs (extra markup), which you pay if you *need* speed *and* safety. Slightly tangentially, but possibly within the spirit of your question, *my* interest in Rust versus *C++* (where I need the *speed*) is nothing to do with *Safety*:- - no header files. - yes, pattern matching, enum - better type inference (shows up when throwing lambdas around) - expression based syntax - easier to declare everything initialized - better macros - better lambda syntax - transitive immutability by default (hope to avoid need for 'restrict' eventually), - move semantics by default. - controlled globals (no way to say 'this doesn't touch globals' in c++) - tuples (easy to group values/have multiple return values) However if you are comparing to Java/C# (and have the option of other JVM/CLR languages) some of those go away. Seems we are doomed to suffer header files etc in game/engine dev...
Ah, I get it. Thanks. Shame this can't be worked out more easily. If there is anything others in the community can do to help move things along, please let us know. And apologies to the Gotham folks for this sidetrack about another project. It shouldn't detrack from the awesome work the Gotham team is doing. It's much appreciated.
- error handling, `c++` exception force you write code that should be ready for interrupt at any point, you should use `RAII` everywhere: you swap two values (how you should handle exception and free resources), you call `f1(f2(), f3())`, what happens if one of function return resource, and other throw, mix with that order of calculation is not defined, plus convert one exceptions to another on layers border not suitable thing, on other hand return error code is not supported on language level, you have no rust `enum`, so `Result` is not for you - No integer promotion and other implicit casts, like `unsigned char ch = -1; assert(ch == -1);` - compiles and abort on assert - basic coding style forced by compiler, no `Qt` naming scheme vs `std::` in one program - `match` gives compile time error if you missed something - `Mutex`, `Sync` and other thread safing mechanizms - `macro_rules` hygiene - yes macros and plugins for compiler is not easy, but it is much more easy to read them `template` + preprcessor magic - You can reuse other code without tremendous efforts via `crates.io` - you can write units tests near of your code and that is out of the box, without some magic from preprocessor and build system - And of course borrow checker - compile time checking of `println!/format!/etc`, yes this feature has `gcc` for `printf like`, but not `VC++` - `C` ffi is simple enough, not as good as in `c++`, but not bad - llvm usage, so many optimizations and many platfrom supported - no function name overloading and default parameters (plus not explicit casts), so you understand what function you call here
Every week, I seem to get a Rust plugin update, when I open PyCharm for either Python or Rust. I played with VS Code for a month, and in that time the Rust plugin got MUCH better.
Panics are exceptions, and they're considered solely for unrecoverable or programmer errors. Almost all code uses `Result` and has the error reflected in the type.
There are [builds of Rust available for SmartOS](https://twitter.com/jperkin/status/707132609969725441).
I am uncertain of their applicability to your use case, but some random thoughts on this: * Is it possible to have the loop execute outside of the `GameLoop`, and in an outer function instead? Though this struct would just be a `Game` by this point. * The observer pattern typically requires some reference cycle, which is arguably not desirable. An alternative is to have a `Command` enum like this: `enum Command { DoNothing, AddScene(Scene), RemoveScene, }` And have each scene returning one of these after each `update()`, as to let the game loop know what action to take.
http://www.rustacean.net/ doesn't use any gendered language, so cannon-wise, not yet answered.