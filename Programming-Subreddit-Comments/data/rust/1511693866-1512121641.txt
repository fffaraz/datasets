This link seems to lead to a 404.
And on the main guillaume‚Äôs blog page too, the blog seems a little broken
I have this line of code: let linecard = match Card::parse_str(line) { None =&gt; return Some(i as u64), Some(c) =&gt; c }; It works, but I'm wondering if there's a shorthand for that. I looked through the docs for `Option`, but the only thing that came close seemed to be `unwrap_or_else`, but I can't make the closure call return for the outer function.
Both work for me. Just a caching issue on github side maybe? The generation process is a bit weird.
&gt; Finding tech content, and Rust content specifically, in my native language is not really common. I find it very refreshing when I get to read Portuguese posts. As a native French speaker, I can certainly empathize with you. The primary reason that drove me to improve my English was that most of the tech content was (and still is) in English. It's no so bad for university students and young engineers, but it is quite a bar for a large portion of the French population who just doesn't speak English well, including the kids and teens who are interested in computing but have to do with often poor French material.
Undefined Behavior happens a lot at the LLVM IR level. Imagine the following piece of code: enum Bool { True, False } fn print_bool(b: Bool) { let x = match b { True =&gt; 0, False =&gt; 1, }; println!("{}", x); } rustc knows that `Bool` can only ever be `True` or `False`, but LLVM doesn't know about `enum`, so how can this be translated to LLVM IR? Since last week, the match will be translated to something like: switch (b) { case 0: x = 0; case 1: x = 1; default: __builtin_unreachable(); } And LLVM will rely on the fact that `b` *should* only have values 0 and 1 when it reaches this statement to optimize it to `x = b`. However, in doing so, it exploits Undefined Behavior. For if ever `b` arrives there with a value other than 0 or 1 (corrupted memory?), then the `default` branch would have been reached.
I'm not sure what to answer to your first question. WebAssembly is a new compile target. WebAssembly certainly has amibitions to be the new executable platform for the web (and elsewhere), but that might not be relevant for a whole lot of people. The native WebAssembly target in `rustc` [was enabled just yesterday](https://www.hellorust.com/news/native-wasm-target.html) and is thus available in the nightly build. That means it just got easier to use &amp; test it (No more Emscripten hassle). But that also means there is not a whole lot of tooling &amp; integration code ready to use yet and with everything in nightly it is unstable and might (and will change) eventually. It will take some more time for it to be *just another target* for everyone.
It works now
With current Rust, you can use the `?` operator in `Option&lt;_&gt;`, which does exactly what you want.
i'm gonna try it out now
Would that not return `None` if `parse_str` returned `None` itself? I'd want to return `Some(i as u64)` in that case. I'll edit my post to clear up that code, to bad there's no preview button on reddit.
Thanks :)
Only in some cases, yes, in particular, method calls. The reason why you need to do it automatically is: &gt; Box also has as_mut function, which is why you have to get through the box first - so that the compiler would see that you are using Option::as_mut. 
I hope my original comment didn't come across as dismissive or (heaven forbid) sarcasm. None intended - `structopt` has a lovely API. My only concern is about the overhead required for _small_ utilities. So here's the first test program (all done with stable compiler): extern crate structopt; #[macro_use] extern crate structopt_derive; use structopt::StructOpt; #[derive(StructOpt, Debug)] struct Opt { #[structopt(short = "a")] alpha: f64, #[structopt(short = "v")] verbose: bool, } Otherwise, clap-based argument parsers give very pretty output, but this is not a personal priority. For big applications that multiple commands as well as flag options, the overhead is necessary; personally when I do small little apps (where the payload is small) I prefer to control the overhead. This may be my 20th C C-programmer background, of course ;) fn main() { let opt = Opt::from_args(); println!("{:?}", opt); } This is 1.4s debug build time, 1.2Mb stripped release size. The lapp equivalent: extern crate lapp; fn main() { let args = lapp::parse_args(" Test lapp! -a, --alpha (float) correction factor -v, --verbose chatty output "); let alpha = args.get_float("alpha"); let verbose = args.get_bool("verbose"); println!("{} {}",alpha,verbose); } 0.6s debug, 448K stripped release (With this version of the compiler, 'hello orld' is around 324K). 
What might cause some difficulty is that you first need to understand how to call C functions using the FFI - mapping references to pointers, how to pass strings and all that.
&gt; @colinmarsh19 removed semicolon note. The PR title is misleading - this one *adds* a note "please remove this semicolon".
I remember running into the same issue when learning Rust. It still sometimes trips me up, e.g. when assigning a value to a mutex-protected variable (must dereference the `MutexGuard`). Would it be possible to create a better error message for assignments that don't compile because the left hand side has to be dereferenced, possibly more than once?
Maybe! I'm not an expert on the way errors are made.
This is amazing; basically we now have the most convenient setup for wasm, and it's only going to get moreso.
Indeed. Updating, thanks!
`fn some(&amp;self)`?
Only if you need the old value though. Otherwise `*ref = val` is the preferred way to assign.
Decentralisation as in not having a central authority. 
https://www.reddit.com/r/playrust/ dont think this is the rust reddit think its for some program
Ok. Thanks!
This is not the subreddit you're looking for. :p 
Trying to make a codebase work, I know this is manual and could be done so much easily but the point is to try it manual. #[derive(Deserialize)] pub struct Coordinate { x: f64, y: f64, z: f64, } struct State { x: f64, y: f64, z: f64, len: usize, } #[derive(Deserialize)] pub struct TestStruct { #[serde(deserialize_with = "deserialize_add", rename(deserialize = "coordinates"))] state: State, } fn deserialize_add&lt;'de, D&gt;(deserializer: D) -&gt; Result&lt;State, D::Error&gt; where D: Deserializer&lt;'de&gt; { struct StateVisitor; impl&lt;'de&gt; de::Visitor&lt;'de&gt; for StateVisitor { type Value = State; fn expecting(&amp;self, formatter: &amp;mut fmt::Formatter) -&gt; fmt::Result { write!(formatter, "an array of coordinates") } fn visit_seq&lt;V&gt;(self, mut visitor: V) -&gt; Result&lt;State, V::Error&gt; where V: de::SeqAccess&lt;'de&gt; { let mut ac = State {x: 0.0, y: 0.0, z: 0.0, len: 1}; while let Some(v) = visitor.next_element()? { ac.x += v.x; ac.y += v.y; ac.z += v.z; ac.len += 1; } Ok(ac) } } deserializer.deserialize_seq(StateVisitor) } Which is not exact but really similar to https://serde.rs/deserialize-struct.html But I get an error in the ac.x += v.x; line. error[E0619]: the type of this value must be known in this context --&gt; src/json_pull.rs:51:25 ac.x += v.x; ^^^ I've tried several permutations but no idea of what's going on.
&gt; I hope my original comment didn't come across as dismissive or (heaven forbid) sarcasm. Not at all! Sorry if my reply sounded defensive, I'm genuinely curious to see if parts could be trimmed down. It's always good to hear real world use cases too so that I'm not optimizing for some made up place holder. Thanks for all the info! :)
I think you shouldn't worry too much, because you're providing a full-featured library. It would be a great amount of work to specify optional functionality using features, and I'd guess most of that functionality resides in `clap` anyway.
You call it by saying `Str::some()`, as long as the `A` trait is in scope.
It says type must be known, so try supplying type information: while let Some(v) = visitor.next_element::&lt;Coordinate&gt;()? { ac.x += v.x; ac.y += v.y; ac.z += v.z; ac.len += 1; } ([playground](https://play.rust-lang.org/?gist=7660879d577129e6698f6769bf4ac294&amp;version=stable)) Since `SeqVisitor::next_element` can return any `T: Deserialize`, conpiler doesn't know you are expecting a `Coordinate`.
https://news.ycombinator.com/item?id=15780702
/r/playrust
nope
No, you're looking for reddit.com/r/playrust
oh i thought this subreddit was more like a "general" subreddit to the game instead of the shitposting one r/playrust nvm sorry 
You could check out Mles, it has a stable websocket proxy implementation available.
Ah, I see. In that case, your example is probably a good way to do it (without knowing the rest of the code it's rather hard to tell).
Great news thanks for this 
You can now experiment with RLS here https://github.com/rust-lang/rust-enhanced#rls Please give feedback to https://github.com/rust-lang/rust-enhanced/issues/210
do you want me to updoot this on HN?
Couldn't you use std::mem::replace to make it plainly obvious what the code does, then discard the result? Like this: let _old_val = mem::replace(&amp;mut v, new_val);
I fail to see how this is more plain than *v = new_val;
Thats awesome! No need to compile emscripten anymore! Nice! :) 
/r/playrust
This is awesome. I can‚Äôt wait for all sorts of WebAssembly stuff to take off. I‚Äôve been working on [wasm-cross](https://github.com/WebGHC/wasm-cross) to make a Nix toolchain capable of WebAssembly cross compilation. As someone who barely even uses rust, let alone hacks on rustc, how hard would it be to try and make rust work with this toolchain? It comes with musl libc and an lld port for WebAssembly. The main thing it‚Äôs missing is the actual implementations of the syscalls =P But it‚Äôd be great if I could just tack on Rust support fairly easily and have it just work once I get the syscalls working. EDIT: the readme in wasm-cross is a bit outdated. The same musl checkout is used for all platforms that it targets. `wasm-syslib-builder` is now obsolete, in favor of https://github.com/jfbastien/musl. I‚Äôll update the readme with this and some other info soon.
If you want performance without purity, stainless-steel has Matrix, BLAS, and lapack crates that are native bindings to optimized matrix math. I‚Äôve had good success with them for high performance large matrix stuff. 
https://orly-appstore.herokuapp.com/generate?title=Offensive%20Rust&amp;top_text=Resource%20management%20and%20offensive%20measures&amp;author=kioba&amp;image_code=33&amp;theme=4&amp;guide_text=Integrity%20and%20Security&amp;guide_text_placement=bottom_right
This is so very cool. The javascript 'glue' that was previously required with emscripten was definitely a point of discomfort. Just a heads up about one of the demos: they use a `fetchAndInstantiate` utility function, but there is neither a definition of or reference to this function. For others who are confused by this: it's defined [here](https://github.com/mdn/webassembly-examples/blob/master/wasm-utils.js#L6).
Right, still got a lot to do to make this all easy to use and understand. There's even a tiny bit more code involved in order to use strings, it's all in https://www.hellorust.com/demos/bundle.js
You meant to post this on r/playrust. This subreddit is for a programming language called Rust.
Thanks! Is there any way to keep using the `cwrap` and `ccall` functions? Those were very convenient. Or were these part of the emscripten glue?
I'm working on a program to generate Ramsey Graphs. I have a working program in C and I'm trying to port it over to Rust. I have working single threaded even faster than in C, but I'm struggling to multithread it. In the C version the longest part is checking graph isomorphisms. I start with a list of (potentially millions of) graphs, and go through and split it up into chunks according to some labeling scheme. The starting index and length of these chunks gets pushed onto a threadsafe stack and the threads pick out chunks off the stack. As it goes through each chunk it sets a flag inside each Graph struct to true, and when all the chunks are gone and processed, the main thread removes all the graphs with the flag set. So the problem is this relies heavily on shared memory and Rust isn't too happy with that. I've looked at split_at_mut to generate the chunks from a Vec&lt;Graph&gt; but I haven't had any luck. At this point I'm not sure if this sort of paradigm is even feasible in Rust, and that's what my question is about. How do I efficiently give threads access to a single Vec? I suppose I could in the main thread create another Vec&lt;Vec&lt;Graph&gt;&gt; with each list, but then I run into the same problems, where different threads have access to the same vector. And then on top of that I'd have to copy over gigs of data which I'd like to avoid. So is there a way to implement this safely in Rust?
Ah, that make alot of sense now, thanks for the explanation
I spent 2 years in Brazil, and would be more that happy to make sure a good translation is available. :)
Could it be that there is an error in the `newString` utility? My strings are getting garbled when passing them to Rust, in the sense that they are getting seemingly random suffices. It may be the case that we're not zero-terminating strings in that function. Adding `module.memory[ptr+len] = 0;` as the penultimate statement in that function seems to work for me.
The last time I stumbled upon programming related reading in my native language (Swedish) was probably 15+ years ago in school. From my perspective I am very happy with how the IT world has embraced English, it has given me access to material that would've otherwise simply been out of my reach. When I started out programming in the 90s as a kid the only material I had access too were a few books in Swedish, and oh boy, they were bad (rediscovered them recently and flipped through some chapters). This might be a controversial point of view, especially when replying to a French speaker ;) but I hope that we get more people speaking English rather than more technical reading in other languages.
D'oh! I copied old code, I fixed [the same issue once alreay](https://github.com/killercup/wasm-experiments/blob/master/src/type-converter.js#L141).
[Working on it](https://github.com/killercup/wasm-experiments/blob/master/src/wrap.js#L17-L19)
ü§ò
I'm like halfway through the book and I'm going to (ha) remake my old C CLI programs once I find time, probably tomorrow morning
Have you looked into the libraries that provide scoped threadpools, like [Rayon](https://docs.rs/rayon/0.9.0/rayon/) or [Crossbeam](https://crates.io/crates/crossbeam)? This can potentially help solve whatever problems you had with accessing chunks by reducing the constraints preventing you from passing mutable slices to threads. And if that doesn't work, then writing a tiny core of your own unsafe code is not a horrible option.
That would be awesome if you could help with that. I guess that means you liked it as well, so thank you (: The original content is on Github if that helps with the process https://github.com/bltavares/presentations/tree/gh-pages/nunca-ouvi-falar-de-rust
Simply: cargo install cargo-wa cargo wa setup cargo wa new my_project cd my_project cargo wa run If you wanted to play with the new backend today but didn't really know what to do you can use this to play around with it. Just make sure the directory is set to run on nightly in rustup! It's far from perfect and could definitely use some work in many areas but this makes it much easier to experiment with it without having to muck around with things. Leave issues on the repo if you run into any problems or have possible suggestions!
I was going to ask about [wasm-gc](https://github.com/alexcrichton/wasm-gc) integration, but I checked the source and it was already there! Nice.
Always looking for comments/criticism. There may be an easy linux program for this, but when I looked for a way to do this in windows, all I got was a non-supported program called FolderAxe. In a nutshell, this programs takes a directory, and splits it into part directories such that each file in the original directory appears exactly once, and that no part directory with more than one file (or sub-folder if the `--recurse` flag is not set) has a size greater than the maximum part size.
Very good bindings. I've tried really hard to get tag reading right using a decodebin and dynamic pads and I've failed miserably. For some reason I don't get the tags like language code and title for subtitle streams. Are there bindings to gst-discoverer?
I quite agree that having a common language allowed me to learn so many different topics because I could read, as you've mentioned. To bring a different perspective, learning English in Brazil is quite expensive, both time-wise and money-wise. A few private schools will teach you as a discipline during high-school, yet it is not most of school that have English available as part of the program. You end up needing to attend to private language lessons, which are not that cheap. This content is mainly targeted to beginners, and it has been covered so many times in English by others. It's mostly a summary of other discussions, with links to allow further exploration and bring up interest in the language and community from others that might have not build enough interest in Rust because they don't understand what it allows and provides. It might be confusing to understand about why we find the language so awesome, if you are having trouble with the translation. So I've been focusing on reaching those that have trouble getting started because of the language. The introduction in english is very well covered, as there are so many presentations on so many conferences already available online. While English will indeed unlock so much more content, we could meanwhile welcome them with introductory content at least. It helps a lot with the learning curve of the language when you don't need to worry too much with the cognitive load that a layer of translation causes. Videogames have been catalysts into learning English. Maybe picking interest in Rust would be a nice learning catalyst as well, as they dig deeper and more english is required. Just my 2 cents :)
Can you create a GitHub issue with testcase for reproducing your problem? Then I can take a look There are currently no bindings for GstDiscoverer, but I know that someone is working on it currently and they should be available rather sooner than later.
Well it's more of an issue of me being bad at using gstreamer, rather than a specific issue with the rust bindings. I couldn't get it to work with the python bindings either.
Grilled! I've just published a new version of `relm` with async support. There's now multiple [`connect_async!`](https://docs.rs/relm/0.11.0/relm/macro.connect_async.html) macros. [Here is an example.](https://github.com/antoyo/relm/blob/master/examples/async/src/main.rs#L133). Thank you all for your work.
This is correct. Event if the method body doesn't need access to any fields and you still want it as an instance method for whatever reason you just add &amp;self or &amp;mut self as the first parameter.
... Or rather a problem of the docs not being sufficient :) In any case, if you want to share some code so we can solve that together just do so. Maybe the mailing list would be a better place https://lists.freedesktop.org/mailman/listinfo/gstreamer-devel . But a github ticket would also work, and maybe we can then transform that into an example application.
Mouhahaha! (And thank you for your work as well)
Does not work silently on my computer. cargo wa new myproject does not create any directory. 
Try `cargo update` and then doing it again; this is locked into a specific version of a nightly-only dependency from 11 months ago that's broken a lot in the meantime.
Since I like light-on-dark looks I added my take on a dark theme for rust docs; a full page colour inversion. body { filter: invert(0.911) !important; background-color: #222 !important; } Simple and it works. Plus it should be pretty future-proof in handling style changes upstream, a problem many user styles have. You can grab it from [userstyles.org](https://userstyles.org/styles/150560/dark-rust-documentation) and install with [stylus](https://addons.mozilla.org/en-US/firefox/addon/styl-us/) or similar.
Same error unfortunately (just to confirm, i did cargo update and then xargo clean and xargo build)
in my understanding, zinc is a bit dead. I wouldn't be surprised if it's just straight-up broken. That said, you also don't *need* zinc. Is there a specific reason you're trying to do this exact thing?
I've tried a bunch of other versions (zinc-less) and I always run into some problem with xargo. I was hoping this would work because the github user who I'm following (blasagna) got it running and we haven't been able to debug it on my computer. Short answer is I just want to run rust on my 1bitsy and start a project. 
https://www.reddit.com/r/playrust/
 Thank you! Yes, it works perfectly!
Same here. The problem is the clap setup is for "cargo wa" but the dispatching code expects "cargo wasm". It *still* doesn't work on my computer because CORS requests are denied for file URLs, so you need to use a local server like [http](https://crates.io/crates/http), but it's a good start.
/r/playrust 
This looks pretty useful, thanks for sharing! A variation on this that I sometimes need is when some borked process spews out a bunch of files (thousands) into a single directory, to the point where you can‚Äôt really do anything with it from the command line and even a lot of tools fall over b/c internally they naively just list all the files in the directory into an array or something. Having a tool like this that would just automatically partition a giant directory into manageable subdirectories would be great.
This program uses the `ReadDir` structure in `std::fs`, which just contains a `fs_imp::ReadDir`, so I can't say that it won't also try to store the files in an array or some other fragile structure. One thing I can say is that the functions that walk directories in this program are all non-recursive, so it should keep performing well into *very* nested folders. Thanks for taking an interest!
Don't buy microtransactions. Also, don't post about the game rust to /r/rust. Post to /r/playrust.
Why didn't you use a crate that does the recursive directory traversal for you? From a brief glance, it looks like it would let you delete a chunk of code from your crate. Also, at least on Unix, the readdir struct holds a single directory entry. If you have a depth first iterator, then you should only need memory proportional to the depth of the tree to walk it.
* Programming exercise to do it myself. That's good news about the linux implementations of `ReadDir`. My iterator is depth-first as an implementation detail right now, but that might change in the future.
You don't really need unsafe code here, just N*cores*-1 calls to `split_at_mut`.
i like skins so fuck off
k
Here's what I'd suggest: - Use a channel since it has a nice API for this - Use `rx.try_recv()` so you don't block if the channel isn't ready - Use `gtk::idle_add()` so the task doesn't interrupt the main thread - `cargo build --release` :) So it looks like this: gtk::idle_add(move || { match rx.try_recv() { Ok(msg) =&gt; { window_clone.add_messages(&amp;msg); window_clone.show_all(); window_clone.scroll_to_bottom(); }, Err(TryRecvError::Disconnected) =&gt; gtk::Continue(false), Err(TryRecvError::Empty) =&gt; gtk::Continue(true), } }); 
Should disable for images
`thread::spawn` still won't have any truck with references, so some gymnastics (or the mentioned crates which do them already) will still be necessary.
I'm sure there'd be support for a PR that adds this within rustdoc directly which would include a theme toggle of some kind. I know I'd be interested.
Does it work to do `python3 -m http.server` in the directory? That's pretty much the easiest way to get a server running.
Yes, any local server gets it working.
parking_lot has a RWLock which can be locked recursively: https://amanieu.github.io/parking_lot/parking_lot/struct.RwLock.html
Is it possible to have images in rustdoc?
Yes. https://docs.rs/turtle/1.0.0-alpha.6/turtle/struct.Turtle.html#method.set_pen_size
Is that a logo clone? Nice.
This looks so hot
I love it.
If you could PR this as a theme toggle in the official documentation I'd love it even more 
Can also do `fn some(self)` to take `self` by value.
&gt; $ rustup target add wasm32-unknown-unknown --toolchain nightly &gt; error: toolchain 'nightly-i686-pc-windows-gnu' is not installed I'm guessing that just having `nightly-x86_64-pc-windows-msvc` installed isn't good enough? I removed the GNU toolchain to avoid updating something I never use.
Excellent. I forked it and made an issue for myself. :) H√° tempo que pratico falar em portugu√™s, ent√£o t√¥ animado -- preciso enfiar a l√≠ngua sempre, hein?
By default, rustup on linux stores the API docs locally in `file:///home/username/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/share/doc/rust/html/std/index.html`, which doesn't seem to match any of your filters.
Try grabbing their Cargo.lock and use the exact same nightly compiler version.
Yup! It's a logo inspired library for Rust. :) http://turtle.rs/
Definitely needs to be disabled for images. Makes them look very off.
In the rust- doc-book there exists a theme switcher, surprised to learn that it's not in the api-docs. Since both projects are on github, maybe try and make a pull request that transfers the feature. Paint brush at the top left is a theme switcher. https://doc.rust-lang.org/book/first-edition/
&gt; Well it's more of an issue of me being bad at using gstreamer, Everyone (except maybe its developers) is bad at gstreamer. It's clunky as hell to use and impossible to figure out what the problem is when things do not work. If you actually want to get the job done, use ffmpeg-sys. The higher level crate is way too incomplete and undocumented to be of use. 
Yeah it's really hard to use well, but it's also really powerful. I'll take a took at ffmpeg-sys, but right now docs.rs can't even show the docs.
ooooo, interesting idea. Works pretty well, I must say!
&gt; but it's also really powerful In theory. In practice everyone uses ffmpeg because no one can figure out how to get gstreamer to work. &gt; but right now docs.rs can't even show the docs. Yeah such is the state of these libs. I think the docs work if you include it in your project and run cargo doc --open. 
Isn't that just a `par_iter_mut()` from Rayon?
I can *only* see 83 as an emoticon.
I'm still working on my GameBoy emulator. God, this is not easy...
I have encountered several times now a situation where I need to count the number of bytes or characters of a stream *per line*, and it's a headache to have to look up the `awk` function, or come up with the magical incantation of `xargs` and `wc`. Additionally, support for Unicode is iffy. I figured this is a good opportunity to simultaneously learn Rust and more about Unicode, so I decided to write a utility like `wc`, but has the ability to count things per line out of the box, and is Unicode-aware. I'm also thinking it may be a good candidate for parallelization with `rayon` or something. https://github.com/dead10ck/uwc It's still in its very early stages, but I managed to get it counting things today. I've learned how unfortunately lacking Unicode support is in the Rust ecosystem. [unicode-segmentation](https://github.com/unicode-rs/unicode-segmentation) is helpful, and what I've decided to use for now, but it only exposes its functionality through iterators, which makes optimizations difficult. e.g., doing all the counting in a single pass is impossible, since I'd need to be able to tell the difference between a grapheme cluster that's a word separator and one that's not. There's also [rust-unic](https://github.com/behnam/rust-unic/), which looks like it could be more useful, but its status is unclear; there appears to be two months of work in master that haven't been released yet.
I am currently learning Rust with the book and exersism.io exercises. I am a web developer by day, but I am really enjoying the language! Does anyone have a suggestion for a project to tackle when I have finished going through the book?
I'll be continuing to work on my scheme interpreter. Over the last week I fixed some bugs and removed all(?) of the remaining panics. I started work on supporting more data types, which was an abysmal experience. R7RS has a very simple grammar for identifiers that ensures they can't be confused with numbers, but every implementation I tested takes a dump on the standard and just says anything goes. I believe I managed to get support for "real" scheme identifiers, which allows things like `\n` as a valid identifier. I also have parser support for all of the number types, but I'm not looking forward to supporting arithmetic operations. This week I think I'll finish implementing numbers and look into supporting vectors. I also need to look into what is needed to support continuations. Supposedly CEK machines make this easy, so I'm planning to read about them.
Yes, author here. I‚Äôd love to provide my readers the most idiomatic examples possible, if you have any specific suggestions and a bit of time I‚Äôd be more than happy to see a pull request about it and I‚Äôd also edit the original post‚Äôs code samples. The url is https://github.com/peteyy/rust-url-parse If you don‚Äôt have time to implement maybe a few suggestions would also do, if I‚Äôll have some time today I‚Äôll add ‚Äòmap_err‚Äô PR on the repo maybe a review could also be helpful. Thank you for your feedback anyways! üëåüèº‚ò∫Ô∏è
[mio_httpc](https://github.com/SergejJurecko/mio_httpc) is coming along really well. I've implemented a simplified interface for non-streaming request/responses. Websockets are next thing on the TODO list.
Picked up [ptyknot](http://github.com/BartMassey/ptyknot) after a long hiatus, and actually got it mostly working good, I think. Then picked up my [rpassword mods](http://github.com/BartMassey/rpassword) that ptyknot was intended to test. Full of deadlocks and races and terrible automatic file closures. Almost but not quite have it straightened out. When it's done, rpassword will read from /dev/tty on UNIX systems to avoid messing with stdin. If I ever get rpassword fixed up, I'll finally finish my Rust [ciphersaber](http://github.com/BartMassey/ciphersaber) implementation. It works fine now, except for using a UNIX-only function from a poorly-tested non-standard rpassword. Yak shaving. Rabbit holes. Hooray.
Great, I'll be using that!
Thanks
But it's as in c++ is an deoptimization?
I'll be working on Molten, a style-preserving TOML parser. A few contributors have helped me speed things along last week, and [you can help too]!(https://github.com/LeopoldArkham/Molten/issues)
Here's a list of beginner projects I keep: * Common cli tools: * ls * tree * find * cp * grep * less * ‚Ä¶ * Games: * Breakout * Tetris * Sudoku * Tower Defense * Snake * ‚Ä¶ * CHIP-8 Emulator * Brainfuck Interpreter * Brainfuck Compiler * Game Of Life * Raytracer * Webserver; Find this at the end of the new book 2.0 * WebSocket chat server * GH or Reddit bot You can also jump into a crate that has some easy issues on GitHub... I just so happen to have one [here](https://github.com/LeopoldArkham/Molten/issues)
Thanks, I've added a rule for this
I hadn't considered images being used in docs, I've added an exclusion. Thanks for the example!
Rustup sometimes bungles the default toolchain on Windows. I don't remember how to fix it at the moment but I had this issue at work the other month and I'll try to retrace my steps tomorrow
Would you mind sharing the updated version?
Yep it's at https://userstyles.org/styles/150560/dark-rust-documentation you can grab the raw css out of there too if you want.
Thank you very much :)
Yes it's nice, my userstyle isn't touching the bits with this option. Hopefully they'll extend it to the docs and I can throw my 2 (now 3) CSS rules in the bin!
Invert filter will break font hinting, not much of a problem with hidpi screens, but it'll either remove hinting or worse : it'll be awful to read if hinting is inverted üòä
Would be surprised if it made it into the official codebase as it's a bit brittle to be applying filter to the entire body. I know CSS is brittle at the best of times, but still. Works well as an addon, but I'd expect to see a "real" dark theme in the actual codebase for the sake of maintainability.
Any good podcasts about rust you can recommend? Something along the lines of GoTime podcast for Golang 
I don't like how `u64` is interpreted as the number of times a parameterless argument is supplied whereas `usize` is interpreted as a parametered argument. I don't have anything else to say about this library, though, and its use of `enum`s for subcommands is very ergonomic.
http://www.newrustacean.com/
Nice idea! &gt; github.com/**softprops**/cargo-thanks And a relevant username ;)
I find your reply very enlightening, thanks for sharing :) &gt; Maybe picking interest in Rust would be a nice learning catalyst as well, as they dig deeper and more english is required. Absolutely agree. 
Nice ! Do you intend to separate it into a library and an executable, to be able to reuse the library ? That would be great for e.g. IoTs or other embedded projects.
Primarily it's a semantic decision if the type is not `Copy`, because it means that calling the method would move the subject. Other than that, like in C++, it's only a pessimization if the copy time outweighs the indirect access penalty inside the function.
Interesting! But this only works with intergers right now, right? I've spend some time [on this little thing](https://github.com/killercup/wasm-experiments) to write a small wrapper that exposes Rust function to JS, including simple (and unsafe) type conversions. Maybe my tool can be used by the transform? It's currently only aimed at node.js, but should work in a browser without much difficulty. (Though I'll have to optimize it for size and reduce the dependencies to make it slim enough.)
It'll be a busy week. I've just taken a few minutes to merge/comment on some diesel PRs, and I hope I can find some time to work a bit more on [my WASM wrapper](https://github.com/killercup/wasm-experiments) for JS.
Heya, Rustify author here. Very cool, yeah haven't thought it through too far yet. Type conversion would be great; we should definitely add it! Was thinking folks could use Rustify in both Node + Browsers too; e.g. depending on the env it does the right transform. Sounds like we have similar goals! ‚ò∫Ô∏è
Awesome! I've probably spend too much time fiddling with pointers and converting buffers in JS :) Feel free to use my code in Rustify! I'm 90% certain that it'll work without changes with browserify's shims (e.g., for Buffer or fs). It shouldn't be too hard to turn into a library you can use, too, but its dependency on `text-encoding` (to correctly deal UTF-8 strings) add quite a bit of bloat. Also, you'll probably want to change the wrap function so it generates JS source code.
Let me know how to help over GitHub. √â sempre legal praticar! Existe um grupo em portugu√™s se voc√™ quiser continuar conversando sobre Rust e voc√™ est√° convidado https://t.me/rustlangbr
I don't have any of the gnu stuff installed, and it worked.
lib.rs on your root src/ folder should export module A, using pub mod A; The structs in the mod.rs file inside src/A/ should also be public.
If I have a datatype like this: `Arc&lt;Mutex&lt;Fn()&gt;&gt;` How does a thread call the "Fn" protected by that Mutex without having the Mutex locked (i.e., after releasing the mutex)? I have to use a `Mutex` because I'm using a `Condvar`
I already intend to add alternative styles in the official docs.
You could only import one trait rather than all of them, but generally, importing the prelude is easier. &gt; So what if i use 5 functions returning Result&lt;A,B&gt; with 5 different A's and 5 different B's we will need to make 10! This is not true; you only need to import each *trait*, not each function.
Just for info, a full alternative dark theme is available [here](https://blog.guillaume-gomez.fr/articles/2016-09-16+Generating+doc+with+rustdoc+and+a+custom+theme) (even if it's getting a bit old). Also, as a side note, I intend to add alternative styles in the officials docs. I just have a few other things to do before this.
Importing each trait can take a lot of time and space as for me. May be better store all the traits in traits directory and import them all via glob `*`. May it be design issue or it will be good in complex project?
You don't need to import everything. But prelude modules, by convention, only export things you're supposed to use very often. So you don't need to use everything, but often you will. That's why examples always show those imports with stars.
You seem to be complaining about both the import everything way AND the import a couple of things way at the same time. I don't really see how differently importing could be done nor how differently other languages do it. Can you point out what were you expecting to do?
Still working through tests on [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis) to support integer storage types. Ended up implementing multiplication and division with a literal right-hand-side and cleaning up some float tests this last week.
I've finished the work to integrate asynchronous methods in [`gir`](https://github.com/gtk-rs/gir/pull/490) and the result was integrated in the new gtk-rs release. I also added some [`connect_async!` macros in a new release of relm](https://docs.rs/relm/0.11.0/relm/macro.connect_async.html) to be able to take advantage of these asynchronous methods. [Here's an example of how to use asynchronous methods with relm.](https://github.com/antoyo/relm/blob/master/examples/async/src/main.rs#L133) I also started the semantic analyzer for my implementation of the language [tiger](https://github.com/antoyo/tiger-rs/tree/master/tiger). Like parsing, doing the semantic analysis in Rust can be troublesome (i.e. you want to look an identifier for calling a function, and then when you want to analyze the arguments, you might want to mutate the environment), so I'll try do find out a solution for that which avoids cloning.
Ok. Look at this short example. C ++. file1.h contains a struct called `foo`. file2.h includes file1.h and defines struct `bar`. It can use struct `foo`. file3.h includes file2.h and can use both `foo` and` bar` and defines struct `baz`. So in file4.h just including file3.h will be able to use all of them. But in rust we have to add modules in each file incrementally. file1.rs defines `foo`. file2.rs defines `bar` uses file1; file3.rs uses 2 modules file1 and file2 and defines `baz`. file4.rs uses already 3 modules. An so on until the use of directives will take a half of the file. May be i'm exaggerating but in large project it can create a number of problems with module imports, can not it? I'm just noob and the language is young, may be it's an issue. It's better to fix design issues when they are not too big
So C and C++ don't have proper imports. They have a precompiler that bunchs everything into a big file then it calls the compiler on that. ( Not really, but it's done as if it was ) It might sound like the same thing we do, but the C way hides a bunch nasty bugs that would make you lose days trying to untangle. The case you've mentiones is exactly one of them. In C it's good practice to #include everything you're using, even if you know it's already included by another .h file, unless the .h file with the same name as your .c file already includes it. Or something like that. Like in C++, in Rust you don't need to import things that your imports import to do whatever you're doing. If module A uses module B, you don't need to import anything except module A. There are some exceptions, tho: 1. If you're also using module B and A doesn't reexport B, then you'll need to import it. This is the case in good C and C++ projects as well. 2. If you have a function that gives you back a trait, you'll probably need to import that trait to use its methods. But if it is only module A doing that then you should not need to do that unless it's passing around the trait to you. Number 2 is rust-specific and it is a little bit of a wart that might or might not change in the future, but in no way it causes the import explosion you've seem to be seeing. tl;dr: You only need to import whatever you're mentioning in your code. If your use block is getting out of hand, it might be a sign that you need to refactor your code into more files. If you're interested in how a big rust project look like, just look at Servo's github.
How could I attach glib mainloop-aware signal to my own structure? Are there any examples? In glibmm (c++ bindings) there is sigc, which can be within any object (even if it was not inherited from gobject), is there anything similar in rust bindings?
This isn't possible. However, if these functions are static functions then you don't need a struct at all, you can simply export bare functions from your module: ``` mod A { pub fn foo() { print!("Static function"); } } ```
The problem is that the vast majority of graphs can be checked almost instantly,while some pathologically hard ones can take days. So if I just assign each core to a quarter of the graphs, the core that got stuck with the hard ones basically never finishes. So in c I have them all take references to a mutexed int, and before validating a graph they increment it. Once the int reaches some threshold, the threads know to stop so that the main thread can get a chance to clear all the voided graphs and save it to file to pick up from later. But even with all that said, my first attempt involved calling split at mut once for each chunk of graphs, but the compiler complained about reassigning variables that had been mutably borrowed, I can post an example if you'd like to give some suggestions
Question want completely clear. Let's say you have `s: String`. `(*s)` is `&amp;str'. If you need to iterate over characters, there is `s.chars()`.
There is certainly a way, it just doesn't exist yet. You could be the one to create it! There are tutorials on [how to setup wasm](https://www.hellorust.com/setup/wasm-target/) and [how to do very basic stuff](https://www.hellorust.com/demos/add/index.html), but *no* ecosystem is ready to do anything advanced with wasm yet.
Do you mean splitting off the data collection parts into a library? Not sure if that would really be helpful, the SNMP data structure is pretty... unique. I don't have any plans in that direction.
This miscommunication is because of rust's reserved "slice" term. I mean "substring" like js's string.slice like function
You need to use the version of Rust nightly that is specified in the tutorial. Using the latest one won't work. Still, you shouldn't use Zinc.
Thanks for explaining
`s.split_at(n)` if you want to take first n characters. More splitting functions are available at the [docs](https://doc.rust-lang.org/std/primitive.str.html).
thanks for your information
 loop { post.upvote(); } 
I've found `String::from_iter` and think there should be a way to use iterators to create substring of type `String` from another `String` copying original object. Examples I found were not so clear.
`&amp;s[start..end]`
There's no more elegant way?
Not sure what you're looking for. What's elegant to you?
&gt; The clap-derive crate will also offer some additional Custom Derive directives for working with enums as argument values. The one thing I thought was missing. I was considering trying to implement that myself. Awesome news!
What would you consider more elegant? Borrowing by default clearly fits rust's philosophy, and creating a redundant version returning an owned value of every function that returns a borrowed value when you could simply use `.to_string()` seems rather ugly as well.
I decided to try it on my rMBP, but found this bug: https://bugzilla.mozilla.org/show_bug.cgi?id=1420912
`String::from_iter` allows you to combine a few strings into a single string. For example, you can turn `["abc", "def", "ghi"].iter()` into a single string. What I think you asked for is to convert a single string into multiple strings. But to do that, you need to decide how you split the original string. You can split by searching a delimiter (`split_whitespace`, `lines`, `split`, `matches`, etc) or by splitting at constant lengths (`chars`, or manual split with `char_indices` and `get`), and then make a copy manually. For example, `s.lines().map(|a| a.to_string())`
I parsed that title as "\[Dark rust\] documentation with" etc. I was looking forward to reading the forbidden secrets of Dark Rust. All those chapters that the Rustonomicon wouldn't print: the `physically_unsafe` keyword... `summon_nasal_demons`... achieving an endless lifetime with a `PhylacteRc`... 
Yeah I mean do a little more to make sure the theme looks right but having a theme toggle isn't a ton of trouble. 
&gt; I just dislike the idea of using processing power to manage memory automatically in any way. So you never use buffered file I/O?
Do you think that rust-wasm would benefit from a bincode implementation (or similar) in Javascript, so that we could use `Memory` to marshall numerous large objects betwixt rust and js? I have been formulating a wrapper for nalgebra in my head, and something like that would need a wrapper that leverages a linear memory model. Bincode is likely not the solution there, and there may not be a general one in the case of nalgebra, but for everything else, using Serde here would likely be a win. 
Now you're just being pedantic :( RAM memory isn't the same as hard drive memory in that sentence.
This was previously submitted [here](https://www.reddit.com/r/rust/comments/7eio8m/cargo_tally_draw_graphs_of_the_number_of/) but I messed up the title in a way that made it sound much less interesting. In any case, since then I have added two major features: support for tallying **arbitrary semver specifications** like `serde:&gt;=0.8` and **transitive dependencies** using the `--transitive` flag. As discussed in the comments of the other submission, transitive dependencies are tricky to tally correctly. If you have crates A that depends on B which depends on C, depending on various version requirements you may need to count the dependency of A on B but not A on C, or vice versa. For example if A version 0.1 depends on B version 0.1 which depends on C version 0.1, but B version 0.2 has been released and no longer depends on crate C, then the set of crates that depend transitively on C should include A but not B. I believe I got all these cases right but I would appreciate bug reports if you see dubious output!
At this point, if you're using React/Native you'd still build the entire project in the traditional way, wasm would let you replace some isolated chunks of functionality as functions, but it seems unlikely that it would replace core React components. For example, if you had a full React application that did a lot of number crunching, you could maybe gain a speedup by rewriting those functions in rust, compiling to wasm, then importing them into your app. The thing about React Native is that its native code actually runs as native code, and the native code loads the javascript bundle using JavascriptCore as the javascript engine. So in React Native, if you have native code, it really is just native, compiling it to wasm might not be beneficial. If you want tutorials on how to compile Rust to run as native on iOS/Android for RN, check out https://medium.com/@marekkotewicz/building-a-mobile-app-in-rust-and-react-native-part-1-project-setup-b8dbcf3f539f
&gt; RN thanks for your informative reply and for the link 
It should be impossible* to do anything with the contained object without having the mutex locked. That said, can you get rid of the mutex entirely and just use `Arc&lt;Fn()&gt;`? A `Fn` object can be called through a shared reference, which `Arc` provides for you without needing any extra locking. \* Impossible, unless you know that you know there's only one `Arc` in existence, in which case you can use `get_mut` on both the `Arc` and the lock. But this probably isn't what you want.
I'll give it a try and if that doesn't work, I'll abandon zinc and switch to something closer to bare metal. Thanks
Last year, I used AoC to learn Rust. This year I guess I'll use it to re-learn Rust since I've singularly failed at using it during the year :-(
I guess I could put the `Fn` in an `Arc` in the `Mutex` inside the `Arc` and then clone the inside `Arc`, but that's not exactly 0-overhead.
Still working on `Metal`, a new os for a new world. The intent is to execute *only* WebAssembly and to only execute code in kernel-land in order to avoid the overhead of system-calls while keeping processes isolated and secure. At the moment, I'm working on getting `cretonne` to work in an environment without `stdlib`, so I can embed it. The actual kernel right now is extremely sparse, if you can even call it such, but it's moving quickly! The plan is to write everything from now on (once I get wasm execution, that is) in wasm. That includes drivers, applications, kernel modules, etc. It's located [here](https://github.com/lachlansneff/Metal). Come by and lend a hand!
I'm sold. I'd like a macro that lets me write carp blocks in my Rust code and then use them directly. :)
Looks more like a feature to me, I want these thicc text shadows, they don't show up for me with WebRender :(
&gt; This might be a controversial point of view, especially when replying to a French speaker ;) I am all for English material. The problem is that the way English is taught currently in France is not helpful. I always was a good student in English classes, yet would barely be able to read a newspaper article at the end of highschool (notably because I lacked the vocabulary), and since most of the teaching is focusing on reading/writing, my oral skills are still subpar (bad accent, frequent stumbles on pronunciation, and my ear still is not that good). English is now introduced sooner and sooner in the cursus, so hopefully the next generations will get better.
Ah sorry, you mentioned the condvar and I just missed it in my own head. What if you used a tuple to separate them, like `Arc&lt;(Box&lt;Fn()&gt;, Mutex&lt;()&gt;)&gt;`?
Rust has a number of language features, and a lot of rules, to handle lifetimes. Carp doesn't seem to. The [documentation](https://github.com/carp-lang/Carp/blob/master/docs/Memory.md) is exhilaratingly brief. How does it prevent dangling references? I have tried to write some Carp to explore it, but i haven't managed to get even simple programs to compile! 
I'm in the middle of a serious performance push on xi, and am currently in the middle of landing [minimal invalidation](https://github.com/google/xi-editor/issues/317). I also [wrote up](https://github.com/google/xi-editor/blob/b2cfcd059780e9c5bdd05e55aa3118295ac3533f/doc/rope_science/rope_science_12.md) ideas behind the design. Over the weekend, I also wrote some Rust code to analyze frames from a 1000fps video clip, to evaluate end-to-end latency in GUI apps. I'll probably also continue to experiment with performance on xi-win.
[Buffered file I/O](https://www.quora.com/In-C-what-does-buffering-I-O-or-buffered-I-O-mean) uses RAM memory. So does [TCP-based network I/O](http://www.onlamp.com/2005/11/17/tcp_tuning.html), which is why we ended up with [bufferbloat](https://en.wikipedia.org/wiki/Bufferbloat). If you truly don't think we should ever manage RAM memory automatically, you should be [doing all your file access raw](https://stackoverflow.com/questions/4703946/unbuffered-i-o-in-linux) and using UDP for all your network connections, and manually buffering when appropriate.
I've been following news on Rust since before 1.0 and lurking in this sub for about a year. I finally found some time to start trying to learn and this week started my first project. A couple of years ago I wrote a program at work that took a hodge podge of export files from one application and converted it all to an XML file that could be imported by another. One of those file was a small binary format I had to reverse engineer that stored some graph data. I found backups of my file format notes and have started writing a small lib to parse the file format using nom. I hit a lot of road blocks with nom early on, but once I figured out the first hurdle, I moved quickly and can now read 80% of the format.
I'm working on an [IPFS library](https://github.com/ferristseng/rust-ipfs-api) to access the IPFS daemon's HTTP API. I think someone had posted an implementation a few weeks ago as well, but I think what I am working on is more complete (at least at the time it was). The library is usable currently, and has most of the API calls implemented. I haven't published it to crates.io yet, but I plan on doing that within the coming weeks as I finish up documentation, and cleaning up some of the code. As a part of creating the IPFS library, I also implemented [multipart/form request bodies for hyper](https://github.com/ferristseng/rust-hyper-multipart-rfc7578). It isn't really complete or well tested, but is probably usable for pretty basic things. It still needs a lot of work to usable outside of my IPFS library. I also don't plan on implementing the server side code to parse multipart/form bodies.
Now there are 8. :)
With Ternimal, now there are 8.
The answer is unfortunately "rethink your design", because you're already starting to fight against the systems you're using. A `Mutex` provides unique access to a resource, so by design you can't access it after releasing the lock. Why do you need to do so? That should be the first question.
Alright, perhaps that sentence was a little far reaching. I don't like garbage collectors. That's all I meant to say.
I don't like manually managing memory, and garbage collectors are fast enough for my purposes as I'm not working with tiny low powered embedded systems.
This looks like a super nice and simple solution! But just in case someone wants to use a theme with a little more control over how it looks, I've made a rust docs theme myself. It should be easy to customize the colors by switching around global variables. Didn't think people would be interested, but I'm gonna share because there seems to be some interest: ![Image](https://camo.githubusercontent.com/d320f7081de4fba24a93d40b22d0301c56ad7d0c/68747470733a2f2f692e696d6775722e636f6d2f50306c374467712e706e67) ![Code](https://github.com/chrisduerr/userstyles/blob/master/undead-rustdoc.css) Don't get me wrong, I'm not trying to undermine the OP, but I thought some alternatives might be welcome. :)
They're not because they were developed as entirely separate tools. We'd love to see some unification here, but it's a ton of work.
I'm going to give it a shot with wasm, I think :)
Is the issue that when you take an index (reference to value in cell) that the cell could get invalidated and the index now points to the wrong data? And you would like Rust to track indexes at compile time or runtime to ensure that they aren't used for the wrong thing (Heartbleed)?
Exciting! I always install `ripgrep`, `exa` and `fd` on any new computer of mine so this is quite reassuring, and I suspect it will make them available to a wider audience! 
this is pretty cool!
In case you haven't heard of it, you might be interested in [macro-lisp](https://github.com/JunSuzukiJapan/macro-lisp), which is what it sounds like.
PSA2: Don't stay up late to get on the leaderboards. It's not worth it.
Ah, didn't know ripgrep was in Rust! Now, th√†t's a suprise to me, and some good news about Rust adoption :)
Why do dependencies for libc saturate at 60%? And why is it so stable over such a long time? That graph would match my intuition if it leveled off at 1.0 or 0.9.
I released [printpdf 2.0.1](https://github.com/fschutt/printpdf), fixed some bugs, made some changes. Other than that, I'm working on [my GIS / cartography application](https://i.imgur.com/Nf3lVIv.png). Projecting points in a GLSL shaders sadly doesn't work reliably, so I'll have to use my CPU-based [proj5](https://github.com/fschutt/proj5) library. Then I'll work on the font positioning system, which is currently not that good.
 use std::ops; fn nand2&lt;T&gt;(a : T, b : T) -&gt; T where T : ops::BitAnd&lt;Output=T&gt;, T : ops::Not&lt;Output=T&gt;, /* what else goes here to ensure (a&amp;b) : T and !(a&amp;b) : T ? */ { !(a &amp; b) }
I never knew I needed this...
The first function can be simplified as well: use std::ops; fn nand&lt;T, U&gt;(a : T, b : T) -&gt; U where T : ops::BitAnd&lt;Output=U&gt;, U : ops::Not&lt;Output=U&gt;, { !(a &amp; b) }
I'm still working on the Rust language plugin for lldb. I had a meeting today to talk about expression parsing; Plan A is to try to use the syn crate, solving the impedance mismatch either with cbindgen or by running the parser in a separate process. However, I'm probably going to take a short break from lldb hacking to try to add better support for discriminated unions to llvm, and then use that from rustc so that the various new enum-packing space optimizations can be understood by gdb.
Thanks! I also got this to work: fn nand3&lt;T,U,V&gt;(a : T, b : T) -&gt; V where T : ops::BitAnd&lt;Output=U&gt;, U : ops::Not&lt;Output=V&gt;, { let res1 : U = a &amp; b; let res2 : V = !res1; res2 } Right now it seems useful to have a nand function where the output type is constrained to be the same as the input type. But I keep running into these problems translating my ideas into rust syntax, so practicality is not yet within my horizon. 
Huh. These graphs really show how much stock people put in 1.0 versions. Serde was pretty much always better than rustc-serialize, but it didn't really catch on until 1.0
For future reference, if you have multiple questions, rather than make one thread for each question please use the comments in the "easy questions thread" stickied at the top of the subreddit each week: https://www.reddit.com/r/rust/comments/7ft1af/hey_rustaceans_got_an_easy_question_ask_here/
You could define both functions and use `#[cfg(debug_assertions)]` over the debug version and `#[cfg(not(debug_assertions))]` over the other. That way the debug version will be used when compiled in `debug` mode but the normal one will be called all other times.
My app https://github.com/Geobert/rusty_flexi was working fine and started to crash today. I wanted to put println! to debug it, but nothing is printed and I can't figure out why :-/ I tried to comment the whole main() body and adding a simple println!("Hello world!"); but it does not work. I'm totally lost here :-/
That's because the corresponding clap method returns a u64. I admit that usize may be more intuitive, and u8 is sufficient. I will not change it now as it would be a breaking change, but we'll take the feedback into account for the next breaking change and the clap integration.
silly me : #![windows_subsystem = "windows"]
**[This link only contains a short summary. You can find the actual announcement here!](https://lists.fedoraproject.org/archives/list/devel@lists.fedoraproject.org/thread/D7PYBU7JKGLRYR2HKRXBM6EGZZEDCK33/)** (also this is a dupe of [this post](https://www.reddit.com/r/rust/comments/7fxdih/announce_7_applications_written_in_rust_are/))
What about making the debug `Vec` a global (e.g. using `lazy_static` + `Arc&lt;Mutex&lt;_&gt;&gt;`) so that you don't need to change the function signature at all? I know the G word is often justifiably cause for offense, but I figure it's worth having everything on the table, in case it might be suitable in your case! :)
Is it like electron, but with rust?
I'm curious, through what venue did you hear about ripgrep if not a Rust-related one? :)
Not really. It uses webrenderer, which is a Servo component, but you write your code in Rust (with a bit of CSS too). [See an example here](https://github.com/Thinkofname/stylish_example). With Electron, you write your code in Javascript and it works like a browser. Perhaps something based on [servoshell](https://github.com/paulrouget/servoshell) or a CEF API could some day be Electron-like.
More importantly IMO is that Serde was primarily usable on nightly Rust (usage on stable was possible, but painful) until its 1.0 release, which coincided with the stabilization of user-defined `derive`.
Oh wow. Didn't know such project exists in rust. Pretty neat. Now just need to add Yoga, abstract some boilerplate code and we almost have full-blown UI toolkit. 
Chugging away with ggez! * Got some hopefully more convenient color constructors implemented * Made it possible to select OpenGL versions * [Got 3D rendering working](https://www.reddit.com/r/rust_gamedev/comments/7fy2kg/got_gfxrs_drawing_to_work_in_ggez/), woohoo! If we can fix transforms, make vertex shaders happen and make shaders in general able to notice when they're not supported by the current OpenGL version (even if only in a very basic way), then we should be done adding features for 0.4!
Thanks, this is a good idea.
Excellent! I'll give it a shot now, `.try_recv()` is probably what I'm looking for :D `.recv()` seemed to block (I think that's the right term, this is my first time diving into a compiled/systems language)
Ah, I suppose you're right. 
I'd guess /r/programming, such as [ripgrep is faster than {grep, ag, git grep, ucg, pt, sift}](https://www.reddit.com/r/programming/comments/544hos/ripgrep_is_faster_than_grep_ag_git_grep_ucg_pt/) or [FZF &amp; RipGrep - Navigate faster than ever before](https://www.reddit.com/r/programming/comments/5vm218/fzf_ripgrep_navigate_faster_than_ever_before/) (while that one doesn't have many upvotes, I've seen references to that floating around other places like Hacker News, and it [looks like there are several people using that combo](https://medium.com/@crashybang/supercharge-vim-with-fzf-and-ripgrep-d4661fc853d2)). Also, Visual Studio Code includes ripgrep support. So, it looks like ripgrep has become pretty well known even outside of the Rust community.
It's not about invalidation of the vec, it's prevention of (sometimes subtle) programming errors. Take this made-up example (I know Rust has defense against this with the `str` class): fn get_first_newline(source: &amp;[u8]) -&gt; Option&lt;u8&gt; { let index = str::from_utf8(source).chars().position(|ch| ch == '\n'); source.bytes[index] // uh oh. } Or more mundanely, each token I parse has a start byte index as well as a token index and an interned string index. I've had trouble accessing the string intern array with the token index and vice versa, forever. Just want enough type safety to at least deal with that. (Typically I don't have multiple intern pools or token arrays laying about to screw up, so types are enough for me to distinguish.) If I'm reading "persistent vecs" right, the drawbacks could be pretty large for me, because I'm keeping large vectors of indices into other vectors, and the pointer would be the same in all of them.
It's not like you were wrong though, though in this particular case it demonstrates how much stock the *developer* put in a 1.0 release. :)
Thanks, I'll close this for the other one.
It's kind of tough to reason about *why* you want a substring. There's definitely valid use cases, but knowing why might be significant because it's possible we could offer you a suitable alternative here. So...**what's your use case?** If you really just need a substring, then it seems to me that the best way to approach this would be to use `Iterator` methods, simply because that's what Rust encourages you to do. [Here's a Rust playground link](https://play.rust-lang.org/?gist=1efd4e2217f500fa24a7a51c9ea7cc28&amp;version=stable) giving a sample implementation for `&amp;str` using a `Substring` trait. **Note, however, that because of UTF-8 code point checking, the `substring` method is O(n) -- depending on the problem you're actually trying to solve, you might be able to avoid that extra cost.** If you want `substring` method accessible everywhere, you can implement something like the `Substring` trait in the playground link above and implement it for more types -- maybe `AsRef&lt;str&gt;` could work. **I do think that it's interesting, though, that there's no convenience method with a performance disclaimer on it -- maybe this would make for a good RFC?** As for your questions in other comment threads about something more elegant that might exist for this particular string manipulation, I'm not sure. Rust is *designed* to be a language that handles the following concerns in this situation: * I could be wrong, but I think that **one of the main reasons that `Iterator`s are encouraged for `String`-related `struct`s is because Rust accepts any valid UTF-8 sequence into them**, which means that slicing via index suddenly isn't so straightforward anymore. The indices you use for slice notation (e.g., `&amp;var[from..to]`) are oriented towards *bytes*, which means **if you incorrectly slice the `String` suddenly you can have a malformed view into the buffer!** * **Do you want to just read the substring, or do you want to modify it as a copy?** Remember: Rust's values are to be FIRST a safe and low-level language, and THEN be ergonomic and productive. `String`-related copies and are immediate concerns with the sort of string manipulation you're talking about, so this is a place where being more explicit is not unexpected.
Note that this might be somewhat dangerous if your code accepts anything other than ASCII -- see my reply to the OP.
Note that this might be somewhat dangerous if your code accepts anything other than ASCII -- see my reply to the OP. 
I found the stability at 60% over such a long time period interesting as well, which is why I featured that graph. I don't think it would be correct to expect near 100% of crates to depend transitively on the libc crate. Almost none of the crates I work on depend on libc. The whole ecosystem of [`serde_json`](https://crates.io/crates/serde_json), [`serde`](https://crates.io/crates/serde), [`bincode`](https://crates.io/crates/bincode), and all of their transitive dependencies: [`dtoa`](https://crates.io/crates/dtoa), [`itoa`](https://crates.io/crates/itoa), [`num-traits`](https://crates.io/crates/num-traits), [`serde_derive`](https://crates.io/crates/serde_derive), [`serde_derive_internals`](https://crates.io/crates/serde_derive_internals), [`syn`](https://crates.io/crates/syn), [`synom`](https://crates.io/crates/synom), [`quote`](https://crates.io/crates/quote), [`unicode-xid`](https://crates.io/crates/unicode-xid), [`byteorder`](https://crates.io/crates/byteorder) and on and on, none of those depend transitively on libc.
The main problem with that is you can no longer take an internal pointer to a reference whose lower bits are in use. For example, this breaks: let n = match some_json { ... HugeNumber(ref s) =&gt; s, ... };
Sweet! RIIR gets to be less and less of a joke to me as time goes on as I see articles like this. :)
TIL about `sn` (AKA `tin-summer` as the repo/crate name, which was not obvious from this comment). Thanks! :)
This podcast is AWESOME. Would definitely recommend it. :)
Yep, this is the bigger factor in my opinion as well. If anyone thinks of a different crate with a high-profile 1.0 release not tied to custom derive, we could check out the graph for that and compare.
Talk to me about the themes. How can one create one? Is there a templating engine?
Will you share your work on github? What kind of adaptation has to be made for a regular rust implementation to work as wasm?
And you'd have to mask out the lower bits when actually using the pointer. The enum optimizations all avoid runtime overhead.
Why, have you not memorized the symbols for all chemical elements? This is outrageous!
I'm using `loc` instead of `tokei` (never having tried the latter though). Is there any advantage over `tokei`? From `loc`'s github repo it seems to do the same job but faster.
Oh, I've recently seen this in use again, in [this LISP impl](https://carld.github.io/2017/06/20/lisp-in-less-than-200-lines-of-c.html) (in 200 lines of C). It'd be interesting to see a benchmark that does this for various structures found in the wild and compares the memory overhead with the pointer-fixing overhead.
You can write it that way, but that's just adding more generics that might need to be caller specified, when you fully know their types anyways. Your first implementation, with the somewhat unwieldly type declaration, is a superset of `nand2` and `nand3`. You won't need them. You can clean it up a bit by foregoing the type annotation on the variables (in fact your implementation for all of these could just be `!(a &amp; b)`) and it would work.
what exactly "is" webrender
It would be nice if a web-app existed that provided similar functionality to [crossclj](https://crossclj.info/). I think crates.io already provides the necessary data, and an app like yours is a good start.
Looks cool. That macro definition is awesome. :) I have a couple cases where this would come in handy. 
What about getting up early?
A small improvement to your code would be somethinglike cols = stdout.split("\t").map(|x| x.ok_or(ZpoolError::ParseError)) which allows you to do `cols.next()?`.
Not in US time zones, unless you're in the habit of going to bed in the afternoon.
If I actually do it, I will. We'll see how much time I have. &gt; What kind of adaptation has to be made for a regular rust implementation to work as wasm? Mostly the I/O parts of it, you gotta get it from and put it back out to the web rather than a console.
Western Europe, it is 6am for me. I am seriously considering taking good habits and going to bed early in order to do this.
will this problem be solved?
Congrats! Even one of the relatively minor updates, having bitflags 1.0 is extremely helpful. Now constants are grouped together in structs, which makes the documentation so much better.
&gt; With pointers, the lower 1, 2, or 3 bits are unused, depending on the target arch's pointer alignment. It depends on the **type** alignment: a &amp;u32 does have 2 unused bits but a &amp;u8 doesn't have any. Let me tell you a secret: in x86_64 only 48 bits from the pointer are used, "bits 48 through 63 must be copies of bit 47" so we could also store some data there. But as others have said, rust is about zero-cost abstractions, and this optimization would save memory at the cost of cpu (encode the data, recover the real address later). So I don't think this optimization should be added to the compiler, but I would love to see options to specify struct layout, it would be nice if users could just `impl get_discriminant` and write their packing code themselves.
I overlooked that it takes a byte offset. In that case, it isn't recommended as the default anymore. Thanks for pointing it out.
As far as I can tell, dangling pointers aren't a problem yet because... there's no way to dereference a pointer. Yeah... maybe wait and see on this one.
I believe this is the link http://shop.oreilly.com/product/0636920040385.do
I'd love if the ion shell ended up joining this group. I've been investigating it as a better way to write maintainable scripts and am trying to use it at work. It ending up in the central repo could mean we deploy it everywhere.
yay! Congrats to the authors!
Would likely require that the owner of the app-dirs crate wakes up so that we can get Redox support, and release a new version of Ion. Right after a few critical bugs in Ion are also fixed.
If you want the fully general version, try this: use std::ops::{BitAnd, Not}; fn nand&lt;A, B&gt;(a : A, b : B) -&gt; &lt;&lt;A as BitAnd&lt;B&gt;&gt;::Output as Not&gt;::Output where A: BitAnd&lt;B&gt;, &lt;A as BitAnd&lt;B&gt;&gt;::Output: Not, { !(a &amp; b) }
Is hard copy available now too? The Amazon link still has the pre-order button.
Another image from the weird statistics department: https://i.imgur.com/6JMtd3V.png (not cargo-tally tho)
I'm fairly sure that `tokei` respects your .gitignore. I don't see `loc` advertising that feature.
https://www.oreilly.com/ideas/were-reinventing-too Unless you preordered before, you will not be able to legitimately obtain a DRM free electronic copy of the book.
I don't get why you'd want that newtype. usize is already supposed to be int for indices. If you're using the indices from one array into another one, that's not a usualy problem the compiler can deal with in compile time. That said, I'm pretty sure there is a function that check the bounds before getting or setting a position in a vec and returns an Option or a Result instead of panicking, like the syntax vec[index] does. 
Does that include pre-order from Amazon?
It's x86_64
Oh, I didn't think about that. One thing I wanted to have is include string it failed to parse in my error but didn't find an easy way to do.
This was based on a from scratch install.
Continuing my work on [`wasm-wrapper-gen`], a crate for generating JavaScript wrappers for Rust code compiled to WASM. It's pretty nice working with the `syn` / `quote` pair for procedural macros, and being able to use them in build scripts as well is a nice bonus. The crate has a two-part architecture of a procedural macro for generating `extern "C"` fns handling the rust side of argument management, and a build script library for making the JavaScript wrapper. Currently it justs support simple integer arguments and integer slices, but I'm hoping to use protobuf or another binary format to add support for arbitrary structs. [`wasm-wrapper-gen`]: http://github.com/daboross/wasm-wrapper-gen
My guess would be no.
I'd also be interested in the CPU overhead to mask the pointer out again when using it.
`str` has `is_char_boundary`, which is useful for checking whether your indices are valid. It would be great if there was a method to find the next char boundary if the index isn't one already.
With the newtype, the compiler can check that I'm accessing the right type of array, at least. And usize is generally pointer sized, isn't it? So 64 bits unless you are compiling for 32 bit arch? The get function checks if I'm in bounds, but as long as I'm actually hitting the right array, that's guaranteed in my case. The big problem for me is many of these arrays are storing indexes to other arrays, so if they are all usize it's really really easy to get your types crossed at some point.
I've been thinking about switching to issue for 3.x. It used to be `u8` back in the day, there are programs which have several thousand or tens of thousands of occurrences of a single argument (`ripgrep` is one for example) so it got bumped to `u64`.
Uploaded a package to [AUR](https://aur.archlinux.org/packages/cargo-tally/). :) Is there a chance it's currently ignoring dev-dependencies?
That seems to fit the use case of the `chars` method and iterator, honestly.
Awesome, thanks for the list! I will have to take a look at Molten when I have a little bit more experience.
It definitely counts dev-dependencies. For example [`version-sync`](https://crates.io/crates/version-sync) is depended on as a dev-dependency by 12 crates according to crates.io, and `cargo tally version-sync` correctly counts 12 crates depending on it. It's just that dev-dependencies do not factor into transitive dependencies the way that normal- and build-dependencies do. So the hundreds of crates that depend on `clap` do not get a transitive dependency on `version-sync` just because `clap` dev-depends on `version-sync`.
I'm working on [criterion-rs](https://github.com/japaric/criterion.rs), a statistics-driven microbenchmarking tool. I've used it for a couple of my own projects now; the level of confidence it gives in even small optimizations is great, and it already provides a lot more information than ```cargo bench```. I've volunteered to take over maintenance (and then got busy doing something else), but now I'm back and I plan to work primarily on this for the next few months. In the short term, I hope to make it more user-friendly while maintaining the statistical rigor and detailed data collection that make it useful. In the long term, I'd like to build it into a solid alternative to ```cargo bench```. Watch for a release announcement of v0.1 in the next week or so, and please send me your thoughts on what you'd like to see in a microbenchmarking library.
That's interesting! I'd expect `clippy` to have many versions with it tracking rust nightly, but I wonder why `clap` is so high. Just that many improvements?
I think that announcement refers to the electronic version. O'Reilly sent files to the printing company last Monday (Nov 20), who said they'd have paper ready to ship by Dec 14th. None of us expected (or particularly wanted!) a 622-page book, and they had to look around for someplace that could do it. We are super-duper with a positively profligate number of cherries on top excited.
IIRC the main use of `libc` is to do FFI stuff - `std` itself will bind to the underlying C library, but the `libc` crate won't be needed unless the crate itself needs direct access to C types.
Thanks very much! I hope it is useful to you in some way. :) :)
Looks like removing the entire toolchain (plus rustup) and reinstalling them fixed the issue.
I still have to finish last year... :/
Good points, I hadn't thought about that.
Ok, that's where I went wrong, I assumed that `std` would use `libc` and thus most stuff would transitively depend on `libc`. Still odd IMO that it's so stable. I would've expected it to trend up or down. Though I am assuming that the overall crate count is exponential, maybe that's not the case.
I've been working on [asn.1 ser/deser lib](https://github.com/SX91/rs-asn1-exp) and [SNMP types](https://github.com/SX91/rs-snmp/blob/master/src/types.rs) based on it some time ago. Didn't finish it though due to lack of motivation. But maybe you'd find it useful, so I could work on it some more (I've started implementing custom derive but didn't find any good material about it).
That stuck out to me a bit too... no error checking, no optimizations, oh but let's squeeze out one bit with this trick.
Woah, I didn't know that. I'm making a CPU implementation in verilog, and I might be able to use that for some interesting optimizations. Thanks! Yeah, I hadn't thought about the cost of masking. I had just reasoned "Oh, a mask is a 1 cycle op". As to the type alignment: You're right, I'm just so used to thinking of the pointer-width as the fundamental unit.
 use std::ops::{BitAnd, Not}; fn nand&lt;A, B, AND, NOT&gt;(a: A, b: B) -&gt; NOT where A: BitAnd&lt;B, Output=AND&gt;, AND: Not&lt;Output=NOT&gt; { !(a &amp; b) }
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/python] [Milksnake - use cffi in setuptools. Crosspost from r\/rust. Should support any language able to generate a shared object (dll)](https://www.reddit.com/r/Python/comments/7g20g5/milksnake_use_cffi_in_setuptools_crosspost_from/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
There is some discussion at what to do.
Is this book different than [The Rust Book](https://doc.rust-lang.org/book/second-edition/)? If not, which version of Rust is it based on?
I understood what you were doing, I just feel it's a bit too paranoia-mode. But maybe you should make an RFC on rust-lang, proposing the index in vec to be also generic, but defaulting to usize.
This is awesome! I've got the basic example working, however I'm having trouble reproducing your string passing in the sha1 digest example. It seems like the ptr returned from alloc is always greater than the length of the memory buffer. 
It's popular enough that even non-Rust people are using it (coworkers and many others too :)).
I made a crate that does this, tagged_ptr. Not searched after however so maybe it uas some flaw.
`std` does depend on `libc` but it's not tracked by cargo-tally since cargo-tally looks at the dependency graph as crates.io sees it.
Rust has a lot of wrappers to existing C libs, it's my guess.
Yeah! And that is also why I remembered this article at all
What's the easiest way to get TiKV working on a single machine for development work right now?
An O'Reilly book...about Rust? Must...buy...must...buy...
The wrapper is looking pretty nice! it seems like a nice approach to wrap rust in JS from the JS side. Do you have any plans to wrap non-builtin types - or will the library stick to mostly String/str/arrays/primitives? I've recently started a crate that approaches WASM-rust-js bindings from the opposite side: it generates a JS file from a procedural macro in a rust crate. I've got primitives, arrays built, but no support for strings nor custom types. Looking forward to seeing how the wasm-experiments repo advances!
It is different than the Rust Book. The Rust Book is written mostly by Steve Klabnik (/u/steveklabnik1) in the first version, and a collaboration between Steve Klabnik and Carol (Nichols || Goulding) (/u/carols10cents) in the second version, though both are open source and have a number of contributors. This is an entirely independent book written by Jim Blandy (/u/jimblandy). As far as exactly which version of Rust it's based on, not sure, but as a metric it mentions a dependency on Rayon 0.4, and Rayon 0.5 was released in November 2016. Looking through the index and table of contents, I don't see references to many newer features, it should mostly be compatible back to fairly old versions of Rust, and should still work (possibly with occasional type annotations added) in modern versions, due to Rust's stability guidelines.
For `s`, I believe the only place information is lost is at the very end: `.sum()` is a method generic over the result type. While there aren't competing implementations in the standard library, https://doc.rust-lang.org/std/iter/trait.Sum.html could be implemented for any result type given input as `u64`s.
The thing that trips the type inference up is `sum()` - you can see that compiler has no trouble if you change `sum()`, to e.g. `nth(1)`. The reason for this is [`sum()`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.sum) has a generic type argument.
Im so glad base100 is packaged. Now I know I can easily access that high performance encoding and decoding of arbitrary bytes into emoji.
You can refer to the following document https://pingcap.com/docs/op-guide/binary-deployment And there is a section for "Single Node Cluster Deployment": https://pingcap.com/docs/op-guide/binary-deployment/#single-node-cluster-deployment Let me know if you have any question.
&gt; [By default, loc respects .gitignore/.ignore files, and ignores hidden files and directories.](https://github.com/cgag/loc#known-issues)
Thanks! Yeah, at some point I asked myself "shouldn't I write a proc macro that generates all this JS?" but I was almost done, soooo‚Ä¶ you wouldn't have a link to that crate, would you? :) Also, if you've seen the issues I opened in the repo, you'll notice how horribly broken everything is. I'm doing weird things to have Js read some slice of bytes and that happens to read a string as it's currently laid out in memory by a recent Rust compiler‚Ä¶ You shouldn't do that. It's only save to use the C ABI (which is specified and stable). A solution to that and an answer to your "what about complex types" question: you'll probably need to serialize the data in some common format. Someone suggested bincode, you could even use protobuf or capn proto if you like. In the future, this may become easier. If WASM supported more than one memory slot, or if you could pass memory modules as params to functions, you could easily manipulate JS/host-owned buffers. And thanks to rust, handle the ownership transfer quite easily.
Try /r/playrust 
`wc` stands for "Tungsten count" now.
If I pre-order the book from Amazon, do I get a soft-copy too? 
/r/vim, to have it handle :Ack. I didn't migrate yet, but I was planning to.
Cool! I hadn't looked too much into the issues on the repo, but I see what you're talking about now. Issue #11 seems pretty general - does the repository currently depend on many aspects of Rust's ABI that could be replaced? I have my current work at https://github.com/daboross/wasm-wrapper-gen. I do depend on the Rust ABI, but I couldn't really figure out another way to do it. The one assumption is that, given a slice of integers, `slice.as_ptr()` points to a length of contiguous memory `mem::size_of::&lt;T&gt;() * slice.len()` long. I'm pretty sure I've seen C interfaces make similar assumptions, but I could be wrong there. Does your code currently depend on significantly more than this, or is this what you're referring to? Then again, I haven't implemented strings at all yet. There are probably more ABI issues there, especially if wanting to be efficient... With the other types, I've definitely thought about using protobuf, but it'd put a bit of a wrench in the whole "generate JS from Rust" part. If I was going that route, there are good JS and Rust libraries, but I don't think there's anything to generate a protobuf definition from a rust struct.. Do you think an extra memory slot would make all this significantly easier, or would the main advantage be clearing up rust ABI? I initially thought about trying to give Rust more memory segments, maybe through the 'import' system, but I realized I don't have any way to manage that memory in JS. With the current model, all the code can rely on Rust's allocator for ensuring memory is non-overlapping, etc. I'm not sure if I'd want to try to replicate that in JS, if I can use Rust's system safely.
This looks really interesting! I'm quite interested to see how WASM will work out as userspace runtime. Oh, but, you should choose a less generic name. May I suggest [generating](http://killercup.github.io/codenamer/) one? (You can even choose metals as part of the name!)
I currently depend on these parts of the Rust ABI: `&amp;T` is two 32bit little-endian words (as WASM32 specifies), the first is a pointer, the second the length; `String`/`Vec` are three words: pointer, length, capacity. Other than that, I rely on these stable parts: `u8` is something a Uint8Array can consume (stable); `str` is encoded in UTF-8. These are quite conservative assumptions, and they don't touch stuff like enum optimizations or alignment, but they are not guaranteed nonetheless.
That works too, but it adds some redundant type parameters to the function signature.
In what environment? (browser [which?]? node?)
I like this. It is easy to get confused when passing a lot of indexes around. I typically get confused when passing multiple IDs as arguments to a function where only the order defines which container each ID refers into. I did something similar with Diesel: [generate_id_type](https://github.com/revolverhuset/fishsticks/blob/master/src/models.rs#L6-L47) I'd love for there to be a go-to solution for both of these cases (Diesel/database IDs and container indexes) in the crates ecosystem.
How about a `#[repr(expensively_packed)]` tag which would let the compiler go wild with CPU-intensive space-optimizations, for cases where you know you need compact data more than anything else ?
I feel like at that point you might as well just write Rust code that talks to the React Native native code (Java/Objective-C) over the [bridge](https://facebook.github.io/react-native/docs/native-modules-ios.html#content)
&gt; Does your code currently depend on significantly more than this, or is this what you're referring to? &gt; &gt; I currently depend on these parts of the Rust ABI: &amp;T is two 32bit little-endian words (as WASM32 specifies), the first is a pointer, the second the length; String/Vec are three words: pointer, length, capacity. Other than that, I rely on these stable parts: u8 is something a Uint8Array can consume (stable); str is encoded in UTF-8. These are quite conservative assumptions, and they don't touch stuff like enum optimizations or alignment, but they are not guaranteed nonetheless. I haven't touched other Vectors, let alone generic ones. Ahh, I see. Those seem like reasonable assumptions, but Vec/String field order does feel like it could change in the future. I've gotten around relying on Vec/&amp; memory representations by generating extra rust code doing the transformations in the macro. I think it would be possible from JS code too with appending generated wrappers to the rust source. &gt; It doesn't have to be protobuf, of course. Just something that writes Rust data in a specified format quickly and can be read by JS without much hassle. (A superset of #[repr(C)], maybe.) A JavaScript parser for #[repr(C)] structs would be amazing! DataView in JS would make accessing all regular fields possible.. hm.. &gt; Oh, I only meant that as a way to not have to copy around the data all the time! If you could give a handle of some SharedArrayBuffer to WASM, you don't have to copy its content to the WASM memory before working with it. I think hope something like this is planned when introduces WASM's threading model. Ah, I see. Multiple memory as in passing slices in, not as in Rust 'owning' multiple large sections. That _would_ be pretty awesome! &gt; Edit: You should play around with proc-macro2 to get a #[expose_wasm] attribute going :) This looks promising - I'll definitely have to look into it, thank you! I'm currently glad to be working on stable rust features (besides wasm target), but if proc-macro2 can do seamless function procedural-macro-attributes, it might be worth it to go to nightly.
[It's all on the wiki!](https://github.com/quadrupleslap/leven/wiki/Theme-Creation) The [template engine](https://github/quadrupleslap/tenjin) is a new one. :)
I'm honestly not sure, but I think you're looking for the community for the Rust game, not for the Rust-lang programming language. /r/rust is the community for the Rust language, /r/playrust is maybe where you want to submit this instead?
Linux recently added support for five-level page tables, which go up to 57 bits. Though I don't think there is hardware support for it yet.
It looks like this project has great progress, and I am very excited for its eventual release in Firefox! Is there a way for me to get a sense of how far away that is? It is good to see status updates like these, but they are like a progress throbber/spinner, it just tells me that people are achieving valuable stuff. But how much more valuable stuff until it is "done"? :)
I don't have any experience with linear algebra libraries in Rust or otherwise, but I know quite a few other developers use / like using https://crates.io/crates/nalgebra. While it was 7 months ago, this post might be useful for you: https://www.reddit.com/r/rust/comments/63wts9/why_are_there_so_many_linear_algebra_crates_which/. It certainly has more information than I do on the topic.
You might not like gstreamer, but it is very much used. I have worked with it commercially and know many large companies that are heavily invested in the technology. My experience with it is rather good. Takes a while to grasp but very powerful.
Here is a more [practical answer](https://play.rust-lang.org/?gist=583d4e3d25f8ea127435bc93e04ddd59&amp;version=nightly). In this context `sum` could return `Foo` or `u64`.
This sounds like a niche use case, but a super useful crate for that use case! I haven't found a need to do this, but I've never stored indices for more than one Vec in the same structure in my code before. I don't know of any other crates which do this, if no one else does, publishing it is definitely a good idea! doc.crates.io/crates-io.html is a fairly good guide on how to do that if you're looking for one.
That's not what I mean. I mean that the distinction between `-a 3` and `-aaa` is non-obvious and you can't have the former if you want a `u64` or the latter if you want a `usize`
O'Reilly books are great in content but lack in editing/formatting! 
Is it for real...what a fcking ugly PL!...IM OUT! 
Do mind explaining that? Wouldn't that just be a matter of masking out the bits used for the tag?
I'd use features and conditional compilation. Add a feature like `debug_draw` to your crate. You can enable this feature from your debugging program. Then, similar to what /u/shadowcynical described, add the line `#[cfg(feature = "debug_draw")]` to the debug version of your function signature, and `#[cfg(not(feature = "debug_draw"))]` to the normal "release" version. That way you can very conveniently control the signature for your debugging program.
Can I start a subprocess from my rust app, and connect the subprocess' stdin to my stdout, and vice versa? Googling made me think I should use the `subprocess` crate, but the docs didn't eli5 it enough for me to form an idea of how to do it.
Might need to ping him out-of-band if you can. I've missed a lot of GitHub notifications myself, because they don't always come through. :(
You can't have the latter, but you can have the former using `parse(try_from_str)`
On page 7, they run rustc --version and get 1.17.0
In the future, I think it would help if you provided code that someone else can compile. &gt; but then how should I deal with values - and 1.1x? There are at least a couple ways. One way is to define a new type that represents your dedup ratio (for example) and then manually implement `Deserialize` for it. Another way is to just ask Serde to use a one-off function to deserialize that particular field. For example: #[derive(Debug, Clone, PartialEq, Deserialize)] pub struct ZpoolProperties { #[serde(deserialize_with = "deserialize_dedup_ratio")] pub dedup_ratio: f64, } And then you just need to write your function: use serde::{Deserialize, Deserializer}; use serde::de::Error; fn deserialize_dedup_ratio&lt;'de, D&gt;(de: D) -&gt; Result&lt;f64, D::Error&gt; where D: Deserializer&lt;'de&gt; { let mut s = String::deserialize(de)?; if s.chars().last() == Some('x') { s.pop(); } let ratio = s.parse().map_err(|err| { D::Error::custom(err.to_string()) })?; Ok(ratio) } I didn't check that with a compiler, but something like that should work. And then if you deserialize into your `ZpoolProperties` type using the CSV crate, Serde will automatically use your function.
The name is from *The Birth and Death of Javascript* by Gary Bernhardt. It's a great talk! I'd recommend giving it a watch! I'm happy to change the name, just haven't thought of a good one! Let me know if you think of one!
&gt; This will find all of your Cargo dependencies, find their github.com repository from metadata hosted on crates.io, and star their github repositories. Is that how people use github stars? I just used it as a bookmark feature. What does it do for non-github projects?
From this post title I at first thought the book was called "Status of Programming Rust" and was a bit confused!
Ah, cool. It's still slightly wonky behaviour by default though 
Is it possible to pass strings to/from javascript (a actual Javascript string objects) without converting them to nul-terminated? Also, is there a good way to represent a Rust-style enum accross the ABI?
This would be incredible, the debug story (using VSCode) is lacking both for lldb and gdb, with python code that crashes on fairly common variants of rust types. Should we consider augmenting LSP for frame or time-travel debugging since we already use the rustc parser for our LSP implementation?
How practical is it to use Rust for a real project in late 2017? I'm working on moving some performance-sensitive sections of a game engine to a lower-level language, and I'm wondering if Rust is *a)* stable enought, and *b)* easy enough to work with (in terms of tooling, cross-platform availability etc.)
I use [this](https://github.com/jremmen/vim-ripgrep) and I suspect it accomplishes approximately what `:Ack` does.
I would expect conservative impl trait to be ~3 months. It's a priority in the impl period. Procedural macros are also fairly well baked as far I'm aware. I'd imagine they'll be stable with 6-9 months (caveat: I'm not really in the know. I just follow this subreddit, and some of the github issues). Async-await, and the generators feature used to enable futures-await is much more experimental, and I'd imagine that will be much longer. A year to 18 months probably until it's stable. However, futures and tokio can be used without them. So I imagine what will happen is that most libraries will stick with raw futures, and consuming applications can choose to pay the nightly tax to put syntax sugar over that at their discretion.. 
Sort of an advance beginner question. I have read a some fixed size buffers from the network , with 0 terminated c style strings. All bytes after the termination are also 0. This causes problems when I want to convert to a String. Ex: String::from_utf8(b.device.to_vec()).unwrap(), - Keeps all the trailing 0s This monstrosity fails: String::from( CStr::from_bytes_with_nul( &amp;b.target ).unwrap().to_str().unwrap() ) `Err` value: FromBytesWithNulError - since there are multiple 0 bytes In my beginners mind, this should be an easy conversion as long as the source comforms to utf-8, but I can't find the easy way :-( Please help.
Yeh, pretty sure it was something along those lines. Didn't feel like installing it yet though. Will soon try!
In general, new, shiny features will always land on nightly, so in some sense, this is the perpetual state in Rust. &gt; In the days of old(IIRC up until custom derive went stable) one had to use nightly to actually use Rust. If you consider today's stable Rust usable, then I don't see why it'd suddenly become unusable just because some new feature being added.
I'm biased, but have you tried reading the book: https://doc.rust-lang.org/book/second-edition/
I'm reading, but I think that just reading a book it's not enough
&gt; This would be incredible, the debug story (using VSCode) is lacking both for lldb and gdb, with python code that crashes on fairly common variants of rust types. If you find crashes, please file bugs. IMO it's fine to file them in the Rust repository; I'm happy to move bugs upstream to gdb as needed, and I realize it can be difficult to distinguish bugs in the gdb-python code that comes with Rust from bugs in gdb itself. Bugs against lldb are also good, though once the Rust language plugin is done, some of them may be obsolete. &gt; Should we consider augmenting LSP for frame or time-travel debugging since we already use the rustc parser for our LSP implementation? Visual Studio has a different debug protocol: https://code.visualstudio.com/docs/extensionAPI/api-debugging I haven't really looked into this much though.
the proc2 macro API and the syn and quote crates are still in flux, so I don't know bout proc macros yet.
In a couple of days, [Advent of Code 2017](https://adventofcode.com/) will start. Back when I learned Rust this was a massive help actually starting to use Rust, as you get nice bite sized puzzles to solve.
`CString::from_ptr` should work (instead of `CString::from_bytes_with_nul`) because it scans for the 0 byte.
This is actually in the standard library. There is a short example here: [Command::output](https://doc.rust-lang.org/beta/std/process/struct.Command.html#method.output). I'm not sure about actually redirecting the original process' standard streams, but you do get handles to the child's streams.
thanks, I'll try it
Which one of `.map(|x| foo(*x))` and `.map(|&amp;x| foo(x))` is the preferred style?
This was in chrome, possibly latest version? I will try and reproduce on my linux box today and post more detailed code + version info.
I wouldn't say that everyone is waiting for `future-await`. I think that's probably most wanted for web stuff, but e.g. game dev can really do without.
Nice. Glad to see someone else trying to use a simple database when a full blown server isn't needed. I like SQLite and TingoDB (works well with Mongo node modules usually.) 
I opened an issue on Github with some improvements I saw immediately. As a general rule of thumb, I would also not recommend taking parameters by value, if you don't consume it in the function body. &gt; On client registration I respond with a public key, so far I have an ugly "clone()" in my response, I gave a quick try with passing the pubkey around as &amp;str but rocket requires a &amp;'static str, which I can't provide. Do you have any idea that might get rid of this clone? I am afraid not. It appears that the state holds reference to your pubkey and thus you cannot move out of it. For configuration path, if you wish to set it at compile time, you can use: 0. option_env!(), which optionally gives you an environment variable. You could then use a default value if it was None. 0. include_str!(), to include it from file at compile time 0. A build script, which will ensure it's presence (maybe prompt the user to enter it if the variable is not found?) 
I'd rather give them time to get it right, rather than have it rushed through and then all have to live with some fundamental problem forever. Let them try different things until it feels comfortable.
Ah just a &amp; too much here: `&amp;s[0..13].chars()` What you want is `s[0..13].chars()` 1. Precedence means its otherwise a &amp; to the chars iterator 2. Method calls take reference as needed automatically. You *could* say this, it's correct, `(&amp;s[0..13]).chars()` but it is redundant
I wonder what results he could get by tuning Elasticsearch instead of replacing it.
It seems that you have two services accessing one sqlite database. How do you solve locking in this case? Or does it work out of the box from Rust?
That's interesting, because I feel like using futures, especially around the main loop, would be very interesting for games to do.
Do you have recommendations? I tried adjusting `ES_JAVA_OPTS` as elasticsearch documentation mentions that the index buffer size is "a percentage of the java heap". This resulted in increased GC pressure. If you have any resources for tuning elasticsearch for low-mem, low-cpu environments, I'd love to give it another whirl.
That was it thanks. Follow up question: Can I convert the characters to u64 while iterating ? Something like Python generator expressions ?
You don't need any additional plugin but just set `set grepprg=rg\ --vimgrep` and then the command `:grep` uses `ripgrep`.
"interesting" and "can't live without it" are quite far apart.
&gt; You *could* say this, it's correct, `(&amp;s[0..13]).chars()` but it is redundant I've been doing that forever. Glad I can drop it.
I didn't find futures to be very useful for games, but maybe they are in your case.
The other option is SFINAE, which is a mess. At least this way you _know_ what the function requires.
You can use filter_map() and to_digit() filter_map(|c| c.to_digit(10))
After skimming the article I get the impression that the author has a different use case than that of ElasticSearch. The latter is focused on *searching* and *analyzing* complex data in a *fuzzy* way. Relational databases aren't good at fuzzy string searches. So if your focus isn't at fuzzy searching but more towards *standardized*, well defined queries, than of course ElasticSearch might be an overkill. Btw: If the task is about real time log analysis than a Kafka and Spark stack should be the better option. 
What, someone is honestly compa‚Äî &gt; Elasticsearch is a Corvette and all I need is a toy car. Ah, it's all good. What was missing from diesel's API, by the way? Group by? You _could_ [use a view](https://deterministic.space/diesel-view-table-trick.html) instead of a hardcoded query if you like.
So start a simple project or contribute to an existing one. The only way to learn is to do.
Yeah, it's not usually a Thing for me either :) But man, writing a compiler seems to be an exercise in Comp Sci 101 and bring up all sorts of use cases I haven't dealt with in years! Thanks for the guide, I'll take a look. Given the feedback here, it sounds like crating it is the right thing to do!
Because it's better to get errors at the place the function is written rather than the place it's used. There are other reasons too, relating to compile time and so forth.
That sounds cool idea! u/rrobukef seems to have already made a crate that does this; this may be one of those cases where it's better to put it in a crate than to put it in the compiler.
That's a good idea. I think I recall reading suggestions to this effect anyway, to allow `u32` and other such indexers. I'd normally agree it's too much paranoia, but there comes a point where your eyes are bleeding from the number of `usize`s in your code and you keep second guessing whether the usize is really the usize you want :) My problem might also be that I'm using indexes as the solution to the "how do I store a pointer to a value in the same struct" problem that lets the indices live with the array without forcing a mutable (or immutable) borrow to live forever. Maybe there is a better way to do that?
I hadn't seen base100 until now, and I love it so much. Seems like it's actually good for read-only checksums (like verifying a download).
Its certainly an inefficient encoding (4-bytes for each byte) and can't be used in URLs, so its use cases are rather limited.
Oh I'll have a look, sound nice !
So, I'm really kind of seeing three questions here: &gt; Why doesn't Rust use C++'s approach? I've used C++ before and frankly the error messages you can generate by messing up templated code are an abomination. I think it's gotten better in the last few years but the issue is still that templated code is essentially unchecked until you actually instantiate it leading to users of your code getting errors instead of you getting errors. I think this is a pretty bad design. &gt; Why doesn't Rust use Haskell's approach? Rust basically does use the same approach that Haskell does but it requires type annotations on your function signatures. The reason for this is that, again, it helps make the error messages better. In Haskell, changing the body of the function can change the function's signature which can result in errors at the call sites. If this isn't what you intended, it can be very confusing why changing code in one file causes unrelated code in a different file to no longer compile. &gt; How do you work with this? Generic number manipulation code tends to be one of the weak points of this system as you've seen. Personally, I don't see much reason for this code to be generic *in the way you've written it*. In the function, you're converting everything to `f32` anyway so there's no performance improvement to allowing any number type. In addition, if that conversion fails you're panicking which removes the calling code's ability to handle that. Here's what I would write instead: fn mean&lt;I: IntoIterator&lt;Item=f64&gt;&gt;(numbers: I) -&gt; f64 { let mut sum = 0.0; let mut count = 0; for n in numbers.into_iter() { sum += n; count += 1; } sum / (count as f64) } This makes it clear to the calling code what's going to happen. If the calling code already has `f64`s, then there's no conversion necessary. Otherwise it's up to the calling code how to handle conversion issues. Additionally, this allows you to use any collection type, not just ones that represent contiguous memory like `slice` does.
[Substitution failure is not an error](https://en.wikipedia.org/wiki/Substitution_failure_is_not_an_error), for those not knowing what this abbreviation means
Have you considered just conditionally printing the information, then piping it to another program that does the drawing? It isn't a Rust solution, but just thought I'd suggest an alternative approach.
I personally linke the second version better, although I'll go with the first if I'd predominantly use `*x` otherwise.
Once you've used unity's coroutines, you won't be able to live without them.
The author mentioned that ES was too much, and landed on SQLite. I have to feel like Kafka would be way too much.
What's most people do is to read the official book then do the https://rustbyexample.com/ and if you have more specific questions you could take a look at https://github.com/ctjhoa/rust-learning
Maybe I am missing things, but _I think_ the use case is perfectly handled by a time series database (metrics store, whatever), that is (pre)aggregated data and not the whole log. I would recommend prometheus, which is pretty light weight.
Take a look at [SQLite's Write-Ahead-Log](https://www.sqlite.org/wal.html). It's not on by default but has a great characteristic: &gt; Because writers do nothing that would interfere with the actions of readers, writers and readers can run at the same time
I've gone through the Guessing Game tutorial and have made a project so I can work out the examples in the book, commenting it as I go. So far that is working pretty well and I'm really enjoying it. It has reintroduced to me the enjoyment of coding.
Please correct me if I'm wrong, but iirc one can't parameterize a `GROUP BY` statement (here's the [full code in question](https://github.com/nickbabcock/rrinlog/blob/42e0bec2cf89906bab264b4c9616ebb6e0e75f4b/rrinlog-server/src/dao.rs#L57-L72)) I'm expecting the sql statement below to be not possible SELECT epoch / ? * 1000, host, COUNT(*) FROM logs GROUP BY epoch / ?, host 
It isn't about *too much* or something. I think he has chosen the false tool for his problem. Of course you could use ES for different settings, but the focus is on fuzziness. If the author hasn't this focus, another approach could be more feasible. 
Once you've used haskell's pure functional programming you wont be able to live without it :P
Can someone explain why this doesn't work? struct S; trait A {} impl A for S {} trait BoxExt { fn ext(&amp;self) { println!("hi") } } impl &lt;T: 'static&gt; BoxExt for Box&lt;T&gt; {} fn main() { let s = S; let boxed_a: Box&lt;A + 'static&gt; = Box::new(s); boxed_a.ext() } Gives an error message "no method named `ext` found for type `std::boxed::Box&lt;A + 'static&gt;` in the current scope" [Playground link](https://play.rust-lang.org/?gist=9c8301a183404bba98a48d90ebc3a9a0&amp;version=stable)
You can't mask out the bits, because `n` is a reference to the internals of `some_json` where the bits must remain. In this simple example you could probably imagine copying the bits, masking out the tag, and taking a reference to *that*. However, that breaks down even with something as simple as taking a mutable reference.
SQLite does that locking for you, as I understand it. It just does it by locking the entire database.
Even when we get hardware support it will have to remain opt-in, though. Javascript VMs make use of those bits to pack pointers into the unused parts of the NaN space, and rely on that for performance.
Disclaimer: What I'm about to say is based on official training, but from a couple years back. ElasticSearch *really* wants to own the entire heap, at least up to the maximum addressable size for 32-bit (the overhead for switching from 32-bit to 64-bit addressing was really substantial). They recommended multiple ElasticSearch processes on the server if you had more RAM than 32 bits could address. It also **really** wants you to not swap. It's designed for clusters of multiple dedicated servers. "low-mem" and "low-cpu" are pretty much red flags that you're not using it for its intended purpose.
&gt;If you consider today's stable Rust usable, then I don't see why it'd suddenly become unusable just because some new feature being added. If you don't need async/await, then don't use that crate. I think the argument is that if the de facto crate for solving some very common problem is using nightly, then that will spider out into *every* crate and suddenly it will become difficult to start a new project on stable rust without pinning all your dependencies to an old version.
I did some googling, but could someone explain the point of Elasticsearch and its benefits over SQL or MongoDB.
I mostly use the second one myself as well. It feels like it makes the main expression a little bit more readable by pushing the extra syntactic noise out into the match pattern.
Ah thanks, maybe I did not state it clearly enough. My process and the other process will need to run side-by-side, communicating over stdin/stdout. So I can't really wait for it to finish or something...
I think one of the issues is if dependencies start using the new features. If people start using nightly features heavily in networking libraries, you may be stuck between using old versions of the libraries (and possibly having semver issues with other dependencies that use newer ones), or becoming nightly only yourself. Basically, Rust may be perfectly usable now, but there have been issues when the ecosystem can have semverpocalypses or large portions of the ecosystem depending on nightly. We have learned from the libcpocalypse, but there isn't that much other than social pressure and a few best practices (type only crates, the semver trick, etc) to prevent another. I can think of a few things that might help; better tooling for ecosystem wide semver checking, tooling for automated semver updates, cargo having visibility in how types in different dependencies interact (are the types exported, or are the types used between dependencies or purely internally), but don't have the time to work on those and those are likely far-off if ever features, so in the meantime, it is good to be on the lookout for ecosystem issues that make it impossible to use large amounts of the ecosystem without relying on nightly.
&gt; In the function, you're converting everything to `f32` anyway so there's no performance improvement to allowing any number type. In the original signature they were planning to return a `T`, I figured they'd just fallen down to returning `f64` in an attempt to get _something_ working. Probably what would be useful would be for it to return some `U` where `T : Div&lt;RHS=usize, Output=U&gt;`.
I already used strictly stable before custom-derive. I won't use nightly builds, if some feature or crate requires nightly then I'll just use a different language for the project instead rather than use an unstable compiler.
The in-progress gfx rewrite might make this kind of parallelized graphics a lot easier. The current (pre-ll) version doesn't really allow easy multithreaded OpenGL (since OpenGL isn't built for multithreading in general). In the mean time look into using Vulkan though vulkano.
The following is valid C. enum CEnum { X = 0 }; enum CEnum new_enum() { return 1; } Running `cargo test` on the following works with stable `rustc 1.22.1 (05e2e1c41 2017-11-22)` but fails with beta `rustc 1.23.0-beta.1 (082b0ff02 2017-11-21)`, with the error message `called Option::unwrap() on a None value`. #[repr(C)] pub enum CEnum { X = 0 } extern "C" { fn new_enum() -&gt; CEnum; } /// ```rust /// cenum::try_new().unwrap(); /// ``` pub fn try_new() -&gt; Option&lt;CEnum&gt; { unsafe { Some(new_enum()) } } Is this expected behaviour or a bug? If it is expected behaviour, what is the correct way to represent `CEnum` in rust?
You need `?Sized` to make the `impl` apply to traits, which are unsized: `impl &lt;T: 'static + ?Sized&gt; BoxExt for Box&lt;T&gt; {}`.
Sometimes I wonder if the infamous Netscape rewrite was in fact a secret plan to replace C++ from the future with a safer language, reverse-terminator style...
Ah, thank you!
I'm very interested in that too. 
You'll need to spin up threads to do that, and you can send over the handles you get from `Command`.
a) reasonably good fulltext search with good configuration options for analysis of text. And couple of other features. b) builtin ability to scale to multiple machines A besides: MongoDB is crap do not use it.
&gt; I agree that C++'s permissive approach tends to generate a lot of obscure compiler messages (though that might be attenuated with the introduction of concepts). Your point about concepts is spot on. I followed C++0x development pretty closely, and back then concepts already had me excited because after only a year or two of daily usage of C++ I had grown tired about its inane template errors. And if you think templates have awful usability in a single program; imagine releasing template libraries. When a client report that your template function generates a compile-time error because you mispelled the function/method/nested type name and you need to release another version... :( Fast forward 8/9 years, and I'm still waiting for concepts. Or rather, I've stopped waiting. I've discovered Rust generics since. I prefer Rust traits to all concepts proposal I've seen, simply because implementing a trait is *intentional*, not *deduced*. Well, and of course they already work. &gt; In Haskell IIRC type annotations aren't necessary when there is no ambiguity. Haskell has global type inference. There are advantages to it: lighter weight syntax, notably. There is also one big disadvantage: a seemingly innocuous change can bring the world down on your head. At a seemingly unrelated place. I dabbled in Haskell for a bit, and I still remember getting error messages in parts of code I hadn't touched, calling parts of code I hadn't touched... and wondering which of the N little changes I had done elsewhere could have triggered this. I'm pretty you get better at the game after playing for a while, but I've got other things to do. In the end, I just typed all my functions in Haskell, it just scaled better. Rust instead deliberately picked a middle spot in type inference: - it uses something akin to Hindley Milner, like Haskell, so that inside a function you rarely need to be explicit about types, - but it strictly annotates all type declarations and function signatures, so that when an error occurs, you have to have modified either the code in which the error occurs, or the immediate code it's using. I think it's a sweet spot. &gt; how do you work with/around it? The first step is to understand how it works; it takes some practice, obviously. The second is to understand your requirements. To compute the mean you need: - a sequence of elements, in Rust this is `Iterator`, - the ability to add the elements together, in Rust this is `Add`, - the ability to have a starting element, aka "zero", there is no standard trait for this, the `num` create is the usual choice, - the ability to count the number of elements, one at a time, aka "one", - the ability to divide the sum by the number of elements, in Rust this is `Div`. That's all; and yes it's already a lot. *Note: it could be argued that Rust should define higher-level mathematical structures, such as Groups, Rings, etc... it can also be argued that this is not something the standard library need bother with.* extern crate num; use std::iter::IntoIterator; use std::ops::Div; use num::{Zero, One}; fn mean&lt;I, T, O&gt;(iterator: I) -&gt; O where I: IntoIterator&lt;Item = T&gt;, T: Zero + Div&lt;O, Output = O&gt;, O: Zero + One { let mut sum = T::zero(); let mut count = O::zero(); for e in iterator { sum = sum + e; count = count + O::one(); } sum / count } fn main() { let v = vec!(1., 2., 3., 4.); let m: f64 = mean(v); // annotation to choose O println!("{}", m); } The main pain point is that mixed-type arithmetic operations are generally not available. It's a conscious choice, forcing you to handle the edge cases caused by going from integer to floating-point, etc... but it can indeed be a bit painful. If we restrain ourselves to a single type (in and out), it's a tad simpler: fn mean&lt;I, T&gt;(iterator: I) -&gt; T where I: IntoIterator&lt;Item = T&gt;, T: Zero + One + Div&lt;Output = T&gt; // Could also use `Num`, directly. { let mut sum = T::zero(); let mut count = T::zero(); for e in iterator { sum = sum + e; count = count + T::one(); } sum / count } *Note: one thing missing here, is auto-deriving `AddAssign` from `Add`; I seemed to remember it was coming...* It probably remains more verbose that you'd like. The key point, though, is that Rust is not optimized for writing: it's optimized for reading *and understanding*^1 . What seems like overbearing punctiliousness on toy samples, is dearly appreciated as soon as the program starts spanning a dozen or more files: no surprise, every requirement is stated upfront, the behavior doesn't drastically change between a `f32` and a `f64`, ... I wish that it will get somewhat terser; after using it on just slightly bigger samples, I do hope it'll remain upfront about requirements. Explicitness makes it much easier to understand. ^1 *Understanding is way too often forgotten. Java code, for example, is generally very readable. However, between pervasive mutability and over-use of callbacks/observers/... comes a spaghetti monster; and reflexion makes it even worse. So it's great that I can read the code, I just find it pointless as I cannot understand how data flows through it.*
Seems like a beta regression. /u/eddyb, do the enum optimizations consider discriminants explicitly set to zero?
Rust enums aren't like C enums. They define exactly what they can contain. Creating one with an invalid value is undefined behavior. The best way to represent a C enum used in this way (i.e. it can have additional or invalid variants) is to use an integer with some constants. pub const CENUM_X = 0; extern "C" { fn new_enum() -&gt; c_int; } For some discussion about this take a look at this issue: https://github.com/rust-lang/rust/issues/36927
It's definitely possible to pass them back and forth without being nul-terminated! The alternative is simply passing a pointer to the start of the string, and a length of the string as a second field. I currently use this for slice-of-integer parameters, and I handle returning a Vec&lt;u8&gt; with allocating a fixed-size Box&lt;[usize; 3]&gt; in rust and returning a pointer to it. JavaScript can then recover (ptr, len, cap) from that, deallocate the box, and then reconstruct the original byte array using ptr,len. The trickier part with Strings is when to translate between UTF-8 bytes used by Rust and JavaScript's UTF16 strings. I haven't handled strings at all yet in my library, but I know /u/killercup's wasm-experiments does this via TextDecoder in JavaScript. I think I'll eventually handle this by turning the strings into [u16] UTF16 codepoint arrays and interpreting them directly in JavaScript.
I haven't checked this but can't you just use aliases? SELECT epoch / ? * 1000 as time_interval, host, COUNT(*) as hits FROM logs GROUP BY time_interval, host 
The OReilly book will also be out soon. I think it just went pre-order on Amazon. https://www.amazon.com/Programming-Rust-Fast-Systems-Development/dp/1491927283/ref=sr_1_1?ie=UTF8&amp;qid=1511901824&amp;sr=8-1&amp;keywords=Programming+Rust
By the way, it's possible to remove most of type annotations and use pattern matching in `iterate` to access tuple elements. #![feature(conservative_impl_trait)] extern crate itertools; use itertools::iterate; fn fib() -&gt; impl Iterator&lt;Item = u64&gt; { iterate((1, 1), |&amp;(a, b)| (b, a + b)).map(|t| t.0) } fn main() { let s: u64 = fib() .skip(1) .take_while(|&amp;n| n &lt; 4_000_000) .filter(|n| n % 2 == 0) .sum(); println!("{}", s); } 
Maybe if you don't care about performance. Otherwise avoid Unity's coroutines. 
Not only are you right, but I have to rescind my earlier statement: SELECT epoch / ? * 1000, host, COUNT(*) FROM logs GROUP BY epoch / ?, host Is perfectly valid and Diesel binds those params just fine.
Strings in JS are fun! I dug a bit deeper into this, and [found](https://stackoverflow.com/a/42241418/1254484) surprising yet JS-typical ways to get this in every browser. If you don't want to trust the JS wrapper to actually give you valid UTF-8, you can of course treat it like a byte slice and call `str::from_utf8` on the Rust side. `from_utf8` is [disturbingly fast](https://github.com/rust-lang/rust/pull/30740) thanks to /u/bluss, and with some effort [^1] a file containing a function that only calls `::std::str::from_utf8(input).is_ok()` is 917 bytes. [^1]: `rustc --crate-type cdylib -C opt-level=z --target=wasm32-unknown-unknown string_check.rs; wasm-opt -Oz string_check.wasm -o string_check.wasm; wasm-gc string_check.wasm string_check.wasm`
I like defining newtypes with associated constants (although these technically aren't FFI-safe without `#[repr(transparent)]`): pub struct CEnum(c_int); impl CEnum { pub const X: CEnum = CEnum(0); }
hold on, that actually doesn't work. `next()` in this case returns `Option&lt;&amp;str&gt;`, so `map()` will be mapping `&amp;str` and that one doesn't have `ok_or()`. Only ways to hide `next().ok_or(ZpoolError)` I see : - Hide in a function (which would be the same as `ok_or`, but don't have to type error variant). - Add a custom trait to anything that implements `Iterator` (adds indirection and hard to read) Now, I can reduce line count by using `map` on `Option` just write `?` twice for every column. Still have to write `ok_or` unless I implement `From&lt;NoneError&gt;` for my error type.
As a co-author of the book, that's wonderful, thank you!
What impresses me the most is that they successfully integrated Stylo with Gecko. The Gecko codebase [is 20 years old](https://en.wikipedia.org/wiki/Gecko_\(software\)#History). It's not even that it was written in a new language, Rust. Improving a complicated, legacy software is always a challenge and often a complete rewrite seems tempting, but it often results in a fiasco (e.g. Winamp3). I would love to read more details about architectural challenges they encountered and how they resolved them.
I was responding specifically to this: &gt;Btw: If the task is about real time log analysis than a Kafka and Spark stack should be the better option. Apparently SQLite did the trick, so setting up a distributed big data analytics stack is too much.
Ah awesome, that's an extremely short method for utf8 decoding in JS! I do wonder about runtime speeds: if it would be faster to export utf8 in rust, or to encode to utf16 in Rust and use String.fromCharCode in JS. I think I'll try to construct some size / speed benchmarks, but they probably won't mean much..
That's so cool! 
Most likely you will be better served by getting a ARM based board, there is plenty of documentation on how to use those with Rust. Overall I'd say that the main value of Arduino is the (software) ecosystem; Rust by virtue of being fundamentally outside of that specific ecosystem is not that great of match for Arduino.
There's a project callaed avr-rust that tries do do that, based on avr-llvm. I don't know how stable it is, however.
Maybe this can help you get started; http://jakegoulding.com/blog/2016/01/02/rust-on-an-arduino-uno/ https://github.com/avr-rust/blink plus part 2 of above article ( http://jakegoulding.com/blog/2016/01/17/rust-on-an-arduino-uno-part-2/ ) should get you up and running. But afaik it's still very much WIP.
Are they worse than stateful objects that perform the same task?
Wrong sub. You want r/playrust Please check where you're posting before you submit.
In terms of performance yes. Because a stateful object can achieve the same effect without memory allocations - which Unity coroutines do a lot of. So you avoid the allocations and then the subsequent GC aftermath. In terms of readability &amp; maintainability that is subjective.
Once you've used INTERCAL's `~` operator, you won't be able to live without it.
If you are looking for a *free* csv file containing (ip, state, country, city) I recommend db-ip.com. I have found their records the most complete one of all the free geoip alternatives. 
We also found that ES is very fast at aggregations with arbitrary filters: sum the incomes of all people with age &gt; 10 and whose name starts with 'X'. Or you know something more realistic than that.
Looks like the host is dead...
I'm kind of shocked‚Äîin a great way!‚Äîof how quickly some of the stuff in the impl period is coming along. Kudos to everyone involved.
It worked for me on the Uno v3.
You're welcome ... and thank ***you!!!*** I really like the style of writing. I find it thorough without being preachy, dogmatic, or condescending. I doubt I'll ever use Rust in a professional capacity, but right now I'm just having fun with it.
Netscape has in fact done a rewrite from scratch and it has hurt them badly: https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/ This time it is being done in a much better way :).
I found exercism.io to have nice steady progression in difficulty. http://exercism.io/languages/rust/exercises
At least in PostgreSQL, you can say `GROUP BY 1, 2` to group by the first and second columns in the `SELECT` clause, without having to explicitly name them or duplicate a complex sub-expression. Saves a lot of typing!
I'm not sure if this solves your user case or not, but I've been curious about this, and I found that [rexpect::process::PtyProcess](https://philippkeller.github.io/rexpect/rexpect/process/struct.PtyProcess.html) allows for communicating with interactive command line applications. Here is the example modified to solve the [guessing game from the rust book](https://doc.rust-lang.org/book/second-edition/ch02-00-guessing-game-tutorial.html): extern crate nix; extern crate rexpect; use rexpect::process::PtyProcess; use std::process::Command; use std::fs::File; use std::io::{BufReader, LineWriter, BufRead, Write}; use std::os::unix::io::{FromRawFd, AsRawFd}; use nix::unistd::dup; fn main() { let mut process = PtyProcess::new(Command::new("target/debug/guessing")).expect("could not execute guessing game"); let fd = dup(process.pty.as_raw_fd()).unwrap(); let f = unsafe { File::from_raw_fd(fd) }; let mut writer = LineWriter::new(&amp;f); let mut reader = BufReader::new(&amp;f); let mut line = String::new(); reader.read_line(&amp;mut line).unwrap(); if !line.starts_with("Guess the number") { panic!("Something is wrong. Bailing!"); } let mut upper_bound = 100; let mut lower_bound = 0; for i in 0..100 { let guess = middle(upper_bound, lower_bound); println!("Guess {}: {}", i + 1, guess); line.clear(); reader.read_line(&amp;mut line).unwrap(); if !line.starts_with("Please input your guess") { panic!("It should say \"Please input your guess\". Weird."); } writeln!(writer, "{}", guess).unwrap(); reader.read_line(&amp;mut line).unwrap(); // ignore the "You guessed" response line.clear(); reader.read_line(&amp;mut line).unwrap(); println!("Response: {}", line); if line.starts_with("Too small") { lower_bound = guess; } else if line.starts_with("Too big") { upper_bound = guess; } else { println!("Assuming win, stopping."); break; } } process.exit().expect("could not terminate process"); } fn middle(lower: i32, upper: i32) -&gt; i32 { lower + ((upper - lower) / 2) } #[test] fn test_middle() { assert_eq!(middle(0, 100), 50); assert_eq!(middle(50, 100), 75); } Here is an example session: Guess 1: 50 Response: Too big! Guess 2: 25 Response: Too small! Guess 3: 38 Response: Too big! Guess 4: 32 Response: Too big! Guess 5: 29 Response: You win! Assuming win, stopping. 
What was the libcpocalypse?
Parameter position impl trait? That certainly makes using some kind of "From" trait for basically every parameter much more convenient.
No. Elasticsearch, by virtue of being a Java program, uses the JVM heap. JVM heap will be immediately allocated by the JVM up to -Xms and will grow at maximum to -Xmx on need, which is the maximum memory allocation pool of the JVM. The JVM _never_ releases that memory. For that reason, you run ES with -Xms and -Xmx the same, as jumps in memory consumptions will probably end you up in -Xmx territory over time anyways. _But_, Elasticsearch relies heavily on the file system cache for working, which means that you should never give Elasticsearch all memory. The rough gauge is around 50% of the available memory, possibly less. Memory use of Elasticsearch is highly reliant on your query pattern. On a properly prepared index, you can even have it respond to almost everything from disc on a search use-case. I've seen systems that would search over 18 million documents (around 10GB of data) in under 700MB of ram. (I'm completely aware that searching 10GB of data with proper preparation is not a hard feat nowadays, I'm just saying ES is perfectly capable to fit in there.) Aggregations, which need to load data from disk for calculations, need more memory. Memory consumption within the heap can be tracked through the appropriate statistics interfaces of ES, it's really quite convenient. With swapping, you are right, but that's pretty much the case for all databases. It doesn't make sense to swap out a program to disk while most of what it does is reading from disk. Still, I appreciate the OPs use case, ES is a _gigantic_ thing and if they found bliss in just doing a smaller thing for now, that's a very fair use-case. (Note: I've been using Elasticsearch since 0.9 and its one of the cornerstones of my consulting business) 
Awesome. Glad to have my piece in stylo :-)
Sorry... blind rage... i appologise 
This is a misrepresentation of Elasticsearch and Lucene. Almost nothing about it is fuzzy, it's very elaborate index building through controlled tokenization of input values. The magic behind it are [inverse indices](https://en.wikipedia.org/wiki/Inverted_index). All this is possible with relational databases, for example Postgres has great support for that. Inverse indices are extremely _well suited_ for log analysis. For example, a query of the style "give me all log lines that have status 404 and contain the term foo" can be easily mapped through an ES index. On top of that, Elasticsearch has a huge [aggregation pipeline](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations.html) for statistics over these things. So, you can extend to: "give me all log lines that have status 404 and contain the term foo, summed in hourly buckets over the last 5 days" (this is literally a 4-clause query in ES that yields results you can immediately dump in the graphing tool of your choice). This feature set is not accidental. It isn't surprising that the main product of Elastic is log analysis through the [ELK Stack](https://logz.io/learn/complete-guide-elk-stack/). The component setup the author describes (filebeat, Elasticsearch, Kibana) is precisely meant for this use-case and widely deployed in the industry at data center scale. Kafka has a place there, but more in the collection pipeline, not for analysis. The OP was using ES just right, with the big _but_ that ELK clusters usually make sense when your logging data really becomes big data. Also, the focus of Elasticsearch as a product is indeed _not_ on fuzziness, not even in the full text search use-case. It's a buzz term that has no relation to actual practice. I'll explain: _fuzziness_ is really just a nice term for "given a query, do n transformations by replacing or flipping characters in it and search again, seeing if you hit something". You can easily do that on an SQL database: generate those values, fire the query. "Fuzzy" is a last-resort mechanism when there's really no other way of generating a hit. Applying it on _properly written input_ has a negative impact on search results. Most of my full text search clients don't use it at all. Funny enough, this leads to a huge problem: people ignore the main technique to avoid typos. That's type-ahead auto-completion. Just make sure people _know_ what they can type in and how it is spelled. Statistically, the first 3 letters of a word are entered quite correct, which is a good starting point for starting to complete. What Lucene and Elasticsearch allows you to do analyzing your input, and apply transformations on it, such as [word stem analysis](https://en.wikipedia.org/wiki/Stemming), [Unicode normalizations](https://en.wikipedia.org/wiki/Unicode_equivalence), finding Synonyms, etc. all specific to the language. It's mostly a huge amount of manual tuning labor. So, for example, after this analysis, "the quick brown fox jumped" might become "the (quick OR fast) brown fox jump" and will be written to the index. On _search_, the same transformations will be applied. For example, if I search for "fox jumps", the stemmer will replace "jumps" by "jump" - and because we indexed "jump" instead of "jumped", we have a hit. This is a very controlled process and control over it is the key to search quality. The misunderstanding of fuzziness and unawareness of that process is - by the way - a very lucrative consulting market. In any case, someone once figured out that similar (specialised) transformations can be applied to log input and the underlying data structures really fit log aggregation use-cases well. tl;dr: ES is good for both. It's just a huge toolbox and skill on its own right and if something smaller fits your use-case better currently, by all means - use it!
You could try running debug builds on the dev host using the normal rust and cargo toolchain. Then compile for Arduino using https://github.com/thepowersgang/mrustc I don't think either this solution, or others outlined in this thread are for the faint. If you just want to run Rust in an embedded context, use an STM32 dev board or a raspberry pi.
I believe Encoders are Send and multiple can be created reflecting the command buffer APIs found in Vulkan, DX12 et al. Command buffers are implemented in the gl backend by a higher level abstraction, the other backends use what the driver provides, but gl has to execute the buffers serially.
Are you limited in any way using this setup? What were you able to do with it, just out of curiosity? 
Nice post. It's worth adding to this though that if you are using Elasticsearch for *information retrieval*, then that fuzziness you're talking about and how it's implemented is crucially important. There are entire academic conferences dedicated to such things (such as TREC). If you dig a little, real IR engines like Elasticsearch (errm, Lucene) will do _a lot_ better than most fulltext search support I'm aware of in relational databases like PostgreSQL. I could write a long story about the differences, but they start right at the top: PostgreSQL's fulltext ranking support doesn't take into account corpus/background frequencies, which means it can't implement things like TF-IDF (or, nowadays, BM25). PostgreSQL does have [interesting support for ranking by various measures](https://www.postgresql.org/docs/9.6/static/textsearch-controls.html#TEXTSEARCH-RANKING), but IIRC, Elasticsearch has all of those things and more, and most of them are configured to reasonable defaults out of the box, including taking into account corpus information. With that said, I would some day like to quantify my claims here more rigorously. AFAIK, nobody has actually done it in a principled way. But there is data (that is, training + truth data) out there that could be used to perform such an experiment, e.g., from TREC. (We use ES at work, and while we do use it for storing logs like everyone else, we also very specifically use it for its IR capabilities. Also, I'm working on an IR engine in Rust, but it's been slow-going for a few years now!)
It depends on what you're doing, but writing a performance-sensitive section primarily for calculating things sounds perfectly doable in stable Rust today. Tooling is very good for binary rust programs and rust libraries to be used by rust. If you're writing bindings to another language besides C, there may or may not be tooling to support that depending on the language. I mean, you can always export raw C functions and import those in FFI from you language, but some, like python or node.js, have rust libraries built specifically for making bindings work well. Rust's cross-platform story is similarly very good, at least in my opinion. Setting up cross compiling to most architectures is relatively easy as long as you don't depend on any C++ libraries wrapped in rust crates (doesn't sound like you will). If you do, or if you're looking for an even faster way to set up, https://github.com/japaric/cross has templates for using docker containers to build project binaries on all platforms Rust supports.
You might be interested in https://mozilla.github.io/firefox-browser-architecture/ which is a growing repository of architectural writing as we improve Firefox. It doesn't have a lot of platform/renderer writing yet, but you might be interested in some of the newsletters and proposals around removing XBL.
What format do you want to write? When I read the title, I figured you wanted to write a binary file (say, a sequence of f64 floats encoded in little-endian order). But your actual comment suggests you just want to print them to a human readable file. There's countless ways of doing that. Here's one: use std::error::Error; use std::fs::File; use std::io::Write; use std::process; fn try_main() -&gt; Result&lt;(), Box&lt;Error&gt;&gt; { let nums = vec![1.0, 3.14, 5.1, 10.6, 42.424242]; let strings: Vec&lt;String&gt; = nums.iter().map(|n| n.to_string()).collect(); let mut file = File::create("/tmp/foobar")?; writeln!(file, "{}", strings.join(", "))?; Ok(()) } fn main() { if let Err(err) = try_main() { eprintln!("{}", err); process::exit(1); } } And to run $ cargo run $ cat/tmp/foobar 1, 3.14, 5.1, 10.6, 42.424242
Thank you, I edited my post to specify that I wanted to print to a human readable file.
You may find this post interesting, especially if you need to run on consoles: https://www.reddit.com/r/rust/comments/78bowa/hey_this_is_kyren_from_chucklefish_we_make_and/
I'll just point out that [my first internal-presentation slide deck on "project Servo"](http://venge.net/graydon/talks/intro-talk-2.pdf) referred to it as "technology from the past come to save the future from itself"; and a year later Brendan's [update deck](https://www.slideshare.net/BrendanEich/future-tense-7782010) starts with a Sarah Connor quote ("no fate but what we make"). Nobody involved in the project has ever conducted temporal displacement experiments though. Categorically. Definitely not. (Yet).
I made a program to blink out messages in Morse Code. I don't know what the limits are, I didn't try very hard.
The main reason futures-await even exists is that generators were implemented under an experimental RFC that explicitly put off dealing with a lot of big questions. I expect quite a lot of discussion around them before they become stable. Then there's also immovable types and something-something-generative-existential-lifetimes before generators can be *really* ergonomic, so that's two more un-RFC'd features on top. Unless a miracle occurs I wouldn't be surprised for futures-await to take years.
Thanks for the less-stale info. I figured I'd mess something up since it's been so long. The point about leaving half the RAM for FS cache *definitely* came up and I totally forgot about it. 
I was going to link to that image that shows the various memory layouts (`Vec`, `Box`, etc.) but I can't find it (my google-fu is failing me). Seems like a visual reference would help disambiguate some concepts for the author. Can anyone find it?
Not a Rust expert myself(far from it), but I do have a few remarks: * The missing lifetime in your first example is not really about "what to do with its `my_cool_pointer` member" when `x` goes out of scope. The answer to that is always easy - do _nothing_. The lifetime is about what the compiler should **allow** you to do with `x. Container types determine what to do when the variable goes out of scope, and you did touch them in the next chapter, but I wouldn't really call them "references"... * Boxing in Java is not about memory management - it's about the type system. In Java everything is an object - except some things(namely _primitives_) aren't objects(for performance reasons). But there are many places in Java where you expect everything to really be an object - so boxing is there to make objects out of primitives. Java - unlike Rust - does not expect it's programmers to care about the stack and the heap. (some still care, though, and have to struggle with Java. That's the greatest curse of a GC - when the programmer decides they need to avoid it) * I like to think of lifetimes as "dependencies". A struct with a lifetime means it depends on something else, and is only meaningful in a context where that "something" exists. No such something - the struct should have no lifetime and should own it's own data.
[Here you go!](https://docs.google.com/presentation/d/1q-c7UAyrUlM-eZyTo1pd8SZ0qwA_wYxmPZVOQkoDmH4/edit)
When can we expect to see non lexical borrowing, incremental compilation and impl trait in stable?
Do you really need the `Arc&lt;&gt;` around the `Mutex`? It's `'static` anyway so you won't ever drop it.
Wow, this is a very neat resource. It looks like there's a move toward RFCs, but I can't find where the actual *commenting* is supposed to happen. Am I missing something?
Early 2018, if all goes well.
That sounds pretty cool. Any chance it's on a public repo?
Awesome, can't wait.
https://peterlyons.com/problog/2017/10/how-i-plan-to-learn-rust
These are more about programming and very much miss the essential rust language features. I tried several and it's a waste of time if you can already program and complete exercises in another language.
These aren't RFCs, they're just a sort of catch-all place to hold current and planned architecture stuff. Discussions happen on the various dev-foo mailing lists.
&gt; targeted at the development of systems that are both highly concurrent and safe Using "targeted at [...] are [..] highly concurrent" is bit strong. It makes Rust sound more like Erlang.
There's no guarantee that Vec&lt;u8&gt; and String have the same layout right now right? As in they do right now as far as I know but Transmuting a String to a Vec&lt;u8&gt; is not guaranteed to continue to work indefinitely as far as I know.
&gt;Pythonista &gt;Rustacean Where do these terms come from?
&gt; if the de facto crate for solving some very common problem is using nightly Is this a situation that's likely to happen, though? I feel that working on a stable compiler is something that most crates, especially the most widely used ones, strive for. The only de facto crate in its given problem area I'm aware of that requires nightly is Rocket.
As someone coming from C++, can I explain my most common Rust "gotcha"? In C++, you are never aware of whether you're dealing with a reference or not. That is, if you have a function that takes something by reference, you consume it within the body of the function exactly as if you had the object itself. Even if you try to get its address, you will get the address of the object itself. The only thing that changes when you pass by ref instead of value is whether or not a copy occurs, everything after that is identical (there are surely some c++ edge cases here, probably some crazy std::is_ref&lt;&gt; or something, but you get what I mean). In rust, if you pass something as a reference (or "borrow"), you consume it differently. You're handling a ref. You have to deref to consume. If you pass it along to someone else, you don't need to re-ref it, because it is already ref'd. This gets me all the time.
Issues and pull requests here: https://github.com/mozilla/firefox-browser-architecture/ Mailing lists like firefox-dev; example post: https://mail.mozilla.org/pipermail/firefox-dev/2017-November/005920.html (archived in the repo, usually) and discussions in IRC: irc.mozilla.org, #browser-arch (and the older channels like #developers). Some of the things in that repo are design and architecture reviews, which are generally _not_ open commentary, but go through various steps of increasing openness, simply because immediate open working is not a good way for humans to work.
I also heard about `Pythoner` and `Rustic`
&gt; In Rust, a boxed pointer sometimes includes an extra word (a ‚Äúvtable pointer‚Äù) and sometimes don‚Äôt. It depends on whether the T in Box&lt;T&gt; is a type or a trait. Don‚Äôt ask me more, I do not know more. Box&lt;T&gt;, &amp;T, and any other pointer types will include an extra word if the type is a dynamically sized type (DST). They are called fat pointers. The two main DSTs right now are slices and trait objects. For slices, the extra word is the length of the slice; for trait objects, the vtable. In future versions of Rust, fat pointers may not necessarily always only be one extra word of memory. It could be more, and maybe it could be zero somehow.
Well, you can abuse arrays to build reference tables like you're doing, you can store *mut or *const pointers; or you can use Rc&lt;RefCell&lt;T&gt;&gt;.
Reading the beginning of the title for this post I thought I was in /r/dwarffortress.
Everybody in the world cares about performance, but if your game isn't getting 60fps, i guarantee that a few dozen yield statements per frame isn't what's causing it.
You have to pass the encoder's back to the thread GL was spawned on and flush them. Gfx's encoder type is sendable. There's nothing Gfx can do to make this work with OpenGL, hence the ongoing rewrite making Vulkan / DX12 / Metal first class citizens over OpenGL and DXpre-12. You can populate as many encoders as you want in whatever multithreaded manner you wish, but you need to flush them on the main thread to cause OpenGL to do anything.
They don't call it the impl period for nuthin!
The referenced BSP crate [doesn't appear to actually be published](https://docs.rs/crate/hifive) (as of the time of making this post, it shows "The requested crate does not exist").
&gt; It makes Rust sound more like Erlang or some other language with concurrency baked so deeply into its thick runtime that it pessimizes non-concurrent usecases. I'm not sure how you'd read that into the sentence. Rust's ownership, borrowing, `Send`, and `Sync` traits are fairly fundamental concepts in the language which allow for high concurrency through native threads while preserving safety with no more overhead than any other systems language. There can be overheads for locking, atomics, or whatever other mechanism you use for safely sharing state between threads, but that's true of any form of concurrency. This combination of low-overhead concurrency and safety is exactly what makes Rust appealing, and it is an explicit design goal of Rust, and why Rust is being used to develop new components in Firefox; concurrency is just too complicated for teams of people working on a large code base to do properly without good tooling, and some of Rust's fundamental language features allow for this. The "thick runtime that pessimizes non-concurrent usecases" is something that I think you've entirely read into the sentence, maybe from experience with languages like Erlang or Go, or even Rust's previous green-threads runtime, but I don't think it's implied at all with "targeted at development of systems that are both highly concurrent and safe."
I'm writing some tools to rescue data from an impaired/dying laptop. The details are [here](https://superuser.com/questions/1268868/can-i-save-these-documents-on-a-dying-machine-from-oblivion) but basically my SSD died but I have some files in the in-memory cache that I'd like to save. Unfortunately, the network, USB, audio, and SD card all seem inaccessible since only certain programs can be run (those that were cached when the disk failed). But I have a Python interpreter, a Rust/Cargo installation, and GCC. My approach: on the dying machine, write a Rust program to read files and then transmit them by flashing parts of the screen on and off. (I can write to a terminal in various colors.) One part of the screen is the clock, the other is the signal. Then on the rescuing machine, I've written a Rust program using the `cv-rs` library that reads from a webcam and interprets the colors flashing on the other computer's screen. In this way I've achieved the extremely slow transmission rate of 1 byte per second. The bottleneck seems to be that the `urxvt` terminal that I am running on the dying machine is extremely slow to draw. I originally had written the transmitter program in Python but because the terminal refresh was so slow I ported to Rust. But even now with Rust the refresh is too slow. Even though my webcam can read at 120fps, in practice I'm stuck at 8fps because the screen is still in mid-wipe on lots of the frames. I'm tempted to CTRL+ALT+F1 my way to a real terminal instead of using a terminal emulator, since I bet the refresh there would be really fast. But I'm worried that once I get out of X windows or Wayland or whatever Fedora 25 uses that I'll never get back, and there's not even any guarantee I'll be able to log in when I get to the real terminal. Things get weird when your main disk is dead :-/ Not sure if he's here on Reddit, but I want to call out Github user Ben Zhang (nebgnahz) for his help making OpenCV's `Mat::at` function work in `cv-rs`. He was help is much appreciated! Next step: send more than one bit per frame.
They're [described as RFCs](https://mozilla.github.io/firefox-browser-architecture/text/0001-documenting-output.html) and follow a Rust RFC-like template...
Concurrency and multi-core parallelism are core design principles of Rust, to the point the [GitHub tagline](https://github.com/rust-lang/rust) for the project is "A safe, concurrent, practical language."
&gt; Note that an incremental style is not the only way to write a performant editor. If rendering is fast, then it's much simpler to just re-render the entire document window on every update. That is very much the style of video games, for example, where they have to re-draw the world on every frame in any case. Is this a hint that a webrender powered text editor might be able to accomplish similar performance aspects of Xi?
You don't need to convince me. I'm well aware of what Rust is. The problem is that past experience has taught people to expect that something which is "targeted at developing highly concurrent systems" will have some kind of runtime to manage green threading or actors or some other lightweight concurrency primitive. Because Rust is such a shining exception to that trade-off, it needs to be mentioned explicitly.
How much can you draw? It might be easier to draw out a QR code (or similar) and capture that on the rescue machine. 
Sometimes I wonder if the community is trying to 'think like the compiler' too much with lifetimes, and missing some potential analogies that can help understanding. The question I would like the answer too is why the compiler doesn't allow it. It's easy from the code that owns the original value, and it's more nuanced from the `struct`, `trait` or `fn` that has the lifetime parameter. We really need to develop vocabulary around lifetime parameters, to convey the lessons that 'fighting with the borrow checker' in a more explainable form.
Yes but, as I replied to annodomini, it's risky to say that away from the Rust website without making it clear that Rust is an exception to the general trend of "designed for highly concurrent systems" (as opposed to merely "ordinary" concurrent systems) meaning that the language has some kind of lightweight primitive like green threading built deep into the language.
Also struct with DST member is DST itself.
That's correct. There's a method (into_bytes if I recall correctly) to do it safely.
I don't imagine it would change. The [docs for String](https://doc.rust-lang.org/nightly/std/string/struct.String.html#representation) specifically state that a String is made up of a pointer to a buffer of bytes on the heap, a length, and a capacity. I suppose it doesn't explicitly guarantee the stack layout like [Vec does](https://doc.rust-lang.org/nightly/std/vec/struct.Vec.html#guarantees), but it would be pretty odd for them to deviate from that representation.
Not disputing this in either direction, but where have you read that?
I've been assuming that fat pointers were never going to be more than two words. Have you read anything to the contrary?
&gt; "designed for highly concurrent systems" (as opposed to merely "ordinary" concurrent systems) meaning that the language has some kind of lightweight primitive like green threading built deep into the language. Aah, I think the term you're looking for is [roflscale](https://www.youtube.com/watch?v=majbJoD6fzo) 
More like I've not read the opposite. I have in no point in `String`s documentation seen any guarantee that internally it is a `Vec&lt;u8&gt;` at all which I'd just read as no guarantees regarding that.
this is mostly a problem with rust's choice of terms and symbols. rust's 'reference' and c++'s 'reference' (pass-by-reference) are not the same, even though they both use `&amp;`. rust's `&amp;` means 'this parameter is a reference type (i.e. a pointer, which is passed by value)', where c++'s `&amp;` means 'pass this parameter by reference'. that is, `fn a(int &amp;x)` is analogous to `void a(int* x)`, *not* `void b(int &amp;x)` (which has no rust analogue, at least afaik). 
Let's say the following hypothetical optimization at one point occurs: The compiler statically diagnoses that `into_byes` is never called and designates a certain heap region reserved for provably utf8 strings or whatever, just for allocations of which the compiler knows in some way they contain utf8 allocations so it doesn't have to do any checks, it just checks the memory addresses to see that it is utf8 in that case because it makes a promise to itself that any allocation between certain ranges is utf8. You transmute to a vector and own the buffer and modify it but it's stil in that range so the compiler assumes it is a valid utf8 sequence even though you modified it to no longer be and you properly use a check before you turn it back into a string and you get a malformed string and undefined behaviour because the implementation skips the check. If you had used `into_bytes` in that case rather than transmute the implementation would know that it cannot use that optimization or quite possibly do some advanced static flow analysis to determine which Strings can get `into_bytes` called on them and allocate those outside of the range. I'm obviously being super hypothetical here but it is possible that someone at some point in the future discovers that similar optimizations would greatly benefit performance and elects to do it because Rust never made a promise that a String is just a `Vec&lt;u8&gt;` and can safely be transmuted to one and they just say "Well if you seriously transmute Strings into Vec&lt;u8&gt;s instead of relying on `String::into_bytes` then you only have yourself to blame for now having undefined behaviour.
&gt; Also, I'm working on an IR engine in Rust, but it's been slow-going for a few years now! Is that https://github.com/BurntSushi/rucd? Would there be an overlap with https://github.com/pipedown/noise?
I think that /u/japaric is a go-to guy for embedded stuff. Look at his github. AFAIK Rust AVR has still some problems. Haven't looked at that for a while, though.
Right, that makes sense. Especially since into_bytes() is a thing that will do what you really want anyway, so no need to rely on the underlying repr even if it's unlikely to change.
I was waiting for the metaphor to somehow relate to Rust /r/HailCorporate
Yah I also disagree with that `Option&lt;ref&lt;T&gt; : NonZero&gt;` makes guarantees about its layout and calls this an "optimization". I feel the proper way is to instead have a method `as_ptr(Option&lt;ref&lt;T&gt; : NonZero&gt;) -&gt; *const T` and make guarantees about that with a massive wink that this is a non-op similar to `String::into_bytes` but still acknowledging the however slight possibility that this might in fact change in the future.
But you only need boxing because of the primitives. And the latter exists due to a smaller footprint. So there is of course a direct link between boxing and memory management. But I would agree that boxing itself is targeted towards type system compliance. 
Yes but Rust used to have green threads and then got rid of them. So it's not like we're optimizing for a different domain and thus disregarding this, we just think that green threading/actor *can* be fully addressed with a library solution.
They decided it sounded cool. I mean, Go programmers are Gophers.....
This looks pretty close to what I need, thanks! Hope I can make it work in my context... 
You are correct. It's not guaranteed until something like `#[repr(transparent)]` lands for structs. I asked a similar question here: https://github.com/rust-lang/rust/issues/45910
And even with that there is no guarantee that `String` is implemented as `struct String(Vec&lt;u8&gt;)` either way.
Vocabulary is amazingly important and last I checked about six months ago the basic documentation was not good. It wasn't until I came across a stack overflow post that said to interpret the colon in lifetime parameters as "outlives" that I was able to work with lifetimes meaningfully. The manual had examples with functions but didn't cover all the cases comprehensively (struct, type, for lifetimes). For the first month or two I had no clue what I was telling the compiler when I passed a lifetime in to something - was I defining something and it was an input, or was I receiving something and it was an output? Was I expressing a dependency relationship and, if so, which direction? Things like temporary objects having a lifetime scope until the semicolon were initially lost on me as a cause for problems. And sometimes I'd feel like banging my head on something because it looked like the compiler was telling me that two lifetimes ended at the same end of the function but it was deconstructing them in the wrong order or something. To this day I really wish someone would really explain lifetimes and write a guide focusing solely on them and explaining them really well. I still don't feel like I completely grasp them and more often than I'd like end up doing trial and error. I also think it would really help to have an idiotically simple (with bright distinct colors and such) diagram of the different types of lifetimes and where different examples are in the code. And / or a tool that you could plug in code and hover over any particular object or lifetime and see where the lifetime is computed to exist by the compiler. I think more experienced people have a mental model that isn't really being conveyed very well by the existing documentation. However I haven't looked at it in a few months.
Wow. I mean, I‚Äôve totally gotten used to the posts about Rust-the-Game, but now we get posts about products related to the non-digital world?! Anyway, this subreddit is about the Programming Language Rust, you may want to try your post again in a different subreddit.
So Stylo and WebRender are fully implemented in Firefox? Quantum Compositor, DOM and Flow will join soon? 
I have a trait which abstracts some behaviour which differs between platforms and two specific implementations of it. The trait looks something like: trait Trait&lt;R: io::Read + ?Sized, W: io::Write + ?Sized&gt; { fn reader(&amp;mut self) -&gt; R; fn writer(&amp;mut self) -&gt; W; } I have a specific implementation of this: impl Trait&lt;Pipe, Pipe&gt; for Type; The trait then gets used in a method of a wrapping type which looks like: impl&lt;T: Trait&lt;io::Read, io::Write&gt; for Wrapper&lt;T&gt;; Which gives the error: the trait Trait&lt;io::Read, io::Write&gt; is not implemented for Trait&lt;Pipe, Pipe&gt; What am I doing wrong?
Yeah, but the RFC covers structs with a single field as well.
Notepad ++ 7.5.2 Final + Portable Free http://www.crack4share.com/2017/11/notepad-752-final-portable-free.html
the maintainer is dead, long live the maintainer!
Smart pointers are generally just a type of type you can make. There is no technical definition other than that they should contain a reference to something, as your type does. If you believe Convex is essentially a type of [Point], then yes, it's a smart pointer.
The final section of the second edition is a guided project: [Final Project: Building a Multithreaded Web Server](https://doc.rust-lang.org/book/second-edition/ch20-00-final-project-a-web-server.html). Of course, there's no substitute for writing something and figuring out compiler errors independently.
You're still missing my point. It's not about potential misconceptions surrounding what Rust does well... it's about potential misconception surrounding what Rust does **poorly**. (eg. Erlang doesn't make a very good language for writing Python/Ruby/Node.js extensions because of its runtime. Rust, on the other hand, does.)
Perhaps a good name for a coroutine library
Uh, haha, no. rucd is just my take on a porcelain for querying Unicode. RE noise: maybe? Hard to tell from README. The right words are there. There's probably more overlap with tantivy, although I'm aiming at a lower level of abstraction.
I mean, it's a somewhat creative troll alright, but I had a good chuckle at the idea that there might be a subreddit for the topic of physical rust... people have the weirdest hobbies :)
I would approach this differently. I would see whatever you are trying to measure as a metric. For example - you want to measure the number of GET you get on a certain endpoint? Add 1 to a counter bucket each time that happens. Then write the bucket to a file at a specific interval. For this you can use Statsd + Graphite and then do whatever kind of processing you need to do using Grafana(although just using Graphite is good enough if you don't need very fancy graphics). The big advantage with Graphite is that a metric database will remain constant in size no matter how long your time series get(10 years or 1 day is the same). This is done by "compressing" older data, so that you keep good sampling rate in the recent past and decrease the sampling rate as you go further back. Integrating Statsd to any project is quite easy. It has binding for all frameworks and all languages you can imagine and you get amazing scalability with it.
I believe Gecko was part of the big rewrite, so it was at least partially successful.
Stylo is. Webrender is still being worked on. Compositor and Flow already happened. Quantum DOM IIRC had some work but has other bits still remaining. 
Working on introducing rust-style attributes to [reproto](https://github.com/udoprog/reproto/tree/attributes), which will be a mechanism for assigning metadata to existing declarations without introducing syntax changes. So services like these: service MyService { hello(name: string) -&gt; string; } Could be convinced to generate http-specific code with something like this: service MyService { #[http(method="GET", path="/{name}")] #[http_response(status=200, type=string)] #[http_response(status=404, type=Error)] hello(name: string); }
Same here. They could have chosen the pointer syntax, since it's closer to a pointer than a reference. I think it would also have avoided a lot of confusion between the 'address of' operator on the one hand, and the reference type on the other hand. That said, the pointer syntax would probably have induced other errors and frustrations I guess (is there anything like pointer arithmetic in Rust? maybe in unsafe, I haven't looked there yet).
Gecko was the *focus* of the big rewrite. It was originally called Raptor and then NGLayout, so if you‚Äôre looking for more info you should try those terms, too. As I understand/remember it, the original plan was for Netscape Communicator 5 to be released based on the old Mariner engine while Gecko was developed in parallel to be the engine in a future release. I can‚Äôt remember if it was Netscape or AOL, but management decided Mariner wasn‚Äôt going to be competitive and the Netscape 5 work was scrapped in favor of focusing all resources on getting Gecko finished. The short-term results were an extended wait followed by an underdone and somewhat disappointing Netscape 6. The long-term results were Firefox, the disruption of the IE monopoly and IE 6 monoculture, and the modern, standards-based web. Dropping Mariner for Gecko was painful and widely derided at the time, but in hindsight (19-20 years later) it may have been the best of the bad options available.
I find the DWARF / gimli section to be out of place and possibly confusing for the target audience. &gt; Okay, so now we know how to allocate new memory and refer to it (use a boxed pointer!). But what if you want to refer to some existing memory somewhere and point to that? &gt; A good example of this is ‚Äì I‚Äôve used this DWARF parser called gimli. It doesn‚Äôt do basically any allocations ‚Äì it just loads all the DWARF data for your program into memory and then points into that data. If I understand correctly the author is trying to convey that *some other* code loaded data and your code wants to point to said data, but I fear this new vocabulary ("DWARF... gimli... what is all this?") will only confuse people not already familiar with those topics. The content then goes back to the definition of the `Container` struct (then heap-allocated data / containers) again never to mention DWARF / gimli again.
&gt; RE noise: maybe? Hard to tell from README. I am not sure whether @vmx is the same as the one on GitHub. I remember that Volke Mischke and Damien Katz (the Noise authors) mentioned "Okapi BM25"/"Lucene Core". &gt; There's probably more overlap with tantivy Ah, thanks for the reminder that this exists. I am currently using Lucene Core and would love to use something in Rust instead. Unfortunately i am a noob to the theory.
Absolute noob here, what does this mean : |x| ?
Wow. This belongs on /r/techsupportmacgyver/ I would keep pursuing audio based solutions suggested on stackexchange. At least then you can get a recording of the data on a good computer immediately before the machine dies and worry about decoding it at your leisure. 
Yeah, I think it's still early days for IR systems and Rust, but I think there is a grand opportunity there. But it's a long road.
I'm interested that you made the count an O rather than a concrete unsigned integer. If it was a usize, you could still require T to be Div&lt;usize, Output=O&gt;, right? What can a count be other than a natural number? Are there any possible O's that would give a different result to using a concrete unsigned integer? Apologies for the tangential bikeshedding!
This thing does not appear in code just by itself - it is a part of anonymous function, and is always followed by an expression. The whole thing looks something like this: `|x| x + 1`. Equivalent thing in javascript would be: `function(x) { return x + 1; }` or `(x) =&gt; x + 1`.
&gt; (is there anything like pointer arithmetic in Rust? maybe in unsafe, I haven't looked there yet). There is, but it's more explicit: https://doc.rust-lang.org/std/primitive.pointer.html#method.offset 
Nope, sorry... I'm pretty sure I'm a way more ignorant version of that VMX :D
Unlike in languages like C#, you cannot just say stuff like let pipe: Pipe = ...; let x: io::Write = pipe; Type `io::Write` is a trait object, and it is completely distinct type from others - not a kind-of-superclass thing like it is in C#. Thus, when you ask for a type that implements `Trait&lt;io::Read, io::Write&gt;`, you cannot give it something `Trait&lt;Pipe, Pipe&gt;` - trait is the same, but type parameters are completely different, and thus compiler complains. To fix this, you can replace trait objects with type parameters, like this: impl&lt;R: io::Read, W: io::Write, T: Trait&lt;R, W&gt;&gt; for Wrapper&lt;T&gt; { ... } Now you don't ask for `Trait&lt;io::Read, io::Write&gt;` - you ask for `Trait&lt;R, W&gt;` such that `R: Read` and `W: Write`, which something that implements `Trait&lt;Pipe, Pipe&gt;` will fulfill.
We don't document them because they're not specified. That said, we do show visuals for String, and thus Vec, in the ownership chapter of the book.
One could imagine imagine a "trait slice" - `&amp;[T]`(**not** `&amp;[&amp;T]`!) that would contain both length and vtable: https://play.rust-lang.org/?gist=baee32f3e98a177facb240d9966b4640&amp;version=nightly
&gt; Vocabulary is amazingly important and last I checked about six months ago the basic documentation was not good. It wasn't until I came across a stack overflow post that said to interpret the colon in lifetime parameters as "outlives" that I was able to work with lifetimes meaningfully. This was a key realisation for me too.
Thanks for this post! The only Android instructions I could find prior was at [this link](https://blog.rust-lang.org/2016/05/13/rustup.html), but I could never follow it all the way through and get it to work. Now I see there were a slew of other important details, and I look forward to trying this later. I'd have to look into it later, but I wonder if it would make things easier to move all those linking steps into the `build.gradle`file? I can imagine changing my Rust code wanting to just pressing play in Android Studio to make things automatically recompile.
you'd have to write / apply some rust plugin for gradle
This is correct, mostly. &gt; There's nothing Gfx can do to make this work with OpenGL Well, that may not be the case, but it's hard to tell just yet. We may be able to create multiple GL context and share resource between them, thus providing a better multi-threaded experience in the new `gfx-backend-gl`. It's quite far from being operational yet, so don't hold your breath :)
Would be nice if it worked with associated types too.
You can execute shell commands from gradle. https://docs.gradle.org/current/dsl/org.gradle.api.tasks.Exec.html I think that would be a fine first pass without requiring a Rust plugin at this point.
When was the last time someone invented a programming language in order to make a thing, and succeeded? Was it C/Unix?
I've decided to toy w/ my WASM-to-JVM backend to see if I could get Rust code to run on the JVM. I succeeded in what is basically a [hello world](https://github.com/cretz/asmble/tree/master/examples/rust-simple). My next step is to see if I can do some more complicated things.
I would not consider `Convex` a smart pointer. A smart pointer is a container type - it should not care about the actual data inside. It can care that it needs to be destroyed/released, it can care that it needs to hold a lock to be used, it can care that it needs copy-on-write, or other stuff about how the data is transported - but it should not care about the data itself, how it is represented, what are it's invariants etc. A smart pointer generally says - "I'll move the thing around for you and handler access to it. If you want to actually **use** it - I can't do that, but I'll let you borrow it so you can do it yourself". The `Deref` trait is how the smart pointer is letting you borrow the thing. Your `Convex` does not seem like a smart pointer: * It _does not_ do anything about moving the `vertices` around - in this regard, the behavior of `Convex&lt;'a&gt;` is no different than `&amp;'a [Point]`. * It _does_ care about an invariant of the data inside - it guarantees the invariant the the polygon represented by the `vertices` is convex. So - it's not a smart pointer, and it should not implement `Deref`. A `Deref` says "as long as you don't want to move me - consider me a `&amp;T`". But you don't want to consider `Convex` as `&amp;[Point]`, because it isn't just a list of points - it's a list of points guaranteed to be convex. When you deref it you discard that guarantee - and that's not something you should be doing implicitly!
Why can't we be Rustafarians?
Do you have a link to that SO post?
A smart pointer is e.g. `Rc`, `Arc` and `Box`. I would not recommend to use it e.g. for newtype structs, because that makea code less readable, whereas for smart pointers you expect that you just access the inner data. The most important point is probably that you should never use it to emulate inheritance.
The best way to see what's going on is the unstable book. So you'd take the feature gate, and look it up like that. For `proc_macro`, that's https://doc.rust-lang.org/nightly/unstable-book/language-features/proc-macro.html This links to the tracking issue: https://github.com/rust-lang/rust/issues/38356 I believe that there are several different feature gates though. But that's how I go about determining these kinds of things.
&gt; writing a performance-sensitive section primarily for calculating things sounds perfectly doable in stable Rust today. Unless you need explicit SIMD.
 use moduleA; //Unresolved import moduleA You never used `mod` to declare that `moduleA` exists. Because of this, I'm surprised moduleA::dodawanie(1, 2) works.
There we go, here is what I was missing. Tomorrow I'll try to write a quick &amp; dirty AAC parser at the london rust conf, then if this goes anywhere, will replace the C++ horror using the superpowered decoder with native rust in my ios and android apps. Good stuff, good stuff!
Operationally, the `Deref` trait gets you automatic access to the methods of the target type, and allows fairly easy coercion to the type. I think the main pitfalls of implementing `Deref` are surprises about which methods are available, ambiguities that may need UFCS to clarify. This is (I believe) just a stylistic / clarity thing, rather than a correctness thing. It is most problematic when you write a `Deref` implementation that dereferences to a generic type parameter, at which point there can be clashes between your methods (those of `Convex`) and the type you dereference to. In this case, I'd say you are fine and there is no real worry. There is also the `AsRef&lt;T&gt;` trait, which you can use if you want the same functionality with less implicit conversion and more explicit `.as_ref()` calls.
Not offhand but I did a Google search and this looks about right: https://stackoverflow.com/questions/30768063/does-a-b-a-mean-that-the-lifetime-b-must-outlive-the-lifetime-a
Rust strings and C strings aren't the same thing and you're trying to treat them as if they are. (The second parameter there is a pointer to a `GLchar`, which is an alias for `c_char`... and your program is blowing up because you're not properly converting the data.) C strings are null-terminated. Rust strings store a length next to the pointer rather than putting a null byte on the end of the string. The fact that it worked at all was pure luck, determined why what just happened to be in memory off the end of the string. You're supposed to use `CString` in place of `String` and `CStr` in place of `str` when interacting with C code. The macro works because it uses `concat!` to stick a `\0` on the end.
From what i gathered from the net, every file creates the module for itself implicitly
That's not true. You need a `mod` declaration for a module to exist.
this is great! It is the second project today that has been on the frontpage of /r/rust that I can immediately use for a project I'm doing. Thanks for the crate!
I think it is worth mentioning that glium is currently the primary opengl crate and even has a tutorial book showing how to use common features. Perhaps you want to learn the FFI, but if just learning Rust is your goal, then you might prefer a more native, safe, convenient, and beginner-friendly alternative. https://glium.github.io/glium/book/tuto-01-getting-started.html
Rust's references are C++'s pointers, with restrictions imposed by the borrow checker. It's only a matter of terminology here, but it shouldn't be *that* foreign to a C++ dev.
It's closer to a pointer *in C++*. I think "reference" has more meaning to it and fits better here, "pointer" sounds like something that should be left in the backend side of things. &gt; is there anything like pointer arithmetic in Rust? maybe in unsafe Not too sure about that but I would guess that pointer arithmetic is safe until your try to dereference the result.
As I mentioned just below the example: &gt; The main pain point is that mixed-type arithmetic operations are generally not available. It's a conscious choice, forcing you to handle the edge cases caused by going from integer to floating-point, etc... but it can indeed be a bit painful. `Div&lt;usize&gt;` is only implemented for `usize` and `&amp;usize`; it's not implemented for `f32`, `f64`, etc... This means that requiring `Div&lt;usize&gt;` outright prevents the caller from using any other primitive type than `usize` :(
I can write text to a terminal, so the QR code approach might actually be feasible. I don't have a node interpreter available so I can't use that library, but I could port it to Python or Rust and type it in to the impaired machine by hand.
The audio approach hasn't panned out so far. There's no OSS device or other raw PCM device that I can just `cat` data into. And I have no access to the ALSA library headers (though I do have access to the shared library, if you know a way to work with that directly.) The pulseaudio server seems to still be running, and I can run `pactl` but not `paplay` (nor `aplay` nor `gsound-play` or anything). But when i try to upload a sample to `pactl` I get "Bus error". Otherwise I could write the data as PCM audio and upload it and play it through `pactl`. I posted a link to my SuperUser post on Tech Support Macgyver. Thanks for the suggestion! https://www.reddit.com/r/techsupportmacgyver/comments/7gf89p/dell_xps_9550_ssd_dies_taking_network_usb_audio/
Go is arguably an example, it was developed to make services at Google.
Can you provide some insight to the rationale here? I felt like this was awkward when I ran into it.
Looks OK, but I don't really see the point of supporting Python given [passlib](https://passlib.readthedocs.io/en/stable/) exists.
&gt; that is, fn a(int &amp;x) is analogous to void a(int* x), not void b(int &amp;x) In terms of language semantics or storage? `void b(int &amp;x)` is implemented as passing `int* x`
The module system is one of the most controversial aspects of Rust, you're not alone :) Many people are very uncomfortable with the idea of the compiler needing to poke at your filesystem to create modules. People cite workflows where they delete `mod foo;` in order to sort of 'comment out' the whole module; you can't do this in that system. This is only one reason, but it's one of the big ones. I personally just want that to exist. It's an uphill battle.
&gt; Note: it could be argued that Rust should define higher-level mathematical structures, such as Groups, Rings, etc... it can also be argued that this is not something the standard library need bother with. For anyone who's interested: [alga](https://crates.io/crates/alga) does this, with implementations for most primitive types, as well as the higher-order types from the nalgebra crate. The tradeoff here is that it's (mostly) mathematically strict, so for example, you can't calculate the mean of a set of integers, because integers don't have true multiplicative inverses in general and so won't implement any algebraic structures that allow one to divide by the number of elements. (I say mostly because I think it ignores the annoyances of IEEE infinity and NaN when deciding if a floating-point type implements a given algebraic structure.)
just semantics
Thanks!
I mostly agree, but `String` implements `Deref&lt;Target = str&gt;` and that's somewhat related to this `Convex` type.
It's too bad there's not a "composition" deref style trait or something. I guess it couldn't really be a trait maybe. You'd have to have a "target" composee to allow the dispatch and probably some way of intercepting dispatches or something... I don't know if I'm making sense.
Is `diesel_codegen` getting a version bump as well? Still shows as 0.16.0 on crates.io. 
It seems like a thing you *might* be able to do with custom-derive, though I don't know if you've got E enough type information there. Something like `#[delegate(Trait, member)]` to generate an `impl Trait` block delegating all methods to `member`‚Ä¶
Thanks really helpful. Just one more question. How do I know whether or not to use CString or Cstr when the type is c_char? Can it be either but depends on whether its borrowed or not?
Thanks really helpful. Just one more question. How do I know whether or not to use CString or Cstr when the type is c_char? Can it be either but depends on whether its borrowed or not?
I was under the impression glium wasn't to active? The author gave up on it?
`String` implements `Deref&lt;Target=str&gt;` because it's a heap-allocated `str`, in the same way `Vec&lt;T&gt;` implements `Deref&lt;Target=[T]&gt;`. 
Glad to hear that someone finds it useful :) If you have any feedback let me know!
Your alloc looks different than [mine](https://github.com/cretz/asmble/blob/8b51e14c330a562bb09c8e938a5c687cbdc962ab/examples/rust-string/src/lib.rs#L32) (part of my [example set](https://github.com/cretz/asmble/tree/master/examples) of running Rust on the JVM using WASM). Granted the heap stuff is only w/ nightly, but so is wasm32-unknown-unknown. I am not a Rust expert, so it's quite possible that my approach is limiting, but it uses the same memory so it works ([here](https://github.com/cretz/asmble/blob/8b51e14c330a562bb09c8e938a5c687cbdc962ab/examples/rust-string/src/main/java/asmble/examples/ruststring/Lib.java) is the Java wrapper).
Right, it's related in that you might consider making a `str`-like `Convex` type.
Yeah, yours is more proper, this one is a bit of a hack :)
Isn't that what OP's `Convex` is in the first place?
&gt; Same here. They could have chosen the pointer syntax, since it's closer to a pointer than a reference. The pointer syntax is used for "unsafe" (C-style) pointers.
Can I make a RISC-V computer for desktop use? Will I ever be able to?
Yes, a Rust reference is closer to a C pointer except memory-safe, const-by-default and possibly "fat" (`&amp;str`, `&amp;[T]`).
`pub unsafe extern fn Java_com_mozilla_greetings_RustGreetings_greeting` Writing this manually *sucks*. Try [javacpp](https://github.com/bytedeco/javacpp) like I used [here](https://github.com/myfreeweb/freepass/blob/c423c550f82cbb687c835731273e177847397ef3/android/app/src/main/kotlin/technology/unrelenting/freepass/Vault.kt) ([build script](https://github.com/myfreeweb/freepass/blob/c423c550f82cbb687c835731273e177847397ef3/android/app/build.gradle.kts#L77-L101)). Would be awesome if someone made a `javarust` tool that generates JNI bindings directly to Rust code (without requiring the code to provide a C API?)
A GUI program *in what context?* A native UI? a game UI? maybe a web interface makes sense in your context. We need more information. There is more than one option since they focus on more than one context.
After adding `diesel_infer_schema` crate and annotating `[macro_use] extern crate diesel`, I found that I no longer used the `diesel_codegen` crate. YMMV.
`diesel_codegen` is going away. from the [CHANGELOG](https://github.com/diesel-rs/diesel/blob/v0.99.0/CHANGELOG.md) &gt; diesel_codegen should no longer explicitly be used as a dependency. Unless you are using infer_schema! or embed_migrations!, you can &gt; simply remove it from your Cargo.toml. All other functionality is now provided by diesel itself. &gt; &gt; Code using infer_schema! or infer_table_from_schema! must now add diesel_infer_schema to Cargo.toml, and &gt; #[macro_use] extern crate diesel_infer_schema to src/lib.rs 
No, `str` is unsized and basically `[u8]` with invariants. `Convex` is sized.
I meant semantically. It's a value not a box. &gt; No, str is unsized and basically [u8] with invariants. And `str` doesn't deref to `[u8], because it has additional semantics and invariants.
Not really. `str` holds the same guarantee about the data as `String` - that it's valid UTF8. The difference between them is of ownership and memory management - things that `Convex` does not add on top of `&amp;[Point]`. If anything, `Convex` is to `&amp;[Point]` like `str` is to `[u8]`: | Borrowed reference | Owned memory ---------------------------------------------|--------------------|-------------- Just bytes - no guarantee | `&amp;[u8]` | `Vec&lt;u8&gt;` Just `Point`s - no guarantee | `&amp;[Point]` | `Vec&lt;Point&gt;` Bytes guaranteed to be valid UTF8 | `&amp;str` | `String` `Point`s guaranteed to form a convex polygon | `Convex` | ? 
Right, `String` derefs to `str` and simultaneously has to maintain its invariants because it allows mutation.
What this tells me is that `Convex` *could* make sense as an unsized wrapper for `[Point]` (rather than `&amp;[Point]`), with `Box` and `&amp;` for its manipulation.
Yeah, passlib is nice, and definitely has aspects we're trying to emulate. I think there's a fair few advantages to libpasta, however. The core being written in Rust brings some nice security guarantees. Plus I think the usability story with libpasta is significantly nicer than passlib with regards to algorithm/parameter choice and migrating from old hashes. For example, the first page you see with passlib shows you how to use PBKDF2, which isn't ideal. Installation seems a lot more awkward (the optional libraries) and potentially may leave you using, for example, scrypt with a really slow reference implementation. These are all the kinds of things which trip people up when doing password storage, and it's usually really hard to reverse this once you make an initial decision. We're trying to solve that by offering a foolproof option. 
From the OP: &gt; The unstable thing that everyone are currently looking for is async function - currently provided by the futures-await crate It's not to the point of being a huge problem just yet, but that's the example provided.
Just curious, why are you saying that GLSL shaders don't work reliably? Is it because you need `fp64`, or something else?
I don't know what OP wanted, but I'd like to know the state of the union for native GUI on Windows, Linux, and macOS. I was able to get a basic GTK app working but I had far less luck with Cocoa, partly because the Objective-C integration seemed very-untyped and spooky.
Boo! I suppose this leaves one option for the truly obstinate: define your own Averagable trait, with a and write implementations for numbers: https://play.rust-lang.org/?gist=279e37c13b66abefad657e74bab3adb2&amp;version=stable Naturally, the trait rules stop you writing a generic implementation for anything divisible. 
No, blame Nvidia and their bogus drivers. I took the screenshot on my laptop, with Intel HD graphics. If I put the same program on my desktop with Nvidia drivers, I get a blank screen. Only the UI still works. I have no clue as to why that is. If you want, you can test it yourself: https://github.com/fschutt/lyon-testcase-openstreetmap - older version of a part of the project. If you get a picture, that's good. If you don't, it's your driver. Maybe this issue is fixed in a newer version of the driver or only appears on Linux (?). I've come to the conclusion that transforming the points in GLSL isn't worth it - the transfomation has to be only done once and takes - at most - roughly 0.5 seconds (with multithreading) for a few thousand points. I only have to project them once, then I can cache the result. Plus I have to have a CPU version anyways to calculate some metrics for the screen boundaries. So I'd have to maintain GLSL + CPU versions of the same code, at very little performance gain, plus I am not guaranteed that it will actually work reliably on all drivers. I only get a blank screen for the UTM GLSL shader, not for the UI shader, for example. It's weird and I tried debugging it with renderdoc, no dice. So I gave up and said that doing a geographical reprojection in GLSL doesn't work (for my use-case).
/r/corrosion
^ That's basically the current state of the union when it comes to native apps. GTK is slowly moving forward into niceness. I remember seeing something on QT at the start of the year, but not much more than that. A ton of UI's for things like games and opengl apps, and the rest seems to be of the 'just use a browser to ui it!' I think the only real thing that rust is missing now is a nice cross os native library. It would make it a truly awesome language for 99% of my uses at that point.
It's likely you'll be able to (risc-V chips with linux support are very likely to be released soon~ish, which you could use as a desktop, raspberrypi-like), but whether it'll be a good idea is another question entirely, which depends on many more factors. I hope it will be a thing, but we're _way_ too early to know yet.
Ah, yeah, that sounds more sensible. Using `Arc&lt;Mutex&lt;_&gt;&gt;` is pretty much a reflex for me because I've only ever used `lazy_static` in a multi-threaded environment. :) 
Oh, all right. So it's the old OpenGL drivers story. Who knows, maybe Vulkan and SPIR-V will be better :). You could try `GL_DEBUG_OUTPUT` next time you run into issues, though I'm not sure who implements it. Actually I tried to Google for that and the second hit was https://chromium.googlesource.com/angle/angle/+/930fefca127fb16c8a65172139ee2fa55a87c2ef; read the commit message. I agree with your reasoning that GLSL is not worth the trouble in this case -- you're reprojecting vector data, not rasters. I tried to run your test app, but unfortunately it's not building anymore.
Sometimes contributor to [avr-rust](https://github.com/avr-rust/rust) here. We have a [gitter room](https://gitter.im/avr-rust) if you wanna hang out! There are several open issues in LLVM that prevent us from compiling libcore, so we have [a fork](https://github.com/avr-rust/libcore) with things disabled to allow compiling what we can. We are always looking for people to help out with the LLVM work! We are a little hamstrung by the fact that Rust master isn't on the newest LLVM, so we recommend using [our fork of that](https://github.com/avr-rust/llvm) as well. 
Lambda operator. This is an idea from functional programming languages. They let you: - save an expression, turning it into a value without executing it - elsewhere you can restore the expression and execute it like a function To explain why this is useful, let's say you want to find the first item produced by an iterator which satisfies some condition. You could use a search loop: let mut iter = stuff.iter(); let result; loop { match iter.next() { Some(x) if ..... =&gt; { result = Some(x); break }, None =&gt; { result = None; break }, _ =&gt; continue, }} The missing expression `.....` would look at `x` and decide if it's the `x` that should be saved into `result`. The rest of the loop is generic enough that it can search *any* iterator. It's only the result expression that needs to be changed for different purposes. Wouldn't it be useful to make it a function? Yes. It's part of the standard library. let result = stuff.iter().find(|x| x == y); is equivalent to let mut iter = stuff.iter(); let result; loop { match iter.next() { Some(x) if x == y =&gt; { result = Some(x); break }, None =&gt; { result = None; break }, _ =&gt; continue, }} `y` is *some other variable* that already exists. The lambda operator in Rust allows you to a) delay the execution of an expression and b) package it together with the other-variables it needs (like `y` in this example). Since this is Rust, it is designed to be memory-safe but optimizer-friendly. Here's how it will optimize: - Each lambda operator generates its own unique type of closure. - The `find` method is generic (type parameter `P`). Whenever you use `find` with a closure, Rustc creates a unique special version of `find`. - Rustc also creates a function (with x and y) that executes the contents of the closure. - These two functions are each only used once, at that specific call site, so both are inlined. - This is exactly equivalent to writing the `find
I'd add that GTK is looking particularly promising because the Gnome folks (or at least a decent chunk of them) seem quite enthusiastic about making Rust a first-class language in Gnome/GTK land.
Question: is it possible to use procedural macros within the crate in which they are defined? All of the examples in the book show them being in an entirely separate crate.
No, they must be in a separate crate for Reasons.
I think it would be really useful tool, thumbs up from me!
How do I turn off a feature for transitive dependencies with Cargo? I want to disable use of libc on the regex crate. The regex crate has a dep on aho-corasick which has a dep on memchr which has an optional dep on libc. How can I not bring libc in?
(Technically Pascal strings store the length next to the characters rather than the pointer.)
That alternative version of `Convex` you talk about - let's call it `BoxedConvex` - would fit in the missing cell of my table: | Borrowed reference | Owned memory ---------------------------------------------|--------------------|-------------- Just bytes - no guarantee | `&amp;[u8]` | `Vec&lt;u8&gt;` Just `Point`s - no guarantee | `&amp;[Point]` | `Vec&lt;Point&gt;` Bytes guaranteed to be valid UTF8 | `&amp;str` | `String` `Point`s guaranteed to form a convex polygon | `Convex` | `BoxedConvex` If you had them both, it would make sense for `BoxedConvex` to deref to `Convex`. Sadly, that's not possible - `Deref` does not allow you to use `&amp;self`'s lifetime... 
But will win32 get a first class GTK story? The last time I tried to get GTK setup for win32 so that I could build some demos the installation process was not at all friendly.
I need a native UI, i just want to make simples windows with button and so on ... Can't you make a web native UI using Rust ? By that i mean something like Electron but in pure Rust with no Javascript ? 
Just to round out these answers -- `diesel_codegen` has been split into 3 crates. The majority of its behavior now comes from `diesel_derives`, which is re-exported from `diesel` itself. Our two procedural macros (`infer_schema!` and `embed_migrations!`) now live in separate crates (`diesel_infer_schema` and `diesel_migrations`) which you need to depend on if you use those macros.
This could be done entirely with `macro_rules!` macros if `concat_idents!` weren't useless
I think the most promising for QT is Rust Qt Binding Generator ([announcement](https://www.vandenoever.info/blog/2017/09/04/rust_qt_binding_generator.html), [reddit discussion](https://www.reddit.com/r/rust/comments/6xwfxe/rust_qt_binding_generator/), [github repo](https://github.com/KDE/rust-qt-binding-generator)) since as the announcement says it's under consideration for inclusion in KDE. Although I can't really say much else about it since I haven't had a project to use it on yet.
/u/rabidferret is the "shouldn't be used anymore" part of this reply correct? Is usage of `infer_schema!` now discouraged? If so, what should be used instead?
(When I use unsafe in this post I mean thread-unsafe) A question about concurrency this time: struct T { a: ThreadSafe, // A reference to a thread-safe C API b: NotThreadSafe, // Unrelated not-thread-safe stuff } impl UnsafeTrait for T { fn not_thread_safe(&amp;mut self) { stuff(b); } } impl SafeTrait for T { fn thread_safe(&amp;mut self) { self.a.external_method(); } } I want to be able to hold two references to `T`, one which can use both the thread-safe trait and the unsafe trait, and one which can only access the thread-safe trait. I also don't want to have to introduce a mutex or other lock because that is already handled by the external api. If it makes any difference, the unsafe part of `T` is also generic.
Oh, heh, I've been starting on an OpenID implementation using Rocket as a backend. Maybe we can "cross-pollinate" in a sense. Anyways, url: https://github.com/xorxornop/oidc-rs
could someone? yes (and someone please do!) but does that exist? not currently. It would actually be pretty awesome.
Most people would mean here a desktop application native ui. And the answer is that rust is still lacking any really idiomatic solution.
GTK is becoming a decent non idiomatic solution. I'm still not really sure what an idiomatic rust solution would even *look* like, truthfully. GTK seems like a reasonable first step until then.
In the world of opensource, the original author (in this case tomaka) moving on doesn't necessarily mean the project is dead. The community is maintaining glium.
&gt; I dabbled in Haskell for a bit, and I still remember getting error messages in parts of code I hadn't touched, calling parts of code I hadn't touched... and wondering which of the N little changes I had done elsewhere could have triggered this. I'm pretty you get better at the game after playing for a while, but I've got other things to do. In the end, I just typed all my functions in Haskell, it just scaled better. But that is the way that most fluent Haskell programmers operate anyway. Type declarations are optional but using more of them generally helps and rarely or never hinders. The more you explicitly tell the compiler about your code's intended types, the better it can pinpoint the cause of why your program doesn't live up to them. One example I've experienced first-hand countless times is that one of the most effective ways to troubleshoot type errors in Haskell programs is to ["wolf-fence"](http://coreygoldberg.blogspot.com/2008/12/wolf-fence-debugging.html) the error by sticking hand-written type declarations into expressions "in the middle" of your code, so as to narrow down the source of the mistake. So I'll often refactor a definition just to facilitate adding a type declaration to what started as a subexpression.
I'm fine with it, but I really wonder, does it work on windows? I always heard some negative comments about it, so I cannot tell.
It does, but if you only want your program to work on windows, then you can just use the win32api crate.
If you don't want HTML then there exists [Limn](https://github.com/christolliday/limn). Otherwise you could just use Electron with [stdweb](https://github.com/koute/stdweb) for convenience. 
&gt; Code using infer_schema! or infer_table_from_schema! must now add diesel_infer_schema to Cargo.toml, and #[macro_use] extern crate diesel_infer_schema to src/lib.rs
The solution is to make `Convex` dynamically sized: struct Convex { vertices: [Point] } Then you use `&amp;Convex` analogously to `&amp;str`, and either `BoxedConvex` (if you want resizing) or `Box&lt;Convex&gt;` which can `Deref` to `&amp;Convex` just fine.
Every day. But having it be general purpose useful is very rare.
Has the query execution part of it been separated from the ORM stuff, or are you still forced to use the ORM? I looked at using it for a project a couple months ago but it doesn't support tables without primary keys, so instead I'm just using rust-postgres "raw".
Regarding [this list](https://github.com/libpasta/libpasta/blob/c86c3df5cf1a33e000f21a88cc5295848b50d978/src/lib.rs#L58-L101): If you really don't want any of these things in your code (that's a good thing :p), you should consider changing the `deny` to `forbid`. The difference between deny and forbid is that deny can be turned off by later code, while forbid can't.
&gt;The most important point is probably that you should never use it to emulate inheritance. Funnily enough, it's used for exactly that reason in a lot of places in the compiler: `FnCtxt` derefs to `Inherited`, which derefs to `InferCtxt`, which derefs to `GlobalCtxt`. "Do as we say, not as we do" :)
Very nice library. The [password hashing theory](https://libpasta.github.io/introduction/password-hashing-theory/) writeup on the website also seems very good.
I would be very interested in using it, but I am working with stable only. The readme mention that nightly is required, do you think it would be possible to port the code to stable ?
Haven't tried it, but the changelog mentions a sql_query function, looks like what you want.
It doesn't look like r2d2_diesel works with this version yet. I'm getting the following error: &gt; 29 | pub struct DbConn(pub r2d2::PooledConnection&lt;ConnectionManager&lt;SqliteConnection&gt;&gt;); &gt; | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait &gt; `diesel::connection::Connection` is not implemented for `diesel::SqliteConnection`
I hope it does. I think the lack of first class dev support for windows is what's holding GTK back.
As OpenID Connect is built on top of OAuth2, maybe we can? I'm not sure as much about previous OpenID versions, I think those would take considerable effort since the specifications are extensions to both base standards. I'll keep track of your work, it looks like it might evolve into a useful collaboration.
It's hard to tell without seeing your specific use-case, but you could create a `!Send`/`!Sync` token which you create on the thread in which `T` originates, and then implement `UnsafeTrait` for `(T, OriginalThreadToken)`. Then you know that `not_thread_safe` will can only be called from the original thread (the thread on which `OriginalThreadToken` was created).
What's the primary difference between sql_query and sql? It seems like they both do the same thing, albeit slightly differently?
Cool :) I am indeed focusing only on Connect with OAuth2
I'm planning to do exactly that as part of improving the ease of use over the next few releases. I can't give a timeline, of course, but keep watching for a stable release. In the meantime, the [bencher](https://github.com/bluss/bencher) crate provides a port of the standard benchmark harness to stable Rust that you could try.
relm is worth a look - it's built on top of GTK: * http://relm.ml/relm-intro * https://github.com/antoyo/relm
Can you just pass a reference to the thread-safe `a` member to your other threads?
Limbo/Inferno too, perhaps.
Good point, I did mean general purpose.
In general, a library like `subprocess` (or mine, `duct`) isn't going to let you do this, because it involves editing global state. Here's what basically has to happen under the covers, at least on Unix: 1. You open a pipe. 2. You spawn a child process with the read end of that pipe as its stdin. (It's important that this step comes before the following, because the child needs to inherit the current stdout.) 3. You call the `dup2` libc function to replace file descriptor 1 (stdout) of the parent process with the write end of that pipe. (Optionally you can try to save the previous value of fd 1, to restore it after you're done with all this.) 4. You close both of the original pipe fd's in the parent process. That step #3 above is the dangerous part, and why libraries don't usually offer to do this for you. You can't do that if you have any other threads running, because who knows when they might try to print something, and you don't want to swap fd 1 out from under them. And if you're planning on restoring the original stdout after you're finished, you need to think about whether the way you're doing that is panic-safe. But if you own the entire process you're writing, and you want to try this, you can use the `libc` crate and just follow those steps. I think the easiest way to open a pipe is the [`os_pipe`](https://github.com/oconnor663/os_pipe.rs) crate, though another way might've come along since then?
This is very useful! It's funny to me to see the comments calling this a niche use-case, because I end up doing this sort of thing all the time -- For example, creating newtypes for indices for one array which has all my data and a second array that has a relevant subset of the same data compressed for cache efficiency. It's so frustrating to have those hidden bugs caused by a typo that you'll spend big chunks of time debugging. One thing that you can do to get instance-level safety at runtime is to assign a random number to a container when you create it, and then have indices used to index that container be something like `(u32, usize)`, and check to see that the `u32` matches the one in the container before using the `usize` to actually index it. I actually do this a lot because it's really easy to disable in release builds, and I sleep a lot easier at night knowing that errors I could easily make with dumb typos will immediately panic instead of silently doing the wrong thing until I pass an out-of-bounds index.
Added an answer above, but just clarifying here: Is there any particular reason your parent process needs to use its own stdout, rather than just having a couple of regular pipes to talk to the child's stdin/stdout? Maybe you could say more about exactly what your requirements are?
- Pure Rust - [limn](https://github.com/christolliday/limn) - but use the [components](https://github.com/christolliday/limn/tree/components) branch. It's the technically most mature I've seen, but it's in a very, very alpha stage. Ex. the font path is hard-coded to `./assets/font/YourFont` which creates heaps of problems if the current working directory is not where you expect it. - [stylish](https://github.com/Thinkofname/stylish), not sure, seems to be for games. webrender-based. - conrod, but the ID system makes it extremely hard to do anything. I'd dare to say it's useless for UI development. It came out when Rust was just in a 1.0 stage and has been dragged on ever since. - Bindings - GTK and QT for traditional desktop apps. The bindings aren't the best, but there have been several apps using Rust + GTK successfully. - `win32` and `coacoa` UIs. But you'll probably have more luck with GTK directly. Or roll your own. Currently I am working on a solution that combines webrender, glium and [yoga](https://facebook.github.io/yoga/). I've also written [another UI layout](https://github.com/fschutt/layout2d) thing, but you [don't want to see the code](https://gist.github.com/anonymous/c6ba2de4376f5743797206383fa16a3d) of that, it works but its hideously verbose.
Right now, that would be an awful lot of work. Eventually? It's possible. If RISC-V manages to take off, I'd say it's likely at some point. It's likely that RISC-V will gain traction in the embedded space that ARM, MIPS, and various niche architectures currently fill first. Making chips, and all of the surrounding ecosystem like motherboards, busses, hardware enumeration, power management, cooling, and the like that are necessary for competitive desktop use is likely going to take a lot longer. But, just like ARM took off in the embedded world but is making its way into the laptop market, and has made a few forays into the desktop and server markets, I think that after some time in the embedded market RISC-V is likely to expand, and may even have an easier time of it than ARM; not having to pay exorbitant fees for a full ARM license to design your own core will likely be more appealing for those wishing to invest in their own chip design.
Quick question regarding this. I've never done any OpenGL or the like and was planning to start https://learnopengl.com/ and take https://github.com/bwasty/learn-opengl-rs as reference this weekend. Now that repo uses `gl` and `glfw-rs` and has says the following regarding opengl crates: &gt; You can also use glutin (a pure Rust alternative to GLFW), but the API is a bit different, so following the tutorials might not be as straight-forward. &gt; You might be tempted to use glium instead of raw OpenGL. I'd recommend against that, at least in the beginning, to get a good understanding of how OpenGL really works. Also, glium is not actively maintained at the moment. Would you still recommend choosing the more idiomatic rust crates or use the ones more closely following the tutorial for just learning it?
It's a matter of how primitive things are. `CString` and `CStr` are proper Rust types, with all of the associated safety guarantees. `*c_char` or `*const c_char` is a raw pointer to a `c_char`. It's Rust's way of representing the actual C data type and, for compatibility with C code, raw pointers support all of C's pointer-unsafety. (Dereferencing the pointer is an `unsafe` operation.) Basically, Rust code should convert to `*c_char` or `*const c_char` as late as possible because, at the point you do so, you step outside Rust's safety checks.
Point. I've rephrased my post so it doesn't sound like I'm saying Pascal stores it next to the pointer.
For win32 there is: https://github.com/gabdube/native-windows-gui
For the Ruby gem, are you thinking of using helix, ruru, or just plain FFI?
It got sort of taken over. We also have gfx from piston, but I've heard it's still not stabilized yet and might not have beginner resources.
Highly recommend orbtk from the Redox project. They have a nice native API and it targets SDL as a backend on non redox systems so its pretty widely supported. It isn't QT, but for simple UIs it has the tools and you can roll the rest.
You may want to take a look at orbtk from Redox as well.
I'm guessing something like QT/GTK?
...or, for someone who doesn't want to deal with a build experience patterned as "embedding a Rust component in a C++ application", there's always the "treat PyQt as a QML analogue for the QWidget API" option. ([PyQt](https://en.wikipedia.org/wiki/PyQt)/[PySide](http://www.pyside.org/) plus [rust-cpython](https://github.com/dgrunwald/rust-cpython)/[PyO3](https://github.com/PyO3/pyo3) plus [setuptools-rust](https://github.com/PyO3/setuptools-rust).) Something like [PyInstaller](http://www.pyinstaller.org/) could then be used to bundle it all into a single EXE file. I know I've used [py2exe](http://py2exe.org/) with PyQt in the past. (It should also be possible to put cargo at the top of the stack by embedding the Python interpreter in a Rust application rather than generating a Rust module to be imported into a Python application, but I've never tried it.)
**PyQt** PyQt is a Python binding of the cross-platform GUI toolkit Qt, implemented as a Python plug-in. PyQt is free software developed by the British firm Riverbank Computing. It is available under similar terms to Qt versions older than 4.5; this means a variety of licenses including GNU General Public License (GPL) and commercial license, but not the GNU Lesser General Public License (LGPL). PyQt supports Microsoft Windows as well as various flavours of Unix, including Linux and macOS. PyQt implements around 440 classes and over 6,000 functions and methods including: a substantial set of GUI widgets classes for accessing SQL databases (ODBC, MySQL, PostgreSQL, Oracle, SQLite) QScintilla, Scintilla-based rich text editor widget data aware widgets that are automatically populated from a database an XML parser SVG support classes for embedding ActiveX controls on Windows (only in commercial version) To automatically generate these bindings, Phil Thompson developed the tool SIP, which is also used in other projects. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Since macros can be re-exported, it's possible to write a ‚Äúfa√ßade‚Äù crate that exports both proc-macros and non‚Äìproc-macros at once. I use this method in [Maud](https://github.com/lfairy/maud/blob/62298aec552f3a5a3b1a90f52762dbda8221de38/maud/src/lib.rs#L21), and I think Diesel does something similar.
I tend to focus on designing objects in my API such that they are initialized into a good state at all times and all methods are correct to use at all times. If they aren't, I create an affine type or helper structs, sometimes using lifetimes, to convey what is correct in the API in the object's current state. This makes it so the programmer cannot compile a program that uses the API incorrectly, though it doesn't prevent them from making their own logic errors of course. So I actually use whatever type semantic is necessary to accomplish those goals (functional, builder, affine time, etc). It also isn't wrong to add functions in Rust. If you look at nom, the parser combinator crate, they have a lot of functions and few objects. I think it's best to use the best paradigm for the job in any given scenario. It may not always be readily apparent though. I also tend to organize in a way which modularizes the interdependency of the code. If multiple things are depending on each other, they belong together. Unless there are too many, I put trait implementations in the same file as the struct they are for. If a file gets to be over 1k lines I generally find some logical way to split it up. Also, I tend to expose all the common things in my APIs at the root of the crate so users don't have to deal with modules. If it gets too clustered, the crate can probably divided up into multiple crates. In fact, make sure you can't split functionality into separate library crates, because many of Rust's best crates do one thing really well, though some require a large API surface to do so (glium/vulkano). I also find that typically one module in your code may often have its own Result and Error from error_chain that spans several methods or functions return values. You usually only need one or two per crate if it doesn't have much API surface. Don't forget you can include unit tests in your modules as well. This may also drive how you organize your code. For instance, when working with Rocket, you might want to test the route in a particular module inside that same module to keep the code all together. When possible, make doc tests, as they are more helpful to readers of your docs, but otherwise I think making tests in the module they are associated with is best.
It depends whether you want to intimately learn how OpenGL works. If you do, you will be spending at least a week reading stuff on the opengl wiki as you encounter new situations. With glium most of that has been dealt with and the only complicated thing left is writing and interacting with shaders, which you will have to read the opengl wiki for. It can also be a bit akward at times if you are trying to send certain data into the shader. If you want to know OpenGL primarily, use it directly, as that will tell you exactly how it works. However, if your goal is to learn Rust, I think it will be frustrating to have to interact with OpenGL natively and learn it at the same time (learning both things at the same time takes effort). You could consider learning OpenGL in C first and then using it in Rust, and I think that might work better, but just dealing with OpenGL is not fun and avoiding it is a quality of life improvement imo.
As someone who has spent the last 10 months of his life exploring writing GUI libraries for rust, patching winit, being heavily involved in the rust-dsp group (trying to bring gui dev to it) and exploring various options for gui lib design in rust, when I see these threads every few days I often wonder whether I should contribute. To be blunt, the way operating systems work currently don't fit rust well. As in, they don't really fit at all. They make heavy use of shared references/pointers and state is passed around like a game of pass-the-parcel. Rust hates this, and so the UIs we need to develop for rust need to think differently. The problem is, there are two main schools of thought in the current libraries, and neither of them are anywhere near appropriate. The first, is the approach winit/glutin/conrod/etc take - basically managing all of the state and event loops and everything inside rust land, and then attempt to communicate that back and forth with the underlying operating system via abstracted data types. This is (sort of) elegant from an API perspective, and allows you to easily control your style of UI - retained or immediate, enums and safety, etc etc. The problem is, it's terrible on performance and not appropriate for apps you want to sit there in the background and shut up when not in use (basically apps like audio plugins, git clients, music players, utility apps, browsers, and ironically, usually these are the things many companies inappropriately reach for electron for). They are fine for games, hence why there's so much development doing game UIs in rust and almost nothing for regular UI using this approach. The second is to pass all of the responsibility to either the OS or another library written in another language and be a thin wrapper layer over the top. This is how the QT bindings work, and some of the libraries I've written and am experimenting on (my github is github.com/robsaunders - tinyui is worth checking out for a mac implementation, but all of these are experiments at the moment until I find the right solution). These have the advantage of being very performant but it's HARD to write anything simple and elegant. I believe I'm getting close to cracking it - but I only have skills in cocoa/objective c FFI and not windows or linux, so I have no help on this basically and can only write tools for mac os. Taking the first approach, you end up having extreme trouble trying to do things that are extremely simple in C/C++, like passing closures around. In rust, this can be a nightmare, and produce ugly APIs. This is a whole separate topic - but I've also personally experienced a great deal of resistance in the rust community around the current tomaka-driven projects just to get small things done/committed. There is a very political scenario going on at the moment and it's tough to get things moving, so I've been writing my own stuff and saving my energy. Lastly, writing FFI code in rust can be tough, it's highly undocumented. Almost all of the stuff I've done has been totally undocumented. I've even got a webkit style gui library going that works extremely similarly to electron, but so far it only works on mac because the build process for webkit on other platforms is a damn nightmare. TLDR: this isn't just a simple problem of writing a library. Rust itself doesn't fit well with the current stateful-soup libs. There are other reasons why this is moving so slow, and it's not just lack of desire.
I wonder if bazel will let an android_library depend on a rust_library as easily as their [c jni examples](https://github.com/bazelbuild/bazel/blob/master/examples/android/java/bazel/BUILD). If not, something to play around with.
So if I just want a simple UI what should I do? It seems to me that starting up a HTTP server inside my app with some web interface is the easiest option right now (if I'm okay with non-native GUI and I care more about speed of development and maintainability).
What I would suggest, before you lose your documents due to power outage etc: Write a script that cats all of your documents to stdout slowly, so that you can take a video of them scrolling by, with your phone camera or a better camera. Maybe borrow a better camera from a neighbor and record in higher fps. Then if any of your future data saving methods fail, at least you can always transcribe the data from the video, maybe you can even automate that with opencv/ocr. Good luck! 
What I would suggest, before you lose your documents due to power outage etc: Write a script that cats all of your documents to stdout slowly, so that you can take a video of them scrolling by, with your phone camera or a better camera. Maybe borrow a better camera from a neighbor and record in higher fps. Then if any of your future data saving methods fail, at least you can always transcribe the data from the video, maybe you can even automate that with opencv/ocr. Good luck! 
What I would suggest, before you lose your documents due to power outage etc: Write a script that cats all of your documents to stdout slowly, so that you can take a video of them scrolling by, with your phone camera or a better camera. Maybe borrow a better camera from a neighbor and record in higher fps. Then if any of your future data saving methods fail, at least you can always transcribe the data from the video, maybe you can even automate that with opencv/ocr. Good luck! 
What I would suggest, before you lose your documents due to power outage etc: Write a script that cats all of your documents to stdout slowly, so that you can take a video of them scrolling by, with your phone camera or a better camera. Maybe borrow a better camera from a neighbor and record in higher fps. Then if any of your future data saving methods fail, at least you can always transcribe the data from the video, maybe you can even automate that with opencv/ocr. Good luck! 
Thank you!
What I would suggest, before you lose your documents due to power outage etc: Write a script that cats all of your documents to stdout slowly, so that you can take a video of them scrolling by, with your phone camera or a better camera. Maybe borrow a better camera from a neighbor and record in higher fps. Then if any of your future data saving methods fail, at least you can always transcribe the data from the video, maybe you can even automate that with opencv/ocr. Good luck! 
What I would suggest, before you lose your documents due to power outage etc: Write a script that cats all of your documents to stdout slowly, so that you can take a video of them scrolling by, with your phone camera or a better camera. Maybe borrow a better camera from a neighbor and record in higher fps. Then if any of your future data saving methods fail, at least you can always transcribe the data from the video, maybe you can even automate that with opencv/ocr. Good luck! 
What I would suggest, before you lose your documents due to power outage etc: Write a script that cats all of your documents to stdout slowly, so that you can take a video of them scrolling by, with your phone camera or a better camera. Maybe borrow a better camera from a neighbor and record in higher fps. Then if any of your future data saving methods fail, at least you can always transcribe the data from the video, maybe you can even automate that with opencv/ocr. Good luck! 
What I would suggest, before you lose your documents due to power outage etc: Write a script that cats all of your documents to stdout slowly, so that you can take a video of them scrolling by, with your phone camera or a better camera. Maybe borrow a better camera from a neighbor and record in higher fps. Then if any of your future data saving methods fail, at least you can always transcribe the data from the video, maybe you can even automate that with opencv/ocr. Good luck! 
What I would suggest, before you lose your documents due to power outage etc: Write a script that cats all of your documents to stdout slowly, so that you can take a video of them scrolling by, with your phone camera or a better camera. Maybe borrow a better camera from a neighbor and record in higher fps. Then if any of your future data saving methods fail, at least you can always transcribe the data from the video, maybe you can even automate that with opencv/ocr. Good luck! 
What I would suggest, before you lose your documents due to power outage etc: Write a script that cats all of your documents to stdout slowly, so that you can take a video of them scrolling by, with your phone camera or a better camera. Maybe borrow a better camera from a neighbor and record in higher fps. Then if any of your future data saving methods fail, at least you can always transcribe the data from the video, maybe you can even automate that with opencv/ocr. Good luck! 
What I would suggest, before you lose your documents due to power outage etc: Write a script that cats all of your documents to stdout slowly, so that you can take a video of them scrolling by, with your phone camera or a better camera. Maybe borrow a better camera from a neighbor and record in higher fps. Then if any of your future data saving methods fail, at least you can always transcribe the data from the video, maybe you can even automate that with opencv/ocr. Good luck! 
What I would suggest, before you lose your documents due to power outage etc: Write a script that cats all of your documents to stdout slowly, so that you can take a video of them scrolling by, with your phone camera or a better camera. Maybe borrow a better camera from a neighbor and record in higher fps. Then if any of your future data saving methods fail, at least you can always transcribe the data from the video, maybe you can even automate that with opencv/ocr. Good luck! 
What I would suggest, before you lose your documents due to power outage etc: Write a script that cats all of your documents to stdout slowly, so that you can take a video of them scrolling by, with your phone camera or a better camera. Maybe borrow a better camera from a neighbor and record in higher fps. Then if any of your future data saving methods fail, at least you can always transcribe the data from the video, maybe you can even automate that with opencv/ocr. Good luck! 
What I would suggest, before you lose your documents due to power outage etc: Write a script that cats all of your documents to stdout slowly, so that you can take a video of them scrolling by, with your phone camera or a better camera. Maybe borrow a better camera from a neighbor and record in higher fps. Then if any of your future data saving methods fail, at least you can always transcribe the data from the video, maybe you can even automate that with opencv/ocr. Good luck! 
What I would suggest, before you lose your documents due to power outage etc: Write a script that cats all of your documents to stdout slowly, so that you can take a video of them scrolling by, with your phone camera or a better camera. Maybe borrow a better camera from a neighbor and record in higher fps. Then if any of your future data saving methods fail, at least you can always transcribe the data from the video, maybe you can even automate that with opencv/ocr. Good luck! 
The pair of notices: 1. I tried to use libpasta with rocket application but I got the error 'Multiple packages link to native library `ring-asm`. A native library can be linked only once.'. 2. Why do `libpasta::verify_password` and `libpasta::hash_password` get `password` argument as `String` instead of `&amp;str`? 
Have you considered to migrate error management to the new crate `failure` before 1.0?
Rust the programming language is completely free, but you're looking for /r/playrust I think :)
hahaha thank you very much! I noticed the logo was a bit different :)
Encourage you to give the programming language a try though!
Pretty cool! Is there a way to autogenerate the header file? I've looked into using rusty-cheddar before, but never got it working. 
&gt; The first, is the approach winit/glutin/conrod/etc take - basically managing all of the state and event loops and everything inside rust land, and then attempt to communicate that back and forth with the underlying operating system via abstracted data types. This is (sort of) elegant from an API perspective, and allows you to easily control your style of UI - retained or immediate, enums and safety, etc etc. The problem is, it's terrible on performance and not appropriate for apps you want to sit there in the background and shut up when not in use Why is that?
My strategy is just do it and start with the low level bits. If something becomes too big or unwieldy, it's time to refactor. Rust makes refactoring pretty safe.
Does this version include a pure Rust driver for Postgres? Last time I tried Diesel it needed libpq.
&gt; is there anything like pointer arithmetic in Rust? Yes, there is. Rust has raw pointer types `*const` and `*mut`, which behave like C pointers. You can do arithmetic on them, like in C, which is perfectly safe, but you need `unsafe` to dereference them.
Yes, currently, a web app is the easiest way to write something with GUI
True! I was mostly considering the case where any compiled, parallelizable language would be an improvement, but if more performance is needed SIMD is not stable. I would still say stable rust can improve performance of python, js, etc. in a context where explicit SIMD is overkill. 
This is the start of a closure or lambda, an anonymous function. [Rust by example](https://rustbyexample.com/fn/closures.html) can explain them better than I can.
Requires nightly though.
I know Windows! Maybe I can help?
Maybe it is. It seems good to me because it jives well with Rust, but it isn't very featured and only provides primitive elements.
Thanks!
I'm actually rewriting my own GameBoy emulator (from c#) So now I've gotten to experience writing a GB emu 2.25 times (failed c++ port) Good luck!
Practically, should this be an issue? I know it's desirable to have a pure Rust stack but libpq is solid and comes from the horse's mouth so to speak.
I will answer above, to keep our conversation in one place :)
Not sure when that was. Diesel has been using rust-postgres for quite some time.
an interesting thing I got while building [sozu](github.com/sozu-proxy/sozu): Rust crates are easy to make, and a good way to separate some functionality. That in turns allows you to reuse code, not only inside your project, but in other projects as well. In my case, I extracted the code to manage routing configuration (which is supposed to be core to the proxy's job) and configuration files in a separate library. That allows me to write quickly a lot of tools to drive it. That's a pattern I'd like to apply more to other projects. Like, a web application for which you quickly write a command line administration tool to help in support, where you can reuse your domain objects and database access code for free.
&gt; I tried to use libpasta with rocket application but I got the error 'Multiple packages link to native library ring-asm. A native library can be linked only once.'. Ahh _ring_, always causing dependency issues. libpasta is using the latest ring 0.12, so presumably rocket depends on an earlier version, indirectly even. I'll double check to make sure it's not a libpasta issue. Have you run cargo update just in case you're using an old version of rocket or something? &gt; Why do libpasta::verify_password and libpasta::hash_password get password argument as String instead of &amp;str? My initial rationale was for security. The idea being that if we take an owned String, then we can make sure it's dropped, and potentially even clear the memory if that can be shown to work. You can see around [here](https://github.com/libpasta/libpasta/blob/master/src/lib.rs#L165) I'm attempting to wrap it in a [clear_on_drop](https://crates.io/crates/clear_on_drop) to do just this. However, I'm more and more wondering whether it's worth the UI hassle, and also that it's likely to be unexpected for most people.
Thanks! I quite like it as it is, similar to clippy, to force me to reconsider rewriting it if possible. But it is nice to be able to override it in selective places, the `#[allow(...)]` annotations make for nice warning signs, much like `unsafe`, to force me/people to check that particular piece of code.
Hey, thanks a lot for your writeup, that told me quite a lot more than I knew before. Tell you what, I'll write down where I'm coming from and where I want to go with this. If it's too much, feel free not to read it/answer to it :) I'll try to link everything that might be of interest so you can click along my line of thought. I'm writing a [neovim plugin](https://github.com/KillTheMule/nvimpam). So neovim starts, then starts the binary via [jobstart](https://github.com/KillTheMule/nvimpam/blob/master/autoload/nvimpam.vim#L84), and by virtue of setting `rpc: true`, it communicates with it over [stdin/stdout](https://neovim.io/doc/user/eval.html#jobstart()). On the rust side, I'm using neovim-lib to [setup](https://github.com/KillTheMule/nvimpam/blob/master/src/bin.rs#L111) a [connection](https://github.com/daa84/neovim-lib/blob/master/src/session.rs#L95) over [stdin/stdout](https://github.com/daa84/neovim-lib/blob/master/src/rpc/client.rs#L54). This works, everythings fine! Ok, now I want to basically turn things around. I want to write a new binary (as customary, my binary is basically just gluing together the library parts) that, when run, starts a neovim instance and communicates with it. For that, neovim has the [headless](https://github.com/neovim/neovim/blob/207b7ca4bc16d52641eaa5244eef25a0dba91dbc/runtime/doc/channel.txt#L18) option, or rather, [embed](https://github.com/neovim/neovim/blob/207b7ca4bc16d52641eaa5244eef25a0dba91dbc/runtime/doc/channel.txt#L159). The way I understand it is that if I connect things propery (and I freely admit that I probably don't fully understand what 'connect' means in this context, I only have some sort of mental model that's probably wrong) I can communicate using neovim-lib just as before. Since neovim-lib uses my binary's stdin/stdout, I assumed I have to connect those to neovim's stdout/stdin (as I understand it, in the reverse case I tried to explain above it's neovim that's responsible for setting up the std* thingies correctly). So that's where the idea is comming from, but if I can do that somewhat differently, I wouldn't mind (as long as it doesn't bork up performance compared to the usual way the plugin will be used, because I'll want to use that 2nd binary for benchmarks). As an aside, an example of how to use this can be found [here](https://github.com/equalsraf/neovim-qt/blob/189abb0e60a5aea595e9d02b1d09da2c0727e49f/src/neovimconnector.cpp), but I understand neither C++ nor Qt, so it's not helping me much. Ok, thanks for reading, if anyone did :) I'm both open to doing things differently and putting time into it (hope I get to it this weeken, but I don't mind my project moving slowly). Maybe the first thing I should do is find docs on how streams really work :) 
Nice ! I am currently using bencher, but the variability of some benchmarks is very high. I'll be looking at the repository !
I wrote a proof of concept for integrating libpasta (in a very early version) with Rails, with a blog post explaining it [here](https://samscott89.github.io/pass/2017/03/28/easy-password-migration.html). Note, the example probably wont work, since the libpasta gem doesnt exist yet. When I wrote that I did it with plain FFI, and used thermite to run the cargo build process. That worked pretty nicely for source builds. For most (all so far) of the language bindings now, I'm using SWIG. Which has it's own way of handling Ruby and just spits out a C wrapper file. So I'd be tempted to use that. I _suspect_ that ruru is overkill for my needs. Though that will probably change as I try to increase the functionality supported by other languages... Basically, I'll keep it simple to start with, but would love to investigate the other options when the time comes. And happy to take any suggestions/contributions/advice in that area. 
Digging into (1) a little more, rocket _was_ depending on cookie 0.9.1, which at that time was using ring 0.11. As of commit [07d4d23](https://github.com/SergioBenitez/Rocket/commit/07d4d23cc888ffec0a6ed9e1eab18b3bbe55b9b9) the cookie/ring dependency has been updated. Although you would need to ask the rocket devs to see if that will be added to a 0.3.4 or if you need to wait for 0.4.
&gt; Have you run cargo update just in case you're using an old version of rocket or something? I use latest stable rocket (0.3.3). It depends on cookie crate that depends on ring 0.11. I got the reason for clearing memory after it's dropped but I think it's useless because typical use-case looks like: fn request_handler(password: &amp;str /* &lt;- it will be not cleared */) { ... if libpasta::verify_password(..., password.into() /* &lt;- it will be cleared */) { ... } } And we have several password copies in web-server buffers, network buffers, etc.
does 'web interface' fit under the definition of gui program 
Heh, the Rust Black Friday Initiative?
Yeah, precisely the same complaint I was seeing on other threads about clearing passwords from memory. Okay, leaning towards changing to `&amp;str`, in the absence of any other arguments. I posted another comment at the same time as you about the dependency conflict. Currently this is just the nature of ring. (See [here](https://github.com/briansmith/ring/issues/575) for precisely this issue).
&gt; terrible on performance and not appropriate for apps you want to sit there in the background and shut up when not in use Huh? There's no reason for it to be terrible, these libraries just don't yet have the amount of optimization work put into them that GTK/Qt/‚Ä¶ have had over the years. (By the way, [GTK 4 is going to have Vulkan-based GPU rendering](https://blog.gtk.org/2017/10/23/gtk-3-92/)‚Ä¶) WebRender actually does nothing when sitting in the background, so [limn](https://github.com/christolliday/limn) should be totally appropriate for this kind of apps.
Last time I tried that I ended up with a 100 MB distributable for the most trivial of programs. As much as I'd like to have a nice cross-platform gui, I do not want to buy that with the hassle of distributing python and enormous packages.
Well, it was free last Friday, too, but we gave a 50% rebate. You just didn't notice!
The economics of open source :) Anyway, I thought the OP wanted to ask if there was an _easier_ way to get Rust (the language). The price of entry is commitment and sitting at the feet of the masters, and he wanted (I thought) to know if there was a 50% off deal. Indeed a good question in This Year of Our Blessed Saint Ergonomica.
It would seem imprudent for version 1.0 of a library before failure has been stabilized.
I researched gui libraries too and currently limn has most potential! still not ready but it is the closest we are to event based pure rust library. there is a lot of place for contributions!
Part of the problem (IMHO) is that nowadays cross-platform apps have just got to be ... perfect. Originally, GUIs were not required to be beautiful - think of Tcl/tk on Unix. Things were generally an aesthetic mess for years, but that didn't stop people hitting buttons. Now people don't like what GTK looks like on Windows, and I can't see the problem - I want to do something with a GUI, not sit back and contemplate its cool shaded gradients. The less said about MacOS people's opinions of 'foreign' GUI elements the better. This is a problem, since the one cross-platform toolkit that people complain least about (Qt) has a very classic old-fashioned OOP design, and the impedance mismatch with Rust is not pleasant. It doesn't seem a bad option to have a GUI written in another language, and the Special Sauce written in Rust. The problem there is the messy communication between these universes, and the fact that the days of a compact GUI framework seem over - they are all very shiny things that come with the proverbial kitchen sink. 
If you want to do async I/O in vanilla Rust with no external libraries, you're basically stuck with using `select`/`epoll`/whatever directly.
My observation is that languages and GUIs are tightly bound (prime example - swift was designed to work well with apple's existing frameworks). as such , the web-UI idea seems best? i.e. Rust's design-motivation centres around internet connected systems.. and the browser is the UI there.
You may have a point there. I develop for Linux these days, so shared Qt is as simple as `sudo apt-get install python3-pyqt5` and the last time I used `py2exe` to produce a nice, small EXE, I was using PyGTK (GTK+ 2.x). That said, 100MiB still sounds excessive. It's likely that whatever bundler you used was playing it far too safe in what it included and could be manually tuned to exclude some of it.
IMHO, with medium-to-large projects you have to split your project into smaller crates early. Otherwise even with incremental compilation the build times will be a risk. This subcrate split might greatly affect the code structure and might be hard to do after a fact. In one of my projects I've been simulating C headers files using Rust traits. At the cost of little indirection I can have crates depending on each other (e.g. circular dependency is not a problem) and only the affected crate is recompiled whenever something changes.
Can libpasta has more relaxed ring version constraint (like '&gt;= 0.11, &lt; 0.13')?
[removed]
It actually was pyinstaller. And looking at the dist folder it created the top contributors are: 25M libicudata.so.57 7,1M libgtk-3.so.0 6,3M libQt5Widgets.so.5 5,4M libQt5Gui.so.5 5,3M PyQt5.QtWidgets.so 5,3M libQt5Core.so.5 4,6M libpython3.6m.so.1.0 3,2M PyQt5.QtGui.so 2,8M PyQt5.QtCore.so 2,5M libicui18n.so.57 2,3M libcrypto.so.1.0.0 1,9M PyQt5 Seems to just package up every dependency by default. No idea what I would even need crypto for. Thanks for the pointers. Seems like in any case packaging is quite an involved process. I'll try my hand at navigating the jungle again.
Maybe you can find some answers in https://rust-lang-nursery.github.io/api-guidelines/.
Perhaps you find this one usefule; Once I implemented an Iterator over a collection of nested tuples via macro. In there nested tuples of type (A, (B, (C, ...))) are turned into flat tuples like (A, B, C, ...). https://github.com/Bendrien/ommap/blob/master/src/iter.rs#L87
&gt; and I can't see the problem - I want to do something with a GUI, not sit back and contemplate its cool shaded gradients. If you want to sell your app it needs to look professional. And today professional means it needs behave like other apps of that platform. Personally, I'd like to see someone trying droping this idea of cross-platform GUIs. Make the best Windows framework you can. Then someone can make the best OSX one they can, etc. If you design your application with MVP, then you can write 2 of the layers platform independant and split only on the view.
It also contains both `libgtk-3.so.0` and the Qt libraries.
there is https://doc.rust-lang.org/stable/std/net/struct.UdpSocket.html#method.set_nonblocking
Generally the exact name of those iterator structs doesn't matter since you call, for example `.chars()` on a `str` and only really care that it implements the iterator trait, not what the type is called exactly. And since you can only create these structs with those special methods, it makes the most sense to name them after those methods. Now for general naming conventions, I try to go for something that is descriptive yet concise of its purpose. Not always an easy thing to do all the time unfortunately. But there is no requirement that certain things must always be a noun or adjective or verb, as you have already seen (at least not in the code based I've worked in).
You also have to remember that the compiler has lived through years of the language changing from out under it. It's in much better shape these days than it's ever been, but it doesn't mean that everything in it is a shining example of how to write Rust code.
This is true - but we're then talking commercial applications, which is on another level to open-source GUI tools. Then, it's true that the best way is to do what the mobile people do - separate logic from display, and write the display in the framework appropriate to that platform. But then you need a serious budget. Also, it's true what you say, _paying_ customers are very picky about look and feel. I worry about non-paying users of open-source software assuming that they can get all that beauty for free. 
Note that the iterator types are usually named after the methods that create them (`cloned()` =&gt; `Cloned`). A method called `clone()` would clone the iterator, whereas a method named `cloned()` returns the same iterator, but returning clones of the items. For `fuse()`, it's the *iterator* itself being fused rather than the items, and so it's a verb. The plural forms tend to be constructed from things that are not iterators, eg. `str::chars()`.
Can you actually receive data from that socket? 
I have no idea; it's certainly not a full solution.
All of this is in the CHANGELOG. &gt; Code using `infer_schema!` or `infer_table_from_schema!` must now add `diesel_infer_schema` to `Cargo.toml`, and `#[macro_use] extern crate diesel_infer_schema` to `src/lib.rs` You can also use `diesel print-schema` instead.
Thanks for the interesting discussion.
`sql` is intended for use when you need a small fragment of SQL in your query, but you're still using the query builder. `sql_query` is intended for use when you are writing the entire query with raw SQL. 
Diesel has never had a public release that used rust-postgres. It was used for like the first 5 commits but I switched to libpq about 2 years ago.
No. There is a pure-rust driver that I wrote for switching to Tokio, but it's more or less on hold at the moment.
Hi all :) I'm happy to finally show you the project I have been working on for the last three months, [Sausagewiki](https://github.com/maghoff/sausagewiki). It is a wiki engine that aims to be really easy to get up and running. Please check it out :) There are some rough edges still, and I wouldn't call this version 1.0.0, but it has been in use by real people for the last two months, so it is absolutely workable. To make it as easy as possible for users, I have opted to compile the whole thing down to a single binary file with no external dependencies (on Linux). This means it uses musl (Thanks, Rust!) and embeds SQLite (Thanks, John Gallagher for libsqlite3-sys and the `"bundled"` feature) and any resources that might otherwise be shipped separately, such as templates and database migrations (Thanks, Diesel!). A massive thanks to the entire Rust community for making this such a breeze! Along the way, I have also stumbled onto some side tracks. I have implemented [Bart](https://github.com/maghoff/bart) for templating, [cargo-license-hound](https://github.com/maghoff/cargo-license-hound) to help with conforming to licenses (it [got some attention here](https://www.reddit.com/r/rust/comments/7d41o7/cargolicensehound_a_tool_to_find_all_the_license/) earlier) and I have used this project to explore the design space of web request handling. I have implemented [tree way diff/merge](https://github.com/maghoff/sausagewiki/tree/master/src/merge), the algorithm we always use for merging text, and I am looking forward to [upstreaming](https://github.com/maghoff/sausagewiki/issues/46) it into the [diff crate](https://github.com/utkarshkukreti/diff.rs), if that works out. Using SQLite, I have been able to run migrations from `build.rs`, since I could make all its effects contained to the `target` directory. This plays well with `infer_schema!` from Diesel, and I have been able to treat the migrations as the absolute truth about my database schema without having to remember to run anything on the command line. This has been a great experience! 
Weird, I was so sure that it was using rust-postgres... Must have mixed it up two projects I was working on.
You can also do async sockets in python
Sure, that sounds reasonable. I can do that for both ring, ring-pwhash dependencies (the latter is kept at version parity with ring).
Personally I think "generic" names are okay. I sometimes get frustrated by projects with cutesy names because I have to remember a whole list of things to keep track of which library is which. Maybe I should create an operating system called "OperatingSystem" ;-)
I made a few vague motions in the direction of IPFS a while ago. Not sure any of my code would be helpful but maybe I'll try to dig it out.
&gt; 2d game framework &gt; Got 3D rendering working ???
[Advent of Code](http://adventofcode.com/2017) is starting tomorrow, if anybody's looking for some puzzles to try!
Pretty sure OP wants to do it specifically in Rust though...
native-windows-gui developer here. Just letting you know that the library is a bit stale at the moment. But as long as you don't need anything fancy, the dev branch should be enough
Yes, via `recv()`. What will happen is that, once you‚Äòve set the socket to non-blocking, `recv()` will return with an error with the kind `io::ErrorKind::WouldBlock` if there is no data. The standard library does not provide you with a `select(2)` equivalent, though. You will have to use some crate for that.
Very interesting! It looks like neovim-lib's Session type has a new_child_cmd constructor that might do what you need without any trickery. Have you tried using that?
Sounds interesting. Do you have any demo server up and running? Makes a big difference if you want people to try your software :)
True! That was _so_ on my list of ideas, but somehow I ended up not doing it. Hold on‚Ä¶
What you probably want is ```pub struct Convex { vertices: Vec&lt;Point&gt; } ... ``` 
I just downloaded and ran the wiki binary. I really like the minimalist approach so far! Some notes: - There should be some hint regarding the valid markup. It seems Markdown-ish. - It would be nice if `#` headlines would result in `h2` tags, not in `h1` (that's already taken by the page name). - Do you allow sub-pages (i.e. some kind of namespacing)? - I saw that you're using vanilla JS with DOM manipulation. Once the source grows, that might get a bit messy. I recently picked up [Elm](http://elm-lang.org/) and really love it so far - might be a nice companion for Rust in the Backend. The [Rust NES Emulator debugger also uses it](https://www.reddit.com/r/rust/comments/75ljsn/demo_of_my_nes_emulator_written_in_rust_and/). Keep up the nice work :)
Yes
The markup is Commonmark as implemented by pulldown-cmark, except it does not recognize inline HTML (by design), plus it allows tables (GitHub style). The lack of help text explaining this is one of the rough edges :) Thanks for your kind words :)
Oh my, I wrapped my head so much around how I can do it with `new_parent` that I did not actually realize the symmetrie and notice that `new_child` function. It does indeed look exactly like what I need, and very convenient. Thanks a lot! When I've made some progess I think I'll put some work into writing examples/documentation for neovim-lib.
What advantage do you see to making Convex into a Dynamically Sized Type? It's just going to make your life harder.
It does seem fast!
Rust magic ‚ú® üíñ üòÅ
There is something I don't understand with traits in Rc/Arc/etc: use std::rc::Rc; use std::borrow::Borrow; trait MyTrait { fn print(&amp;self); } struct MyImpl { val: u32, } impl MyTrait for MyImpl { fn print(&amp;self) { println!("{}", self.val) } } struct Container { obj: Rc&lt;MyTrait&gt;, } fn main() { let test = MyImpl{val: 21}; // Working do_something(&amp;test); let container = Container { obj: Rc::new(MyImpl { val: 12 }) }; let rc = container.obj.clone(); let test2: &amp;MyTrait = rc.borrow(); /* error[E0277]: the trait bound `MyTrait: std::marker::Sized` is not satisfied --&gt; src/main.rs:27:5 | 27 | do_something(my); | ^^^^^^^^^^^^ `MyTrait` does not have a constant size known at compile-time | = help: the trait `std::marker::Sized` is not implemented for `MyTrait` = note: required by `do_something` */ do_something(test2); } fn do_something&lt;T: MyTrait&gt;(obj: &amp;T) { obj.print(); } How should I do this ? I can define a function like fn do_something(obj: Rc&lt;MyTrait&gt;) {} but don't want to handle the Rc in the method, but before the call (because what if I have a Arc&lt;MyTrait&gt; instead next time ?) 
I have been hoping an OAuth2 server impl would come out! I am very excited to see this. :-) I'll try to find time (probably in a few months) to give this a shot -- thank you!
Just for completeness‚Äôs sake, I‚Äôll mention that one thing you *could* do is make `Convex` take a (covariant) type parameter: pub struct Convex&lt;Points: ?Sized&gt; { vertices: Points } impl&lt;Points: AsRef&lt;[Point]&gt;&gt; Convex&lt;Points&gt; { pub fn new(vertices: Points) -&gt; Convex&lt;Points&gt; { if vertices.as_ref().len() &gt;= 3 &amp;&amp; is_polygon_convex(vertices.as_ref()) { Some(Convex { vertices: vertices }) } else { None } } } Now you can produce an`Box&lt;Convex&lt;[Point]&gt;&gt;` from a `Box&lt;Convex&lt;Vec&lt;Point&gt;&gt;&gt;` just by using it as one.
If I find time I am going to work on a chip support crate for the MK20DX256, the microcontroller used on the Teensy 3.1/3.2. I am building it off of the `cortex-m` crate and modeling it after `cortex-m-rt`. I am not using `cortex-m-rt` due to a missing exception and because some decisions were made at that level that I would like to play with. Beyond that, I will not be copying the style of `stm32f103xx` and SVD based chip support crates. I chose to take this path due to the fact that I find that they feel too much like coding in C where we can do much more with the type system Rust provides. This has all come out of a desire to work on microcontrollers using Rust and having a few Teensys laying around. I would like to call out the wonderful tutorials by u/branan which guided me wonderfully in my first steps and really fed my hunger for utilizing Rust's type system on microcontrollers to make them far less error prone.
I don't have much to say other than this looks great! Personally I'm not a fan of the font choice but presumably that can be changed easily. I played with your demo a bit and really appreciate the fast search functionality. I think I'll use this for some internal/private documentation. Thanks for releasing this! Side note: I really like what you've done with the build-script. Anything that automates easy-to-forget tasks is a plus in my book!
You might be able to get pretty far with UdpSocket.set_nonblocking, but you might want to consider relaxing the constraint that you include no external libraries. If you find yourself needing to use a platform specific syscall like select or epoll, don't be afraid to depend on the libc crate. It'll give you access to those functions, in an unsafe and slightly inconvenient way. It has no other dependencies, so if you really wanted to, you should be able to include the source code into your repository. A slightly higher level crate would be "nix" that gives access to C functions, with a little bit of a nicer API, where you don't have to use the "unsafe" keyword. It has a few small dependencies though. If you want something a little bit higher level, and platform-independent, then what you want, is "mio". It abstracts sockets and waiting for them into a platform-independent interface, that will use epoll on linux, and IO completion ports on Windows.
Thanks! Right now, to change the font you actually have to rebuild the project.
It's good to know this will be of use. And I plan on adding to the current feature set, so you can look forward to even more when you have time to incorporate it.
I can't get this to compile.
Regarding unit tests within the same module, a good style is to do: #[cfg(test)] mod tests { use super::*; #[test] fn foo() { ... } } I usually place this at the end of a module's file.
Awesome. Once you get everything working the easy, you should totally implement the inverted dangerous way too just for fun :)
Or if the ultimate goal to avoid heap alloc, the wait for https://github.com/rust-lang/rfcs/blob/master/text/2000-const-generics.md is unfortunately the only choice.
If you WANT to write your own 3D code and use ggez for windowing/input/sound/resources/etc, it is now possible.
 ,
Well, there is `typenum` until then...
It's currently really hard to construct custom DSTs in Rust, _except_ via CoerceUnsized, which basically lets you define `Convex&lt;T: ?Sized&gt;` and coerce to it from `Convex&lt;[T; N]&gt;`. You can have something array-like here but you need to do lots of unsafe fiddling to make it work, and it's usually not worth it. Use `Vec` or `Box&lt;[T]&gt;`, it's much cleaner.
As /u/Manishearth indicates, you can use `CoerceUnsized` to construct unsized things. You can find an example [here](https://play.rust-lang.org/?gist=26be0905cb311eb38fd87d858eee4074). It doesn't accept a vector of points, but hey, you can do everything on the stack, so that's nice.
This doesn't really have to do with the Rc. It's because there is an implicit `Sized` bound on type parameters. So since `MyTrait` is unsized, you can't instantiate `do_something::&lt;MyTrait&gt;(&amp;MyTrait)`. You can fix this easily by disabling the implicit bound with `&lt;T: MyTrait + ?Sized&gt;`. Though if your only going to call `do_something` on a trait object, I would just make it non-generic and have it take a `&amp;MyTrait` instead. Btw, get can get a reference to the thing in an Rc with `&amp;*rc` (you don't need `borrow`) in case you didn't know.
Using full OS threads for these computations will have a large amount of overhead. I would highly recommend using a work stealing library like Rayon for your parallelism here and see what that does for the performance.
Your sequential sieve implementation has an efficiency issue, I think: You loop over the targets unconditionally, but many of these number are multiples of previous targets, so that they can't actually eliminate new numbers. You should instead make the inner-loop conditional: `if v[idx]`. This will make the sequential sieve substantially faster as the limit increases. This might break the parallel sieves, but that's something that can be fixed by changing the way you split the work.
That currently works, but there are no stability guarantees that it will continue working. Still, I'd be kinda tempted to get it into "production" on crates.io so that crater will pick up breaking changes. üòà
Iterator names matches the name of the function that construct them makes sense and is inline with the api guidelines mentioned by u/KillTheMule. But what about trait names? Traits may define more than one function and cannot follow the same convention. The api guidelines also does not seem to mention anything about naming traits. Trait names tend to be directly typed out by users and thus, I assume, should be consistent and predictable. Am I making an unreasonable assumption?
There's a [postponed RFC](https://github.com/rust-lang/rfcs/pull/1406) for that. Personally, I think the motivation is a little thin here and people should just use the delegated-to field directly, but according to that RFC there are over a thousand pure-delegation methods across rustc/cargo/servo.
Just to add to what others have said, Rust doesn't really have a huge standard library. The Cargo ecosystem is extremely convenient to use though, and Rust code in those libraries gets linked into your program. This means you can use a ton of "libraries" and still get a program that only depends on libc. So if you don't want to use libraries just because you don't want runtime dependencies then you're needlessly limiting yourself. 
Not a big issue, but now in addition to putting diesel under your "[dependencies]" you also need libpq installed. I hate it because it's not under source control and makes the project not self-contained anymore.
Thanks ! It's working but it like black magic for me‚Ä¶ Is there any disadvantage to disable the implicit bound or is this safe to do that whenever I got this error ? Also thanks for the &amp;* syntax, I didn't know that. 
On the work splitting side, you're doing something rather inefficient: `sieve_2` spins up 2 threads: - Thread 1 eliminates the numbers that are multiples of even numbers. - Thread 2 eliminates the numbers that are multiples of odd numbers. Most composite numbers are the multiple of at least one prime and at least one even number. This means you end up duplicating a lot of work. Here's an alternate work-splitting strategy that will perform better: - Get the primes (and only the primes) from 1 to `k`, somehow. - Then take the range from `k` to `k`^2 and split it into `n` ranges, 1 per worker thread. Example with 2 threads and k == 10: Thread one gets the range 11-55, thread two gets the range 56-100. - Then you combine the results by contatenating the array.
It would be really helpful to have a screenshot in your README, or even a gif! Even if installing/running is super easy, it's often way too much effort to just check out a project. :)
What exactly would "migrating to failure" mean for a something like Diesel? Implementing the [`failure::Fail`](https://boats.gitlab.io/failure/doc/failure/trait.Fail.html) trait for Diesel's current Error type, [`diesel::result::Error`](http://docs.diesel.rs/diesel/result/enum.Error.html)? Or something more invasive / backwards incompatible?
https://github.com/diesel-rs/diesel/commit/8996f28b3481f6a230491ae61bfec9f9cebfeade if you're interested
Bart looks really cool! It's cool that you build all the templates at compile-time; I can imagine some downsides to that approach, but for something small and fairly static like wiki template pages it sounds great. Also, the demo server appears to be down.
Sure this is possible! [I wrote you a quick example to get you started](https://play.rust-lang.org/?gist=a660f98aa692072160700b74d2f2e264&amp;version=stable).
&gt; I've also personally experienced a great deal of resistance in the rust community around the current tomaka-driven projects just to get small things done/committed. There is a very political scenario going on at the moment and it's tough to get things moving, so I've been writing my own stuff and saving my energy. Can you give an example? I've made small PR's and bug reports to a couple of these projects and that hasn't been my experience at all. I've occasionally gotten things like "this actually is harder than it looks because X" or "this would be nice but it's not high priority right now", but I wouldn't call that political...
[winapi](https://github.com/retep998/winapi-rs) should also have bindings?
I think this post is a followup for this: https://www.reddit.com/r/rust/comments/7gbuj2/what_is_meant_with_deref_should_only_be/dqj9t3y/ The idea is to have: * `&amp;Convex` that borrows it's `vertices` from somewhere else. * `Box&lt;Convex&gt;` that holds it's own data. * Both will guarantee the `is_polygon_convex` invariant. * `Box&lt;Convex&gt;` will `deref` to `&amp;Convex`
Compared to OwnedConvex (which would work like a String), it avoids an extra indirection. I don't need the ability to add vertices to these polygons, but performance is of some importance.
This is pretty impressive.
Great talk! **tl;dw** Swift does generics a different way than the two common approaches: - The Rust and C++ way where the compiler instantiates an independent copy of your generic code for each distinct combination of generic parameters it is invoked with. Pros: your generic code is as fast and memory efficient as if you had handwritten the specialized code directly. Cons: slow compilation because it is compiling the same functions potentially many many times; unable to do separate compilation, so the body of the generic code needs to be available when compiling code that invokes it. - The Java way where anything manipulated in a generic way has the same shape, in their case Object. Pros: generic code is compiled once; separate compilation is possible. Cons: memory usage, an `ArrayList&lt;Boolean&gt;` uses depending on the implementation at least 16 times more memory than it would in Rust Swift does something that combines the benefits of both and the downsides of neither. Generic data is packed the same as it would be without generics, i.e. a `struct Pair&lt;T&gt; { T, T }` used with `T = Bool` has the same layout as a `struct BoolPair { Bool, Bool }`. Generic functions are compiled once and separate compilation is possible, so the caller does not need to have the implementation available. At runtime, zero or more "witness tables" are passed to the generic function to allow generic code to manipulate the concrete data indirectly using function pointers. This is *not that slow* in the common case that your program is bottlenecked on memory or I/O anyway.
I forget how much convenience comes with Linux ;) It's a particular hassle with Windows
...or [alloca](https://github.com/rust-lang/rfcs/issues/618) which would handle the case where the parameter is only known at runtime.
Great talk! (only watched slava's half so far) How swift compiles generics is one of the more interesting aspects of the project that is *mostly* hidden from users, but is in fact visible in the things it can do. I believe Rust originally was aiming for a similar model, but it was ultimately abandoned as getting it to work well was too much work (swiftc is full of compiler heroics). A TL;DR of the talk: So rust basically has the dumbest possible model: all generics monomorphize (copy paste the code for every combination of generic args). Same as C++. The benefit of this is that a type like `Pair&lt;T&gt;(T, T)` can be laid out inline, and all code can be optimally tuned for each type. The downside is it blows up your compile times and code size (which can lead to bad icache usage, hurting runtime in full applications). It also makes it impossible to dynamically dispatch to generics, which is why a trait with `fn foo&lt;T&gt;(T) -&gt; u32` can't be turned into a trait object (they're not "object-safe"). Similarly generic functions don't work as function pointers and can't be dynamically linked. This is in contrast to the other common model: all generics are polymorphically compiled, using a common (boxed) type representation (Java). The costs and benefits are basically completely flipped. `Pair&lt;T&gt;(T, T)` must be laid out as `Pair&lt;T&gt;(Box&lt;T&gt;, Box&lt;T&gt;)` and lots of stuff needs to be virtually dispatched. But you compile fast and have smaller code, and you can even virtualize generic calls! It should be noted compilers with this model can often specialize generic code if it seems profitable, but this is complicated by the boundary between polymorphic and monomorphic stuff (e.g. lots of boxing and unboxing is bad). People familiar with the struggle of `Integer` vs `int` in Java have experienced this first hand. Swift tries to bend this curve. There isn't a common type representation, but generics can be compiled polymorphically. Generic functions are object-safe! And there's no harsh polymorphic-monomorphic boundary! The basic idea here is to create vtables that describe how to do basic operations like copy, move, intialize, assign, deinitialize and so on, called "value witness tables" (there's also slots for things like "copy an array of this type" as an optimization to avoid `n` dynamic copy calls). It's kinda like C++ where everything can have move/copy/assign overloads, but they're all compiler-generated (copying is operationally distinct from moving in Swift because it can adjust reference counts for classes). So a function like func foo&lt;T&gt;(val: T) -&gt; T { let copy = val; bar(copy) return copy } might compile down to (in psuedo swift-c-rust): func foo_abi(val: *Opaque, ret: *Opaque, witness: *VTable) { let copy: *Opaque = alloca(witness-&gt;size, witness-&gt;align) witness-&gt;copy_init(from: val, to: copy) bar_abi(copy, witness) witness-&gt;move_init(from: copy, to: ret) } This same machinery also enables `() -&gt; Self` to be object-safe (again, unlike Rust). I believe `(Self) -&gt; ()` still isn't object-safe in Swift, because the issue isn't an ABI one, but rather a type-checking one. But where this goes completely off the rails is not wanting to have to pass, like, an Int by reference. If someone passes in a `(Int, Bool) -&gt; ()` closure to a function that generically handles `(T, U) -&gt; ()`, they want that closure to have the native ABI you would give an (Int, Bool) function -- passing the actual values in registers. This involves this "reabstraction thunk" magic, which I think basically amounts to: when you pass a closure to a context that expects something *more abstract* than what you are (e.g. `(Int, Bool) =&gt; (T, U)` or `(T, T) =&gt; (T, U)`), you wrap the closure up in a thunk which translates from the abstract ABI to your more concrete one. I don't fully understand the details of this, tbh! 
I haven't put it on crates.io yet, but you should take a look at my [include_dir_macro crate](https://github.com/jcdyer/include-dir-macro): It's currently nightly only, because it uses procedural macros, but the goal is to let you easily bundle a directory of static assets into your binary, and access them through a HashMap, so it seems in line with what you're trying to accomplish here. (Check out examples/web.rs).
It's true that traits are not quite so consistently named. Some traits do only have a single method, like `Extend`, and so are named after that method, while others may represent a concept like `Iterator`. However, `Extend` could equally have been named `Extendable` or `Extensible`. Having a perfect convention is not really possible due to the inherent redundancy and ambiguity in natural language.
You‚Äôre looking for bindgen‚Äôs companion: [cbindgen](https://github.com/eqrion/cbindgen).
Obviously. The basic winapi is however very low level and takes a ton of work to do anything.
It would be nice if you could optionally compile rust code with this model to avoid having to monomorphize all the time and therefore improve build times.
GTK is far from decent outside of linux. 
Our errors are compatible with it if you choose to use it in your crate. We are not going to add something released 2 weeks ago as a dependency.
You can link it statically.
Can you provide more details about what exactly you want to do and what parts of Diesel you don't want to use?
While I'm always happy to see people trying parallelism, you might just want to use [`primal::Sieve`](https://docs.rs/primal/0.2.3/primal/struct.Sieve.html): #[bench] fn bench_primal(b: &amp;mut Bencher) { b.iter(|| primal::Sieve::new(LIMIT)); } My results for LIMIT = 10000: test test_bench::bench_par_2 ... bench: 43,399 ns/iter (+/- 4,462) test test_bench::bench_par_n ... bench: 152,968 ns/iter (+/- 14,911) test test_bench::bench_primal ... bench: 166 ns/iter (+/- 1) test test_bench::bench_seq ... bench: 40,267 ns/iter (+/- 3,809) LIMIT = 100000: test test_bench::bench_par_2 ... bench: 415,628 ns/iter (+/- 41,347) test test_bench::bench_par_n ... bench: 1,008,150 ns/iter (+/- 99,537) test test_bench::bench_primal ... bench: 6,691 ns/iter (+/- 17) test test_bench::bench_seq ... bench: 617,175 ns/iter (+/- 10,515) LIMIT = 1000000: test test_bench::bench_par_2 ... bench: 6,644,013 ns/iter (+/- 140,712) test test_bench::bench_par_n ... bench: 12,170,525 ns/iter (+/- 644,296) test test_bench::bench_primal ... bench: 124,897 ns/iter (+/- 12,527) test test_bench::bench_seq ... bench: 12,255,619 ns/iter (+/- 111,851) 
There does seem to be a convention to prefer verbs or nouns over adjectives with the "-able"/"-ible" suffix, since it would wind up *everywhere*. For example, serde uses `Serialize` rather than `Serializable`. I have seen this convention ignored in some places like Diesel, which favors using the suffix.
It's a tradeoff because when you have a possibly-unsized object, the compiler doesn't know how much space it takes up until runtime. So you can only use such an object through a kind of pointer (including reference, Box, Rc, etc). ``` 19 | fn foo&lt;T: ?Sized&gt;(t: T) {} | ^ `T` does not have a constant size known at compile-time ``` If the object is unsized the compiler will make it into a "fat" pointer which stores the size inline.
It might be possible to parallelize `primal`, but I think it's probably not worth it for sub-millisecond workloads. Maybe even bigger sieves could start splitting their work.
I believe this is how Haskell works, and in a sense, OCaml as well via modules. People have also mentioned adding this to Rust, by adding a `dyn` keyword to type parameters. (Perhaps it should instead be added to trait bounds?)
Often sieves don't bother encoding even numbers at all -- we know the only prime will be 2. Next you can encode only numbers that are {1,5} (mod 6) with 2 and 3 known, then `primal` even does wheels in (mod 30) and (mod 210).
Right now, I use the postgres driver with a macro I wrote that converts a result set into an iterator of structs. The downside is that I need to create a new struct for almost every query. What I'd like to do is compose the query, picking the exact columns/joins/etc I want, but letting diesel handle figuring out what tuple type the result should have. Kind of like sqlalchemy core or jOOQ. When I get home I'll try to remember to expand upon this more.
Yeah the stdlib's naming style forbids "-able". Can't remember the exact details but I think it basically boiled down to "it's noise" and "it makes the method-named ones look similar to the concept-named ones".
I wouldn't call C++/Rust's compilation model dumb. C++ allows: ``` template&lt;class T&gt; void func(T t) { do_foo(t); } template&lt;&gt; void func(int t) {do_bar(t); } ``` Or in other words, specialization. Rust's version is of course more principled. I don't see how swift's model can support specialization. This gives the programmer code that couldn't be hand-coded any better. This is a more complex model as it defers this decision to the user which IMO is a legit choice by a systems programming language which prefers to give the programmer full control. Swift chooses to trade some (minor?) loss of expressiveness for the benefit of reduced complexity which is again a legit call by a non systems language. The object safety rules of Rust basically require the user to perform the transformation themselves: ```fn foo&lt;T&gt;(T) -&gt; u32``` in a trait should be instead something like ```fn foo&lt;T&gt;(Box&lt;T&gt;) -&gt; u32```if the user wants the trait to be object-safe. The user gains a more fine-grained control but pays with complexity which is as I said an appropriate choice for the domain. Another point is that swift is not the first language that tries to bend the curve as you say. C# generics support both models: value types (structs) are monomorphized as in C++ and Rust while reference type are implemented with a polymorphic model much like Java. But again, C# doesn't have specialization. 
It's probable that `std::error::Error` will go away, replaced by `failure::Fail`, so doing the needful to achieve that
I also like to "specify my includes". What I don't like (and maybe I'm not understanding the current proposal) is that the existence of a file suddenly makes it a part of my project. I suppose a better way of saying that may be that I want my project to determine the layout of the files on my filesystem, not the filesystem determining the layout of my project.
 &gt;The programm shouldn't depend on any other than the standardlibs. Is this even possible with rust? The Rust `std` crate, generally speaking, doesn't include features unless they work but the same on all platforms. You'll need `libc` for access to Posix standard stuff like `select`. 
I once did a project in algorithms in which I believe we had to sort a large array. Something along those lines. We had a speed competition, and I was very proud of my results at around 10 minutes, until I saw other results in milliseconds. It turns out making a new thread for every recursion of quicksort is not a good idea. 
Yeah, I avoided bringing up wheel sieves because they're quite cool yet definitely a big increase in complexity.
The standard library has a method on UdpSocket as others have mentioned, but the standard solution for this is the https://github.com/carllerche/mio library. In rust, the standard library may provide a lot of common useful things, but it does not attempt to provide everything. Any libraries included in std will be stable for the remainder of rust's lifetime, so usually things are first worked on as external libraries with separate release cycles (and the ability to use an older version of the library on a newer rust). The mio crate is _the_ low-level rust solution for non-blocking IO.
&gt; Commonmark Thank you! Commonmark is so good!
You can absolutely get a tuple with Diesel. fn get_a_tuple(conn: &amp;PgConnection) -&gt; QueryResult&lt;Vec&lt;(i32, String)&gt;&gt; { users::table .select((users::id, users::name)) .load(conn) }
Haskell (GHC at least) performs type erasure, and so does OCaml. There is no other static compiler for a language that uses the same implementation strategy Swift that I am aware of, other than academic ML compilers from the 90s.
This is neat. Just last night I was thinking about the need for better wiki software. Just so you know I built and ran it on FreeBSD 11.1 and it seems to work fine. BTW I'm the author of the titlecase crate. Super excited to see it being used in another project.
There's no difference between Vec&lt;T&gt; and Box&lt;T&gt; in terms of levels of indirection.
Thanks for the hint but I don't aim to run this code in production. I'm just playing around with parallelism. That's also why I didn't optimize the algorithm itself since I wanted to compare, how it performs in single-threaded vs multi-threaded mode
Thanks for the heads up. I'll give Rayon a try
I distribute windows binaries built with the MSVC toolchain for `just`, and recently someone was unable to run it. I tried building a MinGW binary, and the same user was able to run it without issue. I'm thinking about starting to distribute MinGW binaries only, to avoid this issue in the future. Is there a downside to doing so? Differences in execution speed and binary size aren't important, I mostly just want to make sure that my users can run the binary without issue. Thanks!
I'm aware that my implementation of the algorithm is far from optimal, but my aim was to compare the same algorithm in single-threaded vs multi-threaded mode.
&gt; not the filesystem determining the layout of my project. This is already true of the module system though.
Yeah, it's just that the inefficiency here makes it hard to check whether the multithreading helps or hinders. Effectively you're not doing parallel sieve of erastothenes, as much as parallel trial-division right now.
While others have iterated on the "only use for smart pointers" rule, there are real-world examples of Deref being used on wrapper types that are not smart pointers but preserve invariants about the data, as your `Convex` struct does, e.g. nalgebra's `Unit` struct https://github.com/sebcrozet/nalgebra/blob/master/src/core/unit.rs#L207 You can use constructor functions to enforce that extant values of Convex have the invariant, but you should probably be generic over T instead of 'a and then any place you want a specific Convex value, e.g., make a specific conversion on the Convex-able type [as in this example I wrote for you](https://play.rust-lang.org/?gist=1b8f892372f180de6f76ebebfd906370&amp;version=stable)
Sure, I definitely support exploring this. A prime sieve is a pretty fun problem to play with. :)
Also thanks for your answer. I'm aware that the algorithm isn't optimal and that my work splitting only works (reasonably) well with an odd number of threads but it is still better than my first try where I assigned thread1 to `1..limit/2` and thread2 to `limit/2+1..limit` ;) Since both my parallel and sequential solution use the same inefficient algorithm, the parallel solution still should be faster. Once I got the parallelism working well enough (I think at least for the generic version, the merging of the different thread's results is pretty inefficient), I will try optimizing the algorithm itself. 
But the table/schema types have restrictions, one of which is that every table needs a primary key. But there are plenty of cases where you don't want that.
Since both the sequential and the parallel solution use the same inefficient algorithm, there shouldn't be any difference, I guess?
Can you give an example of a table you've had where there was no way to uniquely identify a row?
You can just pick a random column and tell Diesel that's your primary key if that's your only blocker.
There will be a difference due to the joining overhead, as you asked about in the post. Maybe you could use a tighter bit-vector representation that lets you combine them more efficiently. You may also run into cache problems -- having N independent vectors means that you have N-times more data that the CPU cache needs to keep close. The parallel version will suffer if it has to go out to main memory more often than the serial version does.
Any many to many relationship, really. Typical design is to have a "link table". You could create a composite primary key with both columns in the link table but that seems like a stretch.
In a many to many relationship the primary key is `(parent1_id, parent2_id)`
AFAIK, you can't configure where `rustup` and Cargo put things. The best workaround I'm aware of is to use `mklink` to create a symbolic link to a folder on another drive.
Well, passing opaque pointers like Swift does is also type erasure/uniform representation, no? Then Haskell's typeclass instance dictionaries and OCaml's modules are like Swift's witness tables.
A somewhat glib adage I've followed (and adapted through my career with various languages) is Don't use a Trait when a Struct will do. Don't use a Struct when a Function will do. In general : I strongly advocate a function-centric approach to abstraction. Note, this is just one person, with not a ton of knowledge of exactly what you're building. So apply salt :) Structs are for grouping data so that you can apply them to functions. Traits are for collecting groups of common functions together. Functions functions functions. Start with 1 file, and 1 function, and build more functions as needed. Only use structs when you need to group data together so that it is easier to pass to functions :). Try to avoid the object oriented mentality of structs having methods to mutate themselves, functions use structs, structs don't use functions. Struct Methods and `self` in rust are just syntactic sugar to make it easier to pass structs to functions. fn create_user(...) -&gt; Result&lt;User, Error&gt; { validate_user(); let con = get_connection(...); let user = insert_user(con, ...)?; log_user(user); Ok(user) } after you've built a few create_*() functions it should be clear that you're executing a validate_* call every time, and they look rather similar, now it's time to refactor and move up a level of abstraction. You've got a bunch of collections of data, and, likely you're leveraging some mechanism for Serializing and Deserializing them, I'd also recommend using some mechanism for applying the cross-cutting concern of validation across all of the structs that you're storing and retrieving. This would be in the form of applying schemas or validations declaratively. Something like https://github.com/Keats/validator | Anyway, I'm wondering if anyone had any tips on how to do things the 'Rust' way, in terms someone coming from an OO background can understand, or if there's any particular projects I should be looking at for inspiration. Again, just my opinion, but it might not hurt to learn something like Haskell or Elm to kind of "force" your brain into a functional programming and a function-centric mentality. 
I was also thinking about Rc and Arc where a type analogous to String would have extra indirection.
I disagree. It is the project structure that defines what the file layout needs to be via the `mod` statements, which the compiler then enforces. The proposed system switches that around so that the file layout causes the compiler to "insert" hidden `mod` statements into the project, which defines the project structure. Am I making sense? I'm not sure I'm making my argument very eloquently.
Ah, see, from my perspective, that `mod foo` makes you write `foo.rs` or `foo/mod.rs` is already Rust forcing a layout on you. I think your edit is probably the best way to phrase it. :)
[This](https://github.com/casey/just/issues/266) is the issue you're referencing, right? Googling the error the user gave (not just the DLL name) yielded [this SO Q&amp;A](https://stackoverflow.com/a/33274879/1299804) as the top result. It's typical to see issues regarding missing or broken Visual C++ Redistributables with Windows software; Microsoft fixed it in 10 by making the MSVCRT part of the system, but it may have been linking to a partially broken redistributable install on the user's machine. I couldn't say why MinGW binaries worked when MSVC ones don't, as [they both appear to depend on `msvcrt.dll`](https://imgur.com/awtlfvv), at least in Windows 10 Home (using `ldd` through MSYS2 was the easiest way I could find to list the DLL dependencies of a binary). If the dynamic linker was linking to a broken runtime install I would have expected it'd affect both, but it may come down to differences in how the two toolchains link binaries.
-&gt; /r/playrust
There are theorems asserting you can't prove *everything*, but when it comes to code people actually use I'd wager almost all of it either has a possible proof (in Coq or ATS) or is incorrect.
Ooh, that's exciting to hear :) I haven't written anything particularly platform specific, but with over 100 dependencies it is hard to keep track of everything :) Nice job with the titlecase crate. It is one of many crates that may not seem so big and important, that still saved me all the effort of figuring out the best way to do something and hitting all the edge cases. Instead, I was able to focus on building the wiki. Thanks!
That's super nice to hear after putting so much effort into it :)
[removed]
[removed]
That's a good idea. I'll make sure to have something like that for my next publicity push :)
You again! :P Thanks for your nice words :) Statically compiled templates do have some properties, yes. It fits with a lot of the stuff I want to do, but for many cases you definitely have to go to more dynamic engines. What I have found, which seems slightly counter intuitive, is that it can be useful to have two templating engines: one for static stuff and another for dynamic stuff. For example the result of the dynamic template rendering would go into the body part of a static layout template. In any case, there's definitely room for many templating engines :)
Yup, that's the issue. Thanks for digging into it! Hmmm, interesting. I wish there was more than one data point to off of, regarding whether to distribute MSVC or MinGW built binaries, given that there's no particular reason that the MinGW binary worked and the MSVC one didn't.
That definitely sounds interesting. I look forward to considering it more closely :)
I would give it a regular lifetime, unless you actually have some reason you need it to be 'static, and thread it through all the structures. 'static is notoriously difficult to reason about compared to other lifetimes. Also, the way you've written your implementation (with a public interface at all) isn't in general safe, since it relies on being called from the hook but doesn't enforce it.
A+! If only I had waited to convert new rustdoc over, `bail` and `ensure` took me some time and such to figure out, woulda been much easier :)
Weird issue, but I guess the workaround isn't too bad.
Well part of the issue is that `(*a &amp;&amp; *b)` for 2 arrays is actually a decent chunk of work to do compared to the trial division. Some other strategies: - You can combine the bool arrays pair-wise. This lets you keep more of the work distributed. - You can use `HashSet` or `BTreeSet` instead. It might seem space inefficient but the density of the primes decreases quickly. By only keeping track of the valid primes instead of tracking every number, the amount of combination work you'll need is much lower. You can then intersect the sets to find the true primes. In general though I don't think you can punt on the work-division problem, as it is at the core of whether or not the parallelism is even beneficial. Plus changing the algorithm will change the tradeoffs involved in introducing parallel workers.
I think you want /r/playrust
This should be solvable by statically linking to msvcrt (Microsoft Visual C Runtime). See this issue: https://github.com/rust-lang/rust/pull/37545 `cargo rustc -- -C target-feature="+crt-static"`
Thank you much!
Can I toggle a feature in a Cargo dependency depending on the profile? Ex: in the release profile I want to enable the `go-fast` feature in one of my dependencies.
Yep, me again! Sorry. Perhaps there is room for a single templating engine that addresses the static and the dynamic spaces? Though really that's mostly two templating engines that look similar. Just a thought.
I have a stupid question. Can calls to assert! and ensure! be compiled out on release builds? Is that something rust supports? 
No. A separate macro, `debug_assert!` exists &amp; is compiled out in release builds. There is not currently a `debug_ensure!`, but I'm not sure if that would be justified or not.
More discussion on this is available here: https://www.reddit.com/r/rust/comments/6z23oz/system76s_os_installer_backend_is_written_in_rust/
This was announced in a post on [releasing firmware updates to disable Intel ME](http://blog.system76.com/post/168050597573/system76-me-firmware-updates-plan) in response to the [recent vulnerabilities that have been revealed](https://www.wired.com/story/intel-management-engine-vulnerabilities-pcs-servers-iot/). It appears to be a UEFI application, and includes some support libraries for writing UEFI applications.
Ah, I had missed the previous discussion.
totally understandable, and I am still psyched about System76 using Rust so extensively.
I just downloaded the recent Rust update and now I'm getting this "NullReferenceException: "Object reference not set to an instance of object" error. Can anyone help me with this? I'm not super savvy with computers..
I was just moving from error chain and hit exactly every problem addressed here. Btw. What is the recommend way to unconditionally return an error now? 
If it does everything you need, I'd recommend ring: https://briansmith.org/rustdoc/ring/ If you need stuff beyond that, I'd probably just use rust-openssl.
When we say uniform representation, we mean that Foo&lt;T&gt; has the same memory layout for all T. This is the case in Java (all instances are always pointers), but not Swift or Rust (they're stored inline unless explicitly indirected)
&gt; I don't see how swift's model can support specialization. It's pretty simple to extend Swift's model to support specialization. You just make every call to a specializable method go through dynamic dispatch of some kind, and optimize the dynamic dispatch in cases where the types are known statically.
It depends on the type you're returning. If its your own type, just `return` it the normal way. if its `failure::Error`, you can use `bail!` if you want to create it from a string, otherwise you need to do `return Err((...).into())`. I'd like you to be able to just use `bail!`, but coherence etc.
&gt; conrod, but the ID system makes it extremely hard to do anything. I'd dare to say it's useless for UI development. I use conrod just about every day without any issues (although I am the creator of it). A couple of screenshots I have lying around include: - [An old synth editor from a few years back](https://imgur.com/a/htAuo) - [The GUI for my generative audio workstation](https://www.instagram.com/p/BbOTYyWjDiX/) - [A GUI for a spatial audio server](https://imgur.com/2PycCye) (currently under contract) Unfortunately I can't share the code for these as the first is too old for today's conrod and the last two are for commercial work. Documentation is definitely sparse on the topic and I apologise for this - I can't yet afford to take off a week from work to complete the guide. If you're having trouble managing widget IDs, feel free to open an issue about it.
You can always get that behavior with if cfg!(debug_assertions) { ... }
&gt; `return Err((...).into())` I usually just write `Err(...)?`.
The overhead is due to thread joining. If you change the `LIMIT` to something small, like 10, I get results like: test test_bench::bench_par_2 ... bench: 54,140 ns/iter (+/- 9,633) test test_bench::bench_par_n ... bench: 271,778 ns/iter (+/- 195,722) test test_bench::bench_seq ... bench: 43 ns/iter (+/- 13) where for `LIMIT` at 10,000 I get test test_bench::bench_par_2 ... bench: 72,121 ns/iter (+/- 14,331) test test_bench::bench_par_n ... bench: 408,628 ns/iter (+/- 113,363) test test_bench::bench_seq ... bench: 36,058 ns/iter (+/- 3,872) The effects are much more pronounced if you change the code to be a sieve, which (I believe) is just a matter of putting a `if !v[idx] {` test before diving in to your while loop. This cuts the CPU a bit and leaves mostly thread joining overhead behind. With `LIMIT` at 10,000: test test_bench::bench_par_2 ... bench: 55,535 ns/iter (+/- 17,022) test test_bench::bench_par_n ... bench: 378,712 ns/iter (+/- 116,282) test test_bench::bench_seq ... bench: 4,994 ns/iter (+/- 711) You can also break out the even and odd loops of `sieve_2` into their own benchmarks, which with `LIMIT` of 10,000 and the `if` test shows me test test_bench::bench_par_2a ... bench: 2,634 ns/iter (+/- 420) test test_bench::bench_par_2b ... bench: 2,484 ns/iter (+/- 551) suggesting that the sieve work is parallelizing great, and the thread startup, synchronization, and shutdown is probably what is biting you.
It should be as simple as setting %RUSTUP_HOME% and %CARGO_HOME% as permanent environment variables before running rustup-init and then ensuring that %CARGO_HOME%/bin is on your path after installation. See my [dotfiles](https://github.com/iliekturtles/dotfiles) for all the gory details. I do most of my work in the bash shell provided by git-for-windows. `config-setup.sh` uses `setx` to set user specific environment variables for %CARGO_HOME% and %RUSTUP_HOME%. You can also use the "Edit the system environment variables" or "Edit environment variables for your account" found in the Windows 10 start menu to set these variables and update your path if necessary.
Ok thanks 
Ha. That's what I've converted my `bail!`s into as well. Seemed shortest, but I felt like I'm cheating somewhat. :D
Can't go wrong with sodiumoxide. Though not everything you need is there.
(And rustboot! We started out this way too, but gave up.)
It does so, quite extensively.
I did that. It doesn't work. 
Aren't there cases where this will result in unification errors?
You actually want fn get_state&lt;'a&gt;(&amp;'a self) -&gt; &amp;'a StoreState Which is actually the same as: fn get_state(&amp;self) -&gt; &amp;StoreState
Rust needs a visual framework like Delphi's VCL (Visual Component Library). There are a free/open source version in Free Pascal.
I've started playing with this and it's awesome! Currently converting a medium sized project from `error_chain` to this. One hurdle I've hit is implementing a custom `Display` for an error value in my error enum; I have some more complex values in some of my errors and I want to dynamically structure an error output based on them. Would anyone be able to give me some advice? On mobile right now but can post an example later if the question isn't very clear.
&gt; Dead community Nice typo.
I personally prefer `&amp;x` *when possible*, but it's only possible for copyable types. Otherwise you'll get the "cannot move out of borrowed content" error. Same rule applies to `for` loops.
as u/eugene2k said, `Vec&lt;T&gt;` and `Box&lt;[T]&gt;` involve exactly one pointer. `Box&lt;[T]&gt;` is a pointer to a `[T]` on the heap; `Vec&lt;T&gt;` is a struct that contains a pointer to a `[T]` on the heap (It's not like java, where `ArrayList&lt;T&gt;` is a pointer to an `ArrayList` structure on the heap that itself contains the actual T[] - the `Vec&lt;T&gt;` struct is directly embedded into your type). If your intention is to avoid pointers entirely, then you have two main options: 1) Define your type like this: enum Convex { Small([Point; 32]), Large(Vec&lt;Point&gt;) } This lets you have a pointerless array, but can still grow to arbitrary size. This would require a decent amount of logic to get working, but it'll perform well, especially if you choose N such that `size_of([Point; N]) &lt; CacheLineBytes - 1`. The -1 is there because the enum will have either 0 byte overhead or 1 byte overhead, where that byte keeps track of which enum option is being used. 2) Use `unsafe` code to make a proper sized-at-runtime structure. That structure will have to be referenced whenever rust code uses it; rust does not allow dynamically-sized objects on the stack, IIRC. Instead of writing this yourself, find a crate that does this; (this)[https://crates.io/crates/generic-array] is what I found with a quick google search. A fair warning: this route will rely heavily on unsafe code at some point, either inside your own code or inside the crate's code.
The first is more beginner-friendly because it doesn't require a new concept. (The `&amp;` operator in assignment patterns, "inverse borrow", binds a copy of the target.) However I *do* think that `&amp;x` should be preferred when `x` is a copyable type. *Bind what you wish to use.* This rule has the side advantage that it makes iteration over mutable references look different from iteration over data.
yeah, when I migrated some crates of mine from error-chain to failure, I left the dependency on error-chain just so I wouldn't need to get rid of all my calls to bail!. Now I can get rid of that extra dependency! yay :)
I just can't wait until error-chain accepts the pull request so that all of their errors are Sync. https://github.com/rust-lang-nursery/error-chain/pull/241 Without this change, it's pretty difficult to use failure to represent an error caused by another error that uses error-chain.
Citing my sources: https://twitter.com/badboy_/status/936167183826202625
If the intent is to someday lift Failure into the stdlib, I don't quite enjoy the prospect of having two wholly separate macros just for errors that are basically `panic!`/`assert!`, but slightly different and named completely dissimilarly. :\
I don't know what I was expecting, but it wasn't Lisp :-D
maybe add panic_err! as an alias to bail!, and assert_err! to ensure!, or something similar?
&gt; edit: nm, it looks like failure's version of bail! isn't quite the same :( Is it that you can't use `bail!` to return non-string errors, or something else?
If we lift anything from failure into std that doesn't mean every API in the crate will be lifted.
I want to support more complex displays in the attribute but the compiler won't parse them yet.
Might get messy if the attribute gets too complex too, I think just implementing `fmt::Display` manually is fine for the more complex cases. Thanks for your work by the way!
How long until the Rust compiler gets compiled down all the way to WASM making compilation and execution happen entirely clientside? :D
it looks like I was using it in two incompatible ways: 1. I'm using it with non-string errors 2. It seems that failure's bail! only returns failure::Error? I'm using the old bail! to return my specific error type.
Curious if /u/steveklabnik1 had anything to do with this ü§î
There is `smallvec` crate forwhat you describe in 1.
"All problems in computer science can be solved by another level of indirection" -- David Wheeler Sure, that would work in, what feels to me, a very roundabout sort of way if the compiler can guaranty devirtualization (isn't this usually a best effort optimization?). This still doesn't solve the other issue with Swift's approach - Rust allows the user to control the boxing process and fine-tune it whereas in swift land this is an opaque compiler implementation (the witness tables). in other words, Rust requires the user to make their traits object safe and the user can fine-tune this by choosing what kind of smart pointer to use. I can choose between ```fn foo&lt;T&gt;(Box&lt;SomeTrait&gt;) -&gt; u32``` and ```fn foo&lt;T&gt;(RC&lt;SomeTrait&gt;) -&gt; u32``` for my trait method, for instance.
I'm either very unfamiliar with what wasm is supposed to look like or something is wrong over there. I just hit the "WASM" button on the other side of that link (so, compiling main and a function to add 1 to a number) and it generated an incomprehensible amount of code. I scrolled on my phone for many seconds and then got tired of it and came to make this comment. Is wasm really that noisy?
It's not that wasm is that noisy, but that rustc doesn't generate very good output on its own yet because it doesn't have a wasm linker to remove the unused stuff. This is currently solved by `wasm-gc` but that's not run on the playground.
Thanks! Now onto my walk of shame for not having tried something simpler as my first try.
Thanks! I was considering Ring, but it appears to be a bit too high level on ECDH. Will definitely give it a try, but I'm not sure if it's enough. OpenSSL is great too, thanks for the suggestion, but last time I checked it didn't support curve25519.
Would it be possible to run `wasm-gc` on the playground?
Thanks, looks like a great starting point
Quite some time. This might be easier using the Emscripten target for now, as it includes shins for file operations and such. LLVM is still a beast and will need much more to make it work. Obviously it‚Äôs one of the goals. Eventually the playground will run in your browser with all tools bundled. Take that for an IDE in the web environment!!!
It's something interesting to explore, but it's not what I'm working on right at the moment.
I wonder what disassembler they're using. Apparently not Firefox's because Firefox does it more Forth-y than Lisp-y
Not a knock against the compiler, it's more that I don't trust that documentation as written. It doesn't say what smart pointers are, nor does it explain **why** Deref should only be implemented for them. Plus, the phrase "smart pointer" bothers me for some reason, and I prefer "custom pointer types"... I guess it's because "smart" just means *safe* (it's an import from C++?), and that's nothing special in Rust. Or it could just be that I'm grumpy because I'm up way past my bedtime.
Generally, MinGW binaries Just Work (at least on 64-bit Windows). Although the static link is safest, and not too bloated either.
This is the standard text representation of binary wasm data. It's called Webassembly Text, or wat for short. I'm not joking.
Why does it use an if statement? Doesn't that result in an unnecessary extra instruction? Or does the compiler optimize that out?
As they say in Liverpool, you'll never walk alone
It will compile to `if false` or `if true`.
For ECC take a look at `ed25519-dalek` and crates based on it, for HMAC you can take `hmac` and `sha2` crate. (although it's a bit slower compared to ring's HMAC-SHA256) For AES in case if your soft will work on computers with AES-NI instruction set you can use `aesni` crate, which in addition to block ciphers also provides effective implementation of counter mode.