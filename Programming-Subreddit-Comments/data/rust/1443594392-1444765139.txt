Some open issues: - Where to send output? appropriate to stderr? maybe a file? - How to display in nice tools such as kcachegrind/flamegraph.pl - Ideas for a lighter weight API? - Are there tricks to tell LLVM to not move anything across the block boundaries? 
How many unsafe code you used? Do you think a RUST based OS would have security and maybe speed advantages?
On the flip-side, the problem with a long-running process is that you have to work hard to stop the 'big-ball-o-mud' problem setting in. Separate artifacts and short running processes promote natural layering and loose coupling. 
Its an interesting claim. Got evidence for it? In any case here we are discussing only incremental compilation, not extended code analysis, which would be an invitation for scope creep. But an expanding scope can still be layered. There is plenty of evidence that keeping everything in process does allow more functionality per line of code (see the VPRI STEPS project and related work), which certainly helps deal with the complexity.
http://is.gd/xZ6NjL
No they are not. The end result that the CPU sees is a pure binary without any bytecode or translation help in form of interpreter or JIT. A runtime is not the same thing as a VM. Or now you are going to argue, that iOS with Bitcode or OS/400 with TIMI are also managed OSes?
&gt;* The standard library relies too much on libc, when a significant piece of it could directly call the kernel. You could have a libstd_system that calls the int 0x80 interface for things like read/write/open/close/seek/exec etc... While appealing, it's a massive maintenance burden to ensure that everything works on all the platforms. As well as extra work to ensure that the implementations are themselves correct. System calls on Linux are different for each platform, and potentially different for different kernels. You mention using `int 0x80`, but on x86-64 system calls use the `syscall` instruction. Now multiply that out to three OSes (and Windows doesn't have a defined syscall interface that I know of, you *have* to call the functions) and at least two architectures. Just for the main platforms we support! We have support for BSD and Android too to deal with. As appealing as having a libc-free stdlib is, it's just not worth the effort.
Currently rust processes can communicate to other rust processes only by C calling conventions. Once this changes to a Rust calling convention where safety guarantees can exist, I think we could have something very interesting here.
Thanks, good finding! It seems to be related to the `Factory` rather than the `Interface`. Maybe this code: impl&lt;M&gt; Factory&lt;M&gt; { pub fn property( /* ... */ ) -&gt; Property&lt;M&gt; { /* ... */ } } ...will tie the lifetime of the `Property` to the lifetime of the `Factory` in a way I didn't intend. I wonder if there's any way around it except repeating the functionality for every factory like this: impl&lt;'a&gt; Factory&lt;MethodFn&lt;'a&gt;&gt; { pub fn property&lt;'b&gt;( /* ... */ ) -&gt; Property&lt;&lt;MethodFn&lt;'b&gt;&gt; { /* ... */ } } 
&gt; You can have well-layered, loosely coupled big single process software, but it doesn't happen by accident. I don't think simplicity happens by accident anywhere. If the layering constructs are highly visible to those working on the code, it will exist and be preserved. If not, then not. For one person the distinct programs are clear lines, for another maybe the division of labor is not obvious, so adding a little information to the protocols should be just fine, right? Same applies to the modules or crates or functions or traits or whatever you use to structure in process. The only advantage I see processes "have" over in process boundary types is "share nothing by default", but as soon as you communicate through the filesystem, that's out the window, taking the data-race-freedom etc of rust with it. &gt; You said 'It is also ridiculously useful for implementing stuff like racer on top of' Right. But: - First of all that is optional, and you pay in complexity as you go. Using a long term process does not force you to serve racer from it. That you need to pay extra in design work to do so makes sense. - I didn't say those should be in the same process. Structurally, it is more important for the canonical representation of code to be highly available (since everything starts with it) than for derived properties (where some might be cheap to recompute on call by the dev-env). 
Great, thanks, I'm going to follow that PR!
What's missing?
Will you use [uutils](https://github.com/uutils/coreutils)?
Do you think that both Rust and C++ would get you to make the same effort? And, what features do you miss from Rust that are in C++ and vice-versa?
Pretty sure I will, I had looked at it before. I just need libstd working, which should not take very long.
Safety will be the key. Programs will be sandboxed, and will have to ask for higher level permissions. Permissions can be given to a program permanently, but can be revoked at a later time. This is kind of similar to the mobile app model, but I want to have better support for IPC. I do think there will be a niche to fill, but I do have to support lots of common programs, many written in C, before getting to it.
I was planning to do something similar with MMIO and PIO to avoid these problems: struct PIO8 { port: u16 } impl PIO8 { pub fn new(port: u16) -&gt; PIO8; pub fn get(&amp;self) -&gt; u8; pub fn set(&amp;mut self, value: u8); } PIO8, PIO16, and PIO32 could handle inb, inw, ind. A lot of my driver bugs have come from using the wrong size! MMIO could be handled similarly. The PCI driver could give drivers a limited set of PIO and MMIO structs to operate on, enforced by the TSS. 
libstd would interface directly with a rust kernel, with no C middleman :)
Thanks. To get the Viewer and Player to do something, you can open up a file in the home directory (press enter after clicking on home to open the directory) I'm sure it will get much more impressive when I have some more time to work on the UI!
I have written large software projects in C++, Rust, Java, PHP, Javascript, Assembler, and C. The honest answer is that I miss *nothing* from C++. The most major thing I would miss, if I were an application developer, would be the massive collection of C++ projects to build upon. I don't think there is another language that would have boosted my kernel development as much as Rust has, and a lot of the powerful features of C++ (virtual function tables, for example) are not useable in kernel land, but are useable in Rust in kernel land using Trait objects. It would be nice to have something like dynamic_cast, instead of using Box&lt;Any&gt;, but I don't actually use Box&lt;Any&gt; anywhere.
As for the shell, I want any shells that can compile. I would probably default to a shell that is written entirely in safe Rust.
I would ‚ô• to help You with that. I really want to create something similar to Fish shell written entirely in safe Rust with small and readable codebase.
Yes. All TLS functions sould be added in the future. Currently I focus on most used ciphers and hashes. But for sure it will be implemented (in future).
How far in the microkernel direction do you see yourself going? seL4 seems to be an extreme, where the kernel is so small they manage to prove it correct despite implementing it in C. I would guess the proof burden would be much smaller in Rust, but I'm not sure that's your project :)
&gt; If used incorrectly, for example, wrapping the whole damn thing in unsafe{}, then Rust basically becomes C with classes. One important bit of `unsafe` is that it doesn't turn off the rules, just adds extra capabilities. So while I would never advocate wrapping your whole program in unsafe, it'd still be safer, as a lot of things still get checked.
Paging may have some overhead, but it's unavoidable- paging cannot be disabled in 64-bit mode on x86. Even if you limit yourself to 32-bit mode, paging is used for much more than safety. SPIN, and more recent projects like Microsoft Research's Singularity, are still interesting though, if you're willing to limit the OS to a single language (or maybe a single IR like .NET). They enable more optimizations between applications and the kernel, especially if you compile on the user's machine.
I've done a quick review of the RSA module. There are some nitpicks: https://gist.github.com/Ticki/252f2d1a00788303ed93. Crypto in rust is awesome!
Pretty far, but not yet! The driver interface now is that they can export "schemes" A scheme is something like audio://, network://, or file:// and it identifies an interface that a driver provides. There is no reason that drivers would have to be in kernelspace. In fact, I was thinking about wrapping up PIO and MMIO in safe syscalls so that a driver could only access what the PCI configuration space said a device contains. Still, device drivers can cause significant problems if things are done incorrectly. Therefore, I would maintain device drivers with the kernel, even if they are not running in ring 0. For now, I think it will remain a monolithic kernel, as it has made development of drivers easier. The focus is on safety, an easy programming API for applications, and a good user experience. Some of these make the move to a microkernel less attractive.
That sound cool, but it's a lot of maintanance. What about syntax?
I disagree, I am in the process of porting the libc crate over to Redox. It will not rely on a C library anymore, and it will also run with partial binary compatiblity on Linux. It may not be C-free for all systems, but it will be for Redox.
To be honest, whole `Digest::hex_result` was marked to be deleted as it introduce undesired allocations. I want to make it user responsibility to change slice into string if one want to. I want to make whole library as much `alloc`-free as possible. So thanks for PR, but I probably remove whole function as irrelevant for library.
https://play.rust-lang.org/?gist=d6293ff6cd9759249b19&amp;version=stable I wrote a short max macro for you (:
I used term `crypt` as it should be internal use only and public ones should be `encrypt` and `decrypt`. But as in case of RSA both are the same (the only difference is set of keys) the "helper" function was named `crypt`. It will change. `encrypt` and `decrypt` function also should take `&amp;[u8]` as param instead of `&amp;BigUint` as it should operate on bytes, not numbers. Of course `RandBigInt` isn't cryptographically secure but it isn't used as one. It is used only as a base for [`generate_prime`](https://github.com/hauleth/octavo/blob/master/src/utils/primes/mod.rs#L18) which test against non primes (currently 20 rounds of Fermat's test and 20 rounds of Miller-Rabin's one, need to be adjusted and checked if it is secure enough).
I think I should make it nearly usable in month or two, but I'm making also Octavo (cryptographic lib) so it could take longer. I'll try my best (codename `rash`).
:+1:
Ok that's a good resolution.
I'm developing a closed source indie game in my free time. Don't expect anything revolutionary though. 
Can you elaborate on why C++ virtual dispatch isn't suitable for a kernel, but Rust's virtual dispatch is? To my mind they're the same basic concept, except that Rust puts the vtable alongside the pointer instead of inline with the struct.
I think this is solved by itertools cartesian_product http://bluss.github.io/rust-itertools/doc/itertools/trait.Itertools.html#method.cartesian_product
Here's my attempt. I kept mutable state, but it uses iterators at least. I still like your solution more though. Yours makes it really obvious what is happening. https://play.rust-lang.org/?gist=86eba56e3678411b8c0e&amp;version=stable
Sure thing!
The private key is a tuple (n, d). To get to this you need to know phi(n), where n=pq. If the primes are weakly generated, it's easier for me to get (n, d).
But this happen only if generator is weak. `RandBigInt` is only trait that is implemented for each `T: Rng`. I haven't written enough doc yet but I will mark there to use cryptographically safe PRNG like `OsRng` (as it is described in [`rand` crate](http://doc.rust-lang.org/rand/rand/index.html#cryptographic-security)). In tests I use seeded `StdRng` as tests should be predictable.
You could try TravisCI
I suck at art, but just a random first thought, redox -&gt; red ox (which fits with gnu's hurd icon I guess) https://www.google.com/search?q=red+ox&amp;source=lnms&amp;tbm=isch&amp;sa=X&amp;ved=0CAoQ_AUoBGoVChMIiqGsw52fyAIVAQeSCh2szQHz&amp;biw=1600&amp;bih=759#tbm=isch&amp;q=red+oxen Of course I imagine you are wanting to go more with chemistry.
Even better: http://is.gd/hSUGAd
In addition to using iterators you can use the newtype pattern and impl `Index` for it either for `(usize, usize)` and return the value or `usize`and return `&amp;[u8]` which would allow you to use `[x][y]` style indices. For example, http://is.gd/kYJvie
Full documentation with *lots* of other modes besides `?` and goodies like `#`: http://doc.rust-lang.org/std/fmt/index.html
That's interesting. It gives it a look like BSD as well
Indeed. I've been too busy lately to specifically write new stuff, but I always find this kind of thing super valuable! edit: and, thanks!
My favorite / least favorite thing is when I search for something and find my own blog post about it, explaining what I need to do...
I've been there. I never really know what to make of situations like that, lol.
There were issues with compatibility (and I wasn't around then), but your previous post makes it sound like the GC just plain didn't work :) Swift makes a distinction between types that interoperate with Objective-C and those that don't. If Lattner thought full GC had a significant enough advantage, Swift certainly could have implemented a hybrid model... 
&gt; Don't expect anything revolutionary though. I bet you said something similar about glium ‚Äì the opposite is true. Btw. thanks for that :)
&gt; No way to store a borrower and a borrowed in the same struct. Also my whislist! But I have no idea how to give a type to the lifetimes (eg: of `(a, &amp;a)`) &gt; A joystick/raw-input library [Issues](http://joostdevblog.blogspot.com.br/2012/08/the-craziness-that-is-joysticks-on-pc.html) a good library should tackle. Since joysticks on PC are crazy, it's increasingly common that a game only supports Xbox 360 controllers :(
My issue about using this is: how do you protect against timing attacks? See [this](http://ironframework.io/doc/crypto/aessafe/index.html). What about using something like [nadeko](https://github.com/klutzy/nadeko/)? Is it easy to (manually?) verify that the compiled code does not have timing dependent on secret data? Is it possible to specify on Cargo.toml that the library should not be built with optimizations (even if it's being built as a dependency of a program that enabled optimizations)?
&gt; "Gary".to_string() "Gary".to_owned() Even better ;)
Thanks!
Out of curiosity, what was the reason for having a separate project for the CLI?
I don't think Rust programs will be able to talk to each other since there's no defined Rust calling convention.
&gt; For me RC is not GC I would say the line is crossed and you're on the GC side as soon as there is a cycle collector and tracing gets involved.
Yes. There is library of mine named [`ct`](https://github.com/liboctavo/ct) that main target is to provide time-constant operations. Of course it still will be tricky, but I hope I will find some way to make needed functions time constant. Currently there is no time safety in Octavo (RSA and MAC are time attack vulnerable).
&gt; I'm working on ct Neat! I wish LLVM somehow had support for making the timing of some function not depend on the parameters. edit: I posted [this](https://www.reddit.com/r/rust/comments/3696wt/checking_that_functions_are_constant_time_with/) here some time ago. Perhaps a custom "test" could be able to use valgrind to test if a function was compiled to constant-time code? (on top of any Rust-side solution like ct or nadeko)
In my opinion this is the cleanest iterator based solution. Very readable, I like it a lot! Thanks a lot!!
I think this is the best solution. Using iterators like in /u/Noctune 's answer for example is quite readable, but this is amazing! Please correct me if I'm wrong, but I think this is the most readable version. Thank you very much!
&gt; In tests I use seeded StdRng as tests should be predictable. How do you plan to test nondeterministic/probabilistic encryption?
Indeed you're right. Good catch, thank you! That's why for loops + manual offset calculations should be avoided I guess, it's too easy to get wrong. But I'm afraid I find the for loops still more readable than the chained iterators. They are much more code!
Yeah, that's why I split the computation into for loops, to keep the iterator chaining somewhat sane. Here's a version using windows, which might be better (inspired by another comment): https://play.rust-lang.org/?gist=9c4766442de7e8b8e246&amp;version=nightly
To be fair, nalgebra (the other contender) isn't that much better. A lot of it is a pain in the ass: * Applying rotation is ass backwards * OpStore doesn't work for things it should work for (some_vec *= some_other_vec) * Which brings us to, every operation shits out a new object! Handy a lot of the time, but I want to be able to freaking modify an existing one and not have to do a = a * b or some shit! That's all I can think of off the top of my head, there's also stuff with glium that's annoying like UniformStorage; good luck taking it as an arg and returning a new one, the type signature changed cause you called add(). Single linked list built through the type system. That's really nice when I'm trying to compile uniforms at runtime.
In lieu of a blog post, putting information of this magnitude on StackOverflow is also a great service for people learning the language. :)
For now it isn't a case. And when it became case I will use proper PRNG with `quickcheck` crate to achieve complete cover in tests. For now I needed fast results when running Miller-Rabin and Fermat's tests.
I'm rather skeptical about the whole idea of this "Algorithmia" service. It feels incredibly anti-open source, not to mention the privacy issues inherent in sending data to an opaque cloud for computation. Care to try to sell me on it?
One thing to note: every time you use `raw[]`, you're paying the overhead of a bounds check, if LLVM can't decide its's safe to remove. Whereas iterators don't have that overhead. So usually, the iterator version, all else being equal, will be faster.
You'd ideally want to do it in a divide and conquer way, to get instruction level parallelism (doing it in a chain means each max is dependent on the previous max). So e.g. for 4 parameters you'd do two max operations in parallel (hopefully, let the CPU figure it out), then a single dependent max at the end. 
The process of taking two iterators and pairing each element of the first with every element of the second in turn is called the cartesian product. More specifically, `for (x,y) in (0..8).cartesian_product(0..8) { ... }` gives the same sequence of `x`,`y` values; it doesn't removing the indexing, but does mean that there's only one `for` loop.
Awesome!
Noob here, what does "safe" and "unsafe" code refer to?
Of course if You want to implement them feel free to make PR.
Really? Interesting... Edit: I gave it look on godbold and it's so fragmented that I'm unable to interpret anything from it. My assembly knowledge is far too limited and there were too many colors. The compiler is usually very good at optimizing iterators, so I just assumed that it would be able to handle this one as well, but I may be completely wrong. I can imagine that `chunks` or `windows` may give it a hard time, depending on how they are implemented. Possibly the `filter_map` + `fold` as well. The only way to know for certain is to measure it, as you said.
Different choices were made by the compiler regarding pushes and pops in the context switch function. **Here is the current implementation:** #[cold] #[inline(never)] pub unsafe fn switch(&amp;mut self, other: &amp;mut Context){ asm!("pushfd pushad mov [esi], esp" : : "{esi}"(&amp;mut self.stack_ptr) : "memory" : "intel", "volatile"); asm!("fxsave [esi]" : : "{esi}"(self.fx) : "memory" : "intel", "volatile"); self.fx_enabled = true; //TODO: Clear registers if other.fx_enabled { asm!("fxrstor [esi]" : : "{esi}"(other.fx) : "memory" : "intel", "volatile"); } asm!("mov esp, [esi] popad popfd" : : "{esi}"(&amp;mut other.stack_ptr) : "memory" : "intel", "volatile"); } **And what it disassembles to:** push esi lea esi,[ecx+0x4] pushf pusha mov DWORD PTR [esi],esp mov esi,DWORD PTR [ecx+0x8] fxsave [esi] mov BYTE PTR [ecx+0xc],0x1 cmp BYTE PTR [edx+0xc],0x0 je eade &lt;common::context::Context::switch::h3be38e0b4818cb28u9a+0x1e&gt; mov esi,DWORD PTR [edx+0x8] fxrstor [esi] add edx,0x4 mov esi,edx mov esp,DWORD PTR [esi] popa popf pop esi ret The extra push esi/pop esi has to be handled when contexts are spawned, so that they ret into the call address. This is the only place in the code that requires inspection of the output from the compiler, it is also a little bit black magic
Damn, that's pretty cool üòé 
or "Gary".into()
Of course I've checked that some time ago when I was starting my work on Octavo, and yes I want to add Valgrind tests for constant-time functions to test chain.
This is exactly the kind of bugs that debug assertions help me find in my code.. happens all the time.. :)
indeed, reduction/oxidisation iirc. Which does fit the idea of "rust", but I found red ox seems to fit with the more animalish mascots open source os-es have
&gt;Fire Ox powered by mozilla's technology. Nothing can go wrong!
Take a look [in the book](http://doc.rust-lang.org/book/unsafe.html).
The language could use a marker that says "this type is POD and maintains no invariants, any properly-sized bag of bits is valid". Then you could do a T -&gt; U or [T] -&gt; [U] transmute safely.
Thank you, I don't know how looking at the official docs spilled my mind.
Not sure if this is what you're looking for but this is what gdb gives me: (gdb) run Starting program: /private/tmp/dlopen_rust/main warning: `/BinaryCache/coreTLS/coreTLS-35.40.1~1/Objects/coretls.build/coretls.build/Objects-normal/x86_64/system_coretls_vers.o': can't open to read symbols: No such file or directory. warning: Could not open OSO archive file "/BinaryCache/coreTLS/coreTLS-35.40.1~1/Symbols/BuiltProducts/libcoretls_ciphersuites.a" warning: Could not open OSO archive file "/BinaryCache/coreTLS/coreTLS-35.40.1~1/Symbols/BuiltProducts/libcoretls_handshake.a" warning: Could not open OSO archive file "/BinaryCache/coreTLS/coreTLS-35.40.1~1/Symbols/BuiltProducts/libcoretls_record.a" warning: Could not open OSO archive file "/BinaryCache/coreTLS/coreTLS-35.40.1~1/Symbols/BuiltProducts/libcoretls_stream_parser.a" test_fn: 123456 Closing... Program received signal SIGSEGV, Segmentation fault. 0x00007fff83d79059 in free () from /usr/lib/system/libsystem_malloc.dylib (gdb) bt #0 0x00007fff83d79059 in free () from /usr/lib/system/libsystem_malloc.dylib #1 0x00007fff5fc0dcf5 in ?? () #2 0x0000000000000000 in ?? () 
Why is the Rust version faster? I really don't want to watch a 2 hr video.
I thinks it's just another instance of a known problem that you can't put a reference and a referred object in the same struct. There's a library solution for that, [owning_ref](https://crates.io/crates/owning_ref), but it only works for `&amp;'a T`, not for arbitrary `T&lt;'a&gt;`, which you want. Meanwile (if you want to keep both guards in the same struct), you can transmute everything to `'static` and back, and hope you don't invoke undefined behaviour. Another solution (with a little bit of additional cost) would be to put a person behind an `Arc`, but that may not be what you want: struct PersonManager { people: RwLock&lt;Vec&lt;Arc&lt;RwLock&lt;Person&gt;&gt;&gt;&gt;, } impl PersonManager { fn read_person(&amp;self, index: usize) -&gt; Option&lt;Arc&lt;RwLock&lt;Person&gt;&gt;&gt; self.people[index].clone() } // unfortunately, it still needs calling .read() }
&gt; Fixed-size arrays are missing traits This is one solved by having integral type parameters (similar to C++'s `template&lt;int N&gt;`). I know that a lot of care has to go into the design, but integral type parameters is probably the number one item on my Rust wish-list. It would be so handy for generic programming (and metaprogramming üòà)! It would also clean up a lot of the cruft in the Rust documentation, where traits are implemented for a zillion different `[T; N]`s.
Working on a(nother) proof that `macro_rules!` is Turing-complete.
I skimmed through the video and did not find it.
Wouldn't that freeze a struct in place, though?
Hm... yeah it would. What I wanted is something like this: let x = vec![1]; let mut y = Struct { a: &amp;x, b : 1 }; let mut c = (x, y); If this is were allowed, I perhaps could mutate `c.1.b`?
I was thinking about `Copy`, but it doesn't carry the "number of bytes" in the type (like a `Copy&lt;N&gt;` ) and it doesn't guarantee that all bit values are valid. Other than that, I think this doesn't need to be in the language: you could use type-level unary numbers to have an usafe trait with a conversion method. (you need to somehow manipulate the sizes of `T` and `U` at the type level order to allow this conversion in safe code)
I was trying to remember your username to mention you in another thread. I kept trying to use /u/alexcrichton instead.
As a rule of thumb, any crate that needs `#![feature()]` annotations has to be compiled on nightly because that's the only branch that allows use of feature-gated APIs. Unfortunately I'm a bit too tired to critique your crate in-depth. It looks all right at a cursory glance. I do see your use of `transmute` and I'm wondering why you couldn't store an `*mut TrieNode&lt;T&gt;` instead.
would it be possible to hi-jack the compositing UI in servo, then manipulate the DOM via rust.. that we can completely diverge away from the slow javascript while using the most widely used HTML to present the UI.
Currently I want check if `ct` is really safe in terms of avoiding optimizations. Maybe I will need to write some assembly to achieve that (external assembly file will allow me to make it work in stable).
Another version which uses ```.chunks()``` to do the splitting instead of raw arithmetic and gets rid of one for loop with itertools' ```.cartesian_product()```: let raw: Vec&lt;&amp;[u8]&gt; = raw .chunks(9) .collect(); for (x,y) in (0..8).cartesian_product(0..8) { if raw[x][y] &gt; raw[x][y+1] { hash[x] |= 0x1 &lt;&lt; y } }
From the LtU post: &gt; It's application to C probably won't get much uptake at this point, but I can see this as a useful compiler plugin to verify unsafe Rust code. Just thought I'd post this here.
I'm not the author of this but I saw this in [a comment of a PR](https://github.com/rust-lang/crates.io/pull/104#issuecomment-141782931) that tried to address this [issue](https://github.com/rust-lang/crates.io/issues/99) which continues to be already implemented but very still not exposed. It's useful for me since I *really* like to see how and what other published crates use the crate I'm looking at. [The author appears to have made it for gauging the "trustworthiness" of crates](http://amutake.hatenablog.com/entry/2015/09/20/222222). It looks like the issue and PR was held up by some UI discussions so maybe some popularity, existence, and use of this extension might get it out of the rut. I haven't had a chance to extensively look at this extension yet and it does seem a bit buggy with how it interacts with the Ember UI but it's still a neat demonstration and works most of the time and definitely after a refresh.
At a high level overview I think it would be nice if you were able to remove the `Clone + Default` bounds for the values. I think something like [VecMap](https://crates.io/crates/vec_map) could be useful for that (though it might not be the most efficient solution). Since you already have a valid bitmap it might be better to create a custom drop implementation which makes sure that only valid elements are dropped. Having a few more methods on the Trie type would be useful as well. `get_mut`, `Index/IndexMut` and `len` comes to mind. Otherwise it looks rather nice though as I haven't implemented a trie like this I can't see any actual implementation issues :).
Thanks dbaupp!
Obligatory reference to *[Are We Web Yet?](http://arewewebyet.com)* I don't know that webdev is ever going to be a core Rust domain, but what I love about this sort of stuff is that it demonstrates how flexible a lot of the core language design is. The forced error checks, memory safety, even simple things like everything being an expression - these are all things that people want to use regardless of problem domain.
I'll have to look into the `Clone + Default`, it's possible that those bounds are a holdover from earlier revisions and may not be necessary any more, or they could be refactored out. I need to study the std library collections' code to get a better handle on how they do things. I do intend to implement those further methods; thanks for the `Index/IndexMut` mention, I'd wondered how that was done.
Agreed wrt: there are countless useful crates out there, and countless examples of: - no 'hello world' example (that actually compiles) of how to use the crate. There are lots of examples of folks doing a terrific job too. 
Why this keeps getting referenced when it is very outdated!
~~The double locking is useless because there is no way to hold onto a reference to a person without holding the outer lock so you could just drop the internal locks. Alternatively, as /u/krdin said, you could put the people into Arcs (`RwLock&lt;Vec&lt;Arc&lt;RwLock&lt;Person&gt;&gt;&gt;&gt;`) in which case you don't need a `PersonReadGuard` (you can freely return `Arc&lt;RwLock&lt;Person&gt;&gt;`).~~ TODO: learn to read.
The following will also allow you to wrap references: pub struct Volatile&lt;T: Copy&gt;(T); impl&lt;T: Copy&gt; Volatile&lt;T&gt; { pub fn reference&lt;'a&gt;(ptr: &amp;'a T) -&gt; &amp;'a Volatile&lt;T&gt; { unsafe { mem::transmute(ptr) } } pub fn mut_reference&lt;'a&gt;(ptr: &amp;'a mut T) -&gt; &amp;'a mut Volatile&lt;T&gt; { unsafe { mem::transmute(ptr) } } pub fn value(value: T) -&gt; Volatile&lt;T&gt; { Volatile(value) } pub fn get(&amp;self) -&gt; T { unsafe { intrinsics::volatile_load(&amp;self.0) } } pub fn set(&amp;mut self, x: T) { unsafe { intrinsics::volatile_store(&amp;mut self.0, x) } } } 
There's no obligation on your part, but it's low-effort to update it: https://github.com/teepee/arewewebyet
I don't see any comments in the issues about that. The only blockers mentioned in the PR and issue appear to be GUI.
There's a PR adding email that's ten months old. It hasn't been committed to in general since May.
You can have multiple concurrent read locks on the vector, and each can grab write locks on people as long as they don't overlap. A write lock on the vector itself is only needed in order to change the vector itself, such as to insert or remove people.
I was thinking about owning ref, and I don't see a reason why it couldn't work for arbitrary `T&lt;'a&gt;`. The key guarantees you need are that (1) you cannot get mutable access through the owner without destroying the reference, and (2) that you can't concurrently have both mutable access through the reference and immutable access through the owner. (1) is already handled by owning ref, but it has a much stronger restriction than (2). Since it only lets you use shared references rather than letting you specify your own reference types, it ensures that you never get mutable access through the reference. Again, I think (1) and (2) are sufficient. Also, since you can't copy an owning reference, you don't need the guaranteed copyability of shared references either.
I find my old stack overflow answers at times, and am really happy that I ended up writing it up nicely.
Name is already taken https://crates.io/crates/rush. It is placeholder, so I will rethink using that name. For now I will use Rash.
Actually that was the motivation! That one is a Brainfuck transpiler since it translates to Rust and does the computation at runtime. The proof would be to run the Brainfuck code at compile time, [like this](https://gist.github.com/durka/d666d26131c4bc1a18d1).
I wish they had elaborated on this a bit, because it seems like it would have to have far-reaching effects to validate all the invariants that an unsafe block must uphold, and surely some of those checks designed for C would be redundant with the aliasing rules that Rust already enforces.
Piston is a modular game engine down to its core, unlike the design of most game engines. This is done on purpose because Rust is a new language, and we want to try different things before settling on a direction. The overall architecture of Piston allows us to write lots of code without getting caught up in most breaking changes. In the long term we plan to build more sophisticated tooling, but first we need to mature the ecosystem a bit. The design pattern Piston uses is called [backend agnostic design](https://github.com/PistonDevelopers/piston/wiki/Backend-agnostic-design). The key idea is that most code is generic libraries that depends on a tiny abstraction, as opposed to depending on an abstraction over a platform API. What you get is extremely portable code, but what you pay is an extra library that integrates the platform API with the abstraction. This is called the "backend". Which graphics backend to choose depends on what control you are looking for. If you want to write raw OpenGL, then use opengl_graphics. If you want to use Glium, then use glium_graphics. If you want to use Gfx, use gfx_graphics. If you don't need low level control, only writing a simple 2D game, then just use [piston_window](https://github.com/pistondevelopers/piston_window). Testing different APIs have lead to discovery of bugs and performance issues. It is part of the practical aspect of maintenance and has lot of benefits. I'm sorry that it might seem very daunting to you! Just remember one thing: DON'T PANIC (and bring a towel!)
So I've run into a similar issue if I add a println! to `test_fn`, except the crash happens as the program is quitting. I've tried using beta+nightly, flushing stdout, as well as debugging this myself in lldb but I really have no idea what the problem is. Gist with lldb/output: https://gist.github.com/overdrivenpotato/cdbd413085792c012190 I don't mean to bog you down but if you could help or point me in the right direction that would be awesome!
Oh dear, so this is also quite interesting! Turns out it's basically the [same bug as before](https://github.com/rust-lang/rust/issues/28794) with jemalloc, only this time it's our fault not jemalloc's! Unfortunately I don't have quite as nice of a solution as before to this, and I'm not even sure how we might solve it in the near future... For now you may unfortunately just want to avoid `dlclose` as it's generally a pretty tricky thing to get right :( 
Thanks for the great reply! Are there plans to make libraries for higher level abstractions over graphics? I'm thinking a library with functionality kinda like SFML. Edit: Oh, and are there any "easy" things that you need help with, and how can one help? I'm sooo hyped for using Rust for gamedev, but I feel like the ecosystem isn't mature enough yet, so I should help if I can! 
The concept behind the double lock is that the Vec should not be able to be modified if any thread has a lock to a Person. If a Person lock exists, a Vec lock must also exist preventing removal/replacement. The internal lock then prevents those with a read Vec lock from concurrently editing a Person.
&gt; I can work up an example a little later I would be very happy to see one please.
One good way to learn more about the ecosystem is to help out with updates. We have tool called [Eco](https://github.com/PistonDevelopers/eco) which analyses the Cargo.tomls on Github and generates a todo list. There is also an entire UI framework on top of Piston! See [Conrod](https://github.com/PistonDevelopers/conrod/issues). Write small applications and test it! Testing it for real is important for driving the design further. We need more widgets! Another thing you could work on is adding more features to [select_color](https://github.com/pistondevelopers/select_color). This can be used in widgets for editors. I have not used SFML yet, so could you tell me what are things you are looking for?
Interesting post as always. By the way, gradient descent does work incrementally but in a bit of a different way than incremental collection operations. With gradient descent if you change the input data your cost function changes a bit, but usually not too much. So if you restart the gradient descent from the previously optimal solution it's usually much quicker to converge to the new optimum which lies close by. This is even more true for Newton's method, because Newton's method converges faster the closer you start to the solution. At the start of Newton's method it may only improve a bit each iteration, but close to the solution the number of correct digits doubles at every step. Maybe that kind of incrementalism can be integrated into this framework?
Alright, well thanks a bunch for the help anyway :) In the meantime I'll try to find a way around using dlclose
I'm happy to see so much activity on the regex front!
Does Eco work on Windows? I've actually used Conrod quite a bit, even suggested a widget to be made, but was confused as to how to design a widget on my own. Seemed a bit tricky last time I checked. I'll look into select_color! Well, if we're only going to talk about the graphics features of SFML, it's something like this: SFML is an abstraction over OpenGL, and gives you a few different classes for handling graphical objects. An Texture is a texture stored in video memory (there's also Image, which stores its texture data in RAM), and can be constructed by loading from a file or from memory. An Texture can be drawn to a RenderTarget through a Sprite, which stores a pointer to a texture, and additional transform data such as position, rotation, etc. A RenderTarget can be either a RenderWindow, or a RenderTexture. RenderTextures are cool, because they let you draw Sprites to a texture in memory, which is really handy, as you can then apply shaders to that texture. There are also Views that helps with transforming the rendered scene without having to transform every sprite individually. In short, it makes it really easy to reason about 2D rendering.
Thanks! I sorta feel like the approaches should probably be separate. At least, differential dataflow works hard to re-compute the "correct" answer: the one you would have gotten starting from the new inputs. As you say, most of the SGD approaches don't need that (or, don't care at least). It may become more clear when I get to explaining the details; you'll probably be all "oh, yeah. nevermind about that. *steps carefully back*". :) I think it's fine that they both fit on the same runtime. They don't need to use the same maths to work. DD changes can feed into SGD just fine, and SGD outputs could be re-interpeted at DD changes, but underneath they probably want to do different things (remember their history vs not, basically). I do have an all-reduce impl in timely dataflow, though. I need to test it a bit on some real loss functions and make sure it minimizes something, anything. 
&gt; Does Eco work on Windows? Not familar with all the developer tools on Windows, but I used a powershell to get unix-like commands working. I believe it was [posh-git](https://github.com/dahlbyk/posh-git). About graphics: Piston has a simple [2D library](https://github.com/pistondevelopers/graphics). The texture is an associated type on the `Graphics` trait. The image library can loads data into RAM, and then you can create a texture on the GPU. Here is an [example](https://github.com/PistonDevelopers/piston-examples/blob/master/src/paint.rs). The draw method takes a transform matrix. If your scene uses a matrix, then you need to multiply with the sprite matrix to get the final matrix for each sprite. If you have an idea for making this easier, then open up an issue [here](https://github.com/PistonDevelopers/graphics/issues). Glium supports rendering to a texture. I think Gfx supports this too. The piston-graphics library doesn't know whether it renders to the main frame buffer or a texture, so this is something you do with in graphic backend.
Thanks for clarifying! It seems like their goal is to enforce through static analysis tools. It does seem to stop a bit early compared to Rust.
Yes good point. The SGD would converge to the optimum independent from the starting point for a convex function, but many functions that SGD is used for in practice are nasty. It also wouldn't really compose in any interesting ways with the rest of the system like incremental collection operations do. I've looked into the Naiad paper to understand this stuff better, and one thing I've wondered is whether you really need the vector of loop counters? Can you maybe make a data type so that each loop adds one counter to an opaque data type, so that you only need to think about the local loop counter and never about the global vector of them? Another thing I've wondered is if it's possible to handle time varying computation graphs like in self-adjusting computation / FRP? This totally messes up the could-result-in function though, so maybe not.
I gotta say, the modularity/genericity was really confusing/annoying for me. Basically the first thing I did when getting ready to use it for a serious project was hard fork several components to remove the generics.
There is not, currently. You can use macros to write your own test framework, see https://crates.io/crates/stainless for example.
This is a lazy question but: I'm unclear on the memory implications of using differential dataflow compared to timely. It seems like the default is to keep the result of the calculation as well as the result at (epoch-1) and (iteration-1), which I assume means 3x the memory of the timely equivalent. Is this correct or are you doing something more clever? I ask because it's not completely clear to me when to choose differential over timely. Obviously when your requirements are differential's main use case you pick differential but what about when it might be convenient?
Web services are a _huge_ opportunity for Rust‚Äîin part because there's no standard, portable way to build an HTTP API in C++. Why does this matter? Because HTTP is the most straightforward way to make your service accessible over a network‚Äîand I hope we agree network services should be part of Rust's core domain or else I'm learning the wrong language. Think of any high-performance network service. Ten to twenty years ago, the common way to do this in the corporate world was to use C++ and write a custom protocol. It works, but (1) it's error-prone, (2) it costs a lot of money, and (3) you do extra work for each language you support on the client side. HTTP solves all of these problems‚Äîand C++ hasn't yet made it easy to use HTTP. So there are two big opportunities here. 1. HTTP is an area where Rust can offer something that C++ doesn't provide. I'm specifically talking about a _standard, portable_ HTTP stack. 2. Because clients everywhere support HTTP, Rust can ‚Äúchip away‚Äù at large legacy systems written in C++ and Java. HTTP provides a language-agnostic buffer between services and clients, thereby allowing small pieces of server systems to be rewritten in Rust. This is more likely to happen than rewriting entire systems in Rust. So HTTP is an ‚Äúin‚Äù into the world of corporate legacy systems.
The synchronization stuff in the Rust standard library is all based on RAII, which can be great, but in this case it isn't. You can hack around it by getting creative and being a little unsafe. For example, something like [this](https://play.rust-lang.org/?gist=8d1918d2c5ced189ff14) could work I didn't formally verify correctness so it's probably a mess :-). No documented invariants make things interesting!
Do you have a library in particular that you want to point out?
Have you looked at F#? It sounds like roughly the type system complexity and ecosystem you're looking for. I like the language a lot but I rarely have an opportunity to use .net in general.
I'll have to have a look to see how the current `fn()` to `Fn()` coercion is handed but I could be possible. Based on what I *think* the implementation is, supporting this case could be possible, but would probably require an RFC. 
Does gfx have any way to do sprite batching? It's a pretty important feature if you want to do anything with more then a handful of sprites. 
It is well known to anyone with a performance background in Rust that the SipHasher that is used by default represents a stable, but not too fast compromise ‚Äì it's secure against DOS attacks (where attackers create many hash entries with keys crafted to force collisions), but that security comes at a cost. For maps where you know the keys cannot be controlled by an adversary (either because your user is known to be benign or the map is only used internally) and where the keys are known to be short, the FnvHasher (in the [fnv](https://crates.io/crates/fnv) crate is a good solution.
I had to program [this](https://play.rust-lang.org/?gist=5f5584f26f3560c6ceb9&amp;version=stable).
~~Each function is its own type for optimizations purposes (that is the `{cpu::Cpu&lt;'a&gt;::nop}` part you see). You can cast it to a function pointer with something like `nop as fn(&amp;mut cpu::Cpu&lt;'a&gt;, u16)`, though that might not be entirely correct as I'm a bit unsure how lifetimes would work in such a case.~~ Edit: Turns out that happens implicitly. I must have misunderstood. You might want to consider whether you really need a function table though. It seems to me like a simple `match` might be enough and maybe faster.
I was thinking in unit testing, Rust supports it very well and you can do CI with Travis quite easily. That way you can still cover many scenarios before you get into the more complex functional testing for a OS that is not gonna be something easy at all.
Why doesn't your `func_lookup` method return a `fn(&amp;mut Cpu&lt;'a&gt;, u16)`?
This is correct. Both solutions ~~work~~ compile. Thank you for your help. Can you elaborate on &gt; Side point, I would recommend not using static method function pointers unless they fit your use case. I've rarely seen a situation where that's very useful... C was my first programming language so function pointers and table lookups for them seem natural to me. I have since moved on to higher level languages (OOP and FP paradigms) but a function table lookup just felt right to me here
I suggest asking in the #rust-gamedev IRC channel or [gfx-rs on gitter](https://gitter.im/gfx-rs/gfx).
Notice that there are no profile timings with optimizations enabled in the blog post, so there is no reason to claim HashMap is slow or slower.
I think it's just constant lifting that puts `a` in static storage.
Yep. This has higher overhead, but implementing one more thing is just // stuff you do anyway struct Ufo; impl Vehicle for Ufo { fn drive(&amp;self) { println!("Motorcycle: *woop woop woop*"); } } // unwanted overhead impl AsAnimal for Ufo {} Specialization, when we get it, should even remove the overhead.
I haven't tried this but sans the lifetime of repeat( (0..size) ) I don't know why this wouldn't work and it's probably a decent start. Honestly though it's no cleaner, I just like iterators. let size: usize = 8; let ref mut hash = vec![0u8; size]; let _ = (0..size).zip(repeat( (0..size) )).map( |a, bs| bs.map(|b| { let index = a * size + b; if raw[index] &gt; raw[index + 1] { hash[a] |= 1 &lt;&lt; b; } } );
The alternate syntax suggested later in the discussion looks way better than the main proposal or your example: let Some(a) = x else return; 
I'm starting to wish I had proposed the `let...else` syntax from the beginning. (I had considered it, along with several other possibilities.) I think it would have prevented some initial confusion. **UPDATE:** Okay, I changed the proposal to use `let ... else` syntax.
You've got the wrong user :) I also understood maybe 15% of this post. 
`match` is the general solution, `if let` is just sugar for some convenient forms.
&gt; Wouldn't it be doable pretty easily with a macro? What macro do you propose? Writing a general-purpose macro to replace this syntax is hard because macros can't create bindings in the enclosing scope. Though I'd be happy if someone can prove me wrong! You can certainly write various special-purpose macros like `try!`, but then you need a different one if you want to break or continue instead of return, or log something before returning, or match some pattern other than `Result::Ok(x)`. I think one general-purpose syntax (works with any pattern, any type of expression, any control flow) is simpler to learn than a bunch of special-purpose macros.
This is verbatim the syntax I opened this thread to suggest, I should have kept reading the discussion further.
I would love "let [refutable pattern] = [expression]" to return a boolean value to make this possible, but it would heavily complicate "if let" expressions and control flow analysis in general, so probably better not.
You can only return `&amp;str` (or a Vec of it) if the strings are either `'static` (e.g. string literals) or derived from the input argument, which they aren't here. The `tmp` variable is stack-allocated inside `get_input`, so it will get cleaned up together with its stack frame. This means you'll have to return `Vec&lt;String&gt;`.
To whit, here's a modified function that works: fn get_input(msg:&amp;str) -&gt; Vec&lt;String&gt; { print!("{}", msg); stdout().flush(); let stdin = stdin(); let input = &amp;mut String::new(); input.clear(); stdin.read_line(input); let tmp1 = input.trim(); let tmp = tmp1.to_string(); let return_val: Vec&lt;_&gt; = tmp.split(" ").map(|s| s.to_owned()).collect(); return_val } Note that I also removed the loop because... well, I have no idea why it was there in the first place. The key is using `map` to turn each `&amp;str` into a `String` (the `s.to_owned()` part does that).
does this not work? https://play.rust-lang.org/?gist=e4c7050e23420408d2af&amp;version=stable
No, it doesn't create a binding in the enclosing scope: http://is.gd/YodWix
tmp is totally unnecessary. you can split from a &amp;str
Why not just `if let None = x { ... }` ? As it's about pattern matching, using operators like `!=` doesn't make much sense.
Here's an example: http://is.gd/sHhzAk
You forgot the fourth kind of ownership `üçπT` - `drain`! https://doc.rust-lang.org/collections/vec/struct.Vec.html#method.drain (I guess this is still unstable...)
Yep, I don't properly understand how draining works, I wasn't bothering with it because it's still unstable. Anyway, I asked in the slides thread, what's üçπ? (my Linux box still doesn't render this char properly, it's just a box here)
No. But I can make it return *something* that may inform further control flow.
U+1F379 TROPICAL DRINK
I think I finally understood (from [this example](https://github.com/rust-lang/rfcs/pull/1303#issuecomment-145091620)) that the `if let` binding actually binds a new variable name. This is even more confusing to me as this binding escapes the `if`'s scope.
I'm on debian 8, and it looks like a cocktail served in a hurricane glass. http://www.fileformat.info/info/unicode/char/1f379/index.htm
It would work for &amp;&amp;, but wouldn't make sense if you used ||. All the bindings must succeed for the body to be allowed to be executed.
(üçπ is a tropical drink -- notably with a straw. The slides were a reference to [this scene of There Will Be Blood](https://youtu.be/KQHQ9e9mtng?t=1m18s) which IMO perfectly explains Drain, including the part where you murder someone in a bowling alley, but no one seemed to get it). The basic point of drain is the following metaphor: You have a milkshake, and want to consume its contents. Initially, all we had was IntoIter to do this. IntoIter is semantically equivalent to drinking up all the contents (yay!) and then smashing the glass on the ground (boo!). This is annoying for 2 reasons: * You need to own the glass (so you can smash it) * This wastes an allocation that could have been reused (the glass) Drain *mutably borrows* the glass by inserting a straw into and sucking the contents out. You don't get to touch the glass (it's not yours), but you get all the contents. You now: * Don't need to own the glass * Get to reuse the allocation * bonus (drain range API): can drain a subrange to do an efficient bulk-removal. This has one downside: * The iterator can't transport allocations (`fn foo(Vec&lt;T&gt;) -&gt; Drain&lt;T&gt;` doesn't work) 
Requiring the sub-expression to diverge is super, super ugly...
`format!()` *must* be slower than a straight up concat, right?
Your problem is about ownership and mutability. If you have a string and want to add something to it, you either need to own the string (have a variable of type `String`) or be allowed to mutate it (have reference of type `&amp;mut String`). Rust doesn't implicitly copy the entire string for you when you add to it. Allocations can be slow and have to be explicit, unless they are `Copy` types, like `i32`. There are several ways to do this. Create a new string first: fn foo(s: &amp;String) -&gt; String { s.clone() + "bar" } Take ownership of the string, reuse and return it: fn foo(s: String) -&gt; String { s + "bar" } Mutate the string in place. Note that it doesn't return a String. fn foo(s: &amp;mut String) { s.extend("bar".chars()); } All of these should work. Disclaimer: Haven't checked.
Update: Hi again! We want to know what software processes are used int his open source project how you do you software validation and how you manage the pull request and issues in this project. Also if you wanntalk about how you communicate with each other it would be aslo a great help! 
Oops, sorry :)
I'm really really liking the 2nd version of the RFC. I feel like we could get rid of so much rightward drift with this.
pssssh
`fn concat(&amp;String, &amp;str) -&gt; Result&lt;String, üôÄüåå&gt;`
I definitely can't think of anything better. I was going to suggest some kind of branching structure, but then I realized that `match` statements already exist :P
Wait, why did I specialize this? Clearly needs to be generic...
The pattern may have any number of bindings. It's not clear what the ‚Äútype of the binding‚Äù is in a pattern like `Foo { x, ref y, Ok(z) }`, or how to specify a value of that type that irrefutably matches the pattern.
Your comment is eerily similar to what I [posted](https://github.com/rust-lang/rfcs/pull/1303#issuecomment-145169636) where I suggested overload `try`. Maybe even the macro unless they want a keyword. Actually, the idea is growing on me as I think about it.
You can require the else block to return a value that can be irrefutably matched. `let Pattern(x,y) = something() else { Pattern(2,3) }`
In case you're curious, I cleaned it up a little more into what I believe is fairly idiomatic Rust: fn get_input(msg:&amp;str) -&gt; Vec&lt;String&gt; { print!("{}", msg); stdout().flush().unwrap(); let mut input = String::new(); stdin().read_line(&amp;mut input).unwrap(); input.trim().split(" ").map(|s| s.into()).collect() } If you have any questions about how any of this works let me know. There's some stuff in their which might look pretty weird to a Rust newcomer.
Yeah, that's too complicated and in general not even possible. My first pick would be to require a constant return value.
New RFC: post-structuralist type system
Short and semi-accurate summary: everything boils down to power and who has it. Also, new analysis methodologies. Also I just showed this to ashley and she says: &gt; You're not wrong, but to me, it's more about how powerful norms are, and how those norms are set by who has power, and that that power is recursive.
Is `.into()` the same as `.to_owned()` here? What's the basis to prefer one over the other? (I would prefer to_owned because it's more specific, and relies less on type inference - so I expect error messages to perhaos be prettier)
If the string is ASCII, then the branch predictor will work almost perfectly and the conversion from utf8 to utf32 is just a zero-extension operation.
So in summary: You'd like a "mechanism that would, instead, allow for shared state between components that will never run concurrently, but disallow sharing when they may". Currently you hack around problems caused by not being able to explain this to the compiler by declaring everything that needs to work this way 'static. The example use case being: // Both UDP and RadioDriver need a reference to the // networking stack. impl UDP { // Called from an application to send a packet. Must be able // to tell the networking stack to transmit a new packet. fn send(&amp;mut self, packet) { self.network_stack.outgoing(packet); } } impl RadioDriver { // Called from the main loop when a packet arrives. // on_receive needs a reference to network_stack // to notify it of a received packet. fn on_receive(&amp;mut self, packet) { self.network_stack.incoming(packet); } } The semantics of how the compiler reviews closures and ownership is too general, and forces work-arounds that bloat the code and require a lot of extra work to say something simple, the example being You'd like to write // No other code can access LEDs setTimeout( || { leds.activityToggle(); }, 2000); but instead you have to write: setTimeout( || { activityLED.toggle(); }, 2000); for each led you are managing. You'd like support for statically allocating closures, along with/in addition to a compile-time size_of equivalent. Fundamentally, Rust's disallowing mutable aliasing *entirely* is too strong for the embedded environment, and you'd like a way to encode finer grained "thread based execution context" into Rust that allows for a limited and hopefully type safe mutable aliasing. The gist of the proposal is that this fn spawn &lt;#a, #b, F&gt; (func: F) -&gt; #a() where F: FnOnce() + #b; let x = 0; spawn (move || { println!("In thread: {}", x); }); should be allowed. Along with the notion of an #any context, that can mutably borrow from any other context. So, a few questions. Will there be a forthcoming RFC about the execution context (EC) annotation as outlined in the paper? Have you talked Nico and friends about the implications for the type system if such a thing were implemented, especially around how something like #any would work? If it ECs were implemented, what would anything remain on your "Rust for embedded systems wishlist"? More generally, have things like this been proposed or been through the RFC process before? I don't know the history here. All in all, cool stuff, glad someone is pushing the boundaries! 
In this case, they're the same, as well as .to_string. There are lots of string conversion methods because almost all of the generic interfaces fit well. (They're basically the same amount of generic, from the perspective of the type system.)
The specific example in the RFC could probably be solved using let a = try!( x.ok_or( "bad x")); let b = try!( y.ok_or_else( || "bad y")); https://gist.github.com/a55d871b191707a1aff4
[removed]
As far as I know they are the same in this case--just a matter of personal preference. I like your argument for `.to_owned()` though--honestly I just used `.into()` because it's a few characters shorter.
`MoveCell` is `Cell` for non-`Copy` types: https://github.com/SimonSapin/rust-movecell/blob/master/lib.rs It‚Äôs even safe to do *some* stuff with the value in the cell without moving it out first, if you‚Äôre sure that stuff does not alias the cell: https://github.com/SimonSapin/kuchiki/blob/2f1b64877a/src/move_cell.rs#L75-L112
Doesn't that statement ignore how computers are implemented?
If you're using Firefox or Seamonkey on Linux, I highly recommend installing the [Firefox Emoji font](https://github.com/mozilla/fxemoji/blob/gh-pages/dist/FirefoxEmoji/index.html) to get nice colour emoji glyphs like every other OS has these days.
Wherein Veedrac, teXitoi and I set out to speed up some Rust entries to the benchmarks game.
Abstract for the lazy &gt;Rust, a new systems programming language, provides compile-time memory safety checks to help eliminate runtime bugs that manifest from improper memory management. This feature is advantageous for operating system development, and especially for embedded OS development, where recovery and debugging are particularly challenging. However, embedded platforms are highly event-based, and Rust‚Äôs memory safety mechanisms largely presume threads. In our experience developing an operating system for embedded systems in Rust, we have found that Rust‚Äôs ownership model prevents otherwise safe resource sharing common in the embedded domain, conflicts with the reality of hardware resources, and hinders using closures for programming asynchronously. We describe these experiences and how they relate to memory safety as well as illustrate our workarounds that preserve the safety guarantees to the largest extent possible. In addition, we draw from our experience to propose a new language extension to Rust that would enable it to provide better memory safety tools for event-driven platforms.
https://www.reddit.com/r/rust/comments/3nauhy/experiences_building_an_os_in_rust_feedback/
It's all good!
There's more discussion on [users.rust-lang.org](https://users.rust-lang.org/t/blog-rust-faster/3117).
Why does it take a lot of resources? I mean, I wouldn't expect the site to recalculate it on the fly, but just store a list of rev-depends for each crate, and update the lists when adding or removing a crate.
This is a great quote. What're the odds that something so Yogi Berra-esque would've come from a totally different 'Yogi B.'?
It appears to be an inside joke understand only by /u/Gankro ‚Ä¶
i quite liked it, English isn't my first language so I didn't get the reference of "drain - milkshake"
Thanks for the explanation, loved it, lol.
I've been working on speeding up my ray tracer and various bug fixes for animated scenes. I rendered this to show a more interesting animation: [Spinning Rust logo with Stanford Buddha and Dragon](https://youtu.be/-_Dsp6BIet8). It's just 360p since I wanted the render to finish overnight, each frame takes about 6 minutes, so 48 frames ~5hrs. Youtube's compression is kind of nasty so check it out on my [dropbox](https://www.dropbox.com/s/l573rpsungr1k51/Spinning%20Rust%20logo%20with%20Stanford%20Buddha%20and%20Dragon%20.mp4?dl=0) to see it uncompressed. Also if anyone is aware of a video host that doesn't do so much compression, let me know! Edit: I'm rendering it in 720p now, [here's the first frame](http://i.imgur.com/cp2alV2.png) if you don't want to watch the clip.
Indeed it is, which incidentally is why for the moment you should use .to_owned instead of .to_string for converting a &amp;str into a String (at least until specialization lands).
Great work! As the author of the previous multi-threaded fasta entry, one quibble: &gt; The previous multicore entry could only parallelize adding the line breaks, which a more efficient loop largely removes the need for. What the previous multicore entry did was essentially to allow the data to be calculated independently of the printing of the data. Each thread has its own data buffer, which it fills when it gets its turn to access the RNG. IIRC the time taken to print the data out was quite significant, so this made a noticeable impact - on my machine the single threaded version ran in 2.7s, vs 1.4s for 2 threads, and 0.9s for 4. Other than the figures this is all very vague in my memory at this point though :-)
How come some of the benchmarks haven't made it to the site yet? A few months ago I took a stab at chamenous redux myself but didn't manage to beat the C version.
Ack, I know this. Thanks for the catch.
I believe Veedrac's fasta entry is waiting for review from teXitoi who has also agreed to submit the others, which he hasn't yet.
The odds of something happening to which somebody asks "what are the odds?" are very high.
I have discussed with mioco's author, and he thought that we are doing the same thing with different angle.
Alas, members of the Rust teams are immune from all persecution. Thus begins Rust's slow decline into corruption and decadence!
Unlike on other platforms, on Windows the C++ ABI is not stable. The ABI used by MinGW is different than the ABI used by MSVC and each major version of MSVC has a different ABI as well. Even debug/release are different with MSVC. The only stable ABI on Windows is the C ABI when used across the DLL boundary.
~~Could thread-ring used mioco to pass token around? Would that count?~~ Edit: I've got it. No it couldn't. Programs may use pre-emptive kernel threads or pre-emptive lightweight threads; but programs that use non pre-emptive threads (coroutines, cooperative threads) and any programs that use custom schedulers, will be listed as interesting alternative implementations. Briefly say what concurrency technique is used in the program header comment.
I think we should be able to argue that this is equivalent to the Haskell version (as long as the scheduler is hidden from the program logic).
As a web developer, I just love so much that theres no crap on this blog. It loads lightning fast because it has just what it needs, and nothing else.
 ## Continuous integration Once a pull request has been approved, there's a bot called [homu](https://github.com/barosl/homu) (though using the account [@bors](https://github.com/bors) which was a previous bot that performed a similar task) that [queues up the approved pull requests](http://buildbot.rust-lang.org/homu/queue/rust). One by one, it tries merging the pull requests (and fails them if they can't be merged) into a temporary branch, and then it runs a full build and set of tests on all of the major platforms that Rust supports. If the merge, build, and tests all pass successfully, the bot fast-forwards master to this temporary merge; if any of these steps fails, it says so in the pull request discussion, and the owner of the PR is expected to fix the problems and get the result reviewed and merged again. Sometimes, the tests fails just due to a spurious issue; which running thousands of tests on a large number of machines at once, there can be occasional transient errors. The reviewer of a ticket (or anyone else with appropriate privileges) can just ask that the pull request be retried; if the same merge can be reused (nothing else has been merged yet), then the bot can reuse the results for any platforms that already passed, and only rerun the tests on the platforms that failed. [Here's a simple example that demonstrates the code review and continuous integration process](https://github.com/rust-lang/rust/pull/28729) Certain types of pull requests, such as documentation pull requests, comment fixes, and the like, are very unlikely to fail. Doing full builds and tests can take a long time, so these pull requests are frequently manually collected into a "roll-up" branch, that can all be merged with one single merge and test of the full branch, rather than one for each pull request. Graydon Hoare, the original author of Rust, has a [good blog post describing the rationale for this continuous integration process](http://graydon.livejournal.com/186550.html). ## Release channels As described in the [Stability as a Deliverable](http://blog.rust-lang.org/2014/10/30/Stability.html) blog post, Rust operates three different release channels, for three different stages that software goes through as part of the release process. Every night, there is a build of the `master` branch, producing a "nightly" release channel compiler. This contains all of the latest changes, and based on the continuous integration system above, it is known that this builds and passes the full test suite on all of the major platforms. The nightly build also allows users to opt-in to using unstable features; this allows people to experiment around with features, making sure they work properly and make sense, before committing to those features being part of the stable, backwards-compatible guarantees made for the language and standard library. Once every 6 weeks, there are two more releases made; a new beta release, which consists of the latest state of `master`, including any newly stabilized features since the last release plus any other fixes and enhancements, along with a new stable release, which consists of the latest state of the previous beta release. The beta release is intended for people to be able to test out new features introduced as they will be available in the next release, without being as fast-moving a target as the nightly release, and with all unstable features disabled so that it will behave exactly as the next stable release will. If there are any bugs found that could cause serious problems or stability breakage, they are fixed in `master` and then promoted to the new beta branch. Over the course of the 6 week release cycle, occasional builds are made from this beta branch to ensure that all such issues are fixed properly. ## Ecosystem testing Because Rust is intended to be backwards compatible, and supports a very large ecosystem of packages, it is important to not only run the tests that exist within the Rust repository itself, but also do some real-world testing on a wide variety of code written in Rust. Brian Anderson, /u/brson, has written a tool call [Crater](https://github.com/brson/taskcluster-crater) which checks out the most popular crates on [crates.io](https://crates.io/) and tries building them with two different compilers, and compares the results. If a crate built with an earlier stable release of the compiler, and now fails, then that indicates that there may be a stability regression, and something may need to be fixed. [Here's an example of a summarized regression report](https://internals.rust-lang.org/t/regression-report-stable-2015-08-06-vs-nightly-2015-09-08/2622). These problems are then manually triaged; sometimes, there are just spurious build failures, or certain failures that are considered acceptable according to the [language semantic versioning RFC](https://github.com/rust-lang/rfcs/blob/master/text/1122-language-semver.md), where there may be changes that cause a build to break, but it will do so in a deterministic way and easily be worked around by adding some kind of disambiguation. # Software Validation I believe I've discussed this above in the processes, but to summarize, the main forms of validation are: 1. Unit tests in the `rust` repo itself, along with continuous integration to make sure they all always pass 2. Manual testing by the community of the `nightly` and `beta` versions of the compiler 3. Regular runs of the Crater tool to verify that no regressions are introduced from previous stable releases of the compiler # Pull request and issue management These are generally handled by the [sub-teams](https://www.rust-lang.org/team.html). Each sub-team has regular meetings to triage issues and agree on the status of any RFCs or issues that require agreement before merging. [Notes from these meetings are posted to the internals forum](https://internals.rust-lang.org/t/subteam-reports-2015-10-02/2716). Triage status is tracked using labels on the issues, and periodically a bot [collects these labelled issues](https://internals.rust-lang.org/t/triage-digest-wed-sep-30-2015/2705) to give an overview of the triage status of the project. # Communication There are a number of different means of communication, used for different purposes. For quick, real-time communication, IRC is preferred. Mozilla has its own IRC network, `irc.mozilla.org`, on which there are numerous Rust related channels: * `#rust` is used for general discussion of the Rust language, generally users asking questions and discussing anything Rust related. * `#rust-internals` is for general purpose discussion of "internals", such as language design, the compiler, standard library, Cargo, and so on. However, that got to have a bit much traffic so some of these have been split out into their own channels. * `#rust-libs` for discussion of the standard library internals * `#rust-tools` for discussion of Rust tools internals, such as the compiler * Lots more for specific users of rust, community discussion, and the like. For longer-form communication, there are two forums; [internals.rust-lang.org](https://internals.rust-lang.org/) for discussing the Rust project itself, including language, compiler, standard libraries, and so on, and [users.rust-lang.org](https://users.rust-lang.org/), for user-level discussion. Reddit is a popular, though informal, venue for discussion of Rust, and also provides a good place to discuss blog posts. Sometimes, for very large new features that would affect a lot of the language, discussion starts out in blog posts before moving on to the RFC phase; for example, see Niko Matsakis's series on Virtual Structs, [part 1](http://smallcultfollowing.com/babysteps/blog/2015/05/05/where-rusts-enum-shines/), [part 2](http://smallcultfollowing.com/babysteps/blog/2015/05/29/classes-strike-back/), [part 3](http://smallcultfollowing.com/babysteps/blog/2015/08/20/virtual-structs-part-3-bringing-enums-and-structs-together/), and corresponding discussions on Reddit, [part 1](https://www.reddit.com/r/rust/comments/34y1d7/virtual_structs_part_1_where_rusts_enum_shines/), [part 2](https://www.reddit.com/r/rust/comments/37qpja/virtual_structs_part_2_classes_strike_back/), [part 3](https://www.reddit.com/r/rust/comments/3hqanl/virtual_structs_part_3_bringing_enums_and_structs/). Finally, for formal discussion of RFCs and pull requests, GitHub comments are used. Much of the actual technical discussion of new features, bugs, enhancements, and so on happens in GitHub comment threads, as they are linked directly to the RFC or pull request in question. # Conclusion Whew, that was longer than I meant to make this; I had intended to mostly point to existing resources, but wound up writing up a fairly detailed description myself. Let me know if you need any clarification, but as I said, a followup separate post would probably be a good idea as it will mean that more people in the community will see it and comment on it.
Does this allow for function signatures like: fn produce_iter_static&lt;I: Iterator&lt;u8&gt;&gt;() -&gt; I 
It allows rather for fn produce_iter_static()&lt;I: Iterator&lt;u8&gt;&gt; -&gt; I
Exactly.
Yes. Input type parameters are determined at the call site by the caller. Output type parameters are determined by the implementation of the function. Both features allow for dealing with (passing/returning) unboxed objects. For more informations see aaturon's post and the comments linked by Kimundi.
It's the same kind of difference as the one between `consume_iter(i)` and `let i = produce_iter()`, just at the type level.
Is there a feed we can subscribe to? I didn't see one...but then I'm also on mobile so I didn't look too hard :P
The example seems to use `extern "C"`. How does the C++ ABI come into the picture?
Wow this was awesome! I haven't read it all to be honest, but I will definitely read it because I think this will help us A LOT in our project. If we have any questions we will ask you later if you don't mind, but thanks a lot! You were great. 
Mioco is not preemptive though. I wonder if I could make it preemptive somehow, by handling signals or something like this.
Hooray for more podcasts! :)
Use chan-signal: https://crates.io/crates/chan-signal
Due to static linking Rust is connected with the C/C++ in more ways than just the interface. Rust is controlling which version of the CRT is being linked against, and code compiled with a certain version of the CRT must be linked against that same CRT or bad things will happen. Since the C/C++ was compiled against MSVC's CRT and Rust was using the CRT that MinGW uses, things did not end well.
Yep, that should work totally fine, probably.
[*ahem*](https://retep998.github.io/doc/kernel32/fn.SetConsoleCtrlHandler.html)
I'll weigh in on the nbody a bit. 1. The C++ version uses non standard gcc extensions to vectorize doubles and process them two at a time. 2. I think most native languages can beat the current benchmarks here because the data is not dealt with in the most linear way possible.
Wait, so the podcast page are module docs? Clearly, what needs to happen is to put the audio into a cargo package and have each episode be a different version of said package. Then, write and release a `cargo listen` command. Because that obviously makes complete sense.
Hah! Sorry about that. Yeah, a REPL for Rust itself would be cool.
What's wrong with [rusti](https://github.com/murarth/rusti)?
There's a feed link on the [landing page.](http://www.newrustacean.com/)
That is a valid question, I didn't know about it. &gt; Rusti requires GNU Readline. This seems like a very unnecessary dependency, especially since it is the only dependency. 
I definitely like the milkshake/murder in the bowling metaphor a lot better than the "pre-pooping your pants" metaphor. &gt; Drainage! Drainage, Eli, you boy. Drained dry. I'm so sorry. Here, if you have a milkshake, and I have a milkshake, and I have a straw. There it is, that's a straw, you see? Watch it. Now, my straw reaches acroooooooss the room and starts to drink your milkshake. I... drink... your... milkshake! &lt;sucking sound&gt; I drink it up!
What else would you use?
1. I was [thinking along the same lines](https://github.com/TeXitoi/benchmarksgame-rs/issues/25). 2. Do you have a specific improvement in mind?
Concrete types don't need to be imported to use methods on them, otherwise things like [`Iterator` adaptors](http://doc.rust-lang.org/nightly/std/iter/trait.Iterator.html#provided-methods) (each of which is its own concrete type) would be *really* clunky to use. Only traits need to be imported to use their methods; fortunately `Iterator` is in the prelude so you don't need to import it to use its methods.
There is also http://rustyrad.io/ ;)
Please allow the whole blog to scroll on mobile. The static title is painful.
Readline implements a lot of good interface behavior you'd want for a REPL that isn't implemented by default in the tty's canonical line discipline (like up arrow to bring up previously entered lines). It's basically analogous to a graphical program having a GUI framework as a dependency.
What are the odds I win the next Powerball without buying a ticket?
Is LLVM able to optimize the `match` cases into a jump table, if there are enough cases?
Yes. [Here is a small example.](https://goo.gl/0qNCRz) That `.LJTI0_0:` section is the jump table and `jmpq *%rcx` is the actual jump into the jump table.
&gt; fn produce_iter_static&lt;I: Iterator&lt;u8&gt;&gt;() -&gt; I You wanted to say `fn produce_iter_static&lt;I: Iterator&lt;Item=u8&gt;&gt;() -&gt; I` and such signatures are already allowed.
I think trait objects are existential types.
Well, there's always this: let Some(x) = v.pop() else { let mut y = Some(3); some_opaque_function_from_another_crate(&amp;mut y); Some(y.unwrap()) }; But this is too convoluted for such a simple thing IMO.
How and why does the C++ ABI become involved?
Yes.
&gt; Document all the things! Translated to Rust: `#![deny(missing_docs)]`
There's two main features of Rust: 1. Memory safety / thread safety / iterator safety 2. Zero overhead abstraction The second point is at least as important as the first! Rust has zero overhead lambdas, zero overhead structs, zero overhead generics (monomorphization), and zero overhead interfaces (traits).
To expand, the reason is that inherent methods take precedence over trait methods and can't conflict. You can, however, implement multiple traits with that have the same method names. `use`ing a specific trait means look up can find the correct method easily. Otherwise you'd have to use UFCS. 
Only at compile time. It's technically "there exists a type" but the compiler can say "yes, and it's this one", it just won't. It's important to distinguish this from the compiler not knowing the concrete type. 
&gt; zero overhead generics (monomorphization), Just a comment, another feature of Rust is having a "choose your own adventure" approach to overhead: you don't pay for it except if you actually use the feature. So monomorphization makes Rust compile the generic code for each used instance (like C++ templates), but Rust *also* have trait objects with dynamic dispatch, so you can write stuff that is impossible to monomorphize (example: a `Vec` storing objects of different types, but that implement the same trait - each method call reads from a vtable).
I don't think so.
That's interesting, even when running an user program? What if the program doesn't want to have an history? I mean, it's okay for the shell itself to have an history, but while running an user program I don't see how Windows would provide the "multi-line history" that readline has. When you insert a multi-line input (eg. a function definition), the up and down arrow keys will treat the whole input as one history entry.
I do want my program to get interrupted, so what you describe sounds like the wrong way around. The thing I've worked out with CtrlC works well enough. When the interrupt happens I make note in a variable and the solver's loop checks that variable before looping.
Listened to both of these episodes this morning, great job! I love the aesthetic of rustdoc for show notes. One minor nitpick: Rust _does_ allow for memory leaks, because "leak" is something that's not really possible to define, as it relies on programmer intent. It's true that due to affine types, it's much harder to leak memory in Rust, but we even have a function for it in the standard library: http://doc.rust-lang.org/std/mem/fn.forget.html The docs explain more. Looking forward to more episodes!
Usually the "zero overhead" phrase is understood to be scoped to run-time overhead, but that still might be worth pointing out.
Allows you to chain calls even when a function returns (). vec.tap(|v| v.push()).push(); // vs vec.push(); vec.push();
Both owning and borrowing presuppose systems of oppression. This RFC proposes a share-everything architecture.
Is that necessary to use async file I/O? Actually if this library wants to support async file I/O, it may only support it by adding a separate thread pool, just like libuv did.
It would be *cool* to have an async program that reads from files and do networking with a similar high-level interface. Not sure if it's necessary. Yeah, a library would support it with a separate thread pool (at least on Windows). But perhaps it could special-case the Linux implementation to use its async file I/O interface (using `#[cfg(target_os = ..)]`).
If you care about the extra lines, this works fine too: let mut v = vec![String::from("rails")]; v.extend(std::env::args()); v.push(String::from("-h")); let v = v;
I use google fonts. I guess that could be the cause... If you are unable to fix it, you can also read the markdown [here](https://github.com/aochagavia/Rust-Talks/blob/gh-pages/2015-09-29.md). The only problem is that it may be difficult to distinguish between the real content of the slide and the comments (which always come after a line containing ???)
AIO is a part of UNIX specification, but I am not sure that all *NIX support this API.
That's why I suggest `#[cfg(target_os = ..)]`. I think a generic implementation should use thread pools, but on supported platforms an async API could be used. The important thing would be to abstract over those differences.
I have eye problems ( a bad astigmatism ) so I space out things out more then normal. I'm sorry for the confusion. And it works thank you very much!
Nice. As a non-native English speaker, I'd like to thank you for the slow English...
Does anyone know how this would interact with `thread_local!`?
Adding some more functionality to the newly created [imageproc](https://github.com/PistonDevelopers/imageproc) library, and starting work on a computer vision library that'll use it. First project is implementing the contents of [this paper](http://www.edwardrosten.com/work/taylor_2009_robust.pdf) on image matching. This is my first rust project, so any suggestions or criticisms would be appreciated. Also, if there's something you'd like added please let me know. I'm starting by trying to add as much correct functionality as possible pretty quickly, so there's still a(n awful) lot of performance improvement to be done.
&gt; The schedule was never off by more than five minutes. In general RustCamp was amazingly well-run and organized, Leah Silber and her crew did a fantastic job of planning and orchestrating. I feel like we haven't given them enough credit for that, so here it is. :)
Very interesting, that's something that I've never considered about whitespace-sensitive syntax.
Well, I was working on a work related ETL thing that is currently in Python, but I've got to put that on hold and focus on new tasks. Can't improve older things, must make new... story of my life at work. I'm hoping to come up with a project idea, but it's so hard to come up with unique ideas when I already have a lot of ideas related to work. Doing work related things in Rust in my spare time is probably the only way I'm going to learn the language. It may seem dick-ish to do it in a language that none of them know, but TBH I'm going to be the only maintainer for as long as it exists. I get a lot of freedom to code how I want and with what I want because I'm the only dev maintaining 90% of my team's repos.
Awesome! Thanks.
I disagree with the paper. It argues that mutable aliases can be shared as long as its on the same thread. I disagree, it's easier to reason about as a human, but it's not ensured to be safe. Let me give you an example: struct CStr&lt;#a&gt; { // Null terminated str_data: []byte; } impl &lt;#a&gt; CStr&lt;#a&gt; { fn append&lt;'a, 'b&gt;(&amp;mut 'a #a self, other: &amp;'b CStr&lt;#a&gt;) -&gt; Bool { let max_size = len(self.str_data) - 2; // space for last null char let appending = false; let count = 0; for i in 0..max_size { if appending { self.str_data[i] = other.str_data[i]; if self.str_data[i] == '\0' { return count; } self.str_data[i+1] = '\0'; // To guarantee that there always is null count += 0; } else { appending = self.str_data[i+i] == '\0' } } return count; } } // Now what happens if I do the next: some_cstr.append(&amp;some_cstr); You could argue that programmers should get warned and be careful about this, but then that would make it unsafe code! Instead I think that a better solution is to realize what is happening. A bunch of closures are sharing a some closure but there isn't a problem because each function is only called exclusively. So we create an object that allows for a shared closure. Something like: let closure_set = shared_closure!(variables, we, want, to share); What the macro above would do is create the shared closure type, a struct with those names. Then you just make sure that the shared closure is the first argument of your functions. The thing returned to you would implement the FnSet Trait, which would look something like: trait FnSet&lt;Args, F:FnMut&lt;Args&gt;&gt; { fn add_function&lt;M: Fn(&amp;mut Self)-&gt; F&gt;(&amp;mut self, func: M); fn get_function(&amp;mut self, index:isize) -&gt; &amp;mut F; } Where the `get_function` implicitly pushes itself into the context. The idea is that you can't modify or do anything to the `ClosureSet` while one of it's functions is running, but that's OK because we are dealing with functions called within a single string. If you want to allow the ability to call multiple functions at the same time and internally serialize them you only do another version that is also `Sync`. I might revisit this problem later.
When I have some time, I'd like to continue working on [cargo edit](https://github.com/killercup/cargo-edit) and split it into multiple smaller binaries like `cargo list [--tree]`, `cargo add docopts@^0.6.73` and `cargo add --dev gcc`.
Rereading your original comment now I think I completely misunderstood it sorry! ^^! Since everything in language design has a cost in some form as /u/sellibitze says "zero cost compared to the hand rolled version" makes sense.
Thanks, I was missing that "zero overhead" meant w.r.t. hand-rolled code. Maybe it is because Traits + Trait Objects is my favorite Rust feature, but I jumped at this because Rust gives you generics with "zero overhead" _for whatever definition you have of overhead_. Monomorphization + static dispatch is only half of the story.
Because if you want to use a function to control the current running coroutine, such as `resume()` and `sched()`, you will need to store it in somewhere globally. Also, when you spawn a coroutine, you need to push it into the current `Processor`'s work queue.
Very interesting, but I'm using keepass2, so I probably cannot use this.
In the absence of allocation and ADTs, most of those situations are nonissues (at least from a memory safety perspective). For example, statically allocated intrusive linked lists or trees cannot be invalidated in a memory-unsafe way during iteration (and generally, the "statically-allocated" part isn't a prerequisite as long as higher-ranked lifetimes are used to emulate explicit regions). I think we should be very careful not to misstate the rationale behind Rust's aliasing requirements: they make a *lot* of sense in a multithreaded context, but the special cases start to pile up in a single-threaded one to the point where it's unwise to ignore them completely (to be fair, Manishearth recognizes this in the post :)).
TIOBE is a terrible index. They basically count how many times people have searched "&lt;language&gt; programming" in Google etc. RedMonk's biannual [Programming Language Rankings](http://redmonk.com/sogrady/2015/07/01/language-rankings-6-15/) are much more useful, since they look at the language popularity on StackOverflow and Github. (And they also don't want you to pay $5000 for the data set since it's all out there already.)
There are things wrong with both of them. Depending on what it is you want to measure or analyze, one could very easily be more useful than the other.
That's why i used a rather jokingly title. Of course there is not much to trust about that. But from time to time even the Rust-Community needs a little bit inappropriate Fanboy attitudes ;) 
Reading [september C++ commitee mailing](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/#mailing2015-09), reading [Macros that Work Together](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.307.883&amp;rep=rep1&amp;type=pdf), trying to understand how macro hygiene works, may be fixing some hygiene bugs after that.
I am a TIOBE hater too, but they _did_ change their algorithm significantly a month or two ago. Unsure how good or bad it still is.
&gt; it's still used by many to gauge the relative popularity of programming languages Yup. In PR, this is what matters: what people's _perception_ is, not what you wish their perception was. Lots of people pay attention to TIOBE, regardless of if we think it's a "good" or "bad" way to measure a programming language's quality. Same goes for the benchmarks game, frankly. Or any other similar thing.
It's pretty easy to _create_ "easy" bugs, even in nontrivial bits of code. Refactorings, small additions, etc. As I mentioned in the post, avoiding smaller improvements in your own PRs and filing bugs instead is an easy way of getting bugs.
I hope you find time to work on the Cow lint. It seemed quite interesting :) If I understood Rust's infrastructure or had free time (mid terms), then I would attempt to help :p
&gt; Same goes for the benchmarks game, frankly. Or any other similar thing. Which reminds me that I'm pretty sure a lot of those benchmarks can be made run quite a lot faster with a reasonable amount of work.
There has been a lot of active work going on, there's a post elsewhere on the Reddit page right now you should check out!
More work on my [ray tracer](https://github.com/Twinklebear/tray_rust), I liked how the clip looked in 360p so I re-ran it in 720p, [check it out!](https://youtu.be/4ib2Gu1E7XI) This is at 1024 samples per pixel and took ~16hrs to render (~20min per frame for 48 frames). I definitely need to work on performance improvements. While that was going I worked on various bug fixes and improvements, such as: - Fixing the bug that causes the Rust logo in this scene to spin the wrong way. It actually should have been a short rotation clockwise but I wasn't checking if my quaternions faced the same direction so to speak, so it actually took the longer path around counter-clockwise. - Starting to look at [imgui-rs](https://github.com/Gekkio/imgui-rs) to use with [glium](https://github.com/tomaka/glium) to make an interactive scene editor. It's difficult to get objects placed nicely for a static scenes and even more so for animated ones when you're just directly editing the transformation stack. To this end I've got rough text input added to imgui-rs, but it needs more work.
This was also submitted to users and answered there: https://users.rust-lang.org/t/conflicting-implementations-for-trait-core-convert-from/3149
They use stable. You can rearrange your code until LLVM vectorizes it though.
No go in top 50 :-P 
The use stable. You can rearrange your code until LLVM is happy and vectorizes it though.
Everything below the top 20 is at such a low relative volume that the standings are essentially meaningless. :P Rust could just as easily drop out of the top 50 next month as well. Tiobe is quite prone to fluctuations.
No. The benchmarksgame site only runs stable. I don't think it'd be fair of us to require them to update every day anyway. One update every 6 weeks is enough, also it gives us some motivation to stabilize the respective features, e.g. SIMD.
nice pun!
&gt; In the absence of allocation and ADTs True, however even a `String` has an internally allocated buffer, and thus *many* user types as well.
You want /r/playrust instead.
I've set up a Doodle here: http://doodle.com/poll/8strav9n8yay5yif Please pick the dates that work for you. I'd like to finalize the date within the next few days, if possible.
The new form widgets are definitely rocking that retro 1985 Macintosh look. :)
Yay! A million stealth projects to sneak Rust in under the radar are what will secure our future! Or maybe make everybody mad at us :) Don't get fired over Rust. 
I checked it out. Sweet.
Reminded me of WinXP, really :P
^Sorry ^for ^the ^late ^reply... that worked perfectly anyway 
Thanks! I also read [this](https://stackoverflow.com/questions/8768083/difference-between-posix-aio-and-libaio-on-linux). POSIX AIO doesn't seem interesting on Linux (being implemented by the glibc and all) but libaio might, if someone is sure they are using on a supported filesystem. But, &gt; My understanding is that the block device layer is essentially guaranteed to not block. If you're only concerned about accessing raw disks, you're fine. However, filesystems are not implemented with the assumption that someone may want to use them asynchronously. I tested ext4, reiser and xfs. iirc, ext4 was the one that blocked the most, but it was also the fastest to complete my benchmark. searching the linux-aio mailing list will give you many hits This was some years ago, I can't find if it has changed. But yeah, it may not be worthwhile.
Following up on last week's [successful experiment](https://github.com/jneem/regex), this week I'm going to have a look at the performance regressions and see if anything can be done about them.
Not the author, but I've written on emulators in Rust, and it's certainly a great language for doing that. A few things are a bit annoying though: * Arrays can only be indexed with `usize`. This is annoying because most of the numbers used in emulators are *not* `usize`, but have a specific size, so I have to cast almost every time I want to index. This could be fixed by "lossless integer coercions" from u8 -&gt; u16, u16 -&gt; usize, etc. or worked around with a newtype that implements `Index`. * Fixed-size arrays... suck a bit. They only implement a few traits up to a size of 32 element or something like that, and almost all arrays I'm using are bigger than that. This, again, can be worked around by using a newtype. * `match` doesn't know when matches against an integral type are exhaustive. This would be extremely useful for opcode dispatching and address mapping, where I do things like `match bank { 0x00 ... 0x1f =&gt; {...}, 0x20 ... 0xff =&gt; { ... } }` (this requires a third, wildcard match arm to compile, even though these two are exhaustive). * Compiler's slow, yadda yadda. You've heard this one before, but I'll emphasize it once more, in the hope of change. I've even catched myself trying to optimize my code for fast compilation times! Scientists are currently suspecting that this might be caused by the fact that I'm using Rust on a tablet, but that's absurd, right? ;) All in all, Rust is a really great language for writing emulators, since you "only" have to deal with writing a correct emulator, and not with writing correct C, for example. (disclaimer: I've never written an emulator in C, only in Rust)
&gt; in the hope of change. Lots of work is still undergoing, and it's a high priority. Your hope will not be in vain.
I'd really like to see if this could speed up our benchmarksgame entry.
Your story sounds so familiar that I am wondering if my 'alter ego' wrote it :)
I suspect a limiting factor for emulator-writing would be the lack of coroutine/green-thread support. Many consoles have multiple devices executing in parallel‚Äînot just CPUs, but an audio-processor handling effects and music, and a graphics-processor doing colour calculations. Typically they can interrupt the CPU at any time (or vice-versa), and games are written with the hard-coded assumption that an interrupt from *this* chip will arrive at *that* chip while it's in the middle of some particular task, a guarantee that just cannot be made with a multi-threaded implementation on a modern kernel. Some emulators get around this by building a giant state machine that encompasses every component, but that gets ridiculously complex very quickly. Some emulators have put each component in a separate co-routine and have them yield to each other at all the times when a signal might arrive. In C or C++, you have `setjmp`/`longjmp` or (for industral-strength co-routine switching) something like [libco](http://byuu.org/library/libco/). I imagine language-level support for co-routines (maybe explicit `async`/`await`, for example) would make that a whole lot easier.
&gt; (this requires a third, wildcard match arm to compile, even though these two are exhaustive) If you look at [this](https://play.rust-lang.org/?gist=021ab9b63254a422b452&amp;version=stable) in release mode, it looks like they compile down to the same assembly. Doesn't make for clean source code, but the generated result is good.
Unfortunately, probably not. The searching part of the benchmarks game uses super-simple regexes that the existing regex crate just replaces with a multi-string search. The current multi-string search implementation is in the aho-corasick crate, which is already using a special form of DFA (so my more general DFA isn't going to beat it). However, there is another route to improving the benchmarks game performance: using a different multi-string search algorithm. In particular, my [wu-manber](https://github.com/jneem/wu-manber) crate current thrashes aho-corasick in the benchmarks game. Unfortunately, it also has a much worse worst-case performance, so we wouldn't want it to just replace aho-corasick. The ultimate solution would be to examine the search strings at regex compile time and choose between string-matching algorithms.
&gt;Webrender is a new renderer for Servo which is specialized for web content. The initial results are quite promising! So yall are leaving gecko behind?
http://lists.llvm.org/pipermail/llvm-dev/2015-October/091041.html 
Servo itself is the replacement (i.e. doing the same functionality) for Gecko. WebRender is designed to be a specialised replacement for [Skia](https://en.wikipedia.org/wiki/Skia_Graphics_Engine). The [previous discussion on /r/rust](https://www.reddit.com/r/rust/comments/3mrq32/preliminary_results_for_servos_new_gpubased/) might be interesting too.
My understanding is that this is about building on XP, which we don't support anyway, so it shouldn't affect Rust.
Rustacean. Rustation. I think that's a pun.
&gt; sisyphus' ship Old post but...... Theseus? Or is there another greek thought experiment out there?
Exactly this. We can still target XP just fine.
Probably. On the benchmarksgame site, I still see the old implementation.
Is there a reason for using `gl` directly instead of something like glium?
Writing some custom memory allocators. Right now, I've put together the [scoped_allocator](https://github.com/rphmeier/scoped_allocator) crate, but I plan to pull it together with a few more in an allocators crate.
Nifty. Do you have any idea how much performance improvement should be possible? Is ray tracing runnable on the GPU and if so, is it faster that way? If it didn't used to be practical on the GPU, do things like [HSA](http://developer.amd.com/resources/heterogeneous-computing/what-is-heterogeneous-system-architecture-hsa/) make it more practical?
/u/OverMeHere /u/zonyitoo Here, mioco handling **7 million requests per second**, no less, without much hassle, with a trivial code. % wrk -t8 -c100 -d10s http://localhost:5555 Running 10s test @ http://localhost:5555 8 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 5.01s 2.37s 7.98s 69.04% Req/Sec 554.67k 582.15k 3.28M 84.58% 74197525 requests in 10.39s, 3.66GB read Socket errors: connect 0, read 142, write 0, timeout 192 Requests/sec: 7143230.20 Transfer/sec: 361.04MB https://github.com/dpc/mioco/commit/3d7a78a88526758724558427d5b846e6fabce136 I was actually wrong, and the fact that `rust-event` was not using writeable notification, worked against it's performance. In mioco it's hard to even make a bug like that. :) 
Well, javascript is *the* language of the web. So of course it has a somewhat high position on the index. Objective C was *the* language of MacOS/iOS, and is only recently being replaced by Swift. Pascal/Delphi are still much used when it comes to delivering small cross-platform GUI applications. And I would think that inline assembly also counts as assembly. It may come as a surprise to you, but the vast majority of applications don't need a database.
they changed it and now it sucks! (for real though, i liked the minimalistic style with big font and no border better) /edit: the previous theme is [Pixyll](https://github.com/johnotander/pixyll) for Jekyll. (which probably lacks a pelican port: was TWiR a jekyll project before?)
This feels like misrepresentation. I believe Rust's standard library has code similar to C version inside. 
In fairness, he could have "just" been doing it as a project to learn the language, but of course he could have chosen something "easy" like the original NES if he wanted to do that.
There never were any concrete plans for replacing Gecko with Servo. What's more likely is a new browser based on Servo. Porting the old code to work with Servo is a _lot_ of work.
Hi! Most of the combinators do not care about input type, and the basic data type of nom, `IResult`, is generic over input and output types. The parts that are specific to `&amp;[u8]` are in [src/bytes.rs](https://github.com/Geal/nom/blob/master/src/bytes.rs). This is for parsers and combinators. For producers and consumers, unfortunately, the current implementation (as of version 0.4.0) only supports byte slices. There is a new implementation, faster, more convenient, and completely generic, that you can find in [the 1.0 branch](https://github.com/Geal/nom/blob/1.0/src/stream.rs#L263-L469). It lets you do exactly what you want, combining a consumer &amp;[u8] -&gt; [A] with a consumer [A] -&gt; [B]. I'll do a pre release soon this week. I still have a few things to check before the 1.0 release, but it is coming very soon! Thank you for using nom :) BTW, which format are you working on?
Those functions can be inserted directly, like [here in the MP4 parsing code](https://github.com/Geal/nom/blob/master/tests/mp4.rs#L148-L198). The macros can be confusing, and I'm sorry for that. But they make reading the code easier, and they abstract a lot cruft: data consumption, backtracking, lifetimes, types.
Obviously implementing the decoder is left as an exercise to the listener... :-P
Speculation: perhaps you could run out of memory (which is a panic) while doing.. well I'm not sure, I don't know if there's allocation during a panic outside of destructors. PS: it appears that on Linux (at least by default) it's [very unlikely](https://scvalex.net/posts/6/) that allocating memory would fail, but still possible in case of serious bugs.
Yes.
Yes, indeed. I'm using macros to generate the mentioned [newtype wrappers](https://github.com/jonas-schievink/sneeze/blob/db71ee02b294167cd45833e7b00afa6e2d0395df/src/byte_array.rs) (it even reimplements `Index` if you ask nicely), as well as [opcode dispatching code](https://github.com/jonas-schievink/sneeze/blob/e1b917b55d820959d1078e49fe357057a8f33ffc/src/cpu/mod.rs#L283-L428).
Oh yes! The incremental compilation RFC certainly took me by surprise, I wasn't expecting this so soon. You're all doing great work :)
Oh, great! It would shorten this function at half. Thanks!
I really don't like to code directly using `split.next()`, exactly because of what you said: the previous test for `count()` made the next test for `None` in `.next()` redundant (also because it's better to use [iterator adapters](https://doc.rust-lang.org/book/iterators.html#iterator-adapters) like [`map`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.map), etc). In any case, when you're sure the test makes no sense, you may use [`unreachable!()`](https://doc.rust-lang.org/core/macro.unreachable!.html): if split.clone().count() != 2 { return Err(ParseError::InvalidSyntax); } let name = match split.next() { Some(s) =&gt; s, None =&gt; unreachable!(), };
Can I ask whether you're viewing the post using a tablet/smartphone? I find the new style much easier to read, but I'm looking at it on a 15.6'' laptop screen, so I'm wondering whether that might be the difference.
It does handle credentials for AWS but it also handles accessing the Amazon services APIs (currently s3 and sqs), similar to the boto library. Needs some documentation though.
Great! Thanks a lot! I have to say though, that for me the one thread per connection version is significantly faster than `coio-rs` (even faster if I use a thread pool with 100 threads: https://gist.github.com/anonymous/2a4b80f229cc76670b9f) For the record, my results are * For coio-rs (with 12 threads, since my machine is a hyperthreaded hexacore workstation): Speed: 256412 request/sec, 256412 response/sec Requests: 7692378 Responses: 7692378 * For one thread per connection with 100 threads threadpool: Speed: 351474 request/sec, 351473 response/sec Requests: 10544220 Responses: 10544216 You may want to consider running your benchmarks on a Linux box if you're not, because threads are much faster on Linux than both Mac and Windows and most people run Linux servers. Also, while I didn't try this, it would be worthwhile running the bencher on a different machine since, as it is, it's pre-empting the servers a lot.
Barely looks different to me.
Sorry, my reddit client was buggy.
You are correct.
Hi, I decided to play a bit with your code and ended up with [this](https://play.rust-lang.org/?gist=8f53f105343bf7f648c2&amp;version=stable), it might or might not be useful for you. My goal was to not allocate an intermediate `String` (that is, I read the config and return slices, that are like pointers to the interior of the original string) and support multiple config types: a field `version` that accepts an `u32`, a field `how_happy` that accepts a string from 3 options and `offset` that accepts an `i32` (that must be even). Note that I use [`std::default`](https://doc.rust-lang.org/std/default/) in order to have a default value (eg: the default version is `Version1`), instead of special-casing this in the code.
While this is true, it's kind of missing the point. If you're writing a Ruby extension, you need to deal with UTF-8, as Rails is all UTF-8. If Rust helps you write that code better, that's a win for Rust.
Too far in the future to be sure. Couple of things that look likely: - Gecko slowly but steadily gets more Rust components - Servo forms a new browser - Servo forms a new browser, but is still called "Firefox". This seems likely especially on mobile. Servo as a "drop in" replacement for Gecko in Firefox doesn't seem very likely, not unless XUL/XPCOM/etc go away (XUL usage in Firefox is shrinking iirc)
&gt; It adds a needless indirection, in C I'd just have a big "struct emulator_context" that would contain everything and I'd malloc it at once in main() before calling the init code. Is there a reason why you can't create this struct in Rust? I'm not following.
Looks really cool! Feel free to open new Github issues if you need anything done in imgui-rs. I prefer implementing new features based on real requirements instead of blindly trying to go for 100% API coverage of the original library. Especially when some things in the original API don't directly translate to a safe API. I'm also very open to pull requests if you get the text input in a good shape :)
Cheating HTTP server. Hahaha. I should also try to do that with `coio`
Depending on how complex your config file is (or could get in the future), it might be worth looking into a parser combinator library like [nom](https://github.com/Geal/nom). I just finished watching this [strange loop video](https://www.youtube.com/watch?v=EXEMm5173SM&amp;feature=youtu.be) by the author where he talks about it, and it looks quite cool!
Sure, applications don't need a database, but inside companies there are armies of people writing SQL all day. Tiobe doesn't measure applications in isolation. Inline or not assembly being above visual basic and SQL is pretty crazy. I'm skeptical that Delphi and Pascal should be that high, but at the same time, Rust might be able to carve out some of that use with the right tools.
In a real project there's also the wise option of using an existing format, like [rust-ini](https://github.com/zonyitoo/rust-ini), [toml-rs](https://github.com/alexcrichton/toml-rs), etc.
Wow, thanks. It definitely will be useful for me. I will study your solution and try to tweak it for my needs. Most importantly, I learned quite a few Rust features solving this problem with your help.
Thanks for your input. Actually, this config is quite simple. I have a working parser in C++, and decided to parse it myself to see how Rust can help me with that. I discovered nom today too =) definitely will look into it.
Yeah, good point. This config is used in legacy project, so I can't easily change its format. I try to use toml on my next toy project, I like its syntax.
Can shared libraries be created with Rust? Also I don't understand why box is different than a malloc for a large state strict like you mentioned. Don't they both end up being one pointer to the heap?
It's definitely practical on GPUs and can be speed up, but path tracing is a bit difficult to map onto them. It's extremely parallel which makes it a good fit but a naive implementation also has highly incoherent memory access patterns, since rays bounce randomly all over the scene. New features like recursion in kernels and shared memory with host probably make it a bit easier. I'm not sure on exact comparison numbers, Nvidia has [OptiX](https://developer.nvidia.com/optix) lists a bunch of [GPU rendering partners](http://www.nvidia.com/object/gpu-ray-tracing.html) who maybe use OptiX or have their own GPU ray tracer. However there's also Intel's [Embree](https://embree.github.io/) which is crazy fast on the CPU, so currently I'm not sure if there's a clear choice of GPU vs. CPU. I stuck with CPU since I don't know CUDA :)
&gt; Can shared libraries be created with Rust? Yup. http://doc.crates.io/manifest.html#building-dynamic-or-static-libraries
Sounds good! I've been working on the text input in hopes of opening a pull request, it actually works now but is a bit rough. Some of it is due more to glium related issues, I'm not sure where to get the scancode for a virtual key code (time to read more docs) and for some keys (control, shift) we don't seem to get a virtual keycode, which is odd. When I get some time I'll go ask around in IRC a bit on this. When passing the characters to ImGUI we should also use [encode_utf8](http://doc.rust-lang.org/std/primitive.char.html#method.encode_utf8), I'm not sure if there's a stable alternative or if we should just wait until that stabilizes. Currently the char is just cast to a u16 to pass to ImGui, which isn't so good. I can open a work in progress PR if you want to see where I'm at currently and maybe provide some comments.
And Ignorance Is‚Ä¶ Unsafe?
really? the font is half as high, generic sans-serif helvetica/arial/whatever instead of a custom serif font, less line space, less whitespace, a close border appeared around the blogpost, and the footer became separated by border instead of shaded. the subscription box appeared and the date is monospace instead of italic. [this is the previous style](http://blog.servo.org/2015/10/05/twis-36/)
no, full HD screen. [this week in servo](http://blog.servo.org/2015/10/05/twis-36/) still has the previous style
Can you give a screenshot of what it looked like? I think it was reversed.
i at least filed a bug üòá
Here's my suggestion. * On `.post`, remove the `border` style, halve the `padding` and change `margin-top` to `margin-bottom`. * Remove "Like what you see? Subscribe!" and move the subscription box to the end of the article. * On `.site-header`, remove the `border-bottom` style and add `padding-top: 24px` (or so). Correspondingly change `.page-content` to share the same `padding-top`. * Make the background white again. I'm on a poor monitor ATM so that's maybe skewing my judgment, but it looks off. * Go back to unsaturated underlined links. If you care massively, [Medium has the gold standard of underlined links.](https://medium.com/designing-medium/crafting-link-underlines-on-medium-7c03a9274f9) Otherwise, just make links `#222` and clicked links `#666`. Then again, it's all personal taste anyway.
A bit out of order, but easy to hard: &gt; And even if I box the interconnect I'm not guaranteed that the constructor won't use the stack temporarily anyway, right? `Box::new()` _directly_ should optimize to placement new, right now. While it's not truly guaranteed, it's not really going to change. Using a temporary defeats the optimizer here though. &gt; And I don't want to box the whole interconnect because it adds a pointless indirection. It's going to end up on the heap anyway, right? Which indirection are you concerned about? Sorry if I'm missing something obvious, I haven't had the time to truly dig into your codebase, trying to get some work done at the moment.
OK, but what they had going looked more similar than now. i‚Äôm not sure about the footer, but i think most other details were the same.
Which? Which is your plan?!
War doesn't determine who is right, war determines who is left.
We have always been at war with Goceania.
I don't know whether the compiler inserts some special code when optimizing (since it's supposed to mark code that you guarantee that can't be reached). But you're right, `unreachable!` panics just like unwrap. I would guess that, if the compiler is allowed to omit the unreachable panic when compiling in release mode, then it may have a performance impact.
Great stuff, I couldn't think it could be so quick to create an os with graphical interface.
There's placement syntax coming, but it's not here yet. For the moment, a custom allocator would have to either return a custom pointer type *or* just a plain old lifetime-bound borrowed pointer (like the arena allocators do). This rather unavoidably involves at least one memcpy of the constructed value into position. Also, be aware that `new` in Rust is just a method name; it doesn't have any additional semantic meaning like it does in C++.
The only reason I want to use rust is for safety. This sounds good, but I don't know about the safety of it...
FASTQ is simpler to deal with since it has a fixed number of lines per record. To get a better handle on using Rust and a few libraries, I'm reimplementing an existing C tool before tackling my ultimate aim. This tool filters the records based on various predicates and maintains some statistics about what it's done. Records that pass are written out verbatim and not retained in memory. It's not complicated, but it's sometimes called upon for throughput in the range of hundreds of GB per day, so that's why I emphasize avoiding copies (or transformations like turning into a Nucleotide type). I want to read into a big buffer, narrow to a slice of that buffer, then write it.
Using absolute memory addresses is always going to be unsafe. Even with placement syntax. The only real advantage that placement syntax gives is that you don't have to first construct the value on the stack, and then move it into memory (it would be directly constructed in memory)
Cool project! But MIT license :( ? I hope Micro$oft or crApple will not take it and use it in their proprietary spyware :(
Super gross, platforms have terrible form widgets. :)
If they want to, let 'em. Open source should be open, for everyone. There's absolutely no reason for limiting the usage of the software.
[removed]
As /u/ticki_ said we already have `windows://`. In future it depends. If there lands user-space URLs then yes, probably that what will be visible for user and kernel will provide only `screen://` for communication with GPU.
Generally, we try to make use of the "Everything is an URL" principle as much as possible.
Shoutout to /u/jackpot51, he's the one [starting the whole thing](https://github.com/redox-os/redox/pulse).
I guess I sort of see a difference but it's not that noticeable to me.
Fantastic work! I suppose this is more long term, but have you folks given much thought on what the driver model will look like? From my experience in the Linux world things are a bit of a mess (see the graphics stack).
I'd guess it's probably "just" reusing existing linux binaries. Which is only possible because he implemented linux syscall compatibility -- just about the coolest feature. If the syscall support were truly complete, one would imagine that redox could end up being a higher quality OS (fewer opportunity for design defects and implementation errors), but linux would retain a market share advantage for a Very Long Time. The overall ecosystem: hardware vendors, users, distributions -- they define Linux as much as the kernel itself. (Indeed, it's much of RMS' argument behind calling it GNU/Linux). What might be interesting if redox could create abstractions that simplify porting to new architectures -- perhaps that might draw a better OS. Or perhaps if redox targeted the virtualization marketplace by implementing the virtio or supporting nested page tables, etc. Maybe there'd be some opportunity to formally verify redox.
&gt; when you see an URL you don't know if it refers to something in the internet or on your computer. This is a feature of URIs, not a bug :)
Someone will still have to wrap unsafe functions dealing with raw memory in safe interface with correct lifetimes and thread semantics. Redox [1] and zinc [2] has some code that deals with IO memory access, but it doesn't match your case directly. [1] https://github.com/redox-os/redox/blob/master/src/drivers/src/mmio.rs [2] https://github.com/hackndev/zinc/blob/master/volatile_cell/lib.rs 
Currently Redox can be run only in VM and them provide standardised virtual hardware so until we establish base of the system we do not focus on drivers. It is still long way to run it on bare metal.
I work on Oxide. We plan to port liboctavo. What is needed is porting of std and num. That said, the design of Oxide is not complete yet. You can come join us on redox-os slack channel.
Please avoid the mistakes of the systemd behemoth.
Oh hi small community. Sounds good!
Cannot reproduce problem. When I added http://www.redox-os.org/index.xml in FF everything worked all right. IFTTT also has no problem.
&gt; War is `unsafe` &gt; &gt; Freedom is Safety &gt; &gt; Ignorance is Type-checked (The new trifecta for rust-lang.org)
I think it is a myth that you need ECC-RAM for ZFS, it's just recommended in the environment where ZFS is usually used: servers. Any file system can be corrupted by not-working RAM. Sure, ZFS provides better guarantees for data if you use ECC-RAM than most other file systems, but that doesn't mean that it's worse than other file systems if you don't use it on ECC-RAM.
Nifty. Apparently AMD has a [ray tracing page](http://developer.amd.com/community/blog/2015/08/14/amd-firerays-library/) too (and it's [github page](https://github.com/amdadvtech/FireRaysSDK)).
How is "everything is a URL" better than "everything is a file"? Aren't they both just different ways to write namespaces? And if that's the case, wouldn't it be better to stick with the Linux established conventions like /var/log?
Thanks for elaborating. I somehow got the impression it was more of a hobbyist os.
Oh, ok. I will fix that. Thanks for the help.
Unreachable is just unwrap with a specific message, there's nothing special about it.
It involves a semantic memcopy, but I'd be interested to see if it actually happens at -O3.
You don't need to have a watcher or polling for a file interface. Via UNIX everything-is-a-file files are arbitrary modules that export a node, like Linux FUSE for example. In fact, under Plan9 sockets *are* files, so there really isn't much of a difference. I do like the idea of having URIs like Redox does, so that you can have a device handle another arbitrary path (`log://var/log`?), but it's not all that intrinsically better.
btrfs should be added second, imo. Reason: [Safenet](https://forum.safenetwork.io/)([maidsafe](http://maidsafe.net/)). If you do this, it will greatly help safenet and redox OS. Btrfs is a suitable enviroment for providing resource to the network. It allows hot swapping without having to drop the [vaults.](https://github.com/maidsafe/safe_vault) ~~Dropping the vaults means you lost the data, and somebody is taking your place. It can hinder your income for providing resources to the network.~~ I have been thinking having a basic rust kernel that does several duties required to establish the ecosystem. More secured, and less leaks. Then have safe network provide the rest of kernel scripts, or apps. It's like having a hypervisor inside of the safe network, and all of the apps are run from that hypervisor - anonymously. Safenet has a really cool concept, [unified datastructure.](https://github.com/maidsafe/rfcs/blob/master/implemented/0000-Unified-structured-data/0000-Unified-structured-data.md) It is encrypted file that holds key / value. Scripts can be run when user access to the data. This means you could easily run additional kernel inside of the safenet. With your proposal URI, it would look like this; &gt; safe://rustadditionalkernel/doessomething.rust Have some demon to run it in background. Key / Value fits really well with URI, and other schemes. All of the scripts that is run in safe does not effect your basic OS. This will remain your OS intact. If somebody managed to get your laptop, they don't know what apps you're running because everything you do is in safenet. It requires account information + pin. Which can be access from anywhere in the world. &gt;Also account creation and login happen only from Launcher, i.e. it is the SPOC (Single Point of Contact) for the SAFE Network. This means that no app gets to know user credentials and hence will never have any knowledge of a user‚Äôs MAID, MPID and other keys and cannot tamper with a user's login session packet which would otherwise be disastrous as the session packet contains all information needed to know everything about a user on the SAFE network - signing keys, encryption/decryption keys, data, etc Think about in a business where there are 1,000 computers/users that takes about 8gb for running window os. Thats 8,000gb. In safenet, it only needs one copy and million of users could access to it. We could save tremendously on footprint. Anyways, I didn't realized I turn this into a lengthy essay but I hope this would give you a lot more creative ideas on what you can do by using safenet for additional OS stuff which shouldn't be run on local machines for security reasons. 
So, when using Redox, will there be two URI namespaces? One as [defined by IANA](https://www.iana.org/assignments/uri-schemes/uri-schemes.xhtml) and the other for the Redox itself. Particular scheme (IANA or Redox) can then be associated with application which will handle it. For example when I will click on `udp` link in browser it will be opened in media player associated with `udp` scheme (assuming that `udp` means *MPEG Transport Stream over UDP* as defined [here](https://www.iana.org/assignments/uri-schemes/prov/udp)) and this will not conflict with another `udp` scheme [defined in Redox](https://github.com/redox-os/redox/wiki/Networking) because they are in two separate namespaces? Or will there be one namespace and this will lead to conflicts? I'm just trying to understand how is it supposed to work.
&gt; Box::new() directly should optimize to placement new, right now. While it's not truly guaranteed, it's not really going to change. Using a temporary defeats the optimizer here though. This isn't really true. I've never seen it happen myself at least, and e.g. you can see a difference in behaviour between [`Box::new` and placement-`in`](https://www.reddit.com/r/rust/comments/3npxw4/placement_allocation_in_rust/cvqjyoy?context=1).
Unix domain sockets are local (non-networked) sockets that are represented as files.
You certainly can get away with a timer, atomics, and mutexes, but probably not in real-time; the libco library lets you context-switch ten million times a second, and (I'm told) real kernel threads can't switch anywhere near that fast. I *think* most consoles have all the components running as divisors of some master clock, but the main processor is not necessarily using a divisor of 1, or even the smallest divisor. Still, if there's a master clock you can model the device with a state machine. There's probably consoles with components that run on completely unrelated clocks, but obviously the timing concerns would be much less strict because the historical software would already make allowances for variance. It's also worth noting that there are, for example, SNES games that are buggy on a small percentage of real, actual SNES units due to timing issues, so even if your emulator's timing exactly matches the hardware you're testing against, that still might not be enough.
Do you bellyfeel gcsoc? That is ++ungood!
I'd bikeshed even more: I don't see the value is having the abstract types be between `&lt;&gt;`. The issue is that this implies that these types are input types and alter the function (changing them would create a new function) which is not the case. I'd rather see the function declare that it has a type but is hiding it. Maybe something like: fn f&lt;T, U: A&gt;() -&gt; X&lt;abstract: V, abstract: W&gt;; If you want to you could also name them. fn f&lt;T, U:A&gt;() -&gt; X&lt;abstract B, abstract C&gt; where B: V, C:W; And allows you to do conditionals if you so want to. Basically abstract keyword would be used to declare a type that is hidden and which is only known to be the type. You could make it `abstract type` if you really want to but I'd rather the shorter abstract (or maybe type). I just feel the other two alternatives are not very intuitive. We don't put associated types between `&lt;&gt;`, we should see the function's output more like an associated type than as input types. In other words we should think of abstract return types as putting the next: pub trait AbsFn&lt;Args&gt; { // there could be impl&lt;Args&gt; Fn&lt;Args&gt; for AbsFn&lt;Args&gt; type Output: SomeTrait; fn call(a: Args) -&gt; Self::Output; } pub struct AbstractFunc; impl&lt;T, U:A&gt; AbsFun&lt;(T, U)&gt; { type Output: SomeTrait = SecretType; fn call(a:Args) -&gt; Self::Output {...} } As long as SecretType is not exported there wouldn't be a way to know what it is. So you'd be unable to name it as anything other as `AbstractFunc::AbsFun::Output`. Instead we could simplify all this into: fn&lt;T, U:A&gt; abstract_func(t: T, u: U) -&gt; abstract: SomeTrait {...} Which is simpler and makes intention clearer.
Please don't make fun of me, I went a bit overboard with [Option](http://static.rust-lang.org/doc/master/core/option/enum.Option.html) and [Result](http://static.rust-lang.org/doc/master/core/result/enum.Result.html): [my version](https://play.rust-lang.org/?gist=e6b0a3215c6f416011e3&amp;version=stable). Hey, there are no more `try!` statements or early returns... ;-)
I don't know how POSIXy Redox is going to be, but the daemontools family of service managers is definitely how *I* want to manage my services. Modern members of the family include things like runit, s6 and nosh if you want to look them up.
Shouldn't it be a protocol to the left of `://`? I don't see how `windows` or `screen` relates to protocols such as `http`, `ftp`, etc. The "everything is a URL" principle sounds cool, but I'd encode the system-related URLs differently.
Why? I really like Redox. It really seems like a cool project.
Apparently a lot of people got offended by this comment (-10 downvotes right now). Sorry, I did not want to be a jerk.
&gt; If MIT bothers you then why do you use Rust? Licenses are tools, there is no one license to fit them all. It depends on what you want to do with them. MIT is nice for programming languages but for operating systems at least Apache since it has all the patent retaliation stuff inside.
What exactly do you dislike about systemd and want to avoid? I kind of like it but I'm no expert :)
That is interesting. Mutexes are probably silly anyway in this context. If there is a master clock I think it could be done with just atomics. Loading from an atomic repeatedly if it hasn't been written to I believe should be very fast, I would be surprised if it ended up being any sort of a bottleneck when using an atomic uint64_t. Even accumulating atomic float32, where you have to use a spinlock and add, then compare_exchange actually ends up being about the same as a pow(float,float) with 12 threads on a sandy bridge cpu.
But `HEAP` is the only "place" currently defined and is hardcoded and special-cased by the compiler, right? In which case, I don't think that the fact that the syntax exists is especially useful if the feature itself is barely implemented. :P
Something I had in my dev directory for a while, it's a good alternative for XXHash, same quality (perfect score on SMHasher) and a bit faster. Benchmarks in repo and also http://imgur.com/olhGqhU and http://imgur.com/V8evli2
I am not opposed to optional GC. But I do wonder about crates.io fracturing into two sections. If I opt out of GC, I probably only want to use libraries that also opted out.
Yeah "Micro$oft or crApple" comes off as childish and snarky which probably doesn't fit very well with the spirit of the sub.
Yes, that's the only one defined in the standard library. But no, it's no longer special-cased (that special casing disappeared when the old `box` became `in`, I believe): the whole thing is driven via [traits](http://doc.rust-lang.org/nightly/std/ops/trait.Placer.html) which can be implemented to work externally now. E.g. this allows you to append to a vector by constructing the new element directly into the memory at the end of that vector: #![feature(placement_in_syntax, placement_new_protocol)] use std::ops::{Place, InPlace, Placer}; fn end&lt;T&gt;(v: &amp;mut Vec&lt;T&gt;) -&gt; End&lt;T&gt; { End { v: v } } struct End&lt;'a, T: 'a&gt; { v: &amp;'a mut Vec&lt;T&gt; } impl&lt;'a, T&gt; Placer&lt;T&gt; for End&lt;'a, T&gt; { type Place = Self; fn make_place(self) -&gt; Self { self } } impl&lt;'a, T&gt; Place&lt;T&gt; for End&lt;'a, T&gt; { fn pointer(&amp;mut self) -&gt; *mut T { self.v.reserve(1); let len = self.v.len(); unsafe {self.v.get_unchecked_mut(len)} } } impl&lt;'a, T&gt; InPlace&lt;T&gt; for End&lt;'a, T&gt; { type Owner = (); unsafe fn finalize(self) { let len = self.v.len(); self.v.set_len(len + 1); } } fn main() { let mut v = vec![]; // v.push([0u8; 8_000_000]); in end(&amp;mut v) { [0u8; 8_000_000] }; println!("{}", v.len()); } https://play.rust-lang.org/?gist=1b405e68ee0ca6a1e5c3&amp;version=nightly Like the box example that compiles and runs fine (and prints `1`), but the `push` line will overflow the stack.
This is a very good point, one I didn't really think of. 
Wow, that's cool. So what's left to be implemented? Is the Placer protocol specified and finalized? Are we just waiting for the syntax discussion to settle?
And [here's an implementation for arenas](https://github.com/SimonSapin/rust-typed-arena/pull/2)
Great! I'm always excited to see more hash algorithms. Any idea about the crypto-quality of this algorithm? Not that I can answer that same question for XXHash, sadly...
Hey awesome, usin' muh graphs!
I'd say it's poor, the structure is very simple. I was totally surprised it performed so well quality wise. The constants are all machine generated, you can read a little more details here http://www.jandrewrogers.com/2015/05/27/metrohash/
Thanks for those!
Mainly syntax, although I think there's a few tweaks to the protocol that might be nice to explore.
I can't find a link to the design of this "Everything is URL", so I don't know exactly what you're talking about, but designs like these are usually a bad idea. Everything that looks magic at first is usually a very bad idea. You're essentially encoding into a string what should be a Rust enum or a C union. This kind of design usually also has the consequence that you need to provide a generic getter and setter interface, where you pass the property names by string. In other words you are giving up strong typing and compile-time checks for weak typing and runtime checks. And since you probably can't correctly encode additional parameters in your URL (for example a list of authorized certificates for a network connection), your protocol may become a nasty state machine. 
It probably be rather `log://&lt;app name&gt;`. So to get your aggregator working you need to do `sed 's,/var/log,log:/,g`.
- All in one PID 1. I want to make it more modular via URL design of Redox - There is one tool to rule them all. To be honest it is kind of nice to have one tool that allow you do a lot of thinks in your system, but 134 lines of help? It is too much for human being. - Catch 'em all design principle. `fired` should only run other software when it is time for that and keep them running as long as needed. Left other stuff for other stuff.
That is exactly what I want to avoid. One of the few things done right by systemd is removing all complexity from configuration files and that will be my main principle. Configuration files should be as simple as possible and should contain no logic.
&gt; Oops now you need an OIBIT for Gc-traceability What would be wrong with that?
Epiphany actually was the browser which was renamed to Gnome Web. You see? It's hard to keep up with tons of names.
Awww‚Ä¶ yes. But still, it is CLI, not GUI. In GUI we can name it as we want (even "Mened≈ºer Pakiet√≥w" if we want to). CLI names should be unique among all most popular tools as fi someone port one of these to Redox then there should not be name clash. "Package Manager" isn't good term either for Googling nor for CLI.
Some friends raised questions about the meaning of this part: &gt; Learn from other init systems what not to do &gt; &gt; - be *NIX way, make one thing and do it good &gt; - depend on kernel only &gt; - do not bind to ‚Äúonly one true‚Äù libc Is it a list of things that `fired` plans to **not be** or to **be** ? I though the latter, but it's still written : "What to not be : the nix way" ...
- "`syscall` all the things" - some of the stuff accessible via file (URL in case of Redox) would require creating additional `syscall`s. Using files/URLs reduces amount of needed calls as you can use `write` for everything - "FFI all the things" - if we provide data only wia function calls then you will have to create FFI bindings for each of them. - reusing tools - if there will be as you say `get_cpu_ways_of_associativity(0)` how would you call that in shell script? New tools? Some built-ins added to shell? That would make, i.e. porting `bash` to Redox at least hard. - Why fetching information about CPU should have different api than reading file/socket? I don't see any reason behind that.
Your first three points are basically "programmers are lazy". Unfortunately I can't do anything about that. &gt; Why fetching information about CPU should have different api than reading file/socket? I don't see any reason behind that. Because you know that the informations about the CPUs will always be accessible, while a file may not. Because it doesn't make sense to choose blocking or non-blocking behavior when querying the CPU's infos. Because it should be clearly documented what the unit of the various informations is (for a CPU the frequency is obviously in hertz, but the general principle is that you either lose information or need some additional parsing). Because it doesn't make sense to seek the file that provides the infos. Because many of the errors that can be returned when reading a file's content don't make sense when it comes to CPUs. There are two philosophies that I think are good when it comes to programming: - Expose to the programmer all the corner cases and errors that can happen. Most of the corner cases of reading a file don't apply to querying the CPU's infos. - Make it impossible to have useless states or invalid states. Most of the state related to a file (seek position, whether to follow simlinks, etc.) don't make sense. 
&gt; First of all, /proc is always accessible as it isn't regular folder (and contains no regular files): &gt; About errors then I think that there should be none returned, so that is not a problem for reading file/URLs as it always return valid data. That's exactly what I explained. There is no error while reading the CPU's infos but there can be errors while reading a file, therefore the API for reading a file is not appropriate when reading the CPU's infos because the API can return errors. &gt; And still you haven't referenced to the last point - what about scripting? How would you get # of CPUs in Bash? You don't, or you use a function dedicated to this. If bash doesn't allow this, it's a problem with bash. Adjusting the API of your O/S to fit a scripting language is also a bad idea. &gt; EDIT: It also introduce more and more complexity into OS. It's the contrary. If you have `get_cpu_frequency`, you just read from a Vec and return the value. Dead simple. If you use `read` you have to dispatch to a specific module that handles all the special files and that must handle things like blocking/non-blocking, interfacing with the scheduler, etc. EDIT: &gt; About units then what is a difference between documenting struct field and documenting protocol field? If you have get_cpu_frequency(no: usize) -&gt; u64 then you still need to check documentation about unit. The difference is that you can return a `pub struct Hz(u64)` instead of a `u64`. Of course that depends on the exact situation and may not always be practical, but at least you have the possibility to do it. With a file you don't. In no circumstances. Let me give you another simple example. You want to modify a window's dimensions (since Redox seems to use `window://`). Do you prefer `set_dimensions(window: Window, width: u32, height: u32)`, do prefer writing two lines from a file (which is not really obvious), or do you prefer writing the width to one file and the height to another file? And if you use files, it raises several questions: what if you write only one value? When exactly is the window's dimensions modified (after each value or once both have been written?)? 
But X11 work exactly that way. Also Redox is [exokernel](https://en.wikipedia.org/wiki/Exokernel) so kernel will support 90% of usecases and when you will need other 10% (performance, advance OpenGL, etc.) then you are free to call HW directly. No harm done.
And we have that socket named `window://` or `screen://`. There is no difference except path, and that is what Redox is trying to achieve. We just moved FS socket to abstract socket. You send command via `window://` or `screen://` socket and you receive success or error. Just like in X11 (which by coincidence has terrible design).
You defended "everything is a file" by saying that Python doesn't require C code to access the API. But Python **does** need C code to access X11. X11 is absolutely not "everything is a file". EDIT: unless you want to reimplemented X11 in Python (which happens to be impossible because of a stupid design decision, but that's another topic). Reimplementing X11 in Python is far harder than having to write a small FFI binding. &gt; when you will need other 10% (performance, advance OpenGL, etc.) then you are free to call HW directly You are reaaally underestimating the complexity of a video card if you think that it's a good idea to communicate directly with the hardware for graphics programming. 
Is the four space indent idea effectively going out the window because half of everything is going to be aligned to the opening brace? From the last linked PR: - MethodDecl =&gt; ("method_decl", vec!("id","qualname","scopeid"), true, true), + MethodDecl =&gt; ("method_decl", + vec!("id", "qualname", "scopeid"), + true, + true), info!("({}) Could not find sub_span in `{}` in {}, line {}", - kind, self.snippet(span), loc.file.name, loc.line); + kind, + self.snippet(span), + loc.file.name, + loc.line); If `MethodDecl` is renamed or `info!` changed to `debug!`, there'll be extra churn? self.tcx.sess.span_bug(span, - &amp;format!("Container {:?} for method {} not an impl?", - impl_id, id)); + &amp;format!("Container {:?} for method {} not \ + an impl?", + impl_id, + id)); } Does the increased rightward drift and breaking up of everything longer than ~30 chars inside that `format!` benefit readability? 
I will clarify that in a second. When I was writing that it was late here and I could make some mistakes. My bad.
Thanks. Do you know if there are any hard cover books? Or should I learn it using the documentation?
Yes, Rust has destructors (see the `Drop` trait).
But for example what if you want to upload an image to serve as a background for the screen or a window, as a texture or whatever. How would you do that? I guess that you'd probably write each pixel one by one. But is the format RGB or RGBA? What's the width of the image? The pitch? To give these infos you need to write some sort of header, which raises the problem of the format of this header. All these problems also exist if you use a regular API, but they are strongly mitigated by the programming language. Just like it's much safer to write C than assembly, it's also much safer to use C than to write things manually to a file. The guarantees are stronger. The programming language already handles the ABI for you, and you're voluntarily bypassing this feature. In the end you'd just use a C API for complex things. And for me there's no point in maintaining a complex architecture of reading/writing to special files just to offer an alternative for simple operations. 
If anyone is still reading here: The meetup has been scheduled for Friday, November 13 at 7 pm. Hope to see you there! Link: http://www.meetup.com/Rust-Rhein-Main/events/225850710/
Why not just implement Into or From and use them as type parameters in the function?
Can you elaborate? Are you suggesting having Into and From as the *only* conversion traits? 
Feel free to print [my PDF version](http://killercup.github.io/trpl-ebook/)! :)
&gt; One can eliminate this code-size issue by having the function be a thin wrapper around a non-generic one: Couldn't this be solved by a compiler that is a little bit smarter, combining monomorphizations that seem to be doing the same thing?
What I don't understand is the difference between AsRef and Into/From... Is it just one by reference and the others by value? 
Some some random idea, what about using redox as an [unikernel](https://en.wikipedia.org/wiki/Unikernel) library? That is, given a Rust program that runs on Redox, compile a single binary that runs on a single address space, on top of Xen or another hypervisor. This kind architecture is perhaps suited for microservices. This perhaps could enable a whole-system dead code elimination at link time.
If you are into catching any errors that might happen while closing a file, you still have to close explicitly, sadly. I'd prefer the type system to force you to drop it.
HKT would perhaps solve that, at expense of making function signatures much harder to understand. On the other hand, it would enable us to abstract over `Rc` and `Arc` which are already used *now*, so it's a net win IMO.
Seems like the same basic idea. Given a function, break it into an inlined part and an outlined part. It's just that normal functions start off as "always outline" and generics start off as "always inline". edit: This is from a high-level perspective (e.g. if MIR were doing it). Of course, generic functions are materially different because the part you want to inline is legitimately different for different call-sites.
It is only a feature in certain contexts. 
Very interesting. Would it be possible to use this to train hash functions catered to a specific data set and key size? Does it scale down all to key sizes that are just 4 bytes or 8 bytes? Also technically the preferred hash could depend your read pattern. If I want the fastest hash for a particular data set, a hash that happens to hash values that are read frequently near each other in memory may have better cache performance. Can the analysis account for that?
I think the [Rustonomicon](https://doc.rust-lang.org/nightly/nomicon/README.html) should be linked too, it's more "advanced" but it contains *a lot* of stuff to understand how Rust *really* works.
It seems incredibly strange to take an AsRef type by-value. It seems to me both would explicitly take a reference (`p: &amp;T`), and as such `bar` would state `bar&lt;'a, &amp;'a T: Into&lt;&amp;'a str&gt;&gt;(p: &amp;'a T)`, but this is definitely pretty grody to read/write!
You know, you're absolutely right. The problem is that Unix created the 'everything' is a file abstraction and we now map URI's over that. If we didn't have pseudo mapping it wouldn't be a problem and this conversation wouldn't be happening. These mappings are intended to make networked filesystems "fit" the unix filesystem model, and I assume you know that. I'm not going to be a pedant over this. In a system where there is no 'filesystem' abstraction of networked resources, is this going to be a problem ?
&gt; It seems incredibly strange to take an AsRef type by-value. The standard path API does it: https://doc.rust-lang.org/stable/std/path/struct.Path.html#method.starts_with Note also that the `'static` bound is not contrived. In [GJ](https://github.com/dwrensha/gj) I have a method like this: fn write&lt;T&gt;(self, buf: T) -&gt; Promise&lt;(Self, T), Error&lt;(Self, T)&gt;&gt; where T: AsRef&lt;[u8]&gt;, Self: Sized where `Promise&lt;R,E&gt;` requires `R: 'static` and `E: 'static`. 
I imagine GC libraries will be used to implement generic mechanisms where ownership is naturally complicated. Then most clients will naturally be rusty code, mostly GC free, but opt in to manage these particular objects. For example, a read only cache of part of an object graph (with cycles, so RC won't cut it) used by multiple threads. Since the authoritative copy lives far away (file system, another computer) you only want to drop objects if no longer reachable from any of your threads. So either you use a GC library, or you implement something very near to it manually. The "neither necessary nor sufficient" quip is pretty fallacious, IMO: tasty tap water can be described the same way (cause I can drink bottled, and sometimes I do want tea), but its still pretty wonderful to have.
I've started doing the same recently, and it is awesome for long function declarations: fn parse_null_denotation&lt;'a, T&gt;( &amp;self, null_lex: Lexeme&lt;Self&gt;, grammar: &amp;T, token_stream: &amp;mut TokenStream&lt;'a, Self&gt;, current_led: Option&lt;&amp;Token&lt;Self&gt;&gt;) -&gt; Result&lt;Self::Output, ParseError&lt;Self&gt;&gt; where T: Grammar&lt;Self&gt;, Self: TokenType { //... } 
1. Run rustfmt 2. `git diff` 3. If there are changes, the module has not been rustfmt-ed yet*. 4. Commit the changes if you like them, else fix rustfmt! :) (* Or rustfmt was improved in the meantime.)
&gt;On a technical side, you _can't_ just slap GC into a language like Rust, since you can borrow references to objects that are on the stack. Managed languages have to segregate stack-allocated objects from heap-allocated objects at the language level (struct vs class in C#) or do away with stack-allocated objects and use excessive boxing (Java). Rust's full lifetime checking semantics have to remain in use reverb with a GC because of this, which obviates the need for a GC in the first place. I'm not sure I follow this argument. Go manages to mix stack and heap pointers just fine in a garbage collected environment. It uses escape analysis to determine whether it can leave a given object on the stack or if it needs to be on the heap. Rust has the advantage of being able to encode this at the type level using lifetimes. References work just fine with garbage collected pointers since the pointer is known to be pinned while the reference exists. Certainly there are technical challenges, that's just not a particularly intractable concern.
While escape analysis _works_, it's also really hard, as a programmer. I was talking with some people a week or two ago, and they've had to fight against escape analysis so much. Performance matters to them, and small changes which accidentally cause escape analysis to fail suddenly make a process that takes an hour take ten. So they ended up having to figure out why escape analysis fails, fix that, then leave a comment so that future people don't trip it up. Compare this to just being clear about when something is stack or heap allocated.
Sure - in C# you'd have to implement `IDisposable` on the parent class, then manually call `this.something.Dispose()`(and hope that your caller disposes you, as with any language except Rust) but that's got nothing to do with `using` statements, hence my question. I'm not trying to argue against the spirit of the article (or Rust in general) - I'm learning Rust and really liking it. 
I see. That's the kind of use case I'm targeting too :)
you can try https://www.safaribooksonline.com/library/view/rust-essentials/9781785285769/ https://www.safaribooksonline.com/library/view/oscon-2015-complete/9781491927991/part145.html (sign up for 10 day trial; no credit card required) but some content of book is outdated but better for understand concepts. However official doc is the best.
Upvoted. There's a back and forth here. We need to get `rustfmt` development going, while we figure out the style guidelines, so that we don't bikeshed things forever, but at the same time, we don't want anyone who pushes a commit to `rustfmt` to just decide the official style by fiat. Since `rustfmt` is designed to be customizable, I imagine that this process is more "set the defaults" rather than "re-write the whole thing."
We use `AsRef` by value sometimes for greater flexbility around ownership. It allows you to throw away ownership when only a reference is needed: ``` File::open(some_path.join("some_file.txt")) ``` We're creating an owned `PathBuf` here and then passing ownership of it to `open`, which takes `P: AsRef&lt;Path&gt;` by value. If we had taken it by reference instead, we'd be *forced* to add a `&amp;` in the above example, which is a bit of a paper cut when you really don't care about ownership. The key to making this work in general is the blanket impl: ``` impl&lt;'a, T, U&gt; AsRef&lt;U&gt; for &amp;'a T where U: ?Sized, T: AsRef&lt;U&gt; + ?Sized ``` which "lifts" `AsRef` over references, so that they can count as passing in by value.
&gt; That said, Into&lt;&amp;U&gt; for &amp;T would appear to have the same semantics, so perhaps this is moot! This is roughly correct, but if you do things this way you often have to use explicit higher-ranked trait bounds: `for&lt;'a&gt; &amp;'a T: Into&lt;&amp;'a U&gt;`. The `AsRef` trait moves this concern into the `as_ref` method, making it more ergonomic to bound over. And yeah, as you say the blanket impls vary here -- in particular, we need a "lifting" blanket impl for `AsRef` over references, as I mention [in a separate comment](https://www.reddit.com/r/rust/comments/3ntsbn/whats_the_point_of_asref/cvrdyxr).
Would it make sense to create a style-rfcs repo to track the accepted guidelines, discuss contentious ones and document executive decisions of endless bikesheds, with the expectation that `rustfmt` deviating from the accepted guidelines by default is a bug?
If bikeshedding in the main repo is acceptable, so be it. I suppose 'rfcs' was split out for a reason. The other point is: if a guideline not in the document, should `rustfmt` be enforcing it by default?
&gt; My point is just that there's nothing preventing a language from containing both stack references and garbage collection. :+1:
So overallocating memory will by default fail when you try to write to it? Eek, it seems much better to fail when fail at a place where errors are expected to pop up.
This is a "feature" of Linux, and it happens because the `fork` syscall (or nowadays, `clone`) do not allocate memory immediately, but only after you write to a page. This is called ["overcommitting"](http://www.etalabs.net/overcommit.html) and can be disabled (but typically isn't). Worse: since writing to memory and actually allocating a page doesn't give any mechanism for error-recovery, a program is simply killed as a result. (I mean, how to check whether a simple assignment `x = 1` fails while allocating memory? ). Because of this, I think the Unix model of "forking" a process is fundamentally flawed, specially a process that already allocated lots of memory. And in Linux, the "out of memory killer" won't necessarily kill the program that caused this failure, it will kill the program that has the worst ["OOM score"](https://serverfault.com/questions/571319/how-is-kernel-oom-score-calculated). The idea is that there probably exist a "resource hog" that should be killed, instead of killing a small program. For critical systems, of course, overcommitting should be disabled. (and IIRC FreeBSD doesn't have this "feature"), but one can also disable it for a particular process &gt; One other tweak which is applied is to add the value stored in each process's oom_score_adj variable, which can be adjusted via /proc. This knob allows the adjustment of each process's attractiveness to the OOM killer in user space; setting it to -1000 will disable OOM kills entirely, while setting to +1000 is the equivalent of painting a large target on the associated process.
https://doc.rust-lang.org/book/borrow-and-asref.html
&gt;If code tells on it, that code cannot be mixed with code that can't tolerate GC Latency, effectively fracturing the community. Not really - you can have thread local GC and then critical threads can be GC free while the low priority threads can use GC - and there are valid use cases for it - eg. integrating a scripting language with a GC and using Rust type system and compiler so that it can track GC references in rust code and mark them on stack instead of standard tricks for native interop like pinning. &gt;you can't just slap GC into a language like Rust, since you can borrow references to objects that are on the stack. I don't understand where this would be an issue - are you saying it's dangerous to move a stack reference into a GC-ed object ? Even a constrained GC ref type (eg. can only store owned or GC refs) can be useful. 
Just to comment that the [Rust code of conduct](https://www.reddit.com/r/rust/comments/2rvrzx/our_code_of_conduct_please_read/), the [code of conduct of RustCamp](http://rustcamp.com/conduct.html) and generally the environment of the community probably implements most of those measures.
this. I'd also add that GC should be looked at as a private case of a more general pattern of allocators. Bloomberg in their BDE allocators library deal with the same concerns but more generally. E.g if you have some data structure allocated in shared memory and used by multiple processes, you should not be allowed to store a pointer to memory in it since it'll be invalid in other processes. 
Once everything is under rustfmt control, then style becomes much more mutable. Changing a style guideline today for the whole repo is impractical. But changing a guideline once everything is rustfmt'ed is as easy as setting an option in a toml file. So, I view getting rustfmt working on the repo as a prerequisite to the discussion on official style, rather than the conclusion of it. My take-away from the RFC you reference is that getting agreement is hard. So in the short term, rustfmt should support all sensible styles, which it is working towards (it covers pretty much everything suggested in that discussion thread, for example). I intend to have more RFCs in the future to add more styles to rustfmt and to decide on defaults for rustfmt and the official style guide.
I was thinking of this, but rustfmt (and the rust repo) is evolving quickly and going over a module again often gives new results, so is not wasted effort. I hope that going forward we will start doing bigger and bigger sets of files at a time so overlap is less important. I'll start a checklist when we get close enough that overlap becomes a problem.
Further measures would probably be carried by the [community team](https://internals.rust-lang.org/t/announcing-the-community-subteam/2248) (it's actually a good thing that such team already exist with this responsibility). I don't know what should be done though.
&gt;Diversity is not just a PR campaign ‚Äì developers truly seek out different perspectives and try to understand their own privilege &gt; &gt;Code of conduct explicitly protects diverse developers, acknowledging the spectrum of privilege The whole privilege aspect really ruins this blog post. There's no reason for "privilege" to be involved in a developer community. If someone can contribute effectively, then they should do so, regardless of their "privilege". Otherwise it just devolves into a case of trying to be the bigger victim and shaming those who happen to have "privilege". EDIT: To clarify my argument is that I am against the use of the word "privilege" due to how much of a loaded word it is and how it is often used in an insulting manner. I prefer for the focus to be on accommodating those who are disadvantaged, rather than the "privilege" that people have.
Ok, thanks. Also - stupid question, I can't seem to figure out how to run rustfmt recursively over multiple files. I can only do one file at a time - is this intentional or merely my lack of knowledge?
The part about reverse-isms being ignored goes a bit too far for my taste. People need to understand that people will inherently be unequal in all walks of life. However, by defending one part of the community, and ignoring the fact that reverse-isms can exist, they undermine what they're trying to achieve. I'm all for welcoming new individuals to a project, but you have to treat everyone equally, or others will feel as if they are not welcome. By treating everyone equally, they all feel included in the community. Sorry if I took your comment the wrong way, but whenever I see that GH CoC, it rustles my jimmies... :(
I find the idea of a diverse community pretty exciting. I think Rust has benefited tremendously from having a lot of people involved from a variety of backgrounds, both technical and otherwise. And, in any case, every step that we take to make things more accessible for anyone winds up benefiting everyone. I don't think anyone particularly enjoys an acrimonious community, or particularly enjoys the feeling of wanting to help but not knowing where to start. I think we've done pretty well so far, but I found this list kind of exciting, because it offered a lot of suggestions, many of which I think we could do better with. I found the "succession planning" aspect pretty interesting, for example; that's something that I have wondered about from time to time, but where we haven't really made any effort to setup formal structure. I also think we could do better at documenting "easy" tasks. It's easy to throw up some cryptic notes in the issue tracker without giving a lot of context etc (*raises a guilty hand*). (Though the community team has been [hard at work on this](https://users.rust-lang.org/t/mentoring-newcomers-to-the-rust-ecosystem/3088), of course!)
&gt; If someone can contribute effectively, then they should do so, regardless of their "privilege" The point is not to drive away those who do not have privilege on some axis, it is about making sure that you don't accidentally drive away those who do not have it due to some sort of unconscious bias. I want _everyone_ who wants to use Rust to be able to use it. &gt; and shaming those who happen to have "privilege". Pointing out that someone has some form of privilege is not shaming. Pointing out that someone is acting in a way that is subconsciously biased often involves pointing at _why_ they are biased. Everyone makes mistakes in social interaction. The point is not to "shame" someone. The point is to recognize that humans have bias, and that sometimes, that bias causes us to do things that harm others, in various ways. 
Except for some less-common architectures, the pointer size usually matches the general register size, so `isize`/`usize` might be sufficient.
&gt; From my perspective, one of the greatest strengths of Rust -- an area of its greatest potential -- is empowering people to do systems programming who might not have otherwise tried to. Part of this is technical, but a lot of it is social, and it starts by recognizing the diversity in backgrounds and, yes, privilege that we all have. For this point in particular, I don't think that the voice of people without a lot of experience in system programing should have a too big impact in the leadership of Rust when it comes to the design of the language. For example many people who try Rust were taught object-oriented programming at school, and if the design of Rust was a democratic process, the language would probably have inheritance today. It's a good thing to take suggestions, but I'm glad there's a core team that knows what systems programming is and that has the final word. Otherwise I'd fear that Rust would become yet-another-boring-language. 
I'd like to think that section is just pointing out that racism is racism no matter who's doing it, and not something as stupid as the idea that minorities can't be racist, but I'm pretty sure I'd be wrong. feel like that section is mostly a convenient way to shutdown discussions people don't like. I do feel like most of the non-privilidge points are pretty valid. People with children are incredibly common and it'd be nice to help them out. I think I'd consider everything available containing mushrooms or lactose a shitty thing to do, as well as not having vegetarian options. These are all common and easily met preferences. I don't drink so it may just be my personal preference, but I do think a conference that doesn't encourge any drug use is more welcoming than one that does. I wouldn't expect people to be turned off by a conference not providing/encouging use of their drug of choice, but I would expect people to be turned off by a conference encourgaing the people around them to get fucked up. It's not like I think these should be enforced somehow, but I do think they're easy wins for being more welcoming.
Do you know if its available as a single page book so i can use send to kindle and read it as an ebook?
I don't think anyone's suggesting that language design be put up to a vote. It is in fact exactly issues of diversity and inclusiveness that are the hardest to implement by "democratic process," because the majority of people in a community are necessarily people who haven't been disincluded in some way. And of course, "systems programming" isn't the only skill the core team needs to have to lead Rust effectively. Language theory is an obvious other technical area, but things like empathy and social awareness (which the core team members who've posted on this link have demonstrated in spades) are also necessary to build the sort of strong, welcoming community that increases adoptions and provides good feedback for the design process.
As someone who doesn't drink coffee or alcohol and who doesn't care for any children, paying for child care seems like hands-down the best thing to fund of those things (and I don't mind that my conference money pays for any and all of them).
Thanks for the replies! This all seems reasonable and I agree that getting a consensus will often be difficult. Just note that I had to bring up the indentation issue here for a lack of a designated place (it's not like a lot of people will see a rustfmt issue). It's somewhat surprising (and is thus not easy to guess) that you're willing to churn the repo while working out the style.
But what if some app needs something beyond what you've allowed for? If you allow no scripting and have no programming language, you're forced to extend your conf file with one thing then another ... and then where do you end up? I certainly can agree with the aim of keeping things simple, but what if real life does not permit that? (I recollect some painful experiences with scons, which makes building so so easy ... until real life forces you to try and do something a little unusual. Then the simplicity gets right in your way because there is no flexibility. So instead you have to hack the source of scons itself in Python or try and write extensions pulling stuff right out of its guts to get it to work. If only the project in question had stuck with gmake, a fix would have been trivial! So simplicity risks creating enormous complexity and difficulty.) But good luck anyway. It would be great if you can pull it off.
Being exceptionally friendly is huge. I posted the first thing I wrote in rust here somewhat recently and had like 4 review the code and make useful suggestions or pull-requests. That kind of thing is huge. I only really felt comfortable posting the code to begin with because I'd seen how helpful people here are. 
I'm starting to feel like I just shouldn't have responded to that point. I disagree with various parts, and agree with other parts, of the arguments against what I've said. Child care is not something I feel that strongly about. (Putting this here but it applies in various places).
&gt; Rustfmt does prefer a more spaced out (vertically) style. I believe this improves readability (it does for me at least). Here I'm not questioning the spacing out vertically itself (it seems a matter of taste, when done with care) but the runaway indents. From my experience having indents depend on the length of some identifiers and expressions is too annoying for the good it does. It adds noise to the diffs. Would these changes not be better off with a standard indent (actually not sure about `MethodDecl`)? self.tcx.sess.span_bug(span, - &amp;format!("Container {:?} for method {} not an impl?", - impl_id, id)); + &amp;format!("Container {:?} for method {} not an impl?", + impl_id, + id)); } The 1st argument to anything seems like a red herring.
&gt; vegan and veggie (and paleo, halal, kosher, etc.) is. Which is significantly different from the the OP said already, in that you are trying to include as many groups as possible. Unless food is going to be a major event at the conference, I feel it's not necessary, but this at least isn't inappropriate in the same way to me. &gt; Alcohol I actually prefer dry/dryish events, but that doesn't make it part of a welcoming community. Your later points expand on this better, and make a somewhat convincing argument you should consider this.
&gt; developers truly [...] try to understand their own privilege Well I would say that making "a good community" starts by making it inclusive and not opposing one part to another, especially with a concept often misused like "privilege" &gt; Child care is not the conferences problem at all, it is the parents. Here I disagree, if one wants to make it easier for people with children to come, having a daycare (if feasible) is a very good idea. 
My problem is that it so often feels like a motte-and-bailey thing[1]. Everyone's saying it's not shameful, but then doing everything they can do to make it clear they themselves lack privildge and indeed are incapable of having privildge (see the reverse-isms in the code of conduct linked elsewhere in this thread). I'm not saying it's always like this, but the problem I feel is that there aren't many cases where acknowleding privilidge gets you something more than simple policies that embody civil discource. I feel like it just gives people more ways to avoid discussing actual problems by accusing people of being privileged. I'm sure someone could easily counter my thoughts by simply saying I don't see the problems because I'm privileged, without really addressing what those problems are. [1](http://slatestarcodex.com/2014/11/03/all-in-all-another-brick-in-the-motte/)
Ehh I was playing a bit fast-and-loose here. Generics are monomorphized based on the types, so you can end up with lots of one-ofs which will be strongly favoured for inlining. Meanwhile concrete fns aren't even candidates for cross-crate inlining unless they're marked with `#[inline]`. So basically analysis for normal fns needs to justify deciding *to* inline them (perhaps partially), and analysis for generic fns needs to justify *not* inlining them (perhaps partially). 
I think my biggest problem when people talk about the varying levels of priviledge is that it seems like it usually looks at gender and race as the deciding factors for how much "priviledge" you have. For example, last year the organizers of Gophercon posted on their site that the submission period for talks was open, and that in the interest of diversity, if two presentations were considered equal, the presentation that wasn't submitted by a white male would be chosen. So their way of dealing with potential discrimination and lack of diversity is by using the submitter's race and gender as selection criteria. It seems completely counter-intuitive to generlize someones level of priviledge based on their race and gender, while also ignoring other factors, like economic background, schools availabe where they were raised, etc. This creates (hypothetical) situations where a poor white man could have his presentation denied in favor of an asian presenter who comes from a wealthy family in an effort to increase diversity because the white male is more "priviledged" than the minority asian presenter. Full disclosure, I'm a white male who was raised in a middle class family in the suburbs, but my wife's (non-hypothetical) femal vietnamese friend from a wealthy family that paid for her entire college education, her car, and her house in an upper-class area, is considered less priviliged than I am. I think efforts to create diversity should be focused on outreach and accessability instead of artificially increasing diversity by giving certain groups advantages or enforcing high turnover rates in leadership like the article suggests. Creating diversity by giving specific groups an extra advantage just creates resentment towards the under represented group by the majority, at least in my experience. Sorry about the long post, I actually agree with everything you said, but it seems like a lot of efforts to increase diversity just end up focusing on superficial differences like race and gender, while ignoring things like economic and educational backgrounds. Also sorry about typos, I just realized that spell check isn't working in my browser :P
Alternative answer: you can `Deref` to only one other type, but you can `AsRef` to many. So if you have a `MyType(String, i32)`, you could e g implement `AsRef` for both `&amp;String` and `&amp;i32`, but with Deref you'd have to choose one of them. In std today, `Deref` is more widely used than `AsRef`. Unfortunately, there's [an issue](http://doc.rust-lang.org/nightly/src/core/convert.rs.html#124) that causes `AsRef` to be much less useful than it could have been. [That issue](https://github.com/rust-lang/rust/issues/23442) has recently been closed, so maybe this can be revisited?
There is an option to use block indenting rather than visual indenting. I take the latter as the default because that is what we mostly do in the Rust repo already (I've generally gone with emulating existing style, rather than innovating). Personally I prefer the visual indent, but that is probably just because it is what I'm used to seeing. I don't care too much about noisey diffs - I find it doesn't make much difference to me when reviewing or searching history and I find visual indenting easy for the eye to follow. But I think it is reasonable to disagree, thus why there are options.
It's a common sentiment and I'm glad you voiced it, even if my response was stern. I just wanted to say that it is leaky and problematic and many of the arguments in that space are. I also think it's to some part a problem of the event organisers: we are rarely transparent about how much effort/cost something had. One of the things we should always keep in mind is that conferences are very often operations at least in the 5-figure range. Edge-cases are rare and can often be easily covered. We think too much about those, while "oh, you have problem A? Here's the 50 Euro to fix that" is often the best, smoothest and happiest solution for everyone.
&gt; Unless food is going to be a major event at the conference, I feel it's not necessary, but this at least isn't inappropriate in the same way to me. Well, as a host of a conference, I feel closer to chefs then to programmers. It would hurt my personal pride if I couldn't serve a wish. Most people are easy to serve. It's not too hard to have bandwidth for 20 people with special concerns, once you come the point to stop questioning them on every step :).
Just picking the register-sized-integer won't guarantee that your operation is as fast as possible. For example, if the computation you're performing can make use of SIMD registers/instructions, it can be made quite a bit faster. But it is hard to say without details on what you're going to do with the number.
Linear types. They force you to consume them at some point. For example, Files currently have explicit `close`, which does the same as Drop. Rust currently only has affine types, which can be consumed _at most_ once. See https://internals.rust-lang.org/t/std-fs-tempdir-ignoring-errors-on-drop/1662 for a deeper discussion.
Does Rust support x32?
&gt; AIUI, this isn't much extra work to handle, though /u/fgilcher probably can answer that question better. It's literally a free text field in your registration form and a caterer that doesn't serve fish to the vegetarians. (yes, things fail, sometimes to hilarious effect, and people will not be angry about it)
Diversity is something that should happen naturally, not something that should be forced. It's a side-effect of reaching the goal, and should never be the goal itself. If you try and force it, you'll just end up with lots of hostility from the "non-diverse" members of the community (I don't really need to source evidence for this statement, just look anywhere on the internet), which in the end will result in no diversity at all.
https://llvm.org/bugs/show_bug.cgi?id=13666 is marked NEW. Once it‚Äôs fixed, I‚Äôm guessing it‚Äôs only small changes to rustc, if any.
While they may agree, I don't know that it is ever taken into account. In the example given, they did not look beyond gender and race.
Doing 1 or the other always is too rigid. For example, clang-format will do either on a case by case basis using a scoring system.
resize is marked `[inline(never)]` exactly for this. However you don't need to outline to avoid trashing the icache. If the branch is believed to be exceptional, its intructions can be moved to the end of the function.
IIRC, Go automatically upgrades all values to which references are taken to heap-allocated ones (though obviously escape analysis can perform the same feat, and my information on its implementation may be outdated). In general, pointers *from* the heap to the stack are not a thing in GC'd languages, while they can be in Rust.
I really don't see your point. I also don't see what "natural" and "unnatural" is in that context.
There's a whole lot of anecdotal evidence that diversity flourishes in projects that take steps to encourage it, such as the ones described in the original post. That hardly feels like forcing it to me - it's simply taking deliberate steps to foster an inclusive culture.
Hmm sounds like the same problems faced with auto vectorization. When it is a necessity it ends up unfortunately ambiguous what the compiled version will be like.
Yeah, it's very similar.
I'm not entirely sure I understand what you're saying, but I'll describe my understanding of Go's implementation in case the two aren't consistent, since my first impression of what you said didn't seem right. Go doesn't distinguish between stack values and heap values at the language level. Local variables can be on the heap, and `new` can return a pointer to the stack. Taking a pointer to a variable does not invariably put it on the heap. Instead, the compiler analyzes each function and generates metadata about where each pointer passed into it can escape to, which callers then use to perform the same analysis on their own parameters. A caller can then use that information to determine whether a given value it creates can escape, and decides whether to put it on the stack or the heap on that basis (it also might put something on the heap that doesn't escape if it makes sense to, such as large or dynamically sized allocations, but that's more a matter of optimization than correctness).
Are there any papers or articles on the subject that you'd recommend? I hadn't heard that term and would like learn more about the topic.
&gt; Certainly there are technical challenges, that's just not a particularly intractable concern. Actually it is intractable unless you sacrifice separate compilation. Perfect escape analysis requires a global, interprocedural analysis. Unless you can lift the requirements into function signatures there are fundamental limits on how far you can go without sacrificing separate compilation.
[The Master's Tools Will Never Dismantle The Master's House](http://muhlenberg.edu/media/contentassets/pdf/campuslife/SDP%20Reading%20Lorde.pdf) is probably the most widely read essay that is relevant (though it doesn't use the term 'intersectionality'). It was written by Audre Lorde in the 1980s in response to feminist theorists who did not take into account the way that race, class, and sexuality cause different women to have very different experiences of gender.
Looking at that (and the api docs) are what prompted the question! But I was looking at the stable api docs. The `Hash`/`Eq`/`Ord` constraint to the `Borrow` trait is only explicitly stated in the nightly. (Shout-out to you for adding that note two months ago. Thanks:})
So is there something we can do to make that part more clear? always looking to improve the book :)
&gt; trainwreck of a community/diversity thread just after the 1.0 release Do you have a link to that still? I haven't read it and I'd like to.
The problem I'm referring to in this case is having a language containing both stack references and garbage collection, not escape analysis. I'm not sure why so much focus has been out on my mentioning escape analysis in the context of Go. It was just an example. I'd think Rust would lean on the lifetime/ownership system for this, which allows you to "lift the requirements into the function signature", as you mentioned. 
Whether that was true at some point, I'm not sure. Certainly the escape analysis has been iterated on. However, the main (non-GCC) Go implementation definitely does use escape analysis in order to determine where to allocate values. There obviously are limitations, since virtual dispatch is essentially opaque to the kind of analysis Go uses, but otherwise, Go can make use of stack references fairly extensively behind the scenes. You can use compiler flags to see the results of the escape analysis (`-gcflags=-m`).
The idea of including newcomers in leadership meetings is an interesting one. One of the coolest aspects of being involved in the Rust community, and my internship at Mozilla with y'all was getting to acquire a lot of knowledge by observation. You learn a lot hanging around smart people talking about hard problems. It might be interesting to invite more people to the libs team meeting, partly as an onboarding initiative? We end up spending a lot of time providing background in the meeting anyway, so you don't necessarily need to have a hardcore libs design background to follow along.
The TL;DR is basically "privilege is an N-dimensional problem, not a one-dimensional one." Geek feminism has a good page: http://geekfeminism.wikia.com/wiki/Intersectionality I usually don't really like Wikipedia, but the first bit of https://en.wikipedia.org/wiki/Intersectionality seems good as well. /u/desiringmachines also provided an excellent link, for sure.
Having a non-static lifetime means that the type contains references to values on or owned by the stack. You can't pass such values to another thread because those references will almost certainly be invalid by the time the other thread tries to use them. To solve this you need to either pass ownership to the other thread, by using an owning type such as Box, Vec or String, or use an Arc for shared ownership across the two threads. Before trying to bypass the compiler's safety checks, first make sure that the compiler isn't stopping you doing that for a good reason. In this case a `'static + Sync` bound is absolutely essential for correct behaviour: it shouldn't be too awkward to meet that bound, so feel free to ask for help with that.
&gt; Before trying to bypass the compiler's safety checks, first make sure that the compiler isn't stopping you doing that for a good reason. Nomination for quote of the week?
It's safe as long as you're absolutely certain that you `join` the thread before the end of the scope that the variable is in. The `unsafe` backdoor to do it is to use `mem::transmute` to turn a reference to the stack variable into a static reference, understanding that by bypassing the compiler, it's all on you to avoid use-after-free.
Holy shit you were right; That whole thread was pretty aggravating. I'm pretty glad I didn't see that thread earlier; I'd probably be banned by now, haha!
Another aspect is that a conference wants to encourage as many people as possible. One way of doing this is to make things as comfortable as possible for as many, and as diverse, people as possible. Diversity is useful as it makes it more likely your own points of view will be challenged, which makes for more varied insights or perspectives which may benefit your work. If having childcare allows a few people (who, statistically, are more likely to be women) to go who would otherwise find it too much of a hassle, then that's good. If having vegetarian food causes a few people who went last year and won't bother this year because they ended up hungry half the time to change their mind, that's good too. These things don't have to be the purely utilitarian soviet concrete housing block-style events, you can make things nice for your attendees and people enjoy it more. Obviously, this must be balanced: you can't have a lazyboy chair for everyone^1 , but most things aren't a real expense (especially as things can be cheaper at scale.) ^1 a [conference I attend](https://www.kiwicon.org/) has high-roller tickets, where people bid for a set number of places. These people sit at the front in lazyboy chairs, have knitted themed socks, special badges, champaign, etc. But there's only a few of them :)
Keep in mind that "forcing" is the wrong word for what's being talked about. "Making it easier for it to happen" is a better, if more awkward, phrase. It not like (hopefully) you're kicking out a white man to drag a MƒÅori woman in, it's that you're tweaking the environment to make it more likely for her, and others, to join by loosening the cliquey walls that naturally form around a group of like-minded people. So, in reality, it's more natural as you're reducing the artificial selection of who joins.
Just based on those addresses, that's probably coming from libc or the elf interpreter (ld-linux.so)? One thing you can do on linux is to cat /proc/&lt;pid&gt;/maps to see which modules are loaded where. If that's too hard to pull off, then sometimes ldd &lt;your program&gt; can give you enough information to track it down. There is also the program addr2line. It takes an address and looks in the (debug) symbols to try to tell you were it took place. I don't know how rust implements stack traces, but it's possible they use different ways to figure it out? Maybe?
&gt; In the context of D specifically, much of the problem is that the GC is opt-out rather than opt-in. Among other things, it means that, by default, any D library you try to use will probably be using GC even if it doesn't technically need to be. As a hard realtime (robotics) programmer, this is why I chose Rust over D. The impression I got when I investigated C++ alternatives is that yes, you *can* use D without GC, but you wouldn't want to.
I don't believe it is on anyone's radar, but I think it should be. Yes, rustfmt will do some slightly fancier things than that such as remove unnecessary braces from closures and imports, reorder imports, etc.
lol
&gt; I'm motivated to ask them directly if an official sdk for Rust is in the pipeline. Let us know if they say yes. :)
haha
&gt;I'm actually against that. Leadership should go to those that want to lead and make things happen. Seniority is not necessarily a part of it. Heck, you don't even need to be a programmer. If a non-programmer wants to be a "leader" in an open-source project they can learn to code and contribute like anyone else. We have to deal with people who couldn't print hello world often enough, why should we have to listen to them in open-source? Open-source is a meritocracy, you have to have the skills to back up your ideas.
The problem is that people with privilege granted by background tend to be the culprits of exclusivity within online and FOSS communities. Ignoring the problem just lets people who don't ignore it get away with exclusionary behavior, like belittling over perceived intelligence, which is something that runs rampant across the Linux ecosystem. By and large, this includes the standard minority representation issues -- men often see women in tech as implicitly less intelligent unless proven otherwise. This is readily apparent in the words and behaviors some men use toward women online, whether you see it or not. It happens more often in private dialogue. Ignoring it doesn't make the problem go away.
You use this word "forcing" as if it's even possible or implied that you could force diversity. It is indicative that you have unmentioned feelings about this topic. The point is to be _welcoming_ in a historically hostile environment for people who haven't been represented well in it. The implied environment for most minority groups is one of belittling, condescension, and sometimes outright hostility and harassment. That is why rules and community moderation have to be _explicit_ in how they handle exclusionary behavior.
Is she the one that got so offended by Torvalds swearing, that she made a big thing of quitting LKML? First of all: Rust community is great and you are all very helpful and nice! Some basic code of conduct is fine and keeping good community vibe is a good thing. You're doing a perfect job at it! I am actually posting this using throwaway account as I'm a bit afraid of some people labeling and ostracizing me, that I even dare to have different views than everybody else. Say something politically incorrect, and have people trashing my github issues, or boycotting my hard-worked-on libraries. The same people that are "so tolerant", except when you dare to disagree with them. Especially in the light of previous Mozilla CEO thing, which was utter liberal ridiculousness (IMO, IMO! don't get too upset). I'm afraid that it all leads to infecting software development with social justice agenda, political correctness policing and other ridiculous stuff that it's getting everywhere nowadays. Where more time is being spend on debating "diversity" and "racism" than getting things done. Wasting time couting how many people are which sex, how many are gay, changing "he" to "she" in documentation. I already seen on irc someone asking a some stranger to change nick from "idiot" in the name of someone being offended. (I still don't undersdand why anyone would get offended ...) . Stuff like this just leads to ostracizing people that are not aligned with mainstream liberal views. As open source developer, I don't care if you're a woman, man, minority member, white, straight, gay, if you're a anarchist, republican, democrat, if you were raised in poor neighborhood, or rich neighborhood, if you're liberal fighter, or white supremacists. I don't really care - most of you people I unfortunately won't have even a chance to meet in person. Just don't bring your political agenda with you, pleeeease. I'm not participating in Rust community because it's most friendly one. D community was very nice too. I'm doing it for technical reasons. I care about you helping me get stuff done. And I think both being too concerned about personal feeling and offending someone, and being plain arrogant and offensive are as bad. They are just distracting from what is the goal. At least my goal. Kind of out of topic, I think Linus Torvalds is managing Linux community very well, and Sarah is just not "getting it" and making a big scene and possing herself as a "victim" of some tremendous crimes. Linus yiels and swears at "his people" - which he has deep, important relation with: maintainsers and such. As a occasional Linux contributor, I don't see problem there: noone every bashed me for my own, sometimes stupid mistakes on LKML. Linux kernel community is completely unlike Rust community: it's one huge project, shared by millions of people and companies, with business pulling their own agendas, etc. Managing it must be like herding cats via email. And if someone is not cut to fit into this "management style" it's OK. Just don't play the victim card. When I quit my job because I don't like the management style, I don't make angry posts about it. Do you? Leaving this for some laughs, and to conclude my point: https://www.youtube.com/watch?v=fHMoDt3nSHs
&gt; Open-source is a meritocracy, you have to have the skills to back up your ideas. *cough* If open source were a meritocracy, we'd appreciate that there's non-coding work and reward it. For example, a lot of frontend-oriented open source projects suffer because there is no one who wants to take on design/UX work. Why should they, with stances like this? Also, why do you put "leader" in quotes? I sadly can't read this as any more then "real programmer"-style boundary policing.
&gt; Yes, this is a fairly absurd analogy I don't think it is absurd in any way ‚Äì you captured the concept perfectly. Also most people here who have problems with the word "privilege" probably at one point have been asked to "check" theirs. I know I have, from people who just wanted to shut me up. In such cases, I just answer "Whew, it's still there, you got me worried for a moment". However, this shouldn't keep us from *really* reflecting on the ways we have it easier than others, and thinking about we can make this community better to include more of those who lack those advantages.
Natural refers to acting like a considerate human being such that everybody feels welcome and discussions like this would never need to happen. I understand that this isn't an ideal world, but we can get close enough without having to treat any group differently (for better of for worse). Unnatural refers to treating minorities or "diverse" people as special, which can cause issues and make the whole situation worse. Exclusion can go both ways. I was mainly expressing disagreement at part 5 in the blog post (as it seems several others here have done also). I more or less agree with everything else.
&gt; Natural refers to acting like a considerate human being such that everybody feels welcome and discussions like this would never need to happen. I understand that this isn't an ideal world, but we can get close enough without having to treat any group differently (for better of for worse). This is not natural, but idealistic. Also, a group of considerate human beings can be a very terrible thing if they don't care about listening/adapting (which often happens). &gt; Unnatural refers to treating minorities or "diverse" people as special, which can cause issues and make the whole situation worse. Exclusion can go both ways. The whole point of this is: if you think everyone has equal access and they don't show up, do research. Very often, there are reasons for that, including "I don't feel wanted/welcome". It's about working against those sentiments and ensuring they have no actual basis. Also, some people _need_ to be treated special, because they have special needs. That's the whole point of accessibility discussions. We had a huge upswing in people with disabilities in the speakers roster at eurucamp when we actually announced that we have an accessible venue and someone from the organising team was their direct partner over the whole weekend. An that's the crux of part five: it's about outward motions. Without that, the whole thing is void and we can argue normality for the next five years while waiting for a change. There's a balance to be found, I agree, but positive action in many directions is necessary. For example, eurucamps speakers roster distribution directly maps to the distribution of groups in the CFP - and the quality of submissions does not differ much between them. The fair approach to this is to encourage those that don't feel like they are welcome _to submit_. They won't get their slot for it. The natural way of things is that people get told they are not welcome by many factors, including society, other projects, other communities, other conferences. These are the effects you have to work against, even if you are convinced that your doors are open to everyone. We work on stated problems. The solutions are not always fair in every instance. e.g. courses for women are not _fair_, but without them, many don't feel spoken to. Running them has given the Berlin Tech Scene a huge amount of potential, though. You can play this game very long. Why do turkish people in Berlin not show up in the tech scene? How about making things for them. We are missing out on great people with a lot of talent! Finally, I find distinctions into "natural" and "unnatural" harmful and - given my nationality and upbringing - very problematic, to put it mildly. I'd take care with such wording.
You have no idea how disappointed it makes me to read your comment. It feels like watching years of work go up in smoke. Dismissing people trying to make a programming community that's more welcoming to marginalized people as "SJWs" involved in "PR", talking about "reverse racism" and making false equivalences between outreach activities and *gamergate*, of all things, is not ok. Those are the community managers here and the very people who set up the project. Who do, yes, hold those beliefs sincerely. I would strongly prefer people with this attitude simply leave, go find a community full of thick-skinned, tough-love dog-eat-dog programmers who enjoy a good argument. Goodness knows there are hundreds of such communities who would be happy to have you. This community was built to be compassionate and welcoming, and doing that takes concerted effort, a willingness to make a priority of it. If you speak of that effort as "victim mentality", you're doing the community a disservice.
Also read [Meet Safe and Unsafe](https://doc.rust-lang.org/nightly/nomicon/meet-safe-and-unsafe.html) in the Rustonomicon.
Yeah, that would work too, though I think they're heavier (?).
&gt; Some thoughts I have had can be found here: https://redox-os.org/ It gives "connection refused"
* [Systemd isn't as monolithic as some claim](http://0pointer.de/blog/projects/the-biggest-myths.html) * Where do you get that number from? * Since you aren't bound by the idiosyncracies of Linux, I guess you can move things to other services that on Linux are part of the systemd package. Note that I'm not affiliated with the systemd folks in any way, I'm just a happy user.
&gt; One of them is just helping those who put on events make sure they've thought of everything. Conferences, and those who organize them, get better as time goes on, because each year, bugs happen, get fixed, and a checklist for regression testing happens. Well put. It's frustrating to see how many events start adopting each others solutions after a couple of years only. I think this has to do with the DIY-style of many - we all know better. I was glad that before eurucamp 2012 Jan Lehnardt extended an offer to organisers in Berlin to drop by and talk about problems and - more importantly - approaches to solutions. In the end, it's a very hacky thing. We state a problem ("why are there no women on stage and in attendance?"), come up with solutions and validate them each year. We rethink the problem statement each year. Currently, we are at: "there's are huge communities with foreign ancestors in Berlin. Why is none of them involved in tech?". I'm less and less interested in the high-level discussion at the moment. These effects are real. And often they are as simple as "no one ever told my I could have a look into tech things". The solutions also might be as simple as just taking a step forward an tell people that they actually can! It's not even a huge drag, time-wise.
For the matches, this is due to the way exhaustiveness is checked. For one it's designed with enums in mind The reality is a little more complex, but the gist of it is that we go through the variants of an enum, and for each one we assume that it's that enum and "specialize" the match. We then do that recursively with the new match until we reach some end point (either no more patterns or a pattern that we can't specialize). We know if a match is exhaustive if we have a matching arm for all those variants. Applying the same algorithm would be fine for i8/u8, but would be very long for even 16-bits and not at all practical for larger integers. The algorithm we use is very similar to the algorithm used in ML, however ML allows for non-exhaustive matches (the algorithm is used to generate warnings iirc) so it's not that big of a problem. This isn't an excuse, handling exhuastiveness when using integer ranges should be possible, it just isn't with the current set-up. 
I needed a break from working on Conrod and RustAudio today, so thought I'd take a few hours off and have a go at making a nice little rose tree lib (mainly because rose tree is such a pretty name for a crate) &lt;3
many parts of that blog post are good, but it doesn‚Äôt have any claim on truth. it‚Äôs IMHO perfectly possible to be the best kind of community while ignoring or actively opposing some of the mentioned points. i‚Äôm a strong proponent of the one-rule CoC: ‚Äúuse common sense to ensure you aren‚Äôt being a dick‚Äù too many arbitrary rules that are made up by some flawed human with their own prejudices and fallacies have an increased chance of not actually making things better but to actually intimidate newcomers who are discouraged from communication by having to conform to WALL OF TEXT COC with complex words and gender studies terms that nobody can possibly understand without having read half of the geek feminism wiki. /edit: to be clear: i actually really like the CoC here, although i think it could be shorter without missing content
&gt; If the branch is believed to be exceptional, How does LLVM decide when a branch is exceptional or not? LLVM has intrinsics that one can use to tell it the expected result value of an expression (any expression actually). That can be used to tell it that a branch is exceptional. Another alternative would be to use PGO (but this is dangerous). I don't know any other way to get reliable behavior.
&gt; We've long since outgrown this model You may feel this way /u/kibwen, but you also may not realise how much you've made others feel the same way! Over the past year and a half I've learned a ridiculous amount just by skulking around `#rust` watching you and the other amazing gurus help/discuss/debate various rusty topics/RFCs. The knowledge-sharing pool is still thriving, perhaps you've just become a smart cookie and are on the other side of it all now :)
&gt; What I did see was a vocal minority of posts that seemed to be espousing extreme and dismissive views typical of the SJ community, and not getting called on it. I'm not sure who you mean by that and I believe you fundamentally misunderstood the point of the thread in question. Its core complaint was that the outcome of many months of community work was a huge letdown and is a thing of years to fix. Changing Representation is _hard, hard, hard_ and takes ages. You might also note that many of those arguing in that thread are people doing _actual work_ for the Rust community in those spaces, then and still.
Oh cool! :D
I think they can panic if they "need" to. The problem is you're liable to abort the whole program in case you cause a double-panic. E.g. hypothetically I think it would be fine to have an internal assertion, which is testing for a memory-safety bug in the File code. panic on errors from implicit close() sounds ugly to me. Note if you don't use fsync() (f.sync_all()), you don't know about IO errors (or media removal, or system crashes...) Errors from close() are obscure enough; since File doesn't support it explicitly I'm not sure we should worry about it too much.
There is a ebook version here: http://killercup.github.io/trpl-ebook/ 
Yeah... No. "Racism", as commonly used means "Prejudice, discrimination, or antagonism directed against someone of a different race based on the belief that one‚Äôs own race is superior". What you're referring to is "institutional racism" and can't actually be applied to individuals at all. While (in western countries) white individuals cannot be *victims* of institutional racism, they also cannot be perpetrators of it. Society can have racial biases encoded into it, but that isn't the fault of any individual member of that society. In the end, trying to redefine "racism" this way doesn't do anything to help. It's not like people are going to go, "Oh, you know, those remarks about my race were really hurtful, and I was really upset, but now that you point out it wasn't **racism**, I feel fine now." Instead they will, at best, not care and just go "well, I don't care what it was, I'm still upset" and at worst resent the other group for the special treatment they get. Whether or not a remark is hurtful is not related to the race of remarker. And whether or not you label as "racism" doesn't change the fact that it's unacceptable behaviour.
&gt;I always want more mentoring, but in many ways I've learned so much more when I haven't had someone to lean on. Communities like WordPress and probably jQuery struggle because they try to hold newcomers hand so much that few members of the community ever level up. Instead more experienced community members end solving all the nubes problems with helping nubes learn problem solving skills. In the move to become more welcoming, it's also important not to stunt the growth of nubes. I'd argue that they're doing mentoring wrong. A mentor should really just be somebody that is there to guide the mentee. That means answering questions, but it also means helping the mentee come to the answer their own way. It's hard though, simply answering questions and giving instructions is much easier than actually helping somebody improve. Hmm, I should talk to /u/Manishearth (or post on the thread) about this aspect of mentoring. It's all well and good making projects more amenable to mentoring, but if the mentors suck that's still a problem. 
Wrong sub, this is about the programming language. I think you meant https://www.reddit.com/r/playrust
Yes, while I understand the concept of asking someone to "check their privilege," I know that in a debate, especially one that has become heated, it can serve to merely inflame things more. It is generally only useful if directed at someone who has already fully internalized these ideas, and is aware of and willing to stop and reflect on whether something they just said may be based on coming from a privileged position rather than listening to the experiences of others.
Surprisingly many people, including recruiters / HR folks.
I think what you're trying to highlight is that a) privilege is contextual, and b) it's not something intrinsically negative. [There's a lot to discuss about the use of the term "privilege" .](http://slatestarcodex.com/2014/07/07/social-justice-and-words-words-words/) It's not unanimously popular, and I'd say that's reasonable. 
&gt; talk about what kinds of reasonable accommodations could be made to **reduce or eliminate** those privileges, to give more people a chance to participate on an even footing. I hope you meant something like "compensate for" or "smooth over", because depicting diversity politics as a zero-sum game is guaranteed to turn off anyone who isn't one of {female, black, queer, trans, disabled} and who happens to be looking out for their best interest. Better to adopt the "a rising tide lifts all boats" model, lest you get confused for anti-male, anti-white, etc. 
On paper sure, but the only times I ever see intersectional feminism depart from big ticket items (race, gender, LGBT) is in hypothetical discussions like this one. In particular, intersectional feminism pays almost no ear to class differences, and as a result end up mostly benefitting exceptionally privileged members of disprivileged minority groups. 
If someone wants to be a leader without programming, then they are probably just someone with too large of an ego and control issues. They are the same type of people who are managers in companies that use the actual work of others for their own benefit. 
Of course the problems only arise when the term is misused to try to shut up dissenting opinions ‚Äì in those cases, the goal is to make someone stop, not make them reflect. Another problem I have with this misuse that it implies the same cognitive filter as "indoctrinated"; the latter concept having historically been misused to horrible effect. (From this standpoint I can understand those that see the word itself as a red flag, not that I would suggest such misuse take place within this community). Also I think reflection is best done outside any discussion, in a quiet, private space. Asking someone to do it while in a public discussion would be overstepping social boundaries.
&gt; They are the same type of people who are managers in companies that use the actual work of others for their own benefit. You would be doing just that when someone does non-coding work for you and you keep them from leadership positions.
Sorry, the correct link is now http://www.redox-os.org
We must have different experiences. While there's some amount of allergy to class, it's mostly due to people saying "Class is the only thing that matters", rather than an admission that class doesn't matter at all. And, as I said below, humans are not perfect. This stuff is difficult, and people get it wrong. That's going to happen. That means they did a poor job, not that the theory itself says something it doesn't.
Not everyone who takes issue with SJWs falls on the GamerGate/TiA/KiA side of the fence. If anything, I might take *more* issue with SJWs because they're close enough to my ideological space that I risk being confused for one of them. I don't think questioning feminist canon and growing a lovely friendly garden of a community are mutually exclusive. I understand that you, Steve and many of the Mozilla folks subscribe to that canon, and that's fine; just remember that a criticism of this canon is in no way an attack against you personally. I'd never participate in this community if it was full of GG types. (Which it's not.) 
Thanks :)
Thanks :-)
LLVM literally just defines it as undefined behaviour (specifically, it produces an undefined value), so if it ever sees it, it does whatever it pleases. In this case, it's evidently decided to just read off the memory that happened to contain the loop counter. (someone can dig into llvm's guts and the generated asm/ir to give a more detailed response) https://github.com/rust-lang/rust/issues/10184
&gt;To claim otherwise is basically saying that someone's status depends on their being accepted by privileged people. I feel like that would be a good first approximation of status, no? &gt;There is nothing special about privileged people, but by claiming that their acceptance is more important, you're making them special. Isn't the *definition* of privilege that it gets you special treatment? Privilege would not be a thing if everyone's opinion mattered equally. 
Off-topic: how is privilege *subtle*? It's one of the most basic concepts out there, I feel like even small children understand the idea of privilege. 
&gt;My apologies. I can see how it could be misconstrued, but by "reduce or eliminate a privilege", I mean reduce or eliminate the *difference* between people, not pull anyone anyone down. This can absolutely be done by pulling other people up rather than by pulling anyone down. I don't doubt that. I just think it's worth being 100% clear, because this subject is an absolute minefield. 
Class is HUGE, though! As originally defined, a social class is roughly a cluster of people who share the same privilege/disprivilege story. It correlates very strongly with ethnicity, education level, income, disability, etc. Gender is one thing that's mostly orthogonal to class. Possibly sexual orientation too. So yes, class isn't *everything*, but it's a big chunk of the story.
How is a panic in a destructor a double panic?
I sense a lint could be useful...
Panic in destructors is often a source of double panics, since panics call destructors.
Trust me, I'm a big fan of class-based analysis. I'm just saying that this is a long public conversation, with a lot of history.
Thanks for the helpful tips. I am using a rust lib called 'backtrace' in a custom error handler class to create and keep track of stack traces when errors occur. Normally it provides nice stack traces (with line numbers) so I was surprised when I was getting &lt;unknown&gt; I *think* I was breaking the rules with fork(2) and rust Drop semantics. I was having issues doing FFI work and segfaults - and maybe when a segfault occurs Rust was getting confused. Maybe the addresses were unknown to Rust because the C code was using a different allocator :-) I've switched to sticking with threads and have stopped (momentarily) being stupid with C code so my problems have been resolved. 
Can you suggest any reading on the interactions of intersectional feminism and class analysis? Specifically, I'd like to know why/how the two end up in competition instead of complementing each other. I've never met an activist who was equal parts marxist and feminist - one always seems to dominate, and I think it has more to do with who you hang out with than with anything else. 
&gt; The New Jersey cowboy coders, who have no qualms doing things in their code that would make Bjarne Stroustrup go a little pale around the nose, are simply faster to the finish line, with programs that work, mostly. You do realize that Bjarne *is* one of the New Jersey cowboy coders, right? &gt; In 1979, Bjarne Stroustrup, together with his wife and daughter, moved to New Jersey to join the Computer Science Research Center of Bell Telephone Laboratories (colloqually know as 127 or 1127). ... After the 1984 break-up of the Bell System, Bell Labs became AT&amp;T Bell Labs, and after the 1995 break-up of AT&amp;T, AT&amp;T Bell Labs was itself split into AT&amp;T Labs and Lucent Technologies Bell Labs. From its inception, Bjarne was a member of AT&amp;T Labs - Research, the half of Bell Labs Information Sciences Research that AT&amp;T kept to itself as Lucent and NCR were spun off. -- [Bjarne's bio](http://www.stroustrup.com/bio.html)
The folks at /r/askphilosophy are a bit abstract/meta for my taste unfortunately. Thanks for your insights, hopefully I'll get to shake your hand at a Rust convention some time.
I have a blog post in the pipeline about how an open source community can do mentoring well. Pipeline is rather backed up due to lots of school stuff going on, but I'll get to it.
I think it's basically wrong to allow `as` casts that could fail (eg: casting `u64` to `u8`, `f32` to `u64`, etc). This should require more specialized methods that either 1. return a default value in case of error 2. return `Option` edit: actually, is there such "cast" that returns an `Option` in Rust today?
u64 as u8 can't fail. It's just a truncation (taking the modulo). While this may be semantically incorrect for your usecase, it's definitely an infallible action.
In retrospect I should have just left the food, drink, child care, and maybe even the code of conduct part alone (or in separate comments). But at this point I think splitting my comment would just make this thread confusing.
Yeah that's LLVM being a butt for the most part. `float -&gt; int` and `int -&gt; float` are often cpu instructions, and LLVM punts on platform-specific behaviour by declaring many casts as UB. iirc `as float` miraculously can't fail because we don't have f16 or u128, but floats are just way too big to cram in a u8 (257.0 as u8 is also UB according to LLVM). I believe we need to manually call platform-specific intrinsics rather than asking LLVM to do the cast to get "only" platform-specific behaviour, rather than UB. Thankfully for non-constants we seem to just get platform-specific behaviour (which can involve a cpu fault). Part of this is LLVM refusing to acknowledge rounding modes (it always uses closest, can't remember the tie-breaking scheme).
It existed before Into&lt;&gt; and From&lt;&gt;, and it wasn't removed before 1.0.0.
&gt; I really think that the "motte and bailey" concept is helpful I consider SSC a very political and very problematic space, and do not welcome its assumptions or conclusions in conversation. I see "motte and bailey" used in a conversation as a red flag, similar to what you're describing when you see "privilege". Along with sounding more erudite than the simpler term "equivocation" and signalling to other people that you share politics with SSC, I think the motte-and-bailey "concept" is, in a weirdly recursive sense, itself a bit of a motte-and-bailey. That is, it's a form of equivocation. Specifically it counts basic observable facts of social and political group dynamics (people vary in their radicalism and more-radical people have a relationship of mutual support with less-radical) as though they're *logical fallacies*, even though those group dynamics are universal, and say nothing about the point being made. See [this elaboration](https://thingofthings.wordpress.com/2015/03/08/against-motte-and-bailey/) for a more explicit description of this criticism. If you want to say I'm equivocating on something *substantive*, fine, just say I'm equivocating and point out how you disagree with my politics. If you think that by my taking a position on matters of inclusion and equality, I'm making room for radical / extreme forms of it, and/or leaving weapons of abusive discourse lying around, welcome to human behaviour around politics. That's a simple result of *having any politics at all*. And surprise, all statements of position are political. It's simply a matter of whether you recognize that fact. Either way, having-a-politics means making-room-for-more-radical-forms (as well as shifting the window for less-radical); and that fact alone *doesn't* make the politics right or wrong. Your position, for example, makes (some) room for radical reactionaries (right-wing politics, very well represented in programmer communities these days). I don't need to go far to find programmers who argue that men are more intelligent (and more deserving of positions of influence in programming circles) than women, whites more intelligent than blacks, stanford students more intelligent than the unwashed masses. Seriously. Not hard to find at all. I've met and discussed this with lots of people over the years. Mainstream FOSS culture is full of such people. I consider those people wrong -- politically and morally -- and will argue with them. But I don't think you *making room for them* makes you wrong, or makes them wrong. I think them being wrong makes them wrong. Now, I'm assuming you don't have hard-right views. Probably you'd have left this space by now if you did. But your views make (some more) room for them, and lend some credibility to them, shift the discourse gently in their direction; just as much as mine make room for the radical-left that you take issue with. The choice of who we make room for in this community are a real question, true. I hope I'm making my preference on that perfectly clear here -- egalitarian politics, which are [leftist by definition](https://en.wikipedia.org/wiki/Left-wing_politics) -- but I also hope you recognize that there's *always* a politics embedded in a culture. Always a "who's welcome, who's not". And it's not a logical fallacy, nor an argument against a particular politics, for a space to have a politics. That belief is the fallacy embedded in the term "motte and bailey" itself.
Background radiation of the "yeah but radical feminists are the worst amirite?" form is *directly* in conflict with growing a community that embraces gender equality. It shifts the window in the opposite direction from the one we're trying to push it. [JAQing/sealioning](http://rationalwiki.org/wiki/Just_asking_questions) -- the "I'm just a reasonable man with some questions about feminist canon" style -- is the mainstream format that the internet's relentless supply of reactionary MRA antifeminist pressure takes. It's *so* familiar and *so* painful to *so* many people that we lose a bunch of them every time this comes up. So yes, you need to tread very very lightly here if you don't want to undo the efforts put in to marking this space explicitly (gender-)egalitarian. All feminisms have in common a commitment to gender equality, and I think you should reflect on your behaviour if you find yourself spending your available energy debating them.
* `&amp;[u8]` is preferable to `&amp;Vec&lt;u8&gt;` as input, it's more flexible (lots of contexts can yield 0-alloc slices, not so for 0-alloc vecs), more common and more efficient (`&amp;[u8]` is a reference to an u8, `&amp;Vec&lt;u8&gt;` is a reference to a Vec which contains a pointer to an u8) * it should be possible to create a lines iterator rather than filling a vec of vecs upfront * or not even that, it should be possible to just look for the "break points" and only return slices into the original slice, you can probably limit allocations to the Vec of headers * using a peekable iterator into the slice would likely help (so e.g. if you're on a `\r` you can directly check whether the next item is a `\n` * use byte literals: `b'\r'` will usually be clearer than `0x0d` * and the return value should be a custom struct * there's already libraries for HTTP clients, you may want to just use them ;)
As far as I'm aware there's no way to use From to convert, say, an int to a float
Receiving `&amp;Vec&lt;u8&gt;` is unusual because it's a double pointer, I'm wondering what was the thought process. Anyway if you substitute the parameter to `Vec&lt;u8&gt;`, then you just have to omit the `&amp;` when calling the function and it compiles. Of course receiving an `&amp;[u8]` is better: then you just call `split_packet(PACKET);` and don't need to allocate a vec in the heap if you don't need it! (you can still call it in a vec `v` by using `split_packet(&amp;v)`)
It's not as clear-cut as that. In addition to numeric casts being treated as privileged in hardware, `Into` and `From` are uncomfortably implicit for this domain, especially among programmers who are wary of the footgun that implicit numeric casts present in C. Signaling that "Rust does things differently from C" is one of the only reasons that, e.g., we force you to be explicit about even entirely harmless casts like u8 -&gt; u16.
You should look at the `split_at` function. Instead of the `loop{}` in the middle, you just find the index of the first empty line, and then `split_at` will give you two slices: everything up to but not including that point (which you can use as `headers`), and everything else (chop off the first blank line, and you have the content).
&gt;I think you should reflect on your behaviour if you find yourself spending your available energy debating them. I'm massively triggered by identity politics. Debating isn't a rational response, but it's a response. I just hope the Rust community is a big enough tent to also include non-feminists.
There's no reason that we couldn't introduce a dedicated truncation method (RFCs requested!), and there's currently nothing stopping you from implementing such a thing yourself in your own crates. All I'm objecting to here is the implication that `as` was only left in as an oversight, which is untrue.
&gt;But your views make (some more) room for them, and lend some credibility to them, shift the discourse gently in their direction; just as much as mine make room for the radical-left that you take issue with. Am I correctly interpreting this as you subscribing to the No Platform Policy (example [here](https://en.wikipedia.org/wiki/NUS_No_Platform_Policy))? &gt;I consider SSC a very political and very problematic space, and do not welcome its assumptions or conclusions in conversation. Can you elaborate on this?
[clippy](https://github.com/Manishearth/rust-clippy) even has a lint to check for `&amp;Vec&lt;T&gt;` being passed to a function. Not directed at /u/protestor ...just a general comment for those following this thread ;)
&gt; That backlash comes from people who didn't want diversity in the first place. There's also backlash from conflict-averse folks who'd rather have the community not align itself with either side of the toxic, explosive MRA-feminism conflict. Those folks obviously aren't going to be loud and indignant (see: conflict-averse), but I don't think they're rare at all.
Oh, that's great.
What about adding enum variants as types before landing the whole extended enums design (or even regardless of whether it lands)? It would be useful by itself.
&gt; That's exactly what I fear. That at some point the "goal of Rust community leaders" will be more about political agenda than anything else. This fear is bewilderingly groundless. What possible reason would you have to suspect that?
&gt; Because they don't share liberal woldview or because they are not women, maybe, hmmm? Once again, your accusations are wholly unfounded and come across as blisteringly defensive. Your comments currently require moderator approval, but I won't be approving any more of them if you don't demonstrate that you can engage in reasonable discourse.
&gt;I've browsed your posting history and it seems you're earnest rather than trolling so .. can you elaborate? Here's a bit of context. I've been an active militant since I was old enough to march. I protested with my parents during the [2005 Qu√©bec student protests](https://en.wikipedia.org/wiki/2005_Quebec_student_protests), but I came of age during the [2012 Qu√©bec student protests](https://en.wikipedia.org/wiki/2005_Quebec_student_protests). Qu√©bec activism is a jumble of a bunch of groups. The best represented groups are unions, leftist college students and anarchists. Feminists are a much smaller contingent, and their presence is almost always "tokenist" - one banner, one contingent, one five minute speech in a series of five minute speeches. Most activists who are primarily feminists are *radically* so, more like Dworkin than like you or Steve Klabnik. Still, everyone is at least nominally a feminist. The average feminist here hasn't spent five minutes over the past week thinking about feminism. Intersectionality is almost never brought up, because our gays and black people are pretty much 100% integrated, our women liberated, our wage gap dwindling. MRAs are few and *very* far between, and they're generally considered mentally ill or otherwise troubled. My experience with feminism changed when I joined McGill University, an english-speaking college whose population is by and large NOT French Canadian. Here I was exposed to American-style feminism. I was *very* uneasy with it from the get-go. It felt dogmatic, sectarian, exclusionary. It focuses on gender and color to the almost total exclusion of social class and mental illness. It feels more concerned with signaling games and social engineering than with actual society-wide change. Safe spaces are implicitly not "safe" at all for white males, and because of their very rigid rules they're prime hunting grounds for manipulators and sociopaths. If you're a white male, you're essentially the enemy unless you're willing to out yourself as queer, and then you're expected to take part in the hate. Radical feminists blast "allies" to no end, and a single misstep is enough to earn you ostracism. I started associating less and less with feminists, because the french kind weren't anywhere nearby and the english kind were bad for my mental health. In parallel to my lived experience in english feminist circles, I kept seeing news of horrible feminist acts. Worse, I saw the vast majority of feminists *defending* those actions, encoding a rough, unspoken policy that "an attack against one is an attack against all". From that point on, I wore the "feminist" label less often and more regretfully. I still did, though, because I held the principles of feminism very close to my heart. Then I discovered SSC, which was my introduction to ingroup/outgroup dynamics, and everything just *clicked*. Feminism wasn't the ideology; feminism was the *group*, a tribe of folks addicted to outrage and conflict, full of fancy social rituals and signaling games, high on censorship and gaslighting and groupthink. I feel like I'm recovering from a multi-year sickness. I can now have a safe space *from* feminism, I can experience pro-minorities activism without aiding or abetting the actions of feminists. &gt;Identity politics traumatized you? It's a long-ass story, and one that I don't want to mentally walk through again. Keywords: ADHD, gaslighting, character assassination, depression. It wasn't even about feminism at first, but now when I see something like Donglegate I freak the fuck out.
[removed]
Why does `split_at` exist then, out of curiosity?
&gt; 32760 from http://www.opensource.apple.com/source/llvmCore/llvmCore-2118/lib/Target/CBackend/CBackend.cpp if (IsNAN(V)) { // The value is NaN // FIXME the actual NaN bits should be emitted. // The prefix for a quiet NaN is 0x7FF8. For a signalling NaN, // it's 0x7ff4. const unsigned long QuietNaN = 0x7ff8UL; Quiet NaN: &gt;When an operation results in a quiet NaN, there is no indication that anything is unusual until the program checks the result and sees a NaN. That is, computation continues without any signal from the floating point unit (FPU) or library if floating-point is implemented in software. A signalling NaN will produce a signal, usually in the form of exception from the FPU. Whether the exception is thrown depends on the state of the FPU. http://stackoverflow.com/questions/18118408/what-is-difference-between-quiet-nan-and-signaling-nan
`From` is subject to type inference, whereas `as` isn't.
What the hack is the @ character in that? I don't recognize this pattern. Edit: never mind, found it in the reference &gt; Subpatterns can also be bound to variables by the use of the syntax variable @ subpattern. 
Well if you want to throw some more iterators at it and fewer allocations, you could do something like [this](http://is.gd/PVK1PB). I suppose in theory you could even avoid the `Vec` for the headers if you were to return an iterator that yields them. I'll leave that as an exercise for the reader...
&gt; My experience with feminism changed when I joined McGill University &gt; I kept seeing news of horrible feminist acts &gt; feminism was the group, a tribe of folks addicted to outrage and conflict, full of fancy social rituals and signaling games, high on censorship and gaslighting and groupthink I'd suggest this is more a reflection of the passions of early adulthood in university than an intrinsic aspect of feminism. And I don't know what these "horrible feminists acts" you're describing are; I haven't seen any feminist Elliot Rodgers running around, but maybe I'm looking in the wrong places. Of course, I understand that feminists are (like all humans) capable of crossing the line from radicalism to fanaticism, losing sight of the humanity of the person they're speaking to. And I understand people can be hurt badly enough by thoughtless, forceful words. I'm sorry feminist-minded people hurt you. I hope this community, in its defence of a relatively modest baseline egalitarian politics, does not hurt you the same way. I would encourage you, in any case, to rethink the notion that one can meaningfully be apolitical, as SSC and many modern libertarians wish for themselves; it usually means complicity with existing power imbalances / siding with the status quo. Many issues that actually effect real people's lives as adults have a policy locus, and if you shrug that fact off you're implicitly saying the current policy is fine.
Yeah, I imagine it's hard to decide whether a comment is meant as a suffix to a previous statement or as a prelude to a subsequent statement. But otherwise, I'm basically afraid of running rustfmt and concluding that now my code conforms to whatever standard, when in reality it preserved my terrible whitespace habits that I don't even notice.
You might want to investigate /r/rust_gamedev too
Nope. You don't own either the Fn trait or the Add trait, so you can't do wildcard implementations for them
That's what I thought. I'm guessing there's no trick to it, such as inheriting either trait, that could make it work?
A truncate may always fail to truncate unless you first inspect the value to ensure it is outside the min/max bounds of the type you are converting to. I mean isn't the point of truncate to ensure that a type fits? I think as long as my as you can't truncate to usize the semantics would make sense.
It sure is! Anthony and I spent several minutes coming up with a name. Maybe as many as ten!
Thanks for trying! Maybe you've inspired the seed of an idea in their minds. :)
Piston is a good and modern engine in rust, although it was quite hard to get started a few months ago, because documentation was rare, there were often breaking changes and many useful ideas where split across crates so that I often did not find the right modules to import. There is also cinder, a C++ graphics library which makes extensive use of modern C++ and is thus quite similar to rust. Most other engines I know are in most parts based on inheritance and type erase, but very little compile time generics or multithreading, so very *unrusty*.
You may be interested in https://github.com/rust-lang/rfcs/pull/1218
`From`/`Into` are for unambiguous and well-behaving conversions. There are plenty of ways to convert between floats and ints and all of them can be used inappropriately.
Ah, yes. Hopefully it will one day, but right now it uses 10(!) feature gates, so unfortunately it's stuck on nightly for the foreseeable future. I can make some of them optional, but it kinda has to be an all-or-nothing thing to make sense.
&gt; Now, I'm assuming you don't have hard-right views. Probably you'd have left this space by now if you did. The wider world brands my particular flavor of politics as "extremely radical right." (Not that I personally find it to be a usefully accurate characterization.) On the same token, I find the Rust community, the CoC, its norms and its strive to be welcoming and inclusive to be exactly in line with my politics (and ethics, which aren't always the same for me personally). I think we should be careful about casting implications that [insert label for a large ambiguous group of people] probably wouldn't fit in here. It is certainly not true for me, and I bet it is not true for others. We definitely disagree on the meanings of certain labels (I personally see nothing leftist about the Rust community) and that's OK and expected to happen I think. But we should be cognizant of those reasonable disagreements before making the implication that certain groups of people don't belong here. Apologies in advance if any of this came out wrong sounding or antagonistic because I do not mean it to be!
The community team didn't exist at the time. The situation was one of the reasons it was created, to make sure we have people explicitly working on community efforts.
I don't actually agree that m&amp;b is the same as equivocation. Equivocation is about vagueness; m&amp;b is about switching between two concrete positions to suit the occasion. And I've honestly never considered m&amp;b to be a logical fallacy. It's a tactic, no more, no less. Take an extreme position on the offensive, and when counterattacked fall back to a moderate position and call in support from the much broader moderate community with a cry of "Help, our moderate position is under attack!". I was very surprised to see you describe SSC as a libertarian space in another comment, btw. Not my reading of it at all. I don't follow the SSC commentariat, so maybe things are different there, but I think the only label I'd apply to Scott himself is "rationalist". &gt; If you want to say I'm equivocating on something substantive, fine, just say I'm equivocating and point out how you disagree with my politics. OK, substantive. You say you want a community based on "inclusion and equality"; I'm completely on board with that. You (I think) accept that this environment makes room for extremist positions like SJ. I **don't see** SJ as being "inclusive and egalitarian, only more so". I don't think they have the slightest interest in either inclusion or equality; they just want to be on the right side of exclusion and inequality. I don't expect you to agree with that, but I think that's where the fundamental disconnect is. Concrete example: an argument was made that having an all-white-male community team will lead outsiders to conclude that Rust is just another bunch of obnoxious brogrammers. (I'm not entirely sure what that term means, but I'm pretty sure it's not good.) Someone objected indignantly that such a conclusion would be reverse racism. I didn't agree, but it wasn't a completely insane thing to say, nor was it said offensively. "No, I don't think it would, and here's why" would have been a perfectly fine response. "No, I don't think it would, and I really don't want to derail this important discussion by getting sidetracked" would also have been completely reasonable. The actual response was "No, it's not and you're stupid for thinking it could be, because we've unilaterally redefined the word 'racism' to suit ourselves, and unless you accept that redefinition you have no right to participate in this conversation". (I'm paraphrasing because I really can't face going back and reading the original again, but I'm not exaggerating.) Is that acceptable or not? If it is - if it's impossible to criticise or moderate that kind of aggressive dishonesty without being being greeted by a "Help, our inclusion-and-equality-based-community is under attack!" mob - then I don't want to be anywhere near it. I'm aware that much of the left considers this kind of thing to be OK and even laudible in pursuit of a greater good; I don't. &gt; Your position, for example, makes (some) room for radical reactionaries I'm curious as to what you think my position is. You seem to have me pegged as somewhere on the libertarian right, which I think would surprise pretty much everyone who knows me. In 20 years of (commercial, not FOSS) programming I can't remember ever running into the "not hard to find at all" reactionaries you describe, but if I did I certainly wouldn't want to make room for them.
I'm not arguing with diversity as a goal, I'm arguing with it as an *ultimate* goal. Your "business case" makes diversity an instrumental goal, something to be pursued because it'll help you achieve your actual ultimate goal, not an ultimate goal in itself. As I said, it's a minor and pedantic distinction.
I wrote this toy game engine a while ago: https://github.com/gsingh93/game-engine I don't intend it to be actually used for anything, but it was just something I did for fun/learning.
https://doc.rust-lang.org/nightly/book/casting-between-types.html#as
Hi, just letting you know, the feature you requested has been implemented: https://github.com/dpc/mioco/commit/20fb515e0a9feb767fe995fb32f83441ae8d28fd Thanks for the idea!
That's not _real_ documentation though. The obvious question is what happens when the target is narrower or differs in signedness from the source, what happens when a float is turned into an int, is it only for ints and floats, etc.
Wow, you did a way better job of phrasing what I was getting at with my comment above. I wish I could accurately describe my thoughts as well as you just did here.
So what is the end goal of diversity? Presumably different perspectives, but I have a hard time imagining that race, religion and gender would have much impact on how to design code. (Heck that sort of reminds me of how in ww2 Germany was ignoring Relativity as "Jewish physics") I would imagine having people from different projects in cs, engineering, academia and industry regardless of social factors would give a better spread of perspectives. If it is just for "high minded" social reasons then giving special treatment to "diverse" people seems like it is insulting to them and discriminatory against "non-diverse people". This is especially true for leadership roles, promote the best PERSON for the job, not best man, not best woman, not the best South American immigrant of Asian descent or what have you. Unless..... If you feel that we will attract more useful people to projects by doing this diversity stuff rather than using the resources elsewhere then I suppose being a bit discriminatory could be a win. Ex. &gt;Women Using Rust Conference -&gt; X new quality rusteceans (Presumably mostly women?) vs &gt;Rustecean Conference -&gt; Z new quality rusteceans (possibly more men? ) If and only if X &gt; Z than does it really make sense to spend those specific resources targeting diversity as opposed to increasing total community base.
[WebRender](https://github.com/glennw/webrender/) might be of interest, since it's quite similar to a game engine. A modern game engine will be structured very similarly and will use OpenGL in much the same way.
I don't hear it as antagonistic, and I hope I'm not coming across as *too* antagonistic. I do mean to make clear my disapproval of right wing politics, so I guess I'm willing to antagonize those, though I hope you don't read that as antagonism against your person. I suspect you might be reading "right" and "left" as terms in a very US-culture-war sense (perhaps around gun control, drug use, etc.) whereas I'm using them in their more traditional/general sense, referring to [pro-equality / anti-hierarchy](https://en.wikipedia.org/wiki/Left-wing_politics) or [pro-hierarchy / anti-equality](https://en.wikipedia.org/wiki/Right-wing_politics). When I say the Rust CoC is at least moderately leftist, I mean in a pretty formal sense: it's ... pro-equality! It's saying, to paraphrase, that "the following are ways people have been made dramatically, systemically unequal in the world, and it's not ok to reinforce those inequalities in this space". That's a leftist stance. Not an ultra-left, nationalize-all-the-factories stance. But a stance firmly left of "center", in the sense that right wing politicians frequently decry such terms appearing in anti-discrimination legislation and fight to overturn them. So .. when you say "extremely radical right", I'm curious how you can square that with an approval of our code of conduct, and the norms it expresses. Would you, for example, endorse the existence of [protected classes](https://en.wikipedia.org/wiki/Protected_class) in US federal anti-discrimination law? Because those laws were and still are considered leftist (being pro-equality) by many people on the right. The right fought against them, in the lifetimes of many people still holding office. If you're on the right -- and I'm seriously not trying to paint you into a corner here, just take a temperature of what you mean by "right" -- how do you feel about such laws? What do you _mean_ by right? In my own country, Canada, the right wing is consistently trying to roll back our version of the same laws, the [equality rights portion (section 15) of the charter of rights and freedoms](https://en.wikipedia.org/wiki/Section_Fifteen_of_the_Canadian_Charter_of_Rights_and_Freedoms). Support for that sort of equality-directed legal rights is what I mean when I say left. Along with a variety of economic policies that work towards material equality -- steep progressive taxation and social spending, for example -- but the rust community isn't in the business of administering a tax code or a budget, so that aspect is moot.
I'm in Lakeland, but I haven't used Rust in a little while. A few of my friends are interested, we just need to find something to *do* with it.
All of them ;). And it pains me that I _like_ all of the individuals.
My understanding of these proposals is that methods in the inherent impl for a type are not inherited, only fields. Not certain, though.
&gt; Donglegate I freak the fuck out. One word about Donglegate. One of the problems of that space is that only the extreme outliers get known. PyCon, in that case, has handled the case well, once they got wind of it. Good resolution around issues at public events is above all silent and private. That's also in the victims interest, _if and only if_ the conference staff is working to their support and resolution. I know quite a number of cases where that worked out.
Ah. I recall looking there some time before 1.0, but it seems to have gotten more lively since then. Noted.
Linked a list of mod.rs/lib.rs that currently require formatting Modules | Libraries: Total: 136 Require Formatting: 112 Error: 12 Files: Total: 6241 Require Formatting: 544 Error: 40 Report Link: http://pastebin.com/Q0K4E8Sv Script Used (its not very pretty, sorry): http://pastebin.com/rD1c2rMe 
Thanks, it looks interesting.
If you look at the [URL wiki page](https://github.com/redox-os/redox/wiki/URL) you'll see that a URL has type `URL`, which does not preclude implementation as an enum. Just because something can be potentially *represented* as a formatted string doesn't mean that it can't be stored internally as a more structured data type. URIs basically define a hierarchical namespace, much in the same way that Rust's modules do. There's not much difference between "foo/bar/baz" and "foo::bar::baz" aside from the choice of separator in the surface syntax. Organizing interfaces according to a basic protocol scheme along with a hierarchical namespace doesn't sound like a bad idea to me, and I think you may be reading more assumptions into the design regarding typing than is warranted. Rust's syntax for naming items in modules via a hierarchical namespace doesn't reduce its ability to type them, after all. 
Okay. You're ascribing a few positions ("victim mentality") to me that I don't hold, but I don't think they're crucial, and as you say this has gone on way too long already. &gt; I assume by this you're referring to people rejecting your use of the concept of "reverse racism". I too reject it. I think if you think there is a meaningful concept to denote by that term, you need to go back and study what racism means. No. I don't have a concept of "reverse racism", I have a concept of racism. It's the same as the common usage of "racism"; it defines it the same way every dictionary I just checked defines "racism". Discrimination based on race, assigning negative characteristics to all members of that race. People keep linking to "explanatory" blogs and videos as if the problem is that us ornery ignorami are just *not clicking on them*; they're missing the point entirely. You (collectively) have a concept of "racism plus structural oppression". I'm happy to grant that that's a useful, important concept; I'm happy to grant that it's *way* worse than "racism absent structural oppression". If you want to slap a catchy name on that concept and promote the hell out of it, go nuts. Where I object is when you take an *existing* word, one which already carries a huge weight of public disapprobation, and declare that your new concept is what that word means and always did, and all that ready-made public disapprobation can only be invoked against instances of racism which meet your narrower criteria, and *not* against instances aimed at your outgroup. I consider that, yes, dishonest, and excluding people from the conversation unless they go along with it is, yes, aggressive. &gt; a reasonable thought experiment to conduct in this space is to ask whether you can articulate a difference between, say, a policy that excludes black people, and a policy that excludes the KKK Of course I can. The KKK do not treat people with civility and respect, and they do not recognize equality and inclusion as values. It's perfectly reasonable, even essential, for a community which *does* value those four things to exclude a group which doesn't. It's pretty much the exact same thing I'm saying about SJs. Obviously, you picked the KKK as an emotive example. I'd note that the "right" answer to your question, the one based on racism plus structural oppression, would draw *exactly* the same distinction between a policy that excludes black people and a policy that excludes white people. &gt; I think you have ... maybe not been paying attention? Maybe, or maybe I've just been a lot more sheltered. The orgs I've worked for have been big ones with fairly stringent pro-equality cultures. I'm not disputing what you say you've encountered out in the FOSS Wild West, and I can believe that I may be underestimating the need for extreme countermeasures to it as a result of my narrower experience.
[removed]
The term is "lexicographic" btw.
Hi, what kind of crash/lockup did you encounter while writing redox ? and how did you tackle them ?
This is great. I'm now less worried about the new `&lt;-` syntax being ungoogleable if I use it in my code and then try to get people new to Rust to hack on it.
&gt; "Silent and private" were much harder to pull off since Richards' first reaction was to gather the troops and shoot the starting gun for a public shaming. It's entirely a matter of perspective, but I feel like making an inappropriate joke is simple human error, while public shamings are monstruous. I didn't say I felt like the incident was well resolved, but that PyCon handling was good. They were stern and clear and their later messaging was also on point. The incident makes me unhappy in many aspects, but PyCons reaction is not one of them - they did what they could do, immediately followed up and resolved it for them. On the other hand, consider that I am currently handling multiple complaints at a larger FOSS conference currently and they don't bother moving an inch, although they acknowledged an issue. For more then half a year. Like - they don't even react or mention that they have a different view of things. I can totally relate to people not bothering with the organisers and going public immediately - it puts them in a strong position. I, for me, put a lot of distance between me and the people not taking any stance at all or saying that everything is well handled ad-hoc because everyone is nice. I agree though that we do all have our burns somewhere. 
&gt; most choices like "let's all be nice" do not exclude anyone Apart from a..holes. But it's probably a good tactic to exclude them ‚ò∫.
Thanks! Is Ruby similar to Rust? I'm unfamiliar with "polygot", &amp; will look that up. I became aware &amp; interested in Rust through SAFE Network. I was listening to a podcast where someone involved with the effort encouraged people to learn Rust. Edit: I just realized I totally skipped over your question about what I did with the Atari. Honestly, I don't have any idea, &amp; it may not even be considered coding. lol. I was just kidding around bringing it up. I just remember entering a bunch of commands which resulted in the drawing of a square, &amp; another set of commands that resulted in some really unpleasant chirping. Sadly, that was the extent of my exploring that type of computer use as a kid.
I'd encourage you to check out r/MaidSafe. Maybe it will interest you too. Any chance you guys have considered going to, or starting, a Rust group in the area?
&gt; Most activists who are primarily feminists are radically so, more like Dworkin than like you or Steve Klabnik. You are of course free to have whatever opinion you'd like, but I'm _really_ uncomfortable with sorting people into "good" and "bad" feminism, and putting two men on the side of good against a respected scholar who's a woman. This is of course subject to the parameters that /u/graydon2 was talking about, in a PLT space, seems really bad. Criticizing others' feminism in a space more focused on it seems fine, there are a lot of feminists I disagree with (TERFs for example).
Thanks! I'd like to contribute code to the SAFE Network. It's an effort I value, &amp; it sounds like there will be an opportunity to profit from it too. I assumed Rust was an unusual starting point because of how new it is, but is it more than that? Is there some reason in particular that makes if more difficult? I'd love to start learning Rust, but should there be some other required learning first, I'm fine with that too. Since I don't know, I'd hate to start researching the least rusty language out there, only to eventually realize a much more efficient path to Rust competence.
hi! could you file a github issue with a little more detail? repo: https://github.com/ashleygwilliams/rust-release-explorer/issues happy to add this feature. (o/ hi i am the person who made this thing)
I didn't make a value judgment, I just wanted to highlight that the radfem flavor I've seen in french-speaking environments was more radical, sex-negative, etc. 
&gt;On the other hand, consider that I am currently handling multiple complaints at a larger FOSS conference currently and they don't bother moving an inch, although they acknowledged an issue. For more then half a year. Like - they don't even react or mention that they have a different view of things. I can totally relate to people not bothering with the organisers and going public immediately - it puts them in a strong position. Derp, that's fucked up. No wonder people are making their own justice. Have you written on the subject? It would be good to know how different conferences handle conflict.
&gt; Have you written on the subject? It would be good to know how different conferences handle conflict. Not yet. I have written on the benefit of policies though here and there, it has been a huge benefit for all my conferences. I probably haven't written enough on the matter, though. We have noted down many of our observations when running eurucamp on our blog, though: http://blog.eurucamp.org/2015/08/12/accessibility-diversity/ (and other posts) Even at eurucamp, we had problems at the conference which people didn't tell us because of fear of the org team - and we only got wind of it later. Lack of trust in reporting is a _huge_ problem currently that is rarely discussed and can only be handled by transparent and open communication. We had, for example, to amend our report one year: http://blog.eurucamp.org/2014/03/15/amendment-of-incident-report/ Also, I cannot understand the problem with conferences keeping track and reporting their incidents: when 400 people get together, incidents happen, even without bad faith. There's no shame in that. Shame is in not being able to support them. (And support means clearing a misfired joke in a fashion where you don't need to kick someone out) Sadly, we the FOSS community no framework for training people for that. I recommend asking someone who does festival/concert security about that, they are very knowledgeable. This is something where I am at odds with the DIY-ness of the FOSS community (although I did happily pick up such projects as an amateur myself): they do it all by themselves and subsequently go through discussions and leanings that the pros have already been through. For example, every festival I've been on has behavioral rules you accept with the ticket purchase... 
&gt; Thanks! Is Ruby similar to Rust? From a language perspective, they are very different. &gt; I'm unfamiliar with "polygot", &amp; will look that up. "poly" means many, and "got" here is about language. Many languages. The term can be used with human languages or computer languages.
This kind of concern already arises, in some sense, today: it's roughly the difference between using an enum, or a trait, to say "there are multiple particular values that embody a particular interface". Part of the premise of Niko's post is that the open/closed distinction is a pretty fundamental one. That said, if you start with the closed approach, you can often add a new variant that's basically "Other", which could in principle take a type parameter to allow for downstream extension. That's not as simple as a repr change, but it's not a full rewrite either. Of course, you can't go from open to closed, since that would be taking things away from your clients.
One difference is that only the impl for `Node` has access to the virtual methods defined in the trait, so that's almost certainly where you want to provide the impl. And yes, these are where you'd generally put your non-virtual methods in the hierarchy. Finally, note that in cases where Node is an "abstract base class" you won't have that `NodeFields: Node`, since you can't yet provide an impl of all the needed methods. Instead, you'd have other structs (like `HtmlAnchorElement`) that both inherit from `NodeFields` and impl `Node`.
I totally respect your right to not publicly state politics. It's a scary and unpleasant action. Even the very benign politics I've publicly stated has people on the internet threatening me and telling me I'm a ... what are the words ... "secret-jew cultural-marxist sjw faggot", I think? It's really awkward. For a lot of years I preferred to just keep my head down and not discuss politics at all. I may well go back to that. It's exhausting. Similarly, I hear and respect what you're saying about the blur of concepts surrounding "left" and "right". I would never suggest putting "Rust Code Of Conduct: Be Left Or Get Out" on the label. I just think that -- from my current interpretation of the terms -- antidiscrimination policy is kinda a left-leaning stance. But if it's easier for you or others to digest if separated from that background "left-miasma", I wouldn't force the issue or even really prominently mention it.
&gt; Presumably different perspectives, but I have a hard time imagining that race, religion and gender would have much impact on how to design code. There have been studies showing that diverse groups are more performant. But that's really a cherry on top. The end goal is to remove barriers to participation faced by entire groups of people, just because they are a member of that group. Because it's not nice to have those barriers around, and it's being unfair to a lot of people. &gt; If it is just for "high minded" social reasons then giving special treatment to "diverse" people seems like it is insulting to them and discriminatory against "non-diverse people". Firstly, there's no such thing as "non diverse people". You can have people from a majority, and you can have a non diverse group, but a person isn't inherently diverse or non diverse. But I guess you were talking about majority/minority groups when using those quotation marks. Anyway. Nobody is saying that one group of people is intrinsically inferior to another. People are saying that certain groups of people face barriers to entry. These barriers are often invisible to the majority. It behooves us to find out what these barriers are, and put effort into bridging/removing them. This might mean focusing community resources in this direction. Outreach, paid internships, etc^1. It is some form of special treatment, but in a sense, the people of the majority group already get "special treatment" because of the lack of barriers. This doesn't necessarily mean tokenism in leadership roles. It can, but it doesn't need to. My own views on affirmative action are extremely nuanced (particularly due to where I currently live). I do not think that Rust should try to force diversity into its leadership. But I do think that it should try to fix the underlying issues and make it so that the entire community is diverse (by removing those barriers), (which in turn also makes it possible to get diversity in leadership without "forcing" it, so everything works out in the end!). ^1 I loved the "sponsored ticket" thingy done by Carol/Graydon/etc
Awesome! Was looking for something like this, will check it out later tonight.
Working on fleshing out Redox's shell if I have time. Too many things due this week for class, including lots of assembly code. Makes you appreciate languages like rust and how some real smart people figured all the low level stuff so everyone else can stay sane
I hope that does not cause memory unsafety when used as an index to a slice. I remember the undefined shift overflow behavior caused problems.
Please write a good description what is it. It's probably obvious to you, but "service framework" does not explain a lot to everyone as "service" is loaded with meanings. Good documentation is very important. let n_workers = 4; How is it doing anything?
Didn't know rust project is a political organization/project, where everyone but people with hard left stance are unwelcome... (According to Graydon's comments) Can we leave politics out of scope of the project, and focus on legalistic equality (not controversial), not equality of outcomes (controversial), and also focus on policing political and unwelcoming speech? (on rust community resources only)
Guys, what if (a sketch of an alternative proposal): * structs can extend stucts * inherent methods can be marked as overridable . * an implicit trait is produced for each struct * it includes all inherent methods * a special syntax exists to name it . * this trait can only be implemented by extending the struct * fields can be accessed via this trait . struct Node { ... } struct Element : Node { ... } impl Node { fn non_overridable_node_fn() {...} fn' overridable_fn() {...} // tick used to mark fn as overridable } impl Element { fn non_overridable_element_fn() {...} fn' overridable_fn() {...} } fn with_static_dispatch&lt;T:Node&gt;(t : &amp;T) {...} fn with_dynamic_dispatch(t : &amp;Node+) {...} The implicit trait produced for "Node" is referred to as "Node+" in this example.
That would be polyglot?
This, so many times this. Although not a game engine, it seems like a great idea to learn from this effort. It looks like a well thought out architecture, which can be found [here](https://github.com/glennw/webrender/wiki).
He was pretty explicit: &gt;I consider those people wrong -- politically and morally -- and will argue with them. But I don't think you making room for them makes you wrong, or makes them wrong. I think them being wrong makes them wrong. &gt;You think there's such a thing as "reverse racism", and you feel that "SJWs" have a "victim mentality". Those positions alone make room for more right-wing (anti-equality) discourse. &gt;It's a libertarian space that perpetuates the fantasy that there's some "off-axis" position (SSC calls it "grey tribe") that left-libertarian people can place themselves, that's somehow "above" the traditional left/right tug of war over equality. This is actually a right-wing stance; so-called "left-libertarians" are deluding themselves, along with people who say nonsense like "I'm a social liberal but a fiscal conservative". Substantive equality means taking a side on equality, and the side being taken is the right-wing one ("advantaged people earned it so they can keep their advantage, regardless of how they got there"). The "there's no left or right, only freedom and tyranny" nonsense SSC He's all about not making room for people he perceives (subjectively) as enemies of equality, as he understands it. His position is extremely political and left wing. Considering he makes such a political statements publicly, in a thread where community policies should be discussed, and we already have incidents where core members (Steve Klabnik) participated in political censorship, it is a reasonable assertion that you will get punished within the community for sharing an opinion, outside of the community, that core team strongly disagrees with. They don't make any statements guaranteeing political neutrality. The problem is that it's just a philosophy. It's not a fact. There are other points of view. I find incorporation of politics into software open source projects extremely troublesome and shortsighted. And I'm not even right wing, by US definition.
&gt; which can't be implemented with pure slicing at the moment (the compiler doesn't understand that x[..n] and x[n..] are disjoint for slices). Are you saying there is *a chance* for the compiler to understand this someday?
Any time you import `std::os::unix` or `std::os::windows`, it should probably be behind some type of `cfg` flag, otherwise your code won't compile on non-Unix and non-Windows platforms, respectively. (It won't compile because those modules won't exist!)
Ah ha, thanks! If only we had some documentation that explained all that üòÖ
Creating a stable API that who-knows-what third party tools can use would be a cool thing, among the many many other cool things that there are to do.
Can this work with existing serialization libraries? (it's not entirely obvious to me eg. how would it work with serde or cap'n'proto)
Wouldn't you just want to make a closure that takes two closures as parameters and calls '+' (or a third parameter, a combining closure) with the results of the argument closures for some value?
&gt; I totally respect your right to not publicly state politics. It's a scary and unpleasant action. Even the very benign politics I've publicly stated has people on the internet threatening me and telling me I'm a ... what are the words ... "secret-jew cultural-marxist sjw faggot", I think? It's really awkward. That sucks. :-( I've been fortunate enough not to be the target of that kind of vitriol, despite the fact that I haven't always been so reserved. Interestingly, for me, it isn't the outward consequences of expressing myself that gives me pause. It's the *inward* consequences. When I expressed my views on politics more, I found my quality of life decreasing, focus decreasing and generally experienced more emotional pain and exhaustion. I could either continue on that path or choose to focus on other things in life. I've tried to focus on the other things. :-) Mostly I've been successful and life has been a lot better because of it.
The following answer says that there is no kernel API for determining the creation date of a file for filesystems that support it: [How to determine the creation date of a file? ‚Äì Unix and Linux Stack Exchange](http://unix.stackexchange.com/a/91200/16833).
Hmm. I couldn't find any docs on it. Basically, it's Rust's way to do conditional compilation. For example, if you wanted to write your `creation_time` function, then you might actually want multiple definitions depending on the platform: #[cfg(unix)] fn creation_time(f: File) -&gt; Option&lt;u64&gt; { None } #[cfg(windows)] fn creation_time(f: File) -&gt; Option&lt;u64&gt; { use std::os::windows::MetadataExt; Some(f.metadata().some_windows_specific_method()) } There are a lot of other things you can do with `cfg`. Since I don't know if or where there are docs for it, the best thing I can do is link you to a place with the most comprehensive set of examples: https://github.com/rust-lang/rust/blob/master/src/liblibc/lib.rs
That's pretty cool. Thanks!
I'm not sure what you mean about having inherent methods hidden from child types. The inherent methods in the example are on the *trait* viewed as a type (DST style), which is something you can do today, and will result in a method you can call on any trait object for that trait. Can you elaborate a bit?
Re-reading your post, I might have been confused by what you said. I admit that I keep getting `Node` and `NodeFields` mixed up in my head. To clarify, considering this code: impl NodeFields { fn get_id(&amp;self) -&gt; u32 { self.id } } This is implemented on the struct `NodeFields`. Is it accessible for types which inherit from `NodeFields`, or only for that type itself?
That's a good question -- and one I think we could go either way on. In particular, the pattern I proposed involves this kind of implementation only on the `Node` *trait*, which then just follows the usual rules of the trait system. But struct inheritance is a new feature, and we'll have to decide how it should interact with method dispatch. In a way, the decision comes down to whether struct inheritance should be "only about the data/layout" or also cover behavior. I'm pretty comfortable with the stance that it's only about data/layout, and that we use the trait system when we want to abstract over, share, or inherit behavior.
Yeah, I misread the first line of your grandparent reply that I replied to as saying the implementing on `Node` is only available to trait objects, and implementing on `NodeFields` is available to all child types, when all you really did is clarify what it means to impl on `Node`. It would be my preference that struct inheritance only define data and trait inheritance only define behavior. I think the separation that Rust's syntax creates between the definition of behaviors and types encourages a certain clarity of thought when defining a system.
Well, I don't, I'm excited about this possibility as an user of the language. But what I would expect is some built-in trait to aid the compiler reason about overlapping (instead of special-casing `Range&lt;usize&gt;`). The problem is, `IndexMut` already exists and it controls the desugaring of `&amp;mut x[y]` without any notion of overlapping, and I don't know how another trait could interact with `IndexMut`. But if it were possible for another trait to interact with the `IndexMut&lt;Range&lt;usize&gt;&gt;` implementation for `&amp;[T]` for the purpose of allowing multiple non-overlapping mutable borrows, it should be possible to interact with `IndexMut&lt;Range&lt;&amp;str&gt;&gt;` for `YourType&lt;T&gt;` so that you specify a custom logic that is valid only for `YourType`. If this were possible, we could imagine a custom logic for the `IndexMut&lt;Range&lt;usize&gt;&gt;` implementation of `CircularBuffer&lt;T&gt;` that respects the circularity, etc. Of course this is all hand-waving; I don't have a concrete proposal. Note that this could, in principle, be backwards compatible because it would allow some code that is currently rejected by the borrow checker.
Seems like a lot of work just to get rid of `split_at_mut` :)
https://doc.rust-lang.org/book/conditional-compilation.html
Generally, I don't like pure criticism without a fixing PR.. But then again, I noticed that too. With the old style, the first thing your eyes would do on the page is start reading the text, and it is a pleasant experience. Nowadays you have to re-read the email ad first, remember why this is not a spam secondly, and only after both those considerations start reading the text. Long story short, the old style felt stupid and the new style feels smarter. Stupid was better.
Ah nice! Thanks!
what about MIO https://github.com/carllerche/mio ? Async programming is not easy but if you want to get into it, look no further. MIO makes a great job abstracting most platforms async interfaces to sockets without little to no overhead.
I disagree. 
&gt;And I don't know what these "horrible feminists acts" you're describing are; **I haven't seen any feminist Elliot Rodgers running around**, but maybe I'm looking in the wrong places. This stuck out to me in a funny way. You're basically boasting that feminists aren't *murderously insane*! And I think it highlights an important difference in our viewpoints. From my point of view - and the point of view of nearly everyone I know - feminism isn't competing with MRAs. Feminism is in the same category as Bernie Sanders supporters, student protesters, LGBT pride parades, and people who really like guns. Feminism is a reasonable kind of thing, it's something that normal people believe in. MRAs are up there with 9/11 truthers, PUAs, the tea party, unpleasantly opinionated cab drivers, and school shooters. Nobody reasonable is an MRA, almost by definition. You'll never convince an MRA to see the world through your eyes. They're by and large delusional, disorganized (except on the internet), ineffective (see: their track record of getting absolutely nothing done), and of no political threat to polite society. Well, I lied, they actually threaten polite society in one very specific way (again from my perspective): by constantly needling at feminists, by manipulating them into thinking they are more powerful and more nefarious than they actually are, they're radicalizing feminists. When feminism is under attack, feminists react by pushing for measures like safe spaces, codes of conduct, and whatever the hell is going on with Title IX right now. This is ostensibly done as a push for equality, but I think it wouldn't happen if there wasn't a perceived need for means of defence against MRAs. (Scott has written on the converse effect, in which radical feminism triggers a radicalization of, in his words, [the romanceless](http://slatestarcodex.com/2014/08/31/radicalizing-the-romanceless/). The idea of opposing radical factions synergizing isn't new; Scott discusses it [here](http://slatestarcodex.com/2014/12/17/the-toxoplasma-of-rage/), while CGP Grey also does so [here](https://www.youtube.com/watch?v=rE3j_RHkqJc). From this point of view, the battle between the left and the right is accompanied by an orthogonal battle between radicals and moderates.) &gt;I would encourage you, in any case, to rethink the notion that one can meaningfully be apolitical, as SSC and many modern libertarians wish for themselves; I don't believe one minute that anyone can "meaningfully be apolitical"; politics is nothing less than the fabric of society. SSC doesn't claim to be apolitical either. Scott comes out for [effective altruism](http://slatestarcodex.com/2015/09/22/beware-systemic-change/), [universal basic income](http://slatestarcodex.com/2013/12/08/a-something-sort-of-like-left-libertarianism-ist-manifesto/), [animal rights](http://slatestarcodex.com/2015/09/23/vegetarianism-for-meat-eaters/), and, yes, [social justice](http://slatestarcodex.com/2013/04/20/social-justice-for-the-highly-demanding-of-rigor/). His overarching philosophy makes him essentially an [activist for moderate politics](http://slatestarcodex.com/2014/02/23/in-favor-of-niceness-community-and-civilization/). Neither am I apolitical by any definition that I would consider reasonable; I've camped in OWS-style occupations, I've marched somewhere around a hundred times for the rights of the poor and trodden upon, I've done "mobilisation" for political causes and events, etc. You calling me (and SSC) apolitical feels dismissive and mildly insulting. We subscribe to different schools of thought, and that's okay; but you're essentially saying that my school of thought isn't one, that only your way of seeing things matters. I don't think I want to have a discussion on these terms. I don't care about being right - I don't *trust* myself to be right, neither do I trust anybody else. I just want to grow my garden into something welcoming and peaceful.
Any time. So pumped we got the errors chapter landed.
The current API basically works the same way the github API works. You put/delete/get particular URLs, and get back simple JSON (which cargo just serialize/deserializes with rustc_serialize). Here's the full list of URLs: https://github.com/rust-lang/crates.io/blob/master/src/lib.rs#L73-L114 Working with it a bit, it seemed pretty clean/intuitive.
Show me the way to the errors chapter?
Nightly https://doc.rust-lang.org/nightly/book/error-handling.html is much better than stable.
Yeah, I'd like to see the C++ version wrapped. Seems like a better fit for Rust.
&gt; The rustc_front::visit::Visitor trait is quite similar to LateLintPass Note that lint passes basically _are_ visitors (they're implemented as such). You can give fields to the lint pass, and implement one or more visitor methods as the `check_` methods. The difference is that lint passes will recurse unconditionally -- you can't control this since all lint passes are run simultaneously. Which is why it's more efficient to use regular lint passes instead of passes which delegate out to a visitor. If you don't need the ability to control if/when you visit a nodes children, most such lints can be written as regular lint passes. For example, I have a regular lint [here](https://github.com/servo/servo/blob/master/components/plugins/lints/unrooted_must_root.rs#L34) which is able to keep track of what kind of function it's in. On the other hand, I use your visitor pattern [here](https://github.com/Manishearth/rust-tenacious/blob/master/src/lib.rs) since I need to use ExprUseVisitor, and similarly [here](https://github.com/Manishearth/humpty_dumpty/blob/master/src/lib.rs#L60) because I need to use the visitor's call stack to maintain state. 
&gt; One to ponder I really appreciate you taking the time to reflect / read / engage the topic! I know it's very tempting to simply dig in to defensiveness when someone pushes you on an uncomfortable thing. &gt; something doesn't need to be equivalent to institutional racism to be be worth avoiding At the risk of belabouring the point: while I completely agree with this statement, it's also worth not redirecting a conversation about (say) racism to a conversation about one's own discomfort with the topic. Which is what one does when one interrupts such a discussion to voice concerns about "reverse racism". This is also called "derailing" and it's a sufficiently common problem in such conversations -- even if done unintentionally -- that there's an [entire website dedicated to the topic](http://www.derailingfordummies.com/). Highly recommended reading. &gt; this whole thread has left me exhausted, stressed and thoroughly despondent Oh, I'm sorry. If it helps, picture me as just another foolish, tired, confused ape banging away on a keyboard trying to make my feelings understood. I'm glad our interaction here did not degrade to screeching and throwing poop at each other. Take a nice walk and stare up at the stars. It's not worth getting despondent over.
&gt;Five specific ways: they go on shooting rampages and blame it on sexual frustration. If someone was saying that "Islamists threaten polite society by blowing up crowded marketplaces", I think you would agree with me that it's a cheap shot. Any way you look at it, Elliott Rodgers is an outlier, and you're milking his example for political capital. &gt;but you then, it seems to me, proceeded to disavow that life, recast it as a period of youthful, tribal leftist delusion and take up with the "grey tribe" Not at all! Just two weeks ago, I was part of an on-campus occupation in protest of McGill cozying up with oil companies. Slept on campus in my tent and everything. July through September were peppered with marches and protests and training camps. Just because I don't call myself a feminist anymore doesn't mean I'm changing my habits. More generally, I don't think I've ever seen anyone become *less* of an activist because something rubbed them the wrong way; you fall out of being an activist when you become complacent with the way the world is, not when you realize just how much it sucks. &gt;I also think this musing is wrong, and this so-called "grey tribe" is just a bunch of people who haven't reflected enough on how public policy I think you have some very specific preconceived ideas about "grey tribe" folks that aren't necessarily carried out in reality. In particular, SSC is a central example of the rationalist community, a group of people whose literal hobby is abstract political analysis and dissecting sociology theses. &gt;while simultaneously dismissing everyone currently engaged in political activity as merely enacting tribal prejudices Not everyone in politics, just everyone who's arguing dirty. That's a *lot* of people for sure, but there's enough remnants to make up a movement. &gt;If he has some plan B for achieving universal basic income outside of public policy No one dismissed public policy; it's the only potentially viable option for UBI. UBI is different from classic socialism in that it says nothing about ownership of the means of production, centralized planning, et cetera. I think you're a good guy, and you're someone I'd like to agree with. I think you've been doing some good work, and I'm glad that you seem to be planning to do more of the same. I just hope you can keep an ear out for shifts in discourse, an open mind for new narratives and changes in concerns. I promise I'll do the same, and (who knows?) maybe one day I'll wave the feminist flag again.
Are you looking in future to be compatible with the Open Container Initiative? https://www.opencontainers.org/ 
Huh. Those all just feel like very minor sideshows to me, relative to substantive political concerns of feminism. But maybe that's what you mean by modern, american feminsm. *Shrug*. As a weird aside, [I did write about](http://graydon2.dreamwidth.org/195155.html) Comment 171 and SSC's followup back when it was in the news, too. But it's late and we're burying this thread in our very very very tangent-y tangent here. Thanks for the clarification, goodnight.
This just tells which first element is the largest, not the whole tuple, unfortunately.
If it came to it, I'd vote against both: neither gives any meaningful benefit in exchange for the added complexity. Actually, the comprehension example doesn't make any sense, so maybe you intended something else. Besides, the first could be done with a trait extension method, and the second (assuming you mean an actual list comprehension) [can be done with macros](https://github.com/bluss/rust-itertools/blob/experimental/src/macros.rs#L1-L48).
Hi, This is the binding API for java version. Pivotal's C++ version looks nice, but it seems to need more work according to the jira (https://issues.apache.org/jira/browse/HDFS-6994). So, I firstly started working on the binding API with java version. It may be possible to improve my implementation to use both Pivotal's C++ and Java's one. How do you think about a pure HDFS client in Rust? It may be not trivial work. But, I was very motivated by other friends. See this tweet conversation https://twitter.com/hyunsik_choi/status/652183698637361152. I've already started developing the pure client in Rust. Actually, there are many references like snakebite, libhdfs3, and pure hdfs client in go. So, it may be not difficult and just needs time. Honestly, I also need well-implemented hdfs client because I'm developing on some distributed processing system in Rust.
Here is the repository for the pure HDFS client. https://github.com/hyunsik/libhdfs-rs I've just started this work yesterday. The progress is trivial. I also surveyed some materials for this work. https://github.com/hyunsik/libhdfs-rs/wiki/Survey
I'm not talking about being added to the core rust, I'm talking about cool stuff people would like to see done with compiler extensions
Shameless plug: If you're just looking for a way to retrieve some data from the Crates index, check out my Rust library [rust-crates-index](https://github.com/frewsxcv/rust-crates-index)
It would be nice to have type information in macros for a start.
Thanks! It was /u/burntsushi's blog post that we imported in. :)
The crate lives here: https://crates.io/crates/plumbum The resulting types can be used both for pull- and push-based streaming, which means effortless switching between synchronous and asynchronous IO. IO is also performed completely lazily, which makes it nice to use for paging results, for example, because the next query will only be dispatched when it's results are needed. I'd love your thoughts on this!
Yes macros was the wrong word. Some level of compile time reflection in the stable language is what I meant. Compiler plugins are great, but that is something that will always exist "besides the language" and not be part of the language itself. They are way better than other languages where one basically would need to "fork the compiler" to achieve the same thing (and that's actually what happens often in the c++ world).
This looks very interesting. I haven't looked into the source yet, but: * You may want to add more info to your `README.md` * Even with the example, I'd imagine people not familiar with Conduit will have a hard time understanding this. A high-level introduction (or at least a link to one for Conduit) may make sense * We Want Benchmarks! Take a simple example, write it with Haskell/Conduit and Rust/Plumbum and time the execution. Put the results in a neat table in your README.md for bonus internet points. * Try travis CI ‚Äì you can even get a badge that shows your passing build on your README (this will also be a quick way to see which version(s) your code builds against) If you want, I can open issues for all of the above on your repo. Or at least help with travis.
Some questions, Does Rust have an equivalent of GADT? (trait objects are said to be existential types - do they somehow encode GADTs?). Is there something in this paper applicable to Rust? Would the difference of Rust's type inference (that is local) to Haskell's type inference affect the way pattern matching is processed? One thing this paper tackles is that Haskell is lazy and inserting "dead" cases, that are subsumed by previous ones, may alter the semantics of the program. More and more I think that laziness by default is the wrong choice.
http://news.mit.edu/2014/workplace-diversity-can-help-bottom-line-1007 (http://www.econstor.eu/bitstream/10419/46438/1/638873185.pdf), http://www.mckinsey.com/insights/organization/why_diversity_matters, etc
This looks good! I have been trying to do [something similar](https://github.com/Geal/nom/blob/1.0/src/stream.rs) for the 1.0 release of nom. If it is able to handle partial consumption of byte streams, I might just skip it and use your code. Could it handle reading part of the input buffer, and add more data if needed? From what I see in [your code](https://github.com/srijs/rust-plumbum/blob/master/src/io.rs#L5-L31), a new buffer is allocated on every read, right?
Partial consumption is handled via the "leftover" mechanism. A consumer can read a chunk, split off part of it, and push the rest back upstream to be consumed by the next handler. The code that's in the `io` submodule (which you linked to) hasn't been given much thought yet, and is at this point really just an example of how to write side-effecting sources and sinks. The idea is that the conduit machinery is completely independent from it, and different I/O mechanisms can be plugged in (push/pull, sync/async, copy/zero-copy, etc.). I think it would be very valuable to gather some data on read world use-cases (such as nom's) at this stage of the project, so I'd be happy to discuss your needs with you. Feel free to shoot me a PM if you like :-)
Yeah, but there is a method available as part of the library to automate cloning the index [here's an example of it in use](https://github.com/frewsxcv/crate-deps/blob/3659d21ba3ce8d42c07c27d520c85d9310320c26/src/main.rs#L71-L75)
Thanks. That's still a pretty heavy load of data to just find out a couple of things, but in general it seems ideal.
I'm not sure that makes them GADTs. What you need is Enums where different constructors have different type parameters. 
They could be separate from macros, see [generated functions](http://docs.julialang.org/en/latest/manual/metaprogramming/#generated-functions) in Julia.
Well, the `println!` thing seems possible. The tricky part would be to shadow the real `println!` while avoiding infinite recursion. I'm not sure if _that's_ possible.
&gt; The only thing one can do is create new types based on already existing ones. I don't see how this would be unfeasible since rust already supports it. You can tweak traits and stuff too. What would happen if a macro used trait based info to generate impls? You'd get a paradoxical cyclic dependency. &gt; iterating over all types/functions/struct/enums in a module, getting their data members, names, method impls, trait impls, ... and creating new types or functions based on that. Ah, there you are. This is a totally different feature entirely. You're asking about some form of metaprogramming; this isn't macros (of any type, forget "Rust macros"). (Yes, you mentioned that, I missed it and thought we were still talking about expand-y things, sorry) Iterating over tuple elements and enums is certainly something I want. Variadic generics might actually get us somewhere here, though even just a usable `Reflect` trait might be able to get us most of the way. 
&gt; neither gives any meaningful benefit in exchange for the added complexity I guess you mean, in the case where they are syntax extensions instead of macros or iterators? I'm asking because both sound great to me as things I want to be able to easily express in the language. 
Wouldn't it be possible to have a macro that gives you a type of an expr or ident? So I could do something like this, inside a macro (silly example): macro_rules! do_expr { ($do_it:expr) =&gt; ({ let v: type_of!($expr) = $do_it; ... )} } This was something that I missed having once or twice. Obviously in this example I can use type inference, but there were a few cases where type inference didn't work and I had to jump through hoops to work around it. 
Yes, that is possible, with some compiler tweaks (`TyTypeOf`). But it might make inference hairy.
Thanks for the tip. I'll have to try that.
Nice critique. Rust doc not coloring links is an [old bug](https://github.com/rust-lang/rust/issues/15307) that just hasn't been fixed yet. The most recent major discussion on making rustdoc better happened in [users.rust-lang.org](https://users.rust-lang.org/t/lets-talk-about-ecosystem-documentation/2791). Not knowing which types are supposed to be directly used is a common pain point with rustdoc. One [proposed solution](https://github.com/rust-lang/rust/issues/28057) was to hide indirectly created types (maybe with a toggle). Other suggestions have probably been made in that second link possibly related to how the docs are written and such. That is tricky though because historically, writing docs are hard and often done poorly. There is also inconsistency about how a lot of them are done which isn't great. (I'm not sure if you're commenting about this or not but...) The code examples are linked to the playpen (via a button on the top right when you mouse over it). Any specific things the rustdoc search should be better about? Again, real nice writeup.
&gt; I am on mobile and can't type out a lot, but I wanted to link to http://aturon.github.io/blog/2015/08/27/epoch/ Was crossbeam supposed to support PIDs?
Thanks for the feedback! I agree that we need to improve our library ecosystem -- it's getting there, though. Could you list the libraries which you needed which didn't work on stable? In many cases it's a few tweaks to make them stable-compatible. It's also useful to know what features are blocking stability for libs. Couple of notes: &gt; I've heard each cargo release makes assumptions about the command line interface to rustc, So far I've never come across this, but YMMV &gt; it seems that using persistent immutable datatypes to do sharing is under-utilized? I think Haskell has demonstrated the power of doing this and rust has good features for leveraging it too. A lot of the immutable Haskell patterns don't translate well to Rust. Well, they translate, but they're usually unnecessary. In functional programming, purity is king, and the datastructures you use reflect that. In Rust, we've managed to find a middle ground between purity and the mutation wild west, so we still get safety without needing immutability everywhere. This means that often there's an equivalent or better way to do something in Rust for a given pattern in Haskell. Of course, if you absolutely need them, you can make one yourself. As for singly linked lists, this is a really simple implementation: enum List&lt;T&gt; { Cons(Box&lt;List&lt;T&gt;&gt;), Nil } Linked lists are also rather specialized data structures outside of functional programming -- most times you want a queue or something. &gt; Unfortunately, this doesn't work in the code examples. This sounds like a fun little project, actually. Would make `rustdoc` a lot slower but it could be an optional pass. Filed https://github.com/rust-lang/rust/issues/28954 &gt; as they often have very little line/file/function name info Generally for full backtraces, compile in debug mode and perhaps use a debugger. Setting a breakpoint at `rust_panic` works. &gt; but safe ways to use the API haven't landed yet? [This](https://github.com/Detegr/rust-ctrlc/blob/master/src/lib.rs#L79) seems safe. I'm not sure why the underlying `set_os_handler` functions are unsafe, however. 
You need a box inside of Cons
d'oh, meant to write it, forgot because I was too busy getting the code block indentation right :P
Yeah, people have missed it before. Maybe it should have a permanent button on it and not just on hover. I'm not really sure. Or maybe permanently until you mouse over it and then off again...
Or perhaps begin by just making it bigger and with solid background, with something like **‚ñ∫ Run** written.
&gt; Could you list the libraries which you needed which didn't work on stable? I didn't keep good notes on the specific libraries, but anything that needs compiler plugins seems to be more or less out. That seems to be most libraries that extend syntax or do code generation. lalrpop works because it has its own (simplified) Rust AST and pretty printers for it. Things that depend on syntex work around the need for compiler plugins, but due to a [cargo bug with flag handling](https://github.com/rust-lang/cargo/issues/2021#issuecomment-146415755) I couldn't build things that depend on syntex. The other notable build issue is the readline crate. It was getting to this [line](https://github.com/GBGamer/readline/blob/master/src/linux.rs#L48) and failing. It seems like that code path wasn't intended to build on windows as there is a separate `widows.rs` module. I didn't look any deeper than that.
I would never use `unwrap` unless it's in a doc test.
Thank you!
That's a doubly linked list. The ML code uses a singly linked list and that seems more appropriate me for what they are doing.
The point of op's code is to share environnements. Think closures, if you have 2 closures in a function they both have a link to the function's environment, even if the environment is immutable you'd usually rather avoid copying it entirely, so you chain local contexts via a linked list, and each closure's context links to the same parent context. 
It's for lock-free data structures, which are usually shared-mutable. However it does provide some kind of concurrent GC... but one optimized for "I'm removing this, destroy it when stragglers are definitely not looking at it (box-like)" and not "destroy this when no one is using it (rc-like)"
Ah, plugins. We're thinking up ways to make them at least _somewhat_ more stable; or make things like syntex work better.
Derp
I realize I made a mistake in my original example. Corrected. What I want is the ability to specify defaults for `Foo` in the subtrait `PartialFoo`: those defaults would only exist for things implementing `PartialFoo`, but not for things implementing `Foo`. It would also be nice to declare these defaults `final` or something like that, so that an implementation either can't override them, or has to be very explicit about the fact that it wants to override them. Can defaults be specified by a subtrait like this?
You can use `take` and `collect`: rand::thread_rng().gen_ascii_chars().take(len).collect()
The only issue that I see is that you reexport petgraphs structures. Why so? I've created pull request to remove that bad smell.
The other reason to use it of course would be if you know it cannot not fail for some reason (e.g. the first `next()` call on a `split()` iterator).
That looks like roughly the same idea, thanks for the link! I prefer the flexibility of extending a trait with a new name, instead of partial application based only on the presence of other impls.
&gt; In my experience, parser combinators do not deliver in these areas the way parser generators do (for instance, how do you get warning/errors about the equivalent of shift/reduce and reduce/reduce conflicts when using a combinator library?). As far as I understand it, parser combinators and PEG parsers in general are fundamentally recursive-descent parsers, so shift/reduce and reduce/reduce conflicts are impossible: the parser doesn't do shifting or reducing.
I know there's some vocal naysaying of stable Rust occasionally, but I've found it I can use it for pretty much everything I do with Rust, as long as its not either crazy hacky experiments or compiler hacking (or both at once :P ), and even the experiments can often be done with stable Rust. In any case, there's definitely a pile of important (e.g. hyper) and interesting (e.g. crossbeam) libs on crates.io that work on stable. Concretely, I have a project with 65 unique transitive dependencies in total which compiles against 1.3.
I re-exported the petgraph crate as I thought it would be easier for users to access its `algo` and `visitor` modules, as well as any of the other functionality exposed with a version that is sure to be compatible with daggy. `Dag` allows the user to convert it into the internal, more generalised `petgraph::Graph` data structure so that a user may take advantage of those algos - it seemed a little annoying to require the user to manually import another library to do so? I'm interested to hear more reasoning into why you feel that it is a bad smell? BTW, thanks for taking the time to review/check it out - I appreciate it!
You don't need Rc or Arc to share parent environments between children contexts. You just need references, e.g. as in http://is.gd/80evs4 (obviously, this works for lists too :); you can also replace the references with `Cow`s and allow these structures to be returned from functions and represent persistent BSTs with some extensions to this, but I don't think that's necessary for the unification strategy being used). Anyway, I am looking through the original implementation and there isn't actually much of a reason to share environments like that, I don't think... I'll elaborate more in a bit. It's currently not very efficiently coded (no fault to the OP, it's quite nice looking for a first Rust program and I've done similar stuff during initial translations from ML) so the expressed desire for structure sharing would not significantly improve the running time.
See [PR 28963](https://github.com/rust-lang/rust/pull/28963)
Regarding parsers: Shift/Reduce and Reduce/Reduce conflicts are particular to building certain kinds of parsers. They *may* indicate conceptual ambiguity in your grammar, or they may simply indicate that your grammar doesn't fit within the parser's formalism. A LALR(1) parser like yacc might indicate a conflict when a full LR(1) parser would not. This is a useful warning if you're intent on using that particular formalism, but does not give you an unambiguous indication that there's a conceptual problem with your grammar. Another issue with external DSLs for parsing is that they can make it difficult to provide good parse error feedback to users. Because they require a context-free formalism to build their parsing automata, there's not much in the way of context available for producing good error reports. I think this is the primary reason that very few production compilers actually use DSL-produced parsers, though my next point is significant as well. Real-world parsing situations also rarely have completely context-free grammars to deal with, and often the process of making a grammar context-free adds significant complication to it; e.g. factoring out expression parsing according to the precedence rules of various operators. Many parsing tools provide extensions to the formalism (precedence annotations for operators, order-based disambiguation of productions, semantic predicates), but then you're stuck with the sorts of extensions provided by the tool you're using, which might not work with your particular grammar's cases that need to be disambiguated. So, while parser generators are undoubtedly *very nice* to have in some cases, and I'm sure Rust will get more of them as time goes on, I think that tools like nom's parser combinators are actually a more generally useful building block for production parsing jobs. They provide a syntax that is not too far from a formal grammar notation, but give you the full strength of the host language for disambiguating things and keeping track of the context necessary for good error messages. They're essentially a shorthand notation for the sort of parsers that are actually written for production compilers, which is a nice thing to have around when you've got a known language/format to parse. For *designing* a grammar, they're not too helpful; but you can always use another tool to help you design an unambiguous (or with controlled ambiguity that you know how to deal with) language and then use parser combinators to parse it. I don't want to belittle your preference for external parser generator DSLs, but if the experience of production compiler teams is anything to go by, they may actually be *less* suitable for production use than handwritten parsers. As they provide an *embedded* domain specific language, parser combinator libraries lack a bit in elegance of notation, but I think the compromise in notation is worth the extra power gained in integration with the host language and makes them a real candidate for long-term usage in production code. I'd encourage you to give them another look with this in mind.
&gt;Firstly, there's no such thing as "non diverse people". You can have people from a majority, and you can have a non diverse group, but a person isn't inherently diverse or non diverse. I was meaning diverse or non-diverse w.r.t. current group makeup, IE if you have a group of awesome 'Muricans than a your'o'peein would be a diverse person wheras I wouldn't &gt;People are saying that certain groups of people face barriers to entry. Supposing you are an able bodied person (not color blind, blind, deaf etc) other than being poor what barriers could we have? I mean sure we use English, but then that is the Lingua Franca of CS iirc But we should probably do something for the colorblind, hmm unless they have their own custom css already....... But if these exist and are actual things (not "microagressions" or "Oh my they used 'he' 50 times in a tutorial, but 'she' only 40 times, sexism!!!") then let us address them! &gt;I loved the "sponsored ticket" thingy done by Carol/Graydon/etc Was that the one for women and other under represented folks getting free tickets? if so that is cool and all but also demonstrates the philosophical issue that worries me.... Alice and Bob are fraternal twins who are poor, but both love cs, engineering and rust. Some nice folks are giving free tickets to a rust conference away to under represented demographics so Alice snags a free ticket! yay for Alice! Bob gets nothing and doesn't get to go :-( Bob becomes so depressed he decides to program in go instead :-( and then he decides to become a communist and worse a pittsburg steelers fan! (ok I hope my humor isn't distracting. too much caffine in system) Sooo conclusion giving money to help under represented folks get into rust? Good! Giving money to help just plain old poor folks regardless of demographic other than need? Better? Debating it on the internet and giving no money? ~~Best!!~~ er well I guess that is what I'm doing! Hmm... If there is a local rust conference that I attend I will do my best to bring at least one person with me who could not come otherwise regardless of demographics. (unless they are steelers fans! Go Browns!!!!! {you'll never guess my state XD}) Maybe that should be a thing, bring a fellow rustecean if you can.
Rust lets you have more control. It doesn't have a GC, so you can just use `Rc` or `Arc` for a couple of things you need to share, and no GC for the majority of things you need. Out of those languages it lets you have the best performance and control.
Rust Pros: Safety, same control as C or C++, and it's a modern programming language (so it has nice modern features!). Rust supports functional programming, but it is a systems programming language above all else. On the other hand, Haskell is built entirely around functional programming. Idk anything about Go, so I won't comment on it. Anyways, what do you mean when you say you're considering Haskell, Go, and Rust? What are you considering them for?
Even then, I try to avoid it if at all possible. Rust doesn't have very friendly error messages for failed `unwrap()` calls - it reports the line of the `unwrap()` function instead of its caller, so every `unwrap()` call is suspect...
Working on an issue in rust-websocket that is blocking development for rust-ddp. My PR is aimed at making the library clone less data although after a week of work I'm stuck on one last bug, any help is appreciated!!! This is issue #49 on GitHub.
You sound like you know your shit. I know Scheme and I'm good at getting stuff done in it. Why should I learn Haskell? Assuming I already *actually* understand how functional programming works from a Scheme perspective, is there still a benefit?
Go is a solid, simple language for getting things done, but it is a dead end if you want to explore functional ideas and get a feeling for the benefits an advanced type system can give you. Rust is not a functional language, but it feels functional due to its expression based syntax, and its Haskell/ML-style type system. I would consider it a good stepping stone towards Haskell, and it would give you bang for your buck in terms of giving you the ability to write fast, low level code that would interoperate with higher level languages like JS in a nice way.
Ignoring the static analysis benefits of using a parser gen there is still a "long tail argument": There are a few notable software projects that benefit from the investment of a hand written and tuned parser (for the reasons you mention). For each one of those there are orders of magnitude more smaller projects that need a parser and developer time is scarce/valuable and the parser generators get decent results. It's similar to the arguments for using assembly code. Most software doesn't benefit and is better off using a high level language. Then there are occasional libraries like libgmp.
Nightly rust build? Or is there nightly docs or something like that?
Rust: * doesn't have GC, so you don't have to worry about unwanted stalls * has bidirectional FFI (you can call C functions from rust, as well as rust functions from C easily, without wrapping their arguments) * has zero-cost abstractions just like C++ IMO the biggest disadvantage of rust is that its compiler is still very slow (mostly due to LLVM passes). 
I think that there are just as many similar arguments, if not more, that you could make in favor of parser combinators over parser generators. 1. A parser combinator library is just a library; you don't have to learn a new tool and how it needs to integrate with your language and build system. External tools are generally more adopted for big projects than the small "long tail" ones. 2. Parser generators require learning more parsing theory to determine what kind of grammars are acceptable and how to deal with changing your idea of how the language works to fit the parsing class the tool uses. Parsers built from combinators follow a recursive descent pattern, which is typically already familiar to most programmers. If you've already invested in learning the requisite parsing theory, using a parser generator may represent lower up-front investment, but I'd guess that it's the other way around for many small projects. 3. Parser combinators *are* a high-level language for describing how to parse a language. A well-written parser built from combinators tends to be written at about the same level of abstraction as those written for a parser generator tool. I don't think your comparison of parser combinators to assembly language is very apt, as I think that given familiarity with both the combinator library and a parser generator tool, the amount of effort to get a basic parser up and running with both will be fairly similar. The win with the combinator libraries is that you will be able to change the parser in the future in more ways without doing a from-scratch rewrite as your needs change. You can also use the powerful abstraction features of your base language to help you, whereas with an external DSL you're stuck with whatever features were provided by the tool. I think it's interesting to look at the parser situation in the Haskell ecosystem, which is where the idea of parser combinator libraries came from. Previous to the introduction of combinator libraries, some solid parser generator tools (Alex and Happy) were created and heavily used. More recently, however, almost all new projects that need to parse something use one of several parser combinator libraries *instead* of the solid and previously frequently-used parser generators. If your arguments about the "long tail" held, we would expect that all the small projects in Haskell that needed to parse something would use the existing and robust parser generator tool. But empirically that is not what you see in the Haskell community, and given that libraries like nom that provide both a reasonable level of abstraction and reasonable performance can be written in Rust, I suspect that we'll see a similar pattern here as well even when we have robust parser generators. I have to ask; have you taken the time to learn and use a parser combinator library, or is your experience only with parser generators and completely from-scratch hand-written parsers? I think that if you get familiar with parser combinators, you may find that they're not as bad as you seem to think. On the other hand, you may still strongly prefer parser generators, but at least you'll have more experience with what I think is a very interesting approach to parsing.
&gt; the periodic table ...and I was enlightened For some reason, after all that I've learned about Rust, it's never seemed quite as simple as it does now. Thank you for linking to this. And thank you to whoever made it in the first place.
Yes, for assertion calls [Option.expect](http://doc.rust-lang.org/std/option/enum.Option.html#method.expect) is generally a better idea. Though unwrap would really be more convenient if it reported the relevant error location.
It depends on the problem. Haskell has an LLVM implementation and Go a GCC one, so for small enough microbenchmarks they'll end up pretty much identical. For some (IMO, contrived) classes of problem, optimized safe Go and Haskell can outperform optimized safe Rust. Rust is designed to perform well in real programs (for the most part--it's pretty icache-heavy) and in my experience porting a program to Rust from a language that isn't C or C++ usually results in very noticeable runtime improvement.
Accessibility is another goal. Sure. I have tried the rust docs with Orca and stuff works^1 (Though this was long ago. I should try it again.) &gt; other than being poor what barriers could we have? Here's the thing: Most of these barriers are invisible to those not facing them. Most women get driven away by sexism. Being ignored by others on technica issues. Being "tits or gtfo"'d online. These are generic barriers to joining many open source communities; and even if they're less present in Rust they may still be there. (And their existence in other open source communities colors how people view Rust -- we have to put ourselves apart from the generic default to succeed) Similarly, conferences. You might be surprised at this, but even today many conferences have reports of harassment and other things. Women are also repeatedly assumed to not be programmers (instead, SOs of programmer attendees, or designers, or whatever) at conferences. These are not things they read about. These are not things they here on the grapevine and get scared about. These are things which happen to _most_ women. Stuff like this can make you want to leave a community, or can make you think twice about joining one that looks similar. Look at the number of women in the Rust community. Now look at the number of women in tech (still low, but not _as_ low). It's proof that there are _some_ barriers for entry somewhere. _You_ don't get to decide what barriers there are and aren't -- the barriers are invisible to you. The people facing the barriers get to decide this. It's the same thing about the Alice situation. Alice faces _plenty_ of obstacles making her not want to be a part of the community. Perhaps on being convinced by her fraternal twin she would have joined the community anyway. But there are plenty of other Alices out there who would avoid the community for some reason or the other, and have nobody assure them that it wouldn't be a problem (and honestly, we can't even be sure that it wouldn't be a problem). Sure, the impoverished are another group of people that could be supported. I don't disagree there. Financial support for confs for these people would be nice too. But that doesn't mean we should shy away from trying to fix these problems as well. (Additionally, those issues really stop at confs. People may not be able to attend confs because of their income. Whereas, the sexism/racism issues are pervasive and make groups of people not want to be part of the community at all) &gt; But if these exist and are actual things Did you just say that sexism in tech is not an actual thing? Then you're clearly not aware of its scope. :/ I'm not talking about micro-aggressions. ^1 After being inspired by a blind programmer friend of mine, I often turn on Orca, close my eyes, and try to use the Internet (and do other everyday tasks). It's a good way to learn about these things. I'm unable to do _programming_ with Orca, but that's a pretty advanced skill. I suggest everyone try this at least once.
The performance itself is a minor problem. Garbage collectors are not as slow as often stated, but you loose control and that hurts your optimization potential. In non-gc'ed languages you can store objects on the stack or inside of other objects or use pool allocators, object pools or regions in a time-critical section and often the effort to perform these optimizations is quite low. These control allows you to reduce the number of allocations and deallocations and improves the cache locality which may give a LOT more speed. Garbage collected languages tend to be fast enough most of the time but once your program runs into performance issues there is little you can do and some of the remaining options, like replacing objects with primitives or implementing manual memory management using object pools on top of a garbage collector, completely wrack coding style and maintainability.
Thank you. This was a great explanation of the benefits of using monads. Now I just need to understand them and start using them..
Yes, I wish `unwrap()` actually told me where it was called from... it would save me hours of work when things don't work!
&gt; If you actually use this, I think moving is actually a pretty good name (move is taken, it‚Äôs a keyword). Save the {} for obfuscation contests. Can you not just do impl List { fn consume_the_list(self) { // error: cannot borrow immutable local variable `self` as mutable // self.walk_the_list(); let mut self = self; self.walk_the_list(); } } ? Edit: You can't, but you can do something [very similar]( http://is.gd/pIr4wF). Which, IMO, is much more obvious. Edit2: I suppose the issue with this approach is that it doesn't mesh as well with Method Call Syntax.
I'm concerned about the cost of cycle detection, it's kind of a nontrivial cost. I haven't read up enough about this for petgraph and so on, but what I understand it's fundamentally a very expensive algorithm in the general/worst case, even in the incremental version. However, heuristically, in the practical cases it should be pretty quick to discover or reject the possibility of a cycle, in particular if know that the previous state was a DAG. For example you could check if an edge you add only connects two previously weakly disconnected parts of the graph, then there can be no cycle, or you can prove that an edge is parallel (meaning connecting the same source and target in the same direction) with an existing edge or path, in which case it also cannot form a cycle. It's good to wrap it up in an explicit DAG type, then you can use this always-acyclic invariant. (The above is why I think a [nonallocating toposort](https://github.com/bluss/petulant-avenger-graphlibrary/issues/5) is not the full solution.)
I am going to abuse the *hell* out of this. *Everywhere.* bluss: harbinger of the plague of braces!
&gt; Update: I've since learned that I should use the From trait here, but I haven't attempted this, yet. Have a look at the latest [book chapter on error handling](http://doc.rust-lang.org/nightly/book/error-handling.html), it's only in the nightly book but it should all be stable Rust. I found error handling in Rust *so* painful until I read this.
Or, if you prefer, `fn consume_the_list(mut self) { ... }`.
`unwrap` panics if it fails, which means you can get a backtrace. Just set `RUST_BACKTRACE=1` when running your program.
Sure. This blog post isn't about what you should do, but about curious things the identity function does.
In those cases I tend to either use `match` and `unreachable!` or `expect(concat!(file!(), ":", line!()))`, both of which give file and line info on the off chance you're wrong.
I actually miss the identity function sometimes, it would be nice to have it in the prelude.
Doesn't work on Windows
When in trouble, when in doubt, try it with a struct. struct Closure&lt;'a&gt;(&amp;'a mut Data); impl&lt;'a&gt; Closure&lt;'a&gt; { fn call(&amp;mut self, i: i8) -&gt; &amp;mut Vec&lt;i32&gt; { match i { 0 =&gt; &amp;mut self.0.a, 1 =&gt; &amp;mut self.0.b, _ =&gt; &amp;mut self.0.c, } } } let mut get = Closure(self); Doing so reveals a bug in your program: `first` and `second` may not exist at the same time. Why? Well if I call `get.call(0)` twice, I have an aliasing `&amp;mut` reference to `Data.a`. Soooo, no success there. It must be that we *cannot* call `get` again until the result of the previous call to `get` has gone out of scope. So, what should the type of the `get` closure be? Well, once we have a `&amp;mut` pointer into `Data` we can modify it, so `FnOnce` and `FnMut` seem like good candidates. I see you want to call the function twice, so only `FnMut` remains. Where do we go from here? I have no idea; the `FnMut` trait does not specify a relationship between the lifetime of the `&amp;mut self` in `call_mut` and its `Self::Output` type, so I'm not sure this can be made to work with the `Fn*` traits. I'm thinking what you want cannot actually be done. :(
You're right! That invalidates this approach for me, but perhaps you could still help me get my head around specifying lifetimes for closures. So for example a function might be defined as: fn foo&lt;'a&gt;(a: &amp;'a A) -&gt; &amp;'a B { ... } But how would I specify that signature for the equivalent closure: let foo = |a: &amp;A| -&gt; &amp;B { ... }
As far as I can tell, this is basically the same problem as C++'s templates except with the template written in the base language, rather than written in some weird template language. Basically, calls to the generated function are template specializations. When the function is called, the return value waits on the implementation being specialized (via a call into rust code, which generates some code, and is compiled) to determine the return type. That specialized code is then compiled into the new function which is called from that call site. The biggest problem which I see for rust is that lifetime inference is hard, and this would completely screw with it. AKA. We could have this if we wanted, but it might be really painful to implement in a way which doesn't make it unusable with non-'static references. (Also, we'd have to implement a compile-time evaluator for rust code, which sounds like it might be a pita).
Can you do something like `cargo rustc -- -C llvm-args=...`?
 .ok().expect(concat!(file!(), ":", line!())) It's not perfect but it's much better than standard `.unwrap()`. Alternatively `unreachable!()` gives proper file and line info.
This is great. It reminds me of/feels like the beginnings of http://rgruet.free.fr/PQR27/PQR2.7.html Python quick ref which is one of my favorite structured docs and think a rust version would be really useful.
From https://golang.org/cmd/cgo/, this wasn't clear, so since you seem knowledgable: does the exported Go code have to initiate the Go runtime when the function is called? One of the major improvements after the task system was removed in Rust was not having to write everything you wanted to use from C as `#[no_std]` (because otherwise it would expect the runtime to be present). Or does this only work if the original process is a Go one, and it's more designed for callbacks? Or is this unrelated to cgo?
With the growing number of cargo subcommands would it make sense to make this `cargo deps` with `-a` and `-l`? Kinda like `git remote`. Alternatively `cargo list` should know how to list other entities like binaries, tests, examples.
Did it work for you? I wasn't at a computer so I couldn't test it out.
Funny, this was actually what I did at first. [You can see an older version here.](https://github.com/killercup/cargo-edit/tree/b101dfd41f986cd7f5b20cadd8a6931f6c745efe) This uses the namespace `cargo edit` and allowed you to do stuff like `cargo edit dev-deps add regex`. This didn't work well IMO, though, as the commands become really long and overloaded. For me, this is not something that I'll be using often enough to want to _learn_ how it works.
&gt; Alternatively cargo list should know how to list other entities like binaries, tests, examples. That may be a good idea. https://github.com/killercup/cargo-edit/issues/20
GC performance matters when you need to allocate 50Gb in heap and rewrite it all with new data periodically. For 100Mb heaps in those microbenchmarks GC is not a problem indeed.
&gt; Similarly, conferences. You might be surprised at this Yeah that does surprise me actually I thought we were all beyond that by now.... (But then the only conf I have ever gone to was a physics one so I guess I don't know) &gt;Look at the number of women in the Rust community. Now look at the number of women in tech (still low, but not as low). It's proof that there are some barriers for entry somewhere. For this I wonder, maybe women just don't want to be in tech as much on average? I mean maybe since men and women are in fact different on average more women on average choose other fields just as there are fields men seem to avoid on average as well. Or maybe there is a cultural component idk; I guess I prefer to pretend in free will having more power. &gt;You don't get to decide what barriers there are and aren't -- the barriers are invisible to you. The people facing the barriers get to decide this. &gt;Did you just say that sexism in tech is not an actual thing? Then you're clearly not aware of its scope. :/ I'm not talking about micro-aggressions. Well I guess I should clarify here as these seem related.... Taking sexism and stuff as an example: Are there legitimate problems? Sure. Is everything that we hear going to be one? Eh not so much. Reading feminist articles I've seen the gamut of decently well reasoned reasonable arguments to misandrist polemics that are so nuts I'm almost not sure they aren't parodies to little petty things. For instance I've heard "holding a door open for a woman is sexist and bad and helps the 'patriarchy' " for an example, or helping them carry heavy things. (Although I think people tend to help/hold doors regardless of sex but whatevs) If someone is complaining of that kind of thing as a barrier then that imho counts as something that really doesn't exist as a barrier. If that sounds too contrived I could probably make the argument that Rust's type system is hierarchal and is thus patriarichal-normative and therefore sexist and probably racist; and honestly compared to some more radical feminists and/or tumblr folks it wouldn't even look too out of place. People could also complain about say x% of crates on crates.io are authored by men which is obviously sexist....or Y% of speakers at a conference are men, but then if a disproportionate number of men submitted talks well then there is nothing necessarily wrong with that and calling it a barrier would be wrong imho &gt;Whereas, the sexism/racism issues are pervasive and make groups of people not want to be part of the community at all That does surprise me, I mean tbh I have no idea the races/genders of most people here or on github or authoring prs.... So I guess unless you skype/meet in person I don't see how that could effect things, and presumably by that time you should already have a reputation due to merit?
Firstly in most cases you do not need that reexports. You won't create EdgeIndex by yourself. You will get it via calls to Dag::add_edge or something. Then you do not need to import it anyway, so there is no gain.
Okay I've spent the last couple of hours perusing the source code. Here's the breakdown: On calls *to* C: 1. Go locks the OS thread (this doesn't seem to be using atomics, but I'm guessing nosplit plus thread affinity of all the affected goroutines means this doesn't matter? That's nice). 2. Defers endcgo in case of panic (can this allocate, BTW? Or is it just a calling convention thing? I don't know how the defer stack is implemented, but given the weird state of the system at this point in the process it seems like an important detail... and the function isn't allowed to split the stack). 3. Calls entersyscall. This involves: 4. Swapping out the stack guard, setting the stack to throw on split, and saving the caller's context in preparation for a switch... which is marked nowritebarrier. Does that mean it's calling writebarrierptr_nostore, which takes a global lock on the GC? Actually, were a bunch of these pointer stores acquiring write barriers? 5. Calling casgstatus, which branches to a throw (I don't think it can here, so the branch should be predicted correctly, but I'm not sure the Go compiler can optimize out the exception expense due to the defer?)... then does another branch (unlikely to be reorderable due to the potential panic before, and also panicking), and checks to see if the GC is running--I don't *think* that can happen here, but I'm not positive. Now spinlock using cas to make sure the GC isn't scanning (which burns up processor cycles when written that way on many processors, IIRC, including x86, so I'm guessing that's no fun if that can happen here). This loop also has a branch that can throw, BTW. And some commented out code for helping the GC? Another branch, also to check if the GC is running, now we're finally out of casgstatus. 6. Branch to another throw doing a sanity check on the syscall SP? And a branch on trace, and an *atomic* branch on sched.sysmonwait (I don't know what this does). And a branch on runSafePointFn... I have no idea if any of this stuff happens but it's sure eating up branch prediction resources. And some more stuff that at least looks like it has a write barrier (but maybe not because all the pointers are cast to integers, but won't that make branch prediction not work?) And an atomic store... and a branch on gcwaiting... 7. Now we get to our first system stack call on the fast (sort of) path, but it's not the function you wanted to call. It's entersyscall_gcwait, which takes a global lock on sched (which may be the global scheduler?) and does a cas to do... something involving the GC and scheduler (and yes, another couple of branches, because why not?). I think it might be to make sure tracing works if you turn it on in the middle of the syscall? 8. Now we return from entersyscall and we're finally done (okay there's probably a write barrier that I missed) and call the original function... I'm too exhausted to figure out exactly how that works. 9. Or how long the exit and cleanup portion is. As for the other way, I think it mostly has to do the same stuff; it just does it in reverse order (i.e. calls exitsyscall, then the goroutine, entersyscall on return... sorry for oversimplifying but like I said, I'm exhausted). From https://github.com/golang/go/blob/master/src/runtime/cgo/gcc_libinit.c it looks like it does have to do an atomic check for runtime too. I'm mostly posting this as a "hey this is actually how it works!" thing, but I do feel obligated to point out: this is *tremendously* slow. And no, it's not for safety reasons; the Go code involved here is wildly unsafe, and you're still handed back raw pointers AFAICT and expected to convert them yourself. Rust skips literally every one of those steps; it doesn't even write a wrapper for you, native system calls are just native system calls. This is because Rust does not have the kind of omnipresent runtime Go does, so it can play nicely with C, even on the same stack. That's what people mean when they talk about Rust having great C interop. Looking at how Go's runtime is written: do I think there's room for improvement? Absolutely. But there's just way too much of a mismatch between C and Go's runtime models for it to be viable for anything but extremely long-running routines, especially when you consider how unsafe the interface boundary is (I saw a number of commits as I was researching this that things had to be taken out because they caused untraceable crashes on some architectures).
&gt; women just don't want to be in tech as much on average That argument is repeated a lot. Superficially, it's true, but only because women don't want to be in tech because of factors devolving from sexism. Anyway, when visible barriers exist which are very likely to turn women away, we don't get to say "but maybe they aren't the problem, maybe women never wanted to be in tech in the first place!". No. That's just sidestepping an obvious problem. We fix those. &gt; If someone is complaining of that kind of thing as a barrier These sorts of "barriers" are not what I'm talking about. At all.
Is there any feature of Rust you haven't managed to abuse yet? You should create a repo that consists solely of unidiomatic code abusing rustc features :P
&gt; 10 Jul 2015 FYI
Authoritative documentation is difficult to locate, but Go code called from other languages definitely requires a runtime. IIRC it doesn't spin up on every function call, it just spins up once and then waits in the background (forever?) for you to call more Go code. Go also has very poor documentation regarding proper ownership of values crossing the FFI boundary. The total confusion surrounding documentation in this area leads me to believe that support for this is still considered experimental.
Nice, I had even made a Github issue on Cargo to add the 'add' command. I couldn't tell from the examples, but what happens when you don't specify a version? Does it default to *? It'd be cool if it got the latest version from crates.io instead.
My assumption is that the core team has been getting their ideas straight for a while and are waiting until they're more fleshed out, or an rfc is written, before they open an issue. I have been waiting for an issue for a couple of months, however, so I am thinking of starting one of my own to get people talking about this.
Hehe. I didn't invent it, I picked it up from a discussion with someone, don't remember who.
I mean, Python can lead to some silly bugs if you're not used to the model. For example, a = [1,2,3,4,5,6] b = a b[0] = 7 a[0] # 7 In Rust, you explicitly know what is going on whereas this can bite Python programmers if they aren't careful. Particularly when passing things as parameters to functions.
One could always abuse `Map` and a slightly more complex return type... impl&lt;'a&gt; IntoIterator for &amp;'a Sudoku { type Item = u8; type IntoIter = std::iter::Map&lt;std::slice::Iter&lt;'a, u8&gt;, fn(&amp;u8) -&gt; u8&gt;; fn into_iter(self) -&gt; Self::IntoIter { fn deref(&amp;u: &amp;u8) -&gt; u8 { u } self.vals.into_iter().map(deref) } } Edit: of course using `type IntoIter = std::iter::Cloned&lt;std::slice::Iter&lt;'a, u8&gt;&gt;;` and `self.vals.into_iter().cloned()` is even easier :)
Yeah, my terminology dithering was unnecessary, sorry about that. This sounds like an interesting idea, though!
I agree... `[true, false].iter().filter(id)` EDIT: Ok, this wouldn't work, excuse me, I was tired \^_\^ ... Still: I want this to work somehow (probably with magic)
I would love it to. More and more I see how many problems Haskell has accumulated, simply due to its age.
Ditto for `all` and `any`.
So many `mut`s missing :(
&gt; I have to ask; have you taken the time to learn and use a parser combinator library, or is your experience only with parser generators and completely from-scratch hand-written parsers? I think that if you get familiar with parser combinators, you may find that they're not as bad as you seem to think. On the other hand, you may still strongly prefer parser generators, but at least you'll have more experience with what I think is a very interesting approach to parsing. I hail from Haskell land and use Haskell at work, task permitting. I've written parsers using combinators (several of the Haskell libraries), happy + alex, antlr, by hand, F# parser combinators, and so on. Initially I thought parser combinator libraries were great. It took me a while to realize the subtle trade-offs of using one. These days, if I have a context-free grammar I try to avoid combinators, in Haskell or otherwise.
At the moment, your options are: 1. Box it. 2. Manually implement the closure: define a struct with fields for the closed-over values, and implement the appropriate `Fn[Mut|Once]` traits. 3. Wait for unboxed abstract types to be implemented, which would allow you to name types by a trait that they implement.
I totally didn't think about rolling my own type. It seems heavy-handed though. Do unboxed abstract types work in a situation like this? The size of the struct depends on the closure environment.
I'm looking for a way to describe the type of a closure "enough", such that a struct can contain an unboxed closure without a type parameter. This idea is similar to the "manually create a custom closure type" suggestion above, since I'd be explicitly saving the environment to pass in.
I personally think you should make not using `*` a priority: as you say, it is evil. When upgrading cargo tries to reason about what new versions can be used based on semver compatibility with the specified version in the Cargo.toml, but using `*` throws all this assistance away, making it harder for people to get pain-free upgrades. They are even [outlawed on crates.io](https://github.com/rust-lang/rfcs/pull/1241) now. (I believe the built-in `cargo search` subcommand either reads the local registry or hits the API, so you could look at that for inspiration.)
Changing the closure to explicitly move the captured variable will solve lifetime issues, but not the multiple mutable destructuring issue: let get = |i: i8| { let moved = self; match i { 0 =&gt; &amp;mut moved.a, 1 =&gt; &amp;mut moved.b, _ =&gt; &amp;mut moved.c, } }; [Full example](http://is.gd/XXz2IK)
Hello Javascripter. I don't know about your background or why do you like to explore functional programming languages, but if you want to listen to someone who's still a student and hasn't realized a thing in his life, then here is what i think: I heard about functional programming when I was learning Javascript. First-class functions for example were a very cool concept for me. I also saw videos where Brendan Eich, the creature of the language, talked about Javascript being inspired by LISP. I read also a lot from Douglas Crockford, Marijn Haverbeke and others about LISP and functional programming which they didn't taught us about in (my first year of) university so I went on to learn LISP. I started the journey with CommonLisp which taught me about macros "With macros we don't need to wait slow language designers to introduce new syntax! We all are language designers". I also picked a bad attitude toward type systems. I then went into Scheme which is a clearer LISP with better named functions and hygienic macros (They are more restricted than Common Lisp's macros in order not to break lexical scoping). I learned a lot from the SICP book and then from the SICP video series. Scheme also introduced me to the concept of continuations which helped me better understand what I was doing with Javascript. I also read the first two parts of the book "three implementation models of scheme" which gave me an idea about how closures and first-class-continuations are implemented, and how it plays with mutation. I then learned a bit about the ML family of languages which demonstrated to me how a language can be typed without hindering developers with type annotations. ML also introduced to the sweetness that is pattern matching. I then learned the basics of Haskell from "Learn You a Haskell for Great Good". It is a lazily evaluated purely functional language. It features a static type system with type inference and pattern matching (like ML) and has type classes which are nicer interfaces. Haskellers use fancy concepts like Monads to overcome the problem that a pure language can't be useful (Can't interact with the outside world) and use persistent data structures instead of the more mainstream mutation based data structures. ML and Haskell de-emphasized Macros a little bit in my eyes and made me like type systems. I liked ML more mainly because It's strictly evaluated (less magical). Though, I think that the community of Haskell is more vibrant and the ecosystem is more modernized and developed, but who cares! I don't write useful software anyway. I also looked at other functional languages like clojure (a LISP for the JVM) and Erlang. Erlang has a nice mix of dynamic typing and pattern matching. It also have ultra lightweight processes which made me hate the Javascript model of concurrency and reconsider that we can write parallel and concurrent code and it can be simple and safe. Threads are not bad after all! Blame sharing of data. I started to look at Rust when it was 0.3-0.4 in parallel with Erlang. It has pattern matching, type inference and macros. And it is statically typed, strictly evaluated, performance oriented, type safe without need for GC and it allows mutation. I was and am still an observer, a silent member of the community, and I learned a lot. The community is awesome, helpful, inviting, diverse, has very well informed people. ^I ^miss ^some ^old ^figures. I learned that concurrency problems arise when you mix data sharing (aliasing) and mutation. Functional oriented languages attack the problem by discouraging and controlling mutation with the benefit of simpler systems. Rust tries to not make compromises so it tries to control aliasing to allow mutation. This is in the expense of some more complexity. So like others have said, Rust isn't a functional language, but the baggage i learned from functional languages make me excited about it. I looked into Go. It is a statically typed language with no^* type inference, no pattern matching, no macros, no generic types (Less verifiable for correctness), no guaranteed type safety. But it has first order functions and green threads (Yay! No need for callback soops). Not exciting if you are looking for a modern functional language. Have a good journey!
[Works now](https://play.rust-lang.org/?run=1&amp;gist=c31407c0482a1a77ca51&amp;version=stable) (since 1.2, I think): use std::rc::Rc; fn main() { let x = 1; let rc: Rc&lt;Fn()&gt; = Rc::new(|| println!("x = {}", x)); let rc2 = rc.clone(); rc(); rc2(); } 
&gt; we already have incidents where core members (Steve Klabnik) participated in political censorship, Whoa there, is there a place to get a balanced account of this? It sounds kind of bad or kind of blown out of proportion... Or maybe it is best left in the past?
I don't understand what you mean by that though. If you know the function anyway, just store the data. If you don't know the function, you have to save it in the context somewhere, right? If you need both and don't know either, that seems like a fine place to use a type parameter. Anyway, IMO Rust just needs some way to save on the tedium of writing generic type parameters over and over... like, a type F in an impl block or something (which doesn't work today).
Well sadly the situation isn't much better going from Go to C, it's VERY VERY slow. So definitely not the solution you'd want to try for chatty cross boundary interfaces, in that case, Rust has 0 overhead. No idea about Haskell tho. 
**facepalm** I've just realised that you *are* bluss :) I feel silly, explaining things to you which I only know as a result of you having explained them to me! Oh well, at least the info's here for anyone else who is reading. Shall definitely do some research into other DAG abstractions that are out there and see what other kinds of tricks are used in side-stepping cycle detection. It seems that in most cases the kind of heuristics involved will depend on the application, so it might even be worth adding multiple `add_edge` methods, or perhaps instead a `CycleCheck` type param with a few different options (and a safe default).
If anybody wants to create an IRCd in Rust, that'd be lovely. ;)
Commercial release, so you're planning to sell it? I imagine that would make you the first for-profit user of Conrod, so I'd love to see some screenshots or a video demo of a production-grade Rust GUI. :)
The issue of async IO might be a problem. Libraries are still trying to flesh out how it will look to Rust (mio and all the coroutine libraries on top of it). I don't think we even have a full-feature IRC client in Rust yet, also...I'd get a lot more use out of that than an IRCd :)
That works, thanks. And I think it does what I want it to. Coming from C++ world what I'd like is to just compute the address of the next value rather than compute it and copy it. And I think that's what this would do, at an assembly level?
Huh, how does that even work?
Good news, docs are up! http://dualspark.github.io/rusoto/rusoto/index.html They are linked in the README on Github as well. On the next release they will be linked on the crates.io page as well. Thanks for bearing with us. This is Anthony's first Rust project as well as my first Rust project. Learning by doing.
Thanks! This was just a weekend, though. I hope to get some time soon to do more. I'll probably ask you for the crates.io name when `cargo install` is available :)
I am continuing my work on [twig-rs](https://github.com/Nercury/twig-rs) port from PHP to Rust. Twig is easy-to-use, fast, secure, customizable templating engine, oriented to web, but usable for other purposes too. Last week make good headway in making the first expression parsing tests pass, and started working on core extension (the twig core itself is an extension). I am following idiomatic Rust as much as possible, so many things are way different from original Twig.
Don't know. I'd assume it's because you can have fields and methods with the same name, so they have different syntaxes to avoid mistakes.
[removed]
I had started one with MIO before 1.0, t'was fun. I used a design quite similar to the one described in this article, except with a multi-threaded event-loop, because fun (and thus Arcs, Mutexes and RwLocks everywhere). But it's kinda dead now, and I don't really have any motivation to finish it. Mostly because the friend who motivated me to do it with him gave it up before writing a single line of code. :(
I have another month to work on [Imp](https://github.com/jamii/imp/blob/master/diary.md). I'm pretty much where I left off last time - adding primitives to the query language - but while I was on holiday I figured a nice way to extend Yannakaki's algorithm to handle them.
I guess it would make sense, but I think it's best to leave it outside. I don't have so much time right now, and I don't want to be the bottleneck either.
[Like this?](http://i.imgur.com/CXMVxPn.png) ^^^^^^Oh,&amp;nbsp;not&amp;nbsp;*that*&amp;nbsp;formal‚Ä¶
Where's the best place to start learning about servers, tcp etc (beginner level preferably) in Rust? There's nothing in the official book that I can see.
Ah yeah, sorry. What I meant was "inform the compiler of the closure environment up-front **in addition to the type**". As far as I know (which isn't very far), that's all the information the compiler needs to generate code that will interact with an instance of a struct like this. Maybe there are optimizations that complicate the story, though.
If I want to store the closure in a struct, references won't work neatly, since I'd have to "bubble up" the creation of the closure to live longer than the struct holding it. I'd definitely prefer `Box` over `Rc`, since `Rc` has strictly more performance overhead. It's not a big deal either way, but it definitely feels unsatisfying to pay a runtime cost for a thing that can make total sense at compile-time. It's also worth noting that neither `Box` nor `Rc` implements the `Fn*` traits, so they can't be used as parameters to things like `map`. You can use them via `Deref`, but then you still have the problem that the final `Map` type contains an unnameable closure. Since it's unnameable, the type variable has to propagated up through every struct that contains it, leaking implementation details to anybody who transitively uses the implementation.
There have been similar programs for other languages (e.g. Java) already, so I see no reason why it shouldn't be feasible to write it in Rust. It'll be a lot of work though; we don't even have a `ControlFlowVisitor` yet (that would be a visitor like the `ExprUseVisitor` that emits `flow(..)` calls for each transition between two pieces of code.
I'll be working on program verification. But having soundness results about the language is *huge* for many reasons: 1. It shows that Rust's type system makes sense at all. 2. Programmers have more assurance that any possible errors are in their code and not the compiler's. 3. When verifying programs, if you can prove that all unsafe code maintains the necessary invariants, then you can assume those invariants when doing proofs about the rest of the code. 
Ralf is awesome, I met up with him at ICFP. His model is looking really good, too :) I am hoping it gets into a postable state sometime soon.
No inheritance! All fields and methods should be distributed equally to every struct!
*lol* this pun doesn't work in my mother tongue, so it never before occurred to me ;-)
Am I correct in understanding that this might even expose bugs where unsafe code currently violates the contract?
Continue work on [cargo-add and cargo-list](https://github.com/killercup/cargo-edit/issues).
Thanks for doing this work, I think it is very important. Take as an example the proved correct seL4 [1] micro kernel. Do you think that using Rust and a formalization (such as the one you are working on + covering Traits etc that you are deferring) would reduce the proof maintenance burden? [1] https://sel4.systems/
Awesome!
403 :(
&gt; I'm not at all an expert in automatic program verification. Have you seen [SAW](http://saw.galois.com/)? One of our engineers added rust support. You can see that in his fork in the tutorial: https://github.com/aisamanra/saw-script/blob/master/doc/tutorial/sawScriptTutorial.md#cross-language-proofs-rust
Ahhh, _much_ better! :)
Nice! We were talking about doing this in an official capacity. /u/brson and /u/acrichto will be interested in talking to you!
üéä ‚ë† ‚ì™ ‚ì™ üéä 
strangely this also appears to work: impl&lt;'a, T&gt; End&lt;'a, T&gt; { fn push(&amp;mut self, other: T) -&gt; () { self.v.push(other) } } fn main() { let mut v = vec![]; { let e = end(&amp;mut v); // e.push([0u8; 8_000_000]); - fails to compile in e { [0u8; 8_000_000] }; } println!("{}", v.len()); } which feels like a bit of a bug, even if you could just do `let mut e = e` to make e mutable
I've found it best to define a trait that has a method you would call, and have a generic impl of the trait over closures. This allows you to put in the generic slot an actual type, while also allowing you to use closures if desired. It also doesn't require unstable features, unlike implementing Fn on a struct manually. 
Only 28 more weeks until a [big round number milestone](https://xkcd.com/1000/)!
You shouldn't generate random UTF-8 strings because they introduce a bias (some values are not representable). The right approach is to generate a random `u8` vector as said, and work with it as byte values, not as text.
From utf-8? (strings in Rust - both &amp;str and String - are all utf-8)
Why closed source?
The link to the "102 pull requests were merged in the last week." is 404-ing for me.
Yep, it's already outdated slightly - I'll update the text for the latest versions of mio now. It's a surprise to me that the text has been posted here again.
I don't know where to find the vector source of the formalized Ferris, but the resources for basic Ferris are here: http://www.rustacean.net/
What do you mean?
What about the [mio book](https://wycats.gitbooks.io/mio-book/content/)? (not sure how up-to-date it is) Also other documentation [linked from its Github page](https://github.com/carllerche/mio).
Thanks!
Well, I was only going to keep rust as a hobby, but you've convinced me to look much further into it. Thanks for that.
What if the crate needs to be built for Windows?
&gt; Haskell is widely regarded as having the most powerful type system of any application-level programming language out there. Hmm.... Does Haskell have anything like [SPARK](https://en.wikipedia.org/wiki/SPARK_\(programming_language\))? I think Ada still holds the crown here and likely will for a LONG time. Of course, maybe you meant something besides "type safety" in your use of the phrase "most powerful", but if you're looking for "most expressive", then you'd likely have to name Lisp or maybe Perl before Haskell. 
I one wrote an Atari 800 emulator in Java and I ported a C one to Android. CPU and memory are the easy parts. Video, sound and timing are the hard parts. Good luck! An emulator is a fun and challenging project.
I appreciate this, but a couple services have done this and their maintainers went MIA. Now documentation is all over Google for projects I wrote that I can't update or delete due to a bug with their website. I'd rather use an official crates.io documentation source.
Just a formatting tip, instead of quoting with ```, quote with &gt;, like this &gt; We need to pass in our left and right values to the constructors for our Philosophers. But there‚Äôs one more detail here, and it‚Äôs very important. If you look at the pattern, it‚Äôs all consistent until the very end. Monsieur Foucault should have 4, 0 as arguments, but instead, has 0, 4. This is what prevents deadlock, actually: one of our philosophers is left handed! This is one way to solve the problem, and in my opinion, it‚Äôs the simplest.
Looks good! I notice that it's MIT licensed, but the project page asks that users cite the paper. You may want to use a different license if you want to make that requirement a legal one. At the moment, there is nothing in the license to require that users cite the paper. You may also want to change the bio::alignment::Alignment::cigar function to take an enum indicating whether to hard-clip the string rather than a bool. It's slightly more readable (although this is definitely a nitpick). Nicely done! It's exciting to see this sort of stuff being done in Rust.
&gt;Does the sublime plugin update automatically? Yes, changes in the repo propagate to Package control automatically and pretty quick.
Not sure if joking, but this is his code static PACKET: &amp;'static [u8] = b"HTTP/1.1 200 OK\r\nContent-Type: text/html\r\nContent-Length: 15\r\nDate: Thu, 08 Oct 2015 08:59:11 GMT\r\nServer: Gossamer/0.0.0\r\nConnection: close\r\n\r\nHello, world!\r\n"; /// Splits a HTTP packet into (`start_line`, `headers`, `content`) fn split_packet(bytes: &amp;Vec&lt;u8&gt;) -&gt; (Vec&lt;u8&gt;, Vec&lt;Vec&lt;u8&gt;&gt;, Option&lt;Vec&lt;u8&gt;&gt;) { // Split into lines by \r\n let mut lines = Vec::new(); let mut buf = Vec::new(); let mut cr = false; for byte in bytes.iter() { if cr { if *byte == 0x0a { lines.push(buf); buf = Vec::new(); } else { buf.push(0x0d); buf.push(*byte); } cr = false; continue; } if *byte == 0x0d { cr = true; continue; } buf.push(*byte); } lines.push(buf); // Start line let start_line = lines.remove(0); // Headers let mut headers = Vec::new(); loop { if lines[0].len() == 0 { let _ = lines.remove(0); break; } headers.push(lines.remove(0)); } // Content let mut content: Option&lt;Vec&lt;u8&gt;&gt; = None; if lines.len() &gt; 0 { let mut c: Vec&lt;u8&gt; = Vec::new(); while lines.len() &gt; 0 { let line = lines.remove(0); for byte in line { c.push(byte); } if lines.len() &gt; 0 { c.push(b'\r'); c.push(b'\n'); } } content = Some(c); } println!("[Start Line]\t{:?}", String::from_utf8(start_line.clone()).unwrap()); println!(""); for header in headers.clone() { println!("[Header]\t{:?}", String::from_utf8(header.clone()).unwrap()); } println!(""); if let Some(c) = content.clone() { println!("[Content]\t{:?}", String::from_utf8(c.clone()).unwrap()); } println!(""); for line in lines { println!("[Remaning]\t{:?}", String::from_utf8(line.clone()).unwrap()); } (start_line, headers, content) } fn main() { split_packet(&amp;PACKET.to_vec()); }
No; I have an (whatever the hell GIMP's extension is) lying around, but that's not vector. I basically nicked a likely-looking top hat PNG off Google Image Search (I *do not* own the top hat image), then added two black circles for the monocle (that, I *do* own, but only because it's hilariously awful). The PNG I uploaded wasn't scaled down at all. That said, this particular hat wouldn't be hard to trace. I actually *do* have an SVG top hat I did once somewhere, but I didn't use it because it was drawn at an angle and I needed a front-on one for Ferris.
Well, `cargo doc` apparently supports `--target` so if you could add support for choosing a specific target, then I'd love to use that for `winapi`. You'd have to download and unpack a copy of Rust for each target and merge all the `bin/rustlib` together into the native Rust toolchain, as if you were setting up a cross compiler.
One thing I've been thinking about with my own generation scripts is maybe generating docs for each major version separately, along with branch docs (*i.e.* `master`, `working`, etc.). It's a bit annoying to have online docs for a crate you're using, but the wrong version. Of course, you can solve that by just running `cargo doc` on the crate that's *using* that library... at which point I wonder why having the docs online is such a big deal in the first place and lose interest in what I was doing. :P
&gt; http://is.gd/0o5qGm Awesome!!! this provides a lot of clarity. Thanks a lot for the playground snippet. I do have the opinion that playground snippet should be made part of the book!!!
thanks for the tip, shall follow from now on.
[PR 29009](https://github.com/rust-lang/rust/pull/29009) will make it easier (and is a step towards making it *much* easier).
I'm not personally involved with SAW, and I've never used it, but I think that's correct.
Big improvement! Thanks!
More work on [imageproc](https://github.com/PistonDevelopers/imageproc), (first rust project - would be great to get some feedback/suggestions). And I'll try to get a minimal end -to-end prototype of an image matching system done.
Ah, that seems like a good solution. Though it's not totally clear to me whether that's how it's currently implemented.
Yeah, to be clear, I haven't verified that by reading any code; I've just read that doc a few times. :-)
Why not automatically download every crate from `crates.io` and build the docs of all versions? I want something like `crate.rustdoc.org/v0.1.2/` for every crate out there \^_\^ I already have a build script, that pushes my docs to github pages whenever I push my code to master, so it needs to be easier. Besides: I think I agree with /u/rorlrkfirke here. There were services like this out there already... but now they are unusable and do more harm than good :/ I want something like that, but done right. Maybe you are doing it right...
A formalization of the language semantics is the first step in verifying actual code, and it is something I also need for my project. As I said though, there are some shortcuts I am taking here, which I think would be much harder to justify when the goal is actually verifying that a certain program does what it is supposed to do - as opposed to studying, in general, what the semantics behind borrowing and lifetimes are, and figuring out the contract sitting behind this idea. The actual programming language, Rust, is hardly relevant for my work; the concepts implemented by the borrowck are. As far as I am informed, /u/cmrx64 wants to have a formalization of actual MIR (rather than some idealized fantasy-land version of it) - that's way more suited as the foundation for such a verification task. As far as the proof maintenance burden is concerned, maybe writing the kernel in Rust could help if the same idea can be expressed more succinctly than in C. And maybe it can piggyback on the stronger guarantees provided by the language itself. But then, a kernel will always need significant amounts of unsafe code, and all the things the kernel does have to be defined *somewhere*, and then proven correct. I think what we want for large-scale projects like seL4 is better automation of the proofs, which is not something I work on. The code I verify is usually less than 20 lines long ;-)
:+1:
I did think about doing something like that, but ultimately decided against it: I'd have to constantly check whether a crate was updated, and re-compile it every time if so, which takes about 30 seconds each time. I figured it was just easier to give crate authors a command they can run when they want to do it, plus I avoid hosting other people's docs without their permission (not sure if that should be an issue, but it might be) It's fair enough that people are hesitant about it, but I'm not sure there's much I can do other than wait.
[Apparently.](https://www.reddit.com/r/rust/comments/3ohiyo/rustdocsorg_ill_host_your_documentation_for_you/cvx87am)
This is a cross-post from /r/programming: Rust gets mentioned once, but reduced to &gt; Rust (‚ÄúC++, but less horrible‚Äù) In my opinion, Rust is so much more than that. I also fear this notion is keeping people from trying Rust at all. So how do we dispel this notion?
heh, it certainly sounds like I'm not the only one who had this idea. We'll see how this goes!
Mind, godoc.org caches rather than hosts, nobody chooses to put the docs up there. It takes the documentation directly from the source code that is publicly available. You might only need to point it once to a specific package so it starts tracking...
Yeah, the reason I did this is that I kept on forgetting to update my docs after making changes on a computer without my regenerate-and-upload-everything build script. And then I'd have online docs that didn't actually match and I'd have no idea. Right now it just pulls the crates off crates.io so that's all the information I can work with.
Totally :)
üé∫ üé∫ üé∫ üíØ üé∫ üé∫ üé∫ 
Agreed. If we're always trying to revolutionize programming, we'll never get anything done. That's one of the many reasons languages like PHP are still so popular. People who need to get things done already know them. Same reason I tend to code in Python. As much as I know I'll regret reinventing static typing in the form of a test suite later, I don't have time to get beyond play coding in Rust *right now*.
https://github.com/wolfmankurd/jukebox-rust Not much but working on some software that ties serial port input USB RFID reader to actions on a computer such as playing an album. It uses rusqlite and serial. I'd appreciate anyone looking it over and letting me know of any code improvements I could make!
Going to attempt to write a type safe wrapper around the already present epoll crate. I'm not super knowledgeable about kernel interfaces so it should be a good learning problem.
Just to give more context, you mark types as [`Copy`](http://doc.rust-lang.org/std/marker/trait.Copy.html) when they can be copied by just copying their bytes (that is, when they are [POD](https://stackoverflow.com/questions/146452/what-are-pod-types-in-c) like in C++). This copy is a deep copy (it copies all fields of the type recursively) and is implicit, but a type that contains references or anything that isn't POD can't be `Copy`. Also see [this](https://doc.rust-lang.org/book/ownership.html#copy-types) in the book. If you want a copy of a type that is not POD you implement [`Clone`](http://doc.rust-lang.org/std/clone/trait.Clone.html) (and in this case we say the value was cloned, not copied). But `Clone` doesn't guarantee it's a deep copy: for example, cloning a [reference-counted pointer](http://doc.rust-lang.org/std/rc/) just increments the reference counter, returning what's essentially a pointer to the same data -- `Rc` is only deallocated when all its cloned copies are dropped (see [this chapter](https://doc.rust-lang.org/book/choosing-your-guarantees.html)). But if all the fields of your struct implements `Clone` in a way that actually makes a brand new value (and its own fields, etc), then the clone is "deep". Note that references implement `Clone` (mutable references don't, however), but they will all point to the same value. In a low level sense, only the pointer was copied, not the actual value pointed to.
&gt;So how do we dispel this notion? Well we started the notion. Rust is largely sold as *C++ without A, B, C and with X, Y, Z*. While yes its much more then that. The above is repeated far more often.
&gt; That's one of the many reasons languages like PHP are still so popular. People who need to get things done already know them. I even don't agree with this (fully). PHP is massively popular because it solves a lot of problems admirably that many people in that space have. (e.g. initial deployment) If your software at hand is a thing to be deployed at 200000 locations as a fresh instance, this is a huge feature. Other PL environments don't appreciate that enough. The language might or might not be crap, but that doesn't matter at that point.
For seeking, that's the kind of case the developer has to handle. Usually, you can always seek forward, by skipping elements, but seeking backward depends on the source. I made that part completely generic, because the source could take other orders than seeking, depending on the data it is handling. I also took care of sending a message like this when the consumer produces a value, because I may want to reuse the producer afterwards, so I have to tell him to advance. In my experience, you want to push most of the logic downstream, and let upstream be as dumb as possible.
Take a look at https://github.com/rust-lang/crates.io-index/commits/master
[**@Argorak**](https://twitter.com/Argorak/) &gt; [2015-10-13 13:09 UTC](https://twitter.com/Argorak/status/653920496002711552) &gt; @inkel @cuerbot Would you know anyone on your continent who would be interested to be represented/helping in this? &gt; &gt; http://blog.tcardenas.me/rust-castellano/ ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
This is mostly about conversation and documentation. E.g. Ruby was (and is) mostly developed in Japanese, but still the API is in English. But API's are mostly single words, not comprehensive texts.
Yes.
I am not even 100% sure the chapter will survive, at the moment. We'll see...
That and memoization.
The premise that someone would be using Ruby while sweating over performance didn't get to you first? I think it is actually a pretty good begginer article though. For safe native languages to pick up enough users they will have to get them from the systems side and the scripting side.
De-referencing seems like one possible source of horribleness IMO. I know why its useful, but it makes browsing docs a bit of a nightmare. 
I agree that it's a bad idea. But it is what's necessary if they want to make citing the paper a requirement of using the library. Doesn't mean it's what should be done.
Or just use a language w/ TCO
&gt; The premise that someone would be using Ruby while sweating over performance didn't get to you first? Rubyists often sweat about performance. It's just not an *initial* concern.
I think it's pretty accurate, to be honest.
It can be expressed that way without having to resort to unwinding the recursion.
What /u/gkoz said and you could check the LICENSE for every crate... If every crate owner has do something manually, then docs are hosted all over the internet again. I want a central place for that, I think :/
Yeah, it's a good beginner article. It got me to try linking a c program with a rust lib for the first time. Works as advertised. 
Developing a podcatcher application at https://github.com/red-oxide/red-oxide
I get the opposite result. On my x86_64 Linux laptop, using rust 1.3.0 with no command-line flags, the static version takes around 11.5 seconds while the dynamic version takes around 12.7 seconds.
Cool then no probs I guess
Why would you compare speed of two debug builds? It really makes no sense. 
&gt; Compiled using `rustc thing.rs`, so no debug 
True, but there **are** people trying to revolutionize programming (see, for example, the various efforts linked in the comments on that blog post). The impression I got from that blog post was an undercurrent of "How are revolutionary ideas supposed to get a chance with so many appealing evolutionary ones crowding the stage?"
Question: why do people say "blazingly fast" or "blindingly fast"? Isn't "fast" enough? What's the threshold between fast and blazingly fast?
Let us know your experience adapting that course. :)
I gave a talk a few months ago at the Tampa Code Camp on Rust. http://www.tampacodecamp.net/. I've just been learning on my own, and doing some small experiments. I attend a [TampaDev](http://www.meetup.com/TampaDev/) event every once in a while, due to my day job mostly involving .Net development.
Is it going to be something like ImageMagick?
What are you using to detect RFID tags? Is there a general-purpose Rust library for that?
I'm thrilled to see more Rubyists discovering the potential of Rust for optimizing hot loops, but I'd like to see more documentation for passing things besides integers.
https://github.com/rust-lang/crates.io/issues/65
In Rust, "debug mode" is basically shorthand for "-C opt-level=0" (regardless of whether or not debug symbols are being included), whereas "release mode" is shorthand for "-C opt-level=3". The idea is that you use the former when debugging (faster compile cycles) and the latter when releasing (faster binaries). (We also technically do other things in release builds, like no-opping `debug_assert!`.)
&gt; I invited him to write a minimal incomplete borrow checker that way Would really like to see this tbh
&gt; "release mode" is shorthand for "-C opt-level=3" Oh it's not 2 like `-O`. TIL.
This provides nothing that the embed example in The Book doesn't as far as I can see! Infact it provides less than it because I remember there being a Python example!
I'm waiting for async I/O as well. There's good underlying support for it in Windows through completion ports.
http://ruby-doc.org/stdlib-1.9.3/libdoc/minitest/unit/rdoc/MiniTest/Unit/TestCase.html#method-c-i_suck_and_my_tests_are_order_dependent-21
This reminds me what IDE are people using? I have sublime text 3 with the rust plugin (I love subl but don't think I'd pay for it). When working remotely (I do some light coding on my ipad with servitor and nano with a simple rust highlighting config). I always felt eclipse was too bloated for me but it may become more appropriate as my project size increases and I need more input from the IDE. Kind of wish I'd learnt to use vim now!
My initial use case is to let me write some computer vision projects using only Rust libraries. (I'm only just starting on the first of these projects now, after a couple of weeks of shoving stuff into the imageproc library). However, I intend to support nearly everything listed on the ImageMagick page eventually, so it should be easy to write a little command line tool backed by this library. *The one, massive, thing I'm not planning on covering at all is image format conversion. This library uses [image](https://github.com/PistonDevelopers/image) for image encoding/decoding, so hopefully all popular formats will eventually be covered there.
I use Atom. Mainly because it was the easiest to get started with when I was looking a couple of weeks ago. It'd be a bit of a shame to have to switch to a heavyweight IDE to take advantage of the new features. Hopefully a lot of the new gadgets will be IDE-agnostic.
I'm using Atom. It's alright. I really hope the rust intellij plugin surfaces as the best one. Intellij is arguably the best-in-class IDE for every language it officially supports and because of this so many people are familiar with it already. It would be nice to use intellij by day at work, then come home to use rust on the same IDE via plugin. I know this is a big selling point for vim, but I don't see Rust being at home there. It seems more like a C#/Java/Scala where it would benefit from a full featured IDE platform.