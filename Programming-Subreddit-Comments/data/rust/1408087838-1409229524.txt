This definitely helps. Wish I could upboat twice.
If you are not interested in maintaining it, perhaps you want to move it to the Piston umbrella? This will make it easier to maintain. Visual Studio is used a lot in the game industry. I am sure somebody will pick it up. I am also interested in similar plugins for Xamarin and MonoDevelop.
Ouch! Abuse alone should motivate a `**` operator for exponentiation, so that we have sanity and consistency.
For what it's worth, a definite +1 to the multicomment style. You can see even from this small thread that different comments have sprouted different discussions, and it's nice to keep them together while not losing the small, standalone comments.
You're going through the exact same problem I am. Your blog post is a description of my struggle.
Oh, I didn't mean from a language design perspective, sorry. It's just that feeling — I'm sure universal — of cargo-culting things initially, taking them further, then ending up with something a bit misshapen but not really knowing the obvious route to elegance. That process is janky, and the end result is too.
Would you do this even in the linked case, where the enum has two values and I want to do nothing in the case of one of them? Would the experienced Rustacean expect it see that explicitly stated? How would you do the noop? Just like this? match send { Err(code) =&gt; { break; }, _ =&gt; {} }
You're misunderstanding what lifetimes and references are. `bytesOut` ceases to exist when the function returns. You cannot have a reference to something that doesn't exist, and lifetimes can't make `bytesOut` live longer. You have to return `bytesOut`, or mutate the input slice (if that's possible).
As third option to what Nihy said is to write your code as an Iterator that takes a `&amp;[u8]` and lazily calculates the base64 bytes. This would allow you to choose at call site whether to allocate by collecting into a vector, or to mutate by iterating over it and changing a mutable slice.
in-place base64 encoding is impossible, because base64 encoded data takes around ¼ more bytes than the original unencoded data. Btw. Would it be feasible to create a base64-encoding iterator that iterates on a stream of bytes under the hood?
No idea, I've never used Android Studio.
Awesome! Worth it for `cargo run`, definitely. At the moment I'm developing with [`rego`](https://github.com/ahoward/rego) (old Ruby habits die hard) to recompile and run on every file change, and `cargo run` makes that command simpler.
"You're using quote a few redundant type annotations" — can you let me know where? I've tried to keep type annotations to function definitions and where they're necessary for generic code to give me the right value, but I'm sure I've missed some — it's seemingly the ultimate cargo cult-y thing I do in Rust ("better put a type annotation here to be safe"). Good spot on the unnecessary `mut` — it's a holdover from when I was doing the uniqueness checking in that task, rather than pulling it out to another.
Thanks! I went with `map`/`collect` because it looks cleaner to me, even though my Ruby brain conceived of the problem in `reduce("") {}` terms like Steve's example (and indeed that's how the Ruby version of this works).
Thanks! I might give docopt a try since it will give me experience of using an external dependency, which I so far haven't done.
Thanks so much for your help everyone, I've learned a lot and tidied things up considerably! I expected to find Rust a bit of a slog but worthwhile as a learning exercise, but I'm amazed at how productive even a novice can be in it — I can see myself reaching for it for so many tasks that I would have thought would remain in Ruby's domain forever.
Presumably the additional code generated by unwinding will mean `unwrap` is always at a disadvantage (even if it is just "takes longer to compile").
I think I've got all the redundant type annotations now: https://github.com/robmiller/code-generator/commit/d15c446da9b5369c4f70381bc9762f2861893503
Also (sorry for the many replies to one post, but it has a lot of points in it!): rng.choose returns an Option, which then makes me need a match, which feels clunky to me. Whereas my existing code feels less expressive but is also shorter. It's weird that, given that I'm running `choose` on an immutable array that's defined in a literal a few lines above (and which can therefore never be empty), it still returns an `Option` even though that `Option` could never ever be `None` — I feel like I'm having to write something *beyond* exhausting every possibility and into being frustratingly verbose. But maybe I'm just being silly, I don't know.
I dimly recalled `expect` from the guide, and I'm happy with how it reads: *rng.choose(numbers).expect("Failed to select a random number") https://github.com/robmiller/code-generator/blob/d9bb993c4eecd2cd9d28d486309b8993b5ebdefb/src/codes.rs#L15-L24 Does that offend anyone, or is it normal Rust?
Thanks for responding! I totally see that now. I guess I'm just not used to seeing a rust object that isn't constructed in a single line.. haha. Keep up the good work, I am looking forward to continuing to read this series. I've already learned a bunch of small things that I didn't know how to express before. Like that you can match a range of characters 'a'..'z'. I originally thought this was exclusive to numeric values but I assume rust maps the characters to their numeric values when doing this anyway.
Hmm, that doesn't actually look too bad. Though I would personally only replace the current use of `::` with it, not add it elsewhere, because I *subjectively* think the inconsistency is still preferable to the additional noise.
It didn't take long for this intro to become obsolete ;)
Right, I only cared about runtime here.
`listen` lives in the `Listener` trait. You need to bring it into scope, like the example does via `use std::io::{Listener,Acceptor,TcpStream};`
Ok, I can see the pattern: when I find it in the 'trait implementation' section I need to `use` that Trait. thanks
That used to be the syntax, but it was removed due it being confusing (trait constraints use the same syntax).
http://knowyourmeme.com/memes/i-took-an-arrow-in-the-knee
yay! thanks.
Exactly, unless that trait is exported from [prelude](http://doc.rust-lang.org/std/prelude/).
ah certainly i can see impl..for.. is easier to grep and : would be overused. is there any other keyword combo that might make sense? .. impl type as trait.. (analogous to the trait object) 'for type impl trait' i guess this is unlikely to be changed 
I'm using rustc 0.12.0-pre-nightly (a4553453a 2014-07-25 00:36:11 +0000) 
The methods are defined for up to twelve-element tuples, in [`std::tuple`](http://doc.rust-lang.org/std/tuple/index.html). And twelve is overkill. If you even have a *five* element tuple, you should probably not be using a tuple. Structs are good. Bear in mind that it’s all just simple sugar around `let (val, _, _, _, _, _, …) = tuple;`. Pattern matching is the one true way of doing things and how everything is actually implemented.
Thanks. I now suspect that the purpose is to discourage address comparison. If this is the case, then `==` should be forbidden on references altogether. Explicit dereferencing is better when we do need to compare the referees. EDIT: I see you edited the parent to clarify the purpose of `==`, "always compare the meaningful content". That's actually a saner choice, but still surprising in a "low level" language like Rust. :P 
A lot of the functionality is there. However, there are still quite a few large bugs with them that I'll be ironing out over the next few days, and by-ref captures may not work yet.
The [RFC](https://github.com/rust-lang/rfcs/blob/master/active/0044-closures.md) is fairly readable. The core idea, as I was able to gather from the RFC: unboxed closures desugar to a type that implements one of the `Fn`, `FnShare`, or `FnOnce` traits. I don't understand how exactly this differs from boxed closures, though.
I'm a bit worried that PistonDevelopers will become a dumping ground for random semi-related projects.
I like the `Fn...` traits, it maps well to `apply()` from Scala, which I thought was pretty cool. It's difficult to understand the motives for the rest of the changes. Personally I feel the type annotation syntax is unwieldy. But it also opens up the possibility for partial application. Which I think is awesome. fn x&lt;A, B, R&gt;(a: A, b: B) -&gt; R { // do stuff } fn partially_apply&lt;A, B, R&gt;(x: FnOnce&lt;(A, B), R&gt;, a: A) -&gt; FnOnce&lt;(B), R&gt; { |b| x(a, b) //Capture by value } main () { let a = 5i; let b = 6i; let y = x(a); // desugars to partially_apply(x, a) let z = y(b); }
&gt; It's difficult to understand the motives for the rest of the changes. Performance.
[**@SimonSapin**](https://twitter.com/SimonSapin): &gt;[2014-08-15 17:20:45 UTC](https://twitter.com/SimonSapin/status/500331272435404800) &gt;The second London [@rustlang](https://twitter.com/rustlang) meetup took place at [@MozLDN](https://twitter.com/MozLDN) yesterday. [*pic.twitter.com*](http://pbs.twimg.com/media/BvGIf-1IIAAcl2y.jpg) [^[Imgur]](http://i.imgur.com/x6LC9Qt.jpg) ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/2dng4h%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
As ever I'm willing to offer a compromise: Let's use `foo!&lt;T&gt;()` to make both sides equally unhappy!
That's possible, I meant 'map to' in a more generic sense, not neccesarily literally storing them in a map.
If you're sure, it's better to use one of the methods that's defined. For example, if you have a `Option&lt;T&gt;`, and you _know_ that it's `Some&lt;T&gt;`, you can use `unwrap()` to get this. Which is defined as match opt { Some(x) =&gt; x, None =&gt; fail!("nope lol"), } I forget what the method is on `Result` if you expect an `Err`, and my wifi is really bad, but there is one. It'll use `match` internally. So that'd be good as well.
Gotcha. :)
;)
For those who have followed http://www.reddit.com/r/rust_gamedev/ , this is a step forward to make gfx-rs more ergonomic for single threaded applications. kvark did it!
And it's a problem with current Cargo, but future Cargo will handle this.
At least the DST video didn't work for me in either Chromium or Firefox. A bit surprised that I had to use some fringe webkit browser to get video to play on a Mozilla site. Edit: And seek doesn't work. Oh, well, I've read the blog posts etc. Seems to be silently failing because the encoding isn't supported.
This is one of those things that should be mentioned in a "Rust for C++ programmers" guide, somewhere.
Yeah, air.mozilla.org videos stopped working for me a couple days ago. They do seem to work fine on mobile.
More obvious reason there isn't a `null`: *values aren't boxed.* You can only have `null` if you have a pointer.
Oh, that's a really good point cmr. I should add that!
Well, it doesn't cite either [flycheck](http://flycheck.readthedocs.org/en/0.20/news/flycheck-0.20-released.html#rust) or [flymake-rust](https://github.com/jxs/flymake-rust) to have continuous syntax checking (flymake-rust checks syntax, basically calls `rustc --parse-only`. I'm not sure if flycheck checks only syntax or also types etc).
[There's a list in the Wiki](https://github.com/rust-lang/rust/wiki/Doc-packages,-editors,-and-other-tools)
It's worth mentioning that because of the lack of higher kinded types, Rust doesn't actually have the ability to have a generic Monad trait. But you can write specific monad instances, of which this is one. So _technically_ this is correct, but also sightly misleading...
You can have things that act like `null`s without pointers. One common example is things like [find](https://docs.python.org/3.4/library/stdtypes.html?highlight=find#str.find) returning either the index of the value or -1. -1 serves as a null value, since, like the value of 0 for a pointer, the value of -1 for an index is never a valid value.
Newbie question: why? Wouldn't it be a matter of making dereferences explicit?
Why is this misleading? It's perfectly fine to call it what it is in my book. :/ *Edit:* To clarify, I would take issue with /u/steveklabnik1 saying that '`Option` is a Monad' is misleading just because you can't express the abstraction. In spite of this, this observation could be a little [superfluous](http://www.reddit.com/r/rust/comments/2dnx7k/exploring_the_option_monad_with_rust/cjridje) given the content of this article.
Consider `&amp;'static str`. You probably want to be able to use that as a hash table key…
Bye bye type safety.
Or consider slices and &amp;str- without DST, they can't be dereferenced to compare!
Maybe I'm just tired, but; where is the part about Option *as a monad*? There was a lot of talk about *monad* but I don't know where the actual relevance was highlighted, A good deal of combinators, yes, but I don't know how obvious it was which of those were relevant to the *monad* concept. In general, people seem sometimes to be fond of referring to things as *the Y monad*, when they could have just said *the Y datatype* (I'm not saying that is the case here; maybe I've missed something). This was brought up by the creator of Elm at some time, who thought that people referring to the IO type as the *IO monad* was, though not incorrect by any stretch, slightly weird. In the same way that referring to addition over integers as *the addition semigroup* (or whatever the appropriate terminology would be for that): often, the abstract properties of addition over integers is not that immediately relevant. Same with the fact that types like Option, Result etc. are monads. 
Well, for the reason Steve mentioned, when I saw this headline I did a double take... "Wait, what? You can do monads in Rust?". The content of the article makes sense, but the title itself _did_ mislead at least one person.
But you *can* define types that satisfy monadic laws in Rust, just like Swift. You just can't generalize them with a unified abstraction.
One more thing I just noticed: You probably can drastically improve performance by creating only one `rng` per task. At the moment, you are initializing a new random number generator for every single random letter! This is inefficient, because * it allocates memory, * it needs to get entropy from the operating system to initialize the generator.
I’ve noticed a [category error](http://en.wikipedia.org/wiki/Category_mistake): &gt; It encapsulates the value x, where x is any type. This doesn’t seem well kinded.
Which is definitely quite nice!
I read a bit about that on one of the mailing lists I think. Should I add a disclaimer?
You're absolutely correct. I'm still grasping my understanding of monads myself, and looking at many relevant articles (which I do list). The Option type in Rust acts, and feels, like the Maybe type in haskell that most of them cite as a canonical 'Monad'. If you have any worthwhile reading material on this topic I'd really appreciate it.
Maybe. As I said, you're not _wrong_, but it implies Rust has moads, which it doesnt'.
Right. My comment is that saying "The X moand" implies that you can have a generic monad, which is not true.
You've the word 'strong' in there when I think you mean 'string' if you're looking for proofreading. This article was great btw. I was familiar w/ the option monad from Scala, but it's solidified a lot of my thoughts!
air.mozilla.org videos have never worked from me (in Firefox). I always need to download the file and watch in VLC :(
air.mozilla.org has annoyed me from my first experience with it. I thought HTML5 &lt;video&gt; meant I wouldn't have to be annoyed with video on the web anymore, and then the one place I sort of expect it to be a smooth experience (on a mozilla.org domain) it's annoying and shoves a custom player in front of my face. These days, I watch the network tab in dev tools for the webm file location, copy and paste the url and get the raw .webm file to play. Then I can set .playbackRate, or download it and watch it locally.
The trick here is the closure passed to [`iter`](http://doc.rust-lang.org/master/test/struct.Bencher.html#method.iter) can return a value, to help defeat dead code elimination. Written as you have done is trying to return the `x.iter().map(|...| ...)` expression (which is [a struct](http://doc.rust-lang.org/master/std/iter/struct.Map.html) storing the iterator and closure; see below), and, at the moment, closures are chained to the stack frame in which they are created due to capture-by-reference. Thus value storing the closure passed to map cannot be returned from the closure passed to `iter`, giving the error message you see. Minimal example: extern crate test; #[bench] fn example(b: &amp;mut test::Bencher) { let x = 10; let ns = [0u, 1, 2]; b.iter(|| { return ns.iter().map(|y| x + *y); // equivalent to what you have written (NB. no semicolon), e.g. // ns.iter().map(|y| x + *y) }); } &amp;nbsp; ...:9:30: 9:40 error: cannot infer an appropriate lifetime due to conflicting requirements ...:9 return ns.iter().map(|y| x + *y); ^~~~~~~~~~ ...:8:15: 12:6 note: first, the lifetime cannot outlive the block at 8:14... ...:8 b.iter(|| { ...:9 return ns.iter().map(|y| x + *y); ...:10 // equivalent to (NB. no semicolon) ...:11 // ns.iter().map(|y| x + *y) ...:12 }); ...:9:30: 9:40 note: ...so that closure does not outlive its stack frame ...:9 return ns.iter().map(|y| x + *y); ^~~~~~~~~~ ...:8:5: 12:7 note: but, the lifetime must be valid for the method call at 8:4... ...:8 b.iter(|| { ...:9 return ns.iter().map(|y| x + *y); ...:10 // equivalent to (NB. no semicolon) ...:11 // ns.iter().map(|y| x + *y) ...:12 }); ...:8:12: 12:6 note: ...so that argument is valid for the call ...:8 b.iter(|| { ...:9 return ns.iter().map(|y| x + *y); ...:10 // equivalent to (NB. no semicolon) ...:11 // ns.iter().map(|y| x + *y) ...:12 }); error: aborting due to previous error /u/gnusouth suggestion of adding a semicolon is stopping the value being returned, which then makes the compiler throw out a new warning: ...:9:9: 9:35 warning: unused result which must be used: iterator adaptors are lazy and do nothing unless consumed, #[warn(unused_must_use)] on by default ...:9 ns.iter().map(|y| x + *y); ^~~~~~~~~~~~~~~~~~~~~~~~~~ Specifically: &gt; iterator adaptors are lazy and do nothing unless consumed As stated above, the return value of `map` is a struct storing the base iterator (`ns.iter()`, or `kw_existing.iter()`) along with the closure; nothing is actually executed (i.e. `find` is not called) until that return value is consumed in some manner, e.g. by a `for` loop or via `collect`. Maybe you want to write b.iter(|| for _ in kw_existing.iter().map(|s| keywords.find(s)) {}) But I personally think writing the `for` you currently have is clearest, although the `find` calls may be being optimised out by the compiler, you should consider calling [`test::black_box`](http://doc.rust-lang.org/master/test/fn.black_box.html) on the return value. See [this section of the testing guide for more details](http://doc.rust-lang.org/master/guide-testing.html#benchmarks-and-the-optimizer).
A monad is not only a type, but needs operations that obey certain laws. E.g. in Haskell, these are `return` and `&gt;&gt;=` (also called `bind`). It looks like `and_then` corresponds to bind (and `Some` to return, of course), and `map` corresponds to `fmap` in Haskell (which is part of a functor, and every monad is a functor). It would have been nice to point out these connections somewhere at the beginning. Also, Haskell has a `do` syntax that gets rid of having to write these operations explicitely. Is there anything equivalent in Rust?
Looking great! Keep up the awesome work gfxers :)
On my Debian linux it works in epiphany, but not in chromium.
&gt; Is there anything equivalent in Rust? There's no native syntax, and it's [possible to can write macros](https://github.com/TeXitoi/rust-mdo) that translate `do`-notation-esque code into the appropriate sequence of nested closures; but handling it "properly" really requires a generic Monad (etc.) trait.
You're almost there from what I can tell. The fundamental problem is you've allocated bytesOut on the *stack*, so it will get destroyed when the function ends. If you were to allocate it on the heap instead, what you're trying to do would be fine. And you're correctly using lifetime `i to say that "bytesOut will live no longer than bytesIn does." (Caveat: I'm somewhat new to Rust myself).
What prevents Rust from having a generic Monad trait?
Thanks for the insightful explanation, using a `for` loop fixes it. (The `black_box` was not necessary.) I updated the [code](https://gist.github.com/vks/3d7db656c1ac22b5fc41) and the [benchmark results](https://gist.github.com/vks/b1ac7cbf0fbce84191a3). Interestingly, without optimizations the `PhfMap` is a little faster, with optimizations `HashMap` is faster. This is fairly impressive, because `HashMap` implements a DOS protection, while `PhfMap` does not. (The benchmark used ridiculously small maps.)
No Higher-Kinded-Types, which is required to define the Monad typeclass/trait.
Higher kinds. Kinds are to types what types are to values, and "higher" means "can have function arrows". The thing is that a type like `Option` is not a type, it's a type *function*, you have to give it another type (say, `uint`), to get at an actual type (`Option&lt;uint&gt;`). Rust can obviously do that, but you can't pass such a type function *to* another type, or trait, which is what is needed for a monad trait: It has to receive `Option` as a parameter and fill out the `&lt;T&gt;` itself, you can't just pass in an `Option` with `&lt;T&gt;` already filled out. Why? Have a look at `bind` (for `Option`): fn bind&lt;U&gt;(Option&lt;T&gt;, f: |T| -&gt; Option&lt;U&gt;) -&gt; Option&lt;U&gt; it is called with two different parameters, `T` and `U`. It's just like not being able to pass closures to functions, just on the type level. All that is actually not arcane magic, it's a bog standard thing to have, at least in the functional camp. Someone just has to do it, and from what I've heard it's just awkward to implement in the compiler, in its current state, for hysterical raisins.
Interesting to note that he does not seem to see safety as issue of C++ but performance + productivity.
I see memory safety and security as fundamentally quite related. The quintessential example of this is the Heartbleed vulnerability. You leak the wrong memory back to clients. I'm not sure using C++ would do anything to help that. But Rust definitely would. &gt; **InfoWorld**: What about the issue of security in programming? Is there anything that developers need to do as far as securing their programs? Is C++ a more secure language than others? &gt; **Stroustrup**: I'm a great fan of hardware to aid security. In terms of programming languages, if you want to write good programs, write your code type-safe. You can do that in C++. Don't mess around with low-level features all the time. And don't go to fully general interpreters where you can't track what is going on. Basically, security is a systems issue. I was quite impressed by the answer Stroustrup gave to this one. If you read between the lines, he seems to be saying &gt; Providing good security/safety guarantees is not a programming language's issue. Which I think is fundamentally wrong; this mindset to security works when your program can interact with the operating system/hardware enough that it can actually exploit the safety guarantees in this interaction. But most software is going to do its work within its own process - and the design goal for an OS process is to provide the illusion that - You own the entire system, the whole memory space, and everything in it. Thus your buffer overflows/use-after-frees/etc. are *not* something that can be checked at the systems level (unless your process attempts to leave its assigned memory space), and has to be checked within the application itself. The reality is - yeah, we could redesign our entire notion of operating systems to provide different safety guarantees. But with the OS's that we have right now, and the hardware that we have *today*, your route for strict safety guarantees is in programming languages that offer them: whether it's Haskell, Rust, or whatever else can actually manage to provide them.
Given the current state of the internet, programming languages must do all they can to ensure security.
Ah, ok. Yes, I wondered because higher kinds are not that difficult. So it's just the compiler implementation. Thanks.
I thought the heartbleed issue came about because the creators violated the 'don't mess with low-level features all the time' rule that Stroustrup mentions. Not necessarily because the system doesn't provide safety gaurantees.
You don't have much choice in C, since it's unable to build high-level safe abstractions. I think that while C++ is great at building high-level abstractions, it falls short of the ability to build safe ones. You would have to give up performance by abandoning iterators and references... and then the choice of language doesn't make much sense.
I'm happy to hear that :) What are the biggest productivity-boosting features of Rust, in your view?
A mix of succint syntax with the fact that everything is immutable and private. It's extremely frustrating to have to const everything in C++ and declare private methods in a private or anonymous namespace. This little difference means I don't need to write an insane amount of code. Then there's the fact that the compiler handles testing and the fact that I don't have to guess which includes to use, but these are a very distant second.
Heartbleed in somewhat modern C++ would have been found the first time someone touched that codepath in a debug-build or ran a static-analysis-tool on it: They would have created their own allocator and used it with std::vector or std::string like this: std::vector&lt;char, openssl::allocator&gt; buffer(size); Out of range-access with the []-operator (instead of the at()-method) would still have been undefined behavior, **but** the debug-mode that every relevant stdlib has would have detected that right away and static-analysis-tools have a much greater chance of being aware about the standard-array-type of a language than being aware that some function allocates and returns a certain amount of memory (especially since C's arrays don't have a way to tell their size). OK, granted, we are talking about the openssl-people, so they would have implemented vector themselves too, but they would have done stupid things like that in every language (“Rust has the `unsafe`-keyword. I guess that's the make-it-fast-switch, so let's use it all over the place”). We should also keep in mind that while Heartbleed *may* have been an accident, we should play safe and assume that it was backdoor for some intelligence-agency. 
Header files don't bother you?
What makes Heartbleed-style vulnerabilities particularly challenging is that they depend on _both_ malicious inputs _and_ undefined behavior. So it's entirely plausible that it would have never hit dynamic bounds checking, unless people were specifically testing for invalid length provided by the attacker, and would then ship with the checking turned off. So I don't think it's a good assumption that just writing it in modern C++ would provide much assurance of safety. And the point of the use of `unsafe` is that if you do it right, it's local and it's easy to spot. In C++, UB lurks around every corner.
I don't think there's a fundamental relationship: memory safety guarantees that the certain class of behaviours which can be big security flaws don't happen, but security is so much more than no buffer overflows, and it's a mistake to conflate the two (how many security flaws have been written in PHP, which is memory safe?). I want memory safety in a system I'm designing to be secure, but it's far from the only thing I want.
I include that in the reduced amount of typing.
&gt; And the point of the use of unsafe is that if you do it right, it's local and it's easy to spot. Nobody denies that, but I do deny that the openssl-people would have done it right. I mean, they reimplemented the C-stdlib because some ancient MS-compiler that nobody serious used in the last ten years had a bug. Don't think for a second, that they wouldn't have used unsafe because they believed (it might even have been unfunded from the start) that it might be faster. The whole reason they added their own allocator, which was the main(!) reason for this bug not being found by static-analysis tools, was that `malloc` in Open-BSD was slow, because Open-BSD implemented malloc in a way that would have made heartbleed impossible to exploit! To be very technical: Heartbleed never really triggered undefined behavior! All the memory that was accessed was within the memory-area that was returned by malloc. This is one of the reasons for me to say that we should assume malice in this case: Heartbleed was perfect for what it did.
&gt; So it's entirely plausible that it would have never hit dynamic bounds checking, unless people were specifically testing for invalid length provided by the attacker, and would then ship with the checking turned off. So I don't think it's a good assumption that just writing it in modern C++ would provide much assurance of safety. This is correct. You would have had to use `.at()` (which people generally don't do).
my problem with C++ is summarised "the way classes and headers interact". I like the fact Rust has neither. 
You can derive the [`FromPrimitive`](http://doc.rust-lang.org/master/std/num/trait.FromPrimitive.html) trait (`#[deriving(FromPrimitive)] enum OPCode { ... }`), and then `FromPrimitive::from_u8(x)` will give you an `Some(OPCode)` if it's valid and an `None` if it's not. (Type inference may work, but you may need to provide a type hint for the compiler to deduce that you want an `OPCode` out of `from_u8`; and currently the only way to do this is with a variable binding, e.g. `let op: Option&lt;OPCode&gt; = FromPrimitive::from_u8(x);`.)
Headers are technically completely broken. They are what make C++ compilation so slow. The whole concept of textually including code that may textually include other code is no way to split code into multiple files.
On the other hand, writing headers is a bit of a PITA due to the duplication. This is one of the things about C++ I find annoying. But there are some ideas on how to improve that: Automatically generating a "binary header" from your translation unit (while compiling) that is quick to parse for a machine. This saves typing (less duplication) and should also speed up compilation. At least this is how I understand what the "upcoming c++ module system" is about if it ever lands.
I guess, this is a bit too short for me. :)
Thanks! I figured there should be something like this, just didn't know where exactly in the docs to look.
I think what Stroustrup means is that C++ supports programming styles that are inherently less error-prone than what you can do in, say, C. I even heard Herb Sutter saying at some conference something along the lines of "C++ is safe". Of course, he said this to get some attention. But what these guys really mean is that C++ gives you some very cool tools that you just need to use effectivly. But I also think that C++ does not go far enough and in that I guess we can all agree that Rust has some very nice properties. I _really_ dig the lifetime system, for example. I don't really know whether Stroustrup is even aware of what's going on in Rust. Maybe someone should tell him. Stroustrup did say "Within C++ there is a smaller, cleaner, better language struggeling to come out". And I found myself wishing for someone to come and dig it out. But now, it seems Rust could be the C++ replacement I've been waiting for. It just needs to support generic programming a little better. For example, the "implicit `Self` input parameter" for traits makes it impossible to call "static methods" that don't return something involving `Self`. Also, I really want my "associated items" and "multiple dispatch". The contortions I have to go through sometimes are a bit annoying.
I'm not sure it's a good idea to make Stroustrup aware of Rust. Then would just see lifetimes, borrowing, and an `unsafe` keyword in C++2z.
&gt; A quick scan through a header file usually is more informative than digging through (possibly outdated) documentation. Well, if the documentation is autogenerated (via `rustdoc` for example), isn't that the best of both worlds? You save on typing and compilation time by not having headers, but you get up-to-date docs and pretty formatting by nicely organized docs.
&gt; I'm not sure it's a good idea to make Stroustrup aware of Rust. Then would just see lifetimes, borrowing, and an unsafe keyword in C++2z. I know you're joking, but I think that would actually be great! I want secure software above all else. (Unfortunately I don't see how it's possible without breaking backwards compatibility, which has always been paramount in C++.)
Thank you for the pointers! Looks really interesting...
I would kill for a direct download for all air.mozilla videos.
Are you sure you don't want something like this: #[deriving(Decodable)] struct Foo { bar: f64, baz: Option&lt;String&gt; }
Is this guaranteed to decode from JSON? The documentation don't say anything.. edit: actually [this](http://doc.rust-lang.org/serialize/json/) clarifies that there is a json::decode for all decodables. There is also no need to directly define ToJson since Encodable is derivable. Cool!
In your example, all errors have location: 7. For some reason you need to convert from a raw error and thus need to provide a random default location. It perhaps doesn't make much sense (if you see a ParseError with location: 7, you don't know if it's *really* location 7 or it is an meaningless default) Also, how to use your errors without this convert-from-rawerror thing (in that example, when the location field is decided when the error is signaled)?
&gt;&gt; One, I can only pass stuff back out that lasts at least as long as the input parameters. Not quite right. You can only return something that *does not live any longer* than one of the input parameters. (Its perfectly fine if it lives for a shorter time). (And there are ways to return things tied to lifetimes other than those of your function parameters. For example, inside an impl that has a named lifetime, you can have a function that returns things that live for that lifetime. A named lifetime can appear pretty much anywhere a trait parameter can appear. So, for example, impls, traits, structs, etc. can all have lifetime parameters).
Something like the following could also work (untested) fn expect_eq(name: String, expected: &amp;str, error: &amp;str) -&gt; Result&lt;(), ParseErr&gt; { if name.as_slice() == expected { Ok(()) } else { Err(ParseErr(format!(" {}. Expected {}. Found {}.", error, expected, name))) } } ..... match event { Ok(sax::StartElement(name, attrs)) =&gt; { try!(expect_eq(name,"tag","Unexpected tag")); try!(self.parse_tag(tags)) } Ok(sax::EndElement(name)) { try!(expect_eq(name,"node","Wrong tag closed")) } _ =&gt; () } EDIT: Here you could perhaps write https://github.com/mattyhall/osmxml/blob/master/src/lib.rs#L45 match try!(event.map_err(|e| SaxErr(e))) { .... } Or alternatively introduce a new Trait ToParseResult and implement it for SaxResult, so that you can write match try!(event.to_parse_result()){ .... } Here you could perhaps define a utility frunction that allowed you to write https://github.com/mattyhall/osmxml/blob/master/src/lib.rs#L73 let id = try!(get_attr(attr,"id")); Ideally rust should provide a way to convert an Option into a Result. Then you could write something like the following let id = try!(attrs.find("id").and_then(|v| from_str(v)).to_result_or(|| ParseErr("Could not find id on node ")); AFAICS this for-loop is redundant https://github.com/mattyhall/osmxml/blob/master/src/lib.rs#L146 
Using uninitialized memory is undefined behavior. In fact, compiler optimizations based on this undefinedness led to [another famous OpenSSL bug](http://research.swtch.com/openssl).
When I was learning C++, there were many times where the header and source files would go out of sync and cause indecipherable error messages, sometimes even at link time.
&gt; Well, if the documentation is autogenerated (via rustdoc for example), isn't that the best of both worlds? There are tools that autogenerate documentation for C++. Therefore, I don't see how the ability to autogenerate code can be used as an argument against header files as used in C++.
Link?
Don't you think C++ is big enough as it is?
That is precisely why header files are a burden. The only good thing about them is that they provide an overview, but a program like rustdoc is far better. So we're left with just their negatives. A simple `rustdoc foo.rs` will generate html output like this: http://www.piston.rs/docs/piston/piston/ 
Java's syntax is pretty cool. It's basically C++ done right and light.
Well, each type which implements Error defines an `as_raw` method, which is used in the conversion of `YourError` to `RawError` in the blanket Convertible impl. There's a reason that `RawError` contains an optional extensions field of `Box&lt;Any&gt;`, and it's the reason so much work needs to be done to ensure that this is in fact the right error - you are expected to store any additional information about that error in the extensions field then get it back when you need it in your `Convertible&lt;RawError&gt;` impl, so you need to be sure that this error is actually that error type! Notably - and I think this answers your query - the conversion from an Error to a RawError is unconditional, it's only the conversion from a RawError to any specific error type that is conditional - if you try to convert it to the wrong kind of Error, you'll just get back None. There are no unsafe downcasting methods exposed by this crate - the only way you can cause this to fail is by unwrapping an option that is returned by `raw.to::&lt;YourErrorMarker` - which is just the wrong thing to do. You are supposed to handle specific Error Markers if you can, and if you can't then you should just re-propagate the error. (or, if you are the last line of defense, fail!, or whatever is appropriate)
Unless you are browsing code online or otherwise doesn't have this document generating tool readily at hand.
I'm still confused. At `impl&lt;T: 'static&gt; Convertible&lt;RawError&lt;T&gt;&gt; for ParseError` it builds, for an error marked as parse error, an `ParseError { location: 7u }`. Shouldn't the location always come from the user that thrown the error, without such defaulting? I mean, as it was created, `ParseError` isn't very useful.. [ edit: perhaps the issue is that the example isn't very good for how your error mechanism would work in practice; another issue is that when it "throws", it creates a `RawError&lt;ParseErrorMarker&gt;`, which I suppose isn't the right way to signal an error; instead, it should directly build the `ParseError` ] Also what if I want to catch N kinds of exceptions - would I have N nested matches (or chain it using some `Option` method)? Ideally (in terms of syntax bikeshedding..) there would be something like match &lt;something&gt; { &lt;error 1 I know&gt; =&gt; .., &lt;error 2 I know&gt; =&gt; .., ..., &lt;I don't know this error&gt; =&gt; fail!("unable to handle error") }
Yes, I probably should use the extensions field in the example to show why this is nice and actually works. In reality, the convertible instance for ParseError should check if this is a parse error, then, if so, try to read the extensions as the type it anticipates and get the info it needs from there. Once it has that type, it can create a ParseError with relevant data. I defaulted to 7 to be brief. Unfortunately the best thing we can get for that is: if raw.is::&lt;Error I know&gt;() { .. } else if raw.is::&lt;Error 2 I know&gt;() { .. } else { freak out } I really don't like this, and I wish there was a better way, I just don't know it yet. This is effectively what match does for enums, but it gets to be a language construct. Some kind of expanded macro could implement similar syntax for these errors, but that's not something I'm very familiar with.
You can try to implement `Decodable`, yourself, but I find it kind of clumsy and you may not really be able to do exactly what you want. I think your best bet may be to traverse the JSON structure "manually" using [`json::from_reader`](http://static.rust-lang.org/doc/master/serialize/json/fn.from_reader.html) or [`json::from_str`](http://static.rust-lang.org/doc/master/serialize/json/fn.from_str.html) if you want full control.
Java is *simple*, so is C. The main issue, of course, is that a simple programming language does not make writing programs in them simple. The two facts are unrelated. Thus, I prefer choosing a language that make writing programs simple (for example, by checking more things at compile-time) than choosing a simple programming language.
I thought like that back in 1996, but the way enums, generics, FFI got bolt into the language and type inference, operators, value types are still not there, doesn't make it "C++ done right" on my eyes. Additionally I am still awaiting Oracle catches up with other JVM vendors and also offers AOT compilation on the standard JDK (which they actually have on Graal/Substrate and embedded versions, not sure about J/Rockit).
That's great thanks. I ended up going with this macro because I needed to handle multiple children and the methods called to parse the children taking different arguments: macro_rules! parse { ($iter:expr, $close_tag:expr $(, $tag:pat =&gt; $method:expr)*) =&gt; { for event in $iter { match event { Ok(sax::StartElement(name, attrs)) =&gt; { match name.as_slice() { $($tag =&gt; try!($method(attrs)),)* _ =&gt; return Err(ParseErr(format!( "Unexpected child in {} Got a {}", $close_tag, name))), } } Ok(sax::EndElement(name)) =&gt; { if name.as_slice() == $close_tag { break; } return Err(ParseErr(format!( "Expecting {} to end, not a {}", $close_tag, name))); } _ =&gt; {}, } } } } Use: parse!(self.parser.iter(), "way", "nd" =&gt; |attrs| Ok(nodes.push(try!(self.parse_nd(attrs)))), "tag" =&gt; |attrs| self.parse_tag(attrs, &amp;mut tags)); I thought I'd paste it in just in case people were curious what I ended up with. It ended up getting rid of 52 lines which isn't bad! Thanks very much. Usually I don't like macros but I may be a convert now :P
Java allows you to tackle pretty complex problems in a simple way.
I **totaly** agree with you on that. I guess however that this is another case of getting bitten by the C-heritage: C-style-arrays never had bounds-checks and C++ tried to be consistent. Another reason is probably that the overhead of the checks was much bigger when C++ was invented than nowadays because compilers were much worse back then.
&gt; Using uninitialized memory is undefined behavior. * No, writing to uninitialized memory is perfectly fine (since it is an intialization ;-)), only reading is the problem. * The problem was however, that they **did not** read unintialized memory. The memory was often perfectly initialized by private-keys and stuff like that.
Reading off the end of an object is UB (even if it ends up in some other piece of valid memory): From the C standard (paragraph 8 of 6.5.6 Additive operators; [free-to-access draft](http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1570.pdf)): &gt; If both the pointer operand and the result [of P + N] point to elements of the same array object, or one past the last element of the array object, the evaluation shall not produce an overflow; otherwise, the behavior is undefined. 
&gt; If both the pointer operand and the result [of P + N] point to elements of the same array object The problem with heartbleed was that this condition was fulfilled: char* buffer_start = NULL; char* buffer_free = NULL; char* openssls_alloc(size_t size) { if (buffer_start == NULL) { buffer_start = malloc(1024*1024*10); buffer_free = buffer_start; } char* return_pointer = buffer_free; buffer_free += size; } int main() { char* heartbeat_buffer = openssls_alloc(10); fill_with_user_data(heartbeat_buffer); char* privkey = openssls_alloc(1024); fill_with_some_privkey(privkey); send_data(heartbeat_buffer, 100); } This code is perfectly well defined to send the 10 byte data from the user followed by the first 90 bytes of the privkey. Note that malloc doesn't return an array but a pointer, and we are only passing around other pointers that are all staying perfectly within the 10 Megabyte range that we allocated. I am not saying that their code never, ever triggered UB, but it that only rarely and the bug had nothing to do with that, because it can occur exactly that way in code that is 100% free of UB. 
&gt; The point is that header files are unnecessary as documentation if you have a documentation generator. Any source file may be deemed unnecessary as documentation if you have the documentation or the means to automatically generate it. That doesn't depend on what programming language you're using. Therefore, I don't see how the ability to autogenerate code can be used as an argument against header files as used in C++.
Which Java features would help with that compared to other programming languages?
I haven't thought about this in any kind of detail, but I think they could just do what they have always done: if they really want something to work a given way, but it would break backwards compatibility to change the existing thing to work that way, just duplicate the functionality and bolt on a new, parallel feature which works the desired way, and unofficially deprecate use of the old feature. Uniform initialization, "postfix" return types, `enum class`, and there's probably more examples, if I wanted to think about it harder. So I could see them adding new lifetime- and ownership-checked reference types, `safe` functions and `safe` blocks, and so forth. It's not obviously feasible, but not obviously infeasible, either. (It would be kind of funny if they did this, but as you note, not a bad thing.)
Not features per se, just the fact that it's not as complex as C++. Single inheritance saved everyone a lot of headaches, for example.
That is happening because they are not being used by public functions. Are you putting "pub" on the symbols you want to export for the user? 
There's a pending pull request with HashMap optimizations https://github.com/rust-lang/rust/pull/15720
Yep. They have pub in front of all of them. 99:31 warning: code is never used: `HAction`, #[warn(dead_code)] on by default /home/rick/Projects/hammer/src/bindings/rust/src/hammerll.rs:99 pub enum HAction
So you could just restrict yourself to single inheritance in C++ ? I don't see any Java feature which helps me to tackle complex problem, compared to OCaml for example.
Is the module itself pub? 
One problem of the header files is, that you can't have header files if you are working with templates. Which means that they are even flawed for one of the most important C++ feature. This is why I dislike them. Because they are conceptual just broken… 
Depends - light templates are OK. But if you're into template metaprogramming yeah ... headers become a swamp. But in that case headers usually are implementation files.
We used to have `std::reference::ref_eq(ref1, ref2)` but [it was removed in favor of those gross pointer casts](https://github.com/rust-lang/rust/commit/f17d972014625eae13ac6d7fe98ff82a110a14d3) :(
 pub lat: f64, pub lng: f64, Those are actually saved as I think 64 bit fixed point numbers in the Openstreetmap database right now if I remember correctly. The problem I guess is that you would need to write an own parser for it. If you keep using floats you may loose some bits of accuracy. There's not much documentation about it but for the pbf format it's documented how they store the lat/lon values in integers: http://wiki.openstreetmap.org/wiki/PBF#Definition_of_OSMData_fileblock
Ah Ha! Declaring it pub mod in the lib.rs did the trick. Thanks. 
I've updated the post and noted a thanks to you. Thanks for the input!
See? It helped you find a problem! :D
OpenSSL has some fairly sophisticated exploit mitigation countermeasures to ensure it's equally vulnerable on all platforms.
Google engineers had some biting comments about Rust's lifetime notation, from what I remember on the ML.
link?
Which are now out-of-date, as lifetime elision handles the case that they brought up.
Thanks for this. I'm considering Rust for game development, and this post and subreddit gives me a lot of material to work with. &gt; Bad news: Concurrent game loop is unsafe I'm actually surprised you were surprised by that. The main-thread, non-thread-safe event loop is a core constraint in modern desktop OSes.
&gt; On the other hand, writing headers is a bit of a PITA due to the duplication. Visual Assist really helps with routine.
Which OS requires rendering from the main thread?
"I can't wait for 1.0 so I can actually try it." is the largest thing I hear. We have a dedicated troll in proggit, so that's a certain measure of success ;)
Yeah, but I think he was wrong about short keywords/sigils being uniformly bad. :) Nobody would much like to write: public function inner(reference mutable self) -&gt; reference mutable R { reference mutable self.h.r }
established *software* companies will depend on legacy source bases I guess? There's an adage that a rewrite can the death of an organisation. Ok, huge companies would start new projects.. but they will still want to move programmers and code between them. Maybe Rust will be of greatest interest to startups? I hope it becomes practical to mix rust &amp; C++ ( i know it can interface with C quite well, but imagine if there was some crossover with the close equivalents of rust &amp; C++ features, generics/templates, class methods gathered mapped to trait methods..), .. introduce Rust gradually into an existing project. organisations can impose their own C++ subset &amp; workarounds internally. &gt; everyone agrees that C++ is too complex, [1] I don't actually agree with that: I see it as incomplete, there's features it lacks I wish were added. it has features that are slightly broken so others are misused to workaround gaps. [2]..also not everyone agrees how to replace it, so we get fragmentation whenever we try to.
 public function inner(reference mutable endogenous) -&gt; reference mutable R { reference mutable endogenous.height.radius } ftfy
I quite agree—I think that we have a good balance now.
Why the down vote? This is pretty much exactly true. ...not that rust completely solves the problem (ie. unsafe) but it does do a lot towards memory saftey; I'd certainly choose rust over c++ or c to write a web service.
Mad a comment about game balance on another sub reddit. Dude must be down voting my entire comment history. 
Such people really should be hellbanned from Reddit's karma system... "Oh, you went into 3 subreddits and downvoted only *this* guy's comments in a ten minute period? Well, enjoy not being able to affect karma to anybody else." Edit: I went and upvoted all the comments that were downvoted.
Its a really toxic discussion I regret get involved in, in retrospect. Overall to get back to the original topic. The main interest I have in rust is concurrency and general memory safety. The idea of writing an server in C/C++ often scares me because I don't know enough about those languages, and doing something wrong is easy. Rust to a degree prevents that from happening. I mean I can still shoot myself in the foot in a hundred creative ways, I'm still programming. But having a degree of memory and type safety is a very positive thing. 
A way to render color images is missing. :-)
Try changing the `&amp;Some(self.x)` to `Some(&amp;self.x)` and the return type to `Option&lt;&amp;'a f64&gt;`.
Pull-request: https://github.com/rust-lang/rfcs/pull/205/files 
And I think rust is on a good way for 1.0. It's getting more and more polished.
People I've introduced it to have reacted very positively, though a lot are waiting for 1.0. I'll be giving a talk on Rust today, might informally gauge the reaction later :)
Bikeshedding, but I'd prefer something like `ub5` to distinguish bit types from proper integer types.
Like what? And when was this? Anything before 2014 doesn't really count as the language was too young.
I work at one of those other giants. Scala is just now starting to be taken seriously, with some teams working exclusively in it. I've mentioned/talked about rust with several coworkers, and most echo the line about not really being interested until 1.0. I personally haven't found a project worth introducing rust for. With the amount of infrastructure hassle that would come along for the ride it's made much more sense to work in an already available language. I'll probably try introducing it to coworkers on a hackathon/utility project first, and likely then after 1.0
You can learn it now, just don't write any production code with it. There's a big difference between the two.
it is definitely easy to link C++ and Rust via the C abi. However you lose a lot of expressiveness in interfaces, compared to pure C++ or pure Rust, as you know from the difference between C and C++. I guess there's SWIG .. maybe people are trying more elaborate ways of interoperating 
Post any links?
That guy was a golang fanboy. He added nothing to the discussion. I definitely expected better from Google staff.
&gt; However you lose a lot of expressiveness in interfaces Can you explain this?
you can't use all Rusts or C++'s features with 'extern "C"'. it might be possible to auto-generate wrappers with extern 'c' stuff in the middle. I'm not aware of this having been done yet (haven't looked around recently); I've had a bash at doing this myself, for this exact reason.. I wanted to be able to hedge my bets. (personally I've found mature C++ IDE's X my familiarity count more for my productivity than the superior Rust language design)
That name isn't explanatory at all...
Gotcha.
&gt; I'm actually surprised you were surprised by that. I'm definitely surprised by it, seems like a strange and unnecessary constraint, I imagine it's due to some historicalimplementation decision I'm not privy to, but I've never bumped into it. The more you learn.
Funny thing that it is not possible. `index()` signature is defined like `index&lt;'a&gt;(&amp;'a self, index: &amp;Index) -&gt; &amp;'a Result`, so even in the case you suggested it should be `&amp;'a Option&lt;&amp;'a f64&gt;`. Sadly, `Index` traits are currently unsuitable for anything but references into the structure they're implemented on, and only if their corresponding methods `fail!()` if the passed index is invalid. 
&gt;I'd argue the u is probably unnecessary since we're dealing with bits, but it's a fairly intuitive name. I thought that too, but the RFC has signed fields too, so I'd assume they have some use. 
Usually you use a feature because it seem the better solution and see all the problems that come with it when it is too late. And even if you are aware of the drawback of a feature and decide to not use it, you will probably have to deal with code you didn't write that use it and libraries relying on it. 
When go was new I couldn't wait and started hacking away. With each breaking change in go it really became frustrating and after some time I lost motivation. With rust I'm going to wait to 1.0 before I start anything serious in it.
There's also the issue of endianness for multibyte values. Erlang's [bit syntax](http://www.erlang.org/doc/programming_examples/bit_syntax.html) has a fairly descriptive and flexible specification system: a pattern is of the form &lt;&lt; Value[:Size][/TypeSpec], ... &gt;&gt; where * `Value` can be an unbound name in a match * `Size` is a multiple of the typespec's `Unit` (8 for `integer`, 64 for `float`, all of the binary for `binary`) * `TypeSpec` is a sequence of (optional) dash-separated fields: - data type, one of `integer`, `float` or `binary` (default: `integer`) - signedness, one of `signed` and `unsigned` (default: `unsigned`) - endianness, one of `big`, `little` or `native` (default: `big`) - unit, `unit:UnitSize` provides the native segment size (default: 1 for `integer` and `float`, 8 for `binary`) 
It's only OS X which has this problem. On Windows you just need to be in the same thread that created the window. On X11 I don't believe it matter as long as you don't have concurrent access.
&gt; This RFC does not discuss endianess issues. It is assumed that the bit-fields are defined in target endianess. This is repeating the same huge mistake that C made (which made their bitfields largely unsuitable for cross platform code). This RFC use PCI as part of its justification, as if the bitfields were designed for hardware and binary file formats. But both of those are not dependent on target processor endianess: The standard PCI registers don't change bit definitions around when you're on a big endian PowerPC… Similarly, TCP/IP headers bit are defined in network byte order (big endian) even when the target is an x86. You want a TCP/IP header to look like it does [in the spec](https://tools.ietf.org/html/rfc791#section-3.1): bitdata IP_Header { IP_Header { Version: u4, IHL : u4, Type_of_Service : u8, Total_Length : u8 } } As the RFC is currently specced, I'm not even sure what a IP Header would look like on an x86 machine. Everything reversed? Just the bytes reversed, but the 2 nibbles in the same order? How is a rust program supposed to implement something like this? To do that in C you'd need #ifdefs for every bitfield and endian combination (and possibly more than that since while different C compilers generally do the same thing on a given platform, they are not required to). How about `bitdata_big` and `bitdata_little`?
You should probably avoid the name `Vector` since this is the name of a trait in the standard library. Try this: impl Index&lt;uint, f64&gt; for Vector { fn index(&amp;self, rhs: &amp;uint) -&gt; &amp;f64 { match *rhs { 0 =&gt; &amp;self.x, 1 =&gt; &amp;self.y, 2 =&gt; &amp;self.z, 3 =&gt; &amp;self.w, _ =&gt; fail!() } } } Or better yet: Use an array since you want to index the elements: struct Vec4 { coefs: [f64, ..4] // fixed-length array, no indirection } impl Index&lt;uint, f64&gt; for Vec4 { fn index(&amp;self, &amp;rhs: &amp;uint) -&gt; &amp;f64 { &amp;self.coefs[rhs] } } You might have noticed that I did not use any explicit lifetimes. These are not needed anymore in these cases thanks to "lifetime elision".
Is it complete?
The slides are just aids since I want to be able to point at code. The majority of the explanation is in the talk itself. I might write a script for this set of slides at some point, but I'm really busy these days so it'll take time. Thanks!
Whoa.. whic tool did u use? Looks cool
[Reveal.js](lab.hakim.se/reveal-js/). I plan to eventually submodule it instead of just copying it over. 
The plan is for the language to hit 1.0 by the end of the year.
Except that the C++ standards committee wouldn't risk breaking backward compatibility by say, requiring `unsafe` for all code that has undefined behavior. And I think it's the fact that Rust aspires to be a systems programming language with low level control, *and has no undefined behavior*, is what attracts me to it. 
I like the goal, but wouldn't it be better to jump onto fun staff instead of re-implementing math primitives? There is already a lib or two for that...
Please have a look at the one in scenegraph-rs. It has a small test and a big example too. I believe it's mostly ready for the Ludum Dare type of usage. P.S. scenegraph-rs has nothing to do with scenegraph, at least now. It was meant to experiment with higher-level code. I started with a component-entity system (ECS), and it turned out to be a lot of fun. But this is completely orthogonal to gfx-rs. The asteroids example there is based on multi-threaded gfx-rs though.
9th of June 2014 as per this tweet: https://twitter.com/damienmiller/status/476207923702423552
That's not... cool.
As I am a big, big fan of REPLs and other forms of interactive computing. It drastically speeds the learning of APIs, programming languages and speeds development of large applications. I would love to see such a feature for this reason. I think dynamic codegen could probably have been accomplished with boxed closures, it just happens to be an area of Rust that (afaik) hasn't been addressed yet. 
Does lifetime elision just mean the lifetime is inferred for the most basic cases?
There is an advantage to long keywords and no abbreviations in names: it makes names consistent and predictable. For example, there are now types [`Buffer`](http://doc.rust-lang.org/std/io/trait.Buffer.html) and [`RingBuf`](http://doc.rust-lang.org/std/collections/struct.RingBuf.html), methods [`buffer_length`](http://doc.rust-lang.org/syntax/parse/parser/struct.Parser.html#method.buffer_length) and [`buf_len`](http://doc.rust-lang.org/std/ptr/fn.buf_len.html), etc. When there is abbreviation, it is not immediately clear where to draw the line. If there is no abbreviation, it is always clear. On the other hand, `ui` is _much_ less tedious to type than `user_interface` and `io` is _much_ shorter than `input_output`, so it is nice to abbreviate some things.
Desperately waiting for someone like you to write **Rust for C# programmers**
I would interpret that as one engineer's personal opinion. I personally find Rust very exciting and am exploring the option of using 20% time to improve the language and libraries, as well as implement interesting things in it. That is, of course, also my personal opinion and not an official endorsement by my employer.
&gt;As the RFC is currently specced, I'm not even sure what a IP Header would look like on an x86 machine. Everything reversed? Just the bytes reversed, but the 2 nibbles in the same order? How is a rust program supposed to implement something like this? individual 8 bit values are endian safe *at least in the cases i've tried playing around with Big endian file reading on PC* (which is why a char/char array in c is endian-agnostic)- the issue comes with multiple byte formats (anything bigger than a u8) In the spec, it looks like Total_Length : u16 not u8... So a u16 is endian dependant (for example the number one in a u16 varies by endianness *it could be [0x01|0x00] or [0x00|0x01]*) usually data structures are sent out in an array of bytes, so order doesn't change, just the value of things with more than one byte. as far as your concern for the nibbles, In the example of Version &amp; IHL tags, Since they'd be built up as: u4 Version = 1 (0001) u4 IHL = 2 (0010) in memory they'd be stored as bytes (since usually things are byte aligned on PCs) Version = (0000 0001) IHL = (0000 0010) And probably combined in to a single byte for the output Version &lt;&lt; 4 | IHL to get (0001|0010) version and IHL exactly as laid out in the spec.
I'd love to see this happen, makes working in constrained environments easier (Microcontrollers, space constraints, or optimizers looking to optimize down to the byte level!) I'd love to see this be made part of rust...
&gt; "I was always really annoyed with C++ that the safe alternative was the most verbose one. I would have preferred:" one could make a `std::safe::vector&lt;T&gt;` which you could select with using in preference, and if enough people wanted it , it could be added to the std lib or they could add a load of #ifdef SAFE ... &lt;extra checks&gt; ... add another build config. Sliding scale between debug(with loads of extra checks) -&gt; safe(some extra checks) -&gt; unsafe+speed(all checks removed.. as in current C++ release builds) 
&gt; Unfortuntely, the compiler allows only one implementation of Mul for a type, regardless of the type parameters for Mul. Because regular multiplication of two f32s implements Mul already, we cannot implement it for Vector3 any more. I think nmasakis and pcwalton have been working on that. If I remember the idea was to have "In" and "Out" type parameters and you would be able to write an `impl` for each distinct tuple of "In" type parameters.
Namespaces for enums as in C# were discussed [here](https://github.com/rust-lang/rust/issues/10090) The consensus seems to be that it would be great to have, but it probably won't be in version 1 of Rust. In Rust, enums are specifically the types they are given values for: as the [docs](http://doc.rust-lang.org/tutorial.html#enums) point out, in that 2nd example, enum Color, the types are unsigned ints. In the next example, they don't have precisely defined values, but the types are clearly stated. 
Be warned, the tutorial may be out of date. I'm not actually sure this is still valid, I don't think that you can make enums equal to a number outside of `repr(C)`. But I'm also not sure. (Running on the sandbox, it looks like they are.) I just talked to the core team, and there is a little bit of confusion here. Expect clarification soon. http://discuss.rust-lang.org/t/exact-semantics-of-enums-with-numeric-discriminants/404
This is interestingly similar to what I'm writing currently (spectral path-tracer in Rust as well). I've given up both-sided operator overloading though in favor of more flexible method syntax. Downside: cryptic names. \^\^
Neat. Thanks!
There are still a bunch of utility methods on `HashTable` like: http://doc.rust-lang.org/std/collections/hashmap/struct.HashMap.html#method.find_or_insert_with, which might be what you want.
I think having a cookbook of patterns will be essential in getting the language adopted. From building simple UDP/TCP servers through to various parallelism models (e.g. the various zeromq models: pub/sub, ventilator/worker, fair queuing). Common object oriented techniques.
You should add this as a comment to the RFC, it is great syntax.
Yup, all of that is very important.
There is also [`insert_or_update_with`](http://doc.rust-lang.org/std/collections/hashmap/struct.HashMap.html#method.insert_or_update_with), which might be more suitable. :)
No, it's not inferred. Type inference comes later. There are some simple patterns the compiler recognizes and adds lifetimes automatically. For example, if you have a method taking a `&amp;self` or `&amp;mut self` which also returns a reference, the compiler will automatically use the same lifetime parameter for self and the return type -- because that's almost always what you want. You can still override this by using explicit lifetimes. See [this RFC](https://github.com/rust-lang/rfcs/blob/master/active/0039-lifetime-elision.md) for more details. I don't know whether this already made it into the documentation.
Short version : Yes Long version: https://github.com/rust-lang/rfcs/blob/master/active/0039-lifetime-elision.md
Haha! I'm also writing a spectral path-tracer, but I'm currently using [cgmath-rs](https://github.com/bjz/cgmath-rs) for the maths. I think other parts, like materials and shapes, are more fun, so I just went with an existing library to get myself going.
What are your plans for multi threading and distributed rendering, if I may ask? Just rendering different random seeds and averaging the images?
This is interesting.
You work in pr0n?
Keep us posted.
Dynamic codegen will not be part of the language itself- it's completely counter to its philosophy of low-level control. Dynamic codegen could be done as part of a library, using a macro, without even needing closures, unboxed or otherwise.
I'm just splitting the image into small tiles and distribute them over multiple threads. The good thing with this is that the memory usage is independent of how many threads I have, but the problematic thing is that algorithms like metropolis light transport won't work well. MLT is meant to render the whole image in one piece.
OK thats great thanks for the info! Glad that the namespace thing is a possibility... And it's good to know thats how Enum types are handled *Just wanted to make sure, just cause C has varying rules on this and i hate it :|* 
correcting style (spacing, indent 4 spaces, useless parentheses, name of the iterator variable), and with a workaround for the borrowing error: extern crate collections; use collections::TreeMap; /// Count the number of occurrences of each value in an iterator pub fn get_counts&lt;K: Ord, I: Iterator&lt;K&gt;&gt;(mut iter: I) -&gt; TreeMap&lt;K, uint&gt; { let mut counter: TreeMap&lt;K, uint&gt; = TreeMap::new(); for key in iter { match counter.find_mut(&amp;key) { Some(value) =&gt; { *value += 1; continue; } None =&gt; {} } counter.insert(key, 1); } counter }
Dynamic codegen isn't contrary to the philosophy of low-level control if you have control over it. :) Creating a closure is an explicit action, unlike a JIT that (outside of the programmer's control) decides to compile some specialized code. Because of the overhead of running the compiler though, you'd definitely want the control of deciding whether a boxed closure generates new code or just calls existing code. &gt; Dynamic codegen could be done as part of a library, using a macro I don't follow -- macros are a facility for compile-time codegen. How are you going to use them for runtime codegen, using values only available at runtime?
To be clear, there are two issues. Big/little endian is the byte order. For the purposes of this RFC it is sufficient to just assume native endianness. Byte order is only an issue for communications or writing to disk, and it should be handled there (as this 'bitdata' is represented in memory as a native word/dword/etc anyway). MSB/LSB is 0 is the 'bit order' - whether we number the bits from the most significant or the least. Most communications protocols are 'MSB is 0', as the MSB is over the line first. Everything else is 'LSB is 0', counting from right to left.
On second thought though, the implication of a core language feature creating a dependency on the compiler seems like a non-starter. What's attractive about the idea though is that partial evaluation of a function is a really clean and elegant model for runtime codegen. It seems really difficult to offer a library-based dynamic codegen API that was even close to as easy to use. Unless maybe the library was capable of taking a closure (boxed or not) that was bound by-value and somehow combining the bound function and data into specialized code?
Cool, Looking forward to hearing\seeing more! Thanks
Thanks!
Yes, I'm on the Android frameworks team and work on fonts and text rendering.
Only one comment... https://www.destroyallsoftware.com/blog/2011/one-base-class-to-rule-them-all (Basically, don't use `base` as your root module, it has no semantics whatsoever)
Yeah, I've been considering moving that to the root. The original plan was to have the `base` module contain the lower-level bindings to TinyCDB, and then implement something like a `HashMap` on top of the low-level bindings. I'm not sure how useful that would be, though, so I might just move it to the top-level. Also, thanks for the doc fix :-)
Any time! You may just want to change `base` to `bindings` in that case, maybe?
I don't know the answer for sure, but with a complete procedure macro system a macro could take a block of Rust code as an argument, and generate whatever code is necessary to build multiple versions of that code at run-time. In principle, macros allow you to support any run-time feature you find in VM environments: reflection, runtime code generation, dynamic loading... but, I suppose, only inside the lexical scope of the macro.
I am pretty sure Rust already provides the rust scanner/parser as part of the Rust library. Clearly LLVM is provided as a library. One would just need to combine the two to generate some code, load it onto the heap, and then jump into it. This sounds like an afternoon project ;) In imagining a Rust REPL, this can get complicated quickly, as you need to keep the latest version of all of the symbols around (including the AST that generated them) as any function you have that depends upon them must be analyzed for type safety. Edit: http://doc.rust-lang.org/rustc/index.html for the docs for the rustc API 
I've seen (I think it's in the new git2 bindings) have a separate package (within the same repo) for the low-level bindings, then the base package becomes the high-level api.
Yay! It's back!
Thank you so much for this solution. The first one worked excellent for my purpose.
I vaguely recall that old-school Visual Basic let you specify enum members by just their name (like in C or Rust), but you could have multiple enum members with the same name since they were *technically* namespaced; the correct one was just inferred from context.^1 What I've thought I'd quite like to see in Rust is roughly the same behaviour: when you import an enum, it gets "exploded" into a set of weak names to the members. Weak names can be overloaded any number of times, and used without being qualified *provided* the type system is able to disambiguate them. For instance, this should work, since it's clear which `None` is valid: enum DamageSuffered { None, Some(int) } fn steamroller_roll_over(target: &amp;mut Person) -&gt; DamageSuffered { None } If it's not unambiguous, you have to specify which one you meant. This means that `None` and `Some` and `Err` and the like are no longer (effectively) globally clobbered and can be used in multiple contexts, where they are the words that make the most sense. Currently, ... well, imagine if field names in a structure could clobber those names in other, unrelated structures. That'd just be completely insane. I sure am glad no one is *that* crazy! &amp;#65279; --- 1: Sadly, I can't find a reference for this. I just remember being disappointed to find out one day that C# didn't have comparable behaviour. I *could* be mis-remembering this.
I didn't accommodate for enums storing involving None\Some\Err... i'm still 'transitioning' from C\C# and keep forgetting about these *which i shouldn't, i kinda like that feature*... The whole Inferring from context seems a bit scary, and potentially prone to error (Picking the wrong context *It could happen*) If i recall correctly if implemented like C++, with a bit of modifications you can actually get the best of both worlds you can do enum::name or just name. just name would be best when it's easy to infer context (if a parameter is asking for that enum as a type or match block ), and use the full namespace in areas where you want\need things to be more explicit or if you want them to be easier to understand from a human perspective with the added bonus of throwing an error if the compiler is unsure about inferring the value...
I found [this slide](http://manishearth.github.io/Presentations/Rust/#/6/3) really helpful to succinctly explain borrowing and references. Thanks!
Thanks for writing!
&gt; There are some simple patterns the compiler recognizes and adds lifetimes automatically Isn't it the definition of inference? Type inference is a separate mechanism, i agree. But lifetime elision is a kind of lifetime inference.
Thanks for this, I'm really glad you are continuing it.
&gt; And twelve is overkill. On the one hand, .net only defines [tuples up to 8 elements](http://msdn.microsoft.com/en-us/library/system.tuple\(v=vs.110\).aspx). On the other hand, the same defines [Action for up to 16 parameters](http://msdn.microsoft.com/en-us/library/dd402872\(v=vs.110\).aspx), Haskell implementations [must support tuples of size 15 at least](http://www.haskell.org/onlinereport/basic.html#basic-tuples) and GHC accepts tuples [up to size 61](http://www.haskell.org/ghc/docs/7.4.2/html/libraries/ghc-prim-0.2.0.0/GHC-Tuple.html)
cc. /u/pcwalton This stuff is way beyond me. :P
Seems familiar. [I'm trying to understand this myself](https://stackoverflow.com/questions/25365383/do-i-need-any-of-the-varianttype-markers).
Yeah, that's my answer you can see there :)
I thought Samsung was working on Rust precisely because of mobile devices?
Thanks! I wondered whether this reddit post was inspired by my SO question. :)
Ohh, rust looks sexier every time I come back to it.
I'm very, very sure that you need a special handling for `HANGUL SYLLABLE &lt;CHOSENG&gt;&lt;JUNGSEONG&gt;&lt;OPTIONAL JONGSEONG&gt;` and `CJK UNIFIED IDEOGRAPH-&lt;FOUR OR FIVE HEX DIGITS&gt;`. ;)
nice, thanks :)
Can you present a short example that illustrates the design/language problem?
I was looking into Artemis and didn't understand where the heavy lifting is. Yes, for each system it specifies components that it has access to, but in the end that doesn't affect the ergonomics. How is Artemis more powerful than my ECS?
This is the sort of proposal I've really been hoping to see for Rust! One thing I'd hope to see is for #[deriving(FromPrimitive)] to work with the new integer types (u4, i2, etc.) That would allow us to use enums for bitfields with very little broilerplate. I also agree with the comments on endianness; that's something that *must* be in this RFC for it to be useful for types &gt; 8 bits.
Extremely sorry for the formatting... I'm not sure why the code blocks aren't working I have a trait `BlasVector` and a struct that implements it `BlasVec`. The current implementation here isn't reusable for anything but `BlasVec`. ``` pub trait Norm&lt;T&gt; { fn abs_sum(&amp;self) -&gt; T; fn norm(&amp;self) -&gt; T; } macro_rules! norm_impl( ($t: ty, $rt: ty, $abs_sum_fn: ident, $norm_fn: ident) =&gt; ( impl Norm&lt;$rt&gt; for BlasVec&lt;$t&gt; { norm_fn!(abs_sum, $t, $rt, $abs_sum_fn) norm_fn!(norm, $t, $rt, $norm_fn) } ); ) ``` What is reusable isn't as coherent type-wise but can be used by any struct that implements the `BlasVector` trait, which is what I want. ``` macro_rules! norm_impl( ($trait_name: ident, $t: ty, $rt: ty, $abs_sum_fn: ident, $norm_fn: ident) =&gt; ( pub trait $trait_name: BlasVector&lt;$t&gt; { // default fn impl here } impl $trait_name for BlasVec&lt;$t&gt; {} ); ) ``` For each type $t, I have to have a different trait, but I get the impl for free. I would want the best of both worlds, sharing impl's without macros, and conforming to a single trait.
That is broken. But they enable something that many other languages lack: separate compilation and easy build paralelization.
&gt; The issue with this is that I have multiple traits (say NormS, NormD, NormC, NormZ) instead of a much more nicely typed Norm&lt;T&gt;. Does something like this helps? #[link(name = "blas")] extern { fn cblas_dnrm2(n: i32, x: *const f64, inc_x: i32) -&gt; f64; fn cblas_snrm2(n: i32, x: *const f32, inc_x: i32) -&gt; f32; } trait AsPtr&lt;T&gt; { fn as_ptr(&amp;self) -&gt; *const T; } trait Norm&lt;T&gt;: AsPtr&lt;T&gt; + Collection { // Once we get UFCS, this can become `blas_call()`, and ... fn blas_call(Option&lt;Self&gt;) -&gt; unsafe extern "C" fn(i32, *const T, i32) -&gt; T; fn norm(&amp;self) -&gt; T { unsafe { // this call can become `Self::blas_call()` - meanwhile use `Option&lt;Self&gt;` Norm::blas_call(None::&lt;Self&gt;)(self.len() as i32, self.as_ptr(), 1) } } } impl&lt;T&gt; AsPtr&lt;T&gt; for Vec&lt;T&gt; { fn as_ptr(&amp;self) -&gt; *const T { self.as_ptr() } } impl Norm&lt;f32&gt; for Vec&lt;f32&gt; { fn blas_call(_: Option&lt;Vec&lt;f32&gt;&gt;) -&gt; unsafe extern "C" fn(i32, *const f32, i32) -&gt; f32 { cblas_snrm2 } } impl Norm&lt;f64&gt; for Vec&lt;f64&gt; { fn blas_call(_: Option&lt;Vec&lt;f64&gt;&gt;) -&gt; unsafe extern "C" fn(i32, *const f64, i32) -&gt; f64 { cblas_dnrm2 } } fn main() { let v32 = vec!(3f32, 4.); let v64 = vec!(3f64, 4.); assert_eq!(v32.norm(), 5.); assert_eq!(v64.norm(), 5.); } Sadly, the user of `Norm&lt;T&gt;` has to explictly select the blas call for its struct, but the type safety should reduce the chance of her choosing the wrong blas call. I don't know if this idea can be scaled to work with the more complicated blas calls.
(Sorry for replying and quoting myself :P) &gt; Sadly, the user of Norm&lt;T&gt; has to **explictly select the blas call** for its struct, but the type safety should reduce the chance of her choosing the wrong blas call. I just figured out a way to circumvent this problem: #[link(name = "blas")] extern { fn cblas_dnrm2(n: i32, x: *const f64, inc_x: i32) -&gt; f64; fn cblas_snrm2(n: i32, x: *const f32, inc_x: i32) -&gt; f32; } trait AsPtr&lt;T&gt; { fn as_ptr(&amp;self) -&gt; *const T; } trait Nrm2 { fn blas_call(Option&lt;Self&gt;) -&gt; unsafe extern "C" fn(i32, *const Self, i32) -&gt; Self; } impl Nrm2 for f32 { fn blas_call(_: Option&lt;f32&gt;) -&gt; unsafe extern "C" fn(i32, *const f32, i32) -&gt; f32 { cblas_snrm2 } } impl Nrm2 for f64 { fn blas_call(_: Option&lt;f64&gt;) -&gt; unsafe extern "C" fn(i32, *const f64, i32) -&gt; f64 { cblas_dnrm2 } } trait Norm&lt;T: Nrm2&gt;: AsPtr&lt;T&gt; + Collection { fn norm(&amp;self) -&gt; T { unsafe { Nrm2::blas_call(None::&lt;T&gt;)(self.len() as i32, self.as_ptr(), 1) } } } impl&lt;T&gt; AsPtr&lt;T&gt; for Vec&lt;T&gt; { fn as_ptr(&amp;self) -&gt; *const T { self.as_ptr() } } impl Norm&lt;f32&gt; for Vec&lt;f32&gt; {} impl Norm&lt;f64&gt; for Vec&lt;f64&gt; {} fn main() { let v32 = vec!(3f32, 4.); let v64 = vec!(3f64, 4.); assert_eq!(v32.norm(), 5.); assert_eq!(v64.norm(), 5.); }
Reddit doesn't use Markdown for code, you need to indent code by four spaces instead. See the "formatting help" link below the input.
Wait, what? That makes the default semantics completely different from most common languages with closures. Why is that a good idea? Also, why are closure *arguments* still by pointer? Based on the behavior of other languages, I'd expect the example in the message to work like this: let mut a = 10; [ 1i, 2, 3 ].iter().map(|x| a += x); Why not have x be an immutable reference? In fact, why does that array thing not have a map method itself?
Oh... whoops. Thanks for [writing](https://github.com/huonw/unicode_names/pull/3) the code.
Yes ([e.g.](https://github.com/huonw/unicode_names/issues/1)), but a large flat map was simplest to implement; this was written in a few hours after an IRC discussion about `\N{...}` named literals in Python. Progressive improvements! :)
Capture-by-variable is strictly more flexible than capture-by-reference (capture by reference is literally just capturing a reference); the `ref |...| ...` syntax is just sugar that captures references to the variables, rather than variables themselves.
I'm from GTA, willing to visit the meetup anywhere in Ontario. Can give a ride to 2-3 more people, if needed.
Though I'm not in Ontario anymore, a few remarks: - There's a Mozilla Toronto office, though I don't think any Rust people are there. Maybe could swing some space. - There are Rust people at uWaterloo, and they'd be able to work with the computer science club there to host an event. I might attend an event in Toronto or Waterloo if the timing worked out (which it probably won't for the next little while :P)
I'm in Austin, depending on dates might or might not be able to make it. Note that for international travellers, Kingston is -extremely- expensive to fly to. Ottawa and Toronto are much cheaper.
&gt; That makes the default semantics completely different from most common languages with closures How many other languages have closures and the possibility for by-value capture? I only know of C++, and that doesn't have a default: at the minimum, you have to choose `=` or `&amp;` if you capture anything (AFAIK). &gt; Also, why are closure arguments still by pointer? They are only by pointer when they're meant to be by pointer, `[].iter()` yields references into the slice, and thus references get passed into the closure in `map`. &gt; Why not have x be an immutable reference? Err, it is a `&amp;`? &gt; In fact, why does that array thing not have a map method itself? Iterators are more efficient and more flexible.
&gt; That makes the default semantics completely different from most common languages with closures. Why is that a good idea? References are first-class values in Rust and this is how the rest of the language is designed. C++ closures also default to capturing by value, so I think you're off the mark with your claim about other languages. Rust is a systems language, and the decisions that make sense at a low-level are not comparable to a garbage collected language. A closure with a by-reference capture can never be returned. &gt; Also, why are closure arguments still by pointer? Closure arguments are not by pointer, they're by-value just like all normal function parameters. Rust doesn't have any concept of by-reference passing, it passes references as normal values.
&gt; That makes the default semantics completely different from most common languages with closures. Why is that a good idea? Because Rust has manual memory management, and does not promote captures to the heap implicitly. &gt; Also, why are closure arguments still by pointer? Closure arguments in general are not by pointer. That *particular* argument simply has a pointer type. &gt; Why not have x be an immutable reference? `x` is an immutable reference. That's why I wrote `*x` in my message. &gt; In fact, why does that array thing not have a map method itself? Because we don't have an `Iterable` trait (as would need some language features we don't have). Therefore you need to use `.iter()` to get an iterator.
Oh well, that's a pretty good point against Kingston.
They will be strictly by-value. By-reference is simply capturing a reference. &gt; Also, is there an RFC with the semantics of by-value capture? [This is the relevant RFC](https://github.com/rust-lang/rfcs/blob/96fe95c27bed1cef52e9795fbd4c6ce20cbfa476/active/0044-closures.md). It's pretty simple though: the environment (captured variables) form a struct with a field for each variable, e.g. let x = 1i; let y = "foo".to_string(); let z = &amp;mut 2u; let f = |a: &amp;str| -&gt; f32 { /* use x, y, z */ } becomes (automatically) struct UniqueName_1234&lt;'a&gt; { x: int, y: String, z: &amp;'a mut uint } impl FnMut&lt;(&amp;str,), f32&gt; for UniqueName_1234 { fn call_mut(&amp;mut self, (a,): (&amp;str,)) -&gt; f32 { /* use self.x, self.y, self.z */ } } let f = UniqueName_1234 { x: x, y: y, z: z }; and any calls of `f` call `call_mut`. This means the closures get the built-in bounds like `Send` and `Sync` etc. just like normal structs (based on their captures: i.e. a closure that only captures `Send` variables will be `Send` itself). &gt; When is the cost of copying a mutable value paid? (Or is that even valid.) When the closure expression is evaluated (indeed that is the only evaluation that happens), since that is when the environment is constructed. *Any* by-value use of a value in Rust is a shallow byte-copy, including closure captures. The captures are just byte-copied into the closure environment struct (modulo optimisations removing it). &gt; If a copy has to be made from a mutable variable, then the copy has to be a deep copy, is that correct? No, shallow byte copy always. &gt; Where is the storage for that copy (heap-allocated?) All captures are stored inline in the environment struct, which can be placed anywhere, e.g. `f` above is on the stack, but `box f` would be (uniquely owned) on the heap, `Arc::new(|...| ...)` would be in a threadsafe shared variable (it would have `Send` &amp; `Sync` restrictions in this context). &gt; How are lifetimes handled with closures and tasks? Closures used to spawn tasks via `std::task::spawn` will require that the closure is `'static` just like we have with `proc` today (i.e. not capturing any values with limited lifetimes).
I am in Waterloo and would love to attent a meetup.
&gt; Are closures then strictly by-value or by-reference now? i.e.: one cannot mix and match closure references. They are strictly by-value or by-reference, but in effect you can mix and match by simply creating references manually and capturing those references by value along with your other captured values. &gt; When is the cost of copying a mutable value paid? (Or is that even valid.) At the time of closure construction. &gt; If a copy has to be made from a mutable variable, then the copy has to be a deep copy, is that correct? No, it counts as a move. &gt; Where is the storage for that copy (heap-allocated?) Inside the closure, by value. It is not necessarily heap-allocated. &gt; How are lifetimes handled with closures and tasks? Closures can have lifetime parameters, depending on their by-reference or by-value-ness.
Note that they might still be presenting something at Carleton itself, so flying into Ottawa first to meet up with me and head down together wouldn't be off the table.
Is proc gone or deprecated? I hope it's gone. 
It will disappear, with a direct replacement in the form of the trait object `Box&lt;FnOnce&lt;(Args...), Ret&gt;&gt; == Box&lt;|: Args...| -&gt; Ret&gt;`, but I imagine many users would prefer just taking a generic, meaning static dispatch and no allocations (unlike `proc` now).
It actually *does* use Markdown for code -- the triple-backquote is part of Github-flavored Markdown (which has become so pervasive lately it's often confused for normal Markdown).
So proc () {} will become |:| {} ? How it differs from the capture by value variant? 
Fixing code formatting until he fixes his. See other Sinistersnare()'s and other's comments for how to fix it. 1st block: pub trait Norm&lt;T&gt; { fn abs_sum(&amp;self) -&gt; T; fn norm(&amp;self) -&gt; T; } macro_rules! norm_impl( ($t: ty, $rt: ty, $abs_sum_fn: ident, $norm_fn: ident) =&gt; ( impl Norm&lt;$rt&gt; for BlasVec&lt;$t&gt; { norm_fn!(abs_sum, $t, $rt, $abs_sum_fn) norm_fn!(norm, $t, $rt, $norm_fn) } ); ) 2nd: macro_rules! norm_impl( ($trait_name: ident, $t: ty, $rt: ty, $abs_sum_fn: ident, $norm_fn: ident) =&gt; ( pub trait $trait_name: BlasVector&lt;$t&gt; { // default fn impl here } impl $trait_name for BlasVec&lt;$t&gt; {} ); )
FWIW, the formatting of impl &lt;T&gt;Vector2&lt;T&gt; { is a little misleading (it makes it look like you're implementing for some mysterious type `&lt;T&gt;Vector2&lt;T&gt;`). The conventional formatting is impl&lt;T&gt; Vector2&lt;T&gt; { i.e. declare the generic parameter `T`, and then implementing for `Vector2&lt;T&gt;`. &gt; I know that this has already been discussed about in this topic but I just want to know whether the current situation is going to change or not. There will always a heap-allocated, data-owning string type and a reference "string view" type (currently `String` and `str` respectively); but it's hard to find good names.
Are there any plans to remove the need to declare type parameters when no restrictions are placed on them? For example in haskell you can write foo :: a -&gt; b -&gt; a and only when you need some constraint do you need to write bar :: Ord a =&gt; a -&gt; b -&gt; a 
Newbie here: can you capture with a mix of ref and value? `(|x, ref y| ...)`? Or does that not make sense?
The stuff in the `|...|` are just the closure's arguments, not captured variables. What you have written is just "pattern-matching" the `y` argument by taking a reference to it, it's equivalent to writing `|x, tmp| { let y = &amp;tmp; ... }`.
Moving ownership is a shallow byte copy (modulo optimisations eliminating the memory movement), where further access to the source is statically disallowed. (Any by-value use is a byte copy, and for some types this has to move ownership to ensure correctness.) [More info](http://stackoverflow.com/a/24253573/1256624).
I live in Ottawa, not too far away from Carleton Univeristy (2 OTrain stops away + a 15 minute slow walk away). I'd gladly let someone sleep on my couch. Going to Toronto would be fine. I may be able to convince my parents to allow a few people to sleep over, but it would be a 1 hour commute as they live in Mississauga.
Is the final end-goal to have an Iterable trait that is then implemented for slices, Vec etc so that there's no need to call iter() first? That would be really nice for usability. Which missing pieces are prerequisites for that?
I *believe* HKT, but maybe some others can chime in. I don't recall offhand what was necessary.
This is madness inducing. It makes no sense... The text is appended to the document with `style="display:none"`, but somehow it's getting stripped to `style=""`... /u/dbaupp can I hijack this thread to do some debugging and ask if you did anything custom to your rustdoc build? I just noticed that line 779 of main.js has a typo, I'm hoping that's causing it (somehow). + "&amp;nbsp;Expand&amp;nbsp;description&lt;/span&gt;&lt;/a&gt;") should be + "&amp;nbsp;Expand&amp;nbsp;description&lt;/span&gt;") (closing `&lt;a&gt;` tag removed). Can you try removing that in the static file in your build of rustdoc, see if that fixes it?
It's [just a `cargo doc`](https://github.com/huonw/unicode_names/blob/c6e9b6deda2eb773554229f737dab15e6c1542ed/.travis.yml#L7); this seems to be a problem with all Rust CI docs: - http://rust-ci.org/bjz/cgmath-rs/doc/cgmath/ - http://rust-ci.org/GuillaumeGomez/rust-GSL/doc/rgsl/ - http://rust-ci.org/cgaebel/graph/doc/graph/ - http://rust-ci.org/cacteye/noise/doc/noise/ etc. (I can't test for several hours, but this should be easy enough to reproduce... I imagine running `rustdoc` on `//! Foo` will see it.) I looked over that before; I was thinking that should use more jQuery for building the DOM, rather than just manual string construction.
Hmm, I just build one of my local projects with the latest cargo nightly and a fairly recent rust nightly, and it's not reproducing.
Sorry it's a bit late, but i had a question, because this looks like it just interprets a number - I'm curious how would you do read byte arrays to a struct? (Like how in C you can do an fread and send it to a pointer of a variable with type of struct and it would magically fit), or do you manually to do read_&lt;endian&gt;_&lt;type&gt; for each thing in your struct? 
I work from the Toronto office.
I don't think so, but I am not 100% on top of all the RFCs going around right now
I'm surprised this is so difficult in Rust, seeing how Scala saw fit to promote this to syntax. There's probably something different about Rust's domain that I just don't understand though. I do kind of wish that trait bounds were joined with '|' or something instead of '+', to leave '+' and '-' for co/contra-variance in the future if it's ever decided that it's worth having.
HKT isn't going to be in 1.0, right? I can't see how you guys would manage to squeeze it in while pushing out 1.0 before the end of the year (which I think is the current ETA). I already don't think that deadline will be met; I'd love to be proven wrong, although I'd love it even more if Rust took its time and went out the 1.0 gate fully ready.
Offtopic (I guess), but that page hits me in the nostalgia. I haven't seen a pisg stats page for years. I remember running one for a fairly popular room over a decade ago now, hosted on my home machine and pointed to by a free noIP.com DNS record. I've watched as irc channels I used to enjoy turn to shit and entire servers disappear, but I'm happy irc is still in heavy usage for developer-to-developer discussion.
Watch the network tab and click the .webm video. It'll open the bog standard HTML5 video player, which has a right-click to save target.
I tried to find more information about this but failed. Is there some issue/rfc/discussion available?
HKT is not 1.0, but library stabilization is not 1.0 either, so HKT could still be added and they would change the APIs again to support it. I don't necessarily agree with 1.0 not including library stability, but thats the plan
Do you really need two github repos for this? Can't cargo pick up the macro crate from the original repo somehow? **EDIT**: nevermind... I'm guessing the docs are wrong?
Wrong subreddit, you need /r/playrust.
You're looking for /r/playrust I definitely recommend starting Rust (the programming language) though. It's also free.
I couldn't stress this enough.
&gt; C++ closures also default to capturing by value Arguably, C++ lambda functions default to capturing *nothing* (eg, for the simplest closure: `[]{}`). You must specify `[=]` to capture by value or `[&amp;]` to capture by reference. I wonder if this is a safer default, since it requires you to explicitly state that you want to capture variables at all.
I guess it's a good sign that "thanks" is in the list of the most used words. :)
 In C++, it's easy to capture a reference or a value containing one and then have it become dangling. Rust will just point out that a lifetime isn't long enough at compile-time, so safety doesn't really come into it. You can't get a dangling pointer in normal safe code.
Ah, apologies, I didn't mean memory safety, I meant programmer safety. For example, unintentionally referencing a variable from the enclosing scope: let yy = 10; // later... let square = |y| y * yy; // Oops, should have been y * y Obviously it's a silly toy example, but it illustrates what I'm getting at. If `yy` wasn't captured by default, it would have been an unresolved name error. I'm not saying Rust needs to adopt this, by the way, just pointing out one possible benefit of C++'s choice.
Dang, just missed out on getting in the top #25! :3 Shame he doesn't track #rust-gamedev - I would be interested to see the results.
&gt; Iterators are more efficient and more flexible. Eh? How can a.iter().map() be more efficient than a.map()?
this look similar to c++ lambdas :) Can you also capture by move? Or how do you capture by value non-copyable objects?
nice! Am I right in thinking that this opens the way to returning closures from functions more easily? e.g. (real example from https://github.com/Hoverbear/rust-rosetta/blob/master/src/roots_of_unity.rs) type RootsIterator&lt;'a&gt; = Map&lt;'a, uint, Complex32, Range&lt;uint&gt;&gt;; fn roots_of_unity&lt;'a&gt;(degree: uint) -&gt; RootsIterator&lt;'a&gt; { // today this does not compile! // the closure captures "degree" by reference, so the closure's // lifetime can't leave the enclosing function. // if degree is copied by value this should work range(0, degree).map(|el| Complex::&lt;f32&gt;::from_polar(&amp;1f32, &amp;(2. * consts::PI * (el as f32) / (degree as f32)))) } sorry I could have simplified, but I wanted to make a real example of when this should be a great improvement
I was surprised myself. I seem to have spoken more than many other people - not something I am proud of, those stats point to mental issues IMO.
What type are you thinking `a.map()` would return? A `Vec`?
Capturing by value is capturing by move.
Oh, of course. That was silly of me. But the question still stands - is it possible to mix capture? I'm thinking along the lines of C++'s lambda [capture specification](http://en.cppreference.com/w/cpp/language/lambda#Lambda_capture).
Its still possible to manually capture by reference with a by-value closure
With a by value closure you have the option of manually capturing a reference directly, which allows you to mix it like that
I'm not expert so these things are fairly minor, someone better than me will be able to give some more general feedback: * output.slice(0, output.len()) should be output.as_slice() * You don't need the braces around b'+', b'/' etc. * function names usually are snake_case What problem were you having with returning a string exactly? Did you try it and get a compilation error that you didn't understand?
Got it, thanks!
Yes, I think he's precisely referring to that. By converting it to an iterable you lose information, the compiler might be able to recover this, but it's messy. This `map` is also not general, in that you can't apply it to non-sequential lists. A trie, a quadtree, and so on will not behave well under conversion to an iterable, application of map, and reconstruction. (As the iterable will 'forget' the shape of the input.)
I still think it might make more sense to throw ref inside the `| ... |` instead of outside. I understand you can mix and match by creating arbitrarily complex closures or some boilerplate above, but putting ref inside seems like it makes more sense because you can apply it per-variable. `| ref x, y, ... | ` at that point, it might even make sense to use the `&amp;` notation, but I'm not sure.
I was getting outlives the scope error, not sure how to determine lifetime inside the function
Except the things inside the `|...|` have nothing todo with the captures. A expression like `ref |x| w = x + 10` captures `w` by reference, and assigns to it the value of the regular by-value parameter `x` plus `10`.
You have to return an owned String (String type). So you create it inside your function and move it out on return. 
Iterators and thus this `map` cover the "external iteration" case, for which there will always be uses. `map`ping to a `Vec` directly is slow and non-composable; e.g. if you are immediately summing the return values of the map, it's pointless and slow to create the intermediate allocation. The "structure remembering" map you describe is `fmap` from Haskell; it is definitely useful too, but it's not what `Iterator` and `.map` are trying to do. (Changing the `.map` in question would be a little like defining the word "apple" to mean banana, i.e. completely pointless because there would still have to be some way to talk about apples, just like we'd still have to have a way to do lazy sequence mapping even if it's not called `map`.)
Yes, you can mix captures; capture some variables directly and others by capturing a reference.
`|ref x, y|` is just a closure taking two arguments `x` and `y` (where `x` has a `&amp;` taken to it, immediately inside the closure body), nothing to do with any capturing.
Thanks! I end up using a modified version of this (actually calling the function by adding the vector as a parameter) to avoid extra typing on the traits.
Oddly enough, I wrote some code to do the same thing a day or two ago. Mine doesn't correctly handle endings though. pub fn bytes2b64(input: Vec&lt;u8&gt;) -&gt; Vec&lt;u8&gt; { let mut res = Vec::new(); let mut b64: u8 = 0; for (ix, &amp;v) in input.iter().enumerate() { if ix % 3 == 0 { res.push(v &gt;&gt; 2); b64 = (v &amp; 3) &lt;&lt; 4; } else if ix % 3 == 1 { res.push(b64 | (v &gt;&gt; 4)); b64 = (v &amp; 0xf) &lt;&lt; 2; } else { res.push(b64 | v &gt;&gt; 6); res.push(v &amp; 0x3f) } } //if leftover bytes, handle somehow... res } 
One valuable thing I've learned from these stats is how often rust-phf seems to be used. It makes sense in retrospect: it's basically the answer to "how do I create a constant hash table"...
Please keep on working on it! Some of us find it really useful! ;)
It's seems your problem same as this: http://www.reddit.com/r/rust/comments/2dmcxs/new_to_rust_trying_to_figure_out_lifetimes/
Correct, but without anonymous return types that can only be implemented by erasing the generated type, eg by boxing the closure on the heap to get a Box&lt;Fn&lt;(uint,), uint&gt;&gt;. The issue is that your function needs to know something to pass as a type to the `Map` type once it is changed to work with unboxed closures. With the boxed closures right now it works only if you capture nothing in it, which is equivalent to returning a &amp;'static EmptyEnv that implements your closure body.
I was _so ready_ to downvote + "/r/playrust"
This is pretty amazing! The readme doesn't say much though, is the point of this to be a proof of concept, an alternate MC client, or something altogether different?
Ok. I don't think you want to return a slice from Encode. By doing output.as_slice() or output.slice() you're creating a reference to output. The problem is that Rust will get rid of output when Encode ends and so your reference will be invalid. The solution to this is just to return output itself. arthurprs is suggesting using String which is a bit like a Vec but only for characters.
Also, check out the Rust gamedev subreddit http://www.reddit.com/r/rust_gamedev/
Oh ok. I tried doing box of str and it still complained. I didn't realize str was view. Tried with vec and it works, thanks. Now I'm curios how it did &gt;By doing output.as_slice() or output.slice() you're creating a reference to output. The problem is that Rust will get rid of output when Encode ends and so your reference will be invalid. - Why does slice on output get invalidated when output can live past the function call lifetime? - Is vec always heap allocated? Then where does it get freed? 
/u/hailmattyhall suggested the same too. Thanks, I made the change
Does the hematite project include a rust based server? I've poked around minecraft servers, and frankly their code is honestly terrifying. 
You can have multiple references to a heap-allocated structure, but a single "strong reference" (a single owner), when other things want a strong reference (not just a reference), you copy it (and keep your version) or you move it (and lose your version). Here you don't need the string afterwards, so you can just move it.
&gt; Why does slice on output get invalidated when output can live past the function call lifetime? `output` can't live past the function scope unless you move it. &gt; Is vec always heap allocated? Then where does it get freed? vec is always heap allocated, it gets freed when it's got no owner anymore (a vec can only have a single owner). In this case, the lifetime of `output` is from the start to the end of the function, it's automatically deallocated when the function ends since it doesn't escape the function.
&gt; swgillespie seems to be sad at the moment: 5.8% lines contained sad faces. :( I didn't realize I was that sad :(
&gt;Output can't live past the function call lifetime unless you move it. By that do you mean, return from the function?
There is no server in Hematite.
In this case I think that's correct. I'm sure the person you're relying to will correct me if not. This is quite a good resource http://rustbyexample.com/move.html
Correct, unless you work in `unsafe` and use `push_bytes`. But since u8s are generated one at a time, you can just use `as char` on them, e.g. change `base_index` to return `char` (and probably rename it as well) and cast the `match`'s result to a char fn base_index(index: u8) -&gt; char { (match index { 62 =&gt; b'+', 63 =&gt; b'/', 0..25 =&gt; b'A' + index, 26..51 =&gt; b'a' + index - 26, _ =&gt; b'0' + index - 52 }) as char } 
A tip: change `Vec&lt;&amp;mut Update&gt;` to `Vec&lt;Box&lt;Update&gt;&gt;`.
Wanna run me through why?
The `ref` keyword already existed for by-reference patterns, so it's not actually new.
1. Creating NPC/Character objects on the stack, then casting them to `&amp;mut Update` which is then pushed onto a vector isn't scalable. 2. You cannot easily create NPC/Character objects dynamically, when generating a dungeon level for example. Who is going to own the original object? With `Vec&lt;Box&lt;Update&gt;&gt;`, the Vec becomes the owner, and all these problems go away. The `fn update(objs: &amp;Vec&lt;&amp;mut Updates&gt;, ... ` function should also take a `&amp;mut[Box&lt;Update&gt;]` (read: mutable slice) to do its work. 
Minor change, works like a charm. struct Node { data: i32, next: Option&lt;Box&lt;Node&gt;&gt; } fn print&lt;'a&gt;(node:&amp;'a Node){ let mut temp = Some(node); loop { match temp { None =&gt; { println!("Empty node pointer"); break; } Some(i) =&gt; { println!("Some node, with {}", i.data); match i.next { Some(ref y) =&gt; { temp = Some(&amp;**y); // &lt;---- Help here } _ =&gt; {break;} } } } } } fn main() { let node = Node{ data: 0, next: Some(box Node{ data: 1, next: Some(box Node{ data: 3, next: None }) }) }; print(&amp;node) }
Using `box ref` is much cleaner indeed, nice find.
Awesome! That makes total sense, and I was curious about how I was gonna generate them dynamically. Thanks for the explanation [=
Oh, cool. I used libtcod with Python back when I was in high school. Revisiting it with Rust and a few years' experience under my belt sounds quite fun.
All 3, pretty much. I blame /u/long_void for posting this in two separate subreddits (see /r/rust_gamedev) when it was meant as a teaser for IRC :P.
In general I've felt that newtyping an int (wrapping it in a tuple struct) is the best way to go here. Add some methods to ensure that you can't easily extract the raw value without checking the error.
`Result&lt;u31, u31&gt;` seems unlikely to happen because after every write to a `u31` you'd have to check that you didn't just set the other bit.
IIRC they are just re-exports of the types for consistency.
Parts of core are re-exported in `std`, that's a lot of it. That said, it is confusing.
I agree that it is confusing. The rationale should be explained somewhere in the documentation. (It would also be nice to have a short 'how to read the documentation'. Because of traits, browsing Rust documentation is different compared to most programming languages.)
Haha well I think it is a really cool project. I was actually thinking about doing something like this the other day as I don't like java very much and wondered how MC would perform if written in C/++ or Rust. Glad to see someone else has already thought of it as I wouldn't know where to start. Are you guys looking for any additional help?
Man this is incredible! Don't worry about the lack of comments or points - no one just understands in full what you did there (not claiming I do either). May I wonder, what do you need convex decomposition for?
I was in the first offering of this course in Fall 2013. While I have a much better appreciation for Rust now, trying to learn a new language that is changing rapidly while simultaneously trying to meet your project deadline is incredibly frustrating.
...is C++ trembling in its boots?
Yeah. I wouldn't have wanted to do it around the 0.7 time either. Now? Maybe. In a year? Definitely.
Have a look at [Craft](https://github.com/fogleman/Craft). It's written in very clean C. There are binaries on the [main site](http://www.michaelfogleman.com/craft/). It's so damn smooth compared to minecraft. I get over 500fps in it.
I took this class during the spring semester as an open student (while enrolled at a different college full-time). It was a great experience - the professor posted videos of all of his lectures, and after completing the first two projects on my own I earned credibility to work with UVa students remotely on the subsequent ones. For me it was a really great way to learn Rust and gain a fundamental understanding of operating systems (which were my two main goals, at the time). I will say that using Rust on a deadline during the 0.8-0.9 releases was pretty rough. But at this point it's one of my favorite programming languages. The only real bad thing about the class is that none of my assignments compile any more. Keeping them updated while doing a full course workload + having a job wouldn't be fun. One of the great things about a Rust stable release is that universities who adopt it will be able to produce assignments that don't bitrot in a matter of weeks :D
The C++ subreddit apparently talks about Rust an awful lot (more than any other language and more than many others put together), and since Rust is aimed at replacing many of the tasks C++ is used for, it made me wonder if the C++ community is really beginning to think about Rust seriously.
Can't LLVM optimize away those checks? edit: well I have no idea *how*, but I think/hope that it's possible for the compiler to statically guarantee safety.
I also have this problem (from Australia). Even with a 1 gbps connection.
You got that backwards-- Rust is the one talking a lot about Cpp. &gt; The widths on each end is determined by the relative frequency of the mentionee being referenced by the respective other community. So PHP talks more about SQL than SQL talks about PHP.
I wish instead they'd implement Minetest. Minetest uses Lua to define all the internal game mechanics, which are loaded at runtime, so it's really easy to mod and change the game. It's also pretty generic and designed to be used as a game engine, so many parts of the world are exposed for modding/interfacing with Lua.
The issues tagged [E-mentored](https://github.com/rust-lang/rust/labels/E-mentored) are similarly useful.
I filed a bug [here](https://github.com/rust-lang/rust/issues/16645) for it so the idea doesn't get lost.
*Please note that I am not trying to bash anything*, but even other clones written in Java vastly outperform Minecraft.
minecraft from 3 years ago vastly outperforms minecraft today :p the problem with mc is more the sheer amount of stuff calculated every tick, which hematite + most other minecraft clones don't have issues with since they just implement some subset of creative mode. 
Now, I'm not all that experienced with Rust, but it seems to me that the idiomatic way to represent the result of `fork()` is with an enum: enum Result { Pid(int), Child, Error } Then you would run it as: match fork() { Pid(p) =&gt; println!("In the parent, child is {}", p), Child =&gt; println!("In the child"), Error =&gt; println!("Error, check errno for more info") } Or even breaking out the different error cases into that enum, so you could handle them all separately. Now, sure, that's going to be less storage efficient than a single 32 bit integer. But this is `fork()` we're talking about; it's quite expensive as is. Using another few bytes to represent the tag on the enum is tiny compared to the expense of the fork operation itself. And sure, if you were storing lots of these values long-term, you might be concerned about the expense, but generally you just handle the error and forget about it, only storing the extracted PID long term if it succeeded. If you did want to hyper-optimize a tagged integer just a bit less wide than one of the standard int types, pcwalton's suggestion of newtyping an int and adding some accessor methods that were safe seems reasonable. But I think that the enum above is the more idiomatic and quicker to impelement solution.
Not OP and not too experienced in this, but let me try to answer. Complex geometry, as might appear in a game, can be concave. Eg, see OP's video demo for examples of concave objects. But this concave geometry is hard to do certain operations on. Most notably, collision detection doesn't not work well with concave geometry, many efficient algorithms require convex geometry in order to work at all (eg [GJK](http://en.wikipedia.org/wiki/Gilbert%E2%80%93Johnson%E2%80%93Keerthi_distance_algorithm)). So, convex decomposition allows one to have concave geometry, but then automatically divide concave objects into reasonable sets of convex objects. Similar to fitting a surface with triangles I guess, but in 3d. Then, the concave objects can be used for purposes of collision detection.
Doesn't sound right. Shouldn't most of that stuff be calculated on the server?
I subscribe to /r/minecraft, /r/rust, and /r/playrust, so I was *really confused*.
And please let me know if there's something that makes it unsafe. I've done a lot of testing to make sure that everything deallocates once and only once, but there may be an obscure edge case I missed. Most of the code was hacked together from bits of Rc and RefCell. If there's a more efficient way to do this I would also like to know.
And [Convex Set](https://en.wikipedia.org/wiki/Convex_set) shows well (look at the two first images) what the convex property means.
I really wish they would just put them on youtube :(
That's not the whole story. I ran minecraft through apitrace yesterday and the amount of *immediate* draw calls is ridiculous. They can (and will) get better, but it's so much cruft they have to throw out.
Thank you, there is so much nice things going on with rust.
Can I get anyone's opinion on whether this, or an abstraction like it, belongs in Rust itself? I think it solves many of the problems with today's error types, but I'm unsure if it's too much to be used everywhere.
&gt; Or even breaking out the different error cases into that enum, so you could handle them all separately. The errno can probably either be "unpacked" into the structure or (better I think) provided as a value to Error, so you'd have enum ForkResult { Pid(int), Child, Error(int), } could even have `Error(Errno)` where `Errno` would be an enum for symbolic errno names. This does incur a slight additional overhead in case of error since the `fork()` wrapper will be calling `errno()` every time, but as you note the overhead is likely irrelevant in the face of `fork()`'s own overhead.
As I understand, THE CORRECT WAY is what is written in README.md, "Building on Windows".
Damnit, I missed half of that. In my defense, I also saw instructions saying to install MSYS, MinGW and MinGW-w64 from MinGW-builds (which doesn't seem to *have* MinGW-w64, but something marked as i686-w64 which what even is that?) I think I got frustrated since I already *had* MSYS; it was just gcc that didn't seem to want to play ball. Also, I really didn't want to have two installs of MinGW on the same machine, since I've been down a similar road before and am still having nightmares from it. I read vague warnings from somewhere that the MinGW that can be installed from within MSYS2 *should not* be used *outside* the MSYS2 shell (paths getting screwed up), so I didn't want to risk it. Also also, I *despise* batch shells. Even damn toolchain wants its own specially-configured shell, and half the time they can't be used safely together. *sigh* The only thing worse than wasting hours downloading, installing and configuring three different versions of two dev environments is finding out you were looking at the wrong instructions.
Even with all of the optimizations coming in the 1.8 updates? They're basically multi-threading everything. Would be cool to have some kind of proper comparison.
Short answer: I use an approximate convex decomposition to simulate dynamic concave objects on nphysics, and to compute their mass properties (volume, inertia tensor, and center of mass). Long answer: if you take two disjoint convex objects, and try to figure out the set of pair of closest points, you should see that there is either one such pair, or an infinity (i-e, you cannot find only two, four, ten, etc. pair of closest points). In other words, the function that computes the distance between every pair of point is (non-strictly) convex. This property makes it possible to write very efficient algorithms for collision detection, such as the GJK pointed out by /u/ehsanul (which is implemented on ncollide). Also, if two general concave objects (triangle meshes) are penetrating, there is no efficient algorithm to compute their penetration depth. A convex decomposition makes this kind of information affordable in real-time (which is essential for video games as real time physics engines are usually unable to prevent interpenetration). Usually, I believe that in real-life this kind of decomposition is made by the designer. However automatizing this process is very useful for prototyping or helping the designer. Also, there are other uses of convex decomposition but I do not know all of them. For example, it can be used for automatic skeleton extraction, which is useful for animation.
The language changes a lot between releases, and the standard library is not super polished yet.
I had no problem building with msys2 on 64bit as recently as last week. It was simply a case of installing msys2, opening the mingw64 shell, updating to the newest version of packages, installing the pre-reqs and doing ./configure --build=x86_64-w64-mingw32 --disable-llvm-assertions make &amp;&amp; make check The second configure flag was because of llvm missing a header file somewhere on x86_64. Vadim did a really good job, and a massive amount of work getting 64bit up and running and I juggled a couple of headers in the rust rt c file to make it work with msys2.
Hmm. I ended up getting a compile error somewhere in the runtime with a message stating that 64-bit wasn't supported. Maybe the gcc I ended up with is compiled in a way such that it doesn't work. Or I've messed something else up. Admittedly, I didn't try all that hard to get a 64-bit build going; I was under the impression that it was still not quite ready yet (no 64-bit Windows build on the website last I checked). If it *is* working, that's fantastic news.
(requires a Burrows Wheeler transform decoder) `ndgd...eddg''ehtanremIe'deraouoyatslnsIegef,k.attb I ogsr' $ e ' enh c' uennndllai ooesshrkhdtds tdmhuttbo nnnn cttttts l sdorh'nniauu A'ae aai eaaiiiiuiittscc gfyhw'mntoeeatestea ulee esiuust ussepomgoo ppo t `
What shell did you use? I got errors when I was trying to use the msys2-shell, but the mingw64 one worked.
Cool. By the few articles I have read about the language, it seems pretty exciting. 
`msys2_shell.bat`. I couldn't find any explanation as to what the other ones did. I assumed that they futzed with the path somehow to add the `mingw{32,64}` subdirectories or something. *goes and diffs them* Seriously, what does `MSYSTEM` even do? *ddgs, gives up, googles instead* Son of a... *headache gets worse* So basically, you have to build rust from within MSYS, but it needs MSYS to be configured to pretend it's not MSYS. *cries*
Yep, that sounds pretty reasonable too.
https://github.com/eightbitraptor/bwt-rust/pull/1
I would have thought they would fix at a specific version for the course duration
I'd recommend to use [netvl/rust-xml](https://github.com/netvl/rust-xml/). I originally cobbled sax-rs together for use with gl-rs, but we have since switched to using rust-xml.
I had similar results, compiled fine for me. Then i built Racer, and couldn't get it to integrate with Windows Emacs properly because it was using Mingw style paths, and Emacs wanted to use Windows style paths. There was no Emacs under Msys2 either. Disappointing experience. But lesson learned.. Windows-Rust is built atop a *nix toolchain, and until that changes, it will always be a pain to do general purpose Windows programming with it.
Sorry it took a while to reply. Thanks so much, for the loop as well as box ref
The rust toolchain runs fine under cmd. I'm sure the Racer guys would appreciate someone making it work with windows paths. I do all my windows dev in cygwin's emacs, which I configured to work with either path format, the weird windows path format is definitely an annoyance though.
So y is of type &amp;box&lt;Node&gt; - 1st * de-reference &amp; - 2nd * de-reference box Then get borrowed reference (&amp;**y) Is my understanding correct?
Yup, is cooler. Thing is I'm starting to understand rust only now. Coming from c# background, it took a while. I still don't want to jump into iters and traits yet, wanna get the basic concepts 1st. One question though - impl&lt;'a&gt; Iterator&lt;&amp;'a Node&gt; for NodeIter&lt;'a&gt; { fn next(&amp;mut self) -&gt; Option&lt;&amp;'a Node&gt; { Isn't this recursive rather than iterative?
Would you be interested in coming to the meetup?
`box Nop as Box&lt;Opcode&gt;` gives you a `Box&lt;Opcode&gt;`. `let nop = Nop; &amp;nop as &amp;Opcode` gives you a `&amp;Opcode`.
Opcodes are usually a known limited set (unless you have an extensible system or something), so an other way would be to use an enum: enum Opcode { Nop, Add, Mul, //... and so on } impl Opcode { fn execute(&amp;self, machine: &amp;mut Machine) { match *self { Nop =&gt; {}, Add =&gt; /*do Add things*/, Mul =&gt; /*do Mul things*/, //... and so on } } } This allows you do do exactly this: let opcodes = [Nop, Add]; machine.nextOpcode(opcode[1]); since both `Nop` and `Add` are variants of the `Opcode` type.
As long it isn't &amp;mut Node, I guess its fine right?
I was hoping i wouldn't have to do the huge match, I'm trying to make an Implementation of Chip16, it has 50-60 instructions and wanted a little nicer way to deal with the instructions. The enum is still better than the other idea i had though
When i do opcode.Opcode::execute(blah); It asks me to add a '&lt;' after Opcode::, which i assume is for specifying the exact type. Is there a way to not do that?
It's let opcode = box Nop as Box&lt;Opcode&gt;; opcode.execute(blah);
It still throws the same error. error: expected '&lt;' but found 'execute'
Ah, I see. `execute` is a static function. I don't think it's possible to call static trait functions yet. Use the enum solution. It's better anyway. 
Would it be bad, whether idiomatically or concerning the performances, to make `execute` a non-static function? I suppose we would get the vtable lookup overhead?
You would have to implement all the instructions in either case and I do personally think the enum method would be the best in the end, but I don't know. This is probably a case where I would make a macro to, at least, make it a bit more convenient. Something like: macro_rules! opcode ( (using $machine:ident with $($name:ident =&gt; $operation:expr),+) =&gt; ( enum Opcode { $($name),+ } impl Opcode { fn execute(&amp;self, $machine: &amp;mut Machine) { match *self { $($name =&gt; $operation),+ } } } ) ) opcode!{ using machine with Nop =&gt; {}, Add =&gt; { let a = machine.pop(); //... }, //... } Warning: Highly untested and does probably contain errors!
Shift-right-click and save on the "main" player work for me. (Well, [playback doesn’t work in Firefox on non-Ubuntu Linux](https://bugzilla.mozilla.org/show_bug.cgi?id=1053103), but that’s another story.)
Ah thanks. Do you want me to include this in the post? I don't want to accidentally direct people to what may be the wrong thing.
The problem is the kind of executables that rustc generates, I dont think racer can do much about it. Mingw/gcc just generates executables bound to their underlying POSIX layer, so short of making a native windows compiler, rust will always have this issue I think.
The vtable lookup overhead is exactly how dynamic dispatch happens, isn't it?
I don't even have access to a Windows machine, let alone any idea of how to compile Windows stuff, so patches _extra_ welcome.
I'll have to revisit it then, because if that were so I should have been able to use windows paths everywhere, which was my original hope.
Mingw only provides a posix layer to build and run gcc + it's binutils. The binaries have no dependencies on any posix code. If you build something with cygwin then it'll depend on the cygwin runtime, that's why mingw was forked in the first place.
I am 95% sure that arrows require HKT, right? http://www.cse.chalmers.se/~rjmh/Papers/arrows.pdf I suck at arrows, so I could be wrong here. &gt; The essence of a multi-level language is a functor from one category to another; You can't get a functor without HKT, sooooooo
I believe you are correct, so consider this to be more of a forward facing (post 1.0) goal. I *really* want to see HKT's in Rust sooner rather than later.
Well i was using a prebuilt emacs for windows, and racer built with rustc from git master using the procedure you outlined in your first response (mingw+msys2). I could never get the paths right in the emacs configuration to set all of racers env variables and get it to hook up with the content-assist module.
I bet no profiling was performed. Since the reference count would only be incremented and decremented twice I doubt it makes a measurable difference
Great, that makes sense. Thank you (and /u/ehsanul too!) for explanations. I always saw the collision bodies as something provided by artists, but I suppose with indie scene and the trend to low-poly modelling, having it automatically derived is a win. Looking forward to try it out ;)
FYI about existing developments. [rust-compress](https://github.com/alexcrichton/rust-compress) has a simple encoder/decoder implementation, that is compatible with DC. [dark](https://github.com/kvark/dark) has an advanced linear-time &amp; space implementation (derived from SACA). I was thinking about moving it to rust-compress eventually.
Every categorical construct above basic level requires HKT, I believe, mostly because nearly every construct includes functors applied to various objects.
Wow, this does look like serious drawback. Inability to describe closures accepting references breaks iterators, for example. Hopefully this is just a fixable bug. BTW, Reddit does not understand fenced code blocks. You need to indent the code with four spaces for it to be displayed correctly.
No, what makes you say that?
me too. That way i will be able to download low quality versions of the videos. i have a 256kbps connection :(
But he does reference counting with his boolean flags. For example, the last one between "handler" and "holder" will release the memory in its drop function. `Holder&lt;T&gt;` is something like an `Rc&lt;RefCell&lt;T&gt;&gt;` while `Handle&lt;T&gt;` is something like `Weak&lt;RefCell&lt;T&gt;&gt;` it seems.
You always have the option of returning or accepting a concrete error - you only have to abstract it if you want to. Additionally, the cause method is optional and if you want a lower overhead error you can just neglect to re-implement it.
Can confirm, "Building on Windows" instructions worked for me.
Hi, polymorphic arrays are sometimes a little bit tricky. Here is my implementation without the "Machine" type. Is this what you had in mind? trait Opcode { fn execute(&amp;self) -&gt; (); } struct Nop; impl Opcode for Nop { fn execute(&amp;self) -&gt; () { print!("Nop") } } struct Add; impl Opcode for Add { fn execute(&amp;self) -&gt; () { print!("Add") } } fn run(opcode : &amp;Opcode) { opcode.execute(); } fn main () { let code : [&amp;Opcode, ..2] = [&amp;Nop, &amp;Add]; for &amp;operation in code.iter() { run(operation); } } 
I would be interested in seeing what the difference in efficiency is between the `handle.rs`implementation and a naive implementation such as the following: use std::rc::Rc; use std::cell::{RefCell, Ref, RefMut}; struct Holder&lt;T&gt;(Rc&lt;RefCell&lt;T&gt;&gt;); struct Handle&lt;T&gt;(Rc&lt;RefCell&lt;T&gt;&gt;); fn create_handle&lt;T&gt;(value: T) -&gt; (Holder&lt;T&gt;, Handle&lt;T&gt;) { let rc = Rc::new(RefCell::new(value)); (Holder(rc.clone()), Handle(rc)) } impl&lt;T&gt; Holder&lt;T&gt; { fn get(&amp;self) -&gt; Option&lt;Ref&lt;T&gt;&gt; { let &amp;Holder(ref rc) = self; rc.try_borrow() } } impl&lt;T&gt; Handle&lt;T&gt; { fn get(&amp;self) -&gt; Option&lt;RefMut&lt;T&gt;&gt; { let &amp;Handle(ref rc) = self; rc.try_borrow_mut() } } fn main() { let (a,b) = create_handle(10u); println!("{}", a.get()); b.get().map(|mut n| *n += 10); println!("{}", b.get()); } 
You'll have to return a `Result&lt;u8, String&gt;` as the `format!` macro returns a String, which is an owned (no references, self-contained) version of a &amp;str.
&gt; cannot find -ltcod This means you don't have libtocd installed?
Is it fast enough to run the convex decomposition in real time? This is pretty mind blowing! If this works perfectly, it means you can load an arbitrary 3D model and simulate physics with it. You could break apart a model, cut or slice it as you like and make the new parts behave physically as well.
In your solution to this problem you add a "build directive to the Cargo.toml" that runs a script. That script sends all dylib files you got from compiling libtcod in OSX to $OUT_DIR/, when I compile libtcod in windows all I get are dll files which I tried to send to $OUT_DIR/ through the .build.sh script but that doesn't seem to work.
Thank you! That fixed things, no more compiler errors and much better `Err(format!())` based reporting. :)
I really wish I had the time to learn sublimes plugin API and get RACER support with Sublime text.
I suppose you got me there. It could probably be optimized to run on a different thread or process though. i.e., the performance issue probably isn't *just* due to feature creep.
Yes, this is what i wanted. I'm going with the enum option though, it basically allows me to skip the array completely. I have one question though, is the "run" function required?
Interesting. A bit of feedback: 1) I think create_handle() is odd; most things use Foo::new(). I realize Handle::new() wouldn't actually return a handle, but I think it'd be semantically better. 2) Wow, you really need to add some tests for this. How do you actually use it? I tried: let result = create_handle(f); let hold = result.val0(); let hand = result.val1(); and got: Compiling handle v0.1.0 (file:///Users/doug/dev/handle.rs) /Users/doug/dev/handle.rs/src/lib.rs:253:28: 253:34 error: use of moved value: `result` /Users/doug/dev/handle.rs/src/lib.rs:253 let hand = result.val1(); ^~~~~~ /Users/doug/dev/handle.rs/src/lib.rs:252:28: 252:34 note: `result` moved here because it has type `(Holder&lt;tests::Foo&gt;,Handle&lt;tests::Foo&gt;)`, which is non-copyable (perhaps you meant to use clone()?) /Users/doug/dev/handle.rs/src/lib.rs:252 let hold = result.val0(); I did eventually get it to work by rewriting the function, but usage really isn't very obvious. 3) The borrowing seems kind of inconsistent. Consider: let fr = holder.get(); assert!((*fr).x == 100); let fr2 = holder.get(); &lt;--- Why is this ok? assert!((*fr2).x == 100); let fr3 = handle.get(); assert!(fr3.is_none()); let fr4 = handle.get_mut(); &lt;---- Why is this a runtime error? assert!(fr3.is_none()); This will fail with the runtime error: task 'tests::test_duplicate_borrow' failed at 'Holder or Handle already borrowed.', /Users/doug/dev/handle.rs/src/lib.rs:97 Why not just make it return None? Can't see anything particularly unsafe about it, although I'm not exactly sure what that but I think you'll find that it's actually quite inconvenient to use in practice. If you want a 'light weight' way of keeping an instance like that though, why not just forget() a boxed instance of T, and keep unsafe references to it in various places with a Mutex to handle access; the 'owner' being the one who read()'s the value back at the end to drop it (after obtaining the mutex). If a mutex is too 'heavy' you could also use AtomicBool? ...but I guess it depends exactly what you're trying to do; if this serves you specific need, then fair enough.
Is there a reason Box&amp;lt;str&gt; wouldn't work with DST? edit: Never mind. I checked, and String has a capacity, making it growable. 
This might also help Rust resolve the current tension between trying to make as many things "morally constexpr" as possible (for example, making size_of an associated item for each type) and supporting full compile-time function execution for more complex forms of precomputation. To some extent, a single level of CTFE is already available through procedural macros, but the mechanism is highly ad-hoc, has a super volatile API, and isn't any fun to use--it's certainly much worse than metaprogramming in a real multi-level language. I've thought about using Rust as the base for doing some work in staged PLs, but for the most part it seems too immature: maybe with 1.0 or 1.0+HKT this will no longer be the case, but for now tracking a moving target while building nontrivial extensions seems like it's asking for trouble. Ultimately, it would be great to see synergy between the efficiency benefits of minimizing allocation and managing low-level memory layout as Rust permits and the efficiency gains provided by explicit compile-time evaluation in staged/multi-level languages.
You might be right but I hope you aren't. Without good tools it would be difficult for us to ever overtake C++. And overtaking C++ seems to be the ambition of the fine folks here.
1. It's a bit tricky to return 2 objects, so I went with the simple route and returned a tuple. 2. Usage is in the [README](https://github.com/HeroesGrave/handle.rs/blob/master/README.md). 3. This example isn't very clear, and there is no `get_mut` method. Hopefully you'll get everything working fine after reading the readme, but if not I'm happy to look into any problems. But yes, it could do with some tests. I'm competing in the Ludum Dare so it may have to be after then. As for usage, it takes a lot of pain away from making some kinds of library. Sometimes one system needs to read data, while another system needs to write it. Using Handle/Holder makes the code much more simple and easily expanded upon.
&gt; I do think it would be better to have support in all the common IDEs and editors though such as the IntelliJ platform, Eclipse, Sublime Text, Vim, and Emacs. That's not bad idea either, but can those IDEs "read" macros? That's arguably the most important feature of any IDE. For that reason I think dedicated IDE would be a good thing.
No profiling was performed. I'm quite inexperienced at that sort of stuff. If you know how to do it, please let me know.
what do you mean by "read macros?" We can do whatever we want, as long as their API allows it. That the whole point of custom editors.
Me too. Unfortunately, (as also stated in my other comment), I'm not sure how to go about with benchmarking/profiling. However, I don't think that even in the worst case scenario could Handle/Holder be any *worse* than Rc&lt;RefCell&gt;. So in the end, it's slightly easier to use, and guarantees sensible usage.
That doesn't sound unreasonable. we have `rustc --pretty=expanded`, and we could probably figure out a way to use that. For better tooling we probably need to refactor rustc to allow more modularity. I am not a core dev, so I'm unsure how it would be done :p but sure that is possible.
Thanks for explanation. I do think this is important issue because language macros are usually seen as "that weird black magick no one understands or uses," assuming they exist at all. Having macro system that is easy to use, that is fully supported by some IDE would be great advantage to rust over other equally expressive languages. Something to think about. I think it is about time someone mainstreams metaprogramming.
I think it'd be pretty awesome if JetBrains made a Rust-centric editor
What problem did you run into? I got it going just now. The big missing piece for me was that I'd forgotten to add "C:/msys64/usr/local/bin" (or wherever your rust DLLs are installed; the dir with files like rustc-4e7c5e5c.dll) and "C:/msys64/mingw64/bin" (for libgcc_seh-1.dll) to my PATH. Before then I was getting "racer.exe exited with status 53" upon trying to tab-complete.
Yup, I want this too. I'd love to see the LLVM-to-C backend get resurrected!
The stream started out smoothly, however now i'm getting about a second of AV between ~7 second gaps (i'm in AUS, other vid services seem to be working fine). Anyway, looks like there's some great stuff, looking forward to DLing these :)
I've heard Air Mozilla was giving some people trouble recently. I'm sorry you have had some trouble. Hopefully the recorded video will work for you. 
That would be great!
Instead of the `.build.sh` hack for libtcod, I just moved the `*.dylib` files into my `/usr/local/lib/` directory and the `terminal.png` into the root of the project.
In vim :'&lt;,'&gt;!sed -e '1ifn main() {' -e '$a}' &gt; "rusttmpfile.rs" | rustc --pretty=expanded "rusttmpfile.rs" | sed -e "1, /fn main() {/ d" -e "$,$ d" This expands the macro under the current selection 
I tried to get it working. I can't figure out how the hell to do it without doing 16 different events.
Actually, even better than that: `brew install homebrew/games/libtcod`. Just make sure you have [XQuartz](http://xquartz.macosforge.org/trac/wiki/X112.7.7) installed.
I'm aware the answer is "no", but that doesn't mean it's impossible. I want to know, at a high level, what would it take to make this possible.
I don't think there's a 'high level' answer to this. otherwise it would have already been shown...
In April, Alon Zakai announced LLVM-to-C backend based on Emscripten (not resurrection of old LLVM-to-C backend). Do you know what happened to it? http://lists.cs.uiuc.edu/pipermail/llvmdev/2014-April/071928.html
No, it cannot be used in real time. In fact, I am not sure that a real time convex decomposition algorithm even exists. However, slicing a pre-decomposed mesh might be computable in realtime. For example, slicing by a plane is just a matter of finding plane/edge intersections and computing a few 2D convex hulls. For this special case, no post-slicing convex decomposition is needed.
Fair enough~ &gt; there is no get_mut method get_unwrap() sorry; just pointing out the return types aren't consistent. https://github.com/HeroesGrave/handle.rs/blob/master/src/lib.rs#L131 'luck with Ludum Dare, hope you'll post what you end up with~ (edit: oh yes, the readme does show how to use it. I totally missed that, my bad)
There seems to be a point of confusion here that's putting you off: There's MSYS, and then there MinGW and they're different things. MSYS is a minimal Unix environment for Windows, and MinGW is a compiler toolchain targetting *bare* Windows. When you invoke `gcc` inside the MSYS2 shell, you are invoking the compiler that will generate binaries to run inside the MSYS environment, not free-standing Windows binaries. It's like the Cygwin compiler in that regard. When you use `mingw32_shell.bat` it sets the environment appropriately so that you get the `i686-w64-mingw32` *cross-compiler* when you invoke `gcc`. This one produces free-standing Windows binaries and what you should be using. If you don't have this compiler then you can install it by installing the `mingw-w64-i686-toolchain` package in MSYS2. The edits you have made to the configure file seem to have made it use the cross-compiler somehow, but incompletely. It's much easier to just use `mingw32_shell.bat` in the first place so the paths are set correctly. 
I think that single player minecraft actually does connect to a (local) server.
Here you go: http://doc.rust-lang.org/guide-testing.html#microbenchmarking
Perhaps take notes from the Nimrod community, who have a dogfooded IDE. https://github.com/nimrod-code/Aporia
After the various replies, having slept on it and not having a headache, I think I understand what the current state of things is. It's a little frustrating that people keep (apparently) forking MinGW and MSYS and repeatedly changing how they interact both with each other and the rest of the system, without any clear indication as to what's going on, or what they've changed. I recall when MSYS was a thing you installed after you installed MinGW, and all it did (in effect) was provide a shell and the usual commands so that Makefile and configure script-based source would build. *Then* it turned into something you installed from within MinGW and seemed to have become a sub-component that you couldn't really install independently. *Now* it's turned into something you install first, then install MinGW inside of it. And for some reason it's now like Cygwin in that by default things built inside MSYS only work in MSYS and you need a MinGW cross-compiler to make standalone programs, except I thought that was the whole point of MinGW in the first place... Heck, it's even using a different terminal now.
(racer author here) So you've got racer + emacs running on windows? Yours is the first report I've heard of somebody successfully trying it. Are you able to find-definition into the rust source? I'll try and incorporate your comments into the racer readme - Thanks! 
Same here. Will the recording be uploaded somewhere?
Another approach is to use [`MaybeOwned`](http://doc.rust-lang.org/std/str/type.MaybeOwned.html) with `'static` lifetime, that is, [`SendStr`](http://doc.rust-lang.org/std/str/type.SendStr.html). That way you can have dynamically allocated strings when you need, but you also can use `&amp;'static str`, staying away from allocations when they are not needed. `MaybeOwned` has `as_slice()` method, so you can easily go from `MaybeOwned` to `&amp;str`, whatever variant it really is.
Yes, it works like that since version 1.4 IIRC.
&gt; I do think it would be better to have support in all the common IDEs and editors though such as the IntelliJ platform, Eclipse, Sublime Text, Vim, and Emacs. Racer, which just got [updated](http://phildawes.net/blog/2014/08/21/racer-update3/) goes in that direction, and pretty well I think. AFAIK it doesn't do much about the OP's macro-related questions, but it already makes Vim (in my case) an very nice rust IDE ^ ^ 
Oh, my bad, for some reason I confused you for /u/jaredonline.
EC2 has Windows VMs with RDP access. It might take ages to compile, but the free tier allows you to keep a t1.micro running all the time: http://aws.amazon.com/ec2/pricing/
Racer-find-definition seems to be working fine, at least for the libraries that come with Rust. Cargo is currently broken on 64-bit Windows so I haven't tested with other libraries. For reference, my setup is 64-bit MSYS2, self-compiled 64-bit nightly installed to default dir. Emacs is the regular Windows native 24.3.1 release. Rather than adding those two dirs to my PATH system-wide, I just used set-env within my emacs's init.el.
Well, would assigning it `'static`not lead to an indefinite lifetime for the error messages? Because that's not something I want, it's why I was seeking better alternatives. I have error messages that are hard-coded, which I had been specifying as `'static`, believing that this means the *reference* may expire but the lifetime of the hardcoded string is `'static`, but the problem I was having was with dynamically generated error strings. Would assigning those a `'static` lifetime not lead to memory bloat?
I wanted to believe.
&gt;If Rust is really better than C++ (and most here will assume that it is), it should be easy enough to write a Rust IDE in Rust. Just because writing IDE from scratch might be easier to do in Rust than C++ does not make the task easy. And in reality you also have the ecosystem problem, eg. Eclipse already has a rich ecosystem of extensions, many which are entirely language independent. It would be somewhat waste of time attempting to replicate those. It is not like rustc is pure Rust either. It leverages heavily the existing LLVM project which is afaik c++. Why shouldn't the IDE similarly leverage existing frameworks like Eclipse?
I would advise against using the Eclipse platform, mainly because it implies using a JVM + OSGI platform, which, though having seen some impressive tuning, is rather heavy in terms of memory and startup time. Also I don't know about JVM/Rust interop, but I'd assume that it's a bit more complex than using Rust and C/C++ together.
Eclipse was just an example.
I believe the point was that with `MaybeOwned` you can use either literal strings or allocated (formatted) strings in your output. Probably not useful for a single function (although it might work with multiple return points where early error returns may not have anything to format), but useful for traits: implementor may or may not care to generate extensively formatted error messages, and if they don't they can avoid allocations.
Well, obviously. It's not exactly likely though, even if rust is massively popular, we wouldn't see one for another several years.
Aren't Jetbrains products Java, and not C++?
There is a plugin for [atom](https://atom.io/): [atom-racer](https://github.com/edubkendo/atom-racer). Last time I checked it didn't work that well, but it's a start.
I haven't checked, could be. Even worse, we'd end up with a Java-based IDE, which would mean we'd have to write plugins in Java or do some Java-Rust interop. 
Yeah, no arguments there.
You could add a warning like this to the readme of sax-rs. :)
&gt; How do you actually use it? Handling a tuple? Pattern matching. `let (hold, hand) = create_handle(f);`
My bad, misunderstood code. Call is returned for each item in iteration.
JetBrains IDEs are written in java. They also interop with plenty of CLI tools seamlessly. It seems like an ideological hangup to demand that your IDE be written in rust. If your end goal is to make rust accessible, then an IDE that people are already familiar with would be of far greater benefit than some hand-rolled thing that would take years to become stable.
You can't assign a lifetime to anything; lifetimes are inferred by the compiler. Even more so, even if you could, you couldn't do it *arbitrarily*: `'static` lifetime is assigned only to statically allocated data, and these are `static` items and string literals. So your question: &gt; Would assigning those a 'static lifetime not lead to memory bloat? does not make sense - you can't make anything dynamically generated static. You need to use `String` for that. `SendStr` (which is identical to `MaybeOwned&lt;'static&gt;`) represents either a statically allocated string `&amp;'static str`, which can *only* be obtained from string literals, or a dynamically allocated string `String`. When you need to return some static error message which does not depend on dynamic data, you use `Slice("some literal error message")`, for example. When you need to return dynamically generated error message, you use `Owned(format!("dynamically generated message: {}", data))`. This is some kind of optimization: you use allocation only when it is really necessary. Then the user of your code will be able to call `as_slice()` on your error and obtain `&amp;str` slice, because it is very easy to go from `String` or `&amp;'static str` to `&amp;str`
Maybe pull a Haxe and embed completion, macros, refactoring, maybe even syntax highlighting into the compiler? Compiler knows best!
That actually sounds good.
It was unclear to me because macro expansion would require IDE to know about the code as much as compiler. This would require code duplication. Didn't know that you can simply command compiler to expand a macro.
Since I don't work at JetBrains, I can demand they add a Rust mode just for you all I want, it's not going to happen until the language is at least a bit stable. On the other hand, starting an IDE in Rust would give the current tooling a good whip in terms of modularity. Of course, it's simple enough to do stuff in a hacky way. E.g. I recall that NetBeans - last time I checked - just used mvn or ant and javac to build stuff in the background while the programmer types. Of course, an incremental parser/compiler combination *able to unroll macros* would be pretty cool. AFAIK, only some lisps do this currently. Showing that it is possible without drowning in parenthesis would be a worthy goal in itself. ;-)
Yeh, the clang approach is probably best. Structure the compiler so that all the useful stuff related to the lexer, parser, type checker etc is easily available as a library, then write very thin wrappers so that editors can access the functionality.
Hey, sorry for the slow response. I don't have a Windows machine to test on... a couple things to try: - try using a package manager / binary from their site http://doryen.eptalys.net/libtcod/download/ - I think on windows you should be looking for a .a file, but I'm not sure. - I based my example off of https://github.com/csherratt/glfw/blob/cargo/.build.sh, maybe you can take a look there and get some clues. If you can't get any of that to work, you might try asking in the #rust IRC channel (on irc.mozilla.org), they're super friendly.
Just a quick update: with a freshly installed MSYS2 and mingw-w64-x86_64-gcc installed via pacman, Rust commit e052aa65 (dated 21^st of August) compiled cleanly for x86_64. Tested with a quick hello world.
Great answer this is what I was looking for. D actually does support binding to C++ templates now. I think to really unseat D, rust needs a good story here.
Har! *My* contribution was "I'm an easily confused moron who can't read a README file properly!". At least you wrote something useful. :D
Is there any chance these videos can go up on youtube? None of the air.mozilla.org videos work for me, either in Firefox or Chrome.
My vote goes towards Ottawa or Toronto!
Why create a docker image to compile the application? Why not just deploy the executable to the server? I can see how this could be useful to deploy an application that has many dependencies on dynamic system libraries, but otherwise seems like overkill to me. Isn't the lack of dependencies one of the main advantages of static compilation? EDIT: Unless, of course, the goal of the isolation is to get additional security.
Lifetimes are how rust manages to be memory-safe without needing a garbage collector. If you have a Point struct on the heap and you ask for its `x` field, the lifetime for `x` is bounded by the lifetime of your Point struct. This means that it is impossible for you to use `x` after your Point has been freed. For example, in C++ it is legal to write: int* member; { Point* p = new Point(); member = &amp;p-&gt;x; free(p); } *member = 5; (I haven't written C++ in years, so I might have some typos). In that example, we have a use-after-free of the x-member of the Point struct. Trying to duplicate this example in Rust would be impossible because of the restrictions of lifetimes. It is because of this that Rust programmers never have to worry about iterator invalidation, use-after-free, double-free, race conditions, or any other bugs commonly found in languages that don't track ownership.
Okay, that makes sense, but then what would be a reason to use a function like in my post where it takes the lifetime of p and returns a reference in the same lifetime? I've tried it without all the lifetime stuff and it still works and is still able to return a reference.
Can you give a URL explaining support for C++ templates? The document linked above contradicts this statement. From http://dlang.org/cpp_interface.html &gt; D templates have little in common with C++ templates, and it is very unlikely that any sort of reasonable method could be found to express C++ templates in a link-compatible way with D. &gt; &gt; This means that the C++ STL, and C++ Boost, likely will never be accessible from D.
&gt; I have one question though, is the "run" function required? As you can see, it's just a shorthand, same as `operation.execute();`.
The application shown in the blog post is for demonstration purposes only and thus very primitive in nature, however it is highly unlikely that an actual web application, the kind of Twitter, GitHub, SoundCloud etc. could ever be statically compiled and deployed as a single unit, rather they are likely to employ a multi-services architecture, composed of a number of services, possibly not even all written in the same language, number of internal and external assets etc. By using docker, you're able to increase decoupling, increase security and more importantly being able to hot-swap or change certain services with practically 100% certainty that any neighbouring service won't be affected. Another benefit is that if you have a bunch of in-house servers and some Amazon AWS ones, you don't need to test two separate environments, just because you're running two different environments on your servers. Inside the container, the environment is always the same.
The common case in Rust is returning something with the lifetime of the argument so we allow it to be left out, as a short form.
Someone should just write a bot that pretends to be whatever browser air.mozilla.org actually likes and automatically then crossposts every video to youtube.
They didn’t play for me either very recently, because of https://bugzilla.mozilla.org/show_bug.cgi?id=1053103 , but it seems fixed for me now. If it’s still broken for you, here are links to the webm versions: SD: https://d3fenhwk93s16g.cloudfront.net/6v0w5u/webm.webm HD: https://d3fenhwk93s16g.cloudfront.net/6v0w5u/hd_webm.webm
Using the same trick /u/tiffany352 noted, you can do explicit template instantiations and then link against that. It hasn't been done yet actually, but it is in the works. Also, using some stl from D directly is coming really soon: https://github.com/D-Programming-Language/dmd/pull/3873
Technically it wasn't ALL lifetimes: we had one inference rule. Now there are three. Your point still stands, though.
&gt; it is highly unlikely that an actual web application, the kind of Twitter, GitHub, SoundCloud etc. could ever be statically compiled and deployed as a single unit, This is actually how Facebook works. It's a 1.5 gigabyte binary, last I heard.
I think it is a mistake to deploy with the compiler (+other devtools). A better setup would be to have one container for building, and the copy the built executable (+dependencies) over to the container/image that will be deployed.
See [homebrew taps](https://github.com/Homebrew/homebrew/wiki/Interesting-Taps-&amp;-Branches). Basically, different repos with extra formulas. Installing with that syntax just auto-taps that extra repo before installing `libtcod`.
&gt; Header files are used to perform forward declaration. Sorry, but what is the benefit that you suggest this brings over Rust's module system?
When using an iterator. let mut xs = vec![0u8, 1, 2]; let first = xs.iter().next(); `first` would contain a borrowed reference into the vector. This stops you from mutating the vector (borrowing locks it) while you are iterating it. The practical use: Iterator invalidation problems are avoided.
Is that a whole system image or a single binary? I can't imagine the amount of RAM necessary to link and optimize a binary that large. Don't they still use interpreted/JITed PHP extensively, as well?
A single binary. Also, this was as of a year(ish?) ago, so things may have changed. &gt; Don't they still use interpreted/JITed PHP extensively, as well? It was PHP cross-compiled to C++. Now HipHop is an actual VM.
I am not sure down to that level. This is information that was all public on the web, I'm sure it'd come up with some searching. Maybe the High Scalability blog?
Right. it's often easier to have the struct actually own the data itself. struct MyStruct&lt;'a&gt; { name: &amp;'a str, // ... } is nicer/better/easier as struct MyStruct { name: String, // ... } Sometimes, references are what you want, though, so the former is not _wrong_.
&gt; I can't imagine the amount of RAM necessary to link and optimize a binary that large. You can get quite ridiculous amounts of RAM in single box these days. Just checked from Dell, they'll have 96x16GB (that's 1.5TB) available straight from their web-configurator.
&gt; I think on windows you should be looking for a .a file, but I'm not sure. You're right, the compiler creates .a files in the lib folder. I set the .build.sh script to copy and rename the libtcod-mingw.a to libtcod.a (doesn't recognize it otherwise). That solves the linker error. I still got errors tho (using the code you provided in the "Make a window show up" section): D:\RustProjects\dwemthys\src\main.rs:9:35: 9:55 error: failed to resolve. Use of undeclared module `background_flag` D:\RustProjects\dwemthys\src\main.rs:9 con.put_char(40, 25, '@', background_flag::Set); D:\RustProjects\dwemthys\src\main.rs:9:35: 9:55 error: unresolved name `background_flag::Set`. D:\RustProjects\dwemthys\src\main.rs:9 con.put_char(40, 25, '@', background_flag::Set); D:\RustProjects\dwemthys\src\main.rs:13:13: 13:20 error: unresolved enum variant, struct or const `Special` D:\RustProjects\dwemthys\src\main.rs:13 Special(key_code::Escape) =&gt; exit = true, D:\RustProjects\dwemthys\src\main.rs:13:21: 13:37 error: failed to resolve. Use of undeclared module `key_code` D:\RustProjects\dwemthys\src\main.rs:13 Special(key_code::Escape) =&gt; exit = true, D:\RustProjects\dwemthys\src\main.rs:13:21: 13:37 error: unresolved enum variant, struct or const `Escape` D:\RustProjects\dwemthys\src\main.rs:13 Special(key_code::Escape) =&gt; exit = true, Removing these lines allows the build to complete and the executable creates a window with a black background. I guess that's half working! Edit: Changing 'background_flag' to 'tcod::background_flag' solves the problem. I'll try the rest of the tutorial now. Thanks! Shameful edit: I missed a line in the tutorial, adding the "use tcod::{Console, background_flag, key_code, Special};". *That* is how to solve this problem. That's what I get for not reading the fucking manual.
`&amp;self` means an immutable receiver. If you want to mutate the receiver, use `&amp;mut self`. Come on IRC (see sidebar to the right) for these questions. Also check out http://rustbyexample.com/
Please $deity no. I only have 8gig of RAM in my machine and haven't upgraded to Haswell yet so no syntax coloring for me.
the other bit is, when you say 'other: Monster' in the definition of 'attack', you're passing by value, meaning that ownership of 'other' is being transferred into the function. Instead you need 'other: &amp;mut Monster' to pass in a mutable ref. 
I tried &amp;Monster first, but thanks! The placement of "mut" was what I was missing. :)
+1 for figuring it out though [=
This was a really great meetup. I'd love to hear the rust devs talk more about their goals more often - it was a really nice experience and gave us a lot of insight into the future of Rust.
A small demo and "the kind of Twitter, Github, SoundCloud etc" are two extremes in the complexity scale, and I would guess most applications are closer to the former (of course, that's just a guess). &gt; they are likely to employ a multi-services architecture, composed of a number of services, possibly not even all written in the same language How does Docker help with this (honest question here, not trying to be pedant)? I have some experience with it, and I'm thinking of using it in production, but I don't see how it would make service orchestration any easier. Maybe I'm missing something obvious. &gt; you don't need to test two separate environments (...) Inside the container, the environment is always the same. That's indeed a nice benefit, but in my (admittedly small) experience deploying production services, most problems are related to dependencies in the language itself - incorrect version of the runtime, some library that is missing, installation of some gem/egg etc. None of those apply to a static binary. Can you help me see what could go wrong with an executable that has few OS dependencies, such as a web app?
They are unusual, I'm just saying that it is possible, and some people do it. I wouldn't.
I considered this, but since it's easier to show in the way I did, plus to achieve the setup you want, it essentially just involves removing a couple of final lines from the Dockerfile, starting with the git clone. EDIT: Essentially, just modify the Dockerfile like so: FROM ubuntu:14.04 MAINTAINER Matej Lach &lt;matej.lach@gmail.com&gt; RUN (apt-get -qq update &amp;&amp; apt-get -qqy install curl tar gzip gcc shared-mime-info) RUN (mkdir /home/rust &amp;&amp; cd /home/rust) RUN export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/lib RUN curl -O https://static.rust-lang.org/dist/rust-nightly-x86_64-unknown-linux-gnu.tar.gz RUN tar xf rust-nightly-x86_64-unknown-linux-gnu.tar.gz RUN ./rust-nightly-x86_64-unknown-linux-gnu/install.sh RUN curl -O http://static.rust-lang.org/cargo-dist/cargo-nightly-x86_64-unknown-linux-gnu.tar.gz RUN tar xf cargo-nightly-x86_64-unknown-linux-gnu.tar.gz RUN ./cargo-nightly-x86_64-unknown-linux-gnu/install.sh RUN (rm -rf rust-nightly-x86_64-unknown-linux-gnu/ &amp;&amp; rm -rf cargo-nightly-x86_64-unknown-linux-gnu/) EXPOSE 8080 Now, it'll just install Rust + Cargo and open port 8080. Since a Dockerfile is just a regular text file with a bunch of commands as to what to do while building the image, it's super easy to modify it. Now, you'll just do: $ sudo docker build -t="&lt;username&gt;/rust:v1" And now you have a pure-Rust image, which you can use to launch a container: $ sudo docker run -t -i &lt;username&gt;/rust:v1 /bin/bash Since you can now interact with the container, (as opposed to having it just run as a daemon), you can now fetch and copy any executables over to it etc.
Good luck!
Define fun :P
There was a discussion of this on the mailing list earlier this week. Some interns at Draper Laboratory have it working again, the question is whether anyone wants to maintain it upstream http://article.gmane.org/gmane.comp.compilers.llvm.devel/75943
You're looking for /r/playrust.
Good luck! Do your best!
Compile the rust to assembly then and use that assembler. I'm doing that at the moment.
Ah, the `'foo` notation is just _named_ lifetimes. References in general though _always_ work with lifetimes. What you observed where "lifetime elision": The compiler basically has a rule where it inserts a `'r` like in your example automatically in this situation.
&gt; however it is highly unlikely that an actual web application, the kind of Twitter, GitHub, SoundCloud etc. could ever be statically compiled and deployed as a single unit, rather they are likely to employ a multi-services architecture, composed of a number of services, possibly not even all written in the same language, number of internal and external assets etc. 1) Assets are largely not served with the rest of applications. You'll almost always use some sort of cdn or at least a separate server that is better at serving assets like nginx. 2) Multi-service architectures are largely unrelated to the fact that it may be deployed as a single binary or not. You can certainly have services as a single binary. Note, however, that each service would be a separate binary, not combined into one, of course.
I ended up watching the recordings last night without issue! Awesome stuff! Wish I could've been there in person :)
The reason we need lifetimes is to tell the compiler how long a reference is good for. Im sure you have heard that before though. As I understand, there used to be a Rust where lifetimes were inferred; however, I believe that lead to confusion. Lifetimes are a big part of rust, and to have completely inferred lifetimes is only hiding a problem that will bite you eventually. Now, you can just think that anytime you use an `&amp;` in a struct definition or a function declaration you need to annotate it with a lifetime. There are times where you dont have to annotate though, and you can read about those times in the [lifetime elision RFC](https://github.com/rust-lang/rfcs/blob/master/active/0039-lifetime-elision.md)
Obviously, we need to use a [distributed network of minions](https://www.youtube.com/watch?v=yIs7FWeFaLY) for our string matching. Great post!
Will these changes allow this example to pass the borrow checker? https://gist.github.com/nham/4f01b7fa69547d1ce629 Please correct me if I'm wrong, but I don't think this is unsafe. You can see this at work in the methods for `TreeMap`: the `find` method has an iterative implementation, but `insert` is recursive because the non-recursive implementation won't pass the borrow checker.
That is safe, it [just takes a little trick][pp] for the compiler to see it. I believe it is [#10520](https://github.com/rust-lang/rust/issues/10520). [pp]: http://play.rust-lang.org/?run=1&amp;code=%23![allow%28dead_code%29]%0A%0Astruct%20Node%3CT%3E%20{%0A%20%20%20%20val%3A%20T%2C%0A%20%20%20%20next%3A%20Option%3CBox%3CNode%3CT%3E%3E%3E%2C%0A}%0A%0Astruct%20List%3CT%3E%20{%0A%20%20%20%20head%3A%20Option%3CBox%3CNode%3CT%3E%3E%3E%2C%0A}%0A%0A%0Afn%20find_and_inc%28node%3A%20%26mut%20Node%3Cuint%3E%2C%20needle%3A%20uint%29%20-%3E%20bool%20{%0A%20%20%20%20let%20mut%20curr%20%3D%20node%3B%0A%20%20%20%20loop%20{%0A%20%20%20%20%20%20%20%20if%20curr.val%20%3D%3D%20needle%20{%0A%20%20%20%20%20%20%20%20%20%20%20%20curr.val%20%2B%3D%201%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20true%3B%0A%20%20%20%20%20%20%20%20}%0A%0A%20%20%20%20%20%20%20%20let%20tmp%20%3D%20curr%3B%0A%20%20%20%20%20%20%20%20match%20tmp.next%20{%0A%20%20%20%20%20%20%20%20%20%20%20%20None%20%3D%3E%20return%20false%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20Some%28ref%20mut%20n%29%20%3D%3E%20curr%20%3D%20%26mut%20**n%2C%20%2F%2F%20follow%20pointer%20to%20next%20node%0A%20%20%20%20%20%20%20%20}%0A%20%20%20%20}%0A}%0A%0A%0Afn%20main%28%29%20{%0A}%0A
Careful with taking too much inspiration from glibc and other (L)GPL'd sources, or Stallman might come visit and declare that the whole Rust project now falls under that license ;)
I can confirm; it is using the latest nightly version of rust and cargo.
What does this support entail? I assume it means `rustc` is preinstalled, but, which version? And, where from? (Specifically: is it the [official nightlies](http://www.rust-lang.org/install.html)/[rustup](https://static.rust-lang.org/rustup.sh)?)
It is downloading from the same URL as rustup, but doesn't use rustup itself. See https://github.com/travis-ci/travis-build/blob/33f164134abb64b94c9308d099f5ca1a4733328c/lib/travis/build/script/rust.rb#L46
Awesome! Servo uses custom snapshots, but I bet a lot of the other projects will benefit from this. I wonder if it works on osx too. Edit: It does.
&gt;Assets are largely not served with the rest of applications. No and presumably several of the applications would tap into the same pool of assets. &gt; Multi-service architectures are largely unrelated to the fact that it may be deployed as a single binary or not I meant the Facebook situation when I said that "could ever be statically compiled and deployed as a single unit", you can certainly have a multi-services architecture with a bunch of static binaries, however then Docker still comes to play if you want to e.g. tweak your network settings differently based on what application is running inside the container, without affecting the other applications with these settings etc.
Cool! Builds are now quicker, and travis less confusing to set up.
I think that any IDE-like features should be available in stand-alone tools (like Racer; or ghc-mod for Haskell), so that it can work with multiple editors. An IDE can be built around those tools, but it's important to also have all those goodies in Emacs. ^please
&gt; However, when haystack.len() is less than 20, haystack.len() - 20 will be a very large number; we have an underflow error on our hands. I got a bad shiver down the spine, exactly here. OTOH, didn't the commit just move the wrong-branch-taken issue to an overflow when needle.len() &gt; UINT_MAX - 20? (Admittedly a very uncommon/pathological case)
The result looks amazing, really cool project! :)
Thank you very much, this is great feedback! I've changed get_heights to use a slice and get_heights_requested to use a &amp;str - only in the repo so far I'll update the blog in a bit :) On the ``scale`` point which do you think is better, using a slice or a ``Vec``? The function that calls scale passes in ``heights`` whose order I do not want to change so I don't think I can pass a mutable reference to it unless I clone the ``Vec`` and use ``as_slice``? Once again, thanks very much!
&gt; No What do you mean, no? If you've ever gotten a production web app of some sort up, you'll know that you shouldn't serve assets with Rails, Node, Go, etc... You should serve it with something much better at it than those. That means you don't need to worry about your assets if you're wanting a single, statically-compiled, binary. &gt; and presumably several of the applications would tap into the same pool of assets Those assets need not to be deployed along with the single binary.
As the downvotes say by themselves this is not strictly related to Rust. But if you are interested in making Rust work in Web, there is an [issue](https://github.com/rust-lang/rust/issues/2235) about using Rust with Emscripten, which is possible more or less at the moment (but it is not like that your code would port to Web without any modifications).
Since he talked about LLVM IR transformations, I thought that his work is general and makes it possible to port Rust's **blocking code** to the web. I don't know what are the other issues that prevent the port. Thanks for the link. Edit: i've just found this in that link: &gt; Compiling libcore to llvm bytecode generates llvm atomic instructions, but emscripten does not support atomic instructions. So i think we are not their yet
No, that's #6268, which is a separate issue (but is also fixable).
&gt; Will much code will break due to this change? No code should break. It's relaxing a rule, so all code that was valid before is still valid. &gt; How do you know what you have implemented does not admit unsafe code? (I think they call this soundness?) Yup, that'd be soundness. It's sound because it doesn't change what borrowing _means_, it just makes it more accurate. With the current rules, borrows lasted _longer_ than they needed to, which was fine for soundness, because too long doesn't hurt. This is making them last long enough.
Here's what it does: https://travis-ci.org/steveklabnik/edges#L15-L29
Nothing should break. It seems obviously sound as long as we make sure we formulate the notion of intervals properly. It's just another way of enforcing the borrow check rules we already have.
Oops. Thanks
&gt; what I am trying to say is that it can be useful and it doesn't hurt to know how to use it Good point :) Thanks for the article, I'm sure it will be helpful in the future
Any time. Great post!
Another: &gt; Then chuncks is called on the slice.
Thanks. I appear to be having a shocker in terms of typing! :)
On the other hand, you should test the length of `needle` vs `haystack` first; if the needle is longer than the haystack, it's not contained, that really simplifies things :)
Granted, but that doesn't seem to happen either (does it?). I guess it's a question of how much the caller can assume of the library and the library can assume of the caller. Unless you're saying ´contains()` should also perform this check (IMO, it should), in which case, never mind.
I've had their webstorm IDE open for at least a week and it's sitting at 431 MB of memory used.
I made an example to clarify what I meant as I feel you might have misunderstood me: https://gist.github.com/zokier/30b77638cd4299f09337 The main point is that the actual application container is fairly minimal¹, and that is reflected on the size of the image: only 220MB compared to the toolchain containing image that is over 1.2GB. ¹ Actually most of that Ubuntu stuff is not necessary so I wouldn't call this yet minimal. Building an image that contains only bare necessities is left as an exercise to the reader.
Can you actually build fully statically linked executables (easily) with Rust currently?
Awesome. I suspected there was an issue for it, but couldn't find one. Thanks.
I presume that you did not compile with optimisations. Use `rustc -O` or `cargo --release`. This will improve the performance dramatically. The `drop(stream)` and `drop(acceptor)` lines are completely superfluous, by the way.
I suppose I should have qualified my question by adding "... without dropping libstd". `#![no_std]` hardly can be called static linking anyways when it basically means no linking at all, static or dynamic.
When I run this code, I get `Requests/sec: 37542.20` for Rust and `Requests/sec: 31834.19` for Go. The exact code I used is below: https://gist.github.com/anonymous/c90f722ad5e24f2a366e Rust was compiled with: `rustc -o server -O -Z lto server.rs`, and Go was run with `go run server.go`. The version of `rustc` is `rustc 0.12.0-pre-nightly (711d71027 2014-08-22 00:56:00 +0000)`
That's an optimisation right there.
That's neither true nor fair.
I believe that Rust will be suitable; that’s why I’ve taken it up. I’ll be speaking at Strange Loop about it next month: https://thestrangeloop.com/sessions/fast-secure-safe-the-web-that-can-still-be, and also at the next Rust Bay Area meetup.
This is really awesome - thank you!
Can anyone provide the equivalent in managed C++11?
Will this have any effect on when destructors run, perhaps in conjunction with temporaries?
I can't do managed C++11, but here's one with straight C &amp; libuv: https://gist.github.com/anonymous/49a46b15272d3ae83b97 Compiled with `gcc -Wall -Wextra -O3 -luv -o server-c server.c`, I get `Requests/sec: 40494.87`
Great job sussing this out, nham! I continue to assert that it was the funnest bug to play around with ever. $ "ananas".contains("nana") &gt; true $ "bananas".contains("nana") &gt; false $ "bbananas".contains("nana") &gt; false $ "bbbananas".contains("nana") &gt; false $ "bbbbananas".contains("nana") &gt; true $ "bbbbbananas".contains("nana") &gt; false 
No, it shouldn't. Lifetimes of references don't have an impact on when destructors run.
I hate to brag, but that's really unexpectedly impressive given that we don't have a userland scheduler (by default anyway) like Go does. What OS are you on?
Thanks guys for your feedback. @someone13 I changed my HTTP server code in Go to your example, compiled the Rust code with the option `-O` and now I got the same req/s as in Rust. Rust: $ wrk --connections 1 --duration 10s --threads 1 http://127.0.0.1:8080 Running 10s test @ http://127.0.0.1:8080 1 threads and 1 connections Thread Stats Avg Stdev Max +/- Stdev Latency 2.94ms 2.18ms 4.60ms 63.45% Req/Sec 1.68k 2.25k 5.44k 67.19% 16381 requests in 10.00s, 1.56MB read Socket errors: connect 0, read 16381, write 0, timeout 2 Requests/sec: 1637.80 Transfer/sec: 159.94KB Go: $ wrk --connections 1 --duration 10s --threads 1 http://127.0.0.1:8080 Running 10s test @ http://127.0.0.1:8080 1 threads and 1 connections Thread Stats Avg Stdev Max +/- Stdev Latency 96.16ms 62.83ms 137.23ms 70.07% Req/Sec 1.64k 2.52k 6.44k 70.86% 16380 requests in 10.00s, 1.56MB read Socket errors: connect 0, read 16369, write 11, timeout 3 Requests/sec: 1637.47 Transfer/sec: 159.91KB Could it be that this is an OS X related problem? 
There is an old web development with the generation of html on the server side. To do this, the best fit PHP or Rails. And there is a new web-development, where the server is a thin layer to the database, and a little business logic with json-rpc interface. In this case, you can use almost any language
The surprise for me is that the latency stddev is higher in the rust code. 
See the [community libraries list](https://github.com/rust-lang/rust/wiki/Community-libraries#web-programming) There are a couple fledgling web frameworks. Also there is a mustache implementation in [template engines](https://github.com/rust-lang/rust/wiki/Community-libraries#template-engine)
Shadowing is declaring a whole new variable that happens to have the same textual representation, it's not semantically different to `let x1 = ...; let x2 = ...;` (it just so happens that they are indistinguishable in source form, and hence the first one becomes inaccessible). This is useful with ownership/references where you might have a `String` but only care about using it as a `&amp;str`, e.g. let x: String = read_string(); let x: &amp;str = x.as_slice(); The current scoping behaviour allows this, since the first `x` lasts for the whole scope, so the non-owning view (the second `x`) is valid for that long too. If the first `x` was "cancelled" this wouldn't be possible, instead requiring, e.g. `let x_ = read_string(); let x = x.as_slice();` even though distinguishing the `x_` as a separate variable is not useful (and may even lead to bugs if it is used accidentally in place of `x`; unlikely in this non-matching types case, but can happen with generic code or for examples where the types do match).
Those look so similar that I wonder if you're accidentally testing the same code twice?
I would expect what you observed. Names of local variables don't have any effect on the generated code; that includes whether two variables have the same name.
I thought so too :) But nope, it is correct (EDIT: As you can see the latency (Go) is much higher than for the Rust server) It looks like I get more than 250 packets on an closed port. With the Go server I get everytime I run it in my sys log `Limiting closed port RST response from 4597 to 250 packets per second` Nothing is logged when the Rust server is running
it might make you a better C++ programmer, at the very least
I'm running Arch Linux x64, 16GB RAM and a Core i7-4471. Also: happy cake day :-) EDIT: Also, I am using the latest version of Go: `go version go1.3.1 linux/amd64`
Also: here's my results from the green scheduler. I didn't tweak any settings - literally added: #[start] fn start(argc: int, argv: *const *const u8) -&gt; int { green::start(argc, argv, rustuv::event_loop, main) } and then appropriate `extern crate`s, then ran the test again: Running 10s test @ http://127.0.0.1:8080 1 threads and 1 connections Thread Stats Avg Stdev Max +/- Stdev Latency 8.12us 10.29us 2.32ms 99.19% Req/Sec 33.57k 2.72k 38.33k 75.34% 311155 requests in 10.00s, 29.67MB read Socket errors: connect 0, read 310130, write 1024, timeout 0 Requests/sec: 31115.72 Transfer/sec: 2.97MB
I've found that rust has changed the way that I think about designing programs. Even when I go back to C, I'm constantly thinking about the ownership and borrowing. Any time that I think "this wouldn't be legal in rust", I avoid potential bugs.
I agree with chris-morgan that Rust is not just a suitable language for web development but that it can be a *great* language for web development. I'm leading some of the effort to make that a reality with Iron, and I sure hope it's not going nowhere :). I'm personally making a large effort to ensure that Iron is adapting and evolving to be a cutting-edge framework for building real applications in Rust.
(You may wish to delete and resubmit this :) it got stuck in the spam filter for a few days due to the shortened playpen link; see the end of the sidebar for a work around.)
I thought up this hack to add some flexibility when dealing with `String` and `Vec` in generic types like maps and sets. It's a pretty good way of tackling those common cases, and I think it gets rid of most of the rationale behind `Equiv`. The remaining flexibility could be left to generic functions taking closures. If Rust had more auto-dereferencing, the syntax would be `map.find("foo".as_string())` rather than `map.find(&amp;*"foo".as_string())`. However, it currently only works for method / attribute access.
What, you mean like : [frameworks](https://github.com/iron/iron/) with chained middleware that provide for [sessions](https://github.com/iron/session), [routing](https://github.com/iron/router) and a number of other features? Its not perfect, but I'd say its under control. 
If the language is 'good enough', they will be written progressively. (There's certainly quite a few prototype libraries for various web-related features around.)
You can get the behavior you expected by adding an extra scope to force the drop to happen before the `println`. fn main() { let x = A{a: 1}; { let x = A{a: 2}; } println!("End of scope"); }
Definitely. And learning Rust will also expose you to concepts that will be useful if you later need to learn OCaml, Scala, Swift, or other languages with similar lineage/influences. None of these languages are exactly mainstream in industry yet, but things seem to be trending in their direction. (The next big systems language may not be one of these, but if not then it will probably be influenced by them.)
This isn't the same behaviour, yours prints 2 End of scope 1 since the inner one drops out of scope first. The true reproduction is fn main() { { let x = A { a: 1 }; } let x = A { a: 2 }; println!("End of scope"); }
I don't think it shows it *has* to be the case? It doesn't seem crazy that it could be an error ("can't shadow `x` while borrowed", or "can't use `y` after `x` was shadowed"). Some might even find it more intuitive this way, since it matches how mutability works, and people may regard this name shadowing as a weak form of mutability.
Just as a side note, that implementation of mustache seems to be missing a great opportunity in offering a couple of macros, one for an embedded string, and (if this is possible) one that would open a file and compile it into a static template object. The current implementation (which is a great start, by the way) will encode the data to a JSON map and match the template dynamically - it's neither inherently fast nor safe.
Yeah you are right that i should be more familiar with rust compiler internals but i am totally agree with isHavvy. Btw is there a good documentation of rust compiler or i should just read the code?
Now i see that such a behavior is more convinient but in my case it was tricky to figuring out that shadowed variable borrows until the end of the scope. I am shure that this behavior should be well documented. I am not shure but maybe a some kind of warning about shadowed variables which borrows something or implementing Drop?
Yep!
Knowing the internals of the compiler should not be required to understand how the language works. Having a specification would be nice, but not required or urgent.
... an ORM...
Rust is really really not bad!
This is probably more up-to-date: http://rust-ci.org/projects/#template%20engine
I guess kernel is actually pretty good at scheduling then? 
I'm not sure I follow, sorry; are you proposing a workaround to easily write functions that can receive either `&amp;str` or `String`, or either `Vec&lt;T&gt;` or `&amp;[T]`? That'd be pretty handy, this is one of the wartier parts of Rust in my view.
As others are explaining, learning rust could be helpful in terms of exposing you to new ways of thinking about code. But you're asking specifically if it will help your career prospects. Some employers might appreciate seeing that you are inquisitive, and working on honing your craft by trying new and different languages. That said, rust is still a pre-1.0 language. There are probably fewer than 50 jobs in the entire world that primarily use rust (someone please correct me if you know of an actual number on this). If you want to learn something that will help your job prospects in the short term, rust probably isn't it. 
I do, I think `contains` should perform this check first and foremost (though mark it as `unlikely` if available, for better instructions arrangements).
Is it? I've seen a significant number of companies drool at the performance and resource usage of go to then go back to whatever scripting language they were using because of a lack of libraries, especially ORMs.
His tests are for 1 connection at a time. Therefore the import of scheduling is quite neglible.
My take: If you need an ORM, something's already gone wrong. Just my opinion. I would like to see the web ecosystem develop without one. Then maybe at some point someone will make/port one, then no one will use it. 
This. 
Why? They seriously reduce the amount of code you need to write and handle security for you. What's the problem?
If your hammer is a RDBMS, then by all means, pound whatever nails you have with it. Me, I use relational databases for reporting and ad-hoc querying. I use more suitable databases for OLTP. My (highly opinionated) point was if you need to map an object oriented system into a relational system, you already have two strikes. 1. You're using an object oriented system. 2. You are trying to use a relational database from an object oriented system. 
I agree. It also seems a bit out of date. Maybe someone should offer an updated fork :) 
And? It's what the world runs on. Data comes from the user through my object oriented system and ends up in my relational database. What's the big deal?
It's a theory, still does not translate to real life and its needs.
This problem is called [object-relational impedance mismatch](http://en.wikipedia.org/wiki/Object-relational_impedance_mismatch) (there's also a discussion [at c2](http://c2.com/cgi/wiki?ObjectRelationalImpedanceMismatch)). But it's true that many people work around it. The trouble for me is that in the general case tables represent relationship between objects and not objects themselves. A good modelling in relational terms may be a poor model for objects (or vice versa), and the ORM impose this compromise to the developer.
&gt;libc rustc links against some libc by default. On linux only glibc is supported. &gt;I was wondering if it is possible to access other libraries written in C. Yes. http://doc.rust-lang.org/guide-ffi.html &gt;Is it is possible to use the required C headers (headers included with the library) with the equivalent of an include line? No, but you can use https://github.com/crabtw/rust-bindgen/ to automatically generate equivalent rust files. That being said, bindgen is very buggy and you should manually check if the output is valid. Some C knowledge is necessary. &gt;would it be possible to use the C macros provided in the same way you would with Rust ones No.
Oh I think you're right. It worked for that program specifically, but many programs that need a DB probably wouldn't benefit from being 'scripted' in SQL.
Absolutely. Modern C++ is skating towards where the Rust puck has already gone, so to speak. The concepts around ownership, lifetimes and mutability all apply to C and C++, there just isn't the same support for expressing them explicitly in code and having the compiler check it.
I'd say they'd turn into a big mess.
Which is all nice and dandy apart from the fact that we haven't found a viable alternative.
Err... What? Yes we have. Have you noticed that Rust isn't object oriented? Not in the C++/Java way, at least. When you have no Objects, and you are using a MUCH more expressive language, the need for ORMs really does just go away. And good riddance. Despite the mountains of libraries in the Haskell ecosystem, there isn't a single ORM, because its simply unnecessary. Rust's type system is modeled after Haskell's. I now understand your quote &gt; Which is all nice and dandy apart from the fact that we haven't found a viable alternative. By 'we' you mean you and whatever company you work for. 
rust-bindgen uses the llvm front-end to correctly analyze c code (including macros) I have used it with success in https://github.com/rrichardson/hammer/tree/master/src/bindings/rust which makes wrappers for a rather complex set of includes in the Hammer parser combinator library. (see src/hammerll.rs for the result) As DejanPetros points out, it is a bit buggy. I had to make some minor changes to compile, then I made a few more sweeping changes for ergonomics. 
I don't think this is currently possible in a safe way. You could modify the string (since your struct owns it) and break the iterator. There's a bit of a discussion about it [on the discuss forum](http://discuss.rust-lang.org/t/self-referencing-structs/418). I'm also not sure it can be generally made safe for all variants of the construct. But it might be possible to encapsulate some unsafe behaviors in a wrapper that takes ownership of the referenced value together with the reference, only gives out immutable references to the owned value, and only allows unwrapping of the owned value when no-one else has access to the owned reference anymore.
You are doing good work. Be safe from evil. 
Very interesting! In the `AsVec` destructor, is there any reason why the `Vec`'s `len` and `cap` were manually set, instead of using `mem::forget`?
By we I mean the corporate world. Not a lot of projects done in Haskell or Rust. At this point we may very well treat these languages as academic projects, even though some production code may be written in them. Also, ORMs do much more than mapping classes to tables. They handle connection management, security and all sorts of small things you'd have to manage by hand. Although I assume you would abstract that away to a library and call it something else.
I work for a large (13,000 person) company in Manhattan (finance industry). We use Haskell, OCaml, and Scheme. (and a whole lot of C++ and Javascript :) ) An appropriate DB library will do connection pooling, and it will also provide parametric query APIs to protect you from string injection attacks. I don't think that this falls into the ORM camp just yet. Given such a DB API (which the rust postgres API is close) . It would be pretty trivial to write [serialize](http://doc.rust-lang.org/serialize/) implementations to go to/from SQL result sets and query params. Adding the additional relational features would be a trickier. IMO I wouldn't take it this far. I think SQL is a fantastic, concise, high level declarative language. I would leave the relational logic in SQL, and just provide conveniences for getting your structured data in and out. 
Probably all the 'a can be removed at this point with lifetime elision.
&gt; and Javascript :) What do you use JS for? &gt; I would leave the relational logic in SQL, and just provide conveniences for getting your structured data in and out. Something like iBatis?
Too lazy to google now. It was initially received as mana from heaven, and for someone working in constrained server environments it's definitely good. The problem is the lack if libraries and some have mentioned the awkward type system.
&gt; Separate getter methods for each property would work, but doesn't keep the "ask for many things at once" semantics What if you combine the two approaches? You lose the symmetry, but can get both the efficiency and the convenience: let result = frontend.get_property([GetFrequency, GetModulation]); let frequency: Option&lt;Frequency&gt; = result.get_frequency(); let modulation: Option&lt;Modulation&gt; = result.get_modulation(); Or, if you want more symmetry, switch to a builder-style API: let query = Query::new().query_frequency().query_modulation(); let result = frontend.get_property(query); 
I was able to [remove some of them](https://github.com/mbrubeck/robinson/commit/ffa873e07f7218991692eff69caaaa4f700ce1bd) but it looks like they are still needed in: * Type definitions like `struct StyledNode&lt;'a&gt; { node: &amp;'a Node, ... }`. * impl headers like `impl&lt;'a&gt; StyledNode&lt;'a&gt;`. This is [#15872](https://github.com/rust-lang/rust/issues/15872). * Functions that take multiple reference arguments, like `fn style_tree&lt;'a&gt;(root: &amp;'a Node, stylesheet: &amp;'a Stylesheet) -&gt; StyledNode&lt;'a&gt;` UPDATE: Corrected the description of the third case above.
In a sense the problem is that I'm no sure what exactly I want, it seems to be more about the alternatives being roughly equally...not inviting. But, I guess what I would like to see would be something like this: match frontend.get_properties([SignalStrength, CNR, ErrorBlockCount]) { Ok(properties) =&gt; println!("Signal strength is {}", properties.signal_strenght), Err =&gt; // whatever the error handling would be } ...while still not having to have a huge struct with every field predefined, but that's not really a possibility. Though I guess having a largeish struct isn't necessarily automatically a problem - but still maybe a code smell. The enum way could be either a set_property-looking thing: // The statistics are actually more complicated than just a single number, empty_stats() returns something convenient let mut properties = [SignalStrength(empty_stats()), CNR(empty_stats()), ErrorBlockCount(empty_stats())]; match frontend.get_properties(&amp;properties) { Ok(_) =&gt; (), Err =&gt; // whatever the error handling would be } // Start matching the values let [signal_strength, cnr, error_block_count] = properties; let signal_strength = match signal_strength { SignalStrength(stats) =&gt; stats, _ =&gt; // More error handling } // Et cetera The other enum way would have two sets enumerations, one that has a value field and another valueless ones with a Get prefix: let mut properties = frontend.get_properties([GetSignalStrength, GetCNR, GetErrorBlockCount]) { Ok(properties) =&gt; properties, Err =&gt; // Error handling } In this case, the returned value would be something like Result&lt;Vec&lt;Property&gt;&gt;, so the let destructuring won't work. Otherwise, despite having double enums, this seems in a way nicer when looking at just the function call. Then again, the following could would possibly be some kind of for-match construct, which I guess I would consider even less pretty than the simple matching.
I'm not completely sure, but I take it you'd suggest the "return a big struct" route? I mentioned in my other reply it seems like a code smell to me, but it's not all that strong opinion. Of course having getter methods instead of public members could allow more compact internal representation, but I'm not sure what it would be. (I have to admit I might have a tendency to a form of premature optimization, or thinking too far ahead to see problems that don't even exist yet.)
I'm not normally one to suggest mutable and inout params, but maybe: let mut inout : [Property ..3] = [SignalStrength(empty_stats()), ...]; match frontend.get_properties(inout) { OK([SignalStrength(ss), CNR(cnr), ErrorBlockCount(ebc)]) =&gt; { something_with(ss); something_with(cnr); } Err =&gt; _ } So your get_properties function doesn't do any allocating, it just manipulates each cell and returns back a reference to the one that was passed in. Meanwhile, you should be able to pattern match out the enum params within a slice. 
Probably a dumb or implied question, but did you use the no-mangle directive for Rust so function/struct names don't get modified at compilation? You need that to call Rust libs with Python's `ctypes` for example..
I'm really looking forward to this talk. I won't be able to attend, but I hope the talk is recorded for others to see. All my web development happens in Python, but I'm curious what will be possible in Rust.
It might be interesting to add footnotes where Servo or other browser engines break from the norm (or plan to). Eg mentioning the COW DOM in the part about trees, etc. Can't wait for the layout post :D
I wonder if Rust's macro system and operator overloading would make an ORM more feasible. Go doesn't have much in the way of metaprogramming. Presumably that hurts its ability to have a good ORM.
Well, the interesting thing to me is not scheduling but rather task/thread spawning: it's a userland goroutine in Go but it's a whole OS thread in Rust. Yet that doesn't seem to hurt Rust. I guess Linux is just really cheap at spawning threads!
The fields in a `struct` have their destructors called after the `drop` function has run. It takes `&amp;mut self` so it doesn't have direct control over whether the inner destructors run. In this case, it's easy to stop the inner destructor from doing anything.
I almost let out an eureka-like "Ohhhh!" when I saw that match statement. So far I had only thought of the simple let pattern to extract the individual elements and then tediously matching the elements separately. Being able to match against the specific permutation of variants at once is great! It matches the probable usual use case pretty well, getting statistics or certain specific other properties to monitor the device state, that is. Inouting the values isn't the prettiest thing, but maybe I'm able to live with that. Now I started to think about adding Get-prefixed variants to the Property enum to avoid the default constructing ugliness... but that one I think I should skip for now.
Thanks doener, that's right. I changed the default ephemeral port range to start `net.inet.ip.portrange.first` and `net.inet.ip.portrange.hifirst` at 32768 and now the req/s are 2x higher. I also wanted to set the release delay from 15ms to 1ms, but that had no impact. 
yes; #[no_mangle] extern "C". It does actually work now, (and did some months ago) - its just I've had to do a rather nasty hack of supplying dummy `_Unwind_GetIP` functions manually which I'm guessing will completely break task failure. Something is missing from my linking, or i've got some broken options in compiling the library
&gt; can there stop being a zillion mutually incompatible forks of MinGW plz? I've told you a million times to stop exaggerating. &gt; It's a little frustrating that people keep (apparently) forking MinGW and MSYS and repeatedly changing how they interact both with each other and the rest of the system, without any clear indication as to what's going on, or what they've changed. .. again .. There was only ever one fork of mingw and that was the MinGW-w64 project which is the only way to build native 64bit software with GCC on Windows. Please read my comment here which explains the situation: http://stackoverflow.com/questions/25019057/how-are-msys-msys2-and-msysgit-related-to-each-other/25023611#25023611
Update: I haven't gotten anything on the screen yet (!), so I will continue working on it as a Jam entry to get an extra day. One hazard was getting my head around the OBJ model and how to transform it into a vertex buffer. This problem is now solved by using arrays of ranges that points to other arrays of ranges and so on down to the index buffer.
A minor clarification: {i686,x86_64}-w64-mingw32 are *not* cross compilers in the true sense of the word. They do not link to msys-2.0.dll, they are native Windows programs that generate native Windows programs. They only target a foreign machine if you consider bash.exe to be the OS and since you can use them outside of bash.exe, this isn't enought to qualify them as cross-compilers. FWIW, MSYS2 *does* have cross-compilers where the host is MSYS2 (i.e. they link to msys-2.0.dll) and the target is MinGW-w64, but no one should ever really need to use them (except the MSYS2 project itself). They are a slower due to the POSIX emulation layer.
Does it always have to be about money? Join /r/socialistprogrammers
Sorry, but that's a little too christian-centric for my taste. We should aim at a neutral release date so we don't send out signals that could be misunderstood. /edit: Downvotes? Interesting religious bias in this community ...
I think that this is reasonably well documented in the Rust reference manual: &gt; A task's stack consists of activation frames automatically allocated on entry to each function as the task executes. A stack allocation is reclaimed when control leaves the frame containing it. ... &gt; When a stack frame is exited, its local allocations are all released, and its references to boxes (both managed and owned) are dropped. Given this description, I would expect the variables to be dropped, and destructors run, upon exiting the function, not upon a variable being shadowed.
I had exactly the same problem in my first Rust on Android project, and the way I solved it is here: https://github.com/skligys/rusty-cardboard/blob/master/jni/Android.mk#L11 Android NDK includes source for those functions, they just don't get linked. So I included them in my project as a workaround, and everything compiled again.
thanks 
I'm not Christian, but I do value Christmas as a family holiday. After all, it wasn't actually created by Christians. 
Shouldn't all of those be filed as bugs? Code looks inconsistent this way, they all look like valid cases where the lifetime elision should kick in.
Try making a web app with 50 tables with hundreds of potentially different joins and an automatic admin interface using forms for data validation. With a decent ORM it's doable by a one-man effort in the span of a few months. Without one I wouldn't be touching it with a 10-foot pole.
Most ORMs are built on query adaptors with behaviors similar to that of Linq. Objects are just a nicer way to deal generically with the return types of those data structures.
[Recent job ad](https://jobs.apple.com/search?job=34854355&amp;openJobId=34854355#&amp;openJobId=34854355): &gt; - Knowledge of Haskell, Rust, F#, or similar languages will be useful.
The most common solution here is to just reindex, however, as you say, you can no longer use the nice iterators. let w_id = worldid as uint; let p1 = self.worlds[w_id].pos; for i in range(0, self.worlds[w_id].connections.len()) { let p2 = self.worlds[self.worlds[w_id].connections[i].dest].pos; let dis = (p2 - p1).len_sqr().sqrt(); self.worlds[w_id].connections[i].dis = dis; } Some (very) careful `unsafe` code would work, something like: let (p1, conns) = { let w = &amp;mut self.worlds[worldid as uint]; (w.pos, &amp;mut w.connections as *mut _) }; // this is safe because we only touch the `.pos` field // of each world, not the `.connections`, and so we never // affect this specific `.connections` and thus don't alias // `&amp;mut`s or invalidate the iterator. for cons in unsafe {(*cons).mut_iter()} { let p2 = self.worlds[cons.dest as uint].pos; cons.dis = (p2 - p1).len_sqrt().sqrt(); }
Tough decision! Both versions seem to have their pros and cons, but I'll stick with the first one. Thank you very much for the quick reply!
That explains the lack of activity, thanks. I got an answer anyway, but I'll remember this for next time!
In theory cursors could fix it, if they supported indexing. Presumably you'd be able to access arbitrary indexed elements via a hypothetical `MutCursor`, as long as they weren't the element the cursor was currently pointing to.
There are the Rust developers employed by Mozilla, who are paid to use Rust. Then there are CS professors using it and their student researchers (the only one I know of is [David Evans](http://www.cs.virginia.edu/~evans/), though MIT apparently [used Rust for something](https://github.com/rust-lang/rust/issues/14954)). Practically speaking, that makes ~0 jobs using Rust for anyone already in the industry and not working for Mozilla.
Offtopic: I found myself doing `array[index as uint]` so much I just gave up and started instead to keep all the data I might use for indexing as uint.
Why should I know about the release dates of Ruby? This is /r/rust
Does deliberately offending people for the sake of a gimmicky release date sound like a joke to you? Hell, let's give the 1.0 a nice sexist nickname to make it even more funny!
erm... I use https://github.com/jinzhu/gorm
Looks amazing. Rather sad that I'm over the other side of the world :( (Australia)
SQLAlchemy is an amazing piece of code. Porting it to rust... hmmm...
[Even better](http://www.cwjobs.co.uk/JobSearch/JobDetails.aspx?JobId=60378011): &gt; several years experience with another application or systems language such as... Rust 
You might be the first person ever to offended by Christmas gift
Many people celebrate Christmas now in China and other Asian countries due to western influences, despite not being Christians. So it's definitely impossible to say it's just a Christian thing now.
I think it's pretty obvious that bolting on a static type system on a dynamically typed language is never gonna work out well. Even adding more powerful/strict type system features to (semi-) statically typed languages often fails badly (for example look at the total mess of the Java type system). The C# guys have actually has done a decent job on adding new type system features though. No, the type system is the most crucial part of a programming language, and it's foundation on which to build other features. Creating a new language today which doesn't include the best ideas from Haskell, Idris, Scala, SML etc. (like HKT, type classes (or similar), lambda expressions, type inference, sum types, first class modules etc.) and has a theoretically proven sound type system is just a toy language IMHO and not a viable choice for new software projects (some languages in this category are Go, Dart, Ceylon). Rust is not quite there yet, but it's on the right track and I think it will be a viable choice in the future.
I normally am too. I’ll be back in Melbourne about a week after Strange Loop.
The GitHub username confused me for a second.
There's "glob" imports, and as I understand it, this kind of use case is basically why they're still available (behind a feature gate) despite the fact that they're generally not a great idea (complicates typechecking; potential maintenance problem). &gt; use constants::*; [RFC: Remove glob-imports](https://github.com/rust-lang/rust/issues/11825)
Hmmmmmmmm. I know this is a pretty crap reason but I just don't look like the look of it. And, as [this comment says](https://github.com/rust-lang/rfcs/pull/208#issuecomment-53152354) (I think. I'm really bad at following these types of discussions), it overlaps with as-patterns. Then again I quite like the lisp/ruby way of putting ``!`` on the end of dangerous functions. I think using this for macros is alright though. Also I don't like having "!" for unwrap. I feel like that should be a method, otherwise it's too symbol perl-y. I'd prefer clarity over conciseness. 
At least you are not Groot.
I like the suggestion of 'inherit use' and i wish there was a way of doing the opposite (creating symbols higher in the module heirarchy) - e.g. its' hard to share a load of common uses' across some siblings, because you can't have circular glob imports (a subdir mod.rs might glob use all its' children, but then its children can't glob use that :( ) i generally like the way files are namespaces but sometimes its overkill, because you've also got symbols under types and traits. 
This kind of attitude upsets me &amp;ndash; the anti-sexist/racist/religion/whatever movement is the totalitarism of the XXI century, and it doesn't actually help any cause.
In the conclusion: &gt; Python is a language that suffers from not having a language specification [...] &gt; Future language designers definitely should not make the mistake that PHP, Python and Ruby did, where the language's behavior ends up being "whatever the interpreter does". Have we considered making a language specification for Rust? With 1.0 approaching, it’s not as premature as it used to be. (Edit: formatting)
&gt; match *self { &gt; Person{name: ref p_name, age: ref p_age} =&gt; { When `match` has a single (irrefutable) pattern like this, you can use a `let` statement instead and reduce rightwards drift: ``` let Person{ name: ref p_name, age: ref p_age } = *self ```
(Or, in this case, simply using `self.age` and `self.name` instead of `p_age` and `p_name` works too.)
It's been around for a decade. I don't expect to replace all of it. Also, as I mentioned before. Rust will provide significant type information, which should reduce the amount of wrangling and boilerplate that would need to exist. 
Why not have `@` for attribute and `something!(arg)` for macros/syntax-extension. I think (that is only for me) `println!("Hello {}", "Tim")` look better then `println@("Hello {}", "Tim")` or `@println("Hello {}", "Tim")`. If I understand correctly attributes add metadata to code. Macros transform or generate code. Why unify things that sound so much different. 
&gt; Why not have @ for attribute and something!(arg) for macros/syntax-extension. Second paragraph of 'motivation': &gt; The ! and # notation take up syntactic space that we may want to use elsewhere. For example, RFC #204 suggests using ! for error assertion. Personally, I also find `@println` to be much uglier than `println!`. &gt; I understand correctly attributes add metadata to code. Macros transform or generate code. Only if you phrase it that way. `#[deriving(Show)]` very much generates code.
&gt; Array’s type signature includes its length, but Rust can’t be generic with array’s length. That's a damn shame. From a Rust beginner's perspective, this seems to greatly reduce the attractiveness of fixed-length arrays. Does anyone know what the reasoning behind this is? However, it seems like it should be possible to write a macro that supports converting arbitrary fixed-length arrays to JSON, or am I missing something?
You're right, this is one of the reasons why I'm not really using fixed-length arrays. &gt;&gt;However, it seems like it should be possible to write a macro that supports converting arbitrary fixed-length arrays to JSON That's behind my Rust-fu. If someone could help me with that, it'd be awesome, I'd include it in the blog post part 2.
I really like the `#[]` syntax for attributes... if it goes away I will definitely miss it.
&gt; Does anyone know what the reasoning behind this is? It requires extra type system machinery that we do not have. I forget the exact term.
Yeah, that's what I was doing before I realized that setting `len` was simpler. Note that a zero length vector doesn't allocate any memory, so it might compile down to the same code.
Is it `dependent types`?
I really like this, especially opening up ``!`` for ``.unwrap()``. If prefix-``@`` is a problem, could it not just remain as a postfix for macros? ex. ``println@("Hello {}", "Niko")``, which would also resolve the dislike for attributes and macros being too syntactically similar.
You don't need to go dependent types for parametricy over `[0.. N]`, but you do for `[0.. N + M]`, if that makes any sense. There's a term for what would give us the former.
I think the circular globs are only an issue with `pub use` globs.
Christmas probably has as much pagan-centric origin as it has Christian-centric. Some Christians refuse to celebrate it since many of the symbols of the holiday have nothing to do with Christianity. The December 25 date of birth, the Christmas tree, the 3 kings (technically), the mistletoe, the exchange of gifts... none of them have origins in the Christian texts, but rather originate in pagan traditions. If you really want to be offended by something, I think perhaps you should look for something more convincingly offensive.
Well, I guess it's the price you have to pay when many Rubyists are flocking to Rust. Brogrammer culture and no regard for anything that is not rooted in a western white hetero male culture. I think Rust might become the first language I would not use because of ethical reasons.
Halloween! Why? Because it's two months sooner than Christmas! :-)
Do you really need to extend the type system? I thought the problem was that generics can only parametrize over types and not over values. Something like this does not work currently: fn concatenate&lt;T, M: uint, N: uint&gt;(a: [T, .. M], b: [T, .. N]) -&gt; [T, .. M + N] {...} (This also needs to be able to calculate `M + N` at compile time.)
&gt; Do you really need to extend the type system? I thought the problem was that generics can only parametrize over types and not over values. Right. parameterizing over values would be expanding the type system.
The wait is over! http://jaredonline.svbtle.com/roguelike-tutorial-in-rust-part-3
Rust doesn't have CTFE, so things like `deriving` wouldn't have any place to go. Right?
...oh wait, that won't work. That's the day Martin Luther nailed his 95 Theses to the church door, starting the protestant reformation. Someone might be offended. ;-P
In Ruby, we have an `each_with_index` iterator that returns `[element, index]`. Something like that would make this code much better, but I don't think we have it yet.
The Rosseta Code implementation does not abstract away a lot of details by using `std::cmp::Ord`, they just use generics so it works for any type `T` that is comparable (that is, implements the `Ord` trait). About your code: You should not define every variable in the beginning. A lot of the types can be inferred by the compiler and you are making variables mutable that don't need to be mutable. You can [remove the type annotations and make variables immutable whenever possible.][1] (The semicolons after the `{}` blocks are redundant, I forgot to remove them.) You can then avoid having an `int` variable entirely by modifying your algorithm such that you don't have negative indices. Using `array.swap` avoids the temporary `val` (and is more efficient). If you do all this, you basically get the implementation given on Rosetta Code. [1]: http://play.rust-lang.org/?code=fn%20insertion_sort(array%3A%20%26mut%20%5Bint%5D)%20%7B%0A%20%20for%20j%20in%20range(1%2C%20array.len())%20%7B%0A%20%20%20%20let%20val%20%3D%20array%5Bj%5D%3B%0A%20%20%20%20let%20mut%20u_index%20%3D%20j%20-%201%3B%0A%20%20%20%20let%20mut%20index%20%3D%20u_index%20as%20int%3B%0A%0A%20%20%20%20while%20index%20%3E%3D%200%20%26%26%20array%5Bu_index%5D%20%3E%20val%20%7B%0A%20%20%20%20%20%20array%5Bu_index%20%2B%201%5D%20%3D%20array%5Bu_index%5D%3B%0A%20%20%20%20%20%20index%20-%3D%201%3B%0A%20%20%20%20%20%20u_index%20%3D%20index%20as%20uint%3B%0A%20%20%20%20%7D%3B%0A%20%20%20%20array%5Bu_index%20%2B%201%5D%20%3D%20val%3B%0A%20%20%7D%3B%0A%7D%0A%0Afn%20main()%20%7B%0A%20%20%20%20let%20mut%20x%20%3D%20vec!(3i%2C%202%2C%204%2C%201)%3B%0A%20%20%20%20insertion_sort(x.as_mut_slice())%3B%0A%20%20%20%20println!(%22%7B%7D%22%2C%20x)%3B%0A%7D 
I am all for this if everyone else is :)
steve! of course we have that! It's [`for (i, elt) in xs.iter().enumerate()`](http://is.gd/Odu0Me)
Ah ha! It's hard to find things when you don't know the name. Awesome. OP: Use this. :) It's faster and safer.
&gt; I really don't understand what ethical dilemma you're referring to. Yes, of course you don't. Most people also don't believe that we have a sexism problem in tech - because they are part of the large group that's not affected by this. Yet ask women and transgender people how they feel ... Next time before you deny a social problem exists in tech just check your privileges.
Well, I mean, _everything_ is a matter of time. ;) I'm don't remember if there's someone working on a proposal for this, but I'm leaning towards 'no' for now.
Boy did you miss the point. Just because some random person on the internet posts the word "Christmas" on /r/rust doesn't mean there's any connection between Rust and Christianity. Until you can establish a connection, there's no dilemma. I think perhaps your bitterness is clouding your rational thinking.
`try` inserts a return. How will HKT make that easier? Monadic `do` notation doesn't really work for languages with arbitrary control-flow (well, arbitrary reducible control-flow in this case).
What did the comment say?
I guess it was deleted because I inserted a shortened link to the playpen. Which I now remember the spam filter likes to kill.
I said this: &gt; steve! of course we have that! It's for (i, elt) in xs.iter().enumerate() with a link to the playpen and thus I was killed by the spam filter.
That kind of magic feels like it belongs in a macro. Anyway, you could always do: try!(do { ... }); If you want to abort from the function if there is an error in the do. `?` isn't cleanly overloadable (yet), so I doubt it will scale unless someone comes up with a great way to make it so. Also, I'd personally rather make `unwrap` *longer*, not shorter.
Ahhhh yes. 
It encourages me and scares all together that I can observe so much bike-shedding about how people already get used to some syntax design decisions that are about to be changed. Rust pretending to became very interesting mix after hitting 1.0
Yay! So long, libgreen! And, hello non-blocking and more efficient IO! I'm uncomfortably excited right now.
&gt; &gt; would it be possible to use the C macros provided in the same way you would with Rust ones &gt; &gt; No. Not in all cases, due to hygiene. But in most sane cases (especially the simple ones) you could probably create corresponding rust macros from the C ones. 
can someone explain [missiles?](https://github.com/rust-lang/meeting-minutes/blob/master/workweek-2014-08-18/static-and-const.md)
It's a joke to refer to embedded systems, like the programs that guide missiles.
Haha how strange? Melbourne is starting to warm up. I'm sure you'll be surprised with the weather :)
Of course, if you're really hardcore you can look at the way [std does it using unsafe code](http://doc.rust-lang.org/src/collections/home/rustbuild/src/rust-buildbot/slave/nightly-linux/build/src/libcollections/slice.rs.html#352-393). Of interest is that they don't face the uint/int problem because they bypass all the index bounds checking using ptr::offset(), which takes an int. Also they use proper array shifting functions, rather than manual shifting like you do. Your code also has a bug if you try to make it work for generic elements. If the elements you're sorting aren't Copy, then your shifting function shouldn't compile. `ints` are Copy, though.
This has worse ambiguities with `@` patterns; they are `&lt;identifier&gt; @ &lt;pattern&gt;` and the nested pattern can be a tuple pattern like `(a, b, 1)`, I.e. exactly the same as a macro invocation `foo@(a, b, 1)`.
I actually agree with you, I don't like it either.
There was a proposal, it was postponed for later: https://github.com/rust-lang/rfcs/pull/174
That wasn't the first: https://github.com/rust-lang/rfcs/pull/56
I find the error handling minutes quite hard to follow. Is the proposal really to go with RFC PR #204 and use `!` for `.unwrap()`? It seems incredibly strange to argue that `.unwrap()` is overused/should rarely be used, doesn't sound fail-y enough, etc. and then replace it with something as easy to type/overlook as `!`.
I think it's a conspiracy. four members of the haskell community are constantly watching me on reddit and downvote each my post :)
&gt; I find the error handling minutes quite hard to follow. Yeah, someone in the meeting agrees to write stuff down, and they don't always get it perfect. Nobody is a trained note-taker. :) 
Thanks for taking notes! The community really appreciates it!
I am the one who proposed this originally. But this notation has visual ambiguities with "at patterns". Is `vec @ [1, 2, 3]` a macro invocation or a binding?
Just to confirm, if libgreen is removed will this mean spawning of a bunch of threads Go-style would be inefficient?
Right now the performance of green threads is not much better than the performance of a native thread, so there's little reason to keep it around. So, to answer your question, removing libgreen would not make performance significantly worse than it is today. 
&gt; is not much better It's worse in any vaguely real world benchmark. It's even slower in a tcp server spawning a task per client and writing out "Hello, world!".
A lot of `unwrap` stagments are used to just avoid verbosity, not because they're really needed. I think a lot of them could be eliminated by HKT. And `try!` macro is actually usually used in series, so can be replaced by `do` and `match`stagements (and wrapped into a macro of course, something like `try! { ... }` instead of `do` block). But `f!` and `f?` syntax looks pretty perlish, actually more perlish than `~T` was.
Attributes and macros are different things, I need to be able to tell at a glance which one is which while scanning code.
Many people here in China generally consider Christmas to be Western New Year Holiday, the counterpart to our own Spring Festival. Or Yet Another Lovers' Day, really. It seems that many Japanese/Korean people generally think the same. 
Why? I too thought that people were meant to be discouraged from unwrap()-ing.
A lot of times, the program just can't continue if e.g. an I/O operation, or an array indexing operation fails. Making people write `.unwrap()` everywhere doesn't really help things. We'd like to get rid of implicitly-failing methods throughout the standard library, but there would be an explosion of `.unwrap()` if we did. So we need some kind of sugar. `.unwrap()` isn't evil—it just means that you're either doing something that the type system isn't powerful enough to prove (and if it were it might not be worth going through the effort to prove it), or it's something like a critical I/O operation for which failure is unrecoverable.
More than minutes, just add on top: TL;DR or better: TL;DW;
How does Haskell solve the problem of `.unwrap`? I assume there is a similar problem with Maybe type. 
for what is worth I totally agree with you, also, (I didn't read yet the rfc) but should go on par with `try!` so `!` is getting a specific shape and kind of alert you or the reader on what's going on.
Yep! 
Yes, I think this is exactly what I was looking for! Actually, I really wish we could apply these same concepts everywhere: I have this dirty fantasy that distributed systems should have the same compile-time correctness assertions that Rust provides with multithreaded concurrency: why should multiplexing on a processor have guarantees, but multiplexing on an elastic cloud not have them? Why should memory access have compile-time guarantees, but database access not have them? In principle, these are the same concepts, so why do we treat them so differently in practice? Alas, my utopia.
Getting rid of drop flags and zeroing is another great decision. Hurrah!
Their pattern-matching syntax is nicer, so it doesn't feel as heavy to explicitly handle Maybes. It's also far more idiomatic in Haskell to reach for higher-order functions (map, flatmap) rather than use explicit control statements. They also have `do` notation which makes it nicer to operate 'inside' the monad.
[The patent itself](http://www.google.com/patents/WO2014107545A1?cl=en) is even using the same terminology as Rust: &gt; A language extension that advances safety in system programming by specifying **a lifetime of a reference** The example &gt; public scoped(this) object GetField( ) just seems like a less flexible version of Rust's lifetimes. I.e. that special-case would be written as pub fn get_field&lt;'a&gt;(&amp;'a self) -&gt; &amp;'a object (or avoiding the explicit `'a`s via elision), and the scheme in the patent is definitely a special-case, e.g. they have one lifetime per method: &gt; In order to consume scoped values, a method will mark its parameters or this value as scoped. This restricts the usage of the parameter or "this" to the minimum lifetime of all of the non-scoped input values. while Rust can have as many lifetimes as desired. Furthermore &gt; If the object has no scope associated with it, then the access to the returned value will likewise be unbounded. seems to just be a version of our `'static` phrased in a more complicated manner (as a lifetime, our `'static` is fairly normal, representing the global scope); although they are presumably to be working in the context of a GC'd language, so non-globals can be `'static`.
&gt; we need some kind of sugar I don't see how that follows. Using symbols makes this more difficult to find and, in my opinion, a lot uglier. I also think it's sort of "magic". 
Such patents shouldn't be accepted. Patent review process allows public comments. Can someone more literate in english write about prior arts? Or at least should someone from U.S. contact EFF (https://www.eff.org/patent-busting)?
the ones I wanted to read were very readable. I'm almost always impressed by the transcripts.
I think you can write just `Decodable::decode` instead of `|decoder| Decodable::decode(decoder)`. It might be less regular or less readable, but it's logical to be able to skip the trivial argument re-application -- decode already is a function you can pass.
Another question I had. For a relatively complicated value, where you might forsee possible more efficient data packing for serialization in the future, would you use a version field in the struct serialization?
It's not really a 'joke' (at least not a Rust specific one), it's a somewhat commonly used as a generic "code should be bulletproof" object. Not the best choice, but it's what people seem to use. *shrug*
Yes, I'm doing it both ways. I'm using the function passing in the array example.
I haven't seen that before. The old anymap was a neat hack but this is actually great.
I know that .NET is using assembly version + assembly name when doing binary serialisation, assembly being a unit of compilation + distribution. If these don't match, an exception is thrown. So on one hand it's possible to include the version field. OTOH, this binary serialization is completely opaque and can't be tweaked to reflect the data changes. JSON decoding can be changed easily by a developer, so one can always adapt the deserialisation in the future. I think in the end the answer 'it depends', as always :)
I've trod this ground in the other thread but I may as well tread it again. I think Rust has a pretty good density level. By this I mean it allows you to write code short enough so you can keep lots on your screen and in your head but it's verbose enough to be understandable at a glance. Don't know what ``unwrap`` does? Well it's easily googleable. This is not the case for ``!`` and ``?``. I don't think fails should be made easier to type or easier to miss. I don't think more symbols are the way to go. I can cope with the ``!`` on the end of macros because it's basically part of the name of the macro - the ``!`` on the end doesn't actually do anything other than tell you it's a macro. This doesn't seem to be the case for the change to ``unwrap`` Anyway, lifetimes. I think removing the ``'`` on lifetimes would be an ok thing to do, especially for syntax highlighters. It's not something that really bothers me when I read rust code but I can see why some people don't like it. Leaving a lifetime with no symbol makes it fade into the background a bit, but I wonder if this isn't actually a bad thing. Do people often look at the lifetimes in function signatures or is it something they just put there when writing the function to appease the compiler?
What happened to "Rust has too many sigils"?
WIth regards to lifetime syntax, I think fn foo&lt;lifetime a&gt;(arg: &amp;(a) Foo) -&gt; &amp;(a) Bar; or fn foo&lt;scope s&gt;(arg: &amp;{s} Foo) -&gt; &amp;{s} Bar; or one of the other two combinations (`lifetime` vs. `scope`, `()` vs. `{}`) would be nicest, if there's no grammatic ambiguity. (The braces or parentheses syntax would only be for the built-in reference types, for user-defined types it would be `Ref&lt;s, T&gt;` as today, just minus the `'`.)
It's not a sigil if it's postfix and doesn't denote a type! It's just an operator!
I've been wondering why not using numbers for liftimes? That way you can make a clear disctintion about it being different from a type and you don't need a sigil (as I think numbers next to &amp; are different enough to be clearly distinguishable). So, instead of: fn foo&lt;'a,T&gt;(x: &amp;Foo, y: &amp;'a Bar) -&gt; &amp;'a int { ... } you have: fn foo&lt;1,T&gt;(x: &amp;Foo, y: &amp;1 Bar) -&gt; &amp;1 int { ... } You can use 0 for static lifetime. Some more examples (from the lifetime elission RFC): fn args&lt;1, 2, T:ToCStr&gt;(&amp;1 mut self, args: &amp;2 [T]) -&gt; &amp;1 mut fn new&lt;1&gt;(buf: &amp;1 mut [u8]) -&gt; BufWriter&lt;1&gt; impl&lt;1, 2&gt; Reader for (&amp;1 str, &amp;2 str) { ... }
I feel like having ``0`` as static is a bit easy to miss. 
You have this on the bottom of each page.
&gt; an I/O operation Bring down the entire application because you couldn't open a file? &gt; array indexing operation fails Array indexing is rare. Make it return a `Result`, put a `?` after it and call it a day. &gt; We'd like to get rid of implicitly-failing methods throughout the standard library, but there would be an explosion of `.unwrap()` if we did. Why isn't it going to be an explosion of `?/try!`? No other language I know of makes contract violations so sugared (maybe aside from Swift, but that language has been around for a few months... it seems crazy to borrow untested things like this from it). Usually they use something long like `assert` and then argue strongly how you shouldn't abuse contract violations to report recoverable errors. Adding the `!` sugar would encourage contract violation abuse. The decision to use failure shouldn't be "I don't want to recover from an error because the syntax sucks", it should be "I don't want to recover from an error because it is a legitimate contract violation, and/or I *can't* practically recover from it".
I would say implement HKT and UFCS and comeback and clean everything in a nice and elegant manner, even if it means delaying 1.0 by few months.
Rust's generics system may be extended to support integer constants in the future, types like C++'s `Array&lt;4&gt;` can be a thing. So using numbers for lifetimes without additional sigils is not a good choice. And if additional sigils have to be used, what advantage do numbers have? 
every time i think "maybe i'm being too hard on ms, maybe they're better now", crap like this pops up.
`f!` is exactly what we currently have for macros though.
How is that the opposite? In a language with exceptions, `catch` catches the exception and then does something with it. In this case, propagate it further by returning the `Err`.
You can use mutable references for sharing (i.e. pass `&amp;mut rng` around). Rust makes sure that your mutable borrow can only have one owner, so you are safe from race conditions.
I see that now!
Well, if there are more changes coming, they have to come ASAP, so that there can be enough time for that polish process.
Not actively.
Could something like this be implemented as a compiler plugin? http://doc.rust-lang.org/rustc/
I was more talking about pattern matching being integrated into function definitions, for example. When you combine that with `let .. in ..` and `where` it becomes pretty slick, and really cuts down on the rightward drift.
Yeah. I think these are problems which we should try to fix, as much as possible, instead of accepting them as fait accompli. `if let` helps. We should also add `let`..`else`, and early return from any block, and we should think about better syntax for HOFs as well (perhaps like the old `do`, perhaps something different). Curried functions might be tricky, but not impossible, composition operator likewise. As for `do` notation... as I wrote on the RFC, instead of some kind of `do` notation for the `Result` monad, which seems difficult to integrate well with the rest of the language, I think it would be a better idea to integrate the features of the `Result` monad directly into the language itself (the so-called "ambient monad"), which, as far as I can tell, would be straightforward.
&gt; it's that its legitimate use cases should be relatively rare Disagree. We observed that when moving methods in the standard library to not fail so much, `.unwrap()` appeared all over the place. This is supported by data. &gt; Index out-of-bounds operations are bugs and should be non-existent in battle-worn code. That argues *for* `!`. Currently lots of methods in the standard library implicitly fail. We want to move more methods to not implicitly fail, but doing so was observed to cause `.unwrap()` to appear *everywhere*. &gt; I/O failures are much more common but a lot of systems (webservers, dbs, etc) can't just crash when they happen I'm talking about I/O failures like "couldn't set environment variable" or "couldn't print to screen". There's not much of a point in writing robust error handling code for those; it's just noise. &gt; The problem with unwrap isn't that it exists, it's that it's the easiest possible thing to reach for. Bounds checking failures are not in the same category as errors you really want to handle. &gt; But every unwrap you write for expediency is a bomb you have to remember to go back and defuse. That's not what `!` is for. It is for the errors that are "bounds checking errors" in nature, not the errors you really want.
We have pattern matching in function definitions. We just don't have *refutable* pattern matching in function declarations.
It's actually a reference to the real reason SPARK (the memory-safe dialect of Ada with no allocation) was created—avionics systems for the U.S. Department of Defense. So it's actually reality. But you're right that it was in poor taste to make light of it; I apologize.
Currying and the composition operator are pretty hard, because existential types come with performance costs in a systems language (i.e. you have to box). The current unboxed closures proposals don't allow you to return them without boxing, because you can't name the type. There may be solutions for this, but it requires a lot of thought and isn't simple.
This is a horrible example, but: foo :: Maybe String -&gt; String foo (Just x) = ... foo Nothing = ... fn foo(x: Option&lt;String&gt;) -&gt; String { match x { Some(x) =&gt; ..., None =&gt; ..., } }
Right, that's what I mean by refutable pattern matching.
Ah yep, that's what I meant too when I wrote, "...refutable pattern matching that is limited to the `match` construct..."
Right now there is no official book in the works for the 1.0 timeframe and I'm not aware of any books in progress at all (I'd love to hear otherwise though). All the people most qualified to write a book are occupied working on Rust. I hope that after 1.0 we may be able to collaboratively build something like 'Effective Rust'.
Rust's non-blocking IO seems slower than the blocking variant. And actually Rust used to do non-blocking IO only. The mailing list archive has interesting discussions on changes to the IO subsystem.
Not really. The semantics of the language need to change. You might be able to get something limited, but it'd only be valid where macros are allowed.
I'd be interested to see the data. The vast majority of `unwrap()`s that I see in just a quick spot check are in tests. Even if `unwrap` *is* used all over the place, that doesn't necessarily negate the point, b/c it doesn't necessarily follow that all of the usages are justified. A big part of the critique here is that `unwrap` is overused b/c right now it's the easiest thing to use. &gt; That's not what ! is for. It is for the errors that are "bounds checking errors" in nature, not the errors you really want. What it is intended for and what it is actually used for in practice are two different things. One of the arguments for killing `~` was that it was enticing sugar that caused newbies to allocate all over the place; `unwrap` already does and `!` would further cause a similar issue for Option handling. One of the refreshing things about Rust is its eyes-wide-open philosophy about developer fallibility. I don't understand how you can take such a strong stance on memory safety but then advocate for a footgun like `!`. 
Well that's true. I'd like to see them just so I have something to do on a rainy Sunday to be honest! :)
use protocol-buffers (or other alternatives)
Is M# a microsoft product? It says in their website: "M# is a product of Geeks Ltd , a software house based in London, UK. All rights are reserved."
The patent itself says "Assignee: MICROSOFT CORPORATION". Seems like Geeks Ltd is just a "[Microsoft gold certified partner](http://www.geeks.ltd.uk/microsoft-partner.html)", and presumably some of the people involved in these patents work for them, but the patent doesn't mention anything that hints at that.
Nice! Sounds like it would be nice to have a more general code-generating mechanism in Rust. As far I understand, this can only be used once and blocks for example the possibility to actually implement the “real” `Encodable`-trait for `Document` or any of its fields.
The abstract return types / unboxed trait objects proposal should make it possible to express these without boxing, no? (Of course, we don't have that yet, but we want to, at some point.) I think we're basically in agreement. Not easy, but not necessarily impossible.
I'm not sure how I feel about the trend of using Encodable to implement things that have nothing to do with encoding.
It's not your fault. It's just depressing times right now.
Right, it seems like the Encodable trait was repurposed a bit, and could be very unclear if you didn't look into the definitions.
The name of this project makes me so happy. Technically I've also heard that it's pretty spectacular, but I haven't looked at the code yet. From the readme I see that is designed to be a general purpose tool, with *a C API*. This may be the first major Rust library designed for embedding in arbitrary languages.
Would it be generic enough that it could be included in the basic Rust distribution, and perhaps be used as the basis for `Encodable` itself?
&gt; you just need to squash the error and go on with your day. I... don't see how bringing the entire application down is going on with your day. The latter two in particular, I'd rather ignore with an `.ok()` method call than unwrap them with `!`. &gt; Because writing your programs like that can be annoying. In my opinion, the goal of this endeavour should be to fix any and all annoyance. If you're implcitly admitting `Result` is a failure in terms of ergnomic recoverable error handling, then add catcheable expections. In particular, Rust's move semantics will make it work better than C++ because in Rust you could require `try` to take a `OnceFn + Send`. &gt; Every language with exceptions does. Every language with exceptions has them catcheable. And either way, I don't agree... to take D for example (as it has non-cacheable 'contract error' exceptions, e.g. from bounds checking), it uses `assert(expr)` to launch an unrecoverable error, which I take to be the equivalent to Rust's intended usage of `fail!`. Other languages, in my experience, require some sort of `throw`/`raise` keyword.
Yes, that's what I mean by opposite. This macro catches an `Err` and propagates it further by throwing an exception.
What other cross-language HTML parsers are out there, and how do they compare to this one?
Those are known as phantom types, yes?
Call me suspicious, but I can already see in 10 years Microsoft contacting big companies using future OS projects written in Rust and asking for royalties based on these patents. I really hope someone in Mozilla will give them a polite call now to stop all this nonsense.
A "downside" of me being employed by Mozilla to write actual documentation is that I don't have the time to write books. The good news is that everyone gets what I write for free! For example, my new Guide is 88 pages when rendered as a PDF...
The Validator.nu HTML5 parser is written in Java, but it is [transpiled to C++](http://about.validator.nu/htmlparser/) and used in Gecko, making it kinda "cross-language." I seem to recall Henri was also working on transpling it to Rust for use in Servo at one point, though I think that project was never finished.
Yes, sort of. These types *can* have runtime representations and be used elsewhere - you could also have UserID and LinkID be regular newtypes and be Assoc'd with themselves, if you wanted to.
Noted. This seems like reason enough to avoid globbing, convenient as it seems for my use case.
Maybe then change "@" in "at patterns" to "at" or something similar (use some plain english word instead of symbol)? Macros would be used much more often then this feature, so probably it is better to leave "@" for them.
I just want to say that I'm really excited about this RFC. If Rust wants to compete for performance with C++ it needs to get rid of all runtime checks.
What happens if you forget the call to `.root()`? Is this enforced at compile time?
Ohh... That makes more sense. Any links to the Microsoft language? 
I believe that's what this part is explaining: &gt; We also implement the Deref trait for both Root&lt;T&gt; and JSRef&lt;T&gt;. This allows us to access fields of the underlying type T through a Root&lt;T&gt; or JSRef&lt;T&gt;. Because JS&lt;T&gt; does not implement Deref, we have to root an object before using it. So you can't really do anything with a raw Js&lt;T&gt; because it will error when you try to dereference it, then you know you missed a root() call. 
Nothing official yet. All that we know is some Microsoft developers [bloged about](http://joeduffyblog.com/2013/12/27/csharp-for-systems-programming/) a low level C# that should be used for low level task like future versions of Windows.
So it's basically a book already?
Lots of the changes are needed to get our APIs in order for 1.0. aturon has done a great deal of work identifying the trouble areas we have, and lots of them could be fixed by adding a feature our two. It's either that or have large swathes of the standard libraries marked 'unstable' at release.
/u/pcwalton has done some initial work on one: https://github.com/pcwalton/rustfmt
So as to avoid this game of Reddit tag, what's the best way to contact you further?
Surprised this doesn't build on the existing `rustc --pretty normal` mode. That seems... fairly close to formatted, give or take some comment placement or eager alignment-instead-of-indentation spacing.
Right; Oilpan is mentioned in the blog post. The difference, of course, is safety :)
If it's just an optimization, you can't do interesting things like have function calls in `static`s.
BTW, just hit a problem with my approach. Whenever I try to use HashSet::insert(), it all crashes with stack trace. So obviously something is wrong with unwinding code. I/DEBUG ( 282): #00 pc 001992d8 /data/app-lib/com.example.native_activity-1/libnative-activity.so (_Unwind_GetLanguageSpecificData+8) I/DEBUG ( 282): #01 pc 00183dbc /data/app-lib/com.example.native_activity-1/libnative-activity.so (__gcc_personality_v0+56) I/DEBUG ( 282): 477fbd24 47616c20 /data/app-lib/com.example.native_activity-1/libnative-activity.so I/DEBUG ( 282): 477fbd2c 47616b14 /data/app-lib/com.example.native_activity-1/libnative-activity.so I/DEBUG ( 282): 477fbd44 476932d8 /data/app-lib/com.example.native_activity-1/libnative-activity.so (_Unwind_GetLanguageSpecificData+8) I/DEBUG ( 282): 477fbd4c 4767ddc0 /data/app-lib/com.example.native_activity-1/libnative-activity.so (__gcc_personality_v0+60) I/DEBUG ( 282): 477fbd54 47614eb8 /data/app-lib/com.example.native_activity-1/libnative-activity.so (rust_eh_personality) I/DEBUG ( 282): 477fbd60 4761e0c2 /data/app-lib/com.example.native_activity-1/libnative-activity.so I/DEBUG ( 282): 477fbd7c 47691f34 /data/app-lib/com.example.native_activity-1/libnative-activity.so I/DEBUG ( 282): 477fbd88 4761e0c4 /data/app-lib/com.example.native_activity-1/libnative-activity.so
joined
jmatthews [at] mozilla.com
`rustc --pretty normal` is really broken and this is to *replace* the pretty printer in the first place.
No need for a macro, you can do this: extern crate serialize; use serialize::json; fn main(){ let numeric = [3.14f64, 1.5, 0.4]; println!("{}", json::encode(&amp;numeric.as_slice())); } Prints: [3.14,1.5,0.4] It's true you can't serialize the fixed length array, but you can get it as a slice at no cost and serialize the slice.
you guys are amazing!
The big decision here likely to make many people happy is the merging of the [if let RFC](https://github.com/rust-lang/rfcs/pull/160).
Relevant issue: [#2774](https://github.com/servo/servo/issues/2774).
Ah, I missed that. Thanks, that makes sense.
On the name `push_all_move`, I think it should be simply `push_all`. (It is one of three remaining uses of `move` in the stdlib, others being `move_iter` and `move_from`.) The single element version is named `push` and always moves the argument, so why not using the same convention for `push_all_move`?
AWESOME!!
https://github.com/rust-lang/rust/pull/16657
Cool. So, what are you writing now? :-)
The question was about rust's serialization traits though.
Not discussed: What you can do and not do in the serialization trait impls and still have valid JSON output.
I'll search for those! If you have any particular links let me know!
Studying for an exam, will read it tomorrow evening! Thanks :D
The team is holding off on it before 1.0 - it's a tricky feature to implement correctly, and there are lots of other fish to fry right now. But there is definitely interest. I would love it!
What if you have multiple Option values to match before proceeding? The following results in two indent levels, but perhaps an extension to `if-let` syntax could take care of the two matches in one indent level... if let Some(x) = foo() { if let Some(y) = bar() { ... perhaps something along the lines of, if let Some(x) = foo() &amp;&amp; Some(y) = bar() { ... 
yup. its hard , for example to automatically share with all siblings (e.g. directory root `use *'s` it's files, and each does use `super::*`). When you have struct modname::ModName and most code is methods (namespaces under traits/structs), the deep namespacing gets extraneous, IMO.
I suppose that using a tuple would do the trick. if let (Some(x), Some(y)) = (foo(), bar()) { // ... } Already works in `match`, so...
I really hope that Mozilla does something about this. I hated Microsoft before, but now. .. Rage. 
Some neat stuff here: https://github.com/kmcallister/html5ever/blob/master/src/tokenizer/mod.rs
Regardless of how it is implemented, function calls aren't allowed in statics, and adding that would change the semantics of the language (my original point)
Piston always could use some help. :-) https://github.com/PistonDevelopers
+1 OP, You can normally find most of us on Mozilla's #rust-gamedev IRC if you want to jump on and chat :-)
I think rust is more challenging to format than go, but still the benefits of having a good standard formatter would be enormous.
Piston was high on my list after Manishearth recommended it to me, yeah :)
There's a lot of repos there and some of them are empty. Are these just things people are planning to do and haven't had time for?
Yes. 
On one hand this is good news that Microsoft is taking a serious look at multi-core programming. I'm trying really hard to be glass half full here.
I looked over and improved on the Python implementation: [now at 530KB](https://github.com/huonw/unicode_names/commit/ad72806f022b2717fcf938ac611a6793f34f6054) (the Python tables are about 570KB by my measurements).
Is MS known for being a patent troll?
Not sure if sarcastic. Yes, but it doesn't tend to troll FOSS projects.
This has already been posted here and had discussion. Its not necessarily off topic either.
Was being serious.
Uh, [`matches!()`](https://github.com/rust-lang/rfcs/pull/163) was mentioned in the agenda but not discussed.
&gt; if x == y &amp;&amp; let Some(w) = z { This is definitely not allowed. &gt; It seems to add a bunch of inherent complexity by allowing creation of variables on what should be essentially a boolean expression, Boolean expresssions are unaffected. `if let` is a separate construct from `if`.
I would have much preferred OP just link the D forum to the original post.
Even companies who has not sued anyone yet can change their mind anytime, unless they do an official statement they give up pursuits on the patent. And Microsoft actually use his patents on FOSS projects users. Microsoft collect much more money using his patents against android devices manufacturers than selling his own devices. So it is a already a real problem. 
IMO the cases you rise should just not compile. 
I don't believe you can currently change how a Vec is allocated. That looks like a part of [#12038](https://github.com/rust-lang/rust/issues/12038). You can, however, just use the malloc function from [the libc crate](http://doc.rust-lang.org/libc/index.html) to allocate memory like you would in C. If you need to work with that memory as a slice before passing it to your C code, you can create a [CVec](http://doc.rust-lang.org/std/c_vec/struct.CVec.html). Note that CVec doesn't support reallocating, so you can't push items onto it or pop items from it.
The current idiom: unit-style tests go into a submodule of each module. You basically add #[cfg(test)] mod test { #[test] fn test_eq() { assert!((eq(&amp;"".to_owned(), &amp;"".to_owned()))); assert!((eq(&amp;"foo".to_owned(), &amp;"foo".to_owned()))); assert!((!eq(&amp;"foo".to_owned(), &amp;"bar".to_owned()))); } } To the bottom of each file, with the tests for each file. Then, for more integration-style tests, you make files in `tests`, organized however you want. The main file is `tests/lib.rs`. I guess if you have a ton of unit tests, either the file is gonna be big, or you do like every submodule: break it out by moving it into a subdirectory.
I'm not aware of anyone working on any of them. 1.0 is 'by the end of the year,' no hard date.
Is there a reason if let couldn't be implemented as an ordinary macro? ETA: the RFC says "This could plausibly be done with a macro, but the invoking syntax would be pretty terrible and would largely negate the whole point of having this sugar." but it seems as if a macro that allows iflet!(Some(x) = f() { success code here }); and iflet!(Some(x) = f() { success code here } else { failure code here }) is fairly simple? I suppose it would become more complex if you wanted longer chains, but I assume still totally do-able and this invoking syntax doesn't look very bad---no worse than the average rust macro.
I think it is more accurate to say that we plan to release a "release candidate" around the end of year, with the final final release to follow shortly thereafter.
Yep, especially with tab/space formatting around structs etc...
The macro is a squashed name, an extra three characters, and feels cramped and noisy on the top line. It's also a little jarring to see the open parens after something named 'if' but no closing parens around the conditional before the brace. 
Ok, but it's totally possible to have underscores in macro names and write if_let!, and require the invocation to be if_let!((Some(x) = f()) { ... }) is it not? Maybe the double (( after the bang is also jarring but it seems weird to alter the grammar of the language---when it already has macros---to avoid a few characters.
Fair enough!
So, let's keep [this](http://www.reddit.com/r/rust/comments/2dg8qm/dont_feel_the_need_to_break_down_my_project/) in mind. What you're saying is that if I move my tests into `tests/lib.rs` the compiler will magically see all the private code I have in my `src/lib.rs`?
Oh, forgot the link! https://github.com/pistondevelopers/hematite *Edit: The pull request https://github.com/PistonDevelopers/hematite/pull/72
None of it really does; Rust gives you the choice between boxing and unboxing in all circumstances, so you don't have to choose between language features depending on which you want.
How is he getting the same exact worlds? Is he building them manually or can his implementation able to read Minecraft's map data? Looking incredible by the way.
Hematite (on eddyb's minecraft branch) can read the Minecraft world format. This gets you the blocks that are stored in the format, but not the procedurally generated ones. It also opens up in the same camera location.
Which you just merged, thanks!
Also Rust doesn't really have a GC (yet)
It's not 'magic', exactly, it's just Rust's privacy rules. But yes, a `tests/lib.rs` should be the same. You'll just want #[cfg(test)] mod test; in your `src/lib.rs` in that case, like any other module.
IIRC, it was just mentioned as being kinda vaguely similar to `if let`, but we didn't get to talking to it. We try to pick too many RFCs, so we can fill the whole hour, and some get bumped to next week.
Congrats. https://github.com/rust-lang/rust/wiki/Note-core-team needs an update then.
I'm using cargo now, so if the cargo package is a library, I put all tests in the `tests` directory where I put them in different files named for category of tests. These do of course just use the public API, but it's appropriate enough for me so far.
I have no clue who you are Aaron Turon, but congrats, and keep up the hard work! It's appreciated.
What exactly is the goal of Hematite? Is it to render still lifes of Minecraft worlds? Is it to completely replicate all of Minecraft?
Is huon (/u/dbaupp) part of the core team? I know he's really big in the community, but didn't know that. Is he the only member not being paid, because he doesn't work for Mozilla? Does he work for Mozilla?
Yes, yes, no. :)
Any instructions for getting it to run?
Well I hope you have a super easy and super high paying job, that'll make me feel better :)
Would be pretty cool if we could somehow extend the macro invocation syntax to allow the macro to take two token separate token trees, the `})` at the end of this sort of thing always seems like a hack. Like, allow if_let!! ( (Some(x) = f() ) { }
I'm studying, so not high paying. (Sorry! :P )
Looking good! Very very similar only thing slightly different now is the amount of shading across blocks and where it starts (could just be how you handle ambient light and day/night being different)
This thread has been linked to from elsewhere on reddit. - [/r/VoxelGameDev] [Hematite vs Minecraft 2 - A minecraft clone in rust-lang \[/r/rust\]](http://np.reddit.com/r/VoxelGameDev/comments/2ersjy/hematite_vs_minecraft_2_a_minecraft_clone_in/) *^If ^you ^follow ^any ^of ^the ^above ^links, ^respect ^the ^rules ^of ^reddit ^and ^don't ^vote ^or ^comment. ^Questions? ^Abuse? [^Message ^me ^here.](http://www.reddit.com/message/compose?to=%2Fr%2Fmeta_bot_mailbag)* 
See https://github.com/PistonDevelopers/hematite/issues/63
I started this project originally because there was an article about how to write a "Minecraft clone" in 500 lines of Python. My intention was to replicate the Python clone. Then eddyb decided to join... I think this was the last time we had a goal. Hematite is completely out of control! ;) I will try to refactor out things that are useable elsewhere. We already got a 3D camera and a FirstPerson controller thanks to Hematite.
I published this list in June: https://mail.mozilla.org/pipermail/rust-dev/2014-June/010139.html. It pretty much all still applies though there are some existent projects tackling some of these areas.
You're looking for http://www.reddit.com/r/playrust
I'll ask my manager if I can get a room in the CS building at UW. If this is possible, would you be interested?
Practically speaking there's currently no difference between the 'C heap' and rust heap as far as I'm aware. Box&lt;Vec&lt;T&gt;&gt; is a heap allocated block that can be passed to C. The thing to understand is that Box&lt;T&gt; is a *T; so foo:Box&lt;Vec&lt;T&gt;&gt; is equivalent to the C: struct Vec { len: uint, cap: uint, ptr: *mut T } struct Vec **foo; So you can't simply pass the pointer to C and then use foo[5]. The easiest thing to do is pass the entire Box&lt;Vec&lt;T&gt;&gt; to c as *mut c_void, and pass the data pointer separately: extern crate libc; use std::raw::Slice as Slice_; use std::mem::transmute; use libc::c_void; fn main() { let foo:Box&lt;Vec&lt;uint&gt;&gt; = box Vec::with_capacity(10); unsafe { // fp is now equiv of a (*uint) calloc(10, sizeof(uint)) // However, don't go calling free() on it. let fp:*const uint = transmute::&lt;&amp;[uint], Slice_&lt;uint&gt;&gt;(foo.as_slice()).data; // vp is a void * with leaked memory in it; you'll have to manually clean // it up later using read() to deallocate the memory block, or transmute() // it back into a Box&lt;Vec&lt;uint&gt;&gt; let vp:*const c_void = transmute(foo); } }
1) this patent is an application its not final, needs to be reviewed and accepted. 2) if it gets accepted somehow, I'm fairly sure Mozilla and their legal team will help out, because the patents are BS.
Great list, lots of good projects here. Will definitely keep this bookmarked! (also, woo, my project made the list!)
If you have a file `foo.rs`, then you could add the lines #[cfg(test)] mod test; And move all the **unit tests** into a new file `test.rs` next to `foo.rs`. Integration tests (in `tests/*`) would still have to obey the privacy rules. (There's lots of good blog posts out there about why you shouldn't test private methods, too).
I like the efforts you're making. If I ever allocate the time, I'd love to help out with a general purpose, open source Rust voxel engine. I've already been playing around in that area.
You can pass the pointers to C, but you *cannot* free the pointer in C (at least, you can't call the normal `free`), since Rust is using a different allocator by default. (And vice versa; you can't free a C pointer using Rust's default allocator.) BTW, the correct way to get a `*` pointer to the data of a vector/string/slice is via `.as_ptr`. `transmute` should be a last resort. &gt; using read() to deallocate the memory block What is `read` doing here?
If anything, I think the slight differences in shading are in fact better than Minecraft. Just a little bit of work on the sky and fog and it'll be very hard to tell the difference.
Source?
Minecraft world files are actually fairly easy to read. I wrote a C# clone a couple years ago. There's some documentation floating around somewhere.
Can you render water yet? When you get there make sure to render a waterfall in front of a lake. Minecraft does this funny thing where you can't really see that there's a waterfall in front because it merges the transparent tiles together... or something. It's weird.
 pub fn free&lt;T&gt;(length:uint, value: *mut T) { for i in range(0, length) { unsafe { let tmp:*mut T = value.offset(i as int); read(tmp as *const T); &lt;----------------- This is a required step to avoid leaking memory. } } unsafe { let vp:*mut c_void = transmute(value); libc_free(vp); } } (ie. read an unsafe pointer in as T and discard the result, resulting in it being dropped)
Yes! Definitely!
Rendering multiple layers of transparency is a surprisingly tricky problem. There are several methods, but they all have issues. Games with hand crafted worlds put restrictions on level design to mitigate it, but in a procedural or modifiable world, you can't get any guarantees about what will be in the world. The simplest thing to do that's not totally broken is to render all the transparent stuff after all the opaque stuff, and then keep only the closest transparent pixel, blending it with whatever opaque voxel is behind it. But if you have a waterfall in front of a lake, you'll only see the waterfall where they overlap. More advanced things are possible, but everything costs GPU cycles and at some point you have to just live with it. 
Others discuss but don’t take decision?
Unit testing is also about testing private methods. Except in my case those tests are starting to get pretty complex. But yes, love your answer.
The region files are the most complicated as it requires almost a pseudo file system, but the chunks are pretty easy to read.
&gt; but I'm not sure if all of the libraries it depends on are. that doesn't matter, it's all boils down to machine code at the end of the day ;P
 warning: initializing 'char *' with an expression of type 'const char [27]' discards qualifiers [-Wincompatible-pointer-types-discards-qualifiers] char* main = "usually a programming blog"; ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
Looks really nice! Is the shading precomputed or online?
Online, using a simple algorithm based on voxel adjacency. See https://github.com/PistonDevelopers/hematite/issues/51 for links.
https://github.com/PistonDevelopers/hematite/
Hematite appears to rely completely on Piston, which in turn aggregates everything you could ever want in a game engine: rust-graphics, rust-image, rust-sdl2, rust-sdl2_mixer, rust-sdl2_ttf, glfw-rs, gl-rs, hgl-rs, and cgmath-rs. A bunch of those are just wrappers around (proven and supported) C libs. I'm not a Rust fanboy by any stretch, but I have to admit: between the quality that Cargo brings to the table plus a rich set of solid libs integrated into a core engine - it's kind of impressive.
Maybe it'd be worth posting some of the easy bugs to [openhatch.org](https://openhatch.org/). I'm not a massive fan of the website myself but people from /r/python and /r/haskell sometimes direct people there when they are looking for bugs. I don't know how many people actually use it though so it may be a rubbish idea. Just a thought, anyway
Valid C89 unless you write through that pointer (which is undefined). Invalid C++ (and I think invalid in C11). I'd worry more about the fact that 'main' is not int() or int(int, char*[])!