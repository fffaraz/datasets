What makes you think this isn’t useful for function arguments? fn foo((Ok(x) | Err(x)): Result&lt;Bar, Bar&gt;) { ... }
Thanks! The relevant bits where your feedback was useful can be found at: [https://github.com/ChosunOne/merkle\_bit/blob/6c06f95f2ed848ef24713358ddb3aaf4334837d1/src/merkle\_bit.rs#L229](https://github.com/ChosunOne/merkle_bit/blob/6c06f95f2ed848ef24713358ddb3aaf4334837d1/src/merkle_bit.rs#L229) and [https://github.com/ChosunOne/merkle\_bit/blob/6c06f95f2ed848ef24713358ddb3aaf4334837d1/src/merkle\_bit.rs#L376](https://github.com/ChosunOne/merkle_bit/blob/6c06f95f2ed848ef24713358ddb3aaf4334837d1/src/merkle_bit.rs#L376)
The compiler accepts and respects multiple non-conflicting `#[repr]` annotations, so [you can specify what you need]. In this specific case, you already have align(4) on any platform that prefers to align `u32`, including x86. x86 CPUs may penalize unaligned access, especially if it crosses cache lines, is a SIMD instruction, or the processor is low power or old. There are a handful of SIMD instructions which require an aligned address and will fault. Otherwise the os or a debugger may be able choose whether to fault on unaligned access.
Thanks! That helped fix some of the issues. The last problem I have is this line from main.rs: ``` error[E0433]: failed to resolve: maybe a missing `extern crate lib;`? --&gt; src/main.rs:2:12 | 2 | use crate::lib::error::Result; | ^^^ maybe a missing `extern crate lib;`? ``` I'm trying to reference the Result type in lib.rs error module. I thought that in Rust 2018 that I could use `use crate::lib::error` to get to the error module in lib.rs, but it doesn't seem to be working. Should I be using another keyword, `self` or `super`?
lib and main are a bit special, they are the base of the library/executable and don't get their own names. In other words, `crate` refers to the module of lib.rs/main.rs, so you just want `crate::error`.
That was my impression as well and one of the main motivations. Playlists should be there soon, I need them myself ;) &amp;#x200B; vim-style commands are not on my list (Emacs user, sorry), but I'll gladly take a a patch, as I don't think they'd conflict with the way navigation works now.
So I've been trying to write a blog post about this for a while, but since I don't know quite how long it's going to be before I'm finished, I figured I should go ahead and share what I've been working on as sort of a pre-blog-post. I've been working for a while on fixing [rlua bug #39](https://github.com/kyren/rlua/issues/39) in rlua and I've made some pretty good progress! What I want to talk about though (and what I will *eventually* write a blog post about) is the technique that I'm using in luster for safe garbage collection. Inside luster are two libraries called "gc-arena" and "gc-sequence", and they represent a new (I believe novel?) system for safe garbage collection in Rust. There have been several attempts here before such as [rust-gc](https://github.com/Manishearth/rust-gc/) and [shifgrethor](https://github.com/withoutboats/shifgrethor), and this represents another attempt with... different? limitations more appropriate for implementing language runtimes like Lua. Right now I'm looking for feedback on these libraries and the technique in general. I've used them to implement a fairly complete Lua interpreter, so to some extent the technique MUST work, but I'd like to hear what other people think. I know there are several fledgeling language runtime projects in the Rust ecosystem, and for the ones that have a garbage collector problem to solve (gluon, RustPython), they either seem to solve it with unsafety or with Rc, both of which come with obvious problems. To other people working on language runtimes in Rust: does this technique seem reasonable to you? Do you think that gc-arena and gc-sequence should be made independent of luster so that they can be a used by other runtimes? Am I missing any pre-existing work that I don't know of for safe rust garbage collection similar to what I've done? If you think these libraries are useful, I'm really looking for feedback and suggestions about making the API a bit less crazy to use. Let's talk about it, I implemented most of a Lua interpreter in Rust, AMA.
Some benchmarks to back up your claim?
*Puts on Devil's advocate hat.* I really wanted to create a `regex` crate, but some pesky guy managed to sweep the rug right from under my feet and got the name before I did! How dare he! If that's how it is, I'll report his crate with as many sock-puppet account as I can! That'll teach him!
Thanks! Of course, it should be there soon and has a high priority. Thanks for the hint, I'll look into publishing it.
I've tried the player, but it fails to start because \`librespot\` seems to require you to have a Premium Spotify account, which I don't have. It would be useful to mention that in the readme. &amp;#x200B; Also, it wasn't trivial to find out what the error was: in my terminal, the error message just briefly flashes and immediately disappears. I had to redirect \`stderr\` to a file to be able to read it. &amp;#x200B; Packages I needed to install on Fedora for the player to build, if it's of use to somebody: &amp;#x200B; pulseaudio-libs-devel ncurses-devel openssl-devel
Thanks for the heads-up, I've updated the README with more specific requirements. I'll have to refine the error handling for situations like these (also invalid login credentials).
&gt; If that's how it is, I'll report his crate with as many sock-puppet account as I can! That'll teach him! you could, but the crate managers would check and see that it's a legit crate. not empty got a download a year etc.
Here's a related question that occurred to me: is it better to error on leaving squatting crates up, or taking legitimate crates down? &amp;#x200B; Something that may be worthwhile is ignored crates (no downloads, no updates) are removed after a period of time (as an example time range, 6 months to trigger, and 6 months for the owner to take action--not sure if this should be automated or not...). The thought here is that if the crate is worth while (as determined by downloads), it'll stick around, and if it isn't then they will go away.
Thanks for your work. I'll try `ncspot` again when (if) I get Spotify Premium. I don't like the Electron client very much, and your project looks like a nice alternative.
This looks super neat. I like the idea of using a step-by-step progression as a way to encode safe-points. If understand correctly, this gives you something like: - Rust layer A, outermost. - LUA layer B, outermost LUA. - Rust layer C, middle. - LUA layer D, middle. - Rust layer E, innermost Rust. - LUA layer F, innermost. And when the layer F completes, you can GC any `'F` pointers which are guaranteed not to have leaked, whilst being able to have `'B` and `'D` pointers in layer E and `'B` pointers in layer C. Am I close?
I think so? The restriction on pointers is actually really simple: any time pointers can exist on the rust stack, garbage collection is not allowed. Since 'Sequence' impls implement Collect, in between calls to 'Sequence::step', all pointers are reachable from the root (the Sequence tree is part of the root object), so pointers from any layer will be collectible. It's really a simple sort of "cut through the gordion knot" solution, gc pointers on the stack are problematic, so just find a way to forbid them.
It's already been done I believe, and the crates.io people removed all the squatted crates. Clearly indicating that squatting is not ok, but if you only squat a little that's ok. Or something.
librespot author here, I’m really excited to see a proper terminal UI built on top of it! I’ve not been able to work on librespot in a very long time, both by lack of time and motivation (I don’t use it myself anymore). However I’d love to hear what works and doesn’t work for you. Seems like you use the webapi when possible, which I think is the best way to go. librespot can probably focus on what’s not available otherwise (playback, connect, maybe other things?)
main.rs - `use k8top::error::Result` everywhere in crate - `use crate::error::Result`
Thanks again! I will try this as soon as i get home.
I actually made a small patch already for myself that uses the cursive_tree_view widget as a fast way of showing the playlists. It works ok, but loses the granularity of being able to queue vs play directly.
Such users should be banned outright.
Ok, it's nice to know that my 60-LoC Rust project could be better done as a shell one-liner! Now just gotta find the equivalents for Mac and Windows.
How does this relate to something like git?
When your garbage collector is garbage collected you got problems.
You can wrap buttons in an OnEventView, which gives you more options in adding callbacks. &amp;#x200B; I'm looking into publishing, but librespot is unpublished. Not sure how to proceed.
Can you explain more about how the gc works?
Thank you for your great work on librespot! So far I'm faring well with that combination, but it's still very early. Playback is working great! For some reason I'm experiencing quite high CPU load (about 30%, whereas the official client consumes \~10%), but that may just be a mistake in my implementation. I've tried the PortAudio and PulseAudio backend.
Is this is debug or release build? 30% sounds very high for release, last time I checked it was only using a few percent on my machine.
FYI, your first suggestion would delete https://crates.io/crates/alacritty, which was reserved with legitimate reason 2 years ago and should finally be published soon.
What are the arguments against name spacing on user name?
I find the tendency of physicists (I am one myself, so shame on me) to map everything to the Ising model quiet amusing ;-). Apart from characterising clapping as a phase transition, and Ising happens to have one, I wonder if there is any other motivation for the mapping? For example, Ising goes from unordered to ordered. With clapping both states, clapping and non clapping, seem to be highly ordered. It is not like there are neighbouring claps and anti-claps that cancel. I assume sound level is your order parameter? Also clapping seem to have a long range interaction (sound traveles), whereas Ising is nearest neighbour?
Sure! So this is a pretty complex topic, and there are a lot of possible techniques, but as an oversimplification: the trouble with Rust garbage collection mostly comes down to values that live on the stack. Since rust doesn't have much of a runtime to speak of, it can be difficult to keep track of garbage collected values being moved around the stack: rust-gc uses a pretty expensive "rooting" / "unrooting" step to keep track of stack roots, and shifgrethor drastically limits the ways in which Gc pointers can move around the stack (to the extent that implementing a VM becomes extremely difficult / impossible). My technique is to solve the problem in another way: ensure that at predefined points, no Gc pointers can be on the Rust stack at all! So let me back up a bit. In gc-arena, there is an "Arena" type which I would like to make a real type but for lack of GATs right now must be a macro. Inside an Arena is a single Root type which the user specifies (all pointers in the arena must live ultimately inside this single Root object). The Arena has a single method "mutate" which is how all interaction with the gc arena occurs. During "mutate", the user can move gc pointers around and do any mutation to the held root or sub-types with zero cost Gc pointers, and then through "lifetime magic", once the mutate method is exited, *the borrow checker ensures that all allocated Gc pointers either exist inside the Root or are safe to deallocate*. This is actually pretty useful on its own, but it's a bit restrictive when implementing a language runtime since the calls to "Arena::mutate" must be sufficiently "small" in order to perform continuous collection. To get around this problem, I wrote a Lua interpreter in "stackless" style. Ultimately, the Lua interpreter is just spinning in a simple loop calling "step", so in-between calls to step, I exit the mutate method so that garbage collection can take place! Other than the big limitation around "Arena::mutate", the garbage collector has surprisingly few limitations. There is pretty much unrestricted mutation and movement of Gc pointers, and Gc pointers are cheap zero-cost Copy wrappers of a raw pointer (they simply add a lifetime to do the lifetime magic). Does that make sense?
Oh, that did the trick indeed. It is a lot less with a release build (\~3%). Thanks!
&gt; I would love to see something like that written for spidermonkey. Main reason being that SM will soon start using more and more rust and we could end up with a full stack JS runtime written in Rust. Would be cool if someone picked up Starling and ran with it: https://github.com/starlingjs/starling * Was built on top of spidermonkey and futures/tokio * Used a task hierarchy kind of like how Erlang can link processes (but always a tree, unlike Erlang, which allows arbitrary linking) * All tasks communicated via channels on the rust side and streams on the JS side. I thought it was a cool idea! But then priorities...
I agree, his talks are rarely technical, I would summarize them more as "meta-discussions". But Bryan's focus on values and organisational structure was really thought-provoking to me and I definately learned some good arguments for (and against) open source. And juged by Bryans arguments the Rust team members did a lot of things really right. (Maybe I'll write a blog about that.) And yes, that performance case study is great :)
How would Ramhorns handle data from hashmaps? Sometimes you don't have structs at all like in https://github.com/Keats/kickstart where the context is entirely dynamic or for arbitrary data in a front-matter for example. Ramhorns does not seem to be able to derive structs with hashmaps in them, any plans for that? &gt; maybe in a year or two we can dethrone Hugo from its "world’s fastest" claim! I believe v0.6 (https://github.com/getzola/zola/pull/567) is already as fast/faster. I need to do a site in Hugo to compare but I would have to touch the Go template engine again....
So.. I'm curious. Imagine I have an editor of some kind (text/image)... Could this be used as an "undo" function? I have no project that could need this right now but still very interesting.
I was thinking about this yesterday, it should be fairly straight forward, just need to re-introduce `&amp;str` names into the `Content` methods next to the hash, and just ignore them for everything that use the hash. Properly inlined it shouldn't regress anything. &gt; I believe Zola v0.6 (https://github.com/getzola/zola/pull/567) is already as fast/faster. That is great to hear :D. I was playing with Zola (actually still Gutenberg at the time) and liked it a lot.
Yes that fixed it. Thanks!
I fixed it. Thanks for your help!
I've been using spotifyd to keep memory dedicated to music players down, and i'm super excited to finally have a librespot TUI!
I'm definitely going to take a good look, thanks. I'm currently issuing my own wrapper around the lua53 crate in a project, but would be interested in a more rust-compatible API (mostly no longjmp). I do make heavy use of userdata and metatables though, so I guess I'd have some work to do or a lot of waiting before I could really use it. Are you interested in contributions if I decide to have a go?
time to get a dictionary and a few scripts... start registering some crates
Hi OP! I'm working on a similar (unreleased) project with nearly identical goals, mostly because I was searching for a lightweight Spotify terminal client -- it was my first experiment with Rust as well. What I've written so far uses mio_httpc for networking/event loop, depends on spotifyd to play songs locally (which is just librespot under the hood anyways), and termion for UI. Anyways, I'd love to help out with this project, maybe there's some ideas or parts that I can salvage from my project or experience. Is there a roadmap of planned features or any info about contributing that I should know? Really excited for the future of Spotify on Linux, thanks for your work. Cheers!
Good call on OnEventView! Trying it out now.
 &gt;This is actually pretty useful on its own, but it's a bit restrictive when implementing a language runtime since the calls to "Arena::mutate" must be sufficiently "small" in order to perform continuous collection. To get around this problem, I wrote a Lua interpreter in "stackless" style (this is where all the talk of `Sequence`s come in). Ultimately, the Lua interpreter is just spinning in a simple loop calling "step", so in-between calls to step, I exit and re-enter the mutate method so that garbage collection can take place! Does this mean my tight loops in Lua are slower because it's constantly going in and out of this method?
'rua' also exists if you'd just like a safe Lua 5.3 API *right now*, in case you weren't aware. Contributions are welcome, but mostly why I'm interested in right now is help solving some of the tricky API problems: getting rid of Vec in callback args / returns, making arena macros into not-macros, making Sequence combinations nicer to use, etc. Even just people trying to use it and *complaining* about the hard parts would be useful, if that complaining comes with suggestions :)
No, depending on how often the interpreter is exiting and re-entering. Right now the interpreter executes something like 100 VM instructions before leaving and returning. In the future, the vm code might need to return earlier depending on allocation frequency, so the overhead might become noticable, I'm not sure. Right now, there are other slow things that drown it out :P It's not all bad news though, doing "stackless" style is pretty useful just on its own! AIUI Eve Online is made entirely with Stackless Python, because it allows for some really cool multitasking techniques that are often not otherwise possible.
I have a toy VM project for a homebrew language, which I'm currently using `Rc` for. When I get back to working on it again, I would definitely want to try out your GC implementation for it! So I would definitely appreciate having independent crates for them.... but it looks like they already are? At least, I see that they are separate crates, and they don't seem to have dependencies on Luster-specific code.
Self is typealias for type, which you implements. For your case it is MyStruct&lt;T&gt;.
 trait MyTrait {} impl MyTrait for i32 { } impl MyTrait for u32 { } #[derive(Debug)] struct MyStruct&lt;T&gt; where T: MyTrait { x: T, } impl &lt;T&gt;MyStruct&lt;T&gt; where T: MyTrait { fn new(x: T) -&gt; MyStruct&lt;T&gt; { MyStruct { x } } } fn main() { let s = MyStruct::new(17_u32); dbg!(s); } &amp;#x200B;
Wow, I would never figure it out. Thanks a lot!
There are a lot of similarities with git, but you can consider this to be an immensely stripped down version of it. It was designed with more high-performance needs (using git as your application core would be overkill imo) in mind, so a lot of the features that git has aren't there (diffs, merges, etc). Although, now you have me thinking, you could probably build a git client with this, as the hardest parts are nearly done. On the wishlist is a "diff" feature which would allow you to compare two trees, and then yes, it starts looking a lot like git. 
Thanks. I'll take another look at `rlua` too - it now looks close to what I was aiming for in my wrapper (which I unfortunately also called 'rlua' - serves me right for not getting around to making it public in so long!).
Yes you certainly could use this for implementing an undo feature, where you have the states stored in the tree and all you would need is to decide how many steps you want to keep. You could hold the state roots in a vector and just remove the oldest ones. When you want to revert, you can just move your current reference to the state to one of the previous state roots. &amp;#x200B; In that case, you could use the crate as is and just use the HashTree structure with no extra bells or whistles. 
or meowhash :)
I just formatted and reinstalled my Linux system and when installing Rust and RLS I had to manually install rust-src and rust-analysis. Why is that? RLS needs both those components to function properly, correct? Then why aren't they dependencies of RLS?
None of this is on crates.io yet, because I was a bit worried that gc-arena and gc-sequence would become increasingly Lua specific. Lua has some particular gc requirements around weak tables and "ephemeron tables", and this, combined with fallible gc methods, is what is holding up implementing finalization. It's possible that I'm a bit too worried about this and should go ahead and release these on crates.io. I might do this soon, actually. I have no idea really how to design a Finalize trait that allows for custom error type failure, it's a huge design question that I still have to solve, so I would love some input on this!
Your list didn't render because there's not spacing, do something like text * item 1 * item 2 foo
A generic type parameter is just that: a parameter. It's analogous to a function argument (value parameter) or a field of a struct (value parameter). A generic type would be properly called a type constructor. `Vec&lt;u64&gt;` is what you get when you tell `Vec` that it'll be storing values of type `u64`. It's like a function call but it happens inside the type system at compile time. (Actually, it *is* function application - Church's lambda calculus - with all the computational power that implies. It's possible to write Rust sources that show the Mandlebrot set in an error message. After a very long compile time.)
Yes
Works on new Reddit, not on the old one. ;)
Man I'm really feeling burntsushi's "this a staggeringly complex social problem" right now. Someone suggested "taxation" which I loled at, at first but then thought I had a brilliant solution using it as an inspiration. Spoiler alert: It was still vulnerable to exploitation. So yeah, this is super hard :/ If you're interested in my idea: Basically you want to invoice real world money from squatters for unused crate names, but how do you make sure good crates don't get billed? I figured you could establish some threshold for usage (ie other dependent crates) and/or downloads and then tax those below that threshold after some grace period. But squatters could just squat some additional crates to get over the threshold making the problem worse not better. Maybe crates that are still in the grace period can't contribute to the threshold? But still this leaves good crates that aren't anyone's dependency (ripgrep comes to mind) out in the cold so I dunno. No easy answers to social problems I guess.
I think that's a reasonable suggestion, particularly if organisations can namespace themselves (i.e: `gfx/gfx-hal`).
I guess one strategy would be to check it against a whitelist of allowed paths. Maybe just /usr/bin/foo and /bin/foo. Or even to check it against a single hardcoded path, for the sole purpose of printing and error and quitting if the environment seems to be wrong. Or maybe to do some kind of permissions check against the path in question, in addition to the above?
Thanks! Do you know why `t`'s type must be defined? It's clearly written in the definition of `MyStruct::default`.
Doesn't have to be stated. It can be inferred from the impl MyStruct&lt;i32&gt;::default() So it can be removed.
aaaahhhh this is so cool! :)
&gt; Because o += 1; is sugar for o.add_assign(1). I don't think you have that right, in this example I o is a reference (C pointer), aka memory address. My point was that its automatically dereferenced for a method, and a print! macro, but not for other operations, which is where the machine addressing leaks out. &gt; No. Which is why I say to think of it as taking a reference or borrow, and not think about addressing as it's more an implementation detail. My point is you can't think that way if you have "*" scattered throughout your code.
I've had huge respect for you since I read your posts about modern C++ engine of Starbound and this GC seems really neat, even if I don't really understand the intrinsics of it. Mad props to you for considering it's release to the ecosystem!
a thought I had reading this - how many of the squatters are actually bad actors, rather than people trying to claim authority to decide what the name is used for? if I were to do a bunch of name squatting, I would in fact be open to anyone who wants to use a name for real making use of it.
I have two questions: 1) Is the GC thread-safe? I've been talking to the RaptorJIT (LuaJIT fork) people and a mix of the Lua C API and the current GC - neither of which are thread-safe - are major roadblocks to having a multicore VM. Having this as an example would be useful. 2) Are you planning to keep this small scale for embeddable scripting (with the idea of doing heavy lifting in Rust code), or do you intend much grander things when the codebase is more stable? LuaJIT's future is...*bleak*, to put it lightly.
What is your end goal here?
There is at least one actual JavaScript engine/runtime/interpreter/whatever in Rust, that being [Rapidus.](https://github.com/maekawatoshiki/rapidus)
So I'll add a bit of context. I am doing some low-level network I/O. As such, I need to read bytes from a socket into a raw u8 slice, and I want to overlay Header on top of those bytes. That is the main purpose of the Buffer type in my example. Originally, Buffer was a Vec&lt;u8&gt;, however I realized that on platforms where alignment matters for safety, my original code might be unsafe when I re-interpret those bytes as Header, since the bytes could be allocated at any alignment. So I decided to make my buffer a Vec&lt;u32&gt;, ensuring it is allocated with 32-bit alignment, matching Header's expected alignment. One thing I was hoping for confirmation on is the line assert!(align_of::&lt;Chunk&gt;() &gt;= align_of::&lt;Header&gt;()) Since my understanding is that alignment can only be a power of 2, any alignment greater than that of Header must also align with header. Assuming this is correct, that would allow me to easily change the chunk size (say, from u32 to u64) if I wanted to.
How long does it take to generate your site?
it is a really long story but here you go: &amp;#x200B; I have a library which lets you create a generic simd function. You can then create functions that call into the generic with different traits to produce avx2/sse2/sse41 intrinsics. You can then create a function that does runtime feature detection to call the version of the function that is fastest on available hardware. &amp;#x200B; see example in readme: [https://github.com/jackmott/simdeez/blob/master/README.md](https://github.com/jackmott/simdeez/blob/master/README.md) &amp;#x200B; This is a lot of ceremony. You want to just write one function and you end up writing 6, (Though five of them are small) so I want to make a macro that automates the ceremony. &amp;#x200B; &amp;#x200B;
So right now my goals are pretty much to do what the README says: be an adequate substitute for PUC-Rio Lua and be a better, faster bindings experience than PUC-Rio Lua for Rust. So with that immediate direction in mind, I *hadn't* planned on introducing multi-threading into luster any time soon, at least until the other problems were solved first. Longer term, I'd like to maybe look at integrating something like cranelift as a simple jitting engine to maybe start becoming a viable replacement for LuaJIT as well? I've definitely *thought* about it, but nothing serious just yet. This doesn't have anything to do with multicore, just letting you know my long term plans. As far as multicore goes, I have *definitely* thought about whether the general GC technique used here is applicable for multicore, and the answer is that I *think* so. If we take the view of "`Sequence`s are abstractions to encode safe points" further, we can borrow techniques that other multi-core garbage collectors like GHC's use: run multiple `Sequence`s at once, then wait for them all to reach a safe point, then run multi-core Gc, then continue. There are definitely a lot of fancy techniques here that I don't fully understand, and the actual Gc I'm using in luster right now is PRETTY SIMPLE, so I would take what I'm saying with a grain of salt, but I think it's doable! Okay but that's *still* not multi-core Lua. If you had mult-core allocator / Gc, I think the changes you'd need to make to get multi-core Lua would be pretty involved but not insurmountable. You'd need to make tables and threads thread safe at least... maybe it's not too much more than that? I mean, to do it *well* probably requires a lot of things like atomics, but I actually think it's possible (assuming the rest of the things are in place) that rust would help here. I don't think Rust is a magic bullet of course, there still has to be a good parallel Gc and a bunch of lock-free data structures in the Lua runtime, it's not going to be *easy* to do well, but I *hope* that eventually things might get to that point. I agree with what you're saying re: LuaJIT's future, and that thought *had crossed my mind* regarding the potential utility of a Lua runtime in Rust when I was deciding to work on luster.
Haha yeah. `binutils` contains a ton of really powerful tools that no one ever really uses directly. `ld` is crazy powerful too, linker scripts can just get super complicated so we almost always leave it to the compiler to invoke.
would use this on my raspberry pi, but does it also work with ALSA ? (raspbian has no pulseaudio AFAIK)
Yes, I can confirm that. align(8) addresses are a subset of align(4) and it's safe to cast and deref a pointer `*mut u64` to `*mut Header`. (As long as you also ensure its the right size and lives long enough.) However I'm not sure that will do what you need. Network protocols often don't pad to maintain alignment. You may get an unaligned `Header` and if that is a possibility you should use the r/w_unaligned functions in `std::ptr`. Note: those functions still allow the compiler to optimize the memory access however it wants. On x86, the compiler should (I don't know that it does, but it should) issue normal accesses when they are allowed by the ABI. (I'll need to double check, I'm 90% sure they are on most/all oses.) Other architectures might test if the address is aligned and only realign if necessary. For best performance you'll probably need to profile and read the disassembled code for clues, but afaik that's just the nature of the beast. For example, if a header is designed to preserve alignment and is followed by a payload that doesn't, it may be worthwhile to copy the header before doing anything with it, since you can use whatever instructions or DMA hardware are designed for that task.
The terms `tx` and `rx` are common things in computer science, i thought everyone knew them. I guess I was wrong.
You could just take all the relevant identifiers and leave it up to the user to name them sequentially. There's a concat_idents macro but there are problems with hygiene that mean I don't think it'll work for your use case (at lease right now).
Dash (and [Zeal](https://zealdocs.org/), and https://devdocs.io) are great, but mostly useful when you have some fixed, slow-changing set of libraries and don't mind waiting a little while for properly-packaged docs to become available. Rust, on the other hand, releases a new stable version every six weeks, and Cargo encourages people to add all kinds of third-party libraries. Instead, I generally use [the official standard library docs](https://doc.rust-lang.org/stable/std/) (or the offline version that can be installed from the same place you got the Rust compiler), and run `cargo doc` to build a similar website that includes docs for the crate I'm working on, along with whatever third-party libraries I happen to be using. It'd be really neat if there were a way to have `cargo doc` include the standard library docs as well, so I'd only have one website to look things up in, even if it required downloading the stdlib source code (which I do anyway for use with `rls`). I haven't yet figured out how to make that happen. :(
/r/playrust is what you're looking for.
Oh ok really thanks!
Thank you for the detailed and thoughtful response. I definitely agree that getting a single-core runtime working first is a solid plan, but it probably doesn't hurt to keep multi-core in the back of your mind so you don't back yourself too far into a corner. Tables - as I understand Lua semantics - are just pointers, so they could have an access `RwLock` or whatever, but maybe that interacts with the C API in some way. Cranelift definitely seems more suited to a method JIT than a tracing JIT, but tracing JITs are also fairly simple to implement, so that could go either way. Regarding LuaJIT: god alone knows how much work the RaptorJIT people are going to have to do to undo most of Mike's optimisations to get the codebase usable for future improvement. Luke's rewriting the fancy assembly interpreter in C, for example, and the all-in-one Lua source -&gt; bytecode compiler is probably going to be replaced with a traditional parser/lexer/compiler. I filed [a RaptorJIT pull request](https://github.com/raptorjit/raptorjit/pull/241) this morning to strip out the bundled `malloc` and use the system one instead, shedding 1,400 lines of code. Do you think there would ever be a point where you'd drop the PUC-Rio C API for a more ergonomic and idiomatic Rust API? RJ plans to do something along those lines, although we don't have consensus on what to replace it with - if anything. 
yep that is my last resort if there isnt a better way. would procedural macros offer anything here?
One other thing that was stabilized in 1.33 is using `self: Rc&lt;Self&gt;` and `self: Arc&lt;Self&gt;` as method receivers. Combinations with `Pin` also work, e.g. `self: Pin&lt;Rc&lt;Self&gt;&gt;`. It happened kind of quietly at the end of December, so I'm not surprised if Steve didn't know about that.
You can create items with abitrary names (unhygienic) using procedural macros. There's the library [paste](https://crates.io/crates/paste) which provides a nice abstraction over that, so you don't need to define one yourself.
I actually sent in a PR to put it in the release notes; I meant to mention it in the blog post but it got lost in the shuffle.
It's one of several problems with the overall "crates" approach that make me have the opinion the whole thing isn't nearly as great vs. how other languages handle dependencies as people like to pretend it is.
&gt; Cranelift definitely seems more suited to a method JIT than a tracing JIT, but tracing JITs are also fairly simple to implement, so that could go either way. Well, like I said I only thought about it pretty briefly, and I wasn't expecting cranelift to compete with LuaJIT in terms of speed, just generally thinking about going *in that direction*. It's possible cranelift is totally inappropriate, you sound like you would know more than be about it. This is definitely a case of I don't know what I don't know :P &gt; Regarding LuaJIT: god alone knows how much work the RaptorJIT people are going to have to do to undo most of Mike's optimisations to get the codebase usable for future improvement. Luke's rewriting the fancy assembly interpreter in C, for example, and the all-in-one Lua source -&gt; bytecode compiler is probably going to be replaced with a traditional parser/lexer/compiler. I filed a RaptorJIT pull request this morning to strip out the bundled malloc and use the system one instead, shedding 1,400 lines of code. I don't know about the one in LuaJIT, but I'm assuming it's based off of the all-in-one one pass Lua source -&gt; bytecode compiler from PUC-Rio Lua, and that thing is *nuts*. I mean clearly the people who wrote it are geniuses, but it's not exactly easy to follow or modify. For other people reading, it uses link list structures embedded in both the bytecode and also in the C stack to be a compiler with virtually no extra allocation, it's really cool and really nuts. As cool as it is, it's a bit problematic when errors in the compiler and even errors in the structure of the generated bytecode lead *directly* to memory unsafety, and generally people who try to modify the compiler run into this constantly. Like I said I don't know LuaJIT, but it was based of PUC-Rio Lua which I do know pretty well now, and PUC-Rio Lua is *full* of this stuff. There are countless places where say, missing an operation that roots a value or missing a write barrier means unsafety, but the kind that you'd maybe never find unless you were attacking it. That is kind of my dream goal for luster, I see people make great things by modifying PUC-Rio Lua and LuaJIT, and those things are crazy difficult to pick up and understand (or at least they were for me). I would like to take a *couple* of steps back from the precipice and see what I can make that's slightly more approachable and safe, and see if I don't lose too much speed in the process. We'll see! &gt; Do you think there would ever be a point where you'd drop the PUC-Rio C API for a more ergonomic and idiomatic Rust API? RJ plans to do something along those lines, although we don't have consensus on what to replace it with - if anything. There's no PUC-Rio C API at all, it's even in the "non-goals" section in the README.. I don't even know really how I'd do it. That is actually kind of the other reason for the project's existence, the PUC-Rio C API is again both at once a work of genius and also really problematic. This is something I'd like to cover in the blog post actually, that many language boundaries are so hard *because* exposing the underlying Gc pointers is unsafe or too difficult for the consumer of the API to understand. If you have a magic API that is compiler guaranteed this problem might go away somewhat. Of course, it could also be replaced by brand *new* problems, and the whole thing might be not much better, but my hope is that that's not true. My *dream* here is basically a Lua interpreter where the decision to rewrite a section of a script in Rust is more often than not a speed increase, rather than very often drowned in API overhead, and to have this be possible with a safe API.
ohh that looks perfect i will try it. thank you.
If it's of any use, [Inko](https://inko-lang.org) is written in Rust and uses a garbage collector based on Immix. The source code can be found at the following two places: 1. [vm/src/immix](https://gitlab.com/inko-lang/inko/tree/master/vm/src/immix): the allocator 2. [vm/src/gc](https://gitlab.com/inko-lang/inko/tree/master/vm/src/gc): the garbage collector In both cases `unsafe` is used only in a few places where either necessary, or because I marked functions as `unsafe` myself (mostly because they're only supposed to be used by the mutator threads). &gt; Do you think that gc-arena and gc-sequence should be made independent of luster so that they can be a used by other runtimes? Garbage collectors and allocators are typically very specific to the runtimes they were built for, making reuse less likely. I can see it being useful if somebody wants to build a runtime similar to yours, but I think larger/more serious projects will opt for writing their own.
&gt;Well, like I said I only thought about it pretty briefly, and I wasn't expecting cranelift to compete with LuaJIT in terms of speed, just generally thinking about going *in that direction*. It's possible cranelift is totally inappropriate, you sound like you would know more than be about it. This is definitely a case of I don't know what I don't know :P Heh, well, maybe I could put that knowledge to use? I'm going to keep an eye on this project, and maybe you could post some GitHub issues on things other people could do to get stuck in. It's never too early to reduce a project's bus factor :P &gt;That is kind of my dream goal for luster, to make a more approachable Lua interpreter and see what other people can build on top of it. I see people make great things by modifying PUC-Rio Lua and LuaJIT, and those things are crazy difficult to pick up and understand (or at least they were for me). I would like to take a *couple* of steps back from the precipice and see what I can make that's slightly more approachable and safe, and see if I don't lose too much speed in the process. We'll see! Let's hope so! &gt;There's no PUC-Rio C API at all, it's even in the "non-goals" section in the README.. I must have gotten mixed up with the source code of rlua, I do apologise.
Oh, I actually found this when looking for prior art and I admit that I didn't have time to fully understand how it worked. Do you mind explaining how you get around the problem of being unable to scan through pointers on the Rust stack, or potentially why that is a non-issue in your design? I'd love to know more!
Rust Nice 
&gt; I'm not sure that will do what you need. Network protocols often don't pad to maintain alignment. The protocol I'm implementing will always have a Header at byte 0, so as long as byte 0 is "Header-aligned", I should be okay. There is some data after the header, and I do copy that data into an aligned thing before using it. &gt; you can use whatever instructions or DMA hardware are designed for that task. I'm pretty much relying on std for whatever it takes to get the network data to/from my application. I'm not sure if there is a better way (a goal for this particular project is to not rely on any dependencies, at least for core functionality), but right now I'm using UdpSocket send and recv methods, so I just pass in a &amp;[u8] (or &amp;mut[u8], if recv) and let it do it's thing. I do have to worry about endian-ness, but that doesn't really affect safety. At least not directly.
As far as I understand, the overhead is similar to a regular stop-the-world GC that inserts a stop every ~(however often it trampolines out of and back into mutate). In theory a smart runtime could do so only when GC pressure is high enough such that it'd be indistinguishable from a regular stop-the-world system. So it's probably less optimal than a perfect concurrent GC system (but I'm unsure if those even exist yet) and (with tuning) about equivalent to a stop-the-world system. The real wins come from reducing GC pressure in other (static analysis) ways, anyway. 
Super excited about the prospect of this. Building a server project in Rust that will need a scripting interface (likely Lua). Been looking at `rlua` and have the same concerns. My initial approach was .NET Core + Moonsharp interpreter (good interop between .NET types/methods and Lua code). Hopefully I can achieve similar in Rust.
No worries! Maybe consider adding it on to the next release blog post and say that it was stabilized in 1.33. That way people who only read the blog posts will find out about it.
Inko uses lightweight processes, which technically can be suspended at any given point (though in practise this only happens when returning from function calls). The VM is also register based, instead of stack based. For the sake of simplicity I went with managing my own stacks, which are basically fancy wrappers around a `Vec&lt;*mut T&gt;` (more or less). The compiler knows what the maximum number of registers is for every scope, and the VM will allocate space for all those registers when entering the scope (zeroing out memory upon allocation). Each frame is just a separate boxed structure, with an optional pointer to the parent frame. This might not be the most efficient, but it's fairly straightforward to implement and doesn't require anything stable Rust doesn't already offer. A benefit of this approach is that it makes finding pointers easy: 1. You take the frame(s) you're interested in 2. You iterate over the registers in a frame 3. Every register that contains a non NULL pointer is a valid Inko pointer, or a tagged integer (which the GC can detect and handle easily) Zeroing might be more expensive than not zeroing, but it's probably more efficient than keeping a separate stack map of sorts. The following structures might be of interest: * [Registers](https://gitlab.com/inko-lang/inko/blob/master/vm/src/register.rs): the structure used for storing registers * [Chunk](https://gitlab.com/inko-lang/inko/blob/master/vm/src/chunk.rs): basically a more limited and smaller `Vec`, used by the `Registers` structure. Unlike `RawVec` it doesn't require nightly builds.
It sounds like what you need is something like trait Finalize { type Error: Any + 'static; fn finalize(self) -&gt; Result&lt;(), Self::Error&gt;; } trait FinalizeObject { fn finalize(self: Box&lt;dyn self&gt;) -&gt; Result&lt;(), Box&lt;dyn Any + 'static&gt;&gt;; } impl&lt;T: Finalize&lt;Error=E&gt;, E: Any + 'static&gt; Finalize for T { fn finalize(self: Box&lt;Self&gt;) -&gt; Result&lt;(), Box&lt;dyn Any + 'static&gt;&gt; { Ok(&lt;T as Finalize&gt;::finalize(*self)?) } } (modulo exact syntax). This is (roughly) the trick that can be used to get an object-safe version of a non-object-safe trait. Just throw more dynamicism at it (explicitly). For you it'd probably return some root "LuaTable" type for the generic error. Also, consider this another vote to see the GC crates published so that other people (including me) can try it out. Most interpreters need a single "handle" type (or a bounded set of such) to support interpretation, so I don't see the arena allocation causing major issues.
&gt; Heh, well, maybe I could put that knowledge to use? I'm going to keep an eye on this project, and maybe you could post some GitHub issues on things other people could do to get stuck in. It's never too early to reduce a project's bus factor :P 100% agree, I'm trying to update the [TODO](https://github.com/kyren/luster/blob/master/TODO.md) regularly, but it's pretty sparse right now. There's a *lot* of room for improvement in luster right now, some of which is blocked mainly on API design. As one example: callbacks take a Vec and return a Vec currently, so brand new buffers for every callback call! It's *awful*, but it's waiting mostly on designing the right sort of API to make it impossible to misuse. If you find something you'd like to work on to get your feet wet and it's something that you'd like to discuss, you could make an issue that says something like "Callbacks are the worst, how do we fix this?" and we can discuss it at length. &gt; I must have gotten mixed up with the source code of rlua, I do apologise. No problem, rlua and luster, though getting to the same place, are *really* different architecturally (for obvious reasons).
&gt; Inko uses lightweight processes, which technically can be suspended at any given point (though in practise this only happens when returning from function calls). The VM is also register based, instead of stack based. Lua is also register based, despite having the terminology "stack" everywhere, Lua frames get slices of the stack to operate on in any order. Apologies if you were already aware of this. &gt; For the sake of simplicity I went with managing my own stacks, which are basically fancy wrappers around a Vec&lt;*mut T&gt; (more or less). The compiler knows what the maximum number of registers is for every scope, and the VM will allocate space for all those registers when entering the scope (zeroing out memory upon allocation). Each frame is just a separate boxed structure, with an optional pointer to the parent frame. This might not be the most efficient, but it's fairly straightforward to implement and doesn't require anything stable Rust doesn't already offer. This is very similar to how Lua works (both PUC-Rio Lua and luster). &gt; I would recommend waiting with extracting the code, at least until the project matures more. This way you don't end up having to fork the project for your VM if you need special support for something. I never made a generic Immix library for the exact same reasons. That's pretty much what I was afraid of. I would love it if this weren't true though, even if it was a simple example Gc with limited semantics it might be useful, even if every serious project is destined to replace it? On the previous point though, I'm trying to understand: what stops you from holding an `ObjectPointer` or an `ObjectPointerPointer` somewhere else and accessing it after it has been freed? They don't seem to implement Drop, so I don't understand how it's safe (in the Rust sense of being safe, as in it is impossible to cause UB in safe code). I edited my reply above to clarify the question, so apologies again if you just hadn't seen the edit yet. I'm asking because if you have a neat trick that makes it safe (in the Rust sense), it might be simpler or easier than something I'm doing and I want to know about it! If it's safe in the more literal sense of you just don't do that by *policy*, that's totally acceptable also, I just want to understand in case there is a part of this that I'm misunderstanding.
&gt;C++ has `std::vector`, C# has `List`, Java has `ArrayList`, Python has lists, JavaScript has arrays. I count 1 for vector, 1 for array, and 3 for list.
As old as lisp? I'm pretty sure people have been using list to refer to an ordered collection of abstract items (whose order doesn't necessarily have meaning) since long before computers were even conceived. Your cookbook has a "list" of ingredients for each recipe. The dictionary is nothing more than a "list" of words and their definitions.
Maybe these posts would be less common if this subreddit's theme was reverted back to the default.
What do you mean? Do you disagree...
I use Zeal (a Dash clone for non-Apple OSes) for the Rust standard library docs and I just Google up the docs.rs page for supplemental libraries. (I'm lazy and it's quicker than letting rustdoc run locally) However, it's not difficult to make your own Dash docsets. A docset is just a bunch of HTML files (eg. an HTTrack dump) plus some metadata, so you could run `rustdoc` then have a little script which scrapes the metadata from it. The Dash [Docset Generation Guide](https://kapeli.com/docsets) even links to various examples in various languages. Heck, I [wrote my own throwaway script](https://gist.github.com/ssokolow/4ca5fe898c9cbe3896badd215042056e) from scratch a few years ago (before it linked to examples) to convert a dump of the SDL2 wiki for my brother.
&gt; On the previous point though, I'm trying to understand: what stops you from holding an ObjectPointer or an ObjectPointerPointer somewhere else and accessing it after it has been freed? Nothing. When I first started working on this I tried to come up with ideas for this, but I couldn't come up with anything. I'm not sure if this is worth pursuing either, at least for Inko. The VM makes sure to never store pointers in a place the GC can't access. Inko's FFI does not allow passing managed memory pointers to C, so we don't have to worry about that either. Sharing memory between processes also isn't possible, as all messages sent are deep copied. One small exception is Inko's permanent heap, which _can_ be read from by different processes. Objects on this heap are never garbage collected, so in practise this won't pose a problem either. What you probably could do is add some kind of `get` method that returns a guard of sorts, rooting the object while the guard is alive. When the guard is dropped, the object is unrooted. If you combine this with a `#[must_use]` I think you should be able to protect yourself quite well, at the cost of having to (potentially) allocate memory for the guard on every pointer read and/or write.
I think most people are only familiar with linked lists from an academic perspective since contiguous arrays beat them in almost every way. The main non-academic use is in functional programming where they just happen to be a more intuitive implementation of a list than arrays.
Wouldn't that mean it has a different direction at each element?
Using the word "list" to describe a data structure in computer memory is as old as LISP ("LIst PRocessing language"). For many decades, linked lists (potentially with shared tails) were synonymous with the term "list" in computing. It's like calling a hard disk "memory", something that folks have been doing in recent years. Yes, technically it is a kind of memory, and yes it fits the vernacular definition. But it's more confusing than helpful to anyone who has gotten used to computing vocabulary. Anyway, I think we're pretty far afield for /r/rust. &gt; "When I use a word," Humpty Dumpty said, in rather a scornful tone, "it means just what I choose it to mean—neither more nor less." "The question is," said Alice, "whether you can make words mean so many different things." "The question is," said Humpty Dumpty, "which is to be master—that's all.
&gt;What do you mean? Do you disagree... You're on the wrong subreddit again :^) What I'm suggesting is for r/rust's moderatorship to use the default reddit theme so that people would have an easier time differentiating it from r/playrust (the survival game subreddit). 
Nah, Rust is also a programming language, which is what this subreddit is. He's saying if the theme was changed back to how it used to be, more people would realize they're in the wrong place. We get a lot of posts like yours of people thinking this is the sub for the game Rust. 
You're able to do collections on the inner arenas once their mutate returns, right? Or do you have to return back to the top level to sweep everything at once? i.e. have a function do a mutate, allocate objects inside the arena, return, and collect non-escaped values without trampolining back to the main loop 
All right, thank you so much I compl misinterpreted this entire situation thank you for updating me on this and being very kind and courteous. I'm really sorry I disturbed you.
&gt; Nothing. When I first started working on this I tried to come up with ideas for this, but I couldn't come up with anything. I'm not sure if this is worth pursuing either, at least for Inko. The VM makes sure to never store pointers in a place the GC can't access. Inko's FFI does not allow passing managed memory pointers to C, so we don't have to worry about that either. Sharing memory between processes also isn't possible, as all messages sent are deep copied. One small exception is Inko's permanent heap, which can be read from by different processes. Objects on this heap are never garbage collected, so in practise this won't pose a problem either. That makes sense, thank you for clarifying! It's not necessarily an unreasonable trade-off to make, especially for the internal runtime of a single language. This is sort of the problem that I set out to solve with luster's Gc and it does (I believe) solve it, but it absolutely comes with a complexity trade-off. If you ever *do* want to solve that problem, there might be some techniques from luster that are useful to you? I'm definitely going to be taking inspiration from Inko, so it's only fair :D
I don't think `Sender` impls `Sync`, so the `Arc` approach doesn't actually allow sending to other threads.
I think you might underestimate the mental overhead of the borrow checker for new developers. I'm saying this as someone that works with junior developers in a daily basis: this kind of a tool would make me much more confident rolling out Rust as a larger part of our codebase.
There's actually only one arena. Callbacks aren't on the Rust stack, that's what I mean by writing the interpreter in a "stackless" style. Let's look at an example: ```rust let mut sequence = arena.sequence(|root| { gc_sequence::from_fn_with(root.test, |_, test| { *test + 10 }) .then(|_, r| r - 20) .then(|_, r| r - 30) .then(|_, r| r + 2) .boxed() }); ``` Sequences are constructed similarly to "futures", you don't run code directly, through combinators, you construct "state machines" that execute your code in steps with bits in-between. In futures, you're waiting on async operations to complete, in `gc-sequence`, you're allowing garbage collection to take place. Now this example has no allocation so it's a bit silly, but each of those steps is turned into a single call at the top level `Sequence::step` loop. There's only *one* such loop for the whole interpreter, no matter the sequence of Lua -&gt; Rust -&gt; Lua -&gt; Rust callbacks, because each callback returns a sequence which is then spliced into the single outer sequence which is being run in that *single* loop. You get two things from this: one, you can garbage collect continuously while executing arbitrary script / callback code, and two: your interpreter is stackless. You can do things like pause scripts at *arbitrary* points and resume them say, during the next frame in your game. It's a really powerful and interesting way of interacting with scripts for *certain types of games / applications*. "Stackless Python" is like this. Here's an actual example of a callback inside luster: ``` Callback::new_sequence(mc, |args| { let function = match args.get(0).cloned().unwrap_or(Value::Nil) { Value::Function(function) =&gt; function, value =&gt; { return Err(TypeError { expected: "function", found: value.type_name(), } .into()); } }; Ok(sequence::from_fn_with(function, |mc, function| { let thread = Thread::new(mc, true); thread.start_suspended(mc, function).unwrap(); Ok(CallbackResult::Return(vec![Value::Thread(thread)])) })) }), ``` This is pretty complicated, as you can see, but what this is doing is rather than returning a value, it's returning a *sequence*. This is sort of, I don't know what you'd call it but "continuation return style"? The callback returns a sequence which specifies *what to do next*, and that sequence is spliced into the main sequence. One downside here is that well, you have to construct futures-like state machines often on the *heap*, and there is some overhead here, but actually more importantly the futures-like API can get really complicated (as you can see). I'm hopeful that some day generators can be used to ease this pain, but it will require slightly more than just generators to accomplish (I need to also be able to have custom auto-traits on closures to do this, or some official way of tracing over Rust structures that is not based on my procedural macro, or something like this. I don't know if this will ever materialize. Even just having this without generators would enable me to avoid a lot really gross `xxx_with` variants of combinators that are required to *manually* close over `Collect` values, I'm actively looking for a better solution here!)
I've been looking for something like this! My use case is a 3d scene graph wrapping nvidia's optix library: [https://github.com/anderslanglands/optix-rs](https://github.com/anderslanglands/optix-rs) I'm currently using slotmap for allocations kinda like an ECS and I'd like to add a GC layer on top of that to automatically remove nodes that are orphaned when making edits to the graph. The one tricky thing is that I need to support a custom "deleter" at the gc-arena level since deleting objects through the C api must be done on the main context object (which would probably be stored in the arena type), which means I can't use the Drop trait on each node, otherwise they all need to hold mutable references back to the context itself. Does your system support something like that?
It will support finalizers very soon. Mostly they are unimplemented because finalization in Lua is **complicated**, but I'd like to at least do a simple system for finalization soon, just to show the concept.
It would work great if Lua errors weren't generally Lua values, which cannot be 'static and are fully garbage collected values :( I'm going to have to shove them inside the Root object somewhere... somehow...
Sweet. I will keep an eye on the repo then. Thanks!
Regardless of how complex it is or isnt, or whether anyone likes or dislikes squatting, or what the consensus is, or whatever else you're going on about, i think everyone agrees that squatting is a problem. How much of a problem and what kinds of squatting corner cases are and aren't ok are up in the air but ultimately unimportant at this stage, i think we can all agree on the obvious cases like this. The simple fact is the policy is very clear, in that squatting is OK, and, from what i've seen, the rust team has been very clear in their opinion on the policy, in that squatting isn't a problem and they have no plans to change it, and we should just use unique, non-descriptive, unsearchable names like "kuchiki". Another popular example used in support of the policy, and of it "working" and "not being a problem" for others, is npm, despite the fact it [has policies on squatting, namely that they will immediately transfer squatted names on request](https://www.npmjs.com/policies/disputes#squatting) &gt; When someone has taken the time to start addressing a related issue with an eRFC, it has in turn received thoughtful and careful feedback. I wouldn't say thats related, and explicitly isnt intended to have anything to do with the squatting situation. I'm not sure why you mentioned it. If anything it's about *abandoned* crates, which is a completely separate issue from squatting with it's own set of challenges.(Like is it abandoned or finished? on a particularly long hiatus? etc) "an unrelated issue explicitly not dealing with squatting wasn't subject to the divisiveness i imagine in the squatting debate". [*surprised pikachu*](https://i.imgur.com/1wpmJpd.png).
Thanks a lot, though I have ***complicated feelings*** about the starbound source code.
That was probably [this](https://blog.rust-lang.org/2018/10/19/Update-on-crates.io-incident.html) incident, which was only removed because they were "impersonating" crates.io
 Website - [http://www.hattershop.tk/](http://www.hattershop.tk/) YouTube Video. [https://www.youtube.com/channel/UChtKEtx689sXCLBCiLljduA?view\_as=subscriber](https://www.youtube.com/channel/UChtKEtx689sXCLBCiLljduA?view_as=subscriber) Discord. [https://discord.gg/uqk4bz](https://discord.gg/uqk4bz) Price's - Apex Legends = $12 PUBG = $12 HWID Spoofer/Needed if you are Hardware ID banned from any platforms 1 Week Codes = $20 RUST = $25 **Current Features:** **#ESP** **Player NamePlayer HealthPlayer LinePlayer DistancePlayer SkeletonPlayer RadarVehiclesLoot ESPDead Player LootDown IndicationReviving IndicationAirdrop ESP \[ 2,000 M \]** **#WeaponMod's** **No RecoilNo SpreadNo Sway** **#Aimbot** **AimkeyMagic BulletShoot through wallsPunch through wallsSilent Aim** **#Misc** **SpeedhackGlobal SpeedhackDead crate teleport \[ 100 M \]CrosshairForce Third Person \[ FPP Matches \]** **#Security** **HWID LockedPrivate InjectionAnd more** **#OtherInfo** **Supported OS: Windows 10 1803-1809** **\[ For more info please leave me a message here or discord Fake#6666 /** **Psycho**\#1337 **\]**
I think you want [r/playrust](https://www.reddit.com/r/playrust), This sub reddit is for the programming language.
You've just repeated stuff that has already been said. And yes, indeed, one should read more closely. That eRFC is related. I chose my words carefully: &gt; As much as this is not the objective of this eRFC, the way this experiment plays out will likely inform any future policy on squatting. You asked me what lessons one could learn. I told you. I'm otherwise not interested in rehashing this debate.
Hijacking this comment, I think some of the confusion might be due to multiple definitions of the term "trampolining". I'm using it in [this sense](https://en.wikipedia.org/wiki/Tail_call#Through_trampolining), not in [this sense](https://en.wikipedia.org/wiki/Trampoline_%28computing%29#Low-level_programming).
One argument I've seen (but disagree with) is that namespacing promotes forking without having to upstream your changes, which therefore promotes fragmentation. One counterargument is that fragmentation isn't that big of a deal on GitHub, and forking a project and maintaining it in tandem are often done when a project is abandoned or project goals differ. Otherwise you're forced to use the git url of your fork in your toml which can cause issues. Another one I've seen (but disagree with) is that npm/yarn, pip, ruby gems etc have endured fine without namespaces. But the counterargument is that they have endured *despite* not having namespaces. There are many packages on pip that are abandoned but take up important namespaces. Another argument is that you don't want to cause confusion within the community by having multiple projects with the same name. e.g. you don't want to have another rust project named 'rocket'. But I think if someone were to create a rust project called 'rocket', they would be asked by the community to rename it. Another argument I've seen is that we should force people to come up with creative names for their projects, which is the case when the obvious name for your project is taken. But idk if I agree with this. Some projects don't need creative names and forcing things otherwise can be contrived, e.g. people just end up naming their project 'name1'. If Rust is going to last into posterity (which seems to be one of its goals), then I think supporting namespaces should be a priority. It seems like ruby has had a strong influence on the namespace decision but I think that needs to be rethought since the issue of namespaces keeps coming up on /r/rust. The obvious solution would be to add support for namespaces, while also not requiring them (like docker does), which also keeps backwards compatibility. And if there's a naming conflict in your dependencies, then you can resolve that in your `toml` file.
&gt; You've just repeated stuff that has already been said Seemed to me you needed a refresher, considering your lack of participation in other discussions, and the points you'd repeated. ---- &gt; You asked me what lessons one could learn. I told you. I'm otherwise not interested in rehashing this debate. If you do more than cherry pick *one* quote that tangentially relates to squatting to "support" your argument, things make more sense. **"It is not intended to address the situation of name squatting on crates.io, nor as a gateway to eventual more aggressive forced exchange of crate names."** **"This eRFC is not intended as a solution to the name squatting situation on crates.io. This eRFC does not denounce the behavior of registering crate names without the intention of using them."** "By taking this step, it may be perceived as a decision against ever addressing the name squatting situation more decisively. That is not the intention of this eRFC." ***"This eRFC would like to avoid, as much as possible, any association with a name squatting policy. Such a policy should be a largely orthogonal RFC."*** It's only just barely tangentially related to squatting, in that they both involve transferring package ownership. It doesnt really go any deeper than that, and i don't think thats deep enough to call them "related". The RFC goes out of it's way to avoid relating itself to the squatting debate, even explicitly asking not to be associated with name squatting policies, not that it seemed to deter you from relating them.
Good point, I missed that. So I guess my question only applies to the new implementation.
You can debate whether the word "related" makes sense or not with someone else. My meaning seems pretty clear. The eRFC looks topical to me. It's pretty clear that if it were adopted, it would likely influence future squatting policies.
Fair enough, contrived though it is. I can’t think of any immediate problems with supporting `|` in sub-patterns, but even if that was implemented, due to the syntactic reason of closures, `|` would still need to be a separate top-level element (`$($pat:pat)|+`, so to speak, rather than just `$pat:pat`) in those places that want it to work without parentheses.
&gt;I really, really like this little thing. It's simple, it's elegant, and it feels magical in the way it exploits properties of prime numbers. As one Redditor noted, I could be using an even faster hasher - FxHash - that was originally used in Firefox and is now being used in rustc itself. FxHash is a derivative of FNV that does the same kind of xor multiply magic, but instead of doing it a byte at a time, it loads multiple bytes at a time, which is much faster for long inputs (for short inputs the two are basically identical). I might still do that, but I'd like to research some properties of FxHash, such as randomness and collisions within the English dictionary at very least. 64-bit FNV-1a for that purpose is solid. Collisions are low, but they still happen. I am hoping the actual code does include support for collision detection. This stack overflow indicates that there are a few collisions within the lowercase dictionary space: [https://softwareengineering.stackexchange.com/a/145633](https://softwareengineering.stackexchange.com/a/145633)
I’ve dealt with mutexes a couple of times only, and in neither of those cases did I care if it got poisoned; I think what it was protecting was `Copy` and couldn’t be damaged. The poisoning stuff was just a pain.
Adding a bit to this, a good way to look at the Sequence model is to think of it like futures: futures work well for GC for the same reason they work well for async IO: both situations need the ability to "interrupt" execution at known points to do other work. Sequence isn't _exactly_ the same thing as the Future trait because of all the lifetime stuff, but it's a very similar concept. thread at https://twitter.com/ManishEarth/status/1073651552768819200?s=19
&gt; I would in fact be open to anyone who wants to use a name for real making use of it. Thats what registering the name in the first place is for.. &gt; if I were to do a bunch of name squatting, I would in fact be open to anyone who wants to use a name for real making use of it. That would make you a bad actor
Ugh, r/lostRedditors
Thanks, that nicely explains why it ended up in std. But why should it be in std today? E.g. rand is not in std with similar reasoning, so why should channels be in std when something like rand isn't? 
FWIW, I independently submitted a PR to fix this behavior because I too found it rather not okay.
2 for Vector, since Java had that before ArrayList.
&gt; Did you experience any gotchas or difficulties when using tower-grpc for your production project? The staticness puts a bit of a burden on the application developer. On the server side, when implementing a gRPC service, you have to provide concrete types for the request futures and streams to fill the associated types of the service trait, so you can't use anonymous trait impls. When using future combinators in code, the resulting types can get unwieldy quickly. I had to define concrete types and code future/stream impls by hand for something that could be more easily achieved by combinators.
I'm integrating [uom](https://crates.io/crates/uom) into [battery](https://crates.io/crates/battery), based on the /u/flying-sheep [advice](https://www.reddit.com/r/rust/comments/aw42dk/exposing_ffi_from_the_rust_library/ehkkzpa/) -- no more bugs like `u32 as amperes * u32 as voltage = u32 as watt-hour`, now it will operate only with `ElectricCharge` and `ElectricPotential` types. Since no other crate is depending on it yet, I can do whatever breaking changes I want :)
Writing some bare metal stm32f1 code to drive a waveshare e-paper display.
I guess that, unlike Git, this doesn't currently end up on disk in normal usage. Is there an easy way one could do that? It seems like straight serialization/deserialization would be a bad idea once the tree got large?
Working on a suite of crates for providing comprehensive license audit, review, and compliance.
I'm neutral on whether channels should ideally be in libstd or not.
What’s the +/- compared to the oft-recommended Wormhole?
Did you try installing the documentation? I think `rustup component add rust-doc` should work.
That's numbers for 32 bits though, I'll run the tests for FNV, FxHash and maybe something more robust like sha2 or keccak truncated to 64 bits and compare those.
I maintain a library crate, and it appears that I can't lock down specific past revisions of the tower crates. Apparently as long as tower-grpc has git dependencies omitting any revision information on the other crates from the stack, those cannot get specified down to a known good revision in a dependent crate's `Cargo.toml` either, because cargo will still fetch those from master and the build will fail. Telling every application to hold to old revisions in their `Cargo.lock` files does not seem practical either, because then they lose the ability to update any deps with `cargo update`. So I have to track tower-grpc changes closely for the time being. Any plans for versioned releases?
If I disable Rayon (which has to initialize a thread pool, and does nothing for 1 iteration it has to do) it's 0.000285s. I can speed it up some if I optimize the markdown parsing and syntax highlighting a bit, but I reckon most of that time now is just fs IO. I also have no caching or anything.
&gt; crates.io is intended more for fleshed out projects for end users rather than anybody's fork I disagree. You can't publish a crate with git dependencies. So if you have to fork one of your dependency because the maintainer has gone away, you need to publish that, too. And that's exactly [what](https://crates.io/crates/detsurtnu) [happens](https://crates.io/crates/gnir).
wanted to start some actix_web. got to actix, ended with tokio (because I'm still learning rust). Now I'll try a bit of Amethyst, as Tokio is, unfortunately, a bit over my head for now. Guess it's a game then (trying to port some of my java game to rust). that's it. feeling demotivated currently because Tokio bent me to my knees and told me how weak I am! sry for the rant
Or even just user namespacing like npm does
.raw directly from cameras. Are you going to continue working on this? I would love to contribute (I'm a novice though so not sure if there's anything suitable..)
Oh...thats amazing. I want to get rid of the electron crap so bad.... Q: Why did you went for cursive instead od the other tui libs (like tui-rs)? Keep up dude! 
Just downloaded and compiled servo yesterday. I don't quite know where to go from here but I will probably start hacking around and maybe I can fix one of the easy issues.
Integer type is inferred in most cases. If it can't and any will fit then it is set to `u32`.
They used it for initial prototype. Later changed due to Go having a runtime which may not play well with V8.
I'll check it out thanks
I recently built a couple of small services using Warp and I really love it. Like others have said it is newer and will potentially have some API churn but overall it hasn't been changing much in the last couple of months. I would do more research around the plans for the lib before I put it into production probably, for my co-workers sake. If it were just me I wouldn't hesitate. &amp;#x200B; I have built similar services using actix-web and also really like it, but found warp felt more readable and I was more productive with it. This may have been partly due to my rust skills generally becoming a lot stronger during this time, so a non-scientific measurement to say the least. Both are great, the composability of \`Filter\` though I think is a killer feature.
Most major nosql libraries don't actually block for flushing data to disk, they keep several layers of the db in caches and handle touching the disk themselves. RocksDB is a good example of that. This library can connect to any db provided you give ways to interface with it.
yes, but i think the book has already a new owner ,while im reading your reply
1. To clarify, I don't necessarily agree with those 4 points, just stating common arguments. 2. That yanking situation is definitely a yikes from me. That sounds like a `ring` specific issue though. 3. On the other hand, from what you're saying about the git dependencies, it sounds like that's a pretty broken decision on crates.io's end. It makes sense, but seems to undermine their intentions with crates.io
Cheers. Does it work for Windows? Finally something that doesn't take hundreds of MB of RAM to do a simple thing.
If you happen to know: \- How does this compare, performance wise, with running Javascript inside Rust (maybe via Spidermonkey)? \- And with LuaJIT in Nginx?
I *think* you are looking for /r/playrust But I can't actually tell since I haven't/won't join the Discord.
Just to follow up here, I've run the numbers with a dictionary of 370100 words. FNV-1a got 0 (!) collisions, while FxHash got 64. Code with results: https://github.com/maciejhirsz/lhc
Hey there! That sounds cool! Any help is appreciated. There is no roadmap, but the general idea is to have something like an ncmpc/ncmpcpp UI for Spotify. Also I've created some issues for planned features.
Sounds great!
Absolutely brilliant work! Solid linear algebra libs mean we can do scientific computing on rust!
Thanks. It seemed a little faster to get something going with Cursive, as it comes with a bunch of views that you can use right away and provides more abstraction than tui-rs.
Sorry to hear that rsdocs-dashing didn't work. I haven't used it in quite a long time, but I'll see if there is an easy way to fix it and get back to you! As an aside: Downloadable docsets are the #1 requested feature of docs.rs for a long time, but the maintainers don't seem to care ¯\\\_(ツ)\_/¯
Theoretically it should work with some minor effort. The PortAudio backend supports Windows, and for Cursive to work on Windows I think it only needs to be built with pancurses, which I might add soon.
PortAudio can do ALSA, check the Readme on how to build ncspot with PortAudio :)
There is a [Ratio](https://docs.rs/uom/0.21.0/uom/si/ratio/index.html) quantity, suits well enough. Thanks for an idea, btw :)
Nobody said it was an interpreter, VM, engine or compiler. It's a JS runtime written in rust, like the title says.
Memory permissions can be changed at runtime, for any area of memory.
Memory permissions can be changed at runtime, for any area of memory.
thanks
Oh, just found this : https://github.com/rust-lang/rust/issues/56660 It looks like sourcemaps existed as an interim solution but where removed? 
I have only minimal expirience with writing linear algebra code. But from my (very limited) perspective nalgebra is so much friendlier and easier to understand/use than eigen. 
thank you for the info. I wasn't sure. 
&gt; multidimensional array type You mean `[[[T; X]; Y]; Z]`?
Cool story bro. Try to change a writable mapping to executable (or vice versa) on iOS, it doesn't allow it.
That's an array-of-arrays (of-arrays), though. I think this implies multiple accesses to get at a value rather than an index calculation? I suppose maybe the optimizer can work it out? Or maybe I just misunderstand what `Index`/`IndexMut` is doing under the hood.
It is stored contiguously, so with size on each level known `a[x][y][z]` will just be translated to `a[x + X * (y + Y * z)]`
I'm writing the compiler/interpreter for a language I'm designing. Also, as usual, I'm continuing the live development (on twitch) of my Amethyst game.
You can't not install `rust-doc`. /u/thristian99 would like for their crate's documentation to include the `std` docs.
&gt; Easily &gt; Command line Sorry, I don't mean to be a snark; it actually looks like a really good tool. But as a rule I don't struggle to share files to or from people who are even semi comfortable on the command line; it's everyone else where I struggle.
the best thing about com.java.namespacing is that you have to own the namespacing.java.com domain in order to be able to publish. 
The point is you can upload/download on the command line using ffsend and other people can download/upload on the web using Firefox Send.
/u/desijays, I just checked `rsdocs-dashing` with a newly documented crate, and it still works fine for me. Could you by any chance provide more info to reproduce the problem? Feel free to open an issue on the Github repo as well!
I would like to start hacking servo, but i don't quite know where to start. I already downloaded it and compiled it on my machine. Where could I find some resources ? Also I would like to know which servo components are already implemented in Firefox. I only found some older posts about Webrender and Stylo, but no up to date roadmap etc.
Great job, I am very excited 
There's really no way to distinguish between legitimate and illegitimate on the basis of downloads. As download numbers don't include or filter sources (Not that I think that should be the case). For example I have two crates, [chelone](https://crates.io/crates/krusty) a currently in progress parser for a niche format, and [krusty](https://crates.io/crates/krusty) a squatted crate name. Krusty has more overall downloads and pretty similar recent downloads (25 recent downloads compared to Chelone's 37). &amp;#x200B; That doesn't even include someone acting maliciously to keep their numbers up to pass this "legitimacy check". Arbitrary metrics checks are easily gamed and are not a solution to this problem.
rust doesn't (yet) compile to JS. Stay with a decent frontend language on frontend. Maybe typescript or scala.js. Don't waste time chasing rust on frontend, you'll end up severley disappointed. 
Using Rust+WebAssembly alongside JS/TS works once you get past some initial setup and learning. The hardest part for me personally was getting WebPack to play nicely and configure [wasm-bindgen](https://github.com/rustwasm/wasm-bindgen) correctly. I ended up creating [a template](https://github.com/Ameobea/sketches/tree/master/template) of a Rust+WebAssembly+TypeScript+WebPack application that I end up using for most of my projects now which takes a lot of setup out and makes getting into development quicker.
So using Rust for WASM doesn't make sense?
AFAIK ios supports it via mprotect syscall
What do you mean by a web app? Just the backend part or frontend or do you want some sort of universal web app?
Yes. Just got released in my country. Exactly what I've been looking for
It's a webextension, so it's a weird mix of backend and frontend all bundled in one :P &amp;#x200B; But strictly speaking this is frontend code.
It makes in the following cases: - You hate JS, love Rust and want to write something for frontend. - You want to play and experiment with WASM. - You have a project which requires WASM and/or Rust powers (performance, download sizes, reliability, etc.). Arguably Rust is the best language for WASM right now, so the better question is "do you need/want WASM or not?".
Interesting, so you still have JS/TS in your stack ? It sounds like you use Rust for the WebAssembly speedup. Is that worth it? I'm aware that this depends veeery much on the specifics of the use case. How does it look for you? Are you compiling it to WebAssembly or asm.js ? And if it is asm.js, would you say that it's possible to throw out Typescript entirely? 
In my very limited knowledge- wasm isn't well suited for the document structure. Use wasm for computing stuff. Not for regular event stuff 
Is there a basis for your last statement? I'd love to know.
I read your blog post, very nice! Askama does do capacity hinting already, but it might not be working quite right yet. I haven't had a lot of time to spend on Askama recently, otherwise I would investigate more!
The reasons I use WebAssembly are partly for speed/efficiency and partly just for the ability to use Rust to build the application's frontend. You're probably not going to notice huge speedups due to using WebAssembly unless it's in very performance intensive code (interactive visualizations, realtime rendering, number crunching, etc.) and a lot of those cases have stuff like WebGL to help you out as well. I'm compiling to WebAssembly. Right now, there are no host bindings for WebAssembly (not Asm.JS) meaning that you have to call into custom JavaScript functions in order to do stuff like access/manipulate the DOM, read/write to localstorage, etc. JS/TS is necessary as "glue," at least for the time being.
Hm, after some more googling, it very much looks like you're right. Probably makes sense to choose a hobby project that is actually suited for rust. Instead of trying to squeeze it into webdev.
That's interesting! Do I understand correctly that these are trusted strings defined by the user? If not, and you care about collision resistance, then the keyed SipHash is the way to go. It actually [overtakes FNV in performance](http://cglab.ca/~abeinges/blah/hash-rs/) at 60 bytes input length.
NO- do webdev on the backend. Rust is looking good there. unless /u/sanxiyn delivers, rust won't be usable for frontend. wasm is like self-driving cars. It will forever be 'next year'. 
Thanks for the details :D Unfortunately the overhead sounds rather painful...
It should fail with -EPERM unless you have a special entitlement that only Safari has, or you're running it as a developer, or you're jailbroken.
Makes, sense. Unfortunately, the project is mostly front-end. It's a game in a webextension. From what I see so far, I would have to decouple the game logic (in Rust) from anything to do with DOM manupulation or drawing (WASM doesn't directly support this). This brings in quite some architecture overhead. Which would probably not be that bad after all. Decoupling logic and design is always a good idea. But still, so much refactoring ... Up to here, I would probably do it. But for the game logic I need a debugger. Without something like sourcemaps I just won't be productive. I have the impression that Rust makes a lot of sense, if you have existing code (something heavy, maybe a neat implementation of your custom algorithm) that you want to ship. Compiling the codebase to WASM and interfacing it with the JS backend seems awesome.
GC languages are out the picture right now (at least until JS GC will be integrated into WASM runtime), as they bring their own runtime with them, which is usually a non-starter. Languages like Zig or Nim are too small and immature right now to be real contenders. D does not have the same level of WASM support as Rust. So essentially we are left with C/C++/Rust and Rust wins here easily in my opinion, not only because of the inherent qualities of the language, but also because of the tooling developed and attention from the Rust team.
If by overhead you mean the function call overhead when calling between JS and Wasm or vice versa, it may not be as bad as you think. Firefox in particular has made a [lot of progress](https://hacks.mozilla.org/2018/10/calls-between-javascript-and-webassembly-are-finally-fast-%F0%9F%8E%89/) improving that. Also, you can batch small operations up into single function calls, giving pointers to an array of arguments etc. in order to get around it if it's a bottleneck for you. Personally, I think that Rust + WebAssembly is completely worth it. I'm a huge fan of Rust, to be fair, but I do believe that Wasm brings a ton of possibilities to the table and serves as a great platform for building next-generation web applications. That being said, if you're just building a simple form-based CRUD site or text/image-based frontend, traditional tools like React are going to be a much better choice. WebAssembly is very powerful, but only when used for the right things. 
Interesting. Askama is using `std::fmt::Write`, no? I reckon that's the main culprit. Ramhorns is writing to either `String` directly or `std::io::Write` with a trait abstraction. I recommend looking at `itoa` and `dtoa` crates that `serde_json` uses for writing numbers, you will get an idea of how big the overhead of the formatter is.
They are trusted strings indeed. Wasn't SipHash the default hasher in HashMaps a while back? I'll give it a try!
rust juses uses llvm's backend for wasm. C/C++ can do the same
Use Scala.js if you're using for frontend- you get to try a really cool compile-to-js language. It's another very well designed language. 
Thanks !
&gt; GC languages are out the picture right now (at least until JS GC will be integrated into WASM runtime), as they bring their own runtime with them, which is usually a non-starter. I don't see why that would be a non-starter. 
Not sure if it matters but this person claimed the [rustlang](https://crates.io/crates/rustlang) name which could also fall under "impersonation". Got 'em! I can't help but feel the original intent of naming conventions in crates packages comes from naive optimism about how people will use a public resources but then fail to moderate the resulting mess. Then, when some drama inevitably happens (such as the incident you refer to) some rule is created/applied from thin air just to squash this specific incident (can't impersonate! can't impersonate who? I guess all the other names being impersonated don't matter, only crates.io name matters! maybe we can get the 'impersonation' rule to apply to rustlang? probably too much to ask to apply the impersonation rule to names like ubuntu...). I'm sure some rule will be imagined to fix this particular mess while the underlying issue festers...
FYI if when you read the parts of the book, there are still some things that are not clear to you, the best place to ask that question is by filling a github issue so that the people that maintain the docs actually get notified. 
I have attempted to use Rust to write a frontend + backend in the same project using Warp and Yew. Warp is great, and Yew had a lot of functionality that I needed, it was lacking in some departments. The most notable one was compile times. I don't know if anything has changed in the last few months, but the toolchain that Yew required to build mandated that it be compiled in Release mode, and for a reasonably sized project, with each part of the app split into its own library, that could take up to 3 minutes, depending on how many libraries were touched. Routing, which I don't think you need, wasn't supported by Yew, and the solution I came up for myself would leak because of some missing functionality in Yew. There also isn't a good way to bundle CSS with these Rust-based web frameworks, so that limits the ability for people to share components as crates. &amp;#x200B; I think JS/TS is still probably the way to go for web development now, as Rust alternatives are far too slow to develop on at the moment, and often lack significant portions of functionality that are needed within a webapp. &amp;#x200B; I think the best strategy going forward is to generate TS definitions for your message types in Rust, so you can keep the backend and frontend synchronized with respect to what is sent over the network. I tried [https://github.com/tcr/wasm-typescript-definition](https://github.com/tcr/wasm-typescript-definition) a month ago, which does most of this, but it failed to provide the actual names of the types being converted.
Because it defeats one of the reasons to use WASM: smaller download sizes.
Ah okay. Im in process to create a sma Spoty applet into tray where you could control spotify player as well as basic stuff with playlists. This might result in using webplayer and no need to have desktop app. But I will have a look at your project. Maybe I can contribute somehow.
Merged a PR from /u/svartalf into [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis) to add a number of `ElectricCharge` and `ElectricPotential` units and then released the change as v0.21.1. The last few weeks I've been researching ways to make `uom` more ergonomic. So far I've been stymied by the lack of GATs and specialization issues with associated types. I have some additional ideas to look at this week.
&gt; If you ever do want to solve that problem, there might be some techniques from luster that are useful to you? I briefly looked at luster but I am not sure what I could reuse now or in the future. Having said that, I'm of course more than happy to adopt interesting ideas from other projects when these ideas present themselves :)
OCaml's GC won't be much (if any) bigger than Rust's `Rc` and it has considerable advantages, of course. Would be interesting to compare binary sizes...
Porting over a lazy loading system in our orm. We've been running a graphql service built on PHP that works pretty well, and was a good fit for a loose typed language because we lazy load from the parent. E.g. if your graphql only says `{ shopcart(id: 123) { items { id } } }`, it's smart enough not to need a separate query to get the details on each "item", because we already have an ID from the shopcart. It's definitely something I miss php for, especially for the much more mature MySQL libs. I started with `mysql-simple`, and found their only code example used a method that couldn't query a row with a higher column count than 12, which is crazy small. I started using diesel, but find that it works very poorly for columns returned by an aggregate function. Eg if my `COUNT` is 1, the macros only let me assign it to an `i16`. But for rows where the count is higher, it demands an `i32`. Hitting a wall with that. Feeling like I should build out my own hashmap instead of using structure, and implement some traits that let me request a certain type from the query result. I am really liking the enums system though. Lazy loading used to require setting a bunch of flags, or in the JS world, treating `null` and `undefined` differently. It's great listing my own enums that are appropriate for the project, so in this case an Option that also has Uninitialized. 
I went the `--no-modules` route because of this. After some initial pains getting a minimal bootstrapping setup to work, it just feels better than requiring yet another two tools (npm, webpack) in addition to rustc, cargo and wasm_bindgen to build everything.
Could you please support your statement by a reference? Because so far I think the decision about Webkit-only thing is only political.
I found a bug in the scalar path of simdeez ([https://github.com/jackmott/simdeez](https://github.com/jackmott/simdeez)) while working on rust-simd-noise. Need to do a bunch of good unit tests to track it down, working on a convenience macro to make that less painful. It will be a nice macro for users of simdeez too. It takes a lot of weird, low level ceremony to make your generic simdeez function usable on all SIMD instruction sets, the macro will do it for you. &amp;#x200B; &amp;#x200B;
Ok thanks for the advice!!
I'm diving deeper into my learning-Rust project and building a cli git client. Currently using [crossterm](https://github.com/TimonPost/crossterm). Want to make a quick tool to easily see diffs, stage files and do partial stages from the command-line.
Using `$body:block` (without the comment) works perfectly for me: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=7483c9401867ade2e4c8cc82ab78f467](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=7483c9401867ade2e4c8cc82ab78f467) Quoting the latest stable Rust reference for `macro_rules!`: &gt;`path` and `ty` may only be followed by one of `=&gt;`, `,`, `=`, `|`, `;`, `:`, `&gt;`, `&gt;&gt;`, `[`, `{`, `as`, `where`, or a macro variable of `block` fragment type. ([source](https://doc.rust-lang.org/stable/reference/macros-by-example.html#parsing-limitations)) So you're not allowed to follow `$rt:ty` with an `expr`, or anything that is not in the list above.
Obvious solution: trait Finalize { fn finalize(self, &amp;mut Root) -&gt; Result&lt;(), LuaTable&lt;'root&gt;&gt;; } though you've probably considered something along those lines already. Without knowing much about Lua specifics, I think the solution has to take advantage of the fact that Lua is "mono typed" and _everything_ is "just" a table. I don't think the `Finalize` trait can be generic to any GC, unless maybe the returned type can just be "whatever is in the GC arena".
I intend to keep it small. I think it lacks a statusbar, but don't aim to make it much bigger. Would that still be small enough?
I'm working on IDE-like tooling for [OpenRA](https://www.openra.net) ([GitHub](https://github.com/OpenRA/OpenRA)). &amp;#x200B; OpenRA has a custom configuration/rules language (called MiniYaml) which, IMO unfortunately, hijacked the \`.yaml\` extension long ago. I have a working-as-far-as-I-can-tell implementation of lexing/parsing/tree-building for MiniYaml, now I am building a library that allows programatic management of [OpenRA SDK](https://github.com/OpenRA/OpenRAModSDK)\-based projects (think of it like \`cargo\` but for OpenRA). The next step will be to put together a minimal [LSP](https://microsoft.github.io/language-server-protocol/) server + client pair so I can figure out exactly how to surface symbols and whatnot. I plan on starting with a [Visual Studio Code](https://code.visualstudio.com/) extension. At that point I'd love for the OpenRA community to fall in love with it (even if it is a bit rough around the edges) and have community members implement LSP clients for their favorite editors (\[n\]vim, npp, sublime, etc). Some of the foundational crates I'm using as inspiration: &amp;#x200B; \- [https://github.com/brendanzab/rust-nbe-for-mltt/](https://github.com/brendanzab/rust-nbe-for-mltt/) \- [https://github.com/wycats/language-reporting](https://github.com/wycats/language-reporting)
I think a "early adopter stabilization" would be the worst path to take right now. It would seem like both rushing out the door with a solution and punting on the major syntax question, after all, the syntax will be final. At least for years. Stabilizing early with a stop-gap syntax and usability issues won't help anyone, and will only create problems: * documentation issues with posts/docs/SO answers describing the initial syntax * frustration due to usability gaps * potentially a "let's hold off until things are actually stable stable" attitude from the ecosystem I understand the urge to get things stabilized. But this is a hard engineering and language problem. In other ecosystems it has taken years and years of discussing, implementation and tuning to reach a solution (eg the recently accepted C++ coroutines). I always thought that the rush to stabilization was a bit ill-advised. Let the feature bake in nightly as long as it needs to. Iron out usability issues, get practical experience to uncover API/design issues. Try to get error messages as helpful as they can be without additional aides like existential types. I also understand that this is probably a very challenging thing to work on, hence the lack of contributors. The back and forth with the Pin + Future APIs are probably also exhausting for everyone. But early adopters lived with nightly usage for years and can stick to nightly for now. After all, that's exactly what nightly features are for. It's already really easy to use experimental features in Rust compared to most other language ecosystems. Slow and steady wins the race for me on this one. * let things bake on nightly until involved parties (lang team, compiler devs, major ecosystem stakeholders) are sufficiently happy with it, at least for the medium term * ensure good documentation in the book, in std, prepare blog posts etc If this only happens in 2020, so be it. 
&gt; $body:block (without the comment) works perfectly for me: huh, it sure does. I think I was trying to put the {} around the body block in the macro, which I guess is wrong because those are just part of a block anyway. thanks! 
Your time is so valueless that you'd purposefully spend it on wasting everyone else's time? Don't act like a child.
Thanks. It seems to have worked. The created docset was in the folder from where I ran the dashing command. 👍
i guess i forgot the &lt;/sarcasm&gt;; but my point is that is what people are doing, and no one from rust seems to care? well at least enough to do anything about it
Can anyone explain this: &amp;#x200B; `warning: unused import: \`futures::future::Future\`` `--&gt; src/tv.rs:7:5` `|` `7 | use futures::future::Future;` `| ^^^^^^^^^^^^^^^^^^^^^^^` `|` `= note: #[warn(unused_imports)] on by default` &amp;#x200B; `error[E0599]: no method named \`and_then\` found for type \`impl futures::future::Future\` in the current scope` `--&gt; src/tv.rs:284:30` `|` `284 | let resp = rb.send().and_then(|res|` `| ^^^^^^^^` `|` `= help: items from traits can only be used if the trait is in scope` `= note: the following trait is implemented but not in scope, perhaps add a \`use\` for it:` `\`use futures::future::Future;\`` &amp;#x200B; `error: aborting due to previous error` &amp;#x200B;
Yup. Conceptually Scala is interesting. But I have no interest in the JVM as an infrastructure. And picking up a language that I will only ever use outside of its main usage scenario is not that motivating. By comparison, rust just fits my interests much better. A low level, close to the hardware language. I know, the original question is asking about webdev. Let's just ignore the hypocrisy here :P And in fact, apart from small hobby stuff, I'm much more into algorithms, networking, embedded programming,...
I'm working on adding pattern matching to [tox](GitHub.com/lapz/tox). I've implemented the checking using something I found in a blog post but the codes not deterministic.
Hi and welcome. Please consider to post this on /r/playrust i would guess people are more interested in this over there. This sub is dedicated to the programming language with the same name as the game you love to play.
And actually, I have used Scala before. For a project that used spark. It's nice but (at least for me) python is just so much more productive. Afterwards I redid many parts of the project in python and it felt much cleaner. It was easily fast enough, too.
How does it communicate with Firefox ?
As a uni student who's only played with the AVR chips in arduinos, what advantages do the stm32f1's have in this use case? 
The “browser-like” is misleading you. It just means that it has all the parts of the JS standard that don't need to be available in non-browser environments. It's very much a general purpose typescript runtime.
Going to try and bring rust into an arduino hackathon
Scala.js doesn't run on jvm btw, in case you weren't aware...
Ugh, why would they implement different parsers for markdown.
It will be a busy week. Most of it will be getting [skribo](https://github.com/linebender/skribo) started. But even aside from that, we have the new_algo branch [pulldown-cmark](https://github.com/raphlinus/pulldown-cmark) passing tests, thanks to great work by Marcus, so it makes sense to try to merge to master and do a release. We'll want community input for that. I've been chatting the Rust-VST project, asking some questions about their [roadmap](https://github.com/rust-dsp/rust-vst/issues/81), and also getting a prototype of druid-based GUI working as a plugin. I want to get the changes for VST in early, so that community work done on druid doesn't break it. Oh, and I've filed for an LLC for the upcoming font editor project. I'm actually in need of one or two small invoiced consulting gigs, so if you have one please get in touch (rates very negotiable).
A couple of years back there was a paper about implementing a GC in rust by a group that does a lot of GC related research. Took me a while to find it but here it is. [http://users.cecs.anu.edu.au/\~steveb/pubs/papers/rust-ismm-2016.pdf](http://users.cecs.anu.edu.au/~steveb/pubs/papers/rust-ismm-2016.pdf) Anyways I tried to find the code they wrote but didn't find anything. While searching I also ran into another related work. [https://cse.buet.ac.bd/thesis\_add/thesis\_file/1105015\_1105084\_1105101.pdf](https://cse.buet.ac.bd/thesis_add/thesis_file/1105015_1105084_1105101.pdf) &amp;#x200B; Don't know if this stuff is any use to you, but I thought I'd share it anyways.
I want to make 'pub' optional on this macro, I've tried a few things with no success: &amp;#x200B; [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0e937db81c2911069117328dc69dea0e](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0e937db81c2911069117328dc69dea0e) &amp;#x200B; The workaround is to have two separate matches, which works, but would like to avoid the duplication if possible &amp;#x200B;
Singapore 
oh, neat! i’m happy i could help, uom seems like a very natural fit!
Personal opinion: It sucks for (younger) people who do not own domains and/or who do not work in/for companies. And sometimes company/domain names change. I still see the benefits. But I found it very offputting when I first encountered it. It feels very enterprisey to me and personal projects just don't fit in there. I like the approach taken by Github and Docker much more. You have your primary nickname and then you have a project name. Example: rust-lang/rustfmt [https://github.com/rust-lang/rustfmt](https://github.com/rust-lang/rustfmt) Besides, if you depend on domains for package names, you just move the name squatting conflict to the DNS registries.
&gt; vim-style commands are not on my list (Emacs user, sorry) Emacs and vim commands are pretty similar; the main difference is that the first one are triggered with `M-x` and the second ones with `:`.
Would love to give it a read if it has already been translated. Thanks for your work.
It still is.
well, I can always experiment with this stuff with git checkouts, so don't make a crates.io release just for me :)
Note that npm has org-scoped packages. Also, npm and pip might have no issue of squatting (I didn't check), they have had security issues though, e.g. malicious packages. As far as I'm concerned, I don't mind people squatting for the sake of squatting, in the end it's just using a name, and except if there's a trademark, why not. I mean, I don't mind typing reqwest instead of request, and I don't mind the guy who squatted all popular names with a WIP description, because reading the description tells me not do download it. The real problem will start when people will squat names for malicious purposes, e.g. creating malicious crates with "innocent" names (yaml-parser, ini2json, whatever). That, plus the search system of crates.io which isn't optimal (not blaming them, even npm's is bad), and you have an exposed malicious lib in the official repo of a language which has "safe" in its motto. Rust community is amazing and very contributive, I'm pretty sure enough people would volunteer sight-reading crates just to see if a crate is malicious or not. Also, I would split crate repos in 2 parts, with a trusted repo containing only org-scoped crates (you need to own the domain to register an org, ala Java), and a playground. Debian didn't earn it's reputation of "safe and stable" by allowing everyone to publish crap on the apt repository.
I expect the vector to have roughly millions of elements, and I search between each insertion.
Honestly I'm not entirely sure. I picked it because it's ARM and it seemed like that's a better supported cross-compile target than AVR is for Rust. There's a lot of documentation, tutorials, and libraries aimed at doing STM32 dev with Rust (even though the STM32F1 HAL crate has some pretty important functionality that's currently disabled/not working). I actually started out trying to write a HAL for the e-paper module built on top of the embedded-hal crate, but I wanted to support DMA to SPI transfer for writing image data to the device which is when I discovered that the STM32F1xx-hal crate has the DMA code commented out. Following that I decided to abandon the HAL idea for now and just rewrite using the lower level cortex-m crate which requires doing a bunch of consulting the hardware docs to lookup exactly which bits need to be pushed into which registers. It's been a lot of work, but I've learned a lot in the process which is kind of the point of the exercise. Last time I looked into doing embedded dev in Rust I know that AVR wasn't supported as LLVM hadn't merged the AVR support branch yet, but I'm not sure what the current status of that is. Do you (or someone else) have more recent knowledge of doing AVR dev in Rust?
Any company name or direct email address to send the CVs?
If the vector size &gt;&gt; insertion size in-between searches then the vector is a poor fit. If you can batch insert, nothing beats the data-structures that you can build using a vector performance-wise.
Just go through to the link and hit apply to send your details over. 
thanks. No translation yet.
That is a very polite explanation, outstanding ;)
The only real solution might be to rely on the community reporting bad-faith crates.
&gt; how is that possible there is nothing in them..what exactly is going on here? I am just frustrated that years later and this is still a problem There are legitimate bots that periodically download every crates.io crate ever existed, like [Crater](https://github.com/rust-lang-nursery/crater). Also I guess some big companies have internal mirrors.
I don't think saying they don't care is fair. The problem is that pretty much every reasonable solution to this problem involves human-to-human communication, and they don't have the bandwidth to do that. &gt;1 it makes it that much harder for people to get into rust and publish their own crates Making people go through a name-conflict resolution process to get a name allocated to them does not decrease the barrier to entry. The most beginner-friendly option is the one we have, where you simply pick a crate name and publish with it. In fact, that's one of the reasons it is so easy to squat on crate names! &gt;2 it's deceptive why do these all have 100 or so downloads? How is it deceptive? Crates.io can't tell why something is being downloaded. Someone writes a tool to crawl the site and archive all the crates, then those are going to count as downloads. &gt;I am just frustrated that years later and this is still a problem Pretty sure humans have spent trillions of dollars and many millennia on this problem, so a small group doing it in a few years might be too much to ask.
Is there any place to report users like this one?
As a child I had one of those turtle sandboxes. One day I forgot to put the lid on it -- my cat used it as a giant litter box.
Linked above this guy is squatting 104 items https://crates.io/users/swmon
I would also like to use Rust more on the frontend. Every once in a while I experiment with what is available and I can say it is getting better but in my personal opinion it isn't quite ready for prime time. On the backend I think things are in a state that it is safe to move forward and I have several services running in Rust at this time but I wouldn't bet on Rust + WASM for the frontend at this point in time. &amp;#x200B; That said my most successful experiment using Rust + WASM for an experimental frontend to prove out a backend service used [https://github.com/David-OConnor/seed](https://github.com/David-OConnor/seed). It went really well. I like Yew but Seed is simple and easier to get started with if you want to experiment.
No, don't go there. It's an endless dialoguesqe forms. No , thank you 
Small noob question concerning [Rocket](https://rocket.rs/): Is there an easy way to mutate the managed States? Example: #[post("/clear")\] fn clear(state: State&lt;ServerState&gt;) -&gt; String { state.clear(); // ^--- Mutating fn inside ServerState ("pub fn clear(&amp;mut self) { ... }") // This obviously doesn't compile, "Cannot borrow immutable local variable `state` as mutable". // Changing State&lt;ServerState&gt; to &amp;mut in the function header makes rocket unhappy // and is probably not intended: // "the trait `rocket::request::FromRequest&lt;'_, '_&gt;` // is not implemented for `&amp;mut rocket::State&lt;'_, server::ServerState&gt;`" state.to_string() //not important } In the rocket examples, they often use atomic data structures etc. when mutating state. Will I have to change all my code to use these or is there an easy, obvious solution I'm overlooking? Workarounds are fine, I just want to try rocket with a small application, it does not need to be super safe (well, it will be anyways, because Rust).
You can just use your GitHub to log in, makes things much smoother and quicker. 
Do you have a link for what’s holding this back? Returning impl Trait from trait methods would seem like the primary use case I’d want lol.
I'm working on a personal code coverage report generator (e.g. highlight code \*you've\* written), rounding it out a little this week at work. I'm hoping to open source it.
I did, and then comes next the endless dialoguesqe form you have to reply. It's not worth going through all of it, when what you need is just the email where you can send the CV in.
Started rewriting my reddit bot (originally written in a mix of Kotlin and bash) because currently it just takes too much memory, is too buggy and the code is a mess. Also started writing a text adventure game, or at least the foundation/engine for it. I'm really noticing the very different memory management of Rust here compared to something GC'd like Kotlin, haha
Not to be confused with [Lustre](https://en.m.wikipedia.org/wiki/Lustre_\(programming_language\)), the programming language.
Yeah that’ll be perfect, I’m looking forward to that feature.
Is it planned?
Obviously. It's called Scala.JS I'm just saying: The 'canonical' way to do webdev is Javascript. Maybe with a thin layer on top, like Typescript. Using Rust for webdev would be a way to get better at Rust, not a way to get better at webdev. And I want to get better at Rust. Because there are many scenarios where I can see myself using it (plus it's lots of fun). That doesn't apply to Scala (maybe the fun part). 
seems thorough, would give it a read, too, I guess!
Hello r/rust. I've been working on this tool for only a short period of time. I'm just looking to gather some opinions on whether this is something people would use or not. I originally wrote it for my own usage but I chose to audit and build extensions instead. I've been finding it quite difficult to write clean Rust code. If you take a look at the source, it's not pretty. Feedback would be appreciated. Thanks.
Is anyone able to set the Rust SDK to nightly? I've tried pointing IDEA at it, but...it seems to ignore the directory I choose.
Yes, we've been focusing more time on tower crates with the goal of publishing to crates.io. I can't say exactly when, but it is the goal for soon.
You can change it to `fn clear(mut state: State&lt;ServerState&gt;)`. This doesn't change the actual type of `state`. It just changes the binding of the parameter. It's the same as `let` vs `let mut`.
I was familiar with WebPack and the whole JS ecosystem since I use it a lot on its own, but yeah that's certainly an option as well.
/r/rustservers
Is the plan to have an english translation published? Any planned release date yet? 
It’s actually also off topic for playrust, they need to post to /r/playrustservers
Now it understand doctests and provide highlighting, completion and other code insight for it! 
For example, CloudFlare workers have a maximum bundle size of 1mb. A hello world in Go compiled to wasm is just over a megabyte, thanks to needing to bring the runtime along.
It *should* work with rustup overrides
looks like the many off topic posts made you a Rust(Game) expert! :D
It now supports doctests! [https://twitter.com/intellijrust/status/1102612218460471297](https://twitter.com/intellijrust/status/1102612218460471297)
[Full, not-compiling example without dependencies (except rocket)](https://pastebin.com/kUAVFeBf) This sadly still does not compile (cannot borrow data in a \`&amp;\` reference as mutable). This makes sense as ServerState should be mutable... Thanks for your reply though.
Project ideas for an extreme beginner?
I have been through this process and it only takes about 120 seconds lol! Surely you can see the obvious reasons a global hiring platform would have you apply through them, rather than just giving out email address of hiring managers
The simple solution is to wrap your mutable state in a [Mutex](https://doc.rust-lang.org/std/sync/struct.Mutex.html), then `lock().unwrap()` to get your now mutable structure. This has performance implications, as only one thread can access that State object at a time. If your structure is mostly just read from, look into RwLock as a wrapper instead of Mutex, which allows multiple read-only locks to be taken out at a time. Besides the locking, your code shouldn't need to change. ``` #[post("/clear")] fn clear(state: State&lt;Mutex&lt;ServerState&gt;&gt;) -&gt; String { state.lock.expect("couldn't unlock").to_string() } ```
Is Firefox Send documented anywhere? I clicked on "Learn More" at send.firefox.com, but it goes to this test pilot thing that has been closed down.
Thank you very much, exactly what I needed.
Even for me. I rarely have borrowing issues, but it would be great to be able to see them for when I do.
Yes, but that makes the Gc not independent of Lua then :P That's my only issue really, if I just accept that the Gc is not independent, then it's not such a big deal.
So, just so you're aware, 'rlua' exists as a practical bindings system to PUC-Lua 5.3 that's usable *right now*, this is still in the experimental phase. I don't think it's going to beat javascript engines like spidermonkey or V8, not even close, it's not a JIT, so no LuaJIT either. This is mostly an experiment for general techniques to build interpreters. As far as killing a script after a timeout, that's a technique that works in probably all interpreters, including PUC-Rio Lua and LuaJIT at least (and is exposed via rlua). What works in only a few interpreters (including luster) is the ability to pause a script at 500ms say, then continue it later.
That's unfortunate, I tried to pick a name not in conflict with anything related but I guess I failed... I wonder if I should pick a new name?
Well, Luster is currently just an interpreter, so the moment the JIT kicks in for either runtime, Luster flat-out loses. A comparison to CPython, or LuaJIT in `-joff` might be more apples-to-apples.
Nice, if long, article that highlights Rust as potentially the best "lowest common denominator" language. I was expecting a second GitHub repo though. One that focussed on that as technology that would be reusable for non 'wirefilter' usage (with a non 'wirefilter' example). A repo that others could donate to make optimized FFI bindings to Java, Python etc.
Eh.. it's sufficiently different in scope and Lustre is spelled differently and from 1991 and no one uses it.. I wouldn't sweat it. I just thought it an interesting lesser-known language to throw out there in case it piqued anyone's interest ;) Your software reminded me of it due to the name, that's all.
Can I get a flair here at /r/rust? Have no idea where else to ask :)
Great stuff as always, cheers to all the contributors! // Now if only rustfmt binding respected the project’s rustfmt.toml...
I suppose you are right, this is an unsolvable problem
Thank you [u/jschievink](https://www.reddit.com/user/jschievink/) ! That worked. Command for those who don't wanna google: \`rustup override set nightly\`. That said, I think IDEA still reports the toolchain version wrong? I'm definitely using rustc 1.34.0, but it's still being reported as 1.33.0
Note triple backticks do not render code properly in the majority of reddit mobile clients. Please use 4 space indentation instead. 
I'm working on some PyTorch bindings via their C++ api. The current state can be checked out in the [tch-rs github repo](https://github.com/LaurentMazare/tch-rs) - there are examples training some recurrent neural networks on text data or conv nets on images. In the coming week I plan on adding some standard vision models (resnet, densenet, ...) with pre-trained weights that can be obtained from the python implementation.
Tokio is a quite a tough one! \[This\]([https://www.snoyman.com/blog/2018/12/rust-crash-course-07-async-futures-tokio](https://www.snoyman.com/blog/2018/12/rust-crash-course-07-async-futures-tokio)) superb tutorial made it click in my head though!
Sure, thanks for the info.
Look at it from the employers perspective: dozens of emails are not exactly a good way of managing applications. You end up having to transfer data into some CRM/recruiting tool anyway. Which is both cumbersome and error prone. Time that is better spent in properly reviewing applications, IMO. Yes, I also often find the application forms pretty annoying, but in the end it's a net benefit.
With a modern IDE like intellij-rust you'd just type `.r&lt;enter&gt;`.
Thanks for the feedback! &gt; on that as technology that would be reusable for non 'wirefilter' usage I'm not sure I understand - what is "that as a technology" in this context?
Depends entirely on your level of experience and interests. Advent of Code is often a good place to start.
My only guess is that you are doing something like this: use futures::future::Future; mod inner { fn example() { my_future.and_then(/* ... */) } } This won't work because imports only affect the module they are used in. If this isn't the case, then I'd need to see more of your code.
I would definitely buy a copy of a decent translation. Looks really well-organized, and I like the topic coverage.
thanks, guess I've got some lecture to read!
Great to see a Chinese book on Rust. &amp;#x200B; [u/blackang3r](https://www.reddit.com/user/blackang3r), out of curiosity: how popular / well known is Rust in China? And how much of an issue is it that all the documentation, mainly including the std docs and all the ecosystem libraries, are english only? Are Chinese devs generally sufficiently proficient in English to read those? 
You can't. At least not without significantly more than a single method. OpenGL (and by extension the libraries you are using) are designed for *3D graphics,* not displaying 2D images like the one you have. If you really want to continue on the OpenGL path, then I suggest you find a tutorial to follow. Eventually you'll build up to being able to render a full screen textured triangle, which will achieve the effect you want.
Taking things to extreme is not a good way to argue your point (unless you are doing a math proof...). If I take your position to the extreme, it would look like this (taking the first example from the Rust book): define function "main" begin parameter list end parameter list begin body call macro "print line" begin argument list "Hello, world" end argument list end body
I think If I understand you correctly, you want to send a request to Reddit get the access token, then store it so when other requests are made, you can use it there. Under that assumption, you need to mount another struct into Rocket that will act as the store for your access token. But because this is mutable, it needs to be wrapped in a Mutex so only one thread can access it at a time to preserve Rust's borrowing rules. So you might want something like: ``` #[post("/access_token?&lt;code&gt;")] fn access_token(app_info: State&lt;AppInfo&gt;, global_token: State&lt;Mutex&lt;AccessToken&gt;&gt;, code: String) -&gt; Result&lt;(), WhateverYourErrorIsHere&gt; { ... } 
A compiler/linter for Lua with type annotations (like what typescript is to js)
Yeah, I've noticed that the analogy between ordered/unordered state and clapping/not clapping doesn't hold so well. However, the order parameter (you assumed correctly) and the sound level can be correlated. I believe that my tutor chose this model because it's the simplest one and she's already been studying it for quite some time. Also, we've already talked about the long range influence. The project isn't finished yet and I can still implement it in our model. But since we only record clapping intensity - a dimensionless value - I doubt we'll try make it look realistic. 3D sound analysis with multiple microphones or even video analysis would be required to observe these interactions.
I wouldn't fret too much about it, Lustre is pretty damn niche and only exists as part of a proprietary development suite for safety critical applications.
[removed]
How good is this compared to VS Code? It feels like a very expensive investment to buy the ultimate edition just get support for popular frameworks.
It's neither.
To be able to store the access token in struct form somewhere you'll want to use the \`.json()\` method on the request result (instead of \`.text()\` which you're currently using. [https://docs.rs/reqwest/0.9.10/reqwest/struct.Response.html#method.json](https://docs.rs/reqwest/0.9.10/reqwest/struct.Response.html#method.json) &amp;#x200B; Storing it so it can be used elsewhere is another matter. Currently you're passing it back from the request, but you want to store it off somewhere? You're going to have to store it in the app state somehow. You could use a diesel fairing with sqlite3, or you can stick it in something threadsafe, like an Arc&lt;... somthing&gt; - I'm not sure about how to store it in a thread safe manner. &amp;#x200B; About your template context comment (the todo) - you should be able to make a serde serializable struct and use it instead of a context object. &amp;#x200B; One last caution (not sure if you need it or not) - there's a Json type in the rocket\_contrib crate that you can use to wrap a struct and it'll return it as json (presuming it's implemented Serialize). And that's different than the Json type in the rocket crate which is for the header. &amp;#x200B;
At best, it's abductive inference.
You basically want `vis` type (designator): ``` macro_rules! make_fn { ($vis:vis fn $fn_name:ident ($($arg:ident:$typ:ty),*) $(-&gt; $rt:ty)? $body:block ) =&gt; { #[inline(always)] $vis fn $fn_name($($arg:$typ,)*) $(-&gt; $rt)? { $body } $vis fn fn_b($($arg:$typ,)*) $(-&gt; $rt)? { $fn_name($($arg,)*) } }; } ``` This is very useful resource: https://doc.rust-lang.org/reference/macros-by-example.html
what do you mean? which frameworks? I use the community edition which works great for my (small) projects. I think it missed debugging support.
The "fast interpreter" tech. OK, so no new parser tech then, just a reuse of the previously mentioned Rust pieces I guess.
Realistically it's still going to lose even in an apples-to-apples comparison (but hopefully not by as much). I have tried to keep optimization in *mind* during development, but I haven't gotten to the point of actually optimizing it much yet.
This helped: [https://stackoverflow.com/questions/37375712/cross-compile-rust-openssl-for-raspberry-pi-2](https://stackoverflow.com/questions/37375712/cross-compile-rust-openssl-for-raspberry-pi-2) Had to do: cd /tmp wget https://www.openssl.org/source/openssl-1.0.1t.tar.gz tar xzf openssl-1.0.1t.tar.gz export MACHINE=armv7 export ARCH=arm export CC=arm-linux-gnueabihf-gcc cd openssl-1.0.1t &amp;&amp; ./config shared &amp;&amp; make &amp;&amp; cd - export OPENSSL_LIB_DIR=/tmp/openssl-1.0.1t/ export OPENSSL_INCLUDE_DIR=/tmp/openssl-1.0.1t/include &amp;#x200B;
I' working [rpds](https://github.com/orium/rpds/), a library of persistent data structures. I want the reference-counter pointer type to be parameterized by the user. This way you can use `Rc` for better performance, or `Arc` to be able to share the data structures across threads. To do this I recently published [archery](https://github.com/orium/archery/) which allows an easy way to choose between `Rc`/`Arc`, and I'm now working on using it in rpds.
Is there a crate for working with the slack api that people prefer?
I'm working on understanding references and mutability more, particularly \`let test\_2 = &amp;mut test\_1;\` vs \`let mut test\_2 = &amp;mut test\_1;\` vs \`let mut test\_2 = &amp;test\_1;\`. &amp;#x200B; I'm having trouble understanding the differences. For example, why does \`let mut test = "foo";\` make test \`&amp;str\` but it isn't mutable? What's thee difference between \`let mut test = String::from("foo");\` and \`let test = &amp;mut String::from("foo");\`?
There's loads of stuff that is only sorted in the ultimate edition. https://www.jetbrains.com/idea/features/editions_comparison_matrix.html
aha! spectacular, thank you.
I'm having a problem casting to a JsValue using wasm bindgen: `gl.draw_buffers(&amp;[GL::COLOR_ATTACHMENT0]);` E0308: expected **&amp;wasm\_bindgen::JsValue** found **&amp;\[u32; 1\]** Still couldn't find a way to cast this. Help? :) 
I see you commented that you found a workaound by building your own openssl manually. Have you tried adding this to your dependencies? openssl = { version = "0.10", features = ["vendored"] } This is the fix to openssl build/linking problems that as far as I can tell is most reliable. It uses a monster build script to compile and statically link openssl inside your `target/` directory, all as a part of the normal build process.
!remindme 2 months
I will be messaging you on [**2019-05-04 19:24:28 UTC**](http://www.wolframalpha.com/input/?i=2019-05-04 19:24:28 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/rust/comments/ax86y1/introducing_the_book_the_tao_of_rust/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/rust/comments/ax86y1/introducing_the_book_the_tao_of_rust/]%0A%0ARemindMe! 2 months) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
I'm trying to build a script that is not mine. Perhaps I should post a pull request linking you comment.
Thank you for your help &gt; it needs to be wrapped in a Mutex I read something about the Mutex and that it might be needed, since the State is shared across threads and cannot be mutable, I need a mutex and accss an inner mutable which is my State&lt;AppInfo&gt; if I understood that part correctly. But never had tocuhed a Mutex so, I did not try yet. &gt; Without knowing if you want to return an HTML template or how you plan to handle multiple users, I don't know if I can help more. It's basically a 1 user application. I want to access my reply and the comment I replied to. The ideal would be that I click the buttons from the root and all requests, except the authorization, wich needs me to click a button, would be done in the background asynchronously: index&gt; click authorize &gt; redirect reddit auth page &gt; redirect index &gt; click fetch &gt; receive access token from route:access_token &gt; fetch desired data &gt; redirect to route:index match params if some display on the page. I am currently stuck with even receiving an access token. For some reason it says the code is already used (invalid grant). 
Wrong sub, try /r/playrust
Ah... I suppose it's mostly a description of an approach rather than a library, and, once familiar with, pretty easy to introduce to any project as `Box&lt;dyn Fn(...task-specific params...)&gt;`.
so I add a field access_token: Opton&lt;AccessToken&gt; to my AppInfo, in the route Index I am expecting, instead of an State&lt;AppInfo&gt; an Mutex/Arc&lt;State&lt;AppInfo&gt;&gt; is that correct? &gt; About your template context comment (the todo) - you should be able to make a serde serializable struct and use it instead of a context object. ​will try :) I had trouble there too. 
Send a mod mail asking for the flair and showing your contributions.
Do you think of a Rust reference as a const pointer? ie. you can't change what it points to, but you can modify what it points to. (Not to be confused with a pointer to a const)
I think r/playrust is the place you're looking for g
I'll jump there then, thanks!
When you're writing `let mut test = "foo";` you're creating a mutable binding, that is, you can assign a different value to it, e.g. `test = "bar";`.
Is there an html library that does this? 
Third candidate for r/lostRedditors on this sub which I observed
Yes this is how it is done in the PHP community for example. They use the `vendor/packagename` pattern. Apart from preventing squatting it also has other benefits: for example crates that are abandoned by the original authors can be easily forked and published under another vendor. Also some things are so common that there can be multiple libraries doing the same thing. It's much easier to call your logging library `myname/logger` instead of having to come up with the 200th variant to avoid naming conflicts. Here is how it looks for PHP: https://packagist.org/explore/popular
You can use [minifb](https://github.com/emoon/rust_minifb). It was made exactly for this purpose.
This thread is specific to the IntelliJ Rust plugin. None of the items listed in the Ultimate/Community comparison are relevant to Rust. The only paid vs. community feature relevant to Rust is debugging support, which is only available in the paid CLion IDE. &amp;#x200B; To answer your question, VSCode vs. IntelliJ, w.r.t. Rust, IntelliJ's code intelligence is much better. You can use IntelliJ Community for development and fire up VSCode only when you need debugging. If you need integrated development and debugging, buy CLion. &amp;#x200B; To answer the question it sounds like you're asking, VSCode vs IntelliJ Ultimate, it's an apples to oranges comparison. One is a professional IDE, the other is a very nice text editor with plugin support, and which one will work better for you depends entirely on your specific scenario.
Why does io::Result have to be its own distinct version of the generic Result type?
As it happens, many Rust data structures already implement this pattern: https://doc.rust-lang.org/std/cell/struct.Cell.html#method.take
Only the third? You must be new here! Check [this talk](https://m.youtube.com/watch?v=lY10kTcM8ek) out for a fun way to deal with it.
It's not, it's just a type alias for `result::Result&lt;T, io::Error&gt;`.
It doesn't really affect rust development, the rust functionality for Intellij comes from a plugin that is equally available on both community and ultimate versions.
I'll check it out. Thanks! 
If you're building from source, you can always edit the Cargo.toml yourself. If you want me to handle sending a PR just drop me a URL to the project, always happy to improve other people's experience with Rust.
It won't compile on my system. Something about x11, which I (think) have.
I just used dashing a few days, maybe two weeks ago to generate docsets for zeal out of the imag sources. Took quite some time, but worked. I'm on mobile, so I cannot easily link, but go to the imag repo on github and have a look into the scripts folder.
&gt; The Rust that can be told is not the eternal Rust; The name that can be named is not the eternal name.
Honestly, I'd go even further. I've got a "to-do" list of projects I want to get to and I'm considering grabbing the names of projects that I know that I won't get to for months/years because I don't want a low-quality squatter to get there first. I hate squatting yet I'm considering doing it to protect myself from other squatters. If that's not "encouraging squatting" then I don't know what is.
I guess that's true, but it also means that I would have to have two editors open at the same time to do development if I decided to use Intellij, unless I paid for the license. That's why I asked.
Ironic, but software engineers are the ones who hate software the most.
Still not responding to my PM? 
I've never worked with wasm/wasm_bindgen before, so maybe someone else will have a better answer than me. But the error message alone is enough to discern a few things. The first issue is that you're passing a reference to a single-element array of a value to a function when it's expecting a simple reference to a value instead. If you change your code from `&amp;[GL::COLOR_ATTACHMENT0]` to `&amp;GL::COLOR_ATTACHMENT0` then you'd solve that first problem, but then you'd still have the issue that the function wants a `&amp;JsValue` and not a `&amp;u32`. Looking at the [docs for JsValue](https://docs.rs/wasm-bindgen/0.2.38/wasm_bindgen/struct.JsValue.html), it seems that you're supposed to create one via constructor methods instead of doing a type cast. There's no constructor that accepts a `u32`, but there is one for `f64.` So if I were in your position I would try something like this: let js_value = JsValue::from_f64(GL::COLOR_ATTACHMENT0 as f64)` gl.draw_buffers(&amp;js_value);
It's hard to tell but maybe you're talking about the videogame? In which case you want /r/playrust. That said I'm not sure if you'll get much more of an enthusiastic response over there.
I have CLion and i rarely use the debugger for Rust. Its different for other languages where i often use a debugger but for whatever reasons in Rust i don't. I like to use gdb for embedded development though – its just very helpful to inspect your microcontroller/sensor/motor contraption step by step to watch the peripherals are behaving nicely. So no, you don't need to have both open at the same time – at least not for long. Just speaking from my experiences, YMMV. 
This looks awesome! I'm learning Rust myself and this looks like a fun project to build off of. 
I always like a couple first projects for any language: * Chatbot in any medium: helps learn string manipulation * Simple data structures: helps learn data layout of the language / generics. Full disclosure, this will be harder in rust. * Small webserver: helps learn async properties of a language. You can choose to do this with futures or not. Feel free to use libraries like Actix or Rocket * Small personal project: I recently wrote a program that queries my router for attached devices and a python script that reads the stored data and makes a Gantt chart based on connectivity. * Small shell program: bonus points if it supports backgrounding * Bindings to another non-rust project: grows the ecosystem and helps learn program interop.
Stylo is in prod, webrenderer is enabled by default in nightly Firefox if the host supports it and is behind a feature flag in stable.
I'm going to be doing some work on [tarpaulin](https://github.com/xd009642/tarpaulin), merging in some changes to improve CI support, making some bits more usable and trying to tackle a bad-jump based issue. Also, I've been working on an ndarray based computer vision library [ndarray-vision](https://github.com/xd009642/ndarray-vision). Will be finishing off my Canny Edge Detector implementation and maybe histogram equalisation (waiting for a PR to merge in ndarray-stats). Might publish something to crates.io in the coming week!
I know I should be using CLion since I have a license but I end up doing almost all of my Rust work in IntelliJ anyway since I'm the kind of person who only remembers debuggers exist after peppering the code with print statements.
Relevant links: * RFC: https://github.com/rust-lang/rfcs/pull/2071 * Tracking issue: https://github.com/rust-lang/rust/issues/34511 For some reason Niko closed the tracking issues for this more specific part of the larger `impl Trait` feature, so it's a little hard to follow what's going on with it.
No, that function should receive an array of u32 / i32 enums. [https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/drawBuffers](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/drawBuffers) Wasm is weird.
Do you know where I would be able to read more about the problems you encountered when trying to make bindings to regular PUC-Lua with rlua? PUC-Lua generally tries really hard to be portable and enbedabble, and generally has done a great job at that over time when interfacing with C or C++. Is there something about the current API that makes it interact particularly bad with Rust? Do you think there would be a way to change the current C API to make embedding Lua inside Rust easier?
Well, guess that's what I get for answering outside of familiar domains. I'm not quite sure why the function threw an error about &amp;JsValue if it wanted an array, but I've already demonstrated that I can't stumble upon the answer by navigating the type errors =P
By any chance, does this job have anything to do with a blockchain?
Thanks anyway. I've created a [post with a little bit more detail](https://www.reddit.com/r/rust/comments/axdc8j/webassembly_webgl_casting_an_array_slice_to/).
The PUC-Lua interpreter is already written in stackless style, without recursion (this is what lets it does the coroutines). Could you clarify where luster differs from that? I am getting the impression that you are using a very different style of Rust-Lua API, where the Rust local variables can directly point to Lua variables.
Is there such thing as `&amp;mut str`? I've never run into that before.
We can compare `&amp;**x` to C++ relatively easily Let's say x has a type of `T*`, and T has a member function `U&amp; operator*();`. The rightmost * will dereference the T* to a T&amp;, then the second one will call `operator*()` on the T, and then the last &amp; will turn the reference into a `U*`. Its basically the same in Rust, except it calls the `Deref` trait instead of `operator*`
JsValue is an enum representing JavaScript value. draw_buffers expects to be passed a JsValue, and it expects that JsValue to be an array, and it expects that array to contain only JsValues which are numbers.
Not an expert on wasm, but it looks like you want to make an `js_sys::Array`, which implements `AsRef&lt;JsValue&gt;`.
Yes, but it's not very useful. You can't resize it because it's a slice and doesn't manage the underlying allocation; you also can't do a whole lot to mutate it because it must always remain valid UTF-8, meaning that you can't safely change bytes within the string or replace one character with another (because different characters are encoded with different sizes in UTF-8, so doing so might change the length of the buffer, which as we mentioned before can't be done either). There are a few methods (such as star::make_ascii_uppercase) that expect a &amp;mut str, though.
If you want some help with the blog post you may want to check out [Hisham Muhammad's master's thesis](http://www.lua.inf.puc-rio.br/publications/hisham06study.pdf). It compares Lua's C-API with the C-APIs for Python, Ruby, Java and Perl. &gt; My dream here is basically a Lua interpreter where the decision to rewrite a section of a script in Rust is more often than not a speed increase This is also something I have been thinking about a lot. I have been approaching this from the opposite direction, by trying to design a static language that "conforms better to Lua" with [Pallene/Titan](http://www.inf.puc-rio.br/~hgualandi/papers/Gualandi-2018-SBLP.pdf). At a high level, the compiler can keep track of what local variables are live or not, which allows it to safely bypass the usual Lua API. Under the hood it obviously depends on all those unsafe pointer tricks and carefully-placed write barriers.
&gt;Array I didn't see that array, it seems to compile. Thanks!
Microservices in Rust! that sounds cool
This is the project https://github.com/martinber/noaa-apt I've linked your comment to the owner of the project as well.
Make it a trait for your crate, maybe it's so useful you will want it in a helper library, so you publish it somewhere. trait Take { fn take(&amp;mut self) -&gt; Self; } impl&lt;T: Default&gt; Take for T { fn take(&amp;mut self) -&gt; Self { std::mem::replace(self, T::default()) } }
If `Bar` implements `Default` trivially (meaning without any allocation), shouldn't it implement copy, in which case you can just copy it? More generally, using an option inside the struct to get around consuming the struct seems like a code smell - if you don't care that it's been replaced with a default value, then it should should probably be separate from the rest of the struct... (e.g. you could pull the rest of the fields into new struct that the old struct contains. Then you can implement the methods that don't care about it on the new struct)
TL;DR: Instead of full-on JIT compilation they choose one of the several implementations compiled ahead of time for each AST node and store a pointer to it. This is somewhat slower, but dramatically simpler than a full-blown JIT compiler.
TenX [Here is the job description](https://tenx.workable.com/jobs/689264) 
This looks very interesting. Re: prior art, not a GC technique per se but this has a lot of similarities to 'State Threads' in Haskell (i.e. the ST Monad), which uses a unique phantom type variable (similarly to your lifetime parameter) to define a safe arena of mutability. So you have a type parameter that is inexpressible outside of the ST computation, which all mutable variables are parameterized on, and since it's only expressible within the given state thread, it can safely be accessed there with the guarantee that it will never leak to code outside. (see: [https://www.stackage.org/haddock/lts-13.10/base-4.12.0.0/Control-Monad-ST.html](https://www.stackage.org/haddock/lts-13.10/base-4.12.0.0/Control-Monad-ST.html)) Whilst the usage is difference, the principle of encapsulating types into a safe 'arena' via expressibility of a type parameter seems to be the same. Your use case seems novel to me but also seems like a good application of this technique, I'm very interested to see where you can take this.
Great and intuitive article. I look forward to seeing the future of Wasm.
Have you played with `std::sync::mpsc::channel`? The Rust Book has a [good primer on it](https://doc.rust-lang.org/book/ch16-02-message-passing.html). Think of actors behaving similarly, passing messages to each other and potentially updating internal state.
I don't really know of anywhere you could read about it, because I have never seen it written about anywhere, that's part of the reason I need to write about it myself. the 'rlua' crate represents the best way I know how to make a safe Lua &lt;-&gt; Rust bindings system, so you can look at the complexity there to see how difficult it has been. The major difficulty is using lonjmp for error handling, but there are others.
&gt; The PUC-Lua interpreter is already written in stackless style, without recursion (this is what lets it does the coroutines). Could you clarify where luster differs from that? It is not, but to be fair I might be using the term "stackless" differently or incorrectly, I'm not sure. Lua is written not to use the C stack when interpreting *only Lua*, but it absolutely uses the C stack for recursing into C or back into Lua from C, and there is a maximum recursion depth here of something like 250. This is totally reasonable, don't get me wrong, but it doesn't completely follow what I'm taking to be "stackless style". For example, you can take PUC-Lua and add a hook function to a script to stop if the number of VM instructions exceeds a value. What you can't do is stop the interpreter *and then resume it later*, or say to the interpreter "please execute 1000 VM instructions, then return to me a handle to continue later*. One of the reasons for this is that the interpreter has no way to deal with continuing any sort of callback, so this could only really work with one level of only Lua on the C call stack. Luster is not written this way. I'm not saying it's strictly *better*, it comes with its own downsides sure, but it's a requirement for expressing the safe GC system so it exists, and it has benefits.
&gt; It is a literal non-starter. I agree completely that a 1MB download is a complete non-starter. However, a simple mark-sweep GC should be a tiny fraction of that size. 
&gt; For raw speed I think it might be possible to expose a lower level C API than PUC-Lua does right now, to let you directly hold pointers and so on. In fact, I think there were some unnoficial attempts to do this over the years (I don't have the links with me right now). The only reason PUC-Lua doesn't already do so already is because it would contantly have backwards-incompatible changes, and to discourage uncautious C programmers from shooting themselves in the foot :) I'm going to cover this in the blog post, but the problem here (as I see it, I might be wrong) is that it seems to require manually dealing with write barriers, trace-ability, and GC safety, which are pretty hard problems to solve. The reason I'm working on luster *is specifically to solve this safely*. It's still pretty research-level, right now it works and is safe but it's not convenient or fast yet. I'm pretty sure I can make it fast *enough*, but not sure about making it terribly convenient. &gt; BTW, how does luster handle Lua pointers inside C datastructures? Is there a restriction that all the Rust objects must also implement the "collectable" trait? There's no C, but yeah, there's a garbage collection system underneath this whose *raison d'etre* is to make this stuff expressible safely (in the Rust sense of safe, it is impossible to cause UB without writing 'unsafe'). Without typing 'unsafe', rust structures that live inside the gc "arena" must contain only types which implement `Collect`, and their own `Collect` impl is programmatically generated.
PUC-Lua can optionally be compiled to use C++ exceptions instead of longjmp. Do you know if Rust has a way to let C++ exceptions trigger the Rust destructors or some way to raise a "rust exception" from C code? (I am a bit of a Rust noob)
Thanks
Yeah. We’ll see!
No, Default doesn't imply copy.
&gt; Dynamic template engines load the source of the template and process it somehow at runtime. This category includes Mustache, Handlebars and Zola's own Tera. Poor [liquid](https://github.com/cobalt-org/liquid-rust), it always gets left off these lists. &gt; ll of the dynamic engines I've listed above can render templates out of Rust types, but they always create some sort of a dynamic structure first (usually JSON-equivalent recursive enum using serde's Serialize), and those structures almost always use a HashMap, a BTreeMap or similar. Given a struct: imo I think the cause of the benefit is not coming from a `dyn Content` but from other things, depending on the application. For example, a static site generator will probably be operating on the template engine's native types anyways, removing the conversion overhead. The reason why engines like Tera have overhead is - Accepting a `Serialize` when you already have a template-native type requires `clone`ing everything. This is captured in template benchmarks. - A static site generator needs to merge the data from multiple sources. Some are per-site while others aren't. To put this in template-native types, you generally have to `clone` all of the data into a single hash map. This is not covered by most template benchmarks. Liquid has never used serialize in the API but instead allowed the user to choose when they convert to `liquid::Value`, solving the implicit `clone` from `Serialize`. Recently, Liquid has switched to a `&amp;dyn ValueStore`. While this still needs a lot of work, this solves the second problem. A static site generate can have a `struct Globals { site: &amp;Value, collections: &amp;Value, page: &amp;Value }` that does a `impl ValueStore. Now we no longer need `clone` the data into a single hash map. A couple of problems I still need to solve - Make it so the `impl ValueStore` can have non-`Value` members. The problem here is that Liquid allows you to iterate on any hash, so I need to be able to support serializing the user's data to `Value` on-demand. The reason I can't now is because `ValueStore` returns `&amp;Value`. Even once I do this, it will be up to the user to decide how often someone might iterate on a `struct` and to decide if its worth pre-converting it to a `Value` instead. - Ruby Liquid supports `array.size` but I don't yet. I want to put all indexing into the `ValueStore` rather than special casing this one. The problem is `ValueStore` would need to return a `&amp;i32` but a `Vec` can't offer that, requiring a `Cow`. Some reasons Liquid doesn't see more improvement, at least on [DJC's benchmarks](https://github.com/djc/template-benchmarks-rs) - To support assigning new variables, we need to read a variable "at the same time", so things like for-loops `clone` the entire array we are looping over - When using a for loop, we then need to `clone` some of the data again to put it into the user's named variable since I can't make guarantees on the lifetime of the referenced (again, the user could assign into the variable we are referencing) - Unrelated to a `&amp;dyn ValueStore` is that each execution unit in liquid is a `Box&lt;dyn Renderable&gt;`. I can't as easily bake all of the logic (render, for loop, conditionals, pass-through text) because of the flexibility of liquid. Liquid supports a limited plugin kind of like functions but its tag/block plugins are full language plugins with access to parsing and allow arbitrary execution of code (from liquid's perspective). I've toyed with the idea of improving these but the cost of making these changes is big and the benefit is unclear.
Why not instead rely on PHF? Its designed for this very problem (compile-time generation of runtime lookups).
&gt; The reason I'm working on luster is specifically to solve this safely Even if we find a way to do that, I think that there is a good chance that it will end up looking like a safe API layered on top of an unsafe API. I would expect an incremental GC to need write barriers *somewhere*, right? &gt; rust structures that live inside the gc "arena" must contain only types which implement Collect, and their own Collect impl is programmatically generated. This definitely makes a lot of sense. While the PUC-Lua garbage collector doesn't offer a way to trace non-Lua objects, I would expect that it might be possible to extend it to allow for that if you have the restriction that the foreign objects have the right "header" and that there is a trusted (and preferrably automatically generated) "trace me" function available. It would definitely be a cool R&amp;D project :) You would still need to find a way to tell the Lua GC about variables living on the stack. Maybe you could root things when they come into scope (Rust constructor) and unroot them when they go out of scope (Rust destructor)?
That wouldn't help because you wouldn't want to only trigger unwinding, you would want to turn that error handling into `Result` error handling. That's basically what rlua is built to do. It wouldn't be so bad except `__gc` + erroring exists, so *most* Lua API functions can throw any type of error.
building a rest api with rust / nickel and also a little CLI utility for my own personal use
The mark-sweep GC in my [HLVM](http://www.ffconsultancy.com/ocaml/hlvm/) project was only 100 lines of code, for comparison. 
I know. I considered a proof of concept bot that crawls GitHub for unpublished Rust projects and registers them with crates.io.
&gt; Even if we find a way to do that, I think that there is a good chance that it will end up looking like a safe API layered on top of an unsafe API. I would expect an incremental GC to need write barriers somewhere, right? It does: https://github.com/kyren/luster/blob/366904b4f201f2de5a7089319984f0ffe475761d/gc-arena/src/gc_cell.rs#L8 &gt; This definitely makes a lot of sense. While the PUC-Lua garbage collector doesn't offer a way to trace non-Lua objects, I would expect that it might be possible to extend it to allow for that if you have the restriction that the foreign objects have the right "header" and that there is a trusted (and preferrably automatically generated) "trace me" function available. It would definitely be a cool R&amp;D project :) &gt; You would still need to find a way to tell the Lua GC about variables living on the stack. Maybe you could root things when they come into scope (Rust constructor) and unroot them when they go out of scope (Rust destructor)? This is kind of what luster's gc system does, except I solve the problem in the opposite way by making Rust prove that there are no Gc pointers on the stack when gc takes place. That way, moving Gc pointers around doesn't incur the cost of things not being Copy (In C++ terms, that they would require copy constructors, destructors etc, luster Gc pointers are seriously *just* a pointer and a fancy lifetime). In Luster this is taken to the extreme, even the interpreter itself is Gc safe. Seriously, there's a *few* lines of unsafe code in luster but it's not Gc related stuff at all, it's mostly re-interpreting floats*. (*) Okay that's a *mild* lie, there's a few lines in luster that look [like this](https://github.com/kyren/luster/blob/5ec8aa37e89ea6734d816d0238e687a0e9ff4a4e/src/callback.rs#L9) which are technically unsafe. I hate them, and they only exist for a really, really dumb reason. In order for the automatically generated `Collect` impls to be safe, the type must have an empty `Drop` impl. HOWEVER, writing any sort of `Drop` impl makes it impossible to move out of types with pattern matching (since the Drop impl could observe an uninitialized value), so a couple of types in luster have to have this gross `unsafe_drop` tag to say that IF they had a Drop impl, it would be unsafe, only so the `Collect` proc macro can generate an empty one :/ If there were a way in Rust to make implementing Drop for a type a compiler error, then I could make the procedural `Collect` derive use that instead, thus allowing pattern matching and removing the majority of the word 'unsafe' from luster proper.
&gt; Re: prior art, not a GC technique per se but this has a lot of similarities to 'State Threads' in Haskell (i.e. the ST Monad), which uses a unique phantom type variable (similarly to your lifetime parameter) to define a safe arena of mutability. Yeah it *definitely* is, like I say in the README it's not my idea even, it was explored first by Gankro, there's a reddit discussion about this [here](https://www.reddit.com/r/rust/comments/3oo0oe/sound_unchecked_indexing_with_lifetimebased_value/) where they discuss its similarity to the ST monad. They mention that the soundness argument for the ST monad is based heavily on parametricity, so I suppose if Rust ever loses parametricity of lifetimes, I think I might need to change the API so that the `Context` parameter is always required to access Gc pointers? That seems to be Gankro's response to the concerns about losing lifetime parametricity, that it doesn't matter because after the scope of the callback is exited, all of the indexes are "inert". This is not true for luster's gc, all of the Gc pointers are *not* inert, so I suppose depending on rust additions, I would have to ensure that the `Context` is still alive when accessing `Gc` pointers? I think? I'm not sure I fully grasp all of the implications here, and this is also assuming that Rust ever loses lifetime parametricity, which I'm not even sure if that's still a possibility. Anyway, if it is, and the analysis there is accurate, I still have a backup plan :P
I'd suggest you have a look at [Parcel JS](https://parceljs.org/rust.html) as an alternative to `create-react-app`. It allows you to basically do this: import { add } from './add.rs' console.log(add(2, 3)) Where `add.rs` is a file: #[no_mangle] pub fn add(a: i32, b: i32) -&gt; i32 { return a + b } You can also import Cargo projects too.
If I understood correctly, this "fast interpreter" is exactly the same as one in SICP 4.1.7, "Separating Syntactic Analysis from Execution". Am I correct?
No.
Yes. [TenX](https://tenx.tech/) proclaims, "Spend your cryptocurrencies anytime, anywhere".
&gt; What you can't do is stop the interpreter and then resume it later, or say to the interpreter "please execute 1000 VM instructions, then return to me a handle to continue later". I suspect that this is more of a limitation of Lua's debug API than an inherent problem with the interpreter architecture. I think the other problems you were talking about are much more exciting than this particular one. &gt; One of the reasons for this is that the interpreter has no way to deal with continuing any sort of callback, so this could only really work with one level of only Lua on the C call stack. Luster is not written this way. I think the point I was trying to get at is that the stackfulness is on the C side of the API. If you want to change the Lua API to be more stackless the bigger change will be to the C (Rust) side of things, not the Lua side :) For example, I think that if you forced C to write their code in continuation-passing style then you could modify all the Lua API functions to take a continuation parameter, similar to what lua_callk and lua_pcallk already do. You would then be able to yield back and forth between the two sides with any level of nesting. Or course, writing C code in that kind of continuation-passing style would be unbearable, which is why Lua doesn't already do that in its API. However, if the language you are using to interact with Lua has some kind of coroutine or continuation feature you could allow programmers to write code in direct style while still being able to interact with a low level continuation-based API.
Normal pointer: just a memory location. Fat pointer: pointer plus some other information (slice length, a second pointer to trait information for a trait object). Smart pointer: A pointer like type that add behaviour or restrictions eg `Box` deallocates when dropped, `Rc` tracks how many shared owner there currently are, MutexGuard prevents references outliving the lock and prevent forgetting to unlock once you are done. Combining them: `Rc&lt;SomeTraitObject&gt;` would be a smart fat pointer.
&gt; I suspect that this is more of a limitation of Lua's debug API than an inherent problem with the interpreter architecture. I don't find this particular problem as exiting as the other ones you are talking about. Sure, but Lua uses this internally as well, for example in things like the implementation of `pcall` / `xpcall`. I understand what you're saying, it's not an *insurmountable* change but it's also not *entirely* the fault of the C API either. This is also the reason that the yield API is so crazy, because PUC-Lua needs to longjmp over both your callback frames *and its own C call stack as well*. But yeah, I do get what you're saying, in the environment Lua is operating in (be a usable language from C) it does make sense. &gt; Or course, writing C code in that kind of continuation-passing style would be unbearable, which is why Lua doesn't already do that in its API. However, if the language you are using to interact with Lua has some kind of coroutine or continuation feature you could allow programmers to write code in direct style while still being able to interact with a low level continuation-based API. I don't want you to take what I'm saying as a criticism of Lua or PUC-Lua, I *love* Lua, but I've described it before as kind of the *most* C API you can possibly have :P Lua is perfect at what it is: a surprisingly capable language that's easy to use from C. What I want to do is make Lua, but for Rust instead of C, so the result obviously might be a lot different!
Does anyone know how to turn OFF the type annotations in this plugin? It gets really annoying when I'm using tokio with a bunch of combinators and the IDE throws this gigantic `SplitSink&lt;Framed&lt;TcpStream, LinesCodec&gt;&gt;` in that doesn't let me see the rest of the line. Is there a way to make it like VsCode where I can just hover the variable to see the type?
Copy and Clone have a much higher chance of allocating than Default. Consider that an empty String / Vec / Map / collection does not allocate memory until items are inserted into them.
 &gt;It wouldn't be so bad except __gc + erroring exists, so most Lua API functions can throw any type of error. How do you currently handle this in rlua? Lua exceptions inside __gc are a weird corner case so it would be a shame if they hurt the final Rust API.
&gt; What I want to do is make Lua, but for Rust instead of C, so the result obviously might be a lot different! Indeed! But I enjoy the thought experiment of how *exactly* that would differs from current Lua. Lua designed to interoperate with a system language so it kind of begs the question :) I honestly kind of wonder if we shouldn't see the pain points of the Lua-Rust API as potential Lua bugs, to be improved in a future Lua release.
Sarcastic but surprisingly real answer: *very carefully* I take Rust safety pretty seriously, so if you can cause UB without typing 'unsafe', it's not safe, even in corner cases (*) I mean it's not like I'm perfect with it either, [this bug](https://github.com/kyren/rlua/issues/116) still exists in the latest rlua. It doesn't really hurt the Rust API, it mostly just hurt me while implementing rlua :P I think it requires adding a `Result` to a few more API calls than would otherwise be required, and I guess probably adds a somewhat significant amount of overhead due to the addition of more `lua_pcall` calls. (\*) There is SOME wiggle room here, for example I had a nice debate in #rust on IRC earlier about whether writing to /proc/self/mem counted as UB for the purposes of Rust safety, and we decided that there at least be the requirement that the memory unsafety come from *inside* the process. I guess you have to draw a line somewhere, I just try very very hard to draw it pretty strictly.
I wonder if it would be a lot of work to implement that "pcall everything" pattern inside the Lua interpreter, to avoid that extra pcall overhead. Maybe that could be useful now that languages like Rust and Go are popularizing "option-style" error handling again.
As a fan of rust, it’s great to see the spread of the rust language in China. Already ordered this book. Thank you for your great work！
Depends on what you mean by smart pointer. My definition has always been "pointers with additional behavior to ensure correct usage". So a fat pointer isn't necessarily a smart pointer, but all reference types in Rust *are* smart, because their validity is checked at compile time.
I'm working on interfacing a PS3 controller with some LoRa equipment for long range (~3km) project control, nothing compared to someone the projects going on around here but awesome for learning
Oh, that's a really good example.
Woah, really? I had no idea this was the case. Is there some place I can read the details about how that actually happens? I was literally just debating a `Vec` I (thought I) was allocating yesterday, because there was a chance it might never have anything added to it. Are you saying that never hits the allocator?
You get to share the lifetime with that object. It’s a great relationship 😁. Who wants to share their objects anyway?
There are no special privileges. The owner has the responsibility of destroying an object when its lifetime ends, but that's it.
What exactly do u mean by "reference types"?
There were a few efforts at this before, like [safer-lua-api](https://github.com/DemiMarie/safer-lua-api).
Thanks. That looks interesting.
Rust has several types of pointer or reference: Raw pointers (which can only be used in `unsafe` Rust): - Immutable raw pointers `*const T` - Mutable raw pointers `*mut T` and references: - Immutable references: `&amp;T` - Mutable references: `&amp;mut T` - Owned references `Box&lt;T&gt;` - Reference counted references: `Rc&lt;T&gt;` - Atomically reference counted references: `Arc&lt;T&gt;` There may be more in the standard library that I have forgotten, and it is also possible to create your own reference-types (that can be derefenced with the `*` operator, etc) by implementing the `Deref` trait for your type. Of these, all except the raw pointers are "smart pointers" in that the rules of the borrow checker apply to them, and they will prevent you from doing silly things (like dereferencing a null pointer). But they're not all fat pointers. Of there, all of the types in the first list 
OMG! I didn't know that parcel has own loader with rust by itself. Did you set up the rust-loader by yourself? or Does parcel support it?
I was under the impression that there could only ever be one owner.
Given that there are four different safe Rust gc strategies around I wonder if it may be worth doing a holistic review of them at some point. Hell, we could even publish a paper out of it, though that's going to be a Lot of Work.
I don't believe you need to, you just need rustup installed according to the documentation. I certainly don't remember doing it when I was trying out the [example](https://github.com/parcel-bundler/examples/tree/master/rust-cargo)
Inko might fall into the first camp, it uses an interesting and not widely used gc algorithm (Immix), but enforcing the Gc safety in the interpreter is done by code policy rather than by being safe-in-the-rust-sense.
 yeah, Just translated the table of contents first, See if there is a publisher interested in this book.
Rust is OK in China, everyone appreciates Rust.There are also many companies that use Rust. But not enough,it still needs to be promoted. Most Chinese developers have good English reading skills, But there is better Chinese. &amp;#x200B; &amp;#x200B;
&gt;Just translated the table of contents first, See if there is a publisher interested in this book. Just translated the table of contents first, See if there is a publisher interested in this book.
Cool. It seems that you have seen the Tao Te Ching.
&gt;As a fan of rust, it’s great to see the spread of the rust language in China. Already ordered this book. Thank you for your great work！ thanks
I am also new to Rust and love it. I do not know this answer, but since I have also questioned this, I can share my assumption that might be yours as well. I was assuming the macro makes a copy of it. Does that even work?... I expect I will know here soon.
With a Linux distro you probably have to install the appropriate headers, often called a `dev` package at least in the land of Debian/apt.
ha.. I thought that was a microsoftish name!
Based on [`std::fmt::Display`](https://doc.rust-lang.org/std/fmt/trait.Display.html) the formatting just uses an immutable reference.
&gt; by code policy rather than by being safe-in-the-rust-sense Ah, I see. Still, I should take a look! &gt; I'd be happy to be a part of that, btw! I have like zero time right now but if I ever get some I'll ping you!
Actually, I found the announcement. [link](https://medium.com/@devongovett/parcel-v1-5-0-released-source-maps-webassembly-rust-and-more-3a6385e43b95) It's pretty awesome.
A proc macro has complete ability to form new idents. A macro_rules cannot name new idents. Even the concat_idents macro can only be used to name idents that already exist, not to form new macros.
The traits relevant to being able to format things (`std::fmt::{Display, Debug}` and others) expect `&amp;self`, not `self`. Because of this, the `println` macro will automatically insert `&amp;` before arguments.
From my admittedly limited understanding: &gt; what extra capabilities does a owner of data have over a reference? 1. there can be only one owner of a thing. 2. the thing gets `drop`ped when it goes out of scope. 3. you have the ability to move memory out of the thing without cloning. &gt; how does these extra capabilities play out when there are multiple owners (reference count)? 1. reference counted pointer owns the thing, and you can now only access immutable references. 2. the thing gets `drop`ped when the last `Rc` / `Arc` reference goes out of scope. 3. you cannot move memory anymore, because you can only take an immutable reference. methods like [`try_unwrap`](https://doc.rust-lang.org/std/rc/struct.Rc.html#method.try_unwrap) on `Rc` allow you to recover the original owned value if you need to, but it's not statically guaranteed to work. &gt; what extra capabilities does the mutable reference have over the one which can't mutate data? 1. it is certified unique, that there are no *other* mutable or immutable references to the thing. Things like `Rc`, `Arc`, `RefCell`, `Mutex` allow you to bend the statically verified rules of ownership, mutable / immutable references, and lifetimes at runtime instead of compile time.
In rust is it possible that you can pass a value to a function, but the function only takes arguments, which are reference ls to the type? Is the reference to the type passed to the function instead of the type itself? I hope u got the question. :)
Okay this explanation makes sense to me. So in rust this type of value to reference coercion is possible...( If u consider this a coercion) what other value to reference or reference to value automatic conversions are possible in rust?? Thanks
I've tried some of [https://github.com/RustCrypto/](https://github.com/RustCrypto/) , and they've worked well. They are still pure rust and only use simd etc. on feature toggle.
Me too. Until I came across rc special pointers .. read "the book" chapter on special pointers 
Shameless self-serving plug: (orion)[https://crates.io/crates/orion] is pure-Rust and I've tried to compile it against webasm, without any problems. Though, webasm compilation isn't a part of CI so I can't say for sure you won't encounter problems (some of the integration tests do file IO, so that could become an issue). If you end up trying it out, I'd love to hear about it!
I have the following where \_term is a Crossterm object from the crossterm crate, and I want to essentially center the title on the terminal using startLoc as the starting x position: `let titleLen = title.chars().count(); // usize` `let termX = self._term.terminal().terminal_size().0; // u16` `let startLoc = termX/2 - titleLen/2;` Except because titleLen and termX have different types, the 3rd line fails. I can't find anything on the web that actually explains how to deal with this problem or even how to cast between different number types and get it to compile. Suggestions? &amp;#x200B;
Println and friends are "special" - despite the lack of `&amp;`, they take references anyway. I would go as far as saying this was a design mistake, as it makes the language less coherent, and sometimes causes confusion for people trying to learn ownership and references.
Thanks for the reference. I will
You can't implement trait for trait, because traits are not types. You could create blanket implementation of `Serialize` for all types that implement `VarInt`, but it can be done only in serde crate.
I wouldn't describe `Rc` as "multiple owners". It's more like creating an `Rc`/`Arc` creates a shared location on the heap, and _that_ location owns your object.
When in doubt if something is a fat pointer, I recommend playing with the std::mem:size\_of function: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1be3cddd1c7798cf56cfaebba814de2b](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1be3cddd1c7798cf56cfaebba814de2b) To answer your question: I see fat pointers and smart pointers as two different concepts. Other people have already explained the difference between the two in this thread.
Would you please show some code snippets to me? I am quite new to rust.
It really does cause confusion, a lot actually...
You can also: Call functions that takes object by value (including methods that take `self`) Take ownership of its fields 
Thanks, will do! 
At another angle: both are pointers with additional information. The smart pointer has additional information compile-time, i e, the type of smart pointer tells the compiler what can be done with the information behind the pointer, if the compiler should insert some code when the pointer goes out of scope, etc. The fat pointer has additional information run-time, so it can e g check the length of a slice before accessing it, or invoke some method where the compiler cannot deduce which method it is, it has to be determined run-time. There are also thin pointers, where this additional information is run-time, but at the location pointed to rather than following the pointer itself. These are common in other languages but not so much in Rust (there are crates though).
It's the `as` operator, e g let termX = self._term.terminal().terminal_size().0 as usize; Now they're both `usize` and can be subtracted from each other. 
Being an avid learner at [Udemy](https://www.udemy.com/) , I have written a tool to download udemy courses in batch so I can play them on my TV set from my NAS. There was already a [tool](https://github.com/r0oth3x49/udemy-dl) written in python (and others) which was working fine but required the installation of several dependencies. My tool is largely inspired by this python tool with some reverse engineering. It can download, mark complete and get information about a course. It does not download the subtitles because I don't need them, but this can be added. &amp;#x200B; [https://github.com/bn3t/udemy-dl-rs](https://github.com/bn3t/udemy-dl-rs)
If you are ever unsure how a type is being automatically referenced I would recommend looking up the function or trait in the rust docs. As noted above, you want to look out for `&amp;self` in the function signatures.
Rust macros work by generating code at compile time. The nightly toolchain [has compiler flags](https://crates.io/crates/cargo-expand) that allow you to see the generated code. let foo = 3; println!("Foo: {}", foo); "expands" to let foo = 3; { $crate::io::_print($crate::fmt::Arguments::new_v1 ( &amp;["Foo: ", "\n"], &amp;match (&amp;foo,) { (arg0,) =&gt; [$crate::fmt::ArgumentV1::new ( arg0, $crate::fmt::Display::fmt, )], }, )); }; Notice that it uses references pretty much everywhere. So, while the `println!` macro looks like it takes ownership of the arguments, the generated code actually uses references, as you can see.
Hope you don't mind me jumping in here. When you require a function argument to be a reference the compiler will flag that you need to pass a reference on calling the function. So yes, the reference is actually being passed to the function in that case not the type.
Could you open a PR on [https://github.com/ctjhoa/rust-learning/blob/master/zh\_CN.md](https://github.com/ctjhoa/rust-learning/blob/master/zh_CN.md) ? I think it could bring more visibility to you and help others.
How is it then done that `Into&lt;A&gt;` is automatically implemented for `B` if `From&lt;B&gt;` is implemented for `A`? Wouldn't you need to do something like impl Into&lt;A&gt; for B where A: From&lt;B&gt; { ... }
It can be achieved by setting ‘linker = “lld-link”’ inside the .cargo/config file under your target triplet as note on [the docs](https://doc.rust-lang.org/cargo/reference/config.html#configuration-keys) 
I would agree that it makes things very hard to understand but I think that the problem isn't design (proper use of well designed macros), its that this information should be front right and center when talking about why println didn't take ownership 
Untested, but probably something like: ``` impl&lt;T&gt; Serialize for T where T: VarInt { fn serialize&lt;S&gt;(&amp;self, serializer: S) -&gt; Result&lt;S::Ok, S::Error&gt; where S: Serializer, { serializer.serialize_u128(self.retrieve()) } } ```
That's pretty much what it is https://doc.rust-lang.org/src/core/convert.rs.html#438 Technically, he is correct that you can not implement traits on traits. But you can implement a trait on all types that implements a trait. 
Note that for common crypto algorithms you probably would want to use them via the WebCrypto API offered by the browser. That will use the OS's optimized implementations, which is always at least SIMD optimized and these days often uses hardware acceleration. You just won't be able to beat that in WebAssembly.
Ctrl + Shift + A and then type `toggle hints` and hit enter.
Thanks. But the varint is not a fixed u128 or u64. It changes according to the data stored or the value a variable has.
But `retrieve()` always returns a u128, so you're always serializing a u128.
&gt; there can be only one owner of a thing. &gt; the thing gets dropped when it goes out of scope. &gt; you have the ability to move memory out of the thing without cloning. also an owner can trivially convert an immutable binding to a mutable one (by rebinding).
Why it generates match with single infallible pattern? Is it possible to write `println` that will generate match with multiple arms?
IMHO you should add at least some types because it's very easy to get lost in your example. E.g.: when filtering random integers you should probably include a `bool` type annotation for `rng.gen()` so that the reader immediately knows that you're filtering random integers.
I finally implemented VarIntSerializer. But I don't know how to invoke it:-( \`\`\` impl VarIntSerializer { fn parse&lt;T: VarInt&gt;(&amp;self, value: T) -&gt; &amp;Vec&lt;u8&gt; { self.data.clear(); let mut temp = T::retrieve(value); while temp &gt;= 0x80 { print!("temp = {}\\n", temp); self.data.push(temp as u8 | MSB); temp &gt;&gt;= 7; } print!("temp = {}\\n", temp); self.data.push(temp as u8); self.data } } impl Serialize for VarIntSerializer { fn serialize&lt;S, T&gt;(&amp;self, value: T, serializer: S) -&gt; Result&lt;S::Ok, S::Error&gt; where S: Serializer, T: From&lt;u8&gt; + BitAnd + BitOrAssign + Shl + VarInt, { let data = self.parse(value); serializer.serialize(data); } } &amp;#x200B; \`\`\`
That was /u/Omniviral's suggestion. 
yes. But I don't know how to test it.
&gt; Poor liquid, it always gets left off these lists. By no ill will, the template engines I listed are ones I stumbled upon somewhat organically while trying to build the site. There are more I haven't listed :). &gt; `dyn Content` Just for clarity, I don't use `dyn`, I use static dispatch everywhere. If you use dynamic structures with `HashMap`s or similar as your native types for rendering, then even if you get rid of cloning (which should be fairly straight forward with a specialized method), you are just pushing all the allocation costs up the pipeline. Even then fetching stuff from a `HashMap` will still be slower: you need to load the allocation to CPU cache if it's not there, hash the value, find the index and de-reference it. After that you still have to render the value, and you have three options here: + Your value type is an `enum` with variants for types, and match on that to figure out how to render a string vs how to render a number. So you incur branching costs that Ramhorns doens't have to do. This is probably the most reasonable option. + Your value type is always `String`, which means you had to pre-render non-string types and incur allocation costs which Ramhorns doesn't have to do. + Your value type is `dyn Trait`, which means you incur overhead of dynamic dispatch that Ramhorns doens't have to do.
They're not special, because they are not function, but macros. They generate code that expands to taking the arguments by reference. 
I don't think so. The example seems clear as-is. (In any case, if it's unclear, you'd hover your mouse over expression and IDE would tell you the type.)
Eh, I don't like the idea that an IDE can make up for stuff like this, because not everyone uses an IDE, and there are plenty of cases where you're 'forced' not to use one (looking at diffs, looking at code online).
Side note - be aware of one thing. You can find pure Rust crate, you can compile it to wasm, but there's no guarantee that it will work. I experienced this issue in the past. I ended up adding Node/browser tests in JS just to ensure myself that it really works.
Type hover is such a useful feature that I'd use IDE just for type hover. I think we should add type hover to online code browsers as soon as possible.
I was going to explain on blanket impls, but then I noticed that this is probably XY problem and proceed with solving his real problem )
You invoke it by calling `Serialize::serialize` on value you want to serialize, giving serializer
Your `VarIntSerializer` should implement `Serializer` trait.
This impl is not possible due to orphan rules. And even if it was allowed it will conflict with exising impls.
You would do the community a great service if you isolate the failure cases and file bug reports on them. But as everywhere, you should test on all targets you care about.
I would buy that book. Especially the chapters after 9 are of interest to me. 
God damnit, this is not r/playru... oh. Oh. Nice!
There's also sublime, notepad++, vim, Emacs, these text editors simply don't have the same capabilities of an IDE. Make something clear in the code, don't lean on an IDE.
I know Rc and Arc are thin pointers
I'm already doing this. Here's [an example](https://github.com/uuid-rs/uuid/pull/351). I just wanted to say that _yay, it finally compiles to wasm_ isn't enough.
OP should definitely post this to /r/playrust though
Note asking "how could that possibly work" was in reaction to the claim that it needed to happen at the same time and was non-blocking. The example at the end of that page correctly points out that sending is in fact blocking.
I use vscode and get to enjoy type hover. The only problem is how slow RLS ends up being on big projects
I hope you are joking, but in case you are not, /r/playrust is subreddit dedicated to the game Rust which has nothing to do with Rust programming language, that game is not even written in Rust. And article I shared has nothing to do with the Rust game.
We should add type hover to Vim and Emacs and Sublime Text as soon as possible. (Wait, don't they already have it?)
I don't know why it expands that way. The definition of the macro is [here] (https://github.com/rust-lang/rust/blob/ba43811a07f13975640e58e6acb3ba3d1399cf78/src/libstd/macros.rs#L144-L152) in case anyone better at macros wants to try figuring it out.
Hence the irony...
It was a joke. People keep posting about the game here and it’s annoying. So why not post about rust in their subreddit, that’ll show them huehue
Emacs with lsp-mode has type hover which usually works.
Yes, some plugins for Vim let you achieve something similar to type hover (I'm currently setting up my vimrc), but type hover for RLS is very limited at the moment
Isn't typing a few characters easier than adding type hover to browsers?
What's faster: 1. Seeing a type annotation in someone's code and immediately understanding the type of that expression, or 2. Moving your mouse to the function (and in Rust operators are technically too methods, but type hover doesn't trigger on operators) (also talk to any Vim user about moving mouse), waiting for type hover to start processing that method, and then waiting for response from RLS? While the second one is fast too (on modern hardware), if you use it for literally everything it'll stack up. Also, IDEs can't be used: 1. On old hardware 2. In terminal output 3. In diffs 4. On GitHub (although there's a thing called Sourcegraph) 5. On smartphones 6. In emails 7. In browsers 8. Some people don't want to use IDEs because they're slow.
Making a copy could be slow and inefficient if one of the arguments is huge, and it may be impossible if an argument implements neither `Clone` nor `Copy`. `println!` takes advantage of the versatility of macros and inserts `&amp;` to immutably borrow its arguments.
Woosh
&gt;They are still pure rust Not quite, we have some amount of [asm](https://github.com/RustCrypto/asm-hashes) and [plan](https://github.com/RustCrypto/asm-hashes/issues/5) to expand on that. But either way use of assembly is feature-gated and by default all crates will use pure Rust implementations.
It’s not a coercion. Because `println!` is a macro it can insert a `&amp;` token before the "argument" expression. This wouldn’t work with an actual function. We do have have implicit auto-borrow for the receiver of method calls: let foo = String::new(); let a = foo.len(); // This works even though the len method takes &amp;self, and this program doesn’t include a `&amp;` borrow operator let b = String::len(foo); // error[E0308]: mismatched types, expected `&amp;String` found `String`
&gt; E.g.: when filtering random integers you should probably include a bool type annotation for rng.gen() so that the reader immediately knows that you're filtering random integers. I have mixed fillings about this. On the one hand, having the caller infer the return type is idiomatic enough that even Rust beginners should be able to easily understand what's going on here. On the other hand - this thing would behave weirdly in any other language. In Python, for example, `filter(lambda _: random(), range(n))` will almost certainly return the full range - because even though `random()` is possible the probability to get it is nearly zero (theoretically it is zero - but this is not pure math and all values are discretisied).
Counterpoint: it can often be faster to read the overall code flow without the noise of type annotations, which are only important / useful sometimes. The RLS implementation is poor, so I can see an argument for annotating types in Rust whete they're not obvious. But I never miss them in C# which has better (faster, more consistent) tooling support
Very Cool!
Not trying to be negative, but I'm skeptical about this being a useful layer of abstraction. With `tokio-fs`, file serving is mostly just glue code and some sanity checks (guard against path traversal attacks, ...). Also, actix-web has built in file/directory serving. What's the benefit of this?
`tokio-fs` is not really useful because you don't get straight `Future` and/or `Stream` out of it. I just made abstraction that could be used everywhere (lot of my code inspired by actix-web actually since it is the best library after all). It might feel strange, but I don't think there is lot of benefit for each and everyone implementing own file serving. Maybe `tokio-fs` will become actually useful in future, but for now I don't really think that pseudo async fs is even worth considering for use
This is a solved peoblem. The rust language server means that those editors already have type hover. I *do* agree with you (GitHub does not have type), but editors often match our outclass IDEs in functionality, especially post-lsp. They're just a bit of a PITA to configure.
This blows my mind every time https://os.phil-opp.com/
I appreciated the length. It explained the problem clearly, the approaches tried, and walked you down to the final outcome. It’s much preferable to the “here’s a problem - and here’s what we did” with no context as to “why”.
I’m curious why the new dbg! Macro doesn’t do the same? Any idea why?
I am maintainer of RustCrypto org and I will be happy to hear more regarding experience of using RustCrypto crates! &gt;Unfortunately due to how an hmac is used, we are only able to verify the passphrase after we have read the entire file. Thus we first read the entire file into memory `hmac` crate does support processing of streaming messages (see [`input`](https://docs.rs/hmac/0.7.0/hmac/trait.Mac.html#tymethod.input) method of `Mac` trait), but if you files are just few kilobytes long, then I guess reading the whole file into memory will be the most reasonable approach. BTW you can replace `pkcs7` with [`block-padding`](https://docs.rs/block-padding) which is already part of your dependency tree.
你他妈吃饱了撑得吧？我的这几个都是我要用的。 想要那个你说，我免费转给你，瞎鸡巴扯什么淡。
Just to for informing some of us, what exactly in beta/nightly that is expected to make the binaries 20% smaller? I have not followed what is going on in the beta/nightly recently.
Yeah, that's more ergonomic, sure.
I'm evaluating and playing with JavaScript engine wrappers in Rust (`mozjs`, `duktape`, ...). I have a Rust project where the target is native library and also an NPM package for both node &amp; browser (wasm). I need to add support for executing JavaScript code -&gt; an abstraction layer, which is going to execute JS code via some JS engine wrapper (`mozjs`, `duktape`, ...) (in case of native library) or will use node/browser environment (NPM package). Researching, playing, experimenting, ...
I simplified my example, but in my codebase, `Foo` implements `Drop`. Sometimes, I want to let the drop method run normally, but sometimes, I want to consume `foo` without triggering the destructor: ```rust impl Foo { fn consume(self) -&gt; Bar { let bar = self.bar.take(); // do something with bar bar } } ```
Hello, There an issue with deps and PR is not merged: [https://github.com/SpinResearch/RustySecrets/pull/74](https://github.com/SpinResearch/RustySecrets/pull/74) So you can try to add next in your cargo.toml file: `[dependencies]` `rusty_secrets = { git = "https://github.com/nvesely/RustySecrets", branch = "update-deps" }` &amp;#x200B;
Sorry, but I'm as clueless as you. Perhaps they regretted doing it with println because it confuses people?
Oh and one more thing. &amp;#x200B; The main idea of the algorithm is to 1. create a letter\_counts HashMap for search\_word Traversing it by character:For the word "test" it would be `{ 't': 2, 'e': 1, 's': 1 }` 2. loop over the candidate words (dictionary): 2.1 Check that the words have equal length (if not it can't be an anagram) 2.2 Clone the letter\_counts map. Traverse the candidate word by-character subtracting 1 from each letter in the word. When the map has no such character `return false` early. When the letter\_count would become negative, `return false` early. If the loop finishes normally, the candidate word must be an anagram. &amp;#x200B; As cloning this map on each iteration would be relatively expensive, I did small optimization and created 2 datastructures. letter\_counts as a SmallVec and letter\_indexes as a HashMap. So that only a array-backed vector (letter\_counts )containing the counts would be cloned, but the hashmap can be reused to get the correct indexes: letter\_indexes: `{ 't': 0, 'e': 1, 's': 1 }` letter\_counts: `[2,1,1]` &amp;#x200B; The final anagram checking method is the following: ``` pub fn is_anagram(candidate: &amp;str, letter_counts: &amp;SmallVec&lt;[i32; 32]&gt;, letter_indexes: &amp;HashMap&lt;char, usize&gt;) -&gt; bool { let mut counts = letter_counts.clone(); // subtract candidate letters from word ... sum should be zero for letter in candidate.to_lowercase().chars() { if !letter_indexes.contains_key(&amp;letter) { return false; } let idx = letter_indexes.get(&amp;letter).unwrap(); let count = counts[*idx]; if count == 0 { return false; } counts[*idx] -= 1; } true } ``` Part of my second questions is: Are there a more efficient ways to store the same data? Double indexing also isn't optimal. BTW I tried using the more-ideomatic Match in the for loop, but it seemd to end up a bit slower than doing a manual contains_key check
Something bugs me about the borrow checker and lifetimes. If its always right and so sure of itself, why does it make me do everything? Are there edge cases it cant handle so it doesn't even bother with anything, or maybe its because checking is much easier than doing? Is it theoretically possible that there could be a "lifetime inserter" or would there always be too many ambiguities? Oh wait, is this an "easy question"?
Hi! I'm working on a basic memory allocator for a toy virtual machine (Universal Machine from a past ICFP contest). That VM operates on unsigned 32-bit numbers, the memory allocator should support the following operations: * alloc(size: u32) -&gt; u32 // returns VM address * free(addr: u32) * read(addr: u32, offset: u32) -&gt; u32 * write(addr: u32, offset: u32, val: u32) I'm using Rust vectors for mapping between VM addresses and real addresses of blocks of memory (which I also represent as vectors, even though they can't be resized after allocated). I also use a min priority queue for tracking free cells, so that VM addresses can be reused when they are freed. So, basically my memory allocator data structure is like this: `struct Mem {` `data: Vec&lt;Option&lt;Vec&lt;u32&gt;&gt;&gt;,` `free_pq: BinaryHeap&lt;Reverse&lt;u32&gt;&gt;,` `}` I use Option&lt;&gt; to represent "holes" in VM address space (after "free" operation). Internal Vec represents the allocated memory block. The full code and implementation of the operations is here: [https://gist.github.com/sphynx/e72c84b3d1d80122a1f5ae3cb101c178](https://gist.github.com/sphynx/e72c84b3d1d80122a1f5ae3cb101c178) **Question:** Could you please let me know if this is a good choice of the data structure in Rust? Will it work as expected or there are some leaks/inefficiencies which I am not seeing now? I am a Rust beginner (this is basically my first program), so general comments about style/idioms are also welcome. I know that Vector of Vectors has bad cache performance for obvious reasons (vectors for allocated blocks will be all over the place in memory), but since the allocated blocks can be of any size and there can be "holes" in VM address space (after "free" operations) it's not trivial to keep VM memory in contiguous space while keeping free/alloc operations efficient. But probably possible, I'm thinking about that :) &amp;#x200B;
Where can we buy the Chinese version? This dovetails nicely into my goal of getting better at reading Mandrin and getting better at rust this year.
I don't know and am hoping someone shows up that does.
The latest version available is `0.2.2`. It means that you should have ... ``` [dependencies] rusty_secrets = "0.2.2" ``` ... in your `Cargo.toml`. If you'd like to use GitHub branches / tags, you can - check the [Specifying dependencies from git repositories](https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html#specifying-dependencies-from-git-repositories). It seems that you're not using Rust 2018 edition (based on `extern crate...`). If you're new to Rust, check [The Edition Guide](https://doc.rust-lang.org/nightly/edition-guide/introduction.html) and [Rust 2018](https://doc.rust-lang.org/nightly/edition-guide/rust-2018/index.html) chapter. What do you mean with _I can't call the functions_? Can you share your code (whole file, not just `extern crate...` snippet). What errors do you get? Is there any [use declaration](https://doc.rust-lang.org/reference/items/use-declarations.html) in your code? It's hard to guess what's wrong unless you provide a) exact error message, b) your code (or the whole [mre](https://en.wikipedia.org/wiki/Minimal_working_example)).
&gt;Where can we buy the Chinese version? This dovetails nicely into my goal of getting better at reading Mandrin and getting better at rust this year. [https://www.amazon.cn/dp/B07NW95M76/ref=zg\_bsnr\_143366071\_1?\_encoding=UTF8&amp;psc=1&amp;refRID=FP2TMKN7GXFWCWDKA228](https://www.amazon.cn/dp/B07NW95M76/ref=zg_bsnr_143366071_1?_encoding=UTF8&amp;psc=1&amp;refRID=FP2TMKN7GXFWCWDKA228) you can buy Amazon China Kindle Version of the book.
[https://www.amazon.cn/dp/B07NW95M76/ref=zg\_bsnr\_143366071\_1?\_encoding=UTF8&amp;psc=1&amp;refRID=FP2TMKN7GXFWCWDKA228](https://www.amazon.cn/dp/B07NW95M76/ref=zg_bsnr_143366071_1?_encoding=UTF8&amp;psc=1&amp;refRID=FP2TMKN7GXFWCWDKA228) &amp;#x200B; Amazon Kindle Version of The book
Thanks
I was looking in the Cargo.toml from RustySecret file at GitHub und there the version is "0.2.3-pre". But with "0.2.2" I can add the library. Thank you. &amp;#x200B; I will have a look at the Rust 2018 Guide. &amp;#x200B; Thank you.
Thank you. I tried the solution from zizka\_dev and it works. But thank you for your support :-)
Are you sure that it works? Because I get next error from cargo for rusty\_secrets = "0.2.2": `error: failed to select a version for the requirement \`ring = "^0.12"\`` `candidate versions found which didn't match: 0.14.6, 0.14.5, 0.14.4, ...` `location searched:` [`crates.io`](https://crates.io) `index` `required by package \`rusty_secrets v0.2.2\``
If you'd like to use `master` branch, you can specify dependencies in this way ... ``` [dependencies] rusty_secrets = { git = "https://github.com/SpinResearch/RustySecrets", branch = "master" } ``` ... or ... ``` [dependencies] rusty_secrets = { git = "https://github.com/SpinResearch/RustySecrets" } ``` ... where omitted `branch` means `master`. If you'd like to stick with released versions you should check [rusty_secrets @ crates.io](https://crates.io/crates/rusty_secrets).
Because it is desired to insert `dbg!` in the middle of an expression eg.: `2 + 3 * 4` and you want to only inspect the result of the multiplication you can do: `2 + dbg!(3 * 4)`. Here `dbg!` wants to act as a pass through operator which prints its value as a side effect. Ownership must flow to the dbg macro and back out as if nothing happened. This is different for println, which does not want ownership to pass it somewhere.
As much as I like that example, I think I'd criticize it on code review for the unconstrained integer type, which should probably be `u32` or `i32` as a sensible-for-performance default on PC but may be inferred as `usize` if it is used in an index. Type inference can be smarter than someone reading the code, meaning code can compile without communicating clearly. That said, I'd rather have the compiler be a little bit more clever than clear coding style needs than a little less.
You ar right, I did not check this. I will try it with your version now thanks
Not familiar with this use case, but in general an STM32F1 is far beefier than an AVR. AVR's are 8-bit chips that usually have less than like 8 kb RAM and 64 KB flash, running at up to 20 MHz. (It's surprisingly hard to find an actual product list for them). [STM32F1](https://www.st.com/en/microcontrollers-microprocessors/stm32f1-series.html?querycriteria=productId=SS1031)'s are 32-bit chips that top out at 72 MHz, 80ish kb of RAM and 1 MB of flash; the least powerful STM32F1 more or less starts where the most powerful AVR stops.
you sir or madam, will make a fiiine programmer.
As of Rust 1.32, jemalloc was removed in favor of using the system allocator by default: https://github.com/rust-lang/rust/blob/master/RELEASES.md#compiler-1 --- On Linux, by default, the system allocator is going to get dynamically linked via glibc, so every binary in that environment no longer bundles jemalloc and thus there is a corresponding drop in binary size.
Developer here, thanks for posting! I wanted to wait until I release a 1.0 version with proper binaries and possibly with a proper landing page. But thanks. Anyone having a question about `ffsend`? I'm happy to answer!
You can check out their [repository](https://github.com/mozilla/send)
[I'm surprised that there's not a Clippy lint against usage of `Vec&lt;Vec&lt;_&gt;&gt;` and similar.](https://gist.github.com/jFransham/369a86eff00e5f280ed25121454acec1#keep-as-much-as-possible-in-cache)
Right, that's the drop in 1.32 I mentioned. The question is what's the drop in beta/nightly?
"master" gives me a error `error: failed to select a version for the requirement ring = "^(0.12")` but `branch = "update-deps"` seems to work. Thank you oceanicdev. &amp;#x200B; I did compile a Hello World Programm with rusty\_secret and this gives me back one more error, can you help me with this one too? error: failed to run custom build command for `merkle v1.10.0` process didn't exit successfully: `/Users/kaller/IdeaProjects/dssaa_s/target/debug/build/merkle-f78177df6eb47b03/build-script-build` (exit code: 101) --- stderr thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: Os { code: 2, kind: NotFound, message: "No such file or directory" }', src/libcore/result.rs:1009:5 note: Run with `RUST_BACKTRACE=1` for a backtrace.
What makes `tokio-fs` "pseudo async", as you say?
Didn’t OP say that was the first 20% and now there is another 20% (for a total of 36% compared to 1.20) coming?
Ah, missed that, sorry! But yeah, good question then.
Yes, I missed that part. I skimmed too quickly.
Oh - interesting. Did not even think of that use case. Thank you!
The fact that it is not async? There is no async file APIs(aside from windows) that you can use, so `tokio-fs` enforces you to use multi-threaded runtime
Seems you try to open the file that does not exist. Can you paste your code?
Hi /u/frondeus! i did not know about rust meetup in Wroclaw! If you know about any future meetups in Poland, please share it with me! :D
A `Vec&lt;Vec&lt;_&gt;&gt;` isn't necessarily a matrix.
you failed to rg that eh 
I'm not really a LISP person so it's hard to tell if it's the same :)
Vim definitely supports hover types in rust.
Calm your horses there, Goddamn Batman.
Yes, this is an easy question. And no, it is not the compiler's job to change your code. We have rustfix for that – and that will only work for those cases where the solution is unambiguous *and* correct. This fails in a surprising number of cases.
Sublime supports it when using RLS with the `LSP` package.
It just forwards to built-in macro `format_args_nl`
What, if any, effect does this have on RLS? I still feel its pretty slow in VSCode, but then again I don't if I should have high expectation comparing it to other static checkers.
Holy mackerel. That's bloody *amazing*. What is this sorcery??
I thought an unconstrained literal's type is resolved to either \`u32\` or \`u64\` during compile time. But [I see now](https://doc.rust-lang.org/reference/tokens.html?highlight=integer#number-literals) that if there is no context, then the default is \`i32\`. I see what you mean by sensible-for-performance now. Thanks.
you want /r/playrust, this is the subreddit for the programming language Rust
So to be clear, in my post I was talking about the cause of "dramatic benefit". While what you talk about would improve things, I suspect it is more icing on the cake. This also gets into cost/benefit/risk trade offs. I need "good enough" performance while wanting a certain feature set and degree of maintainability. I made my post to help highlight different design trade offs wrt those traits. As for risk, this gets into how I use my time and getting the biggest payoffs. I've taken care a lot of the low hanging fruit. What remains for improvement could make noticeable differences or none at all. I won't know until I've done it but there are so many other things for me to be implementing, I feel my time is better spent on those. &gt; By no ill will, the template engines I listed are ones I stumbled upon somewhat organically while trying to build the site. There are more I haven't listed :). I know. No ill will taken. &gt; Just for clarity, I don't use dyn, I use static dispatch everywhere. Makes sense if that works for your template language. Liquid allows applying "filters" (ie functions) to a variable before rendering. The simplest route is to have a uniform format for processing the data, so my `Value` is an `enum`. I could instead push all of the logic on my `trait ValueStore` such that I can look up a value and get it as an `i32`, or render it, etc. This is effectively what it'd take for me to convert to static dispatch. A couple of challenges with this - Cost/benefit of making such an invasive change, including putting all of Liquid's implicit conversion logic onto the client (even if embedded in a `derive`, just doesn't seem to be there for me. - In some cases, we have to look up the value multiple times (processing floats from integers differently). Either the look up happens multiple times or we need a cursor and the added complexity there. - I'm trying to work towards having a stable API but pushing all of my logic onto a trait makes me either more susceptible to needing to make breaking changes or I have more hoops to go through to make certain kinds of changes. &gt; If you use dynamic structures with HashMaps or similar as your native types for rendering, then even if you get rid of cloning (which should be fairly straight forward with a specialized method), you are just pushing all the allocation costs up the pipeline. As I mentioned - Yes, a global must be stored as a template-native type, including using a hash map if relevant, but this is something I want to improve - Once that is fixed, it'd only need to convert it to a hash map if we need to operate on it like a hash map. I guess I could always go a step further and use`Box&lt;Iterator&gt;` though I suspect I'd run into a lot of "owned" vs "reference" issues, lifetimes, etc that I'd have to deal with. - Caveat: Variables on the stack will almost always be in template-native types though these are less comon - Depending on the application like a SSG, a lot of the data structures *are* dynamically created, requiring a `HashMap` anyways, so the allocations will be happening regardless. I could do hybrid solutions, where it is `HashMap&lt;String, UserType&gt;` though a user would want to iterate on a lot of those hash maps and runs into the problem mentioned above.
It was our 8th meetup. Next one will be on 4th of April, as we want to move it from the end of month to beginning. Right now I can recommend watching [https://www.meetup.com/Rust-Wroclaw/](https://www.meetup.com/Rust-Wroclaw/) and our twitter account [@RustWroclaw](https://twitter.com/RustWroclaw). We are also active in our [Slack](https://join.slack.com/t/rust-wroclaw/shared_invite/enQtNTQ2NjEwOTA3OTIwLTQwMjRmM2VlMWU1OGZhZjcwYjA3ZWNiNTU2MDg3MjEzYmFjNGQ5NzNjNmYwN2EwZTAyZDY4MDczNDVhMDkxNTI) We would like to add next meetup to This Week in Rust calendar, as we did last time (unfortunately too late). 
The total is 43% by the way, not 33.6%. It's If you follow the link you have the comparison numbers with 1.20 and with the previous version for compile/size/run. I screwed up transcribing, the gain is 27% and not 17%.
That is a nice read. Thanks. But as tim\_vermeulen mentioned, all the inner vecs are not of same size.
What does it use if you statically link it in Linux? 
tomorrow.
So what makes your crate *not also* "pseudo async"?
Thanks for elaborating! &gt; Makes sense if that works for your template language. Indeed. I've taken a bit of a closer look at liquid, the design goals are definitely different here. Ramhorns is constrained to Mustache (without partials or anything equivalent, for now) logicless templates, so a lot of the problems you run into I won't, just based on what you enable users to do within the templates.
RLS has improved a bit but check out rust-analyzer.
In this case, a general framework for encrypting binaries or sections thereof is going to be miles better than focusing on this one thing as the section that must be encrypted.
If you liked using ECS for your game dev, check out the [Amethyst game engine](https://www.amethyst.rs/). It is built on [specs](https://slide-rs.github.io/specs/) (ecs library) and takes care of a lot of pipeline for you. 
In first place it doesn't claim to be async, the only purpose is to serve files over HTTP
They do have a common maximum size, though, so the elements can be something like Option&lt;NonZeroU8&gt;.
Well in that case (which is what I suspected) then I don't understand why you're disparaging `tokio-fs` for using the same threadpool technique that you used.
Because I cannot use single threaded runtime with it? You don't really need thread pool for async IO, but you need it for stuff like file systems
I haven't looked at your repo, and I'm not sure how you want your serialized values to look, but you could probably use (`typetag`)\[[https://github.com/dtolnay/typetag\]](https://github.com/dtolnay/typetag]) to de/serialize your trait. It creates a serialized representation that looks like `{"u32": 23}`.
I recently answered this question over on the users forum: [https://users.rust-lang.org/t/why-can-lifetimes-not-be-inferred/25645/9](https://users.rust-lang.org/t/why-can-lifetimes-not-be-inferred/25645/9)
No, that's not it. code here: &amp;#x200B; use select::document::Document; use select::node::Node; use select::predicate::{Class, Name, Predicate}; use futures::future::Future; use reqwest::r#async::Client; pub struct BeebURL&lt;'a&gt; { url: &amp;'a str, } impl&lt;'a&gt; BeebURL&lt;'a&gt; { fn load_async(&amp;self) -&gt; BoxResult&lt;IplayerDocument&lt;'a&gt;&gt; { let client = Client::new(); let rb = client.get(self.url); let resp = rb.send().and_then(|res| select::document::Document::from_read(res)); Ok(IplayerDocument{doc: resp, url: self.url}) } } &amp;#x200B;
Can someone answer some quick question :) &amp;#x200B; 1. I believe I read that a crate is a translation unit, so does that mean that if I have a large create, I can't reap the benefits of recompiling only what has changed? 2. Does the fact that Rust does not use header files make it slower to compile, as there is no separation of interface and implementation? 3. What is the slowest part of the Rust compilation process? Is it the type system? The borrow checker?
I'm having issues with the borrow checker and lifetimes. Here is a [playground link](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e31a1559d168e0c1e923586856f3d1b4) If anyone can explain the situation that would be amazing!, starting to get to the point of wtf o.O （╯°□°）╯ ┻━┻
You can download Rust for free at http://rustup.rs
Not as heavy weight as the other commenters in this post but I was taking a look at webscraping in rust and it seems quite good. Here is a blog that I have written on it. [https://medium.com/@joydeepubuntu/rust-and-webscraping-ebecc9ae536c](https://medium.com/@joydeepubuntu/rust-and-webscraping-ebecc9ae536c)
I'm new to multithreading. How does Rust handle system memory limits across threads? For example, if I am reading a 15 GB file into memory in Rust, I'm not going to have a ton of RAM left on my computer to do things with. If I create a for loop and spawn a new thread for each task I need to do on that 15GB data: 1. How is it possible for Rust to create 100 new threads if there are only 8 cores on my CPU? 2. What happens if one of those threads doesn't have enough RAM left to do what it needs to? Will Rust wait for the other threads to finish first and then spawn the other threads?
Looks awesome
Wow, never looked too closely at Mustache before. That does seem like an easy to optimize template language. Maybe I'm biased from the background / experience I'm coming from but I feel like it'd be very limited in applications without at least filters.
That's quite strange. The other thing I found after some googling is that you may have two different versions of the future crate, if reqwest depends on a certain version and your program depends on a different version.
This is how I am planning to start. Amethyst looks really promising to me. 
This is my first project with Rust. I've been doing developing mostly in Web dev field. So, I chose building GraphQL API as my first project. I think I'm very enjoying to make something with Rust day by day. I'd like to port other APIs with Rust. I'm still struggling with error handling and how to make a better structure with Rust, So Please comment anything, any advices and reviews are big welcomed.
&gt; I believe I read that a crate is a translation unit, so does that mean that if I have a large create, I can't reap the benefits of recompiling only what has changed? rustc maintains a cache of already compiled functions, so incremental compilation is much faster than from scratch compilation. &gt; Does the fact that Rust does not use header files make it slower to compile, as there is no separation of interface and implementation? On the contrary, header files are an abomination. There's a reason that C++20 will have modules. &gt; What is the slowest part of the Rust compilation process? Is it the type system? The borrow checker? Apart from specific performance issues which crop in from time to time: code generation (LLVM). rustc produces really verbose LLVM IR, and LLVM takes a long time to translate it into object code. This is one of the driver for the `cranelift` project, which first aims at offering a very fast Debug build for rustc, and may later add some optimizations on top.
&gt; I believe I read that a crate is a translation unit, so does that mean that if I have a large create, I can't reap the benefits of recompiling only what has changed? The compiler does incremental compilation, so you still get those benefits. Theoretically this works at an even finer granularity than C++ (where you almost always rebuild a whole `.cpp` file), but practically not all parts of rustc are incremental yet, and many parts of it are a bit inefficient (also linking is often very slow). &gt; Does the fact that Rust does not use header files make it slower to compile, as there is no separation of interface and implementation? Not inherently. Rust stores metadata in compiled libraries, which is comparable with a header file. It is also incremental, like I wrote above. &gt; What is the slowest part of the Rust compilation process? Is it the type system? The borrow checker? This depends a lot on the specific code you're compiling, but in many cases a lot of time is spent in LLVM, the backend used by rustc. There are plans to add an additional code generation backend, [cranelift](https://github.com/CraneStation/cranelift), which is much faster at producing code. A lot of crates are also spending a lot of time in the type checker, but there are also plans to fix that (which will hopefully come to fruition in 2019). During normal development with incremental compilation, linking can also take a long time. This isn't really rustc's fault, but it could also be fixed by using a faster linker like LLD by default.
It'd be awesome if it was open source, the part I'm particularly interested in is the implementation of the in-game programming language
Both built-in pointers like `&amp;T` and smart pointers like `Box&lt;T&gt;` are thin if `T` is statically sized, and fat if `T` is dynamically sized (i.e. `T` is a slice or trait object). For lots of examples, see [this playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c02f22d86a12a238a14dcfa28405becb) which produces this output: Thin built-in pointers [src/main.rs:7] size_of::&lt;&amp;u8&gt;() = 8 [src/main.rs:8] size_of::&lt;&amp;mut u8&gt;() = 8 [src/main.rs:9] size_of::&lt;*const u8&gt;() = 8 [src/main.rs:10] size_of::&lt;*mut u8&gt;() = 8 Thin smart pointers [src/main.rs:13] size_of::&lt;Box&lt;u8&gt;&gt;() = 8 [src/main.rs:14] size_of::&lt;Rc&lt;u8&gt;&gt;() = 8 [src/main.rs:15] size_of::&lt;Arc&lt;u8&gt;&gt;() = 8 Fat built-in pointers [src/main.rs:18] size_of::&lt;&amp;[u8]&gt;() = 16 [src/main.rs:19] size_of::&lt;&amp;mut [u8]&gt;() = 16 [src/main.rs:20] size_of::&lt;*const [u8]&gt;() = 16 [src/main.rs:21] size_of::&lt;*mut [u8]&gt;() = 16 Fat smart pointers [src/main.rs:24] size_of::&lt;Box&lt;[u8]&gt;&gt;() = 16 [src/main.rs:25] size_of::&lt;Rc&lt;[u8]&gt;&gt;() = 16 [src/main.rs:26] size_of::&lt;Arc&lt;[u8]&gt;&gt;() = 16
1. Incremental compilation works on changes smaller than a crate, so it shoudl be non-issue. The only strictly-per-crate step is linking, which can be slow with LTO (link time optimization) enabled, but IIRC there are some advancements in incremental-LTO so even linking can be incrementalized. 2. I'd say that in theory it could even make Rust faster. Rust creates `.rlib` files for dependencies crates, which (in addition to compiled machine code) contain header-like metadata in a compiler-friendly format. So one could say there are something "header-like" for Rust, but it's hidden as compiler's implementation detail. The most important difference here is that since crate is a compilation unit usually bigger than `.o` file, compiler has to look at more code at once (which is slower, but optimizes better). 3. Actually, IIRC the slowest part is code generation and optimization done by LLVM. Rust has zero-cost abstractions, but they are zero-cost on runtime and memory, not necessarily compile times. But this is still worked on – it's planned to generate cleaner and pre-optimized code for LLVM, so it has less work to do.
oopsie 
I gotta say, it looks pretty great. I was reading about how the encryption works, and it's pretty cool - it puts the secret key in the hash part of the url so that it isn't sent to the server. But it stores a signing key in the server so that it can verify signed requests
https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=95305a13f1be86ccc767c4f2b209fd84 You need to specify that `&amp;self`'s lifetime needs to last as long as `Game`, otherwise a user of the function could supply a reference with a shorter lifetime: let game_key = { let game = Game { ... }; game.key() }; // game_key now contains a reference to freed memory 
Exactly! The upcoming Firefox Send version (probably released soon) will work slightly different, but uses the same concepts. File metadata is encrypted and stored on the server. This is essentially what the optional password is used for (if I remembered correctly). There's also a 'hidden' owner token used to authenticate yourself as file creator, allowing you to manage it (delete it, change the password, change the download limit).
That probably works well with my little library "[bacon](https://www.github.com/aspera-non-spernit/bacon)" that encrypts any struct with SPECK
Is the link under Learn to the official FAQ broken? I got a 404
I heard about cranelift while reading about Fastly's web workers thing. So is the long term goal to move Rust off of llvm onto cranelift? If llvm takes a long time to produce object code, isn't that something the llvm folks would want to fix for the Rust team? I assume every llvm language would have this same pain point.
I'd be interested in seeing what your ORM needs look like (what kind of API would you like to see available?). It's pretty incomplete at the moment, but I have an in-progress port of Eloquent to Rust that I've been working on sporadically...
Do you ensure the course work is required you to implement a library of numerical analysis rather than focusing on numerical analysis itself (i.e. using the library already provided by Julia/Python (Numpy, Scipy))? 
Does that mean that each crate is turned into exactly one .o file? Would LTO be faster if I wrote more small crates instead of one big crate? &amp;#x200B; &amp;#x200B;
Here's the first problem, written out explicitly (For clarity, you can't actually put lifetimes in borrows like this) impl&lt;'a&gt; Keyable&lt;GameKey&lt;'a&gt;&gt; for Game&lt;'a&gt; { fn key&lt;'b&gt;(&amp;'b self) -&gt; GameKey&lt;'a&gt; { (&amp;'b self.date, self.home_team, self.away_team) } } The borrow of [`self.date`](https://self.date) has the same lifetime as the borrow of `self`. We can't just force the borrow to match, because then it doesn't match the trait signature. impl&lt;'a&gt; Keyable&lt;GameKey&lt;'a&gt;&gt; for Game&lt;'a&gt; { fn key(&amp;'a self) -&gt; GameKey&lt;'a&gt; { (&amp;self.date, self.home_team, self.away_team) } } // error[E0308]: method not compatible with trait So what can we do? We may need to change the trait: trait Keyable&lt;'k, T&gt; { fn key(&amp;'k self) -&gt; T; } impl&lt;'a&gt; Keyable&lt;'a, GameKey&lt;'a&gt;&gt; for Game&lt;'a&gt; { fn key(&amp;'a self) -&gt; GameKey&lt;'a&gt; { (&amp;self.date, self.home_team, self.away_team) } } This is the easiest way I can think of to solve it. By doing this, we can specify how the borrow of self in the key method relates to the output.
&gt; I heard about cranelift while reading about Fastly's web workers thing. So is the long term goal to move Rust off of llvm onto cranelift? No, LLVM will stay since it generates extremely good machine code. Cranelift would be added in addition to LLVM, and might be turned on by default for debug builds in the (far) future. Cranelift is fast at generating code, but the resulting code usually runs much slower than LLVM's optimized code. &gt; If llvm takes a long time to produce object code, isn't that something the llvm folks would want to fix for the Rust team? I assume every llvm language would have this same pain point. Yes, that's true, but it's more of an architectural problem that is very hard to solve. LLVM is focused on ahead-of-time compilation with lots of optimizations to make the generated code run fast, and that's generally what Rust and other languages *also* want. Cranelift was designed also with just-in-time compilation in mind, where it will generate slower code as quickly as possible instead.
&gt; So is the long term goal to move Rust off of llvm onto cranelift? Off? No, the plan is to add a Cranelift backend in addition to the LLVM one. Cranelift will be used for debug builds where compilation speed is most important and LLVM will be used for release builds where runtime performance is most important. &gt; If llvm takes a long time to produce object code, isn't that something the llvm folks would want to fix for the Rust team? A lot of this is that rustc is just really bad about generating LLVM IR. Contributing to this is that idiomatic Rust tends to be much more monomorphic than many other languages which results in a much larger amount of IR generated in the first place.
&gt; Does that mean that each crate is turned into exactly one .o file? This used to be the case, but nowadays the compiler will basically automatically split the crate into object files as needed (resulting in dozens of object files). &gt; Would LTO be faster if I wrote more small crates instead of one big crate? Unlikely, the work the compiler has to do in roughly the same. Using multiple small crates can still have advantages though, since incremental compilation isn't quite perfect, so there's still some work the compiler will do for *every* build. If that work is only on a small crate instead a large one, it will be faster.
Rust has very little to do with threads, it just tells the operating system to make threads and the OS handles the rest. 1. The operating system uses [preemptive multitasking](https://en.wikipedia.org/wiki/Preemption_(computing)#Preemptive_multitasking) to run many software processes/threads on few hardware threads. Think about back when CPUs only had one core; they could still run multiple processes/threads (after DOS at least). The OS just switches between them very fast so it looks like they're all running simultaneously. 2. Rust doesn't have any sort of intelligence running in the background to make decisions like this. It's a low-level language: it does what you tell it to and nothing more. If a thread fails to allocate memory, the `oom` handler is called which by default just aborts the process. One common tactic for working with large files is to use [memory-mapped IO](https://github.com/danburkert/memmap-rs), which allows the program to pretend the whole file is loaded in memory but the operating system only actually loads the parts which are being accessed. If you don't need the entire file in memory, then don't load the entire thing in memory. This is what most programs that deal with large files do. Load a small amount of the file, process it, then load the next bit. If you do need the entire file loaded in memory, then you'll need more than 16GB RAM to work on a &gt;15GB file.
Tbh, I'd just use Next.js, it does exactly what you need. You can still use Rust for the API.
I’ve considered it, was hoping to use as much Rust as possible in order to learn :)
Awesome, thanks a ton, especially with the example that would cause a bad reference. Another question, in your linked playground you had slightly different code: trait Keyable&lt;'a, T: 'a&gt; { fn key(&amp;'a self) -&gt; T; } What does the `T: 'a` mean? Not sure what it means for a generic type to subclass a lifetime itself.
It means the references contained in `T` (if any) will be valid for the lifetime `'a`.
Thank you very much! I think that makes sense. I need to specify that the `self` lasts as long as the returned key, or else someone could hold onto the key which would reference part of the `self`, and could cause a reference error. I think I got confused because I thought my generic type `T` had to also declare a type param `'a`, like `GameKey&lt;'a&gt;`. Something like: fn key(&amp;'k self) -&gt; T&lt;'a&gt;; Which gave me errors.
I think it's also very valuable to link HN discussion which contains a lot of great information as well: [https://news.ycombinator.com/item?id=19306666](https://news.ycombinator.com/item?id=19306666)
Most of what happens here is OS-dependent. For example, some systems are happy to "give" you ridiculous amounts of memory when requested by e.g. a `malloc` call, but in reality no actual memory is assigned to your process until you try to make use of it. Then what happens after you *do* make use of it is also system-dependent. Some of the excess memory might get shunted off to a pagefile, or maybe the OS will decide it's tired of your shenanigans and will kill your process if too much memory gets used. The OS will also happily spawn more threads than you have CPU cores and will schedule them all in and out like a juggler keeping balls in the air. But if you have *that* many threads going on then the overhead of juggling them will be greater than the benefits of having threads in the first place.
Hi! I need help with the serde, especially, how to serialize struct into externally tagged JSON object, which can be easily done with enums, but I could not find any info how to do that with struct. For example pub struct A { name: String, config: HashMap&lt;String, i32&gt;, } let a = A { name: "struct", config: hashmap!{ "value" =&gt; 10 } }; I would like to serialize the struct into value: `{"struct": {"value": 10}}`, so the name field would became the externall tag for the structure. Can this be done without manual De/Serialization trait, and if yes, how? Thanks &amp; Cheers !
As you mention, a vector of vectors has bad cache performance, but it isn't that bad of a solution. You could look into how system allocators work. A relatively simple structure for this is a "free list". Since your blocks of memory don't need to be resized, you can use boxed slices instead. These are similar to vectors but lack the capacity field and cannot be resized. All you should have to do is replace `Vec&lt;u32&gt;` with `Box&lt;[u32]&gt;` and convert with `vec.to_boxed_slice()`. I would recommend adding a panic if you try to allocate when you already have `u32::MAX` values, since you can't represent any further addresses. The `v.clear()` you point out is not needed. When you set the element to `None`, the vector is dropped and will free its contents. Also, you've already indexed once with `get_mut`, you could bind to the block by matching `Some(v@Some(_))` and then just do `*v = None`. Rather than using those matches though, you can reduce nesting in some of your functions by using option methods. For example: fn read(&amp;self, addr: u32, offset: u32) -&gt; &amp;u32 { let block = self.data .get(addr as usize) .unwrap_or_else(|| panic!("read: address {} has not been allocated", addr)) .as_ref() .unwrap_or_else(|| panic!("read: address {} has been deallocated", addr)); block.get(offset as usize) .unwrap_or_else(|| { panic!( "read: offset {} is out of bounds for address {} (len: {})", offset, addr, block.len() ) }) } Another thing to look into is that it is usually preferred to return Results with a custom error type from your functions instead of always panicking. Overall, this is a good solution, especially for a Rust beginner!
I'll keep that in mind. Thanks!
While this also impacts how fast RLS gets its index data, the frontend of the compiler (parsing, macro expansion and name resolution) is not yet incremental, so it’s something that is done on every rebuild now. The RLS also loads everything upfront rather than lazily computing the answer, so there’s another aspect that influences the latency.
My [sugarmantra](http://github.com/BartMassey/sugarmantra) does something reasonably similar. It sort of works with non-ASCII text, since it uses a hasmap-based multiset to store the character counts, but it has some English-specific heuristics (it does stemming on the dictionary and includes some heuristics for English, so it will find some extra English anagrams) and has only been tested with English. It's single-threaded, and substantially slower than your solution: on a similar task it outputs all anagrams in about 40ms. I sort all the words in reverse order by length before I start, which speeds things up and also outputs anagrams with longer words first.
I have open sourced the more generally applicable utilities that I developed for the game, most notably [glyph-brush](https://github.com/alexheretic/glyph-brush) which lead me to take over maintenance of [rusttype](https://gitlab.redox-os.org/redox-os/rusttype). Also [spin-sleep](https://github.com/alexheretic/spin-sleep), [single-value-channel](https://github.com/alexheretic/single-value-channel), [linked-hash-set](https://github.com/alexheretic/linked-hash-set).
Still continuing my journey to Rust contributing to [https://github.com/svenstaro/miniserve/](https://github.com/svenstaro/miniserve/) I learn a lot, be it on Rust and on contributing in general. Also, I think the tool is great, and will be awesome when all features will be added. Exit SimpleHttpServer :) 
So uh, hi there. How do i get through "trait cannot be made into an object: method has generic parameters"? trait Layer { fn learn&lt;T: Output&gt;(&amp;mut self, input: &amp;Vec&lt;T&gt;); } impl Layer for ConcreteLayer { fn learn&lt;T: Output&gt;(&amp;mut self, input: &amp;Vec&lt;T&gt;) { LayersShared::learn(self.content, input); } } trait Output { fn output(&amp;self) -&gt; f64; } impl Output for Entity { fn output(&amp;self) -&gt; f64 { self.output } } impl Output for f64 { fn output(&amp;self) -&gt; f64 { *self } } pub layers: Vec&lt;Box&lt;dyn Layer&gt;&gt; As you can see i have layers which can have tons of different inputs, but all inputs implement "output". I just want dynamic dispatch for layers and uniform processing of inputs and fast processing of layer contents, which are vectors. Read handbook, literally no idea what to do.
Just had my *super* minor PR merged into ALE, allows vim users who use ALE for async linting to use clippy by way of RLS. It was already available by way of the `cargo` linter, this just adds it through RLS via the `clippy_preference` setting (or can also set other RLS settings). Thanks to this subreddit for being so tolerant (and even encouraging) to me and others new to rust, hopefully some of you find this useful!
So, basically you're asking how to draw an image using OpenGL 3/4. The single call you have to make is glium::Surface::draw onto your target frame, but to do that you also need a vertex buffer for a Quad and a shader to map the vertices and sample the image. Basically you should follow some of the simple textured glium examples
It will use whatever you've statically linked. So most likely whatever allocator comes with musl.
100% Rust? This looks fantastic, and is also very inspiring.
&gt; Maybe my default_cost is too hard. You can try a cost of 10 or 11 instead of the default 12, that depends on your server and what you consider to be an acceptable speed.
If you find anything through fuzzing, please add it to https://github.com/rust-fuzz/trophy-case I've been doing some fuzzing runs recently and discovered dozens of new bugs in previously fuzzed projects. Looks like we badly need fuzzing on CI, one-off fuzzing doesn't cut it.
Can you share at least the general algorithm of your in-game language implementation? Or can you share resources you've used to build and design it?
Awesome news
For `Serialize` you could write an impl by hand, it's not that big ([playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=421626c45a141074edf966c01f15cabb)): impl Serialize for A { fn serialize&lt;S: Serializer&gt;(&amp;self, serializer: S) -&gt; Result&lt;S::Ok, S::Error&gt; { let mut map = serializer.serialize_map(Some(1))?; map.serialize_entry(&amp;self.name, &amp;self.config)?; map.end() } } Though I'm not sure how to deserialize this nicely.
I tried to write one of my fried (encrypted) bacon (any struct) into the [persy.storage](https://persy.storage). When I try to insert it says segment not found. Don't know why. &amp;#x200B; // fry struct let fried_bacon: Bacon = fry!(vip, key_128); // persist in file system // open or create and open persy storage println!("Trying to open: {:?}", path); let result = match Persy::open(path.clone(), Config::new()) { Ok(p) =&gt; { println!("persy opened."); Ok(p) }, Err(e) =&gt; { dbg!(e); println!("Trying to create: {:?}", path); match Persy::create(path.clone()) { Err(e) =&gt; { dbg!(&amp;e); Err(e) }, Ok(_) =&gt; { println!("persy created.\nTrying to open: {:?}.", path); let persy = Persy::open(path.clone(), Config::new()).unwrap(); println!("persy opened."); let mut tx = persy.begin().unwrap(); match persy.create_segment(&amp;mut tx, "def") { Ok(_) =&gt; { println!("segment default created."); }, Err(e) =&gt; { dbg!(e); }, } Ok(persy) } } } }; // persy fried bacon into persy.storage let persy: Persy = result.unwrap(); let mut tx = persy.begin().unwrap(); // ERROR NEXT LINE 'called `Result::unwrap()` on an `Err` value: SegmentNotFound' let id = persy.insert_record(&amp;mut tx, "def", &amp;serialize(&amp;fried_bacon).unwrap()).unwrap(); dbg!(&amp;id); drop(fried_bacon); // load fried bacon from persy.storage ... // decrypt attempt with correct key .... &amp;#x200B;
Sure. Do tell more.
I'm the project mentor and I'm happy to answer any questions about it.
I suspect you are looking for [/r/playrustservers](https://www.reddit.com/r/playrustservers) instead.
PR sent. Found some aborts from too large memory allocations, a way to make the program take very long by creating a very long image, and nothing else so far. I wrote rawloader mindful of the issue from previous experience fuzzing the equivalent C++ codebase. I spent less time writing the initial version of the crate than I had already spent trying to plug the holes in the C++ code. Some things I knew to fix from the start (e.g., prevent infinite looping TIFF structures). For everything else I decided I wasn't going to sprinkle the code with tests for corner cases that only happen in manufactured files and that I can't verify are ever complete. So I let rust do the heavy lifting for me and have just caught panic in the top level decode function and turned it into a normal error. It's a somewhat controversial way of doing things but it's worked well. I see no point in figuring out all the corner cases myself when the compiler is already doing that for me. Raw formats are too finicky to not automate things like that in my experience.
I don't understand the following? let id = None; let to_find = vec![1;20]; for record in persy.scan_records("seg")? {..} Why would I search for something in persy when I have it already allocated to to\_find?
message me on discord C2Woody#2317
Not exactly what you're looking for, but David Tolnay compiled a list of projects that don't exist yet: https://github.com/dtolnay/request-for-implementation
[https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=00979eac3428e743e92cdbbbf1029191](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=00979eac3428e743e92cdbbbf1029191) &amp;#x200B; I am getting a "SegmentNotFoundError" ,when I try to insert something into the segment.
This is awesome although I am more looking to contribute to something that exists already. I may start my own crate but that still seems a bit daunting to me.
&gt; At another angle: both are pointers with additional information. A smart pointer has additional behaviour, it doesn't _need_ to carry additional information. Also, any pointer to a trait object is a fat pointer because it needs the address of the vtable as well as the object's data.
&gt; At another angle: both are pointers with additional information. A smart pointer has additional behaviour, it doesn't _need_ to carry additional information. Also, any pointer to a trait object is a fat pointer because it needs the address of the vtable as well as the object's data.
If you want to contribute to the compiler or associated tooling, hop into either of: + https://rust-lang.zulipchat.com/#narrow/stream/122652-new-members + The [`#contribute` channel on Discord](https://discordapp.com/channels/442252698964721669/487245758739906560)
I wrote the lexer, parser and interpreter from scratch in 2017. I think nowadays there are more well known fancy crates to help with this stuff. The interpreter has a deeply integrated debugger-like controller so the game can highlight the current expression as the program is running and I can pull stats out of the run, ie to see how many unique expressions were run. It has mechanisms to connect the program to the game world. Other than that it just recursively goes about interpreting and building up it's virtual stack. So it's all very specialised and I would guess the bits that aren't are probably already better served by existing crates. It was quite fun to create a simple language actually, making a game around it turned out to be much harder!
Do you have a specific interest? &amp;#x200B; Is not the same look for improve something that starting something established (like for example support Json) to experimenting... \----- p.d: I'm building a relational language (in the sense of python, Lua, ...) that combine relational/in-memory database concepts and common language implementation: [http://tablam.org](http://tablam.org)
[This Week In Rust](https://this-week-in-rust.org/) has a Call for Participation section which list ways new people can contribute. For example, this is the latest one: https://this-week-in-rust.org/blog/2019/02/26/this-week-in-rust-275/#call-for-participation Have a look at a few TWiR posts and see if anything strikes your fancy. Some of those tasks even have mentors.
This is perfect thank you so much.
I have found the Servo team really approachable and supportive. They even tag issues that are relatively easy so you know which ones to look at: https://github.com/servo/servo/issues?utf8=%E2%9C%93&amp;q=is%3Aissue+is%3Aopen+label%3AE-easy 
This seems really interesting and they do make it very easy to find what you can work on. Thank you!
Is there an RFC or plan stated anywhere about allowing compiling some parts in release mode and other parts in debug. Hopefully per crate?
Hi! Thank you very much for your kind words and your answer, that's extremely helpful! You even answered some of the questions which I had, but forgot to ask :) Indeed, I read about Boxes and wanted to use one around an array with Box::new(arr). But I didn't know how to create the array with dynamic size! But you've shown this trick with into\_box\_slice(), so I can now create a vector and then convert it to a Box to show that it's not resizable and save some space on capacity field, great! I've added the check for u32::MAX, that's a good idea! But when I tried to write a test to fill all the memory it didn't work, of course, since creating 2\^32 boxes (even with just 1-element blocks) does not happen very fast :) I waited until I get close to the end of my virtual memory and then terminated the test ;) I wonder how much memory would it take in total, but it looks like probably around 64 GB (2\^32 = 4 billion of boxes and each Box will take some space, maybe something like 16 bytes, I'll have to check with mem::size\_of\_value). Regarding v.clear() -- thanks for confirmation! I was not sure that it will be dropped, but I made some experiments with Valgrind on simpler code and it looks like there is no memory leaks indeed :) Also, a nice trick with "\*v = None"! I haven't yet reached the point in the book when you introduce explicit dereferencing operator, so it was completely new to me in Rust. Regarding the chains: I'm not quite sure that it works for me at this stage, but I can see that's it's neater for an experienced Rust programmer. I've rewritten all the functions in the proposed style, but I think that those long chains lead to more obscure error messages which are harder to read, since they are not pointing to a single line, but rather to some specific points in the chains. Also, I still haven't fully figured out why that as\_ref() is needed. I'm guessing that it's needed to convert Option&lt;T&gt; to Option&lt;&amp;T&gt;, so that we borrow instead of moving into 'block' variable, but when I removed it, again, the error message was somewhat hard to read and I had to go to the documentation to figure out what's going on. I've added rewritten functions with suffix "2" to the file here: [https://github.com/sphynx/um/blob/e81bca8531ee7ea9e45e108a9ca3343c7f2b1515/src/mem.rs#L129](https://github.com/sphynx/um/blob/e81bca8531ee7ea9e45e108a9ca3343c7f2b1515/src/mem.rs#L129) I'm also interested in benchmarking this, I think it would be interesting to check performance and memory usage with Box&lt;\[u32\]&gt; against Vec&lt;u32&gt;, can you recommend any good tools/libraries for that? Thanks again for your time and for writing that thoughtful review. 
Let's say I have the following Enum enum MyEnum { VariantA, VariantB, VariantC, } I can derive the PartialEq trait for the whole enum by doing so #[derive(PartialEq)] enum MyEnum { VariantA, VariantB, VariantC, } What I want to do, is derive the trait but only to particular variants and not the whole enum. Is that possible? (or does it even make sense?).
FWIW, I think that's a great approach to open source and games. That's more or less what I was planning to do, but my game idea is now officially on the back burner. I'm looking forward to trying this one!
Enum variants are not considered their own separate types, so that doesn't really make sense. What behavior do you expect if that *were* possible?
I could be mistaken, but I'm pretty sure this already works. There are knobs you can turn in your `Cargo.toml` to talk about the optimization level of dependencies vs. your crate. Search for `opt-level` to see examples: https://doc.rust-lang.org/cargo/reference/manifest.html
oh, awesome! I love it. i was literally asking about this in IRC yesterday.
Thank you for posting this! Your algorithm is very elegant and more akin to what I would have wanted to write (probably not nearly as well though), if I had understood the requirements in that way. But I was quite confused by the following requirement of the task: &gt;4. Does the application need to find multi-word anagrams, e.g. if the input is “kalamaja” should it find anagrams like “jama kala”? *When the input is multi-word, then it’s expected to match a multi-word anagram (the basis being that the input contains space, the output should also contain space).* I even asked extra questions to clarify this, and based on the response it seemed that they were only interested in exact anagrams e.g. all the letters of the word in one dictionary entry. Which makes the problem trivial, compared to sugarmantra's case (all possible combinations of smaller words having the same letters). It seemed odd, as this does not fit well into the [common understanding for anagrams](https://en.wikipedia.org/wiki/Anagram), which could have any number of spaces (or sub-words), but this is what I extracted from the requirements. But as I also had limited time (only discovered this contest with 2 evenings to spare) I went with this trivial approach. While I won't change the contest entry (and it's too late anyway) I'll probably try out something closer to sugarmantra in a branch of the project, as that makes the problem an actual challenge allegorically 
Some variants are types from other crate which can not derive the PartialEq trait. I'm happy if I can derive only for particular variants (though that might be bad design)
You could look through the `rustc` issues on github and try to find ones tagged `mentor`, meaning there is someone who is willing to mentor someone else as they work on the issue. https://github.com/rust-lang/rust/labels/E-mentor 
If deriving doesn't work then you can always try a manual implementation. Maybe that won't work either but it's the next route to try at least.
You'll want to look into [Associated Types](https://doc.rust-lang.org/book/ch19-03-advanced-traits.html). I'd need more information for a better answer, though, preferably a complete example on play.rust-lang.org.
Yeah I'd recommend sticking with Tokio for a bit. I found once I'd pushed through and written a couple poll methods by hand things started making a lot more sense. The concepts were pretty hard but there aren't too many of them.
&gt; recursively goes about interpreting So I guess it's a tree-walking interpreter, am I right? I'm actually asking about learning resources: books, articles, maybe other projects etc. You know, I want to write a language that will basically be a modern rethink of Lua, but with the same goals (i.e. it'll be embeddable and it won't have some fancy syntactic sugar), so I'm reading a book called "Crafting interpreters". Unfortunately, this book isn't finished yet, and my project has a very low priority right now.
I'm continuing to plug away on [tallystick](https://github.com/phayes/tallystick) (nee `tallyman`), a rust library for tallying votes for a wide range of tally methods. 
You did some amazing work for a two-night project. I suspected the constraints might be different: seems like you tuned well for them. Thanks for sharing this.
You should contact Packt Publishing and O'Reilly. Both seem to be aggressively seeking new authors.
Regarding long chains, that's totally understandable. I'd recommend breaking them up into steps, which also gives you a chance to understand what the type is at each step. Here's how you could break one up, but you could go even further if you wanted. pub fn read2(&amp;self, addr: u32, offset: u32) -&gt; &amp;u32 { let allocation: &amp;Option&lt;Box&lt;[u32]&gt;&gt; = self .data .get(addr as usize) .unwrap_or_else(|| panic!("read: address {} has not been allocated", addr)); // A borrow of Box&lt;T&gt; can be either &amp;Box&lt;T&gt; or &amp;T // Read up on box and smart pointers for more info let block: &amp;[u32] = allocation .as_ref() .unwrap_or_else(|| panic!("read: address {} has been deallocated", addr)); block.get(offset as usize).unwrap_or_else(|| { panic!( "read: offset {} is out of bounds for address {} (len: {})", offset, addr, block.len() ) }) } You're right on the reason for needing as\_ref(), you can't move out of self.data, so you have to borrow instead by turning an &amp;Option&lt;T&gt; into an Option&lt;&amp;T&gt;. When you match on an &amp;Option&lt;T&gt;, there's a feature called "match ergonomics" that automatically borrows, but when doing it this way, you have to do it explicitly. I agree that this error message is confusing when you first see it, but it'll definitely become second nature over time to deal with these sorts of things. I forgot to write the as\_ref() when I was writing it, but when the error message popped up I barely had to read it, because I've seen it before and had intuition on where the issue was. For benchmarking performance, the crate criterion is very popular and well written. For memory usage, I suppose you could either use the popular general tool valgrind or something that wraps the allocator and keeps track of usage, like the crate stats\_alloc.
What command did you use to build the program? Was it `cargo build --release`? I ask because I would like to know if this is an optimized build (as opposed to a debug build, for example.)
It's a release build, yes, I'll add that to the methodology.
associated types can't be boxed as well. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=7eb6c2ce6e63ab7e7ffc2dcc55723e2c here you go. afaik this literally can't be implemented in rust. did this in c++ in 2 minutes btw.
Really need to try this out. I would require media keys and library/playlist browsing to completely switch over from the official client though. Thanks!
Dang it. I'm using glyph_brush_layout but I wrote my own spin-sleep. Should have looked at your other crates.
Shameless plug for an Elm/React-like \[frontend framework\]([https://github.com/David-OConnor/seed](https://github.com/David-OConnor/seed)) I built. Caveat: I'm not sure if it's compatible with an isometric approach, but it is capable of sharing data structures with the server, eg the \`server integration\` example.
This works, but I don't know enough to know how good of a solution it is: [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b6c96ed99305c910d4f4dc51f0eae27e).
This looks really cool! It might save me hand-rolling the storage solution for a project of mine.
While fuzzing PNG and Vorbis decoders in Rust, some panics actually pointed to bugs that impacted decoding valid data, not only maliciously crafted files. So you should try at least making a pass without catching panics, it might turn up something actually relevant. Also, any reason why the panic is automatically handled in the library instead of leaving this up to the caller?
Huh...I had an idea which was crazy similar to this. An idea for teaching kids how to code, with a little robot that you write scripts for. I thought about calling it "robot, please" because each "do" block would be prepended with the keyword `please`. I thought about taking it in a more resource collection / fabrication direction, and then you find ways to automate it. Maybe a kinda stardew valley esque thing with code. This is a huge inspiration! Can't wait to check it out.
In case anyone is interested, I just wrote a very simple python script to automate this process slightly, so that you can do \`./gen\_docsets.py serde regex serde\_json\` and it will build the docsets and put them in a single subdirectory.
https://github.com/PistonDevelopers/image 
Thanks for your comment. I guess I'm gonna try with 10.
I've just imported the Library at the cargo file: [dependencies] rusty_secrets = { git = "https://github.com/nvesely/RustySecrets", branch = "update-deps" } afterwards I created a main.rs with a simple Hello-World function: fn main() { println!("Hello, world!"); } afterward, I tried to compile this with the terminal an cargo by `cargo build` and this is the terminal output: Compiling merkle v1.10.0 error: failed to run custom build command for `merkle v1.10.0` process didn't exit successfully: `/Users/kaller/IdeaProjects/dssaa_s/target/debug/build/merkle-f78177df6eb47b03/build-script-build` (exit code: 101) --- stderr thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: Os { code: 2, kind: NotFound, message: "No such file or directory" }', src/libcore/result.rs:1009:5 note: Run with `RUST_BACKTRACE=1` for a backtrace. ``` But folder at the External Libraries at me IDE for merkle v1.10.0 with flies seems to be there.
&gt; So you should try at least making a pass without catching panics, it might turn up something actually relevant. I'm considering that for the fuzzing of the decoders themselves. &gt; Also, any reason why the panic is automatically handled in the library instead of leaving this up to the caller? The API is only correct when panics are caught. The contract is that it returns the image or an error in case it's not readable. Catching panic is an implementation detail. Having the caller have to catch panic would make for a really awkward API. The only downside is that the crate is not really suitable for situations where you want panic=abort for some reason.
I find it amusing that a language where nobody complains about this but arguably has the worst case is Haskell, simply because every single monad is, in effect, a different color. It's not as intrusive simply because it has a standard DSL (do_notation) which allows you to write functions that are polymorphic over color.
I've written a bytecode version of lox in rust from crafting interpreters. I've found the book gets you most of the way! For the rest, you can check out [Bob's code on GitHub](https://github.com/munificent/craftinginterpreters). Should be a help!
The nightly-only profile-overrides feature can be used to customize the optimizations for each crate: https://doc.rust-lang.org/cargo/reference/unstable.html#profile-overrides
&amp;#x200B; you need to commit also the tx that create the segment.
How is performance for this? Is clippy fast enough to work as you type on a larger project? It currently takes between 5 and 20 seconds to do a typical *cargo check* on one of the subcrates of my current project, for example. I guess clippy does a lot less work than that though.
Thanks for the plug! Looks like a super interesting project and I really appreciated your documentation; helped me understand how I might structure a project using Rocket. Thanks again!
I know the ALE is the plugin of vim for linter. What is the `clippy` exactly?
https://github.com/rust-lang/rust-clippy
I have not worked on any large projects (still trying to work my way through Advent of Code). Would be interesting to hear your experience if you give it a shot. I would hope that the incremental compilation magic in the RLS may lead to a better user experience, though I think cargo already uses some of those tricks. 
Didn't SPECK get dropped from Linux just now because of how weak it is as well as backdoor concerns?
The first step many reviewers here will give you is to run rustfmt and clippy. [Rustfmt](https://github.com/rust-lang/rustfmt) is a formatter, which will give your code a consistent layout. Right now, your code looks very cramped since you don't seem to like spaces :). I have my editor set to run rustfmt whenever I save. [Clippy](https://github.com/rust-lang/rust-clippy) is a linter, which will give you warnings on many common mistakes present in your code. I have it set up with my editor to underline any issues. Using these tools alone will take you pretty far in writing idiomatic rust, and then after that, a review will help you go further.
aah. thank you. works and successfully implemented into my bacon lib: https://github.com/aspera-non-spernit/bacon/blob/dev/examples/persy.rs Would be cool if there would be some simple p2p activity like IPFS.
We're always open to contributors over at [remacs](https://github.com/remacs/remacs)
mainly because NSA wasn't willing to tell why they used certain techniques, so auditors were suspicious, but there's no known public way to break SPECK with the larger keys and blocks. SPECK is lightweight and not aimed to protect the super top secret stuff. Here's a challenge for you. Tell me what info is encrypted: let ukwn_fried_person = "{ \"data\": [ 199989347279576730303273302831594482298, 89686176579382696547722799744440123650, 200571766683922312051532064628431861624, 272773095845529367494637394170706300494, 135123051543652942388160897815955354259, 241581523358705025852766085352301738865, 294742954104957886459273945034249829905, 170057818899735271015144833461180432525, 86971309882052014176151965736908291274 ] }"; The decrypted data can be deserialized into a struct Person using bincode::deserialize: enum Gender { Female, Male } #[derive(Clone, Debug, Deserialize, Serialize)] struct Person { name: String, age: u8, gender: Gender, address: String, description: String } The exact algorithm can be examined here: https://github.com/aspera-non-spernit/bacon/blob/dev/src/speck.rs I'll use another encrypttion algorithm if anyone in the rust community can break it :)
Not necessarily. As a comment below mentions, `Rc&lt;u8&gt;` is a thin pointer (to an allocation which has the refcounts and the `u8`) while `Rc&lt;[u8]&gt;` is a fat pointer (to an allocation which has the refcounts and the `[u8]`). The latter includes the size of the `[u8]` along with the pointer.
Rookie mistake not to use automatic tools. Thank you kind stranger.
&gt; Yes, Rust could look at function bodies and infer lifetimes. Not doing so is a choice. Ok, that helps. But I'm curious, is it theoretically possible to infer all lifetimes? If so, would the difficulty be at the level of a perl script or require a warehouse of supercomputers? I think every beginner reaches the point where the borrow checker complains about something and they think "If you are so sure about it, why are you making me do it?" And it doesn't help that all the book examples would be easy for it to figure out.
This looks like a very interesting paper, and has been put on my reading list. One thing I find hard about academic texts however is use of words. I fully understand that they utilize formal words to give a serious and professional tone. However for a average person I really have to grok each sentence to understand the mening. Listen to this one; &gt; This presentation takes a new view of lifetimes as approximate provenances of references, and our type system is able to automatically compute this information through a flow-sensitive substructural typing judgment for which we prove syntactic type safety using progress and preservation. This is a mouthful of a sentence, however it does flow quite nicely. 
Well, the meat of this paper is a type safety proof, and proofs have to be precise to be valid. The precise language of proofs is often not the easiest thing to understand.
if it compiles you are fine :)
Crawl quotes from [https://www.goodreads.com/quotes/](https://www.goodreads.com/quotes/). Src: [https://github.com/pearl2201/quotes](https://github.com/pearl2201/quotes) Result: [https://pearl2201.github.io/quotes/data/quotes.json](https://pearl2201.github.io/quotes/data/quotes.json)
I don't think the goal is actually to sound serious or professional (certainly, that's not _my_ interest), but rather, the goal is to express oneself precisely and concisely. The latter is very important because we have pretty stringent page limits, and there's basically never enough space to truly say _everything_. Fortunately for academics (but unfortunately for people outside of the community), we have jargon that helps us express complicated things concisely. For example, the phrase "flow-sensitive substructural typing judgment" can probably help a reader with the right background to imagine the shape of the typing judgment before ever seeing it, as well as get a sense of some of its properties.
Couldn't find it. I settled for saving it to jpg. GUI isn't my main goal, but would have been nice.
Gotcha. In other words, OpenGL probably isn't the easiest way to do this. I figured out that I can use conrod's imagebuffer using a vector of arrays, but I decided not to implement it. Thank you so much for your help though. &amp;#x200B; I don't remember if it was conrod that had that specifically, maybe "image", but it was all... linked...
Oh, also worth adding: I don't think there's many people who are _seriously_ reading these things fast. My personal experience is that reading papers is _much_ slower than reading a book. The text is very dense!
I wouldn't say that it's exclusively compile-time. \`Cow&lt;'a, T&gt;\` is a form of smart pointer with dynamic rules.
While there's certainly a degree of professionalism required, I find this attitude very slightly offensive as someone who worked very hard on their group's papers (oh, papers are just written this way because the authors are stuck-up, self-important, ponderous oafs!). That said, I don't doubt that some people do, in fact, put on airs when writing academic papers. From my personal experience, a *lot* of time is spent carefully tuning the words and phrasing so as to be as precise and accurate as possible, whilst still fitting in the word and/or page limit. [1] To be frank, it's probably one of the most *exhausting* parts of the process. Imagine taking every word you write and going over it a minimum of five times. You need to deconstruct every sentence and work out what you're trying to say, what you're actually saying, and how what you've actually said might be misinterpreted to make it look like you're saying something that isn't true. Often, you will need to take whole paragraphs of carefully worded information and crush it into a few sentences whilst preserving the meaning. You'll most likely end up completely rewriting at least 50% of it twice over. Much of the complexity in academic papers is a consequence of the complexity of the subject matter, which is compounded by publishing requirements. If there's a three-word phrase that can take the place of an entire paragraph re-defining what it means, you're going to use the three-word phrase. If some unusual word is closer in meaning than four common words, you're going to use the unusual word. Simple words aren't used more because simple words tend to have broader meanings. [2] You don't want broad, you want *precise*. *I'm not an academic anymore.* --- [1]: It's somewhat ironic that in school, there are all sorts of tricks people use to try and get over the minimum page count. In academia, there are all sorts of tricks people use to try and get under the maximum page count. School trains you to be wandering and indulge in vacuous verbiage to draw as meandering a thread through the topic as the language will allow, dragging the reader on a sprawling Shandified trek through the subject matter. Academia demands brevity. [2]: Like "agent". I don't think I ever managed to find two people with the same definition of the word. I once tried to work out a consensus definition of it, and ended up with something so broad that it included both advanced learning AI and flush toilets. That's why I don't like the word: it is broad the point of uselessness. 
The programming is impressing. The gameplay is lacking. Please make it an open world game like hackMUD with graphics or Minecraft. That would be awesome. Add multiplayer. Add server federation. Then it would be awesome. tl;dr: I have seen to much level based programming games and I don't want to play another.
If you're interesting in frontend web programming, contributions to [this framework I'm working on](https://github.com/David-OConnor/seed) are welcome.
Slowly coming to terms with how to make databases dance to my tune, rewriting lots of old code for a data analysis project to make it suck less, and trying to sleep.
Cool, I'll take a look at those tools! Thanks again for your help, much appreciated!
Macros are special and compiler built-in macros are even more special :-)
I can't speak for other research fields, but I will say in mine the language we use in journal articles is targeted towards a very specific audience with a specific domain knowledge/expertise. It's because of this papers can be hard to parse for anyone outside of the field. The other points that the other posts have made are also true.
Actually, I wouldn't call `Cow` a pointer at all because if `T` isn't a smart pointer then `Cow::Owned` isn't. Rc / Arc are indeed smart pointers, so the compiler can insert function calls e g when they go out of scope. (That function can in turn have dynamic behaviour.)
&gt; Imagine taking every word you write and going over it a minimum of five times. So basically the way I write every email or Reddit post, minus the part where I decide after an hour to just cut my losses and hit Send? :p
Not exactly sure what you're trying to accomplish but I think if Layer looked like: trait Layer { fn learn(&amp;mut self, input: &amp;dyn Output); } ...then the trait would be object safe. Now that changes the Output trait, maybe like this: trait Output { fn output(&amp;self) -&gt; Vec&lt;f64&gt;; } impl Output for [f64] { /* ... */ } impl Output for [Entity] { /* ... */ } 
When the value is used for indexing, I don't think it's more sensible for performance to go out of your way to specify a 32 bit integer type. If usize is 64 bits, then that 32 bit value will have be sign extended every time its used as an index. Otherwise usize is already 32 bits (or smaller).
&gt; And no, it is not the compiler's job to change your code. It dereferences references when methods are called without any complaints, that could be argued is 'changing your code' It could be argued that lifetime elision is also 'changing your code' Maybe it could even be argued that associated types are just a sneaky find-n-replace in your code. &gt; and that will only work for those cases where the solution is unambiguous and correct. This fails in a surprising number of cases. This is more of what I'm interested in. Is it failing because its difficult, or theoretically impossible?
Recently I've been trying to trace a process using `nix::sys::ptrace`. My question: Are there plans to to implement additional helper functions/wrappers for the various types of ptrace requests? Or is the documentation just not up to date? It seems odd that `nix::sys::ptrace::ptrace` has already been deprecated without any successors being mentioned for things like `nix::sys::ptrace::Request::PTRACE_GETREGS` etc.. I am still able to compile my tracing program using the deprecated features, but I'd love to quell all of the compiler warnings. &amp;#x200B; `warning: use of deprecated item 'nix::sys::ptrace::linux::ptrace': usages of \`ptrace()\` should be replaced with the specialized helper functions instead` `--&gt; src/main.rs:5:40` `|` `5 | use nix::sys::ptrace::{attach, detach, ptrace};` `| ^^^^^^` &amp;#x200B;
What do you mean? Nix 0.13 has [`nix::sys::ptrace::getregs`](https://docs.rs/nix/0.13.0/nix/sys/ptrace/fn.getregs.html).
It's a pointer in the sense that it isn't a value in itself, but points to a value, which it may or may not own. It's fat in the sense that it tracks whether it is owned or borrowed, and then smart in the sense that has the machinery to manage that state.
&gt;Shandified I understood that reference!
&gt; School trains you to be wandering and indulge in vacuous verbiage to draw as meandering a thread through the topic as the language will allow, dragging the reader on a sprawling Shandified trek through the subject matter. Academia demands brevity. Bravo!
Absolutely this. Properly reading many academic paper require close attention, and the occasional "think break" where you mentally assimilate as you slowly work your way through the paper.
&gt;then that 32 bit value will have be sign extended every time its used as an index Rust doesn't allow negative indexing and cannot allow it to have the same meaning as C. As always, out of bounds indexes *must* panic, and if you skip that check they are undefined behavior. Currently Rust sidesteps the issue by only indexing by `usize`. Since only non-negative values can be valid, it is correct to use zero extension, even if the starting type is signed. Zero-extension of 32 to 64 bit values is free on x86 in most circumstances. Even if it's not, a smaller type is likely a performance gain in situations where many values will flow through the cache. That said, since Rust is compiled using a back-end written to handle C, it might not be able to take advantage of that particular optimization yet.
I'm going to experiment with using Rust and Godot (via GDNative) to try and do some voxel/cubic terrain gen stuff.
I also had a great time jumping into servo thanks to their community.
Thanks for answering so fast. I just tried this and it works (I was mistyping it like a dumbass). Just curious, how were you able to find this? I don't see it listed with the other helper functions in [docs.rs](https://docs.rs). It looks like a few others might still be missing (again though, I'm just guessing the function names at this point). `error[E0432]: unresolved imports \`nix::sys::ptrace::peekdata\`, \`nix::sys::ptrace::peektext\``
They are located in the module `nix::sys::ptrace`. So you go to docs.rs's docs for nix (located [here](https://docs.rs/nix)), click on sys, click on ptrace and see the functions.
Yeah - as somebody who consumes papers for their job, I really wish papers were easier to comprehend, and I know you would be the first to agree on this! Your [poster describing Oxide](https://aaronweiss.us/pubs/popl19-src-oxide-poster.pdf) was excellent!
As with [patch](https://github.com/uniphil/patch-rs) and [unidiff](https://github.com/messense/unidiff-rs), this assumes everything is UTF-8 - that everything will fit in a `String`. About the closest diff(1) gets to worrying about character encoding is when it checks the input files for NULL bytes, and that can be switched off.
Rustfix doesn't always know what you mean. For example, if you have a C function that takes an size 12 int array `void do_stuff(void* arr);` but it is passed as a `void*`, you won't know what it expects except by reading the docs. Likewise, if you have a `fn blubblub(q: Vec&lt;Box&lt;dyn Number&gt;&gt;)` you won't know what kind of numbers it expects.
I would highly recommend the slides: https://aaronweiss.us/pubs/popl19-src-oxide-slides.pdf
thanks for suggestion
Thanks for feedback
Thanks for feedback
Thanks for feedback
Worth noting that while the intuitions from capabilities are still reasonable (and got us to what we have today), these slides and the poster are from January at POPL where we were inspired to try to radically simplify Oxide. So, the semantics in the paper differs quite a bit (and indeed no longer has effects and capabilities).
As someone who used to play a role in academia, I completely sympathise with your opinion and agree that the sentences and structures used in papers can get wildly out of hand; however, having said that, the reasonings include that sometimes it really is better to have a long sentence to avoid repetition, there is often pressure from the rest of academia and from publishers to make papers more formal and, frankly, more obtuse in order to fit the status quo, and above all it is easiest to confound reviewers and dissuade them from making comments that might make your messy, crowded paper even more crowded- not to mention you want to do everything in your power to dissuade that one reviewer who always thinks every paper should actually be related to their own work from making a comment.
Yeah, I wrote this RFC [last year](http://rust-lang.github.io/rfcs/2282-profile-dependencies.html), it's implemented but unstable now.
The READMEs here are basically one-liners. It would be really useful to externalize more information on the current state, feature comparison to the GNU version, road map, etc. 
There is a Tokyo rust meetup? :O Is there a way to sign up to hear about future events?
Sorry, I made a typo on mobile, I meant `rust-docs`. 
What if `T` is something like an arrayvec? Then Cow can store all data it owns without pointing to anything.
Bat horses
How does this compare to lmdb (in terms of use cases, performance)?
There's an [English-speaking Rust Meetup](https://www.meetup.com/Tokyo-Rust-Meetup/) that meets very sporadically and a more-regular [Japanese-speaking Rust group](https://rust.connpass.com/) (but I haven't been yet)! We're doing this event independently but if this experiment feels good we agreed we want to do more regular workshop/challenge-style events in Tokyo. If we end up doing periodic events, we will certainly set up some kind of channel to announce them to the community, but we don't have one yet :). It's very informal right now.
What does your `Cargo.toml` look like? Also bear in mind that Reddit doesnt format the same universally so your code doesn't display properly for many people. I'd recommend formatting it the old way or putting your snippets on a GitHub gist or Pastebin etc...
This is a good point. As mentioned in other comments, arriving at such precise language was probably a daunting task and it is rather impressive. 
The following is the `Cargo.toml` file: ``` [package] name = "cryptonote-account" version = "0.1.0" authors = ["calidion &lt;calidion@gmail.com&gt;"] edition = "2018" [dependencies] rand = "0.6" chrono = "0.4" leb128 = "0.2.1" tiny-keccak = "1.4.2" rust-base58 = "*" [dependencies.ed25519-dalek] version = "1.0.0-pre.1" [badges] travis-ci = { repository = "cryptonote-rust/account", branch = "master" } codecov = { repository = "cryptonote-rust/account", branch = "master", service = "github" } ```
That poster is indeed excellent. I personally really appreciate a visual intuition in most problem domains. I find that I understand why more concepts when they are visually represented and explained. E.g [3blue1brown](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw) has explained me many mathematical concepts which I doubt I would understand without the great illustrations. 
Is this is a rest stop on the way to implementing Git or Mercurial in Rust?
For a moment I thought this was a playrust post, luckily I read the whole thing. 😅
Totally did not consider that possible confusion...
Thank you for the insight. This makes a lot of sense all things considered. Further I can imagine that one well-formed sentence is probably superior to a paragraph of vague hints. As you mentioned regarding academics, I would imagine as one explores the field the jargon will grow familiar and prove helpful.
r/playrust
I appreciated how lackadaisical your description of the meandering writing was, and how brief your summary of the other.
Which macros are built into the compiler? Because so far I was always able to jump to their definitions in the standard library. 
Just for clarity; I was not trying to deteriorate the impressive work of the authors, as I can imagine countless hours have been spent to achieve such brevity and precision. Further I don't think the authors are "stuck up, self-important, ponderous oafs". I was trying to highlight a fenomenon I frequently see as I'm approaching academia as an undergraduate. In retrospect I definitely see the value of such succinct sentences over vague paragraphs explaining the same manner.
Thanks! Unfortunately can't come this time, but would love to if it happens again
I have question, would it make sense to return the PersyId as a hash of the data stored? Or have PersyId a Hash as field of the data stored? I wonder, if I want to store a \[u8\] version of say: struct Person { first_name: String, last_name: String } and I create p\_1 and p\_2 let p_1 = Person { first_name: "Francis", last_name: "Ford Coppola" }; let p_2 = Person [ first_name: "Francis", last_name: "Bacon" ] Then I would like to try: let p1_parts = HashMap&lt;&amp;str, PersyId&gt; p1_parts.push("first_name", persy.insert_record(&amp;mut tx, "default", p_1.first_name)?); p1_parts.push("last_name", persy.insert_record(&amp;mut tx, "default", p_1.last_name)?); let p2_parts = HashMap&lt;&amp;str, PersyId&gt; p2_parts.push("first_name", persy.insert_record(&amp;mut tx, "default", p_2.first_name)?); p2_parts.push("last_name", persy.insert_record(&amp;mut tx, "default", p_1.last_name)?); Then, "last\_name" is only stored once in persy, and when I distribute persy over several machines across the globe, I could retrieve parts for my struct from anywhere. I couls also store blocks of something bigger across sveral instances of persy. &amp;#x200B;
How about quilt? That's the one i really want a windows port for (if for nothing else to distribute diff patches collections easily).
People do underestimate the clarity that can be gained from breaking things up in sentences. I know I used to write tons of crappy run-ons until I noticed how messy it got.
Why are you not using Results for error handling, though?
No worries, if it happens again we will at the very least post on the subreddit again!
You can’t publish with that * dependency. Do you have a .cargo/config anywhere?
Good for you
Do we need new operator for that? Wouldn’t it be easier to create macro for that? I mean, that language itself should be kept relatively small, as there already is enormous amount of stuff going on. And this is simple enough that it easily could be a macro. 
The language, in fact, is absolutely not small, and this operator is very straightforward. Have you read the rfc? It does not nly contain pipeline operator but also new placeholder semantics., what is also worth a discussion. Also,6 having it implemented inside rust gives us more advantages, than having it as a 3rd-party macro.
All of that should be possible with macro. And macro can be in `core`, so it will be “1st-party”. Also you stated Elixir as inspiration, and as Elixir developer I can tell you, that this is exactly why I have proposed macro (as `|&gt;` in Elixir is macro). This is what I find most appealing in Elixir, that this language is so minimal, excluding few things in `Kernel.SpecialForms`, everything can be “redefined”, that includes `def`, `defmodule`, and even `defmacro` “keywords”. So again, do not do operator/language feature of something that can be macro. I still have a problem with fact that `?` become a thing. 
I understand your concerns, but Elixir is not the same as Rust. Can we have anything which could operate the same way as it was described in the RFC and not being a part of language at the same time? We can't, so \`?\` is not something what is a macro (but in Elixir, LISP it could be), that is why pipeline can't be as well (but again, in Elixir, LISP it could be). I am a LISP lover, but things from my RFC can't be implemented only using macros and anything else not really related to the language itself (we have to modify the syntax adding more rules and parser as well), that's unfortunate. This can't be integrated so flawlessly within the code in Rust, but in Elixir and LISP it can. That's just it.
I do that except I then edit the post a minimum of four times. I really shouldn't do that but I sometimes can't help myself.
It's poetic how your machine translation misses every important part of the reply, making it way too more civil than the original. Well, broken sentences get broken treatment… 骂, 吃饱了撑, 瞎鸡巴扯淡, all missing from the translations.
[https://github.com/SpinResearch/merkle.rs/issues/47](https://github.com/SpinResearch/merkle.rs/issues/47)
Why don't people check where they post before they do ? (o\_O)
A shared pointer I guess, arenas would probably be better though. Have a look at typed_arena on crates.io.
You could wrap them in a wrapper that implements PartialEq for which the implementation always returns false. Then you can derive the enum.
Has anyone used [include\_bytes](https://doc.rust-lang.org/std/macro.include_bytes.html)? I'm tryng to include a video of 850MB and I'm having big problems of memory while compiling, up to the point that rustc is killed :S
&gt; minus the part where I decide after an hour to just cut my losses and hit Send? :p Or just decide it doesnt matter or you dont want to get into an argument, so erase it all. an hours worth of writing and rewriting..
Can someone explain in laymens terms what a formal semantics is? Thanks 
&gt; So I let rust do the heavy lifting for me and have just caught panic in the top level decode function and turned it into a normal error. It's a somewhat controversial way of doing things but it's worked well. I am quite sure that this approach is almost unanimously considered a bad practice and is heavily discouraged.
There is more or less regular Rust group here: [https://rust.connpass.com/](https://rust.connpass.com/) We are going to have a lightning talk event this month ( [https://rust.connpass.com/event/122377/](https://rust.connpass.com/event/122377/) ). It's full ATM, but usually there's some cancellations (and we might ramp up the limit), so list up if you're interested!
Question: Is this meant to be challenged as a team or as an individual? If former, can you form your own team?
Seems pretty good to me. On the timing note, is that with —release? 
Try to use u128, then you won't have problems with the borrow checker
You can use ` b += &amp;b * i as u8;` instead. When benchmarking, be sure to compile with `--release`. Rust has `u128` available, if that's enough for your code (it's not for this test).
I am using results for error handling. I'm just implementing some of the error catching by leveraging the compiler instead of writing manual checks.
It seems there is a typo in &gt; The never type **15** for computations that don’t resolve to a value. It’s named after its stabilization date. 
would be interested, too! 
Using panic handling as a way to do exception handling and catching in code is generally discouraged yes. Here I'm replacing a bunch of "if (corner case that only happens in manufactured file and is very hard to define) return error" with letting the compiler do that heavy lifting for me automatically. It's controversial and something I weighed against the alternative in the beginning. So far it's proven to be a good choice by all the metrics I care about.
This is really interesting work. I've only read a few pages but as a relatively new Rust programmer, one thing that clicked for me is that `mut` has two distinct purposes within the language. This was a point of low-grade confusion for me and it's nice to have that spelled out.
Taking b by reference (&amp;b) is probably the most appropriate option here.
If I change this code to: fn main() { let mut b: BigUint = BigUint::from(1 as u8); for i in 0..100 { b += &amp;b * i as u8; } println!("{}", b); } (Note: I use `&amp;b` to borrow `b` instead of `b.clone()` to clone `b`. I also removed the `extern crate` as this is not required in the 2018 edition). Then build with `cargo build --release`. Then running time ./target/release/mult 93326215443944152681699238856266700490715968264381621468592963895217599993229915608941463976156518286253697920827223758251185210916864000000000000000000000000 ./target/release/mult 0.00s user 0.00s system 59% cpu 0.010 total Then it runs in 0.00 seconds according to the `time` command (not sure how to get more accurate time measurement).
I don't think you should need to convert your numbers to u8... BigNum does have implementations to these opterations with usizes. I've also seen some people saying if you care about performance, you should use one of the gmp bindinds.
Hello, I had the same question, and I decided do not use actor for db now. It is because I did make some local benchmark for my cases and actors gives some overhead (heap) for simple CRUD API. For simple select query I got 25K RPS, when with actor for db I got only 21K RPS. I think that actor system is good thing for large application. Anyway, this parrent seems fine: [https://github.com/actix/examples/blob/master/async\_db/src/db.rs#L21](https://github.com/actix/examples/blob/master/async_db/src/db.rs#L21) . You can create two enums like (Request, Response) with possible variants for single DbExecutor. Btw, each request contains cpu pool and you can use it for executing queries. [https://docs.rs/actix-web/0.7.18/src/actix\_web/httprequest.rs.html#129](https://docs.rs/actix-web/0.7.18/src/actix_web/httprequest.rs.html#129)
runtime probably about the same since python probably using similar or same underlying bignun library
Fixed in https://github.com/cmr/this-week-in-rust/issues/848
&gt;letting the compiler do that heavy lifting for me automatically I still believe it's a bad design decision and abuse of `catch_unwind`. Not only because of `panic=abort`, but also because it goes against Rust principles. How much code will be added if you'll process those errors "manually"? Fixing it is not an urgent matter of course, but I hope you'll work on it eventually. Maybe at least create an issue for it?
&gt; Mar 20. Vancouver, CN - Vancouver Rust meetup. Typo with the country digraph.
rust-analyzer was merged in RLS or I get it wrong?
A formal semantics is a mathematical model that describes what programs in a language “mean” by describing how they run. There’s a variety of styles of formal semantics, but one of the most common now adays (and the one used here) is reduction semantics which gives you a style of rules that’s sort of like a math version of an interpreter. It says things like “when I have a branch whose condition has been evaluated to true, I can continue evaluating by evaluating the first part of the branch.” Of course, for a language like Rust, there’s lots of programs that don’t run because they don’t type check, and so a formal semantics for Rust (or any other typed language) also has to account for how type checking works (and in this case, that’s probably the more interesting part).
It means they have come up with a mathematically precise description of how the language works. Because it's mathematically precise, they can do things like mathematically prove that the borrow checker algorithm actually does catch all memory management bugs.
I don't know of any actual downside so I'm not going to spend time on it. Unless there are actual issues introduced by catch_unwind there's no issue to fix. I went down that particular rabbit hole with the C++ codebase and gave up. For this kind of API there is a very clear point where all the state can be thrown away and the program continue with no issues. I don't see any sound engineering principle that's broken by this, but I understand it's an unusual setup.
You are not alone. What often takes seconds to minutes in other languages usually takes a good deal more while you are learning Rusts quirks. I spent 30min yesterday reading about match as switch case isn'5 available and ended up with an if else block to get it handling function patterns
Cool! I've only been learning rust for a week, so I love learning unusual code-golfy things like this. As someone with more of a C background this reads a bit weird to me, but now that I'm getting a bit more comfortable with implied types this actually makes tons of sense. 2.6s on my macbook air :)
The Rug version can be made a little faster by allocating another buffer and reusing it rather than cloning, which allocates every time. use rug::{Assign, Integer}; fn main() { let mut a = Integer::with_capacity(20*1000* 1000); let mut b = Integer::with_capacity(20*1000*1000); b.assign(1); for i in 0..100000 { a.assign(&amp;b * i as u32); b += &amp;a; } println!("{}", b); }
Downsides are: - Incompatibility with `panic=abort`. - You catch all panics indiscriminately, so you may miss real logical bugs this way. (i.e. processing errors forces you to think more carefully about corner cases) - Fuzzing becomes a bit less informative, usually for parsing libraries panic = bug, while you simply throw an error. - `catch_unwind` may [have](https://github.com/rust-lang/rust/issues/34727) negative performance impact. (though I am not sure, maybe it's fixed).
Why are you taking "i as u8" ??? Doesn't that cut off the upper bits here? Never mind run time, does this even produce the correct result?
I like `?`, but I agree about macro's. `=&gt;` looks a lot like lambda functions in Javascript, which makes it natural to suppose the left hand side is a function argument. I also dislike the implicit binding to `_`. If the entire block were wrapped in a `pipeline!()` block, it would make the meaning more obvious from the context.
It has not been merges and is part of the "RLS 2.0" effort. https://github.com/rust-analyzer/rust-analyzer
It's not "code-golfy" though, it changes the semantics, we're avoiding an unnecessary `clone` here :)
Yep, I'm aware of those. One by one: - I don't know of any situation where you'd want to load image raws with panic=abort, particularly untrusted ones. If someone does have a valid use case for that I'd love an issue describing why. - Logical bugs: panics are still reported on the console and I look at them when bringing up new formats or testing new files. For anything that's an actual file that should work I know if there's a panic and fix it - Fuzzing works fine, it just tests the actual cases that would be issues (mostly infinite loops and memory problems from huge allocations). I did have to patch afl.rs because it was doing deeper surgery that defeated catch_unwind. - Performance shouldn't really be an issue since any panic should just abort that file. Files take 10-700 ms to decode so the overhead of a single unwind is small. I did find a bug in rayon that does create more overhead in some cases: https://github.com/rayon-rs/rayon/issues/638 If I could get the compiler to add the tests automatically and return an error instead of panic I'd use that instead, if nothing else to support panic=abort. But since these formats are very poorly designed and defined also very hard to fuzz I don't think it's a productive use of anyone's time to try to replicate manually and with a bunch of flaws what the compiler already does automatically.
As someone who just started rust a week ago, I would have *loved* it if every 2018 tutorial hammered in the new syntax around importing crates. I probably spent my first 2 hours coding in rust confused about which parts of this code example I needed.
I'm pretty sure match is a strictly more powerful/expressive switch-case. Can you clarify what you were having problems with?
The required answer is actually 100,000!, which requires 1,516,705 bits. 128 bits just isn't enough here.
Having function returns as patterns, saw no way to make that happen kept getting compiler hickups
Hi! Thanks, this works! I was already using `--released`. One thing that confuses me a bit is this. I guess there is some sort of "operation overloading" going on here, right? This would allow two non basic types (two BigUint) to use the `+=` operator as if they were basic numbers. Now how can such operator accept either a BigUint (`b += b.clone() * i as u8;`) or a reference to BigUint (`b += &amp;b * i as u8;`)? Because I tried the following struct MyBigInt { n: u128 } fn add (n1: MyBigInt, n2: MyBigInt) -&gt; u128 { n1.n + n2.n } fn main () { let mbi1 = MyBigInt { n: 10 }; let mbi2 = MyBigInt { n: 20 }; println!("{}", add(mbi1, mbi2)); } and `add(mbi1, mbi2)` works while, as I would expect, `add(&amp;mbi1, mbi2)` does not. 
So lmdb is a key value, this is not a key value, it store data flat on the disc more ore less like an array (but is not an array check the structure part on the site ;) ), Persy has as well as indexes i think that is the closest thing to lmdb. In terms of API usage is quite different, lmdb you have "just" K/V operations, in Persy you have raw records operations, you cannot lookup a record with user key, you can just browse records, and then you have indexes that may be used to link a record and lookup it faster. The first scope of Persy is not produce a big high scalable storage, but one small "enough fast" and **safe** storage that can be handle well crashes (not yet fully done, not considering yet failure on disc side). In terms of performance, I expect lmdb to be faster because i didn't do yet any hard toning and neither some meaningful benchmarks+profiling, lmdb instead has been there for a while and this has been done, anyway feel free to do some benchmarks yourself :) Other big thing lmdb rely on memory map and Persy do not. &amp;#x200B;
Various overloads have been implemented: https://docs.rs/num-bigint/0.2.2/num_bigint/struct.BigInt.html#impl-Add%3C%26%27b%20BigInt%3E
It's a complete and entirely mathematically rigorous specification of an abstract computer and how it runs. If you're familiar with Turning machines, they have a relatively simple formal semantics. The TM has a head in some state, some symbols on a tape, and a transition function that defines how the head moves and what symbols are written to the tape. The precise formalization of what the machine is and how the state (contents of the tape, head position, head state) evolves over time is its formal semantics. One can in principle write down a formal semantics for a modern x86 machine, but inconsistencies in implementation across processors and devices, not to mention the sheer enormity of such a specification, would make it impractical. The main advantage to having a formal semantics is that it serves as a witness that your way of expressing computation is completely defined: every program has some well-defined behavior. You can think of it as (the core of) a specification for the compiler. (The compiler is really just translating syntax from rust to x86/whatever, but specifically in a way that preserves semantics.) Currently rust lacks that. This is problematic since it means we don't have a clear standard for whether code that uses `unsafe` is actually safe or not. The present paper is a significant step toward resolving that problem.
Ah yeah, I considered trying something like this, but I didn't bother once I found my rug version was faster anyway. For comparing timings, that one runs in `1.71s` on my machine. I think it's a fair comparison, as it's just avoiding an allocation rather than fundamentally changing the algorithm used.
Hi, &amp;#x200B; This is how works a key value, Persy is not a key value, you can do this with an index check this example: [https://gitlab.com/tglman/persy/blob/master/examples/indexes.rs](https://gitlab.com/tglman/persy/blob/master/examples/indexes.rs), i know that a key value approach would be faster for that specific use case, but i'm trying to keep Persy more generic and not binding it to a specific storing style, allowing to do different storing styles, that may be faster with other use cases, see object(maybe struct), graph that may not use a key as link, and as well store multiple entities in the same "record" . &amp;#x200B; &amp;#x200B;
Either that, or the geopolitical situation has *really* changed since the last time I checked.
Formal semantics aren't actually that difficult but the notation and verbiage takes some getting used to. And it's really hard to get used to them while looking at a complex type system. They are also a clean and concise way to talk about type systems, though. Most words in that sentence are pretty standard with the exception of 'approximate provenances' which is introduced slightly earlier.
I know, but the rest of my comment still applies. You can't remove them.
Oh, well 😅
It could be made faster still by diving into GMP, as the following version reduces a copy per iteration as well: use gmp_mpfr_sys::gmp; use rug::{Assign, Integer}; let mut b = Integer::with_capacity(20_000_000); b.assign(1); let ptr = b.as_raw_mut(); for i in 0..100000 { unsafe { gmp::mpz_addmul_ui(ptr, ptr, i); } } That is possible because with pointers it is possible to alias the source and target, and GMP supports that aliasing. In Rug support for `mpz_addmul_ui` with the same source and target isn't supported as there really is no need; it is already possible to for example `a += &amp;b * i` (different source and target) and that uses `mpz_addmul_ui`, while the unsupported `b += &amp;b * i` can be replaced by the simpler `b *= i + 1`.
The quote about `TryFrom` seems pretty accurate.
Formal semantics give a way to reason about a language separately from any implementation. The two common variants are Denotational Semantics and Operational Semantics. You can think of Operational Semantics as interpretation. You might have heard about the C abstract machine model before. With operational semantics we can make statements about the execution of programs and proof them. Denotational semantics attach a mathematical meaning to programs - think types. This is useful to proof a type system is sound, for instance. On the other hand we lack the operational interpretation so for instance we can't proof that an optimization is beneficial because we can't have a cost model.
Out of curiosity, how much of an improvement did using references instead of cloning?
Only problem I find with most boilerplates are missing a layered structure for business logic. (Onion, data access layer)?
So what's a provenance of reference?
Hi, thanks for your time! Yes, that `100` / `100000` was obviously a mistake in the pasted code. Thanks for pointing out rug. On my machine it is even faster the num with 1.8 seconds :)
docs.rs/petgraph
Yep, I used --release that gave me a much better result
To my surprise, I didn't see any performance improvement.
Oh, ok, thanks!
I see. That's probably because BigInts are heap-allocated in all cases, so the multiplication must do an alloc anyway.
Let's make it a post about rewriting Rust in Rust.
Thanks for this, I'm just starting an academic project and this is very useful meta-information on how to read papers.
Does anyone have any good references for the environment judgement - how to understand them.
But there is an allocation anyway. If the input operand is a reference and the return value is owned, there is an allocation; so the num-bigint crate is cloning inside the function.
what did you expect to work? I have trouble understanding what a "function return as pattern" is supposed to look like.. match function_call() { ... } would work just fine for matching on the result of a function call, but I don't think that is what you meant.
I'm experimenting with this as well. I'm not as concerned about actor overhead at the moment, but instead with having a team of people be able to write code without stepping on each other's toes. So currently I have controllers that do things like input validation, calling services, and transforming the results of service calls into http responses. The services do the bulk of the work, and pretty much each service function takes a DB actor Addr as a parameter, and returns an impl Future, with the Error type being my application's main Error enum. In each service, I have a "handlers" module that Implements the Handler trait for the various actor messages that get sent to the DB actor. That way people aren't always touching the same db_actor.rs file. Right now the handlers are just separated by functionality - for example the user service has DB actor Handlers for user-related messages. I don't know if this is the best way forward yet, just started trying it out today...
&gt; assumes everything is UTF-8 - that everything will fit in a `String`. isn't that how VCS's work in general? otherwise you need a map into the binary to deconstruct it to strings. afair, that's how Chrome distributes its binary patch updates. I'm focused on code, content, and config files at the moment, which can generally be stored well in text, as planned for patch files and using this new database [ContentDB](https://github.com/foundpatterns/contentdb). &gt; worrying about character encoding how could we go about this? how could it benefit users?
You can form your own team! We will give each attendee one access key, and you can choose to either use them or combine your powers towards one bot.
match true { f1 =&gt; do something, f2 =&gt; do something else} It's totally fine the if else handled it with no loss of speed or clarity as it called fX in order to determine if they returned true 
Well, to return something new you need a new allocation, sure. But with the `clone` call, I'd have expected 2 allocations to happen, one to satisfy the `clone`, the second to write the result into. Of course, that might not actually happen in the final machine code, but the general principle "use references instead of clones if you can and your type isn't copy, in which case you don't need to clone anyways" seems the right thing to do.
&gt; Is this is a rest stop on the way to implementing Git or Mercurial [Gut](https://github.com/foundpatterns/gut) is a VCS that, so far, uses some of this functionality, instead of shelling out, like before. But instead of copying Git and Mercurial's [hash tree](https://en.wikipedia.org/wiki/Merkle_tree) data architecture, it's more like [Quilt](https://en.wikipedia.org/wiki/Quilt_(software)) with a "line of changes" data architecture. I'll document more about [trees vs graphs](https://stackoverflow.com/questions/7423401/whats-the-difference-between-the-data-structure-tree-and-graph) in Gut and [ContentDB](https://github.com/foundpatterns/contentdb)'s readmes today. &gt; in Rust In [Speakeasy](https://github.com/foundpatterns/speakeasy), which runs on a Rust-based interpreter, called [Torchbear](https://github.com/foundpatterns/torchbear). 
PS I expect some growing pains as I learn the language. Hoping for the promised land when I can think in Rust and not need to continually look up how to do X or Y and find Rust handles it differently than other languages. I think if Rust was my first language it would be easier to dive in
Yea, I like Quilt too. I'm going to add some of its docs today to Gut to show its prior art. I'd have used that before for what I'm ultimately building, if it made managing related patches easier, and had integrated change management and decentralized file sharing, like [GitTorrent](https://github.com/cjb/GitTorrent).
Specifically, after macro expansion, you can find this in num-bigint: impl&lt;'a&gt; Mul&lt;u32&gt; for &amp;'a BigUint { type Output = BigUint; #[inline] fn mul(self, other: u32) -&gt; BigUint { Mul::mul(self.clone(), other) } } 
Same question.
One way to think about this is that the impl block doesn't actually create a new scope in the same way that method bodies or curly braces inside them do. So if you were to put a use statement there, which scope would the imported names be added to? If you really think every method is going to need that import, there's no harm in putting it before the impl block (or at the top of your file) so that the imported names will get added to the global (private) scope of your module. 
What would the semantics of `pub use crate::LinkedList::*;` be in that context?
IIRC, Python uses a custom implementation, not the GMP library like RUG.
Congratulations on the release! It seems that part of the appeal of Torchbear is a Lua environment with Rusty batteries included. Are there any particular libraries you plan to add to the built-in environment? Separately, what's a use case you think Torchbear is especially suited for?
I am ok with the operator, I am not ok with the semantic. I would prefer it to be “coalescing” operator rather than “early return”, so `a.b` would be rough equivalent of `a.and_then(|a| a.b)`. This would leave old `try!` macro as is and would not require new `catch` blocks in the language. 
&gt; the part where I decide after an hour to just cut my losses and hit Send No, that's still there. Papers have submission deadlines.
This would actually be useful! (minus the `pub`)
Can you explain more details about layered structure for biz logic?
I don't think a switch would help you either. What you're doing is not pattern matching.
Right on, if else handled it ok. The swap from switch case to match was just another oh wait this is also done differently let's understand why that can take time
If you’d like to make your first foray into understanding programming language theory, the usual recommendation is the book Types and Programming Languages by Benjamin Pierce. It’s fairly standard in classes, and covers a lot of ground for the essentials. Another option would be Practical Foundations for Programming Languages by Robert Harper. It’s less common, and takes a somewhat different approach.
as said, without that `pub` part, it would make all enum variant visible inside of the block. So instead of everywhere writing the `LinkedList::Nil` you can write just `Nil`. Same as you can write just `Some(...)` instead of `Option::Some(...)`
&gt; &gt; assumes everything is UTF-8 - that everything will fit in a String. &gt; &gt; isn't that how VCS's work in general? [No](https://github.com/ntp-project/ntp/commit/27b2000b28ac58c6efbfe44782111a3669a9a5b1.diff). People commit non-UTF-8 data to version control all the time, even when it's text. To give an even more mundane example, think of how many latin1 files are out there where the &amp;copy; symbol is encoded as `\xA9` instead of `\xC2\xA9`. &gt; &gt; worrying about character encoding &gt; &gt; how could we go about this? Do what C does and *don't*. Instead of `&amp;str` use `&amp;[u8]`, instead of `String` use `Vec&lt;u8&gt;`. And if you must extract a filename into a `PathBuf`, do it via `std::os::unix::ffi::OsStringExt` if possible, because those are just bytes too. &gt; how could it benefit users? They're less likely to have it explode in their faces with `stream did not contain valid UTF-8` :)
You can use futures-cpupool directly
I don't quite understand what you mean, but I can assure you that it is possible. I would be willing to help you in case you have a concrete code example at hand.
Not really sure, but to me, it looks like the `mod {...}` block, does not create scope either, merely makes `use`s visible inside of that block, so at least to me, it is not question of scopes, merely block visibility ?. So what I would expect of this, would be that, imported names would be visible in all blocks of the defined methods in the impl blok and associated types/constants exactly as is in the mod block.
I mentioned an example below, it's not strictly pattern matching and if else handles the case fine as I noted. It was simply the shift away from switch case in some code I was translating that cost some time.
Brilliant thanks for your answer!
your service is struct with methods or trait?
Why did you cast the `i` to a `u8`? 10000 is clearly larger than 255. 
[RustPython](https://github.com/RustPython/RustPython) could always use more contributors, and it's easy to start contributing to!
I, Thank you for the reply and the awesome work behind actix! But i'm talking more in term of code scaling (how multiple people can work on the same backend without stepping on each other's toes.) instead of performance :)
Scope might not have been the right word for me to use. From your block visibility point of view, I can see what you mean. There are actually many things you can do in a `mod` block that you can't do in an `impl` block. For example, you can't declare statics either. This is one of those things that I think could be possible, but haven't been implemented yet. I don't disagree with the semantics you described. Maybe worth opening a thread on the Rust internals forum?
Hi, thank you for the response! To recapitulate: * You use 1 main Error enum for your application (using failure ?) * You have 1 DbActor but the handlers are spread across multiple files I'm right ?
`mod` creates a completely new module namespace, it's not a block scope and doesn't import anything form the outside like a block does, you have `use super::*` to do that.
Yes, I think I will do that ! Thanks.
This is the first time I have seen a construct such as yours :) As others have pointed out, that does not really include any patterns and is such a bad fit for match. I hope any decent language would forbid this in switch-case statements as well! You can probably make a macro or something similar if you need to write this very often. Sorry for not delivering on my promise ;)
I'm a little confused about where the Speakeasy language comes into play. All I see is Lua and the readme for the Speakeasy repo currently makes no elaboration.
Hi, Thank you for the reply ! As I understand the inner working of actix is that we should indicate to the system how many thread / actor we want SyncArbiter::start( pool_size * 2, move || { DbActor(conn.clone()) }) So isn't there some problem to use 1 Actor per Model ? Like how many `DbUserActor` should I launch, knowing that my DB have a limit of connections And I use a `r2d2` pool to connect ? 
Thanks, Zack. It's been so long comin'! &gt; Are there any particular libraries you plan to add to the built-in environment? Honestly, software development seems like it could be 1000x easier. I've wanted to do so many simple things before and finding an app for it has been hard, sometimes impossible. It wouldn't even take any code to make it, if the libraries were already there and integrated in the programming environment, hence Torchbear. Most of the libraries I'm focusing on right now are on top of Torchbear. Rust is astoundingly mature, which I believe is an important point we need to echo. As the logic becomes apparent in Speakeasy, we can lower it to the machine level, though I'm also astounded by what Will has in development with [Ullage](https://github.com/iwillspeak/ullage) (as you can see in [Ullage's performance benchmarks](https://github.com/iwillspeak/ullage/issues/20)), so it's starting to make me rethink how powerful the scripting layer might become. Those libraries can be found in [Lunar Transit](https://github.com/lunar-transit). [Lighttouch, as just announced in /r/lua](https://www.reddit.com/r/lua/comments/axtjye/introducing_lighttouch_a_lua_application_framework/), especially, has been my focus as a built-in application framework for Speakeasy. It's an integral piece to making [no-code development](https://en.wikipedia.org/wiki/No-code_development_platform) ([What Is No-Code Development? Why Are No-Code Apps So Popular?](https://kissflow.com/no-code/)) available. &gt; Separately, what's a use case you think Torchbear is especially suited for? The "killer app", a term we can hopefully rename now, has always been [Radiojade](https://github.com/foundpatterns/lighttouch). Everyone hyperfocused on solving real world problems seems to be working on this from one angle or another. But they've only bitten off one piece at a time. I guess I wanted to take a different tack and find uncharted winds along the way. 
I'm still trying to wrap my head around what this is, and why I should use it. From looking at the source, I have come to some conclusions, but I'm not sure they're correct since they seem to directly contradict other statements by the OP. It looks like torchbear includes PUC-Rio lua via rlua. I don't see a Rust-based interpreter (as claimed [here](https://www.reddit.com/r/crypto/comments/axtnhn/introducing_file_witness_a_libsodium_code/)) And looking around at the examples, the code just looks like lua. Sure, there are a lot of modules added, but I'm wondering if there's really a "new Speakeasy language" or if it's just a rust-centric packaging of lua. It doesn't help that the [Speakeasy repo on github](https://github.com/foundpatterns/speakeasy) appears to be a joke. Am I just having a senior moment?
Reexport the items so that they're accessible as `Type::item`, just like you do with `pub use` in a module. Associated types and associated functions already exist, but until we get associated constants and associated statics, those latter two would probably be compiler errors.
In this case the match true is no different than an if else with less syntax but to each their own :)
&gt; it looks like the mod {...} block, does not create scope either, `mod` certainly does create a new scope for the purpose of `use` visibility. If you have something like use a; fn b() ... { .... } mod c { // `a` and `b` not visible here }
Right now they're just modules with functions in them, though I suppose you could create one and give it an Addr to the DB so you don't have to pass it every time. But for now I'm keeping it simple.
yeah.
Yes to both! And yes I'm using failure for the error enum as that seemed to be the path of least resistance.
Yeah, that one too. That's most of my /r/cpp posts' ultimate fate. :p
This a good question. If you have 100 connections in r2d2, then you will split them for each actor/SyncArbiter. So if you create SyncArbiter with 20 threads then it will use only 20 connections for r2d2 pool.
Relevant RFC: https://github.com/rust-lang/rfcs/pull/1976 with https://github.com/rust-lang/rfcs/pull/1976#issuecomment-301903528 being the most relevant comment for why `use` shouldn't be in `impl` just for bringing an item into scope. One idea suggested was `impl Foo for Bar use Whatever {}` clauses instead.
Answer is the same. You can execute queries in-place, so you wouldnt need to update sync actor every time you need to handle new query
Quick look at the examples and I'm seeing Lua too. Maybe we'll get some updated info 
I was thinking more of signed integers being not what I want. I guess there would be some optimizations for unsigned types and I was missing out on those.
see Torchbear's [Add Ullage environment](https://github.com/foundpatterns/torchbear/issues/234) issue. I see Torchbear's built-ins as integral functions in Speakeasy, though I want to make sure the general semantics match the design goals of the Speakeasy project. I'll make an issue shortly for Speakeasy about syntactic shifts from Lua where I'll start laying out my current plans. just as a starting point, see [MoonScript](https://moonscript.org/); and in the issue queue, you can see more of the semantics I'm thinking about beyond basic control structures, syntax, etc.
[Not according to the World Meteorological Organization](https://en.wikipedia.org/wiki/Country_codes:_C#_Canada).
I've seen better solution where a file was appended to binary after compilation (with a footer that denotes start location). Can't remember crate name, but should be easy to do. 
&gt; Support defining C compatible variadic functions Sweet, I didn't know this was a thing. Is there a possibility that we'll get this for safe Rust? Doing a ton of trait impls for various arities of tuples is a pain, and taking a [T] is also not very elegant either. It would be nice to have some syntax sugar for turning varags -&gt; [T]/Vec&lt;T&gt; (e.g. last point in [#323](https://github.com/rust-lang/rfcs/issues/323)).
If I want to return an iterator e.g. over a vector from a function I could use the following signatures: fn f(...) -&gt; std::slice::Iter&lt;...&gt; or fn f(...) -&gt; impl Iterator&lt;Item = ...&gt; . Is the second one in any way better or more elegant? Which one should I use?
Let me share my experience with big numbers. I tested a fast Fibonacci implementation timings for the following languages: - Python (CPython) - Ruby (MRI) - Rust For small input, Rust was the winner, as expected: 1. Rust 1. Python 1. Ruby For input like `50,000`, Rust was the worst one, like follows: 1. Python 1. Ruby 1. Rust For my Rust implementation I used the `num` crate, AFAIR. The way the `num` crate implemented memory management is my suspect #1 for such poor results. As mentioned already in the thread, using more sophisticated implementation with a predefined buffered should help a lot.
I'm not 100% sure how `include_bytes` works, but if it converts binary data to hexadecimal that's bloating it to four or six times the size. It's possible to store binary data in an object file or static library and access it via `extern const` and a touch of `unsafe`. https://csl.name/post/embedding-binary-data/ I'd be happy to mess around with it a little bit if you're having trouble. I'm currently not developing on Windows, so I'm not sure how to make this work with an IDE and whatever the build system of the hour is, but it should be straightforward on anything that has binutils. NASM or YASM might be easier to work with.
&gt;The most common channel configuration I see works essentially like a Unix pipe: I think that this is an interesting analogy. (By convention) unix processes have stdin, stdout and stderr. Where stdin and stdout are for structured data and stderr is for reporting messages back to the user/the thing controlling the pipeline. Arguably what is missing is some means of sending control messages from the user/controller. In Unix we have signals, which are pretty hard to get right. I think you still want such a control mechanism when running in process - and it could be represented by another channel. There's overlap here with structured concurrency. You kick off a bunch of threads, and then when you have the answer you're looking for - or an error - you want to tear them down again. So I propose: 1. You pass the `Receiver` end of a channel for every thread you start. Call this the control channel. 2. You still have your channels set up between the threads, much like the pipes in your unix pipes example 3. Instead of writing `stdout.send()` for writing to your stdout you replace it with: select!{ send(stdout, msg) { Ok() } recv(ctrl_in) -&gt; msg { // No messages arrive here, only EOF assert!(msg == TryRecvErr); msg } }? 4. You signal that the threads should stop by closing the `ctrl_in` channel. So it goes: 1. Create channels 1. 1 `ctrl_in` channel with a `Receiver` for each thread. `Sender` belongs to the parent scope, each `Receiver` belongs to each thread. 2. An `stderr` `Sender` for each thread, perhaps all connected to the same channel 3. Connected `stdout`, `stdin` pairs for each thread 4. An `stdout` from the "last" thread 2. Launch threads 3. `select!` over your `stderr`s and the final `stdout` to get the final value, or any error from any thread if it occurred. 4. Close the `ctrl_in` channel `Sender` - causing all the threads to terminate gracefully 5. join the threads 6. All done - perhaps return the value your pipeline calculated, or the first error you saw. This depends on `send` not `panic!`ing when used in conjunction with `select!` but it needn't return an error either. `panic!` might still be valid for standalone uses of `send` (e.g. without `select!`). I guess this is an argument in favour of `panic!`ing `send`, just not in combination with `select!` - plus in favour of establishing standard patterns around starting and stopping threads. It is an argument against relying on `EPIPE` for cancelling threads. An alternative - more explicit approach would be to introduce cancellation tokens and to add support for `select!`ing over them - which might be a good idea, but would certainly broadens the scope of the discussion.
This is a great paper (I've skimmed it but not read deeply). I'd love for academic programming language theory to adopt Rust as a testbed for demonstrating its usefulness, and I'm very gratified to see movement towards a future where it might be possible to prove Rust implementations correct.
For completeness, on machine, - The parent comment code takes `0.99s` - `rug` with `b *= i + 1` takes `0.97s` - python with `b *= i + 1` takes `6.32s`
Yeah.. I had a lot of fun making that Readme. Readability suggestions and patches definitely welcomed. But thanks for the laugh; I'm happy you see the comedy in it :) "claim" answered in reply to 8E4F787A43D3807E9EA2.
The second one is cleaner and shows your intention without exposing the internal of your function (this function returns something that can be iterated over). However, the first one exposes the actual type and thus can be stored by the user. Use the first one if you are making an API that users will use, use the second one for internal functions. There is even a third option: create a special FooIterator struct that wraps the std::slice::Iter, this allows users to name the type without needing to know the internals.
(just a side note that triple backticks for code formatting doesn't work in mobile reddit clients - use single backticks for I line code or 4 space indentation for code blocks)
I wouldn't go as far as saying it is a design mistake, but the Rust book does need a paragraph explaining what is happening when they first introduce println!. I remember being puzzled with this as well until such time that I became comfortable with macros and saw what println! was doing. It was the first edition of the book though, so may be it was remediated.
The [format_args](https://doc.rust-lang.org/std/macro.format_args.html) macro is a compiler builtin, and `println!` as well as `print!, `write!` etc, are wrappers around `format_args!`.
I for one would appreciate it. I hadn’t heard of any sort of events for Rust in Tokyo before this post, and I usually read the weekly newsletter to keep up with the community. 
This. Here's the code I ended up with: ([playground](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=2c9311b444068a3264900f091af343dc)). Sadly it runs too slowly on the Playground and is killed even in release mode. Running it on my home box, I find that it runs in…7.84s! Our [Nickle](http://nickle.org) programming language has a highly optimized chunk of code for this kind of stuff. I thought. `time nickle -e '100000!'` gives…13s. So…yeah. Computing big factorials is memory bound and slow.
Is there an interface to HashMap&lt;String, T&gt; that supports Into&lt;String&gt; automatic coercion from references or other to\_string types? This would clean up a few interfaces for me (where I manually call to\_string()).
```rust use num::BigUint; fn main() { let mut b = BigUint::from(1 as u8); for i in 0..100000 { b *= i as u32 + 1; } println!("{}", b); } ``` This is a little faster for me. 5s vs 7s according to `time`. I guess it avoids the clone hidden in `&amp;b * i`.
Read and study aws/firecracker-microvm source code.
I look at it this way. The purpose of code is to not only make the computer do something, it is to explain to someone (likely my future self) *how* the computer does something. If I write something and 30 seconds later I need the computer to help me recognize what it means, I have done something *very* wrong for code readability. 30 days later I'm gonna be screwed. Most of those features fall into that category for me. Syntax highlighting. Local variable highlighting. Type hover. All those bells and whistles might make things more obvious, so yeah, I guess turn them on when you're trying to figure out something that's utterly puzzling and awful. But if you always use them, you have no extra tools to help you deal with your silly past self. Never mind the level of difficulty that is added by somebody else's code. I don't code in monochrome vim because I'm so badass and elite. I code in monochrome vim because it forces me to constantly confront my temptation to write unreadable code. I can't be the only one. Please tell me I'm not the only one.
The Seattle meetup is actually on March 12th, not the 11th (the meetup information is correct after the jump). 
&gt; Support defining C compatible variadic functions ... What ... WHAT‽ IT'S ACTUALLY HERE‽
I've worked with Elasticsearch and Logstash a lot, and one of the things the docs say is to lock the memory for the Java heap to 1/2 of the system RAM so that the JVM doesn't try to reallocate memory dynamically in production, which can be an expensive process. &amp;#x200B; So far, I haven't seen anything like that in Rust. Is this kind of concept something unique to garbage collected languages? Or if Elasticsearch/Logstash were to be rewritten in Rust would it also need to have some configuration to lock the memory to some amount?
I don't use an IDE. Github doesn't display code using an IDE. A diff isn't an IDE.
I use Sublime Text, and I don't want that. I don't write code with my mouse. And I don't often view other people's code on my own machine anyway.
\[Not-Yet-Awesome Rust\](https://GitHub.com/not-yet-awesome-rust/not-yet-awesome-rust) tries to lay out the holes that currently exist in the Rust ecosystem. If you're looking to join an existing project it might not be what you want, but creating something new in an unfamiliar domain is a great way to grow as a developer!
Counter-counterpoint: We're all viewing this code via reddit, which is not an IDE.
I just saw the post.
I think your SubBase type needs to be sync and send in order to work there?
The problem is not in the code you've posted, it's in your definition of the `SubBase` trait. You are using it as a trait object (`Box&lt;dyn SubBase&gt;`) which means it can contain any type implementing the `SubBase` trait. However, the `Arc&lt;Mutex&lt;..&gt;&gt;` pattern requires that things you put in it can safely be sent between threads (because one thread could put something in the mutex, and another thread could take it out). For this reason, you need to add a constraint that the `Box&lt;dyn SubBase&gt;` can only contain things implementing the `Send` marker trait. You can do this by making `SubBase: Send`, or else by using `Box&lt;dyn SubBase + Send&gt;`.
In addition to what others have said, you'll need to move the `subs.clone()` call outside of the `thread::spawn` closure: let subs = Arc::new(Mutex::new(HashMap::new())); let subs2 = subs.clone(); let join_handle = thread::spawn(move || { // ... do stuff with `subs2` in the child thread ... }); // `subs` is still on the main thread
Yeah, that's unique to languages like Java that run in a virtual machine with garbage collection. There's no equivalent for Rust.
Yes, the FAQ is [missing](https://github.com/rust-lang/www.rust-lang.org/issues/291) from the new web site.
What's Radiojade?
This. Here's some [code](http://github.com/BartMassey/bigu) that does the right thing. Rust runs in 7.8s on my box, Python in 6s.
I remember seeing it initially here on the subreddit. They hurt with how true they are. I think it would be silly for never to implement traits that generate a value of the type, but it should be fine to implement any trait that reads from an existing instance.
You could do that in macro.
What about something like `objcopy` instead?
This code does not compute 100000!