If _fast_ is the emphasis, and you're on Linux, there's [splice](https://docs.rs/nix/0.11.0/nix/fcntl/fn.splice.html). It's what fastcat uses. It performs the entire copy in kernel space without the overhead of copying memory back and forth to userspace.
Ctgbtt
Still working on [Projects.rs](https://gitlab.com/anire/projects-rs). It's been a little slow the past few days, because I've skipped the unit converter for now, jumping to the alarm clock, which I really need to think about, but hopefully I can get through it.
To be honest, having your methods pass down `Result`s and calling things using `?` seems to be the best way right now. Also, consider using the failure crate (I haven't used it, I use `Result&lt;T, Box&lt;dyn (::std::error::Error)&gt;&gt;`)
I have never heard of mdoc before. Am I right to assume it's similar to roff and/or can compile down to roff? Because: The man crate uses my _very_ simple roff lib internally as a writer. When I wrote this, I had so little understanding what was needed that I even called it roff even though what I really wanted was to use the man macro package. People have been writing better/other crates but haven't had the time to really dive into this. Mostly, because this one does the job for now. If changing it to output mdoc means it'll still work on Linux/macOS/BSDs with no extra setup: PRs very much welcome. Hell, you can rewrite or replace the whole roff crate, if you want! (But ping me before you do that, please.)
Oh yes: https://github.com/killercup/clap-man-demo
...You don't know what you are doing or talking about....do you ?
From the fact that a hello wold program has a binary size of 250 KB I assume that there are still more things that could be omitted.
The overhead for these extra vtable entries is extremely low though, bordering on hard to measure. It doesn't need to read the whole vtable, it just has a pointer to the start of the vtable and the offset is known at compile time based on which method is being called. So having extra entries in your vtable, while it will make your binary bigger, doesn't seem like it would cause any extra dcache or icache pressure. This seems like a very small price to pay for things to work the way you would logically expect, and more similar to static usage of traits.
Last week I didn't get round to doing my [tarpaulin](https://github.com/xd009642/tarpaulin) stuff so I plan on doing that this week. Expanding out my module ignoring system which means adding some new stuff to source analysis. Also, moving to the 2018 edition! However, I did get Rust working on my STM discovery board for the first time so I will also be working on my embedded-hal crate! Hoping to move timer traits along though as there are 4 different types of timer I probably won't get it finished.
Precisely! I've take the train a few different places, and I always find it both relaxing and productive.
&gt; elba The only real choice of name
Yes, but we simply don't \_use\_ trait objects that much. I'm not saying it can't be added, I'm saying that trait objects themselves are very rare in Rust code, which makes complicated use of such trait objects even less common, and there's a simple workaround involving a defaulted trait function.
On my machine, with `lto=true`, this code produces a 172 kB binary: use std::alloc::System; #[global_allocator] static GLOBAL: System = System; fn main() { println!("Hello, world!"); } Not 250 kB, but your point is well-taken. If you use a lot of nightly features to essentially stub out the panic handling with no_std and do a bare syscall, you can get the size of a hello world down to 6,128 bytes. Japaric's explanation from [this comment](https://github.com/japaric/xargo/issues/133#issuecomment-299599419): &gt; Formatting stuff heavily bloats Rust programs. Even an empty program fn main() contains formatting code because the code that runs before main to initialize the Rust runtime may panic and those panic messages need to be formatted. I'm not convinced tree shaking is going to help much here, since the code that's left behind after the LTO passes is probably still all reachable. That said, I've thought of toying around with throwing additional optimization passes at a Rust binary, maybe I'll finally try that out...
There is no point in avoiding *this* "extra" run-time dep, though.
When gcc does not emit specialized implementations of memset/memcpy, it emits a call to the libc function. Which is perfectly standardized. So yes, you have to have a memcpy implementation available for linking (I think it can even emit memcpy/memset instead specialized code for copy of big structs). And I don't understand why it would be a problem ? It certainly isn't even for a kernel. Just provide your own memset/memcpy if you want. So does it make sense to move the shared version of memset/memcpy out of glibc? Mostly no. Not more that it would make sense to move any other standardized C function out of their libc (they could have similar quality of implementation characteristic that you want, so use the libc you like in that case). And the fact that some C compiler know the semantics of somes, and can apply as-if rules accordingly, does not change that. 
Safe code will *always* be either slower, or just as quick as unsafe code. Sure, the compiler *should* be able to optimise stuff like this, but you can fall back to unsafe when you know you're right.
You linked libstdc++, not libgcc Weirdly, libstdc++ is part of GCC, while glibc is not, however libstdc++ depends on a compliant libc, given C++ include the C standard library. But it is merely a detail; libstdc++ could nearly be a separate project (well, with strong ties with gcc, cause you have to use tons of non-standardized intrinsics to write a compliant c++ standard library, it is ironically virtually impossible to do in strictly conforming C++...) 
Most of it is probably not even loaded though; and even if it is, it does not prevent ripgrep from being one of the fastest grep available. Still I agree that it could be optimized. (well, maybe especially if big parts are unused...) 
&gt; Trait inheritance just doesn't crop up as much as it does in other languages. I'm not sure how that can be; what trait inheritance represents is just something pretty intrinsic you see in both SE/CS; the idea of strengthening/weakening a contract. E.g.: &gt; Ord requires that the type also be PartialOrd and Eq (which requires PartialEq). &gt; pub trait Float: Num + Copy + NumCast + PartialOrd + Neg&lt;Output = Self&gt; { &gt; It's not our answer to impl inheritance (though you can hack it) -- our answer to impl inheritance is composition. Right, my point is that trait inheritance is the answer to interface inheritance (which again is just contract strengthening/weakening), which has severe limitations used dynamically. Again, not the end of the world, but let's not pretend it's ideal.
I doubt these optimizations are used for the ripgrep debian package, though.
Uh I'm not sure what is happening. Probably not the problem but I'm not sure if you need to annotate lifetimes of the references in _compare_both. The lifetimes aren't escaping so those annotations shouldn't be needed. Oh you're missing a `T: PartialEq` bound on `decode_both`. You start with just the `FnMut(&amp;T, &amp;T) -&gt; bool` bound, you cannot pass this generic with additional bounds `T: PartialEq` to the next function.
&gt; The ability to change the length of the vector at will. Suppose you read bytes from the network. It is a common pattern in Rust to reserve enough capacity, let the network stack write into the vector buffer, and then manually change the length. Maybe I need to read up on Rust semantics and containers, but how is changing the length randomly, _in general_, safe? C++ won't allow you to do this, because the containers are generally built around copy semantics, with some move(s) added lately. I wouldn't use any of the STL containers to absorb preallocated memory (as in your example), but the standard ones do guarantee that they will not slice or leak anything. If I can just change the length in Rust in _any_ direction, what is stopping me to cut off the elements at the end of the array? Serious question. &gt; Me neither and neither does Rust. The C++ API forces you to remove the element from the set, and reinsert it. That requires a couple of syscalls to delete and reallocate a node, for no reason... OK, you literally meant _set_. Yeah, C++ won't let you do that ,_in general_, but you can do "mutable" on the members you want changed and it will work fine. I hear _mut_ is popular in Rust too? As before, can Rust guarantee that the element you changed in situ will not have to re-inserted because of your changes? Again, I'm just curious, I haven't looked at container API in Rust, so a genuine question.
I definitely agree that this upcasting thing makes them feel different... but using that in particular is a rather circular argument.
Just finished my first ever [blog post](https://brycx.github.io/2018/08/06/hmac-and-precomputation-optimization.html). It's about my most recent crate [rigel](https://github.com/brycx/rigel), going through how the HMAC-SHA512 optimization was achieved.
Link to the commit [https://github.com/gorhill/uBlock/commit/e163080518d4a841f61359781739327a8890c1c3](https://github.com/gorhill/uBlock/commit/e163080518d4a841f61359781739327a8890c1c3)
&gt; T: PartialEq Even with this not work. Is weird. Now, I'm forced to do: (Column::I64(lhs), Column::I64(rhs)) =&gt; { let apply = match op { Operator::Eq =&gt; PartialEq::eq, Operator::NotEq =&gt; PartialEq::ne, _ =&gt; panic!(" Operator {:?} not boolean", op) }; _compare_both(lhs.as_slice(), rhs.as_slice(), apply) }
Yeah I know, I've linked it in my OP as well. But I'm still learning the rudiments of Rust, so there's no need to go deep into syscalls for now :) 
Well, C mentions that modifying data declared as `const` is undefined behavior, which gives implementations a license to use memory protection if they want. The C++ example is interesting. It seems that Compiler Explorer's clang is using an older version of libstdc++: by inducing a warning and checking the output, I was able to tell that "clang (trunk)" uses libstdc++ from gcc-7.2.0, while "gcc 8.1" unsurprisingly uses gcc-8.1.0. That explains why one output checks if it's already empty and the other doesn't. It seems that the check was added in [this commit](https://github.com/gcc-mirror/gcc/commit/09cc3d83763d20efbe1226bd6d2ae38bf1278fe6), labeled "Add AddressSanitizer annotations to std::vector" (the relevant function is `_M_erase_at_end`). Kind of odd.
Ok I'm starting to see the issue, the problem is that your Column type isn't generic, rather it contains a fixed set of cases. You're trying to bridge this fixed set of cases Column enum with the generics world which can be very tricky. The code you show should work yes but I'm pretty sure it can also work generically. Do you have the definition of Column for me so I can run it in the Rust playground? I've tried to figure out a definition of Column that makes it work but it's not that simple.
Currently working on a web spider. I'm finding increasingly that checking every URL at every step for CannotBeBase errors is a pain, so I'm just about to put the finishing touches on a thin wrapper around the Url type which checks for base suitability on creation/conversion in.
I'm not at my personal machine at the moment so I can't check to be sure, but try making your project a staticlib instead of a regular rust executable. ( In Cargo)
There's a language feature called `impl Trait` that was made precisely for this kind of thing. The idea is that instead of trying to name the type you're returning (which sometimes can be unnameable, which I believe is the case here with closures), you instead use `-&gt; impl Iterator`, which allows the compiler to infer the otherwise unnameable type for you. I was able to use that to make a version of your function that compiles with a few minor changes: fn _compare_both&lt;'a, T, F&gt;(left: &amp;'a [T], right: &amp;'a [T], mut apply: F) -&gt; impl Iterator + 'a where T: PartialEq, F: FnMut(&amp;T, &amp;T) -&gt; bool, F: 'a, { left.into_iter().zip(right.into_iter()).map(move |(x, y)| apply(x, y)) }
Other people have mentioned "impl trait", which is the new hotness for solving exactly this sort of issue. But an honorable mention might go to "boxed trait object", which was the old way to work around this stuff, if you could tolerate allocating memory.
It‚Äôs worth noting that that blog post is very old by now, and there‚Äôs a bunch of work still developing. The API has changed a bit. It‚Äôs correct in broad strokes, just don‚Äôt latch onto the exact details.
I kinda figured that since the template syntax seemed to be very different. XD Thanks
What? I am confused by what you mean, the ripgrep package from the link posted only depends on libc and libgcc, there are no other dependencies because the rust code is all statically linked into the binary.
Because it's useful for debugging? I realize that sounds flippant, but that's pretty much it. I basically never run ripgrep in debug mode because I always want to play with it with optimizations enabled, and compiling it with optimizations with incremental compilation is conveniently fast enough. The debug symbols are useful for backtraces, but the real thing I use them for is for profiling. I profile ripgrep _a lot_. Any time I see a case with performance different than I expect, I slap a `perfr` at the beginning of my command, and it drops me right into a profiler. I do this at the drop of a hat, and the only way that's possible is if I'm always compiling with debug symbols. It's immensely valuable. The only cost, as far as I can tell, is a few MBs and some people on the Internet getting upset about the gratuitous waste of space. Sorry to be so snarky, but golly, it drives me bonkers. :-)
`r` is logically reborrowed in that example, so yeah. It should be fine as long as you don't have any code that's concurrently reading or writing from `r` during the FFI call.
How's amethyst for 2D dev? I'm currently using rs-gfx and specs and it's a treat once a lot of the asset loading boilerplate is done. How much does amethyst give you in terms of features, is it easy to really rip into the ECS and change stuff around &amp; add arbitrary computation? I personally feel like the ECS is best for allowing you to have loads of flexibility when designing, would suck to lose that by fitting a bulky engine around it. Looks like you're basically just re-exporting a lot of the specs code from a brief look at the pong tutorial examples, is it pretty lean? Looks great regardless! 
I couldn't see from the doco any physics library or networking related stuff. I am assuming that you can wire this up as extensions though.
Yes, this is something I'd like to know the answer to as well!
amethyst-rhusics is an external physics crate you can use in amethyst Regarding networking, we have started working on that, and some basic features are leasted in the article as coming in 0.9
Amethyst and specs are fundamentally linked as the ECS is the core of the engine. You can think of Amethyst as a toolbox around specs. That means that in the context of Amethyst, you have access to everything specs. Amethyst will provide you with 3D rendering, positioning, lighting, cameras, asset loading, prefabs, input handling, animation, UI... Specifically on 2D, with 0.9 (or in a couple days if you use the develop branch) will come a special Sprite pass to have very efficient and easy to use 2D sprite rendering. You can then combine that with all the tools of the engine (animation, physics through amethyst-rhusics, etc...). Amethyst does all the graphics aspect you do with gfx, so that you only have left to write your game logic using specs.
I've talked about mdoc in the cli-wg Gitter before. mdoc is just an alternative macro package for roff, like man is, but it's more semantic. Where man says "make this text bold, and this text italic", mdoc says "this is a flag, and this is an optional argument".
This bug comes up for me when I use a generic trait that generates both SSE2 and AVX2 variants of the function, so I can't put the avx2 feature on it, or it may not run on people who do not have avx2 cpus. I rely on the inlining to put it into a function that has the target_feature. In creating the minimal code to reproduce the error I yanked out the generic traits, so it looks like just a dumb implementation, but there is reason behind it. I don't expect to fully inline the recursion of course.
that is fascinating!
Some of it seems outdated, pre 1.0. For example, it says that signed integer overflow is undefined behavior in rust, which i don't think is the case? It's specified as twos compliment isnt it, though it's permitted(required?) to panic in debug mode if you're not explicitly using the wrapping versions, but very much not *undefined*.
Just make sure to give it back in this lifetime
If there was something like "if constexpr" as in c++ though, wouldn't it be really simple and straightforward?
I can't speak 100% to the current state of Amethyst/specs, but from what I've seen of both Unity's upcoming ECS and specs, the two are very similar. Yes, there's a lot of cool things that Unity's Burst Compiler is capable of doing, but I don't think there's anything that's outside of the realm of possibility for Amethyst (eventually).
One problem is that your vector is not mutable. 
The `push` method is for pushing a single item. You're trying to push an array of characters / bytes. You want to use `extend_from_slice` instead.
push didn't work for a single item
Couple things: 1. You have to mark it mutable. `let mut my_v = ....` 2. Single quotes denote a character, so b"a" is still a Vec&lt;u8&gt;, not a u8. You want `my_v.push(b'a'); 3. You can't push vectors, you can use .extend() though. https://play.rust-lang.org/?gist=fd201a9f0ada8096b3b3512a82cbb6fa&amp;version=stable&amp;mode=debug&amp;edition=2015
Because `b"a"` is not a single item. It's a vector of items with a length of 1. `b'a'` is a single item.
I feel like you need to read the beginners rust guide if you're asking that question. Rust is very different than other languages in the sense that everything is const by default. You would need to declare your vector in the following way for it to be mutable. `let mut my_vec = Vec::new();`
I'm also confused.
See [https://lifthrasiir.github.io/rustlog/why-is-a-rust-executable-large.html](https://lifthrasiir.github.io/rustlog/why-is-a-rust-executable-large.html) for a discussion.
I agree with /u/DavidBittner, it sounds like you should take an evening and read through [the Rust Book](https://doc.rust-lang.org/book/second-edition/) until you feel more comfortable with the language. It's a really good introduction to the language and you'll save yourself a lot of time and frustration by reading it early in your learning of Rust.
put your unwanted advice into your ass
It appears to be using https://github.com/gorhill/lz4-wasm, a rust lz4 implementation built for compiling to WASM.
This is not how you behave to someone looking to help you.
please fuck off.
What's generally considered idiomatic, especially for libraries, is to define your own error type as an enum with variants as sum types of other error types, as well as variants for your own errors. You should probably implement From for all the inner types - passing the error up with `?` is the idiom here - as well as `std::error::Error`. You might also be interested in crates like error_chain or failure. https://doc.rust-lang.org/book/second-edition/ch09-00-error-handling.html
This is hand-written wasm, where do you see Rust here?
Especially in Rust as well, it can feel *very* much closer to idiomatic Rust. http://aturon.github.io/2018/04/24/async-borrowing/
I could be completely wrong, it was just that lz4-wasm's built binary is named `lz4-block-codec.wasm` and the file added in https://github.com/gorhill/uBlock/commit/e163080518d4a841f61359781739327a8890c1c3 is also named `lz4-block-codec.wasm`.
\&gt; Can you elaborate on how Rust addresses the (returns Future&lt;X&gt;) composability problem So not at all. Good thing there's sound language design these days like GoLang (in some respects). Oh well, didn't think hipsters were actually on top of it.
hm. I fail at reading comprehension.
will you?
Please note, if you want to actually use the resulting `bool` values returned by the iterator, you need to specify the `Item` associated type in the return value like so: `impl Iterator&lt;Item = bool&gt; + 'a` 
I found rust fairly fun. The borrow checker isn't too frustrating, you get used to it, and then you like it. It's like memory management. This article is quite biased imho
Previous discussion: [https://www.reddit.com/r/rust/comments/8jmmq1/\_/](https://www.reddit.com/r/rust/comments/8jmmq1/crossbeamstm_a_simple_software_transactional/) This crate used to be called Crossbeam-STM, but the STM part confused a bunch of people because my implementation wasn't actually an STM in any sense of the term. I think the name Crossbeam-ArcCell is a lot clearer. And, because benchmarks are always fun, albeit rarely accurate: \`\`\` // Crossbeam-ArcCell test cb\_arc\_load ... bench: 9 ns/iter (+/- 0) test cb\_arc\_update ... bench: 456 ns/iter (+/- 4) test cb\_arc\_update\_no\_reclaim ... bench: 74 ns/iter (+/- 0) test cb\_arc\_set ... bench: 444 ns/iter (+/- 6) test cb\_arc\_set\_no\_reclaim ... bench: 64 ns/iter (+/- 0) // Arc in stdlib test arc\_load ... bench: 11 ns/iter (+/- 0) // RwLock in stdlib test rwlock\_load ... bench: 26 ns/iter (+/- 0) test rwlock\_update ... bench: 25 ns/iter (+/- 0) // RwLock in parking\_lot test pl\_rwlock\_load ... bench: 16 ns/iter (+/- 1) test pl\_rwlock\_update ... bench: 9 ns/iter (+/- 0) \`\`\`
Rust is hard, but I'm getting great help in this reddit, so that is motivating me to continue. A good community is the *best* asset any open source project have.
Should not be always slower, the whole point of Rust is safety, but it makes a little sense when it gets your code slower
Sorry I missed/forgot that!
Cool. I don't think we need to use the mdoc source to build HTML when we still have the actual data structures that made it, but using a more semantic markup sounds very good. Adding support for another macro package in roff-rs won't be hard. There's also another crate out there, rroff, which is already generic over the macro package being used. And using this in `man` is most likely just a matter of calling other methods. Feel free to ping me with any questions here or [on gitter](https://gitter.im/rust-lang/WG-CLI) or on discord!
Is there anything to support bash completion?
I've been looking for an excuse to use Rust, I'll give it a shot! :)
/r/rust like to help people, and part of this is not tolerating such abuse. I'm sorry that you feel that people aren't helping you enough, but abusing them for it isn't an appropriate response. Please refer to Rule 1 in the sidebar, and refrain from behaving like this in future.
Holy shit lmao. I thought I was being friendly? I definitely did not intend to insult your knowledge or anything. I tackled rust the same way at first, I just dove in and started writing code. All that did was give me headaches so I was trying to spare you from that. Christ. 
Having man pages in your $MANPATH should be all that's needed iirc. Otherwise for Clap there's clap_generate.
Right, good catch there.
Looking at this table... why can't parking_lot be included in the stdlib?
Parking_lot is too new and some things behave a bit different. There is a fork of parking_lot that behaves more like standard, but it is in some instances 70% slower than the normal parking_lot, but still faster than std. Maybe some day parking_lot will be included.
Thank you for helping to make this community kind and welcoming. (termhn has been helping me answer lots of Rusty questions recently, as I try to make sense of gfx-rs --- in some sense, they are the embodiment of what this post is about :)
Thank you! This is just what I needed. Please keep this blog series going :)
It makes me really happy to hear that \^.^ I'm glad to be helpful :D
* [reqwest](https://crates.io/crates/reqwest) for html GET requests. * [scraper](https://crates.io/crates/scraper) for css selector. I am not what to use for bot. I will probably use twitter but a whatsapp bot would be perfect.
Working on panini &amp; gearley crates: a general purpose context-free parser generator.
&gt; Maybe some day parking_lot will be included. Or maybe the std components will be deprecated, and people will be told to look for them elsewhere.
Maybe you can compromise on `debug = 1`, I think it's sufficient for `pref record -g`.
The return type in this case contains a closure.
I think the docs (if not the name) should mention that this is an implementation of [RCU](https://en.wikipedia.org/wiki/Read-copy-update).
Respectfully, so what?
Omg I was very much considering doing this. But also I'm co-organizing the conference so I can't disappear from the internet for two days before the conf :/ Maybe should have done my trip back on the Starlight.
How do you write the return type then? Since it must contain the type of the closure, but you cannot name that.
Heh, the spotty cell-phone coverage is a disadvantage. Although I bet it's not as bad on the Starlight as it is going through the Rockies.
You cannot name the concrete type of a closure. You can only name a trait like `Fn` or `FnOnce`. 
Actually the nightly rust compiler has the SIMD proposal implemented: Available features for this target: atomics - Enable Atomics. exception-handling - Enable Wasm exception handling. nontrapping-fptoint - Enable non-trapping float-to-int conversion operators. sign-ext - Enable sign extension operators. simd128 - Enable 128-bit SIMD.
I got it to compile. I had executables true now false. Still not sure about the differences in the target specification for the efi boot loader. It's now (a mix of all boot loader target examples I've found: { "llvm-target": "x86\_64-efi-pe", "target-endian": "little", "target-pointer-width": "64", "target-c-int-width": "32", "env": "pe", "os": "efi", "arch": "x86\_64", "data-layout": "e-m:e-i64:64-f80:128-n8:16:32:64-S128", "linker": "rust-lld", "linker-flavor": "lld-link", "pre-link-args": { "lld-link": \[ "/Subsystem:EFI\_Application", "/Entry:uefi\_start", "/Machine:X64" \] }, "panic-strategy": "abort", "default-hidden-visibility": true, "executables": false, "position-independent-executables": true, "exe-suffix": ".efi", "is-like-windows": false, "emit-debug-gdb-scripts": false, "disable-redzone": true, "features": "-mmx,-sse,+soft-float" }
At the very least, it allows you to return pointers to different types from the same function. That is, if `A` and `B` both implement `Foo`, you can return `Box&lt;A&gt;` _or_ `Box&lt;B&gt;`, dynamically, from a function that returns a `Box&lt;Foo&gt;`; with `impl Trait`, you can return either `A` or `B`, and the type has to be statically known at compile time.
This is a very dangerous and harmful behavior that that person had. It might confuse people and give them wrong assumptions. However, they‚Äôre right: C++ is not designed to be friendly nor productive. And that‚Äôs one of the reason why people keep hacking around languages that provide better abstractions and developer experiences. There‚Äôs SO MUCH MORE to programming than ‚Äúbeing a God that find a segfault‚Äù. I‚Äôm happy to see you around and having fun here though! ;)
Ah, the classic flexibility vs performance tradeoff. Makes sense, thank you!
Right... it's time to read the docs again (last time was waaay before 1.0) - because I either am misunderstanding your words, or just don't agree with Rust philosophy over what constitutes good language/compiler guaranties. I'll bookmark this comment to come back to it, and thanks for the interesting discussion.
Can anyone explain how this can be faster? I would imagine that Load for ArcCell is an indirect aligned load, while for Arc the data is already on the stack.
+1 for the minimalist approach, hyper, tokio and vanilla js. I'll use this project as a template for similar tiny things.
Some functions don't require any unsafe code to be as optimised as they can be. Like, a function that adds 3 numbers passed in as arguments. I don't think there's any way to do that unsafely but quicker than the obvious approach.
Came here to say this.
When will it be possible to target wasm32-unknown-unknown in stable Rust? Stable rustc seems to create a js file for hello world.
Ah. Sorry. Missed the link :)
&gt; Asks for advice on problem &gt; Recieves advice on problem &gt; "put your unwanted advice into your ass" 
The data is not already on the stack for `Arc`, why do you think that?
Well clearly just because I named the return type of the function in its definition does not necessarily mean you can name it somewhere else. In that respect my solution is no worse than all the people suggesting `impl Iterator&lt;Item=bool&gt;`. And when a real function is passed you *can* fully name the result, while the `impl Trait` solution loses it forever.
FWIW no language can guarantee that destructors will run (e.g. you can always turn off the computer before they do) and very few languages without a Gc can protect you from memory leaks (e.g. if you create a cycle between two shared pointers). There is a lot of discussion about this in the context of Rust if you search for why is mem::forget safe.
Uh, brain short circuit. 
Great, thanks for the links.
Yeah, if one pulls out the closure into its own function, or object with a spellable type (e.g. using the function traits), then one can write the type.
cc /u/bzm3r In Rust constants (associated and top level) are inlined at compile time, so all references to the name is replaced by the value bound to the constant. So if you have `const PI: f64 = 3.14`, then everywhere that you use `PI` the compiler replaces it with `3.14`. However, this doesn't work in trait objects as the value is not known at compile time, and can only be given by looking up in the vtable. A workaround is to place the constant in a function that does not take `self`, so you can have `fn PI() -&gt; f64 { 3.14 }` and this will be a valid trait object as it's behind a pointer.
I didn't even know `debug = 1` was a thing. [It does not appear to be documented](https://doc.rust-lang.org/cargo/reference/manifest.html#the-profile-sections), although one of the examples there does use `debug = 2`. I will try it out next time I get a chance.
I think it maps to $ rustc -C help | rg debuginfo -C debuginfo=val -- debug info emission level, 0 = no debug info, 1 = line tables only, 2 = full debug info with variable and type information
[removed]
The `rust-sdl2` bindings are very stable and work very well, however I would caution against using them as an entire game development tool. Instead check out [ggez](https://github.com/ggez/ggez) for painless 2d game development. It has a much more efficient and extensible (and very easy to use) rendering engine, does audio handling and cross platform window management. It actually uses `rust-sdl2` under the hood for window management for its current release version, but is switching to a pure-rust crate called `winit` for its next release (not because the sdl bindings don't work well, but rather because it's removing a large external dependency and makes building the engine that much easier and smoother with pure rust). There's also [Amethyst](https://github.com/amethyst/amethyst), which just had a major new release and are about to land a major update to their 2d sprite rendering capabilities in about a week. It is a larger and more complex game engine, but it's also more extensible and takes better advantage of multithreading out of the box, so depending on what you want out of an engine you could choose either.
I don't have any experience with SDL, but http://arewegameyet.com/ might be interesting for you, if you're looking for libraries for games.
Do you mean the trait syntax? The one in the blog post seems up to date to me.
When working with pointers and atomics, I realized that it's not safe to load pointer and then manipulate reference count because the pointer might become invalid at any point. How exactly is it prevented in this case?
I'll look into them. I prefer something that leaves control in my hands more, and I prefer coding over drag-and-drop solutions. I don't know why, but it just feels better for me. As I said before, it's a hobby for me, so even as inefficient as coding every color and position and collision blocks and whatnot is over using a better toolbox(I hear this argument often), this is just a hobby, and I do it to have fun, and this is what's fun for me. I don't want to go in without any libraries though, as that would be a bit too hardcore(tried following Handmade Hero along for WinApi game development, but using some basic libraries that deal with rendering and such for me just feels better. Amethyst for me looks more attractive, but I definitely will check out both. But let me ask, since I use Windows, not Linux(yeah I know...probably should change, but there are a few games I like to play that cannot be played properly on Linux), do ggez and Amethyst work on Windows as well? Like do they have any dependencies or something like that(I guess ggez can work on both if it uses sdl2, since sdl2 has dependencies for windows and linux as well), but amethyst is only talking about Fedora and Ubuntu dependencies, so I'm a bit unsure/afraid that it won't work on Windows. Thank you very much for the reply, I'm hoping I'll find what I'm looking for here\~
Thank you very much. Will definitely check it out\~
The evangelism is now turning to the community. Interesting...
&gt; I'll look into them. I prefer something that leaves control in my hands more, and I prefer coding over drag-and-drop solutions. I don't know why, but it just feels better for me. As I said before, it's a hobby for me, so even as inefficient as coding every color and position and collision blocks and whatnot is over using a better toolbox(I hear this argument often), this is just a hobby, and I do it to have fun, and this is what's fun for me. I don't want to go in without any libraries though, as that would be a bit too hardcore(tried following Handmade Hero along for WinApi game development, but using some basic libraries that deal with rendering and such for me just feels better. This is exactly what ggez does... no drag-and-drop to be seen for any Rust game engine (yet at least) ;) Take a look at the [examples](https://github.com/ggez/ggez/tree/master/examples) (the Snake and AstroBlasto examples give good overviews of a lot of the functionality that ggez does, and doesn't, provide). &gt; But let me ask, since I use Windows, not Linux(yeah I know...probably should change, but there are a few games I like to play that cannot be played properly on Linux), do ggez and Amethyst work on Windows as well? Like do they have any dependencies or something like that(I guess ggez can work on both if it uses sdl2, since sdl2 has dependencies for windows and linux as well), but amethyst is only talking about Fedora and Ubuntu dependencies, so I'm a bit unsure/afraid that it won't work on Windows. Nope, both are made to be completely cross platform and should work on Linux, Windows, and macOS. One of Amethyst's most active core developers uses exclusively Windows, actually, and I personally still use Windows the majority of the time as well, though I also spend another 40-50% on both macOS and Linux depending on which computer I'm using :)
I'm very happy to hear all of this. Thank you again, and I will definitely give both a try.
[Either](https://docs.rs/either/1.5.0/either/enum.Either.html) also implements iterator if both Left and Right are iterators. If the number of variants is small you should still be able to avoid the allocation (untested though).
That's why the std must remain slim if we want to avoid having a standard library full of deprecated crap after a few years.
IIRC, parking lot doesn't support _lock poisoning_ by default (a lock becomes poisoned if a panic occurs in a thread that holds the lock, and attempting to lock on a poisoned lock spread the panic to other threads). There's an implementation that support poisoning, but it makes everything much slower, defeating most of the performance benefits brought by parking_lot.
You can also dynamic dispatch using an enum. That being said, box has other advantages: * Can be used in case of trait methods - it's impossible to use `impl Trait` in trait methods right now. * If the returned value is expected to move a lot, it might be more performant to allocate and move only a pointer.
I've being going through the same stuff just 2 days ago. Had to dig into their tests to find the solution. I liked Diesel, but they need to update the docs to make such information more accessible.
Wait, do you mean a tool that takes in XSLT and emits WASM? So you could do something like call an XSLT-compiled-to-WASM program from JS on a webpage? That sounds like a bit of an abomination, but it could be a great project!
I just installed it on my server and my wife has no idea how it's called. ;)
Ooh, I like the enum idea.
Heh. Fancy seeing you here.
Awesome, I didn't know there was a Rust group so close to me! Thanks for the heads up!
I've been playing with making a safe atomic pointer for a while, and I am also curious how this is accomplished. It looks like it uses something called epoch-based garbage collection.
* [https://twitter.com/chinedufn](https://twitter.com/chinedufn) has been doing some really neat stuff with webdev and gamedev * [https://twitter.com/jackmott42](https://twitter.com/jackmott42) \- that's me, I sometimes talk about gamedev and SIMD stuff with rust, and have been doing some streaming. * [https://twitter.com/michaelfairley](https://twitter.com/michaelfairley) doesn't tweet much but when he does it is interesting. I think he is the first person with a commercial game written in rust
I wonder if they'll ever make a dedicated Rust IDE as with C/C++, Go, PHP, Ruby and so on...
This was posted here 2 days ago?
It can also provide better performances if the returned iterator is a big pile of complex stuff and gets passed around: all that stuff needs to be memcpy'd from one function to the next, whereas the boxed iterator at the cost of an initial allocation just needs to copy two pointers.
Sorry. I did search for the URL but nothing showed up.
`diesel` schema macros now resolve correctly, yay!
&gt; only a difference of 2 nanoseconds 20% is nothing to sneeze at. the update looks like it could use some work, but depending on how often you update a 20% improvement could be more than worthwhile. 
I would imagine so, too. I think they‚Äôre still a healthy ways off from commercializing a Rust IDE, though. I‚Äôd say in two years, it‚Äôs a very likely possibility, but Rust has a lot of maturing to do to pick up necessary market share to justify a commercial product. 
You can see the implementation of the method by clicking '[src]` in the documentation. Should be on the right.
Fair enough. With reddit, `Explore Domain` only appears after you post it, and searching with a link works occasionally.
The documentation is clear on what it is, and what the tradeoffs are and why. I would love to see a toy example of why/where this might be appropriate, to give context for beginners like myself. Is this useful for: * creating a visual debugger for a game loop? * creating a shared web counter? * creating a multiplayer drawing game? * writing a commandline tool? etc...
I missed the previous post, and this was an interesting read, so thanks. :) 
And if you want to present your first time here, feel free! This particular venue is great for presenting. :)
https://twitter.com/ManishEarth/ https://twitter.com/RustLang
could they be resurrected as an opt-in (I understand they'd have a performance impact everywhere, different stack behaviour right?)
[removed]
&gt;Abstractly, the "?" appended everywhere just looks like clutter. And this all feels like checked exceptions where at every level I have to catch them and re-raise. Perhaps I'll get used to it, but for the time being it feels suboptimal to me. You're right that it is very much like checked exceptions. The nice thing about Rust is that the "catch and rethrow" ritual is literally one character instead of `try { } catch { FooException } finally {}`, etc. &gt;Concretely, something like the following is what I'm talking about: &gt; &gt;self.translate\_bin\_op(self.translate\_exp(a)?, self.translate\_exp(b)?)?; &gt; &gt;Perhaps it'd be cleaner to use let bindings here for the two arguments. Suggestions are most welcomed. That looks perfectly fine to me. I understand that it looks a little noisy with the `?` all over the place, but it's very clear to me that `self.translate_exp()` and `self.translate_bin_op()` return `Result`s and that we have taken those into consideration. This is opposed to Java's unchecked exceptions where maybe the person calling the function has considered its unchecked exceptions and has *chosen* to ignore and let them propagate, or maybe it should have been caught and there's a bug. The only style tip I do that might help with your example is this: self.translate_bin_op( self.translate_exp(a)?, self.translate_exp(b)? )?; I tend to do this with most functions where I'm passing in complex things as parameters. The side effect here is that the `?` tend to always be near the end of a line, so it's a little more accentuated. &gt;At the risk of asking for something I maybe don't really want, I think it'd be helpful for the compiler to do the "?" automatically for me here. Much like the new match ergonomics, I think it'd be helpful to see that the type I want is the Ok side of the Result and handle the destructing for me. This would be taking the syntactic sugar of ? a step further by integrating it into the type system. Not to sound combative, but can you imagine the potential oversights that this would cause- and for the price of not typing one character? That trade off doesn't seem worth it at all. Then, again, I have actually been a bit disappointed by some of the ergonomics changes, so maybe I'm the weird one.
&gt;Avoid UI freezes while typing string literals Finally! 
&gt; This is opposed to Java's unchecked exceptions where maybe the person calling the function has considered its unchecked exceptions and has chosen to ignore and let them propagate, or maybe it should have been caught and there's a bug. But you could call a method for side effects (ignoring the return value) and forget to use the "?" on that call, which would lead to silently swallowing the error too, right? Or is my understanding of that flawed? &gt; Not to sound combative, but can you imagine the potential oversights that this would cause- and for the price of not typing one character? That trade off doesn't seem worth it at all. Then, again, I have actually been a bit disappointed by some of the ergonomics changes, so maybe I'm the weird one. I wouldn't take the suggestion too seriously. I've only been writing Rust for about a month. It's just an observation from a new user and a not full thought out idea of how it might be nicer. The whole thing could be as trivial as others not happy about needing semi-colons or parentheses. I was initially asking just to see if there were a better way.
Lack of trait inheritence and Rust's general weaknesses involving dynamic dispatch are the major things that have kept me from writing a widget toolkit in Rust. Trait objects may not come up often in some people's experience, but it seems that any time I try to make something other than a parser, the core language seems to lack exactly the things I need to continue. We can't just brush these things off and expect people to work around these weaknesses forever.
Feel free to edit your post to correct the code sample ;)
&gt; When working with pointers and atomics, I realized that it's not safe to load pointer and then manipulate reference count because the pointer might become invalid at any point. This actually depends whether you have weak pointers or not. If you have only strong pointers, then the mere fact that you have the pointer in hand means that there is some variable in your thread having ownership of this pointer, and therefore the pointer cannot be invalidated under your feet. You can therefore perfectly clone it and then increment the counter. When you have weak pointers, however, promoting the weak pointer to a strong pointer is more complicated. If you use a naive `fetch_add`, there is a risk that the result of `fetch_add` is 0, meaning that you incremented the count of live owners from 0 to 1: you just "resurrected" a dead value. Decrementing it afterward is not a viable strategy: another thread could see the "1" and conclude the value is live and use it... hilarity ensues. Note that only the promotion is complicated. Cloning a weak pointer is fine, since it has strong ownership of the storage of the counters.
[removed]
I'm glad &gt; Fix false positive `Cannot borrow immutable local variable` annotation for index expressions was fixed. The Rust plugin keeps getting better and better.
I'm glad &gt; Fix false positive `Cannot borrow immutable local variable` annotation for index expressions was fixed. The Rust plugin keeps getting better and better.
I feel like they should try and make one main IDE and make languages as plugins. This would make a lot of sense since most of their tools work largely in the same way. 
Hey neat, I wrote an API that did rpg dice stuff too :) [https://github.com/UnicornHeartClub/roll-api](https://github.com/UnicornHeartClub/roll-api) \- Good luck and have fun!
It turns out, at the end of the day, God has more responsibilities than a mortal would every care to have. Manual memory management being one notable example.
That's Intellij does right ? üòÅ
I guess intellij it trying to do that. But I wish they comitted to it more :)
This is the answer, but you should also read the [first chapter of the book](https://doc.rust-lang.org/book/2018-edition/ch01-00-getting-started.html), in particular, the [section on cargo](https://doc.rust-lang.org/book/2018-edition/ch01-03-hello-cargo.html).
Well there is some marketting to it, if you don't need everything it costs less and has less. I don't see how converting the same point as plugins would help, especially when you have a not-yet-sellable part such as rust vs Java
That's nice.
In theory, sure. In practice, it's not gonna happen at this point.
How can I silence log messages from `cargo` itself while running tests for my binary project? I am using `pretty_env_logger`, but there is lot of `INFO` and `DEBUG` messages that are just not relevant to me.
oh damn, thanks!
What datatype should I use to split up read-only bytes among threads? Say, I have 1MB of bytes in a Vec&lt;u8&gt;, and I want threads in a pool to each own 1KB. Lifetimes and borrows seem like extra work, and I want the threads to "own" the read-only bytes, and drop them when complete.
I've been using VSCode recently with good results (I was using atom previously as I couldn't get VSCode to work at the time). It's been pretty seamless.
Is vscode any better than atom?
https://twitter.com/Jonhoo
If your example code is stable and unlikely to change, I think it would be helpful to intersperse snippets from the example source code. Reading code inline with the blog post helps me grok concepts. For instance, show how to create and pass the channels to workers.
Nice piece. I think it's important to emphasize that it's tricky to avoid all extra value generation. You use a `sync_channel` with bound 0 to get a rendezvous, but you must then wait for the receiver to "approve" the value somehow before generating the next one. The easiest way to do that would be with a back channel. Futures are another way to avoid all extra generation in this example. None of this is unique to Rust, of course: any generate-and-test architecture has to make the choice of how much speculative generation is done. No speculation = no parallelism, and too much speculation can be an expensive waste. Efficient parallelism is hard.
[removed]
Seems like you could just put the `Vec&lt;u8&gt;` into an `Arc&lt;Vec&lt;u8&gt;&gt;`, send it to all threads, and assign the threads ranges of indices (e.g. `0..1024`, `1024..2048`, `2048..3072`, you get the idea).
I hope they don't. Otherwise plugin will be disabled in the Community version.
Seems like you could just put the `Vec&lt;u8&gt;` into an `Arc&lt;Vec&lt;u8&gt;&gt;`, send it to all threads, and assign the threads ranges of indices (e.g. `0..1024`, `1024..2048`, `2048..3072`, you get the idea).
What dedicated C/C++ IDEs are there?
[removed]
[removed]
Clion and Visual Studio.
My understanding is that this changes life for unsafe authors only; they can run their code in Miri and have this system report, at runtime, that UB has been triggered. (Once it‚Äôs implemented, of course) It‚Äôs also possible that my understanding is wrong. 
May I ask a follow up, is Vec::split_off() as slow as it seems? It's cheaper to pass a reference-counted pointer of the original vector? Fair enough.
Would it be possible to extend this or have a variation of this that does as below? * Make the `Arc` optional * Allow const initialization, in order to store this cell directly in a `static` item (possibly with `None` being the only possible initial state, with the above change)
Without benchmarking one can't be sure, but I strongly suspect that 2 * |threads| atomic inc/dec operations are faster than 1024 vector allocations. But if you*really* want to know you should benchmark! I imagine making larger chunks (e.g. 10kb instead of 1kb) will also be faster, but since you haven't described what you are trying to do it's hard to give better advice.
You're welcome. Try as many editors as you can, and pick what feels best. Just make sure you set them up properly for rust integration first :)
On what IDE it can be installed? Can we install it on the community version of IntelliJ? Or does it requires clion?
In what way does it implement it? I don't see wasm mentioned anywhere in the actual code here. Or is that just through auto vectorization + the target-feature activated?
[these folks here](https://twitter.com/killercup/lists/rust) are awesome
I hope it isnt due to some browser setting of mine, but I would really appreciate code snippets interspersed between sections rather than linking to the github at the beginning. If it is but my ad blockers are being weird, then sorry and great article!
CLion is intelliJ, so wouldnt that make IntelliJ rust just as dedicated as CLion? And visual studio isnt dedicated, it's general purpose. it supports many languages, like python, .net, C#, etc.
This is a proposal for a memory model.
It should work with all of the JetBrains IDEs, including IntelliJ IDEA Community Edition. It seems that debugging is only available in [CLion](https://github.com/intellij-rust/intellij-rust/issues/535) at the moment, though.
Is there a way to do it? I was thinking of (sometimes) offloading the job of dropping the stored data to the Weak pointer that's in the middle of trying to upgrade. eg, a Weak pointer starts the upgrade process, in the middle of which the last full Arc drops. Then instead of forcing the Arc to drop the data, it just lets it go, while the in-progress Weak either finishes upgrading, or else drops the stored data.
For that case, would `Box&lt;impl Iterator&lt;Item=bool&gt;&gt;` work?
Check out the [refmove crate](https://internals.rust-lang.org/t/library-level-by-move-reference/8133).
Also there's a lot of discussion about possible `&amp;move` references in the [DerefMove RFC thread](https://github.com/rust-lang/rfcs/pull/2439).
\[removed\]
Pretty sure that if a large value gets passed on the stack the compiler will sneakily turn it into a reference anyway.
Yeah, I meant weak pointers, since strong aren't a problem at all. When I was implementing such schemes in C(++), I resorted to rw lock - do the clone &amp; increase behind read lock. Maybe a faster solution exists, but I didn't find any. Also, so far it doesn't look like a bottleneck.
Sorry if this is a silly question. In Rust, is there any special name for "::" ? I always pronounce it as "double-colon". 
Been learning and experimenting with macros for an experminental side project, [struct_gen](https://github.com/robertDurst/struct_gen). Also up to day 46 on my every day rust blog, http://therustykrab.fun/!
Is there some reason you're being secretive about your port target? I'm going to guess that this might not even be your bug, but instead a bug in the sketch-sounding system threading you are using. The more information you share when you post something like this, the easier it will be to help you.
Best of luck!
Perhaps repost it in internals? Compiler and lang discussion happens there and there is less traffic. You'ld get more visibility from the people that could help you. internals.rust-lang.org
CLion has it's own proprietary features as well, the debugging of C/C++/Rust programs works a lot better on CLion than in Intellij.
Let me try to understand this: You are working on something, which you are not sharing the code of. (nothing wrong with that per se) You have a problem that is related to multithreading/concurrency. The thing i think is problematic is: you want others to help you debug this, without sharing the whole code. Debugging concurrency problems is hard work, when you have the whole system to examine. It is impossible otherwise.
&gt; But you could call a method for side effects (ignoring the return value) and forget to use the "?" on that call, which would lead to silently swallowing the error too, right? Or is my understanding of that flawed? Not using a `Result` produces a compile-time warning in Rust. So it cannot be swallowed silently. 
Have a look at [https://os.phil-opp.com/](https://os.phil-opp.com/)
You already know about redux but there is also: - https://os.phil-opp.com/minimal-rust-kernel/ - https://github.com/tock/tock Also, not rust related, but here are some other very nice resources you may find interesting: - https://0xax.gitbooks.io/linux-insides/ A very detailed look at how Linux works - https://www.nand2tetris.org/ A fairly simple guide on building a simple 16bit computer from NAND gates to an OS - https://www.happyassassin.net/2014/01/25/uefi-boot-how-does-that-actually-work-then/ A detailed description of how UEFI works
In my opinions, asking for help is best done on a public forum like you did. Many people can potentially answer, and many people can profit from everyone‚Äôs answers if they happen to have a similar problem. Then if you have a reason to believe a specific person involved in a relevant project might be more able to help than others (`git shortlog -s` on a specific source file might help find who) it‚Äôs acceptable to ping them, preferably using the forum‚Äôs own "mention" system if there is one. What I would not encourage is asking directly (not linking to a public forum thread for example) in private email. Such a message expects a response from a single person, without an opportunity for someone else to help. Worse is emailing multiple people separately, as this shows an expectation of some answer from *all* of them.
Possibly a game console whose specifics are under NDA? Just a guess.
I think `impl Trait` only works for typing arguments or return values. A boxed trait object would be `Box&lt;Iterator&lt;Item=bool&gt;&gt;` or using the new disambiguation syntax `Box&lt;dyn Iterator&lt;Item=bool&gt;&gt;` (I don't think there's any difference between the two, the latter just makes it clear the dispatch is dynamic)
Surely such an NDA would not specifically exclude the Rust core developers?
Well, you might call those "concurrency memory models". ;) I do not think "memory model" a priori has anything to do with concurrency. The post is mostly concerned with the aliasing aspect, but of course we'd also have to define pointer arithmetic and pointer-integer-casts and so on -- and then I think it is fine to call this a (sequential) memory model. After all, it defines how memory behaves, i.e., which operations are legal when. It is not concerned with concurrency, but, in highly optimized low-level languages, [that doesn't mean things get simple](https://www.ralfj.de/blog/2018/07/24/pointers-and-bytes.html).
It shouldn't be in the language if you can implement it in library. It may be part of std though.
In such a case, talking to the Rust team would breach the NDA and the Rust project can't easily sign an NDA. In this case, talk to one of the consultancies, they can enter such agreement. asquera.de (full disclosure, this is mine) integer32.com 49nord.de
Project has been selected. The projects could be made based on any field: data mining, AI, robotics etc
\[removed\]
You probably already know about the paper *Regular expression derivatives reexamined*, but that paper uses the smart constructor technique to construct a DFA from a regular expression. If you memoise the function that computes the derivative you get an algorithm that builds the DFA state machine lazily. The simplification rules guarantee that you'll have a finite number of DFA states for any given regular expression, and if you include additional simplification rules then you get the minimal DFA in most cases.
I use Intellij Ultimate with an open source license and everything works pretty well usually. Admittedly Webstorm/Phpstorm are a bit more coherent and stable for their respective environment, but Intellij works fine.
IANAL but I'm guessing being employed by Mozilla would complicate things. But not everyone is, e.g. I have my own consultancy, so you could find Rust team members who could help.
Wrong sub, you're looking for /r/playrust 
It won't ship in the initial version of the new edition, because it's unlikely to be ready then. It will ship sometime in the subsequent months (without the need to wait for another edition).
Ah yeah right! I've read that paper a few times. :-)
Trying to learn rust using exercism.io, it's got mentors and stuff. Looks pretty neat to me
Reading this post clarified something for me and now I think calling Rust 2018 an edition is maybe not so good. When I think of an edition, it's like a release. But if I understand correctly Rust 2018 is like a period, spanning over a certain amount of time. So if there's a new feature within that period, it would be part of Rust 2018. Is that right? Calling it an edition then would be kinda weird.
Qt Creator, XCode, KDevelop
"Using" is a fairly broad term though. E.g. none following lines give a warning. Naturally I agree it's hard to do one of these by accident. [Result::Ok::&lt;_, ()&gt;("hey")]; (Result::Ok::&lt;_, ()&gt;("hey"),); Some(Result::Ok::&lt;_, ()&gt;("hey"));
This post gives a good overview https://manishearth.github.io/blog/2015/05/17/the-problem-with-shared-mutability/
Because you can still invalidate a reference in single threaded code.
 let mut option = Some(5); let option_reference = &amp;mut option; let mut backup = 0; let reference = match option_reference { &amp;mut Some(ref mut n) =&gt; n, _ =&gt; &amp;mut backup, }; /* if the next line was allowed, what would be the semantics of the line after that? */ //*option_reference = None; *reference = 10; 
because jetbrains is making a product and wants to sell it for money? and not all of them have community editions? all of their software has a paid version with more features? Such as [Pycharm](https://www.jetbrains.com/pycharm/features/editions_comparison_matrix.html)? Community edition doesn't support web development, databases and sql, frameworks, remote debugging. as far as i understand it?
&gt; You are working on something, which you are not sharing the code of. A rust port is a considerable amount of code - I could share std::sys::thread, but it's quintessentially a unix copy, since it entirely runs on pthreads. 
I guess it's technically compiler development, but perhaps not quite what they do (the port is almost complete, since a large amount of std is functional) - is there a good IRC channel I could post to? #rust-beginners can't reallly help with this sort of question, and some of the channels are a bit dead
`try_mm` or `maybe_mm` or just `mm`.
I dont really understand the use cases for Box&lt;T&gt;. i understand that its for heap allocation, but to my understanding, if i create an object in a function and return it (or move its owner in doing so) its also allocated on the heap? And T gets dropped (or freed) if its owner goes out of scope, but thats also the same if i just create a variable of type T. Any ellaboration would be greatly appreciated :)
Does `Result` stay "very expensive" after optimizer if you ignore the error with `Result::ok` or `unwrap` or something?
Go to IRC, irc.mozilla.org, hop onto #rust, and ask there. There you will find many Mozilla staff, people that work directly on the development of the rust programming language and all the surrounding ecosystem. They are very helpful, just try showing up on work days during work hours, on the weekends those people are out enjoying life.
Thanks. I also considered `maybe_mm` before, but it doesn't really seem "rusty", `try_mm` is an interesting option as Rust developers use this convention already, but I personally don't like it to start with a verb. And just `mm` I would prefer to return a Result as long as it's a part of a public API and looks cleaner.
&gt; But you could call a method for side effects (ignoring the return value) and forget to use the "?" on that call, which would lead to silently swallowing the error too, right? Or is my understanding of that flawed? You're correct. I believe that ignoring the return value is a compiler warning, though, so you'll at least end up with something like `let _ = sideEffectFn();` which makes it clear that you're purposely ignoring the result. &gt; I wouldn't take the suggestion too seriously. I've only been writing Rust for about a month. It's just an observation from a new user and a not full thought out idea of how it might be nicer. The whole thing could be as trivial as not being happy about needing semi-colons or parentheses, in which case I'll just adapt. I was initially asking just to see if there were a different way to handle errors because I really didn't know if I was doing it wrong. Right, fair enough. As others have mentioned, you're not doing it wrong. That's just how Rust is. And it honestly can be frustrating to see that most of your code for a module is dealing with the error paths rather than the happy path (defining your own `Error` types, implementing `From` for them, etc). But I kind of like how Rust forces us to put all logic paths on equal footing, in some sense. Error handling feels like an after thought in most other languages I work with.
Sure, but there‚Äôs a whole bunch of reserved keywords: https://doc.rust-lang.org/book/second-edition/appendix-01-keywords.html async isn‚Äôt on it, though, so yeah it‚Äôll be added with 2018 edition, I‚Äôm sure. 
I agree with this. I think the idea of editions is confusing. I'd much rather they just released Rust 2.0, and then 2.1, etc. In fact, I think I might propose this.
Why not just have the function return a `Result` and have people use `.ok` when they want to ignore the error?
I'll be speaking at this! Looking forward to seeing some of you nerds there.
Can't it also just not copy anything if it can use it where it's already located in the stack? I thought that was one of the advantages of the ownership model.
good luck with your endeavours lol
Tech that will not be used is in my case. This is specific to my project, but the conditions for any valid project can include robotics etc
I see. Apologies, and good luck with your project!
Semantic versioning was rejected for this purpose because ... 1) it implied **major** breaking changes (that is after all what the first number in the triplet stands for) 2) Rust 2015 is not discontinued. New features that don't require any breaking changes will still be available to projects not opting into Rust 2018. Switching between compiler version 1.28 / 1.39 won't automatically switch you to Rust 2018. Its more like a feature that you have to enable to use it. There might be more reasons. Source: Mostly the Rust edition guide ([https://rust-lang-nursery.github.io/edition-guide/editions/index.html](https://rust-lang-nursery.github.io/edition-guide/editions/index.html))
Thank you!!üòä Maybe it was just me not being clear in the comment because of the post text... :7
The only way to be sure the answer is 'yes' is to bring your own...
I was working on an interpreter for my toy language and I wanted to write about it, but I didn't have a place I could post to, so I'm currently working on a minimalist static blog generator. It's surprisingly fun to make and gives me a very much welcome break from tearing out my hair when hitting roadblocks in the language department.
What about a cases where we can prove a memory wont change until its dropped? for example, a Vec with fixed size that cannot grow/shrink/reallocate, is it ok to take multiple references to the same index? isn't most of the stuff fixed in memory? I'm sure we can think of something that would allow multiple mut ref without using unsafe(?) for example, in the example you gave, the lifetime of reference will be connected to both backup and optional reference, and if one of them changes - reference will be dropped and you will not be able to use reference after one of them changes
Just allowing several mutable references would break even on one thread, as /u/thiez pointed out. If you want a slightly weaker version of "multiple mutable references", you can look at std::cell::Cell, which only works on a single thread and allows you to swap out the value contained in it through shared references.
&gt;My point is that even if it would do that, you can catch the exception Nope.
Do you have prior programming background? Did you try the Rust Book: https://doc.rust-lang.org/book/ Rust is a programming language, you can build anything you want. Are you interested in any specific areas like Games, Web Development etc.?
I thought async was a contextual keyword for the edition?
Several high profile projects have switched to using semver for minor breaking changes though. For example Angular is now doing 6-monthly major releases, and TypeScript has just release a mostly-backwards compatible version 3.0. Rust is different in that it will be supporting the old edition in parallel. But I still think it might be easier to keep track of one version number rather than two...
Cargo is the package manager, generally you'll use it instead of using \`rustc\` directly. But yeah, as /u/mdaffin said, you'll probably want to read the Rust Book.
Depends on what the optimizer thinks about it. It's certainly one of the optimizations that *can* be made.
How minor? I think porting [Halogen](https://github.com/slamdata/purescript-halogen) to Rust/wasm would be an interesting &amp; useful project (considering the [issues](https://github.com/DenisKolodin/yew/issues/350) with Yew).
Are there cases where it's beneficial to move memory even though it's not necessary?
&gt; if i create an object in a function and return it (or move its owner in doing so) its also allocated on the heap? As far as I know Rust **never** heap allocates implicitly. Rust's "return semantics" (if that's even a thing?) should be about the same as C's. I'm not 100% sure about the specifics, but IIRC if the return value fits in a pointer it's returned normally (using a register), otherwise it might be simply copied from the function's stack to the parent's stack. Rust can also perform return value optimization (RVO), though it's not guaranteed as far as I know. This works by allocating a hidden variable for the return value on the calling function's stack, and the address of it is passed as hidden argument to the function. The function then writes the result directly to the callee, without copying anything.
I would talk to the person leading the project, explain what's up and get their advice. You might get permission to disclose enough some things, or you might get suggestions about other ways to proceed with the problem.
True, I was only talking about the cases where the value is owned by the "function's stack" directly.
Nope, that would not allow async blocks and async closures.
Idiomatic rust: take some wrong (even impossible to compile) rust code and make it idiomatic via iterative refactoring, like those cool presentations from Raymond Hettinger about idiomatic Python.
`#rust-internals` is a better channel for this kind of thing
The second edition of the book is frozen at Rust 1.21, so that list is out of date. A bunch of the "reserved for future use" ones have been un-reserved, for example.
It has been, for exactly this reason.
Thanks a lot :) 
This is the subreddit for the rust programming language. You'll have better luck at /r/playrust :)
it's hard tho, because you really didn't discuss memory; the only part of the thing where you did talk about memory was that a `&amp;[mut] T` "owned" `sizeof(T)` bytes. Aliasing models belong in their own section, apart from the object and memory models, although obviously the three depend on each other.
Is \#rust the best channel for it? 
`Rc&lt;T&gt;` is cloneable even if T is not. As long as it doesn't need to be mutated that could work.
&gt; if i create an object in a function and return it (or move its owner in doing so) its also allocated on the heap? Go works like this sometimes, like if you return a pointer to a local variable. But in Rust that sort of thing will always be a compiler error. Apart from heap allocation, another common application of Box is to give you an owned trait object (using virtual dispatch under the covers). For example, if I have a `Box&lt;dyn AsRef&lt;str&gt;&gt;`, that could hold any type that's capable of giving me a string. The recent "impl trait" features are able to handle some of those use cases without allocation, but sometimes you still need Box.
I also discuss what extra state is kept in memory and pointers, which is a big part of a memory model. I agree that the concurrency part is somewhat separate, but then I am not sure which part you would keep in what you call "memory model". I'd say a memory model is all of these things together -- an aliasing model, a [pointer model](http://sf.snu.ac.kr/publications/llvmtwin.pdf), a model for concurrent accesses. There will likely be some interaction though. Oh, and I still disagree on the need for an "object model." ;)
It looks like you can nest impl Trait in other types: [playground] (http://play.rust-lang.org/?gist=2e54b4657815d4f6de2ca2bdf7dfb993&amp;version=stable&amp;mode=debug&amp;edition=2015).
It's obviously easier to keep track of one version that two, but it also doesn't serve the same purpose. You can use two different editions within the same project, which greatly reduces the impact of breaking changes on the ecosystem and makes for a much easier upgrade path. You can't use two different versions of the compiler within the same project unless Rust commits to a stable ABI, which would be a huge commitment and could greatly reduce the ability to add new features to the language.
I think a CAS on the live count should be enough to only increment if it's non-0.
For performance reasons -- making an instance of Error could involve some computations to construct an error message and backtrace info gathering, which is very expensive.
Thanks for including my comment!
When you write: ``` if let Some(_) = val { something(); } ``` The compiler rewrites your code to: ``` match val { Some(_) =&gt; { something(); }, None =&gt; {}, } ``` That's going to end up, after compiler optimization, to be essentially identical to the `if val.is_some()` approach, since `Option#is_some()` is implemented as follows: ``` pub fn is_some(&amp;self) -&gt; bool { match *self { Some(_) =&gt; true, None =&gt; false, } } ``` In other words, I wouldn't worry about which is optimal. They're going to have near-identical performance. If this is a *super* important part of your code performance-wise, I'd try both ways and measure.
If you really can't find one you like why not start a project.
The #rust channel is a good place to start. However [steveklabnik1](https://old.reddit.com/user/steveklabnik1) here that just answered my post as well, he is on the rust group on github, and a persistent presence on #rust himself, so his suggestion(#rust-internals) is probably even better. I wouldn't worry too much about it though, we are a friendly bunch on IRC, if you have a better chance of getting an answer elsewhere, we'll point it out.
So what you would need to implement would be `impl Mul&lt;Point&gt; for Point` and `impl Mul&lt;f64&gt; for Point`.
Questions I ask my students when they ask me this: * What are your interests outside of programming? What areas of interest and expertise do you have that you could write software for? * What are your strengths? Is there an area of tech in which you have fun working? * Can you find a project that is highly incremental: you could get to a tiny MVP very quickly and then improve from there? Those are the best for deadlines. * What are the success criteria for your project? How is it graded? (I usually know this.) Do you want to get more out of it than just a grade?
The nice folks from the Rust Utrecht meetup have done workshops a few times, where everyone (potentially in groups) reimplemented a limited version of a venerable unix utility like grep or wc. A smaller version of thr performance workshop at RustFest Paris could also be cool. 
I'd also be interested in this. I was considering working on a dirb alternative.
The code in the barriers section has an issue: the first function should return an u32 (the x?) but you're not. This looks great though! Excited to see how the discussion around these memory models progress. 
It seems like `double` is a general-purpose mocking crate, but for your needs, manually implementing `Read` is enough. Mocking the read method is pretty easy: ``` struct ReadMock { calls: u64, } impl Read for ReadMock { fn read(&amp;mut self, buf: &amp;mut [u8]) -&gt; Result&lt;usize&gt; { // increment # of calls self.calls += 1; // iterate through the buffer for byte in buf.iter_mut() { // set byte to zero *byte = 0; } // We "read" (the length of buf) bytes // and we never encounter an error. Ok(buf.len()) } } ``` &gt; validating call's arguments I don't understand. read takes a buffer to read into and nothing else. You shouldn't look inside the buffer, either, you should write to it.
To store first argument convert it to `(*mut u8, usize)`, don't dereference it later. For returning store `Result&lt;usize, io::ErrorKind&gt;` and convert to `Result&lt;usize, io::Error&gt;` on demand.
Posted there as well, but this seems to be a bit of a nasty problem. I don't know reallly where to look, and I don't even really know the full extent of what will be useful, so it's going to be hard to really get help 
It depends on the context -- in some cases, it is expected to have None there in the other context it's an error which has to be signaled.
That makes sense thanks, but to simple types like numbers or simple structs where you dont need drop and dont care about replaced, this is very nice thing to have. Aka most of the stuff are simple, like vectors, numbers, strings and etc.. If drop is important, lets create Vec which do not accept Drop values, will it then be safe? I'm trying to understand better the problem, personally I'm not a fan of wrapping stuff in types to achieve something basic that I know is safe but dont have the ability to express it 
thank you :)
Rust2018 is an option that enables syntactic breaking-changes with respect to Rust2015. That is, when you enable it, the syntax of Rust becomes different in a backwards incompatible way with Rust2015.
Might check that out but for now the project is different. Looks interesting...
Your approach is a bit different from mine, since mine only has the wrapper type, while yours also has traits that are implemented for existing types.
Well I can't find one at all. Starting a new project might be beyond the amount of time I'm able to commit 
Too much match :) for example: let resources = match self.entries.get(&amp;entry_key) { Some(ref resources) =&gt; resources.clone(), None =&gt; return None, }; why not `let resources = match self.entries.get(&amp;entry_key).cloned()?;` ?
That's a good one, and it could be the topic of a next blog post :)
Yes. Windows has no OOM killer. If you're accessing invalid memory and you have an exception handler for it you can handle it. 
Shameless plug [for a tutorial I wrote](jsandler18.github.io). This is in C, not rust, but it still teaches the concepts.
You could take a look at this list and pick any: https://github.com/servo/servo/issues?q=is%3Aopen+is%3Aissue+label%3AB-interesting-project
There is now a PR to stdsimd, that implements most of the simd128 intrinsics: https://github.com/rust-lang-nursery/stdsimd/pull/549
Option works fine with `try!/?` fn f(x: &amp;HashMap&lt;&amp;str, i32&gt;) -&gt; Option&lt;i32&gt; { let y = x.get("aaa")?; unimplemented!(); } compiled just fine with rustc 1.27.2
Options only work with `?`. The `try!` macro is implemented as a match statement on result: https://doc.rust-lang.org/src/core/macros.rs.html#299-307
Options only work with `?`. The `try!` macro is implemented as a match statement on result: https://doc.rust-lang.org/src/core/macros.rs.html#299-307
For `Copy` types you can use a `Cell` which AFAIK has no overhead
Another great tool to avoid cascading matches is using `map` on an `Option`, like [here](https://github.com/KillTheMule/nvimpam/commit/195f1768182869f33628ea16c28e27d20f8dfa9e#diff-4dc3a6ee0271e46bd91a05886a0be83aL263).
There are a lot of things going on. I have good knowledge about privacy , dark web, history of software and its influence on everyone, baremetal with regards to gaming and high end applications, user needs and wants, bit of Linux, modding phones and maybe a few more. I am yet to learn Rust, but I can do it. Can sit in front of a computer for 8+ hours without any physical issues since childhood. Currently a simpler project has been selected by my peers. They made me a part of their group at the last moment. Currently getting it to work will be the major part. Grades can come in later. It can be a good testing ground for my Rust skills as I am responsible for making all the data mining algorithms.
TY im new to reddit. sorry! 
The RefCell overhead is the UnsafeCell overhead, which is intentional, because the compiler can't make assumptions about aliasing and caching if there is more than one mutable reference. So when you need to make a ref into ref mut you must use UnsafeCell so the compiler doesn't optimize. So removing the overhead from RefCell would just disable optimizations the rust compiler can generally do...
You could define your own opaque return type that defers the expensive computation unless the user asks for a result. Requesting the option out of the return value would be cheap.
For additional ideas, for Utah Rust: - [specific presentations we are considering](https://github.com/utah-rust/utah-rust.github.io/issues?q=is%3Aissue+is%3Aopen+label%3Aidea-presentation) - [categories of presentations we are considering](https://github.com/utah-rust/utah-rust.github.io/projects)
You might want to have a look at https://web.stanford.edu/class/cs140e/
`channel` is unbounded, if information from it is being read slower then it is written its buffer will grow indefinitely. 
why is it expensive to change one value? b.set(2); is just doing a single integer assignment.
I meant when your value is bigger like 4x4 Matrix or something
&gt; is there any reason for this? iteration invalidation
The only community where this has worked well has been Julia. Their projects almost always end in .jl 
since cells don't have any overhead, a 4x4 matrix of them behaves the same as a raw float matrix
Hmm, this is a very interesting idea, I'll definitely consider it, thank you. Hope it's not an overengineering)
Since the rules hold over memory locations, I would suspect a borrow of `S` is equivalent to individual borrows of all of its elements (plus padding or such, to the extent to which that matters).
That's normal. It'll need to compile LLVM the first time you start it
I don't get it, how would you get the backtrace later?
Probably not the type of "testing" tool you meant, but I have a small [HIBP CLI utility](https://github.com/brycx/checkpwn) that can be used for reconnaissance/OSINT. Don't know how much there is to contribute though... Why not make a OSINT collection library?
It works better with the 8400k's hyperthreading and six cores, which would give it more parallelism, but he doesn't have that.
This is an incredible post and I am both humbled and utterly impressed. Thanks for taking the time to write it. Long posts like these can be very difficult to mentally justify sometimes.
1. To get debugging symbols in release: `env RUSTFLAGS=-g cargo build --release` 2. To record in perf: `sudo perf record -g -- target/release/${BIN} ${ARGS}...` 3. Either `sudo perf report` or `sudo perf report --hierarchy`
How can i lend part of a vec, without chaning the indices? Imagine i have a vector of length 10. I could borrow a slice 3..7 (for example), but i then index that slice with 0 to 3. I want instead to give a function access to the slice 3..7 of a vec v, which they would still access as v[3],v[4],v[5],v[6], but force an error (out of bounds?) If they accessed outside the allowed range.
Perhaps you could write a little wrapper struct that implements `std::ops::Index` and does this translation for you.
1. Thanks :) 2. + 3. Sorry, I didn't phrase that clearly. I know how to operate perf, I just could not get anything really usefull out of the report. But I didn't know about `--hierarchy`, I'll check that out.
Woot. Cya there! 
You‚Äôre probably looking for r/playrust
Very good point. Also, you should make sure to set `codegen-units = 0` to reduce bottlenecks
Ok, so it seems unless you had a way to store the information needed to construct a backtrace, etc. this method wouldn't work? Anyways, nice question!
Your link to "why pointers are complicated" is broken. It's: https://www.ralfj.de/blog/2018/08/07/2018-07-24-pointers-and-bytes It should be: https://www.ralfj.de/blog/2018/07/24/pointers-and-bytes.html I'm still in the middle of learning saf
&gt; Its like going through hoops in order to achieve something simple that should be built in somehow in the language, or at least its my opinion Considering that `Cell` is in `core` and is implemented using the magic intrinsic `UnsafeCell`, I don't see how much more "built in" it could get
Should I be worried that the first post I read is about booze? 
Yeah, they're kept in a closed state until the time of the announcement, looks like I missed it when flipping the switch to open. Fixed now, thanks.
Wdym?
I'm just teasing. You're on the wrong subreddit. Head over to /r/playrust.
Your comment is missing a link 
But there is no way to be sure that the answer is _no_.
No those lifetime are for things external to T. 'parent is for things not in T that parent might have a reference to not for parent itself. 'parent: 'child just means that the things parent may reference, last at least as long as things child may reference. You could pull the work out of Child::drop and put it into T::drop. But since this is for FFI, then you'll probably want ManuallyDrop. https://doc.rust-lang.org/std/mem/union.ManuallyDrop.html
Cool idea. Thank you!
For an example of what Im trying to achieve look at `middle_man1` in the code I posted. It has ownership of `value` (via a box) and it wants to pass that ownership to `middle_man2`. It can't pass the box because `middle_man2` doesn't take a box, and it can't copy `value` because `value` is unsized, so copy elison doesn't apply here anyway. It's kind of an arbitrary situation, but it's based on real code I have and the point is there should be a way to pass ownership of something without prior agreement on any allocation mechanism (box/stack). The callee takes ownership of the object (and must drop/move it), and the caller keeps ownership of the memory (and must free it without dropping the object).
Thank you!
Thanks for the heads up!
If you have a link for this I‚Äôd love to see it 
That's exactly what I'm looking for, thanks!
I'm on Firefox on Linux (KDE Plasma) using a Dark Theme and the text for the short answer questions is white on white. It seems like the CSS is hard-coded to use a white background but use the theme's fg color. Made the short answer questions difficult. 
For the German survey: One question was untranslated (forgot to note which one). And on the page "Rust √ñkosystem" the translation of one word seems misleading, if not completely wrong. It seems like "critical" was translated as "kritisch". "unabdingbar" would be a much better word here, as "kritisch" has more the meaning of "troublesome" in German. (Don't know if this is the right place for this, or who I should contact about this.)
[https://github.com/rust-lang/rfcs/issues/998](https://github.com/rust-lang/rfcs/issues/998)
Well, It's intended to be used for pretty much everything C and C++ are currently used for, but I would use it for so much more, since cargo makes it so easy to work with rust! Also Rust is safer in a lot of aspects (for example concurrency) than even high level virtualized languages (such as java and python). So I'm at the point now where I would use rust for pretty much everything except scripting/automation.
https://github.com/DenisKolodin/yew https://github.com/chinedufn/percy Those are the two I know of so far. I've only played with Yew, but it seems to work well enough.
Yeah I'm on the survey team this year so I'll bring it up! Thanks for letting us know!
There is always the stock's physical limit, so you can do it, for the second day...
cc /u/llogiq who did the translations
Interesting -- I've heard of Yew before. I wonder why these aren't listed in the Frameworks list on [Are We Web Yet](http://www.arewewebyet.org/topics/frameworks/) ..
Nothing useful in perf's report? Do you have `-Cforce-frame-pointers=yes` in your `RUSTFLAGS`? If you have debug info, you can also use `perf record -g --call-graph dwarf`, but I've heard asking perf to use debug info can cause erroneous results.
Warp isn't on there either. Just looks like it's outdated.
Thank you!
I missed that RFC, so that means that ManuallyDrop is mainly for FFI when the field order can't be controlled?
This subreddit is for the rust programming language, you want /r/playrust for the game.
Very kind. That you. 
WebAssembly, at least wasm32-unknown-unknown and wasm-bindgen side of things, is immature but developing at an extraordinary pace. I wouldn't be surprised if people are building compelling frontend applications with rust this time next year. I'm using wasm to build the bulk of my current project, but I drop to traditional JS+React for anything UI-related. Can't speak to stdweb or enscripten-based workflows.
Possibly now more of historical than practical significance with how much Rust has changed since then, but U.Va. had an Operating Systems class using Rust in 2014: https://www.rust-class.org/
I think it's meant to be more like GCC version x.y.z supporting C++11, C++03, C++98 and so on. Compiler version number and language version numbers are separate, and a single compiler can support several language versions.
I usually look at some of the code by BurntSushi, a.k.a. Andrew Gallant. He has some really nice blog posts on exception handling and other Rust features in his blog on [https://burntsushi.net/](https://burntsushi.net/). His github repo has a couple of nice and simple crates like [https://github.com/BurntSushi/rust-csv](https://github.com/BurntSushi/rust-csv), and [https://github.com/BurntSushi/xsv](https://github.com/BurntSushi/xsv) . The packages are not too big, so you don't have to spend a lot of time hunting around through files hunting for function calls. Good luck.
That's when you'd normally start using RefCell.
vist the website for all mods and more info i4ani.com
I believe that est31 was/is trying to get gimli's addr2line into rustc for symbolication of stack traces.
Thanks, I'll look into it.
Use UnsafeCell then and hope you do the right thing...
&gt; That makes sense thanks, but to simple types like numbers or simple structs where you dont need drop and dont care about replaced, this is very nice thing to have. Aka most of the stuff are simple, like vectors, numbers, strings and etc.. You can still cause problems very similar /u/thiez's example above, with just a vector of ints: let mut my_vec = vec![1, 2, 3, 4]; let int_ref = &amp;my_vec[0]; // This is illegal. my_vec.push(5); In that example, the illegal line might cause `my_vec` to reallocate, which would mean `my_ref` is a dangling pointer. Here we don't even have aliasing `&amp;mut`'s. Just a single `&amp;mut` aliasing with a `&amp;` is enough to break the world. Now suppose we get even more restrictive and say, "Ok ok, clearly the problem is that `Vec` is a complex structure using heap memory. But surely we could be allowed to alias an `&amp;mut` in a simple slice of ints, right?" Unfortunately, no: let mut mybytes = *b"hello world"; let mystring = std::str::from_utf8(&amp;mybytes[..]).unwrap(); // This is illegal. mybytes[0] = 0xff; The `from_utf8` call succeeds and produces an `&amp;str`, because `mybytes` is valid UTF-8 at the time. But then on the following line -- which could be possible if aliasing `&amp;mut`'s were a thing -- we make the first byte invalid. Now `mystring` contains invalid UTF-8, even though it's supposed to be statically guaranteed to be valid! Unsafe code in various modules might be relying on the validity of the encoding to e.g. skip bounds checks when reading characters near the end of the string, and so producing a string like this can lead to UB when combined with other unsafe (but correct!) code.
I think it's something like rustup component remove self? 
In your user folder ("C://User/&lt;YourUser&gt;") there should be a folder called something like .rustup or maybe .multirust. Look through that folder for toolchains or the like, and delete it. I think that's where its found. I'm at work at the moment, so I can't check. 
As soon as IDEA-Rust plugin was installed on my PC, I understood that RLS works very bad: long time to rebuild after ctrl+S, goto works bad, autocomplete works bad. Looks like 1-2 devs on salary are doing much better than 100+ devs open-source community :)
Note that you might have to start your console through the "VS2017 x64 Native Tools Command Prompt" in order to have the VS build tools in your PATH.
It's not security focused, but [lorikeet](https://github.com/cetra3/lorikeet) is a rust based testing tool. You could use it to create security style tests.
`rustc` finds the location of `link` from the registry. I can't remember if `link` in `PATH` takes precedence, is a fallback, or is even used at all, but it is certainly not required to have `link` in `PATH`.
When you are on Windows you probably run the rustup installer. You can just run that again and select uninstall.
Oh great! I didn't realize that was the case. This is a lot more convenient.
IntelliJ Rust has a significant number of volunteer contributions as well, and that helps tremendously! I'd even say that (judging by the number of commits by non-paid contributors) IntelliJ received *more* contributions than RLS. However, I don't think that the difference is explained by the number of work hours paid for (some people working on RLS get money as well). Rather, its a question of differences in the architecture. With IntelliJ, we already had the best IDE architecture with deep support for doing things incrementally and on demand, so the only thing we needed to do was to write a Rust compiler fronted in Kotlin. With RLS, the opposite was true: the IDE side of things was a clean slate, but there was an existing compiler available. Unfortunately, the "everything on demand" architecture of IDE has never found its way into RLS. The philosophy seems to be "let's link all existing command line tools into one binary", so today RLS links rustc, rustfmt, two versions of Cargo, clippy and racer, but still uses compiler as a batch processor.
\[removed\]
The idea is really to welcome all skill-levels, and you could learn Rust as you go. I off-course understand if you want to get better acquainted with Rust in other ways. Personally, my first line of Rust was a commit to Servo https://github.com/servo/servo/pull/13412 :)
Uh no, didn't know about that, thanks. It's not that there was NOTHING usefull in there, but I just could not go down the stack to see what's happening, and the numbers were strange.. I manage to fix the valgrind issue, and it immediately gave me much more, just sort of the way I expected it :)
I've been experimenting with wasm32-unknown-unknown and it works just fine with super standard `cargo build --target=wasm32-unknown-unknown`. However it is required you write the exposed APIs specifically to target wasm, you cannot just accept stuff like slices, or Vecs or Strings, neither can you return them. But wasm does work.
What are the implications of this? Will rls in vscode never have these features, or it will take a longer time to build up the backend?
It's hard to say for sure, but I believe that current RLS architecture indeed makes adding IDE features costlier in terms of work required, and that the end result is less robust and has worse worst-case latency. 
When I lack ideas I plow through problems on Project Euler. 
It wasn't standard implementation of weak pointers, though. In Rust, it'd be RwLock&lt;Arc&lt;T&gt;&gt; put into static variable. That RwLock can be replaced by atomic.
The model works on the level of individual memory accesses. Data members are only relevant to compute the offsets and sizes at which these accesses happen, so that is not a concern any more. I probably did not make this point clear enough though, so thanks for the question. Your code is probably legal because when you are creating `t`, that freezes the entire memory covered by the reference (`t` has type `&amp;S`, so this covers `mem::size_of::&lt;S&gt;` bytes). Then you are assigning to `a`, which unfreezes the first 4 bytes. Then you are using `t` to read the last 4 bytes, which checks if they are still frozen -- which they are, so you are good. I am saying "probably" because there might be extra rules around expressions like `t.b`, where maybe `t` as a whole gets activated even though you just need a part of that place (lvalue). There were plans to change MIR's syntax to only allow a single projection; that would make a variant of this case with `t.b.f` pretty interesting to look at -- it would desugar to `TMP = t.b; TMP.f`, and it seems like that *should* activate `t.b`? So, these questions are not entirely settled yet. However, if the function returned `t`, that would be considered "data leaving the function" and hence trigger an activation, which is UB. This is a trade-off between allowing more code and allowing more optimizations.
Thanks, I fixed that typo!
Thanks, fixed!
There are still tons of things outside of the memory model -- like evaluation order, or which memory accesses a certain expression actually performs when it is executed. But everything that is related to memory *is* part of the memory model. Hence the name. ;) Language semantics can often be factored into two parts, where one part translates the source program into a bunch of memory events ("write value `v` to address `x`", "read from address `y`") -- this defines evaluation order and how addresses are computed and so on -- and then another part defines how memory reacts to those events. This can be formalized e.g. in a process calculus (write events become sent messages, read events become received messages).
In general, we need a lot of translation services and even have a team (i18n), so please watch this space for more announcements :).
There is also domafic https://github.com/cramertj/domafic-rs/blob/master/README.md I used that for an offline app about a year ago. I failed to package it with Cordova back then, possibly because of emscripten. But I got it working as a progressive web app by using a service worker that doesn't really do anything. 
&gt; Rust 2015 is not discontinued. a new major version doesn't say that. the only difference between 2018 edition and rust 2.0 seems to be the name. thats all. theirs a new, mostly source backwards compatible version, and the previous version still maintained. call it what you like, you just have and maintain both rust 1.x and 2.x, backporting to 1.x. and either way, at some point they'll have to decide to stop backporting features. can't really keep doing that until the end of time. upgrading to rust 2.0 is also the same as opting into rust 2018. &gt; 1) it implied major breaking changes (that is after all what the first number in the triplet stands for) To quote semver.org, `MAJOR version when you make incompatible API changes,` is 2018 edition making an incompatible API change? Yes, source level. increase major. rust is violating semver.
Aren't you asking twice about other programming languages?
Thanks for pointing this out. I've added the below note to the article: "Sine we're using an unbounded channel, the buffer of that channel could grow without bounds if the producer is much faster in producing than the consumer is in consuming values from the channel. However, this isn't quite a 'resource leak', since when the receiver is dropped, the producer will certainly stop producing, and any "left-overs" in the internal buffer will be dropped as well. It could however be a problem if the generation is very expensive in itself, and see the "[note from a reader on reddit](https://www.reddit.com/r/rust/comments/95at09/rust_concurrency_patterns_feedback_wanted/e3s8r20/)" below for a bit more background on that."
In my experience, Packt has the lowest standards of any technical publisher. I'd wait for any other publisher to cover the topic, myself...
&gt; Would it be possible to extract everything that intellij-rust does into a separate binary that implements the language server features? Unlikely :-) IntelliJ has its own architectural problems as well. By default, everything is pretty tightly coupled to the IDE itself. It is possible to make a standalone JAR with analysis machinery, but that requires explicit effort. As for other editors are not vim, it is true! I think though, that editors are like programming languages: you could write Haskellesque code in Rust, but its usually less painful to stick with Rust idioms. The same is with IDEs: you can try to pretend that IntelliJ is Emacs (oh, and I **really** know what I am talking about here :) ), but in the end its more productive to use IntelliJ as IntelliJ (and carry over only the best bits of Emacs :D ). So, I'll try to give you my specific workflows for issues you've mentioned :) &gt; Tab pages So, this is about the ability to have several viewports into a single file? IntelliJ for sure has this: you can open a single file in different editor tabs, in different editor splits or in different windows. And I've spent a lot of time trying to mimic Emacs workflows (whose buffer management is **glorious**) and in the end ended up with a completely opposite workflow. Now, I don't use editor tabs (it's possible to disable them in settings) and editor splits, and only occasionally use more than one window. Instead, I make heavy use of IntelliJ navigation features ([1](https://www.jetbrains.com/help/idea/navigating-to-class-file-or-symbol-by-name.html), [2](https://www.jetbrains.com/help/idea/navigating-with-structure-views.html) and [3](https://www.jetbrains.com/help/idea/navigating-to-recent-file.html) mainly). With emacs, my workflow was "I need to look at X, and it is in buffer Y, so let's open that". In IDEA, I just open `X` directly (or just use [quick definition](https://www.jetbrains.com/help/idea/discover-intellij-idea.html#QuickPopups)). For navigating inside a singe file (which is what view ports give you), I can't emphasize `Ctrl+F12` ([structure view](https://www.jetbrains.com/help/idea/navigating-with-structure-views.html)) enough: this is a tree overview of the file structure with fuzzy-search build-in. &gt; Per window history If this is about navigation history (a-la go back/forward in browsers), I personally find IntelliJ lacking in this department [as well](https://youtrack.jetbrains.com/issue/IDEA-190569) :( Instead of going back, I usually just use some navigation shortcut. This probably not about *editing* history, but I'd like to point out [local history](https://www.jetbrains.com/help/idea/local-history.html) just in case, because it is really awesome: you never loose the work due to `git reset --hard` or unfortunate `rm -rf` (well, unless its [really unfortunate](https://github.com/matklad/config/commit/ee12c06ca6bd677b01ddf05a75a3aee807663c08)). &gt; Searches with separated keywords with spaces Yup, [wish for that as well](https://youtrack.jetbrains.com/issue/IDEA-147367). However, some filtering is possible. For example, if you search for `vulkan/lib.rs`, IDEA will only show `lib.rs` which have `vulkan` in their path. You won't be able to append `vulkan` after `lib.rs`, you'll need to go to the beginning of search bar first. Similarly, when looking for symbols, you can filter by modules like `std::Mutex` vs `pl::Mutex`. &gt;Ability to only search for structs, impl, function, traits, and not every symbol. In vim I just use ripgrep for this, which works reasonably well. So, IDEA has two shortcuts, "Navigate to Symbol" and "Navigate to Class". The first one gives all symbols, the second one only type-like things (i.e structs, enums, traits, but not functions or fields). Usually, the second one is enough to narrow down the search, and additional filtering by "is struct?", "is trait?" is not required, even for large projects. Additionally another useful filtering dimension that IDEA has is "you project/libraries". By default, symbols are looked for in the current project, but if you press the same shortcut the second time (or if there are zero occurrences), the symbols across all dependencies are searched for. 
This Firefox extension has fixed all of those things for me: https://addons.mozilla.org/en-US/firefox/addon/text-contrast-for-dark-themes
Oh, and I've almost forgot, multiple cursors + extend selection ([docs](https://www.jetbrains.com/help/idea/using-code-editor.html#editor_code_selection)) beat vim's text objects hands down :D
Thank you, and yes I just noticed that I'm in the wrong subreddit haha. New to the game, so yeah. Thanks, though!
This does not answer your question, but since you mentioned you are new to Rust. A plain slice of bytes (\`&amp;\[u8\]\`) does implement \`Read\`. A \`&amp;str\` also dereferences implicitly to a \`u8\`. This usually allows me to write test without a dedicated mock. Not to say, there are no use cases for one, but I just wanted you to be aware of this. 
Thanks. I enjoy reading tech books, I've read the two most popular books, and the nominicon (sp?), Was wondering if anything else was worth reading.
Firefox uses the desktop background colour and the CSS foreground colour. It was a compromise to make everyone equally miserable.
&gt; avez-vous d√©j√† contribu√© √† une cagette (crate) Are you for real?!
For those of us who don't speak French -- is there a problem with that translation?
I read `The Book (2018 Edition)`, but now I don't know how to get started, because I feel like I do not know the Standard Library, yet and can't say what I could do. Is there any convenient way to explore the std without crawling https://doc.rust-lang.org/stable/std/ ?
The fact that there's a translation is in itself the problem (well, it's not really a problem, it's just really funny). In French (in France at at least, French Canadians may differ) we don't usually translate technical terms like this. Or when we do, we usually pick a specific word which isn't a direct translation of the common sens of the original English word. For instance, a ‚Äúthumbnail‚Äù is translated to ¬´miniature¬ª and not to ¬´![ongle de pouce](https://upload.wikimedia.org/wikipedia/commons/b/b9/Nail%28thumb%29.jpg)¬ª. I'm sure that no French Rust developers ever use the word ¬´cagette¬ª to talk about a ‚Äúcrate‚Äù (well, except ‚àí maybe ‚àí the guy who wrote this translation) and I suspect that most of us didn't even know what a ‚Äúcrate‚Äù mean outside of the Rust context.
See https://github.com/rust-lang/rfcs/pull/1892. Basically, calling `mem::unitialized::&lt;T&gt;` is instant UB unless for `T` any bit pattern is valid. This is probably easiest to understand with uninhabited types. If you have an `enum Void {}` and then have `let x = mem::unitialized::&lt;Void&gt;()`, compiler is free to assume that the code is unreachable, because there can't be an instance of `Void` (I've actually hit this bug for real: https://github.com/crossbeam-rs/crossbeam-channel/issues/76). Similarly to `Void`, `mem::unitialized::&lt;bool&gt;()` is also instant UB: compiler assumes that `bool` is always either `1` or `0`.
I want to take time with it.
Also, depending on who you ask, even if for a type all bit patterns are valid, creating a reference to uninitialized memory is probably also instant UB: let a: (i32, i32) = (0, mem::uninitialized); &amp;a; // UB Since methods implicitly create `&amp;self`/`&amp;mut self`, if a part of an object is uninitialiazed, any `x.foo()` method call is probably instant UB as well (the only good ones are inherent method calls `x::foo`). 
There was an MSI installer for older versions of rust that has that option, but when I rerun rustup it just gives me the same install options and no uninstall one 
To be precise, Vulkan accepts SPIR-V only and shaders are compiled AOT and the SPIR-V spec is open, so any language can compile to it. However, the most widely used source language is GLSL which has all of the caveats you mention.
Yup, you've got it about right. We've gone through a number of front ends on the project. We originally had: 1. Dart VM: A parser, compiler, and JIT written in C++. 2. Dart2js: A whole-program optimizing parser and compiler to JavaScript written in Dart. 3. Analyzer: A parser and static analyzer written in Dart for IDE support. 4. Dart Dev Compiler: A fast, modular compiler to JavaScript. It used the same front end as analyzer with its own code generation back end. That's three separate front ends, which is a lot to maintain. With the transition to Dart 2, we are moving to: 1. A common front end written in Dart. It parses, analyzes, and translates to a lower-level "kernel" representation. 2. Dart VM: Uses the common front end and then compiles kernel to native code. 3. Dart2js: Uses the common front end, does whole program optimization on the kernel, and then outputs JS. 4. Analyzer: Uses the common front end and then serves analysis results for IDEs. 5. Dart Dev Compiler: Uses the common front end with a simple back end that converts kernel to JS.
Rust's standard library is actually pretty small compared to other languages, because most of the "batteries" are provided in crates. I'd say just jump in: most of what's important is already in the book, and you'll quickly pick up on what isn't if you keep an eye on this subreddit and other places like it.
I don't know. Can you provide a example? But to give some example of what I'm doing, I'm creating a mock for Read/Write to avoid using Stdin e Stdout when testing. 
I'm kinda really new here. How can I do this conversion?
Yeah, I won't look inside the buffer. I need this mock to replace Stdin.
Yeah, I suppose I should have been more clear about that. In practice, though, I don't think it's possible to compile Rust to SPIR-V yet, aside from rlsl.
Indeed that's very true. It tends to be that this kind of knowledge is passed through the old apprentice way and then people don't have time anymore to describe all those tasks or to write books. I'm not an expert myself but I'm learning and trying to write down as much as I can! 
That sounds like a great idea. Let's do it! :)
Comparing OpenCL with CUDA is difficult. When people talk about CUDA they usually mean the high level API that everybody uses, but CUDA also has a low level API that is used by the high level API. OpenCL on the other side resembles more the low level API of CUDA. The high level equivalent for OpenCL is SYCL which is rather unknown. In the end what Rust needs is a SYCL-equivalent that uses OpenCL together with SPIR/SPIR-V binaries. 
this deserves a blog post!
My mistake. The documentation I've seen - blog posts, etc. seem to focus on using rlsl for graphics.
No problem, I am not doing a good job of advertising it at the moment. I want to polish it up first.
We don't really need any of that. Doing something like this: let mut stat; let result = libc::fstat(fd, *mut stat); // create raw pointer to stat would be enough. 
I'm working on a Rust game+engine with a Cuda path tracer as renderer. My approach is to compile the Cuda tracer into a lib and statically link it with my Rust code, as if it were C code. So far it has worked great, it even supports seamlessly stepping between Rust and (host) Cuda code when debugging. I debug the device Cuda code by having a separate Cuda project with a small testbed, that exercises the path tracer lib. That way, I can utilize Nsight's unparalleled (no pun intended) visual Cuda debugger. 
For those that, like me, had no idea what this crate actually did: &gt;This crate can parse a C++ ‚Äúmangled‚Äù linker symbol name into a Rust value describing what the name refers to: a variable, a function, a virtual table, etc. The description type implements Display, producing human-readable text describing the mangled name. Debuggers and profilers can use this crate to provide more meaningful output.
Overall, this is a nice model. I'm concerned about whether the concept of barriers might put too much emphasis on function boundaries. In the post, the `*x = 42` can be moved below the call because of a barrier at the function boundary: ```rust fn demo5(x: &amp;mut i32, y: usize) { *x = 42; foo(y); } ``` However, this doesn't work for the `*x = 42` in code like this: ```rust fn demo5_variant() { // ... arbitrary code here { let x: &amp;mut i32 = ...; let y: usize = ...; *x = 42; foo(y); } // ... arbitrary code here } ``` This means that manual inlining in the source code changes which optimizations might be valid. It also means that while this proposal is well-suited for LLVM's `noalias` argument attribute, it wouldn't permit the generation of LLVM's scoped noalias metadata from the frontend, and it might restrict the options for hypothetical alternative optimizers.
Fair enough, In your example it's still tricky, when can the compiler assuming stat is now initialized? Eg. let mut stat; let _ = *mut stat; // Is it now safe to access stat? When will it be safe?
[This](https://github.com/rust-lang/rust/issues/51623) might also interest you.
&gt; The high level equivalent for OpenCL is SYCL which is rather unknown More like unsupported. Neither GCC, nor Clang, nor MSVC, nor pretty much any other C++ compiler supports SYCL. There is a single SYCL compiler, and it is both incomplete and proprietary and based on an old clang version (so no C++17 goodies).
But, but, but cargo is made up of crates. The metaphor.
While I did personally translate _some_ of the French questions I avoided anything with technical terms so this translation is done by a couple Rustaceans who do speak French natively. I have seen French Rustaceans use Rouille to talk about Rust before (but it's confusing since Rouille is also a Rust crate) so this doesn't feel like a major stretch.
Yes, though you may want to hurry. Can you DM me an email?
Very true. Frankly it would be nice to get rid of `as` for casting anything except pointers.
Absolutely, that would be lovely to see.
I have been improving on a new long division algorithm and updating the fuzz testing for it against Rust's implementation for division when I discovered that `i128::MIN / -1` panics both with and without debug assertions enabled. I have always expected that without debug assertions on, the only kind of arithmetic overflow that will panic is division by zero. Every other kind of overflow should have a defined result. Truncating twos complement, my algorithm, and even the Windows calculator all agree with the result `i128::MIN`. Do most CPUs throw unavoidable exceptions on this or is an assertion being wasted on this case? Also, I feel like there is some document on overflows and casting related stuff that I have missed or that should exist.
I wasn't sure how to answer the first question. I haven't used Rust in a while, but I would if I found the right opportunity. I put "yes", but I could have just as easily written "No but I used to".
Actually, the most widely used language sourcing SPIR-V is HLSL, by *far*.
It is in the book! Right at the start.
Can you use `core` in those shaders? Do you have examples ?
The uninstall command is, the toolchain switch isnt as far as I can see. Either way, it should be in rustup-init or on the install page so you cant miss it imo 
Nice analysis! IMHO Clippy is overreaching here. "If you rewrote this code you would have a problem" doesn't seem all that helpful to me. It's not like the types in question are taken from a typename or something: they are literally hardcoded into the program. As long as Rust supports `as` without checks, I think this lint should default to off, as the original code is perfectly safe and reasonably idiomatic.
You can even use `std`, I just implement my own version of the `std` library based on core, with **many** things that are just not exposed. For example `Vec` will never be usable in `rlsl`, so it will just fail to compile if you use it. In the future I might also need to rewrite `core` because some things have some weird special implementation, so that llvm produces the best output, but it also breaks `rlsl`. For example IIRC Iterator::next on ranges uses ptr math. I haven't yet decided how I handle those things. Currently I just wrap ranges in a new type and implement iterators on the wrapper. There is some effort in unifying `std` and `core` with a lot of `cfg` attributes, but I don't know when it will be usable.
If every single bit pattern in 4 bytes is a valid `i32`, I don't see how using initialized memory to make one is UB. No matter what bits were in the stack there should be valid, right?
&gt;most of us didn't even know what a ‚Äúcrate‚Äù mean outside of the Rust context. It's a woody baguette, obviously. 
Got it! Ty.
IMO that new list is a bit too verbose. E.g. is "examples can now be multi file" really a major change? Also, there are two entries about the `?` operator. They should be unified.
https://github.com/rust-lang/rfcs/pull/2484 proposes adding more explicitly-named APIs for other conversions such as truncation. (My opinion is that there is a lot of design space to explore and I don‚Äôt know yet what would be a better design.)
Could you implement it for `Deref` or `AsRef` or something more generally?
Thanks for the explanation! I understand better now. &gt; This is a trade-off between allowing more code and allowing more optimizations. Indeed. It might be possible to start off with a conservative model (more optimizations allowed), and relax it only as necessary... but overall I think I'd prefer as simple a model as possible. Bugs occur when the mental model does not match the reality, and even automatic run-time enforcement might not catch all violations (since it depends on the quality of test coverage). 
WebAssembly can't manipulate the DOM directly. The frameworks listed in other posts go through a JS layer to achieve this. It's possible but slower than using only JavaScript. Once WebAssembly gets direct DOM access it will be faster than JavaScript because a lot of checking can fall away. At least I've read that somewhere.... :p Anyway, Rust isn't the only language attempting to get a slice of the SPA market. There is also [blazor](https://github.com/aspnet/Blazor) by Microsoft that builds on .Net, as well as other frameworks. But Blazor is i think the most famous one.
That's odd, when I try that out in the Playground it wraps around just fine in release mode: https://play.rust-lang.org/?gist=2439b2c05cfe7e152c3cd405f9caba45&amp;version=stable&amp;mode=release&amp;edition=2015
I'll agree to that.
I'm in the same learning boat - I've never touched toolchains or Buildroot before but it's suddenly become relevant at my work to understand how these things work so I'm reading through "Mastering Embedded Linux - Second Edition" to get a better idea of it all. That doesn't help me too much with going from "I have a toolchain that cross-compiles for this one platform" to "I have Rust built using that toolchain and it's building compatible binaries for that platform". Let me know if you think I could contribute :)
Any way you could post an example of how this works? This would be a good solution in my mind. I don't mind writing a bit of cuda c if I can call it from rust easily. 
&gt; Recently, I was trying out clippy ‚Äî a **new** linting and static analysis tool for Rust Clippy is at least a couple years old, I would not qualify it as new any longer. --- As for the lint, I'd disable it. Right now the code is fine; *if* it changes, then let a lint warn about the issue.
I wrote an unreleased CUDA implementation for Rust, using the low-level CUDA API when working on my cryptocurrency miner. Kernels are written in CUDA C, compiled to PTX, and then loaded and used in Rust. I mapper multi-GPU execution to a thread pool and custom futures executor, allowing the sequencing of various GPU and network actions. Seeing this post makes me want to polish it up and release it.
On Linux, you could simply apply the `strip` command to the executable. Not sure about Windows. I will also say most companies produce their release binaries in a CI system, and one of the least significant benefits of doing it that way is there's no personally identifiable information on a CI system.
There is some more discussion here: https://github.com/rust-lang/rust/issues/38322 
That's the same thing as editions except more confusing because you're calling the two different concepts by the same name.
It seems like tower web (well, the example from the post and the middleware example I checked) could easily be implemented using filters from warp underneath - is that the current plan? This is more of a curiosity question.
That is roughly the route I am thinking. In practice, it might require changing the Filter trait a bit, or have Filter implement Resource. Once we start digging into the merge, we'll know more :)
This doesn't make sense to me. Maybe I don't fully understand the concept of UB, maybe my brain is stuck in C land. I can't figure out why this code has an issue: let a: u8 = unsafe { uninitialized() }; println!("{}", a); I understand that `uninitialized()` memory has unknown contents, and that for most types, very bad things could happen if you try and use the memory before initializing it. But because `u8` is valid for any bit pattern, _and_ it doesn't have anything like special destructors or external references, this code should be completely fine. Since `uninitialized()` is generic, it could result in UB if you used something other than `u8`, `i32`, etc, and so I understand that the compiler can't promise anything. But as the programmer, _I_ know that the value is already valid for the `u8`. That's why the function is marked as `unsafe`, because manual verification is required in order to avoid UB. Unless I misunderstand what `uninitialized()` does? What you are saying might make sense if `uninitialized()` doesn't actually promise to provide a region of uninitialized memory, but in fact doesn't even promise to provide _any_ memory until you attempt to write to it (or rather the compiler would do this).
You should! Or at least write a post about it somewhere. Yeah, in the long term I'd like to try to map async GPU execution into the futures/async-await model. Rust provides a lot of tools (iterators, futures, etc.) that C doesn't, so I think we can build a nicer GPGPU API on top of CUDA if we can get the compiler to work.
&gt; You can even use std, I just implement my own version of the std library based on core, with many things that are just not exposed. For example Vec will never be usable in rlsl, so it will just fail to compile if you use it. What's left in `std` over core; you obviously don't have access to `std::os`, and if you can't have `Vec`, `std::collections` are right out the window? Is it just `core` + `Box`?
I agree with Clippy here. We should strive for "fearless refactoring". Writing our code such that it's possible for someone who doesn't know the codebase to make changes and get compiler errors if they've done something wrong. (It's important to note here that "someone who doesn't know the codebase" could also be _yourself_ a few months from now.) In every way practical we should make that a goal. Using Clippy's suggestion takes a step in that direction. It's a fairly common thing for types to change, especially get larger, in the future. And while the example shown in the article is simple, real codebases will be large and types will infiltrate several layers deep. I guarantee a big Rust project is going to experience a u16-&gt;u32 at some point, and a committer and reviewers are going to miss at least one or two places where that type gets used.
https://github.com/brson/stdx is what you looking for 
I was not focusing so much on the how to truncate, and more on the warn about correct *in case it changes*. Any single line of code may be wrong if something changes; I fail to see any value in such warnings.
But how to detect truncating uses of `as` in current code? &gt; Interestingly, clippy doesn‚Äôt complain if you do u32 -&gt; u16 via as ‚Äî it assumes you know what you‚Äôre doing.
I would also prefer to remove absolute paths; not so much for privacy, but rather for *reproducibility*. I wish the paths simply followed the `&lt;crate&gt;/&lt;version&gt;/&lt;relative-path&gt;` pattern; so that no matter where a crate is hosted, the compiled binary is identical.
I dont understand how it can become "silently" lossy. In that example you need to change the function parameter from u8 to u32, that not silent 
The `clippy_pedantic` lint set contains the [`cast_possible_truncation`](https://rust-lang-nursery.github.io/rust-clippy/master/index.html#cast_possible_truncation) lint, which warns about this.
&gt; How many of your dependencies are 1.0 or above? Is that direct or also including transitive dependencies?
This is best
This kind of refactoring change can happen from afar though. Suppose there was a `struct Foo { bar: u8 }`, and in one place you had a `foo.bar as u16`. Then somebody decides that it needs to now be `bar: u32`, and doesn't notice that the `as u16` is now lossy.
That really does not sound right to my ears. Rust is arguably closer to Haskell than Python: - Both are statically typed with type inference (as opposed to dynamically typed Python) - Haskell has typeclasses, Rust has traits, which are pretty similar, whereas Python has duck-typing and class-based inheritance. Of course you could argue that Python and Haskell share traits (no pun intended ;-)) that Rust lacks, like a runtime including a GC, or providing exceptions as a language feature (though Haskell code often uses return types for communicating errors, like Rust). I however think these are comparatively minor to the type system disparity.
Ok you are right. I tought the compiler would warn you if try to cast u32 to u16 
Using a value that hasn't been initialized is still technically UB even if the bitpattern in that region of memory happens to be a valid value of `T`
That‚Äôs UB. The docs are wrong. That‚Äôs how tricky uninitialized is.
It is explained in the comments in the example code you quoted: let mut data: [Vec&lt;u32&gt;; 1000]; // It's ok to mutably iterate the data, since this // doesn't involve reading it at all. // (ptr and len are statically known for arrays) for elem in &amp;mut data[..] {
You can use the `--remap-path-prefix` flag to rustc to adjust those strings: --remap-path-prefix FROM=TO Remap source names in all output (compiler messages and output files)
Did you notice that `elem` is also a reference to uninitializied memory? And it is not of array type, so your explanation doesn't fit, sorry.
I think it is valid to initialize the memory with a write-only method, but technically the assignment should be done with `ptr::write` rather than `=`
This info is from verbal conversations with members of SPIR-V working group. See also - https://github.com/Microsoft/DirectXShaderCompiler/issues/216
Did you install the rustup component? Or just `cargo install clippy`? I think the rustup way is the new officially supported one.
&gt; Basically, calling `mem::unitialized::&lt;T&gt;` is instant UB unless for `T` any bit pattern is valid. Fun fact - if this is true (and I'm getting conflicting answers depending on who/where I ask; e.g. the [docs](https://doc.rust-lang.org/std/mem/fn.uninitialized.html) imply that it's only UB if it's accessed) then this safe Rust code is UB: use std::collections::HashMap; fn main() { let mut map: HashMap&lt; (), &amp;u32 &gt; = HashMap::new(); map.insert( (), &amp;123 ); for (_, v) in map.drain() { println!( "{}", v ); } } Why? Well, here's how the `Drain` iterator is defined: impl&lt;'a, K, V&gt; Iterator for Drain&lt;'a, K, V&gt; { // ... #[inline] fn next(&amp;mut self) -&gt; Option&lt;(SafeHash, K, V)&gt; { self.iter.next().map(|raw| { unsafe { self.table.as_mut().size -= 1; let (k, v) = ptr::read(raw.pair()); (SafeHash { hash: ptr::replace(&amp;mut *raw.hash(), EMPTY_BUCKET) }, k, v) } }) } // ... } And here's `ptr::read`: #[inline] #[stable(feature = "rust1", since = "1.0.0")] pub unsafe fn read&lt;T&gt;(src: *const T) -&gt; T { let mut tmp: T = mem::uninitialized(); copy_nonoverlapping(src, &amp;mut tmp, 1); tmp } So the original code is effectively doing this: let (k, v): ((), &amp;'static u32) = mem::uninitialized(); And for `&amp;T` not every bit pattern is valid.
The resources that the others have posted are useful. My own 2 cents is [The OSDev Wiki](https://wiki.osdev.org/Main_Page) and its forums.
Attributes parsed from comments though... Good old idea from PHP world :)
&gt; let scary: T = unsafe { ::std::mem::zeroed() }; Never do this. Using `uninitialized`/`zeroed` with concrete types is iffy (but will *probably* be fine depending on the actual type, \**cough*\* at least until the next LLVM update \**cough*\*), however it's *definitely* not safe to use `mem::zeroed` with generics. For example, this Rust program will immediately segfault (at least on nightly): fn main() { let value: &amp;u8 = unsafe { ::std::mem::zeroed() }; } LLVM sees that you're trying to create a reference with a value of zero, and since rustc told it that references can never be zero it will maliciously replace it with the [ud2 instruction](https://c9x.me/x86/html/file_module_x86_id_318.html).
It makes sense for the lint to trigger *after* someone does that refactoring, since it would be a lossless cast then. Before, it's just noise. Warnings that aren't true teach you to ignore warnings.
I *think* it's so that the code compiles on stable. It could change to attributes when those stabilize.
Cool! I tried to take a look at the api docs, but the link doesn't seem to work right now. I've never published anything to crates.io, but should this doc link point to somewhere else? https://github.com/carllerche/tower-web/blob/master/Cargo.toml#L14 Also the api doc link in the readme doesn't lead anywhere yet.
I think what you're thinking of would an `unspecified()` function, a function that generates an arbitrary (valid) bit pattern for the given `T`. That's not how the compiler sees `uninitialized()`, the compiler sees the 'values' as litteral demons, it assumes it produces a value that litterally does not represent a valid value, _even if_ all possible bit patterns are valid, and will optimize (read: throw code away) any code which implies that such a value is interacted with. This is what people dread about _Undefined Behavior_, that's what they mean with nasal demons. That's how an uninitialized boolean can lead to either branch being taken, or none, or both at the same time. Or nasal demons to fly out of your nose. All because people want fast code, and the fastest code is the code the optimizer can throw away :)
https://internals.rust-lang.org/t/pre-rfc-unions-drop-types-and-manuallydrop/8025 swung the debate into a new direction.
That's the clang release notes, not llvm.
So I guess the question is - in practice is this implementation-defined or undefined behavior? Because I don't think it can be both. If it's not UB when it's in the stdlib then it's not going to be UB in the users' code. Of course, we may *pretend* that it is UB (as in - Rust as a language doesn't guarantee that it will work), but internally depend on it not being UB in practice (as in - LLVM will always treat it as valid and defined, even if we tell our own users otherwise). But that feels a little disingenuous, so I can't say that I'm a fan.
In fact, these release notes are for Clang. For LLVM, they're quite hidden, the [current release notes](https://llvm.org/docs/ReleaseNotes.html) are for the next version, 8.0.0, but the [old releases page](https://releases.llvm.org/) does not list 7.0.0, because it appears it still has not been publicly released. You need to go to the [pre-release website](http://prereleases.llvm.org) to find [them](http://prereleases.llvm.org/7.0.0/rc1/docs/ReleaseNotes.html). 
Say this in the PR?
Just in time - I'm building my HTTP server this upcoming weekend.
From the article: &gt; Tower Web opted to use doc comments as annotations to enable supporting stable Rust today. Once attribute macros land on the stable channel, Tower Web will switch to attribute macros.
Is it possible to use Tower without any macros? I try to avoid using macros when learning a new library because I find that compile errors are really hard to debug when you're using macros.
I got the inspiration from here: https://github.com/termoshtt/link_cuda_kernel/
&gt; I'm assuming this is for back-tracing, If that's the case, you can use [panic=abort](https://stackoverflow.com/a/47664111/489590), I imagine that might change the behavior.
Beat me to it :)
The hard requirement was that it worked on stable. I tried my best to avoid comments, but it was the only way. As soon as macros 1.2 lands on stable (\~3 mo I think?) I will switch over to that.
Yeah... I have no idea why [docs.rs](https://docs.rs) is failing to build :(
As someone writing Python 2 every day, I'm numb to putting semantic values in comments. At least there's a path forward for tower-web with attributes.
Tower itself requires no macros, but that isn't Tower Web. I hope to make the errors as friendly as possible. However, look at \[warp\]([http://github.com/seanmonstar/warp](http://github.com/seanmonstar/warp)) for an API that does not require macros. As mentioned in the post, Warp and Tower Web will be merging into one crate soonish.
Hah I would, but sadly I'm really a beginner, would make a lot of mistakes. Maybe we all could edit a wikibook or something like that here on Reddit or another website? That would be cool.
For what kinds of things is `rustup component add` intended, and for what is `cargo install`?
For tooling it should be rustup component add, for binaries it should be cargo install. But it is not always very clear...
`clippy-preview` is not available on some tier-2 platforms like `armv7` (raspberry pi), where `cargo install clippy` is the only choice for now.
I'm glad to hear they plan to switch eventually, but that argument makes no sense. You can't see the contents of a doc comment from a normal macro. The whole thing is getting passed to a macros 1.1 already. It'd legitimately be easier to implement using attributes today than a magic comment
Interesting, thanks. I'm trying to use Rust for my next project, and I'm trying to determine the extent of its use. I'm guessing it makes the most sense to just work with Rust in the back-end for now, which is not to say that Rust **can't** do front-end, but that using React or something just makes more sense right now.
I think that if you want to be on stable today, it is a reasonable choice. That said, attribute macros are coming to stable pretty soon; I‚Äôm using them in my (yet unreleased) toy framework/library. Once they‚Äôre stable, they are clearly the better call, IMHO.
I'm just confused by the choice since they're manually parsing either way. This is coming off way more attackey than I want it to though :\
Even PHP doesn't have to use many magic comments these days, they've become somewhat of a rarity thankfully ;)
Would you accept a PR that works on stable today and uses attribute syntax?
Sharing this here because I distinctly remember the moment when I started reading about atomics in Rust and had my brain melt. https://doc.rust-lang.org/nightly/nomicon/atomics.html The paper, I believe (haven't gotten far into it), presents a model that potentially avoids brain melting. The blog presents a nice introduction in case you don't want to jump into the paper directly.
It's is interesting how many thought this was a criticism; I think it is a neat trade-off.
Could you say more? I'm not sure that I'm following the solution.
Yup, they use a custom fork so it takes a long time for bugs to get fixed. Diesel hasn't built on docs.rs in months for the same reason
https://github.com/carllerche/tower-web/issues/56
If I remember correctly, `i128::MIN / -1` is undefined behaviour (UB) inside LLVM, so the Rust function has to check for it in order to avoid UB.
Who is primarily authoring tokio these days?
I'm trying to use a trait's associated constant inside a generic function, but it's not working and the error message isn't helping me, not even with `rustc --explain`. Am I missing something? trait Foo { const BAR: i32; } impl Foo for i32 { const BAR: i32 = 42; } fn baz&lt;F: Foo&gt;(a: F) { const BAR: i32 = F::BAR; println!("{}", BAR); } fn main() { baz(1i32); } 
Ok, I will setup doc uploading later tonight. 
&gt; If this is about navigation history (a-la go back/forward in browsers), I personally find IntelliJ lacking in this department as well :( Coming from VIM (tbh I still use it, I just use PyCharm atm for refactoring purposes), I'm very used to C-o and C-i for going back and forth between both definitions and just general navigation. I've bound navigate back/forward to Cmd-+ and Cmd-- and use them quite often (yeah why not just bind to C-o and C-i? because Cmd-+ and Cmd-- are in VS, and for some reason they work better with my muscle memory, I know ... :D). But there's a huge downside, actually multiple ones. First of all, if you do `back` a few times, it takes a different number of `forward` to go back to where you were. I only started using it a few days ago, but this feels like a ridiculous thing and I intend on filing a bug report if there isn't one. Luckily enough, if you go back forth back forth a few times, it keeps taking the same path. It's a different path in each direction, but at least it stays consistent.
Any chance of multipart support?
The first part of the error (`can't use type parameters from outer function`) is correct - items defined inside functions cannot reference generic parameters of the function they are defined in. Therefore you can't use `F` in the definition of `BAR`. However, the hint (`try adding a local type parameter in this method instead`) seems rather confusing - this is actually the first time I see an error referring to `local type parameter` - and I have no idea what's that. You can try opening an issue on the compiler repo, as the explanation does not explain how to fix this case, and completely lacks an actual explanation on how the hint suggests to fix the error.
Care to share the reason for moving away from grpc? I'm curious in the context of Rust. 
Not this moment, but open an issue and we can work on getting it added. I could probably provide some guidance for a Pr
There's a separate on-by-default lint for that, but there are plenty of cases where folks actually want that. I don't see this lint as "not true", it's just a bit annoying (which is an argument to make it pedantic) But it's very much in the spirit of the rest of rust -- what this lint does is guide you towards a more robust bit of code (arguably, more idiomatic). This is true of a lot of Rust's borrowing system as well, just because things aren't a problem the specific way you use them doesn't mean that they won't be a problem when things change.
Just type annotations. But I use them everywhere, so like, tons of my code has \`# type: blah\`
\`rustup component add\` only supports a limited set of things that the Rust project is officially distributing (see \`rustup component list\`). \`cargo install\` can install anything from [crates.io](https://crates.io). Thus, use \`rustup component add\` when you need one of the official things (e.g. a standard library compiled for a different target, for cross compiling), and use \`cargo install\` when you're trying to install something from [crates.io](https://crates.io). There's only a couple of things where there's overlap, clippy, rustfmt and rls (I think?). I believe there's overlap because they were previously being developed on [crates.io](https://crates.io) and have recently become good enough to be published more officially. In summary, if something is available as a \`rustup\` component, that's the right place to get them, for most people.
Thanks. Do things like Clippy really have to be moved from `cargo install` to `rustup component add` just because they get official endorsement? Isn't it cleaner to install all such things, official or not, via the former method?
In general, yes, things should stay `cargo install`. Clippy hooks into the compiler, which means it breaks often, which means the plan has always been for it to be a rustup component.
It was less moving from grpc and more moving away from synchronous communication. I moved all of my services to async communications based on SQS. The data format is still protobuf though.
&gt; in practice This isn't quite the right question to ask: it might not cause actual memory unsafety in practice at the moment, but it can still be undefined behaviour, because the language is not wanting to define it to have a certain behaviour (even unspecified behaviour), leaving room open for, say, future optimizations. &gt; Of course, we may pretend that it is UB (as in - Rust as a language doesn't guarantee that it will work), but internally depend on it not being UB in practice (as in - LLVM will always treat it as valid and defined, even if we tell our own users otherwise). But that feels a little disingenuous, so I can't say that I'm a fan. It's not disingenous at all. It's perfectly reasonable and even normal for APIs to have a stronger contract than they are willing to commit to publicly (and so users can't rely on it), but calls of that API from within the same library can rely on it, because changes to the API that break the stronger contract can also change those callers. The compiler and stdlib are tied together in a similar way. I say it is normal because it happens ~all the time; unless an API is committing to its exact implementation, the stated public guarantees are going to be more limited than its true behaviour.
Interesting, looking forward to some benchmarks comparing this to awesome actix-web.
I wanted to add some static assert that some types don't implement a given trait, but found it pretty tricky to, especially given that we don't have negative impl or negative bound. Eventually it occurs to me that multiple applicable items can be utilized to do the trick, and thus this crate. 
Yup. I'm using actix right now, mostly because I'm including other stuff with the web server (TCP server, socketless local clients), so actix's actor model has worked pretty well for the non web stuff. However, I have other projects that only do web, so perhaps I'll give Tower a look. If it's nearly as ergonomic as Rocket, runs on stable Rust, and is pretty close to actix-web in performance, then it'll come down to features.
A lot of the things you mentioned I typically like to do with a reverse proxy in front of the the application. It's one more service to deploy and maintain but they usually have much more flexible configuration options and powerful features. It's worth the extra complexity in deployment to pull some of the complexity out of the app server. Everything you mentioned can easily be handled with an nginx proxy.
Thanks for the elucidation. &gt; Clippy extends the compiler, and rustfmt uses the Rust parser from the compiler Could Clippy and rustfmt use the Rust Language Server, and would they then still be considered to build upon the compiler and have to be installed via `rustup`?
Might be interested after I finish event port support for mio 
I have seen this only in the theme of the #rust-fr irc channel. It says says "Bienvenue, petite Rustac√©e. Canal d√©di√© √† la programmation en Rouille et en bon fran√ßais.". The inhabitants of that channel all say Rust, as far as I've seen.
^The linked tweet was tweeted by [@ManishEarth](https://twitter.com/ManishEarth) on Aug 09, 2018 22:03:12 UTC (43 Retweets | 140 Favorites) ------------------------------------------------- Discord's new game store makes significant use of Rust!! [Attached photo](https://pbs.twimg.com/media/DkMKP12UUAARpU_.jpg:orig) | [imgur Mirror](https://i.imgur.com/CSRv5Xj.jpg) ------------------------------------------------- ^^‚Ä¢ Beep boop I'm a bot ‚Ä¢ Find out more about me at /r/tweettranscriberbot/ ‚Ä¢
Serde uses attributes on struct fields, which is perfectly legal on stable. When I've done proc macros in the past, I'm fairly certain that you're given basically read-only access to the stuff being derived on. You can then generate additional code to go with that code. When function attributes become stable, things might be different there, I'm not sure.
The last time I built a proc macro I could swear the output was nothing by default, and you could include the original source if you wanted to. Either way, this isn't a big deal to me.
&gt; `--remap-path-prefix` flag I won't pretend to know anything about rust-internals but I think this ought to be the default behavior and the other way round should be behind a feature flag. 
Is the client mutable? Instead of creating repo via Repository.new(), could you instead create it via the client (e.g., client.repo()), and have repo keep a reference to the client?
No, they can't use the Rust Language Server, because they need to work with the actual source-code while RLS only provides summarized information suitable for display in an editor or IDE. However, RLS incorporates clippy and rustfmt (if the channel you're using also includes them separately) so you don't strictly-speaking need to install the clippy and rustfmt tools to get their benefits, if you're using RLS.
That makes sense.
Yea it could be immutable. It seems weird to me to keep a reference on every API object though
Great work! Really looking forward to an alternative to Lucene that we can build Python, PHP, Node plug-ins with. This is such a great project that has great potential beyond the rust ecosystem. 
So I tested [it](https://play.rust-lang.org/?gist=3e5c52416974e138b5ef86007d18c68a&amp;version=stable&amp;mode=debug&amp;edition=2015). In the function `baz`, change `BAR` from a constant to a normal variable. Then it compiles. This is my best guess for the error. The constant itself in `baz` is not generic. So it tries to make a single constant that is referred to in every monomorphization. If you refer to the error that this produces, you can see that if you made a function in `baz`, for example, the same thing would occur. This is bad: fn baz&lt;F: Foo&gt;(a: F) { fn boo(b: F) { // Bad // Something } boo(a); } This is good: fn baz&lt;F: Foo&gt;(a: F) { fn boo&lt;F: Foo&gt;(b: F) { // Good // Something } boo(a); } So I'd imagine you want something like: fn baz&lt;F: Foo&gt;(a: F) { const BAR&lt;F&gt;: i32 = F::BAR; println!("{}", BAR); } However, this doesn't exist (I think). Note: remember that monomorphization is elided and, for functions, can be invoked explicitly using turbofish syntax. `boo(a)` is actually `boo::&lt;F&gt;`. `BAZ` should be `BAZ&lt;F&gt;`. This error happens because generic parameters aren't visible in scopes other than the ones in which they are declared. This makes sense, because things are only made generic/monomorphized if they are declared to be. You can't make generic constants, as far as I know, with the exception of how you made `F::BAR` generic. If you don't want to use a variable inside `baz`, you can also use a [static reference](https://play.rust-lang.org/?gist=02dbd7444edd52a15c32290cb9b85f15&amp;version=stable&amp;mode=debug&amp;edition=2015) instead. Or you can just use `F::BAR` [directly](https://play.rust-lang.org/?gist=405c5ee96a4055e412dba301c8b61741&amp;version=stable&amp;mode=debug&amp;edition=2015). [Constant Functions can be generic](https://play.rust-lang.org/?gist=f7553a6a20d19720eaa901276398ae91&amp;version=nightly&amp;mode=debug&amp;edition=2018), but doing it this way requires turbofish syntax since this isn't passing in anything. Or you can use a [normal function](https://play.rust-lang.org/?gist=947021d6422b7498391d195aa6fd42a7&amp;version=stable&amp;mode=debug&amp;edition=2015). [This also works](https://play.rust-lang.org/?gist=b72b963a09803171d2d2cb5e8bc78eec&amp;version=stable&amp;mode=debug&amp;edition=2015), but only with normal functions. So essentially, just change it from a constant to a variable in the baz function.
I don't think that they could be implemented on top of RLS (they want more detailed information about the syntax than that), but if they could then that would be a good way to decouple them from the compiler version.
Is the `ToString` trait not implemented on `usize`? In the docs for usize (https://doc.rust-lang.org/std/primitive.usize.html) I cannot find (CTRL+F) "ToString" or "to_string"?
Nice. Do you want to add more info at [tantivy-search.github.io](https://github.com/tantivy-search/tantivy-search.github.io)? Right now it's showing 404 :)
I have deployed the docs here: [https://d1n3hucxjxvv7h.cloudfront.net/tower-web/v0.1.3/tower\_web/index.html](https://d1n3hucxjxvv7h.cloudfront.net/tower-web/v0.1.3/tower_web/index.html) I'll be updating it it in the repo as well.
Text from the attached image: &gt; hi rust friends. Discord engineer here. Now that the press is out (we're launching a game store). I just wanted to thank the rust core team, community and contributors for building such an awesome language. Rust has been a significant technology investment for Discord! For example, all the native code that powers the store is written in rust, Our game SDK is written in rush (with C, C++, C# bindings), and our multiplayer network layer is also in rust! Honestly, it's been nice to write all this stuff while avoiding a huge class of problems that we woulda had in C++.
Side note: a fun tool to do this (on Unix platforms, at least) is [`strings`](https://linux.die.net/man/1/strings), which is a command that will scan a binary (or any file) and print out any subsequence that looks for a printable string. For instance, when I run `strings $(which rustc)` on my mac, this is part of my output: active-toolchainbinary not foundactive toolchaincalled `Option::unwrap()` on a `None` valuelibcore/option.rscalled `Result::unwrap()` on an `Err` value /Users/travis/build/rust-lang/rust/src/libcore/slice/mod.rsverboseinstallupdateuninstalldefaulttoolchainsrc/rustup-cli/rustup_mode.rsinternal error: entered unreachable code A few interesting things I noticed: first, the exact issue you're describing is definitly showing up in my own Unix binary. The other thing is that you can actually see Rust's effeciency in action: because it's a safe language that doesn't use `\0` terminators like C, many of the strings embedded in the output binary are directly concatenated, and `strings` sees them all as a single string.
I'll forward that to someone that is more competent than me!
It's not really short, but I was pleasantly surprised when I made a GUI demo in Rust and it worked on both Linux and Windows without much fuss (though we did have to install a couple libraries). It's not really what you're looking for, but it's definitely related. I'm also pleasantly surprised by the quality of the WASM libraries given how immature WASM is, especially with Rust.
Yeah, _really_ don't panic on things that behind the scenes code will be calling on its own.
This uses the `Display` trait.
[removed]
You may be interested in [Region-Based Memory Management in Cyclone](https://www.cs.umd.edu/projects/cyclone/papers/cyclone-regions.pdf).
I use this to check if a binary we produced was what I expected. Basically, does it have that fancy new println that I threw in to catch some behavior so I can be sure that the behavior never happened instead of wondering if perhaps the binary didn't take.
Use `main` returning `Resutl` and change `unwrap`s into `?`.
Are they already done with Elixir?
A 2.0 does not mean end of support for 1.X, nor does it require significant breaking changes. If you make frequent major version bumps, people will get the idea that it's not a big deal. However, it *does* have the nice side effect that version numbers become more understandable. Version 2.0 means the first release after a (probably minor) breaking change, and numbers stay nice and small for a while. When numbers start getting big, it's getting close to the time for another major bump. If Rust wants to make it even more obvious that nothing is going away, they can include the major+minor versions in `cargo version` (perhaps with an arrow indicating the current create's version). However, they kind of made a huge point of never having a "2.0", so going back on that is a little hard, hence the song and dance about editions. Honestly, I just want small version numbers because they're easier for me to remember. I like that Linux is rolling over every ~20 release, and I think more projects should follow suit. Also, I'm of the opinion that breaking changes are fine, provided they're incremental and can be fixed more or less automatically (e.g. with rustfix).
You're looking for /r/playrust
Thanks! What's the difference between `ToString` and `Display`?
Not for handling the audio iirc
https://forge.rust-lang.org/bibliography.html
How does rise fit in with tower-web and warp? Superficially, they seem similar, but I don't know enough to make any deeper comments.
Did you know that http://nphysics.org/ has demos that you can run in a browser? :)
Say you write `x as i16` where `x` has type i8. This code works exactly as intended today. Later, someone else changes the type of `x` to i32. Now, the code still compiles, but it could loose information in a surprising way. But here's the thing: linters can't warn about the new code, because they can't tell the difference between an `as` where you meant to do a truncatoon and an `as` where you didn't. So there is no warning, just silent potential misbehavior. The situation may change in the future when more explicit convetsoon functions are added; when that happens, clippy should be adjusted accordingly.
You might want to check out a GitHub client author's thoughts https://mgattozzi.com/refactor-rust For global values, try checking out lazy_static crate.
Is the note about HTTP crates referring to https://github.com/hyperium/http , possibly foreshadowing having it lifted up into the nursery? Excited at the prospect of a blessed crate for URLs as well. Also curious what the goal of Rise might be; is it just to get hands-on experience with async/await in a web dev context?
The catch is, linters can't warn about it after, because they have to assume that you might have intended to use `as` for a truncating cast.
It's implemented for shared references already. I don't think that implementing it for Deref makes lot of sense, since I'd implement it for Box too and that's nonsensical (two boxes never contain same pointer). Maybe it'd make sense to implement it for StableDeref + Clone. (StableDeref from rental crate), as that guarantees reasonable properties.
I'm curious: is the the JIT hot? Or to be more precise, could you give some small explanation of the testing methodology and how it is fair (i.e. representative of typical workloads and usage style) to both pieces of code?
good bot
Are you sure about that? Because I am 100.0% sure that faitswulff is not a bot. --- ^(I am a neural network being trained to detect spammers | Summon me with !isbot &lt;username&gt; |) ^(r/ spambotdetector |) [^(Optout)](https://www.reddit.com/message/compose?to=whynotcollegeboard&amp;subject=!optout&amp;message=!optout) ^(|) [^(Original Github)](https://github.com/SM-Wistful/BotDetection-Algorithm)
&gt;testing methodology and how it is fair (i.e. representative of typical workloads and That should be in the README. Class are loaded, JITted, page cache is hot as well. I run the bench 1 time for warmup. Then, I run 5 times and measure timings. The benchmark in link contains the best time out of 5, so it should not be impacted by GC either.
&gt;g forward to an alternative to Lucene that we can build Python, PHP, Node plug-ins with. I'm waiting for the API to stabilize to start working on bindings. Javascript and Python would certainly be nice.
Oops, I must've somehow missed it. Thanks!
Oh yeah, I was wondering when I saw jake on the rust discord... 
Thanks, that was very helpful.
good bot
Here's an example from the quicli docs, using request but also serde and structopt: https://killercup.github.io/quicli/commit.html You might also like [this one](https://killercup.github.io/quicli/thumbnails.html) where we resize images specified by a glob pattern in parallel (generated [full source](https://github.com/killercup/quicli/blob/5e4979016e20f612d6f48e910671c9ce70660f73/examples/thumbnails/src/main.rs)).
I've opened [issue 53241](https://github.com/rust-lang/rust/issues/53241).
Are there any benchmarks for indexing speed?
What did you use? I'm still in search of a good cross-platform GUI library.
Elixir is great for big servers and chat rooms and stuff like that, for an sdk I don't think it would make as much sense.
For context: https://blog.discordapp.com/the-discord-store-beta-9a35596fdd4 That store is what it's all about.
No reason to infer that from the post. According to TFA they're using Rust for: * The SDK (integration between game and store for stuff like DLC, communication, achievements, etc‚Ä¶ similar to the Steam SDK), Elixir is absolutely not suitable for that unless you're only targeting Erlang/Elixir software * Multiplayer network layer, a bit less clear but I'm guessing this is also an SDK of sort for game devs to use, so again Elixir not suitable * The native code which powers the store, that's self-described. The non-native code could well be Elixir. Writing native BIFs or ports or nodes is not abnormal in the Erlang ecosystem.
No benchmark for indexing speed. I haven't found a nice protocol to compare indexing speed yet. It is quite difficult to compare apple to apple when Indexing stuff as it is highly dependent on the number of segments you get in the end. One could force the search engines to reach a single segment, but \- that does not reflect the real world \- tuning the buffer size then becomes super important, optimizing your pit-stops in formula 1. If you try to run the current benchmark on your computer to time indexing, the result might be misleading as the Java code is much much slower because it is single threaded right now.
there's the [xori dissasembler framework](https://github.com/endgameinc/xori) and [Suricata](https://github.com/OISF/suricata) (not entirely written in Rust, but it recently integrated Rust parsers.
#ignore
The only projects that I've seen embracing comment annotations in PHP are Doctrine and testing frameworks. Even PHPUnit seemed to drop those in favor of actual methods that adjust how the test cases are run. Then again I've mostly developed in the WordPress/SlimPHP/Laravel/Symfony Console bubble. :)
&gt;&gt;. I'd love some ideas on some mind-blowing impressive demos. seems to me Rusts advantages are in the journey rather than any specific end result .. if people dont get that, they wont be swayed be any specific peice of software (where end result capabilities wont look any different to C++)
Can't you just create the arguments somewhere else? i.e. `let args = format_args!(...)` and then just use the variable. This will prevent it from being dropped too early.
I'll try that, but I'm pretty sure a &amp;str is required for later methods. I'll look into Cow. It is a String from the `heapless` crate, this library requires no-std. Thanks!
This is for a library, and I'd really like to limit extra syntax required to use it. Thanks though :)
`#[ignore]`
Awesome! It's been a long time since I've worked with Tantivy myself, but I'm very happy to see that development is still progressing actively. Amazing work on this project so far!
I think you were one of the very first user
&gt; I can't figure out why this code would have any issues: It is actually simple when put it in the following way: the behavior of **valid** Rust programs does not depend on the contents of uninitialized memory. If a program's behavior depends on the contents of uninitialized memory, it is not a Rust program. Therefore, if you write: fn main() { let a: u8 = unsafe { uninitialized() }; println!("{}", a); } a **good** optimizer will: * detect that the behavior of `println!("{}", a)` depends on uninitialized memory * conclude that therefore, for this to be a **valid** Rust program, that statement cannot ever be reached * remove the statement * realize that `a` is not used after removing the statement * remove `a` generate code for `fn main() {}`. Does that make sense?
You can always go from `String` to `&amp;str` cheaply using `as_str()` or `deref()`. Not only that, any method that expects `&amp;str` will take `&amp;String` due to deref coercions.
u/seanmonstar I answered this here: https://www.reddit.com/r/rust/comments/95vxdy/understanding_ub_with_stdmemuninitialized/e3xvi5d/ &gt; If every single bit pattern in 4 bytes is a valid i32, I don't see how using uninitialized memory to make one is UB. No matter what bits were in the stack there should be valid, right? Creating an `i32` with uninitialized memory is not UB. What's UB per Rust specification (the incomplete one we currently have) is creating references to uninitialized memory (pointers are ok), and having the run-time behavior of a program depend on the contents of uninitialized memory. You can use `ptr::read` to read uninitialized memory, and write it somewhere else, that's all fine, _as long as the behavior of the program doesn't depend on what exactly its contents are_. Does that make sense?
&gt; If you want, Discord can scan your computer for games. Then, you‚Äôll be able to launch any of your games through Discord even if they require another launcher (Discord will boot the other launcher and game). I hope this also includes the steam and blizzard launchers. If I can launch everything from one place that would be a big incentive to start using Discord more. Now it has happened that I just forget about a game because I don't often check the different lanchers I have..
good bot
Are you sure about that? Because I am 99.9999% sure that jaapz is not a bot. --- ^(I am a neural network being trained to detect spammers | Summon me with !isbot &lt;username&gt; |) ^(r/ spambotdetector |) [^(Optout)](https://www.reddit.com/message/compose?to=whynotcollegeboard&amp;subject=!optout&amp;message=!optout) ^(|) [^(Original Github)](https://github.com/SM-Wistful/BotDetection-Algorithm)
Ah, [the ignore attribute](https://doc.rust-lang.org/stable/book/second-edition/ch11-02-running-tests.html#ignoring-some-tests-unless-specifically-requested). So the idea here would be that I mark all my symlink-related tests as `#[ignore]`, and tell people to run: cargo test &amp;&amp; cargo test -- --ignored ...but if the ignored tests fail for symlink-related reasons, they can stop running them? I guess that would work, although it's a bit clunky.
All this in addition to newborn baby. :). Good job! Needs documentation and examples, though... 
Good human. 
Good good human bot bot.
Display is meant to be displayed to people, provides a way to write output to formatter and can fail (it returns result). ToString converts data to a string and cannot fail. Use Display when you want to present data to users by printing on screen or to a file. Use ToString for all other purposes, mainly when you want to have textual representation in memory for further use.
First of. I like the idea of space optimization. But on average this approach will not be faster because of data locality. Additionally the best solution in terms of space is when the compiler recongizes that some representation won't be used by the enum. (Although this is probably only done with NonZero types atm) If you believe this approach is required for your usecase , the easiest solution would be to require T: Default and drop the unsafe call. 
I am tring to write a cmall command line tool to log system resource use. This data is collected into a text file that a call like this \`\`\`\` let mut file = OpenOptions::new().read(true).write(true).create(true).append(true).open("Measurments.txt"); \`\`\`\` However when i try to write some thing to the file i get the following error. \`\`\`\` error\[E0599\]: no method named \`write\_fmt\` found for type \`std::result::Result&lt;std::fs::File, std::io::Error&gt;\` in the current scope \--&gt; src\\main.rs:26:5 | 26 | write!(file, "{} {}:{}\\n", sys.get\_used\_memory(), timestamp.tm\_hour, timestamp.tm\_min)?; | \^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^ | = note: this error originates in a macro outside of the current crate (in Nightly builds, run with -Z external-macro-backtrace for more info) \`\`\`\` How should I write formated text to file with OpenOptions?
In terms of *demo*, there's [C√©lerie-R√©moulade](https://github.com/phaazon/celeri-remoulade), which debuted at Evoke 2016. But as others observed, there's more to Rust than being able to create flashy graphics and thumping beats. The real killer is that Rust will nudge you towards doing the right thing from the start. I outlined this thinking in [Corner Cutting vs. Productivity](https://llogiq.github.io/2018/04/03/corners.html), which may be of interest to you.
In terms of *demo*, there's [C√©lerie-R√©moulade](https://github.com/phaazon/celeri-remoulade), which debuted at Evoke 2016. But as others observed, there's more to Rust than being able to create flashy graphics and thumping beats. The real killer is that Rust will nudge you towards doing the right thing from the start. I outlined this thinking in [Corner Cutting vs. Productivity](https://llogiq.github.io/2018/04/03/corners.html), which may be of interest to you.
This is really nice! This should really be included in std, in my opinion.
Let me tell you a secret: if they didn't work on tower, the time very likely wouldn't be spent on tokio instead.
I have been caught debugging the wrong binary regularly for more than 20 years and never thought about this. Thanks a lot.
Looks cool. One final question, does this works on MacOSX ? As in, are the spirv kernels converted to metal ? 
I recently learned that `panic=abort` prints a backtrace of where the abort was triggered on error. 
The core of discord's business is still the chat and voice servers of course. Those are probably powered by Elixir because they involve a bunch of lightweight networking.
Hello, this library started as a convencience for my OpenGL GUI ramework written in C. The fact that I was writing Rust on a headless instance made me create a WebAssembly backend. Publication on crates.io is planned after I finish the docs. Please see the [WebAssembly example](https://github.com/axelf4/vfin/blob/master/vfin-dom/src/lib.rs) for example usage. Feel free to ask any questions!
rlsl just outputs SPIR-V, if you want to run it on Apple you have two choices. You can convert the SPIR-V to MSL with glslang and use metal, (I have never done that), or you can use something like MoltenVK/gfx-rs, which can consume SPIR-V. 
Hmm, I wonder how hard it would be to hook this up to one of the many ray tracers I've seen and maybe render a cool animation?
SIMD package where you can write one SIMD function and generate SSE, SSE41, and AVX2 versions automatically, and select one at run time: [https://github.com/jackmott/simdeez](https://github.com/jackmott/simdeez)
Yeah, this is a great one. I really like the runtime feature detection. I'm looking forward to NEON support. 
I was glancing over the doc for tuple. I noticed stuff like: `impl&lt;T2, T3, T4, T5, T6, T7, T8, T9, T10, T11&gt; Debug for (T2, T3, T4, T5, T6, T7, T8, T9, T10, T11) ` It's probably a very elementary question, but could someone comment on why this is so? Thanks! https://doc.rust-lang.org/std/primitive.tuple.html
Show them the error messages!
https://rocket.rs/ - of course it uses nightly features so it's rather cheating.
As a follow up question, is the idiomatic way of performing this operation? let mut file = OpenOptions::new() .read(true) .write(true) .create(true) .append(true) .open("Measurments .txt")?; 
You can do that in C/C++ just as easily tho
I have one https://ivanceras.github.io/svgbob-editor/
You can do it, but it isn't just as easy. Three aspects are harder: * There isn't an equivalent "target\_feature" attribute in C++, so each version of the function needs to be in a separate compilation unit. * Using templates and/or macros to do what I did with traits is a bit more painful (perhaps this one is arguable) * feature detection is not part of the stdlib, and requires different techniques on different compilers. On the other hand there are now 3rd party libs that can do this for C++.
Can you go up a level in terms of what you're trying to do? I'm honestly not sure I understand the reason for the constructor that takes `core::fmt::Arguments`
I have simplified my example somewhat. The actual code uses a `bitvec` for the null vector, so it should be faster (though I haven't benchmarked). In any case, speed isn't really the point - this is the data layout I need for library interop. I would like to avoid adding a `Default` if possible, it would mean adding enums to the array would be a pain, for example (you'd have to implement `Default` even if you never intended to use it). I'm leaning towards using an empty unsafe marker trait, add impls for `Copy` types, `Vec` and `String`, then check it doesn't segfault. Then the library user can impl the trait on their own types, at their own risk.
Wait, what's wrong with ``` fn main() { let result = [1, 2, 3, 4].iter().map(|v|format!("{}",v)).collect::&lt;Vec&lt;String&gt;&gt;().join(", "); assert_eq!(result, "1, 2, 3, 4"); } ```
How so? That's essentially how Java works, and people don't seem to get confused (to be fair, I think the actual version is 1.X, but everyone says "Java 8"). I guess it's a matter of taste, but a version number is just a number, and bumping the major number seems "less" confusing than inventing a new "edition" concept. Since Rust is committed to not breaking backwards compatibility, staying at 1.X seems silly. I'd much rather use Rust 4.0 than 1.120 since it's easiesr (IMO) to keep track of smaller numbers. In fact, huge version numbers is one thing I hate about rapid release cycles. I wish Firefox only bumped the major version at each LTS release since "backwards compatibility" doesn't mean much for an application. Version numbers over 40 or so lose all meaning to me.
I love the source links and I use them all the time. Go has them as well, and they're super handy for tracking down bugs (e.g. which types of errors can this function return) when the documentation doesn't cover all edge cases.
I like this one, I'll kick the tires on it. Thanks!
Well TBF you can write that as: fn main() { let result = [1, 2, 3, 4].iter().map(|v| v.to_string()).collect::&lt;Vec&lt;String&gt;&gt;().join(", "); assert_eq!(result, "1, 2, 3, 4"); }
Looking at the discussion for various language RFC's that have been accepted and implemented might be interesting too.
I'd be really interested in something like Haskell's Accelerate package: http://hackage.haskell.org/package/accelerate
Panics are not unrecoverable, there exists a function in the standard library whose [entire purpose is to recover from a panic](https://doc.rust-lang.org/std/panic/fn.catch_unwind.html). However, you're not obliged to have your types behave correctly after a panic, only that they don't violate memory safety or cause UB.
In trying to answer this question, I stumbled across [the `UnwindSafe`](https://doc.rust-lang.org/std/panic/trait.UnwindSafe.html) trait which appears to offer a soft promise of exactly what you want to express. So it looks like you could `impl !UnwindSafe for JoinIter` and at least get a step closer to ensuring "this value is unusable if the closure inside it panics and the panic is caught". I'd say that documenting that behavior in the module docs is probably then Good Enough.
Have you read [the Rust book](https://doc.rust-lang.org/book/2018-edition/index.html) yet? It sounds like what you're trying to do is pretty common, like read the command line arguments for a program, but you're getting tripped up on some of the details of enums and strings. The Rust book should give you a stronger foundation on those details, and it's worth reading from cover to cover. After that, you might want to take a look at some of the libraries people use in Rust to make command line parsing easier. "Clap" and "Docopt" are two of them. But I think mastering the basics before you reach for a fancy library will be more helpful in the long term.
&gt; I run the bench 1 time for warmup. Then, I run 5 times and measure timings. You should use JMH if you can, it's not that hard. Either way, how do you know the classes are JIT'd? One time is not usually enough for Hotspot, and 5 times is also far fewer than common microbenchmarks on the JVM. Granted I have no doubt it's still faster. 
Primarily the fact that you have to convert all those ints to Strings AND collect them into a vector AND create a NEW vector. My library is lazy and zero-allocation.
I don't like the following things: - Not open source (notice the GitHub is just headers, and it's not unlimited free for commercial use) - There don't seem to be any cases of modifying the actual view from the C++. The implication is that this is possible, but the API doesn't seem conducive to it. It seems like you're still supposed to do UI updates in JavaScript. I'm not really happy with a GUI framework that requires you to use another language. - It really seems not very far along at all. A good amount of work has clearly been done, but there's virtually no documentation, no examples, and it's closed-source so there's no transparency on when or if that will happen. I think it's great to keep an eye open for potential solutions, and I think an HTML-based GUI offering might be the right move for Rust, but this doesn't seem to be it, at least not for right now. Personally, I think the optimal HTML/XML/markup-based GUI offering for Rust would leverage macros heavily to allow users to very efficiently and correctly express views in Rust. This can compile down to any code you want (JSX-style; see [yew](https://github.com/DenisKolodin/yew)), so the library backend doesn't need to understand HTML natively outside of those macros.
(‚Ä¢_‚Ä¢) ( ‚Ä¢_‚Ä¢)&gt;‚åê‚ñ†-‚ñ† (‚åê‚ñ†_‚ñ†)
When you're able to run a complete game such as Dota2 it seems strange that there are so many tests still not passing in the portability test results table in README.md. Is Dota2 not using many features, or is this out of date? Either way, really cool to see such promising numbers. 
How about having the build date and time available? One of the first things we log is the date and time of the build, branch name, commit and debug/release configuration. 
I'm pretty sure that at least clang and gcc have target feature attributes for C and C++.
doing some googling it does look like GCC has something equivalent, but maybe not clang. Could be old info though. 
I'm quite happy with \[web-view\]([https://github.com/Boscop/web-view](https://github.com/Boscop/web-view)). The compiled binary is \~10MB.
I want to iterate over a String (or a &amp;str) using indexing, what is the best way to go about this? One way was using .as_bytes() but that returns &amp;[u8]. Now, I want to use these u8 bytes for two things: 1. Compare characters (so will need to convert back using `as_char`). 2. Use these bytes for various calculations (so will need to do an `as i32` everywhere these are used.) Any help appreciated. Some follow up questions: - Is there an alternate to as_bytes that I can use/write, something like String::as_i32? - Would I be better served by using str slice and .chars() instead? https://play.rust-lang.org/?gist=0120d6060037504fa4cee40937eae0f0&amp;version=stable&amp;mode=debug&amp;edition=2015
yeah i've read thru the book. getting an arg from the execution is not what im tripped up. I've seen Clap but im not interested in using a library, im interested in learning. This is just an exercise. I posted a solution that got me working the way i want. 
Was coming to say this. Methods have to be executed 1000's of times before aggressive opts start taking effect. Also, would be interested to know what startup flags and GC was used. Was this the default (G1GC)? Did you have "-server" set? I would suggest that you switch to the parallel collector, turn on -server, and whack the server a whole bunch (like 10 seconds worth of the benchmark) before doing any comparisons. I double 5 requests give the VM enough time to trigger all the optimizations it is going to trigger. Ideally, you would use something like apache benchmark or JMeter instead of just hitting the server 5 times. The JVM is primarily meant for long running processes and Lucene will be long lived in most real world use cases.
It sure is one of the best option, although it may not be the complete GUI framework we deserve. Also, I read that the engine under the hood being the system's native, not that I care but on Windows you'd end up using MSHTML ... Do you really want to support IE11 ? 
One difference is that `rustup component`s are updated with the toolchain.
Does that mean that you can't have a tuple with more than 11 (or is it 10) different types as things stand? (I think that's a lot of types and if you have to use that, might as well use a struct instead.)
You're right, I do want to achieve the python functionality. I could use `.chars()` on a String, but if I had a string slice, would it be efficient to convert it to a String first and then use `.chars()`?
Clang definitely has it. Take a look at the intel headers. Basically all the intrinsic functions are tagged with a target feature attribute, just like how stdsimd does it.
Tantivy or the baby?
They have a Vulkan rendering engine, and there is a DLC that downloads `libMoltenVK.dylib` in their library path, which is used as a dynamic library implementing the Vulkan driver. Since we also implement a Vulkan driver, all we needed is just setting `DYLD_LIBRARY_PATH` to find our path first and aliasing the name of `libMoltenVK.dylib` See [earlier discussion](https://www.reddit.com/r/rust/comments/8pmniu/first_screenshot_of_dota2_running_on/e0cfkfs/) on the topic.
What are you building with this ?
I wouldn't make &amp;str into a String before calling chars, given that String::chars is based on Deref to &amp;str, so there is no point in doing that.
You can have it, but it's like a second class citizen in Rust, where you have to implement a lot yourself.
bad bot
Ah, now it's starting making sense to me. So the lint advises `x.into::&lt;i16&gt;()` because when the type of `x` switches to `i32` then no `From` implementation will exist and I'll get a compiler error instead of silent truncation. So it is indeed future-proofing; but it's still not clear to me whether it's worth going with the extra verbosity for the cast.
This is the subreddit for the Rust programming language. You're looking for /r/playrust
Ordinarily I‚Äôd agree on keeping std minimal, but I think this particular case is somewhat special. Also while keeping std minimal is a good goal, that doesn‚Äôt mean that *no* new inclusions can be made. String joins are already in std via the SliceExt trait, but it only works with slices, not iterators. So this is functionality which already exists in std, but with limited functionality. I for one was very surprised that this functionality does not exist on iterators. Additionally it‚Äôs a very common operation which most languages include in their standard libraries, so it‚Äôs not really unprecedented to include it.
You could make `text` a `heapless::String` instead and have `from_args` accept a `T: Into&lt;heapless::String&gt;`. I think that would satisfy the ownership, no-std, and ergonomic concerns. Though you would have to figure out how you want to handle the length for the `heapless::String`.
/u/manishearth =&gt; I can see that Discord is not on the Friends of Rust page, since it's now official they are using the language, maybe we should request their permission?
Have you checked out [vfin](https://github.com/axelf4/vfin) which I posted earlier today. It is a more lightweight yew alternative.
Just to be clear : it's one full run of the benchmark, and this is not a microbenchmark. At this point a function like skipTo have been called millions of times. I've never seen jit not being done at this point but sure... I can run it in a loop for an hour or so to see if it is stabilized. I didnt use jmh because I am trying to compare search engines written in different languages using a fair benchmark. If I start using language specific microbenchmark framework, it is going to be very hard to audit.
This is not 3 request. It is all of the requests in the benchmark once. This takes around 3s (I think) . I didn't use -server. I'll try that. This is the default GC... But I am comparing the best out of the 5 five following runs. I doubt changing the GC will have a positive effect. I don't want to use language specific benchmark frameworks.
Yep, that seems to be a restriction. Trying to make it _even more_ generic than it already was, it still didn't want to budge, even with `#![feature(specialization)]`. You'll either have to implement it only for numbers using something like the `Num` trait from the `num` crate (like I did [here](https://play.rust-lang.org/?gist=a1ab3d1960a1337a326915c74436ec16&amp;version=stable&amp;mode=debug&amp;edition=2015), I only did it for `Mul`) or implement `Mul&lt;T&gt;` for each type you want yourself, optionally with macros.
G1 trades memory locality and allocation speed for lower latency. I couldn't tell you how much of an impact it will have, but I can tell you that the parallel collector will have the lowest overhead. It is also wicked fast, faster than G1 for smaller heaps. The tools I mentioned aren't language specific. They are common endpoint testers. Methodology wise, to be the fairest to Java, you need to give it quite a bit of warmup. I'd still be dubious that a single run through all the tests would be enough. If you want to keep this methodology is suggest all least playing around with number of runs and latency. You'll see that the more runs you do, the faster the JVM will be.
Have you looked at iui?
I discovered the interrogation mark operator just the over day working with crate `numpy`. It's really handy !
CLion has pretty decent debug support, and InteliJ has module support, everything else is as far as i can see same
also don't forget to turn on "dark mode" difference is like between night and day (pun intended)
Listed in my [lang-enhancing crate list](https://users.rust-lang.org/t/list-of-crates-that-improves-or-experiments-with-rust-but-may-be-hard-to-find/17806?u=vi0).
There was a lot of questions at that time though, so maybe it was overlooked. I think it's worth asking again.
Thanks for thumbcloud and thanks for packaging it in debian. I want something like OwnCloud but there's php :p.
[removed]
I'm going to come right out and say it. This is \_spooky\_.
Ok, thanks. Admittedly, I've never tried something like this before, but hey that's how you learn. Thanks for the advice I'll absolutely look into that. 
None, afaik. Your best choice for now is cairo bindings.
The imageproc crate has very basic support for drawing shapes: https://github.com/PistonDevelopers/imageproc
The `pathfinding` crate has a nice `astar` implementation: https://docs.rs/pathfinding/0.8.1/pathfinding/directed/astar/fn.astar.html
Please try it before you start packaging it for Debian. All of the dependencies are MIT licensed except of one JS file which is Apache2 but I might be able to replace it if it is necessary.
Debugging only works im CLion atm.
If you're playing with SQS, can I ask how you deal with long running tasks? I used it at my last job, but I basically was running solo, and it felt clunky to essentially send a "heartbeat" every minute or so because it didn't seem like a well documented use-case. Also how're you finding using it in Rust? I used Scala, and it *ok*.
Forgive us father, for we have sinned.
When it comes to AI/ML/linear algebra, just wait for const generics to land in nightly. I sense a storm coming ;).
No, but I've played with conrod, and it's pretty cool, but I'd hardly consider it production ready. It looks like they're pretty similar?
I've always thought that Java's main redeeming feature was the JVM... and now it doesn't even have that. Poor Java :(
ohnobabywhatisyoudoing.jpg Joking aside, I love it, in a mildly horrified way
I suspect the answer is: "because we can."
It is so energizing to me to see how excited people get over Rust--did a similar thing happen when C and C++ first came onto the scene?
This is more leftpad then kitchen sink ihmo
This isn't even a proc macro. Impressive.
As they say, some folks can write Java in any language... Now we can literally do that in Rust! Impressive!
Press F to pay respects. 
I knew this would happen ever since I first read about macros in Rust.
I'd love Rust to be boring. Not having a new tool to do X every week. That will be superseded by the next one. Or will go through major revisions with completely new APIs to compete. I don't know if the latest web framework is going to still be updated next year. And the same thing is true for most crates, even for essential building blocks such as managing errors or async i/o.
I'm not sure why everyone seems to be so hip on HTML GUIs. I guess it's so web developers can use their knowledge to build desktop stuff, but there are plenty of high quality options to choose from. I think it makes a lot more sense to embed servo than WebKit because it's already written in Rust. If I'm going to use HTML, I want to statically link as much as possible so deployment is easy, otherwise I'll use an established GUI framework like GTK or Qt.
Are there plans to enable Rust debugging outside of CLion? Specifically IDEA?
This is not about being or not. The idea is to get a cross language benchmark. The program making the measure is actually written in python. You keep repeating "one time". This is not a microbenchmark. The code runs without any payload for a few seconds, and then 5 times that. I'll multiply the number of run and have it run for 1h and republish the result. 
The core idea of a JIT is But then a part of the code that the JVM goes through 5 times in 3s does not matter... Any way... I will rerun the bench. Have it warm up for 1 hour and republish the result. \&gt; It's just not true that running once makes sure that the JIT kicked in. Well, yes there is no way to know if Java JIT will not kick in in the future. There are two problems with that. 1- a JIT run pollute the timing of hte test which is running. 2 - waiting more might have given better results. 1 is not a problem because I take the best of 5 pass. 2 I assumed that a warmup of a few seconds was sufficient but you are right, there is no way to tell if it was. I'll raise the number of passes to have it run 1hour and republish the result.
Found the Aperture Science Reddit account
Java code execution and optimisation (via JIT) involves (a) and interpreter, (b) initial, cheaper, unoptimised compiling and (c) heavy optimisation based on execution statistics. Hotspot instruments methods to see how often they're called (and other heuristics that can vary with version - various complexity measures), if they're called often enough then they'll get additional optimisation - how they get optimised depends on the data they ran on previously, with JIT optimising for the 'hot path'. Uptime isn't an input into this decision AFAIK. This does make Java benchmarking tricky, as (a) you have to run enough to get optimisation and (b) you have to run it with representative data to ensure the hot-paths are relevant. A further complication is that the effort to prepare the system for benchmarking can produce garbage for the collector and there's a chance that the GC effort (a) doesn't kick in during the benchmark (not long enough, not enough garbage, GC favouring allocation over collection when the JVM is not idle) or (b) it kicks in more often because the benchmark is testing a garbage-rich scenario that would usually be a low-frequency event in practice. To be clear, I'm not defending Java here... I'm hopeful Tantivy is actually genuinely faster and is a lot more productive for it's memory footprint.
Perhaps it can be of help in converting Java code to Rust?
hmm, why doesn't rust do that with the intrinsics? Would be nice!
I didn't try G1 but the result with a longer bench is posted above.
So, how do we handle lifetimes, and multible mutable references? (Or don't we?)
You could try checking back in 5\~10 years :) Things will probably be boring by then. New languages need time to find their footing... it takes a while.
I think I am decent Java developer. I am certainly not a JVM ninja but I have a rough idea of how the JIT works. &gt; Uptime isn't an input into this decision AFAIK. Uptime? Idle uptime does not matter of course, but I am running my bench in a loop. Considering the codepaths I go through is rather small, it directly translates into number of times hot path are going through. The amount of time it is running is actually more interesting than the number of "runs" of the test. For example, people commenting about 5 runs not being large enough are comparing that to their experience with microbenchmarking. In this benchmark, each test is running a query and which consists in itself in a big for-loop that goes through a relatively small piece of code. You might be thinking that this is a bit to specific to my code, and that I have no way to prove that, but this is actually a general property. That's genuinely really hard to craft a program that runs for 3min without running millions of times into its hot path? Anyway I ran the full bench 100 times. It took roughly 30mn. The results are unchanged. You can inspect the timing for all of the runs to see by yourself if you feel it stabilized or not.
We do? It wouldn't work otherwise.
This is not microbenchmark. A test is running a specific query so taking a few ms is normal. Running it 1000 times takes seconds. Running all the test even if they share the same codepath will take hours. I believe this is absolutely useless in term of JIT but if it is what it takes to convince ppl I'm ok with that.
https://github.com/bluss/petgraph also has astar implementation.
Leaks are memory safe, don't worry about it.
I used web-view, to wrap a database GUI [https://github.com/ivanceras/diwata](https://github.com/ivanceras/diwata) . I can deploy the app as a webapp and also can distribute it as desktop app.
As it happens, this project started as an RFC and stdlib suggestion! However, as it got a bit more complicated (particularly when `Join` became a separate type from `JoinIter`), I figured it'd be better to start it off as a library. I'd be more than happy to donate it to stdlib, if the maintenance team decides they want it!
I think you mean r/playrust subreddit. This is for the rust programming language.
I'm always super excited to see these posts. I missed out when Linux was being developed in the open I never get to see the growth of an operating system from the start like this. By the time I got into software the news was all about how ext4 was going to be supplanted by btrfs and how the FreeBSD guys "had this stuff since Sun Microsystem" etc etc. So I'm just super stoked to see this kind of from-the-ground-up development :). Awesome work!
"The reason anybody would do this, if they could, which they can't, would be because they could, which they can't"
F
Where's the fun in that? :^)
https://memepedia.ru/wp-content/uploads/2018/03/c1ciiaxv8xs-kopiya.jpg
Woohoo! That's my FAT32 lib someone's using! I always meant to come back to it, but the larger project I was building it for kinda peetered out. Looking at the fork, there aren't too many bugfix changes, so I'm really happy about that. One of the biggest things that needs to be fixed with it is to easily support either no_std mode or regular mode with a feature flag. I hadnt a need to actuallh use it in nostd yet, so i just left it in std mode. Looks like i should get back to that. It'll need write support at some point, and that'll be a lot trickier just cause of my understanding with how it works.
The repo appeared to just have the macro. I was hoping for unit/integration tests, too.
This is kickass. I'm exploring rust as a language for my company's next (mobile) game, and this is something super easy to digest for folks not too familiar with rust. If nothing else, this demonstrates that gfx has metal support, it's fast, and it's complete enough to power Dota2. Nice work!
Do we have a Gc&lt;T&gt; implementation somewhere? Only then can we truly program Java in Rust!
My first job at a high-tech company was a summer position in 1983 at Tektronix writing a full userland implementation of FAT-12 in C for a UNIX workstation they were building (6100 Stratos). I have been told that this later got enhanced and open sourced as the `mtools` package, but I'm not sure whether that's actually true ‚Äî there are certainly none of my copyrights in the current version. The code is similar in function in any case. FAT-12 was challenging for me at the time. The filesystem has 12-bit block indices that are interleaved pairwise in a funny way that really only makes sense when loading them little-endian. That took me a while to figure out. Nice to see that folks are still building this stuff.
For a non-farsical example of this principle, see the js! macro in the stdweb crate, which parses a non trivial subset of Javascript and templates it with Rust values and closures.
Check the examples directory
Rocket is very loveable, although tied to unstable for the foreseeable future. Warp has taken its place in my heart, and the example programs are beautiful _examples_ of how to demonstrate and teach a framework.
Does anyone know why `is_x86_feature_detected!` is only in std and not in core, given that all the other x86-specific SIMD stuff is in both?
Nice. Definitely cool, was just wondering if the general idea of "parse non-Rust syntax but run as Rust program" had some kind of application.
you can have a `do_parse` with a struct in each of the block parsers, then call those parsers in the top level one and assemble the sub elements in a larger struct
Last I asked it, they went the conservative route of being std-only. If you are on nightly, you can use coresimd, which should become available on stable at some future point.
Why does the same company have different features for the same language in their two editors?
See if `fn eval_internal(&amp;'p mut self, ...)` helps.
We do what we must because we can.
I would post a meme if it wasn't against the rule[s](https://imgflip.com/i/2fonay)
I tried it, and it appears to have solved the error. However, it also caused the entire module to explode with mutable aliasing errors... whoops. It seems like I have some deeply rooted design issues to begin with. Thank you for the tip nontheless!
I just started learning and don't understand lifetimes too well, or the proper way to do this recursive type allocation. Someone ought to know though.
I've been contributing a little to [a friend's project](https://github.com/pedroscaff/geoshaper) that is basically the same idea... For rendering the result it's just using the [image](https://crates.io/crates/image) and [nsvg](https://crates.io/crates/nsvg) crates
Portal 3 when.
Hey, that looks great! I've been working on an JS implementation as a prototype and I'd like to hear if you have any ideas how to improve the optimization :D 
I think I read somewhere that a good rule of thumb is that correct code should _never_ panic. That panics should always indicate a bug in implementation.
Using a mutex as in the spin crate?
Just had a quick look through and found [this](https://github.com/evansmurithi/cloak/blob/master/src/otp.rs#L100-L104). That can be simplified by just using the `format!()` macro ([rust playground](https://play.rust-lang.org/?gist=32cd623f9f28136baf8fa447428c0b6b&amp;version=stable&amp;mode=debug&amp;edition=2015)): format!("{:0width$}", hotp_code, width=self.output_len) I also had a look at the demo gif and it looks pretty cool. I think it might be a good idea to ask for confirmation on deletion though.
Yes, you are right, you could use a mutex to get around the unsafe. 
Thanks for the feedback, I will implement the changes
I see the results in microseconds. For those results to have value, they should each be tested in isolation IMO. Convincing people is not that big of a deal, it's just that if you go around saying this specific piece (or these specific pieces) are faster than lucene on the microsecond level, you should have isolated microbenchmarks saying "see, running this ten thousand times there is X ns, and here is Y ns". Just my opinion of course, don't feel the need to change everything up or run for longer or whatever on just my account, I'm already convinced (and I don't think a difference in a few ns has as much value as other things).
I'd love a solr/es tantivy drop-in, but I reckon that'd be a massive job to get there.
&gt; Working on a project for two months without successful compilation and having compiler yelling that you have made 34174 mistakes is a bit scary. However, they say that the more mistakes you make, the more you learn. I guess I have made a lot of mistakes and I have learned a ton as I have constantly been pushing the Rust-lang to its limits in large Servo codebase. All in all, this was an awesome project, and I enjoyed it very much. Congratulation on your persistence. It's not fun slogging through a mire of compiler errors, especially when one wonders whether when it finally compiles the goal will be reached.
Creating a macro to parse Java-like syntax should also be against the rules :^)
If you'd like to try using rtfm, here's an example how I do it there https://github.com/etrombly/sandbox
I believe Chucklefish are using Rust and have integrated the PS4 SDK into it. The short answer is yes, technically, but you can't really do it without access to the SDK for that platform. 
Yes if you have the SDK. IIRC the PS4 is x86 and the switch is ARM, both are supported by Rust.
println!("Please enter password:"); // this is just a little test, no real passwords..... let mut password = String::new(); io::stdin().read\_line(&amp;mut password).unwrap(); // do something with the input here, program never makes it this far This code does not work for me on macOS. It compiles successfully, however if I enter some text it never continues. Did I miss something?
OTP = "one true pairing"
If you wan't to build a tree/graph you can change your parent value to be Rc&lt;RefCell&lt;_&gt;&gt; or store an index instead of a reference. As far as i know, you can't generally do useful things if you have a circular lifetime bound.
I *think* the problem is your Environment structure (and the `extend` method) are defined as the "child" environment having the same lifetime as its parent. You need to have two lifetimes, `'parent` and `'child`, an environment's own lifetime is `'child`, and you need to specify their relation as `'parent: 'child` (so that the borrow checker knows `'parent` can outlive `'child`)
&gt;One more thing: the Point&lt;T&gt; is a duplicate of {integer}x2 types, like f64x2, i8x2, etc. Thank you for the reply. As I figured out that rust forbids multiplication/division of different primitive types without explicit casting, I've achieved my goal by reducing amount of generic parameters. The resulting code is a little bit prettier than yours and it doesn't require external dependencies: [Here it is](https://play.rust-lang.org/?gist=d30ee1c4bcfeeffd41fed968a7366bc1&amp;version=stable&amp;mode=debug&amp;edition=2015)
OTP = "one time pad"
Congrats! I adopted libreauth in my project. It features an intuitive API and does exactly what I need from such a library. 
The acronym refers to either "one-time pad" or "one-time password." I'm assuming this client is compatible with the TOTP (time-based one-time password) protocol.
It seems Rc&lt;RefCell&gt; is indeed the way to go. I wish there was a cleaner way, but I'll take what I can get.
The spin crate should work on cortex m. But you can have a deadlock if th√© main loop use th√© mutex, ans th√© interupt try to use it. Else, you can use a higher level framework as RTFM, but RTFM is quite broken right now.
Next, C# support! Yay!
Well actually it makes sense to use Web technologies to build UIs, since HTML CSS were pretty much designed to do exactly this. Regarding embedding Servo, yes, I think that it would be much better. But the effort hasn't been made yet and I'm not sure whether someone is going to do it one day or not, sadly :(
OAuth is pretty popular, so I‚Äôm curious what‚Äôs broken or impractical about it?
Wow, 2 auth crates on the subreddit front page at the same time! 
&gt; I believe beginners would find C++ much easier to learn than rust. Yes C++ can be more complicated than Rust but you need not use all the features in C++ because they're not mandatory. I‚Äôll bite this, because my experience is exactly on the contrary. My team (of 0 experienced C++ programmers) recently started using C++ in our C code base due to allure of not having to implement yet another linked list/vector/etc by hand. Unsurprisingly, even between all of us there are major differences in understanding of C++. Some people in my team still very much consider C++ as a `C` with an `std::vector` and keep implementing things as basic as `std::find` directly in code as they cannot be bothered to look at the documentation. Some other people struggle making object-oriented patterns to work in their favour and instead fight the short-sighted class hierarchies of yesterday. They struggle to understand basic principles like RAII, move semantics, etc. that are abundant in the standard library and are critical to writing efficient and high quality code. This is very troubling for us, because while some team members are struggling to grasp the basics of the language, the more experienced members are frustrated over having to argue about/explain every single new standard library function that some other team member has not seen before (i.e. everything that is not an `std::vector`). Heck, there was a major discussion within team about `std::abort` (because of the namespaces)! I‚Äôm sure we‚Äôd encounter all the same challenges if we used Rust instead. So‚Ä¶ &gt; You can write in C++ to be as simple and clear as possible I consider this statement to be not true (well, perhaps it is true in a context of a one-man team). Also, you can just as well do the same in Rust (and many other languages) as well. The only difference between Rust and C++ here is that with C++ one implicitly opt-ins to all of its "good" parts, whereas with Rust it is necessary to explicitly opt-out (by e.g. marking functions unsafe and not using libstd).
It is true that this makes the function boundary special. However, I think the only alternative is to make lifetimes meaningful for program execution, and for several reasons I think this is a bad idea. Your code is actually a great example for that: What is the lifetime of `x`? With NLL, it will likely be just the three lines from `let x` until `*x`. This means it is actually perfectly fine for `foo` to mutate the memory pointer to by `x`, since `x` is not a live reference any more! You would have to use `x` again after calling `foo` to make sure the reference remains live. When emitting scoped noalias metadata, we will have to anyway be careful about which scope to use. Likely, we will want to pick a scope where the reference is guaranteed to be live, i.e., used again. That is, I think the only choice that is actually still safe with NLL -- and I think this also works fine with my model. We might consider providing an operation to keep `x` "fake alive", so as to artificially extend the lifetime of a reference -- this would make NLL check that the larger lifetime actually works, and it would trigger an activation in my model checking that the memory has not been messed with by others.
Sorry I misunderstand. If I use an AVX2 intrinsic, but don't compile the program with and AVX2 cpu trarget, or apply the target_feature to the function the intrinsic is in, it doesn't work. LLVM downgrades it. 
r/https://www.reddit.com/r/rust/comments/78bowa/hey_this_is_kyren_from_chucklefish_we_make_and/?st=j951bz1d&amp;sh=79262787 Kyren also released a paper(just google that) noticed that they port the whole std lib onto PS4/Xbox/NS
Yes, that's more or less what's doing RTFM under the hook.
It's been a while since I read the rust book, so you might be right that they explain it poorly. I disagree that the c++ model is easier. You need to have every function declared in the source using it, whether through a header or otherwise. In rust you just write the function and you can call it from anywhere. You might have to prepend the namespace or if it's in another crate declare that the crate exists, but no need to declare the function again. It just works
Heads up your link is a bit off.
A really good illustration of defense in depth: - use of Rust to avoid many classes of exploits from the get go, - use of fuzzing to suss out most of the remaining potential exploits, - and hardening on top to ensure that whatever exploit remains can do as little damage as possible.
HTML and CSS were designed for a stream of content that can be as long as necessary to fit it all. Recently, HTML and CSS have been getting features to make dealing with a fixed view area nicer. For example, flexbox basically reinvents what most desktop UI frameworks have had for decades. HTML and CSS were also designed to remove as much control from scripting as possible. Recently, we've been getting more features (e.g. Media Source Extensions), but it's a "security" first situation since the browser can't trust the code it's running. Desktop applications are completely different. Features that are kind of a pain in JavaScript are built-in to desktop frameworks (e.g. menus, pop-up windows, file browsers), and you just don't need many of the features. HTML has a lot of great uses, but it's not ideal for desktop or mobile applications because it has very different design goals. Yes, it's getting features that make it nicer to use for desktop type stuff, but those features aren't unique to HTML at all and are often nicer to use in desktop frameworks. If we are going to use Servo, it would be interesting to use a different language. I'd like to use Lua for scripting in a desktop app if possible :)
It sounds like https://github.com/DougLau/footile might satisfy your requirements.
Just use lyon to generate some triangles and fill those triangles will do, i think.
I've always found criticism about syntax to be so superficial. I've used a few languages, and with each language I've had to follow a variety of style guides, from naming convention to whitespace to brace placements. At first, I found the change of syntax or style jarring, though I usually adapted within hours. Now I barely even notice it. It's surprising how quickly humans adapt, and I just let the code formatter take care of the nitty-gritty details. This does not mean that I don't prefer certain styles, of course. There are two properties that syntax should always have: 1. Clear: I despair that many languages have settled on `!` for the not operator and that many styles ask you to attach to the negated expression. `!ast` is so similar to `last`, the very important `!` does not stand out at all! 2. Simple: I despair of languages like C++ whose syntax is so complicated that parsers choke on it regularly; when the very IDE you use to develop is confused by the syntax, and fail to properly highlight, auto-format, match braces, etc... you end up cursing the language designers who did such a poor job of it. Apart from those very objective properties, I find subjective "elegance" and "taste" are so personal that they are not really worth debating. Everyone has their own preference, in the end.
Awesome work! I've been wanting to get U2F/TOTP set up, but I was annoyed that Yubico decided to become more closed instead of more open, and Nitrokey doesn't offer U2F on their devices (well, their upcoming device does, but it doesn't offer other many of the other features). Unfortunately, I probably won't be able to use this as a library in many of my projects because of the license. Any chance in dual licensing it with something more friendly to proprietary software, like the CeCILL-B or CeCILL-C? If not, that's fine, I'll just use it with my open source stuff.
[removed]
&gt; C++ header files and .LIB files are easier to comprehend than Rust's modules. I would dispute that. Header files seem to confuse a lot of beginning programmers and languages that don't have them (like: all the other languages) make life easier. &gt; What a load of horrible mess. Should've started by introducing users to a simple way to use a function say, in testfunc.rs, show how a function inside is to be called from main.rs This is actually a constructive comment and, FWIW, I agree with you. Remarkably, this is an issue that was noted [some years ago](https://github.com/rust-lang/book/issues/328). So, yeah, I agree with you. The "Module" section should start off with a simple example of breaking up your code into multiple files and then move on to the more impressive things you can do with modules. &gt; With C or C++ I just use extern keyword and i don't necessarily have to use a header to be able to call functions from another cpp source file. You don't have to use a header file in rust, either. Honestly, calling a function in another `.rs` file is about as simple in rust as it is in C++. The documentation could make this clearer, however. Although, as a side note, I don't recall finding this very difficult when I wrote a multi-file rust program although I probably had to do some experimentation.
I didn't see OP mention *anything* about OOP. RAII isn't OOP, even if it often uses objects to get that effect. For example, JavaScript is an OOP language but has no RAII. Namespaces also aren't OOP, they're just a nice abstraction to group like things together. Move semantics has nothing to do with OOP either. C++ has all sorts of features around transferring ownership or lending ownership, and these are critical to understand, especially in the context of OOP (though it's important when writing non-OOP style code as well). I think OP's team is having problems with *abstraction*, not OOP or any specific programming style, and this makes complete sense for a team familiar with C. I work with some electrical engineers who have a similar problem understanding abstraction but do really well with procedural C.
I read the link you pointed me. Oh dear god the community is toxic. They just simply refuse to acknowledge the issue and insist on beating the threadstarter into submitting to THEIR way. 
&gt; I believe beginners would find C++ much easier to learn than rust I experienced the opposite.
Well, parsing non-Rust syntax *can* be useful if you feel that the "proper" Rust syntax for what you're trying to do is inconvenient. We do have multiple parser generators, for example.
And documentation won't be there, so you'll be on your own for quite a bit of it if you run into problems.
oh, I posted the wrong link...So in edited link, they says: ‚ÄúWe had Continuous Integration that would build on the three desktop architectures, and, more than weekly, we would write code that broke on one or more of them.‚Äù Even after taking into account the ten days needed to customize Rust for the Xbox, PS4, and Nintendo Switch consoles, Chucklefish saved time previously spent debugging cross-platform idiosyncrasies. 
Noob question: I'm very new to rust style languages. If I wanted to have a file with a bunch of constants and utility functions to access globally, what is the best structure to use? Traits? In an OOP language I'd use a static class.
Title says that it has Cow semantics. Does that mean when you try to write to reflink, file system will copy whole file in reflinks place?
I encourage you to write an issue against the [book](https://github.com/rust-lang/book) with your concerns, or submit a PR with changes that would have helped you understand. Not everyone's experiences are the same and some people will just intuitively understand something, or just correctly assume, and others won't. Now that you've taken the time to understand and formalise what you expected compared to the reality, you're in the perfect position to provide feedback that could help others who weren't browsing r/rust during the short period of time this post will be active.
because there is no dedicated InteliJ editor for Rust (currently), Rust support is just a plugin piggybacking on other InteliJ editors there is 10+ dedicated InteliJ editors for specific languages, for complete list check https://www.jetbrains.com/products.html?from Menu for languages with no dedicated editor (not enough paying users for dedicated one for example) there are plugins, a lot of them, and few like Rust are supported by InteliJ employees themselves future set of Rust plugin is same in all these specific IDE versions except two exceptions i mentioned, CLion is only IDE that supports C++ style debugger (this one can be also used for Rust) so its only IDE version with debugging support for Rust (out of InteliJ editors, other like Visual Studio do also have debug support but that is different company and very different functionality and limitations) why modules are supported only on IDEA (Java version) i am not sure, but they said this is temporary and they will try fixing it in future, C++ debugger on the other hand is unlikely to appear in IDEA in short i would suggest you start with CLion
reflinking is a mechanism that leverages COW (copy on write). When you reflink a file, the new file has its own inode, shares its on-disk data with the source file. Only as soon as one of the files gets modified, the actual copying is by the OS. Reflinking is useful for file copies where you know that none of the files will be modified (or won't be modified often), such as backups and snapshotting
This depends highly on the file system and the OS, yes. On linux, only the modified blocks will get copied (the "rest" of the file is still reflinked)
Have you tried using the library on EXT4? Does it return an error?
Nothing. It's complementary. HOTP tends to be used for account recovery, think the recovery codes you are asked to save (securely!) for some services. TOTP is frequently used for two-factor authentication. Think Google Authenticator. Password schemes still see use for various reasons.
Yes ist returns the corresponding std::io::Error
So on Linux there's on BTRFS and XFS?
Have you considered using `hmac` crate instead of `ring`? To me it looks like an overkill for your use-case.
Is there not a way to just move (vs borrow) a struct into another struct as a reference instead of using a container? Seems like this would be a common enough problem that it would have a less complex solution.
I'm not a game developer but if you have a console license, you have access to the developer forums for that console, and I hear that there is a/are thread(s) on using Rust on the closed platform.
And the winner is u/kzys Congrats and enjoy RustConf :)
I'm sure there are far more C++ users though, so you'd potentially end up contributing more than receiving. That's fine, but it's certainly something to be aware of.
Why do you need access to it? If you want to know the type use io::Error.kind() which will give you an enum you can match on. If you want to display the error to a user then you can simply just add it to a format string.
That won't work. It the spinlock is taken in the mainloop, the ISR will never be able to get it (since it doesn't get preempted), and the program will be stuck. Better: Implement a custom Mutex/CriticalSection type, which is disables interrupts on acquiring the mutex and reenables them when releasing the mutex.
Does this mean I can finally have inheritance? I might as well wrap the insides of main() inside jrust then.
I want to access it because I want to tell the user for what file the error happened. And no, I cannot know what file it is since the code is in a function that accepts a list of filepaths. But I guess that converting the `ErrorKind` to `&amp;str` will suffice :)
I don't think the underlying message contains the filename. ErrorKind only returns static strings and I don't even think the OS provides this in the error output in any language. As far as I know it is the responsibility for the program to track this info and correlate the filename with the error.
Same, I avoid using GPL stuff as much as I can :/
Ah right sorry, I wasn't clear. Yes, the message doesn't contain the filename, but I can append the filename and the message and then return a custom io::Error. That's why I want it.
There absolutely is and that is the general case. The problem i'm describing is when Struct A has a reference to (a different) Struct A as in the example. Or when A has B and B has a reference to A etc. 
Yeah you can just create a new error type that wraps the io::Error with any additional information you need. Then combine this when you print out the error. Also see the [failure](https://github.com/rust-lang-nursery/failure) crate for some interesting patterns you can use.
A common criticism of OAuth2 is that it is hard for app developers to implement securely. [Some background around this criticism](https://hueniverse.com/oauth-2-0-and-the-road-to-hell-8eec45921529). That said, OAuth2 is not meant to be a replacement for mechanisms like passwords, HOTP, TOTP, or U2F/WebAuthn. So it makes sense that LibreAuth shouldn't support OAuth2. [Some background on this aspect]( https://www.scottbrady91.com/OAuth/OAuth-is-Not-Authentication). 
Maybe try `description()`?
I'll bite too. Incoming TL;DR: Modules are being worked on. Perhaps not to OP's liking, but they are being worked on. The obj.func1().func2().func3() pattern can nice when used tastefully (I agree it looks bad when it start line-wrapping, but that's a formatting issue). But nothing forces you to do it that way. I continue to use C++ for a personal project. C++ is a fine language, and it has more mature GUI support, and I (somewhat) know what I'm doing. But I'll try to explain the main appeal of Rust to me, which it sounds like OP has not considered. I am currently tracking down a semi-reproducible memory-scribbling bug in a large mixed C/C++ codebase which also contains plenty of third-party code. The least significant byte of a pointer sometimes gets cleared, causing it to point to valid but garbage memory, and chaos ensues. And not necessarily the same pointer or address, so forget watchdogs, even if they were available on this platform. To isolate it, I'll have to hope I can continue to reproduce it in a reasonable period of time, and also hope that it's not happening from another thread (which would make it much harder to track down). I will probably come off as a jackass for saying this, but some programmers can't fix this. They don't have the tools, understanding, desire, or perseverance to do so. I've seen devs insert a random NULL check somewhere, claim they just can't reproduce it, insert hacks that make the issue less reproducible but don't address the root cause, or revert a recent change that made the bug more reproducible. If OTOH somebody noticed you can fix bugs like this, then you'll be assigned more of them, because who else is really going to fix them? When you are put in that position, a language like Rust becomes very appealing, and you will put up with a lot of crap from it in exchange. I could be implementing new features or doing useful refactoring. But, I'm frustrated by the time I spend tracking down threading issues, array overruns, and other thinkos. Rust is not a magic bullet, and it has issues, but it also has promise. IMO Rust scales better than C++ wrt both code and developers. Obviously the utopia solution here is just that everybody's a good programmer, but, well, I haven't worked at a place like that yet, and good programmers make mistakes too. /rant
I, for one, would appreciate it if you explicitly disclose that you are the maintainer for a crate you're recommending. (You have the rustcrypto flair, but that's not all that obviously related to hmac or any of these other generically named crates you're publishing.) And as a counterpoint, I would much rather have my code rely on ring, where the code descends from BoringSSL and the author has an extensive history of working on security code, than on these other implementations for which the providence is much less clear to me. 
I don't see it as toxic, but I was amazed at how the community failed to grasp what he was talking about and it's clear he found that infuriating.
Mine was less pretty because it also included multiplying a point by a scalar, which was the problem you raised originally. Note also that the `T: Copy + Clone` bound on `Point&lt;T&gt;` is unnecessary, since none of your operations require it be `Copy` or `Clone`. If you want the `Point&lt;T&gt;` to be `Copy` or `Clone` if `T` is `Copy` or `Clone`, do something like: ``` impl&lt;T: Copy&gt; Copy for Point&lt;T&gt; { fn copy(&amp;self) -&gt; Point&lt;T&gt; { Point{x: self.x, y: self.y} } } impl&lt;T: Clone&gt; Clone for Point&lt;T&gt; { fn clone(&amp;self) -&gt; Point&lt;T&gt; { Point{x: self.x.clone(), y: self.y.clone()} } } ``` I know using `#[derive(Copy, Clone)]` does the same thing, but it requires those trait bounds on the initial struct itself. Here, if the unbounded generic type `T` also happens to implement Copy/Clone, the `Point&lt;T&gt;` will be Copy/Clone. **But you can also make a `Point&lt;T&gt;` of a type that doesn't implement Copy/Clone.** It's like what you did with `Add, Sub, Mul, Div`; you only implemented `Add&lt;Point&lt;T&gt;&gt;` if `T` implemented it.
Works for me on OS X as-is. What error are you getting?
Thanks for testing. No error, the terminal does not "accept" the input however. I can press return all I want, it just opens another line.
Hmm. Which terminal are you using? It works for me in both the OS X \`Terminal\` and \`iTerm2\`. Maybe it's set to insert something other than \`\\n\`? Do any other combinations work, like \`Shift + Enter\`, \`Ctrl + Enter\`, \`Ctrl+R, Enter\`?
Yes, that just moves the cursor to the next line.
Try running it in a new terminal? Or: copy and paste this into `test.rs`: ``` use std::io; fn main() { println!("Please enter password:"); let mut password = String::new(); io::stdin().read_line(&amp;mut password).unwrap(); println!("Input: {}", password); } ``` And then `rustc test.rs` and `./test` **inside the native Terminal app**. If that doesn't work, there's something _seriously_ wrong with your machine.
Nice, but that doesn't return the message from OS.
`io::Error` implements `Display`. // Say you have a `&amp;Path` named `file`, and an `io::Error` named `why` eprintln!("{} failed to open: {}", file.display(), why
All great points. I'm always a bit torn on how important these kinds of rankings are; some people ignore them, but others take them very seriously.
+1. Damn, was it that simple? There's an extra piece of information, "(os error x)", but I can blow it away :) If we were on StackOverflow, I'd mark this as the answer.
Thanks! This would be handy for a tool I'm making.
&gt; I find it much more difficult and verbose Verbose in what way? You criticized the language for feeling like a dynamic language due to not being verbose at the end. You're contradicting yourself. Rust is not verbose, it is explicit. It conveys precisely what it means to convey, and does not waste time with conveying what is already known (the types are inferred based on context). &gt; .func1().func2().func3() This is easier to reason about than the onion syntax, where the inner-most expressions are evaluated first, and then evaluation gradually moves back to the start. func3(func2(func1(value), arg), arg) The syntax also has nothing to do with Javascript or promises. The syntax existed well before JavaScript was even a thing. &gt; I believe beginners would find C++ much easier to learn than rust. I've yet to hear anyone say that. &gt; in Rust you seem to be forced to do things their way I'm assuming you're referring to the ownership model. It's not about doing things Rust's way, but about doing things the right way. Rust makes it easy to find flaws in way that you're managing memory in your software. It will therefore ensure that you're able to guarantee that your memory is being handled safely. C++ allowing you to get away with outright undefined behavior with zero guarantees is not a good thing. &gt; But due to lack of jobs It's a sad day if that's your only evaluation of a programming language's value.
Better better: use a lock-free FIFO queue (some equivalent of `boost::lockfree::spsc_queue`) and you don't have to worry about locking.
I don't know about JavaScript and C#, but I am pretty sure it will not be easy. I think that Lua via [`rlua`](https://github.com/kyren/rlua) will easiest and closest to production ready solution. Other more experimental solution is [`dyon`](https://github.com/PistonDevelopers/dyon), but it's again dynamically typed. If you really-really want to use strongly typed language for scripting and don't mind experimenting with bleeding edge then you could try WASM via [`wasmi`](https://github.com/paritytech/wasmi), with Rust as your scripting language. ;)
What I used to print error messages when a function failed to open a file (because it didn't exist): match File::open(somepath) { Ok(file) =&gt; do things here with opened file... Err(e) =&gt; eprintln!("{}", e); // This will print the OS error message }
Thanks, but as I said at the end of my post, I had tried figuring out a configuration scheme using TOML, but it got really messy.
You can use any of the formats supported by serde, like yaml/json/etc. You can even change your mind about format and only have to change one line of code. Honestly, serde is great.
Right, I just tested it: No such file or directory (os error 2) # Display trait entity not found # description() Error: Os { code: 2, kind: NotFound, message: "No such file or directory" } # Debug trait I always thought `description()` would be the same as the Display implementation. This is probably the `&amp;'static str` limitation the sibling mentions. Anyway, /u/mmstick already gave you the right answer.
Hey! Thank you for writing nom! :) I realize now that I didn't impart this in the slightest, in my original post: parsing each of these blocks would be fine, if there were only one each. In reality, I'm figuring there would be any number of `listen`, `set`, `pool`, etc. blocks, and in any order. What I am having trouble figuring out, was how I could parse multiple instances of each of these blocks, in any order.
I think after Rust 2018 and async/await story stabilization it would rise up! :) p.s. Completely disagree with rating results, in my opinion the ecosystem getting more and more power.
Thanks, /u/richhyd! I've played around with serde already, and while it's super awesome, I'm still pretty timid with Rust, and I was feeling a little stunned when I saw what was required for writing custom implementations of the `Deserialize` trait on my types. My sources of inspiration for the configuration format are [pf](https://man.openbsd.org/pf.conf.5), and haproxy. I spent a good chunk of time trying to figure out how to express the `policy` block (in my example above), in a structured format like JSON, YAML, or TOML. What I'm tyring to achieve with the `policy` block, is a list of ordered rules for determining how to handle a DNS query, where the last-applicable rule wins (similar to pf, or iptables).
Gc&lt;T&gt; is not mutable.
Aah I think I see - the tools you mention define their own simple language for describing rules. What i would say is: don't worry about parsing anything until you are happy with your data structures. Use structs, enums, vecs, options, to accurately map your data model into code, so that it's not possible to have inconsistent states, if possible. Once you know what your data needs to look like, you can start to design the config. You can serialize into some types using serde's derived ser/de impls and see if it looks reasonable - this might save you a lot of effort in the long run. I guess I just think that designing your own language is quite a big undertaking.
The Clap library prints in help.rs/write_default_help the help message in order: bin_name, version, author, USAGE, .... How can I replace this default with a customized help that starts with USAGE and ignores bin_name, version, author? There is a function write_templated_help, but I can't figure out how to this custom template engine :-/ Bonus points if it works with structopt, too. 
How do you see the tower crates in relation to the rest of the more inhomogeneous ecosystem like actix(-web), rocket, grpc, capnproto-rpc? For example, I really like actix-web, but a more homogeneous crate ecosystem in relation to a http based service / API stack would be more sensible in my opinion. Writing a multi API application is a bit a crate hazzle for now... :-/
I'm using wasm as an embedded language as well for a project, but the huge downside to that is that you can essentially only execute Rust, as all other languages make heavy assumptions about the host.
Hey everyone! I'm having an issue with a dependency in my cargo.toml. I am using Ubuntu (Windows Subsystem for Linux) I created a blank project and added this to my Cargo.toml [dependencies] poly2tri = "0.1.0" when I enter "cargo run" I get c++ compilation errors the gist of the error message seems to be that usage of "auto" has changed in c++11. Is there a way to pass in c++ compilation flags in my .toml? Or am I misunderstanding the issue? Here is the full error log in case it helps... https://pastebin.com/M6KFgLmJ
&gt; Contributions/testers with access to a Windows Server welcome. Microsoft does have [evaluation copies of Windows Server 2016](https://www.microsoft.com/en-us/evalcenter/evaluate-windows-server-2016) that you can use for 180 days. That's not much for a server, but it should be more than enough to install the Visual Studio Build Tools and run "cargo test" a few times. ;)
Fair enough, and thank you for the suggestion. You're probably right; I tend to work from one end of the program, to the other. Meaning, I'll typically write the entrypoint &amp;mdash; along with the configuration parsing &amp;mdash; first, then worry about satisfying the intent of the configuration afterwards. Again, thank you for the gentle reality check. I'll probably hold off on configuration parsing, unless I have an epiphany or something.
lol fuck c# with a carrot, dont wanna touch that shit if I ever play your game - would rather use JS.
&gt; I find it much more difficult and verbose compared to C++, yet it does not reward me in the same manner. Can you give some examples? Do you actually provide same amount of information to compiler in C++ and Rust? &gt; The modules management are not to my liking. I don't like the way it is implemented. They need to fix this. What needs to be *fix*? In the end, C++ doesn't have *any* modules management, they debate about modules for last decade, but they are not here. Do you wish Rust abandon its modules to be more C++-friendly? &gt; The language is unnecessarily verbose at some area and it seems to try too hard. It's like a mix between C++ and Javascript. That Promise style .func1().func2().func3() pattern is ugly and I hate it. I don't want a systems/game development language that feels like ugly javascript. 1. You always could write ```rust let a = func1(); let b = func2(a); let c = func3(b); `` 1. What alternative do you suggest? &gt; I believe beginners would find C++ much easier to learn than rust. Yes C++ can be more complicated than Rust but you need not use all the features in C++ because they're not mandatory. You can write in C++ to be as simple and clear as possible but in Rust you seem to be forced to do things their way. Well, your believe is wrong, based on comments on reddit. I'd actually be surprised if brand new language would be harder to learn and understand. All successor languages are trying to get best traits from their predecessors, as well as remove their cons (nice reference to LISP, isn't it? :) ). &gt; But due to lack of jobs and purpose of Rust, I don't find it a useful language because C++ already has everything I need where Rust is trying to replace. It is also over-engineered and feels like a dynamic language (even though it's not) You are probably too young, but 20 years ago all bank software was written in COBOL and there was plenty of COBOL developers, and there was a Java "for coffee machines". Well, nowadays you can see that things have changed. And you probably don't want to be on of these COBOL developers. Yes, there is not much demand in Rust developers, but 1. things may change 1. sometimes you learn language just to shift your mind. You can learn some new language and start writing better code in your *current* one. No jokes, you can learn Rust to write better C++ code. I suggest you to read [Beating the Averages](http://www.paulgraham.com/avg.html) article, it's wonderful. &gt; I find the user manual/documentation to be a long winded text. Every documentation is a long winded text. But you probably want to have one rather than none :) You will thank this "long winded text" later. &gt; Anyway, I hope Rust can improve in time. The tooling is good, just the language and module organisation leaves a lot to be desired. I hope that too. I actually hope that every language will improve, and I wish C++ get better tools and modular system. --- I apologise if I was too sarcastic or offensive, I didn't mind it. I hope you will just reconsider your position. I have been talking with chinese developers and here is a direct quote from one: &gt; Too young to simple, sometime naive! &gt; rust, haskell, prolog they are all engineering fail language &gt; Software engineering is not some kind thing that just mind shift at all &gt; Programming 15 years in C/C++ for OS kernel like me, then you can talk about what is good what is bad &gt; don't be a "syntax expert", be a real developer please! You can see that this guy is writing in C++ 3 times more than I program myself, but it's stuck in his role. He's writing the same bugs over and over again. He's an expert in all C++ pitfalls. But I don't think he may create something really new and shiny. He's virtually dead as a developer, he's coding from day to day, but his soul is burnt. Don't be like him. Read the article I linked above and be a real developer. I hope you will succeed. 
why do you think C# is shit?
&gt;This is easier to reason about than the onion syntax, where the inner-most expressions are evaluated first, and then evaluation gradually moves back to the start. f(g(h(x))) is something that confuses high school maths students for about half a lesson, and then they get it. Never been an issue since. Not sure why you think it's 'harder to reason about'. It's much simpler. No special argument. Why would the first argument be special?
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rustjerk] [\[Call To Action\] Drop whatever you're doing and hit StackOverflow NOW](https://www.reddit.com/r/rustjerk/comments/96k8la/call_to_action_drop_whatever_youre_doing_and_hit/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
It might be difficult to use with CeCILL license. It means another step to get approval from compliance tea, which is time consuming process. 
Upvoted because Shepmaster is a supernatural being that does not rest.
That's excellent news :) I know from experience that Java benchmarking is challenging. From Java8 onward the thresholds for C1 (the cheap compiler using various levels of, or absence of, profiling info) and C2 (optimising compiler) depend on the how much compilation effort is queued - if you're right, that the code-based is highly focused on a very small number of paths, you might be getting C2 compilation early (and therefore will continue to see stable results). IIRC -XX:+PrintCompilation doesn't say which compiler was used until Java10. The hope is that all of the hot-path methods get C2 compiled. I expect that in your busy 30min, 100 iteration run that this will have happened for the most critical paths. Thanks for the effort and the great work.
North America accounts for only 5.9 million of the 24 million GitHub users (source: [https://octoverse.github.com](https://octoverse.github.com)) That said, StackOverflow is just not something we send new users to. Only those that go there naturally would ask questions there. There are plenty of other forums pointed to by the official Rust documentation to get help (urlo, irc, etc). This likely means that we're being scored lower there just because of our beginner help venues.
It doesn't compile on latest nightly and is not compatible with latest cortex-m-rt. I manage to make it working here https://github.com/TeXitoi/wave-test but with nightly-2018-07-10 and stm32f103xx 0.9 when 0.10 is available. But that's a really good software, just the maintainer is overbooked.
What library are you using for WASM? Also what platform (s) are you targeting?
Or [dyon](https://github.com/PistonDevelopers/dyon), though it seems to be dynamically typed.
I guess it really depends on how you want to handle errors.
I think StackOverflow is significantly less relevant overall nowadays, all things considered, than many people think it is. Personally it would never even cross my mind to go there for anything for any reason, ever, when I know from experience that in the majority of cases asking on a language-specific forum or chat room for whatever my problem is is hugely more likely to result in a correct answer in a far shorter amount of time. I honestly feel that SO is an increasingly pointless early to mid 2000s relic that isn't actually very useful at all, and I really don't think I'm alone on that.
The error suggests that something went wrong in the build script. From looking into the repo, there seems to be a fix but hasn't been merged (2 years ago...), so you probably need to fork it and add the changes and use this as your dependency. The fix is just adding for linux systems a cfg flag for it.
&gt; It's much simpler. It is backwards. Consider a diagram: f g X ‚Üí Y ‚Üí Z A natural order for composition is, of course, the [diagrammatic order](https://ncatlab.org/nlab/show/composition): `f g`. But the standard notation is backwards: `g(f(x))`. Nowadays, with the discovery of the category theory, there's no reason to prefer the backwards notation.
I agree with the first part. I'm sure async/await is going to result in a LOT of questions on StackOverflow which will surely boost Rust into the top 20 :P No, but seriously, I think a lot of people have been waiting for async/await to stabilize before making another thrust at Rust.
It makes sense. It's hard to get excited for something if there's that lingering doubt it your mind that what you're investing time into is going to be supplanted or forgotten within three years time. Rankings like these can become a sort of confirmation bias that you've made a good decision in backing a technology.
I'd like to add: the Error trait requires that Self implements Display and Debug. Therefore, every error message can be printed 
This isn't supported on NFS right?
You can use cranelift-wasm.
No, Windows only supports this on Windows Server on ReFS and smb shares
Thanks for the help. I can't believe I didn't think to check the PRs. It's too bad the crate isn't maintained.
&gt; Absence from Stackoverflow: seriously, who *actually* uses StackOverflow? And why?
I must be doing something wrong, because I read Stack Overflow a decent amount (though I never ask or answer any questions). But the frequency really depends on the type of project and how high up in the Google search rankings it is. If I'm working on something unfamiliar, I might refer to it a lot. If I'm working on something familiar, I might not use it at all.
It may be the end of the beginning but it most certainly isn't the beginning of the end, keep up the good work!
I looked at cranelift because I wanted to mess around with making a Lua VM with a JIT, but there were a few things I couldn't figure out from the documentation, and I kind of gave up since I didn't want two large projects. I didn't know that `cranelift-wasm` was a thing, which is pretty neat. It would probably be easier to target WASM than cranelift directly, so I'll have to check it out.
That would be awesome, but I think it would make more sense to either contribute it as an example to the project or make a post about it so others can benefit as well. And yes, the documentation could use some improvements. I spent an hour reading through it and couldn't figure out whether it was complete enough to use.
In my example im using DummyEnvironment, even though they say you should only use it for tests, but it works and I don't know what makes a good evironment. And im using some unsafe code, that could likely be made safer.
I understand this sentiment for Rust, which actually has a high-quality forum. But how would you *ever* do web development without Stack Overflow? There are just so many high-quality answers, and frankly, where else would I ask questions?
I don't see a lot of multilingual usage of stack overflow so less precence there could simply be because the language used on stack overflow is not always forgiving to non-English speakers. 
Not the advice you want, but I'd recommend formatting your crate with rustfmt: https://github.com/rust-lang-nursery/rustfmt, especially before a code review. 
This is super helpful! I hadn't heard of this before. Thank you!
I use it as a quick lookup for basic C++ questions ("how do you inherit from a base class that takes arguments in its constructor" etc.).
In `Puzzle::print`, you can use [`String::push`](https://doc.rust-lang.org/std/string/struct.String.html#method.push) to add characters instead of adding them to a `Vec` and then joining them into a string. Several functions, including `Puzzle::contains` and `Puzzle::check_guess_string` take `String` as input when they could use `&amp;str` just as easily. This saves on `to_string` or `clone` calls, makes it slightly more efficient, and makes it easier to make some kinds of changes later on. From your comment in `Puzzle::Update`, I see you've run across one of the annoying aspects of Rust's strings. They're stored as UTF-8 with no index, so you can't directly access the characters. Some ways around that: * Change the string you're storing to a `Vec&lt;char&gt;`. That's effectively converting it to UTF-32, which can be accessed directly since every character is the same width. A simpler way to do that than what you have in the code right now is `let chars = self.current_puzzle_board.chars().collect::&lt;Vec&lt;char&gt;&gt;();`. * If you know that the string is ASCII, you can index the bytes directly. The program will panic if you try to index a single byte out of a multi-byte character. You can use the [`str::is_ascii`](https://doc.rust-lang.org/std/primitive.str.html#method.is_ascii) function to check this ahead of time. I don't imagine that Wheel of Fortune is all that friendly to any characters besides the 26 English letters anyways. In `Puzzle::get_dashes_from_` (which I'd rename without the trailing `_`), there's a pattern that I see in a few other places that's like `for value in iterator { other_collection.push(some_function(value)); }`. You can make that more concise and easier to understand by using the iterator function `map`. The fragment above turns into `let other_collection = iterator.map(|value| some_function(value)).collect()`. That makes it clearer at a glance that what you're doing is making a collection with one element for each element in the other collection. In `Puzzle`, it's probably better to make `guesses` a private member too. Any type that has invariants it needs to uphold (which is pretty much anything more complicated than `Point { x: i32, y: i32 }` should make sure that the variables can only be accessed through functions that preserve the invariant. If you still need to be able to read the value, you can make a `fn guesses(&amp;self) -&gt; Vec&lt;String&gt; { self.guesses }`. That will other parts of the code read it but not change it. Small thing with your use of `rand` in puzzle.rs: it provides a [`sample_slice`](https://docs.rs/rand/0.5.5/rand/seq/fn.sample_slice.html) method that you can use to directly choose an element instead of choosing an index and then using that index. Just a way to make it a little less likely that a change you make later might break that code. This one is more of a convention, but with other peoples' projects I've almost always seen their mod.rs containing only declarations for the submodules and re-exports, not any code of its own. What's in there right now might be better organized in a new file named game.rs.
Still trying to figure out some really basic stuff here. This code: fn mean(v: &amp;Vec&lt;i32&gt;) -&gt; i32 { let total: f64 = 0.0; for &amp;i in v { total += f64::from(i); }; total / v.len() } This gives me the error "can't divide f64 by usize" but I can't seem to find any way to convert usize into f64 as with ::from() Seems like there is something a little odd with usize that I'm not understanding.
Rust doesn't do automatic numeric casts, so you need to add them: (total / (v.len() as f64)) as i32
It's just convention. `std`, Haskell and many other languages call it a prelude so that is the name people tend to use. Some people like to call the module `util` and it's just the same. The compiler doesn't do amythinv special to it.
If `Row` and `FieldNames` are fixed types, Try this: ``` struct FieldNames {} struct Row {} trait Relation : Iterator&lt;Item = Row&gt;{ fn row_count(&amp;self) -&gt; usize; fn names(&amp;self) -&gt; FieldNames; } struct Test {} impl Iterator for Test { type Item = Row; fn next(&amp;mut self) -&gt; Option&lt;Row&gt; { None } } impl Relation for Test { fn row_count(&amp;self) -&gt; usize { 0 } fn names(&amp;self) -&gt; FieldNames { FieldNames {} } } ``` This just means that any relation type you define must also implement Iterator. This gives you the `next_row` functionality you want, with the added perk of working in for loops, e.g.: ``` let x = /*something that impls Relation */; let rows = x.row_count(); for row in x { /* do something */ } ``` If you wanna spice things up and use a generic `Row` trait instead of a fixed struct, you can do this: ``` struct FieldNames {} trait Row {} trait Relation&lt;Row&gt; : Iterator&lt;Item = Row&gt;{ fn row_count(&amp;self) -&gt; usize; fn names(&amp;self) -&gt; FieldNames; } struct Test {} struct RowImpl {} impl Row for RowImpl {} impl Iterator for Test { type Item = RowImpl; fn next(&amp;mut self) -&gt; Option&lt;RowImpl&gt; { None } } impl Relation&lt;RowImpl&gt; for Test { fn row_count(&amp;self) -&gt; usize { 0 } fn names(&amp;self) -&gt; FieldNames { FieldNames {} } } ``` 
&gt; hi rust friends. Engineer from Discord here. Now that the press is out (we're launching a game store). I just wanted to thank the rust core team, community and contributors for building such an awesome language. Rust has been a significant technology investment for Discord! For example, all the native code that powers the store is written in rust, Our game SDK is written in rust (with C, C++, C# bindings), and our multiplayer network layer is also in rust! Honestly, it's been nice to write all this stuff while avoiding a huge class of problems that we woulda had in C++. --- Transcription made with https://ocr.space
What's Nebulet? 
The irc channels #rust and #rust-beginners are probably a big reason. I frequently got high quality answers within minutes from all the awesome people in there when I got started with rust.
If anyone wants to play around with xi, I made a pure rust GTK frontend called gxi. It's still a little rough around the edges. https://github.com/bvinc/gxi
The is the subreddit for the rust programming language. You're looking for /r/playrust
You could also do this from userspace (as root).
I really love these little cross-platform libraries. Other favorites are [clipboard](https://crates.io/crates/clipboard) for clipboard and [scrap](https://crates.io/crates/scrap) for screen capture.
Gotta admit, this would be an interesting feature for a compiler.
I've used it a few times with mixed results. But I've never felt like asking a Rustlang question makes sense there.
 cargo build REEEEEEEEEEEEEEEEEEEEEEEE
&gt;The widely used standard for mathematical syntax is flawed as well, and alternative syntaxes do exist that eliminate the need for them. Polish Notation avoids the need for PEMDAS rules entirely. For example. + 5 * 8 4 can be read as "Add 5 after multiplying 8 by 4", which is equivalent to 5 + (8 * 4). Unlike our standard mathematical syntax, Polish notation here fits better with how you would say it with words. I disagree entirely that that's how people say formulas out loud, but even if it were, that's not a good reason to adopt particular notation. The universal standard on the precedence of mathematical operators is not flawed, it's the result of many many years of people trying out alternatives and them coming up short. &gt;What we're describing are linear, logical steps. There's no need to use a backwards syntax to describe that linear progression. The onion syntax can get quite confusing, and it gets very messy when what you have is a long series of sequences. What's hilarious about this nonsense is that you literally suggest using polish notation above for mathematics, which is **exactly the opposite of what you're saying below**. `5 + (8 * 4)` is essentially `5.add(8.times(4))`, while `+ 5 * 8 4` is essentially `plus(5, times(8, 4))`. There's no such thing as 'onion syntax'. f(g(h(x))) is not 'backwards' any more than 5 + 3 * 2 is 'backwards'. It's outside in. There's nothing backwards about writing it outside in. It's how function application is written everywhere. It's perfectly easily understandable. If an expression is complicated enough that you find it hard to read, you should factor it out into separate expressions, not invent ridiculous new notation. &gt;There is no 'special argument'. It is merely invoking a method that belongs to that value, and each following chain is invoking a method that belongs to the value returned by the last expression. Most programming languages support this functionality. There is absolutely a special argument. The first argument to a function is made special, able to be placed first as in `w.f(x, y, z)` instead of along with the rest of the arguments as in `f(w, x, y, z)`. The latter is far more sensible.
&gt;North America accounts for only 5.9 million of the 24 million GitHub users (source: https://octoverse.github.com) I don't see how that has anything to do with what I said. &gt;That said, StackOverflow is just not something we send new users to. Only those that go there naturally would ask questions there. There are plenty of other forums pointed to by the official Rust documentation to get help (urlo, irc, etc). This likely means that we're being scored lower there just because of our beginner help venues. It literally doesn't matter. It's an irrelevant ranking that nobody should pay any attention to whatsoever. You don't have to invent reasons why it might be wrong, it's *prima facie* wrong.
&gt;A natural order for composition is, of course, the diagrammatic order: f g. But the standard notation is backwards: g(f(x)). Complete nonsense. &gt;Nowadays, with the discovery of the category theory, there's no reason to prefer the backwards notation. LOL. Category theory has been around since the 1940s, before the first computers. Category theory has not been recently discovered. It's always been around. And it has absolutely nothing to do with programming whatsoever. The reason to prefer the normal forwards notation f(g(x)) is that it's simpler, it's easy to understand, and it represents what's going on perfectly. 
This is definitely true. Stack Overflow pages often are high in Google search results, and I tend to prefer them because it's a familiar page layout and answers are often clear and short. I can go in, get what I need, and get out, without having to wade through a long blog introduction to discover if the page is actually about the problem I'm trying to solve.
I kind of worry about the inrush of people once async/await becomes stable. I suspect it'll be a little more time until people find the right patterns to use it painlessly with Rust, without getting annoyed by lifetime problems.
What is frc?
That's indeed true, but sometimes I wonder if their curation isn't doing some harm **for this kind of benchmarks**: they really eagerly marks question as duplicate, which reduces the number of active questions about Rust on StackOverflow.
Bookmarked!
About the absence from StackOverflow: I'd add the really active irc channel #rust-beginners. I personally don't use StackOverflow anymore since I know I can get answers on IRC in about 5 minutes. Maybe I should try and post these questions on stackoverflow anyway, with the answer to help other people.
Unfortunate that I won't be able to use it because of the license :\
This is an old link, but I could find https://github.com/google/xi-editor/blob/master/docs/docs/crdt.md on master.
First two paragraphs: This document contains a detailed description of the data structures and operations Xi uses for text. These data structures and the merge operation also form a **Conflict-free Replicated Data Type (CRDT)**. It being a CRDT * allows Xi to be used for concurrent editing of text on multiple devices, * can merge edits, including those made offline, between multiple devices * converge on a consistent document that includes all changes. Beyond synchronizing text, these data structures and operations allow Xi to * handle asynchronous editing of the text from plugins, * support undo and redo, * allow incremental updating of editor state and the view based on differences between revisions.
&gt; Complete nonsense. Oh really? Than why the pipeline operator became so popular in modern functional languages? &gt; LOL. Category theory has been around since the 1940s, before the first computers. And most people are still ignorant of it after so many years. &gt; and it represents what's going on perfectly In reverse order. Because to get the result of `f(g(x))` you have to compute `x` first, then `g(x)` and then `f(g(x))`. 
[https://discord.gg/9c7MYX](https://discord.gg/9c7MYX)
You're looking for /r/playrust . This subreddit is for worshipping the process of oxidation.
Hi! I'm writing a rust wrapper to a web music api and I'm trying to maximize code reusability within similar objects, but every approach I can think of seems *off*. The exact use case is: * Access a resource appending some text to a url depending of the type "tracks/", "albums/" and some id (u32). * Capture the response with serde. * Return the resource as a type "Track", "Album". **Approach 1** Use a generic function that returns the type used to call it and use trait bounds. impl Client { pub fn get&lt;T: UriId + Capture&gt;(&amp;self, id : u32) -&gt; T { ... } } and call it: let tr : Track= client.get(135794); I don't like it because it can't infer the type and forces you to specify it. It seems to me that this is the best option, but I don't know if it is rusts way of doing things. **Approach 2** Returning the value in one of the arguments: let tr = client.get(tr, 135794); **Approach 3** Calling it with an enum and returning another enum, with one variant for each type. It seems to me that it would waste a lot of memory somewhere, but I do not know a lot about rust internals (yet). 
It's an AGPLv3-licensed library. If you wish to build a BSD-licensed application utilising it, you're outta luck.
Would it be possible to add another function that attempts reflink, and if that fails because the operation is not supported or spans multiple filesystems, does a copy?
Or a pre-condition violation. E.g. only call this unsafe method with a non-null pointer. When the user calls it with a null pointer, the method is allowed to panic (but it doesn't have to).
&gt; On the other hand, the type of user who runs into nontrivial problems in Rust might just be more predisposed to do thorough research before asking a question. This is what I was getting at with "less beginner programmers". When starting in programming it's easy to get bogged down by rather trivial issues, as time passes however, your experience in exploring the unknown grows and you need less and less help to find the answer.
&gt; And who is shepmaster? The top user on the Rust tag on StackOverflow; not only does he have about as many answers as all other users combined, but even when he does not answer he will often edit either question or answer to correct the formatting, spelling, and keep both up-to-date as the language evolves. He's hard to miss if you ever check Rust questions on StackOverflow. In "real life", he's the cofounder of Integer32, a Rust consultancy, with Carol Nichols from the Rust Programming Language book. 
&gt; I also like how you're *immediately* shown the highest voted answer, isolated from other noose. I've never seen another site do that well. Though, as the site ages, the highest voted answer is increasingly obsolete. Nobody has found a good mechanism to that phenomenon yet :( 
how does this compare to existing protocols that serve the same purpose, some of which also build on crdts? [gobby / libinfinity](https://github.com/gobby/libinfinity), etherpad &amp; forks and [tandem / teletype](https://github.com/typeintandem/tandem) come to mind.
By default, a type parameter is `Sized`. If you want to specify that `T` can be something that is not `Sized`, you can use: struct BoxWrapper&lt;T: ?Sized&gt; { /* ... */ } impl&lt;T: ?Sized&gt; BoxWrapper&lt;T&gt; { /* ... */ }
&gt; I personally don't use StackOverflow anymore since I know I can get answers on IRC in about 5 minutes. I think this has a lot to do with it. StackOverflow is **scary**, it has developed a reputation for being tough on newcomers, and it is, really, if only because it requires effort to post a MCVE (Minimal, Complete, Verifiable Example). On the other hand, there are other venues, such as IRC, which are not as demanding for two reasons: - the questions are not meant to be permanent, so it's OK if there's less context exposition and less refinement, - IRC is a chat, so questions do not need to be posted as a "block" and instead will be more of a conversation with other users guiding you into what they need (and pointing out what is useless). So I am not surprised that users would shy away from StackOverflow and instead use more informal venues. Easier, less scary. &gt; Maybe I should try and post these questions on stackoverflow anyway, with the answer to help other people. I think this would be helpful. I may be naive, but I still believe in the original goal of StackOverflow: building a database of curated questions/answers so that one doesn't have to *ask* one's question, instead one can find the answer in a matter of seconds using Google. I do believe that this approach scales better, though maybe the Rust community does not have such a large influx of newcomers that such scaling is necessary yet :) 
&gt; If an expression is complicated enough that you find it hard to read, you should factor it out into separate expressions, not invent ridiculous new notation. If your notation requires excessive refactoring just to be barely readable, then something is wrong with it.
If you statically link against this, sure. But this project seems to me more like an interactive program than a library. You can use it as a program however you want without it ever affecting your project's licensing (just as you can compile things with GCC all you want without having to make them GPLv3).
Rereading your post, I think I only repeated things you already said anyway :)
A kernel executing WASM programs in ring 0.
oh, in that case, you could put the sub elements in an enum, and have an alt or switch parser that returns a sub element in that enum form, and the top level element a many of that parser. You can then post process the vector to assemble the elements by type, etc. You could also take a look at the permutation combinator
This C function has confusing argument types . I assume the `p` prefix means `pointer`. For `pNumberOfBytes` you're passing a pointer pointing to memory address `result.len()`, NOT a pointer pointing to the value of `result.len()`. My guess is that you have to pass a pointer to a memory address containing the length of your buffer. Something like: let mut len: u16 = result.len() as u16; receive(result.as_mut_ptr(), (&amp;mut len) as *mut u16, std::ptr::null); Note that this assumes a NULL pointer is valid for the pMoreDataAvailable argument. You might as well have to do the same thing as with len there.
I totally understand your frustration and generally have the same opinion, but right now, it's necessary since the language is still very much in development. It's unclear what exactly idiomatic Rust APIs should look like and it needs to be figured out by trial and error. Especially with an uncommon mechanism like lifetimes, a sweet spot between copying and explicit passing is yet to be found. I'll give them three years so they have time to land async, NLL and the other big fish; if the "identity crisis" isn't at least partially solved at that point, it would be time to look for another language. It would mean it's either ridiculously hard to make the type system and borrow checker work nicely, or the language designers lack the skill to do so given the constraints of the existing language.
&gt; But this project seems to me more like an interactive program than a library. Ehm: &gt; Xori is an automation-ready disassembly and static analysis library
That solved my problem, thanks!
Thanks!
Your points about the familiar format vs random blogs are spot on for me. I guess I should start paying some attention to who's written the stuff I'm reading. Thanks for the explanation!
&gt; feels like a dynamic language I know that feeling, I almost always get it when I can't tell what's going on under the hood. Frameworks are the worst, like having to reach elbow-deep into the mouth of a huge animal I know nothing about. &gt; I find it much more difficult and verbose compared to C++, yet it does not reward me in the same manner. That was my first impression as well. It became much better the moment I decided to stop fighting the borrow checker and stuffing things into nested `Vec`s instead of structs. From there, I was able to make progress and it felt better. &gt; The modules management are not to my liking. I don't like the way it is implemented. They need to fix this. Yeah they suck. I have to look them up pretty much every time I touch Rust code. &gt; The language is unnecessarily verbose at some area and it seems to try too hard. It's like a mix between C++ and Javascript. One word: E X P L I C I T N E S S. They tend to go overboard on it. &gt; I believe beginners would find C++ much easier to learn than rust. Yes C++ can be more complicated than Rust but you need not use all the features in C++ because they're not mandatory. You can write in C++ to be as simple and clear as possible but in Rust you seem to be forced to do things their way. Having done both, I can confirm this. All of it. Of course it depends on the introduction you get, but I feel that one can have a much better time with mediocre C++ tutorials than with even excellent Rust ones. I want to emphasize that I haven't given up on the language despite all of the above and was able to get a better at it over time, but this thread should serve as an example: **This is the first impression people get from Rust. It needs work.**
&gt; So what is the difference between having to specify the storage type and using MatrixMN ? Is there any advantage ? There is no difference besides the fact `MatrixMN` is easier to use. So there is no advantage to specify the storage type explicitly. I would say it is better to avoid specifying the storage as its is more error-prone because not all storage can compile with all dimensions. &gt; I will add this way of indexing because it looks far better! Just I think it is odd that in this case the first index correspond to the rows compared to the column major mode adopted when reading the values of the matrix. It is a bit confusing. The `(i, j)` indexing aims to be closer to the mathematical notation where the first index is always the index of the row. The difference here is that those indices are 0-based while mathematics usually start at 1. Indexing with a single integer `i` on the over hand sees the matrix as a single vector, so it has to follow the layout of the matrix in-memory (which is column-major as you mentioned). &gt; But you may need to further verify if what I wrote is correct. From now I will rewrite my post to include your comments. Besides the few remarks I've made so far, all the rest looks actually right to me and very well explained! 
FIRST Robotics Competition I think.
Shepmaster is the solution to that problem :P but not every language is fortunate (or small?) enough to have a Shep
In that case I am even more confused as to what this is.
It is an interesting conversation to be sure that we should learn from. Though for the record, in my experience the Rust community is the *least* toxic programming community I've ever witnessed.
How does one update things that has been installed with Cargo?
Instead of doing a review like Minno, I instead opted to fork your repo and do the review as a [series of commits](https://github.com/Measter/Wheel-of-Fortune/commits/master). If you start at the bottom of my commits and work your way up, the comments and changes will make more sense as I change the same part multiple times.
If you want something structured and proven to work, these books are basically the authority on their subjects: - Randal E. Bryant -- Computer Systems: A Programmer's Perspective (3rd Edition) - Andrew S. Tanenbaum -- Modern Operating Systems (4th Edition)
Might be nice to add Trinity (c++): https://github.com/phaistos-networks/Trinity
Is there any difference in performance between (memory vs mmap) when everything is cached in mmap and searching with only a single thread/core ? Meaning does mmap have to do (any/a lot of) serialization ?
Which one should I read first ? considering the facts : 1. I am following the tutorial: [https://os.phil-opp.com/](https://os.phil-opp.com/) 2. I am a noob to OS development 3. I like hands on practise more !!! 
I have a just forked rtfm and ported to nightly 1.30 [here](https://github.com/MabezDev/cortex-m-rtfm). It's not perfect though, currently can't use systick as a interrupt source (I've replaced with a basic timer).
kinda wierd question but sense this is disigned to be paralel could you compile this to almost entirely run on the gpu?
It's a high school robotics competition. Teams are given a challenge they need to design for, and they have 6 weeks to design, build, wire, and program a bot to face that challenge as best it can.
Oooh, okay! I'll give that a try. Thank you very much!
That would be awesome yes. I will ask the maintainer if he is interested in adding its support. Sphinx and redissearch would be interesting too. I haven't found anyone to integrate with bleve too and I don't know golang. I tried to add noise but somehow failed indexing 100k docs. I must be doing something wrong.
Interesting read. Your last section I think ends somewhat abruptly. I'm not sure what you are really trying to say in the wrap-up. Especially the last bit about Perl. It just seems to come out of nowhere and seems like an odd point to end the post on. All-in-all it is a very informative and interesting post though. Thanks for taking the time to create it.
Ramdirectory vs mmap you mean? I don't think there is a difference (apart from anonymous memory vs file mmapped that is) but I am not entirely sure. Unrelated with the directory, if you want your index to not take a gigantic amount of RAM gigantic you will need to use lnteger compression. That's the main "serialization/deserialization" happening there. Regardless where the data is stored, you'll have to do it. 
this is the way to go, IMO. tricks around interrupt disabling (rtfm or explicit) might give you another byte of buffer, but in the end you need to deal with overflow anyhow one or the other way, and a lock-free FIFO queue (often implemented as a ring buffer) is performant and easy to manage. i haven't used any rust implenentation of it yet, but [rb](https://crates.io/crates/rb) and [fifo](https://crates.io/crates/fifo) look promising - please let me know if they work for you!
Thank you! :) About those features, I believe they have their place in different crates. I would like to keep LibreAuth close to the authentication mechanism as possible. Plus, some problems cannot be solved by implementing functionalities because they are really too close to user interaction like, for example, the way the password should be display or hidden (yes, there is a point about it in the NIST SP 800-63B). Another example is checking if the password is part of a black list: some people will store it in a plain-text file, others in a database, and the password can be in plain text or hashed: this is too much things to take into account, it won't fit into the library. However, a crate that check a password against Troy Hunt's list would be much appreciated!
this is the way to go, IMO. tricks around interrupt disabling (rtfm or explicit) might give you another byte of buffer, but in the end you need to deal with overflow anyhow one or the other way, and a lock-free FIFO queue (often implemented as a ring buffer) is performant and easy to manage. i haven't used any rust implenentation of it yet, but [rb](https://crates.io/crates/rb) and [fifo](https://crates.io/crates/fifo) look promising except they don't advertise being no_instd - please let me know if they or something else works for you!
this is the way to go, IMO. tricks around interrupt disabling (rtfm or explicit) might give you another byte of buffer, but in the end you need to deal with overflow anyhow one or the other way, and a lock-free FIFO queue (often implemented as a ring buffer) is performant and easy to manage. i haven't used any rust implenentation of it yet, but [rb](https://crates.io/crates/rb) and [fifo](https://crates.io/crates/fifo) look promising except they don't advertise being no_instd - please let me know if they or something else works for you!
&gt; Also, since I'm out of the loop apparently, which forums and chats are people using for Rust? Well, theres this subreddit. The discord is also helpful, along with the forums on the website, and all the glitters.
&gt; Also, since I'm out of the loop apparently, which forums and chats are people using for Rust? Well, theres this subreddit. The discord is also helpful, along with the forums on the website, and all the glitters.