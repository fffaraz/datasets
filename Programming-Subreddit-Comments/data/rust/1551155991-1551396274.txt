I can't think of a funny response, so I'll just say sorry, you're on the wrong sub. You want /r/playrust
You have a few... hehe... *options*: For clonable values (copyable values don't get moved anyway): option.cloned().map(|val| { ... }) For everything else (closure is passed a reference): option.as_ref().map(|val| { ... }) For mutating (closure is passed a mutable reference): option.as_mut().map(|val| { ... })
Yes, I tried it and produced the following results: `0: &lt;unknown&gt;` `1: &lt;unknown&gt;` `2: &lt;unknown&gt;` `3: &lt;unknown&gt;` `4: &lt;unknown&gt;` `5: &lt;unknown&gt;` `6: &lt;unknown&gt;` `7: &lt;unknown&gt;` `8: &lt;unknown&gt;` `9: &lt;unknown&gt;` `10: &lt;unknown&gt;` `11: &lt;unknown&gt;` `12: &lt;unknown&gt;` `13: &lt;unknown&gt;` `14: &lt;unknown&gt;` `15: __libc_start_main` `16: &lt;unknown&gt;` This makes me unable to start, is my code problem...?
These are mostly oriented towards how it's implemented: - https://rust-lang.github.io/rustc-guide/type-inference.html - http://smallcultfollowing.com/babysteps/blog/2017/03/25/unification-in-chalk-part-1/ - http://smallcultfollowing.com/babysteps/blog/2017/04/23/unification-in-chalk-part-2/ I'm not aware of any documentation from a purely language perspective. There are quite a few text books if you want to learn more of the fundamentals (like Benjamin Pierce's books).
It's a problem in your binary. It might be easier running it manually to test it. 
This looks great. I'll have to give it a try!!!
The Example API is unsafe there's nothing stopping the MyCell from being dropped while it's borrowed. The borrow and borrow_mut need a lifetime parameter that binds to both inputs and the output. By default a &amp;self or &amp;mut self method uses the lifetime for self for any returned references. The unsafe block effectively casts away the MyCell parameter's lifetime. Miri will can detect his if T isn't a Copy type (under tools in the playground), and the MyCell is dropped while borrowed.
They're convinced that Discord with their phone verification and captchas, which are essentially, more proprietary software with baseband modems and obfuscated scripts gathering tracking data, helps them stop spam, when it actually is no different than fighting spam on Matrix or IRC given bot-writing and administration effort. Fighting spam is a cat and mouse game.
/r/playrustserver
You're looking for /r/playrust. This is for the Rust programming language.
Thanks! \`swym\` does not currently use any TSX code. I've tried using the instructions in a past C++ STM (very similar to this one), but I had a really hard time getting speed gains out of it. Part of the reason I have traits for transactions is to give swym some room to explore hardware transactions. It is not a priority tho.
IRC, Matrix, Gitter, etc. have been tried and found lacking. Whether that's in usability, moderation tools, or whatever else, Discord is the least bad option as far as the teams using it are concerned. It's not unanimous, either, though- some teams use Zulip and others are still on IRC. There's just not a clear winner in this space.
 /// # Panics /// /// This (and [instance_unchecked]) must not be called more than once for any particular type. #[inline] pub fn instance() -&gt; Self { const TAKEN: Cell&lt;bool&gt; = Cell::new(false); let taken = TAKEN.replace(true); assert!(!taken, "multiple instances of unique singleton type"); unsafe { Self::instance_unchecked() } } /// # Safety /// /// This (and [instance]) must not be called more than once for any particular type. #[inline] pub unsafe fn instance_unchecked() -&gt; Self { RWToken { marker: PhantomData } }
Thank you! I'd there maybe some sort of vocabulary used widely in industry? Maybe it is not too late to rename all the things :)
I've been trying to figure out how to draw text in Piston without requiring the draw loop to be part of a `draw_2d` closure. I'm using a `GlGraphics` object to draw, and the text draw method apparently doesn't support it. Here's an example of what I call: text::Text::new_color(self.get_text_color(), self.font_size) .draw( &amp;self.text, &amp;mut self.font_cache, &amp;c.draw_state, c.transform, g ).unwrap(); And the error I get is: error[E0271]: type mismatch resolving `&lt;opengl_graphics::back_end::GlGraphics as graphics::graphics::Graphics&gt;::Texture == gfx_texture::Texture&lt;gfx_device_gl::Resources&gt;` --&gt; src/widget/text_widget.rs:77:14 | 77 | .draw( | ^^^^ expected struct `opengl_graphics::texture::Texture`, found struct `gfx_texture::Texture` | = note: expected type `opengl_graphics::texture::Texture` found type `gfx_texture::Texture&lt;gfx_device_gl::Resources&gt;` Any help would be great. I found lots of other posts related to this, especially the "Why is it so hard to draw text with Piston" post ... I have to agree. Why is it so hard? &lt;Archer&gt; PHRASING &lt;/Archer&gt;
You need to build the server in debug mode to be able to get useful information out of this.
Ah perfect! Thanks for the link and best of luck. 
There's a ton of great resources out there for anyone wanting to learn Rust but I'm slightly bias towards this book as it went into the most detail. I agree if anyones interested in really understanding Rust its a good complement to any reading / learning you're doing.
Do you know if romio is going to be merged back into tokio when this whole mess is over and done with? What's going on with that?
I think I used it when doing streaming io with an iterator? So I had iter.next() =&gt; Option&lt;Io::Result&lt;T&gt;&gt; and I wanted to have Result&lt;Option&lt;T&gt;&gt; so I could do let nextline = iter.next().transpose()?;
To be honest, I don't know what easy issues I can offer to you right now :( This one would be easy enough, I think: https://github.com/svartalf/rust-battery/issues/1 And `battery-cli` crate really needs more love, because I spent only a one day making it and realize now that everyone are using it. There [are](https://github.com/svartalf/rust-battery/issues/8) [few](https://github.com/svartalf/rust-battery/pull/11) [issues](https://github.com/svartalf/rust-battery/pull/10) about platforms support and I had a thought about rewriting internal implementation so I could add unit tests, but this is just an idea and I had not thought yet about how it should be done.
Why Windows ARM? 
Yes, it does not supports UPS right now and this was intentional, because I want to get the stable interface for internal batteries first. What worries me is that you are getting an `101` exit code, it means that program is panicking. By any chance you are using Mac? I have a few bug reports about MacOS at the moment.
Why Windows ARM? I don't see Windows ARM devices on MS roadmap.
Speaking of the await syntax problem, is there a tl;dr somewhere for that? I'm curious about why it has been such a struggle, but I don't want to comb through the discussion if I don't need to.
Hololens probably uses ARM no?
You can see the difference from the book covers immediately. TRPL - tales of the seafloor for elementary school kids. Programming Rust - highly advanced crustacean, a perfect machine for separating edible particles from the tidal mud.
Sure, just that. I just don't personally understand how that is enough. The hololens market is barely a baby.
[yes, it will](https://github.com/tokio-rs/tokio/issues/804). tokio doesn't want to make a release that requires nightly, so using async await in tokio proper will have to wait until futures stabilize in `std`.
Thanks!
in the original rfcs, it was generally assumed that the current macro-like `await!()` syntax would be replaced by a single keyword, placed before the expression to evaluate - so called "prefix await". the main issue people have brought up is the precedence issue with await and ?, namely: what does await foo? actually do? An alternative syntax people have brought up is "postfix await", where await syntax looks like a method or struct member call, with a dot `foo.await()` or `foo.await`
I found the problem, it is about the use of `CombinedLogger`. So, I have to find a new log lib to replace it.
I personally hope they go with prefix await. I don't mind having to learn the rules around whether I need to write await foo? or (await bar)?
is this book updated with latest rust? I'm new to rust and heard that the language is not friendly for legacy codes, e.g., old codes in cs140e cannot pass compilation with newest rust compiler. 
I don’t know what roadmap you’re looking at. The very first search result for me is https://docs.microsoft.com/en-us/windows/arm/ “Windows 10 runs on PCs powered by ARM processors.”
If you could provide some kind of argument or position instead of a myriad of semi-coherent links, that'd be great. 
Very promising! Could you also add [https://github.com/jonhoo/rust-evmap](https://github.com/jonhoo/rust-evmap) to your benchmarks? Would be interesting to see how it compares.
Well, there's quite a bit of other stuff, too, it just doesn't do a lot for me and my small project :) What I wanted from pattern matching was something like \`if let x = Some(b) &amp;&amp; y = Some(a)\`, but that doesn't seem possible. Still, you're right, probably a nice improvement once you get to use it.
And the worst type of captchas..
Nice thing, that's pretty neat! Huge graphs can be pretty unreadable though, maybe there could be a way to make them taller and less wide? Also, I don't understand why, but when I try to run it on [SCTK](https://github.com/Smithay/client-toolkit), it fails with this error message: &gt; error: Could not parse toml file: Missing name or version Even though these fields are present in my `Cargo.toml`, and cargo is perfectly happy with it...
What is the difference between putting the ```&amp;``` operator in these two positions? ``` fn foo(s: &amp;u8) { } ``` ``` fn foo(&amp;s: u8) { } ```
Good question! They way battery and battery-ffi does it is how I personally prefer it. The outer FFI layer crate is a layer and can be cleanly separated from the inner Rust crate. That way, users of the Rust library do not need to bother with the FFI layer at all. If the inner crate is a library that can be written in pure safe Rust, that inner crate can use \`#!\[forbid(unsafe\_code)\]\` wile the outer layer FFI crate can use unsafe.
The first one's valid, the second isn't. What works is \`fn foo(&amp;s: &amp;u8)\`, which I think, which is a pattern and binds the passe \`u8\` to \`s\`, just as in \`fn foo(s: u8)\`, just that you pass it a reference instead of a value. That's only possible because \`u8\` implements \`Copy\`, so the value can be copied out of the reference.
I mean, you can already do this: if let (Some(x), Some(y)) = (a, b) { //... }
It would be nice to have some graph layout algorithms as pure rust crates though, traits would allow you to make the algorithm generic over the data structure meaning you wouldn't need to have an intermediate representation like you do with GraphViz. 
&gt; Do I need to do a separate crate called dicenotation-ffi like battery-ffi does and do my binding generation there by linking my original lib? It does look pretty common e.g. battery aside, that's also what /u/burntsushi does for [regex](https://github.com/rust-lang/regex), it has a [regex-capi](https://github.com/rust-lang/regex/tree/master/regex-capi) subcrate (in the same repository) which provides the C interface and does the FFI work.
A definitive and comprehensive summary is being worked on right now. See [here](https://github.com/rust-lang/rust/issues/57640#issuecomment-464152929).
There are several Windows ARM devices out there already, an example is HP ENVY x2
I'm very partial to this guide: [https://learning-rust.github.io/](https://learning-rust.github.io/) It doesn't try to go into detail, it's more or less expecting that you know roughly what basic programming language constructs are and showing you what they look like in Rust.
A question I've been dying to ask for a while relating to this: What's the deal with with these libs like lapack, in that they get wrapped more often than reimplemented? Why would someone use rust bindings for lapack over a pure impl of these routines? Is it such that the Fortran impl is so much more performant? Is the code so complicated that no pure rust impl can compare feature-wise yet?
Wow, nice. This is actually pretty useful. I can finally see how much turning down the backlight and closing Facebook tabs is helping my CPU usage.
Hmm, when the lock file was missing you get a message like this: &gt; error: Could not find `repo/Cargo.lock` in `repo` or any parent directory Indeed, I confirmed that that's the case for the repo you linked. It kind of sounds like you're running cargo-graph, which gives all kinds of confusing error messages. &gt; Huge graphs can be pretty unreadable though, maybe there could be a way to make them taller and less wide? Not sure, but you can pass in whatever settings you want to Graphviz dot. The actual rendering part of it is not the job of cargo-deps.
I'm still working on my thesis project. I compare performance (run time, memory consumption, and binary size), between C and Rust implementations of different problems (sorting, numerical integration, linear interpolation) and a kind of general introduction to Rust (what is not widely known in my university and even in my town at all). My source codes will be published under GPL when I'm done.
Have a coworker that does lots of ML and he uses Pandas all the time.
I would love to see how one could feed matrices (ndarrays) to functions to do elementwise operations, like take the exponential, etc. Coming from python / numpy, things are a bit confusing!
Huh, that did not occur to me, awesome, thanks!
Saw this at the O'Reilly booth at FOSDEM a month ago. Unfortunately for me it cost a whopping $60, albeit with a %10 discount -- but I wasn't about to dish out that kind of money on a paperback book, although it did look very nice, to be fair -- I mean, FOSDEM itself is a free event, so you know I'm a cheapskate.
There is a `map` method to apply a function to all elements of the array. I will touch on it soon enough :)
Please do! :)
I've been following it on and off and haven't had any problems with using it, it is sadly missing some of the newer stuff but for the basics I found it far better than the official Rust book.
That's because cs140e was using nightly rust. Stable rust (which is taught in the book) works just fine in later versions of compiler. Of course, the book teaches a bit about unsafe as well.
Hey, I am really glad that someone is really using it :) 
How do you create UWP components in Rust then?
You could wrap the README-only elements in divs and then add inline CSS in a docs comment to hide those divs by class. You can mix `///` and `#[doc(include)]`.
Thanks! I figured it was something along those lines, but I can't make heads or tails of most assembly and I know even less about processor architecture, so that's quite enlightening.
A quick search on crates.io revealed that both -ffi and -capi suffixes are used but -ffi seem more common. I guess there is not a unique convention at the moment. 
There is an async book: [https://rust-lang.github.io/async-book/](https://rust-lang.github.io/async-book/) &amp;#x200B; It's WIP, but it will get you started.
I don't try it yet, but https://github.com/tomaka/android-rs-glue seems a good point to start. Also https://github.com/kennytm/rust-ios-android and https://gist.github.com/michaelfairley/d86137085307d2e5c16ee0df2fb84cd9 have some information about how to export to this platforms, and the last one talks about SDL2. 
I've written a few WebSocket servers with actix and I can definitely recommend it as a solid choice. Take a look at their chat examples in the official repos to see how to use it.
That would be pretty crazy and entirely unnecessary. I doubt they are interested in anything other than getting Rust libs compiled so they can be linked into UWP apps. 
I got the e-book version for cheap from The Humble Book Bundle: Functional Programming (alongside some Elixir, Haskell, Scala and Clojure books). I wouldn’t be surprised if it shows up in another bundle some time.
thanks , let me read your links. I was just googling some more:- hmmm... [https://developer.android.com/ndk/samples/sample\_na](https://developer.android.com/ndk/samples/sample_na) &amp;#x200B; Am I reading this right: you \*CAN\* actually compile something that is purely native code, no Java stub - and the android build tool will 'make the java stub for you'. (does the java version of SDL use that?) This seems to be what I used last time (so long ago I can't remember the details). i was just looking though to find the java bit, and there isn't any :) [https://github.com/dobkeratops/android\_rust\_gl/blob/master/android/jni/main.c](https://github.com/dobkeratops/android_rust_gl/blob/master/android/jni/main.c) &amp;#x200B; that seems like it might be a bit easier than I thought.. it's just so difficult to see whats going on behind a GUI IDE and/or other people's build scripts.. &amp;#x200B; This makes me want to go back to an ad-hoc makefile, which could invoke 'cargo build..' and 'ndk...' ... but how to get SDL into that.
No. NixOS (Linux x86_64)
Thanks for the clarification, I'll try to reproduce that bug.
Elaborating on this, `systemd-run` can be useful in debugging execution of systemd services. It lets you run your program interactively in an environment that's similar to how it's run as a daemon.
While true regarding porting Firefox, it is not enough as long term roadmap of having Rust usable in all system programming scenarios that matter to Windows developers. 
How do I parametrize a type by an integer? In C++ it is possible to do something like ```c++ template&lt;int dim&gt; class Vec { ... }; ``` This allows for some optimizations. Is it possible to do something similar in Rust?
The first hololens uses an Intel x86 (not x86-64) Cherry Trail SoC. It's not a fun target.
I like agressive memory stuff
The more common solution would be HashMap&lt;i32, Rc&lt;Item&gt;&gt; Just use Rc::clone if the lifetime is too short. This would also allow deletion from the HashMap. I think your assessment of the safety is mostly correct. The safe API still needs to be into a separate module so that it can't be accidentally bypassed. I think Pin could allow generalizing over more than Box but I'm not familiar enough with it to be sure. 
Probably because Hololens use it
Because Mozilla does research on VR and AR.
&gt; Even if they aren't high-middle class white males Starts off with racism and sexism. &gt;tend to be heavy supporters of economic liberalism and a lot of them are socially conservative status quo apologism is heavy, because the status-quo is not bad to them. Attacking an entire group for differing ideology founded on baseless generalizations. &gt;With its heavy male environments sexism rampant too. And to top it off a sexist claim that is supposed to fight sexism. &amp;#x200B; &amp;#x200B;
Another reason to do it this way is that you probably want the non-FFI crate to be an `rlib`, while the FFI crate should be a `cdylib`.
It's pretty hard to correlate optimized assembly to the original source code. I couldn't tell you what most of those instructions are doing, all I can tell you is that the serial version appears to be significantly simpler which suggests that the parallelization overhead is dwarfing any potential gains. You can amortize the overhead by summing chunks of the input vector in parallel and then summing the result: v.par_chunks(16).map(|c| c.iter().sum::&lt;u64&gt;()).sum() Now, each thread will sum 16 integers at a time, which should get you vectorization and pipelining back. You can adjust the chunk size until you see the kind of speedup you were originally expecting. The default implementation of `ParallelIterator::sum()` probably assumes the addition operation is the most expensive aspect so it's not applying this optimization by default. Ideally it would buffer some work locally and dynamically scale how much work it does serially on each thread to maximize throughput. It may be the idea to implement that eventually, I'm not sure.
HashMap does resize (i.e. move around in memory) when it reaches capacity.
It's a common thing to do and I'm asking if there's a conventional or idiomatic way to do this, maybe with a crate I haven't found yet. I don't mind implementing it manually, but it's worth it to search the ecosystem.
What you've essentially got is a custom formatting language, that doesn't seem like a very common thing to do. Regardless, it doesn't seem like there's really any room for a library to make this any easier; Rust already has really good pattern matching syntax which you can use to match the `%` commands, and if you need more complex stuff (like `%2.3f`) then you'll want to look at a proper parser like [https://github.com/Geal/nom](https://github.com/Geal/nom)
&gt; where await syntax looks like a method or struct member call, with a dot foo.await() or foo.await You forgot to mention postfix sigil (`fut@`), macro (`fut.await!()`) and keyword (`fut await`) variants.
This sounds pretty good to me. Any suggestion on which naming convention to use?
The actually use case is more complicated than this and Rc is not appropriate because the lifetime of the item shouldn't be extended by the borrowing calls. Using Rc will delay the destruction of those items. Weak isn't good either because those borrows should be dropped when the container is dropped.
But Box&lt;&gt; should be able to fix the address of the actual data right?
The problem is that the most common variant will be `(await foo)?` and result of `await foo?` will be unintuitive (i.e. it will increase mental load on programmers). Some have proposed introduction of `await?`, which will await first and then bubble error, but many find such solution too ad-hoc. Also prefix variant will play badly no only with `?`, but also with chaining (though some have argued that chaining is not so important for sync code).
Based on absolutely no rational arguments but simple personal taste, I'd go with -ffi.
I'm sorry i misread the question. Yes you are mostly right. A Box will almost always be the same pointer. The most commen case when it isnt is : Q2: Yes it offers more guarantees, that arent very usefull to you. 
I wouldn't need to use `Rc` if that would take care of it. In real life, I need `Rc` because it is holding working state that is referred to from different places, e.g. from an I/O callback and also a callback registered with a timer.
This has been proposed and accepted as [RFC 2000](https://github.com/rust-lang/rust/issues/44580) but it has not been implemented yet. I await it eagerly myself, I have loads of use cases in mind as well.
It's dividing m (which is 128 bits long) into two pieces, m1 (which is the first 64 bits) and m2 (which is the other 64 bits). As for why it takes two 128 bit blocks instead of 4 64 bit blocks, I couldn't say. I suspect it needs more context.
Thanks! Yes, I was unsure about drop behaviour. I was deep in Rc trying to figure out whether it could go wrong. I'll work though your suggestions.
There are very few uniform conventions in crate names. So my suggestion is to not worry about it, or just pick the most popular one. (I, personally, have always used `-capi` for this, long before the seeming rise of the `-ffi` suffix.) We aren't even consistent on the use of underscores vs hyphens. One convention that is followed reasonably well are the names for crates that are only bindings to other libraries. Such crates are pretty consistently named with a `-sys` suffix.
https://crates.io/crates/battery-cli says: &gt; Since it is still in early stages, there might be a lot of bugs. Also, it is not working in Windows, sorry. Is this outdated?
Thank you. It makes sense, although I don't understand how than dividing works mathematically. The two blocks are 1. the message 2. the key. Both got divided into 64 bit blocks. Would it be possible to use 4x64 bit keys for a 256 bit sized key, although rust doesn't support u256? 
I wonder if I should this crate into sysinfo... That seems like a nice match. In any case, you did an awesome work in here!
You can buy a laptop running Windows 10 on ARM [today](https://www.lenovo.com/gb/en/laptops/yoga/yoga-c-series/Yoga-C630-13Q50/p/88YGC601090). They've been around for about 2 years. The HoloLens 2 is also ARM based.
Wow! I wonder whether that is really sound? It's a very neat trick if it is. I thought I'd have to use a type map. [Looking at the reference](https://doc.rust-lang.org/reference/items/constant-items.html) it says that constants are inlined where they are used, so for this to work, then it effectively needs to do the `Cell::new(false)` just once for each specialization (by T) of the code and store it statically. I can't see any use of this pattern in the std library code (which would "bless" it as supported to some extent). I will think some more on this.
Are you asking about bugs or Windows support? :) This crate is PoC, basically, so I can't guarantee anything :) And last time I checked it was not compiling for Windows targets, because `tui` dependency by default uses `termion` lib and it does not works with windows.
If you're going to, I would be glad to hear your thoughts about library interface, it would be really nice to have someone else opinion
&gt; This project is an improvement on the unmaintained and buggy cargo-graph. Isn't it too harsh to declare the original project _buggy_? Especially, a project with history and features, not just a dummy crate. And more especially, if you make a fork of it. Forks can (and should) outgrow their parents and become more useful and convenient, but please, show some respect and honor. 
[roxmltree](https://github.com/RazrFalcon/roxmltree) seems like an interesting parser. I have yet to look into it, but it's on a different path than xml-rs and serde, which looks fruitful. In terms of generating, I see [tera](https://github.com/Keats/tera) as offering a good approach, though fwiw, this belief lacks a supporting technical foundation and, at least for json serialization, a smart team member admonished it because a standard (de)serialization library is more reliable than individual templates for each data model. Perhaps later those could be generated, and more broadly, it seems like there are a handful of under-examined angles here.
From the docs, it seemed pretty nice. Maybe add some examples in there? It also helps in case you have breaking changes (since \`cargo test\` also runs doc examples...).
&gt; why does encrypt_block takes u128 blocks and casts it down to u64 as first step? Why is that neccessary? Judging by the code, the algorithm involves operations which do `modulo 2^64` wraparound. The simplest, most efficient way to do that is just to use `u64` variables and rely on the processor's native behaviour for over/underflowing arithmetic. (eg. `round!` is using `.wrapping_add` so that, even in debug mode, an overflow will silently wrap rather than panicking.)
I have never read about hostile allocation. But at first glance this seems like it is preventing errors that mainly beleaguer C and other unsafe languages. Is that correct?
Can't you do it with macros somehow?
Lol
There is a list of [rust in distros](https://repology.org/project/rust/versions), if I didn't miss anything important 1.24.1 in debian is the oldest "common" version. The next debian release is going to ship 1.32.0 very soon though. There was a discussion recently about that topic on the rayon repo: https://github.com/rayon-rs/rayon/issues/586
Since there is no support (like security fixes) whatsoever for Rust versions older than the current stable, I maintain (for my spare time projects) that supporting older rustc does not make sense for new releases. However, I do try to make releases that require a newer rustc semver-incompatible (so if my library is at 0.7.1 and I want to start using rustc 1.33.0, I would name a release that does so 0.8.0, not 0.7.2).
I'm also very interested in feedback on this. I have asked before, but specifically for package maintainers in distros, and the general consensus was "we track latest Rust stable." See here: https://github.com/BurntSushi/ripgrep/issues/1019 That issue caused me to change my policy, such that, at least for _applications_, I now aggressively move towards the latest Rust stable release. But this is for an application.
That assert will never trigger, because `TAKEN` is a const, and so when you call `.replace()` on it, you're actually replacing a *copy* of `TAKEN`. For this to work you need to use a static, atomic bool.
_All_ DigitalOcean IPs are blocked from Russia?
I've accumulated a large amount of feedback for [sn0int](https://github.com/kpcyrd/sn0int) when it went popular on r/netsec that I'm still working on, but I managed to hit a [compiler bug](https://github.com/rust-lang/rust/issues/58674) and I'm currently considering pausing development because I can't push new releases due to this.
You wouldn't believe the blocked IPs amount in Russia: https://usher2.club/en/
It depends on what you're trying to accomplish. Macros can't access items that are restricted from the scope of their invocation which limits encapsulation. They also can't be invoked as methods which restricts API design, and they can't affect type definitions unless you're generating the type yourself. The main use case I have in mind is for trait impls that can be generic over the length of an array. You can generate those with macros so you don't have to copy-paste each one but it still has to generate `N` individual impls that bloat API docs. Another problem is, you can't have a macro repeat just by telling it to count to `N` (a procedural macro could but that's its own challenge), you have to provide at least `log N` input tokens and the macro emits some number of impls for each token. Because of this, the stdlib doesn't bother implementing traits for arrays of lengths greater than 32, which makes it frustrating to work with larger ones.
Thanks, I just successfully compiled to wasm32-unknown-unknown so it should work but I have no idea how good the performance is. I don't think WASM supports SIMD yet and HashLife is a huge memory hog.
No, it doesn't currently support either. I would expect it to pick up http2 support when it adds async support, which I would estimate as happening sometime over the next year. Websocket support is definitely planned too. In the meantime, Actix-Web (http://actix.rs) is probably your best bet if you want those features in Rust.
What does `&gt;|` mean in the instructions? Doesn't work on Windows. I tried `cargo deps | dot -Tpng &gt; graph.png` but this results in an invalid PNG.
What is the difference between impl&lt;T&gt; Trait for T where T: AnotherTrait { } and impl&lt;T: AnotherTrait&gt; Trait for T { } ? I noticed that the former 1) cannot be used more than once for the same `Trait` and 2) complains about `T` not being a dynamic trait object if `AnotherTrait` contains generic functions. The second works like a charm. :) However, I cannot understand _why_ the difference, and whether it is just a limitation of the compiler or something deeper.
Some people says that Wasm is safe, but it is memory safe only if the source language is memory safe. Yes, Wasm has a sandboxed memory model, thus it decreases the unsafety surface, but it doesn't protect against buffer underflows or overflows for instance. A good reading is [https://00f.net/2018/11/25/webassembly-doesnt-make-unsafe-languages-safe/](https://00f.net/2018/11/25/webassembly-doesnt-make-unsafe-languages-safe/).
Dang, when was that? I must have missed it...
I think this belongs to /r/rustgame
r/lostredditors
Ah, I was using `&gt;|` because `&gt;` alone didn't work for me if the file already existed. See [here](https://stackoverflow.com/questions/4676459/write-to-file-but-overwrite-it-if-it-exists). I'll update the Readme. As far as Windows goes, I'm afraid I can't help you there. If you find the answer, let me know and I'll update the Readme.
We tried tracking old rusts for our own libraries and our own usage but finally gave up with 1.31. There is really no point in supporting old rusts from what I can see. I have yet to see someone ask for an older Rust version but on the other hand I had people ask to bump our deps up and that's also something I already came across in other libraries. For instance rayon uses an ancient version of crossbeam which is annoying because just because of rayon we now have two crossbeam implementations in our code.
cargo-graph is buggy and I don't appreciate the attempt at policing my speech considering I spent two days just fixing its bugs and patching sloppy code. Even if you could get cargo-graph running on a crate, the results are usually wrong and thus, unreliable, except in the very simplest case (you have only regular dependencies and no build, dev, or optional deps). &gt; Forks can (and should) outgrow their parents and become more useful and convenient, but please, show some respect and honor. I'm not going to say much more on this except that I should have written cargo-deps from scratch instead of forking it from cargo-graph.
Speck may be parameterized with 128-bit blocks and 256-bit keys ([among many other options](https://en.wikipedia.org/wiki/Speck_(cipher)#Cipher_description)) costing only a couple extra rounds to account for the larger key. [Considering the lack of transparency in its design](https://www.spinics.net/lists/linux-crypto/msg33291.html), I wouldn't recommend it as more than a mere toy.
I have a bit of a feeling that WAS is not the same as WASM. Don’t know where this feeling comes from though.
"Please, sir, could I have some memory?" "NO! Leave me alone you filthy cripple! Bah Humbug!" On a more serious note, googling for "hostile memory allocation" has this repository as the top link. But reading the blurb, on the repository, it seems as though the goal here is a memory allocater that does specific things to cause applications to fail when they use mistakes. An example is having a guard page that immediately causes an exception in the case of a buffer overflow, so that the overflow is caught right away. It's a clever idea, I think. 
r/playrust
Working on improving https://github.com/jackmott/rust-simd-noise * speeding up cell noise * adding more cell noise options * converting the public api to use the builder pattern I'm in one of those big refactor messes where one wonders if it will ever work again. I think I need to have a think on it and see if there is a simpler approach to what I'm trying to do. 
I suppose in that case you can either put let mut iref = item.borrow_mut(); iref.v.push(1); in a scope (wrap with curly braces) or do `std::mem::drop(iref)` before calling `test3_sub`
&gt; An example is having a guard page that immediately causes an exception in the case of a buffer overflow, so that the overflow is caught right away. It's a clever idea, I think. How is this different from the sanitizer?
Just tried and cargo-graph doesn't even produce correct output for itself. &gt; cargo graph --optional-deps false | dot -Tpng &gt;| graph.png lists ansi_term as a direct dependency of cargo-graph despite optional dependencies being turned off. clippy, the other optional dependency, is not displayed.
Yes, please! Especially because it seems to imply `ìf` and `match` in `const fn`.
Fixed it - needed to change type from "cargo" to "shell"
Another one bites the Rust.
From my experience should be at least compatibility with previous versions that less 1 year old. Change of version of compiler is huge step - several hours of rebuild from scratch, find and fix clippy, rustfmt, cargo issues, and after all you may be faced with some critical bugs, so you have to fill new/subscribe to existing issues in bugtracker and stick with previous version of rustc and Co. Thus this huge step happens not every new rustc release, because of team may busy with something, and only if new release bring some great features there is volonteer to test and update CI virtual machine images to bring new version of rustc to production.
Did you think of adding support for anything like [docopt-rs](https://github.com/docopt/docopt.rs)? It would be really great if we can just generate the `USAGE` section, for example.
This is something I've heard a lot, but I'd really like to hear more specifics. Rust is _supposed_ to be easy to upgrade. Could you say why, in more detail, it is hard to upgrade? Is this limited to a specific type of environment? Or do you find this to be generally true? For example, at my company, we use a tiny bit of Rust and a lot of Go, but we spend exactly zero time building either of those compilers. We use compilers that others have built, such as whatever is in `brew` or whatever other package manager one uses. The key here is to judge how prevalent your environment is so that we can make decisions about how much effort and time to allocate supporting it. (Because supporting older compilers is something that really needs broad sweeping buy in from all of the core ecosystem crates. Building that consensus is work, and of course, sticking to it is also an incredible amount of work too.) I know I've burned _tons_ of time just thinking about this issue, nevermind actually trying to support older compilers.
It's going to be hard to search for though given WASM's popularity
I am working on getting Rendy working with IMGui. Bit of a tough going since the Rendy examples are for 0.1.0 and the code got refactored in 0.1.1 but I am making a bit of progress.
There's a long tradition of such memory allocators in C and C++, simply because the problem is so common, so in that sense there's nothing novel there... Which isn't to say that WAS is not useful: - I doubt the sanitizers work on WebAssembly yet. - The set of checks seem pretty thorough. - And it's pre-packaged for ease of use.
Thanks for the recommendation, friend! I'm an experienced dev too (about as long as you) and I've always found it a bit of a nuisance when so many guides for people new to a language assume you're completely new to programming. 
My understanding is that it's expected that libstd is currently using some forbidden APIs that will require a new UWP-specific libstd.
`rand` compiles to WASM. You have to enable either `wasm-bindgen` or `stdweb` [feature](https://github.com/rust-random/rand/blob/master/Cargo.toml#L31-L32). Sample applies to other crates, like [uuid-rs](https://github.com/uuid-rs/uuid/blob/master/Cargo.toml#L76-L77). I'm using both crates in my WASM code.
Fundamentally, they're the same thing. The \`where\` syntax is strictly more expressive. &amp;#x200B; The \`where\` syntax came later, and it's also a bit longer, so the original syntax was also kept. Generally, I use it when my bounds are short, and \`where\` when bounds are long.
People do it with zero sized types, see [https://docs.rs/typenum/1.10.0/typenum/](https://docs.rs/typenum/1.10.0/typenum/)
Here's the `rand` code for: * [wasm-bindgen](https://github.com/rust-random/rand/blob/master/rand_os/src/wasm32_bindgen.rs) feature * [stdweb](https://github.com/rust-random/rand/blob/master/rand_os/src/wasm32_stdweb.rs) implementations feature
It uses Rust 1.17.
But why does the where syntax not work in this case? The compiler basically changes it to `where T: dyn Another year&gt;`. It's also possible that I was doing something else wrong, I will try to distill an example.
You could use nom, combine, or pest, if your language is complex enough, but IMO those kinds of libraries add unnecessary complexity if your grammar isn't particularly sophisticated. On the other extreme, there are a few scanf-like crates if your language is simple enough for that. I know at least one of them supports regex patterns.
Yes, that would make it safe. But there is no warning or error from the compiler. You need to keep up a discipline with RefCell to hold the references for as short a time as possible. You have to consider any call out of your code whilst holding the reference suspiciously, in case one day it is extended to add a callback or whatever that might lead to two accesses to the same object, triggering a panic. If you're careful it is fine.
&gt;Are there specific versions of Rust deployed in distros or elsewhere we should keep compatibility with? I am always worried by this justification. Are distros shipping officially unsupported versions of rustc? If so they better be backporting security/soundness fixes (good luck fixing fixed-by-NLL soundness bugs without NLL). If they're not, should we be endorsing the shipment of known-broken software this community is centered around?
Ooh thanks! I thought it was weird for consts to allow interior mutability. It makes more sense that they don't. But now I'm more confused: where are the copies coming from? Cell's aren't Copy.
Sorry I don’t have a definitive source, that one should do just fine though. I don’t see anything else immediately obvious that’s incorrect or obscure. Things like OCV and voltage sag are irrelevant in a low power application with an integrated BMS. 
https://youtu.be/vgiDcJi534Y In case you were wondering where the name comes from :)
&gt; Thank you. It makes sense, although I don't understand how than dividing works mathematically. Dividing m into m1 and m2 happens on lines let mut m1 = (m &gt;&gt; 64) as u64; let mut m2 = m as u64; (m &gt;&gt; 64) is a bitwise shift to right moving the 64 leftmost bits 64 steps to right. Then it's casted to u64 with "as u64". Easier to demonstrate on u16: (0x1234 &gt;&gt; 8) is 0x0012. (0x1234 &gt;&gt; 8) as u8 is 0x12. Then m2 is constructed using "as". "as" keyword is lossy and it keeps the least significant 64 bits of m. Example as u16: 0x1234 as u8 is 0x34.
Gotta get some Rust in there.
I expect most soundness bugs like that would be the compiler accepting code that it shouldn't. But if your code is *also* compiled and tested with a newer compiler, then using the old compiler should be harmless. For security, yes distros should be patching, but this is often reactive. This is a good reason to consider filing CVEs even for things that are already fixed in the latest stable.
The Rust compiler? It takes me about 45 min. Can take double that with tests. It is a huge amount of code. If it is any consolation, once you do it once, there are ways to make it recompile faster (depending on which parts you are modifying).
And here I thought it was a (stretched) Bloodborne reference! https://youtu.be/vpYAlTeHdZk
Space as in memory, on linux? Try downloading some more ram via zram (it's like swap but instead of swapping out to disk it runs a compression algorithm on pages not currently in use): ``` modprobe zram echo lz4 &gt;&gt; /sys/block/zram0/comp_algorithm echo 16G &gt;&gt; /sys/block/zram0/disksize mkswap --label zram0 /dev/zram0 swapon --priority 100 /dev/zram0 ```
Thanks a lot!
How about trying an alternating 8 voxel grid analogous to the [single rotation rule](https://www.youtube.com/watch?v=r5GbvJ-LKH8)? Something you could take advantage of is handedness in 3d space. It cannot be done symmetrically with a single on cell, but two cells side by side could rotate around the axis they line up on in a right handed way, for example.
No, actual space. I have a 128 GB SSD.
Didn't want to steal u/chmln_'s thunder, but since I didn't see any fanfare for a few days I decided to risk it. I contributed the patch that allowed this to compile on Windows, because I was excited to add this to my "standard" personal toolkit. :) 
Nitpick: I always find the “why X” sections of stories like this to be a little arbitrary. I think it’s almost better to not have them at all, or just replace them with “we chose Rust because we wanted to”. Including rationale usually just opens up the conversation to bikeshedding. Here’s mine: the “overhead” of installing the JVM on a system is not a very good reason to rule out Java. Ruling Java/other JVM languages out because a team simply views them as “uncool” or has had previous bad experience with them is actually much more reasonable in my mind. You can focus on the reasons why Rust was chosen, but the second you start contrasting it with other languages is where the trouble starts. A passionate and experienced C++ developer might read about how the npm team loved that Rust offers zero cost abstractions with no memory management woes and think to themselves “yeah, you could do that with this library and that C++ spec”. But you don’t really give them an opening to get snarky if you don’t even mention how hard it is to do correctly in C++. Anyway, first post in /r/Rust - hi everyone! :P
Why exactly was java excluded ? you go to the trouble of telling us you wrote 3 versions to test performance then don't tell us what sort of performance difference there was between node.js, go and rust ? I like the fact the main take away from this is rust is boring. I have to do on call and boring code is good.
It's a little complicated and I'm not sure I have this 100% right, but it's as though the `Cell::new(false)` expression was repeated everywhere the constant is used. This is allowed because the expression must be a constant-expression and so cannot have side effects. In reality, I *think* the `Cell::new(false)` call is executed once at compile time, and then it's the static representation of the resulting value which is repeated everywhere the Cell is used, so it doesn't require `Copy` because *semantically* it's not copying the cell, and could be implemented that way... but as an optimisation is *is* in fact copying the cell, knowing that it cannot change the behaviour.
It sounds like you wrote something like `impl Trait for AnotherTrait` which is *not* equivalent to either of the examples in your original comment. Instead, it is equivalent to `impl Trait for dyn AnotherTrait`. That is, it is implementing `Trait` for a trait object type, rather than for concrete types that implement `AnotherTrait`.
Note that this executes `a` and `b` before matching whereas `let x = Some(b) &amp;&amp; y = Some(a)` wouldn't. The latter will come in due time, but it's not implemented yet.
I love this - it exactly demonstrates the point I’m trying to make in my sibling comment!
I don’t really see the relationship between docopt-rs and the README… can you tell me more?
Indeed, crossbeam's `Cargo.toml` file notes this as a backwards compatibility thing: # This is deliberately not the latest version, because we want # to support older rustc than crossbeam-deque 0.3+ does. [dependencies.crossbeam-deque] version = "0.2.0" 
I want performance graphs!
I caught a gist that they wanted to avoid operational issues with managing the runtime.
I tried it for fun, and immediately found an unexpected use -- it may show you dependencies you didn't know you have. I was depending on "num" because I needed complex numbers. What I hadn't realized is that num just groups a number of sub-crates, including num-complex. So I replaced num with num-complex, and immediately reduced my dependencies (and of course my compilation time). I also noticed that I had a library and its dependent application using two different versions of a library, for no good reason. Another cleanup almost for free! Thanks, cargo-deps!
I'm not sure I really understand where you're coming from here. My read of this clearly distinguishes this paper as a (light on the details) experience report. They didn't say they didn't use Java because it's "uncool." They gave reasons, and honestly, I have similar reasons why I don't use Java (plus others). Given the amount of space here and the target audience, I also found the evaluation section useful. It's light on the details so there's only so much you can take away, but it's rooted in a real experience and totally fair. Frankly, we don't have enough of this kind of stuff. There are likely also some unstated sensibilities and cultural values that go into these things. For instance, it's totally reasonable that the folks at npm would attach a lot of weight to Go's dependency situation (at the time), where as others might not care as much, or at least, be OK with simpler solutions (such as where I work, although, we're now migrating towards Go modules).
Well, I just like to have all the essential stuff in the README to make the first run simple for my users. So I often include the contents of my Docopt spec in the README.
NPE
&gt; npm called out the Rust community as a positive factor in the decision-making process. Particular aspects they find valuable are the Rust community’s inclusivity, friendliness, and solid processes for making difficult technical decisions. These aspects made learning Rust and developing the Rust solution easier, and assured them that the language will continue to improve in a healthy, sustainable fashion. Yesssss. Good to have a whitepaper with this in it. I've had such a good experience with the Rust community, and I want to see that recognized! :)
&gt; Why exactly was java excluded ? From the paper: &gt; Java was excluded from consideration because of the requirement of deploying the JVM and associated libraries along with any program to their production servers. This was an amount of operational complexity and resource overhead that was as undesirable as the unsafety of C or C++. 
Yes my point kinda got lost in my verbosity. Apologies. Let me TL;DR it: I wish these “experience reports” just focused entirely on the thing in question, and not confuse matters by making subjective arguments that are easily turned into strawmans. If I’m trying to make the case for Rust at my workplace, waving a white paper around saying “npm did Rust and it was successful and they liked it!” is effective. The “and we chose it over X and Y because blah” doesn’t add any value.
So wait, you _can_ download more RAM‽
Hello! Welcome to the Rust subreddit! :) &gt; the “overhead” of installing the JVM on a system is not a very good reason to rule out Java. Ruling Java/other JVM languages out because a team simply views them as “uncool” or has had previous bad experience with them is actually much more reasonable in my mind. The fact is, the NPM team stated clearly that additional operational overhead was undesirable, and they chose a technology with that consideration in mind. To me, that's much better than choices made unconsciously, viz. with criteria for selection being unrecognized. You may not value the same things; that's fine, diversity in values is great! That said, the validity of your point would then seem to boil down to disagreeing that deploying Java would be a significant operational overhead. I take it you don't think deployment of the JVM is a big deal, then? Not a trick question, by the way. I'm legitimately curious, as somebody who's never particularly liked installing Java on new machines and was wondering what other perspectives would be.
It's not doing what I thought it did (I didn't have any `should_panic` test). Apparently, `const` values are copied implicitly even if they are instances of non-`Copy` types. I understand this to be sound because of the restrictions on creating `const` values, but it confused me because until now I would have thought these things are true: 1. whether an object can be copied is determined by its type 1b. only objects of `Copy` types can be copied (stronger form of 1) 2. `const X: T` and `let x: T` bind values of the same type Clearly (1b) is an oversimplification, which is ok. I expect to encounter edge cases that refine my mental models. What squicks me out here is that either (1) or (2) must be wrong, and they both seem awfully fundamental. If (1) is wrong, Rust's typesystem doesn't really support affine types, which contradicts what I would have described as Rust's keystone feature. I'm inclined to look it as (2) being wrong: although Rust doesn't support treatment of "`const` values of `T`" as a first-class type, they are actually treated differently from `T` in multiple ways. Here we're seeing that "`const` values of `T`" are `Copy` for all `T`, but another example is that `Cell&lt;T&gt;::new(x: T)` only returns a `const` value of `Cell&lt;T&gt;` when `x` is a `const` value of `T`. The `const` distinction acts like a typesystem distinction, even though only the compiler is allowed to parametrize over it.
Yeah, I was writing `impl&lt;T&gt; Trait for AnotherTrait&lt;AssociatedType = T&gt;`. I've now hit another issue, which is that `impl&lt;T: AnotherTrait&gt; Trait for T` does not work if Trait is defined in a different crate. But that's not something that I can solve, I'm afraid, so I'll have to put Trait and AnotherTrait in the same crate.
Yea, I was definitely interested in seeing some perf graphs and such. Overall, happy to see the paper. Glad things are working well for the npm team’s Rust projects. 
I really appreciated reading this as well. A strong, inclusive community isn't just about good feelings; here's a case where a big player solved a big technical problem and attributes a large part of that success to the health of the community. (Good feelings are also good though)
Thanks for the warm welcome :) I brought up the JVM thing as an example of how easy it is to get sidetracked with those kinds of comparisons. It wasn’t really meant to be a core point. But since you ask, no, I don’t think the overhead of JVM deployment is a big deal. The JVM has been around a long time, is very mature, and trivial to install on all OS. The operational overhead of actually “productionizing” a JVM deployment, things like process supervision, logs, monitoring, etc are tasks you need to perform regardless of whether you’re using Rust, Java, or QBASIC. In fact in many of those important tasks, it’s pretty easy to argue Java is a clear winner due to the maturity of the tooling. “Deploying libraries” is also completely irrelevant: even novice java developers know you can trivially pack all dependencies into a .war, or take the more modern approach of “shading” everything into one Uber JAR. Both approaches can be done with very straightforward Gradle/Maven config. Now I should note here we’re talking specifically in the context of a server deployment. Rust is a clear winner for CLI tooling, since minimising runtime dependencies for end-user deployments is a Very Good Thing. So if this paper was talking about how npm was very happy with it’s rewrite of the npm CLI in Rust (which would be hilarious), then mentioning how Java was outright ruled out because worrying about what version of Java is installed on a users machine is not something any sane person is going to argue with ;)
&gt; Here’s mine: the “overhead” of installing the JVM on a system is not a very good reason to rule out Java. 100% agree. Deploying Java is these days a non-issue.
&gt; but we spend exactly zero time building either of those compilers I don't mean build of compiler, we use Linux as development platform, and all rust tools installed via rustup. I mean rebuilding our code base in Rust language. The new compiler obviously requires rebuilding not only the code we write, but all the dependencies that we use. After that in case of compiler update we need to rerun not only our unit/functional/automatic and manual gui tests, but we also run `cargo test` for all dependencies. 
Plus because of rustup installation all tools also need retesting. For example was one case when rustfmt format code in such way that clippy gives error on this code. And because of PR should be formated with rustfmt, this prevents upgrade to X version of rustc.
Interesting. I would normally not think of any of that as expensive. It would be great if we could get a more detailed write up on what steps you're taking for each new Rust release and how long those steps take. I realize it's a lot to ask, but I think we're going to need someone to do it eventually. I strongly suspect that the answer for your case is not, "stop evolving," but rather, "make evolution faster." It shouldn't be a time consuming ordeal to move to the newest Rust compiler. I maintain _tons_ of projects and I spend almost no time on it at all. The most I can remember in recent history is moving some code to Rust 2018, but the cadence there is measured in years, and even then, it wasn't that bad.
It's... slightly ridiculous that it takes this much code to robustly copy a file.
&gt; . “You will write a correct program, but you will have to think about all the angles of that correct program,” I watched a few youtube videos of Bartosz teaching and he asked them something like "is our goal at work writing correct programs?", to which the class all laughed. I tend to agree, striving for correctness is good, but we don't write correct programs. The amount of work that would go into such an effort is prohibitive.
The font is this pdf is very hard to read. https://screenshots.firefox.com/QvFuQ9NJnEvofFdg/www.rust-lang.org#
I'm a bit confused here. Are you suggesting that anyone using a rustc distributed by their distro should also be testing with the latest stable? Doesn't that defeat the point of leaning on a distro for package management? And secondly, are you suggesting we open CVEs against Rust, on account of _fixed_ security issues, so that distros backport them? Maybe I misunderstand the CVE process, but it sounds to me like the Rust team would be within their rights to request that such CVEs be immediately closed as already fixed.
Yeah, I think that jives with what the reference currently says: "Constants are essentially inlined wherever they are used, meaning that they are copied directly into the relevant context when used. References to the same constant are not necessarily guaranteed to refer to the same memory address." But this doesn't feel to me like a consistent paradigm, and I know I haven't found it intuitive. There's a precedent for the expression inlining model in C: `#define VALUE (some expr)`, but Rust's `const` doesn't act like that at all. Rust `const`s: - look like bindings - act like bindings: they take a single type, that can' The combination of requiring `const`-initializing expressions to be referentially transparent &gt; but it's as though the `Cell::new(false)` expression was repeated everywhere the constant is used.
&gt; What I hadn't realized is that num just groups a number of sub-crates, including num-complex. So I replaced num with num-complex, and immediately reduced my dependencies (and of course my compilation time). I had the same experience with `num` when I first used cargo-graphs! That was a year and a half ago, I think. Being able to visualize your dependencies is really useful. Thanks for the comment!
I think that quote is vastly overselling the effect of Rust in this area. The language doesn't prevent logic errors, and you're totally free to `.unwrap()` a `Result` instead of writing error handling.
I love this discussion, by the way. * I agree that in a (SaaS) server context, deployment and environment are far less weighty of a consideration. There's little you can't automate, and Java installs weren't difficult to begin with, like you say. * I don't think there's much room for argument that the Java ecosystem -- both in terms of operations and development -- is extremely mature. * Java is still pretty good in terms of performance. It's not quite the same magnitude as with Rust, but the difference is small enough that I think the above point could easily outweigh it with the right values. So...yeah. :) Point made. I understand the opinions. Thanks for taking the time to elaborate!
As a side note: Why do so many crates end up depending on `winapi` when I'm building on Linux. Couldn't this be trimmed out? Does anyone know?
&gt; racism and sexism You keep using those words…
I had the same experience. Its ok in my case but i can image that people with problematic eyesight could get in trouble reading this.
No one pretends otherwise. What rust does is it prevents memory errors, resources management errors, and data races. It's mostly trivial to write rust code that doesn't crash, especially if you use clippy on strict settings. You'd be surprised what % of bugs are caused by the above issues. So in a very real sense, rust code is much more likely to be correct than code in many other languages. It's even safer than most GC'd languages in many applications.
I like how this whitepaper sidesteps the "but the rewrite is the real improvement!" by also rewriting the service in Node.js along with Go and Rust.
Aren't most programming languages quite inclusive? Certainly the PHP, Ruby, and JavaScript communities have been very inclusive from what I've seen - super helpful to newcomers.
About 45 mins from scratch. The whole rust path contains about 7.3G, and I have 4G of RAM, which completely suffice. Running GalliumOS.
It still forces you to make the choice to unwrap it.
Thanks!
Looks cool - try 'find' or 'ls | grep' too though if you're on linux / osx! &amp;#x200B;
Cool! It's always nice to see more CLI tools being developed with Rust. &amp;#x200B; Were you aware of [`fd`](https://github.com/sharkdp/fd) before you started writing this? I'm curious if you have any plans to add something it doesn't have. :)
&gt; Are you suggesting that anyone using a rustc distributed by their distro should also be testing with the latest stable? I mean that most *upstream* projects will probably be testing with rustup stable releases already, either for direct development or in CI. Long term, yes I'd love to see people reach for the distro toolchain for normal development, but we'll need to resolve community support for non-latest compilers first. I'm trying to keep Fedora and RHEL as current as possible, but there's some inherent delay, especially in the latter with its longer QE/release pipeline. I think we also need some rustc/std version awareness in Cargo.toml for this to work well. &gt; And secondly, are you suggesting we open CVEs against Rust, on account of fixed security issues, so that distros backport them? Maybe I misunderstand the CVE process, but it sounds to me like the Rust team would be within their rights to request that such CVEs be immediately closed as already fixed. I don't think that's so unusual -- for instance, [CVE-2018-1000657](https://nvd.nist.gov/vuln/detail/CVE-2018-1000657) was published in August 2018 for an issue that was fixed in Rust 1.22, November 2017. This doesn't have to create a rust-lang/rust issue at all, where the upstream Rust team would be affected. The CVE itself is more like an announcement, and affected distros will open their own tracking issues to be sure fixes are deployed.
Are you able to use CI to offload some of the build times and validation? Obviously setting it up takes time, but it seems like something that could be mostly automated using a build matrix and possibly branches.
Same. And where I work projects/teams are very small so a policy like this works well. I was surprised recently when looking through a PR for the winapi crate that the maintainer was checking compatibility against rust 1.6. It's been nice that the winapi crate "just works" no matter what I try, but keeping the code building on 1.6 seems like an unnecessarily high bar to me (I haven't seen the maintainer's justification, it might be well justified).
Next time I will compile redox I will try adding ff to my "redox distro". :)
Thank you! I came to know that there exists fd (and ff) already when I tried to publish it with \`ff\` name on [crates.io](https://crates.io). I use \`rg\` (ripgrep) very often and that's what inspired me to write this tool. I am open to and would really appreciate the suggestions, feedbacks and help. Right now, this tool feels slow while searching through a lot of files. I am thinking to try to address the slowness issue first.
Oh, how many antiquated servers do you maintain? Do they have large OS partitions? Nothing funky in the environment like a unchanging root partition you would need to reboot to change I take it. Probably don't have to worry about already having reached the max size and now you have to remove programs to fit anything else on it. Sure maybe you can make a virtual file system in memory to fit java into and load it during runtime. Oh, the servers are already strapped for memory as it is... Tell me more about how it's a "non-issue".
&gt; the “overhead” of installing the JVM on a system is not a very good reason to rule out Java. I thought the point could have used more elaboration. They already have a deep stack of JavaScript, which requires having JS installed on their systems. Why is the JVM different? Maybe they're trying to get away from having to install system packages on their hosts, which is, I think, a valid concern. But if that was the underpinning reason, it was not illustrated that I read.
&gt;But since you ask, no, I don’t think the overhead of JVM deployment is a big deal. At my $dayjob, I work on a java server application (something that's deployed into a tomcat application server). Dealing with JVM deployments is something we have to spend time on. It's not something we can ignore. Last week I tracked down a problem that was related to different JVM installation directories on different machines, and this week we're dealing with problems related to which version of the JVM we're going to use. Would problems like these influence the my language choice for a future project? I don't know. But I can say for sure that in my experience, dealing with JVM deployment issues is something that takes up a non-zero amount of my time.
Thanks. This nifty utility is intended to be used in place of those commands. If you have any suggestions or feedback, please let me know.
May because of you work with small Rust projects you didn't see what is pain to work with big one? For example let's take `ripgrep`, on my machine time build of fresh checkout of ripgrep with obviously empty `target` directory takes time cargo build --release real 0m28,590s user 4m22,611s sys 0m5,281s while my project release build from scratch takes 15 minutes on the same machine
I acknowledge the pain with rayon, and I do want to relieve it. I intend to write a new rayon-RFC setting a version policy, in which we may bump requirements with only a minor semver change. I'll probably still keep that fairly conservative though, something like a year of rustc support.
Wow! Then ff really needs to shine and be responsive. :)
Regex by default (or at least I assume that's why you're escaping all the dots, i.e. \\.png) seems odd, given that a big use case for this would be querying file extensions
Fair points. I didn’t say that JVM deployment equates to zero overhead ;) Rather, I said I don’t think it’s that big a deal. I spent a few years working at a primarily JVM shop too. I remember needing to do annoying crap like updating timezone databases and dealing with those f***ing security policy files, among other things. Despite that, I still don’t have the overall opinion that JVM deployment is particularly problematic or time consuming.
Why are you replacing all quotes with special unicode quotes? It breaks compiling.
&gt; Are you able to use CI to offload some of the build times and validation? &gt; Obviously setting it up takes time, but it seems like something that could be mostly automated using a build matrix and possibly branches. We use CI of course. But obviously you have too reduild code on local machine too, may be only for one or two variant of build matrix, but this obviously takes huge amount f time. Plus there is issues with tools, if you see many problems in CI for some variant, it is not convenient to read text logs from CI and jump by lines with errors by hands, so you need rebuild on your machine failed variant.
You can do *anything* if you put your mind to it. I'm still waiting for someone to put their mind to this whole car thing though.
Thanks for the feedback. Right now, the provided pattern is parsed as a regular expression. I understand your concern and will surely try not to parse patterns to regex for querying files by extensions. My intention is to keep things simple. One need not to remember an additional flag just to search by regex. Default behaviour should be sensible, handy and quick.
Of course, it is 2019! https://downloadmoreram.com
I want to debug Rust in VSCode. (I'm having trouble with searching) 1. Is LLDB to be avoided? In the book it says it's unstable on windows 64bit. 2. Do I install GDB using an extension or externally? I tried: - I set default build to run `cargo run`. (Which compiles and runs correctly, without debugger attached) - I installed VSCode extensions: - Native Debug (web freak) - Rust (rls) - c/c++ - I installed `Visual Studio Build Tools 2017` for c++
Ultimately it depends on what NPM do. Where I work if we want to deploy a new service then we just spin it up on a new server. We don’t try to fit it onto a pre-running server. In that environment deploying Java is trivial. In fact I would say Java brings the least number of headaches.
This is actually very cool! Is there a way to use this outside WebAssembly? There's [libdislocator](https://github.com/mirrorer/afl/tree/master/libdislocator) filling a similar niche but it's not really maintained, and ASAN is not always an option.
Most fundamentally, it’s the difference between and empty array and no array. It’s perfectly valid to want to treat an empty array differently from no array. It’s part of Rust’s goal to be able to represents differences like these in the type system to aid the programmer in preventing bugs. Technically/literally, an `&amp;[f64]` (a slice) is stored as a pointer and a length. The `.len()` function is a function on a slice (not an `Option`) that returns the length stored. Like the other reply said, if you actually want to treat no array as zero length, you can do it pretty easily with something like `opt.map(|x| x.len()).unwrap_or(0)`. Which is beneficial because it shows the true intent, treating no array as a length of zero.
True, but I'm not a fan of short-circuiting logic for real applications, especially in Rust. Feels like the perfect spot for weird logic errors to pop up.
Direct link to the list of projects: https://tokio.rs/gsoc/
Well... the C and C++ communities are not always the most welcoming. I think it's a bit better on StackOverflow now, but at the beginning I remember answers on the `[c++]` tag that were full of vitriol. I also hang around on r/cpp where I've been subject to rather nasty replies to my comments, usually after criticizing certain aspects of the language or the standard library, usually telling me I was too stupid to understand them (for the kindest ones). And there's a rampant attitude that other languages can be summarily criticized and rejected which I've seen applied to... basically all potential competitors of C++: D, Go, Nim, Rust, Zig... Usually by a subset of individuals, but when the moderators/community don't argue against it and the comments get upvoted, then it certainly feels like a wholesale rejection.
&gt;Replace newlines with commas: &gt;sd: sd '\n' ',' &gt;sed: sed ':a;N;$!ba;s/\n/,/g' Does that mean that `sd` matches over the entire buffer, and loads it entirely in memory before starting?
The distro maintainers are paid by their customers to do that maintenance themselves. Distros understand that asking library maintainers to do unpaid work to help them is unreasonable, so they'll happily pay for any work they actually want you to do.
&gt; “Deploying libraries” is also completely irrelevant: even novice java developers know you can trivially pack all dependencies into a .war, or take the more modern approach of “shading” everything into one Uber JAR. Both approaches can be done with very straightforward Gradle/Maven config. As someone who only dabbles in Java (ie, I occasionally copy/paste a `pom.xml` to create a new library in an existing codebase), you're scaring me ;) Remember that NPM engineers come from a different ecosystem and may have absolutely no prior experience with Java, so: - No experience with Gradle/Maven, how hard is it to setup/maintain? I don't know. - No experience in those `.war` or "shading" stuff, I've only seen forests of `.jar`, how hard is it to setup/maintain? I don't know. - No experience in diagnosing/tuning the JVM, how hard is it to do? I don't know. By contrast, Rust promises a straightforward package management story (name + version of dependencies, done), a statically-linked binary (copy/paste single file and play) and no bizarre run-time options (I had to set some options for CLion's, wasn't fun, found contradicting advice on Internet :x). I can definitely relate to them! 
Isn't this solved by modern deployment workflows, i.e. embedded Tomcat in Docker? I realize this isn't a possibility for all organizations, but I'm also not sure we should compare "legacy" JVM deployments to modern languages like Go / Rust. To be clear, shipping a single binary is waaaay nicer, but I'm not sure JVM deployments are a reason not to choose Java. At worst, the maturity of operational tools around the JVM that other languages lack should make it a wash.
I don't necessarily want graphs, but I do want closure. Teasing us with announcing a performance test and not mentioning any result isn't fair :(
Most things that usually aren't a big deal have some context wherein they become a big deal. It may not matter to me, but it may matter to someone.
&gt; I like the fact the main take away from this is rust is boring. I have to do on call and boring code is good. Fully agree. Operationally Boring is the best compliment a language can get.
Android build tool doesn't make the Java stub for you. What happened was that Google just added a Java activity class with a couple of native methods similar to what everyone was doing already. https://developer.android.com/reference/android/app/NativeActivity?hl=en So you either create a shared library with the entry points expected by the NativeActivity class, or you just write your own Java class with the native methods that are more convenient to you. Which is exactly what SDL does, they bring in their own set of Java classes. http://hg.libsdl.org/SDL/file/c005c49beaa9/android-project/app/src/main/java/org/libsdl/app I have a very old example [here](https://github.com/pjmlp/TownGL), still with Ant and ndk-build. If anything just send me a message.
I made a little tutorial here, it uses tide web server but should work with anything really [tutorial ](https://gill.net.in/posts/creating-web-server-deb-binary-with-rust/) 
I’m rewritting with rust an Adaline (neural network) implementation I had in python. For now is really enjoyable, I can’t wait to see it running.
Thank you for reply. &amp;#x200B; But vectors are used in "for" loops. using reference and value [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=540f5dc043dad03a1a95973420d63f59](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=540f5dc043dad03a1a95973420d63f59) &amp;#x200B; &amp;#x200B; do we need to build "IntoIterator" for this ?[https://doc.rust-lang.org/std/iter/index.html#for-loops-and-intoiterator](https://doc.rust-lang.org/std/iter/index.html#for-loops-and-intoiterator) &amp;#x200B;
I think we're veering pretty far off track here! &gt;Remember that NPM engineers come from a different ecosystem and may have absolutely no prior experience with Java, so: If that's the case then it 100% crystallizes my original point. Making assertions about language/framework/idea XYZ is a great way to feed the internet trolls like me. Let me restate what I was trying to get across originally. Writing a recap about how great Rust is at solving a problem you had is 100% fantastic. Dismissing other alternative solutions with a mere sentence or two is just inviting criticism that detracts from the original goal of promoting Rust. Maybe I haven't been clear in my comments so far, I'm a big Rust fan that is only falling more and more in love with the language and the ecosystem. Not sure if it's Stockholm syndome, but I even love the borrow checker! ;) But what I love even more is debates with randoms on the internet. So you're in a luck! Here's a point by point response: * Gradle and Maven are trivial to set up. \`brew install gradle\` or \`brew install mvnvm\` ([mvnvm](http://mvnvm.org/) is a fantastic ShipIt project from a former colleague of mine). * Building a "Fat JAR" is easy. [Here's an example Gradle config to do it.](https://gist.github.com/TurekBot/4a3cd406cb52dfd8bfb8022b982f0f6c) The relevant lines are #11, #16, and #30-34. * Diagnosing and tuning the JVM is actually by far the biggest selling point of the JVM as a runtime for server applications. HotSpot GC is the gold standard by which all other GCs are held to. The JVM has a whole host of utilities, tools, and libraries to assist in every aspect of operationalised services (thread dumps, core dumps, extracting runtime metrics, logs, etc). In addition, thousands of years of human effort have gone into exploring and documenting all these aspects in various high quality documentation resources/blogs/talks/whitepapers/etc. &amp;#x200B;
Upgrading `rustfmt` and `clippy` are not so trivial, I agree. These didn't *used* to be tied to the `rustc` version, but now `rustfmt` is — I can see that as being a problem.
&gt; True, but I'm not a fan of short-circuiting logic for real applications, especially in Rust. The need for `let x = Some(b) &amp;&amp; y = Some(a)` that short-circuits happens quite frequently in real applications. Most notably, the degree to which this pattern occurs within `rustc` is silly. However, `rustc` instead uses nested `if`s and that leads to poor readability due to right-ward drift. &gt; Feels like the perfect spot for weird logic errors to pop up. I have no idea why you think that; why would nested ifs lead to logic bugs?
Here are lookups (evmap is the higher blue) [https://imgur.com/a/ur4kIwJ](https://imgur.com/a/ur4kIwJ) Inserts are worse, and don't scale at all due to the fact that the writer has to be wrapped in a mutex. At two threads, both skipmap and swym-rbtree are faster, and Mutex&lt;evmap&gt; just gets worse as you add more threads. It's a little too apples and oranges for my taste to be in the repositories benchmarks (not to mention the lookups graph gets really skewed by adding it). If I wind up making a STM backed hashmap, I will definitely include it in the benchmarks!
Seems like we'd be better off calling them out for being assholes than congratulating everyone else on being inclusive. &amp;#x200B; Being civil is how you're supposed to be. We can disagree but being hostile is uncalled for.
That logic can be applied to virtually any argument for or against, well, anything really ;)
Looks like it does -- see the \`read\_to\_string\` invocations [here](https://github.com/chmln/sd/blob/master/src/input.rs#L124-L145).
&gt; sed: you need to remember to use -e or else some platforms will consider the next argument to be a backup suffix Nope, sed -i simply is not portable without a backup suffix. `sed -i -e`, on BSD sed, will simply use -e as the backup suffix.
Yes and no. Many tasks seem simple until one starts thinking about all the corner cases. I’m glad this function takes it’s use semantics seriously, so that users of this function won’t have to.
`IntoIterator` won't work either. Consider what happens when someone calls `.collect()` on your counter. If every item it gives is a reference to the same value, then the container would end up with references to the same value that you're trying to mutate when you advance the iterator, which is not allowed. `Iterator::collect` is implemented for every `Iterator`, so any struct that can't implement `collect` can't be an `Iterator`. `IntoIterator` just provides a method to turn the struct into a value that implements `Iterator`. You can implement `IntoIterator` on your `Counter`, but then the struct you return needs to be able to implement `Iterator`, so it can't hand out references to a single internal value either. `Vec`'s iterators work by holding on to the entire collection. Each call to `next()` returns a reference (or move, for the one that `into_iter` returns) to a different element in that collection, which is allowed.
Looking at the code, that appears to be the case. Kind of takes the "stream" out of "stream editor". :(
\&gt; Which is exactly what SDL does, they bring in their own set of Java classes. &amp;#x200B; ah so it does indeed need a mixed java/c++ build, sounds messy (more like i was originally expecting i guess). I guess it must streamline their implementation though thanks for the link, i'll take a look
It's such an elegant solution though. I love being able to move fast\[er\] for prototyping knowing I can come back later and search for all my unwrap/expect uses.
\&gt; I have a very old example [here](https://github.com/pjmlp/TownGL), still with Ant and ndk-build. &amp;#x200B; do you know if that still works? is there any reason \*not\* to just keep using it ? (although not SDL, i have my own adapted native-activity sample.. i guess i dont want to re-implment 'the bits of sdl i use' though..) &amp;#x200B;
Hey, sd author here. You are correct. I personally haven't tested memory usage beyond 1GB files, but if this ever becomes a concern I will implement a more robust replacement method. Please feel free to file an issue for any problems you encounter while using sd.
I'd be interested in hearing what issues they encountered with Matrix. Not doubting, but wondering what the pain points are for a use case like this.
&gt; npm’sfirst Rust program hasn't caused any alerts in its year and a half in production. 
Username checks out. Back on topic: some communities are nice on the surface, but have their own problems that aren't necessarily always easily visible on the surface. For instance, some parts of the JavaScript community tend to be assholes to each other regarding framework wars. I remember seeing many people calling the State of JS post "Facebook astroturfing" due to its high rating of React. In general, I think the JS community is pretty good, but they have topics to avoid that will generate flamewars.
Thanks! I don't know enough to get involved in type theory discussions! I'm using a lazy_static `Mutex&lt;HashSet&lt;TypeId&gt;&gt;` now to detect attempts to create multiple singletons with the same marker type.
 { let c = String::from("gg"); test.s = c.as_str(); test.s = b.as_str(); } C goes out of scope, so it doesn't seem reasonable to expect to hold a reference to it from outside of that scope?
&gt; Long term, yes I'd love to see people reach for the distro toolchain for normal development... ...I think we also need some rustc/std version awareness in Cargo.toml for this to work well. So what's your advice to current Fedora and RHEL users? Should we be installing our own rustc because the one you're shipping may come with unexpected ecosystem incompatibility (with the promise that you're working to remedy this)?
`unwrap` is _so close_ to an elegant solution, it just needs `RUST_BACKTRACE=1` to do anything debuggable when things go wrong. Which they do, because this is the real world.
I can say that personally, using Matrix primarily as an IRC bridge, it's been very very slow, frequently misses notifications, can't keep track of who's online, and (subjective, less important, has improved recently) doesn't have a very pleasant UI.
The problem is the initial assignment of the borrow of `c`. If there were a panic immediately after, then it would never get to where it used `b` instead. This would allow the borrow of `c` to escape the block where it is valid. So, NLL doesn't help with this particular case.
As a library author I try to not upgrade the required rust version unless I’m otherwise making a breaking change *anyway*. This means that some of [my libraries](https://github.com/nagisa/rust_libloading) are stuck at supporting versions as early as 1.14, while [others](https://github.com/nagisa/rust_rdrand) require versions as new as 1.30 (for good reasons).
That is correct behavior. If `Test` was `Drop` and fn drop looked at `s`. Then if there was a panic between test.s = c.as_str(); panic!("boom"); test.s = b.as_str(); Then Test::drop would have a use after free issue. As for what NLL helps with can be read in Niko's Blog posts. http://smallcultfollowing.com/babysteps/blog/2016/04/27/non-lexical-lifetimes-introduction/ http://smallcultfollowing.com/babysteps/blog/2017/07/11/non-lexical-lifetimes-draft-rfc-and-prototype-available/ http://smallcultfollowing.com/babysteps/blog/2018/10/31/mir-based-borrowck-is-almost-here/
Another alternative is to stick with prefix await but add delimiters like `await(foo)?` or `await { foo }?`.
While I'm glad for their use of Rust (whoop whoop!). It's a little disappointing they didn't go into numbers of resource usage, or performance (one of their motivation for switching to Rust). Also, it seems they didn't tell us a good reason for not using Go, besides "we didn't like the dependency management" which is valid, but is it a big enough reason to dismiss the entire language? This white paper left me wanting more details (in a bad way).
Now add that up across _all_ of the project I maintain, which is well into the dozens. If I had to do a bunch of stuff everything I upgraded Rust, I'd be hosed. But yes, a 15 minute build is definitely unpleasant. But the solution there is to make compile times faster. Not hold the ecosystem back. A 15 minute build every time you update Rust (which is at worst once every 6 weeks) doesn't seem like that big of a deal to me. Keep in mind the original context of this discussion. We want feedback from folks about why they specifically need crates to work on older compilers.
You have a couple mitigation strategies available to you: 1. Use a memory map. The OS will handle memory usage for you. 2. If the pattern can never match through a `\n`, then you can do incremental searching. If you use libripgrep---and I think you can---then it will handle this for you.
Does this remove hidden sections in doc tests as well? https://doc.rust-lang.org/rustdoc/documentation-tests.html#hiding-portions-of-the-example If so I'll definitely start using it 
This looks like it's directed at /u/chlmn_.
Of course, my comment was if anything finding fault with the operating system: this PR is great, but as a programmer, I shouldn't *have* to think about corner-cases like sparse files or other features that may not have even existed at the time I was writing my program. *Particularly* when files are such a fundamental concept in *nix. If the operating system exposes a concept (like a file), it should also expose mechanisms to work with that concept in a forwards compatible way. 
OpenBSD's malloc (`omalloc`) with the `S` option is pretty nice. In order to test C apps, I often replace the allocation functions with libsodium's guarded memory functions: https://download.libsodium.org/doc/memory_management
- Look into what is missing for https://github.com/Keats/tera v1 - See what else can I add/fix before shipping [Zola](https://github.com/getzola/zola) 0.6. It already contains the first batch for multi-lingual sites (still taking feedback in https://zola.discourse.group/t/rfc-i18n/13/24) - Thinking about the api for the next version of [jsonwebtoken](https://github.com/Keats/jsonwebtoken/issues/76), feedback welcome Not much coding!
Yeah, there's a whole class of claims, like "I am tall", that may be true in one context, but not in another. I'm not particularly tall, but I'm big in Japan, as the saying goes. Anytime you catch yourself saying something unqualified like "foo is not a big deal," without specifying any context (for what purpose, to whom, at what scale, for teams of what size, etc.) then your claim is probably too broad.
The truth is perhaps somewhere in the middle. When people complain about "deploying" Java, it is more of a death by a thousand paper cuts type scenario. The JVM is a few hundred megabytes and depending on distribution, needs to be installed separately without the help of the Linux distribution's package manager. You also have to be aware of which JVM you are using and the legal repercussions from a licensing standpoint. Typically next you have to enable full unlimited cryptography strength in the JVM by downloading another file (navigating Oracle's website and accepting the license agreement) and manually install that. The cryptography strength in Java is limited due to "legal reasons," because, Java. Managing TLS certificates within keystores can be a chore. Process management and performance analysis can be difficult when every process is named "java". (Of course, there are ways around this.) Java services typically consume 4x to 10x as much memory and more svelte languages, creates a certain amount of operational overhead and development pain, especially when juggling many microservices. Java services use relatively a lot of memory and many medium to complex applications will require extensive and continued tuning of the GC parameters. Many Java services use application servers like JBoss, which are a whole other beast of complexity. Application servers were created in the 90's because of the large amount of RAM Java uses. The idea was to put common services in the application server, and restart apps within the application server container. This has as you can imagine mixed results, to put it nicely. An ostensibly "idle" JVM uses a little bit of CPU constantly, creates at least 20 or 30 threads (mostly for RMI and GC). (Compare with a bare Node.js process that uses no CPU at all when idle, and 8 threads out of the box mostly just waiting in a threadpool for file I/O.) While the JVM itself ostensibly starts up in less that 300ms, classloading is still very slow and a typical microservice takes 10-30 seconds to fully load and bootstrap, a larger application server app can take minutes. Academics have written tons of articles explaining the many ways of how Java is actually fast and that we just don't realize it, which kind of proves that Java not actually fast. Maven (package manager) sometimes corrupts itself, require re-downloading of many gigs of packages. Enterprises typically have to deploy their own Artifactory instance to manage artifacts and libraries. Yes, all this can be automated and dealt with, and none of these are particularly difficult, it's just all the additional hurdles add up.
I forgot that panic statement triggers stack unwinding and thought it works like std::terminate(). Then yes, that's right, thank you for your reply.
&gt; Gradle and Maven are trivial to set up. `brew install gradle` or `brew install mvnvm` (mvnvm is a fantastic ShipIt project from a former colleague of mine). Okay, they are set up, now how do I use them? &gt; Building a "Fat JAR" is easy. But first you need to know that you even want to do that (and why)
I'm not really sure I agree here. I didn't qualify "the JVM is not very difficult to deploy in server environments" with any particularly nuanced context, because I don't think it's necessary. The JVM is straightforward to deploy for any size team (see: startups building on Java/Clojure/Scala/whatever through to large enterprises) at any scale (see: Twitter) in virtually any context (see: straightforward enterprise apps, HPC, high frequency trading apps, set top boxes, mobile phones, etc), and to any platform environment (see: packaging of Java in literally any and every OS package manager you can possibly think of). You're right that qualifying claims is important, and if you were to call me out on making a specific claim that is too broad then I'm happy to elaborate further or cede some ground. I just think this particular claim isn't a great candidate to challenge, since we're talking about one of the most popular and widely deployed language/runtime in the world ;)
Well, Ant is no longer a thing in Android world, having been replaced by Gradle. ndk-build might still work, given that after some wrong turns, Google has ended up with a mix of ndk-build and cmake as NDK build tools. So, replacing the build.xml by the corresponding set of Gradle files might do the trick. 
 &gt; Okay, they are set up, now what do I do with them? Cmon, I don't think that's fair :) If someone was a complete newbie to Rust, they don't magically know what to do after they've run `rustup install stable`. Even if they know what Cargo *is*, that doesn't imply they know how to use it. &gt; But first you need to know that you even want to do that (and why) That's a fair point. Building Fat JARs comes in many guides to "modern Java". In fact most modern Java frameworks, tooling, bootstraps will probably spit out a fat JAR for you by default (I know Spring Boot does for example). Java definitely has more history, complexity and legacy cruft that results in the whole "do I want a thin JAR, WAR, fat JAR, or something else" topic. It's certainly much more complicated than a nice self contained binary from Rust!
Wow, this is a great opportunity. For those that don't know, Brave creates a privacy-oriented web browser, and was initiated by Brendan Eich, former CTO and/or CEO at Mozilla, and probably the person most responsible for making Rust happen - by funding Rust's early development when pretty much nobody believed in it. Sadly, their browser is based on Chromium, but I'm super-excited that Brendan has finally circled back and begun incorporating Rust into Brave. Having this on one's resume would be huge for anybody looking to make a career in Rust in particular, or systems programming generally.
It's never mentioned when someone asks this, but I think it's important so I will also add that even if all the stuff currently in the works is stabilized, we still can't return `impl Trait` or use async functions in trait methods. :{
&gt; Typically next you have to enable full unlimited cryptography strength in the JVM by downloading another file (navigating Oracle's website and accepting the license agreement) and manually install that. The cryptography strength in Java is limited due to "legal reasons," because, Java. This has not been true since Java 8 update 161 https://bugs.java.com/bugdatabase/view_bug.do?bug_id=JDK-8170157 
On my NAS (which I use to build Rust): ``` user@host:~/rust$ uname -a Linux host 4.15.0-39-generic #42-Ubuntu SMP .... x86_64 x86_64 x86_64 GNU/Linux user@host:~/rust$ cat /proc/cpuinfo | grep "model name" model name: Intel(R) Core(TM) i7-7700K CPU @ 4.20GHz user@host:~/rust$ sudo smartctl -i /dev/nvme0n1p2 | grep "Model Number" Model Number: Samsung SSD 960 PRO 512GB user@host:~/rust$ sudo lshw -short -C memory H/W path Device Class Description ================================================================== /0/0 memory 64KiB BIOS /0/3d memory 64GiB System Memory /0/3d/0 memory 16GiB DIMM DDR4 Synchronous 2133 MHz (0.5 ns) /0/3d/1 memory 16GiB DIMM DDR4 Synchronous 2133 MHz (0.5 ns) /0/3d/2 memory 16GiB DIMM DDR4 Synchronous 2133 MHz (0.5 ns) /0/3d/3 memory 16GiB DIMM DDR4 Synchronous 2133 MHz (0.5 ns) /0/43 memory 256KiB L1 cache /0/44 memory 1MiB L2 cache /0/45 memory 8MiB L3 cache /0/100/1f.2 memory Memory controller user@host:~/rust$ rm -rf target build tmp &amp;&amp; ./x.py build ... Build completed successfully in 0:32:41 ```
&gt;It's even safer than most GC'd languages in many applications. I agree. Actually, Rust is much safer than the *vast* majority of GC'd languages. Most languages have a null/nil/undefined value, don't prevent race conditions, don't force you to handle errors, etc. I heard that Haskell is very good at enforcing safety as well, but I've never used it.
About 20 minutes here from scratch to stage1 codegen tests. ``` Build completed successfully in 0:24:38 915% (1479.20 real, 538.29 kernel, 13004.72 user); 4084680k resident ``` This is a desktop that I’ve build for Rust compilation as its primary purpose. I wish I went for a beefier system nowadays :) There are a lot of specific choices I made building that make compilation somewhat slower (NAS-grade HDD drives) while compensating for the speed loss somewhat in other ways (ZFS + huge l2arc + huge arc).
The only point that I'd like to leave you with is that the document comes from real people who have told us what does and does not work for them in their context. I am not going to presume to know more about their needs than they do. You go right ahead, though. I just think it's more likely that they know more about their own constraints than we do.
If you use `expect` instead of unwrap, you don't even need `RUST_BACKTRACE=1` ;).
You have a lot of excellent points that make it clear you've got a respectable amount of experience with the Java ecosystem. Your comment is also a tiny bit Gish Gallop-y though. Either that or virtually all of your experience stemmed from working on Java apps from &gt;10 years ago. I won't try and cover all of your points, instead I'll begin with the ones I agree with: &gt;Managing TLS certificates within keystores can be a chore. True. \`keytool\` can burn in the fiery lakes of hell for all eternity. &gt;Many Java services use application servers like JBoss, which are a whole other beast of complexity. Can confirm. I've wasted days of my life looking at Glassfish source code. Here's some places where I think you're wrong though: * Modern Java app startup time is nowhere near as bad as you're making it out to be. I've written dozens of Java microservices that are starting up and receiving connections in under a second. * Yes, Oracle is not a particularly pleasant company, but even those folks are not changing their license agreement every point release. * If you're at a point where you're deploying multiple Java services on a machine, it's pretty likely you also know how to use Google and learn of the existence of \`jps\`. * I'm assuming you meant Ubuntu/Debian when you mentioned "Linux package manager". [There's this](https://launchpad.net/~webupd8team/+archive/ubuntu/java) for Oracle Java packaging for example. * Idle JVM is nowhere near as chatty as you implied. I'm guessing this stems from your experience with antiquated Application Servers, which I agree definitely had a lot of pointless crap running in the background. Not so in modern Java apps though. * Ancient versions of Java definitely required a lot more GC tuning. These days, if you're finding you need to tune your GC it's because you either a) are at Twitter scale (congrats!) or b) have a bunch of garbage programmers who are generating a lot of inexperience. Err, wait ... * I used Maven in my day job fulltime for years and never once had a corruption event like you described that required me to re-download that much. Though if you want to assert that Maven is just generally dumpster fire, I will happily agree with you :) Just a reminder: I'm just here to troll because I like arguing on the internet and I also still think Java is cool. But let it be known that I would reach for Rust over Java in a great deal many situations for both server and client side. Since we're in r/Rust I just want to say: Rust r00lz! :)
Absolutely fair points and solid rebuttal. &gt; written dozens of Java microservices that are running and receiving connections in under a second. That's quite impressive. What libraries are you using to build this with / which version of the JVM? 
If you're using a systems level language like rust, you kinda signed up for it.
This was a couple of years ago when I was deploying on Java 9. I was using Dropwizard IIRC.
Would like to see this too as I also have a browser w/ a [C++ ad-block rule parser](https://github.com/cretz/doogie/blob/master/src/blocker_rules.cc#L290) that could be replaced. The rules are fairly straightforward. I'd say parsing is less important than the runtime lookup.
But the great thing about implementation details is that they can often be tweaked after the fact.
That's funny, this answer fits really well with the overall description of the parent post.
Definitely not Wildfly. Source: am Wildfly user. I've done some smaller things in Javalin that were pretty quick, but they were small one offs that also served their brief purpose and then were entombed in the great repo in the ~~sky~~ cloud
Oh just one other thing to add to my critique. &gt;Enterprises typically have to deploy their own Artifactory instance to manage artifacts and libraries. I guarantee you when Rust really takes off in the Enterprise it will be in exactly the same situation. The reason companies deploy an Artifactory instance is to shield themselves from third party outages. [crates.io](https://crates.io) is great, and I've never observed it go down (unlike, conveniently, another package hosting service that is contextually relevant to this discussion whose name starts with "n" and ends with "pm". It went up and down like a yoyo back in the day), but most large organizations will still want to mirror all the crates they use to an artifact manager under their control.
The Dependency management in Go was horrid before Modules. Not just bad, but basically non existent. If you're a Dependency Management company, poor dependency management is probably a bigger irritant for them than for your average developer, and oh boy was it an irritant. I lucked out in that my work didn't really dive into Go until 1.10ish, or at least that was the first version I had to install, so we were only pained by dep and it's precursors for a short while.
To be clear, it can do either. You can pick which behavior.
I'd also like to add that you should try and have a name that stands out at least a little bit so people can remember it, and find it again later. I may only half remember something, and google won't help me find it, if it's got a super generic name. I backed an SBC on kickstarter, called the C.H.I.P. A little 9 dollar Arm based computer, if you haven't heard of it. Do you know how hard it is to find relevant information when googling something like "Help installing arch linux on chip". CHIP is such a dumb name for a computer. Pick better names for your hardware/software.
Google Summer of Code is a great program! I did GSoC last summer (not with Tokio) and it was an amazing experience.
4 letters is pretty comfy to type (grep, find etc.), and it is a vastly larger set than just 2 letters. &amp;#x200B; But I personally wouldn't be afraid to go even further. Power users who will use your command often can just alias it, or use the reverse search tool of their shell (which, by the way, I often utilize for quickly running various cargo commands).
&gt; Cmon, I don't think that's fair :) If someone was a complete newbie to Rust, they don't magically know what to do after they've run rustup install stable. Even if they know what Cargo is, that doesn't imply they know how to use it. I'll grant you that it's not fair, but cargo is much closer to npm than maven/gradle are, in philosophy and usage. 
`expect` prints the error message I give it, but it doesn't tell me which line of code in which file the `expect` that launched the crashing panic is on.
I have no issue with this. If anything, I think Debian should proactively rename a lot of the really short/generic package- and file-names that they've been carrying since the 1990s and 2000s-- a time when name clashes were a far smaller issue, for obvious reasons. Name transitions are a bit annoying, but they can be accomplished fairly smoothly over one or two releases.
&gt; To evaluate candidate solutions, the team rewrote the authorization service in Node.js, Go, and Rust Alright, this just got very interesting - it's extremely rare to see companies willing to rewrite software not only once, but three times, to ensure that they've picked the right tools. I wish that more had been said about Go. Was the dependency issue really the one thing stopping them from using it? If Go had Cargo, and was 3x faster to build, what then? I'm not convinced that Rust is the right choice here, just based on this data. Obviously JS can't perform, but I would have liked to have heard more about it. The biggest selling point is clearly the stability/ 'boring' aspect - but it throws away the coolest data points, which are the rewrites. Were the new JS/Go versions ran in production at all? Were they operationally more difficult or buggier? Would love to hear more here. Given the rarity of a company rewriting a service 3 times it would be really cool to see a much more in depth analysis. Like, I struggle to recall any research on PL that involved triple re-writing a real, production service, and that's something that I would consider a very valuable contribution. edit: I'm aware that this is not a research paper, I just see a lot of potential for it to be one.
If prefix await is chosen, I'd probably (1) not chain methods at await boundaries (2) write `?` on subsequent lines: let result = await future; return result?.map(...); Anything to avoid parens. :)
Basically there's an insanely large userbase for winapi, and breaking anything ever with that crate is not to be taken lightly.
I own a chip. Also backed it on kickstarter. Apparently the business shutdown. But in other news, you can install rust on it.
I used to work as a computational neuroscientist. The two most used large-scale simulators are named "Nest" and "Neuron". With Nest you can at least search for something like "nest simulator", but good luck trying to find relevant pages for Neuron...
In general, debian packaging rules can rename your binaries if they happen to conflict with existing software on the debian platform. The same applies to other distribution packaging, as well.
Hello all, I started Forge a few days ago with the goal of creating a scripting language that can be used in Rust-driven games and similar projects that need runtime-defined behaviour. It's quite fun to program in, and inherits a lot from the worlds of Rust, Python and JavaScript. I'm looking for feedback on its design. If you have suggestions, criticism, or any other comments I'd love to hear them! As an aside... I also happen to currently be unemployed. If you're looking for someone to write remote code remotely at a low price, send me a PM!
Debian supports some ancient packages, and there may be proprietary applications which call out to, and therefore expect, applications with certain names.
This is exactly right. The response this has received is probably exactly why people don't publish experience reports very often. They get picked apart because they aren't being valued for what they actually are. Almost any kind of experience report is useful, and the in depth good ones are pure _gold_.
I’m probably unreasonably excited about [underscore imports](https://github.com/rust-lang/rfcs/pull/2166), but this looks awesome to me!
I named my little tool [lorikeet](https://github.com/cetra3/lorikeet) for this reason, to make it unique, but it fails to present what it's used for in just the name, so discoverability does suffer if you go the other way. I still think it's fair that shorter names should be checked for any conflicts of existing tools though. Is there a good resource for discovering which names are in use?
Hi. Would you be interested in someone willing to work remotely? I live in the UK, so commuting to San Francisco wouldn't exactly be possible. Relevant thing I've done/am doing: https://github.com/zesterer/forge
Haskell is good at safety because it's side effect free, meaning you can't do anything /s But in all seriousness, being able to encode all kinds of effects in the type system is why it's so good.
Even `libc` requires Rust 1.13 though. I think this is the crux of the question: if winapi increased its minimum Rust version to `CURRENT - 8`, who would notice? Why?
You want /r/playrust. This sub is for the programming language Rust. Although I'm willing to be a programming buddy for you if you want.
Control flow is pretty much next on our agenda for `const fn`; when those are in a reasonable shape, we can stabilize `panic!(..)`s in `const fn` since they start becoming useful.
Programming buddy? :o &amp;#x200B;
Howdy! We have a London office. I imagine (but can't promise) that for the right candidate we could figure something out. There is def a strong preference for someone who can be in SF, but we would probably be able to make exceptions for the right candidate
Interesting! Do you have any more information about the role available elsewhere?
nope, whats in the post pretty much covers it :) But if you have specific questions, happy to take a try at them here
Ok, thanks! I'll probably send my CV over.
I wish I can participate. But I'm already graduated :/
To all of this I would also add, "keep in mind how often users will type the name of your app". `ld` is a great example of a wasted short name. Perhaps 40 years ago people manually invoked it over teletypes, but these days it could just as conveniently be called `the-gnus-not-unix-linker` because manually invoking it is incredibly rare (and for those who do, it's easy to set up an alias) (and, lest there be any doubt, I write C++ professionally). If you're writing a GUI app, you do not need a short name. If you are writing a library you do not need a short name (I'm looking at you `libm`). If you are writing ripgrep you definitely need a short name (7 characters?? ain't nobody got time for that).
It is never too late to go back to school!
I'm trying to get my first project in piston up and running but for the last 4 hours all I've encountered is "Could not compile \`lazy\_static\`" and it's honestly driving me insane. I've started this project before and did so on my missus' Alienware laptop with ease. It still works even now. However, I'm trying to get it all set up on my rig (windows 10 btw) and all I keep running into are lazy\_static compilation errors. Not a clue why and it's doing my head in. Can anybody help a poor dude out? &amp;#x200B; For further info: `error: \`&lt;core::cell::Cell&lt;T&gt;&gt;::new\` is not yet stable as a const fn` `--&gt; C:\Users\Conor\.cargo\registry\src\github.com-1ecc6299db9ec823\lazy_static-1.3.0\src\inline_lazy.rs:20:33` `|` `20 | pub const INIT: Self = Lazy(Cell::new(None), ONCE_INIT);` `| ^^^^^^^^^^^^^^^` `|` `= help: in Nightly builds, add \`#![feature(const_cell_new)]\` to the crate attributes to enable` &amp;#x200B; `error: aborting due to previous error` &amp;#x200B; `error: Could not compile \`lazy_static\`.` `warning: build failed, waiting for other jobs to finish...` &amp;#x200B; Is the console log after every attempt at a `cargo run` for some reason. I've added the #!\[feat...\] lark to my [main.rs](https://main.rs) to borderline nil effect. I say borderline because it still gives me the exact same error and "help", but also breaks \`stb\_truetype\` for some reason.
I got one from the kickstarter, and then a second one for 8$ as part of their black friday sale the year it launched. I heard the company went under from Lunduke. I was kind of bummed out. I like my Chip's. I've never used more than once at a time though. I've got one running as a server, that I use to fileshare tiny files with my sister, and as a local git backup. It's sitting in a neat little lego case I built that looks like a spaceship.
So it's not actually sed or anything remotely like it then.
I mean it's a nice tool, but it doesn't appear to act like sed at all.
I understand that it 'had' existed. I know they are on the market currently. I'm talking about future. I expected next gen hololens to move away from ARM. 
&gt; If you are writing ripgrep you definitely need a short name (7 characters?? ain't nobody got time for that). To be fair, it's common to write a wrapper to work around the lack of a config file for default settings and call it `rg`.
\*nod* When picking names for my projects, my guideline is to never accept more than a double-digit number of existing Google results and (which accounts for typos and random weird junk in forum posts... often in other languages) and, if possible, to come up with something that has *no* Google results when using quotes to kill "Also searching for..." behaviour. (I'm rather partial to portmaneaus for their mnemonic value. For example, the placeholder name for the (not even public yet) repo for a set of parsers I'm planning to get back to working on soon is "parscellany" (parser miscellany).)
This is for the Rust programming language. You want r/playrust.
I think: Give the package a medium-length name which is memorable and unique in internet searches, and suggest a short name that the user might want to use in their alias list.
...but it has to plan for the stricter requirements of the unwinding case, because the behaviour is chosen by `Cargo.toml`, not the source code.
Or, to put it more effectively, "`expect` tells me *where* an invariant was broken, but it doesn't tell me *why*".
The problem of your code is that you had broken the rule of borrow. You can borrow mutually no more than once. You lent two times here. ( &amp;mut self) and (&amp;mut self.count), The second lend will move the self , So self.count is dangled.
oh shit my bad!
Plus modern shells have autocomplete, so you usually only have to type a few characters of a name anyway, regardless of length.
About 30 minutes from clean on an 8 core/16 thread i7 with 32gb of RAM and a M.2 SSD (openSUSE Linux).
This is the sub for the programming language Rust. You want to post in /r/PlayRust instead.
It seems you're looking for r/playrust
[More or less](https://github.com/graphitemaster/moreram)
Thankfully thats changing soon, theres some PR or other that'll add line numbers to unwrap, which is all i really need to debug. As is, `expect("unique message")`
Just the other day I lamented that sed doesn’t support modern regex, (plus the /syntax/ could be better) and halleluyah, apparently we can have nice things :)
`cargo +nightly run`?
Which is why it's an "alternative" and not a clone. :-)
&gt; remote code remotely This made me giggle.
`expect` gives me a string I can grep my source code for and pray it only appears once. That's not a location.
I'm operating on the assumption that you've managed to keep your `expect` strings unique. In that situation, it'll tell you where your program panicked, but not how it got there.
The C++ standard isn't made by a community.
Out of curiosity, which syntax were you looking for? POSIX sed, at least, does have an `-E` flag which adds extended syntax.
Well that’s kind of a silly policy. Short binaries have been around forever. You didn’t think we’d stop writing new binaries did you? Sounds like you need namespaces my friend. 
Debian just doesn't break stuff like that.
How would you namespace `/usr/bin`?
man mount_namespaces
Whoops, thanks for noticing the typo!
i love my little chip. sad to hear the company went under.
The changes I would be able to do if I increased the minimum Rust version would also be breaking changes to the API of `winapi` anyway. Therefore there is no point in just increasing the minimum Rust version would releasing a new major version anyway. 
I've been waiting for several features to all become stable so that I can make a single transition to `winapi` 0.4 where I will bump the minimum Rust version to 1.33 so I can take advantage of unions, `repr(align(N))`, and the recently stabilized `repr(packed(N))`. Until then I just stick with Rust 1.6 because it's really not that big of a burden.
I don't see an implementation PR, but here's the tracking issue for the RFC: [https://github.com/rust-lang/rust/issues/47809](https://github.com/rust-lang/rust/issues/47809) This issue has been known for a while, but it looks like it's awkward to design and implement a good solution. But since the RFC's been approved, hopefully it isn't too far off.
yeah it's a bit of a mess. And mine is running debian 8, so I'm worried about getting security updates. I have no idea when that is gonna stop. However, talking about my CHIP again, has motivated me to just go ahead and try and do that ARM Gentoo install I've wanted to try for a year now. So we'll see how that goes.
Everyone should at least give Brave a try. It is downright life-changing on mobile. Really cool to see them using Rust, too!
In some cases I would expect this to have security implications if a tool is called by such a proprietary application with the "right" parameters.
If anyone is seeing this: I need a language that has borrowing, concurrency, types, generics and ownership, but is JIT. Basically, I'd love to have JIT Rust. :D
Yes, absolutely.
Ah. Cool. BTW, when is that gdi+ PR gonna land? I could have used that a week ago :) I'll probably use d2d instead though as I think `winapi` already has support of it. I really just need a transparency aware paint function and I don't feel like doing it in gdi.
That's... A lot to ask for. Given Rust's current compilation times, I doubt it would be feasible to JIT such a thing. With regards to Forge, I'm planning to emit bytecode and maybe even do JIT compilation in the future.
You can't expect from FOSS projects as much as Discord. Discord has hundreds of millions of dollars of funding, the rest is run by enthusiasts. Using FOSS is at first a choice that is driven by love for the principles of FOSS, not competitive advantage. FOSS projects try to be as good as they can with their community, the first thing you can do to support them is using them so they are better motivated for improvement. Waiting until they're good and meanwhile using Discord just wont work. IRC has very good desktop (Konversation, Pidgin) and mobile clients (Revolution IRC on Android). If you think the way you are right now, you can be pretty assured that you'll always be using a majority of proprietary software.
Fedora should be fine. I usually build new releases within a day or two, and then the queue through updates-testing takes about a week. If folks can't wait that long, we're lost. For RHEL, as long as you're cautious with `cargo update`, it may be OK. It's a bit of a chicken and egg, but I hope as more people start using Rust on RHEL, more crates will care to keep at least that level of compatibility -- especially since we're not letting it lag *too* far behind. (RHEL7 now has 1.29, and another update will come soon.)
Darn, I just accepted an offer for this summer, I would have loved to apply though :/
Actually \`-E\` almost did the trick, but the main issue was the lack of unicode character classes. Plus support for often used shorthands for character classes such as \`\\s\` and \`\\S\` and \`\\d\` would have been nice for shorter and readable expressions.
Using FOSS software is only one consideration among many. "Using a majority of proprietary software" is fine for a lot of people. But most importantly, the people choosing to discuss Rust on Discord are already aware of this. Comments like this that don't consider that fact don't help anyone.
Just released Pushrod 0.1.12, which now includes the ability to draw text on the screen. Might not seem like much, but it was a pretty massive restructuring to get that little bit of "magic" to actually work! https://www.github.com/KenSuenobu/rust-pushrod/ Please take a look. I welcome all comments!
Please include location in the post title in the future.
The ripgrep binary is already called `rg`. 
Nice summary. I've compared various API gateways recently, among them apiman, written in Java. The Docker container for it uses 4GB of RAM out of the box, while being idle. Absolutely insane.
I admit I've been neglecting to keep up with updates, but I didn't think I was *that* far behind. How long ago did that happen?
I love Rust, I really do. I really take issue with the content of this paper. Specifically, their comparison between Go and rust seems very parochial and circles around the things that an **engineer** should concern themselves with. The package manager is really a selling feature of Rust, but to choose Rust over Go at the expense of a week's worth of time seems ludicrous, especially since there was no comparison of the efficiency or maintainability of the final programs. It sounds like they chose a language that modeled their own software out of vanity. That might not be the case, but that's what sticks out to me given the lack of a detailed comparison. &amp;#x200B; Also, completely discounting C++ when considering Rust is crazy. Yes, Rust is **better** in ways where it counts, but Rust is still just reaching some maturity milestones, while tools like asan, fuzzing, smart pointers, etc. have vastly improved C++, while still keeping C++ in the lead on number of bodies to fill roles, libraries, and in most cases efficiency. **npm** is betting a lot of its future on new and shiny here, not that I doubt they have the capacity to make it work. &amp;#x200B; That's not to say that I wouldn't have concluded Rust as well, I'm simply trying to point out that this is not strong evidence for anything other than that the npm team thought Rust looked cool and decided to fit it into their stack. They would have better served the community giving honest feedback about what could be improved than this type of gratuitous article.
Aside, Rather than wrapping each line in backticks, try indenting the code by four spaces. The backticks are for inline code; indention is for blocks of code. Reddit's markdown parser doesn't support the fenced code blocks you're probably used to (i.e. triple backtick blocks). BTW, the Reddit Enhancement Suit browser extension adds a button to the post/comment editor to indent code blocks.
Can you get rid of the RefCell? Then you could really simply keep the Box implementation: &amp;#x200B; \`\`\` struct Item { prop: i32, } &amp;#x200B; struct ItemHolder { // update to use Box so re-allocation during HashMap resize won't effect the address of our item. hash\_map: HashMap&lt;i32, Box&lt;Item&gt;&gt;, } &amp;#x200B; impl ItemHolder { fn new() -&gt; Self { ItemHolder { hash\_map: HashMap::new(), } } &amp;#x200B; // we only insert and never ever delete fn insert(&amp;mut self, key: i32, item: Item) { if !self.hash\_map.contains\_key(&amp;key) { self.hash\_map.insert(key, Box::new(item)); } } &amp;#x200B; // the returned reference lives as long as self. fn get\_item\_ref&lt;'a&gt;(&amp;'a self, key: i32) -&gt; Option&lt;&amp;'a Item&gt; { match self.hash\_map.get(&amp;key) { Some(item) =&gt; Some(item), None =&gt; None, } } } \`\`\`
I can alias stuff to a single letter if its useful, I'd prefer long very descriptive names for easy search and recordkeeping. Long names also force me to alias to short names. If grep was called GlobalSeaechAnDRepace I would have aliases it to g by now. Saving me probably hours in life. 
That’s the sort of terrible hack that works in practice but makes me fairly unhappy. I don’t consider `#[doc(include = "../README.md")]` to be an good solution unless it includes the ability to properly exclude lines in some way, e.g. by specifying the line’s contents (or a line number, though that’ll be fragile): #[doc(include = "../README.md", start = "&lt;!-- start crate docs include --&gt;", end = "&lt;!-- end crate docs include --&gt;")] #[doc(include = "../README.md", start = 5, end = -8)]
I agree with /u/NodeMasterPro on that one point, Maven does corrupt binaries. It might be due to vpn connections (that's what we believe), but it happens probably once a month for me. 
If you use `Box` you can also use `Box::leak()` rather than having to do the conversion yourself.
I would have thought that await foo? would have awaited first and then done ?. What does foo? mean if foo is a future that isn't being polled? I'm not actually that familiar with futures in rust yet. I used 0.1.0 when it was first announced, but haven't really looked since then. I wanted to wait until things had stabilised a bit.
That doesn't seem so bad to me. I'd just wrote the parens. I might also split things across lines to help make it readable
I used RefCell here because I don’t want getting one reference to lock the entire strut.
Leak take the ownership of the box though. I still want it to be dropped when the entire holder is dropped.
... I'm not sure there's ever been an install package that used a different binary name. 
I would say that await(foo)? Would make loads of sense if we had parens around if, while, match, etc. I'm fine with the {} version though.
Can a student on an F-1 Visa apply?
It is great to see such initiatives! It would be great if you provide a comparison to the prior art: * https://github.com/jonathandturner/rhai * https://github.com/PistonDevelopers/dyon * https://github.com/gluon-lang/gluon
Totally agree with that! Cargo is one of the nicest build tools I’ve worked with, and that it ships with Rust is one of the best design decisions they made IMO.
I wonder if the whole "positive reinforcement works better than negative reinforcement" thing applies here, if you try arguing against these people they definitely start to get defensive. 
I opened the pdf and just didn't know what was wrong with it so closed it. How did you pinpoint it was the font?
It’s like you don’t want to understand my original point at all :) If my strong opinions on the state of Java/JVM made you believe that I think I know better than teams that are building and maintaining a service that handle billions of package requests per day, then I apologise. I don’t think that at all. I wrote a whole bunch more to try and restate my original case but decided not to post it. If you want to understand where I’m coming from better, feel free to PM me and we can discuss further!
My condolences to you and your team that you must still deal with Maven in 2019 :( 
Right. I think it's safe with the concurrent modifications
If your error message is descriptive enough (and then unique), you can easily find the faulty `expect` by grepping the message.
npm is literally a company that maintains a package manager. I'd imagine they value a quality package manager to their developer experience more than perhaps any other developers alive. That that was a factor in their process seems wholly unsurprising -- it would be in mine as well, and I don't actually work on exactly that product day in and day out.
I wasn't really commenting on the naming scheme, more confirming that creating a separate crate (possibly within the same repository) does in fact seem like the best practice. But now that I'm thinking about it, `-capi` seems clearer than `-ffi`: in the vast majority of languages, "FFI" is calling a native library (Rust's `-sys` crates), not exposing one.
I wonder though, is there any way of writing such a paper that *doesn't* invite arguments? If the paper says "we tried Rust and Go because they are fast and easy to deploy", how many people would then say, "why didn't you try Java/MyFavoriteLanguage, it's also fast and easy to deploy?"? They basically said that they don't consider Java to be easy to deploy, and in the end, that's their call.
It should be a factor, just not a primary one. Package management is a small facet of the cost/benefit software development.
I think that’s the crux of what I was originally trying to say. Making a public appeal for a particular technology is always going to invite commentary from zealous acolytes of other technologies - technologies which are *clearly* The One True Way that must be preached to the unwashed masses. So when that inevitable criticism comes, do you want it to just be a general “hey X is awesome and I think it could have also worked well here” which people can read and dismiss as they please, or do you want it to be a “err, you asserted that X sucks at blah compared to Y, but actually that’s wrong because &lt;insert 3000 word essay here&gt;”? I’m trying to make the case that in the latter situation, by actually taking a position on other competing technologies, you’re effectively weakening your original case because it’s mixed up with assertions that are easily attacked, debunked, or met with millions of words of nuanced debate (see: all the back and forth regarding Java/JVM in this thread!). Ultimately, it depends on what the purpose of this paper actually is/was. I’m assuming it’s intended to be a tool to evangelise the adoption of Rust by more organisations. In which case I stand by everything I’ve said so far. In that case, I think a better format is “we had something that was not scaling well and in need of a rewrite, we chose Rust. (&lt;— Important full stop here). Rust was great because ... &lt;lots of fluff about how excellent zero cost abstractions are, how frictionless Cargo is, how badass LLVM-powered optimisations are, mixed with a tacit acknowledgement that becoming familiar with the borrow checker has a bit of a learning curve but is worth it, etc etc etc&gt;”. It still achieves the same original goal - it’s a well known organisation lending its brand equity to Rust. It just (hopefully) results in less bikeshedding from asshats like me ;)
It doesn't seem all that hacky to me. The biggest thing I see is the known issues with using Markdown inside of HTML tags in some implementations. I forget what Rustdoc is using now and if it has this problem. I would also suggest providing a predefined CSS class in the Rustdoc stylesheet to make it standard, which also avoids the need for inline CSS: .rustdoc-hide { display: none; } It's not a half-bad idea of using comments to delineate the content to import but they should be predefined at least, otherwise it would be confusing for anyone reading the file and seeing random HTML comments. What about `&lt;!-- rustdoc include --&gt;` and `&lt;!-- rustdoc exclude --&gt;` and the processor wouldn't require them to be matched, it would just start and stop copying respectively as it reads the file. Alternatively, what if you could specify a list of [heading IDs](https://www.markdownguide.org/extended-syntax#heading-ids) to import; it would copy the heading and all content following it until it finds a heading of the same size or greater. We'd probably want it to error if it can't find one or more of the passed IDs. It could even be combined with comment-delineation if you wanted to provide the crate author more options and control.
Yeah. My bad. I just went and checked and I'm just a sleep-deprived idiot. (I got carried away last night and blew past bedtime working on a project.)
A private discord bot designed to be scalable with easy. About to be open sourced
Looks neat! But personally I'm never choosing a scripting language without proper u64 support again. I had far too much headache in my previous job.
To u/link23's point re. Curry-Howard, Here's a talk by LambdaMan™ about products (AND) and sums (OR): https://www.youtube.com/watch?v=V10hzjgoklA
Whenever I gain the time and energy to review a PR that is 8,558 lines...
If that's something you're looking for, I can add support for that.
I make an exception for elemental programs due to the coolness factor... ag for the silver searcher and hg for mercurial are clever and cool enough. Both are very useful tools so I say they deserve it.
Good idea, I'll add that when I start writing up documentation.
More generally, they are [coproducts](https://en.wikipedia.org/wiki/Coproduct) (in the category of types).
Just a personal tip, never pitch yourself at a low price, even if you're willing to work for a low rate. Just leave the low price bit out and see what offers come in. If I were looking for a contract worker or employee and saw your message, I would instantly be tempted to lowball your offer. Best of luck with the search! 
This works: #[derive(Debug)] struct Test&lt;'a&gt; { s: &amp;'a str, } fn main() { let a = "Hello world"; let mut test; { let b = String::from("Bye"); { test = Test { s: b.as_str() }; { let c = String::from("gg"); test.s = c.as_str(); test = Test { s: b.as_str() }; } test.s = a; dbg!(test); } } } It may be a limitation of NLL?
Thanks for the advice!
I tried reinstalling via rustup (which is how I installed in the first place) and using the nightly instead of the stable, but it didn't work still, would they have the same effect? I'll probably try this anyway when I get back from work, just curious. Thanks for the response either way. :)
Hm, but it's possible to do this: let c = String::from("gg"); test.s = c.as_str(); test = Test { s: b.as_str() }; Shouldn't `test.s = b.as_str()` be identical to `Test { s: b.as_str() }` here?
Can you add a sentence describing what Pop!\_OS is? Example from [https://this-week-in-rust.org/blog/2019/02/26/this-week-in-rust-275/](https://this-week-in-rust.org/blog/2019/02/26/this-week-in-rust-275/): &gt; Hello and welcome to another issue of *This Week in Rust*! [Rust](http://rust-lang.org/) is a systems language pursuing the trifecta: safety, concurrency, and speed. &amp;#x200B;
Here's one way fn split_at_delim_n(sentence: &amp;str, delim: char, match_index: usize) -&gt; Option&lt;(&amp;str, &amp;str)&gt; { let mut idx = 0; let mut iter = sentence.splitn(2, |c| { if c == delim { idx += 1; idx == match_index } else { false } }); Some((iter.next()?, iter.next()?)) } 
I see someone has already given you some pretty nice functions, but I just wanted to build on your example: fn main() { let nth = 6; let sentence = "No idea what I am doing but some days it just works out".to_string(); let spaces = sentence.matches(' ').count(); let pre: Vec&lt;&amp;str&gt; = sentence.rsplitn(spaces - nth + 2, ' ').collect(); let post: Vec&lt;&amp;str&gt; = sentence.splitn(nth + 1, ' ').collect(); println!("{:?}", pre.last()); println!("{:?}", post.last()); } Counting nth space from left to right.
To avoid options, you can return `(iter.next().unwrap(), iter.next().unwrapOr(""))`.
The worst is the open source Nvidia driver for Linux nouveau which mean new in French, so each Google search is a torture. But to my surprise (or thanks to the personalized search) when I tried to look up some code doing neuro evolution with rust "NEAT rust" gave me good results.
That's good question. It won't compile if Test implements Drop or on rust 2015 (no NLL), so my original explanation may not cover a non Drop type.
 fn split_at_nth(s: &amp;str, p: char, n: usize) -&gt; Option&lt;(&amp;str, &amp;str)&gt; { s.match_indices(p).nth(n).map(|(idx, _)| s.split_at(idx)) } Note that to split at the first occurence of `p`, `n` has to be 0.
Yes, ripgrep's binary name had always been rg, since its initial public release. (Before the release, it had other names, like xrep.) Also, ripgrep supports config files now. It was added a long time ago. See the man page.
Now that you mention it, I vaguely remember that. I think I'm still on the last version before you added that, and I didn't upgrade because it came at the worst possible time for me and then I forgot about it.
Finally `TryFrom`/`TryInto`! Super excited I can use this without nightly soon.
This looks really cool! I really like the syntax and could definitely see myself using this either in conjunction with Rust or as a standalone scripting langauge. It'd be great to see some more documentation and code examples.
I just implemented a loop, which is good enough for now with the limited format syntax I support. This is my 2nd Rust program, and I'm now questioning things like if lazy_static!{} has a thread safe variant, and trying to figure out how to profile my Rust code to see why it's slower than the old C version of the application.
Thank you for the suggestion, I went with a hand coded `for character in string.chars()` loop.
Dyslexic people in particular have issues with reading serif fonts.
Interesting, do you have a source for this?
What's missing from the current crop of templating engines that you think Tower needs another one? Wouldn't it be easier to adapt one of the other ones for your needs? 
Can you eli5 why TryFrom and TryInto matters, and why it's been stuck for so long ? (the RFC seems to be 3 years old)
Breaking backwards compact by changing names is probably one of the *most* disruptive and damaging changes a distro could make imo. So many bash scripts and other software would break it's not worth it. Especially when do unilaterally by one distro. 
Interesting, thanks. I'm always on the lookout to hear more about folks that actually use the various Unicode character classes in order to understand their use cases better. I use them myself, but only very sparingly.
I don't have insight into why it took 3 years. `TryFrom` is the generic form of the existing trait `FromStr` and can signal failure during conversion. Same for `TryInto`. Think invalid IP address or out of bounds numeric value. 
Am I right that the traits and `try!` macro will land in 1.33?
The try macro? Isn't that as old as the hills?
If you stabilise `Try{From,Into}`, you also want implementations of the types in `std`. So you want things like `impl TryFrom&lt;u8&gt; for u16`. But that requires an error type, and that was (I believe) the problem. `u8` to `u16` *cannot fail*, so you want the error type to be `!`. Except using `!` as a type isn't stable yet. So use a placeholder enum! But that means that once `!` *is* stabilised, we've got this `Infallible` type kicking around that is redundant. So change it? But that would be breaking. So make the two isomorphic? Woah, woah, *hold on there*, this is starting to get crazy... \**new person bursts into the room*\* "Hey, should `!` automatically implement all traits, or not?" "Yes!" "No!" "Yes, and so should *all* variant-less enums!" Everyone in the room is shouting, and the curtains spontaneously catching fire. In the corner, the person who proposed `Try{From,Into}` sits, sobbing. It was *supposed* to all be so simple... but this damn `!` thing is just ruining *everything*. ... That's *not* what happened, but it's more entertaining than just saying "many people were unsure exactly what to do about the `!` situation, which turned out to be more complicated than expected".
Maybe I'm a bit conservative, but I don't think 15 min is much every 6 weeks on a new rust version.
Thanks a lot, that was both funny and instructive !
Yes it is, I got confused. It's been a while since I employed TryFrom because I don't use nightly. Please excuse my bad memory.
What is the `!` type?
cc /u/Headwiki /u/Cocalus thank you very much. I am always amazed how people that figure out so quickly. I am a total loser when it comes to efficient for loops or use of closures.
The [never type](https://doc.rust-lang.org/std/primitive.never.html) for computations that don't resolve to a value, named for its stabilization date.
Rust does have return statement.
Thanks. I don't remember the name right now, but I could swear we already had a type we used for functions that never returned. Maybe this is different. It's also interesting that under examples for use they list `FromStr`. The point of `FromStr` being fallible is that, AFAIU, String to String can fail. Well, str to String to be precise, but maybe that minor detail is what they mean in https://doc.rust-lang.org/std/primitive.never.html#infallible-errors when they say &gt; since converting a string into a string will never result in an error althought it's lowercase "string into a string" not "String into a String".
&gt; Thanks. I don't remember the name right now, but I could swear we already had a type we used for functions that never returned. Maybe this is different. The classical name for this is the "void" type. In Rust, you can create such a type by defining an enum with no variants: `enum Void {}`. You might have seen this in a few places scattered about the ecosystem (and `std`, internally at least).
&gt; It's named after its stabilization date :( 
&gt; Thanks. I don't remember the name right now, but I could swear we already had a type we used for functions that never returned. Maybe this is different. There is a way to say that functions don't return: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1d5ab817d67ef5c0614761b81362c086](playground). But as far as I understand it the situation on stable is that it is still compiler magic, not a type. Trying to implement `From&lt;!&gt;` fails to compile: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=172af6b83b15c82067a5f86ecb46399f](playground)
I think I read about it in the O'Reilly book. To be honest, it reminded me of a construct I knew from functional languages and I didn't think twice when I saw it. Does it require nightly to use?
If I change `fn from(_: ()) -&gt; Self {` from your gist to `fn from(_: !) -&gt; Self {`, it compiles with nightly. But, what does it mean in practice to implement `From&lt;!&gt;`? 
The first playground builds with stable, which is surprising.
`enum Void {}`? No. That was available since Rust 1.0. Another name for this is "bottom", and yes, it does crop up more in functionalish languages. There's more about it here: https://en.wikipedia.org/wiki/Bottom_type I'm less clear on the capabilities of `!` specifically in stable Rust, but `!` is indeed the bottom type. My sibling comment points out that `!` can be used in stable Rust, but it's limited in what you can do with it.
Gah, I meant to change that back to an exclamation point. And the reason it builds on nightly is because there it is a type, which means it is a valid value (at the type level) for a type parameter. On stable it isn't.
Lazy static is thread-safe in the sense that it will refuse to allow you to put something not-thread-safe inside of it. You can wrap your static T in a \`Mutex&lt;T&gt;\` or an \`Arc&lt;T&gt;\` or some combination to ensure that it's thread-safe. &amp;#x200B; Are you building with \`cargo run --release\`? Otherwise the standard C profiling tools should work for you.
This is awesome. Support for .raw files coming anytime soon?
20 minutes clean build but I have a threadripper (16 cores) so it's probably not the best indicator. Two years ago it was about an hour and a half on my old laptop
Wrong sub try r/playrust
But it is not necessary, it's a small gripe but I understand it: explicit over implicit.
But hey u do u fam 
By what definition of 'functional' is Rust a functional programming language? It looks like the post equates having a modern type system to FP. That can't be right, because there are plenty of languages without types that are functional. Rust's support for higher order functions is also pretty hairy (3 different closure types), and that's fine, they have different goals. I like Rust a lot, and I like functional programming languages too, but I think it's misleading to call Rust a functional language. 
We love to categorize things. It's probably better to treat ad hoc classifications---like those found casually in blog posts---as more like a subjective binning of something. If you look at the bullet points under the "rust is a functional language" heading, it's clearer to see why the OP is binning Rust as functional. They're all good points, but some of them are certainly only traditionally associated with functional languages rather than being fundamental to them. TL;DR - Maybe read it as "Rust has many features traditionally found in functional languages that I appreciate."
Still a language newbie and I might be out of the loop but what are those range operators? I only know of 0..2 for example and that one has been quite consistent for me. I've never been "off by one" with that one. 
We're transferring to grade! I'm the one actually doing the transfer! Our previous Maven version took 12-15 minutes to compile and run tests and on Gradle without a build cache it only takes 6 minutes now! Gradle is difficult in other ways though. 
For all higher languages, it's implemented in low level somehow, too.
&gt; Shadowing looks to be a freaking nightmare My personal take on this is that I use shadowing when I have data in some type and I want to change the way it is represented and forget about the old representation. Example: I have a string representing a number and I parse it. Shadowing here makes sense to me when it obeys three rules: * The overlying data it aims to hold or represent is the same * You change type * You want to explicilty forget about the previous variable &gt; The lack of a return statement for a function is awkward. Simply omitting a semicolon makes it a return statement? This is just asking for trouble. I certainly disliked this at the start, but now I like it. And the author got it wrong. 1. There is a return statement if you want to exit the function before the last line 2. The only time it is not necessary is by skipping the semicolon and the return keyword AT THE LAST LINE The reason I like it now is because it forces me to write short, easy to understand, functions. It also feels much better when writting clousures. &gt; the range operators are begging for off-by-one errors I don't understand this one... Python does it exactly the same as rust if I'm not mistaken. Counting by one off is the most common thing IMO. &gt; The ideas of ownership and borrowing Those ideas are necessary if you don't want a GC in runtime and want memory safety... So yeah.
There is an right-inclusive operator that looks like `0..=2`. But the right-exclusiveness of range operators is pretty much a resolved standard, so I'm not sure why anyone should have a problem with it.
There's a bunch of them: [https://doc.rust-lang.org/reference/expressions/range-expr.html](https://doc.rust-lang.org/reference/expressions/range-expr.html). &amp;#x200B; \`0..=2\` - the inclusive range is likely the second most used behind \`0..2\`. &amp;#x200B; Anecdotally, since I switched to primarily using Rust, I've become way worse at dealing with off by one errors, likely because I just don't encounter them often enough anymore.
If you need an inclusive range, rather than using `0..n + 1` you can use `0..=n`.
Specifically, `..=` mainly exists for situations like `0..=255u8` where you have to iterate up to the upper bound of a type. (`0..256u8` would trigger integer overflow and become `0..0` and alternatives are bothersome at best.)
It is done.
I think it is referring moreso to the style by which code is often written. Just recently I wrote a [series of methods]( https://github.com/vadixidav/hwt/blob/b096ad63f1ccdc92d2fa7037de4a2084f33eefba/src/lib.rs#L471) that call the next in turn and in specific cases flattened their iterators to produce one final iterator. The sort of things you do in Rust often produce minimal overhead state machines under the hood from a bunch of declarative style code. I think declarative might be a better term to define Rust style than functional, but there is definitely something to be said about functional style in Rust even if it is limiting. Rust lets you write functional code that can cause side effects without data races, which is very unique. In C++ such code would be considered incredibly difficult to ever write, but in Rust it is common because of the type system.
Again short names Please see [https://www.reddit.com/r/rust/comments/av4omn/on\_the\_trend\_of\_short\_program\_names/](https://www.reddit.com/r/rust/comments/av4omn/on_the_trend_of_short_program_names/)
I don't think this question is significantly different in the software world from any other domain. A person is trustworthy when their morality aligns with yours and you have evidence of that. If you want to be seen as more trustworthy, you have to show people what you want, and take steps to ensure it happens, and preferably in a non-game-able manner. But that's just how people earn trust everywhere. Even if you're doing it through the medium of online communication and software development processes, you've got the same responsibilities.
As I see it, the assignment test.s = c.as_str(); is illegal. The lifetime annotation on your struct means that your borrowed value should live at least as long as your struct, which c does not do. To see which problems NLL solves you can look into its RFC https://github.com/rust-lang/rfcs/blob/master/text/2094-nll.md 
Just gonna make one comment to not clutter this thread up but a huge thanks to everyone who answered. I've never actually seen the right-inclusive operator but I don't find it confusing at all. The only thing I found funny in retrospective is that I thought if you did end..start like 2..0 it might reverse the range but no that one's (0..2).rev() which is not that intuitive but I suppose if ranges like that existed that might add a whole new layer of confusion and error-proneness
I've never understood why we needed a specific piece of syntax for this case and couldn't just do `0..256u8 - 1`
Looking at the PR, 1.34.
Yeah, the implicit returns/semicolon thing worried me coming from dynamically typed languages, but it's not a problem at all given rust's strong static type system.
The default (`..`) behaves exactly like Python's `range` (it's right-exclusive aka `a..b` will go from `a` to `b-1`) which is convenient. However since Rust has bounded integers it has issues at the upper boundary: `u8::MIN..u8::MAX` will be missing one u8 value. There's an inclusive range pretty much just for that sort of use case.
Quote of the week right there, hah.
Second this. The contrast between the chosen font color and the background is awful too. I wonder how the target (usually older) audience of this document will handle this typographic issues. I expect they'll immediately close the tab too.
There’s a 3D printing company called “Objet”. For the life of me, I can never type it correctly.
.raw file can be many things, do you mean the photoshop format, or raw camera image? &amp;#x200B; Whichever it is, entirely possible but i'd have to look into it
Try it. 0..255u8 + 1 resolves to 0..256u8, but 256u8 doesn't exist. You'd need to do one of the following to make it work without inclusive ranges. (0..255u8).chain([255]); (0..256u16).map(|x| x as u8);
`0..255u8 + 1` wouldn't include 0. 
It happened to me without VPN, but also probably once per month.
:)
&gt; This is a desktop that I’ve build for Rust compilation as its primary purpose. That's some dedication :)
Remember the last line of a function *can* retain the semicolon and will still return. Just (likely) not what you expect... { some_binding; } returns `()` (Rust's unit type), while { return some_binding; } and { some_binding } both return the value contained in `some_binding` (likely the author's intent). The last form is considered idiomatic. Nevertheless, this is one case where it sounds scarier than it is; the succinctness of that last form is very handy, and I've heard of anyone running into problems with it, once they've gotten used to it a bit.
*The bindings through which you access data are immutable by default. The data itself is always mutable. 
I don't have good web access right now, but search for "GhostCell". It uses invocation of a closure create a new lifetime type which in turn is used as a token to unlock cells. 
Past behavior does not guarantee trustworthiness. Nothing guarantees trustworthiness. If you haven't audited the full code of the current version of a crate, you can't be sure - and I'm sure some would argue that even then you can't be sure. It's a far better idea to try to eliminate undue *confusion* than it is to eliminate untrustworthiness, which would be impossible to fix. Sources of confusion could be transparent crate handover, transparent replacement of code keeping the crate version the same, not pinning a crate to one explicit author, using feedback mechanisms for users per crate version, etc. etc.
I find it strange that those are the three things he's weirded out by. The shadowing of variables is his most valid point; accidentally shadowing variables is a potential source of logic errors. But this is a problem with shadowing in general, not specific to Rust's choice of allowing shadowing within the same scope. Even plain C is perfectly fine with, e.g., int main(void) { int a = 5; { int a = 6; } return 0; } which is enough to cause confusion. I never encountered a situation where Rust's added flexibility for shadowing made things less clear. I'd be interested to hear an example from him; his current reference to JavaScript is an unfair comparison. JavaScript's `let` was added to introduce block scope (a feature Rust has), not to disallow shadowing. Shadowing is still very much allowed in JavaScript: function f() { let x = 5; { let x = 6; console.log(x); } console.log(x); } His complaint about off-by-one-errors for ranges feels very strange to me. Perhaps he's referring to the temporary (experimental) existence of an operator `...` for inclusive ranges, which in hindsight was indeed a bad choice. If that's not the source of his complaint, I don't get his point at all. The fact that `1..5` means "from one to five" is not more confusing than what any other language offers. If anything, the meaning of ranges seems more obvious than the distinction between using `&lt;` or `&lt;=` in the condition of a `for` loop. Finally, I don't get his claim that implicit returns are "just asking for trouble". It's not as if internal expressions suddenly cause an early return if you omit a semicolon. The last expression of a block is returned. Which raises the question: what happens when one means to write `{ expressions; last_expression; }`, but accidentally writes `{ expressions; last_expression }`? Well, one of two cases: either `last_expression` is not of type `()`. If `{ expressions; last_expression; }` was valid, then this block has return-type `()`. Returning a non-`()` expression is hence a compile-time type error, where your IDE points to the very line where you have to add the semicolon, telling you that you're returning the wrong thing. Hardly "asking for trouble". The alternative case, is that `last_expression` _is_ of type `()`. In that case, there is no distinction in behavior between `{ expressions; last_expression; }` and `{ expressions; last_expression }`. Even less "trouble". All in all, a strange "first impression" by OP. I can't really place his complaints, yet his "about" section on his website suggests he's got a professional background I can relate to. Let's hope he has a Reddit profile and drops by. :)
Sed also doesn't have non greedy matches, [although that is not always a problem](https://stackoverflow.com/questions/1103149/non-greedy-reluctant-regex-matching-in-sed)
If you haven't you should check out `rg` aka `ripgrep`
Just use an alias in bash?
TBH, I have not dug into Askama in depth. The things I care about: * Well integrated w/ tower-web (i.e. no boiler plate). The user should not have to specify every single template location, etc... * Zero copy at render. Instead of rendering into a string, I want to render into a rope like structure. * Layouts where the main template can provide snippets for the layout. For example, the layout may have a sidebar slot and the main template can provide the contents for the side bar (similar to rails). * Compiled at build time.
I'll be working on them as and when I finalise the syntax! It may interest you know know that Forge is now Turing-complete. As proof, I created this: https://github.com/zesterer/forge/blob/master/examples/forge/brainfuck.fg.
N.B. in this case, `enum Void {}` is not a sub-type of all types since covariance does not apply, e.g. `Vec&lt;Void&gt;` is not compatible with `Vec&lt;u8&gt;`. Uninhabited types in Rust are better described as [initial objects](https://en.wikipedia.org/wiki/Initial_and_terminal_objects).
Functions with `-&gt; !` return type is a [diverging function](https://doc.rust-lang.org/nightly/book/ch19-04-advanced-types.html?highlight=diver#the-never-type-that-never-returns) and has been stable since at least 1.0. The big change here is making `!` a real type that can be used in other situations.
&gt; Lazy static is thread-safe in the sense that it will refuse to allow you to put something not-thread-safe inside of it. You can wrap your static T in a `Mutex&lt;T&gt;` or an `Arc&lt;T&gt;` or some combination to ensure that it's thread-safe. Ok, I'll probably pass the data through the call stack before I introduce synchronized access. If I need threads, which right now I don't. &gt; Are you building with `cargo run --release`? Otherwise the standard C profiling tools should work for you. I was benchmarking a release build and didn't consider the perf record would be more revealing in debug. It's obvious in hindsight, but it's interesting that the stdlib parts were demangled with full symbols. I mean, don't we have a `cargo --release+profiling` somehow?
Thanks for the link.
If someone is behaving badly, it is important to call them on it. Otherwise they may think that what they're doing is normal and acceptable. They will definitely get defensive, but I've found that appealing to their goals is a good way to get around their guards. (Example, "hey, what are you hoping to achieve by saying that? Obviously they don't think it is funny, and you're not exactly helping them either, so whats the point?").
It is absolutely necessary when you're writing imperatively and you need an early return that isn't `?`!
Sorry, I think there's an even better quote [just below](https://www.reddit.com/r/rust/comments/avbkts/this_week_in_rust_275/ehe50oj/) ;)
You can (and arguably should) just write just plain ol `..` to cover the full range of `u8`, or `3..` to iterate up to the upper bound. If the upper bound is stored in a variable, though, you kind of need `..=` to make the right thing happen sometimes: `for i in x ..= y`. Otherwise you can't iterate up to the maximum value of a type. I suspect Rust programs in the wild have a lot of such errors: they're hard to notice in practice.
The Rust `return` statement may be used to return a value in tail position: this syntax is used to indicate that you are a recovering C programmer and your code should be read carefully. :-) As a long-time C and Haskell programmer, I'm as confused as anyone can be at the end of a block.
* In Askama, template context types have an attribute like `#[template(path = "foo.html")]`, is that the kind of thing you don't want? How do you propose views and templates are linked? * Askama's `Template` has a `render_into(&amp;self, &amp;mut dyn std::fmt::Write)`, would that be good enough? (I've tested with `std::io::Write` but that appeared to actually be slower, and I'd be open to change this API if that would improve performance.) * Askama provides template inheritance today, as well as includes. * Askama templates are compiled at build time and are fully type safe. I'd be happy to work with you to figure out if Askama can fit your goals, and if not, if it can be improved to meet them.
Can you DM me on gitter or something and we can hash it out :+1:
You want to use hdrhistogram (there is a rust port) and measure over longer periods. That should be enough to get you started. I put up a crate, histlog, that offers a nice interface for doing this off thread. 
Hello! I have a server that reads in the stream and convert it to a String. Now if I print the String I have the display of the value I want, but when I try to parse it to have a u64 there is a ParseIntError... The code: **let mut** buffer = \[0; 512\]; stream.read(&amp;**mut** buffer).unwrap(); **let** value\_to\_string: String = String::*from\_utf8\_lossy*(&amp;buffer).to\_string(); println!("{} ", value\_to\_string);//OK **let** value\_to\_u64: **u64** = value\_to\_string.parse().unwrap(); println!("cast {} ", value\_to\_u64);//Failed with ParseIntError
I just started learning Rust, and for my first project I am working on a CLI tool called [time manager](https://github.com/pauljickling/time-manager) that tracks the amount of time spent on specified activities. So it has an interface of `tm start debugging` and `tm stop debugging`, and it will produce a csv file that keeps track of the time you spent on that activity.
You're referring to my comment about ripgrep? There's no need for an alias, ripgrep installs as `rg`, it's a great example of a well used short program name.
`rg` is only a wapper? I didn't realize that, I thought the binary name was just different from the package name. I was offering it as an example of a good use of a short name.
Ah right, yeah, I always forget about this. It's primarily a result of the fact that the various POSIX regex flavors use "leftmost longest" semantics, where as the Perl flavored regexes use "leftmost first." Rust's regex engine falls in the latter camp (because it in turn inherits from RE2, which was designed to port as many of Perl's regex features to finite automata).
Hmm, right, yes. Good point about the subtyping aspect of bottom. I forgot about that.
Can you share your specs? Would love to read a rundown of your thought process. Build times are an issue for me too.
&gt; I will cry in a corner now. Just in case you're not joking (or in case anyone reading doesn't think you're joking), there's nothing wrong with learning something new! That's why we're all here :)
FWIW clippy has various lints that let you allow/disallow shadowing of different kinds
Honestly there's been enough "why Rust" arguments to start off with "why not Rust" instead. Stop the bikeshedding at the door. 
I wrote the [Elsa](http://docs.rs/elsa) crate for this purpose. You're right that with Box it should know the address doesn't change, but HashMap doesn't know this (nor can its API work with this since it returns a reference to the value, not a reference to the thing the value points to). elsa::FrozenMap does. The crate, despite being marked not-ready, should be okay to use. Contributions welcome!
&gt; The ideas of ownership and borrowing play heavily into alleviating a huge number of common concurrency issues. Rust’s solution is not as succinct as C#’s, JavaScripts, or Go’s. I think these languages are all aiming for substantially different levels of thread safety, apart from their syntax or performance differences. My understanding: Go programs can trigger undefined behavior through data races. C# and Java do some implicit synchronization to prevent data races from leading to UB. JS doesn't allow multiple threads to access the same memory. Rust allows sharing data between threads but doesn't allow data races in safe code.
 struct Strct; trait Trt {} impl Trt for Strct {} fn main() { let a: Box&lt;dyn Trt&gt; = Box::new(Strct {}); let b: &amp;(dyn Trt) = &amp;Strct {}; // Is there a simpler way to write this following line? // I don't feel like I fully understand what the following line is doing. let c: &amp;(dyn Trt) = match a { ref r =&gt; &amp;**r}; } [Above code in Rust Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8cdc671de4584deda5166229e13c94dc) Can someone help me understand the \`let c = ...\` line? This is a simplification of something I saw while looking through a crates source. It compiles, but I don't understand all that is going on in the \`let c = ...\` line.
The way the magic extern crate stuff works is that cargo passes flags to rustc telling it what crates are around. This does not include any of the extra libraries shipped with the stdlib. For the most part, these libraries are either reexported by std, or are used by the internal compiler implementation. They're all unstable to directly use. If it still worked with the automagic extern crate stuff, then your crate would suddenly have a bunch of implicit loaded crates that trigger confusing errors. So it doesn't. That said it may be worth lifting this restriction on test crates for libtest, but with luck we'll have a much better stable testing framework when the custom test frameworks RFC gets implemented
The thing you need first and foremost for compilation are cores, and then fast cores. I currently use AMD Ryzen 1700, which I bought on almost release day. I’m eyeing one of those 7nm parts as an upgrade path. 16G of RAM. Storage is complicated, because I use ZFS, but in terms of raw hardware it has 2 SATA SSDs and 3 5600RPM HDDs. The SSDs serve for OS storage *and*, more importantly, for 2nd level filesystem cache. This machine also happens to serve many other purposes such as being a NAS (which is why the data is on an HDD, rather than SSD), home server etc. So decisions made here, especially as far as storage is concerned, were made in part for *those* use-cases instead. What I would do today is wait for the 7nm AMD Ryzens to come out, and also invest into more RAM -- possibly going for as much as 64G and ECC. Perhaps get a Threadripper if I did not have better uses for my money. That would get the stage1 compilation+test time down to under 15 mins.
Yep, turns out it was an issue to do with the edition of Rust I had installed. Apparently when I used rustup it'd gave me 1.22 which is ever so slightly out of date. XD Thanks dude.
&gt; and I'm sure some would argue that even then you can't be sure. Even if you audit the full genome of a crate maintainer to look for signs of untrustworthiness, you have no guarantee that their parents didn't endow them with malicious transcription enzymes that could reproduce both themselves and other untrustworthy proteins.
isn't plain `enum Void {}` actually UB and not recommended anymore, too?
I just **closed** [issue #88](https://github.com/wahn/rs_pbrt/issues/88) and added everything needed to render the **cover image** for the [first edition](https://www.elsevier.com/books/physically-based-rendering/pharr/978-0-12-553180-1) of *Physically Based Rendering* book: https://www.rs-pbrt.org/blog/2019-02-27-cover-image-first-edition/
Yes, but you don't want to have your binary installed as a different name on different platforms. Documentation and finger memory want the same name to work everywhere.
Really? That's news to me. Link?
No, to any program that isn't as useful/generic as a grep. Anyone can alias is while keeping the program name long (and easy to man/google).
This is quote of the year
/r/playrust
Ok. I think I can answer my own question here. The line in question can be rewritten as `let c = &amp;*a;`, much simpler. It helped me to remember that `&amp;Trt` and `&amp;(dyn Trt)` are the same, the `dyn` keyword is there to clarify that `Trt` is a trait rather than a concrete type. It's obvious in this small case though, so I will not use `dyn` in my explanations. The `ref r` was a point of confusion, but I understand it now. In `match 42_u8 { n =&gt; ... }`, `n` has type `u8`. In `match 42_u8 { ref n =&gt; ... }` (notice the added `ref`), `n` has type `&amp;u8`. `Box` implements `Deref` which allows it to have custom deref behavior. Now, regarding the simplified line `let c = &amp;*a;`: - `a` has type `Box&lt;Trt&gt;` - `*a` has type `Trt` - `&amp;(*a)` has type `&amp;Trt` - `&amp;Trt` is the same type as `&amp;(dyn Trt)` I had also forgotten you can have a variable with a trait type. For example, you could have `let x: Trt = ...`, that could compile, but only if `Trt` had a known size. But many (or most?) traits don't have known sizes at compile time. I was thinking traits were more nebulous than they are; it helped me to remember you can have a value whose type is a trait.
&gt; “I wouldn't trust myself to write a C++ HTTP application and expose it to the web,” explains Chris Dickinson, an engineer at npm. I mean, you heard the man. Personally speaking, even with asan and fuzzing, the most I can do is eliminate bugs in test coverage. With borrow check I (almost) have a proof of validity. I am definitely more confident in the latter. Also, why do you think the rewrite in Rust is a waste of time? The candidates, Go and Rust, are decided beforehand. Until rewrite is done in both candidates the evaluation is not complete. Even if they choose Go, they still had to finish rewrite in Rust for an accurate evaluation. Otherwise I agree with you that the article is not so unique in either contents or insight. 
I think there are two questions here. One is, how do you judge whether an individual, who happens to be a crate maintainer is trustworthy. I don't consider this the most important question, and it's general. The second is, what *practices* can be put into place to improve the trustworthiness of a crate? I have some ideas there, as I try to improve community participation in my crates: * Having a number of community members as co-maintainers, with admin privs. Having a single owner is an anti-pattern. * Having an explicit policy regarding code review when merging. The [xi-editor](https://xi-editor.io/contribute.html) project has very carefully written guidelines. * Having a transparent and archived location for discussions. This can be github issues, or in the case of my crates, a [Zulip instance](https://xi.zulipchat.com). I've run into a recent (non-Rust) project where most of the discussion happens in private chats, and this makes establishing both community participation and trust more difficult. * Good CI and other testing improve trust, but this is perhaps more minor. 
I don’t think writing some comparison prototypes is a bad idea. The way they compared them was my issue. Yeah, I’m not saying that Rust doesn’t improve upon what even modern C++ tooling can get you. I just think that it isn’t very helpful to be so dismissive instead of taking some experimental measures in speed/number of issues over some timeframe/development time/number of memory leaks detected at runtime. I just don’t need an article telling me that it’s impossible to write good software in C++. 
What I could find, so it's at the least discouraged and UB-prone these days. https://doc.rust-lang.org/stable/src/core/ffi.rs.html#29-36 https://doc.rust-lang.org/nomicon/exotic-sizes.html#empty-types 
The work may be costly, but not prohibitively costly. All code going on a NASA Mars Rover has to be correct, and they still do it. Embedded programs in a automobile system also requires correctness and stability. When AWS touts their 99.9999% availability, that’s correctness and stability too. I think the joke is rather “is our goal at work writing programs?” Goal at work should be to provide a service, programs are just a means to an end. If the program is not necessary for the service, don’t write a program at all. If the service doesn’t require correctness and stability, like a one-off data analysis script, then there’s no point in investing into correctness for that case. If the service requires correctness however, the program better be correct lest consequences ensue. 
I believe the first Rust compiler was written in OCaml, so really Rust has the lineage of an ML. It’s like a cousin to Haskell. I like to think Rust might be the first ML to be adopted by mainstream. 
\[matrix project lead here\] - yup, there have been points where the IRC bridge (and the main [matrix.org](https://matrix.org) server) have got horribly overloaded, and in fact since Riot 1.0 launched last week we've seen a \~50% growth in traffic on matrix.org which is causing some perf impact. All I can say is that we're working as hard as possible on perf, implementing algorithmic improvements, and stuff should be landing over the coming weeks/months. Meanwhile the IRC bridge itself got a major overhaul in July of last year and is not a bottleneck at all any more (and is very stable). We have folks like [kde.org](https://kde.org) now using Matrix primarily, and the pressure is on to make sure that IRC bridging kicks ass. In terms of the UI, we tried very hard to make the new [riot.im/app](https://riot.im/app) UI at least as good as Discord or Slack - if we failed, please let us know. Finally, there's a really good Discord bridge these days which could be of use should y'all ever wish to go FOSS.
In \`let ref x: u8 = 2;\` what is the type of \`x\`? The type of \`x\` is \`&amp;u8\`. Is this just some unfortunate syntax, or am I parsing that expression wrong? What is the form of a let expression?
Just one bikeshed: I prefer `let` for declaring variables as that’s what both Rust and ES6 do now. But I guess that ship has sailed?
I only started development a few days ago, so that ship definitely hasn't sailed. My justification for using `var` is that variables are mutable by default in Forge, whereas `let` implies some degree of immutability, especially if you're coming from Rust.
``` trait Trt1 {} trait Trt2 {} fn foo(x: &amp;(dyn Trt1 + Trt2)) {} ``` The above code will not compile. The error says: ``` error[E0225]: only auto traits can be used as additional traits in a trait object --&gt; src/lib.rs:4:24 | 4 | fn foo(x: &amp;(dyn Trt1 + Trt2)) {} | ^^^^ non-auto additional trait ``` So this will only work if (and only if) `Trt2` as an "auto trait". Then I try this code and it compiles: ``` trait Trt1 {} fn foo(x: &amp;(dyn Trt1 + 'static)) {} ``` Is `'static` an "auto trait"? I've been racking my brain for two hours trying to understand a compiler error, and wondering how the static *lifetime* has to do with it, but it's all perfectly clear now that I realize `'static` is a trait. I've never heard that `'static` is a trait before.
Thanks! I'd love to be able to use Matrix for IRC so I'm excited for the upcoming work, and I'm a fan of the Riot redesign.
Rust is not declarative, at least not to the Wikipedia definition https://en.m.wikipedia.org/wiki/Declarative_programming 'This is in contrast with imperative programming, which implements algorithms in explicit steps.' The semicolon (expression lists) pretty much makes Rust a declarative language. As a side-note, if you want to experience a truly declarative language, prolog is worth a curios look. No execution-order and all arguments to rules are potentially both input and output at the same time.
Review crates. Use https://github.com/dpc/crev/tree/master/cargo-crev . :) . Become a trustworthy reviewer. :)
Hello All, I got two questions about licensing. Let's say we are developing and selling software within a company (across business units, so different countries and legal entities), and deliver it in binary form. The company also has an OSO, who isn't really interested in these things, unfortunately. We inevitably use Rust libraries for our tools, most of which are MIT. MIT mandates no warranty, no endorsement, and license inclusion. So, here they come: * Do we have to include the names of all the crates that were used (together with secondary dependencies, even), or a single copy of the MIT text is sufficient? * What happens if one of the secondary dependencies isn't MIT but eg. some form of GPL? (OSS scan should take care of it if done properly, on the full source I assume, but does Cargo have an option to warn about this, maybe?) Thank you!
I used to have a horrible hacky python script, which let me embed function calls anywhere in a markdown script, and replace them with the function's output. You would write at the top something which let you include some prefix, then in the body could write (my notation) #{makediv("abc", 4)}, which would run a python function called makediv which had to return a string. I found this made it super easy to extend markdown with little tweaks, define functions to define common extension, etc. Don't know how reasonable it would be to do something similar in rust :) 
To answer my own question, the form of a let expression is \`let pattern: T = ...\`, which means that \`pattern\` matches against a \`T\`. So \`let ref x: u8 = 2;\` means that the pattern \`ref x\` matches against the type \`u8\`. It does not mean that \`x\` is a \`u8\`.
&gt; Rust is not declarative, at least not to the Wikipedia definition https://en.m.wikipedia.org/wiki/Declarative_programming 'This is in contrast with imperative programming, which implements algorithms in explicit steps.' &gt; The semicolon (expression lists) pretty much makes Rust a declarative language. Did you mean to say that Rust is an imperative language (as opposed to what you wrote in that second or third sentence)?
Rust is imperative, but also supports declarative programming. I have written a whole toy language parser and executor with purely iterators and combinators. Some Rust programs may contain more declarative code than imperative code.
[Found it.](https://github.com/ppedrot/kravanenn/blob/master/src/util/ghost_cell.rs) This does some stuff with lifetimes that I don't understand, and appears to be WIP, unfortunately. I have a basic crate almost done. I was going to do some testing to see how it worked in a bigger program before releasing it. I was including an ID-checked cell (concrete, flexible, easy to understand), and a type-checked cell (no overheads, slightly less concrete, requiring a singleton owner instance). However, this lifetime stuff in the ghost cell is like subtly manipulating the aether in comparison. Perhaps I could see about adding the ghost cell as another option, copyright permitting. Compared to using a singleton type, it avoids the singleton check (and general singleton awkwardness affecting reusability) but apart from that should behave the same. I'd have to see how the ergonomics are in comparison. If I run the same compile tests against it then I suppose we could be reasonably confident in it even if it's hard to understand.
That's simply not helpful attitude to have across the board really.
I just want to note that (imo) code generation in build scripts is obsoleted by procedural macros. 
If it doesn't do what you intend, you'll probably just get a compile error anyway.
&gt; The fact that 1..5 means "from one to five" I don't agree with the off-by-one complaint personally, but 1..5 is actually 1 to 4. 1 to 5 would be 1..=5 or 1..6
This is what something like that would look like using my current system. For Rust: ```{.rust .cb.run} // Could simply define this externally and use extern crate fn makediv(text: &amp;str) { println!("&lt;div&gt;{}&lt;/div&gt;", text); } ``` `makediv("abc")`{.rust .cb.run} For Python (which is also supported, along with Julia and R): ```{.python .cb.run} # Could simply define this externally and import def makediv(x): print('&lt;div&gt;{}&lt;/div&gt;'.format(x)) ``` `makediv("abc")`{.python .cb.run} I suppose it would be possible to define a shortcut so that instead of using Pandoc code attributes of the form `{.lang .cb.run}` you could use something shorter like `{.fn}`.
&gt; My personal take on this is that I use shadowing when I have data in some type and I want to change the way it is represented and forget about the old representation. Yeah I think shadowing is really useful, but I really wish they'd made it opt-in. 99% of the time shadowing causes some kind of type error before it causes a logic error, but it _has_ bitten me before and I think making it opt-in would have removed another 99% of that 1%.
Everything you linked is correct, but none of it implies that `enum Void {}` is bad. It's just bad for one specific thing, and that's for modeling C's `void*` when doing ffi.
'static is a lifetime not a Trait. &gt; error[E0225]: only auto traits can be used as *additional traits* in a trait object A lifetime is not a trait so the "auto trait" restriction doesn't apply to it. 
What do you mean by 'making it opt-in'? Like a macro defining you're going to use that feature?
&gt;Finally, I don't get his claim that implicit returns are "just asking for trouble". It's not as if internal expressions suddenly cause an early return if you omit a semicolon. I think describing it as "implicit returns" perpetuates this misconception; I think he's worried about it because he thinks that \*is\* the behavior. It's a very common misunderstanding. (Not that I think that it's your fault here; it's just a common way of describing it)
Something like: ``` let x = 0; let shadow x = 9; ```
It's probably my favorite thing about Scala. 
Ouch!
That's certainly true of some code generation, but people generate all manner of code in `build.rs` files, and I don't think proc macros cover all usecases. For example: on-the-fly generation of Rust code representing structures defined in a Protobuf `.proto` file -- you can't put proc macros in there.
&gt; https://github.com/rust-lang/rust/pull/58431 I can't tell if this is fixing UB? It would be nice if UB patches were called out more explicitly - I get not issuing CVE's, but I look out for these things and they play into my considerations when updating my compiler version.
I think I kind of digressed to test versus proof and led you to kind of miss the point there. *Confidence* I think is the key here, since they are picking the tool they themselves will use, not to study objectively any thesis. The problem with C++ is that all the guards require *awareness*, therefore with limited experience, one cannot be confident that all configurations are correct and in place to produce correct code. Rust gives that confidence by having borrow checker built-in and turned on, no config required. I think this is as important as any technical advantages. For the experimental data you want (which I want too), I’d wager that realistically a ecosystem wide study is more suitable. 
This reads like the author has done some reading about Rust but hasn't written any Rust code. Why? - It has comments about things that can seem weird at first but quickly become no big deal in practice: e.g. shadowing, returns. - It has no comments about practical aspects that are usually commented on in this kind of post: e.g. compiler error messages, Cargo, build times.
I'm not a native speaker, but I believe "from one to five" actually usually means the numbers 1, 2, 3 and 4, whereas "one through five" is what you would say when you specifically want to include 5. I would definitely have preferred ranges to be end-inclusive by default, though.
&gt; For example: on-the-fly generation of Rust code representing structures defined in a Protobuf .proto file—you can't put proc macros in there. Serious question—why not? 
Well… I prefer the syntax of this scripting language: [https://github.com/RustPython/RustPython](https://github.com/RustPython/RustPython) :trollface: &amp;#x200B; We can do better than curly braces and semi columns. 
Same is true for e.g. wayland protocols, OpenGL and Vulkan API definitions etc. There always is and will be more complicated build steps required that can't be expressed in the rust code itself or in Cargo. Rust is supposed to be a system programming language and as such has to work in those environments.
&gt;I'm super-excited that Brendan has finally circled back So… no Gecko/Servo?
Absolutely. Thank you for pointing it out!
Is it really about the alignment of morality? What if you are both deeply selfish?
.proto files aren't Rust source files -- they have a [defined, standard syntax](https://developers.google.com/protocol-buffers/docs/proto) that doesn't have a macro mechanism. The code generated by transforming them into Rust could contain proc macros, I suppose, but the task in question here is the generating of the Rust code in the first place.
&gt;The Rust type system separates interface and implementation with trait and impl, respectively. *However, you can implement any trait on any type.* Strictly speaking this is not correct but I think the author meant it more loosely.
That's not a sufficient complete description of someone's morality to resolve the ambiguities in your question.
&gt;For example: on-the-fly generation of Rust code representing structures defined in a Protobuf .proto file -- you can't put proc macros in there. What do you mean by "on the fly?" And you definitely should be able to do that with proc macros. 
Since Forge is a scripting language, my argument is based on the scripting language community. - Python, Perl, Lua and Ruby don’t have a keyword. - JavaScript has `var`, `let` and `const`, with `var` and `let` being mutable, and `var` considered deprecated. - C#, also popular in game programming, uses `var`. My initial intention is to keep in line with JavaScript, the most popular language, while also not drift too far from Rust. I don’t think `let` would give people a false sense of security because it implies mutability in Rust, because at least personally, I always use `let` and mutate away, relying on Rust to tell me where I should add `mut`. `let` for me means binding, whether the binding is mutable or not is largely language specific. Indeed it happens so that languages using `let` for binding are often functional languages where bindings are immutable by default, such as Haskell, OCaml, Lisp, Clojure, and Racket. But with JavaScript so popular I suspect that most people wouldn’t have immutability in mind looking at `let`. That said I went to investigate some other scripting languages for games: - UnrealScript now uses Blueprint, a visual programming system, but before then they use UnrealScript which uses `var` - Unity uses C# which uses `var` - ActionScript uses `var` So for the gaming community, I think `var` is the popularity winner. P.S.: The old one, Tcl, uses `set`. 
Isn't this kinda how rust's documentation tests work?
True, yes—I was _specifically_ thinking about `protoc`, which have several pure-rust implementations. I didn't think beyond `protoc`.
"On the fly" meaning automatically at compile time, rather than manually in advance. And yes, see my other comment: you maybe could (include the schema file into a Rust source file and then transform it in place), but it would mean the compiler would need to be written in Rust rather than benefiting from whatever existing ecosystem might exist for handling the schema language you're working with. I'm also not sure a TokenStream would be the most natural way to interact with all schema languages -- suppose they're in XML, or a binary format, or whatever else. Could all that be done? Probably. Does it mean other ways of doing it that leverage existing tools are obsolete? I don't think so.
Prolog isn't properly declarative due to the cut rule shenanigans: You do need to manually specify evaluation details not just for performance, but also correctness. There's dialects which fix this, though, e.g. LambdaProlog. There's also Datalog (not turing complete but rather erm a recursive SQL), and languages like maude. Parser generators and the like are also very much declarative. Tying imperativeness to having expression lists would make Lisp, Scheme and ML imperative -- they are, though, usually considered to be functional. Not because you can easily express imperative programs, but because they *also* can express things very well in functional style. Haskell is rightly called "purely functional" because of its side-effect discipline -- yet, it is an excellent language to write imperative algorithms in: Just throw monads at it. All those languages are miles apart from the imperative (or better said structured) classics -- Fortran, Basic, C, Pascal, and the OO languages that put objects onto that structured basis. You *can* program functionally in Java (even before it had lambda syntax), but it's a pain in the arse. XSLT is more suited to functional programming than any of those (and it'd actually be properly suited for functional programming if it was properly suited for any kind of programming, starting with having a syntax that is not XML, or better put metastatic cancer). I think a reasonable heuristic to the question "is the language functional" is "is using maps and folds idiomatic", or maybe better said "are functions first-class, are there proper closures, and are people actually using them as functions and not objects (that disqualifies JS and Lua)". I'd like to say something about encapsulating side-effects and state, but OO languages do that, too (just in a not properly composable manner).
I am a native speaker, and I would avoid using that phrasing for anything technical, to be honest. "One through five" is definitely the clear inclusive range, but "one to five" could be taken to mean either, depending on context or just how you happen to interpret it. Example, I'm pretty sure I've had teachers assign homework in the language "read chapters 1 to 5", and fully expect us to read chapter 5. Or if I say some event is going to be scheduled "from March 1 to March 5", I would interpret that to mean the event is still taking place on the fifth. When I am doing technical documentation (not in code, mostly other areas of IT), I will always use a clear inclusive phrasing, or else explicitly state that something is exclusive ("1 up to but not including 5"). Even saying something like "1 to 5, exclusive" might be taken to mean "2 through 4" (what end are you excluding? both ends? just one? it isn't clear, in my opinion)
Or maybe you want to compile some JavaScript code you want to include in your executable.
No, it's not a wrapper. ssokolow is just talking about doing something like `alias rg="rg -uu"` to set default options in lieu of a config file. (But ripgrep has supported config files for a year now.) Your initial thought is correct and easy to check. See [here](https://github.com/BurntSushi/ripgrep/blob/master/Cargo.toml#L2) and [here](https://github.com/BurntSushi/ripgrep/blob/master/Cargo.toml#L29).
This is especially important when you're matching against a value you own, but which you don't want to move at the moment. Consider this function: fn foo(v: Option&lt;Vec&lt;u8&gt;&gt;) { if let Some(vec) = v { println!("the length is {}", vec.len()); } dbg!(v); // error[E0382]: use of moved value: `v` } The problem here is that the `if let` moves/takes ownership of `v`, and because `v` isn't `Copy`, it's not accessible anymore when we get to the last line. But all we want to do in the `if let` is to print the length of the vec, which should only need to borrow `v`. The `ref` keyword tells the binding to do that: if let Some(ref vec) = v { Now the binding is explicitly taking a reference, and the function compiles. For a long time, the `ref` keyword was the only way to handle these cases. However as of [Rust 1.26](https://blog.rust-lang.org/2018/05/10/Rust-1.26.html#nicer-match-bindings), a much nicer / more magical syntax is available: if let Some(vec) = &amp;v { This used to be a compiler error. The compiler would notice that `Some(...)` isn't a reference and therefore couldn't possibly fit the `&amp;T` pattern, and it would just error out. But today the compiler says, "Ah, I see you're trying to match a type against a reference to itself. Allow me to both 1) implicitly add the `&amp;` on the left and 2) implicitly add `ref` to all of the bindings inside, since that's the only sort of binding that could be legal through a shared reference anyway."
Are you looking for contributors, and is this related to the Veloren project in any way? Are you planning to release the parser in a separate crate ? IMO that would lay the basis for people to start working on some tooling without having to depend on the whole project, and is generally a good idea for modularity.
My point was that if I was a selfish person with a morality that aligned with another selfish person (I was reading "aligned" to mean "the same as"), I would do well not to trust them. It seems to me that morality is somewhat orthogonal to trustworthiness. One person may honor their commitments because they are a hard core Kantian, and another may honor their commitments because they worry about their reputation. As long as they do so, they are trustworthy, and they are trustworthy to everyone, not just people who share their morality. Obviously there are some moralities which engender trustworthiness, but alignment of morality isn't the issue.
I'm surprised more languages don't use the standard math notation where square brackets mean inclusive, and round brackets mean exclusive. So [0, 3) means 0,1,2 but (1, 5] means 2,3,4,5
Code, including sqllite, has bugs. [Safe languages](https://github.com/rust-lang/rust/labels/I-unsound%20%F0%9F%92%A5) have them too. Sqllite is well tested enough that they are rare.
Personally I'd like it to be a warning by default. Say I glance at a function I'm not familiar with, `fn does_a_thing(x: u32, msg: &amp;str)`, I might be interested in code halfway down the body, and completely miss that either `x` or `msg` changed types. The compiler makes it pretty hard to make mistakes, but not impossible. If it was a warning (and ideally would have to be `#[allow(...)]` at the function level, for the whole function), then I would see the `allow` at the top of the function and be wary that types may change. Then if needing that extra line really bothers anyone, the easy answer is to pick better variable names.
Super font and graphics noob here: how does Skribo compare to Pathfinder in scope and abstraction level?
&gt;I'm also not sure a TokenStream would be the most natural way to interact with all schema languages
Sure, it's a great question, as there are an awful lot of moving pieces of the puzzle. They're completely different in scope, but have strong potential to cooperate. In fact, skribo is to a large extent fulfilling the last block in [pcwalton's 2019 blog post](https://pcwalton.github.io/2018/12/07/plans-for-2019.html). Basically, skribo does the text layout given style information, where a layout is at heart (x,y)-positioned glyphs, and Pathfinder renders those glyphs on the GPU.
You wouldn't use `TokenStream` to parse the schema. Proc macros can perform IO, so the macro would just need to parse its invocation for a string literal for the file. I also believe you can invoke an external command from a procedural macro. There's some discussion about this [here](https://internals.rust-lang.org/t/let-proc-macros-pass-information-to-the-compiler/8350/6). Granted the above are pretty... sketchy and balloon compile times. But I'm still of the belief that the majority of use cases are covered by procedural macros, and `build.rs` usage should be limited by new projects. 
There are some similarities between my program and documentation tests, and more broadly rustdoc. Both are using markdown and executing code as part of creating the final document. As far as testing and detailed documentation are concerned, rustdoc with its documentation tests is much more advanced, and I have no interest in competing with that. I'm more interested in less formal documents like tutorials or blog posts. I believe rustdoc executes each markdown code block independently. My program can combine multiple code blocks into a single program, and show stdout or stderr next to the code block that created it. This allows you to show a few lines of code at a time with their output, and then have some explanatory text in markdown before the next code block. So you don't have to duplicate code [like this](https://doc.rust-lang.org/rustdoc/documentation-tests.html#hiding-portions-of-the-example).
That makes sense. Thanks for the explanation and good luck on this fascinating project!
When I am talking about morality, I am talking about how someone evaluates possibilities and assigns preferences to them. If two selfish people would prefer a situation to resolve in the same way, then they can trust each other to that end. If instead they are competing, and would each prefer different outcomes, then they can't trust each other. Alignment of morality mean alignment of preferred outcomes. If someone wants a different outcome from you, then you cannot trust them to help you achieve the outcomes you prefer.
True... or to avoid a footgun (and paired with an explanatory comment) if there's concern that some newcomer on the team might refactor to use `u16` (perhaps to minimize the number of type conversions elsewhere) without understanding that the algorithm should *still* use `0..=255` as its range in that case.
For example in `build.rs` may be code to extract Rust code from `README.md` and check that it is compiled. And obviously you need it only if README.md updated, so you put timestamp file somewhere into `target` directory. Is it also job for procedure macroses? Or for example you need compile sqlite library in `build.rs` and also cache results, to prevent rebuild every `cargo build`, is it job for `build.rs`?
It's still a proof that requires a lot of axioms. Rust is built on unsafe code, which is a requirement to do anything useful. You're still relying on the std and 3rd party libs to get things right, and that's why a lot of the same C++ tools are still needed in Rust.
Would I be enormously off-base to compare this with Jupyter notebooks?
That sounds very similar to what rusttype does (except rusttype doesn't do any complex text layout). What are the reasons for not simply extending upon what rusttype is doing? (Not sure if that would make sense, I don't know enough about the specifics)
A major reason is not to be dependent on rusttype, you might want to use platform 2D rendering or Pathfinder instead. My hope is that it will integrate well with rusttype, but I am open to ideas to make this even smoother without negatively impacting other use cases.
&gt;For example in build.rs may be code to extract Rust code from README.md and check that it is compiled. And obviously you need it only if README.md updated, so you put timestamp file somewhere into target directory. Why would you put code in a readme that you need to compile? &gt; Or for example you need compile sqlite library in build.rs and also cache results, to prevent rebuild every cargo build, is it job for proc macros? Not sure what that has to do with code generation? But since this post is about Meson, then that's a job for Meson. 
Super excited to read more about the project, hope that I will be able to help at some point.
&gt; (0..256u16).map(|x| x as u8); &gt; Neither of which are very clean or intuitive. Or safe in the case of the latter example. A subsequent invalid edit of the code (by the new intern, of course) will happily compile without complaint... https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=af91e9b4aede78dfb168d6ed6c813f8e 
What is Meson?
Multi language build system 
A short guide for drawing a single pixel with sdl2, please?
I don't agree. Being able to use combinators doesn't make rust any more functional than a language like python or JavaScript. All it does is obfuscate terminology until every buzzword can be applied to any language and distinctions are meaningless. Nevermind that many of those iterators are implemented with mutation. higher order functions and referential transparency are the defining features of FP IMO.
I definitely do not need easy issues, I'm an experienced dev of 20+ years, but small issues help lower the cognitive load and are definitely easier to approach. Thanks for the issue links! I'll see what I can tackle 😀
&gt; Why would you put code in a readme that you need to compile? To extend `rustdoc`'s "code examples are checked for validity" guarantees to a file it doesn't handle.
Yes for early returns. But tail returns don't necessarily need a return keyword.
&gt; If part of the Unix philosophy is that shit can be glued together with environment variables and stringly-typed stdout... it's a pretty bad philosophy. All the cases above boil down to having a well-defined, more or less strongly-typed way to pass information between programs instead of shaking proverbial tree of the filesystem and the environment and seeing if something usable falls down. No, that's just people getting implementation confused with theory. The UNIX Philosophy just espouses reusable, composable components with standard APIs and, if people had continued to iterate on the design, we'd probably at least be seeing JSON-based shell pipelines today. Things like ActiveX controls (which were only a bad idea because Internet Explorer allowed websites to request and install specific ones) and KDE KParts (which worked beautifully in Konqueror's heyday as an alternative way to power `&lt;embed&gt;` and `&lt;object&gt;` tags) would also satisfy the composability requirements if there were a comfortable, easy way to plumb them together in one-off scripts.
Sorry my point was not that the return keyword itself should not be necessary, it was that specifying the keyword in the tail return position is not necessary 
And that it annoys some people because it's seen as implicit being favored over explicit 
This would be similar to a Jupyter notebook that was based on plain text files rather than a browser interface. R Markdown, but for arbitrary programming languages, or Org Babel, but for markdown, would be somewhat closer comparisons if you're familiar with either of those.
I actually tend to put return statments in my Rust programs. I find it reads clearer. I definitey appreciate them being able to be left off though. For closures and blocks it is super useful, and for consistency it makes sense to apply it to functions too.
I figured out how to replicate vs code completion breaking. https://github.com/rust-lang/rls/issues/1383 Hopefully someone can fix that and I can just go back to vs code.
Previously [here](https://www.reddit.com/r/rust/comments/atevrm/).
You can call whatever tools you’d like from procedural macros, including shelling out to tools the user may or may not have installed. There are some code generation tasks that are very hard to achieve with just the visibility that a proc macro has into the codebase.
It was obviously put in to minimize a bit of the expected closure noise. TBH, i kind of prefer the 'function pointer approach', ie: C# Predicate and friends, but i don't mind the language making this easier when there is no ambiguity (like in rust, because if you're using it outside of a closure, you already wrote the return type and can only write this last return on the last line anyway.
Even if `some_binding` was a Unit and thus passed by the compiler, is there any harm since Unit is 'obviously' a 'singleton' type and rust has no subclassing? Might as well put in a `()` in place. Maybe auto conversion to a union might be a problem...
When I began writing Rust, having come from a Python background, its expression orientation seemed like a gimmick. I quickly came to understand just how great it was, and now I really, really miss it in JavaScript which is now the main other language I use.
What's the reason for mutable by default? In javascript it's considered good style to use `const` everywhere you can, so for a new language, it would seem like a good opportunity to make `let` (or `var`) immutable by default...
It's on purpose for when you're using x,y arguments that you 'don't know where they come from' to the range, you get the sane [] (empty) range by default when x&gt;=y.
&gt; 0..n + 1 should be a clippy warning specifically because of the whole range case.
\`node\`/\`nodejs\` come to mind
I'm using the `diesel` package to persist some database models. I want to create an idempotent create function. The function will try to persist a model, and if a unique constraint violation is raised by the database, then I want to catch that error, fetch the model by its unique property, and then return that model instead. Essentially, it's find_or_create, but safe from race conditions. I wrote this function twice for two different models, and I want to implement it generically now, but I'm having trouble with the types. Please help! The types: ``` #[derive(Queryable)] pub struct Team { pub id: i32, pub name: String, pub code: String, } #[derive(Insertable)] #[table_name = "teams"] pub struct NewTeam&lt;'a&gt; { pub name: &amp;'a str, pub code: &amp;'a str, } #[derive(Queryable)] pub struct Player { pub id: i32, pub team_id: i32, pub espn_id: i32, pub name: String, pub number: i16, pub position: String, pub age: i16, pub height_feet: i16, pub height_inches: i16, pub weight_pounds: i16, } #[derive(Insertable)] #[table_name = "players"] pub struct NewPlayer&lt;'a&gt; { pub team_id: i32, pub espn_id: i32, pub name: &amp;'a str, pub number: i16, pub position: &amp;'a str, pub age: i16, pub height_feet: i16, pub height_inches: i16, pub weight_pounds: i16, } ``` The two idempotent functions: ``` pub fn create_team(conn: &amp;PgConnection, new: NewTeam) -&gt; Team { let res = diesel::insert_into(teams::table) .values(&amp;new) .get_result(conn); match res { Ok(t) =&gt; t, Err(e) =&gt; { if let DatabaseError(UniqueViolation, _) = e { println!("Already created, fetching..."); teams::table .filter(teams::code.eq(new.code)) .first::&lt;Team&gt;(conn) .expect("Should have one Team") } else { panic!("Unexpected error: {:?}", e) } } } } pub fn create_player(conn: &amp;PgConnection, new: NewPlayer) -&gt; Player { let res = diesel::insert_into(players::table) .values(&amp;new) .get_result(conn); match res { Ok(p) =&gt; p, Err(e) =&gt; { if let DatabaseError(UniqueViolation, _) = e { println!("Already created, fetching..."); players::table .filter(players::espn_id.eq(new.espn_id)) .first::&lt;Player&gt;(conn) .expect("Should have one player") } else { panic!("Unexpected error: {:?}", e) } } } } ```
This web of trust stuff is not foolproof, but it at least increases the cost of someone who isn't trustworthy trying to fake it. I bet a good chatbot type thing, with a good training set, could make lots of semi-convincing reviews. But I doubt those reviews themselves would become highly regarded. You could make lots of bots that regard each other's reviews highly... But then you get a cluster or island with few connections to real humans. But in the style of six degrees to Kevin Bacon, maybe a few would be enough to be convincing connections? It's an interesting problem! Maybe something to learn from the systems that attempt to obfusticate Bitcoin transactions, since in the end those come down to a similar "who in this web is a real person and who is a bot" type question.
It's also ok to cry.
To be 100% clear, and many people don't know this, rustdoc can also operate on .md files, to run the examples as tests. As you say, you're doing something a bit different though :)
From a fresh "cdylib" crate type and a test executable, I was able to attach a Visual Studio 2017 (version 15.9) debugger to a running Rust executable. All I can say so far is I'm very impressed with how initially usable the .pdb support appears. I was able to set breakpoints, step through code, change local variables from the Watch pane, and visualize a Vec&lt;i32&gt;. Combined with &lt;[https://github.com/dgriffen/rls-vs2017](https://github.com/dgriffen/rls-vs2017)\&gt; to provide editing capabilities, I'm excited by the prospect of providing a way to use Rust from Visual Studio for the rest of our C++ team. &amp;#x200B; I'll definitely be doing experiments in linking to and debugging Rust-built dll's from C++ projects made with Visual Studio, which appears that it can provide a very usable experience. &amp;#x200B; The weak area seems to be working with a Rust library directly - being able to start an executable or debug tests from Visual Studio. It looks like an extension was able to do this at &lt;[https://github.com/PistonDevelopers/VisualRust](https://github.com/PistonDevelopers/VisualRust)\&gt;, but the last commit was 2 years ago, and the latest supported VS version is 2015. Perhaps the RLS extension could steal some work from VisualRust to debug a cargo project and aggregate tests in Test Explorer. &amp;#x200B; Language Server support and a decent editor experience seem to be very recent things for Visual Studio, so it would seem there's a decent path ahead to make Rust more attractive to people who are used to the Visual Studio IDE.
Welcome to reddit. Please take the time to check the subject of a subreddit before posting. This subreddit is for the rust programming language, the subreddit for the game is /r/playrust
I think the modern container/VM scale-out world is where Java actually has the most friction. Running on bare metal (or with a few large partitions) is where the JVM shines because the disk and memory usage overhead is amortized, startup time is less important, and JVM performance under load can be amazing. When you're trying to scale on demand having to double your resource usage on your AWS instances to fit the JVM is a pain and you can't react to demand surges very fast when you have to deploy such a large image and wait for the JVM to start up and load your app. The startup time and disk usage are things Oracle is working on solving with AOT compilation and modules via Graal and Java 9+ so things are getting better here. With careful programming, you can reduce or change the pattern of your garbage creation so you can get away with tuning to GC to modes that have less memory overhead but now you're doing extra work and might be more productive using a different language.
Congrats to your talk, you should also post on /r/amethyst and /r/rust_gamedev.
That's just how I've started building it. I may handle immutability later, but it wasn't my first instinct for a scripting language.
I agree that there's friction with the model of VM runtime + container. I do sometimes wish that we focused more on per-VM performance rather than horizontal scaling. Startup time is a real problem, especially when combined with all the enterprise cruft like Spring and Hibernate. However, as far as deployments go, Docker has _greatly_ simplified our CI/CD pipeline. Fat JAR deployments are easy, and eliminate basically all the problems we ever had with dependencies and Tomcat. Also, I will say that Kubernetes has allowed us to achieve much greater density per host than our old Tomcat on VM model, even with the inefficiencies of having more JVMs / fatter JARs. Overall, it's been a net win for us, although not without some problems. It's not perfect, but I'm still very bullish on JVM on modern deployment workflows. Some of our more modern services are much slimmer, and eschew Spring / Hibernate for more minimal performant alternatives. We see sub 20s startup times on those, which isn't too bad even when scaling for load.
I'm very happy to accept PRs, although I warn you that the codebase probably isn't very friendly towards other developers yet (lots of uncommented code and messy use of tuples - also, my error handling is whacky af). It's not related to Veloren, although I've briefly entertained the notation that it might be used as a mod development tool. Extracting the parser would be a good idea. There is a lot that needs doing before the project is ready for release. Disentangling the final executed representation from the first-stage AST, for example. I'll be working on those things over the next week or so.
Thanks for taking the time to post this! Lots of interesting information! I hope `var` is the right decision. I think I'll keep it for now, as you say, but I'm open to having my mind changed.
*screams in inconsistent indentation*
If someone can correctly guess your implementation by looking at your interface, it might not be a detail and might not be so easy to tweak after the fact.
Have you looked at \`frunk\`'s \`Validated\`? &amp;#x200B; [https://beachape.com/blog/2016/10/24/accumulating-results-in-rust-with-validated/](https://beachape.com/blog/2016/10/24/accumulating-results-in-rust-with-validated/)
It had two severe *remote code execution* vulnerabilities in two years in the same subsystem
Nit: Rust has a `return` *expression* form ;)
This was a joy to read; Thank you for a balanced and pragmatic delivery.
I have to agree, the font choice and (lack of) contrast with the background makes it very... "uncomfortable" to read.
This subreddit is about the Rust programming language. You're looking for /r/playrust.
Huh? You are misusing this words.
Would love to see futures 0.3 integration on the list too.
&gt; I think there are two questions here. I think you're absolutely right, and I've not correctly scoped the question. When you talk about judging a persons trustworthiness and what practices could be put into place to increase trust of a crate, that is what I actually meant by my question, as I think those two co-exist in terms of giving a "trust-score". Those are some good thoughts though, I hadn't before thought about the importance of transparent and open communication between project members.
Nice, thank you.
&gt; Become a trustworthy reviewer To that same end though, a person probably has some indications they use to judge whether the reviewer is trustworthy or not. The way I see it, becoming a trusted maintainer has most of the same "obstacles" as becoming a trusted reviewer. That being said, I'm excited about `crev` and really hope it takes off.
Geez lol my bad.
It's quite interesting how shadowing freaks everybody out but never actually makes an issue in practice.
This is true, but how feasible is it really to take into account all the potentially malicious transcription enzymes?
Pathfinder takes an input of shaped glyphs and where they should go, and draws them. A glyph here is a bunch of paths, basically. Harfbuzz/Skribo would take a block of text and a font and decide which glyphs to use (the glyphs exist in the font), and how to position them (including things like kerning, Arabic/Indic joining, Korean syllable-ifying, but not including linebreaking). The pipeline is that you have some system doing inline text layout things like linebreaking, which then converts the text to glyphs using harfbuzz/skribo, and then passes this stuff on to pathfinder which efficiently draws them on screen. Servo is working on Rust crates for inline layout, which are the first piece of this pipeline. (Well, block layout and styling are also part of this pipeline, but that depends on context -- many users of this won't need that, but Servo will)
I always thought of the explicit 'let' repetition as an 'opt-in'. Maybe is not clear enough tho.
Let declares a new variable, it gives you no indication as to whether that variable has already been declared. Basically I want there to be an obvious difference between declaring a new variable and _re_declaring a variable. 
IIRC the idiomatic way to do this is implement is have implementations for `Value`. Implementations for references should be provided in these cases: 1. `Value` is `Copy` - so implementations for references is basically a free ergonomics improvement. 2. You want usage to be ergonomic - so you basically hide `.clone()` calls inside those implementations. 3. Operations on non-references are not cheaper (for example you are not able to reuse heap allocations from arguments, or type could be copy but you just don't want it to be for some other reason). For example, numeric types have implementations for both values and references (because of point 1), and `BigInt` type from `num-bigint` also provides both implementations, but in this case it's because of point 2.
How so? It is made by the community of the C++ language contributors. Anyone can submit papers, attend to meetings, review PRs to the standard online, etc. It's free. &amp;#x200B; Then there is the sub-community within that community that takes part on the final votes, but that's just like the small group of people that can approve Rust's FCPs (not everyone is allowed to vote). &amp;#x200B;
Functional programming is just programming that works, right? It's programming that _functions_... I'll see myself out. 
Avoid attributes on expressions. Adding the representation attribute to a specific instance of a type sounds like a bad idea to me, since the representation is a direct fact of the type. I'd expect an allocator function to be more suitable. For `mem::transmute_aligned`, I wonder if it'd break backwards compatibility to just add that functionality to `transmute`.
I actually use `..=` far more often than `..`. IMO `..` only really makes sense for indices, and I almost never use indices explicitly. 
In one sense, it's not UB because it's the standard library that is only supposed to be used with one compiler and it works a certain way on that compiler. But it does seem to be fixing a violation of Rust's rules, so in that sense, it's fixing a UB. But yeah, I understand the want for UB/UB-like patches to be more prominent.
True. It *is* also useful for making code's intent as intuitively obvious as possible.
Because `mem::transmute` operates on values, not pointers, it should be fine to transmute from low-alignment type to a high-alignment one. (If it doesn't work in practice, then `transmute` should either be fixed, since it can work relatively easily, or at least have a warning, since every invocation of `transmute` has full layout information.)
It's fascinating how complex text rendering is! It's just text, but there's way too many details.
My question would be: why
I'd recommend to share your `log4rs.yaml` configuration (or code which configures `log4rs`). Also what's unclear to me is the _main page_ &amp; _rest of the pages_. What do you mean with this?
Thanks! Also, just figured out how to cross post -- have to use old.reddit.com
Seems like a case for generics, or even const generics for me. Example: #[repr(transparent)] pub struct AlignedArray&lt;T, N: usize, A: usize&gt; { array: [T; N], marker: SomeTypeThatForcesAlignment&lt;A&gt;, }
I think [https://github.com/astonbitecode/j4rs](https://github.com/astonbitecode/j4rs) has a bit of an overlap with my [https://github.com/kud1ing/rucaja](https://github.com/kud1ing/rucaja). Did you know about this? Or where there reasons to not use it? Nowadays i don't use the JVM that much but duplicate efforts make me a bit sad. 
&gt; It's just bad for [...] modeling C's void* when doing ffi. How would you write an `extern` declaration for a C function that takes `void*` as parameter?
I saw it after I had started implementing j4rs. However, the approach taken is different, I think. j4rs uses reflection in the Java world in an attempt to make the things simpler for people that know java, but not JNI... As an aside, I found out about one more attempt for calling Java from Rust (https://github.com/rawrasaur/rust-jvm) but unfortunately it seems inactive...
Seems not to work with workspace projects, am I right?
For real lol. I've come to realize how much I've been taking for granite.
Sure but the compiler could assume that: let x = "hello"; x = 3 the second assigment is an implicit shadowing. I'm not disagreeing with the opt-in shadow tho, your solution looks quite clean. But I personally would prefer if the shadow keyword didn't require the let keyword. More like: let x = "hello"; shadow x = 3;
Oh! I know this one! My use case is [`include_bytes!`](https://doc.rust-lang.org/std/macro.include_bytes.html) where I import a blob of bytes in a `static` item. This data is binary and already formatted in a way that all I need to do is reinterpret it to my `#[repr(C)]` structures to use the data in my code. Except... These repr C structs have alignment requirements (typically 4, 8 or 16) and for the longest time I was unaware I was invoking UB because the compiler happily included the file blob in a static array with an odd address. I found this when I went back and added checks for alignment and my code started failing them. I solved with a one off structs with alignment but it would be nice if I could have done this instead: #[align(16)] static BLOB: [u8; XXX] = *include_bytes!("blob.bin"); Note that in this example there are some tricky edge cases, eg what should happen if I wrote this instead? Does the alignment work on the reference itself or the data behind the reference? #[align(16)] const BLOB: &amp;[u8] = include_bytes!("blob.bin"); This is essentially the same issue as /u/isHavvy points out with attributes on expressions. Perhaps this can be solved by having the std lib provide a fixed set of wrapper types with appropriate alignment (eg. 2, 4, 8, 16, 32, 64, 512 and 4096) so I don't have to write these one off structs myself.
Looking at the LLVM IR generated, it is easy to write unsafe code using `mem::transmute` that causes undefined behavior, without it being obvious that anything is amiss --- IMO, either Rustc should recognize that and make stack allocations with better alignment, or something like I'm proposing. I'm trying to lessen the burden of always keeping pointer alignments in mind.
This is IMO a less-than-ideal workaround, as damn near every time a buffer is allocated on the stack, this would be appropriate to use.
I believe that https://github.com/jni-rs/jni-rs added Rust -&gt; Java ffi functionality a while back as well, though I've never used it myself.
I have a hashmap of type `HashMap&lt;KeyEnum, Box&lt;Any&gt;&gt;` and I am trying to get rid of the Box. I understand that `HashMap&lt;KeyEnum, Any&gt;` does not work, because Any has not a known size. My question is: Can I have something like a `HashMap&lt;KeyEnum, Any + Sized&gt;` where I use different types with different sizes as values? My gut feeling is that this is not possible, wanted to ask anyway.
I agree that `transmute` is very dangerous, but I don't think alignment of values (not pointers) is one of them. Do you have a specific example of of `transmute` on that sort of argument that has UB because of alignment? For instance, consider the following code that has a pointer, but only transmutes values: pub fn foo(x: &amp;[u8; 4]) -&gt; u32 { let y = *x; unsafe {std::mem::transmute(y)} } In release mode, this compiles to: define i32 @_ZN10playground3foo17h33535b24ac3f6eecE([4 x i8]* noalias nocapture readonly dereferenceable(4) %x) unnamed_addr #0 { start: %y.sroa.0.0..sroa_cast = bitcast [4 x i8]* %x to i32* %y.sroa.0.0.copyload = load i32, i32* %y.sroa.0.0..sroa_cast, align 1 ret i32 %y.sroa.0.0.copyload } That is, it does optimize to a pointer cast and load, but, because this all happens inside the compiler, the alignment on the load is correct. (The debug mode pre-optimized IR uses a `memcpy` (which has alignment 1), similar to one correct way to do it in C.)
&gt; Things like ActiveX controls (which were only a bad idea because Internet Explorer allowed websites to request and install specific ones) and KDE KParts (which worked beautifully in Konqueror's heyday as an alternative to NPAPI plugins for powering `&lt;embed&gt;` and `&lt;object&gt;` tags) would also satisfy the composability requirements if there were a comfortable, easy way to automate and plumb them together in one-off scripts. Never used KParts, but ActiveX is actually pretty easy to use in VBScript. So it is composable - as long as you stay within the MS ecosystem...
The way the rust compiler does it for the built-in arithmetic types (`i32`, `u32`, `f32`, etc) is to define the arithmetic traits for *both* values and their references. That way minimizes the number of unnecessary `.clone()`s and `&amp;`s you have to write. Also, if you ever have generic code, it doesn't matter if the generic code requires `T: Add&lt;T&gt;` or `T: Add&lt;&amp;T&gt;` (or some other variation), your type will work with either. There is a minor downside to doing it this way: occasionally you'll need to add an extra type annotation sometimes. For example, code like let total = my_vec_of_values.iter().sum(); needs to specify that `total` is a `Value` because rust doesn't know if it should be adding `Value`s or `&amp;Value`s. That minor downside doesn't outweight the upsides of implementing the arithmetic traits for both values and references though. And don't forget the `-Assign` variants (`AddAssign`, `MulAssign`, etc).
What if I want to generate rust structs and impls from, for example, protobuf definitions?
[https://github.com/rust-unofficial/awesome-rust#ffi](https://github.com/rust-unofficial/awesome-rust#ffi) knows of at least one more.
Thanks for sharing, I hadn't heard of frunk before and this does look very similar. One thing I'd say is I prefer the API of `multi_try`, as I'm not much of a fan of using operator overloading (as they do with the plus sign) unless you have a use case which very well aligns with the general meaning of the operator.
Fair enough, i've added your project to [https://github.com/rust-unofficial/awesome-rust/blob/master/README.md#ffi](https://github.com/rust-unofficial/awesome-rust/blob/master/README.md#ffi)
It can depend on how expensive creating a new `Value` is. If `Value` is small and `Copy`-like, like primitive types, you can implement `a + b`, `&amp;a + b`, `a + &amp;b` and `&amp;a + &amp;b` to all return a new value. If `Value` is not `Copy` and is expensive to allocate, it can be different. For example in my [Rug](https://crates.io/crates/rug) crate for bignums, where bignums have to allocate, you can do this: * `a + b` consumes both `a` and `b` and returns a value reusing one of the two allocations. * `&amp;a + b` or `a + &amp;b` reuses the allocation of the number passed by value. * `&amp;a + &amp;b` does not allocate a new value; what it does is return an item referring to the two operands, kinda like lazy evaluation. The returned item can then be used either (a) to create a new bignum, which involves an allocation, or (b) to assign to another existing bignum, reusing its allocation. The [num-bigint](https://crates.io/crates/num-bigint) crate behaves the same for `a + b`, `&amp;a + b` and `a + &amp;b`, but behaves differently for `&amp;a + &amp;b`; in this case it allocates a new bignum and returns it. It is effectively like case (a) above but simpler to use, but does not allow for the (b) use case where you want to assign the value of a sum into some other existing bignum.
Thanks for that! Few of the projects seem inactive though... Does this say something about the use case itself? Is it maybe that Rust does not need Java, or that Rust people have different background?
**UPDATE:** Slowness is considerably reduced since now ff parallelizes search using threads.
In my case i've tried to realize a MVP: in doubt i wanted to be able to call code from some nice JARs (like TinkerPop), in case there is nothing comparable in Rust. Since the JNI border is a bit slow i think the use case is limited. So maybe it's technically interesting but not that useful?
It sure does, you just have to cd into a crate so that `cargo-deps` can parse its Cargo.toml. This crate will be the root of the graph, but you can pass the `--orphans` option to make sure all workspace members get included. The first graph in the Readme is an example of this. But your post got me thinking. It would be cool if one could run cargo-deps on the Cargo.toml of the entire workspace. Then it could search for the Cargo.toml of each workspace member and graph *each* of them as a root. It could also automatically create a subgraph for all of the workspace members. It adds a bit of complexity but should be possible. Will take a crack at it :)
Indeed, maybe it is not that useful. However, I also view it like a potential big door that may benefit rust users. For example, GUI in desktop and in Android apps, JMX etc...
This is an awesome layout abstraction, what would be interesting is to also have a simple rust backend that is enough for english and most common latin based languages with basic advance+kerning handling. Because * HarfBuzz is a huge dependency * cross platform issues if we rely on direct write/core text, and what about wasm..
 However, Rust is full of ceremony that sometimes seems really annoying. You have to use cargo.toml and extern crate for example. what's the alternative to this (especially considering extern crate is no longer required)?
use ```rs App::new().resource("/test", move |r| { ``` instead of ```rs App::new().resource("/test", |r| { ``` Unfortunately I have no idea why this works.
Thanks! I will try this tomorrow, when I'm working at the project again. I also don't really know why, but I think it has somehow to do with the requirements on the with_config arguments ...
Now I'd like to read a comparison of adding features by someone who didn't write the code 
I'm a native speaker from the northeastern US. If the numbers are integers or other ordinal symbols, "from X to Y" is `x..=y`. - [from 1 to 10](https://youtu.be/J2D1XF40-ok) I would expect that usage to be universal in the US, even if it wasn't before *Sesame Street* - that show is literally more influential than school. - "from first to last" and "from a to z" are idioms for "all" and "everything" - "rate from 1 to 5" allows ratings of 1 and 5 but not 0 or 6. - "up to 10" excludes 11, [thus this sketch](https://youtu.be/uMSV4OteqBE With continuous quantities the endpoints are ambiguous. Most people would say "1 to 2 pm" and "2 to 3" have no gap and do not overlap, but would disagree about how to classify the instant of 2:00.
To be quite honest wrt to wayland protocols, I've really been thinking about making [wayland-scanner](https://crates.io/crates/wayland-scanner) into a proc-macro, and I think it'd be perfectly possible, and probably more ergonomic in the long run. I've other priorities than digging into proc macros though.
you get a much better error message if you move the definition of `limit` into the closure passed to `server::new`. I don't know why this error isn't what's displayed as you defined it. I think in English the reason it doesn't work as you defined it is that the closure passed to `resource` has a static lifetime bound and `limit` doesn't outlive static so you have to move it into the closure. error[E0373]: closure may outlive the current function, but it borrows `limit`, which is owned by the current function --&gt; src/main.rs:22:38 | 22 | App::new().resource("/test", |r| { | ^^^ may outlive borrowed value `limit` 23 | r.method(Method::POST).with_config(test, |(cfg,)| { 24 | cfg.limit(limit); | ----- `limit` is borrowed here | note: function requires argument type to outlive `'static` --&gt; src/main.rs:22:9 | 22 | / App::new().resource("/test", |r| { 23 | | r.method(Method::POST).with_config(test, |(cfg,)| { 24 | | cfg.limit(limit); 25 | | }) 26 | | }) | |__________^ help: to force the closure to take ownership of `limit` (and any other referenced variables), use the `move` keyword | 22 | App::new().resource("/test", move |r| { | ^^^^^^^^
If your text editing font has a lambda glyph for \\, you're a real functional programmer. 
The problem is that the hash-map code can't index its array of values because it doesn't know how large the values are. So it's not possible with `Any`. There's a similar pattern where you know which types will be used as values. Make an enum of the types and store that in the map. There's a variation of that pattern requiring unsafe: use a union. This may perform *slightly* better when you know the type of the data by inspecting the key, but in this case I'd be surprised. 
I think a lint could be written, something like `#[deny(align_on_refs)]`.
All I can think is how inconvenient that hat must be indoors.
Minimal complete example of UB due to transmute alignment: https://andrewkelley.me/post/unsafe-zig-safer-than-unsafe-rust.html
With rustc 1.32.0 (9fda7c223 2019-01-16) I get his as part of the error message: note: closure implements \`Fn\`, so references to captured variables can't escape the closure In other-words no variable can be declared outside of the closure, or it needs to be moved into it (either by moving the code or using the move keyword). The simplest fix is to move the variable into the closure: &gt;App::new().resource("/test", |r| { let limit: usize = env::args().nth(1).unwrap().parse().unwrap(); r.method(Method::POST).with\_config(test, |(cfg,)| { cfg.limit(limit); }) }), It works neet with multiple apps as well: &gt; server::new(move || { vec!\[ App::new().resource("/test", |r| { let limit: usize = env::args().nth(1).unwrap().parse().unwrap(); r.method(Method::POST).with\_config(test, |(cfg,)| { cfg.limit(limit); }) }), App::new().resource("/test2", |r| { let limit: usize = env::args().nth(1).unwrap().parse().unwrap(); r.method(Method::POST).with\_config(test, |(cfg,)| { cfg.limit(limit); }) }) \] }) If you use the move keyword, then limit would be moved, so the second app won't be able to move it as well.
Have you taken a look at what this subreddit is about? (No.) r/meteor, r/javascript, or r/playrust 
Wrong subreddit, /r/playrust. Please check what subreddits are about before posting. 
I think you're referring to using uninhabited enums as C void (basically you're gonna only work with raw pointers, and convert them to references. You can use extern type now.
I'm not sure whether to applaud, point to /r/rustjerk, or mention that releases usually happen around 1pm PDT (?)
You can make a dumb struct and put a custom derive on there. For example, ```rust #[derive(ProtoBuf)] #[protobuf(“test.proto”)] struct Test; ``` You can also encapsulate that in a macro to hide the ugliness from the user. I don’t think there’s any codegen workflow that cannot be codified with proc macros. Whether that’s a good idea though... that’s another matter :P
It's possible to infer the type for the compiler. let map: HashMap&lt;A, B&gt; = HashMap::new(); So, I don't understand the point with type inference.
&gt; /r/javascript Lmao
forge.rust-lang.org: &gt; Rust 1.33 stable will be released on Fri Mar 01 2019.
Oh, I was looking at the GitHub repo which said 2019-02-28. I guess I'll have to wait another day then, thanks :)
If that's the sort of game you play, then you deserve to have things break on you. Don't depend on the properties of programs that you've 'guessed' about their implementation. Depend on the interface.
I actually only have about a dozen different value types I want to use, so this is an excellent suggestion. Thank you!
Hardly! Analternative implies it fulfills at least some of the same use cases, not that it fulfills them in the exact same way or that it fills even all of them. I would consider Python and Rust alternatives for some projects because they can both be used for my needs! Behavior need not be the same -- otherwise, a "clone" would be a more accurate term.
Looking forward to it. I'm implementing essentially the same thing for resvg's [text layout](https://github.com/RazrFalcon/resvg/blob/new-text-layout/usvg/src/convert/text/mod.rs) now, based on `font-kit` and `harfbuzz`. But `font-kit` lacks a lot of features for now, like name aliases (`serif`, `monospace`, etc.) and script based quires (like, give me a font that supports Japan script). It would be great if I could move some part to the `skribo` side. Even through that SVG text layout is much more complex.
I believe the intent is to run the release starting around 18:15 UTC which means it'll be complete some time after that.
How would you forsee it? I've used proc macros already in wlroots-rs and thus are familiar with them, so I could take a crack at that if I find time in my schedule. Eventually I'll need to integrate with your scanner if I want any wlroots based compositors written in Rust to easily define their own protocols without using unsafe. 
Arguing that NASA may strive for correctness therefore it's not prohibitive proves my point more than anything. Most people won't get anywhere close to their rigour. Additionally, while I'm not sure what their internal processes are, I wonder if even NASA 'proves' a program to be correct. AWS is a poor example too IMO, it's more about fault tolerance than correctness. Proving programs is extremely difficult, and almost none of us do it, therefore correctness is just not a goal for most engineers. I think the original comment stands: it's laughable to think we write correct programs, by any meaningful definition of correctness.
Duck typing for files in the src directory I guess. Just parse what looks like rust.
Nothing layout is guaranteed for `#[repr(Rust)]`. Period. End of story. That said, there's some push towards guaranteeing structs with the same definition to have the same representation. That would make this guaranteed, as `PhantomData` is guaranteed to behave in a struct as if it doesn't exist IIRC.
I mean, isn't the C alternative just a makefile? how is that less ceremony?
I actually liked the blog post. What it points at are real issues with how things are done with cargo, and i've seen these issues affecting new Rust programmers a lot. &amp;#x200B; The way cargo, compiles and runs build scripts and how they communicate is super adhoc and implicit, which means that one has to learn a lot of things before one becomes able to understand what's going on. &amp;#x200B; I've seen a lot of people surprised because they thought they knew enough, but they were missing some bit here and there, and they couldn't realize that something was missing because it was being handled implicitly. &amp;#x200B; Implicitness isn't bad per se, but cross-platform [build.rs](https://build.rs) have always been an unresolved issue. 
I'm not sure if you wrote this to agree with me, but the reason I quoted it is because I think the statement 'you will write a correct program' is pretty absurd
One way is to clone your Arc&lt;AtomicBool&gt; before making the thread so the cloned instance is moved rather than the original one. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=6a3cacf8cb3d680af88dd8a231087ca1
I'm using actix for a small side project, and i'm really just leaning on my past patterns with Node, as well as figuring it out as I go. https://github.com/agmcleod/sc-predictions-server/tree/master/src db folder containing models &amp; connection logic. The routes contain the req/response logic, as well as implement the handler for the db actor for that route.
I'm not 100% clear on that, but with my recent changes, the scanner-generated code no longer depends on external parameters like build flags or so, and there is just one single file generated per protocol per side (client/server). So I could imagine it to be a macro with an API similar to `include!(...)`, except it'd take as argument the path to the protocol file, and generate the translated code. So It'd probably be a rather small wrapper around the functions currently in wayland-scanner.
So my birthday is special after all!
It would be hard to implement this interface in a streaming manner.
I like the practice of having a separate library for database and server, and then a simple main file in the server project's src/ that starts the application. This forces a separation of concerns between database and routing/auth/data transforms/validation. You also get the benefit of marginally reducing Rust's compile times when you are only working on one of the libraries. There are some drawbacks though. For example, if you want to give the name of the row that you couldn't find in the db in a 404 error, you have to handle that in the server lib, instead of in the function that handles the database query (Assuming you don't create yet another library for errors, and make both the database lib and server lib dependent on it.). I'm applying this separation practice for a group project for a web-dev class: [https://github.com/hgzimmerman/SWEN344-web-project/tree/master/backend](https://github.com/hgzimmerman/SWEN344-web-project/tree/master/backend)
Thanks for the quick response - this works. So although the Arc is cloned, all of the clones refer to the same underlying AtomicBool?
Yes: https://doc.rust-lang.org/std/sync/struct.Arc.html
Yes that's correct. An ARC is an Atomically Reference Counted pointer in effect. So when you clone an ARC, you are not cloning the value that is pointed to, just the pointer. If you were to duplicate the actual AtomicBool, you'd have two separate independent values. That point is moot though, because AtomicBool doesn't implement Clone (or Copy), so it cannot be duplicated that way.
Typo: should be "taking for granted"
Making a function that consumes the struct and produces a new one with the same content but a different generic parameter would be a solution. That function would be optimized away by any compiler worth it’s salt. e.g #[inline(always)] fn foo_x_to_y(x: Foo&lt;Y&gt;) -&gt; Foo&lt;Y&gt; { Foo { name: x.name, count: x.count, _type: PhantomData } }
Use triple backticks on a separate line before and after code: \`\`\` Code here \`\`\` 
&gt;It sure does, you just have to cd into one of the workspace member crates so that &gt; &gt;cargo-deps &gt; &gt; can parse its Cargo.toml. This crate will be treated as the root of the graph, but you can pass the &gt; &gt;\--orphans &gt; &gt; option to make sure all workspace members get included. The first graph in the Readme is an example of this. &amp;#x200B; Oh my god what have I done? The resulting PNG is 10 MB !
Sorry for the naive question, but can I use rust to do the exercises in CLRS? 
I typically use a second channel to send a shutdown signal. Is using an AtomicBool more idiomatic?
It would be better and so much easier if rust closures had to be explicit about captures.
This does not show up as code for me on mobile, but: Any number Of lines All indented 4 spaces Does 
I don't know the OP's specific problem they're trying to solve (although it would be nice to include it /u/lowprobability), but one place where this might crop up is if you have a `Vec&lt;A&gt;` and want to convert it, cheaply, to a `Vec&lt;B&gt;`. If `A` and `B` have the same in-memory representation, then this should be doable. (And you don't even need a transmute. You can use a raw pointer cast.)
Actually disappointed that it isn't a rust program
What are the benefits of writing Rust instead of Java in this case?
I don't know. I hadn't thought of using a second channel but I would be interested to know which is faster.
I see where you're coming from, but to be honest I'm not that interested in that use case, simply because it cuts out over a billion people from having their languages supported. Also, kerning is not as simple as you might thing because modern fonts are built with a more efficient and powerful [gpos](https://docs.microsoft.com/en-us/typography/opentype/spec/gpos) table as opposed to the older and simpler [kern](https://docs.microsoft.com/en-us/typography/opentype/spec/kern) table. Now if you had phrased that as: can we actually render those languages with a shaping engine much lighter weight than Harfbuzz, that's an interesting problem and a very hard one. If there are enough users (for example, making small devices with displays) who want this problem solved, they should get in touch. I don't think cross platform issues are too bad, both DirectWrite and CoreText are pretty solid and should work well in well over 99% of cases. I think it's better to have subtle rendering differences than have text not shaped at all.
Nice! You know what this means? There is enough time to Rewrite It In Rust!
I'm quite open to working together. Since resvg is MPL and skribo is MIT+Apache, I would need your permission (or you sending PR's) to adapt code. As I said in the roadmap (but not so much in this blog post), part of the work is to figure out what's lacking in font-kit and file actionable issues to get that done. I feel this is more of a coordination task than a coding task, so the most immediate need is clearly expressing what's needed. I've been talking with Behdad and plan to do script-based itemization (selecting fonts based on coverage). Minikin ingested the cmap from fonts and used a clever bitmap data structure, but required extra metadata to resolve scripts beyond Unicode coverage (for example ja vs zh-Hans vs zh-Hant). Does SVG have need of this type of query beyond the script tag in [BCP-47](https://tools.ietf.org/html/bcp47) lang tags? (In the latter case, the needs seem like they're pretty similar to HTML layout) For casual readers of this thread, I've touched on two or three topics that will definitely be the subject of future blog posts. Stay tuned :)
It doesn't show up as code because I escaped the backticks to be clear how to do it. ``` It should still work on mobile ```
This seems like a decent approach, but I can't use it, because in my case I actually need to transmute `Arc&lt;Foo&lt;X&gt;&gt;` to `Arc&lt;Foo&lt;Y&gt;&gt;` and there might be other owners of the `Arc`.
It also does not display on the old site -- the only way to ensure it shows up is by using the four spaces.
Don't use triple backticks please. They don't work on old Reddit. Use indented blocks (4 spaces) instead.
`tar` allows you to pull individual files out of an archive, but this duplicates them in your filesystem -- once in the archive, and once outside. If your tar archive is more than twice the size of your hard drive, you won't be able to fully extract it. `taro` is designed to truncate the archive as files are extracted, such that the above use case is now possible. &amp;#x200B; This tool would have helped me out quite a bit a while ago, so I'm sharing it in hopes that it can help someone else in the future.
r/boneappletea
Atomics are faster. Channels use much more complex machinery.
&gt; it would be nice to include it Sure! I have a wrapper around vulkan buffers, where I want to encode the usage flags into the type of the buffer: `Buffer&lt;Vertex&gt;`, `Buffer&lt;Uniform&gt;`, ... so it looks something like: ``` struct Buffer&lt;U&gt; { raw: RawVulkanBuffer, _usage: PhantomData&lt;U&gt;, } ``` Problem is I also need to stash the buffers somewhere until they are done begin used for rendering, so they are not disposed of prematurely. But I don't want to have separate stashes for each usage type and also I don't really care about the usage at that point. So was thinking about type-erasing the usages into something like: `Buffer&lt;Nothing&gt;`, so I can use only one collection for buffers of any usage. The buffers are also in `Arc`s for reasons not important to get to. So I was thinking to `mem::transmute` say `Arc&lt;Buffer&lt;Vertex&gt;&gt;` into `Arc&lt;Buffer&lt;Nothing&gt;&gt;` would do the trick, but I wasn't sure it's safe. I can also use `Arc::into_raw`, cast the pointer then `Arc::from_raw` I guess, but is that actually safer?
Rusttype's design isn't compatible with what we want to do in browsers, for a couple of reasons: 1. We want to do the actual glyph rasterization on GPU, not on CPU. The way to do that on GPU is different enough that all of the rasterization code in rusttype would have to be replaced. 2. Rusttype reads TTF/OTF files directly instead of using the system libraries or FreeType. This is nice for all the usual reasons pure Rust code is nice, but it's incompatible with having fonts look native to the OS. The reason is that some OS's want to do hinting, and hinting is basically impossible to implement in a compatible way to the OS. For instance, Windows has all sorts of hacks—the published TrueType spec doesn't match reality—and FreeType frequently relies on its autohinter, which is a giant pile of hacks with no spec at all. Unfortunately, if we were to fix these two issues, then there wouldn't be really any code left in rusttype to start with!
In the general case it's unsafe, because you could use it to construct a `Foo&lt;!&gt;`. With a specific value for Y, I can't think of how'd it cause unsafety. Even with specialization, calling the "wrong method" wouldn't do anything undefined.
Small suggestion, set random color for every new object.
/u/ralfj might know the answer to this. If I had to guess, I'd say that if you have an `Arc&lt;T&gt;` and an `Arc&lt;U&gt;` where `T` and `U`'s in-memory representation is guaranteed to be the same, then it seems like you ought to be able to transmute there (or do a pointer cast). But I'm not actually 100% solid on that point. The other part of this is actually determining whether `T` and `U` have the same in-memory representation. As others have said, if they are different type definitions, then you don't have this guarantee in general, but there are some circumstances where it's possible. For example, if the type is marked with `#[repr(C)]` or `#[repr(transparent)]`, then I think you can make this assumption.
&gt; Even so, 15 minute build every time you update Rust This is obviously not all, +25 minutes for tests, and this is one platform. Project should be tested on three, so if one person will check that this all works it would be 40 minues * 3. Plus static analyzers, like `cargo clippy`, because of known issues in clippy you need clean build to get all warnings, so this is +15 minutes t all time. Plus this development machine, on CI it make 2x slower, because of CI cluster shared among developers, so it is near ~2 hours per platform. 
If you don't mind me asking: What's the point of this \`Foo\` type? Why is it generic if its state has nothing to do with \`T\`? Usually, the point of \`PhantomData\` is to control variance w.r.t. a type parameter (something that's necessary here and there when building low level abstractions using unsafe code).
It is just build, no `cargo test`, no functional tests, not gui tests, no static analyzer and so on. On CI it takes ~ 1-2 hours depend on CI cluster loading. And this is only if all ok, usual it is not all ok, so developer need reproduce problem on his machine and then rerun CI build and do this several times.
High marks on a nice application form that respects people with names that differ from their legal names, and of course HOLO is super cool.
If you can swing it, I'd encourage you to write up your experience in detail. I suspect it will be very useful to some folks. I'm not sure it's a good enough reason to hold back core crates in the core ecosystem, but it's certainly a good enough reason to focus efforts on compilation speed. Of course, folks are already doing that. :-)
&gt; Why would you put code in a readme that you need to compile? Many crates put example code into `README.md` and it is pleasant if somebody copy/paste it and it works out of the box. So tests should check if code compiles, there are several crates for this job like https://crates.io/crates/skeptic `cargo test` can check that code in comments compiles, why not check this in README? &gt; Not sure what that has to do with code generation? There is point that there is no job for `build.rs` because of procedural macros, this is one of reason why procedural macros do not supersede `build.rs`
OP can specify `#[repr(C)]` for the type
Not a technical issue, but I've gotta tell you, the first thing your gitlab link does is insist I sign up for an account before I can see your code and that is exactly where I stopped. I suggest using some other method of sharing.
The relevant part would be checking the value of the atomic vs. reading from the channel since that's what gets run multiple times. I'd be curious what the speed difference is on those operations.
When do you stash that buffers? I do the same in [rendy](https://github.com/omni-viral/rendy). My buffer type define as (essentially) struct Buffer { Arc&lt;Inner&gt;, } struct Inner { raw: RawBuffer, } and `Inner` on `drop` sends raw buffer to the queue where it waits until it is guaranteed to not be used by GPU.
Most makefiles I have worked with are essentially just duck typing: They compile everything that ends in .c to an object file.
It's not just for variance, although yeah, that's definitely a good use case. Sometimes you just need it if you're doing type level stuff, or if you want to carry a type parameter around without needing to actually use it in your definition. This is typically occurs, in my experience, when you carry around values that are effectively in correspondence with your type parameter, but use a different representation for efficiency purposes. For example, in my `regex-automata` crate, a sparse DFA's state [carries a type parameter `S`](https://github.com/BurntSushi/regex-automata/blob/ffefcf61c1c6505ece70e6d629597c8cf22d7466/src/sparse.rs#L1080-L1100) which corresponds to the chosen state identifier representation. But the sparse DFA internally represents state identifiers as just plain bytes. The type parameter carries with it the necessary [routines for decoding state IDs](https://github.com/BurntSushi/regex-automata/blob/ffefcf61c1c6505ece70e6d629597c8cf22d7466/src/sparse.rs#L1131-L1134) from the raw bytes.
404, even while signed in to my gitlab acct
Weird, I thought Gitlab was less obnoxious about stuff like that! It's also [here on crates.io](https://crates.io/crates/taro) if that works better for anyone.
Yes, compilation speed helps, but doesn't resolve the issue. If you have big enough software project, then event if compiles less than 1 minute you still need test all it's functionality. And this can take hours or even days. And normally more functionality =&gt; more Rust code, and more functionality means more tests (automatic or manual). And change of compiler means that your executable or shared library that was successfully tested need full retest.
Can I put `#[repr(C)]` on a struct that contains stuff that isn't `#[repr(C)]`?
That's actually wrong, it's going to be released today (2019-02-28). The JavaScript powering that page is a bit broken.
You certainly can - after all, most language are turing complete and thus equivalent in (ultimate) expressiveness. I don't know much about the book, but I assume you will be building basic data structures and algorithms to deal with them (efficiently)? Rust may not be the best choice here - a lot of the low level details may be awkward to implement efficiently in safe rust and if you're willing to write unsafe code, you throw away most of the handlebars Rust is giving you. If you want to learn Rust anyway, might as well use it to do the exercises, though.
Previous serial shell script builds took 6 hours to render a set of CAD models. Now it takes 1 hour. The key line in the Rust version is: *let \_result: Vec&lt;String&gt; = paths.par\_iter().map(|path| make(path, image)).collect();* Thank you, rayon!!!
I stick them into my wrapper for command buffer. The command buffer, when submitted lives inside my wrapper for command queue until the corresponding fence is signaled, at which point it's dropped. Btw, I've been looking at rendy for inspiration. It's a pretty nice crate! I might even swap my thing for it at some point, but so far I'm having too much fun reinventing the wheel.
I believe it does that if you have some sort of privacy setting on the repo or your account, e.g. only registered users can see it or something like that.
Yeah I would like to learn the 2 subjects and thought that combining them would be efficient if possible, thank you for your answer!
In other words, upgrade to new version of compiler is like updating every line of your Rust code in one commit. And if test coverage is not 100% you need do manual tests and wait automatic tests to run. This is job that need to be done, and if changelog of compiler tells that team stabilize several functions in stdlib and fix several not related to you bugs, any reason to do upgrade to this minor release?
I'll be very disappointed if they don't release 7 patches to make it 1.33.7
You probably have the repo set to "private" or "internal" visibility. You need to have it set to "public" for others to see it.
Wow, I tried with crossbeam-channel and it's a fairly substantial difference. #[bench] fn read_bool(b: &amp;mut Bencher) { let is_stopped = Arc::new(AtomicBool::new(false)); b.iter(|| { (0..1000).fold(false, |old, _| { old || { is_stopped.load(Ordering::Relaxed) } }) }); } #[bench] fn read_channel(b: &amp;mut Bencher) { let (_tx, rx) = unbounded::&lt;()&gt;(); b.iter(|| { (0..1000).fold(false, |old, _| { old || match rx.try_recv() { Ok(_) =&gt; true, Err(TryRecvError::Empty) =&gt; false, Err(TryRecvError::Disconnected) =&gt; true, } }) }); } Although, the channel version does have the advantage that it can handle shutdowns on disconnects (i.e., nothing is ever going to send a shutdown signal). Although maybe you could accomplish that by checking the count?
You might want to look at [Learning Rust with entirely too many linked lists](https://cglab.ca/~abeinges/blah/too-many-lists/book/) in parallel. I haven't read it, but it has been recommended quite frequently and teaches you how to deal with C-ish low level stuff in Rust.
That is not an issue with gitlab, but rather with how antonok configured the repository.
This post is about an IR implemented in a compiler written in Rust.
seems interesting, will check it out! I am doing "The book" right now and I am super impressed with Rust, find it so much more fun than python!
You can, and it'll work as long as the type is identical between them, since the fields will be in the same location.
You're absolutely right, whoops. Fixed!
So much text, such [poor aim](/r/playrust).
Thanks! I don't know if this will work with my real use case, but for this one I think it's the most clean one.
Sure, but the cadence of Rust releases doesn't need to dictate your cadence of upgrading Rust. If you only upgrade once every six months, then that just means you also shouldn't upgrade your crates until that point. Either way, my core point here is not to argue with you, but to get people to write up detailed experience reports on how they use the Rust compiler and how compiler upgrades impact them. Most people aren't in your shoes, so it can be very hard to understand and empathize with your perspective. If we don't have that, then the ecosystem is never going to get tuned for use cases such as yours.
Im sorry, poor aim? Who are you? (If you mean that its badly structured, I know, sorry, I dont usually do this kind of stuff XD)
I will make a PR for rustup, which includes this feature 😎
you're in the wrong subreddit
Nah, just trying to nudge you towards the [correct subreddit](/u/playrust).
Or the next best thing, rewrite it in ion shell.
But it needs to run in Redox!
I was half-expecting some people complaining about me calling XML metastatic cancer, referring to the no-zealotry rule. I could have defended myself by saying that XML is not a programming language and thus isn't covered by the rule, but truth be told my preferred defense is that it's a true statement of fact: It steadily creeps into places where it decidedly doesn't belong. Like build system syntax.
Oh man, rust and openscad really combines my past and my present.... this is awesome!
It's getting worse... Are they just pretending to be lost or are they really trying to take our command post? 
Time to rewrite it in Rust
This is awesome. What languages do you plan to add? I would be also interested in something like... C. Is there any way to get guidance to do add more languages?
The crate's up now: [https://crates.io/crates/qcell](https://crates.io/crates/qcell) I'm leaving GhostCell for another day, but I've linked to it and added it to the comparisons.
Please feel free to file issues for font-kit. It'll definitely need all those features in the future. &amp;#x200B; By the way, thanks so much for your work on resvg! Having an SVG loader available has been really helpful in making Pathfinder 3 much easier to use than Pathfinder 2 was.
The list is just a bunch of ideas. Students may propose other things. I opted for projects that could be developed in parallel with a small integration surface. If you have other ideas, you can propose them via PR to the tokio website: https://github.com/tokio-rs/website/blob/master/content/gsoc.md
What makes you say that it is "unsafe" in Ada?
Please; it is Ada, not ADA.
are you referring to the output of combinators like many0 or many1? Or using SmallVec as input to nom?
&gt; If your tar archive is more than twice the size of your hard drive, you won't be able to fully extract it. If your tar archive is more than twice the size of your hard drive, how are you holding it in your hard drive?
Haha. I'm guessing they meant takes up more than half the space on the drive.
It's the former, the data that is parsed is a string wrapped in a located span (from nom_locate) for the sake of syntax highlighting. 
At the moment, I'm trying to fix those issues ([#25](https://github.com/pcwalton/font-kit/issues/25), [#28](https://github.com/pcwalton/font-kit/issues/28)) by myself. But I'm not familiar with fontconfig, coretext and directdraw, so its taking a lot of time. QFontDatabase supports everything I need, so I'm trying to understand how it works. Like [QFontconfigDatabase::fallbacksForFamily](https://github.com/qt/qtbase/blob/5.12/src/platformsupport/fontdatabases/fontconfig/qfontconfigdatabase.cpp#L715). It's not that big, but it has a lot of edge-cases. And for each OS they are different. Also, I have no idea how to test it. There are also problems with a low level font metrics. `font-kit` provides only underline position and thickness. But not overline, strikethrough and baseline tables. Also, looks like *pcwalton* is very busy, so question-answer lag is pretty big. As for `skribo`, I'm not sure how low level it would be, but I need an access for each glyph + outline. So as low as possible. And Qt doesn't allow this (that's why I'm dropping it). Not sure about `pango`. And for high level stuff, do you plan to support vertical text or is it out of scope? Qt doesn't support it and pango does, kinda. As for a concrete example, it would be great if I could pass a string to the `skribo` and it will return a list of outlined glyphs/clusters. So it will find a font using specified properties (family list, style, weight, stretch), find fallback for missing glyphs (my main struggle right now) and do the shaping. PS: there were only two month since I started learning how the low level text layouting works, so I have little use. Unless you have some specific tasks which I can handle.
Could someone ELI5 phantom data to me?? I've read the entry for it in the Rust docs and the nomicon but it's just not going in like I'd hope.
Uh... I'm not sure a procedural macro version of bindgen will fly.
To my knowledge, this is not possible with a single crate (but I could be wrong). However, this is what [cargo workspaces](https://doc.rust-lang.org/book/ch14-03-cargo-workspaces.html) are for. With your current project layout, it seems like making it a workspace would be trivial.
Correct... I can't pull bytes out of the air unfortunately!
I've already created few issues and one pull request. Thanks! SVG text layout is the biggest change right know, especially because no one really supports it. Even Chrome and Firefox have a lot of problems ([example](https://github.com/w3c/svgwg/issues/628)).
&gt; It is important to appreciate that the call of Free is safe because the user’s view of the type Stack is limited and so the user cannot have made a copy of the structure. This means that it is not possible for there to be any other reference to the deallocated storage. &gt; An abstract data type should always be constructed so that any deallocation is safe. The key is to avoid shallow copying. One approach is to make the type limited so that any copy has to be through a procedure defined as part of the abstraction; another is to make it controlled so that Adjust can ensure that a deep copy is always made as in the type Linked_Set of Section 14.9. &gt; Another problem is that an object such as a stack or queue might go out of scope when it is not logically empty in which case the allocated storage will be lost. This can be overcome by making the type controlled so that Finalize can deallocate any residual storage. &gt; if we specify the size of the pool by setting the attribute Storage_Size as explained in Section 25.1 then indeed the pool will be released at the end of the lifetime of the access type. https://www.adacore.com/papers/safe-dynamic-memory-management-in-ada-and-spark https://people.cs.kuleuven.be/~dirk.craeynest/ada-belgium/events/14/140201-fosdem/03-ada-spark.pdf https://arxiv.org/abs/1710.07047 https://www.adacore.com/about-spark https://docs.adacore.com/spark2014-docs/html/ug/en/usage_scenarios.html https://www.adacore.com/gems/gem-107-preventing-deallocation-for-reference-counted-types
All generics need to be used in a Rust type declaration. E.g. the type `struct Foo&lt;T&gt;(*const ());` is disallowed. Adding a field of type `PhantomData&lt;T&gt;` makes the containing type act "as if" it contained `T`. This is useful for "ghost" type parameters (ones used at the type system level only), when you're doing something clever with pointers, or for changing inferred variance.
build.rs allows cargo's configuration to stay simple and I like this a lot. Of course if there's any reason I can't build a rust library it's because someone misbehaved in a build.rs script. pkg-config, cmake, bindgen, and cc crates all add external dependencies to the build process... and in the case of pkg-config that dependency only *barely* exists on Windows. I don't think Meson is the answer... I kind of like that cargo outsources all of the complicated things to a generic program. I just wish that build.rs crate dependencies and library crate dependencies were distinct sets so that crates.io could analyze the full requirements of the build.rs and notify me that "this crate uses pkg-config so don't even try using it".
Not just for cross-posting but for sanity and load times too.
I want to like and use Firefox, but I'm just having such a hard time switching away from Vivaldi.
Dude chill XD Its my first post EVER! I dont know what subreddits are the correct ones.
Out of curiosity: Whats wrong with constructing a `Foo&lt;!&gt;`? (Given that you don't need to construct a `!` for it …) 
What happens if you interrupt the extraction? Is your tar file now containing non extracted data only?
And even said sub-community is open to nigh anyone volunteering. It's just that volunteering takes time and money, notably due to the travels required, so it's mostly individuals sponsored by their companies.
I guess I'll never really "get it" since I can only imagine what those cases are, but thanks for the explanation!
Yeah, this boils down to whether the two types have the same layout in memory. This has been [recently discussed](https://github.com/rust-rfcs/unsafe-code-guidelines) and some results have been [written up](https://github.com/rust-rfcs/unsafe-code-guidelines/tree/master/reference/src/layout), but many questions remain unanswered. In your case, it seems you can make use of `repr(transparent)` since you have only one non-ZST field ``` #[repr(transparent)] struct Buffer&lt;U&gt; { raw: RawVulkanBuffer, _usage: PhantomData&lt;U&gt;, } ``` and for this we do guarantee that the layout (and function ABI) is equal to `raw`, and hence you can transmute things around. Notice that this also relies on the fact that these types are actually yours. In general, when we are talking about types from some other library you are using, types having the same layout may still not be transmuted -- you have no idea what extra invariants the libraries are upholding on these types. So the general answer to the question "Is it safe to transmute Foo&lt;X&gt; to Foo&lt;Y&gt; if the generic type is used only in PhantomData" is certainly "No", for this reason. (I am aware that this is likely not what you meant, but I feel it is important to remember this point.)
I think given the way nom works you will have to reimplement / copy those macros and change Vec to SmallVec. The cleanest way would probably be to write a PR with an implementation that can be parameterized over the type to use (expecting a Vec-like interface) and then instantiate the "default" many0! with said implementation using a standard Vec. But /u/geaal might know a cleaner way.
[removed]
 find . -name \*.scad -print0 | xargs -0 -n1 -P8 -I fn openscad --render -o fn.png fn
Wow, that's cool. You must have a bunch of hardcore models. I thought taking a few minutes to render was slow!
probably f00k all unless your application's doing some heavy-ish processing
7 point releases in 6 weeks sounds like a challenge!
I'm planning to add Bash, Ruby, and Octave soon, and expect to add several more after that. C would probably be straightforward. Adding languages is based on a relatively simple config + template system. If you look at the [existing definitions](https://github.com/gpoore/codebraid/tree/master/codebraid/languages), you can probably get a good sense of how it works. There is some documentation for adding languages in [index.bespon](https://github.com/gpoore/codebraid/blob/master/codebraid/languages/index.bespon), but I haven't posted complete, proper documentation yet since the system is still evolving a little. Rust is the first compiled language, so I'm hoping the features are relatively complete now. Feel free to open an issue for adding C or other languages.
I was worried that might be the case. Simply switching them wouldn't work; I wanted to use a smallvec in one particular place, not generally use them instead of vecs. Sure, that leaves room for extending what exists, but that's a pretty major undertaking for a problem I can solve in other ways. If it's really impossible, I can probably work around it by introducing some new enum variants. 
I've always found `let` cryptic, though, whereas `var` is just the start of `variable`.
Sry, I thought I was making a gamer joke but i guess I had a type error... =/ 
Hm. It looks like I'm mistaken. I thought that `impl Foo&lt;!&gt;` methods being able to be called broke type safety, but Googling around I can't find anything about that.
I've always thought of `build.rs` as a pragmatic response to "we need something that works now". I definitely hope that over time we'll get something *better*: - I want structure, not ad-hoc inputs/outputs. - I want cross-platform, not pkg-config. - I also want *post* build actions. - And as mentioned in the article, customizability for integration with existing build systems or projects would also be helpful!
I was wondering about the windows support in particular. There will always be bugs ;-)
Awesome, thanks for explaining this! :D cc /u/lowprobability See the parent.
To be honest, I don't think it's a good idea. You'd be much better off just packing your data up into a struct and using \`sort\_by\_key\`
AFAIK: `SomeTypeThatForcesAlignment&lt;A&gt;` can simply be `[A; 0]`.
Honestly, even just *that* context would help me make decisions. Like "UB, but not practically" is totally reasonable and lets me know that I should update soon, but not high priority/ stop the world and update.
Doesn't you proposed `#[align(x)]` syntax *also* require per-buffer annotation?
Think minkowski() of Lego Technic and you can see the worst cases..
I think the really issue is when operating over pointers/references: fn undefined(source: &amp;[u8; 1024]) { let dest: &amp;Foo = unsafe { mem::transmute(source) }; // ... use Foo } There is no guarantee that `source` is suitably aligned for `&amp;Foo`: - Making it a compile-time error in `transmute` seems backward-incompatible: just because `source` MAY not be aligned doesn't mean that it IS not. - Introducing a `debug_assert!` is possible, I think, using specialization; it would need to handle all thin pointers/references combinations, but that's what macros are for. In general, Zig solves this by requiring annotating over/under-aligned pointers to be able to prove the safety at compile-time; without extending Rust syntax I suppose annotations could do the job... while another would be C++'s `std::aligned_buffer&lt;SIZE, ALIGNMENT&gt;::type` + deprecation of transmutes from `*const u8` and co.
Honest question, why isn't pkg-config cross platform? It works on Linux/windows and mac and I'm sure it is being used in cross compilation projects.
There may be issues if you use it to convert from `Foo&lt;&amp;'a mut T&gt;` to `Foo&lt;&amp;'a T&gt;` as this may have weird consequences on the borrow-checker...
Missing the contributors list?
For now. I got a new computer and didn't have it set up yet. Currently fighting to get Diesel to understand where my postgres installation is. It'll be there, just give me some time. Sorry about the delay.
In general, latency measurements will imply percentiles/CDFs to see both distributions and tails... ... and unfortunately chasing down tails can be pretty frustrating as most tooling is about aggregate data (such as perf) whereas tail latencies are about singular events; such as `free` performing some consolidation work, the OS doing a hard page-fault on a memory access, etc...
Yes, but it doesn't give the obscuring overhead of a recurring pattern using a wrapper type. I'm hoping to avoid the introduction of patterns, for ergonomic reasons. Compare: let mut x = Aligned8([1u8 ; 1024]); let y : &amp;mut [u64; 128] = mem::transmute(&amp;mut x.0); with #[align(8)] let mut x = [1u8 ; 1024]; let y : &amp;mut [u64; 128] = mem::transmute(&amp;mut x); or even let mut x = [1u8; 1024] #![align(8)]; let y : &amp;mut [u64; 128] = mem::transmute(&amp;mut x); Bascially, I'm grasping at the fact that LLVM IR lets you annotate each `alloca` instructiong with an `align N` attribute. I want that in Rust. It should be there.
No worries, just curious.
I don't understand why both `NonZeroXXX::new_unchecked` and `NonZeroXXX::get` are made `const`, but `NonZeroXXX::new` is not. Shouldn't it be possible to write `const One: NonZeroU64 = NonZeroU64::new(1).expect("1");`?
Spoilsport. I should have listened more to my father. Instead I used (cough) PowerShell.
And another step for [const generics](https://github.com/rust-lang/rust/pull/58503)!
I'd also like if they were called out more explicitly because it gives me insight into what to do, and NOT to do, in unsafe code.
The implementation of \`new\` uses an \`if\`, and \`if\` is not allowed in \`const fn\` yet. It will be!
Check out the crates enum-map and fixed-map, one of these may fit your use case :)
`new` uses feature that is not stable for const - `if`
Aha, that explains it! Thanks! I'll be looking forward to that!
Nobody contributed. Rust started writing itself to avoid human bugs.
C++ uses `std::aligned_storage&lt;SIZE, ALIGNMENT&gt;::type` for this, and it works really well. Specifically, your solution doesn't compose well: - You need to annotate stack variables, okay, but... - You also need to annotate data members, - You also need to annotate function parameters, - You also need to annotate **pointees**, - ... And a type solves ALL THIS! So, while you may not appreciate the syntax, in terms of semantics and composability, it's just an order of magnitude better.
It's possibly an honest mistake on my part; I seem to remember reading about portability issues with pkg-config :)
If splitting is an option, check out the cargo workspace option to still be able to build and test both at the same time.
I don't think it's a bad idea. It all depends on what you want to do with your data.
Asimov needs a 4th law to `#![forbid(unsafe_code)]`.
Congratulations to everyone involved. Also to all of us! 🧡🎉🦀
I can't consider myself a programmer, who knows Windows ecosystem, so, yeah, here be dragons :)
Something not mentioned in the changelog: `shell32.dll` [is no longer used for command-line parsing on Windows](https://github.com/rust-lang/rust/pull/56568), which means the ~15 DLLs that `shell32.dll` depends on are also not loaded. This includes `gdi32.dll`, which [can cause hangs when creating/destroying lots of processes](https://randomascii.wordpress.com/2018/12/03/a-not-called-function-can-cause-a-5x-slowdown/). Also, a small cli utility I made now uses half as much private memory (~1200k -&gt; ~550k), and I'm pretty sure it's due to this--the binary is nearly the same, but it [loads half as many DLLs](https://i.redd.it/ggbipgsbadj21.png).
Or use `fd` or gnu parallel
What do you want to do with your data, then?
You can parallelize scripts in PowerShell
Really great read, thanks for sharing!
I followed with automobile control software expecting you’d say NASA is too distant from normal life. But there is a commercial product with over a decade of history working on formal verification and code generation in the embedded control software industry: http://www.esterel-technologies.com/products/scade-suite/ Software in the cars, trains and planes everyday people’s lives depend on. I know that proving a program mathematically correct amounts to some pointlessly excessive work. I disagree that’s the only meaningful definition of correctness. It’s not as broad as “working as intended”, as that would include the one-off scripts which don’t handle any errors. I believe “correct” in an engineering sense should be that the specification is designed to fulfill intended function, guard against foreseeable risks, be ethical, and be logically consistent by itself (formal), and the program is proven to implement the specification within industry standard assumptions. 
If the atomic is Arc'd, you could get the strong count from it to determine if your thread is the sole owner of that atomic. You'd just be checking two atomic values instead of one.
Can we use logical and and or yet in const fn? That seems like the most glaring omission.
Not yet, only bitwise.
Channels are based on atomics and concurrent data structures, so they'll always be slower than a single atomic. The std channel is based on a Mutex, for example.
Thanks for sharing! Although the C++ "vs." Rust example doesn't really highlight why Rust is beneficial for security. A C++ vector also can do bounds checking.
The audio quality needs work. ):
Fantastic piece — well written and informative. Found the JSFiddle charts hard to use and distracting, I'm afraid. The default view needs to be the graphic: it took me quite a while to realize this wasn't just a page rendering bug.
Sadly, only arrays are allowed to have projections :(
'Fraid you lost me at "taro is delicious". :-) :-)
That is transmuting pointers, not non-pointer values. 
Yes, that is what my parenthetical is referring to.
I see that more and more functions in stdlib are prefixed with `const`. I was wondering... is `const` really required? I mean, shouldn't the compiler be smart enough to internally add `const` where applicable?
`const` is an API guarantee, and so going from `const` to non-`const` is a breaking change. In general, Rust considers the function signature to be the contract, and so makes you write out everything. We could infer types too, but don't.
&gt; If you only upgrade once every six months, then that just means you also shouldn't upgrade your crates until that point either. No, no, no. That is the thing. Compiler upgrade means that all your testing of all your code base and all crates that you use as dependicies is invalid, and you need full re-test. While upgrade or adding one dependency is modular thing. You need much less efforts, plus it is part of job that you pay for. User need new feature, and you implement it with help of some third party crate. While update of compiler is not part of any feature that you implement.
Entity Component systems.
Oh shit, sorry. I didn't get it XD
Could you explain how that's in any way related? I'm having trouble seeing how \`co\_sort\` could be useful in such a situation.
Is there tooling that scans my codebase and tells me which functions are currently not const but could be marked as const? Are there any benefits doing that?
That's why I find the idea of skribo useful, we don't have to judge use cases. It is possible to start with a simple backend and then change. And about kerning, I usually just use the gpos table with a fallback to the kern table: https://pastebin.com/F0AHY9gQ 
It causes UB and it is not obvious why; this makes it hard to write correct unsafe rust, and as the author notes, this pattern is ubiquitous in OS code.
Java is not that far-off from c/c++/rust IMHO…
Nice work publishing a crate. What do you use this for? 
Well, since it's common to store parts of ECS 'components' in a array to avoid cache misses when iterating over a general game function. And it's very beneficial to iterate on the order you expect you need to access them at runtime. If your game/system has knowledge that 'Bryce' will come before 'Jameson', on a sort of law of big numbers, that's much better than zigzagging through the array. Basically a response to dynamic requirements. There is also the 'i'm going to need a different sort order for this subset' case, but 'subset' pretty much implies that some copying of indexes and sorting that by indirection is going to be better, which this also applies too (first you copy the keys you want to sort on and their ECS 'ids' to different arrays of the same type (eg: a straight memcopy); then you sort the keys with the key sort function and the 'co_sort', then you use the sorted ids to do whatever). Though in this case maybe sort as you copy would be better.. bah, I don't have a clue.
Makes sense. Does it mean that it is possible to create a tool that would analyse the code and point which functions could be marked with `const`?
Makes sense. Does it mean that it is possible to create a tool that would analyse the code and point which functions could be marked with `const`?
Possibly!
It should be there now!
Java is not that far-off from c/c++/rust IMHO…
I tried to simplify the code the most I could but without knowledge in ECS I'm not sure if it's enough, let me know. struct Components(HashMap&lt;TypeId, Vec&lt;Any&gt;&gt;); struct System { ids: Vec&lt;Box&lt;[usize]&gt;&gt;, // this is sorted types: Box&lt;[TypeId]&gt;, } struct Systems(HashMap&lt;TypeId, System&gt;); // I picked a tuple of 4 but it can be any size fn add_components(&amp;mut self, vecs: (Vec&lt;A&gt;, Vec&lt;B&gt;, Vec&lt;C&gt;, Vec&lt;D&gt;)) { let type_ids = [TypeId::of::&lt;A&gt;(), TypeId::of::&lt;B&gt;(), TypeId::of::&lt;C&gt;(), TypeId::of::&lt;D&gt;()]; let ids: [Vec&lt;usize&gt;; 4] = [ (self[type_ids[0]].len()..self[type_ids[0]].len() + vecs.0.len()), (self[type_ids[1]].len()..self[type_ids[1]].len() + vecs.1.len()), (self[type_ids[2]].len()..self[type_ids[2]].len() + vecs.2.len()), (self[type_ids[3]].len()..self[type_ids[3]].len() + vecs.3.len()), ]; self[type_ids[0]].append(vecs.0); self[type_ids[1]].append(vecs.1); self[type_ids[2]].append(vecs.2); self[type_ids[3]].append(vecs.3); co_sort![type_ids, ids]; // We are trying to find all the systems with types matching the ones we have // and if they match we get a vec of the type's index in the system for system in systems { if let Some(order) = system.match_types(type_ids) { system.append((ids[order[0]], ids[order[1]], ids[order[2]], ids[order[3]])); } else { continue; } } }
Good call on ECS, I think the crate can be used in other situations but it's my use case.
I want to see [this](https://www.youtube.com/watch?v=umN2iHsw3UY) sort of stress testing with 3d printed blocks for comparison!
In the process of extraction, `taro` has to reverse the original tar file so that it can be truncated in the right order. It will create a `.rat.header` file and a `.rat.contents` file, containing the tar archive headers and file contents, respectively, and then build from there. No data should be lost during extraction, but you may end up with some weirdly-formatted files. Adding a feature to continue an interrupted extraction is on my todo list for `taro`. 
To be fair, taro by itself might be really gross; I've never tried it. But when it goes into bubble tea, I can't resist the stuff.
Why didn't the shell script use the `parallel` tool? It also makes parallelization very easy. There's the GNU variant and the [low-overhead Rust rewrite](https://github.com/mmstick/parallel).
Using a struct-of-arrays layout where properties from a single entity all lie at the same index of several different arrays (rather than the conventional array-of-structs layout, see also https://en.m.wikipedia.org/wiki/AOS_and_SOA) can have good cache behaviour and can make it easy to apply other optimisation such as using SIMD (both explicitly and via autovectorization). This sort of function allows sorting that SoA data.
Are there any philosophical problems with the dumb, trivial approach of just sticking `const` on every function and checking if it compiles?
According to https://news.ycombinator.com/item?id=18604194 the performance issue is fixed in Windows itself in the latest (or upcoming) Windows release. However, there is at least one other reason to prefer this change: https://github.com/rust-lang/rust/pull/56568#issuecomment-466247750.
http://troubles.md/posts/why-phantomdata/
The only issue I could think of is that it might take a loooong time...
I would guess that it could be bad if you want to avoid API breakage. that is, if you write `const fn foo() {}` in version 1, but then `foo` changes to include features that are not compatible with `const` that make it have to be just `fn foo() {}`, you would have to deal with the semver implications of a breaking change
Thanks, I use it in an ECS, you can look at some pseudo code in a comment below.
If you always recurse on the right side I would just write an iterator https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=12dd527d884e95442d458c7276cf67ac 
They are still using Rust for Wargroove server, but not for the new game. Witchbrook (the new game) will reuse the C++ engine used for Wargroove.
It looks like [clippy has a lint for it](https://rust-lang.github.io/rust-clippy/master/#missing_const_for_fn).
Wow that first sentence threw my head for a spin. Could you add the work logical before or?
Spoiler: Bors continues to be #1 most productive rust contributor
Compare, the recent npm whitepaper: &gt; Downsides: Maintaining Multiple Stacks. Every technical decision comes with trade-offs, and adding Rust to npm's production services is no different... It just happened that trade-offs came other way for Chucklefish, due to downsides of maintaining multiple stacks.
This is a clippy lint!
That last part is a bit of a burden for APIs that don't require any stability guarantees, such private APIs. (But I'm going to assume I'm beating a dead horse.)
You have the power to botch 5 releases by accident, right? (Asking for a friend)
I think they meant that if you wanted a tool that checks whether a function could be made const, you could achieve that by *temporarily* making it const and seeing if it compiles.
If I had to sum up your experience, I think I'd say, "Despite the fact that Rust compiler updates are themselves easy, some types of development environments will always impose large costs on updating the toolchain because of various things that cannot be fixed by simply making the compiler faster." A more in depth write up would help a lot. It's going to be a hard sell to get an entire ecosystem to devote serious resources to supporting older compilers though, unless there are a lot of situations like yours. My guess is that it would be easier to find ways to speed up the process on your end, although I understand that may be hard.
thank you for your help. Does this support changing split positions throughout the recursive split somehow? &gt; let iter = RightRecurseSplit::new(data, |source| split_part_at_nth(source, ' ', 5)); The position may change with every part of the sentence, 
Note that this has to be explicitly enabled, as it's not yet stable.
Wonderful!
Have you tried https://crates.io/crates/fxhash instead of fnv? The former is much faster for long inputs.
When you need if you will get it.
Wow, nice logo. Where did you get it?
That would be a breaking chance because you can't call non-const for const, right?
&gt;You can now have multiple patterns in `if let` and `while let` expressions. That's the most interesting thing for me. I'm glad I clicked through from the blog post to the detailed notes.
Your `Parts` struct is an attempt at a node for a singly-linked list. I strongly recommend reading [Learning Rust With Entirely Too Many Linked Lists](http://cglab.ca/~abeinges/blah/too-many-lists/book/) ([repo](https://github.com/rust-unofficial/too-many-lists)).
I personally use [marcaria](https://www.marcaria.com/ws/en/home), but I believe many others use [istanco](https://www.istanco.rs/). There's some silly paperwork to establish a Serbian presence, but it's a formality. I've had a good experience but the pricing is higher (I think $77 vs $26). I'd guess Google doesn't do this domain because of the special paperwork, there are a bunch more domains. Best of luck!
Cosorting is very common in many maths algorithms. I'm more used to it being called 'ParallelSort', but I think nowadays that could be easily confused with a sort algorithm which ran on multiple threads. 
I'll just address the third to last point. Rust does have smart pointers, the prominent one being Box&lt;T&gt;. With Box you can create recursive data structures. As you go on you'll start to really appreciate the compiler, so get friendly with it. Hang in there for Rust, she's worth it. 
Oh yeah I ran into Box when I was learning how to share data with Rc&lt;&gt;. I guess after reading over \[this from stackoverflow\]([https://stackoverflow.com/questions/36167160/how-do-i-express-mutually-recursive-data-structures-in-safe-rust](https://stackoverflow.com/questions/36167160/how-do-i-express-mutually-recursive-data-structures-in-safe-rust)) I was a little leary of building up with recursive data that may have mutable references to its parents (which is super handy for recursive data). 
The input is a FnMut(&amp;str) -&gt; Option&lt;(&amp;str, &amp;str)&gt;. So that could split where ever it wants. If that FnMut needs to mutate state then that might need some care to handle the lifetime of that state. Here's a basic example using mutable state, which you may not need. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=227bdfac85b69bedddbcd5a8a464397a 
ps I'm not going anywhere. Just need a bit more grease to get productive (and QUICK) building with it.
This was a fun read. Thanks for sharing! &gt;I was curious why not std lib that super duper cool/useful bit Rust is rather different from, say, Python or C++ in that it only keeps fundamental building blocks in `std`. Everything else is expected to be a crate. The theory is that this will let the ecosystem evolve faster and independently of `std` and the developers of `std` to keep better focus on Rust's core offering, instead of something like the infamous quote about Python saying, ["The standard library is where modules go to die."](https://www.reddit.com/r/rust/comments/6ddp3e/why_does_rusts_standard_library_feel_so_small/di1zbsr/). &gt;even simple recursive data structures are pretty much a no no I hope you don't still think this! :( You just need to use an indirection like a `Box` to make it work! You've probably already figured this out by now.
It's not different. They already have to deal with horror of JS deployment, so they don't want to add horror of JVM deployment.
Man those both look rough! Have you had any problems with marcaria so far? Can you setup DNSSEC?
I got that vibe from the modules so far. I didn't mean to say recursive data structures are impossible, but from what I could gather the memory lifetimes and ownership rules make having child nodes with mutable references to parents problematic. I linked a stackoverflow question in a comment above or below 
&gt;DateTime being a third party lib (chrono, chrono_tz). I was curious why not std lib that super duper cool/useful bit Everyone has different requirements. Some people just need a quick timer, while others need a full international calendar with fifty different formatting styles. Date calculations are notoriously complex, and there's no reason to select either 'the perfect calendar' or 'the quick and simple' as the standard implementation. Especially when Date &amp; Time structures aren't major API composition hazards like strings and numbers are. In short, the std library includes the things that are needed to make the Rust ecosystem function, not simply anything that could be useful to people.
I use instanco and it's great.
But if a bummer but obviously they need to do what’s best for their business. Best we can do is keep improving the language and ecosystem to make sure the decision turns out differently next time.