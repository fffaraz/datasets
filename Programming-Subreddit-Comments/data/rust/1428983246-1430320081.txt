You may be right. I took the reference from the Wikipedia article on Exit status, but I'm not really acquainted with Windows specific stuff. Regardless of the fact that maybe Windows has adapted to the Unix convention, I still think the specific exit code used to signal success or failure should be hidden under a meaningful and platform-independent API. I don't think this needs more argument other than the fact that exit codes are clearly platform specific and non-portable. IMO the current `std::process::exit` is very platform-centric and this should be avoided, as it has been avoided in other standard libraries. Besides, `exit(1)` is somewhat cryptic, really.
thanks!
I replaced my static mutexes by: lazy_static! { static ref MY_MUTEX: Mutex&lt;()&gt; = Mutex::new(()); } The `lazy_static!` macro comes from [the crate with the same name](https://crates.io/crates/lazy_static).
Minor typo for the piston project update: Piston 0.1 was released, not 1.0 as the update states :) Edit: Not to just point out the problems, I really enjoy these updates. Thanks a lot for making it easy to keep up to date with the Rust world :)
I'm looking for people to help write explanations for errors emitted by the compiler (not ICEs). There are lots of errors*, so the more people we can get behind this the better :) *Even more than I realised when creating the issue, will update it soon.
Another typo: the link for multirust in the Project Updates section points to the post on Fearless Concurrency!
@killkrt I just implemented the [non-blocking API](https://github.com/jeremyletang/rust-portaudio/blob/master/examples/non_blocking.rs) :)
&gt; Now if there was a good UI library Not sure if you've seen [conrod](https://github.com/PistonDevelopers/conrod) ([this](https://www.youtube.com/watch?v=n2UrjogA0j0) is what it looks like) - I started it for the same reasons! It's far from fleshed out and could still use a lot of features / love. I'm currently working on some [experiments](https://github.com/mitchmindtree/elmesque) that might make it easier to compose widgets together. Anyway, just thought I'd mention it. Not sure if there's a way to follow an organisation other than following the individual repos you're interested in - if you're interested in contributing etc I could add you to the organisation (in which case you'd automatically be subscribed to each of the repos)?
Submitted a PR already
It does indeed, but at the moment there are only a handful of messages for match expression errors.
Does the crate actually contain anything? It might just be a reserved name, in which case, the homepage/repository may have never existed.
I only knew high level languages before using Rust, and it only took me a week or so to be completely at home with pointers and all the other low-level concepts.
This news made my day! Thank you!
Good point. I see that Borrow makes sense.
The problem is the `Rc` pointer being borrowed immutably. You either need to wrap the parent in a `RefCell` (which won't work with the current return of a `&amp;mut` pointer), or change how the ownership of the data structure works. If it helps, I wrote a union-find using an underlying vector, rather than a linked structure. EDIT: You could also just make all your operations on `Rc` instead of `&amp;mut`.
Indeed, the plan is to de-stabilize `scoped` for the time being, while we decide the best way forward. The problem here isn't the idea of sharing stack frames, but just that you can't actually rely on a destructor being run in today's Rust. You can, for example, put a value into an `Rc` cycle that will cause its destructor to never run, which in this case means that there's no guarantee that the parent thread will wait for the child to finish.
There needs to be some appropriate error message in cases where the programmer tried to do something so clever (or inane) that the compiler's mind was blown. [Like this](http://stackoverflow.com/a/213441/1725151). Alternatively, you can punt on mind-blowing corner cases for 2.0.
What's an OIBIT?
&gt; Identify which error codes are hit most commonly so they can be prioritized for extended error messages. How would you do this? A complier hook that sends any error codes encountered to a webserver somewhere?
Well, that's really dependent on what you mean by preemptive I guess. As far as I am concerned: - cooperative: the user has to yield (explicitly) - preemptive: not cooperative For me, the compiler inserting "flag checks" such as what the Go compiler does is preemptive *if* I can always suspend a given thread within a limited amount of instructions (ie, I don't have to worry about infinite loops). I will admit I do not know whether Go matches this definition exactly, having not used the language, I had no necessity to check it.
https://github.com/rust-lang/rfcs/issues/629
A quick way to make some progress fast would be to just conduct a poll. To automate it I think what I would like to do is add a flag to rustc that writes some anonymized json to a file somewhere, then have *multirust* prompt people to opt-in during installation and periodically upload. My reasoning for putting it in multirust is mostly that it doesn't require any debate to add data-collection to that project.
Could you expand on how this lifetime parameter in `Arena`? I don't quite understand how `Arena` can require its contents to have a longer lifetime than itself since it allocates and deallocates them.
You might as well just do [this](https://github.com/rust-lang/rust/blob/88fc543866c2c48b3b1a32e9d55a4eb77d1dee66/src/test/run-pass/const-binops.rs#L12-L19).
Let's have a look at some definitions: pub struct Arena&lt;'longer_than_self&gt; {} impl&lt;'longer_than_self&gt; Arena&lt;'longer_than_self&gt; { pub fn alloc&lt;T:'longer_than_self, F&gt;(&amp;self, op: F) -&gt; &amp;mut T where F: FnOnce() -&gt; T { } } Notice that `alloc` only places the `'longer_than_self` lifetime bound on `T`; the returned `&amp;mut T` has an elided lifetime equal to `&amp;self`. With this parameter, `Arena` is restricting `T` from having references with lifetimes equal to or shorter than its own. This way it can't contain cyclic references: let arena = new Arena(); let my_ref = arena.alloc(|| 1i32); let _ = arena.alloc(|| my_ref); This may look harmless here, but with more complex reference types it could get quite nasty.
Don't compare floats for equivalency at all. Subtract them and see if the *absolute value of the result is within some small epsilon, or use greater than, less than, etc operators if you can. *Edit
oh please don't
I was wondering about rust and RC cycles is was it possible to prevent them statically. By dissalowing RC of types that contain RC pointers. But I guess that's too difficult or restricting.
As if it was Vold---rt?
D actually uses 'voldemort types' to mean something...
In games, yes. ;)
I'd start by looking into println! and the Fmt Traits, I'm fairly sure you can adapt the idea to your use case.
Very useful
* [byteorder](https://github.com/BurntSushi/byteorder) does endianness stuff. * [rust-cbor](https://github.com/BurntSushi/rust-cbor) is basically binary JSON. CBOR is an IETF RFC with implementations in other languages. * [bincode](https://github.com/TyOverby/bincode) has its own binary encoding scheme.
byteorder looks very interesting, for what I want to do! The others (including the ones mentioned by wacky) seem too specific for reading arbitrary bin files. Still, byteorder don't have the elegance of the struct module in Python; but this will give me some hints.
On the one hand this really sucks, but on the other hand it's exciting that we get to experience a trial run of dealing with newly-discovered unsoundness in stable code. This should be a valuable experience for influencing language development post-1.0.
&gt; Still, byteorder don't have the elegance of the struct module in Python Nor should it. `byteorder` is something you might use to *implement* an interface like Python's `struct` module. &gt; The others (including the ones mentioned by wacky) seem too specific for reading arbitrary bin files. Right. They solve the problem, "I have data and I want it in binary, but I don't care too much about the exact format." They don't solve the problem, "I have some weird data format given to me by someone else and a specification, now I need to read it."
&gt; The only thing I found doing both compile time and run time execution is the regex crate, which is too much complicated for my understanding right now :-(. But I think I will take a closer look at it. If you're on IRC, I can help give you a tour of it. (My nick is `burntsushi`.) But you're right, it's not going to be easy to digest. It's basically a code generator for an NFA simulation. You might find the `docopt!` macro a bit more digestible: https://github.com/docopt/docopt.rs/blob/master/docopt_macros/src/macro.rs --- You should read the examples first to get an idea of what it's doing. (I could also give you a tour of this too.)
&gt; I tried this, and this seems fine, except that I don't know how to read the packed data, because this has to be done at run time. Right. Basically what you'll have to do is take the format string and generate code that reads/writes packed data *in that particular format*. So if you have `&lt;xxIh`, then you'll need to generate code that does the following: * Read one byte. * Read one byte. * Read 4 bytes in little-endian into a `u32`. * Read 2 bytes in little-endian into a `i16`.
The language is pretty much stable for 1.0 at this point, the time leading up to 1.0 is intended for polish work on the existing features. Meaning: slice patterns and box patterns are extremely likely to still be unstable for 1.0; they'll still be usable on nightly, and they'll probably reappear in stable in a 1.x release with x small (hopefully 1 or 2).
How broad a scope are you going for with this crate? Would you consider writing something along the lines of [`tempfile.mkdtemp`](https://docs.python.org/2/library/tempfile.html#tempfile.mkdtemp) from the Python standard library? (To quote the start of the docstring, "Creates a temporary directory in the most secure manner possible.")
I'm not sure I totally understand the release cycle. Is 1.x release with x 1 or 2 going to come out in 6 to 12 weeks after the upcoming stable release?
I've found it useful for writing tests which test things which depend on the file system.
Wonder if there is an overlap here with structs: #[repr(C, packed)] struct Struct { a: i16, b: i16, c: i32 } 
You seem to be confusing endianness with bitfield layout. Two separate issues.
Ideally, that and an indication of the on-disk endianness would be all you'd need. As I understand it, crufty, non-portable old C code would often just write a struct to file verbatim (sometimes not even bothering to pack it) and the modern approach I see C programmers recommending is to reinvent that by manually walking through the struct, conditionally byte-swapping as you go. The properly elegant approach would be just to have a "read struct from file handle" function which can understand the struct's structure and do endianness conversion on a field-by-field basis. (Ideally, with the serialized endianness defined by annotating the struct so the format definition is as unified as possible) To be honest, I suspect that the only reason Python's struct support is based on format strings is that it predates the metaprogramming features used for more modern things like ORMs.
Still not right, see [this](http://floating-point-gui.de/errors/comparison/) or [this](http://www.cygnus-software.com/papers/comparingfloats/comparingfloats.htm). (I mean, conceptually it's sound, but a fixed epsilon will fail for small floats)
Slice patterns are unstable because the slice pattern reform (https://github.com/rust-lang/rust/issues/23121) is not implemented yet. As you can see, jakub- was going to implement them for beta, but didn't finished the work for some reason, so the patterns were destabilized.
If you run `cargo update` this will be sorted now. For the bad experience, I'm happy to help you if needed (just PM me).
The problem can only manifest if the shared pointers don't form a DAG can't it? Any thing that breaks that needs to be a weak reference.
This is basically what [libpnet](https://github.com/libpnet/libpnet) does now, for example a UDP packet is defined as: #[packet] pub struct Udp { source: u16be, destination: u16be, length: u16be, checksum: u16be, #[payload] payload: Vec&lt;u8&gt; } More examples: https://github.com/libpnet/libpnet/tree/master/src/packet Documentation: http://octarineparrot.com/assets/libpnet/doc/pnet_macros/index.html
If this is an inter-process communications library, or intended to be, then: * how does another process discover the name of the temporary file * what locking mechanisms are recommended Documentation: * `fn shared()`: s/guarentees/guarantees/ * what happens when the structure goes out of scope, does the file get deleted? 
You can create a temporary file, spawn another process passing the filename, and delete the file after this process exits. That's the usefulness of temporary files in languages like shell script anyway. On Unix platforms, passing /dev/fd/xx as "filename" and writing to it with a pipe is usually better, unless the other process need to seek while reading. On Windows I'm not sure what's the alternative.
But anonymous mmap in this case is just memory allocation, right? I suppose that jemalloc will call mmap when allocating large blocks.
'This variable has the property that must not be named' 'myvar is you-know-what' 
&gt; The real problem is that programmers have spent far too much time worrying about efficiency in the wrong places and at the wrong times; premature optimization is the root of all evil (or at least most of it) in programming. - Donald Knuth, renowned computer scientist The bit operations are implemented with Rust intrinsics, which presumably compile down to either single instructions if the CPU architecture supports them, or a reasonably fast implementation. I doubt they will be a bottleneck in your application. Write your program first. If it "feels" fast enough, let it alone. Only after you've determined that it needs to be faster/more efficient (for example, if you need a specific minimum throughput) should you start profiling for performance bottlenecks. Slow (large big-O factor) and/or cache-thrashing algorithms are far more likely to cause a noticeable performance drain than some sub-optimal bit-twiddling.
You meant to say that it returns an unsigned type for when taking a signed input right? Or am I missing something?
Like Ruby's fibers?
Excellent! Thanks for following up with me. I'll give it a shit today and reach out if I have any issues.
That was a nice talk. The Rust open space meetup the next day was also super-interesting.
Great talk!
There are fonts that are specially designed to interpret such compound symbols as typographic ligatures. You can try using one designed for Haskell, that uses the arrow symbol too: https://github.com/i-tu/Hasklig
See the tempdir crate.
I hate to bang that drum, but: Unlicense. Unfit for anything where you actually have to ensure sound licensing.
I was in that audience, and a number of Pythonistas with me were all of a sudden very interested in Rust. Well done! Personally, I wished there had been a bit more about interoperating with Python, but it was a very clear talk overall!
Yeah, it's important to make the distinction between the two.
A silly question: what licence should one use for his crate if he doesn't care about licensing? MIT?
[the book](http://doc.rust-lang.org/book/) has, among many other things, an introduction to Rust FFI. /u/steveklabnik1 probably can help you more.
It's not exactly on topic, but since you're here, is there anything keeping us from exporting Rust functions parading as C to Matlab?
Great presentation. It helped me understand Rust's ownership-borrow feature, and its python corroboration is very exiting! 
I don't know much about Matlab, but if it can call into C code, it can call into Rust code.
Why not raise issue with burntsushi? He changed licence for regexp, no?
Not an expert but CC0 should probably also work…
If you look at the open issues at the project you will see that there is an issue about the license and the author is considering dual licensing using unlicense and MIT.
Nice short talk! And nice T-shirt, too! :) One minor nit, though: For the graphical pointer representation at 9:21 to be correct one would need to change the code y = &amp;x; to y = &amp;*x; since x is not the heap-allocated `i32` but the stack-allocated `Box&lt;i32&gt;`. Deklaring `y` as `&amp;i32` might also work and trigger the "Deref-coercion".
/u/burntsushi and /u/fgilcher have had a number of conversations about it here in the past, it's not likely to change, in my understanding. Which of course, he's free to do. (I personally prefer the AGPL, so I'm used to being the one getting yelled at for license choices...)
Actually, both work. Try it out by annotating the type of `y`. It can be either a `&amp;Box&lt;i32&gt;` or a `&amp;i32`, depending on the way you annotate it.
Isn't that too often? I mean it is great cycle for development, but when language is stable, then new versions IMHO should be more "stable", I mean that if Rust keep 6-week release cycle then IMHO version numbers will grow a little too fast. I would suggest that the time between releases should be a little bit longer.
I've the feeling that you missed my point. In Dan's code `y` would have been of type `&amp;Box&lt;i32&gt;` if the borrow checker had not complained. But the arrow was pointing from `y` directly to the heap-allocated `i32` instead of the stack-allocated `Box&lt;i32&gt;` to which `y` *actually* was pointing. IMHO, this should not be glossed over. Pointer and pointee are not the same thing even though Rust kind of fosters such a potential confusion a little bit by the implicitly dereferencing dot operator.
Some data is too big for RAM so it wouldn't work in that cases (i.e. you are fetching your program installer from net and it weights 10 GB). So there are cases for that.
[It looks like it is getting dual-licensed as MIT](https://github.com/BurntSushi/byteorder/issues/26#issuecomment-93420612)
Neat!
Just curious, why would you use CC0 over MIT? Isn't the MIT license much more widely used?
You are absolutely right, thanks a lot! Fixed it.
And since you're here ;) let me share my opinion on the usage of `Box` in examples like these (including the book's ownership chapter) in the hope that it could improve documentation: I don't think it's a good idea to use `Box` for simple `i32` values in these examples. The `Box` serves no purpose in these cases and I've already seen some redditor thinking that ownership transfer implies something that involves a `Box`. Boxes are only useful if an additional layer of indirection is needed. I'm concerned about beginners overusing boxes. In Niko's and Aaron's talks we can see examples using `Vec`. Pushing new values onto a vector *requires* this indirection(*) that is also intrinsic in `Vec`. And `Vec` is probably more popular in real code. That's why I think it's a better example of a non-`Copy` type that involves heap memory usage. (* assuming you don't want to limit the capacity and inline all the elements)
The docopt macros indeed seems much easier, I'll take a look, and maybe ask for some help ;-) Thanks!
First of all, I'm planning on re-doing the ownership chapter, so thanks for the feedback. :) &gt; The Box serves no purpose in these cases It does serve a purpose: to demonstrate the stack vs the heap. There's always tension with examples: you're right that boxing an integer is never useful, but the purpose isn't to show off _useful_ code, it's to provide a minimal reproduction of the concept. Introducing a more 'realistic' example adds complexity which causes _other_ distractions. That said, I am generally leaning towards using `Vec&lt;T&gt;` more, for similar reasons. TL;DR: this stuff is really hard.
&gt; doesn't care about licensing I *do* care about licensing. That's exactly why I use the Unlicense.
With #2, it also sounds like you could potentially enforce correctness of the passed parameters via the type system itself.
To be clear, I'm not a practicing ideologue. I happen to have *very strong* philosophical opinions on certain things (we all do) that are a bit more nuanced than "software licensing sucks." I try to find meaningful ways to express that. Making it *meaningful* is hard because it tends to imply that you have to go against the grain of *something*, which implies there are costs. As much as I care about that stuff, I tend to care a lot more about my actual local interaction with people. I say that because it pains me to erect artificial barriers (assuming the environment is unfungible, which, in practice, it often is) between me and others. At the end of the day, people I interact with tend to win out in my book. That probably makes me a pragmatist. OK, two paragraphs of off-topic drivel is about all I want to commit to. :-)
Wait, Servo is not going to be released? Why?
A post in response to mine shows how to derive the epsilon.
"Don't use RAII" is a real option. Only clean up in the destructor but require a function call if the operation should be meaningful. For example with files: In the destructor, only close the files, without checking for errors. To meaningful write things to disk, you need to explicitely close the file (a method which takes the file by reference).
I like the approach to use a (kind of) builder pattern here. Makes the API fairly clean. And it is also nice that you get rid of the state machine interface, that `term` provides. Have you considered integrating this new API into the term crate?
I think some IO RFC in discussion tries to change it so it doesn't flush on drop.
Nice! I think it’s good that a low-level API and a high-level convenience API both exist. I like how `Style::paint` uses the `Display` and `Debug` traits. I’m less sure about `Style::with` as I usually try to avoid thread locals (a.k.a. less bad globals). What hack are you referring to? “Advertising” open-source tools that can be useful to Rust developers is fine in this subreddit IMO.
I’d use one-liners like `write_all(&amp;transmute::&lt;u32, [u8; 4]&gt;(x.to_be()))`.
Thanks! I don't like those thread-locals either... but the physical terminal is a "global" anyway, so I figured it would be ok to use them. And I would need them anyway for crazy cases like those: println!("{:?}", Red.paint( ("red", Bold.paint("both"), "just_red") )); Without saving the last state, "just_red" wouldn't be red, but completely normal. EDIT: Forgot about the hack. It's not really a hack, but to avoid writing functions like `bold()` or `fg(..)` twice, I used the `ToStyle` trait... 
There are libraries like [nalgebra](http://nalgebra.org/doc/nalgebra/trait.ApproxEq.html) and [cgmath](http://rust-ci.org/bjz/cgmath-rs/doc/cgmath/trait.ApproxEq.html), that handle this more nicely using either some fixed tolerance or (in the case of nalgebra's ULPs feature) ignoring the least significant bits when comparing.
My mind always melts just a bit trying to apply these type system concepts in the context of Rust, such as figuring out what a concept that relates to using a value exactly once vs at most once means in an imperative language that supports mutation. I can reason about hot potatoes, though ;). I suppose non-copy values are "affine" in the sense that you can either move them or drop them, but you can't use after move ("using" them at most once, ignoring mutation), whereas "linear" types would have to be moved ("used" exactly once, again ignoring mutation)?
Yes, exactly. Though some argue that these types are actually linear with automatically inserted drops, but as the various edge cases under discussion demonstrate, this isn't always the case.
Is this what you mean? (this compiles on nightly) fn decode&lt;T&gt;(reader: T) where T: Read + Send + 'static { thread::spawn(move || { reader; }); }
Switched to atom. Still no cargo support though
Thanks, that worked! I didn't realize you could add the trait as a constraint like that.
Oh, damnit, you're right. I'll have to re-think how I draw those slides for the future. Thanks for catching that! I'll also lean toward using Vec in the future. This was my first real run at this talk, and I'm quite the Rust newbie myself. :-)
Glut in works with the excellent glium library for 3D graphics. No link br cause I'm on mobile, sorry.
Well, that's what's Google's for :P Also, glium looks delightful. It always annoyed me that nobody built good-looking wrappers around GL in other languages that LOOKED like the language. Glium LOOKS like Rust, and that makes me happy :3
&gt; **unique** objects **in memory** To be clear, that's "object" in the C sense of "a contingous sequence of bytes which stores a value of some type".
I should know better than to say 'never'
A lot more people are going to be Interested in rust now that its reached 1.0 (very soon I think), I know the very often changing of syntax was a turn off for me
If you were to use `Rc` to "lose" a `MutexGuard`, the mutex would stay permanently locked rather than allowing multiple threads to access the data.
Yeah, as the drop itself might fail (which is the point of this thread :D), it's a bit of a stretch to call a droppable affine type a linear type. Another common claim seems to be that as long as the stack is allowed to unwind past linear types, they aren't strictly linear.
I've added a `NamedTempFile` variant for when you absolutely need a path and are sure that a temporary file cleaner won't interfere.
https://gist.github.com/archer884/6cae4445f238344f185b
When in doubt, you can do anything in vim
&gt; f.lines().filter_map(|line| line.ok().and_then(|l| l.parse().ok())).collect() This line from your original post works for me, and is not what you are using in the gist you posted. Is it not what you want?
So, on a complete guess, since your gist does not yet include the `deserialize()` function, you still don't post the error messages you get on your current code, etc. You have two occurrences of this pattern in your code. In the gist one is on line 118, the other on line 145. It seems to me you might be fixing and breaking the former one, while ignoring the later one.
So, then, the *actual* problem is that I haven't learned to look at line numbers yet because I'm an IDE nub.
In the `calc.py` example, you could pass in a Python byte string as `const char *script`. What is the equivalent for arrays of ints? from cffi import FFI ffi = FFI() ffi.cdef(""" int func(const int arr[]); """) C = ffi.dlopen("target/release/libcalc-771b1f816b5bd78c.dylib") def main(): result = C.func(???) print(result) if __name__ == '__main__': main() 
You can wrap the inputs in an `enum`, like enum Input { Standard(io::Stdin), File(fs::File) } There is a simple example in https://gist.github.com/ayosec/2ee0993247e003b42c5c . I guess that the code can be improved using [`AsRef&lt;io::Read&gt;`](https://doc.rust-lang.org/std/convert/trait.AsRef.html). 
Thank you all for your thoughts!
As far as I understand it was only rejected because some people had issues with the patent clause which is kind of weird asserting GPL3’s existence…
OK, thanks so much for taking the time to clarify that for me!
Vim has a configuration file that can add tons of extensions. Everything from compilation, code completion, error highlighting, everything. I hear that that one operating system disguised as a text editor can do the same, but I am not a heathen so I don't use it.
Good idea, added one screenshot to the GH-Readme... I don't think I can add images to the documentation, right?
Except for all the things you can do in Emacs. Evil-mode ftw. 
Cool! Does this work (i e print "Red Green Red" in the expected colors)? println!("{}", Red.paint(format!("Red {} Red", Green.paint("Green")));
4 . Log them with the `log` crate.
Yes but when would you have a use for it? Since these methods are O(n) It sounds like an awful waste of cpu to iterate through 2^32 elements just to skip them. If this is the use case, the programmer should solve it with a different algorithm (for example a different data structure).
There is probably put more thought into that crate. Plus I have not benchmarked any of my code.
I would be interested. What's your startup?
Yehuda Katz's startup, is doing this with Ruby in production with [Skylight](https://www.skylight.io/). They've got two decent blog posts up about their experiences: * [Bending the Curve: Writing Safe &amp; Fast Native Gems With Rust](http://blog.skylight.io/bending-the-curve-writing-safe-fast-native-gems-with-rust/) * [Rust Means Never Having to Close a Socket](http://blog.skylight.io/rust-means-never-having-to-close-a-socket/)
I'm interested
Computational Analytics Engine. You can query against huge, multi-dimensional datasets and it reduces the result into a 2D time series/table. You can do very powerful analytics. For example, if you're investment manager, and want to know the volatility (stddev) of all your assets for each historic year. You can then easily decompose the year dimension into month/day/hour/min/sec/us intervals and also can expand it by adding more dimensions, let's say by adding a financial markets dimension; so you now have a time-series that is `volatility of asset x year x financial market` so you could easily see the volatility of all asserts for each year and financial market. This is all driven by a UI so no SQL is used by users. We've built a prototype in C++ but we're starting to build the production version in Rust.
Also interested, I currently work for a big software firm but doing lots of sideprojects in Rust.
We did it a couple times at Mozilla London http://www.meetup.com/Rust-London-User-Group/ but then had a hard time findings potential speakers. (Also, I have since moved abroad.) But maybe meetups don’t really need formal talks and can be more unstructured discussion. If you need a location, I can try to find someone to host it there.
Also, it would be awesome if you do it on [May 15](http://blog.rust-lang.org/2015/02/13/Final-1.0-timeline.html) ;)
I would be interested as well
That would be great timing so we can have a small celebration/party too. I was thinking of doing informal lightning talks so people can easily develop a talk around thier work/life schedule. I don't have a venue yet so it would be perfect to host it at Mozilla London on May 15.
Yes, definitely. I think it mostly needs someone to step up and organize it. Mozilla can provide the space and probably some food.
Nice! It looks like a refreshingly simple/intuitive API. 
I would definitely be in!
fixed the answer, sorry for the confusion. this was the way i worked through it in my `guess_the_number.rs` code and felt like it was worth sharing. definitely appreciate you teaching the preferred method
It's all good! :)
I wouldn't mind...
&gt; What are some good resources for learning assembly? [Programming from the Ground Up](https://savannah.nongnu.org/projects/pgubook/)
Definitely interested!
You know about LLVM IR, right? Rust generates LLVM IR internally and hands over to LLVM to generate the final CPU-specific machine code. (Or did I misunderstand the question?)
It goes Rust -&gt; LLVM IR -&gt; Asm or machine code. The LLVM libraries take care of everything from LLVM IR onwards.
Is 27k the 5x number? 
Since when "Building an API" means "hello world" example with json response ?
That's what I was thinking and it's not clear. If the results are before he said he passed the Ruby production var to Ruby (guessing this is equivalent to -O). then JRuby is faster than his Rust code. 
x-post from /r/programming. Lots of stuff relevant to Rust.
(Discussion should happen on the discourse post.)
I'd be interested in numbers for JRuby _after_ it jitted. Also, which Implementation - I'd be very interested in numbers for JRuby 9000.
I also found the community really enjoyed just getting together for a dinner now and then, so don't feel like you need speakers to meet. It's pretty easy to scale up and down depending on the size of the local community. That really helped to bootstrap the SF meetup.
Definitely, I've been thinking of going to a Paris meetup so London would be great.
I'd like to leave some kudos to the core team and all contributors. Rust is shaping up to be awesome!
I'm excited about almost everything on that list :) Especially looking forward to "Virtual structs" or something alike.
Just saying "API" is super vague. I didn't realise this was about a web API until it started talking about HTTP microframeworks.
Yes, I think it's important that we dispel early on any notion that Rust compilation is slow by necessity rather than merely slow by accident. The D compiler already serves as proof that a C++-replacement with a rich feature set can feature very fast compilation. There's all sorts of things that we can be doing but we aren't, like for example writing out crate metadata *before* trans so that dependent crates can start compiling while LLVM is still chewing on their dependencies (thanks to kmc for the idea), to say nothing of more well-publicized wins like parallel codegen and incremental recompilation.
Me too.
&gt;I'm wondering what kind of ASM does it output From a very quick glance it looks like x86_64 using AT&amp;T syntax &gt;I'm wondering... ...how to better understand asm generated. Reading the output of a real world compiler can be confusing if you don't know about the optimizations it can make. Things like a simple `for` loop can wind up having all kinds of seemingly inexplicable instructions added. On top of that `rustc` adds some extra safety checks, so there is going to be a bit more "noise" around certain things. The result can be some very messy code that is clear as mud. If you want to buff up, I would start by writing some by hand. Then look up the calling conventions for your platform. Once you are comfortable with it (a good litmus test would be to call a C program from ASM, return a value from C and then print it to console from your assembly), then start trying to understand the output of the compiler. You can get` rustc` to output assembly by using `--emit asm`.
Awesome! Added to all my crates. :-)
Yeah, I liked the looks of that too. I ended up going with this: fn read_args() -&gt; (usize, Result&lt;Vec&lt;String&gt;, Vec&lt;String&gt;&gt;) { let argv: Vec&lt;_&gt; = env::args().collect(); let argc = argv.len(); (argc, match argc { 1|2|3 =&gt; Ok(argv), _ =&gt; Err(argv), }) } fn main() { // some other stuff let (argc, argv) = match read_args() { (n,Ok(m)) =&gt; (n,m), (_,Err(m)) =&gt; { println!("Ussage:\t{} [data_file] [meal_file]", m[0]); return }, }; let (data_file, meal_file): (Box&lt;BufRead&gt;, Box&lt;BufRead&gt;) = match argc { 1 =&gt; (Box::new(BufReader::new(io::stdin())), Box::new(BufReader::new(io::stdin()))), 2 =&gt; (Box::new(BufReader::new( match File::open(argv[1].to_string()) { Ok(n) =&gt; n, _ =&gt; panic!("Could not open file {}", argv[1]), })), Box::new(BufReader::new(io::stdin()))), 3 =&gt; (Box::new(BufReader::new( match File::open(argv[1].to_string()) { Ok(n) =&gt; n, _ =&gt; panic!("Could not open file {}", argv[1]), })), (Box::new(BufReader::new( match File::open(argv[2].to_string()) { Ok(n) =&gt; n, _ =&gt; panic!("Could not open file {}", argv[2]), })))), _ =&gt; unreachable!(), }; // etc
This is great, I was just thinking about this the other day!
[**@rustlang**](https://twitter.com/rustlang/) &gt; [2015-04-16 02:55 UTC](https://twitter.com/rustlang/status/588536274509811714) &gt; @abraaoisvi @paulosuzart there's a second version of that stuff coming ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://www.np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
&gt; in one time. As always, it's worth remembering that if it doesn't, it's just six weeks until the next one. Not the biggest deal.
No, using json::encode/json::decode would also work here AFAIK. I'm not sure why RustcEncodable is derived *and* a custom json function is created.
&gt; The D compiler already serves as proof that a C++-replacement with a rich feature set can feature very fast compilation. Ada and Modula-3 compilers already proved it long time ago. Even C++ enjoyed very fast compilers via Lucid Energize and a variant of IBM C++ Set, which where capable of incremental compilation at function/method level although they were very resource hungry and failed to get any traction. The secret was to use their own linkers, instead of relying on the classical UNIX model.
I think I asked about this recently, and the reason there isn't one is simply because no one has written one since it isn't a high priority thing to include in the std. Someone please correct me if I'm wrong 
~~I'm not sure if it's supposed to, but~~ using '0$' seems to work http://is.gd/LBmhfC edit: After rereading the fmt docs, I'm more sure it works. See http://doc.rust-lang.org/1.0.0-beta/std/fmt/#syntax . Note the part about 'width', 'count' and 'parameter'. Is this covered somewhere else in the docs?
It also doesn't help that the language doesn't have variadic functions, or the ability to unpack arbitrary tuples. I imagine a runtime equivalent to `format!` would have to be built with method chaining.
TIL, thanks. It is supposed to, the documentation of `std::fmt` states: &gt; The value for the width can also be provided as a `usize` in the list of parameters by using the `2$` syntax indicating that the second argument is a `usize` specifying the width.
&gt; '0$' Indeed it does seem to work. Thanks!
Already did. Thanks.
I really liked the blog post, I'll make sure to check out the source code when I can. 
I would *love* to see this project become feature-complete enough to allow me to use it instead of sqlite :) !
Yes, but I think it matters whether we're talking about with optimizations or not. Generally you trade compile time for faster code. dmd is probably significantly faster at compiling than gdc or ldc, even with optimization turned off.
But would that not mean that you cannot interact with the filesystem in stable 1.0?
 Looking at your problematic example: Usage: prog cmda cmdb prog cmdb cmda prog cmda ... cmdb Yes, allowing multiple subcommands at once doesn't translate nicely into an Enum. But if you make the restriction, that only one subcommand can be used at once - which seems to be a quite often use case - then you could translate it quite directly into an Enum. Perhaps having a separate macro for this case could work. 
 let word_cmp: String = word.chars().flat_map( |c| c.to_lowercase() ).collect(); Is this really how you convert a string to lowercase?!
Could you please put suggestions on the issue tracker? (Your suggestion is discussed at length.) &gt; Perhaps having a separate macro for this case could work. I maintain three syntax extensions that will not see wide use for quite some time. I'm not keen on adding another.
You can interact with the filesystem in stable 1.0, just with a more limited API (for instance, no support for reading symlinks, no handy utility for recursively walking a directory tree). But the basics are there, like creating files and directories, iterating through all of the files in a directory, and so on. If you need, more than that, you can always implement it yourself by calling out to `libc` directly, or writing your own utilities like the recursive walk.
The vast majority of compilation time for a Rust program is optimisation. If you turn optimisations off, it's mostly code-generation. We don't need tips and tricks, there are some pretty obvious things we can do to improve compilation times (incremental compilation is a big one). It's just that said things are a lot of work. Using tricks from dmd would be like micro-optimising a bubble sort.
I'll have to read up on that! B+Trees are hardly implemented at this point (it was a serious blocker, which is why I have `tempdb` and ad-hoc `BTreeSet`s right now), so anything could go. My initial plan was to roughly follow SQLite's idea of B-Trees and have some of the payload stored in the node cells. If the data's too large for the cell, then the remainder gets put into overflow pages. This should be great for quickly comparing the beginning of payloads without being too harsh on caching in most cases.
I had a similar problem, so the way it works currently in clap is only one valid sub-command is allowed per set of matches at runtime. For example, if `prog` had two possible sub-commands `cmda` and `cmdb`, only one of those could be used at runtime. But then those sub-commands `cmda`/`cmdb` could have their *own* sub-commands as well (say `cmda` accepts a `cmdc` and `cmdb` accepts `cmdd`). Add to that, each sub-comamnd can also have their own arguments, so a full valid argument list is represented as a tree: prog |-cmda | |-arg1 | |-arg2 | |-cmdc | |-arg3 | |-cmdb |-arg4 |-cmdd |-arg5 |-arg6 And a valid use can be derived from that (i.e. you can't jump branches, only continue down the same branch): prog cmda arg1 arg2 cmdc arg3 ... Which actually ends up making it quite logical, when speaking about concrete examples (this vague arbitrariness makes it look confusing or less functional). But take `git` for example. If `git` had two sub-commands `branch` and `add` (each with their own sub-sub-commands and arguments) it wouldn't make sense to be able to do something like git branch -d &lt;name&gt; add remote [...snip...] Well, other than maybe super simple tasks to be done in series, but beyond that it gets very ambiguous. Especially when sub-commands have similar arguments or sub-sub-commands. I.e. what if `git` had a third sub-command `remote` and the `add` sub-command *also* had a sub-command named `remote`. Doing something like: git add . remote [...snip...] This would be ambiguous because is this `remote` the sub-command of `git` or `add`? Ok, that was waaaay more than I meant to write, and not directed at anyone cause I think I actually got off topic...so lets just call it "explaining out loud to myself" :) One last thing about enums since it was brought up, in clap they can be used as valid values for arguments using some clap macros, but that's about the extent of it right now... arg_enum! { #[derive(Debug)] pub enum Foo { Bar, Baz, Qux } } fn main() { let m = App:new("app").arg_from_usage("&lt;foo&gt; 'some foo'").get_matches(); let f = value_t_or_exit!(m.value_of("foo"), Foo); println!("{:?}", f); // You can only satisfy the &lt;foo&gt; argument using 'Bar' 'Baz', or 'Qux' } I'm working in baby steps :)
I learned a lot from this book, as a professional C++ developper.
Correct. And also, IIRC, are just a variant of B+ trees (I can't remember the precise details).
The problem is that word is &amp;str so input must live as long as closures. But that is not guaranteed. One solution is to give every closure copy of the slice: for word in words { let tx = tx.clone(); let word : String = word.to_string(); thread::spawn(move || { tx.send(word).unwrap(); }); } EDIT: Another solution is to make sure that input outlives spawned threads: use std::sync::mpsc::channel; use std::io::prelude::*; use std::io; use std::sync::Arc; use std::thread; fn main() { let mut input = String::new(); let _ = io::stdin().read_to_string(&amp;mut input); let (tx, rx) = channel(); let words = input.split(' '); let mut t = Vec::new(); for word in words { let tx = tx.clone(); t.push(thread::scoped(move || { tx.send(word).unwrap(); })); } drop(tx); } 
It's always tricky writing things strategically. You never want to burn too much time on pointless optimizations, yet you might want to allow for certain redesigns (e.g. optimizations) in the future and not write yourself into a hole. It feels like a paradox that you just have to "know" what the best course of action is, but I suppose that's just the intuitive nature of programming. :| But yeah, totally. Mainstream RDBMSes are total behemoths. There's almost no way I'll have the motivation to implement locking, let alone "file systems". The idea alone makes my head hurt. 
&gt; the first times ahhhh how fondly we'll look back on these days once we don't have to constantly update everything every single day...
Unicode case conversion can map one character to several, or combine several characters into one. The iterator API is about as good as you can do without making assumptions about how the caller is using/storing the result. Case conversion also depends on locale. And it's not the same as case folding, used for case-sensitive comparison. I don't know which operations are supported or planned for `String`, but it's a [pretty complex area](http://unicode.org/faq/casemap_charprop.html) that you don't necessarily want to bake into the stdlib.
I wonder if there is some combining character sequence where the base characters lower case form depends on what combining characters are attached to it?
&gt; The `unsafe` keyword makes code and security audits much more streamlined. If a segfault occurs in a Rust program, one can `Ctrl+F` for the word `unsafe` and investigate. Undefined behavior bugs are now shallow. The last sentence here dramatically overstates what Rust can guarantee, and doesn't follow from what's said immediately before. `unsafe` restricts which code could contain undefined behavior, but it doesn't isolate the *effects* of that undefined behavior. By definition, undefined behavior is unrestricted. A mistake in `unsafe` code can subtly corrupt the heap, leading to nondeterministic crashes much later in safe code. When this happens we use the same tools you'd use for C, e.g. Valgrind's memcheck. Or maybe it only happens on pathological inputs; then you might find it with [a fuzzer](https://github.com/kmcallister/afl.rs/). The simple syntactic rules around `unsafe` are no silver bullet. Furthermore, it's *really* hard to audit `unsafe` blocks in isolation. Often they interact to uphold certain invariants assumed by the safe code. If I give you a 100,000 line C program and tell you there's a heap corruption bug in one of *these* 500 lines, that doesn't actually make your life that much easier. You may have to understand the entire system to understand what one of those 500 lines is doing wrong. And it's not hard for a substantial Rust project to reach 500 lines of `unsafe` through FFI, performance tweaks, etc. Remember, your dependencies can corrupt the heap as well. Building auditable systems with `unsafe` code requires a whole lot of careful engineering. On the Servo team, we did a preliminary survey of security-critical bugs in Gecko and decided that Rust would have prevented about 50% of them. But, reducing the bug count by 50% is not the same as reducing the proportion of *time when your product is critically vulnerable* by 50%. For many purposes, an attacker only needs to find *one* bug. This is why defense in depth is so important, and it's why the Servo team is pursuing OS sandboxing, fuzzing, model checking, etc. alongside Rust's safety guarantees. I'm a big fan of language-based security, but there are many security experts who are *intensely* skeptical, and they're permanently in "gotcha" mode. We need to make realistic claims.
I was wondering if anyone has more information on how to do this: - how to say Higher instead of Answer::Higher in a pattern It was listed at the bottom of the article.
Not quite the same, but the usual example of a non-1-to-1 mapping is German lower case "ß" versus upper case "SS". There is an upper case version of that letter but it's [rather nonstandard](http://en.wikipedia.org/wiki/Capital_%E1%BA%9E). See [the Unicode case FAQ](http://unicode.org/faq/casemap_charprop.html) for more.
leave me alone
A small nit: You may wish to use `.read_to_string().unwrap()` rather than `let _ = .read_to_string()`. The former ensures that you don't miss the possible error conditions.
You really want to use an `if...else` for FizzBuzz -- match is intended for pattern matching, not arbitrary algebraic matching. Nevertheless, you can use a match for FizzBuzz like [so](http://is.gd/TuDRkK)
I didn't know you could do this! How very exciting! I have some `use` statements to clean up.
Throw some "if"s on those match arms! These are called guards. http://is.gd/sSIvYc &lt;-- working code http://rustbyexample.com/flow_control/match/guard.html &lt;-- relevant rustbyexample That being said, if/else just feels more natural for this kind of thing. Guards on matches seem like they exist for more complex things like destructuring and advanced pattern matching, but I assume it all compiles to the same thing though.
One way is to do this: _ if x % 15 == 0 =&gt; println!("FizzBuzz"), The underscore matches everything. It's followed by a guard, which is just that boolean expression you had before. Finally, notice the comma at the end of the line, you'll need that between each arm of the match. Edit: I agree with mdcox. :)
Sorry, I just didn't want people to go there! I should have left a note what I deleted.
I prefer [the following](http://is.gd/dihjgP) for FizzBuzz using `match`, I think it's a lot more of a direct translation of the requirements: fn main() { for x in 1..100 { match (x % 3, x % 5) { (0, 0) =&gt; println!("FizzBuzz"), (0, _) =&gt; println!("Fizz"), (_, 0) =&gt; println!("Buzz"), _ =&gt; println!("{}", x) } } }
edit: read /u/eddyb 's reply
This is cool. It did take me a second to realize what was going on though. Definitely required more mental effort than an if/else or guarded version for me. Do you have a background in ML or Haskell? It looks way more like the way I've seen people write Haskell than the way I write Ruby or JS.
Upvoted, I agree with this very strongly.
I agree, the if/else version is the most clear, I just think the version I posted is the nicest way to do it using `match`; using `match` with guard expressions is just a strange way of writing the `if/else` tree, and I thought that the version that /u/Manishearth posted looked a little clumsy as well. I don't have much of an ML/Haskell background, though I have dabbled in them. I have programmed professionally in Scheme, C++, C, Python, Ruby, Java, and Bourne shell, and dabbled in a lot of languages.
Good call. Thanks!
http://is.gd/dwzyvN works great, thanks! The second solution is interesting. If I understand it correctly: Because _t_ will exist until the end of the block, _input_ will not be freed until _t_ is freed. Is that right? edit: oh, i just saw that you are using a scoped thread. I was told in IRC those are broken by design at the moment.
Never heard that they are broken. Many examples use them. Do you remember *why* they are broken? Maybe you are referring to this issue? https://github.com/rust-lang/rust/issues/24292 The problem is not with the thread::scoped but with leaking objects in general in some situations. That is not the case with the example.
I can see a minor subset of users forgoing usage after a few errors. I finally worked the errors I was given here (again, all lifetime related). I could see someone who is just looking at the language for fun moving on to other pastures at that point. I'm evaluating the language for work at the moment so I need to work through some of these problems to get some prototypes finished to test with. Improved documentation would be excellent if Rust is selected and we have to onboard other developers to the language.
Awesome, I love that you took the time to do the writeup! I haven't taken a look at the source yet, but I want to tonight. This a neat idea and I like comparing how people tackle this problem in different ways. Edit: I'm guessing the reason for the no matching on expressions is because you're matching patterns, not expressions. You can add expressions using guards, like you did, but without those it's just a pattern.
That's wrong, `expr` is meant to be an rvalue and no borrowing occurs at all. Maybe you were on to something but "borrowed" is surely the wrong term to use. The difference is in rvalue scopes: any temporaries in `expr` will live for the whole duration of the `match` block (think `let id = expr in ...`) while temporaries in `expr` found on the RHS of `let` will only live for the duration of the initialization. Simplest example I can think of: use `&amp;vec![1, 2, 3][..]` in place of `expr`.
The compiler doesn't know that `v[1]` and `v[2]` are different items. It just sees a call to the overloaded `[]` operator in the `IndexMut` trait. As far as the compiler is concerned, the second call to the `[]` operator might do anything to the vector, including deallocating the memory behind `*a`. You can use [split_at_mut](http://doc.rust-lang.org/std/primitive.slice.html#method.split_at_mut) to get mutable references to disjoint sub-ranges of the vector.
I see, so the borrow checker is just as ergonomic as it can reasonably be, not necessarily right in every case, and thus we need workarounds like `RefCell` and `split_at_mut`. I guess I'm thinking about the borrow checker too religiously. Thanks, and thanks for the `split_at_mut` link.
DMC++ does use the incredibly fast [Optlink](http://digitalmars.com/ctg/optlink.html) but it is still quite a bit faster just at generating .obj files.
DMD is tuned for speed when doing debug builds. The idea is to make the edit-compile-debug loop as fast as possible. Turning the optimizer on makes DMD quite a bit slower, the idea being this is done relatively rarely and the programmer would be willing to spend more time optimizing in exchange for a faster release build.
I noticed stability attributes now give a compile time warning saying they will be removed soon...is there a replacement for them?
Thank you so much for this detailed write-up. I only understand bits of it at the moment, but I intend to digest this fully throughout the day. EDIT: This is really, really interesting information. Thanks. EDIT2: And I'd be super interested to hear about your language ideas if you ever make them public :)
I would disagree, I find the match version much cleaner because this is one of those cases where match is more concise and you exhaustively check for every case, although I would write it like this: fn main() { for x in 1..100 { match (x % 3 == 0, x % 5 == 0) { (true, true) =&gt; println!("FizzBuzz"), (true, false) =&gt; println!("Fizz"), (false, true) =&gt; println!("Buzz"), (false, false) =&gt; println!("{}", x) } } }
The idea is that all the features that are unstable will be moved into a "future" version of rust (not 1.0.0 in this case). The stable and "oficially" supported version of rust will not have unstable attributes, period. If you wish to use unstable features, you should use the nightly or alpha/beta for the next version (maybe 1.1.0 in this case?) which support unstable features (with the risk associated that your code might get broken by changes).
If my understanding is correct the stability attributes aren't meant for user code, but only for the std library. They are meant so that people know which features of the language are "done" and they can begin relying heavily on them, vs features that are still in flux. The main reason Libraries should instead offer a stable version through cargo and leave unstable versions on git. It's not intended for other reasons. If you want your library to use it's own stability attributes you should make your own as [compiler plugins](https://doc.rust-lang.org/book/compiler-plugins.html) for both the attributes and lints. This would mean that each library that has stability attributes would have to individually be told if you are working on the stable or unstable release, which is an advantage (you want to reduce the amount of libraries that you could accidentally be using in unstable/unsupported ways). Of course the issue is that compiler plugins are still unstable, so you could only do that on unstable branches. To that I can't really say other than: this is a 1.0.0 language, it's rare to have something as mature as rust is going to be at 1.0 (because it has years already) but the stabilization must be done slowly (since once a feature is done, it's done forever). I think that running things on rust-nightly will be common at first, until ver 1.1 or 1.2.
I'm building a relational language at work (in rust!). We found out a lot of things that you might find interesting. SQL is a mess, especially when it comes to grouping and aggregation. It's possible to express the same kinds of queries with a much simpler language. An example translation: SELECT ( SELECT name FROM artist WHERE album.artistid = artist.artistid ) AS artist, count(*) album_count FROM album GROUP BY artistid; for artist in artist: their_albums = (album in albums where album.artist = artist.id) yield artist.id, count(their_albums) `for row in relation` iterates over a relation. `(row in relation where constraints...)` returns a subset of a relation. Functions like `count` and `limit_by` operate on sets. `yield ...` returns rows. So far we haven't run into anything that's hard to express this way. There has been a ton of work recently on better ways of evaluating relational queries. You can get respectable performance without all the complexity of an optimising query planner. The underlying ideas are very simple and elegant but there isn't yet a good source for understanding them. The original papers (eg http://arxiv.org/abs/1210.0481, http://arxiv.org/abs/1310.3314, http://arxiv.org/abs/1404.0703) can be pretty obtuse. Frank McSherry wrote about a [similar algorithm](http://www.frankmcsherry.org/dataflow/relational/join/2015/04/11/genericjoin.html) and I [compared it](https://gist.github.com/jamii/77bff2ed93a7f339d9ff) to the papers above. [Cracking](http://www.vldb.org/pvldb/vol7/p97-schuhknecht.pdf) can potentially simplify query compilation too. Rather than having to specify indexes up front and then have the compiler choose which indexes to use, you generate a plan that calls into a simple API on the table and have the table adaptively build indexes as it goes to answer efficiently. I started writing up a [tutorial](https://github.com/jamii/make-you-a-database) on the subject but got sidetracked by, you know, actually doing my job. I hope to finish it once our own implementation has settled down somewhat.
Thanks for the input! What I said does over-promise what Rust can guarantee, so I'll tone this one down. I also never meant to claim that `unsafe` could trivialize all bugs or security exploits (it can't). My initial explanation was built on the false premise you described, on which I assumed unsafe blocks were basically self-contained. You're right, though: even if one knew approximately where the problem code was, it doesn't mean the effects are only undefined within the garden walls of an `unsafe` block. We still need tools like valgrind in 2015. To me, `unsafe` is an interesting feature because it self-documents all possible places where Rust's memory-safety guarantees _could_ be violated. If you're going to write `unsafe` code, then there needs to be some strong justification for it. Would it be correct to state that `unsafe` blocks generally attract more scrutiny, and hence have value in systems security?
Cross-posting for visibility since I need event organizers to email me stuff.
Yes, the current stability attributes were designed for the compiler only, and are tied to the release channels concept. They weren't intended for non-Stdlib code. It _is_ important for user code to have something, but those needs need to be taken into consideration when releasing something. This change was meant to happen earlier, but slipped through the cracks.
Really? I logged out and it worked. Go [here](https://encrypted.google.com/search?hl=en&amp;q=site:users.rust-lang.org+what+needs+to+be+explained+about+lifetime+parameters) and it's the first hit.
I agree that user-code should have something. But before we can do this macros and compiler plugin's need to be stabilized. Then you could have a "stability" plugin where each crate can mark the stability status of its things (and also have the ability to compile a "release" version with nothing marked unstable). The stability plugin could then expose a way to declare how stable each crate should be, something like `#[use-unstable(crate.mod.etc)` which allows using anything unstable that is on path or a child of it. It can probably be done already, but again you won't be able to use it on rust 1.0 because the library would use rust's unstable features.
This is not /r/playrust.
A lot of the work around [LMS](http://scala-lms.github.io/) is also very relevant eg [LegoBase](http://data.epfl.ch/legobase) specifies query operators in naive scala and then separately applies various optimisations.
No changelog because of time constraints?
(I keep it up to date, so it’s merely that it was *initially written* some time ago.)
A relevant link from the wiki: http://c2.com/cgi/wiki?SufficientlySmartCompiler
Yeah, hopefully more people can make it! One other person at this time has replied, so 3 is getting there! Do you have any coworkers or friends that would be interested?
Well, I don't think I know anybody else who'd want to come.
I would imagine there's not a lot of rush until 1.0 final.
Looks like the destructuring isn't being used as a proper coercion hint. As long as the `a`, `b`, and `c` fields are `Copy`, this *should* work. I suggest opening an issue on Github.
In general, for minor beta updates I think we will not update the changelog, since they will mostly be small patches fixing last minute bugs. We'll probably produce the changelog for the next release at the start of the new beta, then make final updates right before the release to stable. *This* beta update was unlike that since it pulled in all changes from the past two weeks, but I used the above logic any way to convince myself not to bother. The stable release will have a full changelog.
Thanks!
`.chars()` will return an iterator of characters. If you want to mutate the characters of a string I might recommend to collect that character iterator to a `Vec&lt;char&gt;`, mutate it there, and then change it back into a `String` with `.into_iter().collect()`. 
Yes, each element in a `Vec&lt;char&gt;` is a ~~full Unicode grapheme~~ Unicode scalar value. On the other hand, `String` and `&amp;str` are backed by `Vec&lt;u8&gt;` and `&amp;[u8]`, respectively, so they cannot represent multi-byte characters as a single element. Indexing a string is `O(n)` and mutating individual characters could possibly require reallocation, so it's not safe to do so from a fixed buffer (e.g. `&amp;mut str`).
Thanks for the clarification. That makes sense.
/u/Quxxy made the valid point that even `char` may not represent a full language character. The `.graphemes()` iterator yields string slices that each represent a full Unicode grapheme; however, this isn't exactly useful as most use-cases will have it yielding one-character strings.
Calling `.to_string()` on a string slice isn't the most efficient way of converting it to a string (this may change in the future). `.to_string()` goes through the formatting framework and incurs a non-negligible amount of overhead, when really you just want to copy the string slice directly into an owned allocation. Do this instead: let mut m: String = From::from(&amp;s[..pos]); Or (if on nightly): let mut m = String::from_str(&amp;s[..pos]);
Based on the arguments that I saw the package maintainer get into on some RFCs, I'm going to assume he doesn't want to maintain the package any longer. It probably needs a new maintainer.
`ToOwned` isn't in the prelude, so you have to import it to get `.to_owned()`.
That's true, but for me it chains better with other stuff.
Someone in /r/programming made it more readable: http://www.reddit.com/r/programming/comments/32zcqn/pdf_the_death_of_optimizing_compilers/cqg92zh
There's rust-beta-bin on AUR, I think /u/Kbknapp maintains it.
On the topic of visibility: I hate to sound like a broken record, but some people (me included) would appreciate it very much if the discourse forums were available via HTTPS. It's a mystery to me how you guys are fine with "auth cookies" and/or passwords being transmitted in clear. reddit is the only place I go for that reason. So, thanks for cross-posting. :)
Yeah, `slice` is for `&amp;[T]` or `&amp;mut [T]` which is a view into `Vec`. `&amp;str` is a view into `String`. Fundamentally, a `&amp;str` is the same as `&amp;[u8]` but it has a different set of methods because UTF-8 strings have to handle multi-byte characters. You can call `.as_bytes()` on `&amp;str` to view it as `&amp;[u8]`, but that's generally not very useful unless you're working on verified ASCII strings.
&amp;str is a slice of utf-8 characters. It often behaves like &amp;[char] but is stored as a memory friendly &amp;[u8]. Normal slices use a memory of len*size_per_element but &amp;str is different because characters can have different size.
A better example over iterator invalidation is: let mut x = Some(1); let z = &amp;mut x if let Some(ref mut y) = x { *z = None println!("{}", y) // uh oh! } Conceptually, aside from the memory unsafety caused by enums, having the ability to mutate things from multiple places at once in a large codebase is almost as bad as having mutable pointers from different threads -- one subconsciously writes code assuming that the only mutator is the local one.
Could you explain what you’re trying to achieve, and why you’d need to change a character in the middle of a string? As other comments have pointed out, [*a character*](http://www.unicode.org/glossary/#character) is not concept that’s easy to define in Unicode, so there may be different answers for different use cases.
`&amp;str` has the same memory representation as `&amp;[u8]`, but guarantees that its contents are well-formed in UTF-8. The `[u8]` methods don’t necessarily preserve that guarantee, so you can’t use them directly. However you can use the `.bytes()` method to get a `&amp;[u8]` from a `&amp;str`.
This can probably be done through refinement typing...
I primarily come from a Haskell, Python background and I was trying to compare how I might do string manipulation in Rust. I was not trying to achieve anything specific. Was just trying to learn how to work with strings/&amp;str in Rust.
We're seeing some of this presumed dialog in the form of compiler hints, e g, gcc has `__builtin_expect` indicating whether the compiler should optimise for a branch being taken or not being taken. Maybe we'll see some of this in Rust too one day. Also, it would be nice if there was a way to mark code as hot or cold - the hot paths would be optimised for speed and the cold paths for size.
The error message is complaining about the assignment to `b`, not use of the `a` value. Slicing with `a[x..y]` is really directly the returning the memory location of the elements `a[x]` through `a[y]`. This chunk of memory has type `[i32]`: some number of `i32`s. To get a `&amp;[i32]` one can manipulate/assign, one has to take the address of that memory location, i.e. `&amp;a[1..2]` in that case. This is somewhat similar to how `a[1]` yields a `i32`, but `&amp;a[1]` yields an `&amp;i32` pointing to the `1`th element of `a`. (`a[x]` is sugar for [`*a.index(x)`](http://doc.rust-lang.org/nightly/std/ops/trait.Index.html#tymethod.index) (or the `IndexMut` equivalent), whether `x` is a plain index or a `1..2` range or whatever.)
I don’t know how strings work in Haskell, but in Python (ignoring some details) they’re a lot like `Vec&lt;char&gt;`, so it’s easy to manipulate individual `char`s. Rust’s strings are UTF-8 which is “variable-width”, so only transformations like [`make_ascii_lowercase`](http://doc.rust-lang.org/std/ascii/trait.AsciiExt.html#tymethod.make_ascii_lowercase) that don’t affect the number of bytes can be done in place.
&gt; Changing them in-place is dangerous because you can't guarantee that the new character is actually going to be the same length. You can always use [`len_utf8`](http://doc.rust-lang.org/nightly/std/primitive.char.html#method.len_utf8) to check if the ~~characters~~ codepoints are the same length, or if you want to get the length based only on the first `u8` you can use this: fn utf8_length( value: u8 ) -&gt; usize { if (value &amp; 0b10000000) == 0 { 1 } else if (value &amp; 0b11100000) == 0b11000000 { 2 } else if (value &amp; 0b11110000) == 0b11100000 { 3 } else if (value &amp; 0b11111000) == 0b11110000 { 4 } else { panic!( "Invalid UTF-8!" ); } } 
The point is that you can't guarantee it *in general*. Yes, there are specific circumstances under which it works, but that's true of a lot of things in life. And anyway, that code is misleading: it only works for characters that are comprised of a single code point, which just goes to reinforce my point that text is hard and being clever about it is a *really* terrible idea. :D
&gt; The programmer using such a system will write his beautifully-structured, but possibly inefficient, program P; then he will interactively specify transformations that make it efficient. i'd always thought a more functional approach would suit this, however haskell etc seem too far from low level optmization... this is kind of why i liked some aspects of rust originally i.e. being low level but a bit cleaner, a bit more functionally flavoured, with nicer lambdas in particular. Maybe the old do notation could be reconsidered after 1.0..
Pretty sure I saw Docker running VirtualBox in headless mode in the process list.
Short version: you're telling the compiler `b` is of type `&amp;[i32]` but the expression on line 2 is type `[i32]`. So either add `&amp;` to the second line `&amp;a[1..2]` or remove it from type of `b` (`let b: [i32]`)
Aha. Got it. I mistakenly thought a[x..y] expression returns &amp;[T]. But it actually returns a subset array - [T]. But why does the compiler prevent any direct assignment of the a[x..y] expression? let b:[i32] = a[1..2]; //Compile error
Yep. QuickCheck is now dual-licensed too. https://github.com/BurntSushi/quickcheck/blob/master/COPYING
There is a `multirust` package on the AUR that I use and recommend. Once it's installed, just do: multirust update Now you have both the `nightly` and `beta` Rusts installed! You can switch between them: multirust default nightly multirust default beta
Probably. Depends on when exactly it ships (if it is May 15th, which is the last date I heard mentioned, I'm going away then, so no).
So to be clear here, there are three kinds of contiguous storage: * array: `[T; n]` - on stack, fixed size * vec: `Vec&lt;T&gt;` - on heap, dynamic size * slice: `[T]` - some kind of reference to contiguous memory of *runtime* (but fixed) size *somewhere* Critically `[T]` is *unsized*. It is not a type that can exist on its own. It must live behind a pointer. This produces the following types: * shared slice - `&amp;[T]` * borrowed slice - `&amp;mut [T]` * owned slice - `Box&lt;[T]&gt;` The problem at hand is that the slicing/indexing notation performs an automagical *deref*. It returns &amp;/&amp;mut [T], but then derefs it so you have a `[T]`. To put it back to an &amp;/&amp;mut[T] you need to make a reference to it. Hence `&amp;a[1..2]`. This actually turns out to be super convenient because you can hook into either `Index` or `IndexMut` with `&amp;mut a[1..2]` or `&amp; a[1..2]`. The compiler will pick the right trait. 
&gt; You could always reimplement your own MyUnsafeCell too, I suppose? And then both MyCell and MyUnsafeCell could just #[derive(Copy)]. You cannot reimplement `UnsafeCell`. It is a language item. If you have aliased mutable references to something that isn't `UnsafeCell`, that's UB in Rust. &gt; Side note - the whole thing would be more flexible if we allowed fixed array initialization for types implementing Clone rather than Copy. This would be unsafe, because a non-`Copy` `Clone` implementation could panic before the array was completely initialized. &gt; If I'm going to write bigger projects and have to decide between C and Rust, it's all the pointers and references that is my biggest problem with Rust actually. This is one example of where, if it was C, I had just put a pointer there and it would have worked just fine. So if you can solve the crossreference issue I would be appreciated. :-) I started working on this yesterday but got sidetracked. I will probably post a fixed solution later today.
Yes it does, I corrected this in the video's comment. It's good that it's easy to forget though, as plenty of complexity is hidden that way.
I am not trying to do anything specific. Trying to learn Rust and its semantics.
A value of type `&amp;[T; n]` is able to be *coerced* to a value of type `&amp;[T]`. This coercion is automatically inserted into the generated code by the Rust compiler. The design for how coercions work is laid out here in a recent [RFC](https://github.com/rust-lang/rfcs/blob/master/text/0401-coercions.md), though note that design is not 100% implemented yet. But the big idea is: It is always possible to convert the reference of type `&amp;[T; n]`(which is a single-word pointer that just points to the data itself, since the length `n` is embedded in that type at compile-time) *into* a reference of type `&amp;[T]` (which is a two word *fat* pointer: it has the pointer to the data itself, but also carries around an extra word for the *length* of the data being pointed to).
Add a Copy bound, like this: http://is.gd/mw0keK
Could you please tell me why is that trait constraint required?
If T is not [Copy](http://doc.rust-lang.org/std/marker/trait.Copy.html), you cannot move out of the array as you are doing. You're writing generic code, so you need to express that T is Copy to the compiler.
You're immutably borrowing slices of `T`. The resulting `Vec&lt;T&gt;` needs new instances of `T`, because the old ones are not moved or consumed (they cannot be, because they're immutably borrowed). So they need to be copied somehow from `v1` and `v2` to `v`. If `T` is `Copy`, then your solution works. Another option is to require `T` to be `Clone` (which is less of an restriction), and then you need to call `v1[i].clone()` to get the new item to push into `v`.
&gt; A few months ago, I filed a bug for Cell to implement Copy, which was closed. The rationale was that usually you do not want to copy a Cell. Btw, even if `Cell` does not implement `Copy`, I wonder if it would mean any trouble if `UnsafeCell` did? To me it seems to bring advantages without disadvantages, since `UnsafeCell` is just a building block you shouldn't use except inside other cell-like types (which can then decide themselves if they want to be `Copy` or not).
What's ugly or not is highly subjective, what do you like this? match (v1_len, v2_len) { (0, 0) =&gt; return Vec::new(), (_, 0) =&gt; return v1.to_vec(), (0, _) =&gt; return v2.to_vec(), _ =&gt; (), }; let mut v: Vec&lt;T&gt; = Vec::with_capacity(v1_len + v2_len); /* etc */
&gt; In general, if a struct is both Copy and !Send, wouldn't it be safe to have multiple &amp;mut pointers to it? Correct (well, that isn't safe anyway, but I digress). Otherwise Rust assumes that they aren't aliased (think `restrict` in C) and passes that information on to LLVM. As Rust takes advantage of this more and more, it will become more and more important. &gt; This does not seem too hard to solve safely - just keep track of how many items you've initialized, drop them, then continue panicking? This would slow down the general case. Rust is not big on inserting runtime checks for safety, especially for language features.
I would very much like `UnsafeCell` to be `Copy`... if you want to try filing a bug for it, please do :)
Just to see if I'm understanding correctly, you're suggesting something like this? struct CellRef&lt;'a, T&gt; { ... } fn from_mut&lt;T&gt;(&amp;mut T) -&gt; CellRef&lt;T&gt; { ... } impl&lt;T: Copy&gt; Copy for CellRef&lt;T&gt; fn get&lt;T: Copy&gt;(CellRef&lt;T&gt;) -&gt; T { ... } fn set&lt;T: Copy&gt;(CellRef&lt;T&gt;, T) { ... } // I think you could also have: fn from_cell&lt;T&gt;(&amp;Cell&lt;T&gt;) -&gt; CellRef&lt;T&gt; { ... } (with `Copy` potentially being loosened to `Clone` for both `Cell` and `CellRef` if we find a way to do so safely - not sure what exactly you have in mind) If so, I like it. Needs more thought, obviously, but...
It's perhaps less readable, but the _ case can be rewritten as: let mut v: Vec&lt;T&gt; = Vec::with_capacity(v1_len + v2_len); let (mut v1_i, mut v2_i) = (0, 0); while v1_i &lt; v1_len &amp;&amp; v2_i &lt; v2_len { v.push(match compare(&amp;v1[v1_i], &amp;v2[v2_i]) { Ordering::Less|Ordering::Equal =&gt; { v1_i += 1; v1[v1_i - 1] }, Ordering::Greater =&gt; { v2_i += 1; v2[v2_i - 1] }, }); } for value in if v1_i &lt; v1_len { &amp;v1[v1_i..] } else { &amp;v2[v2_i..] } { v.push(*value); } with the same functionality. Edit: A special case for Ordering::Equal isn't necessary-- we can just push/index whichever and we'll catch the other one the next time around/when they stop being equal. Also, there's no need for two separate if statements; in order for the while loop to exit, either v1_i = v1_len or v2_i = v2_len. If it isn't one than it's the other, so an if/else statement suffices. Because of the way statements like that work in Rust, we can actually just write one for loop.
Thank you so much for the detailed answer and really getting to the bottom of things. Now I have to read up on type coercion and fat pointers :)
&gt; Since it's a fundamental design decision that can't be changed later I don't think "optimize later" is useful advice here. I don't think you're looking at this the right way. Why would you blame the design for being slow before scrutinizing the implementation? Or usage? A few cycles' difference between the two approaches might not be negligible when repeated a thousand times, but then you have to see first if you can eliminate those few cycles, or a good chunk of those repetitions. Any API can feel slow if it's used wrong. 
Except this method is probably going to be used as part of a mergesort, and so a precondition of the method is that both inputs are sorted.
Maybe they are, but OP didn't mention that (or I overread it). And I don't want to just assume.
Ah my mistake, that's what I get for not testing it. Thanks for the correction :)
It seemed to me that this code would already only be useful for individual arrays/vectors that are themselves ordered, so that would never be an issue.
Your analogy doesn't really work because if you have a `fn sort&lt;T: Ord&gt;(&amp;mut [T])` then you can replace the sorting implementation without breaking the API contract (ignoring stable vs nonstable sort). That's what I've been talking about all along WRT "optimization".
What's the problem with `Pattern`?
Just a note: it would be really awesome to add `byte` / `be` / `le` keywords to podio, as I imagine a lot of people are going to be searching for those terms.
A bunch of talks could be nice.
&gt; What makes `Pattern` horrible? It's way too complex. Don't get me wrong - I find that the vast majority of Rust's stdlib is really well designed; dealing with the `Pattern` was the **only** time I genuinely thought "damn, this sucks", and decided that it would be faster and simply less painful to just implement my own pattern trait than dealing with what is in the stdlib. I'd say that the worst thing about it is that the same `Pattern::Searcher` is supposed to be used for searching **both** forward (`next`) and backward (`next_back`); it's not even clear how those two modes are supposed to interact, if they should at all, and if they shouldn't then they shouldn't be in a single searcher. Implementing your own `Pattern` is pretty painful. (I tried!) What I did was to create a simple trait like this: pub trait StringPattern { fn pattern_match( &amp;self, slice: &amp;str ) -&gt; Option&lt; usize &gt;; fn pattern_bounds( &amp;self ) -&gt; (usize, Option&lt; usize &gt;); } The `pattern_bounds` tells you the `(minimum, maximum)` length of haystack required for the pattern to match and `pattern_match` tries to match the pattern to the haystack, returning how many bytes did match. (Ideally `pattern_match` should be able to also return how many bytes to skip in case there is no match.) While probably not perfect (e.g. I didn't put any thought into whenever it can support [more advanced search algorithms](https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm) than simple char-by-char bruteforce) it works, is fast enough, is simple to understand, and implementing it is trivial. &gt; What kinds of extensions have you written? Would you consider releasing it as a library on crates.io? I have 1k lines of generic string extensions and over 1k lines of extensions dealing with the (real world) language I'm dealing with. The generic extensions could potentially be released on crates.io (not sure if anyone would care?), after being cleaned up a little and perhaps extended in a few ways. As to what I have implemented - for example, when processing large amounts of text I do not want to be making throwaway allocations all the time; one of the things I need is a search and replace function - sure, there is [`replace`](http://doc.rust-lang.org/nightly/std/primitive.str.html#method.replace) in the stdlib, however it always allocates a new string. My search and replace function looks like this: fn gsub( self, aux: Option&lt; &amp;mut String &gt;, src: &amp;str, dst: &amp;str ) -&gt; CowString&lt;'a&gt; This trait is implemented for `&amp;'a str`, `String` and `CowString&lt;'a&gt;`; the behavior of the `sub` function is as follows: 1. If no substitution will be made then it just returns `self` as-is inside the `CowString`. 2. If a substitution will be made: 1. If the `src` and `dst` are of equal length and `self` is a `String` then the `self` is mutated in-place and returned. 2. If `aux` is `None` then a new `String` will get allocated and returned. (Just as stdlib's `replace`.) 3. If `aux` is `Some` then the result will get saved in the `aux` and returned, but before returing: 1. If `self` is a `String` then `self`'s buffer will get swapped with `aux`'s. 2. if `self` is not a `String` then `aux` will be set to `String::new()`. Basically it tries **very** hard to not allocate memory unnecessarily, but otherwise it works exactly like stdlib's `replace`. I've also implemented Ruby-like indexing (e.g. `0..-2` excludes the last character; convenient for porting my Ruby code to Rust), more substitution functions (substitute only one time, substitute a character for a character, substitute with a lambda), cropping (drop X characters from the front and Y from the back; again, tries to avoid reallocation if it can), appending, my `StringPattern` trait, and some other minor things.
`str` is a special type. It represents a sequence of bytes that holds a valid UTF-8 encoding. It's distinct from the `[T]` family of types, which are also called slices.
I don't know enough personally about the design constraints on `Pattern`, but /u/Kimundi would probably be able to better respond. I very strongly suspect that it is covering cases you haven't considered. Either way, filing an issue with your comment here and cc'ing `kimundi` seems like a good idea. &gt; Implementing your own Pattern is pretty painful. (I tried!) I wonder if `regex` is at fault for this. I know Kimundi carefully designed `Pattern` so that it could handle regexes, which have their own interesting constraints. I agree that [implementing `Pattern` can be tricky](https://github.com/rust-lang/regex/blob/master/src/re.rs#L987-L1024). It took some careful thought to [come up with the corner cases to test](https://github.com/rust-lang/regex/blob/master/regex_macros/tests/tests.rs#L140-L173). &gt; Basically it tries very hard to not allocate memory unnecessarily, but otherwise it works exactly like stdlib's replace. Your replace function looks great! Certainly, the `regex` shootout benchmark could benefit from it. [A lot of time](https://github.com/rust-lang/regex/blob/master/regex_macros/benches/shootout-regex-dna.rs#L101-L103) is spent allocating new strings and throwing away old allocations. Limiting this to one additional allocation and swapping I bet would be a nice improvement! Your other stuff sounds very cool. I know it's a lot of work to clean up code and release it, but I'd encourage you to do so. :-)
Seems like you'd want to start with as high a level of abstraction as possible and work to more specifics from there. So maybe the way to go would be to state required properties of the result set and input set, then somehow navigate the solution space based on the capabilities of the target hardware. Giving a specific algorithm like quicksort is perhaps already making assumptions about the underlying hardware - the number of cores, the organization and accessibility of memory, etc. So maybe quicksort could only emerge during the hardware specialization phase; you wouldn't be able to specify it during the requirements phase, where you only state that elements ought to be sorted. 
It would be even better if it could optionally display input and/or output values to the method.
Sorry, I'm not sure what you mean. You can't reinterpret `&amp;str` as `&amp;[char]` because their elements are different sizes.
Nice! This is exactly what I need right now.
I tried to address this with &gt;While a sorting algorithm can be changed easily, an API cannot. As such I think it's important to realize that the design of an API *can* and will affect its performance. I believe that in the C/C++ world it's well understood that APIs constrain your possible optimization.
If there's enough interest, it would be great to get a few talks from people about their projects written in Rust/experiences/views from other languages perspectives. Other suggestions welcome, of course! Failing that, the plan would most likely be to sit in a pub and befriend local Rustaceans [that would probably be the plan anyway, just with added talks].
I believe the launch date is the 15th, so if there is enough interest, it would happen that evening.
As far as I can see that's not correct: you're discarding half the zipped values (only taking the biggest of el1 and el2, unless they're equal then you take both). The original code is merging sorted vecs into a sorted vec (to implement a mergesort or something similar)
/u/LousyBeggar probably has the best answer for this case, but in general if you still need to have the match expression consider writing a function for the last case. This looks quite nice to me: match (v1_len, v2_len) { (0, 0) =&gt; Vec::new(), (_, 0) =&gt; v1.to_vec(), (0, _) =&gt; v2.to_vec(), _ =&gt; merge(v1, v2), }
Indeed, it is incorrect.
Thanks for you help, but that was not the problem. `foo` and `bar` reside directly under the root module. The problem must be that I'm doing something wrong with the `use bar::*`. When I remove that line, both errors disappear and [everything works](http://is.gd/dsjFu6).
The feature annotations are entirely for people working at the edge, adding things to the language or making the risk of using something that isn't stable. The alternatives to feature gating is not having a feature until it is done (untenable), compiler flags for each feature (slow), or having it in the standard library but telling people that it's not yet back-compatible (untenable). Each and every annotation in rustc has a use, and the alternatives either do not exist, or would involve adding new keywords to the language.
There is no immediate replacement. I’m just speculating, but since it was already stable for some time, the chances are good that it ends up being in 1.0.
And what about other annotations such as `#[derive(PartialEq, PartialOrd)]` ?
I've seen much weirdness with glob import. Try importing everything explicitly and see what happens (can't test, at work).
Those can save an amazing amount of boiler plate code. Particularly for the encodable and decodable traits.
That works definitely, I tried it. There are however so many symbols, that I'd rather avoid that.
While I have great hopes for refinement types in future versions of Rust, I'm somewhat unconvinced that they'll be helpful for directly optimizing code (as opposed to proving to the compiler that an existing optimization is safe and/or semantics-preserving).
If your language needs annotations to express something would either be too verbose or complicated to express natively then that's a failing in your language -- clogging up those holes with an annotation "meta language" justs makes your code a frankenstein creation, i agree with sentiment expressed in the following article on java's abuse of annotations: http://blog.jooq.org/2015/04/15/how-jpa-2-1-has-become-the-new-ejb-2-0/
&gt; If your language needs annotations to express something would either be too verbose or complicated to express natively then that's a failing in your language That's a good point, I'd like to see some of the frequent Rust attributes (e.g. `derive`) to be elevated into first-class language constructs if only to make the program look nicer in the editor. &gt; i agree with sentiment expressed in the following article on java's abuse of annotations: http://blog.jooq.org/2015/04/15/how-jpa-2-1-has-become-the-new-ejb-2-0/ To this I would like to point out that Rust attributes are nowhere near the Java annotations. The Java annotations are mostly the runtime (or bytecode enhancement time) artifacts targeted at third-party libraries. As such they are a source of runtime errors and weak IDE support. Rust attributes, such as `derive`, are a part of the core language. They work and are checked at compile time and IDEs will have no problem knowing what `derive` is. Indeed, if you would want the functionality of the Java annotations in Rust then you'd likely be disappointed, for I think there's no such a feature yet in the language. So the only real concern with the frequent Rust attributes seems to be the "sharp" syntax.
I'm not familiar with the rules of /r/playrust, but I don't think that post would be very constructive there either :o)
You can just get rid of the else all together: http://is.gd/rTVTfm As to why it's complaining about if and else having different types, it's because if blocks can also be expressions, which lets you do stuff like `let x = if something { 1 } else { 2 }` and in these circumstances the two branches can't have differing types.
if/else are expressions in rust not statements... if divisor == 0 { // Division by zero triggers a panic //panic!("division by zero"); println!("just a test"); // No result, no return value. If this branch executes you don't have anything to return } else { dividend / divisor }
You can definitely `use` a module by itself. This seems like it's almost certainly a glob-related bug, as you noted. If you need a quick workaround, your example appears to work if you move the `use` into `main()`: http://is.gd/ek5wBQ.
In your else arm of the if statement you are returning an int, in the if arm you are returning nothing, i.e. (). To fix this you can put in a 0 after the println!("just a test");. Rust enforces the same type for each arm for consistency, otherwise it would have to construct a new type such as an enum for each arm's return type. Probably not what you want.
And the reason that this isn't an annoying restriction is that you can always make the type of an expression be `()` by just including the trailing semicolon.
Right now, no, you need to have a chunk of contiguous memory lined up beforehand. I've also been doing [some work](https://github.com/TyOverby/unreliable-message) with UDP recently, specifically the fragmenting and re-building of messages.
Many thanks!
The problem is that im not exactly sure how big this data will be, i just gave that range as an example, I should have been a bit more clear.
I looked through their front page, and missed the crates integration. If I had noticed, I'd have just used that. However, it turned out to be neat getting to use hyper for more than just contrived examples and theory. 
If you think about it, this can never work. You're trying to make borrows of a value escape into that value itself. However, the value needs to be unborrowed when it goes out of scope so it can be dropped, since dropping it while borrows exist would be illegal. No matter how you cut this, if the compiler allows you to do this, then it's violating memory safety. ~~Besides, even once you got this to work, you wouldn't be able to move the value out of the function, since it contains references to the function's stack frame. So you're not "making the guards live as long as the value".~~ Edit: I get what you mean by making the guards live as long as the value now. You don't want to be able to move the value around and have the guards move with it, you just want the guards to be hoisted into the value's stack frame from a nested stack frame, which is reasonable. The only way I can think of to do it is to have the semaphore passed into `new`, so that it can have its own independently-tracked lifetime. There's no way to really do this from inside `new` that I can think of. http://is.gd/dTYJAe
Yes. with_keys is how you seed the hashing algorithm. All `SipHasher::new` does is call `new_with_keys` with two random values.
Ok, thanks. Why does it take 2 values instead of 1?
If I apply this to the unreduced example I get a problem with the life time of the semaphore. Is there way to combine it with &amp;mut self safely? http://is.gd/0rALDc
Only by putting the `Semaphore` in a separate, shared borrow with a distinct lifetime: http://is.gd/dTYJAe This is the only way I can think of.
Awesome! Ill email /u/brson now to see what he thinks :D Do you have anyone that you could bring along?
Regarding using hyper: if you start seeing that people would like to chose different Clients, you could create a trait, twilio::HttpClient, and implement it for the popular ones (or just hyper or whatever). Then, someone who wishes to supply a different Client just needs to implement the trait. 
Though it's marked unstable. Could copy the implementation into a local file, if you wanted to use it with beta. 
OK, that makes sense, I hadn't thought about that. I was thinking about exposing the internals for parsing, request validation, and such as well, but given that it grabs certain headers, etc, it would end up being pretty annoying to work with. If any future HTTP libraries(that get traction) have similar concepts, your suggestion sounds like it would let people use it pretty fluently, which is nice.
Thanks, that's what I was looking for. Any idea why the name is `connect` instead of `join`?
I don't agree. Lots of functions are marked unstable because of not wanting to commit to an API that might not be future proof. Copying these locally can solve that problem if you need your library to work with beta/1.0
It can't in practice be much bigger than that due to the [Maximum Transmission Unit](http://en.wikipedia.org/wiki/Maximum_transmission_unit) which over the internet does typically not exceed 1500 bytes,
`windows` for instance is one of the methods I'd like to be able to use on `&amp;str`
I'm confused? `convert` is available in beta? Or are you saying, `convert` doesn't cover what you want?
You don't have to in this case. SliceConcatExt is in the prelude. Its methods are stable which makes them usable on beta.
FYI, itertools has a `.join(separator)` for iterators too.
Probably not what /u/genbattle was referring to, but `convert` can't do generic number conversion.
It's possible some of my coworkers might join.
&gt; Is this really idiomatic Rust code? It's comparable to using `fromJust` in Haskell. I'd probably say that OP's code uses "poor man's error handling" which loosely translates to "crash the program on error." It's not an invalid approach, but not ideal either. Note that `unwrap` isn't always bad. On occasion, the surrounding invariants of the code guarantees that `unwrap` will succeed (or there is a bug in the code). In those cases, an unwrap can be just fine. (Probably `expect` is better.) It would be instructive to convert OP's code to proper error handling. Having a side-by-side diff would be really nice. I bet it wouldn't be too big with `try!` and `From` and `Box&lt;Error&gt;`.
Rust very badly needs a scanning library aka fscanf in C. Interestingly enough Java also went along for many years without a scanner library. We had to do the very same thing to read input from files (read line, split and parse).
ahh BufferedReader
We can get rid of a few unwraps and make our computation dependent on the success of the parsing of the lines: use std::io; use std::io::prelude::*; fn main() { let mut reader = io::stdin(); let mut b1 = String::with_capacity(16); let mut b2 = String::with_capacity(16); reader.read_line(&amp;mut b1).unwrap(); reader.read_line(&amp;mut b2).unwrap(); let result = b1.trim().parse() .map(move |x : u32| -&gt; u32 { b2.trim().parse() .map(move |y : u32| x + y).unwrap() }); println!("{}", result.unwrap()); }
Then if that function is found to be in some way broken you'll never get an update because you're using your own stuff.
The first needs higher kinded types, and isn't currently expressible with our type system. `Read` represents a more general concept than `BufRead`: the second is buffered. If you want to read a line at a time, you'll need a buffer...
I will admit this is one thing I really don't like about rust... the tendency to encourage long lines like this. Yes, I know, you're not forced to write exactly this... You can separate it to other lines (and you kind of should), but I miss the relative simplicity of int i; scanf("%d", i); and the fscanf variant.
OK, now using: pub fn agencies(&amp;mut self) -&gt; io::Result&lt;Vec&lt;Agency&gt;&gt; { let file = try!(self.archive.by_name("agencies.txt")); let mut txt = String::new(); try!(file.read_to_string(&amp;mut txt)); let data = csv::Reader::from_string(txt); data.decode::&lt;Agency&gt;().collect::&lt;Result&lt;Vec&lt;_&gt;, _&gt;&gt;() } Getting: src\feed.rs:35:5: 35:59 error: mismatched types: expected `core::result::Result&lt;collections::vec::Vec&lt;feed::Agency&gt;, std::io::er ror::Error&gt;`, found `core::result::Result&lt;collections::vec::Vec&lt;feed::Agency&gt;, csv::Error&gt; ` (expected struct `std::io::error::Error`, found enum `csv::Error`) [E0308] src\feed.rs:35 data.decode::&lt;Agency&gt;().collect::&lt;Result&lt;Vec&lt;_&gt;, _&gt;&gt;() ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ From which I gather that the error types aren't quite matching up. I thought I could just pass a second type argument to io::Result to specify an error type, but no luck. Based on [this example](https://github.com/BurntSushi/rust-csv/blob/master/examples/nfl_plays.rs) but obviously I'm trying to return the vec from a method. Thanks.
Generalized `do` notation does, in my understanding. I'm not familliar with Scala here, so maybe I'm wrong.
`io::Result&lt;T&gt;` is an alias for `Result&lt;T, io::Error&gt;`, so it will expect only one type of error. You can define your own error type that includes both `io::Error` and `csv::Error` as variants: pub enum Error { Io(io::Error), Csv(csv::Error) } impl From&lt;io::Error&gt; for Error { fn from(error: io::Error) -&gt; Error { Error::Io(error) } } impl From&lt;csv::Error&gt; for Error { ... or try to convert one into the other: io::Error::new(io::ErrorKind::Other, my_csv_error) //Tremendously untested
I'm interested -- never helped organize a launch party, but if it seems like we can get together some people, I wouldn't mind helping out if needed. Do share more details or PM me if you think this is something that can happen.
I appreciate you doing this and the code looks clean. But, here's something I have to say. This is 2015. We should not be writing synchronous HTTP clients. In a recent project I had to use Plovio SMS API. At times these calls can be slow. I don't know if hyper supports reactive programming. But that is the direction we should be going.
Interestingly, Rust is flexible enough that you could code a better `scanf` in it, probably with procedural macros.
udp packets can be fragmented, so MTU should not limit max udp packet size, which is 65,507 bytes.
Just allocate big buffers. It's 2015, we have lots of RAM. Also, it's virtual memory. You could alloc 64K but if you only ever access the first 4K then the OS won't actually waste those additional never-used pages.
Yes, in theory. In practice you cannot rely on it over the internet.
&gt; why do you use `Rc&lt;Box&lt;Animal&gt;&gt;` and not just `Rc&lt;Animal&gt;`? `Box` because I have store it in a vector (to make it `Sized`). `Rc` because (in a different project), I have to store references to the same thing in multiple vectors.
Yes, and I'm willing to help. Feel free to PM me.
The reason for gating them *is not* fear of bugs, but rather that Rust doesn't want to stabilize those things. As I understand it, copying functions into local crates is pretty much the intended behavior, because you get the stability Rust isn't able to provide (Your program will compile tomorrow). **EDIT**: Also, there's not much you can get wrong with a `.join` function.
PM me as well with details, I can assist or just hang.
This is neat! I found Elm's graphics API much more intuitive and easy to use than Canvas. I was going to start writing a basic charting and dataset visualization library for Rust. I think I'll base it off of this :)
Thanks! So can I rephrase this statement: type RcAnimal&lt;'a&gt; = Rc&lt;Box&lt;Animal + 'a&gt;&gt;; as "Whatever the lifetime of a reference contained in an Animal may be (call it `'a`), it better be bigger than the lifetime of RcAnimal." ??
The simplest way to fix it is to return `Vec` instead of `Iterator` and add `collect()` call after `map`. The issues that you are facing trying to return `Iterator` arise from the fact that iterators are lazy, which means that particular iterator that you will return from your function must hold all of the intermediate values which are necessary to compute further elements and that means that iterator's type is depended on what computations you are making inside your function. There is a proposal to add possibility to compiler to automatically infer return type without the necessity to specify it explicitly but it is not yet implemeneted. As a workaround you can use trait object, that is wrap returned iterator in a `Box`. Other problem is that csv reader will be destroyed at the end of the function and compiler will not allow you to keep any references to it while iterator would need such reference. Nevertheless it is possible to make it work, but if you don't need to read giant files which do not fit in memory than it probably won't worth it, just use a `Vec`. &gt; that will only differ in a) the filename and b) the type I want to deserialize to, can I use a macro to generate these functions? for (a) use function argument, for (b) - generics. And please, try to make more informative titles instead of this nonsense. 
That's a long standing bug with macros, the workaround is: macro_rules! expr { ($x:expr) =&gt; ($x) } // HACK macro_rules! tuple_index { ($tuple:expr, $idx:tt) =&gt; { expr!($tuple.$idx) } }
Struct variants used to be a feature (behind a feature gate `#![feature(struct_variants)]` or something like that), but I haven't tried using them in a while, so I'm not sure if they're still around. You could also box a trait and use a trait object so long as each of these types has common functionality and you're OK with using boxes. Or just implement the functionality on the enum itself. 
This code works for me (I'm on `rustc 1.0.0-nightly (00978a987 2015-04-18) (built 2015-04-19)`) enum TestEnum { DataA { f: String, l: String }, DataB { n: String }, } fn main() { let x = TestEnum::DataA { f: "Maximus".to_string(), l: "Hardcorion".to_string(), }; let y = TestEnum::DataB { n: "Maximus Hardcorion".to_string(), }; print_data(&amp;x); print_data(&amp;y); } fn print_data(data: &amp;TestEnum) { match data { &amp;TestEnum::DataA { ref f, ref l } =&gt; println!("{}, {}", l, f), &amp;TestEnum::DataB { ref n } =&gt; println!("{}", n), } }
Primary is definitely English! Sometimes we get discussions going in Danish but we always try to keep everything as accessible for everyone as possible. I'm not very good at Danish myself and it's never been a problem. People are usually very considerate and switch to English as soon as someone non-Danish speaking wants to join a Danish discussion.
Yeah, it would be good to see better async support in Rust. It seems that the standard libraries have focused on sorting out sync I/O support, which itself is going through a lot of changes. It'd be nice to have a simple system of wrapping sync stuff in a promise, even if it used native threads under the covers.
http://doc.rust-lang.org/style is a better link. We haven't been linking to it prominently because it hasn't been updated in a while, but I think is a few commits ahed of what you linked to.
I sent you a PR.
On mobile so I can't check, but are you sure you need `*const T`? I think just `PhantomData&lt;T&gt;` will work.
The [`PhantomData` docs ("Indicating Ownership")][1] say to use `*const T` if the data structure doesn't take ownership of `T` and doesn't need to be bound to a particular lifetime like with `&amp;'a T`. [1]: http://doc.rust-lang.org/nightly/std/marker/struct.PhantomData.html
For this to work you'll have to employ similar implementation strategies to those used for `Mutex`. Your `put()` method will have to take a `&amp;self` instead of a `&amp;mut self`, so that it suffices to have a shared reference to the data structure. Making this work likely will involve unsafe code `transmute()`ing the reference. You will also have to `impl` both `Send` and `Sync` for your type. There is a good [blog post](https://huonw.github.io/blog/2015/02/some-notes-on-send-and-sync/) by huonw on what exactly that means. In general I'd suggest having a look at the implementation of `Mutex`. Note that you shouldn't mark the `put()` function as `unsafe`, if it is itself safe to call. Instead use an `unsafe {}` block within the function.
Can you add [trace](https://github.com/gsingh93/trace) to the project updates?
Done!
Thanks! This is very helpful.
Thanks for the advice. Can you explain the PhantomData thing a bit more? Would declaring a new BloomFilter differ if the struct is parameterized? 
What is the use case for `std::iter::empty()` aside from being similar to `std::iter::once(3)`? It's not obvious to me.
It's actually considered undefined behavior in Rust to transmute from a &amp;T to &amp;mut T. This is declared in the docs of UnsafeCell. And so, in cases where you need to do so, an UnsafeCell should be used internally instead. 
~~I think `-C link-args=-s` (post-linkage stripping [1]) would remove further chunk of binary.~~ (Oh, it passes through another external pass including `-Wl,-s`.) Nevertheless, that sounds promising! [1] This of course disables the ability to format the backtrace with symbols.
If someone's keen to make a .gif of `examples/graphics.rs` in action and do a PR for the README, that'd make my day!
&gt; I wonder if `regex` is at fault for this. I know Kimundi carefully designed Pattern so that it could handle regexes, which have their own interesting constraints. Actually, I think even without `regex` it might have turned out similar due to wanting to support `char`, `&amp;str`and `Fn(char) -&gt; bool` patterns. With only `char` and `&amp;str`, you might be able to only track the starting position of a match, but with `Fn(char) -&gt; bool` you get variable length per match, and at that point you basically arrive at something that behaves like a regular expression. 
Were you unable to get a [target spec](http://doc.rust-lang.org/rustc_back/target/index.html) to work for musl, so that the linker need not be invoked manually?
I just filed https://github.com/rust-lang/rust/issues/24658
The compilation step already includes `-C lto`. Given that the minimal hello world program in Rust (with glibc) results in about 290K in the same architecture, remaining 150K can be regarded as a static libc overhead.
So does that mean lifetimes are only applicable to reference (borrow) types and not ownership (move) types?
Lifetime parameters as part of a type always means borrowing / referring to something that is owned by somebody else. But I wouldn't say that there is a clear distinction between "borrowing" and "owning" types. For example, you could have a vector of borrowed references. The vector would be an owner of the references but it would also be borrowing whatever these references would point to. I have a problem with your "a lifetime being applicable to some type". It does not make sense to me. If you have a specific type at hand there is either a lifetime parameter involved or not. If not, you can't just "apply" one. I guess, what's possibly confusing about this is lifetime elision and deduction, meaning, you don't have to *name* or *write* a lifetime in every situation. In these situations they are *implied*. For example, { // &lt;-- let's call this scope 'a. let i = 99; let x = &amp;i; let y: &amp;i32 = &amp;i; } // scope 'a ends here Here, I didn't say anything about any lifetimes (except for the comments). But that does not mean there is no lifetime parameter involved. In fact, the "full type" of both x and y is `&amp;'a i32`. So, in the first case, the compiler deduced both things, the lifetime *and* the type of the pointee. In the second case, the compiler only deduced the lifetime because I fixed the type manually to `i32`. I just can't spell the "full type" because the scope does not really have the name 'a — not as far as the compiler is concerned. It's just an unnamed scope. So, there is actually no way of being even more specific here. But that's fine. The compiler takes care of it. We don't have to name this scope. There are more places where we don't have to say anything about lifetimes. Example: struct Foo { x: i32, y: i32 } fn getx(f: &amp;Foo) -&gt; &amp;i32 { &amp;f.x } This might look like there are no lifetimes involved. But this piece of code is just short for struct Foo { x: i32, y: i32 } fn getx&lt;'a&gt;(f: &amp;'a Foo) -&gt; &amp;'a i32 { &amp;f.x } So, `getx` is actually a *family* of functions (polymorphic over all lifetimes). But this is such a common pattern (input lifetime parameter = output lifetime parameter) that we are allowed to use the shortcut syntax from above. :) However, the generic `Clone` implementation for references is a situation in which we *have* to name the lifetime parameter that is *always* involved with references. We want this to apply to references of type `&amp;'a T` for *all* lifetimes `'a` and *all* types `T`. I hope this helps. :)
Thanks! We changed conrod over to it just last night ([PR](https://github.com/PistonDevelopers/conrod/pull/385)) it's getting quite a bit of love atm! I'll be keeping an eye on carboxyl for sure
Ahh, excited about this! This is something we'd like to have working out of the box...
Thanks for writing about this! It is really about time and you need to show this in the discussion about choosing to fix Rc vs. allowing destructors to not run.
re thead::scoped: "That awesome thing Rust can do? It can't actually." How humble and honest.
&gt; clang's -fsanitize=thread Could you please TL;DR what this does? Is it static analysis that looks for possible threading issues? Thanks :)
Yes it can be fixed. We need to find a solution that is not overly restrictive.
Sorry, nothing real to add here, but rustic is an awesome name for it.
Could you elaborate? *edit ah, I think it's probably relating to this book: http://www.amazon.com/The-Grammar-Graphics-Statistics-Computing/dp/0387245448
Man, *really* wish I could come to this. :(
Exactly, it has been implemented in R as `ggplot2` and is the most enjoyable and expressive plotting package that I have ever used.
Does redirecting stdout and stderr fix that? http://users.rust-lang.org/t/stderr-stdio-redirection/780 Edit: set_print is marked unstable, not sure if it helps in that case
This project has been pretty neat so far and I'm once again appreciating Rust's type system: * `dispatch_sync` can return a value in Rust where it doesn't in C because it's difficult to express without generics. * Building a parallel map on top of `dispatch_apply` was fun and makes for a much friendlier API than the C version. * The `Sync` and `Send` traits seem pretty simple and yet the fact that they can prevent data races with just a few annotations is awesome. * And this may even be more performant than the Objective-C block API in some cases! (Haven't done any profiling though.) Because objc blocks are all boxed and Rust's closures don't always have to be boxed.
I don't think a Leak trait even solves the problem properly, e.g. if the destructor of an element of a Vec panics, any later elements are leaked, and restricting Vec to Leak seems untenable.
Have you attempted to run rustc test suite linked against musl? Or rustc itself (dynamically)?
I prefer Rusty, personally. Not sure why, but it doesn't help that rustic has a completely different meaning in everyday English.
What happens if you want to read from two different lua arrays? Would it not be easier to use fixed indices rather than -1, that way, it keeps working when you add another element to the stack?
Then add a new type of destructors that must run but can't be put in leaky containers.
Oh I see. When you have to return an iterator, all cases must be handled. `empty()` handles the null case.
This is currently not possible. I have a (complex) solution, but it requires HKTs :(
So make panics in destructors abort. Which they can already do anyway (double panic).
There is nothing inflexible about a `Leak` trait that would only not be assigned to types where it would be an *error* to not know exactly when the destructor was run, given that the whole point of reference counting is to dynamically determine drop time. The only issue right now is that reference counting types aren't the only way to leak.
Cool :) have not been hastily following the discussion, but I hope something cool like this works out :)
Very cool project! &gt; objc blocks are all boxed and Rust's closures don't always have to be boxed Yeah, the [implementation of blocks](http://clang.llvm.org/docs/Block-ABI-Apple.html) is quite complex.
But `-C lto` can't process `musl` unless it was compiled with `clang` and the LLVM IR written out into object files.
https://github.com/TeXitoi/rust-mdo a syntax extension for monadic do notation.
If you want to share and use such a data structure between threads without wrapping it into a `Mutex`, do the following: * write get/put to take `&amp;self` instead of `&amp;mut self` (without making them `unsafe` methods). * make sure that your data structure can *only* be *safely* shared and used between threads (no data races, etc). So, everything the user could do without an `unsafe` block should be safe. * make sure that you only accept element types that are `Send` since your data structure can be used to send "elements" from one thread to another. * implement `Sync` to acknowledge that you've taken the measures to make sharing between threads safe. * implement `Send` to acknowledge that you've taken the measures to make sending it from one thread to another safe. With this, the compiler will trust you (w.r.t. obeying all the rules) which is dangerous unless you really know what you're doing. You will probably have to use `unsafe` code inside your methods. But this way, you'd be providing a safe API for the users to use. With your datastructure being `Send` and `Sync` you can, for example, wrap it into an `Arc` and share it across threads via clones of this `Arc`. The `Arc&lt;YourDataStructure&lt;E&gt;&gt;` will give you access via a `&amp;YourDataStructure&lt;E&gt;`, a shared reference. But that's ok, because you get to invoke `get` and `put` because they only take `&amp;self` a. :-) Usually, `&amp;self` is used for non-mutating methods. But what `&amp;T` really means is *shared reference*. It's not necessarily about mutation. `Mutex`, `Cell` and `RefCell` offer `&amp;self`-based interfaces but let you mutate things. That's actually the reason of their existence. But these abstractions also have taken measures to make it safe: A `Cell&lt;T&gt;` does not let you borrow its inner `T` value. It only offers copying get/set methods. A `RefCell&lt;T&gt;` let's you mutably borrow its inner `T` value but keeps track of these borrows dynamically ("reference counting"). This is how it avoids violating the aliasing rules. A `Mutex&lt;T&gt;` also lets you mutably borrow the inner `T` but guarantees mutual exclusion similar to how `RefCell` offers `borrow_mut`. The difference is that a `RefCell&lt;T&gt;` is not `Sync` but a `Mutex` is. So, the reference counting in `RefCell` is not implemented in a thread-safe way. Also, locking a `Mutex` might block. Good luck. :-)
Yes it is! I've also worked on a project to create and invoke blocks in rust: https://github.com/SSheldon/rust-block It was cool that something that requires a language extension in C can just be implemented without any special language support in Rust.
It's not really the best answer, but instead of `panic!`ing, you could write to a log file. This doesn't really solve your issue, cause it still means you have to handle all the `.unwrap()`s manually, but relying on a `panic!` for end-user errors probably isn't the best way to do it since it can have other unsafe effects instead of exiting gracefully.
As we've branched off for beta, work on `master` will now end up in 1.1. /u/brson and I have been working out something spelling out the exact details of how branching works, but the TL;DR is: everything goes to `master`, the person who `r+`es your PRs will deal with porting.
It's awesome! 
Thank you. That sound quite badass.
Is there going to be a separate Homu queue for beta, or will Homu learn how to build from two branches, or will people who merge be manually kicking off buildbot builds?
&gt;**2**: They mean the same thing. Read the generic parameters (*i.e.* the bit inside `impl&lt;...&gt;`) as "there exists". Thus, it's "there exists a lifetime `'a` and a type `T` which might be `Sized`; as such, `impl` `Clone` for `&amp;'a T`... I'd characterize it more as universal rather than existential quantification. So, "implement, *for all* lifetimes `'a` and types `T` where `T` might [not] be `Sized`, the `Clone` trait for the type `&amp;'a T` as follows...".
Woa, is `char` an actual type in Rust? Is it a single UTF-8 encoded character? Guess that would also make it `?Sized`. Is it any different from `&amp;str` other than the static guarantee of having length 1? edit: after R'ing [TFM](http://doc.rust-lang.org/std/char/index.html), I found that it can always be cast to `u32`. How does that work? Can an UTF-8 char not have an arbitrarily long binary representation? edit2: I seem to have conflated Unicode and UTF-8 (a representation). Still, the number of unicode characters is not bounded, is it?
`char` is a type, yes. It's a single Unicode scalar value, and is always 4 bytes. http://doc.rust-lang.org/nightly/book/primitive-types.html#char
Very cool. Thank you for your explanation.
Not necessarily, destructors run even when the thread isn't panicking.
This Week in Rust is awesome, as are rust-lang.org posts. I've never been as excited to check out posts about a programming language before :) 
You're more confident than me that we've discovered all cases where problems occur.
Rustic: &gt; constructed or made in a plain and simple fashion, in particular
I meant after you panic, the destructor guarantee is no longer important, because thread is already panicking and any objects it uses are unreachable. This was our understanding of the situation with thread::scoped after it was fixed the first time, right? And why it had to propagate the panic.
It is still important, e.g. for `thread::scoped`, execution still has to stop and wait for the scoped thread to finish to ensure all references are valid, whether or not the main thread is panicking or not. Execution is not allowed to leave the stack frame containing the guard without running the destructor.
Perhaps so, I just thought it interesting that that specific definition seemed to fit.
May I ask how you came up with this schema? Have you developed it, or is it a common one?
So does "rusty".
Yes the original goal was to link the compiler itself against musl statically, so that one can ship a rust toolchain that comprises of two files, `rustc` and `rustdoc`, and the standard libraries for each target triple. That's why I went through hoops to build a cross toolchain and LLVM and friends. I can get `rustc` to be linked dynamically against musl just fine (didn't run the compiler test suite but will do when I find time, probably over the anzac weekend). I can get `rustc` to be linked against musl statically. But when I run the resulting compiler, it panics with thread '&lt;main&gt;' panicked at 'called `Result::unwrap()` on an `Err` value: "Dynamic loading not supported"' Presumably the compiler plugin needs dynamic linking capability to work, and because `rustc` was statically linked against system libc it fails. I don't have any idea of the compiler internals but the plugin support probably needs to be refactored to not require dynamic linking. &gt; used -C linker=musl-gcc and didn't find myself needing any extra toolchain things Yes this probably works as well. I was trying to build LLVM so I need a C++ toolchain. The musl wiki recommends building a native musl-targeting toolchain in this case because the C++ standard libraries need to be compiled against musl and the simple `musl-gcc` wrapper would not work in this case. &gt; How'd you get libunwind to get linked in? I used `libgcc_eh.a` that the `musl-cross` script built for me instead of libunwind, which has the same unwinding symbols. &gt; Does panicking work for you? Yes it does work for me. By compiling the compiler libraries with debugging I was able to get a stack backtrace for the panic that I just described when running the static `rustc` executable.
Native speaker here... the definition that typically comes to mind for me is the one provided by parent poster. Rustic is fine.
Oh man, this is more promising than I thought! I've started a [stack of patches](https://github.com/alexcrichton/rust/commits/musl) on a branch of mine for MUSL support in the distribution itself, and I'd love to help move it upstream soon. I haven't focused on building the compiler itself against MUSL just yet, but that would indeed be pretty awesome :) &gt; Presumably the compiler plugin needs dynamic linking capability to work I think this was actually [coming from the standard library](https://github.com/alexcrichton/rust/commit/f3c5b8a7ae912bcf71b315f5774c43dc68afe699) when it tried to create a thread. &gt; The musl wiki recommends building a native musl-targeting toolchain in this case because the C++ standard libraries need to be compiled against musl and the simple musl-gcc wrapper would not work in this case. Right, I always forget that our compiler links against C++. That would indeed be quite hairy! &gt; Yes it does work for me. By compiling the compiler libraries with debugging I was able to get a stack backtrace for the panic that I just described when running the static rustc executable. Fascinating! I wonder if I'm just miscompiling libunwind somehow. I'll try investigating your instructions for building a musl toolchain instead.
No, `Rc&lt;T&gt;` still needs a sized `T`.
Try using the same compiler options that produce a .so file on Linux and see what happens.
Yes it is possible. You wrote in the code comment that you want a default implementation for every implementor(X: Distance). What you tried was to implement a implementation for a trait object (Distance) that is a difference. Both is possible. The latter needs a ?Sized trait bound. The first is something like impl&lt;X: Distance, ...&gt; Distance for X.
Well, now, I use the term "default" because the examples I've seen also use the term "default," e.g. // A trait can provide default method definitions fn talk(&amp;self) { // These definitions can access other methods declared in the same // trait println!("{} says {}", self.name(), self.noise()); } ...from rustbyexample. But I don't mean something that can be overridden; I don't really care if it can be overridden or not. (And I don't know if that makes any difference; I'm just trying to be thorough.) So what I'm wondering is only whether or not this (or some other similar thing) is possible. I ask because, if it *is* possible, it would sure save me a lot of typing. :)
I don't think I see the difference between the two options you're talking about.
I've run into this problem. A Windows windowed mode application built with a `gcc -mwindows %*` linker shim will silently terminate itself the moment the program tries to write anything to stdout. I expect to have most end users running binaries like that, and if my program panics for whatever reason, all they'll see is it silently shutting down. Ideal behavior would be to capture the panic message and pop up a Windows dialog before terminating the program so that the user will see the message and can file a bug report. "Don't panic!" amounts to "write bug-free code", and the gag-rs crate says on its README it doesn't support Windows yet.
Ok, I came up with... impl&lt;T: Distance, D: Distance&gt; Add&lt;D&gt; for T { type Output = &lt;Self as Distance&gt;::Value; fn add(self, rhs: D) -&gt; Self::Output { Self::Output::from_normal(self.to_normal() + rhs.to_normal()) } } rustc tells me that only traits defined in the current crate can be defined for a type parameter. :|
I know it's the same but can't you say "codepoint"? People know that term, and noone should be worried about the representation details (possibly modulo size) unless they're writing a string/encoding library. 
Oh, I did not know that ... I never used Rc (only Arc) and never on trait objects, and just assumed it worked the same as Box. Any reason why it doesn't?
I asked similar question once ago. http://stackoverflow.com/questions/23339361/doubly-linked-list-with-remove Not sure if amswer still relevant Another answer http://stackoverflow.com/questions/22268861/how-would-you-implement-a-bi-directional-linked-list-in-rust
Not that I can see; however, it implements both the `FromIterator` and `IntoIterator` traits, so there's no reason you couldn't do something like this: `list.to_iter().filter(|&amp;x| x != item_to_erase).collect();` (assuming the elements of your list are `Eq`). Rust likes to use iterators a lot, so converting to and from should be reasonably cheap.
Using trait objects utilizes dynamic dispatch while the generic case is a compile time construct that has no runtime overhead.
Hey, I came up with the macro idea after realizing that the Add trait was probably off limits, and I kind of like how it worked out, but I don't know if this is what you meant by least specific etc... https://gist.github.com/archer884/eafef3bca7003c67917d This actually just writes all the boilerplate I was trying to avoid for each type (not that I'm complaining about only having to write it once!). Is that kind of what you had in mind?
I need to insert and erase elements frequently. Using `filter` and `collect` is very cost i think.
OK, that's cool. It turns out the problem was something else.
Frequent iteration is an inherent cost in using a linked list. However, it could stand to support something like `erase()` that wouldn't require moving the whole list out of and back into the heap element by element. /u/Gankro could weigh in on this. He's done a lot of work on libcollections. Alternately, have you considered using `HashSet`? It sounds like it might be better suited to your use case, but without more context I couldn't say for certain. 
&gt; I know it's the same It's not quite the same. The difference between code point and unicode scalar value isn't a matter of representation/size, but rather range: &gt; - Code Point. (1) Any value in the Unicode codespace; that is, the range of integers from 0 to 10FFFF. (See definition D10 in Section 3.4, Characters and Encoding.) Not all code points are assigned to encoded characters. See code point type. (2) A value, or position, for a character, in any coded character set. &gt; - Unicode Scalar Value. Any Unicode code point except high-surrogate and low-surrogate code points. In other words, the ranges of integers 0 to D7FF and E000 to 10FFFF inclusive. (See definition D76 in Section 3.9, Unicode Encoding Forms.) http://unicode.org/glossary Rust's `char` is the latter: it is illegal to have a `char` with value between 0xD800 and 0xDFFF (inclusive).
I really need a double linked list. Because both elements' sequence and insert/remove speed are important. Just can't believe that LinkedList as a standard container misses a so important method. There is nobody use it, or they use their own implentations?
For most use-cases, the Rust community tends to steer people towards `Vec` for sequential data storage. Generally it's well advised, but sometimes, like now, people really do need a linked list. I think I've got a solution for you, though: https://github.com/contain-rs/linked-list Have a look at that, specifically the `Cursor` type. It should support the operations you need. If it doesn't, feel free to submit an issue, or a patch.
It would be great if these sessions can be recorded!
Thanks for your pointing out. I'm considering use VecDeque instead.
Looks about right. :)
Good idea! Currently I do not know if I'll be able to attend.
Great ! Please add some comment in the official™ [github issue](https://github.com/Byron/depot/issues/1), which tracks everything we come up with.
I'm totally happy to put up with any delay you need for parsing crates/files when I start vim. I basically leave vim running all day so I'll rarely even notice a startup delay. A perfectly working code complete solution is really valuable to me. It will save me from losing so much time trying to find out what fns are available. Deleted constructive criticism on Rust website docs :-) 
The cons in particular seem to be not uncommonly misunderstanding Rust or what exists at present. As I’m going to bed now I will only comment on a couple of them that are particularly simple and clear-cut: &gt; It has virtually no automatic conversion semantics nor overloading, and hence requires you to spell out manually every single bloody conversion by hand - it won’t even auto convert a comparison of Option&lt;T&gt; to T. How *should* it convert a comparison of `Option&lt;T&gt;` to `T`? The concept simply doesn’t make sense. Silently unwrapping (i.e. panicking on `None`) would be positively evil. If you make automatic conversions happen too easily when the correspondence is not 1:1, you will hit all sorts of surprises, mostly unpleasant ones, and Rust would spare you that. It’s saving you from yourself, really it is. &gt; std::mem::swap(a, b); &gt; &gt; But this won’t work because swap() only take mutable references. So now you try: &gt; &gt; let x = &amp;mut a; &gt; let y = &amp;mut b; &gt; std::mem::swap(x, y) No! You write `std::mem::swap(&amp;mut a, &amp;mut b)`.
The language lacks the placement features necessary to make it work. Eventually it will work, but for now it doesn’t.
The main beef the author has with rust is that async IO and green threads are no longer in the runtime (because as it stands, Rust has no runtime). This was done deliberately, because while having a runtime with those features is a great thing in the server space (and libraries to afford this should be available on crates.io), it kills the possibility of doing tiny-embedded work (by this I mean everything below JavaCard space where you don't want the cost of a runtime).
How strange, I just wrote some docs for `cfg_attr` yesterday: https://github.com/rust-lang/rust/pull/24673 Wonder why we both thought of it at the same time!
Offtopic: I love Prague. Such a great city.
The `cargo build` should just build everything, including a library.
The guy seems to be a Boost dev, and works at this [MaidSafe company](http://maidsafe.net/) doing something like a new 'decentralized internet', so he probably gets some leeway to look into new low level technologies that might help achieve that companies goal.
&gt; * Partial type specialisation (called matching) is overused in Rust due to the lack of language support for anything better right now, a bad thing because it is too easy to get surprised by a change in type relations in one place having unexpected partial specialisation matching outcomes in other places. In other words, change ripples have all the same problems as in C++ for type pattern matching, but because Rust implements its switch statements and much of its if...else logic as type pattern matching the consequences are much worse here. I can see this being a real problem for scaling out Rust to very large code bases, because you change some small thing in one place and all sorts of compiler undetectable logic change consequences could result in unpredictable locations. I don't understand this part. What is a typical "change in type relations" in this context? 
And how would one check if Some(1) is higher than None?
&gt; being flamed isn't something you really have to worry about too much in the Rust community But what if I want to be flamed with great borrowing semantics? You *may* have my lighter, sir.
&gt; And now try to ask about why there is no fall-through match in Rust. But there is: https://github.com/pythonesque/fallthrough/ (I didn't agree with the downvoting for the comment you reference, but the ensuing discussion turned out to be quite productive since I discovered that you actually *can* get fallthrough match in Rust :))
Hmm. That is a bit surprising. It looks like it's due to the `derive(Ord)` declaration: /// The `Option` type. See [the module level documentation](../) for more. #[derive(Clone, Copy, PartialEq, PartialOrd, Eq, Ord, Debug, Hash)] #[stable(feature = "rust1", since = "1.0.0")] pub enum Option&lt;T&gt; { /// No value #[stable(feature = "rust1", since = "1.0.0")] None, /// Some value `T` #[stable(feature = "rust1", since = "1.0.0")] Some(T) } My expectation would be that `Option` would implement `PartialOrd`, where `Some(x)` values would be comparable, but comparing to `None` would give you `None`. I'm wondering in what cases `None` comparing as less than all `Some(x)` values is actually desirable behavior, and doesn't indicate that you should have extracted the values and had a branch handling the `None` cases separately.
You shouldn't be using `.as_slice()` anymore, `&amp;foo` will give you a full slice, or `&amp;foo[1..3]` for a range.
What is "Ok-biased"? Something that involves code generation to make branch prediction favour the Ok path?
Well, Servo may end up implementing a library. The team was pretty sad when we removed `libgreen`. Or someone else might, we'll see. But that's basically it for now: we expect things like this to grow in the Cargo ecosystem, by the community or by the team itself. We don't have it in a schedule somewhere right now, though, as there's more language-level concerns to address at first.
You are far from the only one. Rust's error handling is one of the better things about the language. I think we need to do a better job advertising option (2) since it would resolve a lot of people's complaints.
I would prefer a couple of traits like `CrossPartialEq`, which I could implement for my `enum&lt;T1,T2&gt;`, so that I could compare: foo: enum&lt;T1,T2&gt; == bar: T1 foo: enum&lt;T1,T2&gt; == bar: T2 Then you would be able to compare `Result&lt;T,T&gt;` with `T`. Just a thought :)
I dislike `unwrap` in libraries if it is used for anything other than logic errors, because it doesn't give me a choice about how to handle the errors. In executables, it's quite justifiable.
Just that you flatmap/bind/return the Ok-value so that do-notation works naturally, i.e. (using some made-up do-notation): fn readInt() -&gt; Result&lt;i32, Error&gt; { do! { text &lt;- readFile("bla"); value &lt;- parseInt(text); return value } } This in combination with using an error container that is a semigroup (so you can combine many errors) you basically have a generic, convenient and composable way of handling errors.
I would love to go! Unfortunately I do not have much time to help with organization
&gt; Implicit conversion is the source of countless bugs and defeats the purpose and benefits of strong+static types. I disagree, what you wish to avoid are: - lossy conversions: integral/float conversions in C++ are nasty - throwing conversions (`Option&lt;T&gt;` to `T` with an implicit `unwrap`) however there is little reason to force a call to `as_slice` for example. Thus, I think that Rust strikes a rather good balance at the moment with `Deref` and `DerefMut`.
&gt; And this is but a small place where the lack of overloading or inference is a problem, though I must admit surprise as to why the standard swap function isn’t a generic taking any inputs (obviously with some constraints) which does the right thing. I think they will discover another Rust feature: it's impossible to write a Rust function that is called as if it would take ownership of two values, but then it doesn't. We simply can't do a `swap(a, b)` that doesn't take ownership of the exact `a` and `b` values.
Also, `Box::new(5)` is just a temporary thing and `box 5` will be coming back soonish. I think this is the relevant RFC: https://github.com/rust-lang/rfcs/blob/master/text/0809-box-and-in-for-stdlib.md
It is not very similar to the `new` in Java. Rather, it is just a function for providing the struct constructor with default or calculated values. This to make the API cleaner for users. The name `new` is not special either, any other name could be used, it just happens to be a fitting in many cases. Vec::new, for example, internally constructs the vector using an unsafe function with default values, but exposes this construction through a safe, clean API.[1] [1] http://doc.rust-lang.org/nightly/src/collections/vec.rs.html#172
That's one HELL of a party :D
By the way, `~str` was replaced by `String` and `~[E]` by `Vec&lt;E&gt;`
new is just the conventional name for the primary constructor of a type.
Maybe racer could be a service with a DB running so that it doesn't reparse files on vim close and reopen.
He's probably referring to function name overloading, which is what most people refer to when they use the term overloading.
[unwrap_or](http://doc.rust-lang.org/nightly/std/option/enum.Option.html#method.unwrap_or)
I do very much like haskell's pattern matching top level functions. However, for chaining a bunch of IO operations that might fail, I think we need a Result monad, or something that looks like it. 
Trait multidispatch does that
That's the more expanded, full form, but often, `&amp;foo` is all you need.
Rust. I don't know of any articles.
I’ve been intending to write about `cfg_attr` for a few weeks, I just didn’t get round to actually writing the article until the last couple of days.
As I understand it, you cannot present green threads as a safe abstraction in a library as long as the standard library exposes OS TLS and uses it under the hood (e.g. for printing IIRC).
We build a custom rustc anyway with multiple cross compilation support. I personally do have a copy of Servo's rustc in my multirust toolchains, which I sometimes use for working with deps. Jumping from nightly to nightly won't work just yet. Servo is too large, and rust upgrades block other PRs and work.
Ah, yes, that's a better idea than wrapping a `std::fs::File` in every variant of an enum. However, I'm not sure if it's currently possible to determine if a file is something other than a regular file or directory.
That doesn't solve the cross compilation issue (yet), unfortunately.
No, because of the crosscompilation thing -- the official tarballs don't contain those. (Also because we often backport fixes and whatnot so we're not always on a nightly) We might eventually switch to nightlies though.
&gt;Implicit convertion is the source of countless bugs and defeats the purpose and benefits of strong+static types. **Some** implicit conversions are the source of bugs. I would love to have you tell me how an implicit conversion of `T` to `Option&lt;T&gt;` is going to cause problems. *Especially* if it is done by value. I'm also curious how an implicit conversion from `u32` to `usize` (assuming the architecture defines `usize` as &gt;= 32 bits, and again, by value) is a problem.
We also disable `--enable-llvm-assertions` when building our rustc, as it results in a significant speedup for our build times.
&gt; I'm also curious how an implicit conversion from u32 to usize (assuming the architecture defines usize as &gt;= 32 bits, and again, by value) is a problem. &gt; *assuming the architecture defines usize as &gt;= 32 bits* I think you just answered your own question.
Yes, that's the hashing algorithm the hashmap uses by default.
It's actually pretty terrible compared to Haskell's do notation
&gt;e.g. Murmur hash Which is positively dangerous for most use cases...
You can add a `#![deny(warnings)]` attribute to your crate. If you want it to be conditionally enabled, e.g., only for testing, one can use `#![cfg_attr(test, deny(warnings))]`.
`Rc&lt;RefCell&lt;T&gt;&gt;` is a common pattern for interior mutability. In most cases, you really shouldn't need it though, and you should try to design your program so that the trait only has one owner, especially since with `RefCell&lt;T&gt;` you may end up with runtime panics from `RefCell::borrow_mut` if you try to do things that Rust would disallow in the first place. I think the verbosity it's not that bad, though, since it makes it very explicit about what the type is. `Rc&lt;T&gt;` provides cheap reference-counted cloning, `RefCell&lt;T&gt;` provides runtime-checked interior mutability, so putting them together describes what you want from it.
You shouldn't need the `Rc&lt;RefCell&lt;...&gt;&gt;` part to get a "list of mutable trait objects". If you need a "list of shared pointers to mutable trait objects", then yes, I believe you more or less need what you have. As for "an `Rc`-like smart pointer with mutability and direct support for trait objects", you can do that yourself: struct LetsPretendWereUsingPython&lt;T: ?Sized&gt; { ptr: Rc&lt;RefCell&lt;Box&lt;T&gt;&gt;&gt;, } :P But in all seriousness, you seem to feel that this is somehow a bad thing. I'd argue that it's not: it's just that Rust forces you to spell out the semantics you want. I doubt Rust will ever get anything that is, say, as straightforward as a Python reference, because that would imply a lot of invisible dynamic borrow checking in order to uphold the aliasing guarantees that are a big reason to use Rust in the first place. Actually, I can see a case being made for a variant of `RefCell` that supports dynamically sized types; that, at least, would simplify it to `Rc&lt;DstCell&lt;T&gt;&gt;`.
If you only have one owner, then just `Vec&lt;Box&lt;Trait&gt;&gt;` should work fine. RefCell is only if you need to be able to reason about the object's mutability (make sure there is only one `&amp;mut` at a time) at runtime instead of compile-time, which with `Box&lt;T&gt;` you don't need to do.
`RefCell` (along with `Cell`, both of which are built on `UnsafeCell`) just wraps a value with an extra field which keeps track of how the interior has been borrowed. The "rustic" solution isn't to make a magic do-everything type, but to instead have a `*Cell` variant that supports dynamically sized types (which is what you want). In that case, the `Box` would be redundant; it's only required here because `RefCell` can't be used to store a trait object. That way, you'd be down to *just* the `Rc` vtable pointer, so it should be a single layer of indirection. (Just FYI: if by "double dispatch" you mean obj_ptr -&gt; vtable -&gt; fn_ptr, Rust actually uses fat pointers for trait objects, so it's (obj_ptr, vtable) -&gt; fn_ptr; one indirection. At least, I *think* so...)
The trait method that I'm calling has a signature with `&amp;mut self` and `Box&lt;Trait&gt;` doesn't allow me to get a mutable reference to the trait object (as far as I can tell).
C++ owes many of its gotchas to its C inheritance.
&gt; Rust’s language design makes you write code with optimal performance almost always. In other words, you don’t need to have read and fully understand the compiler’s source code to write optimal code as you nearly do with C++ nowadays I'll have what you're smoking.
Love the writing in this!
First of all, when asking for help with code that won't compile, you're more likely to get an answer quickly if you post either a minimal test case, or the *full* error message. For reference, the error I got when I added enough stuff to the example was: &lt;anon&gt;:21:29: 21:30 error: `s` does not live long enough &lt;anon&gt;:21 let res = s.contains(p); ^ &lt;anon&gt;:10:81: 35:2 note: reference must be valid for the lifetime 'b as defined on the block at 10:80... &lt;anon&gt;:10 fn run&lt;'b, P&gt;(&amp;mut self, p: P) -&gt; Option&lt;()&gt; where P: str::pattern::Pattern&lt;'b&gt; { &lt;anon&gt;:11 loop { ... &lt;anon&gt;:17:50: 29:14 note: ...but borrowed value is only valid for the block suffix following statement 0 at 17:49 &lt;anon&gt;:17 let s = format!("{}", c); &lt;anon&gt;:18 // s doesn't live long enough to call contains, ... &lt;anon&gt;:21:41: 21:42 error: use of moved value: `p` &lt;anon&gt;:21 let res = s.contains(p); ^ note: `p` was previously moved here because it has type `P`, which is non-copyable Taking the first error, the first clue that something's weird is that it's claiming the string should be valid for the duration of `'b`, which isn't obviously related. So, if you look up the definition of `contains, you find: fn contains&lt;'a, P&gt;(&amp;'a self, pat: P) -&gt; bool where P: Pattern&lt;'a&gt; And *there's* your answer. You've stated that the pattern must be valid for some lifetime `'b`. `contains` defines the `Pattern` result and input string to have the same lifetime, but `s` is *definitely* not going to live that long. I'm honestly not sure what to do about this. On first glance, it looks like a bug in the definition of `contains`; I can't immediately think of a reason the input string and the pattern should have the same lifetime, when the result is just a `bool`. As for the second error, your code will *potentially* use `p` more than once; this is easiest to solve by changing the constraint to `P: Clone + str::pattern::Pattern&lt;'b&gt;`, and using `p.clone()` in the call to `contains`.
My apologies for not including the error. I provided enough code to demonstrate (well minus a few lines) the exact error but I will remember to be more complete in the future. Thanks for the information. 
No problem.
Blog posts like this are so helpful. I frequently find myself wondering how others, especially those who work with Rust a lot, develop using the language and surrounding ecosystem.
&gt; Cause all panics in destructors to immediately abort the process. Will this lead to `std::rt::unwind::try` being safer(without the "this might not call some of the destructors if nested")? 
I do not really have time to plan anything fancy. If somebody does it, that's great! If not, I would be just for a simple meeting in a cafe or somewhere, talking about our experience, projects, 'n stuff :)
Minor point: &gt; Since it needs to be send, we're not going to be capturing any references Not quite! In fact, the reason it needs to be `'static` is not because of `Send`, but because of [`Any`](http://doc.rust-lang.org/nightly/core/any/trait.Any.html).
Ah, you're right! Thank you for the correction.
One thing that you could do is use a type alias: type RcRefCellBox&lt;T&gt; = Rc&lt;RefCell&lt;Box&lt;T&gt;&gt;&gt;; Which would simplify your type signatures a bit.
Could you please give or link an example?
Is there a deadline for registering?
I believe the debate was put aside for 1.0, but it has already been expressed that a little sugar would go a long way, either with `do` notation or with a `?` operator. You argue that exceptions are nice because they do not hinder the "main" flow, this is true, but this has the disadvantage of hiding them, making it more difficult when looking at a particular routine to know which functions may throw or not. In any case, error-reporting and error-recovery are perhaps the most difficult topics a programmer has to deal with, and I have yet to see an ideal solution. I personally think that `Result` with some sugar could come close, it's just a bit bitter at the moment.
Firstly thanks to whoever it was who told me about this reddit. My "main beef" wasn't exactly as you say. Firstly, I said that Rust (and this new generation of systems programming languages) excites me, and the last time I got excited about a programming language was in 1999 with Python. Secondly, my poorly conveyed point was that not having async i/o and stackless coroutines at its core I feel is a missed opportunity as lots of new Rust code currently being written will not use modern programming idioms, and it is my opinion that this weakens the use case argument in favour of choosing Rust over alternatives significantly, especially as the most popular development target Windows is employing WinRT and for compatibility with that target your language and libraries need to never, ever block. Microsoft contributed WinRT support to Boost, and most Boost libraries have good WinRT support. I would struggle to see how currently one would write a WinRT app in Rust because the Rust language and runtime is in the way. (Some may feel that first tier support for Windows isn't important. You can choose to believe that of course, but 70-80% of global software development still targets Windows, and as a personal opinion I think therefore 70-80% of your design effort also must target Windows) I also have no idea what you mean about needing a runtime for async i/o nor stackless coroutines. The former requires no more complex a standard framework library than non-async i/o, proposed Boost.AFIO for example is only a couple of thousand lines of code with excellent Windows and Linux support. Boost.Fiber, which implements your selectable choice of anything between stackless coroutines right up to the fullest fat M:N scheduled userspace threads is similarly only a few thousand lines long. Both work excellently on very tiny devices, indeed AFIO per-commit is Jenkins CIed on a small ARM dev board.
&gt; If I understand correctly he basically wants unchecked exceptions like in C++, No, I want **unsurprising** exceptions which don't have the misfeature of unpredictably fatally exiting the process or unpredictably doing something I didn't consider (in particular, exception throws are one of just two places in C++ without guaranteed time complexity guarantees). C++ right now can't do that, which is why many users of C++ disable exceptions entirely (e.g. games development) throwing the baby out with the bathwater. A lot of why exception handling has a bad rep is precisely due to its lack of predictability, which in turn is caused in large part by (a) throwing exceptions when memory allocation fails and (b) insufficient call tree analysis by the compiler to determine potential points where unpredictability could occur, and then refusing to compile that code and (c) because a RTTI lookup must occur during unwind, and RTTI lookups have unbounded complexity :( &gt; and his suggestion that all functions should return Result&lt;T, E&gt; is just absurd. Hardly. Possibly coming in C++ 17 is a std::expected&lt;T, E=std::exception_ptr&gt; which is a monadic result transport quite similar to Rust's Result&lt;T, E&gt; except expected&lt;&gt; can do quite a few more tricks. Firstly, unless there is ambiguity you can treat expected&lt;T, E&gt; as a T and it all just works and it decays to a T. If however it contains an E, and E is throwable, attempting to use expected&lt;T, E&gt; as a T will rethrow E. All this happens internally to the compiler thanks to constexpr, and the assembler output is generally optimal i.e. optimal runtime overhead. expected&lt;T, E&gt; is huge for C++ because it lets you mark up entire sections of code with noexcept, and therefore that code will never surprise you with unexpected fatal application exits caused by exception throws colliding or choppy performance due to unbounded complexity RTTI lookups. The optimiser can also do a much better job when it no longer need consider two routes of exiting a function. C++ didn't invent any of this of course. We borrowed monadic returns from Haskell, and I think the team who developed expected&lt;T, E&gt; did a great job in delivering as much of the power as Haskell's Maybe monad as is possible in an OO language. Its only real negative is that right now using expected&lt;T, E&gt; rather increases your compile times. Anyway, I really would consider having Rust always return a Result&lt;&gt;. It probably could even be done in a new release without breaking much existing code. &gt; His argument that documenting the error as part of the API is brittle just because of sloppy developers is not even a technical argument just an opinion. It's an opinion borne from working on multi-million line code bases in some very large multinational orgs. If you ever had to act as code reviewer for one of those orgs and seen some of the stuff which ends up in shipping products I think you would agree with my opinion - average programmers are very lazy, and a programming language which aims to become a major world dev language needs to default to the least bad outcomes laziness and a lack of care in multi million line code bases produces. 
Great article, really fun. The biggest thing I took away from this though, is all the great work done by the Iron and Hyper contributors. I was expecting WAY more code from a language as low level as Rust, but this was barely more code than the equivalent Sinatra server.
+100 The only thing worse for a *systems programming language* than unpredictable unbounded stack unwinds is defaulting to implicit abort() scattered everywhere in your code. It's probably not a bad idea for Web 2.0 languages like PHP where you have the die keyword, and every statement you write is x || die so instead making the die implicit makes sense. C++ already may unpredictably call abort() in far too many circumstances which makes it exceptionally hard to regression test. Again, for top tier dev languages used by big multinationals you need ease of formal correctness testing to be at the top of the list. As much as any of the .NET languages never excited me, one thing they really aced was testing - you can formally prove mathematically that some bit of .NET code really is 99.9% bug free. Not quite to Erlang standards where I think can reach nine sigma reliability (which is just mind boggling), but much better than C++ unless you disable exceptions. Rust needs to get there too eventually, and I would suggest the compiler refuse to compile any code which could panic :)
&gt; I am definitely against a mandatory Result for all functions, because for 90% of functions, the additional information conveyed would not be used, if you're not going to respond to a function Result differently based on the information it carries, then there is no point in carrying the information. Rust's variant implementation (enum) is entirely static and compile time. Therefore if a function never returns an E, the compiler would not generate code for anything but a T return, and therefore there is no runtime cost to the additional *potential* information. In other words, Result&lt;T, E&gt; only generates overhead if an E *could* be returned, and even then the compiler has huge scope for eliding any actual runtime overhead for that.
Then you suck at your own language. https://www.google.com/search?site=&amp;tbm=isch&amp;source=hp&amp;biw=&amp;bih=&amp;q=rustic&amp;btnG=S%C3%B6k+med+bild#
Senior engineers in C++ compilers are regularly surprised by what the language allows and doesn't allow, and are even more surprised by what their own compilers do or don't do when fed certain code patterns. As are people on WG21. As are Boost library developers. It's simply a factor of the language's age and maturity that contraindicating rules are laid on top of one another, and to be a world expert in C++ is mainly being expert in what you don't understand and can't predict. Rust, being brand new and designed from scratch shouldn't have those problems, and so far in my experience of it its designers have done a great job in aligning what the compiler needs to be told with how much detail is requested from the programmer.
I still believe the API is in error here. The only method on `Pattern` that should apply a lifetime to its `&amp;str` argument is `Pattern::into_searcher()`, because it needs that string to create the searcher; and then, it should use a lifetime at the method level, or better yet, leave it to elision: impl&lt;'a&gt; Pattern&lt;'a&gt; for MyStringPattern { type Searcher = MyStringSearcher&lt;'a&gt;; // Elide the lifetime of `haystack` and `MyStringSearcher` fn into_searcher(self, haystack: &amp;str) -&gt; MyStringSearcher { // impl code here } } The other methods most definitely *should* use elided lifetimes, as a longer lifetime is not necessary, and causes unintuitive problems with generics like OP's. I would probably relax the trait bound to be `for&lt;'b&gt; Pattern&lt;'b&gt; + Clone` and call `.clone()` in the loop; though all the in-library implementers are `Copy`, generics should normally use the widest bounds possible to accommodate user implementations of traits. Edit: if elision requires `&amp;self` to work, then all methods in the `Pattern` trait should use method-level lifetimes.
We basically already have that because there is a [`impl From&lt;String&gt; for Box&lt;Error + Send + Sync&gt;`](https://github.com/rust-lang/rust/blob/master/src/libstd/error.rs#L90-L108). It just isn't well advertised.
I don't know. I agree it's confusing, but my understanding is that it's because `_` is actually not a variable name, but a pattern. Since the `_` pattern doesn't actually cause a move, the return value dies in place.
In the context of the runtime removal ([RFC 230](https://github.com/rust-lang/rfcs/blob/b75b8c781ba592c13b3785c251947acc9ed5eac0/text/0230-remove-runtime.md)), lightweight/"green" threads were removed and "tasks" were renamed to "threads" (as they are always OS threads now).
&gt; Looks like the future is near I appreciate the author posting this. My comment is more about hyper and iron. Unless we get an asynchronous reactive web framework we are solving yesterday's problem. In the Scala world we had Play offer a reactive framework from very early on. Java now has asynchronous web service through JAX-RS 2.0 but many implementations (such as TomEE) still doesn't support it. To make matters worse Java 8 and Netflix's RxJava is fragmenting the architecture. For example Couchbase database client adopted RxJava which will not be trivial to use along with another library that uses Java 8 CompletableFuture. The well respected AsyncHttpClient does things in its own way and [refuses to adopt](https://github.com/AsyncHttpClient/async-http-client/issues/399) either Java 8 or RxJava. My point is that if we have a delay in coming up with an asynchronous framework, different libraries will fill the void in a different way. A fragmented ecosystem will not be a good thing.
I'd definitely join :) 
Rude.
Yeah, that's becoming clear to me now. This design was taken from a project done originally in C++, and there it was perfectly sensible and helped avoid globally accessible state, but it seems like Rust wants me to take an even safer approach (not that I have a problem with that).
Many of the C++ cons are just in the way people choose to use it vs using it wisely.
Actually since C is not a complete subset of C++, it does not always depend on the compiler.
It almost got changed to `assert`, but the community coudn't come to consensus on an alternative name.
Maybe that particular cause should get a better flag bearer.
If you're using Linux and installed the rust nightly, the full rust docs on doc.rust-lang.org (in HTML) can be found in `/usr/lib/rust/rust-nightly/share/doc/rust/html/`. I find them very adequate.
The current design does not rule out libraries to allow whatever concurrency paradigm developers can come up with, whereas baking green threads into the language would have restricted that design space considerably. It's the same as with Lua tables vs. OO. (Meta)Tables allow for multiple OO paradigms, but carry none of the baggage.
Awesome! I was really hoping there would be a gather up for AMS. I live in Eindhoven and I'd really like to participate!
Hey, I think I have garnered enough people since my reddit post to make a thing out of this (got a few private messages and people IRL saying they would go), and so I made this page to get people informed on when and where. Currently there is no where, but I am looking for venues to host us, so hopefully that will be set up soon! If you have any questions, please never hesitate to email me at my reddit username @ gmail. thanks!
Seems reasonable to me. Is there any part specifically that you have a hunch might not be great? There _are_ different options here, depending.
&gt; we are working to make it possible to bring the web platform to wearables and appliances with less than [64 MB]. Maybe it's a bit off topic, but will a JIT be able to run in that? Also, do you know if SpiderMonkey or V8 is better suited to the task? &gt; Some modern browsers plan to solve this [iframe issue] by spawning a process per iframe, but it is unclear how that will work for sites with tens to hundreds of iframes. Not primarily looking to point fingers in a "we're better than them" manner, but can you elaborate on which ones? This is a new issue to me. Also, could they potentially mitigate this issue by grouping iframes into processes once they reach a certain number? I know Chrome groups multiple tabs into processes.
How are 0..10 style ranges defined in the standard? Is it simply by '..' being an operator, and the integer types implementing it?
Looks like it. '..' operator triggers #[lang="range"] which forms a Range object.
The article mentions using Rust tasks in order to support iframes and parallelization, but there hasn't been lightweight M:N threading support for a while now. Is the idea for the Servo team to work and bring back a green threading library, or is the information just out of date?
Would it be considered backward-compatibility-breaking to have an "issue a compile-time warning on any use of `unwrap`" lint and turn it on by default? (Apologies if it does this already; I haven't had a chance to play with Rust for a while.)
It avoids allocating every time you do a read. By passing in the string, the API lets you reuse an already allocated buffer. An example of where this is nice is if you are iterating through a file line by line. The String might get reallocated a few times, but you aren't allocating and freeing a String every iteration.
The unwrap() is kind of nice, because it will make your program crash in the (rare) case that reading a line from stdin fails, rather than silently continuing on. 
On one hand, it makes sense now that I think about it. On the other, why not have both? When you just need to read one line, explicitly allocating a string just feels ... awkward.
&gt; In Servo, we avoid this problem by using Rust’s lightweight task spawning mechanism. Is this just colorful language for statically-safe thread concurrency, or is Servo still using libgreen?
Yes, as someone who has done the `let _` bit, I think `unwrap` ends up being nicer.
Although I guess it is still missing any description. The rest of the binary operators have a blurb.
Nope, `unwrap` isn't incorrect. That lint would be far too noisy. It's just a tool that needs to be used carefully. For example, in [this recent PR](https://github.com/sw17ch/forestfire-rs/pull/7/files#diff-639fbc4ef05b315af92b4d836c31b023R35), I use unwrap because I _know_ that it can't be `None`. I've already done the work to do so. You have to balance lints, if they get too noisy, people just ignore them all.
Adding a convenience function is certianly possible. We're focusing on a strong, minimal core at first. I can imagine this being somewhere, maybe in some sort of 'simple io' library that has an easier to use API but handles fewer errors, crashing instead.
&gt; Is the idea for the Servo team to work and bring back a green threading library? We're not sure yet. Servo uses work-stealing queues for parallel layout. And it will use OS processes in order to sandbox tabs from each other and from the trusted parts of the engine. With those two extremes of granularity covered, it's not clear that we'll *also* need green threads. Another option is a task-queueing system like libdispatch.
I may be misunderstanding you, but this isn't really true. The compiler can't look at an arbitrary `fn foo() -&gt; Result&lt;i32, X&gt;` from the outside and see that `Err` will never be returned.
[**@BrendanEich**](https://twitter.com/BrendanEich/) &gt; [2015-04-23 22:55 UTC](https://twitter.com/BrendanEich/status/591374980476051457) &gt; World map of @rustlang contributors: https://github.com/jakub-/github-contributors-geojson/blob/master/rust.geojson ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://www.np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
This article was originally authored when the green task library still existed, but was in review while that changed. It's still true from a certain point of view, though, because Servo already has its own task pool for parallel operations. We're also likely to do work to reduce our currently-ludicrous pthread usage, some of which might end up in an even lighter-weight green threads-like system.
I think you misunderstood me. Lifetimes work independently at the trait level and at the method level. With `into_searcher`, `Searcher`'s lifetime parameter would be reduced to the method-level lifetime, elided or not (elision would simply omit the lifetimes at the method level and let the compiler assume them): trait Pattern&lt;'a&gt; { type Searcher: Searcher&lt;'a&gt;; fn into_searcher&lt;'f&gt;(self, haystack: &amp;'f str) -&gt; Self::Searcher&lt;'f&gt;; } This limits the lifetime of `Searcher` to the lifetime of `haystack` instead of requiring `haystack` to live as long as `Pattern`. The other methods wouldn't need `Searcher` to live longer than their own bodies, so an elided lifetime should be fine: impl&lt;'a&gt; Pattern&lt;'a&gt; for MyStringPattern&lt;'a&gt; { type Searcher = MyStringSearcher&lt;'a&gt;; fn is_contained_in(self, haystack: &amp;str) -&gt; bool { self.into_searcher(haystack).next_match().is_some() } }
Yeah, unfortunately that particular paragraph is somewhat out of date. I'm just lucky the Rust pseudocode wasn't also invalidated before the article made it out :-) See my other comment, though, about our need to address our current situation post-libgreen (which uses up to 80 pthreads to show a blank webpage). Lots of it is clownshoes and easy to fix, but some will be hard.
Maybe you could spin it as "lightweight (task spawning mechanism)" rather than "(lightweight task) spawning mechanism": `std::thread::spawn(|| { ... })` is pretty lightweight. :P
/u/timonvonk can you email your shipping address to banderson@mozilla.com so I can hit you up with some swag?
Good to know, thanks!
From my understanding of Rust, `Self::Searcher&lt;'f&gt;` wouldn't compile, because `Searcher` here is a concrete type and accepts no lifetime parameters. Your solution would work when Searcher would be not a type, but a type constructor taking one lifetime parameter. And this is currently impossible to express in Rust.
I think when you refactor things and you have a catch-all `_ =&gt; something();` it can change based on the fact that you added things to that case and it's not possible to detect that this wasn't meant to be done
You can be a rust contributor without working on the compiler/standard library, by creating crates for instance. I'm nowhere near the level of expertise to work on the compiler, but I still try to create crates and develop the ecosystem.
&gt; it's not clear that we'll also need green threads Alternatively, we could deliberately make Servo into a living demonstration of every concurrency and parallelism strategy known to man! Rust's status as world's most concurrent language confirmed!
I would love to hear more about the design of Servo's bespoke green thread library, if it happens. If it's even lighter weight than libgreen used to be (or lighter weight than any other language's native green threading system), it would be a great argument in favor of our decision to not bake a green threading model into the language itself.
Could you benchmark your Go implementation again after removing the interface? Function calls on interfaces require dynamic dispatch, so there's a non-trivial amount of additional overhead compared to your Rust version. edit: doh, I see that your benchmark runs in the same package as the implementation, and uses the unexported type, so it shouldn't be testing interface overhead as well. That said, I still don't like forcing callers to use the interface when they might not need to. :)
My Go version is here: https://github.com/Workiva/go-datastructures/blob/master/queue/ring.go. Consumers can directly get a pointer to a ring buffer. There is real overhead in the use of interface{} though, and I have had some people that I work with actually copy/paste the Go code with static types to get better performance. Not much else to do given Go's lack of generics.
Hmm, I do see that. However, it still appears to be an error in design. `haystack` should not need to outlive `Pattern`, just `Searcher`.
As /u/typopex says, `x..y` is equivalent to`std::ops::Range { start: x, end: y }`: http://doc.rust-lang.org/nightly/std/ops/struct.Range.html
Yes, you are right! I considered updating it to correct this and other inaccuracies, but instead just added a link to this thread...
Firstly, there is no slicing happening in `&amp;(vec![1,2,3,4])`. All that happens there is you take an immutable borrow of a temporary, which is of type `&amp;Vec&lt;i32&gt;`. Now, as it happens, there is `impl&lt;T&gt; Deref for Vec&lt;T&gt;`, with `Target = [T]`. In other words, assuming you have some `v: Vec&lt;T&gt;`, then `*v` is of type `[T]`. However, the compiler *also* uses this as an indication that it's acceptable to automatically coerce a `&amp;Vec&lt;T&gt;` into a `&amp;[T]`. This is why you can borrow a vector and have it mysteriously turn into a primitive slice. I believe that `AsRef` exists for the sake of generic code that wants to be able to easily say "I will accept any type `T` which I can turn into a `&amp;U` on-demand." Finally, `v[..]` is done using the `Index` trait. Specifically, `Vec` (as well as slices) has implementations of `Index` for `usize` (*i.e.* individual indices) as well as the three kinds of ranges (`Range`, `RangeFrom`, and `RangeTo`). In this particular case, indexing a `Vec&lt;T&gt;` with a `RangeFull` results in a `[T]`, which you then re-borrow to get `&amp;[T]`. Hope that helps, as opposed to just confusing you further. :)
Yes, good catch, wrote documentation from scratch so didn't bring that over from the golang library. Has been added.
Does using a match like this take n comparisons, compared to the hash map's O(1) lookup, or does the compiler build some sort of jump table?
Amusingly, I'm assuming that rust-url is still built against a pre-beta version of the compiler, since Servo itself hasn't updated for a while. :)
I haven't asked for a while, but for easy cases like this rustc should be building a jump table, yes. (The routine to generate code for matches can take several different approaches depending on contents of the match arms, it's reportedly one of the more complex parts of the compiler.)
No need to worry, you're fine now. :) (To everyone else, there was a post about this yesterday that got caught in the filter and basically fell off the page before ever being seen by anyone, so I gave permission to repost it.)
&gt; Rust was paied great attention in China. We don't get much news from Chinese Rust users! :) Who is organizing the event? Is there a link that people can use to follow up with you?
Is the risk triggering an ICE at a later point, or miscompiling?
Both, I guess. But I'm not on the rustc team, so I don't know what checks they have in place. I'm just not sure if rustc has had enough coverage to rule it out.
Well the intent is a regular meetup spinning off of it, so I'm sure we'll be seeing you soon enough!
Yes, I was a bit surprised, too, when I learned about that. Anyway, thanks for the support. I think somebody else already requested its stabilization, even though without a concrete use case.
Does it have a chance to actually be included in Firefox?
Alright - who is in Alice Springs?
A C-style enum gives you constants *and* exhaustive matching.
How is the data collected?
I thought Firefox builds with Visual Studio on Windows while Rust is limited to mingw. Would that not hinder any attempt to include Rust code in Firefox?
Haha, again? You've got mail.
I think you should post the venue, whether there will be any talks, etc.
day day up
I assume they're happy to ship rust code on one platform to start out with.
&gt; unsafe impl&lt;T&gt; marker::Send for RingBuffer&lt;T&gt; {} &gt; unsafe impl&lt;T&gt; marker::Sync for RingBuffer&lt;T&gt; {} Wouldn't you have to require `T: Send` resp. `T: Sync` for this to be safe? By my reading this would currently allow you to transport non-`Send`/`Sync` types between threads by wrapping them in a `RingBuffer`. (But it's possible that I don't understand how OIBIT works.) `Send`/`Sync` bounds may also be warranted on `get`, `put`, and/or the `RingBuffer` type itself.
Only supporting back to rhel 6 presumably.
I completely agree. I might be tired, but I've pored over the `rc` module for a bit now and I can't see any reason why weak references should keep the value from being unwrapped. The logic is almost exactly the same as dropping the last strong reference, except, obviously, the contained object isn't destroyed. I wouldn't call it a bug, though; there's probably some clear design decision in this, it's just not very apparent. I'd love for a team member to weigh in on this. Unfortunately there's not really a way to work around this outside of the stdlib without causing a memory leak. `forget()`ing the last strong reference will prevent the strong refcount from being decremented to zero and the internal heap allocation won't be freed. Unsafely copying the contained object and then letting the `Rc` drop will obviously invite a use-after-free issue for contained types that also manage their own allocations. **Warning: the approach I am about to suggest is *massively* unsafe. Attempt at your own risk.** Getting the contained object via `ptr::read_and_drop()`, and then letting the last `Rc` drop, *should* give you the contained object without causing a leak or use-after-free. It sets the drop flag on the pointed-to memory so that its drop glue will not run~~, but doesn't waste cycles zeroing it out (which would also prevent the drop glue from running, IIRC)~~. I would only use this as a stopgap solution, **if you really need it**, until a safer one presents itself. This will probably not work forever as [drop flags are currently in the process of being redesigned.][1] [1]: https://github.com/rust-lang/rfcs/pull/320
No; you are borrowing `v`; nothing else happens. If you adjust the code to: fn main() { let v = vec![1,2,3]; let _m: () = &amp;v; } The error given is: &lt;anon&gt;:3:18: 3:20 error: mismatched types: expected `()`, found `&amp;collections::vec::Vec&lt;_&gt;` (expected (), found &amp;-ptr) [E0308] &lt;anon&gt;:3 let _m: () = &amp;v; ^~ This trick lets you find out what type the compiler thinks a given expression is. Here's an expanded example that shows a few ways of going from a `Vec&lt;i32&gt;` to a `&amp;[i32]`, with the steps (hopefully) spelled out in full: use std::ops::{Deref, Index}; fn main() { let v = vec![1,2,3]; let v_ref = &amp;v; // Use auto-coersion; the compiler knows this is OK because there exists // impl&lt;T&gt; Deref&lt;Target=[T]&gt; for Vec&lt;T&gt;; given &amp;Vec&lt;T&gt;, it can // implicitly produce a &amp;[T]. let _v_slice: &amp;[i32] = v_ref; // Alternate: Use deref sugar to get [i32], then re-borrow. Note // use of `v` instead of `v_ref` here (see below). let _v_slice: &amp;[i32] = &amp;*v; // Alternate: slice the Vec&lt;i32&gt;, then borrow result. let _v_slice: &amp;[i32] = &amp;v[..]; // Explicit conversion (with Deref sugar, like `&amp;*v` above) let _v_slice: &amp;[i32] = ( &amp;( // : &amp;[i32] *( // : [i32] // &lt;-- desugars to deref call *( // : Vec&lt;i32&gt; v_ref // : &amp;Vec&lt;i32&gt; // read up )))); // Explicit conversion (without Deref sugar) let _v_slice: &amp;[i32] = ( v_ref // : &amp;Vec&lt;i32&gt; // read down .deref() // : &amp;[i32] ); // Explicit conversion (without Index slicing sugar) let _v_slice: &amp;[i32] = ( &amp;( v_ref // : &amp;Vec&lt;i32&gt; // read down .index(..) // : [i32] ) // : &amp;[i32] ); }
Heroic!!
Is it possible to make turning this on and off an option to the compiler?
There is a MinGW dependence policy. One of the things blocking rust in Firefox is the MinGW dependency. It is a goal of Rust to remove this dependency in the future. 
I live in Cologne, but my Github profile just says "Germany".
You might be interested in the projects under https://github.com/contain-rs
&gt; what I need is "multi-consumer, single-producer" I'm not sure how heavy in weight Rust's channels are, but having one channel for each connection thread is one possible way. The Redis thread would then send the same message to each thread. Not sure if this is scalable at all. &gt; That second problem is that, as I understand, receiving messages from the websocket is a blocking operation, so there's no way for me to wait for messages from the client while also waiting for messages that come from the "broadcast channel". There's [Select](http://doc.rust-lang.org/std/sync/mpsc/struct.Select.html) (usually used with the `select!` macro) which listens on multiple channels and returns a handle to one as soon as one becomes ready. Sadly, it's marked as unstable.
pcwalton is of course right (barring any errors in codegen masked by assert statements, but LLVM engineers are probably above such types of error).
&gt; And it will use OS processes in order to sandbox tabs from each other and from the trusted parts of the engine. How would it work if I dragged and dropped one tab from one instance of &lt;Browser-Servo&gt; to another instance? This works smoothly on Firefox.
I'm in essentially the same boat, implemented something like a person database api with crud functions.
Firefox doesn't use mingw for building, that's an issue. Also other things which I forget. 
An incubating start-up in Develer, [greenApes](https://www.greenapes.com), is planning to use Rust in a deployed micro-service. I'll let you know how it goes.
It's from the information you give (or don't) in your Github profile.
We're not planning on directly stabilizing it anytime soon, though we _do_ want to try to land some sort of generic "allocate me x bytes please" API reasonably soon. &gt; std::raw Not likely to become stable. We currently don't make any guarantees about the layout of internal structures, and I'm not sure when we plan on doing so.
There's also one on the Desolation Islands in the middle of the ocean.
The presence of assertions is controlled by a flag that is passed to LLVM when LLVM itself is being compiled. I imagine that you could find a way to separately compile LLVM twice, once with the flag and once without, and decide which of the resulting artifacts to use with the aid of a compiler flag. But that doesn't seem like much of an improvement over just having both a nightly version of the compiler installed (for when you want assertions) and having a beta version installed (for when you don't) via multirust.
Good progress made. This will defiantly improve development speed.
Oh my, *no*. You have to understand that macro expansion happens at the *lexical level*. That is, macros have *absolutely no access to semantic knowledge whatsoever*. They can't see variables, constants or types, because that information *doesn't exist when they're expanded*. The best you could do theoretically is a macro that expanded a *literal* string... but you can just do that by removing the quotes from the string in the first place. I also can't think of a practical use for a macro that somehow constructs a string literal that couldn't be served by just generating token trees... aside from incomplete grammar constructs, mind. So I suppose there's that, at least, but I don't know if there are enough fundamental macros in place for that to be feasible.
Fantastic - really great to see such progress :-)
Definitely! What date/time were you planning on?
Can't you implement a socket timeout manually by selecting both a socket and a timer channel? May not be efficient, but it should work.
Continuations refer to callbacks or coroutines. I haven't watched this yet, but "chaining" sounds more like composition. 
Good catch; however, in this case only `T: Send` is required for `T: Sync`, as the data structure performs the synchronization itself and it never returns references to the interior type. I submitted a PR to fix this. It is also not necessary to add bounds to the functions or the type, because it's perfectly safe to use with those types in a single thread.
I haven't seen the lecture yet but continuations can be used for composition as well. See [CPS](https://en.wikipedia.org/wiki/Continuation-passing_style) for ex. (ninja edit: As well as callbacks, co-routines and more. Very useful in functional languages)
I think it works for any number of `references (&amp;)`. I'm not sure if the following is semantically correct, but it seems to compile. No problem. let v = vec![1,2,3]; let _v = &amp;&amp;&amp;&amp;&amp;v;
Does Firefox even support running multiple instances simultaneously, as opposed to just multiple windows of the same instance? I've personally never managed to get two different instances of Firefox running at once (such as with different profiles, or even different release channels).
Would anyone who has used this like to provide a review?
A fun/horrid hack is to use Vec::with_capacity(x) and then v.as_mut_ptr() and then coerce to a ptr you need. 
The Rust compler is written in Rust, and so will always be able to use unstable code internally. Otherwise, it wouldn't work!
Makes sense. Thanks!
How would you implement something like `uv_loop_t`? The struct has [fields that change](https://github.com/libuv/libuv/blob/v1.x/include/uv.h#L1434) depending on the OS. Is it possible to ignore these (since they're private), or would you have to implement the same thing in rust using `#[cfg(...)]`?
You need them in there for consistent layout, but `#[cfg(...)]` will handle them just fine.
/u/daogangtang I got your email with your info. My reply though bounced as undeliverable, so I'm just letting you know here.
Yup! I'm a huge fan of Haskells Pipes library, which are composable continuations. See also, exactly what a monad is. Promises are also composable continuations. It's just not *function* composition at that point. 
That's pretty much what I'd thought...but I wanted to ensure there wasn't something I was unaware of. It's a common occurrence of mine to find out that I'm wrong about things...especially Rust related :)
That's RHEL 5.
Very nice article. Though the introduction, which promised "[easy talking] to languages like Python and Ruby just as seamlessly as with C" caused me to expect something that wasn't there. :(
There's no sort of global 'turn off all the checks' switch. You can't even change the out-of-bounds stuff off with a swtich, you have to use a different, unsafe method. The only checks that turn off in a release vs a normal build are the integer overflow checks.
Very nice! I think these, "Why would/How could Rust be applicable to me if I write in [x] language?" articles are awesome :)
I'd guess this would be just as seamless in Servo, as fundamentally it's just a layout engine with no notion of windows. The browser chrome would be the one responsible for the task of determining which tab appears in which visible window.
Fair enough - I'm using nightlies anyway (as I'm currently experimenting with lint plugins).
No idea. The whole point of Rust is the borrow checker, as far as I'm concerned. That said, I know /u/pcwalton was in favor of adding a flag or something.
I agree: they aren't – for a low-level systems programming language. But there indeed is some high-level abstractions – like composable futures – that manage to make things much flexible and straightforward. Fortunately Rust – I think – is low level and expressive enough that we'll be able to see such features as library-implemented features in the future. (Maybe some compiler magic needed for better ergonomy, though?)
&gt; I'd guess this would be just as seamless in Servo, as fundamentally it's just a layout engine with no notion of windows. I meant in the browser, which is why wrote Servo-browser (I don't know what the browser would be called).
I'm coming at this from the perspective of games programming where security is less of a concern than raw speed. Disabling runtime checks in release mode seems like a common practice, so I was curious if you could do that in a global way in Rust (no, according to /u/steveklabnik1). I wasn't aware that unchecked accessors were available, though, so in practice I imagine it will come down to profiling and only performing the unsafe operations in performance-critical code. On a related note, do you know if there's any way to perform an unchecked downcast from `&amp;Any` to a concrete type?
:+1:
Whoops, thanks, too much time trying to build binaries for old glibc versions. I'm still disappointed RH aren't providing devtoolset-3 for rhel 6 Edit: add thanks for correction of sloppy recollection!
Ah! I didn't know you were in the Boston area; I figured you (and most of the Rust team) were in the Bay area, but it looks like it's considerably more distributed than I originally thought. Anyhow, I was hoping to use the release party as an excuse to meet some local Rustaceans and a jumping off point for a more regular meetup; so even if you can't make this one, hopefully it can turn into a more regular event.
No, it's installed as a plugin. I consider that a positive.
&gt; time crate gave errors because it could not find gcc. The `time` crate links to C code, and therefore, _does_ need the MinGW stuff. But if you're doing just pure Rust, you don't need it. Lots of useful things are C bindings, so it's still probably worth it.
Right well maybe I didn't articulate myself clearly. I have enjoyed my time doing pure rust, but now I need to do relatively simple things such as sending an email and getting detailed date/time information, both of which require time crate, which requires c-bindings, which is putting me in the frustrating situation I am in now that I have no idea how to solve.
Hey /u/captain_hoo_lee_fuk, your success has inspired Rust to work on supporting musl natively: https://github.com/rust-lang/rust/pull/24777 It's not quite the same use case as what you were looking for (concerned with building Rust programs with musl rather than the Rust compiler itself), but thought you might be interested. :)
I'm glad you found a safe solution, but I think I might still open an issue on GitHub to see if this is truly the expected behavior of `try_unwrap()`.
I use go generate in some projects, but mostly just to generate serialization and deserialization methods for some structs in msgpack and json. It would probably work for this, but man, it'd be nice to just have it be part of the language. In that vein, in that go-datastructures repo a dev added an issue and some examples showing what could be done with a version of gcc go he/she hacked :D. Was pretty interesting, but they were also right in that it would probably never become part of the language.
Excellent thanks, that looks perfect! I had installed MinGW but I probably didn't do things right so it's good to have some best chance instructions to follow. I'll give that a go later tonight!
That's awesome! Glad to see this is getting upstream. Yeah it probably makes more sense to focus on static linking first, as there aren't many musl-based distros out there so dynamic linking is probably not very useful, but one of the major reasons for using musl is its support for static linking.
Ah, sorry I misunderstood. I assumed you use on of the old installers (which required gcc). You might have accidentally installed some weird/old/incomplete version of mingw. Try not to mix mingw from different sources or different versions. Check if you can compile simple hello world in C. Paste somewhere output of `gcc --version -v` and paste whatever compilations errors you are getting from cargo. As for mingw version AFAIK it's recommended to use either [MSYS2](http://sourceforge.net/projects/msys2/), [mingw-builds or win-builds](http://mingw-w64.yaxm.org/doku.php/download).
The other day I read "[Representing Monads](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.8213&amp;rep=rep1&amp;type=pdf)" which goes into detail about the connection between monads and delimited (aka composable) continuations. Very cool stuff!
I tried running your example in playpen but it produces the expected LLVM IR and assembly. It would help if we saw the exact output you're getting.
I believe that, at some point recently, it was changed such that trait object references had an implicit `+ 'static` bound on them by default. I don't know what the actual rules are, but it looks like `&amp;'a A` implicitly narrows down to `&amp;'a (A+ 'a)` without further work. You can test this by changing `I` to `struct I&lt;'a&gt;(&amp;'a i32);`. On the other hand, you definitely need a `+ 'a` constraint when dealing with `Box&lt;A&gt;`. In the following, modified version of your code, you definitely need it in `Box&lt;A + 'a&gt;`: trait A { fn val(&amp;self) -&gt; i32; } struct Bar&lt;'a&gt; { foo: &amp;'a A, } struct Baz&lt;'a&gt; { foo: Box&lt;A + 'a&gt;, } struct I&lt;'a&gt;(&amp;'a i32); impl&lt;'a&gt; A for I&lt;'a&gt; { fn val(&amp;self) -&gt; i32 { *self.0 } } fn main() { let x = 42; let i = I(&amp;x); { let b = Bar { foo: &amp;i }; println!("{}", b.foo.val()); } { let b = Baz { foo: Box::new(i) as Box&lt;A&gt; }; println!("{}", b.foo.val()); } } 
[RFC 599](https://github.com/rust-lang/rfcs/blob/master/text/0599-default-object-bound.md) lists the current default bounds; `&amp;'a A` will in your case be precisely equivalent to `&amp;'a (A + 'a)`.
You could add this option and market the version as C+++. :-)
&gt; And then I tried to abstract the font rendering code into a widget concept, and everything broke down. The Rust compiler has many false negatives - situations where it is a compile error due to safety, but actually it's pretty obvious that there are no safety problems. I would love to hear more specific feedback about this. Don't leave it there! :)
This isn't very useful unless you say exactly what you were having trouble with in Rust.
And, probably, stop emitting `noalias` for references. `noalias` without borrow checker would be like walking through a minefield. This would make Rust worse than C++ in some respect, because the latter has type based aliasing restrictions at least.
I was actually pretty disappointed at the author's comment on the GTK bindings. They seem pretty solid from my perspective. Though they're still missing some features, the contributors are *super* nice and [take user requests into consideration.][1] However, I understand the author's frustration if they were trying to get it working on Windows; it's still pretty bumpy even for someone like me who's used to build problems. Conrod is awesome and I was happy to help out with it, but I will be frank; if you want to make an application that feels really *solid*, it's going to take a lot of work. Using GTK or Qt is really attractive because the toolkits themselves are very mature, and focus on a native look and feel, which puts a lot less pressure on UI design. [1]: https://github.com/rust-gnome/gtk/issues/28
Either just let it panic or use a function that returns Option like this: fn division(dividend: i32, divisor: i32) -&gt; Option&lt;i32&gt; { if divisor == 0 { None } else { Some(dividend / divisor) } }
Most lints are on by default, IIRC. It probably wouldn't be *overly* difficult to create one for this purpose but I'm not sure how useful it would be. Perhaps this could be fixed by adjustments to your convention; I personally prefer to keep generic bounds as wide as possible. You shouldn't be adding traits to type bounds unless you actually *need* something from them, be it a method or a safety guarantee or what-have-you. That way, you don't introduce any unecessary coupling and your generic APIs are as accepting as they can be.
excellent post. curious what synth engine you were using. I'm starting to poke around puredata, supercollider, Csound, and the live coding libs in haskell, clojure (overtone, tidal) etc, to see what's available sequencer-wise. I guess i could use another utility to do SysEx dumps but i need NRPN's to drive a hard synth (Mopho
&gt; This means that the zero overhead FFI not only applies when Rust calls into C, but also when C calls into Rust! #[no_mangle] pub extern fn double_input(input: i32) -&gt; i32 { input * 2 } This might look like a safe example, but it isn't. Rust might panic, ~~or even worse, have undefined behaviour,~~ if given the wrong input (so that the calculation overflows). I think that's a quite important part left out in this blog post - i e, what happens if Rust panics inside this function and how to handle that? (Side note - I thought you were supposed to write `extern "C" fn`, not `extern fn`. Can there be a difference between these two?)
Here's how it'd go for me: 1. Start research 2. See ardour 3. Give up
Strange, it's showing up in my tests. $ rustc lto-test.rs -O $ nm lto-test.exe | grep foo 0000000000401520 T foo 
There's a reason for this. Examples aren't very forthcoming right now because I'm very tired, but there is a reason.
Ok, now I have to give it a go!
I'm on OSX. Same OS as the speaker (I saw the Yosemite background in the talk).
&gt; undefined behaviour, if given the wrong input (so that the calculation overflows). It's worth noting that non-release builds have assertions to check for overflow, so hopefully that helps with this. &gt; what happens if Rust panics inside this function and how to handle that? It's undefined behavior to unwind over the FFI boundary. We have http://doc.rust-lang.org/nightly/std/rt/unwind/fn.try.html , which isn't stable yet, that's intended to help out with this. &gt; Can there be a difference between these two? `extern fn` is short for `extern "C" fn`.
&gt; not much will have changed from the beta I'm currently using That's the good and bad thing about the train model: there's sort of a twelve-week waiting period of relative stability before a release, so pre-releases aren't that exciting.
This sounds like a tree with parent pointers. I implemented various approaches and wrote up some explanations: https://github.com/SimonSapin/rust-forest
That's true, I suppose. There's an activity monitor thing he uses in the talk that made me assume he was doing it on osx. I actually figured my problem was in not understanding the difference between the following: `thread::scoped` `thread::spawn`
Shouldn't it be checked with "nm -D"? (Thanks for your patience and time :P)
http://blog.piston.rs/2015/04/07/piston-0.1/ says the core works on beta.
Wrong subreddit dude. http://www.reddit.com/r/playrust
So _Pythonic_! :D
Do you know why I can't use ``libc`` crate in Windows: extern crate libc; fn main() { } ``rustc`` says: test.rs:1:1: 1:19 error: use of unstable library feature 'libc' test.rs:1 extern crate libc; ^~~~~~~~~~~~~~~~~~ error: aborting due to previous error rustc 1.0.0-beta.2 (e9080ec39 2015-04-16) (built 2015-04-16)
Are you using Cargo and have you added `libc` as a dependency? It's only available as an external crate. (Or, it is also embedded into the Rust distribution I think, but you can only use it that by enabling the `libc` feature, which can only be done on Rust nightlies.)
I was building the synth engine itself.
Ok, setting up mysys with those instructions worked (with the caveat of having to add msys/mingw64/bin to my environment path). Apparently whatever I did with the mingw installer was incorrect. I'm now able to run `cargo build` and work on projects in powershell that require time, and other c-binding dependent crates. Thanks again.
woo! any time.
I can only guess, but the current rules looks quite reasonable. In C++ TBAA is crucial because it is the only thing they can rely on. But in Rust there are `&amp;` references with much better guarantees, than type-based ones, and they are widely used. And there are `*` pointers, which don't have any aliasing guarantees at all and [don't break code doing various low level transmutations](https://lwn.net/Articles/316126/), they are used less often and not so crucial to optimize (?). (Anyway, some selectively used `restrict`-like attribute for raw pointers would probably be useful.)
Didn't realize this even existed, thanks for sharing! I'm now heavily considering taking a dependency on this for query_rs to save myself the time and effort of writing similar iterators for that project.
I have similiar problems. It seems rustc will emit some dead code marked to be exported only if a library is being build. The same code is removed when building exectuable, I guess on an assumption that if you're building final executable there's noone to export this symbol for anyway.
You almost seem to address your own concerns over usefulness! Such a lint would help you create more unrestrictive APIs. I personally think that this is a great idea.
That'd be nice. Sadly it's the Yandex geocoder going awry.
I guess I did. What should be the process for getting another lint in `rustc`? Does this go through the RFC process because it *technically* affects the language user or do we just add it to, e.g., the `dead_code` lint?
Yeah. I'm mostly trying to make sure the basics are covered at 1.0. I'd love improvements here, though, if you want to elaborate on why Cell is awesome.
But if you can't use all the members of `self` anyway, then why pass the entire `self` type? Just write a free function to do the same thing, using `let` destructuring to split out the structure into separate components. Sure, you have to list the fields you *are* using, but is that really worse than having to list the fields you aren't? Either way, you're explicitly annotating fields to tell Rust they don't alias.
I'm not sure how I feel about this. It seems like a bad idea to work on 1.1 before even releasing 1.0, because that means there's fewer people working on polishing the release. Version 1.0 will be many people's first impression of Rust, so it needs to be as polished as possible.
Thanks. I'll bookmark this and see if I can hammer it into something for that page sometime next week.
weird thing is it doesn't complain about it being dead, furthermore it won't export it even if it's not really dead (i.e. you call the function you want to export from the main). Does anyone know if the devs of the language buzz around here? or should a bug report be filed?
I've decided to ditch the universe and instead redesign it from scratch. What? It better fit my use case.
You could do the same as in C and skip the `InternalMillipede` struct, but then it would be the user’s responsibility to make sure `Millipede` never moves by e.g. only having it in a `Box`. This is of course a memory-safety hazard in both languages.
At some point there was a talk about do notation in Rust (and even some macro implementations). Also the idea of tail-recursive functions (by calling `become` instead of `return`) that haven't materialized yet, but seem important enough. I was hoping that Rust would move a bit more to the functional side, but curried functions seems out of scope for it (I still hope for some library-level support for currying, perhaps relying on macros) But perhaps Rust 1.x, for some x, will become more functional? I don't think its *syntax* will ever become clutter-free in the same sense as Haskell or OCaml though. Or that memory management will cease to be a concern.
You’d have to use `RefCell` in all more complex examples which may and will panic.
Is there anyway to compile the sample code other than using Cargo?
The tail-recursion we have now is more or less fine, though I would like to see ```become``` make an appearance, even if only to cause compilation to fail if your tail call can't be optimized. There is (or was) strong resistance to do-notation in some quarters, but the objections I have heard sound like nonsense to me. I think this was a rationalizatoin of the earlier "Rust is not Haskell" stance on anything that looks like a Haskell feature. But I just watched an hour and a half video about how C++ needs monads to handily beat 300 Intel engineers at making parallelization efficient—so what are we afraid of? Implicit currying isn't something I expect from any language. It's nice when it's there, but it really only benefits languages like ML/Haskell and so on. I wish explicit currying was nicer. The example I gave isn't even sufficiently general because of the static bound. It would be rather nice if you could ask the compiler to curry things for you, working out the optimality/generality tradeoffs per invocation. Memory management will always be a concern. It wouldn't be Rust otherwise. All I could ask for is to have certain things made cleaner, be it by adding more to the language or by building it in libraries with macros and syntax extensions.
&gt; You could do the same as in C and skip the InternalMillipede struct, but then it would be the user’s responsibility to make sure Millipede never moves by e.g. only having it in a Box. Is it possible for a caller to move the struct out of the Box? I was expecting a Box to have an `into_inner` function, but it does not. If this is not just an oversight - if `Millipede::new` returns a `Box&lt;Millipede&gt;`, maybe that would be a safe interface? Or could there be other ways to get the Millipede out of the box? &gt; This is of course a memory-safety hazard in both languages. Well, it's impossible for the user to move out of the box in C if you design it as such (by having just `typedef struct millipede millipede` in millipede.h and the full struct definition in millipede.c). 
You can dereference a box with *b.
Good question. We haven't solved specialization, which means that in generic `T: Iterator` code we can't conditionally take advantage of further iterator traits for optimizations. If we could, maybe this would be useful (unless llvm is so good it already compiles our contiguous iterators into "perfect" code).
If you have any cool general iterator functionality, we're happy to have them in itertools too
Sidenote, `std::slice::from_raw_parts_mut` allows implementing slicing without bounds checking in a bit cleaner way.
&gt; slice::Iter also offers a way to go back to a borrowed slice (but it's an unstable function for now). It implements slicing (Index trait), so you can use `&amp;iterator[..]` to get a slice in stable Rust.
Works really well and is very easy to setup. Something that would be really nice to have (unless I just haven't found it yet) would be pre-made run configurations for the common cargo tasks like test, bench and run. Haven't tried the debugger yet, but it looks very promsing. 
One thing is that in the `C++` version, you would trigger UB in `lsb_differ_index` if `a == b`, because `__builtin_ctz`is undefined for zero. OTOH rustc asks LLVM to produce code that is defined for zero as well, which leads to less efficient assembly. In this case adding two conditional moves. 4.03 │ movzbl %cl,%ecx 0.04 │ bsf %ecx,%ecx 4.61 │ cmove %r10d,%ecx 8.47 │ cmp $0x20,%ecx 4.08 │ cmove %r11d,%ecx `%r10d` is set to `0x20`, `%r11d` is `0x8`. The numbers in the percentage of time spent for that instruction (output from `perf`). At first glance, it looks like LLVM could lower that to just a single `cmove`, but I didn't think about it enough to say for sure. Edit: I guess this raises the question if we want to expose the version of the intrinsic that is undefined for zero, too.
Nice one. I'm using a lot of zipped vec.iters(), to compare (with some non-standard notion of equality) vectors of trait object refs. I was thinking about "lifting" my eq-functions over the vec, so that is_x_eq_vec(left : &amp;Vec&lt;X&gt;, right : &amp;Vec&lt;X&gt;) -&gt; bool { left.len() == right.len() &amp;&amp; left.iter().zip(right.iter()).all(|(x, y)| is_x_eq(x, y)) } would automatically be generated. What's the *rusty* way to do that? Is this an ideom that others are using as well?
The function looks pretty good already, doesn't it? It would be rustier to use slices in place of &amp;Vec, though: fn is_x_eq_vec(left: &amp;[X], right: &amp;[X]) -&gt; bool due to deref coercion, this doesn't change how the funciton is called. As for generalizing it, the first step could be to take the comparison function as a closure argument?
Easter egg time: https://github.com/bors
So I'd have a function like the following? fn is_custom_eq_slice(left: &amp;[X], right: &amp;[X], eq_fn : Fn&lt;X, X&gt;) -&gt; bool { left.len() == right.len() &amp;&amp; left.iter().zip(right.iter()).all(|(x, y)| eq_fn(x, y)) }
You can go crazy generic and turn it into this, which should produce the same code for the slice case. Not sure how much is won here, except some generality over all "extactsizeiterator" which are just a few (but most collection iterators). use std::iter::IntoIterator; fn is_custom_eq&lt;I, J, F&gt;(left: I, right: J, mut eq_fn: F) -&gt; bool where F: FnMut(I::Item, J::Item) -&gt; bool, I: IntoIterator, J: IntoIterator, I::IntoIter: ExactSizeIterator, J::IntoIter: ExactSizeIterator, { let i = left.into_iter(); let j = right.into_iter(); i.len() == j.len() &amp;&amp; i.zip(j).all(|(x, y)| eq_fn(x, y)) } fn main() { is_custom_eq(&amp;[1, 2, 3], &amp;[-1, -2, -3], |x: &amp;i32, y: &amp;i32| x.abs() == y.abs()); }
Nice!
&gt;make something a library because that's easier to get accepted in the committee than a language feature (even if there is good argument that what is provided is fundamental) Heh sounds like rust.
You can use rustc directly for simple things, but as soon as you need a dependency, Cargo becomes much easier.
Actually that does not sound like rust at all. I think that rust is very good at providing just the right amount of language support by using language items. The tradeoff is very simple: libraries give the most flexibility at the expense of built-in ergonomics. C++ fails at both extremes, it has many redundant features that should NOT be part of the language as well as many useful idioms that lack much needed language support. 
Bitfields really shouldn't have field syntax (they don't behave like normal fields, see C for why this is bad). Bitfields with method syntax could be done very well by a syntax extension (see the `bitflags!` macro). They may be included as a built-in syntax extension a-la `#[derive(..)]` or `format!`, but not more than that. 
Thanks, that's exactly what I was after.
Sure, treating them directly as fields may not work out, but allowing you to construct them like normal struct/enums and destructure them in match expressions would be convenient, and I think would be somewhat awkward to do with just a regular macro or syntax extension. I haven't thought through it in detail, however, so I could be wrong.
The annotations you're proposing break the promise of the interface (that is, someone who writes to the public interface can be broken by internal changes to the structure). I suppose you could argue that this is no different from lifetime constraints, and that there is no promise broken as long as the annotations are explicit, but it seems to me to be an awful lot of machinery of limited utility (it can *always* be worked around by sufficiently complex member functions). I would much rather focus on fixing Rust to allow things that you *cannot* work around in safe code.
And I'm currently working on a panic-free libcore, which is another way to make certain you never panic.
I asked the same question not long ago, and the answer was that this was not possible, unless you write let array = [AtomicBool::new(false), AtomicBool::new(false), AtomicBool::new(false), AtomicBool::new(false), AtomicBool::new(false), AtomicBool::new(false), AtomicBool::new(false), AtomicBool::new(false), AtomicBool::new(false), AtomicBool::new(false)] 
What alternative would you expect to work?
I don't think this is (easily) possible with macros right now, because macros can't count. The closest thing I can come up with is ([playpen](http://is.gd/I3PGFF)): macro_rules! init_array { ($expr:expr; $($tt:tt)*) =&gt; ([$({stringify!($tt); $expr}),*]) } Explanation: expr is the expression used to initialise each element, terminated by a semicolon. Then, for each following token, one element is added to the array. The stringify!() is essentially a noop, but you have to use the $tt variable somewhere in the loop. 
I can imagine several alternatives: * possibility to initialize a fixed array from an iterator would be awesome. * cloning * some macro or language feature There is a panic problem to consider, i e, make sure we do the right thing if whatever generates the new items panics when only half the array is initialized. But that should be possible to solve, I think.
PR to fix the performance: https://github.com/rust-lang/rust/pull/24846 The unsafe rust code is as fast as the C++ code now. It wasn't in the above benchmark because I had built the code with `-g` to figure out where the conditional moves came from and then forgot to remove it again when I ran the benchmark.
As you said yourself, `Cell` only works if its contents are `Copy`. Thus everything which is more complex needs a `RefCell`.
Thanks! I actually stole this technique from borrowck ;P If you like writing lints like these, http://github.com/Manishearth/humpty_dumpty could use some help :)
The same toolchain works fine with some C code from another Pebble app, linked to all the same libraries. That code doesn't define _kill or any of the other missing symbols.
Actually, the docs clearly state that `i.peekable()` disposes of `i`: fn peekable(self) -&gt; Peekable&lt;Self&gt; Note that `self` is passed by *value*. Anyway, you could avoid that by doing it like `i.by_ref().peekable()`.
You might be interested in [this post](https://plus.google.com/+nialldouglas/posts/AXFJRSM8u2t), which was also discussed on the subreddit recently. To a large degree, Rust codifies the conventions of modern C++, while abandoning loads of backwards-compatibility cruft. So it's pretty compelling if you like "the C++ way of thinking" but find yourself frustrated with some of the language's archaic aspects.
The amount of "getting used to" required is the exact reason why I've moved on. Productivity is more important to me at this moment. 
You might find this useful to look at: https://github.com/mahkoh/scan
In these ocasions I find myself relying on: unsafe { mem::zeroed() }
It's up to the person writing the FFI bindings to declare arguments with meaningful pointer types. If a FFI function may mutate the contents of a pointer, it should be declared *mut accordingly.
It would be great that array initialization will call Default::default instead of Copy!!
It took me a while to understand what the title meant. The release binaries from Github are ~300MB, and extract to 1.2GB! Apparently Google has tons of public APIs. Cheers to Sebastian for all the work he's put in. I recommend anyone interested in this project to watch this video he made documenting the process: https://youtu.be/2U3SpepKaBE
&gt; When I call expect a method I expect to either do something with the object or do something on the object. Not give it away. Consuming it is doing something with the value (in my mind, at least). In any case, I've never personally encountered a scenario when a method moving a value was the cause of a confusing error message (i.e. where an equivalent free function would result in a clearer one): the compiler has always precisely pointed out where the move is for me.
&gt; I'm learning C/C++ right now Step number one: don't call it "C/C++". :) Such a language doesn't exist. You're either writing C or you're writing C++. Idiomatic C and idiomatic C++ are so _wildly_ different from each other that they might as well have nothing in common. Their similarities are skin-deep. Java and C# are _much_ closer to each other than C and C++ are and yet nobody says they're writing "Java/C#".
Yes, that's basically it. This can happen if you pass a pointer to a C library, for example, or to [a garbage collector](https://blog.mozilla.org/research/2014/08/26/javascript-servos-only-garbage-collector/).
You can still move when a `*mut` is in the picture, right? I think we would need to pass `&amp;mut` (or create an `&amp;mut` and convert to `*mut`) assuming we know the size of the thing.
I've got a prototype macro that should work in beta (doesn't use a synext), which looks like this for a similar example: scanln!("hello", a:u8, b:i32, c:String =&gt; (a,b,c)) **Edit**: to clarify: you interleave string literals and captures. The only problem is that I don't have time to polish it yet. If someone else wants to take the current `macro_rules!` stuff I have and run with it, let me know.
I think the real reason is that the only one of the proposals that is (IMO) at all likely to be accepted (`?Leak`) can be done backwards-compatibly. The others would all involve preventing `Rc` from being used for types that it can currently (safely) be used with, or abandoning it altogether; given how much trouble `Rc` has caused the type system (this isn't the first popular API that had to be yanked because someone forgot about `Rc` at first), I can almost guarantee that if people thought that was acceptable they would have done it already.
&gt; I don't think I can make my point any clearer I may not necessarily agree with it, but I understand your point (there's no need to shout it at me, please!). I was just saying that I've never personally encountered a circumstance where a method consuming something was dangerous/confusing to me, and in my mind this validates the design: method chaining feels often more natural to me (yes, even with ownership transfer), so offering it is nice. I guess this may be a matter of Rust idioms/expectations differing to those in other languages.
Hi, I know it's a crosspost, but given the current users/subreddit split, I'm fine with that :). I'm struggling with this problem for quite a while and I'm not sure if it's me or larger problems at hand there. See the playpen here: http://is.gd/oiUh5M
Thanks for that, it was A enlightening, B hilarious. That's my Monday morning off to a better start than usual.
Why would you want that? Can't you just do `let array: [T; N] = Default::default()`?
You can use `std::mem:uninitialized` and a loop ([playpen](https://play.rust-lang.org/?code=use%20std%3A%3Async%3A%3Aatomic%3A%3AAtomicBool%3B%0A%0Afn%20main%28%29%20{%0A%20%20%20%20let%20mut%20array%3A%20[AtomicBool%3B%2010]%20%3D%20unsafe%20{%20std%3A%3Amem%3A%3Auninitialized%28%29%20}%3B%0A%20%20%20%20for%20i%20in%20array.iter_mut%28%29%20{%0A%20%20%20%20%20%20%20%20*i%20%3D%20AtomicBool%3A%3Anew%28false%29%3B%0A%20%20%20%20}%0A}&amp;version=beta)). It needs unsafe code though. 
I hope this gets fixed in some way. I wouldn't want rust to end up needing something like c++'s rule of five in ten years..
Aha, so you then have to expose `Legs` to the caller, because the caller needs to allocate both `Legs` and `Millipede` manually, and then call a third function to connect them. &gt; When you start using Cell like this, even though the code is safe, that feeling will go away. If you mean that feeling that "I shouldn't have to use Cell here, because the only time I need to change it is during construction", I agree.
I think the problem is that as stated, your trait bound isn't quite right... I was able to get this to work, for example: http://is.gd/bWXg7c (the commented-out `AsRef` was just because it didn't work for `Vec`).
I totally second this: Writing small libraries as separate projects usually results in nice, orthogonal code, which is super-easy to use thanks to the Rust-Ecosystem and tooling. Thanks for the writeup - I wish I would have found a link to the actual tool you are advertising, as I'd be interested to run it on my own photo-library.
A closure captures the variables that are referred to in it; it cannot do any sort of partial borrowing. So where your `position` closure refers to `self.dlt`, it cannot know that it is just borrowing the `dlt` field (a partial borrow) but must instead borrow all of `self`. Ditto for the `map` closure; it wants to borrow `self`, not just `self.num`. The solution is to handle the partial borrowing outside of the closure: pub fn remove(&amp;mut self) -&gt; bool { let dlt = &amp;mut self.dlt; let num = &amp;mut self.num; num.iter() .position(|&amp;n| { if *dlt &gt; 4 { *dlt = 3 }; n &gt; *dlt }) .map(|e| num.remove(e)) .is_some() }
The difference between all the conversion traits, why each necessarily covers a different use case and cannot be combined with the others, and especially the difference between Borrow/AsRef are all areas I am totally lost.
I agree completely. If you dig into iron's internals, you will discover not a lot of code and a whole bunch of small, highly generic dependencies (with their own small generic dependencies). It's definitely the best way I've found to organize "large" rust codebases.
I’m not so into the compiler internals couldn’t you easily trigger UB by having a safe `forget`? In your example with `struct Foo(&amp;mut u32)` you end up having two mutable references to the integer that are afaik marked as `noalias`. Additionally you’re pointing to uninitialized memory after `data` goes out of scope.
I don't see that connection at all. This pattern isn't even bad in any way, IMO.
Gankro, you're one of a kind -- instead of writing the PR for this, you re-implement it all for a blog post instead, and have to write twice as much or more in the process! I don't agree with the title though because - I'd like to use different words - It's not bad in any aspect. Leaking the destructor is permitted but is bad. We just create a value that promises to set everything right once you are done with it, and the borrow checker makes sure you can't observe the transient state of the vector at all. On the whole, I totally think this is a pattern that we will come to use a lot. What we have done here is just an optimization, but we could explain it easier by having `.drain()` swap out the vector for an empty vector, and swap the drained version back in the destructor.
Pointer aliasing is a question of what values are usable, not raw pointer equality, e.g. let mut x = 1; let y = &amp;mut x; { let z = &amp;mut *y; } `y` and `z` have the same pointer value, but only `z` is usable so the code is legal. The nature of `forget` means that UB through `&amp;mut` aliasing is (AFAICT) impossible to trigger: the forgotten value is no longer usable.
Building both beta (stable) and nightly in travis is great, I saved notes on [the configuration I used here](http://users.rust-lang.org/t/psa-1-0-0-beta-2-is-out/1019/14)
The things we do with drain here aren't even feasible to do in C++, because we rely on the borrow checker to let us use the source vector as our own scratch space while the iterator is running. Well maybe it would be feasible in C++, but there is no compiler to check usage, so leaving the vector in this incomplete state would be.. much less advised.
You're easy to humour. I guess I envy that.
I hear this argument quite often and I find it very tiring. C is still (almost) a subset of C++. While idiomatic C and C++ may be quite different they share a lot more common behavior. C++ is separated from C by just a skin-thick layer. Imo it did never emancipate itself enough from C for having the earned the right of replacing the slash with an “and”. Nowadays C++ would be better of without the C.
1.2 GB of *binaries*? That is huge. Is that really to be expected for that many API's or is there some redundancy? Edit: Oh, it contains debug information. Without that it is 266MB, which is probably to be expected for that many API's.
Curious how people took this as an insult. I guess easily having a good time is bad? Hmm.
As an aside, it's funny that the int/uint drama had much more discussion than this memory safety issue.
There are twoish sources for leaks here: * `Rc` and `Arc`. * Panics in destructors. Number two is the really terrifying one (IMO). I suspect this is the one that will be fixed first--the proposal I'm fond of to do that is to essentially make every destructor `noexcept` in the C++ sense. Number one isn't nearly as terrifying, and once two is fixed you can have specific types opt out by just not allowing them to form cycles. However, if you *do* want to use `Rc` or `Arc` without leaking for *all* types *and* allow cycles, you will quickly run into serious issues (as in, undecidability). Getting Rust's type system to the point where you could represent every cyclic data structure people care about without allowing leaks is a language idea (maybe several language ideas) in itself, not something that can be grafted on in a couple of weeks.
In face of this behavior, would you actually need unsafe code to trigger memory unsafety? [This example](http://cglab.ca/~abeinges/blah/everyone-poops/#dealing-with-it) has unsafe blocks, but I don't know whether it's actually needed.
This is the first article I'm reading about Rust. Given all of the hype around this language, I have to say I'm baffled by the design choices and the naming conventions. Is this supposed to be the simple and safe C++ alternative? Because all I see is complex mess with insane bugs. 
I know the core team is committed to the release date, and nobody wants to reschedule the release parties, but.. is the consensus that this issue has 0 chance to postpone Rust 1.0? The problem isn't exactly the design pattern proposed in this post, but committing to this semantics for the entire Rust 1.x cycle. It just makes the language more tricky than it should.
Safe yes, but simple? I think Rust gives great benefits over C++, but requires getting familiar with quite a bit of additional knowledge. Also, you're getting wrong impression because the whole topic is about a bug. 
This might be the most beautiful solution i ever saw.
Well, that kind of goes against the initial goal of the post, avoiding the lifetime for Key. Ignore Vec for a second and just remove the local "From" implementation and you get this: http://is.gd/Vz4lx5 I am completely at loss _how_ the compiler exactly computes the bounds in that case, so it may be that they are not quite right. But it's rather frustrating that a rather generic "from binary" is so hard to build :). 
Why? What makes it huge? If it's mostly cli tools (hopefully available separately) - then it _obviously_ makes sense (e.g. 270mb / 70 API = ~ 3-4 mb). If it's API/SDK only, when I have to wonder why? What's that big in them? I suppose the former is the case, which makes it OK 
&gt; Naming conventions are a bit short at times, but otherwise it'd be worse than Java in verbosity (AtomicallyReferenceCounted would make quite the mess as opposed to Arc). There's no requirement to jump from one extreme to the other. `AtomicRc` would've been fine and many people agreed. Just nobody got around to implementing and pushing for the change (myself, of course, included).
I thought support for Windows XP had been dropped sometimes last year?
For Firefox? Nope, it supports XP: https://www.mozilla.org/en-US/firefox/37.0.2/system-requirements/
But making forget safe is backwards compatible but reverting it isn't. So why rush it for 1.0?
In this example (`Arc`) the issue I have is not the shortness itself but that the shortening results in a name with a completely different literal meaning.
If I understand correctly, Rust without unsafe blocks gives you several nice guarantees: 1) Memory safety. 2) Unreachable memory will be freed. 3) Destructors will run. If some library wraps unsafe code and calls it safe, many people will assume that they're getting the same guarantees. We can try to educate people that in truth they're only getting (1), but that's unsatisfying. What are the important use cases for Rc and Arc?
`Cow` is fun as well.
Oh yeah. :) 
&gt; We have already established = to assign defaults in type parameter lists for structs and for functions and methods, **so we don't have much choice but to use a different symbol for type equality.** Ahem, what about doing something like PHP7's [combined comparison operator](https://wiki.php.net/rfc/combined-comparison-operator) `&lt;=&gt;` except it'd just be used for type comparison, plus it doesn't look too bad when typed.
I think an important point here is that for people new to Rust the big picture context of the original article is very hard to grasp, and without understanding that context the article makes Rust look really, really bad. This is how qSOLid, Bewilderforce, and I (a new-ish Rustacean) read it before I dug into the comments here. A bit of context at the top of that article would help deflect unwarranted negative PR.
I think it would make `&lt;T: Iterator&lt;Item=u8&gt;` look like `&lt;T:Iterator&lt;Item&lt;=&gt;u8&gt;`. IMO not an improvement.
Heh. It wasn't exactly written with non-Rustaceans in mind, though I do think it's an interesting view into "the first world problems of a safe language" :P
Note that bluss actually wrote a PR fixing the issue before I ended up writing up the whole post.
I had a similar reaction (re: your first paragraph). I mean, it's cool that he's doing all this awesome Rust stuff, but isn't it MORE important to make sure the Homestuck flash stuff will keep working as browsers drop flash support?
I think we currently decided that leaking any kind of object can not be a memory safety bug, until we get `Leak`, and in that case `!Leak+'a` objects can't get stale/exist after the lifetime `'a`. The lifetime `'static` doesn't end, so such objects need not be freed.
Leak is an OIBIT - you won't need to `unsafe impl` it.
Not sure if it's possible, but `&lt;T: Iterator&lt;Item: u8&gt;&gt;` makes more sense to me.
&gt; memory unsafety that happens in corner cases, between the interface of two peculiar pieces of code that may be very distant (even in different crates), not contained in a unsafe block, and depending on a semantic that few Rustaceans will master (if C and C++ teaches us anything). Hm, I'm not sure what you're referring to: there is no threat to the basic safety guarantees in Rust here. This requires unsafe code in the guard, and the debate is largely about what that unsafe code should be able to assume.
Still not panic safe, but turning it into a macro is quite straightforward: macro_rules! init_array( ($ty:ty, $len:expr, $val:expr) =&gt; ( { let mut array: [$ty; $len] = unsafe { std::mem::uninitialized() }; for i in array.iter_mut() { unsafe { ::std::ptr::write(i, $val); } } array } ) ); fn main() { let myarray = init_array!(AtomicBool, 10, AtomicBool::new(false)); } 
I dunno, there's been quite a bit of discussion! - https://github.com/rust-lang/rfcs/pull/1066 (236 comments!) - https://github.com/rust-lang/rfcs/pull/1084 (37 comments) - https://github.com/rust-lang/rfcs/pull/1085 (58 comments)
EDIT: [moved comment](http://www.reddit.com/r/rust/comments/3404ml/prepooping_your_pants_with_rust/cqqg13n) to reply to OP instead.
Please see [my comment to the OP](http://www.reddit.com/r/rust/comments/3404ml/prepooping_your_pants_with_rust/cqqg13n) that tries to lay out some of the ways forward, and clarify the stakes here.
Any comments on this?
Instead of using a script, you can simply copy the Cargo binary to the directory containing the cross-compiler and give that to multirust as [indicated here](https://github.com/brson/multirust#custom-toolchains). Then when you want to compile something for my raspi, just do `multirust override raspi` followed by `cargo build --target=arm-unknown-linux-gnueabihf`. 
&gt; Any comments on this? About what exactly? It took a long time to do. It was pretty fun. Overall rust was pretty good except for 1 major issue.
Right, allocations. Well, eyeballs and problems. I figured that if more people read the article more angles would be analysed.
I think the PrePoopYourPants pattern has potential, but some refinement is in order. - Why poop your pants? That is a pretty drastic measure. First of all, your pants are not guaranteed to contain all of your poop. First consider if the fecal matter is more pellet-y - then some pellets can easily escape down your pant-legs. Then how would you clean them up? Pick them up and put them in your pocket? Another concern is more of a runny substance: then they might soak and penetrate the fabric of your boxers, and in turn perhaps run down your pant-legs, or even through the fabric of your pants. So, I propose to that you wear some kind of diapers. - But even if you are wearing diapers, that is considerably less comfortable than just being near a toilet in case of imminent nasty shit-bits. Or maybe you are *supposed* to be uncomfortable in such unsafe circumstances? I can buy that. Maybe the nasty, sludgy and stinky bits that you have to sit on while you program (or whatever you're doing in this scenario - eating some unsafe stuff?) is an anal-ogy for how uncomfortable you're *supposed* to feel - tense, alert, and very aware of the unsafe poopy soup you might be concocting if you're not careful. - How are you able to selectively shit out the *nasty parts*, and not the rest of the substance that you originally put in your mouth at the same time? Do you have some kind of magical colon? Does your colon have the ability to reorganize stools? Or, well, in the case of just shitting out the nastiest bits it wouldn't even be stools, but some pre-digested matter. But then how do you signal to the walls of your intestines to not try to absorb any nutrients that those nasty bits has? I guess the draining of fluids from the material is benign, since water is bound to be a benign substance in this anal-ogy. - A more immediate analogy for me when I encountered this was colostomy bags. Those seem more natural than just shitting your pants. But I'm not intimately aware of their use or the ailment that make them necessary, so I'm sorry if I'm off the mark on this one. So in summary, for the next iteration of the PPyP, I suggest: - Consider diapers over pants, for safety and containment. - Incorporate what the role of the toilet has for intermittent shits in this anal-ogy. - Elaborate on how such a controlled and disciplined colon is possible. - Colostomy bags might be a more apt anal-ogy rather than pants, or even diapers.
&gt; Heh. It wasn't exactly written with non-Rustaceans in mind, Well you're the one who shared it to proggit and HN. But your "first world problems _" point is noted. 
Yes, indeed; there is a potential for bugs that aren't related to memory safety. What I'm mostly trying to clarify is the impact on Rust's basic guarantees, since I've seen a lot of confusion on this topic -- e.g., people thinking that leaks make it possible to cause memory unsafety in otherwise-safe code. Rust, of course, does not and cannot guarantee that it will prevent *all* bugs, but it does try to categorically rule out certain *classes* of bugs (like memory safety bugs). I think it's very important to be clear on this point, so that people know precisely what Rust is, and is not, buying them. For other kinds of bugs, it becomes more a matter of tradeoffs. How easy is the bug to make? How complicated or unergonomic is the means of preventing it? In my experience, storing an RAII guard behind a reference count is already quite rare, and creating `Rc` cycles is also pretty unusual (although easier to do by accident). On the other hand, each of the proposed ways of catching this kind of thing comes with its own downsides, either through loss of flexibility, or through additional complexity (and need to ensure that trait objects are annotated with `Leak` if you ever want to store them within an `Rc`).
Strictly speaking I don't think the guard has to use `unsafe` code. Something somewhere needs to be using unsafe and relying on the dtor to fix invariants (which might be a safe operation in-and-of-itself).
I wasn't intending to "shout" or seem aggressive in any way. I'm sorry if that wasn't my intention. The emphasis was added just to draw attention to aspects that I thought were being lost in communication. I enjoy method chaining too, like in the example I provided where I first encountered this problem I was trying to chain. It's quite possible to do so, so long as I first create a reference to the iterator before calling `peekable` which is just another method in the chain. This issue isn't even the one that started my thought process on doing things with another language anyways :P I've said it a few times, but I'd like to keep this clearly stated - I still enjoy Rust's goals, but at the moment I don't think it's what I want to build things with. I'd like to see it evolve after a couple of years and pick up some mainstream use (widespread, not just a small group) to see what people do with it.
I think this is interesting, and points out a way that Rust has changed over time. We always assumed that OS developers wouldn't be using the standard library, because in the past, it assumed a runtime. Once the runtime was removed, it became feasible to do so. I'm pleasantly surprised that was the only real issue you ran into! Thinking about this and its implications would be good for deciding what no_std actually is, in the future, and the constraints we should design libraries in mind with.
&gt; I'm pleasantly surprised that was the only real issue you ran into! I was too. :) There were a few other issues that I had but they were mainly fairly simple to work around and would not really preclude rust from being used. The biggest of these was the fact that it is so hard to use static allocation.
"Opt-In Built-In Trait"
Sure, but either way you have to know, in advance, that you want to work with that type rather than `Box` (and this has to be true along any of the APIs on the path to yours -- you have to know that `Leak` holds from the moment you create the trait object to the point that you want to embed it in an `Rc`).
I don't think "trait objects need to be annotated with `Leak` to store them in an `Rc`" is a bad thing (people already have to annotate trait object stored in `Arc` if they want to use them across threads, so it's hardly unprecedented), but it is certainly possible to avoid as part of a backwards-compatible solution to this problem; for instance, there could be a `+ ?Leak` instead. It's not an inevitable consequence of that approach by any means.
One proposal makes the `Leak` bound a default (kind of like `Sized` is today). One thing that's nice about that: it also makes it backwards compatible to add after 1.0.
Isn't this exactly why [rustaceans.org](http://www.rustaceans.org/) exists? /u/neutralinostar, looks like you need to add yourself!
Very interesting work! It seem to me that using `libstd` for kernel work in Rust is a bad idea - due to problems you dealt with yourself. My plan (for https://github.com/dpc/titanos) is to use only `libcore` and build libraries on top of `libcore` only.
Yes possibly. A large part of why I started this project was to see how a newer language helped with kernel development. An important part of all programming languages is their standard library, which led me to try to use it extensively. Also the main problem I had was with how the rust compiler views 'box', which, is (somewhat) separate from the standard library. Good luck with your project.
Not excited. I'll consider getting a flair on this sub though.
I felt genuinely sad when reading that article about the [failed attempt to make a DAW] (http://genesisdaw.org/post/progress-so-far.html). Especially after this: &gt;At this point I felt crazy for even considering Rust. :(
libstd does abort on allocation failures (it actually aborts, it doesn't unwind as you claimed), but you don't have to use it.
Would custom allocators fix this? That is, a kernel would define a custom allocator that tries to free memory (kill user processes, evict cached data, etc.) when it runs out.
I am fairly certain that allocation failure will unwind the stack in user code, being invoked in signal handlers. Regardless this does not really change anything b/c this abort is a problem, whether it unwinds or not. Also while you can avoid it doing so prevents you from writing anything resembling standard rust (assuming you actually use heap allocation)
[Pull request](https://github.com/cmr/this-week-in-rust/pull/53) already submitted to fix it.
Possibly, I rather doubt it though. At some points the kernel does need to just decide that memory allocation isn't happening and return enomem. Otherwise you could get syscalls that never terminate, constantly waiting for memory. I'm unsure if custom allocator would support this use.
Custom allocators are one approach, but another, today is just to use the unstable `std::rt::heap::{allocate,deallocate}` directly. You lose `Box&lt;T&gt;` as a type, and types which are built on it, which is not the greatest. We're interested in stabilizing this API relatively soon, but since most Rust code (at first) will not be at that level, we've been focusing on the higher-level stuff first. There's a number of unstable features that are important for operating systems development: this and inline assembly being the biggest, I'd say.
You can make a wrapper whose contents are only exposed through an `&amp;` reference.
Could you abstract over that with a type variable (i.e. the function returns the `Box` version of this thing if you give it a `Box` or likewise with `LeakBox`) or is that beyond Rust's current type system? Such as: struct MyContainerThing&lt;'Box_t&lt;Foo&gt;&gt; { Bar: 'Box_t&lt;Foo&gt; } fn MyFunction&lt;'Box_t&gt; (a: Foo) -&gt; 'Box_t&lt;Foo&gt; { //something } Actually, I think this might constitute HKT, which is sort of a landmine in these discussions, if I recall. Perhaps there's a minimal sort of HKT that suffices to make `Leak` usable, though.
Only if it makes sense for the library to be stable. With such small libraries, I'll probably bump a few.
He's probably right, if his interest is in making a DAW and not learning Rust or helping out with building up the Rust ecosystem. Pre-beta, Rust was changing so rapidly that it was unlikely your code would keep compiling; if you had any dependencies on other libraries, then that became even more complicated, as not all would necessarily be updated in lockstep. Even with the beta, there have been a few breaking changes that got missed during the alphas, and the beta means that a lot of code broke due to enforcement of feature gates. Really, you have to have a pretty strong interest in both learning how to do engineering under Rust's constraints, and keeping up with the whole ecosystem, in order to be able to use Rust pre-1.0. That's why there has been so much effort to try not to stick more things into 1.0 or slip it. Rust needs to hit a backwards compatibility milestone, where the vast majority of code will continue to work as new releases come out. Sure, there will always still be some stuff that relies on feature gates and only works with then nightlies, but post 1.0 that should be a much smaller set, and each release of Rust should hopefully lead to a strictly large set of software working. I would say that even at 1.0 launch, Rust will still be mostly good for early adopters, but those early adopters will be able to spend a lot more time bringing up the ecosystem that makes it useful for everyday coding. Maybe by 1.3 or so will things have settled down enough, the ecosystem built up enough, and enough crates waiting for more feature stabilization to be usable on the stable channel, that it would be worth recommending for people who don't have "playing around with Rust" as one of their primary interests.
I'm not sure Rust is the correct language for this, wouldn't something like Haskell be a better fit? You could wrap an Arena and return `&amp;` instead of `&amp;mut` references on alloc.
If you're not using `unsafe` code, there's still nothing to worry about. If you are using `unsafe` code, you still need to be very, very sure about what you're doing. This issue does not change the fundamental calculus of Rust, and does not impose anything like the sort of worry C++ does ubiquitously.
+1 to the destructors-are-noexcept proposal. +100 to the first person to submit an RFC for it.
The insane bug was in `scoped`'s API, which was fixed weeks ago.
Heh, just a few hours ago I was telling people that [`std` probably isn't appropriate for an OS kernel](https://www.reddit.com/r/rust/comments/3404ml/prepooping_your_pants_with_rust/cqq507t?context=1) for just this reason. Of course, you weren't using `std`, but it looks like you were using `collections` which depends on the normal Rust allocation behavior. I'm wondering whether it would be a useful effort to put together a separate collections library built on`libcore` that provides similar general purpose data structures, but with allocation failure threaded through the design, so pretty much anything that could allocate would need to return a `Result` rather than just panic on OOM.
If I understood what he was saying correctly, his only problem was how restrictive the borrow checker was, not that he didn't want to learn the language or he couldn't keep up with the changes. He said that Rust was preventing cases that "were obviously" safe. As we all know, Rust does this when it can't *prove* the case is safe, even when it seems safe to us. But often when a case seems safe, we may be missing a corner case, or it may no longer be safe after the code has been changed many times. I can put up with the borrow checker because I know I will at some point make a mistake (as I have many, many times in C++). His attitude seems to be that he is either very confident that he can consistently write safe code without a borrow checker, or that he's fine with writing unsafe code and debugging it later if it means he can prototype faster. So this is a problem that won't change after 1.0.
Where are you seeing hype? We actively discourage hype here, as evidenced by the fact that this article is one of the most-upvoted articles in the history of the subreddit (see also any of the hugely-upvoted threads regarding general discussion of what Rust is bad at, such as https://www.reddit.com/r/rust/comments/2zu3eo/what_is_rust_bad_at/). C++ is an obscenely powerful language. Many, many languages have attempted to be a "simple and safe C++ alternative" (most notably, Java), but C++ is still here because those languages simply don't provide the low-level control that C++ does. Rust is the first language that even approaches this level of control, and manages to do it while giving you the ability to ensure memory safety. Given that this is something that's never been done before (no, neither Ada nor Cyclone do what Rust does (ATS might be worth looking into, though)), it's hardly surprising that there are some guidelines that we're still discovering.
Right, that's HKT. It might help alleviate some of these problems in the future, though with complexity costs of its own :)
Thanks for posting! I naturally went straight to the analysis of drawbacks to see what we could do better :) Are you familiar with the "std facade"? The standard library is broken up into a few internal crates, precisely to facilitate re-use in kernel development where a lot of what `std` offers isn't appropriate (due to allocation semantics). In particular, all of `libcore` should be useable for a kernel, since it doesn't allocate at all, and the rest you should be able to develop on top. (That said, hooking into `box` syntax in particular is still under development, but you don't have to go that route to allocate.) Most of the other things you mentioned would be addressed by some kind of "virtual struct" feature, which is something we [intend to look into very soon](http://internals.rust-lang.org/t/priorities-after-1-0/1901). Better support for static data, though, definitely needs additional work.
His issues went beyond just the borrow checker: &gt; But nothing in life is free. GTK is sufficiently complicated that a Rust "safety wrapper" is in order. The one available was not complete. &gt; &gt; At this time I began to have a new philosophy: Stop depending on libraries that hold the project down. &gt; &gt; This led me to ditch the idea of using GTK or Qt and instead code the user interface toolkit from scratch. This would work out better anyway if I wanted to sandbox plugins and provide a user-interface API for them to use. So, the first problem is that the library ecosystem is not complete, so he had do do a bunch of yak-shaving just to get widgets up on the screen. And [the developers look like they're waiting for 1.0 to hit before even trying to run on stable Rust](https://github.com/rust-gnome/gtk/issues/42), and maybe even waiting longer as they depend on a lot of feature flags; so that kind of issue is going to continue to be a blocker for a bit. &gt; Next I began to experience Rust development. I went back and forth between GLFW and glutin for window library as one or the other seemed to be better. I created groove-rs - bindings to libgroove. I wrote my own 3D math library because the existing one's API was too hard for me to understand. I fixed a lot of code after updating to the latest Rust compiler each day. The next is having to learn Rust and build up the ecosystem, while also dealing with rustup problems. &gt; And then I tried to abstract the font rendering code into a widget concept, and everything broke down. The Rust compiler has many false negatives - situations where it is a compile error due to safety, but actually it's pretty obvious that there are no safety problems. And finally the author ran into some borrow checker issues that were the straw that broke the camel's back. Now, it's hard to tell what the author's problems were specifically. But given the other issues; library ecosystem that isn't quite there yet, constant need to rustup, and need to learn a new language and model for the code in order to become productive in it, it makes sense that if you're actually interested in writing a DAW, using a language that's more stable and you understand better, and just work from there. The borrow checker does reject a lot of things that should be valid, and which there are tentative plans to allow in the future; now, there are generally ways to work around those, so if you get to know Rust well then it's not actually too much of a problem in practice. But if writing a DAW is your goal, rather than learning Rust and helping it bootstrap up a library ecosystem, it makes sens to use tools you know better.
Me and my friends are going to build a Rust unikernel over the September - April period :) I'm very interested in your work!
Very nicely written. The paper gave me better hindsight into discussions related to memory allocation.
Thanks. Yes I have heard of the std facade. In fact the std I used for this was actually a custom one, it's in kernel/rustlibs/basicstd. It is only those parts that are usable for my kernel. Having them all split up was very helpful for making this. :) The box syntax though is necessary if you want to deal with objects that can't for on the stack (like new threads stacks) in an idiomatic way. Also I really wish virtual structs were there and yes they would solve most of those problems but I was writing about rust as it stands now. In fact I'm pretty sure I mentioned that they were planned to be added. EDIT: Phone Autocorrect
Was there ever a final answer on if stability attributes or something like them are coming back? Edit: for user code*
&gt;but requires getting familiar with quite a bit of additional knowledge. Like what? I've found that almost all of my C++ knowledge, with just a bit of Haskell knowledge, has been all I've needed to understand what I've seen of Rust.
Not in the immediate future. There hasn't been an RFC for them, and the last I heard them mentioned it was in the context of "it would be nice to have, but not an immediate priority" (sorry, don't have a reference on hand). I think that probably the best alternative is to just use a [feature](http://doc.crates.io/manifest.html#the-[features]-section) like `unstable` that doesn't have an associated dependency, or even something more specific describing the actual unstable feature, to indicate unstable code.
The problem is that stability attributes are tied to the release channels, which doesn't make sense for user code; it's not going to be stabilized based on the Rust release cycle, it's entirely independent of whether users are using nightly, beta, or stable releases. You can instead just use a [feature](http://doc.crates.io/manifest.html#the-%5Bfeatures%5D-section) to conditionally enable some parts of your code. The error messages might not be as good, but it will do the job for now until someone proposes how stability attributes should interact with code that isn't part of the Rust stdlib and implements that behavior.
&gt; With C it is perfectly feasible to keep even a moderately complicated kernel like weenix’s down under 4 megabytes, and in fact almost nobody has ever run into this limit during CS169’s history. With rust, however, this limit was blown through almost immediately. :/ I'd be curious to see an accounting of what's making up most of that code. Edit: The point about memory allocation is a bit overstated, I think (dealing with allocation failure is just hard in general, even Linux has lots of trouble with it), but it'll be good to remember when writing the [final, customizable version of `box`](https://github.com/rust-lang/rfcs/pull/809) and whatever else is going to be implemented for DST allocation etc.: it should be possible, if discouraged, for an allocator to instruct the caller not to evaluate the inner expression at all (because it couldn't allocate memory for it). 
Nope, I don't even have enough time for the book, even though it takes up all my time :(
&gt;are the integer overflow checks. Is there a place where one can read rust documentation on these and other checks? Also, I know when I compile C++ I have to make sure to pass things like -w,noexecstack -pie etc, how do I pass these to rust/ is there documentation on flags?
I just follow the `rustc` convention. In commits where I break things, I make sure the phrase `[breaking-change]` appears somewhere and explain how to fix things.
&gt; knowledge about the C-stdlib applies to both languages Nope. If you're writing C++, there's _nothing_ in the C stdlib that you want to use. - Instead of `malloc()/free()`, use `new/delete`. - All the string manipulation functions are replaced by `std::string`. - All the math functions are replaced by their generic versions in `std::`. - All IO is replaced by iostreams. - Date and time stuff is also entirely different in C++11. - `rand()/srand()` also have much better alternatives in C++11. - You also now use tons of data-structures and algorithms from the STL. There's nothing like it in C. For instance, do _not_ use C's `qsort`, it's slower than `std::sort` since it must use function pointers instead of inlining functors. - etc. In the _extremely rare_ case where iostreams perf overhead is too high for your use-case, you might use `printf`. That's about it. Again, this is _rare._ **Stay away from the C stdlib in C++.** There's basically always a better option in the C++ stdlib. So the only thing that idiomatic C and idiomatic C++ have in common is some superficial syntax. The same amount of syntax C has in common with C++ it also has with C#, and yet you're not saying you're writing "C/C#".
You could still mutate it by reassigning the wrapper value, unless you add indirection there too.
/u/playrust
ok thanks ill delete my post
ok thanks ill delete my post
You're going to have a difficult time doing anything without memory so you might as well either free up some memory by swapping/OOM killing or crash. The idea is that the custom allocator would be responsible for doing this. Additionally, if you have an operation that you don't want to fail half-way through, you could reserve thread-local memory ahead of time (I believe the linux devs are considering doing this...).
Phone autocorrect. Virtual structs
The error message is pretty confusing, but I think it's the `dispatch_slots: Vec&lt;Arc&lt;Box&lt;DispatchSlot&gt;&gt;&gt;` field on `Dispatcher`. `DispatchSlot` contains `Sender&lt;CustomFunctionCall&gt;`, which uses `UnsafeCell&lt;Flavor&lt;CustomFunctionCall&gt;&gt;` internally. `Arc` requires `DispatchSlot` to be `Sync`, but `Sender` is not `Sync` (a single instance is not meant to be shared between threads; it should be cloned and moved). You should try to use `DispatchSlot` without `Arc`. If need be, you can derive `Clone` for it. Also, you should only use `Box` for unsized items (trait objects, boxed slices) and large items (arrays, very big structs). `DispatchSlot` is neither of those.
Standard Rust (and standard C, and standard C++, and standard Python, and ...) treats allocations as infallible, so of course it can't handle OOM-s. However, you can still allocate and fill objects without box or copying via the stack (see http://is.gd/IyXp9j). You can certainly allocate without box. 
there is currently no reasonable way to iteratively build up an fixed sized array, which means there is no way to collect to one an no way to emulate Vec's API.
Runix ?
Thanks for this! Any plans to also SSLify the front page?
How does rust/cargo deal with conflicting dependencies? If I have 2 packages that depend on conflicting versions of a 3rd package will it flip out and break like PIP, force you to choose which version (and likely which of your deps to break) like bower or allow each one to depend on their own version like npm? The ability to have conflicting dependencies is pretty key to being able to effectively compose small libraries. 
Ah that's very good to know, thanks for the elaboration, so basically I was afraid of nothing -_-. 
For Microsoft: [Windows XP support has ended](http://windows.microsoft.com/en-us/windows/end-support-help).
Yep, use with caution.
The only thing that could panic is `AtomicBool::new`, right?
One smaht made it through. &gt; Most collections and smaht pointer types ...
&gt; backwards compatible to add after 1.0 Doesn't it break code that defines a trait called `Leak`?
As someone fairly new to rust and woefully unread in language and compiler design, this discussion largely goes over my head, although I have been reading it voraciously as it goes on. I'm going to risk typing and saying incredibly stupid things. Intuitively, I like the solution proposed here. Announcing that your Rc can or cannot contain a cycle adds explicitness to memory management in this context, and provides the ability to reason about what is going on in a particular case. It adds a little bit of noise, but not much. Additionally, stating that destructor leaking is not considered unsafe is completely counter intuitive to me, and everything I expect to be gaining in using Rust. I know it probably won't ever bite me personally, but knowing that a bug like this may be lurking in some library I'm using seems to be just asking for all kinds of security issues down the line. Given the claims of the language, this could be a major shortcoming and harm adoption. The proposed Leak trait seems to me a kludge. It adds a lot of noise, and seems to unnecessarily restrict what can be stored in Rc or makes every type have to think "Can I handle being in an Rc? What if someone up the line from me can't? Or down the line?" I think this moves cognitive burden, and potential for mistakes, onto the programmer when it seems it can be contained in the compiler/lifetime/ownership/type system. Unfortunately, I cannot comment on the soundness or feasibility of the solution proposed, but for ergonomics, it seems vastly superior to Leak.
There's some discussion on this very topic: https://internals.rust-lang.org/t/setting-cfg-nightly-on-nightly-by-default/1893 . (I've now added a link to it to the post.)
Oh neat! I was thinking about trying to do this someday... This error message is pretty terrible, but /u/DroidLogician is on the right track, as far as I can tell...
yes, or requiring a temporary heap allocation for example.
The `DispatchSlot` is the opaque pointer being sent to libsass for an user defined function. It is then passed back as the `cookie` argument when said function is invoked in the scss file. Given this use case, would it be ok to pass the pointer around if it's not in a `Box`? 
Yeah, that's my focus over the next two weeks. One is going to be bringing the Guessing Game back. Another is going to be a little `wc` clone. I haven't decided on the other one or two to shoot for pre-1.0. I want to do something with HTTP, but I also am afraid of depending on third-party libraries, for multiple reasons: picking favorites is one, introducing a burden on someone whose day job isn't writing Rust is another. I'm open to suggestions if you have thoughts :)
How about a small commandline utility? It should show some interesting features of rust as a systems programming. Just a thought.
That is great to hear
LOL, learn something new everyday. ;)
This is really great work, good job :) I'm starting to read through it and came across the quote: &gt; This allowed me to not worry about implementing many of the lowest level pieces of the kernel, *such as the memory allocators, which are not specific to operating system development* Could you please explain this a bit more? I thought one of the main functions of the OS is handling memory allocation :/
I'd personally like to see some projects which make use of a wide variety of Rusts features (spread out across numerous projects of course). While a word count program is good, it probably won't demonstrate how to utilize traits, the module system or much of the standard library. I have a few suggestions which might be useful. **Word Search** A word search would be one suggestion. It can be a fair bit involved if need be. Here are some of the things I did when I solved the problem: - Load a text file of letters into a n*n matrix. The program should work with puzzles of different sizes. - Load a text file of words to search for within the matrix. - Eliminate words which are too long to fit in the puzzle. This requires determining the dimensions of the matrix. - Find the starting locations for each word in the matrix. For example, there is an 'a' at (0,2), so we can begin searching for 'apple' there. - Search for a word in all 8 directions. Record what percentage of the word was found, at what coordinates, and searching in which direction. - Report your findings: which words were found, where were they found, what percentage was found, etc - Display the puzzle with full words uppercased, and all other letters lowercased. - I also added some command line arguments so that words under a certain percentage would be excluded from the report, or so that you could search for just select words **HTML Parsing** To expand upon your HTTP idea, it might be interesting to supply a URL and have the program output page data. This could be used to demonstrate how the module system works. Each module could parse a different portion of the web page: links, title, description, stylesheets, robot.txt, etc. **Command Prompt Instant Messenger** The idea would be that a few command prompt windows could be opened and messages could be sent from one window to another. This could be used to demonstrate intra-process communication, writing platform independent code, and Rusts threadding features (spawn a new thread for sending messages). **INI Settings File Manager** This might be a good way to demonstrate how to work with files in Rust. You could probably demonstrate how to lock files or have many threads read them at the same time. For example, the program could list different statistics about the file, with each statistic being gathered by one thread, and finally being aggregated and displayed by the main program.
I find myself in a similar situation to you, and also think this approach seems like it could be the best of the ones proposed. I *really* think whatever the solution is is very much worth taking the time to get *right*, despite the imminent and apparently set-in-stone release date. (I think the rationale for not delaying---this isn't a memory safety issue---is a little weak given that the release of 1.0 means backwards compatibility with *everything*---not just things directly implicated in memory safety.)
I concur completely. I'm very concerned that at the 11th hour we could be stuck with Leak cruft for the lifetime of the language. I'd rather see a inconvenient but temporary 'static lifetime requirement on Rc than to see us have to deal with a kludge forever.
Memory allocators, such as malloc, share much the same design whether they are being used in a kernel or user space. Assuming good page allocation methods the challenges are much the same and the implementation would change little between the two spheres.
`Leak` is the most ergonomically lightweight of all the solutions, particularly the backwards-compatible variant. You literally will not have to think about it most of the time (the only exception is in `Box` types, and the backwards-compatible variant means you won't even have to think about it there), and all current types will continue to work with `Rc`. This solution changes what types will work with `Rc`, and also changes the overhead and performance characteristics of `Rc` in unacceptable ways. The posted solution doesn't clearly extend to `Arc` without even more performance overhead, since it relies on a backing vector that needs to be synchronously updatable. It will also introduce failures at runtime for `Rc`, making it much less trustworthy than the existing variant. If you can get away with using this solution with a non-`'static` lifetime, you shouldn't be using `Rc` in the first place--you should be using `TypedArena`. I personally *do* think most uses of `Rc` are probably unnecessary, but that doesn't mean that the existing legitimate uses of `Rc` need to be excised. The destructor leaking not being unsafe is a rule that has been there since before I started using Rust. `Rc` and `Arc` (the versions of `Rc` and `Arc` which are frequently used to form dynamic cycles, not the hybrid arena and weak pointers proposed by this RFC) don't effectively work without allowing some destructor leaks. This RFC doesn't solve that. It just removes the ability to use `Rc` and `Arc` for those non-`'static` types and accepts leaks for `'static` ones.
So now you have to separate your library types into those that accept types with static lifetimes vs. those that accept types without? That seems like a just as arbitrary a distinction as (and a much more annoying distinction than) `Leak` vs non-`Leak`. But either way, all my comments were about the non-`'static` version, since this solution doesn't prevent leaks of static ones anyway.
This is an intended bastardization of the English language. "smart pointers" are not that always that smart.
I don't know if there's been a thorough discussion of it yet, but it's discussed in [this post on graphs](https://github.com/nrc/r4cppp/tree/master/graphs#node-and-unsafecell). Note that the `UnsafeCell` isn't necessary; this is just one application of arenas. I do agree that it largely obviates the proposal posted here and that it should be better-known.
The compiler makes extensive use of reference counting with limited lifetimes (`'tcx`, specifically). This is because the reference-counted objects contain references to other data that is, in fact, stored inside a typed arena. Any time your Rc objects aren't `'static`, it's because they contain a borrow and have a limit on their lifetime anyway, which means there is a spot you can put the guard. If your objects are `'static` then you don't need a guard to uphold the guarantee and nothing needs to change.
There's no reason you can't use the same type for both static and non-static data, and only require a cycle guard for non-static data.
I noticed you created a ton of google-* crates. Why did you decide not to make a big crate for all of Google's APIs? Do any of these crates share code or leverage patterns in the others?
I also want to note that the primary purpose of this proposal is to allow destructors to be reliable without having to resort to a band-aide like `Leak`. I introduce the idea of a `ScopedRc` because the ability to have a reference counted type with non-`'static` lifetime and support for cycles was discussed as being a mandatory in the original `mem::forget` discussion.
My point is that we don't need to "fix" `Rc` for this purpose. The main reason people are going to be using `Rc` with types with lifetimes is because the lifetimes just happen to be part of the type, and it's being passed to something that uses `Rc` internally. A secondary reason will be because they have larger structures referencing types with non-`'static` lifetimes that need drop immediacy. In both cases, your proposal isn't going to help, in the second case because it simply doesn't provide the correct functionality, and in the first case because people won't know in advance that they're going to be using `Rc` with a fixed lifetime.
Both the interface and the required fields look different to me for the different usecases (for example, there's an extra pointer and index).
With little to no functionality, seems as if he made it himself and just didn't bother with that yet. I've been there, sometimes you just want to write something, post it (get it off your chest) and not care about how people get there lol
I'm fairly certain the _amount of code_ is reason enough to split them into multiple crates… Youtube is about 20k lines. Imagine compiling that and then 70 more of that size as a dependency.
The only difference to the interface is the added lifetime parameter. For the implementation, size of the internal RcBox would theoretically only have to grow by one pointer for non-guarded cases (no point in allocating space for the index if the cycle_breaker pointer is null).
Arenas operate very differently. They hold on to everything allocated with them until they are dropped. You are completely ignoring the the point of Rc's, which is to free the memory as soon as it's no longer needed. Otherwise, why have an Rc at all? An Rc containing a non-`'static` type already has lifetime restrictions. You already have to statically know my when it must be cleaned up. Nothing changes, here. &gt; In cases where there are no cycles, you should just be able to use Rc without all the extra machinery, regardless of whether there are lifetimes or not. Yes, which is why I am also proposing the possibility of using Rc's for non-`'static` lifetimes be retained, just made unsafe, and also suggesting that an Rc type that statically disallows cycles may also be useful.
I'm not ignoring it. From a functionality perspective, your proposal largely equivalent to a minor variation on an arena where you get a `Rc&lt;T&gt;` instead of a `&amp;mut T`, and the `Rc` metadata is stored in the arena. The differences are fairly minor. This is why I say your proposal is a hybrid weak pointer / arena, rather than a full replacement for `Rc`. Besides the `Deref` panicking, you are also increasing access time for every dereference. Again, this is justifiable where it's *absolutely* necessary (bounds checks) but adding it to t &gt; Yes, which is why I am also proposing the possibility of using Rc's for non-'static lifetimes be retained, just made unsafe, and also suggesting that an Rc type that statically disallows cycles may also be useful. Making currently safe types `unsafe` seems like a hard sell to me. Destructors running is a useful property, but in most cases it's not directly required for memory safety. It's certainly a dubious proposition when you consider that a much harder borderline case (exposing uninitialized memory) isn't considered UB in Rust.
Where the author uses pattern matching over a received value in Rust selecting operations on different channels would be more appropriate in Go - at least for this particular example. EDIT: Didn't take a close enough look. Ignore this paragraph. Still, sum types can be useful, so I'll make a shameless plug with a code generator I wrote https://github.com/szabba/govariant Something akin to marker traits can be done if an interface contains a no-argument no-return-value method. You still won't get generics though. The GOPATH thing can be surprising and unfamiliar. Works well in practice though. Also note: technically where files belonging to a single package should be placed is a convention of the build tool, not the compiler. There's `gorename` for changing variable, field and type names. Most Go plugins for text editors integrate it. Similiarly for imports there's 'goimports' (which both updates the import list and runs `go fmt`). Most people have it run automatically on save. For unused variables there's _ = thisVariableIsUsed
I'm posting this separately, but what exactly do you mean by "Higher Kinded Types?"
Don't miss [checking out what go people said about this](http://www.reddit.com/r/golang/comments/3464lb/a_rust_contributor_tries_their_hand_at_go_20150424/), they know the language better and explain how to express it more naturally.
How does that work? Doesn't the destructor have the same access to the type as any other method?
Thanks for making the video. I didn't pay 100% attention throughout, but I did listen to your story about the dependencies and the build time. We need faster build times, even for optimization.
I don't think you can make a type which is strictly immutable but you can abuse the type system so that you can only do stuff with it after it's been completely locked down. Specifically, being borrowed will prevent moves, reassignment and mutable borrows. So if you make a value borrow *itself*, that value is completely locked until it falls out of scope. use std::{cell, marker}; pub struct ImmutType&lt;'a&gt; { init: cell::Cell&lt;bool&gt;, _self: marker::PhantomData&lt;&amp;'a mut ImmutType&lt;'a&gt;&gt; } impl&lt;'a&gt; ImmutType&lt;'a&gt; { fn new() -&gt; ImmutType&lt;'a&gt; { ImmutType { init: cell::Cell::new(false), _self: marker::PhantomData } } //this can function as the "real constructor", maybe? fn init(&amp;'a self) { self.init.set(true); } fn use_immutably(&amp;self) { if self.init.get() { println!("using!!"); } } fn mutate(&amp;mut self) { } fn take(self) { } } fn main() { let mut i = ImmutType::new(); //mut makes no difference here i.use_immutably(); // does nothing, the value hasn't been locked yet. i.init(); i.use_immutably(); // prints "using" //i.mutate(); //Error: cannot borrow `i` as mutable because it is also borrowed as immutable //i.take(); //Error: cannot move out of `i` because it is borrowed //i = ImmutType::new(); //Error: cannot assign to `i` because it is borrowed } I don't know if this sort of thing would be usable in your case. (inspired by [this post](http://www.reddit.com/r/rust/comments/33tk1a/crossreferences/cqofx3j))
Thank you for the explanation and suggestion. This is perfect.
Using `Float::zero()` blew up in my face but it seems like `Zero::zero()` works fine. Thank you. impl&lt;T: Float + Zero&gt; Point&lt;T&gt; { fn origin() -&gt; Point&lt;T&gt; { Point { x: Zero::zero(), y: Zero::zero() } } }
Even an uncontended lock still has atomic overhead (unless you are sure your can elide it, but in this case you can't be), so my point is that you're doubling the time spent locking and unlocking, in addition to the other extra overhead. As for "the performance impact of this check will be negligible" this is something that needs to be experimentally verified in real scenarios using lots of `Arc`s. Incidentally, as most of my other concerns have been alleviated (though not all): the biggest issue I have with this approach is that `Rc` and `Arc` can't be easily used with generic `T` inside constructors. For example, `channel` currently uses an `Arc`. For it to support types with lifetimes, it will have to take a `ScopedGuard` in order to instantiate a channel. My prediction is that most types *won't* do this; they'll just use `Arc&lt;T + 'static&gt;`. This will cripple a lot of APIs by dividing Rust into two ecosystems; the `'static` ecosystem that almost exclusively uses `Rc` and `Arc`, and the `borrow` ecosystem that doesn't. This is what would have happened, for example, if `Send` still required `'static` and people tried to add on scoped threads later using a different formalism; I fear that your proposal will bring us back to those days. I don't see any real way around this in your proposal. Just using the same type for both doesn't really solve this problem if instantiating them requires a whole different pattern. You may argue that the `Leak` solution has the same properties, but many fewer types are going to be `Leak` than are going to have non-`'static` lifetimes. We can always implement a solution like this *in addition* to `Leak`, with a `CollectingRcGuard`, which would allow us to use reference counting together with leaky types; again, it would have the same problem, but many fewer types are going to be `Leak`. This seems like a substantial regression to me. It will make code and libraries a lot less composable. I *especially* fear that it will encourage people to use `Rc` and `Arc` where they're not necessary, just to be composable with APIs that use them; using them extensively IMO defeats a lot of the purpose behind a language like Rust.
Or just `T::zero()` ;).
Yes, `Arc` will give you a consistent pointer as it uses its own heap allocation. You're passing that pointer around anyways, not the inside `Box` pointer, when you transmute `Arc&lt;Box&lt;DispatchSlot&gt;&gt;` to `*mut c_void`. Also, you don't need to transmute `Box&lt;CString&gt;` into `*const CString`. Instead of moving it into a `Box` you should take the value of `.as_ptr()` and then pass it to `mem::forget()` so it won't be freed. That will make your intentions much clearer. However, if you want to free it later, the approach you're taking is probably simpler than anything I can come up with. [1]: http://doc.rust-lang.org/nightly/std/boxed/fn.into_raw.html
It would be very useful. Keep in mind that "not having a destructor" isn't the limiting case: read the RFC carefully. It's only destructors that could potentially access another reference with the same type, which is actually not as many as you would think; you can nearly always split the type into two parts, one with the offending reference but without an explicit destructor, and one with the destructor but not the offending reference. In practice this deals with the majority of interesting cases, *without* causing runtime overhead like your proposed solution. Making the remaining cases (those where you actually *do* want to explicitly look at the potentially freed reference in the destructor) unusable here is perfectly fine, because your type isn't going to guarantee a destructor order anyway. Example of a cycle that's totally legal already: #![feature(rustc_private)] extern crate arena; use arena::TypedArena; use std::rc::Rc; use std::cell::Cell; fn main() { let foo = TypedArena::new(); struct Foo&lt;'a&gt;(Rc&lt;Cell&lt;Option&lt;&amp;'a Foo&lt;'a&gt;&gt;&gt;&gt;); let x = foo.alloc(Foo(Rc::new(Cell::new(None)))); x.0.set(Some(x)); } Note that the only reason I used the `&amp;'a` here was to add the lifetime. Your proposal would be a lot stronger if it did not introduce extra runtime overhead on access and couldn't panic (though I would still have reservations). Your current implementation of `ScopedGuard` can't take advantage of this because it allows you to add `Rc`s of multiple types, but this seems to me to be easy enough to resolve: require each `ScopedGuard` to be of a single type. They will all still have to be dropped in the same scope if there are cycles between them, and dropck will ensure that they can't cause problems in destructors with references between each other.
The little libraries post and this one are really great! I've started using this method to build and deploy documentation as well and it's very nice, but I did run into one issue. It seems that sometimes `tc` tries to run the Linux [tc](http://man7.org/linux/man-pages/man8/tc.8.html) program instead of the script, causing the build to fail. A simple workaround is to just specify the full path, like `./tc`.
Arc has to do atomic operations every time a reference is cloned, dropped, downgraded, upgraded, et cetera. I therefore suspect (though you are correct that I can't be sure without benchmarks) adding a couple to allocation and deallocation (which happen much less often) would have a relatively low impact. &gt; For it to support types with lifetimes, it will have to take a `ScopedGuard` in order to instantiate a channel. I think it would be sufficient for it to add an invariant lifetime parameter and require T to outlive it, though I'd have to test it to be sure. If that is sufficient, it could use the unsafe unguarded constructor internally. I do not think there would be any kind of split. The problem with `Send` was that there was no alternative: if you wanted to send a type, it had to be static. There are solutions, though, for using Rc for shorter lifetimes while still enforcing the guarantee proposed by my RFC. I do agree that having different Rc types could be problematic, though (especially given the lack of higher-kinded types), so I'll try to work my `ScopedRc` and `NoCycleRc` in with the standard Rc. Then you'd just have one `Rc&lt;'a, T&gt;` type that you could construct using `Rc::new`, `Rc::unsafe_new`, `rc_guard.new_rc`, or `rc_marker.new_rc` depending on your needs and use them interchangeably.
I don't really like installing software that isn't handled by my package manager, so I wrote this quick script that grabs the latest `.tar.gz` and builds a `.deb` for me. It then prints out the `sudo dpkg -i PATH` that I use to install the package. It's been working fine for me for the past couple months so I thought I'd share it. As long as the files stay in the same place in the tarball, this script should work. I'll try to fix it as soon as I notice it breaks.
Good point, added to the post.
s/conversion/convention/;
This is solved by storing boxed Trait objects, instead of generics. 
I second that. As all types are static, there is no way to have 'one codebase suits all', which is the approach chosen for python for example. I was told they go as far as to pull the latest API definition file from Google Discovery before the library is used to be sure to be uptodate. For a language like Rust I figured such a runtime centric approach wouldn't be a good fit though.
The Moscow event links to Portland too. Correct link: http://www.meetup.com/Rust-%D0%B2-%D0%9C%D0%BE%D1%81%D0%BA%D0%B2%D0%B5/events/222092229/
If Rust is ever to be used to write an efficient operating system kernel, this should better be addressed: http://scialex.github.io/reenix.pdf This seems to be the only real obstacle the author was facing. This would truely boost Rusts claim to be the perfect C replacement while still staying safe and concise.
The Amsterdam event links to Sidney. Correct link: http://www.meetup.com/Rust-Amsterdam/events/221569942/
there are many modern 32 bit systems. I'd bet they are at least an order of magnitude more common than 64 bit systems. They are in phones (yes i know the first 64 bit phones are out there), washing machines, tvs, routers, ovens, cars,......
So you have a package just for cargo? What about rustc proper, you use another package?
I use this PPA on Ubuntu for rustc: https://launchpad.net/~hansjorg/+archive/ubuntu/rust
I wrote a [string interner](https://github.com/Marwes/haskell-compiler/blob/master/src/interner.rs) modeled on the one in rustc a while back. It won't compile since it hasn't been updated in a while but at only 70 lines you are free to use it if you can get it compiling. I do have a better version but that is unfortunately specialized to work more efficiently with that specific project.
 get_shortest(names) .and_then(|shortest| find_user_by_name(shortest)); .and_then(|json| json_to_user(json)) This can probably be written as: get_shortest(names) .and_then(find_user_by_name); .and_then(json_to_user)
I'm not sure if I understand what needs to be done (or if my rust-fu is strong enough to tackle it). So you want to add some sort of flow analysis?
There's a typo in the article: `get_shorest_length`
All three of these methods (unwrap_or, map, and_then) are also on the Result type, and just as usable there. I found it too much an impedance mismatch to use the Option type in JS, but I use the Result type everyday, and I learned the lessons of these articles first hand.
Very nice article! Btw. if I haven't understood things totally wrong, Option&lt;T&gt; forms a monadic API with .and_then(), right?
&gt; string-cache […] is rather specialized to Servo, The only thing specialized is the [built-in list of static atoms](https://github.com/servo/string-cache/blob/master/plugin/src/atom/data.rs). I’m interested in moving this out of the library to make it more generally useful. I think this can be done by making some types generic over a trait that provides the list of static atoms. More interesting still would be the ability to have each library like html5ever specify a set of static atoms, and in a given program use the union of the sets of all libraries being used. But I don’t know how to do that. Ideas welcome :) &gt; requires nightly rust, As far as I know there is two reasons for this: * `phf` (which string-cache uses) requires a compiler plugin * `string-cache-plugin` is itself a compiler plugin. It allows interning static strings at compile-time, for code like `if attr_name == atom!(href)` I think it would be possible for string-cache to have a Cargo feature flag to replace usage of `phf` with a simple hash map and disable support for compile-time interning. This should work on Rust beta/stable. **Edit:** It’s actually more than that. string-cache uses a number of unstable feature right now. &gt; and isn't on crates.io. This is easy to fix. It’s just that nobody asked so far.
&gt; These seem nice. Thanks. I made them to learn rust, and also do something useful. &gt; Any chance of getting them into rustc itself? Not sure. I've asked the same question on users.rust-lang.org, but there has not been any answer so far. In any event, it's easy enough to add them to your dev.dependencies.
It does. .and_then() is Option T -&gt; (T -&gt; Option T) -&gt; Option T which is bind / &gt;&gt;=
From the [most meeting minutes](https://github.com/rust-lang/meeting-minutes/blob/master/weekly-meetings/2015-04-28.md#transmute), it sounds like the core team feels like there are too many lints already, and would prefer to move more lints to an external tool or package. So yeah, keeping it as a dependency seems fine, though it would be nice if there were one package that collected up a large collection of commonly useful lints.
I like to think of javascript's promises as an asynchronous extension of Result, which works very nicely indeed.
&gt; phf (which string-cache uses) requires a compiler plugin There is actually a codegen version ([repo](https://github.com/sfackler/rust-phf/tree/master/phf_codegen) and [crates.io](https://crates.io/crates/phf_codegen)) for build scripts. The tricky part is just the compile time interning, but it can probably be somewhat solved using some kind of preprocessor, like [syntex](https://github.com/erickt/rust-syntex).
Actually it's "Option T -&gt; (T -&gt; Option U) -&gt; Option U", but otherwise correct :)
I read the minutes as "we need some policy for lints", but yes, on one hand, the compiler has probably enough lints (and the ones I wrote aren't exactly core material). Btw. Just a few minutes ago, someone submitted an issue to consider merging with another lint project of /u/Manishearth.
Yes, /u/Manishearth has been writing some good lints.
Just curious, did you read the book before I wrote the chapter on coercions, or after? Taking a &amp;[T] instead of a Vec&lt;T&gt; is nice because it just borrows ownership, rather than taking ownership. Derek coercions just make it a bit nicer to convert between two types.
You assume an OOM killer, but most of the world isn't Linux (even android disables the oom killer iirc)
I wonder if rustc will ever use cargo (that'd be sweet) 
Interesting, thanks!
We have a big open for it. It would be cool, but it would also be very difficult, and it's unclear exactly how much benefit it would have. This is because rustc needs to do the bootstrapping process, which is a bit unique.
Re: Licensing concerns mentioned on github You wrote all the code in the repo right? Then you still own the copyrights despite releasing it under the MIT license. You can go and release it under a MPL license as well. If you're willing to do this, combining the repo's really isn't a problem legally. (I am not a lawyer)
It would be really nice to have html5ever working with stable Rust. It's currently the only up to date HTML parser available, as far as I have found... I have been thinking about porting one of its macros to a build script, to help it on its way.
Also nightmare for deploying on other platforms from what I heard. You need Cargo to build Rust, you need Rust to build Cargo, which causes circular dependencies.
There's a mistake in the first command, it says `git clone git clone https://github.com/rust-lang/rust.git`, should be `git clone https://github.com/rust-lang/rust.git` Other than that, great stuff!
Awesome, I'll see if I can think of a way to help with that, because it would be great if I could use string-cache. 
Nice! I read the book before so I'll read that chapter now, thanks! (btw: It looks like the chapter is only on the "book nightly" and not on the "book beta") UPDATE: I just read it and I found the explanation really clear. This was a "black box" to me before but it is actually pretty simple what is going on. Going through the std API docs, is there a way to easily show the Deref implementations for a given type? I'm just searching for Deref in, for example, the std::collections::vec::Vec page, but I guess this is something I will search for very often in the near future now that I know what it means.