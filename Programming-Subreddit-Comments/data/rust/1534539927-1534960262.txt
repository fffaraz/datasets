Yep. Probably you should just accept that you opened it and leave it at that. Let open/read tell you if it's readable. Another bug: using `&amp;str` for filenames blocks non-UTF-8 filenames: -% target/release/cat foo$'\377'foo thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: "foo\xFFfoo"', libcore/result.rs:983:5 This is what `&amp;OsStr`, `Path`, etc are for. You might consider using `AsRef&lt;Path&gt;` for the API to keep it as flexible as stdlib.
&gt; Is it safe to write as *const _ as * mut _ in that situation ? As far as I know, casting between pointer types is perfectly safe. Aliasing `*mut T` is fine, just aliasing `&amp;mut T` is undefined. One thing to check would be whether libyaml is actually mutating the pointer you're giving it; if get_node doesn't actually modify the document / the returned node doesn't allow modification, then modeling it with shared references is perfectly safe. If the node can modify the document, then you have more of a problem. Maybe have Node and MutNode types, and only allow one MutNode at a time? You might want to take a look through the [nomicon](https://doc.rust-lang.org/nomicon/), I've found it helpful for this stuff in the past.
WRITING MINECRAFT IN RUST
Just an application, i tried the Boxing variant but was not completly happy. Im gonna look at the failure crate, missed that somehow and found only the error\_chain crate. Thanks for the examples!
Thank you! That works like a charm.
Oh, sure. I missread that somehow ¯\_(ツ)_/¯
The particular error you're running into seems to have something to do with [Higher ranked trait bounds](https://doc.rust-lang.org/nomicon/hrtb.html). I don't really understand those, though, so I can't explain them much. If you know ahead of time what operations you need to support, you could just make a `Command` enum, and then add a function that matches on the enum to pick the operation to perform. If you really need arbitrary functions, you might be able to use trait objects instead, e.g.: ``` trait Command { fn perform(&amp;self, &amp;mut target) } struct DoThing; impl Command for DoThing { ... static DOTHING: DoThing = DoThing; fn q() { let cmd: &amp;'static Command = &amp;DOTHING; } ```
Looks to me as though [the C API](https://github.com/yaml/libyaml/blob/df5c05e12080c6f710da54b6e3348288f3506d46/src/api.c#L1180) could have been yaml_document_get_node(yaml_document_t const *document, int index) and then your problems would largely go away: you could write `get_node()` with the signature that you want. C APIs are often less precise than Rust with respect to `const`\-ness. But if you add `const` to the header file and re-run` bindge`n you should be golden. Maybe you could even consider sending a pull request t`olibyam`l encouraging more use of \`const where appropriate. However: perhaps you *also* want a `get_mut_node()` \- which takes a mutable document and returns a mutable node? In that case you're sort of back where you started; you'll only be able to get one such mutable node at a time. I think it's going to be hard work to get around that.
*Do* Read [The Rust Programming language](https://doc.rust-lang.org/book/) *Do* Understand the difference between a borrow and a move. *Do* Understand Option/Result and how to use them *Do* Learn the Iterator trait inside out *Do* understand what the standard derives do: Debug, Clone ,Copy, PartialEq etc. *Do* make use of "{:#?}" inside println! for pretty printing your structures. *Do* Use a decent text editor, VS Code is pretty good right now *Do* understand the module system and how to separate your code into files. *Do* learn how to (a) implement a trait for a struct (b) write your own trait (c) write a function that takes a parameter that implements a trait. *Do* Watch the following series [Hello Rust!](https://hello-rust.show) and this video (Rust Programming Techniques)[https://www.youtube.com/watch?v=vqavdUGKeb4) *Do* clone https://github.com/rustlings/rustlings and try to get all the challenges to compile *Don't* Fight the borrow checker, if it says you are doing something wrong, you almost certainly are. *Don't* try to have circular references i.e. parents have a pointer to children and each child has a pointer to a parent *Don't* try to mimic inheritance from OOP rust has it's own patterns *Don't* worry about asking questions Rustaceans are lovely people 
It is very hard trying to get into Rust with minimal programming experience. This website gives me hope to not quit trying to learn rust.
An expected outcome when a package manager does not support namespacing.
Update: next nightly should include these Rust 2018 changes: * [#53427 rustc_resolve: overhaul `#![feature(uniform_paths)]` error reporting.](https://github.com/rust-lang/rust/pull/53427) * [#53347 rustc_resolve: don't allow paths starting with `::crate`.](https://github.com/rust-lang/rust/pull/53347) * [#53413 Warn that `#![feature(rust_2018_preview)]` is implied when the edition is set to Rust 2018.](https://github.com/rust-lang/rust/pull/53413)
While I like the anology. Data driven design has proven very useful for me when designing systems. Starting with the structs and the WHAT DO I WANNA DO, followed by the impls or HOW DO I DO IT. The code tends to come naturally when you know the data.
HAPPY CAKE DAY!!!
Note that if you use such a lock, your other stores don't actually need to be atomic! I'd say a bare "store" is almost a red flag with atomics, likely to be a race condition. You'll more commonly be doing something like compare-and-swap or atomic-increment.
Fourth attempt at writing this is the charm it seems. (Actually it's probably the morning coffee that helped nail it down a bit.) Fundamentally, to the wider points, I'm pretty sure I mostly agree. I just feel there's a hidden role of the hardware that we like to optimise out of our pretty world views sometimes. The release of Ryzen was eye-opening to UB in standards compliant code due to things outside of our control. It wasn't undefined behaviour in the C/C++ sense, but it was a mess. Having re-read it a couple of times to really nail it down there are only three things that really got me: 1. The C-focus feels a bit "I hate C" until you get towards the end (I realised you weren't in my first read through it, it's just that it places a slant on it all). A simple note that C has the best/richest history to draw from at the start, to explain why C is taking a beating (real or perceived), would really help reduce that fatigue that I think rubbed me up the wrong way; 2. UB isn't actually defined in the post/article. But even if take [take an existing definition](https://en.cppreference.com/w/cpp/language/ub) you get hit with the issue that it's not really comprehensive, and isn't portable outside of C. (As a linguist I see it as a misinterpretation between the intent of the programmer and the action of the compiler, but I also see it as the intent of the compiler and the action of the assembly, and so on and so on forth, from author -&gt; code; code -&gt; interpreter; interpreter -&gt; translation to assembly; assembly -&gt; hardware; hardware -&gt; inner workings (where applicable)); 3. The C camps you propose aren't limited to C, but I suspect you're trying to avoid a religious war between factions in describing them that way. Particularly militant groups from Linux, Microsoft/Windows, and MacOS camps, all do certain things in certain ways because they can. That said, other than Linux, languages (and runtimes) have been made to make it easier for given platforms/targets (e.g. .NET and .NET-native; Swift and ObjectiveC). I went with the re-reading to make sure I wasn't dragging in my own baggage, and it turns out I was to a degree. Rust isn't perfect, but it gives the best-case split at this time given the complexities of hardware below the super-helpful LLVM hood that a lot of languages lean on. Older languages (like C) didn't have that, so they made a lot of decisions (with a lot less support and evidence for why not). As DJB stated a few years ago (and you link to), rewriting would require more or less starting again in some parts. Rust did that. Swift did that. Go did that. While their approaches are different, they stand tall due to the past mistakes and what has been learned from them. As for the C angle, how we'd go about changing that is reflected fairly well in the politics of most countries. It's slow, painful, and good luck getting consensus for those that matter. Short of people making a bunch of compiler extensions to eliminate or restrict to "safer" modes, or to warn on unsafe (which I'd suggest is borderline impossible in C and C++ at the moment), I don't think it'll happen. But similarly I wouldn't try to apply it to assembly. I know the blog post isn't a "write Rust" post, but I don't think it would hurt to openly contextualise it in a time when the "rewrite it (all) in Rust" camp is pushing for safer code. (Not that Rust is a silver bullet either due to FFI and need to do unsafe things for critical components like allocation.)
Having *no* undefined behavior in a low-level compiler IR, even for safe languages, is very limiting. For example, a Rust array access needs a bounds check. We want to optimize away bounds checks in various cases. How should we represent an array access with the bounds check removed? The most convenient way is to make the IR capable of representing an "unchecked" access, with no bounds check. But that's an IR construct which, if misused, could evoke undefined behavior. 
Makes sense. Is undefined behavior defined the same way as in the C standard in CraneLift? (I don't mean to cast aspersions on your work, by the way; CraneLift is really cool :)
Like this, I think: &lt;https://play.rust-lang.org/?gist=9fc4ee789e5dff3269cc2d2a0ce25fc0&gt;
Pretty much; to follow the example above, once you have a single unchecked store go out of bounds, it's practically impossible to describe a bound on what could possibly happen.
Actually yes! I didn't know I could tap the top of my touchpad to "middle click" - this did the trick. Thank you
I think that depends what you mean by 'C'... :-) This post might put that comment in context: https://raphlinus.github.io/programming/rust/2018/08/17/undefined-behavior.html Basically, if you use a non-optimising compiler / write 'old-school' C then it can be an easily understood, if low-level, language. But modern C/C++ is actually pretty similar to rust, but without the guard rails. Modern C is deceptive.
There were Java physical machines, and ARM with Jazelle is pretty close. The reality is that having no UB isn't unobtainable, or even that limiting, it's a question of trade-offs. In the terms of processing overhead/cost, it's probably quite bearable if we start to look at things in certain ways. The real question isn't "should we?", it's "what do we get out of it?". When I start to look at it more I start to wonder why we're not actively pushing for it in certain areas where security is important (and with security comes the ability to protect against UB and general "I didn't expect that" issues).
As someone for whom Rust was their first "low level" language: I ended up learning C too. Rust is great, but until I started learning C and assembly, the 'machine' never clicked for me. Honestly: I've been doing rust off and on for 3 years, and the memory model didn't make sense to me until I started with C. Rust just abstracts away too much for it to make sense without other experience. 
&gt; Is Rust more approachable than C and C++, or do writers just make it seem that way? I would say the former. &gt; Could Rust ever help someone to understand software written in C, in the same way that C does? I don't see why not. You can get into the more arcane parts of Rust with the Rustnomicon. In most cases you'll never need to dig that deep, though. From the [Rustnomicon introduction](https://doc.rust-lang.org/nomicon/): &gt; Should you wish a long and happy career of writing Rust programs, you should turn back now and forget you ever saw this book. It is not necessary. However if you intend to write unsafe code — or just want to dig into the guts of the language — this book contains lots of useful information.
The community's general attitude makes a big difference, independent of the actual language. This one is pretty nice. C and C++ are useful to know, since if you're working in areas that use Rust, you'll probably also run into a lot of code written in those. Rust also covers some aspects of the underlying hardware better than C does (unless you're getting into the [really spooky stuff](https://doc.rust-lang.org/nomicon/)), which makes it a bit harder to understand those aspects.
https://doc.rust-lang.org/rust-by-example/index.html this is part of the official Rust docs btw.
If someone who did not program asked how to learn rust, I would tell them the first step to learning rust is to learn python. Its not a good first language.
I know python and still don’t understand rust
That mention towards the end that ["everything is broken"](https://medium.com/message/everything-is-broken-81e5f33a24e1) is just painfully true. It seems like every industry needs to maim someone at the absolute minimum before anyone will take fixing things seriously. The [Therac-25](https://en.wikipedia.org/wiki/Therac-25) was a wake-up call for medical device manufacturers. Randall Monroe [put it well](https://xkcd.com/2030/): &gt; I don't know quite how to put this, but our entire field is bad at what we do, and if you rely on us, everyone will die.
&gt; Could Rust ever help someone to understand software written in C, in the same way that C does? Doubt it. C is much more fluent with low-level programming. Most of the C you see written today isn't applications-level, whereas a good deal of Rust you see today is. See e.g. https://gist.github.com/vmchale/555ee6169d5d9cb851f43e3c6b5df5a9 for something you can do in C but not in Rust. &gt; I commonly see it being associated more with embedded programming, writing OS's, languages, and other more highly ambitious projects where speed is a top priority. There are many good reasons to use C for such projects, but speed is rarely the reason C is chosen. I usually see new languages written in OCaml/Haskell, many embedded platforms don't even have a Rust compiler, and operating systems often have a lot of unsafe or low-level code (though that's not to say Rust is a bad choice for OS development!). &gt; Rust seems like it's easier I would agree there. &gt; It just seems like an exaggeration at this point to call C a general purpose programming language Yes. C is primarily a systems language. It has some suitability for embedded work, but it is not a good choice for applications programming today (unless you have particular requirements).
I'm assuming you are trying to get the nth fibonacci so a few things 1. your loop doesn't run for positive integers `while Readline &lt;= lfn` If you enter a number like 5, since 5 is not less than or equal to 0, the loop will not run. consider using a for loop `for _ in 0..Readline` 2. you are [shadowing](https://en.wikipedia.org/wiki/Variable_shadowing) your variables, not mutating them `let mut lfn = ffn + sfn ;` `let mut ffn = sfn;` `let mut sfn = lfn;` should be `lfn = ffn + sfn ;` `ffn = sfn;` `sfn = lfn;`
This is a tiny emacs extension I've been hacking together the last couple days; it adds support for the compilation and execution of rust snippets, including the ability to pull in external crate dependencies. It allows you to use rust almost as if it were an interpreted language, and through babel's org table interface it allows exporting rust results to other languages. There are also some niceties with caching generating cargo projects for some performance improvements. Here's an example of me using it in a jupyter-esque setup where I'm piping data from a local rust crate to python for visualization: [https://i.imgur.com/UZcYTug.png](https://i.imgur.com/UZcYTug.png)
For C, the initial book from Ritchie is the recommended reference. For C++, any book from Herb Shutter is good. Rust is not easier to learn than C, it just has an amazing community that helps all beginners to learn. This changes a lot the learning experience. I believe that learning Rust can help you understand C/C++ and their underlying limitations. I think this is good to learn C because this is a very simple language and not so far from ASM: the translation from C to ASM is pretty straightforward, not sure this is as easy for Rust.
Ah, by wrapper types I mean a struct to hold the whatever value the enum was holding. I don't think you'd lose much expressiveness, at least not in your example. In your example you're only ever matching a single variant at a time. I think in that case it'd be better to split each variant into it's own type. And while tests can catch them (and should!), I'd rather ban invalid types at compile time, not run time (a good static type system is a replacement for a great many tests). OTOH, if you have multiple options you need to deal with, then yeah, enums are great. But in your example you don't gain anything by using an enum. Each stage handles a distinct type. I'd probably create an enum for each stage if the stages needed to handle multiple types of messages. 
Oh yeah this is really, really good, but don't follow a learning experience, it just teaches how it can be done, and you only really understand if you read something before. I guess what I mean is difficulty increasing with steps, as if on each one there is a final phase that you get to use all that you learned and progress to the other chapter beginning with this knowledge and not changing the software that is being written, making maybe parts of it to teach other ideas. I guess it would need a book with a whole project only, to use this way of teaching. Sorry for the long post hah :D
I've written a simple class in Java and Rust. I think you will find that the two languages have quite a bit in common as far as defining concepts. Check it out: [https://pastebin.com/raw/a9xgXe0n](https://pastebin.com/raw/a9xgXe0n)
&gt; Does crates.io allow hypens or underscores in crate names? Both, actually.
I believe you're looking for /r/playrust.
How come `Container` is not an enum, e g: enum Container { Alpha, Beta, Undefined, } You can then use a crate like enum_derive to get some more methods on that enum that helps converting it back and forth to an isize value.
&gt; See e.g. https://gist.github.com/vmchale/555ee6169d5d9cb851f43e3c6b5df5a9 for something you can do in C but not in Rust. No, you can do that in Rust. Not *safe* Rust, but it would only take ~2 `unsafe` blocks&amp;mdash;that program can be translated pretty directly. I wrote a simple hobby OS this spring following /u/phil-opp's [blog series](https://os.phil-opp.com/)&amp;mdash;the only part written in assembly is the first-stage bootloader, and the rest is Rust. It's just as expressive at the low level as C is. 
I was flirting with Rust when I read the original Therac paper a while ago. If I'm being honest it kinda scared me into sticking with the language for a while. Rust certainly isn't perfect, but imo it's a hell of a lot better than everything else in wide usage. (At least as long as you're not willing to spring for something like [Coq](https://coq.inria.fr/tutorial-nahas), and multiply your implementation time by 10.)
Title is super click-baity. Was expecting some discussion of what made it last for years and also how it was vulnerable. tl;dr of Rust std lib part: The Rust standard library had a security vulnerability whose fix was shipped 11 months ago. No CVE was filed, and the devs don't intend to file one. This is a problem because some distros are slow to update and still ship vulnerable versions.
I disagree. The title is accurate.
For me I'd say it is more approachable. When I had read half of Bjarne's book, I noticed that most concepts in C++ were easy to grasp. But god forbid when I tried to import multiple external libraries, I noticed my knowledge wasn't any more useful that printing hello world. In rust, managing dependencies is so simple. Cargo is a very straightforward tool. I don't need to learn cmake, very extravagant compiler dependent flags or whatever I had to learn to be able to program, and wasn't explained in c++ tutorials.
The title felt like click-bait upon opening, but the content made it fitting. The tl;dr is selling it short, so to anyone opening these comments first, give the article a shot.
Higher-level languages have even better memory safety guarantees than Rust, at the cost of worse performance in many situations and being unable to implement many classes of programs. There's not much that can match Rust's thread safety story, though. It also adds on some features not directly related to memory/thread safety like affine types (not being able to use moved-from values) that make it easier to write correct programs.
Yep I misunderstood your point. TBH, I don't think that kinds of books exists for any language, you have to do a project from scratch by yourself. 
I agree 100% that it's accurate title. I disagree that it's representative of the contents of the article. Equally accurate and equally representative (in terms of words spent discussing it) is "How anyone could steal passwords from your browser for 10 years and nobody noticed". They're both good summaries of small bits of the article. Like those large quotes that often appear in the middle of articles.
&gt; However, Rust is different from languages like Python or Go in that it lets you use `unsafe` outside the standard library. On one hand, this means that you can write a library in Rust and call into it from other languages, e.g. Python. Language bindings are unsafe by design, so the ability to write such code in Rust is a major advantage over other memory-safe languages such as Go. You can absolutely use unsafe code outside of the standard library in Go (using the unsafe package or directly with assembly/cgo). Technically, you can in Python with some ctypes shenanigans, too. You can also call into Go code by compiling it as a shared library, though it is a bit noisier than Rust's FFI.
&gt; The Therac-25 was a wake-up call for medical device manufacturers. What makes you believe this? From what I know of current medical device manufacture practices, they're still quite poor. The FDA allowed Therac-25 sales to continue after the disaster, with the software almost entirely untouched and an extra hardware interlock put in. An industry needs to consistently maim a lot of people over a long period of time before anyone will take fixing things seriously.
https://www.mdtmag.com/article/2009/03/safety-critical-coding-standards-reduce-medical-device-risks It looks like they have adopted some of the coding standards used in other safety-critical computer components like cars.
One factor is that most of Rust is *safe*. This means you can learn it piece by piece and you can still get a lot of programming done without understanding everything about the underlying concepts. With C and C++ right from the start there are a lot of caveats that need to be discussed if you want to be a responsible teacher.
An interesting option for working with C# used by the music manager [seiri](https://github.com/RonnChyran/seiri): [CoreRT](https://github.com/dotnet/corert) seiri states the following in their readme, &gt; libkatatsuki, is a forked version of Katatsuki's Track handling code, written in C#. This is needed because the native version of TagLib lacks features that TagLibSharp implements that are required for compatible semantics with Katatsuki, and richer queries (such as cover-art size). Rust bindings are created using CoreRT to compile C# to native code, and a C interface. libkatatsuki and its Rust bindings are automatically built when building seiri-watcher and seiri-client.
I've had multiple attempts to learn C++ and always miserably failed. Mostly due to how its community perceive a beginner as a punching bag. Then onto Rust. I asked a very broad question yesterday and its pretty well-received here when I'm 100000% positive I would get downvoted so hard if I ask identical question in r/cpp or SO. As a language, I think both are equally hard, but Rust seems easy at first (here's the first pitfall I know). And boo, no inheritance! I was REEEing so hard the moment I knew this, then I learned how to write equivalent data structure in Rust idiom (component-based approach or what we call here as ***composition***). Turns out it feels a lot more intuitive. This would blend pretty well with React (my first intention to learn Rust is because of WebAssembly). So, yeah, TL;DR : Rust is indeed more approachable than C and/or C++ by an enormous margin. 
I'm not convinced that it's a useful exercise to intentionally create code that has problems but isn't caught by the static analysis tools. Those guidelines are intended to catch mistakes, not intentionally introducing bugs. That thing about matching on the wrong enum type is pretty bad, though. It's statically determinable and almost always a mistake, and it's one that could be realistically made by mistake.
Have you tried Java or C#?
I just generally can’t wrap my head around compiled languages
Glad it helped :) 
I disagree on this. Instead we should add more new comer friendly resources.
I have some plans, actually for 2 years :D Mostly I might able to add a new sections besides docs around end of this year :) 
The author's talk, and I think the article, made a pretty good case that the MISRA-C standards are basically a fig leaf on the reality that when compiling C code nobody's quite sure what it's going to do. Writing medical device code in C is irresponsible nonsense, and better coding standards won't change that. (If they even are better: like most such things there's little direct evidence that MISRA-C does anything in practice.) Writing medical device code without a formal proof of correctness properties for critical sections is bad enough, but to even make that possible requires using a programming language with a defined formal semantics. In current year, your most mainstream choices are Scheme and Standard ML: maybe Ada depending on how you squint at it. (There are proof games that the seL4 folks have played with C, but that's a rabbit hole I'm not going to go down in a Reddit comment. Read the relevant papers for details. ([1](http://ts.data61.csiro.au/publications/nicta_full_text/1852.pdf), [2](http://ts.data61.csiro.au/publications/nicta_full_text/7371.pdf))
You don’t even need ctypes/cffi to do unsafe in Python. There are many interfaces which lead to segfaults when fuzzed (for instance just loading bad bytecode). 
What's the thing that puzzle you the most? Let's see if I (we) can help. :)
I'd say it's probably easier to learn C or C++ than Rust. This is partly because the paradigms that they implement have been around for a long time now so they're more similar to other languages etc. Rust has some things that make things easier like type inferencing, but it also has unique features like borrow checking and uncommon features like enum algebraic types. So there end up being things that can get kind of complicated or that don't have equivalents in the most commonly used programming languages. I agree that it's a lot easier to understand what sort of things rust is doing for you if you learn C/C++ first.
So many words. So little meat. TL;DR the author couldn’t find bugs in the wild so it started looking at the issue trackers. It found a potentially exploitable bug in the Rust std library, that has been fixed for almost a year. The only real issue is that this particular bug wasn’t marked / Identified as a CVE. 
Rust allows unsafe code with just a single keyword, and that lets you cause whatever problems you want. Something like C# or Python restricts your access to memory to solely be through type-checked pointers that are managed so that none of them can be freed until nothing is capable of accessing them.
Wow! Do you have any experience with this approach? Their github says it only handles simple programs. It is hard to guess which features are implemented. I don't use reflection in my program but I dont know if my dependencies are, for example.
Could you give an example? I can't quite get my head around it.
&gt; There's not much that can match Rust's thread safety story Have you tried tools like http://parallel-checker.com/ with C#?
I was trying to make it more accessible than my previous one, perhaps I went a bit overboard on that. Thanks for the feedback.
Ironically medical device manufacturers believe they can not use Rust (or memory safe languages like Python) instead of C because regulations make it difficult to use open source software.
C# has an unsafe module and python has built in ctypes, they provide just as much ability to segfault or create data races. Unsafe blocks in Rust only give you a few additional powers, ie the abilities to: * Dereference a raw pointer * Call an unsafe function or method * Access or modify a mutable static variable * Implement an unsafe trait Everything is still type checked just like the rest of the language, that's absolutely no different to the state python and C# except that rust has a lot more useful tools for managing memory, so you don't need to reach for unsafe tools as often to achieve the same low level behaviour.
Oh sure, I was just referring to writing "unsafe" code by hand as a feature itself rather than some actual bad code which produced unsafe results.
Ironically some medical device manufacturers believe they can not use Rust (or memory safe languages like Python) instead of C because regulations effectively prohibit using open source software.
That is impressive. Their FAQ mentions that it isn't intended to do more than find some of the issues related to races and deadlocks, while Rust's Send/Sync blocks all data races that cause memory safety issues, but doesn't check deadlocks at all,
If you add "There are probably more bugs like this lurking in Rust stdlib and we need to do something about that" - that's the TL;DR, yeah. I was trying to make it accessible to people who are not familiar with Rust, but looks like that backfired. Thanks for the feedback.
There is a "No dragons here" flag - `#![forbid(unsafe_code)]`, but hardly anyone uses it. Using it by default [has been brought up](https://www.reddit.com/r/rust/comments/8zpp5f/auditing_popular_crates_how_a_oneline_unsafe_has/e2l7y29/), but does not make much sense.
 #[macro_use] extern crate text_io; fn main() { println!("Please select the least faobinci scqunce to analyze/"); let mut Readline:u64 = read!(); let mut ffn:u64 = 0; let mut sfn:u64 = 1; let mut lfn:u64 = 0; while lfn &lt;= Readline { print!(" {}",ffn); print!(" {}",sfn); lfn = ffn + sfn ; ffn = sfn; sfn = lfn; print!(" {}",lfn); } } 
As an enormous proponent of Rust, I do worry about this piece. Maybe it's similar to other high level languages in this way, but it's definitely the case that if you learn Rust first, you don't understand why it is so incredibly useful. Even then, when you start getting closer to the metal, it may be the case that you want to "feel" it by working in a way that's more akin to what's happening under the hood. All that said... given the value propositions of Rust... probably worth getting over it, just like the learning curve, IMO, haha.
&gt; Higher-level languages have even better memory safety guarantees than Rust, Their guarantees aren't better, they just make it less easy to bypass the guarantees. Just because most of the unsafe stuff in Java isn't written in Java doesn't really make the language's guarantees any stronger, it just moves the problem from the language to the runtime.
&gt; However: perhaps you also want a get_mut_node() - which takes a mutable document and returns a mutable node? I'm not really sure how I will handle that. I haven't thought that far ahead yet. If I look at what git2-rs does, the interior of libgit's structures mutating through functions using `&amp;self` is not a concern ([example](https://github.com/alexcrichton/git2-rs/blob/master/src/repo.rs#L369)). It boils down to the difference between `struct Wrapper(*mut raw::document)` and `struct Wrapper(raw::document)`. In the former case the C library provides opaque pointers and you have some sort of 'interior mutability' because the wrapper remains const but the underlying object is mutated by the C library. In the second case, the struct is defined in the header file and you must call a function that initializes a value you allocated yourself. You don't have this interior mutability anymore. I'm looking for the best way to get back that interior mutability. RefCell comes to mind but it has a (small) runtime cost and `as *const _ as *mut _` looked scary even though it made the compiler happy.
&gt; There are many interfaces which lead to segfaults when fuzzed (for instance just loading bad bytecode). Those are bugs though.
There is a tool that checks the dependency tree of your crate for unsafe code and attempts to quantify it: https://github.com/anderejd/cargo-geiger
I don't think ease of access to unsafe weakens the guarantees of safe code. Furthermore, very few languages protect against data races, which are just a special form of memory safety violation.
The `unsafe`s in set.rs are scary! pub fn new_unchecked(slice: &amp;[T]) -&gt; &amp;Self { unsafe { mem::transmute(slice) } } This transmutes away the lifetime, creating an [unbounded lifetime](https://doc.rust-lang.org/nomicon/unbounded-lifetimes.html), according to the [Rustonomicon](https://doc.rust-lang.org/nomicon/transmutes.html). This means that Rust will consider the reference to the slice valid *forever,* even after the underlying slice has been dropped. This creates an exploitable security vulnerability known as "use after free". [Chapter 10](https://doc.rust-lang.org/book/second-edition/ch10-03-lifetime-syntax.html) of Rust Programming Language explains how to solve the problem without introducing security vulnerabilities. Also, avoid `unsafe` like the plague until you have read and understood both the [Rust Programming Language](https://doc.rust-lang.org/book/second-edition/foreword.html) and the [Rustonomicon](https://doc.rust-lang.org/nomicon/). Writing unsafe code that does not introduce security vulnerabilities is a lot harder than most people think.
Actually, high-level languages tend to either have unsafe hatches or C FFI, if not both. C# allows manipulating raw pointers, for example, Java has an `Unsafe` package, etc...
Ho! You are totaly right ! I should have written this: ``` pub fn new_unchecked&lt;'a&gt;(slice: &amp;'a [T]) -&gt; &amp;'a Self { unsafe { mem::transmute(slice) } } ``` I will publish a new release ! Do you think I need to yank the other versions ? Could you please check if these `unsafe` `transmutes` usage are good ? https://github.com/Kerollmops/sdset/blob/master/src/set.rs#L279-L312 The next time I will need `mem::transmute` I will think of this sentence: &gt; Almost no reference is 'static, so this is probably wrong. transmute and transmute_copy are the two other primary offenders. One should endeavor to bound an unbounded lifetime as quickly as possible, especially across function boundaries. 
Alternatively, you can do it like this: pub fn add_commands(&amp;mut self, cmnd: fn(&amp;mut CommandModule)) { ... } You get the error because in struct definition you use `fn(&amp;mut CommandModule)`, which means `for&lt;'a, 'b&gt; fn(&amp;'a mut CommandModule&lt;'b&gt;)`, but `add_commands` you say `fn(&amp;mut Self)`, which means `for&lt;'b&gt; fn(&amp;'b mut CommandModule&lt;'a&gt;)`. Notice the difference - in first case it says that all lifetimes on `CommandModule` work, but in the second case only one specific lifetime works (the one on the struct, to be precise), and that's why you can't assign the latter to the former. The fix is simply to use the same type on the function parameter as for the struct field. /u/po8's solution will probably also work for you, but it forces adding a lifetime parameter on `Command`, which might end up needlessly infecting other code that stores `Command`s.
&gt; TL;DR the author couldn’t find bugs in the wild so it started looking at the issue trackers. This is exactly how a hacker would proceed, though, so I'd say it's fair game. Why spend days reading/fuzzing/torturing code when a simple search on the bug tracker can: 1. Reveal unfixed bugs that could be exploited (`smallvec`), 2. Reveal fixed bugs that could be exploited in older versions (`VecDeque`). Hackers are pragmatic; why would they waste their time searching for a 0-day when there's a perfectly fine vulnerability ripe for exploitation just sitting there? They'll spend enough time studying the vulnerability to turn it into an exploit as it is.
I, on the contrary, really enjoyed the presentation! Initially it indeed sounded like “meh, Rust is not safer than C++», and it is exactly the right tone to switch to an actionable “Rust is not a silver shield, we need explicit commmunity effort to make it not theoretically, but practically safe”.
It's a potential security vulnerability so I'd yank the old version.
With the Slice &lt;-&gt; Set operations, I would just implement/define methods to do it, so From/Into/TryFrom/TryInto, and then the amount of unsafe code can be limited.
Done! `0.2.2`, `0.2.1` and `0.2.0` yanked ! Thanks for this great review ! I will think more about lifetimes when using `unsafe` and `mem::transmute` the next times.
Yeah that is a little confusing.
But you can do set ops, right? Like intersection, union, difference and set membership. What ops can't you do?
Thanks, I'm working on an emulator in rust now and this seems like a great follow up.
I am aware, yes.
Haskell's heavily experimenting with affine/linear types now from the looks of it!
Yeah, please yank the vulnerable versions. &gt; `pub fn new_unchecked&lt;'a&gt;(slice: &amp;'a [T]) -&gt; &amp;'a Self { unsafe { mem::transmute(slice) } }` Why do you need `transmute()` in the first place? You should be able to do everything you need with safe code only. What's wrong with simply returning something like `Set&lt;T&gt;(slice)`? `vec_sets_into_slices()` and `slice_sets_into_slices()` can be dropped altogether . All you need to do is implement the [Into trait](https://doc.rust-lang.org/std/convert/trait.Into.html) for `Set&lt;T&gt;` into `&amp;[T]`. After that you will be able to pass Set to any function where a slice is expected. As for `vec_slices_into_sets_unchecked()` - my expertise is insufficient to say whether this is vulnerable or not. Fortunately, this function is probably not needed at all: if you need to operate on slices from a vector as if they were ordered and deduplicated, and you're sure they're already ordered and deduplicated, why don't you simply perform the conversion via `new_unchecked()` on every individual slice after fetching it from a vector? So please drop it this function for the time being.
It's more of an intro to very basic Rust.
Thanks! However, Rust's default HashSet is expected to perform poorly on small inputs such as integers. It defaults to SipHash function that is optimized for medium-sized inputs and making it hard to deliberately trigger collisions. A comparison against hash set with [FNV](https://crates.io/crates/fnv) hash function would be more of an apples-to-apples comparison. The FNV crate contains a hash function that is optimized for small inputs such as integers, and is used in the Rust compiler among other things.
The C language is defined by an international standard, there's no intrinsic property of a programming language really making it open or closed source. It's kinda non sense, don't you think? I think the point isn't really the **language** but the compiler. Probably legislators thought that a closed source compiler is safer as nobody can see the source and mess with the software. But it is kinda non sense, I'd say. An open source project is seen by hundreds of eyes. A closed source one is seen only by the people who worked on it and already seen it and are less likely to reason about it from the ground up.
&gt; However, compiler authors got bolder over time, feeling that everything allowed in the standard was fair game, at the same time getting more sophisticated in what optimizations could be done with stronger assumptions. You make this point, in one form or another, several times in the article, and I find it... unhelpful. It is *true*, but without noting the motive, it seems to pitch compiler authors as *adversaries* whose goal is to trip the poor developer and laugh at its expense while taking refuge by the standard to justify their wiles. The truth of the matter, however, is that developers are constantly urging compiler developers to improve the performance of generated binaries. They may not *explicitly* do so. Or not fully realize that they do. Yet when one uses gcc when Clang has so much nicer error messages because it produces faster binaries, one is "voting with one's wallet" and making it clear that performance of generated binary trumps everything else, even user experience. And so compiler authors have no choice but to try and eke out as much performance from the code as they can, leveraging ever more subtle clauses of the standard in an attempt to lead the race. --- As for undefined behavior, I would note that it's not strictly a language issue. In x86, for example, certain instructions have unpredictable results in their pre-conditions are not met; which leads to [such builtins](https://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html): &gt; Built-in Function: int `__builtin_clz (unsigned int x)` &gt; Returns the number of leading 0-bits in `x`, starting at the most significant bit position. If `x` is `0`, the result is undefined. On x86, calling `clz` on `0` may return any number. You could reasonably expect the result to be between 0 and 32 when `unsigned int` only has 32 bits, but `clz 0` can actually return a negative number, or a very large number. The compiler would then need to either: - check that the input is not 0 prior to calling the instruction and use a branch/`cmov` to provide an alternate result, - mask the output to constrain it to a certain range. And neither would be particularly welcome by developers only ever using `clz` with non-0 values. --- Now, I am not arguing that a fair number of cases of UB in C should not be erased once and for all. Turning them into implementation defined behavior (as Rust did for integer overflow) seems sufficient to (1) still ensure that static analysis tools can flag dubious usages and yet (2) ensure a reasonable output of the compiler regardless. However, I also think that a number of cases will require hardware changes. And perhaps, more difficult, a mindset change in hardware providers; though I have some hope that the onslaught of Meltdown, Spectre and lately Foreshadow, will assist in raising awareness that while performance is desirable, blindly racing ahead is a recipe for disasters.
It is not possible to simply return `Set(slice)` because `slice` is a `&amp;[T]` and `Set` is unsized and need a `[T]`. In other word, `Set` is a unsized `slice` (`[T]`) and need to get the same reference as the `slice` in parameter, this is here to add type safety, it must be marked `#[repr(transparent)]`. https://play.rust-lang.org/?gist=559fcab414a2e13dd3b33deb61ce863a&amp;version=stable&amp;mode=debug&amp;edition=2015 Rust does not do auto conversion using the `Into` Trait it will not be so easy to just add the `Into&lt;[T]&gt;` impl to `Set&lt;T&gt;`, I will need to mark my functions as a accepting `Vec&lt;X&gt; where X: Into&lt;&amp;[T]&gt;`. I Implement the `AsRef` Trait on `Set` and `SetBuf` types for this purpose, the user need to use it anyway. The `vec_slices_into_sets_unchecked` is here for something: if you have many many many (many?) slices into a `Vec` that you are sure are sorted and deduplicated you don't want to create another allocation for all these slices. I will not this in the documentation. Thank you for this review :)
Languages with unsafe as a feature are all languages with an ffi though. C# famously has the ability to write unsafe in the language. 
&gt; There's not much that can match Rust's thread safety story, though. It also adds on some features not directly related to memory/thread safety like affine types (not being able to use moved-from values) that make it easier to write correct programs. Immutability can help get most of the way there in other languages.
@fulmicoton Do you think that tantivvy would be a good candidate library to index hundreds of millions of p0wned passwords? While there is a public API offering access to an actively maintained index, it throttles requests to 1 every 1500 milliseconds. The latest password dump is about 10GB! https://haveibeenpwned.com/Passwords 
You're right, it's about the compiler, not the language per se. And it's about support contracts. And about development processes that don't match the regulations. Where are Rust's requirements, specification, risk analysis, verification documents and so on? The device manufacturer would have to write them. Apparently for commercial C compilers it's assumed that the compiler vendor has done this work. Sounds questionable to me.
I agree, in the example, where only one 'type' of message is ever sent for each stage, a struct would do fine. I do want to use enums, even in the simple example, because while structs would do fine in a limited subset of cases(like this example actually), if I were to use those it might give someone new to Rust the idea that one should use structs 'in general', when modelling channel messages. 
Ok! so here I updated the README to display benchmarks with an `HashSet` using the `fnv` custom `Hasher`. https://github.com/Kerollmops/sdset
&gt; The `vec_slices_into_sets_unchecked` is here for something: if you have many many many (many?) slices into a `Vec` that you are sure are sorted and deduplicated you don't want to create another allocation for all these slices. Even without this function you would not need to. At some point you would be extracting those elements and operating on them one by one, so all you need to do is convert the individual elements using `new_unchecked()`, which the compiler should optimize to a no-op. If you're building the vector yourself, e.g. from an iterator, you're much better off using `new_unchecked()` on individual elements as well. So the only use case for this function is when you receive a vector of sorted and deduplicated slices that is not annotated as such from some code you don't control and pass it to some other code that excepts a vector of sets that you also don't control. This should be solved by annotating the original slices, not including an unsafe transmute into your library.
I agree with the author: The world needs formal verification.
This is actually not the case here, as shown in this playground: https://play.rust-lang.org/?gist=fd75d2e7e784a728a9c50e07a2d8ea24&amp;version=stable&amp;mode=debug&amp;edition=2015 The thing is, while transmute could indeed return an unbound reference, it doesn't, because the function requires it to return `&amp;Self` - it looks like this doesn't have a lifetime **but it does due to elision rules**. The code wouldn't be made any safer by providing explicit lifetimes.
&gt; This should be solved by annotating the original slices, not including an unsafe transmute into your library. This is probably not a good idea to force the user propagate the `Set` type all over its code base, the `Set` type is a specific type of a specific library for specific set operations. Let him do what he knows, give him some power and mark this power with words that force him to think twice (`unchecked`).
I was pretty sure of that the first time I wrote this code, the lifetime elision is here for that. But I fear this sentence of the [Rustnomicon](https://doc.rust-lang.org/nomicon/transmutes.html): &gt; Transmuting to a reference without an explicitly provided lifetime produces an unbounded lifetime If the lifetime elision is safe so I can unyank all of the previously yanked versions of sdset.
Arguably, stating lifetimes explicitly is more erroneous than relying on elision. Consider these examples: fn foo(x: &amp;Bar) -&gt; &amp;Baz; // ok, both lifetimes bound by lifetime elision fn foo&lt;'a&gt;(x: &amp;'a Bar) -&gt; &amp;'a Baz; // ok, lifetimes bound explicitly fn foo&lt;'a, 'b&gt;(x: &amp;'a Bar) -&gt; &amp;'b Baz // DANGER, UNBOUND LIFETIMES Only the last case is dangerous and only in body of that function `transmute` could produce an unbound lifetime. Anyway, having no lifetimes in your code is almost always correct.
Let's look at the signature of `transmute`: pub unsafe extern "rust-intrinsic" fn transmute&lt;T, U&gt;(e: T) -&gt; U It looks pretty scary, but we can ignore `pub unsafe extern "rust-intrinsic"`. There isn't really anything special about transmute. Every function with that signature would have the potential to produce unbound lifetimes. When we substitute generics for actual types used in your function, it's clear that no unbound lifetimes occur, because `U` is `&amp;Self`, which lifetime is bound to `slice` by lifetime elision.
I'm already using `AtomicPtr` for this. A mutex would be far too expensive, as the work to perform happens a lot.
The main difference with medical development is there's a bunch of paperwork. Some of this paperwork does encourage you to think about the details of what you're writing, but in general it seems to be very high effort for the increase in quality that you get. 
And let yourself write incorrect lifetime bounds by mistake? Elision works, period. The only way you can make this function unsafe is **by using explicit lifetimes**: pub fn new_unchecked&lt;'a, 'b&gt;(slice: &amp;'a [T]) -&gt; &amp;'b Self The above is *the only* way to let `transmute` give you an unbound lifetime in this case.
The `Ord` trait doesn't define if a `slice` has all it's values in ordered, It just define that the slice have specific methods to know if it is `Greater`, `Less` or `Equal` to another `slice`*. I created these functions just to hide the interior mecanisms of doing this conversion, if the user knows that this is not useful to check if the `slices` are valid `Set`s so he can call these functions without fear because I handle the conversion for him. He can trust the library.
By the way, over in haskell lands, my formatter "brittany" also supports all mentioned types of alignment, although it very configurable for these aspects. One of the more crazy examples of this is the following: go [] "" = True go [WildCard ] "" = True go (WildCard :rest) (c:cs) = go rest (c : cs) || go (WildCard : rest) cs go (Union globs:rest) cs = any (\glob -&gt; go (glob ++ rest) cs) globs go [] (_:_) = False go (_:_) "" = False which is indeed formatted in this way by brittany in default settings. Just for reference, our phrasing is of course somewhat different, we call it - "regular indentation" for simple indented code blocks, what you seem to call "block alignment" - "hanging indentation" [is what is shown in this issue description](https://github.com/rust-lang-nursery/rustfmt/issues/439) (and this is similarly avoided, although not entirely abolished - I have left the default behaviour a bit lax, but users can disable hanging indentation entirely in their config) - "vertical alignment" is any non-start-of-line more-than-one whitespace. but this is by no means in any way "official" or "objectively correct" naming. If there is any interest in similar features for rustfmt, feel free to ask me about details (the relevant code is probably the most unreadable, messy part of brittany, but it is still a non-trivial algorithm that needs not be reinvented entirely.)
* Old releases of X have unfixed bugs! * Some bugs could be security bugs, even if they are not flagged as such! * The *stable* freeze-the-world distribution model is broken, and the premise behind it is a joke! Shocking findings, really.
Sure, but people only need the Rust tool chain for development. Those installing binaries like ripgrep just get the binaries. The last toolchain with the error is one year old, which in Rust world where a lot of people use nightly is really really old. I mean, if that’s the worst that could be found, it is actually pretty good. No PoC of weaponizing this was provided, and even if it was easy, it would be pretty useless. So I don’t know, too many words, for too little meat. I don’t think this was worth a read. 
&gt; I mean, if that’s the worst that could be found, it is actually pretty good. No PoC of weaponizing this was provided, and even if it was easy, it would be pretty useless. I agree! I am also personally more worried about `unsound` bugs against `rustc` itself than bugs against the `std` library at this point, as well as the still too loosely defined semantics for `unsafe` code (pinning high hopes on the RustBelt project). At the same time, though, I believe that raising awareness and striving to improve are still necessary. It was sloppy not to raise a CVE when the problem was discovered, as it undermined the effectiveness of security notifications/updates for downstream users. So in the future it's something we need to keep in mind: UB invoked unintentionally in `std` =&gt; assign CVE and communicate to downstream users on top of fixing the issue. The Rust community is young, still, so there's no shame in not having a smooth and detailed procedure/response in this case. There's also no shame in reflecting and improving, though, so let's strive for that eh? Or in the words of Socrates (translated): &gt; Falling down is not a failure. Failure comes when you stay where you have fallen.
Yeah, I'll try to fix that, thanks for pointing it out. It's a bad habit of mine to start writing a paragraph and never get around to
The world *already* has formal verification. For example, [Liquid Haskell](https://ucsd-progsys.github.io/liquidhaskell-blog/) is probably one of the most approachable ways to write proofs about code. How trivial does it need to be to use so that we focus on correctness rather than maximum profits/performance? We already have a formally verified C compiler in CompCert. Yet most of our C code is still being compiled using the most aggressively optimizing compilers...
Rust is a compromise between living with C (C++) forever and using a GC language (which costs some performance and/or cpu/ram resources). There is some risk of using unsafe (which should always be extracted into an "abstraction" library IMO and not mixed with other code), but overall it's a good compromise.
&gt; Is Rust more approachable than C and C++ Not so much for me as I have already a lot of experience with C++. But I am learning it bit by bit. &gt; or do writers just make it seem that way? I am not sure why they would. Maybe they are comfortable with the language. You can get comfortable with it too if you practice. &gt; Could Rust ever help someone to understand software written in C, in the same way that C does? I doubt that. But to be honest, I couldn't understand C until I started Assembly :) The mileage may vary. &gt; I wouldn't want to miss anything by not learning C IMHO you should learn C. Then you can really see the benefit of Modern C++ or Rust or Go or Python....
i know its a tragedy but what does this picture have to do with the rust programming language?
Do you have benchmarks on large sets? Although the tests are named `big`, input sizes of 100 are really tiny. It would be interesting too see where the limit of usefulness is.
Those ops aren't optimized for HashSet. Intersection is O(n^2) for example. Use binary tree from std instead.
We can spot on the histograms that the other collections will always be less performant than `SdSet` if your data is already composed of already sorted and deduplicated slices. The tests are much more to show how the different types behaves on different kind of overlaps. The `slices big` tests are where the numbers are the most overlapped (`0..100`, `1..101`, `2..102`) and the `slices big3` tests are where they never overlaps (`0..100`, `100..200`, `200..300`) and this is where the `SdSet` is the better collection to use. You can just consider that the benchmarks times are all linearly related to the sizes of the slices. Another thing to consider is that the `BTreeSet` and the `HashSet` moves the values into heap allocated memory blocks so it will be an important overhead, that `SdSet` doesn't have.
've been using c++ for more than 10 years. It was good to learn, you have to understand a lot of low level thing. With the c family you have to learn the meaning of ownership, lifetime the hard way: through mysterious crashes. It won't be easier in rust either. Borrowchecker will make you mad for sure. Once you've learned one of them don't start learning the other by comparing the two. At first they look similar but I had to forget c++ to really understand rust. They have similar concepts but sometimes they cannot be mapped. Ex classes vs traits similar goal for abstraction but they are just completely different (like apple and orange). 
In my experience helping out C and C++ beginners, the biggest problem of these languages (and other unsafe languages), which makes them IMO unsuitable for teaching the basics of programming, is that they are not safe; that programs can exhibit undefined behavior, and that this behavior might look like the programs work. This is absolutely disastrous for teaching. There is nothing more confusing and discouraging for a learner than being told that their program - which seems to work fine for them and solves their problem - is actually wrong, and possibly in a way that is hard to explain. Rust, as long as you don't use unsafe, does not exhibit this problem. This makes it IMO infinitely superior to C and C++ for beginners. (But so are Java, C#, Python, Ruby, and all the other memory-safe languages of today.)
This is why I was surprise that the `HashSet` has set operations. But as you can see, the `fnv::HashSet` is better than the `std::collections::BTreeSet`. https://github.com/Kerollmops/sdset#histograms
&gt;I had to forget c++ to really understand rust. Really ? For me the modern c++ memory model made it somewhat easier to understand. Having said that, I agree there are lots of other differences for the good.
The world already have formal *verifiers*. The parent comment was a joke.
Why can't fruits be compared?!
You don’t have to understand why Rust is useful to use it, or at least, no more that you have to understand all intricacies of “horse” maintenance to be able to drive a car.
Haskell because it's gc'd can't be used for real-time systems and can have space explosion behavior. A simple foldr over some calculations for example. Or a foldl over other calcs. And it's not trivial to determine or see what may cause a space leak. Haskell being lazy is it's own source of problems. So not suitable for embedded use either. Current best bet is Ada.
C# has unsafe facilities as well. You can't do most system level programming without raw memory access.
You just create a struct with these two fields. How is it more expensive than what you are doing now?
&gt; The parent comment was a joke. Whoopsie.
Maybe part of the problem is the all-or-nothing approach of `unsafe`. Then again, categorising its usages is probably very difficult, since it would not be used otherwise. Doing this by hand using human reviews is definitely a possibility. 
You could also review documentation, both reference and guided/tutorial style.
There's no vulnerable version. The function above is perfectly safe.
I appreciate your desire to help, and I agree that `unsafe` is scary. However [crying wolf](https://idioms.thefreedictionary.com/cry+wolf) is not helpful. Too many false alerts and people will get inure to them. If you had simply used the playground to validate your claim, you'd have realized that there's no issue: use std::mem; fn new_unchecked&lt;T&gt;(slice: &amp;[T]) -&gt; &amp;[T] { unsafe { mem::transmute(slice) } } fn main() { let x = { let y = [1, 2, 3]; new_unchecked(&amp;y) }; println!("{:?}", x); } Yields: error[E0597]: `y` does not live long enough --&gt; src/main.rs:10:24 | 10 | new_unchecked(&amp;y) | ^ borrowed value does not live long enough 11 | }; | - `y` dropped here while still borrowed 12 | println!("{:?}", x); 13 | } | - borrowed value needs to live until here 
Good point, edited in.
I didn't read the code properly. It should really say **if** it's a security vulnerability. Sorry for any confusion/issues.
Even stuff like Haskell has "UnsafePerformIO" and friends; you need such escape hatches for FFI and such.
My feeling exactly. I hope Rust doesn't end up in the same state as JS, with Medium tutorials and Medium clickbait...
Yea, I have an insanely hard time going from C/C++ to Rust. I prefer C/C++ still, but rust has it's benefits.
Please use a code block. So is it really hard for potential helpers to ready your code. :D
"Rust is a *new* systems programming language" - it is?
I think this is a tooling issue rather than an issue with the language itself. Rust tooling is fantastic; C++ tooling is... not. (although, headers are awful)
I am new to Rust and stuck with this problem: [https://www.reddit.com/r/rust/comments/98d8tb/new\_to\_rust\_can\_anyone\_help\_me\_with\_this\_problem/](https://www.reddit.com/r/rust/comments/98d8tb/new_to_rust_can_anyone_help_me_with_this_problem/) It's probably something around the fact that I don't truly grok the borrowing concept in Rust. Any help would be appreciated :)
Yeah, and while you can technically use unsafe for learning how memory works, it feels like there's a ghost in the machine because the compiler moves everything around and it's doubly hard to reason about what's going on. At least, that way my experience.
&gt; Unsafe blocks in Rust only give you a few additional powers I don’t understand the point of stating this in the context of this conversation. I’m not disputing that it’s true (of course it is), it just means nothing for the purpose of this thread, as these ‘few additional powers’ are more than enough to bring the whole thing down. Type checking doesn’t really mean much when you can trivially just use transmute and/or pointer tricks to just declare a memory location a different type. 
If you are trying to get a the Nth fibbinocci number than using a for loop would be better `for _ in 0..Readline` This will always run Readline times meaning that sfn will contain the Nth Fibonacci number What currently is happening with the while loop is you are finding the fibbinocci number that is less than Readline `while lfn &lt;= Readline` so if you enter 10 as Readline you will get this output `0 1 1 1 1 2 1 2 3 2 3 5 3 5 8 5 8 13` This is not the 10th Fibonacci number, ffn will contain the 7th Fibonacci number 13, and that is because the 7th Fibonacci number is the one that is greater than Readlines; 13 &gt; 10. so the loop terminates. Since the growth rate of Fibonacci numbers are nearly exponential comparing them to their index isn't that useful, for example the 5th Fibonacci number is 5, but the 10th Fibonacci number is 55, and the 100th Fibonacci number is 354224848179261915075.
put it into a github gist or something to make it readable
Yes, this seems like a better approach. Thanks!
My experience was that it was. C and C++ were the first programming languages I attempted, and re-attempted a few times the years following, but it was difficult to get anywhere between the lack of documentation, segmentation faults, cryptic compiler errors, &amp; the need to mess with headers and system libraries to get anywhere.
Please ignore the robots demanding a perfect signal/noise ratio from what was a fun post to read.
 struct Dog; struct Cat; struct Fox; trait Name { fn name(&amp;self) -&gt; String; } trait Talk { fn talk(&amp;self); } impl Name for Dog { fn name(&amp;self) -&gt; String { "Dog".to_owned() } } impl Talk for Dog { fn talk(&amp;self) { println!("Woof!"); } } impl Name for Cat { fn name(&amp;self) -&gt; String { "Cat".to_owned() } } impl Talk for Cat { fn talk(&amp;self) { println!("Meow!"); } } impl Name for Fox { fn name(&amp;self) -&gt; String { "Fox".to_owned() } } impl Talk for Fox { fn talk(&amp;self) { println!("Ring-ding-ding-ding-dingeringeding!"); println!("Gering-ding-ding-ding-dingeringeding!"); println!("Gering-ding-ding-ding-dingeringeding!"); } } fn what_does_it_say(thing: impl Name + Talk) { println!("The {} says:", thing.name()); thing.talk(); } fn main() { what_does_it_say(Dog); what_does_it_say(Cat); what_does_it_say(Fox); } `Dog`, `Cat` and `Fox` are nouns - they describe a thing. `name` and `talk` are verbs - they describe things you can do. `Name` and `Talk` are adjectives - they are describing certain properties of the objects. `what_does_it_say` requires "something that has a name and can talk" - it gives a description that it's argument should fit into. The convention in Rust is to have single method traits and name them after that single method, but their role is still of an adjective.
Thanks for the suggestion. I've added the gist to the post ([https://gist.github.com/tanin47/03a511f303699f9a383a30fec004c770](https://gist.github.com/tanin47/03a511f303699f9a383a30fec004c770))
True, but when Oracle wanted to remove it with Java 9, they found that so much code depended on it that they had to settle for a warning instead.
Indeed it is, but without the tooling writing in c++ is as useful as writing in latin for me.
Inside an unsafe block, I can effectively assert any memory location is any type I want. How does that not count as being “less typechecked” than the rest of Rust?
For learning purposes, C is in many ways a smaller, simpler language. You can read Kernighan &amp; Ritchie or some other introductory book, and get the basics of the language in an afternoon – enough to write toy programs and understand basic code written by other people. Rust can take a much longer time to understand to a similar level of completion. However, for writing real-world programs, there's a lot more you need to know than just the basic language syntax and semantics. The C standard library is old and crufty, and the larger ecosystem of libraries and tools is complex and varies from platform to platform. Pitfalls and edge cases are numerous. Rust can make it much easier and faster to write reliable, cross-platform applications and to build on other people's work.
You may compare them but don't start to create applejuice in the same way as orange juice . 😃
Because acquiring a mutex very frequently is more expensive and performing a simple compare-and-swap. Spinlocks (e.g. via parking_lot) will reduce overhead, but it's still more expensive (as I measured as well).
No stream, but it was all recorded, the talks will be up... someday.
Having written some small commits for Rust projects and some C/C++/asm for school, I’d say writing somethibg small that “works” is probably easier in C, but hacking on some public repo made by someone else is a lot easier in Rust.
Listen in [my crates collection](https://users.rust-lang.org/t/list-of-crates-that-improves-or-experiments-with-rust-but-may-be-hard-to-find/17806).
Nice ! Thank you !
It is less type-checked, but that doesn't change the fact that you can do the exact same thing in unsafe C# (or in python ffi modules, but that isn't surprising). Both Rust's unsafe and C#'s require explicit casts to turn a pointer of one type into a pointer of another, though. It means much less guaranteed safety, but having explicit operations in an explicitly opened unsafe block means at least some ability to code-review unsafe operations with more scrutiny.
Or use the new 'fancy pants' editor. fn main() { Target::initialize_native(&amp;InitializationConfig::default()).unwrap(); let context = Context::create(); let module = context.create_module("main"); let builder = context.create_builder(); let i32_type = context.i32_type(); let fn_type = i32_type.fn_type(&amp;[], false); let function = module.add_function("main", &amp;fn_type, None); let basic_block = context.append_basic_block(&amp;function, "entry"); builder.position_at_end(&amp;basic_block); let ret = i32_type.const_int(123, false); builder.build_return(Some(&amp;ret)); let triple = TargetMachine::get_default_triple().to_string(); let target = Target::from_triple(&amp;triple).unwrap(); let target_machine = target.create_target_machine(&amp;triple, "generic", "", OptimizationLevel::Default, RelocMode::Default, CodeModel::Default).unwrap(); let path = Path::new("./output.o"); target_machine.write_to_file(&amp;module, FileType::Object, &amp;path); }
Modern C isn't too similar to Rust. C has barely changed actually. The best we've gotten is VLAs and a Generic macro. Modern C++ is similar in effect though, yes. 
Eh, not sure I agree with that personally - but the snark was really directed at the use of "new" in contrast to the title (which is clearly written in such a way to make it feel much older). 
Ambitious, I like it. It would be nice to abstract the transport so one could replace TCP with say RDMA. Features important to _me_ * End user extensibility (WASM, Lua, JavaScript), I am favoring WASM for lots of reasons, language agnostic, fast runtimes, good sandbox, opt-in bindings to host, etc. * Event notification subscriptions (object creation, metadata update, read, etc) * Permission, authentication * Views, composite objects * Object lifecycle * Management interface * controlling rates and frequency of internal processes These are all "just features" to bring something new to the table, would be to support both an FS and multiparty streaming (Kafka) with the ability to have source and sink processes (in WASM). Pre and post read/write hooks for objects (WASM). I think all of these things can be supported by a generalized layer that supports applications, those applications would be the FS interface exposed to clients but the backend would have a basic number of primitives. I really like how Kafka is implemented in Kafka. This has lots of nice benefits for abstraction and correctness. What distributed filesystem papers are you reading? Another area of consideration is how it will be tested and how it will be shown correct. Both will be instrumental in developer velocity and end-user adoption.
&gt; Show me your flowcharts and conceal your tables, and I shall continue to be mystified. Show me your tables, and I won’t usually need your flowcharts; they’ll be obvious. [Fred Brooks](https://en.wikiquote.org/wiki/Fred_Brooks) younger brother to [Mel Brooks](https://en.wikipedia.org/wiki/Mel_Brooks)
&gt; Do Use a decent text editor, VS Code is pretty good right now VS Code is awesome, it uses more wall clock time than my web browser. Really do give [IntelliJ](https://www.jetbrains.com/idea/download/) a try, the [Rust plugin](https://github.com/intellij-rust/intellij-rust) development is support by Jetbrains and it shows. 
Is it undefined behavior to make a trait object from a zero sized struct , set `std::TraitObject.data` to null and then call functions on the trait object?
That sounds similar to my library [vfin](https://github.com/axelf4/vfin)! Would you mind writing a comparison together when you're finished?
Yeah I like the idea of the abstractor transport. That'd be really nice to be able to support RDMA. I def like the features you're talking about. One additional one I think would be quotas. Rate limiting has been a key feature that is missing from both gluster and ceph. It's a hard thing to add on later once your project is already well under way. Could you expand a little on your command about end user extensibility with WASM? I'm not sure I follow what you mean. Some distributed filesystem papers I've read in the past include Sage's PhD dissertation on Ceph. I've also read the paper on Dynamo and Cassandra. They're starting to get a bit dated at this point though. I'm very familiar with the internal workings of Gluster. I haven't gotten far enough to start thinking about how it'll be shown to be correct. I'm familiar with how hard distributed filesystems are in general though and how hard it is to make them correct. That's a good point. 
I strongly discourage the use of the `[..]` syntax whenever I see it, since I think it's ugly/opaque at a glance, it is virtually never needed, and when it is needed, it's better to just do `.as_ref()` or `.as_str()` for clarity.
Could you provide an example? The following causes a compiler error. trait T&lt;S&gt; { fn t(&amp;self) -&gt; Box&lt;dyn S&gt;; } trait T1: T&lt;T1&gt; // causes "infinite recursion"
&gt; The triple-backtick syntax doesn't work here. Actually, annoyingly, it does, but only for the New Beta Theme. You can check [here](https://new.reddit.com/r/rust/comments/98d8tb/new_to_rust_can_anyone_help_me_with_this_problem/) 
That is something I hadn't considered, and definitely accurate. The article could definitely be more self-coherent.
Apparently so. Ideally they would have just made the much better backtick syntax work for the useful theme. Backticks are much easier than adding spaces everywhere. I think the new one even supports syntax highlighting. Seems like a nasty trick to try and force people into the beta theme, to me.
That's by calling a very particular intrinsic function, or another function that calls that function, you can audit for that, safe rust code writtent inside an unsafe block is just as safe as if it wasn't inside the unsafe block, unsafe doesn't relax any of the existing checks on safe code, it _only_ allows you to do some additional unsafe things. That's a very important distinction in mind.
Swapping out the transport can have a substantial effect on performance and design. For example if you want to have low latency then you would design for rdma and you don't use erasure coding because reassembling the file parts negates the benefits of direct memory access. If you build for resilience or scalability then you use http2 and EC because you want to have the resilience of EC instead of replication. And you want to be able to stream through proxies and existing http infrastructure. If you want to build something, choose some tradeoffs. Set off to make that and only that. As for your original idea, it sounds like HDDs which Hortons is building in upstream Apache Hadoop. They think of it as hdfs2 and it's protobuf, raft, I think a fuse driver will be in the works as well as inotify. I like your idea of transformation pushdown. Maybe you can add that to ceph and get your best feature without having to invent the world.
Good point. I'm not deeply familiar with how RDMA works. I haven't given much thought about adding this to ceph but that's food for thought. 
To make things work, you need a direction. Nothing will click if you take from here and there without a reason to do that. In my case, I always build a ORM-ish library/framework (because I work mostly around RDBMS). I judge a language in how good is to talk to RDBMS. Also, this open a lot of cases. Like, how deal with dynamic data, conversion of types, networking, exceptions, parsing and a lot of small but diverse stuff. I always find that because the impedance mismatch, RDBMS make almost any language to get out the confort zone and deal with a moderate yet well know problem. So, have a specific project in mind and try to build it in rust. Is VERY useful if is the same kind of project around your work revolve: Is web apis? Is games? Is networking?... etc. so you don't need to learn ALSO the domain but just how implement it. Plus, if you do this many times, you already have interiorize how do this well. So, if this lang is TRULY a improvment, it will not because you also refactored old code and blindy think the improvment is because you use a new language. \--- With respect a paradigms, with my long experience of 2 weeks of rust, is all about vectors and operate on list. Decompose data in even more granular form than objects, and then move data around. I think that is better to avoid traits (not as easy to use: Like, try to print a trait. You can't. Rust HATE HATE HATE HATE polymorphic code). So stay with structs + vectors as long as you can. That is my opinion so far.
&gt; don't use erasure coding because reassembling the file parts negates the benefits of direct memory access Erasure coding handles both checksumming and missing portions of the file (should servers be unavailable or slow). The use of EC doesn't conflict with RDMA. EC should be used regardless of the transport. RDMA never stands alone and would be a component in the transport mix. One will still have a TCP control-plane or fallback channel. 
This might be a bit hard to solve without more domain knowledge of how inkwell works. Have you tried asking on [their gitter](https://gitter.im/inkwell-rs/Lobby)?
Thanks to [Vincent Isambart](https://twitter.com/vincentisambart) for tracking down the story: [Finding a CPU Design Bug in the Xbox 360](https://randomascii.wordpress.com/2018/01/07/finding-a-cpu-design-bug-in-the-xbox-360/).
That was...not their point.
I totally understand that. How about a focused question that might be easier to answer? What is the difference between putting that line inside a method vs. outside of the method? To me, there seems to be no difference.
End user extension would handle some of the callbacks or delegates for the response to events. One could push security policy or conformance checks, structured search, metadata extraction, post/pre read/write actions, multi object updates, crdt algos, etc. A little bit of programmability goes a long way. Lots of the features I outlined could be implemented as end-user extensions instead of having to be baked into the core. Another internal design consideration is the use of pervasive counters for flows/events/actions both good and bad, basically anything that leaves a coordinated failure boundary should go through a counter. Most distributed systems end up looking like a coordination interface over queues and then the application is layer on top of that. Take a look at the Erlang VM, it isn't good for large messages (Riak mistake) but it is *excellent* for everything else.
Depending on your use case I've implemented something that already works here: https://github.com/pedrocr/syncer The use case is more for syncing your own files across machines and not having to have all files in all machines at all times and still pretending that you do. The only server that's needed is an ssh+rsync endpoint. It works already and exposes a full POSIX filesystem that's quite fast. I need to finish the rename tracking properly to be able to announce a usable version for testing.
What's important is that the language actually cares about the problem and tries to fix them. Even if it doesn't succeed the lofty goals and attempts will at least lead us down the right direction.
I just checked the old version of reddit. The triple-backtick looks very bad. [https://old.reddit.com/r/rust/comments/98d8tb/new\_to\_rust\_can\_anyone\_help\_me\_with\_this\_problem/](https://old.reddit.com/r/rust/comments/98d8tb/new_to_rust_can_anyone_help_me_with_this_problem/)
Idk if I'd call it a compromise. Maybe for the programmer if you're from a high-level world. The language itself is suprisingly uncompromising if you come from a performance oriented mindset. I'd argue less compromising than modern c++. Very few languages give the level of correctness checking that Rust does, period. And on top of that they rarely compromise on overhead cost for their abstractions. I suppose having unsafe is in itself a compromise, but for a c programmer it's comforting to know that I can always fall back to that level in case it's necessary for whatever reason when every cycle, cache miss and memory fetch counts.
I have some new development. I've been performing some gorilla debugging (by moving lines around to see which combination works). Here's a simplified and more focused version that works: \`\`\` fn build\_mod\_static( module: Module, function: FunctionValue, context: Context, builder: Builder, ) -&gt; (Module, FunctionValue, Context, Builder, BasicBlock) { let basic\_block = context.append\_basic\_block(&amp;function, "entry"); builder.position\_at\_end(&amp;basic\_block); let i32\_type = context.i32\_type(); let ret = i32\_type.const\_int(123, false); builder.build\_return(Some(&amp;ret)); (module, function, context, builder, basic\_block) } fn main() { let context = Context::create(); let builder = context.create\_builder(); let module = context.create\_module("main"); let i32\_type = context.i32\_type(); let fn\_type = i32\_type.fn\_type(&amp;\[\], false); let function = module.add\_function("main", &amp;fn\_type, None); let (module, function, context, builder, basic\_block) = build\_mod\_static(module, function, context, builder); println!("{:?}\\n{:?}", module, function); let triple = TargetMachine::get\_default\_triple().to\_string(); let target = Target::from\_triple(&amp;triple).unwrap(); let target\_machine = target.create\_target\_machine(&amp;triple, "generic", "", OptimizationLevel::Default, RelocMode::Default, CodeModel::Default).unwrap(); let path = Path::new("./output.o"); let result = target\_machine.write\_to\_file(&amp;module, FileType::Object, &amp;path); println!("{:?}", result); // This line will tell me whether it writes to output.o correctly. The exception isn't raised, btw. } } \`\`\` The above version works. However, if I remove the line \`println!("{:?}\\n{:?}", module, function);\`, it will stop working. I have tried other combination as well. For example, \`println!("{:?}", module); println!("{:?}", function)\` still doesn't make it work. This is super weird. Why would \`println\` impacts the result?
Yeah I'd think that you'd want crdt and such at a higher level just because they would be parsing and working with the file data instead of any clustering or storage integrity. Not every file type could be put into a crdt for handling that
Is the goal an object store, block store, or both?
&gt; I think your standards might not be very representative for what constitutes "approachable." Perhaps it wasn't clear what I meant. What I meant was that: amongst the proof techniques that I've seen being applied to programs, Liquid Haskell ranks as highly approachable. IMO, the proofs are very similar to what you would write by hand. Of course, I'm happy to know about more approachable alternatives to it that integrate with a mainstream language. 😄
``` trait T { type Ret; fn t(&amp;self) -&gt; Box&lt;dyn Self::Ret&gt;; } ``` And then for the impl ``` trait T1 { type Ret = Ret1; // etc... } ``` They are called associated types.
I've been playing with something related. (http://github.com/rawler/bithorde) It's not a writeable filesystem, but a distributed content-distribution-system with an optional read-only fuse filesystem. I first wrote it in D, then rewrote in C++. Currently I'm rewriting parts of it in Rust. The end goals are different, but I think some parts can be reused between the projects, (I.E. FUSE - libs). I believe you will have faster progress (unfortunately, I have very little time for Rust), but I will be looking out for opportunities of cooperation. One word of warning though; Bithorde is also built on top of protocol buffers, a design decision I regret. Protocol Buffers, while being a very nice protocol to work with, have some non-neglible overhead, especially quite a bit of extra memory copies. Fine for small messages, where CPU-cycles are mostly spent in other code anyways, but for high-performance I/O throughput, it does not suffice. This can be resolved with writing custom implementations of PB, but PB as a whole is non-trivial, and much of the things it solves (dealing with complex fine-grained information structures and it's versioning) does not really show up in high-performance I/O applications. PB simply does not offer enough to be worth it, in my experience.
I agree protocol buffers is nice to work with. I was wondering about the overhead myself but I never looked into it. I know Ceph's RPC isn't self describing and comes with a huge amount of memory overhead when serializing and deserializing. I was kinda hoping that protocol buffers improved on that but I guess I'll have to look deeper into it. I'm not married to it. I don't mind switching it out for something else as long as the overhead and throughput are good. Gluster settled on XDR back in the 90's probably for the very reasons you're talking about. I'd have to rewrite my api spec but that's not a big deal. Do you have ideas for other protocols that might be better as far as throughput goes? The other nice part about protocol buffers is if someone decides they want to write another client for the cluster in some other language they can do that by just generating against the spec. If the throughput sucks though nobody is going to want to use it anyways haha. 
Oh, and one more thing. I don't think it's very useful for an R/W filesystem, but my main focus in right now is developing a separate codebase for object storage. The key here is the use of the "hash-as-id" paradigm, and Merkle Trees as a way prove parts of an object is correct. I have some code for the Merkle Tree here; https://gitlab.com/rawler/stored-merkle-tree. It's not perfect, but it's nearing the point of a 0.1 release. There are other implementations of Merkle Trees for Rust, but one thing I haven't managed to find for either of them, is how to efficiently map trees into persistent storage and back. Likewise, few of them has a flexible concept of partially stored trees and incremental patches as a way of transferring.
&gt; LLVM error message isn't helpful. It says "File name too long". I'm guessing the addresses of some variables are corrupted This sounds like `ENAMETOOLONG`. Maybe it's something simple like an interesting filesystem interaction or a generated filename that isn't quite right. Are you on linux? If so you can use `strace` to see the operation that failed.
Maybe using `println!()` brings in IO and formatting code which would otherwise be trimmed away and that big affect on the codegen process makes a difference? All of this weird behavior is definitely pointing to something else causing undefined behavior and that undefined behavior only causing errors depending on unrelated things.
I'm not sure what your point is, then? You say that you can do this in C, but if the code has undefined behavior, it means you actually can't?
I'm getting tripped up by lifetimes here: https://play.rust-lang.org/?gist=5b0d674c3976fbc4827602a0baeb93f9&amp;version=stable&amp;mode=debug&amp;edition=2015 Basically, I want a struct to have a vec of functions which act on itself. So, that should require that the function args require a lifetime that is the same as the overall struct. However, it's suggesting that I need lifetime specifiers in other places, and I'm not sure why. Can anyone clarify? Thanks
As I am hitting it with random code, things just perplex me. I think you are on to something and might be right. What I've found is that the length of code within the `main` function seems to matter. In fact, adding `format!("aaaaa");` makes it work. However, if we use only 4 `a`, it errors with `File name is too long`. 
The fst crate is probably sufficient and easier to use for this use case.
Yeah I kinda figured it might be an unterminated string.
The idea of "second class" auto-generated clients were precisely the reason why I chose protocol buffers as well. In practice I think the people integrating a file-system based on protocol buffers, are equally capable of implementing a simple protocol on top of reliable streams. If I got the time to deal with changing the protocol today, I would design my own minimal messaging protocol, similar to protocol buffers maybe even byte-compatible, yet constrained enough to only have the parts I really need. (prefix-length encoding, single-byte message tags, and simplest possible message payloads). One thing I regret not considering early, is building in support for message-priorities and multiplexing into the protocol. In a protocol with similar requirements I designed more recently, I split every message in a chunk-size chosen to be ~2 ms targeted connection-rate. Every chunk is then prefixed with a couple of bits representing discrete queues, one bit signaling "last chunk of message", chunk-length + chunk. The sender can thus send multiple requests in parallel, and prioritizes lower queues over higher queues. This is useful for several things, in particular "forget resource" messages can be injected in the middle of large data-transfer-messages and be prioritized before "open new resource-request", improving latency and avoiding congestion. One related design-space left to explore is moving multiplexing out to completely separate TCP connections (maintaining sessions over bundles of connections). Single-connection TCP can sometimes fail to fully utilize bandwidth.
I wonder if you know how to fix it. I've read the SO post and not sure how to fix it. Here's the code of \`write\_to\_file\`: [https://github.com/TheDan64/inkwell/blob/master/src/targets.rs#L870](https://github.com/TheDan64/inkwell/blob/master/src/targets.rs#L870) \---- it seems very relevant to the SO post. My quick hack that seems to work now is to use `let path = Path::new("./output.o\0");`. But this looks like a wrong solution...
Instead of `path.as_ptr() as *mut i8` have you tried `path.as_bytes()`? The SO answer suggests OsStrExt trait and that's the one that seems to make sense.
It's going to be even harder to avoid unsafe now that impling Futures will virtually require unsafe. I rewrote a &lt;2,000 LOC library with the futures in nightly and ended up with about 30 unsafe blocks.
It's all started when I failed to easily cross-compile nbd-server for Android.
I only use the old(read: good) version, which is why it's so annoying that it only works in the new theme.
Another byproduct is a FUSE utility crate [readwriteseekfs](https://crates.io/crates/readwriteseekfs). If you have some `Read`+`Write`+`Seek` (or even withough `Write`) impl then you can mount it.
I find the given example easier to read than its split-out counterpart. 
it's really easy to scan consistent syntax. When you have pattern breaking syntax, it takes a lot more thought to read. What syntax in Rust is known for breaking a pattern to save a few characters?
Because to_string() allocates a new string which is a copy of the string slice. I do not think many, if any, implicit things in Rust allocate new memory.
Given that adding `\0` fixes it, I think https://github.com/TheDan64/inkwell/blob/638306fdc79dd362ddf3cf474cbb794e6dcfb9c3/src/targets.rs#L875 is the line with the bug. It should be turning the path into a `CString` before passing it into LLVM so that `\0` is automatically appended.
However, it would be possible to tweak `String` to allow it to point to static data (by setting its capacity to 0, for example). This way we could create `String`s from string literals without allocation.
My personal opinion: For what it's worth, whenever I see this in C/C++ (which is my day job right now) it's always really jarring. Sure, this saves you a few keystrokes, but it always seems harder to read than just typing out the type again. It's usually pretty rare to do this more than 2 or 3 times in common data structures IME. I don't know that there IS an explicit stance on this in the Rust community, but those are my two cents. :)
You could use `std::any::Any` and cast your data into `Box&lt;Any&gt;`, and then you could use the `get_type_id` method to do something similar. The `TypeId` struct is Opaque though, so I'm not sure how much useful information is available there, though is TypeId's are gonne be constant, you may be able to define a match statement to do the work.
*Then* you would allocate. Which presumably isn't a big deal because `push` is already where you expect to allocate.
 You might want to look [`std::borrow::Cow&lt;&amp;str&gt;`](https://doc.rust-lang.org/beta/std/borrow/enum.Cow.html). `Cow` stands for copy-on-write. Basically, it will hold an immutable reference to the `str`. Then, when you want to change mutability, the `Cow` will create a new `std::string::String` from your `&amp;str`.
Thanks for sharing!
try: fn foo(s: impl Into&lt;String&gt;) { let s = s.into(); println!("{}", s) } you can pass either a String or a &amp;str to foo() and it will work. If you don't really need a String in foo this is better: fn bar(s: impl AsRef&lt;str&gt;) { let s = s.as\_ref(); println!("{}", s) }
That's how [`Cow&lt;str&gt;`](https://doc.rust-lang.org/std/borrow/enum.Cow.html) works.
No, not quite. `Cow` tracks whether it's a `&amp;str` or `String` by being an enum; this `String` tweak would fold it into its normal operation without changing the API or memory layout.
Same principle, though. It's a type that can be made out of a reference to static data, but once you try to change that it switches to owned data. `Cow` just makes you do that transition explicitly, since Rust usually tries to make costs explicit.
It's not short-vs-long though, it's all about making things readable. `&amp;`, `'a`, `!`, `?`, etc. are pretty short syntaxes, but they stand out, and they're all consistent. I see many more design decisions aligned with consistency over ease of writing, and all of those help code be more maintainable. Rust forces all fields to declare their own types just like `let` is always in the form of `let single_lhs = single_rhs;` and ternary (`x ? y : z`) operators are left out in favor having `if` be an expression. It's all for more consistency across the language, and therefor more maintainability.
&gt; Code completion is syntactic, performed by Racer. Because it is syntactic there are many instances where it is incomplete or incorrect. However, we believe it is useful. If my memory serves me correctly, I seem to recall at some point hearing that RLS would eventually do completion on its own, thus deprecating Racer. Is this still planned?
&gt; into a function expecting a std::string::String. There's your problem. You can't complain that Rust is noisy if you're writing unidiomatic Rust. There's few reasons for a function to take a String; it should be taking a &amp;str. The only exception is if the function is going to store it somewhere.
I like rls and use it with vscode all the time. It's definitely got more stable since I started using it, but really wished they fixed compatibility with [oni](https://github.com/onivim/oni/issues/1926) 
Maybe they shouldn't be separate crates. Sometimes things are worth separating into libraries.
I agree. It's super weird to me that anyone would be against *this*, of all things.
That's the entire point I'm trying to make, though- in the `String` case the cost can be folded away so there's no reason to make the cost explicit.
&gt;It makes the struct / parameter list harder to parse for both humans and compilers in order to what, save very little typing? You could say that exact sentence about so, so, so, many things that are already a part of Rust and have been forever though.
By a factor of 10? That seems kind of low to me o_o 
I use vscode for most things these days but I just can't for rust. I'm not experienced enough with the language and the rls integration is too spotty to help me. A couple of chained method calls and I'm left without any completions/suggestions. Also having to specify the type of every variable so that rls can complete on it is tedious. I will try rls again since I haven't in a while but I'll probably stick with rust plugin on intellij, it just makes it so much easier for someone unfamiliar with rust to see what's going on.
Warning: I'm just spouting thoughts here in reply. This is intended to further the conversation, not win a debate. :) Fundamentally, `String`'s implementation operates under the assumption that any calls to mutate are acceptable because it has a buffer all on its own that's fine to change as necessary. To implement your suggestion, one would at the very least need another boolean value to indicate that underlying buffer isn't actually owned and needs to be cloned upon mutation...which would be 100% isomorphic with `Cow&lt;str&gt;`! Obviously, Rust as-is doesn't make getting `Cow`s from literals any easier than `"literal".to_owned()`...but I guess I just don't consider this a bad thing, coming from a background where performance by default is a better default. I see the OP's idea as the flip side of the fundamental trade-off of performance &amp; implementation simplicity vs. convenience for some really common code -- the "pit of success" that Rust encourages people to fall into is performance here. 
That doesn't really solve the problem of "too much `.to_string()`, though. It's more a way to reduce the actual copying than to reduce syntactic noise, which it doesn't do.
right push would allocate *and* free the old memory
The trick is, as I mentioned, to make the capacity 0 if you don't own the buffer. Then, it turns out, you can fold all the checks into the existing branches you already need for cases like empty strings. No extra boolean and no extra branches.
For this and other reasons, I oppose this 1.0 RC declaration. RLS is not ready for 1.0, as much as it pains me that this must be the truth even late in 2018. Completion is less effective with RLS than almost any other language server.
You could do the inverse and match `.as_str()`
Is it still not possible to mark struct fields as immutable? https://stackoverflow.com/questions/23743566/forced-immutable-struct-field-in-rust#23748710 One use case for this would be to avoid accidentally adding methods that mutate the field which can break invariants (cache invalidation).
For a structure with groups like that, I think it would make sense to use additional structs for each of them
Looks like lots of other people are questioning your stuff here -- I'd love to see an implementation, though. You've got me cautiously excited to see something working!
You're in luck! It's already been implemented and discussed quite a bit: https://github.com/rust-lang/rust/pull/46993 https://internals.rust-lang.org/t/pre-rfc-allowing-string-literals-to-be-either-static-str-or-string-similar-to-numeric-literals/5029
Thanks everyone for the suggested solutions, but its a lot less annoying once I understand why its forcing me to be explicit.
While I have noticed that the RLS has improved over the past year (props to the authors!), I still don't believe it is in a state to be pushing for 1.0 just yet, due to the same reasons as others have detailed in this thread. It's quality is just not on par with what the language servers for other languages provide. With all that being said, credit where credit is due, there's been some great work on it so far and it really has improved over the past year. However, I just don't believe it is ready for prime-time, but that's OK! Writing good software takes time :)
That's correct. Any RFC would probably need to address the interaction with unsafe code, with a hypothetical DerefPure, and with the analogous change to Vec, on top of the coercion idea, and there doesn't seem to be enough interest/bandwidth to do that right now.
oh yeah that makes sense. but it would feel really strange to me if rust would auto convert `&amp;str` to `String` but not i.e. `u8` to `u16`. however to have literals to be `&amp;str` or `String` depending on context sounds like a nice idea to me.
Ok that's way less scary. I suspect this is not really a bug and more a lack of documentation. For instance, do you open more than one index (e.g. one per thread?) ? The effect of load_searcher only impacts an Index and its clone. Index that were opened independently are not affected. Is there any chance you could share your code? 
It definitely wouldn't for the particular use case relevant to my example.
I agree with you, and tbh it makes sense to just work with the IntelliJ team at this point. Rust is not a small indie language, it has the corporate backing of Mozilla, so they could leverage the business aspect of problem solving this rather than code. RLS is fairly weak in it's completions and seems inconsistent. With the language in so much flux, I'm not exactly sure why they are pushing for 1.0 other than to try to get it to coincide with 2018 edition (therefore what can approximately classified as "marketing" reasons).
What is the recommended way to use RLS with vim?
explicit &gt; implicit
I'm not even sure what you mean by "pattern breaking", as I wouldn't say Rust syntax can generally be grouped in patterns in every area. A very simple example would be even just something like, what's with the trailing commas everywhere? (As within structs, e.t.c.) I can't be the only one who thinks they look quite jarring and out of place. I've always thought the closing ones should be semicolons, if anything.
https://github.com/w0rp/ale seemed to work without doing anything.
The trailing commas are a continuation of the pattern, which makes it easier to reorder lines, and makes diffs less noisy since adding another line to the end doesn't change the previous line by adding a comma. That consistency makes it easier to just mentally ignore the commas. Personally, I wish Rust had copied Go on this aspect: no commas at all (and definitely no semicolons) in struct declarations. They're not helpful, but it's better to use trailing commas if you're going to use comma separation. I say all this as someone who has worked in languages that require commas, but don't allow trailing commas. Even just editing the VS Code preferences could be so annoying because of that. I think they eventually changed it to start allowing trailing commas.
Why, though?
`A: B` doesn't mean A inherits from B, but rather A depends on B. If you want to generalize traits T1 and T2, then you can remove that dependency and leave only the stuff unique to each trait inside. If you want to state that T1 and T2 cannot be implemented without implementing some common base trait first, then you extract the common base (which the functions you specified are not part of, due to having different return types) into trait T and make T1 depend on T being implemented by writing `T1: T` in trait declaration.
So rust uses expressions rather than statements for it's control blocks, so that means that match expects a return value. In the first match statement you have above, one arm returns whatever HashMap::insert returns, and the other arm returns nothing (technically it returns the [unit](https://doc.rust-lang.org/std/primitive.unit.html) type). What rust is complaining about is that these two are not of the same type. HashMap::insert returns a `std::option::Option&lt;entity_factory::Property` so your second arm needs to also return something of this type. Option has two states, Some and None, you can use Some to create a default value, or None to represent no value. for example you may want something like this. match (prop_type, property) { p1 | ... | pn =&gt; properties.insert(prop_name.to_string(), property), _ =&gt; None } If you want you can wrap the first arm in an Result::Ok and the second arm with an Result::Err.
I might be wrong, but I think that might have more to do with the very odd way that C declarations handle pointers. See this (possibly deliberately) confusing example: int* a, b; That reason, at least, does not translate to rust.
The problem is that `insert` returns a value which in turn means that that match arm "returns" (I think I'm abusing the nomenclature slightly here, but hopefully you get what I mean) a value, and since your other arm doesn't return a value then the two don't match. What you need to do is suppress the value that is returned in the first arm using a semi-colon (which unfortunately means you'll have to wrap that arm in curly brackets) [like this](http://play.rust-lang.org/?gist=7df1ab5e07ece9d38f71aa80c5d3edda&amp;version=stable&amp;mode=debug&amp;edition=2015). I feel like rust should be able to know that you're not using that value and therefore does this for you implicitly, but maybe there are good reasons that it doesn't. BTW peeps who are in charge of the playground: can we turn off the fancy editor and just use a dumb text box or something if we detect that the user is on mobile, please? Because Jesus Christ writing that example was an exercise in frustration, every time I entered a comma or a bracket it would just randomly delete a couple of preceding letters. 
You can collect an Iterator of `Result&lt;T, E&gt;` into a `Result&lt;Collection&lt;T&gt;, E&gt;`, where collection is a storage typ, so like a Vec.
Just started learning Rust a couple days ago. Can someone tell me why `let up` returns an error while doing basically the same thing inside the match works? fn event(&amp;mut self, event: &amp;Event) { let code = if self.is_second_player { Key::Up } else { Key::W }; let up = Event::KeyPressed { code: code, .. }; /////// error: expected expression, found `}` match event { up =&gt; { self.moving = 1 } Event::KeyPressed { code: Key::S, .. } =&gt; { /////// &lt;- works perfectly well self.moving = -1 } Event::KeyReleased {..} =&gt; { self.moving = 0 } _ =&gt; {} }; } 
Because in the match block, it is a pattern, which allows you to use the .. syntax sugar to ignore fields that you don't need. Patterns are only allowed on the **left** hand side of a `let =` statement. So what you need to do is to fill in the rest of the struct's fields if you want to use it on the right hand side of a let binding. As well as that, is there a reason for creating an instance of an event instead of destructuring in a match bolck?
This is just doing 1.0 tool releases to check an item off a project milestone in a PowerPoint. RLS can’t do completions using the compiler, which was the whole point, given that racer did already exist before it. Rustfmt can’t Format macros, comments and other basic things (comment spellchecking, etc). Changing the version number of all tools to 1.0 doesn’t magically fix them, and the only thing it will achieve is disappoint everybody giving the language a second chance when Rust2018 is released. Will they ever give it a third chance?
Almost every completion engine does LSP now. I use asyncomplete with if executable('rls') au User lsp_setup call lsp#register_server({ \ 'name': 'rls', \ 'cmd': {server_info-&gt;['rustup', 'run', 'nightly', 'rls']}, \ 'whitelist': ['rust'], \ }) endif 
LSP integration through [LanguageClient-neovim](https://github.com/autozimu/LanguageClient-neovim). You can check in my [vimrc](https://github.com/kooparse/dotfiles/blob/master/.vimrc)! :)
Great to see an interesting storage-related Rust project!
&gt;IntelliJ Rust has created a superior language aware product in a significantly shorter period of time. Thanks for the kind words! However, the bit about "shorter" is technically incorrect: IntelliJ Rust is slightly less than one year *older* than RLS.
I wish there was a better way (and there probably is), but right now something like that should be enough, thanks! Also, the library is rust-sfml.
It's confusing, hard to edit and therefore maintain, could result into unnecessary big diffs. We also don't allow this in our company.
I use RLS with vscode or vim all the time, and I really like it. RLS has improved a lot over the past year. However, it is still short of the aims it set itself and its still documented as only working on small and uncomplicated projects. Maybe its the right call for marketing reasons, but I'm worried people might be disappointed for something that still has a lot of room to get better. Maybe its unfair as its significantly more mature product, but the only other LSP that I know well is the original Typescript one. The Typescript compiler LSP integration + prettier + tslint combination is significantly more capable than the analogous RLS + rustfmt + clippy one. The rust compiler in its current form doesn't seem to be able to give the timely feedback that the RLS needs, hence this fallback to Racer that has long been described by the tools team as a placeholder until the compiler was ready for RLS. 
Oh come on. Rust is full of inconsistencies, often for the sake of programmer convenience. It starts with basic stuff. Sometimes "=" means copy, sometimes it means move. Sometimes you need the deref "\*", sometimes you don't. A lot of Rust's rules comes across like those for campfire card games, where kids come up with stipulations like "Well, an ace is the highest value card, except on weekends and odd-numbered days ..."
I'm not sure if I agree with this argument, for two reasons: - Not all code is written to be read many times. Sometimes you write one-off programs. - You sometimes want as little typing as possible e.g. when prototyping. In the final product you're still free to use more verbose syntax if you want. Having shorter syntax doesn't mean only using it and nothing else. 
Wouldn't this force you to write one documentation comment for all three fields?
Totally agree about being able to use it w/o understanding, my point is less direct in that - one of the purposes I think of learning c/c++ in, for example, an academic environment, is to get a better idea how things are working under the covers, e.g. "what the machine is doing" w/o going all the way to writing assembly. In many ways Rust abstracts that away more than c/c++, and so is less useful for that learning aspect, which is what I think jackie was getting at.
Sacrificing readability for either of these two cases is an extraordinarily poor tradeoff. 
Yes. But that wouldn't really be a problem in this specific example since the fields are only joined together like that if it would make sense to document them together anyways.
&gt; In the final product you're still free to use more verbose syntax if you want
This logic can be used to justify literally anything. Design is about leaving things out, not adding as much as possible in. 
I don't think it is any harder to parse for compilers: the parser/grammar just has to check to see if it has a `:` or a `,` and then parse a type or another identifier, respectively. It already has to do essentially this much checking because it needs to check that the `:` exists. There's certain types of code that declares a lot of locals with identical types (e.g. numeric code with a lot of `f64`s), and writing out either `let (x, y, ...): (T, T, ...)` or `let x: T; let y: T;` doesn't exactly help make the code obvious. (This comment reads a little like a post-hoc justification of the rule Rust happens to have.)
While there are definitely inconsistencies (the names of `str`, `String`, `Path`, `PathBuf` and `Vec` being one), I'm not sure that those two particular ones are good examples. Certainly for `=`, there's a deeper consistent rule that it follows: `=` is always a bitwise copy, and there are only some types for which this is also a semantic copy (and for those types, one continue to use the source, otherwise one cannot).
There is no even reusage of results of `cargo check` run. And you tell about "pull model", "keep in the memory" and so on. At first I suppose huge success would be just coordination of efforts with compiler. 
The `String::into_bytes` method currently guarantees that it doesn't copy the contents of the string. If `String` was more than just a `Vec`, I think it would break that guarantee. Either that or `Vec` would need to play along with the capacity-zero convention, which might contradict a lot of explicit guarantees it makes to unsafe code in its own docs.
For real projects I use `emacs` + `racer` + `cargo-mode`. It is not as good as `IntelliJ Rust`, but starts become better thanks to @kngwyu for his work on `racer`. `rls` is too heavy for my i7+16GB RAM + Intel SSD. 
&gt; At first I suppose huge success would be just coordination of efforts with compiler. That's a common "compiler writer fallacy" I guess? "We have a compiler already, so let's just plug that into an editor and be done with it". In practice, however, I think all successful IDE efforts were developed as a **rewrites** of the primary command-line compiler. At least, this happened with C#, whose Roslyn was a rewrite, with Dart, whose analysis server [was independent](https://www.reddit.com/r/rust/comments/95r7qh/intellijrust_update_language_support_improvements/e3vpfv6/) from the VM's parser, with Java (both IntelliJ and Eclipse went with building their own compilers), and might happen with the new version of Scala, Dotty. Kotlin and TypeScript are exceptions, but they started as IDE-first compilers. 
You are making some very good points! Just as a word of warning: IntelliJ folks are very good at bootstrapping support for languages, because they can reuse a lot of their existing frameworks. What they are less good at is supporting the full language, because they literally need to reimplement the typechecker. So IntelliJ is rather good at what it does, but often what it does is not covering 100% of the language. The Scala support is a very good example, with years of "good code red" issues, many of them still unresolved. Therefore, Rust really needs it's own, independent tooling, especially to avoid having a single IDE dictate how people write code and forcing developers to avoid constructs because their IDE doesn't support them. Again, the failures of Scala in this regard are instructive: If one IDE becomes predominant, the subset that it supports becomes the defacto language. Avoid this at all costs. That's why it's important to have competitive first-party tooling available.
not really helping your request but: when you are done with the GC can you extract it so others can use it? Optimally with a GC&lt;T&gt; type.
I think the `git2-rs` example may have misled you. You don't get any sort of interior mutability by having a pointer - it just becomes easier to write the bugs. The only reason that the example you link to is safe is because `git2-rs` does not implement `Sync` on its `Repository` - which works as a way of preventing any concurrent access at all, but is limiting. I'd claim that the correct signature for that `set_workdir()` would be to take `&amp;mut self`.
I would recommend eglot over lsp-mode as it deals better with restarting the underlying language server (without freezing your editing session); and RLS crashes *a lot*. My general experience with the combination is that sometimes it works, sometimes it doesn't - and it's not entirely clear what happened in between. It's probably best to become proficient at writing Rust without relying on completion. 
&gt; That's a common "compiler writer fallacy" I guess? &gt; We have a compiler already, so let's just plug that into an editor and be done with it No, I tell about reuse of `cargo check` results. And I don't even tell about reuse of AST that `cargo check` produced after 10 minutes of dependency parsing. Let's start with something simple, reuse of `build.rs` results, please do not run `build.rs` during rls analyzes, just reuse results from `cargo check` or `cargo build`.
Thanks for the correction! I've indeed misinterpreted the original statement as "using compiler will solve **all** issues".
What is the most simple and lightweight program to intreface RLS? Is there a CLI for RLS?
`entry.path().display().to_string()` allocates a new `String` every time you call it. That's three allocations per iteration, or _a lot_ of allocations. You can just print `Path`s directly, which will probably save you quite a bit of time.
"Only frozen 3 years ago with fairly minimal syntax and stdlib and keeps evolving rapidly" is very young by systems programming standards. For comparison, Ada and C++ are over 30 years old.
Thank you for the correction! I'll try to actually verify the impression I get from the docs next time.
Replace `properties.insert(prop_name.to_string(), property)` with `{properties.insert(prop_name.to_string(), property);}` which causes the expression to evaluate to `()`, then do the same with the other arms
RLS is mostly a conglomeration of existing command-line tools: `rustfmt` for formatting, `racer` for code completion, `cargo check` and `cargo clippy` for warning about compilation problems. The big benefit of RLS is that it ties all those tools together with a consistent API (the Language Server Protocol specification) that many existing editors and IDEs can use.
&gt; Clippy is installed as part of the RLS. You can turn it on with a setting in your editor or with the usual crate attribute. What kind of editor setting would that be? If I had an editor with LSP integration, what special message or command-line argument would I need to send RLS to turn on Clippy linting?
Thanks for writing the article. Do you plan to make such a analytics also to the golang 
Thanks :)
Why do build rust from source when you have rustup? I assume you're not working on the compiler in a Windows env?
In a word - no. I do not consider Go to be as critical for IT security on the grand scale as Rust, because Go can only replace C/C++ in certain niches, while Rust could do it universally. So I will keep spending my free time on securing Rust for the time being.
Read the error carefully :) It mentions \` IntoParallelRefIterator\` and you are looking at \`IntoParallelIterator\` definition. In this case, simply use \`into\_par\_iter()\`
Upon reading many of the comments here, I'd have this to say in reply: Do not let the perfect be the enemy of the good!
Yes, that's the problem. Methods which change the capacity would work out of the box; however in-place mutations would break.
Something which I would love to see in a distributed filesystem would be ground-up support for proper auditing (users deleting, creating, modifying files). As for management interfaces, it would be nice to have metrics/counters exposed via [Prometheus](https://prometheus.io/) (Rust crate [here](https://crates.io/crates/prometheus)) so I can visualise it all nicely on dashboards and setup alerts.
How do I get the "Code intelligence" aspect of it as a command-line tool? Does racer support e.g. "find all implementations". Can I call a CLI tool to edit my sources code, renaming an identifier at file:line:column to specified name?
And in `File::open`, don't call `display()`, it can take a path object directly.
``` let mut file = File::open(entry.path().display().to_string()).unwrap(); let mut s: Vec&lt;u8&gt; = Vec::with_capacity(file.metadata().unwrap().len() as usize); file.read_to_end(&amp;mut s).unwrap(); ``` is just `std::fs::read`.
Isn't oni "just" a neovim GUI? What happens if you use `LanguageClient-neovim` instead of oni's built-in client thing?
Ah 😣 Thank you, I should be more careful.
Ah, an update to the program I only run when I mistype `clear` before I type `ls`
Suspicion: Rust doesn't buffer file IO by default, Go does. Hence why switching to a single big read speeds it up. If you want buffering, you should look at `BufRead`.
Funding would be a problem, but I'd be happy to talk about that job thing. We're heavily looking for people good at tooling, but have to secure money first. contact@ferrous-systems.com
Nit: Go's `os.File` does not do buffering by default. Folks tend to use the standard library's `bufio` package to add buffering. With that said, the OP's Go code reads the entire file into memory at once, just like in the Rust program.
I wrote this last night (~5h, the code is a bit messy), I did all of this manually before that. There are some know bugs, but I think it gives a pretty good idea of problems that are going to show up along the way of packaging it. Some background on this: debian requires that all the source that is needed to build a project is packaged in debian, which means that we're [creating packages for each crate][0]. We're generally trying to avoid packaging outdated crates though. This is a cumbersome process and we've started filing a lot of PRs and posted issues on github. If you've been wondering why, this is the reason. :) [0]: https://qa.debian.org/developer.php?email=pkg-rust-maintainers%40alioth-lists.debian.net
Perfect, thanks!
What you *could* do is create a `struct Immutable&lt;T&gt;(T);` with a single method `get(&amp;self) -&gt; &amp;T`, so that the inner value can only be accessed and not modified. This obviously doesn't prevent reassignment of the immutable structure (or a `Cell` child), but it can prevent a few mistakes. 
io::copy basically does buffered r/w internally, except it skips the BufReader and allocates the 8k buffer (same as BufReader's default) on the stack directly.
New Rust Quote Of The Week: &gt; Rust is a `cargo` cult [~iamsexybutt on /r/programming](https://www.reddit.com/r/programming/comments/98brvj/how_to_alleviate_the_pain_of_rust_compile_times/e4fuek8/?context=3)
Look at the data. Your benchmarks are in the low tens milliseconds. This is just a whisper above measuring process overhead. Running your exact programs over a larger directory tree will be more meaningful. For example, on my Linux system on a checkout of the Linux kernel: [andrew@Cheetah linux] hyperfine /home/andrew/go/src/play/boyter/target/release/boyter-rust Benchmark #1: /home/andrew/go/src/play/boyter/target/release/boyter-rust Time (mean ± σ): 1.947 s ± 0.048 s [User: 1.374 s, System: 0.563 s] Range (min … max): 1.889 s … 2.037 s [andrew@Cheetah linux] hyperfine /home/andrew/go/bin/boyter Benchmark #1: /home/andrew/go/bin/boyter Time (mean ± σ): 2.371 s ± 0.032 s [User: 1.651 s, System: 1.066 s] Range (min … max): 2.338 s … 2.425 s However, on a smaller directory (a checkout of `git` itself), the Rust version is still faster: [andrew@Cheetah git] hyperfine /home/andrew/go/src/play/boyter/target/release/boyter-rust Benchmark #1: /home/andrew/go/src/play/boyter/target/release/boyter-rust Time (mean ± σ): 163.2 ms ± 5.2 ms [User: 77.6 ms, System: 84.9 ms] Range (min … max): 153.7 ms … 173.0 ms [andrew@Cheetah git] hyperfine /home/andrew/go/bin/boyter Benchmark #1: /home/andrew/go/bin/boyter Time (mean ± σ): 138.9 ms ± 10.9 ms [User: 63.6 ms, System: 89.6 ms] Range (min … max): 123.9 ms … 161.0 ms w.r.t. to using the `bytes` method on `File` directly, that is indeed slow, because you aren't doing buffered reading. That method is going to read one byte at a time from the underlying reader, which means a syscall for every byte. That is _gratuitously_ slow. If the method existed in Go it would be slow there too. You can somewhat fix this by wrapping your file in a buffered reader (`std::io::BufReader`), but that still turns out to be a bit slower since handling each individual byte like that has some amount of overhead. Namely, each byte is wrapped in a `Result`. In general, the `bytes` method is a performance footgun and I think I can say should never be used if you care about writing fast programs. Others have remarked on your additional allocations. It would be good to remove those. Here's the source for that: https://gist.github.com/BurntSushi/37cf13595516acda9bd45e5003be4ea9 But it doesn't make a difference [andrew@Cheetah linux] hyperfine /home/andrew/go/src/play/boyter/target/release/boyter-rust Benchmark #1: /home/andrew/go/src/play/boyter/target/release/boyter-rust Time (mean ± σ): 1.964 s ± 0.058 s [User: 1.361 s, System: 0.593 s] Range (min … max): 1.900 s … 2.085 s Which makes sense if you think about it, since the other work you're doing in your program dwarfs the time it takes to copy file paths. Two other things that can be done: * Use buffered writing. * Clean up the code and just handle errors. It's easy to do, so just do it. Here is your cleaned up program: https://gist.github.com/BurntSushi/bc44576642c4fe9feedfb9f839245d92 --- The benchmark remains mostly unchanged on my system, although there is a slight decrease in sys time, probably because of buffered writing. As to why your Rust program is slower on your machine than your Go program... Given the difference in sys time there, and the extraordinarily tiny scales at which you're operating, it wouldn't be completely out of the question that the extra allocations are hampering you. This could possibly have an impact if your directory tree is somewhat large but contains very small files.
Is the second example more idiomatic than just accepting &amp;str and letting the caller make a reference? Also, I've been out of touch with recent sugar additions and didn't realize `impl Trait` was valid in argument position. Thanks for showing me!
Hmm, that's kinda' annoying because now I must litter the struct's methods with `get()` calls instead of just doing field access. 😐
&gt; Others have remarked on your additional allocations. It would be good to remove those. Here's the source for that: https://gist.github.com/BurntSushi/37cf13595516acda9bd45e5003be4ea9 An additional possibility in this one is lifting the Vec out of the loop. That probably removes a bunch of allocations (after the Vec has grown enough, maybe pre-size it to avoid the initial resize as well) and the metadata() call (if walkdir already stats the file and caches it, but in case it does not that's a stat avoided).
Personally I would certainly prefer a `&amp;str` parameter. Using generics in this case seems to be unnecessarily complexity and code size increase.
You can also look for another direction, pick a theme that motivates you, then ask yourself “what do I want to be better ?” : That led me to make some suggestions to nphysics : https://github.com/sebcrozet/nphysics/pull/133 ; so far I’m still discovering and not sure any of this is really useful and appreciated, but it’s fun for me for now. Tl;dr : you don’t have to wait for someone to ask you for help, start small, and find a way to open source :)
Having used a few vim/neovim language clients, I’d personally recommend going with ALE. It supports RLS, is easy to configure, and has good documentation. Obviously it’s asynchronous. Between the configuration options and documentation, it just feels the most “mature” of any of the clients I’ve tried, although development is still very active. w0rp and others have done a lot of impressively quick work to make it a good LSP client for many languages.
If you're into getting system information from (often nasty) OS APIs, [systemstat](https://github.com/myfreeweb/systemstat) needs more things to be implemented on Windows and macOS. And support for new platforms (NetBSD, SunOS/illumos, Haiku, Redox?) is always welcome too. If you're into terminal emulators and GTK, [galacritty](https://github.com/myfreeweb/galacritty) needs things like mouse support. 
Then you lose the field names, which are certainly meaningful in my example. Furthermore don't you think that kind of tuple definition demonstrates precisely why stacked fields are no less readable than anything else?
&gt;can we turn off the fancy editor and just use a dumb text box You can go to the config at the top right and turn the style to simple. 
I don't want maintainers so much as contributors (same thing? I don't know), but on the off-off-chance you're interested in modern Prolog implementation: r/http://github.com/mthom/rusty-wam
&gt; Linaro toolchain should work. In .cargo/config you must set path to libraries set ar and linker to linaro toolchain. Thanks for the suggestion, but no luck with this -- after adding full paths to `-ar` and `lib/` or with also specifying `CFLAGS` etc. in a `build.sh`, the effect is no different than before: ./hello_world ./hello_world: line 1: syntax error: unexpected word (expecting ")") 
Despite reading BurntSushi's guide to Error Handling, I'm still a little confused as to what the best practice is for reducing the nested explicit case analyses on a Result of the form \`Result&lt;(), SomeEnum&gt;\`. Here's my code: ``` use std::{num}; enum OutboundMessage { Success(String), Failure(String), } enum AppError { Num(num::ParseIntError), // Other(some::other::ErrorType), } fn main() { let parse_err = "not a number".parse::&lt;i32&gt;().map_err(AppError::Num); let outbound = { match parse_err { Ok(_) =&gt; OutboundMessage::Success("success".to_string()), Err(e) =&gt; match e { AppError::Num(ne) =&gt; OutboundMessage::Failure(ne.to_string()), // AppError::Other(oe) =&gt; OutboundMessage::Failure(oe.to_string()), }, } }; } ```
I strongly agree with you there. I recently tried out VS code + RLS again after reading about it approaching 1.0. I was quite disappointed to find that even on very small codebases completions are bad and stability is very spotty and unreliable. Rust is surely a hard language to write an RLS for due to the advanced type system, generics, borrow checker, type inference, auto conversions (From/Into) etc and I understand this is a big effort which requires a lot of resources and dedication. But I don't think praising RLS as 1.0 in this state will do the public opinion any favors since it is quite far from the experience developers have come to expect for other languages. I could only recommend VS Code + RLS at the moment if someone has a very strong aversion to IntelliJ, because it is just so much better. (even though it does become quite slow on medium+ large codebases as well.)
`io::read` is not really blocking (in the sense of blocking the thread), it's just going to return `Async::Pending` until it has received at least one byte. How long do you want to wait for a byte before sending `DATA`? If the idea is to send a message out then wait as long as necessary for a response, then reorder the steps. If the idea is to send the message if no response has come in by time X, use timeouts. If the idea is to saturate the socket with `DATA` while waiting for any bytes to come in, use `select` to race the read and the write.
The implementations you are suggesting do not appear to be well encapsulated. x should probably be left private and you should be accessing it through a getter. If you did it this way, then clients would not need to know if x was coming from the struct directly or form a sub-struct.
I'd like it to return 0 if it can't read something so there rest of the loop can complete. I actually tried rearranging my code to write the protocol's hello first and then read but this doesn't seem to fix it either. The full code is on this link below but it's obviously more noisy than the test case. https://github.com/locka99/opcua/blob/client_tokio/client/src/comms/tcp_transport.rs I had another branch where I tried splitting the read / write into separate loops. They all seemed to block. I might try a cargo update next to see if it's some odd version issue. Something very odd about it.
Thanks for the explanation and your implementation. I think I'll try to work out the lifetimes for the second round of errors too, and that helps a lot. And yea, in the actual code, I'm returning a Result from the checks, but I removed it to make the question more clear. Thanks!
I'd love help with SIMDeez: [https://github.com/jackmott/simdeez](https://github.com/jackmott/simdeez) A SIMD library, that I need to start adding Neon and AVX-512 to if possible And SIMD Noise - a noise library which uses SIMDeez to do noise very fast: [https://github.com/jackmott/rust-simd-noise](https://github.com/jackmott/rust-simd-noise)
You star, thank you. Probably should have checked more thoroughly before making that statement, but I was just so damn frustrated. 
But has anyone actually shipped vulnerable code that can be compromised with the VecDeque bug? One thing I've learned from the security community is that it isn't an exploitable bug until it's \*actually\* an exploitable bug. There has to be some piece of software out there, preferably widely used, that can be compromised for a bug to rise to the level of a security vulnerability. Until then, it's a vulnerability \*concept\*, not a vulnerability. (I learned this from Go, which has a completely unsafe implementation of interfaces that we would not stand for in the Rust community and could lead to arbitrary code execution, but security people rightly pointed out to me that this is very unlikely to happen in practice, so until that happens it's not a security problem with Go.) It's easy to get used to thinking in terms of, for example, a JavaScript engine, for which any imaginable program that can be used to violate memory safety constitutes a security vulnerability. But, crucially, that's because \*JavaScript engines run untrusted code\*. By contrast, Rust is not used to run untrusted code (and, in fact, it can't—there are known miscompilation bugs that make that unwise). So these kinds of bugs are not vulnerabilities and, in my mind, do not deserve a CVE.
&gt; Why do build rust from source when you have rustup? I mean, I do have a copy of rustup, but I'm not sure how that's relevant exactly. I build GNU-Toolchain Rust from source on Windows for the purposes of building and testing cross-platform applications, within an MSYS2 environment so that I can make use of the many libs MSYS2 has available that are difficult to find otherwise, and so that I can make use of the GCC 8.2 toolchain in conjunction with Rust as opposed to the rather outdated GCC 6.4 the official Windows GNU Rust toolchain ships with. &gt;The language server concept is superior in every way that you can build this once and integrate with any editor supporting the Language Server. This is the future. It's only "superior" in the sense that it's (arguably) more widely compatible with various software. As far as functionality though piped JSON is never going to compete with a realtime language-specific parser/analyzer. For example, IMO an IDE-focused parser written in Rust exposed through a `cdylib` would be just as widely compatible as a language server implementation, while being more useful/performant in general.
Pest, an easy-to-use programmable parser, is currently getting ready for a major release, with [a few things missing](https://github.com/pest-parser/pest/milestone/4). There is also a handful of [other issues](https://github.com/pest-parser/pest/issues) that I'm happy to help with.
To be honest, I have yet to understand how this language is "Rust-like". The syntax is strikingly similar, but the cloth does not make the man.
To be honest this is something I'm new to, but a friend shared the link with me and I figured this would be a good Reddit for it. Maybe someone else can shed some light on it.
Here is the homepage of the project: https://anydsl.github.io/
Even with rustup and having installed absolutely everything in the default locations, the plugin would still sometimes not find things. It's baffling. However, I've had the same problem with the very popular vscode Python plugin, which absolutely refuses to find any version of pylint - be it from a distro package or installed via pip.
How do I do monadic parsing in rust? I figured out how to do it using a StateT in Haskell, but I'm having trouble to convert that knowledge to rust. Esentially I'd like to know how to implement a parser type that is generic over some parsing state (usually the input string) and the result type. A parser should have a Parse method that takes some state and produces a optional result with a new state. The rust signature would look a bit like fn parse&lt;A, S&gt;(state: S) -&gt; Option&lt;(A, S)&gt; The critical thing is being able to combine to parsers, similar to and_then for result. I don't really know how to implement that, and lifetimes are making this code even messier, because rust can't just assume that A in Parse is a owned value. If somebody could point me in the right direction (maybe with rust equivalent of haskells bind, item and sat functions for parsers) that would help a lot. 
Sure, but why? Why not either use Cow or accept a string slice?
What if you start a local webserver to serve your WASM instead of loading it from a file:// URL?
You can use `line.chars().nth(0)` to get the first character of the String.
Just to be clear, &gt; I'd like it to return 0 if it can't read something Within what timeframe? Your CPU is 1000s of times faster than the network, it will almost certainly not have any bytes to read the first time it checks.
Here's a fixed version of the code that doesn't hang. Tested it locally against a modified version of the echo.rs example (so that it'd run on the port # your client wants to talk to. Note how I reordered the write to happen first. This may not be what you want to do. extern crate tokio; extern crate tokio_io; extern crate futures; use std::net::SocketAddr; use futures::Future; use futures::future::{loop_fn, Loop}; use tokio::net::TcpStream; use tokio_io::AsyncRead; use tokio_io::io; // This is a HELLO message sent from a client to an OPC UA server const DATA: [u8; 57] = [ 0x48, 0x45, 0x4c, 0x46, 0x39, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x01, 0x00, 0x00, 0x00, 0x19, 0x00, 0x00, 0x00, 0x6f, 0x70, 0x63, 0x2e, 0x74, 0x63, 0x70, 0x3a, 0x2f, 0x2f, 0x31, 0x32, 0x37, 0x2e, 0x30, 0x2e, 0x30, 0x2e, 0x31, 0x3a, 0x34, 0x38, 0x35, 0x35, 0x2f ]; fn main() { run_connect_task(); } fn run_connect_task() { // Default address for echo.rs let addr = "127.0.0.1:4855".parse::&lt;SocketAddr&gt;().unwrap(); tokio::run(TcpStream::connect(&amp;addr).map_err(move |err| { println!("Could not connect to host {}, {:?}", addr, err); }).and_then(move |socket| { println!("Connected"); spawn_looping_task(socket); Ok(()) })); } fn spawn_looping_task(socket: TcpStream) { // Split the socket into a reader and writer let (reader, writer) = socket.split(); let looping_task = loop_fn((reader, writer), |(reader, writer)| { println!("Loop"); // This io::read() could read some bytes or 0 bytes let in_buf = vec![0u8; 1024]; println!("Writing data"); io::write_all(writer, &amp;DATA[..]).map_err(|e| { println!("Write IO error {:?}", e); }).and_then(move |(writer, _)| { io::read(reader, in_buf).map_err(|e| { println!("Read IO error {:?}", e); }).map(move |(reader, _in_buf, bytes_read)|{ (reader, writer, _in_buf, bytes_read) }) }).map(move |(reader, writer, _in_buf, bytes_read)| { println!("Got {} bytes", bytes_read); let quit = bytes_read &gt; 0; // quit when we got *some* bytes (reader, writer, quit) }).and_then(|(reader, writer, quit)| { Ok(if quit { Loop::Break(()) } else { Loop::Continue((reader, writer)) }) }) }).map_err(move |e| { println!("Loop ended with an error {:?}", e); }).map(|_| { println!("Loop finished"); }); tokio::spawn(looping_task); } 
Comment spellchecking doesn't sound like a rustfmt's work at all to me.
I'm not sure how electron works. Does it use `file://` internally for the content? Or some other, electron custom protocol? I know that `instantiateStreaming` doesn't work on `file://` because it requires the MIME type to be set, but file never sets any MIME types. You can work it around using `instantiate` instead. You might be the victim of a wasm-bindgen bug. It seems that the wasm-bindgen code about this [is a bit stupid](https://github.com/rustwasm/wasm-bindgen/blob/b15ebf27a895ed5629d960951ab57c18b6a7dfc6/crates/cli-support/src/js/mod.rs#L409-L415) and just uses `instantiateStreaming` if it is available. But on the `file://` protocol this function can't be used atm. So IMO it should be extended by a check that if the file protocol is used, instantiate should be used, even if `instantiateStreaming` would have been available.
&gt; How do the optimizations done in MIR compare to their new IR? Which optimizations does Rust do on MIR ?
It'd definitely work, but it's an impractical solution for a self-contained application. I could do that for testing (something like [webpack-dev-server](https://github.com/webpack/webpack-dev-server) might be useful) but would have to ship a static file server inside the application for distribution.
The OP describes one motivation- creation of `String`s could be made less noisy. There's also potentially better performance- `Cow` has to branch on `&amp;str` vs `String` all the time; this would not. And it would extend `Cow`'s "don't allocate until necessary" behavior into existing `String`-based code.
I'm not 100% sure who exactly is responsible for the `file://` URL. Webpack appears to fetch `./` URL's, and Chromium seems to resolve this internally into the full `file://` URL. I don't think this is a `wasm-bindgen` bug (though I agree the behavior likely could be changed), as the generated code is from webpack entirely. That said, you're on to something: if I snip out webpack's call to `instantiateStreaming` and just instantiate directly, things work. Planning to open a PR with webpack to see if we can get this changed for `file://` URL's, you're a lifesaver.
Continuation-passing style means you write in such a way that instead of returning values from functions, you simply call the next function with the result instead. There is a [transformer](https://hackage.haskell.org/package/transformers-0.5.5.0/docs/Control-Monad-Trans-Cont.html) and corresponding [mtl class](https://hackage.haskell.org/package/mtl-2.2.2/docs/Control-Monad-Cont.html) for this in Haskell.
Continuation-passing style means you write in such a way that instead of returning values from functions, you simply call the next function with the result instead. There is a [transformer](https://hackage.haskell.org/package/transformers-0.5.5.0/docs/Control-Monad-Trans-Cont.html) and corresponding [mtl class](https://hackage.haskell.org/package/mtl-2.2.2/docs/Control-Monad-Cont.html) for this in Haskell.
https://boats.gitlab.io/blog/post/2017-12-27-things-explicit-is-not/
I can recommend Servo, that is how I learned Rust. https://github.com/servo/servo/blob/master/CONTRIBUTING.md You might want to start with easy issues: https://github.com/servo/servo/issues?q=is%3Aopen+is%3Aissue+label%3AE-easy and then look at "less easy" ones: https://github.com/servo/servo/issues?q=is%3Aopen+is%3Aissue+label%3A%22E-less+easy%22 After you still have "hard" https://github.com/servo/servo/issues?q=is%3Aopen+is%3Aissue+label%3AE-hard and also "interesting project" https://github.com/servo/servo/issues?q=is%3Aopen+is%3Aissue+label%3AB-interesting-project Personally, I think that contributing to Servo is an effective way to learn Rust. The maintainers in Servo obviously have a lot of experience in Rust, so you'll get valuable feedback, and the (very large) codebase is a real repository of knowledge on how to do things in Rust. It's also quite interesting how you can get quite a lot done with only limited knowledge. There is so much code around what you are trying to do, that you usually can find some "entry point" to solve a problem without needing full understanding of the topic. And off-course you can always ask for help... 
The traditional tool for this are either plugins (a user provides a DLL that adds extra code conforming to a given API) or by embedding a scripting language.
Thanks very much for looking at this. On the link I had reordered to write first too but it wasn't working that way either but I'll review the code and see if I've missed something.
I think rust and the rust community have tried to avoid the pitfalls of c++ and that makes rust more approachable as a result. For example there's a single Rust Book from the creators of the language; no such book exists for c++.
BuT 1.0 oNlY mEaNs StAbLe, NoT rEaDy
Woah it works! Thanks alot!
That form of encapsulation is really just not helpful for cases like this.
I don't know, but I recall part of the point of it was that you could do optimizations that were not possible in LLIR.
The official Rust releases are not really tuned for performance in my experience, and are definitely not suitable for every use case, especially if you're using Windows GNU. And there are very valid reasons to do that... it's far easier to write cross-platform stuff if you target Windows GNU for the Windows aspect instead of MSVC. There's many crates you either cannot build at all or cannot easily build with Windows MSVC, while being able to do so with Windows GNU.
&gt;stage0: your existing Rust compiler. Let's ignore how you got hold of it; it was probably from your distribution, or a binary downloaded from the website. How do you compile this initial rust compiler? Do you have to build ocaml and then build rust with that and hope that the current rust compiler can be built with the ocaml one?
Once again thank you very much! I've just managed to create my first rust application that calls c# code this way. I'm so excited because it opens a lot of new opportunities in my company, which have a lot of good and working c# code and is slowly switching to rust. 
Wouldn’t this have the downside of adding a lifetime to String though? (Unless you only supported 'static lifetimes)
Our current Rust compiler absolutely would not work with the OCaml compiler... Rust has changed a lot since then. But yes, the chain of rustc eventually ends up in OCaml. There is a compiler written in C++ that can compile *correct* Rust (it can't borrow check), so you could bootstrap with that.
&gt;There is a compiler written in C++ that can compile correct Rust (it can't borrow check), so you could bootstrap with that. Doesn't seem to support anything but amd64. How many people have actually done this building from the ocaml source? It sounds like everyone is using a compiler that was bootstrapped from a compiler provided by someone else. This raises pretty big security concerns for I think.
That's called a "trusting trust attack" or a "Ken Thompson attack." mrustc has ruled that out to a large degree. Read [this thread](http://www.reddit.com/r/rust/comments/8covpo/-/dxh4ej6) in this post's comments.
[kafka-rust](https://github.com/spicavigo/kafka-rust) has been stagnating for a while, because its contributors don't have as much free time as they used to. It could use some love, if you're interested in diving into the Kafka protocol.
mrustc doesn't really fix the trusting trust issue unless people actually perform the checking. Are you aware of anyone having done that?
I'm trying to use r2d2-diesel with Warp. My last filter gets fed a `r2d2::Pool&lt;r2d2_diesel::ConnectionManager&lt;PgConnection&gt;&gt;` and inside it I do `&amp;pool.get().unwrap()`, but this doesn't work, because of this error: ``` the trait `diesel::Connection` is not implemented for `r2d2::PooledConnection&lt;r2d2_diesel::ConnectionManager&lt;diesel::PgConnection&gt;&gt;` ``` What am I supposed to do here?
Perfect. And like I said, that would still be really nice.
I think you have the wrong subreddit
I would recommond the crate [combine](https://github.com/Marwes/combine) for what you want and how you would implement it
It would still need to track whether or not the string was owned. It's the same cost either way.
&gt;/u/StallmanTheCold, if you want the level of conspiracy-proof verification you're talking about, really you should do the cross-bootstrap yourself and not trust others to claim it has been done. I'm mostly concerned that distros aren't even compiling it themselves and possibly distributing compromised compilers to a lot of people. Personally I've just opted to not using rust at all since there doesn't seem to be many (if any) people who care about these things in the rust ecosystem.
I'm afraid not even that compiles :/ trait Gen&lt;T&gt; { fn gen(&amp;self) -&gt; Box&lt;dyn T&gt;; }
I am familiar with associated types but I'm afraid this does not compile either.
thanks for the hint. I'd rather not use a crate for now, but it can't hurt to get some inspiration :P
I imagined having users being able to download and compile the external packages from source code. So I guess they have a pretty high trust level. I like the idea of dynamic libraries. They don't really have to be super-user friendly. End-user shouldn't have to touch them. Only author of library. I will look into IPC channels more. Definitely ok with Rust-only support. These are some great suggestions. I was really just looking for a place to keep researching (was getting a little stuck), so this is perfect. 
Sorry for being dense but I don't understand your question. The problem statement in the original post outlines the purpose of reducing code duplication. (A nit that may serve for clarification: it's about consolidating common code into a supertrait rather than combining traits into one.)
Which crate are you running into? I use MSVC every day and have never experienced this.
That's actually being worked on - there's discussions about memory models that'll help make Rust much much safer than before. (Check out [Stacked Borrows](https://www.ralfj.de/blog/2018/08/07/stacked-borrows.html) for an example of initial theoretical work (explaining how Rust currently works, sort of.) 
Consider something like the Relm crate. Getting GTK3 and all its dependencies built with MSVC is possible, but something of a pain as it's just not Windows oriented at all. Someone using the Windows GNU toolchain in combination with MSYS2 though could just install the GTK3 libs through MSYS2 Pacman and be able to build and use Relm normally without any issues.
Ah interesting, thanks! That makes sense.
Depending on the trust levels as well as your desire to experiment with hot new stuff, compiling the plugins to wasm and running that (with a fixed environment for 'FFI') might be fun!
Hmm, I should probably put that in each of my posts to save you the trouble. =) Thank you!
The same concept applies to various tools written in Rust, by the way. Like to build Cargo with the MSVC toolchain, you'd have to go and do git checkouts of a bunch of heavily Unix-focused libraries like libcurl and such, and attempt to get them all built with MSVC beforehand. Whereas they're all readily available for download in prebuilt forms that are directly compatible with the GNU Toolchain.
Huh, I build the compiler myself with MSVC on a fairly regular basis, and it always Just Works for me. Maybe it's just building rustc and not Cargo... but I do sometimes build Cargo as well, and I've never needed to build manually.
Well, considering who you are I'd say it's totally possible the necessary libs made their way onto your computer at some point whether you remember it or not, haha.
Hey, Don't really want to highjack your post, but I was wondering how people found mentors VS the previous community submissions. Is there a real need for this mentor features ? How many people know, and use independent mode instead ? 
It isn't afaict. The title is misleading.
Thanks for the detailed response. I did not realize `bytes` operated as such. I need to start thinking lower level than I am used to. BTW I actually did try it out on a checkout of the linux kernel but removed it from the above posting because it had the same issue there, just with a higher level of error. I should have included it. It had about the same issue though with the Go program being about twice as fast. ``` Benchmark #1: ./go Time (mean ± σ): 1.131 s ± 0.022 s [User: 708.5 ms, System: 534.7 ms] Range (min … max): 1.116 s … 1.190 s Benchmark #1: ./rust Time (mean ± σ): 2.222 s ± 0.016 s [User: 1.639 s, System: 0.578 s] Range (min … max): 2.198 s … 2.255 s ``` I just tried out you last modified version (which I will be studying so thanks for that) and it still produces roughly the same results. Going to assume its due to my toolchain. Although a quick check shows it to be Rust 1.28 `rustc 1.28.0 (9634041f0 2018-07-30)`. 
Could you estimate how much time mentoring consumes every week?
hehe :) I'm a fairly recent Windows user, but maybe...
For python, there is the CSCircles course: https://cscircles.cemc.uwaterloo.ca Is that, what you (or you, /u/VampyrBit ) are looking for? (Except it's for python, of course ...)
Isn't this the builder pattern?
Not many yet as they're somewhat unstable currently.
&lt;3
Here is how I did it: https://github.com/George3d6/Inquisitor/tree/master/agent Basically, there is a Plugin crate that does nothing but return a vector of plugins that impliment a trait. That way all you have to do is add a dependency to the Plugin crate and it gets automatically added into the binary and hooked into the run loop,
It depends. If the function actually needs a String instead of a &amp;str, say because it wants to store it in a HashMap, then the second version is suboptimal - it will always need to do s.as\_ref().to\_owned(), which causes an extra allocation. In other cases where the function just needs a read-only non-owned reference to a string the second version is better.
Just to be sure: you are compiling with optimizations on, right? I didn’t see how you’re compiling this, though I may have missed it.
This produced the result I was looking for, however it is now no longer iterating the bytes of the file, and as such is no longer comparable to the Go program.
My [project](https://github.com/xmr-rs/xmr) needs some love :P, it's a monero implementation in Rust but I stopped development because I don't have the time to work full time on it and because the monero codebase (the original) is pretty undocumented.
I'm currently going through the Rust track on Exercism. For the mainline exercises I've been waiting for mentor approval before moving on. The extra exercises do not seem to get looked at much, probably because there are insufficient mentors and hence this request, so I've been just skipping the approval process on those. I like the mentor part of it because they'll often suggest alternate methods which then you can try to use. Looking at previous community submissions works too, but I've found the quality of community solutions pretty hit and miss. For instance, a lot of them will allocate extra memory or be more succinct at the cost of higher algorithmic complexity.
/u/annodomini has [mentioned](https://www.reddit.com/r/rust/comments/909gsd/were_there_any_memory_safety_issues_found_in/e2oym2q/) that some network-facing code was affected. Sadly I am not aware of the details. However, it is generally unhelpful to hold back promoting a vulnerability to a CVE for a number of reasons: 1. It has been [demonstrated](https://googleprojectzero.blogspot.com/2014/08/the-poisoned-nul-byte-2014-edition.html) time and again that almost any memory error, no matter how small, can be exploited given enough determination. 1. Even minor issues that are not exploitable by themselves can be devastating when used together (exploit chaining). 1. Writing a proof-of-concept exploit is a lot of work, even for trained professionals. Their time is better spent discovering more vulnerabilities than proving that the already discovered ones actually matter. &gt; There has to be some piece of software out there, preferably widely used, that can be compromised for a bug to rise to the level of a security vulnerability. It is impossible to prove absence of such software as long as proprietary software exists. Not to mention that new software can get written and compiled with an older version of the compiler, e.g. shipped by Debian.
Yes. Compiled with `cargo build --release` and then copying out the resulting binary from `target/release/`. I do not have the CPU specific optimizations turned on though, just the default settings.
How confident in rust do you need to be? I’ve been doing rust off and on since just before 1.0 but wouldn’t consider myself an “expert” ... not sure if I’ll ever feel like I am haha.
Cool cool :)
Unfortunately, `MaybeUninit` is only subtly better than `mem::uninitialized`. It still requires extensive `unsafe` code to use. It's a step in the right direction, but it's not a full solution. In my own personal use case, which is partially initializing larger structs (too large to fit on the stack), it provides no benefit over `mem::uninitialized`.
Rust **does** do static uninit checking. It **does not** do field-level uninit checking. I'm not sure if Java does; it's been too long since I've dealt with Java.
The network facing code was in the code that the bug report was filed about. From the example code given, it was doing some kind of raw packet parsing. May have just been someone experimenting with writing such code, or may never have made it into production because the author found the bug before shipping, but it was still clearly network exposed code. In that thread I posted some searches of code to see if I could find any other exposed code. There is a lot of use of `VecDec`, but not as much that used the buggy method. However, I did find a use of the buggy method in Xi.
Honestly I think wasm might be beyond the scope of this project for now. Thank you for the suggestion, though. 
I didn’t even think to google for “plugins”. This sounds really promising. Thanks!
Pretty much my boat. I've been using rust more weeks than not for the past year and a half or so, but I'm not really a programmer. I'll take a look tomorrow and let you know if I feel useful or not.
WebAssembly might be a reasonable thing to embed, if you go down the embedding rule. WASM was designed for sandboxing, and a lot of effort was put into the WASM target for Rust. There is a [WASM interpreter](https://github.com/paritytech/wasmi) written in Rust (which is fairly slow, being an interpreter) and a WASM compiler called [Cranelift](https://github.com/CraneStation/cranelift). (I'm not sure if Cranelift supports WASM directly - it is designed to ingest its own IR into which WASM is translated; if that's not included in Cranelift, you can get that part from [nebulet](https://github.com/nebulet/nebulet)).
You are looking for r/playrust
It does iterate on all the bytes, how else would `buffer.iter().position(..)` determine whether there is a null byte in the file? It only looks different but I really just hid the counter in the `position` function. And when there is no null byte, `position`'s counter's is discarded but it's value would just be the length anyway. The only behavior that I changed is the double printing that would occur for binary files, which I assumed wasn't wanted. But that has little to no performance impact.
Java doesn't do field-level uninit checking. Fields in Java are always implicitly initialized to null (except primitive fields, which are instead initialized to zero or false). For Rust that's an obvious nonstarter.
&gt; Clippy is installed as part of the RLS. You can turn it on with a setting in your editor or with the usual crate attribute. It's the `clippy_preference` configuration setting. See https://github.com/rust-lang-nursery/rls#configuration which also gives you the LSP message used for configuration (`workspace/didChangeConfiguration`). In VSCode, you open up your settings and set `"rust.clippy_preference"` and it automatically tells RLS about the configuration change.
&gt;notable, it doesn't work with Rust itself, but that is large and has a very complex build system Why [plugin](https://marketplace.visualstudio.com/items?itemName=kalitaalexey.vscode-rust) unmaintained since 2017 can provide reasonable 80%-working go-to-definition and code completion for rustc codebase even if it doesn't look at its "very complex build system" at all, but RLS can't do the same thing and just dies immediately?
Not yet! Eventually though!
So I read yesterday that CPS is equivalent to SSA. I'm not enough of a compiler nerd to evaluate that statement, but I'll just pass it along. &gt; [Kelsey's dissertation] also got set down precisely on paper something all the CPS people knew at some intuitive level: that the whole "SSA" revolution in the classical compiler community was essentially a rediscovery of CPS. (Harrumph.) http://www.paulgraham.com/thist.html 
I need a good post on this subreddit when they are! 
Hello, I am trying to write a simple networking program that shares the x-y positions of two objects (possibly for a game? I'm just trying stuff out right now), and I'm running into an issue when trying to both read and write from both client and server (the server prints out "Connected", but doesn't seem to write the data for the client to read or somehow stops the client from reading?). My current theory is that it's because I'm running both on one computer but that seems shaky at best. Here is the source code for both the [client](https://pastebin.com/WzSeuVba) and the [server](https://pastebin.com/LSiNRsFw). Thank you for any help in advance, I really do appreciate it.
Doesn't that just use RLS and Racer too, though?
[https://play.rust-lang.org/?gist=9edf5372dfaf82661295c59e4b7eb338&amp;version=stable&amp;mode=debug&amp;edition=2015](https://play.rust-lang.org/?gist=9edf5372dfaf82661295c59e4b7eb338&amp;version=stable&amp;mode=debug&amp;edition=2015) Can't have `trait T: Gen` and then try to set `type Ret = Box&lt;dyn T&gt;` inside `impl Gen for Foo` because `T` is not fully specified inside `Foo`. You end up having to manually write `type Ret = Box&lt;dyn T&lt;Ret=Box&lt;dyn T&lt;Ret=Box&lt;dyn T...` (infinite type). Default associated types might actually solve this whole problem. 
&gt; but something of a pain as it's just not Windows oriented at all Well theres the problem, that and the general lack of Rust gui libraries to begin with. It's hardly fair to use a very linux focused library as an argument against targeting MSVC, especially when one in an area that the rust ecosystem as a whole is lacking in. Qt is much more popular on windows(And fairly popular on linux, as well), but comes with it's own problems for rust integration. It's my understanding gtk was simply the easiest to write bindings for. I would even go so far as to say it's disingenuous to use as an example. GUI is also hardly a majority, i wouldn't go so far to say they're "many crates that don't work with msvc".
\*jealous\* I really hope I can go next year! Is the location decided yet?
Yeah, this was intentional. To be clear, there was not a "beginner" and "advanced" track (maybe that accidentally ended up happening?), but individual talks were scheduled concurrently with this in mind. This was one of the motivating factors behind multi track in the first place, we can opt for more talks that are less generally targeted. I'm reminded of Sean's talk from last year -- it was on a relatively advanced topic that he had made generally accessible (because he's pretty awesome), but there was a potential for a more focused advanced talk there too, and with a single-track conference it's hard to get _any_ of these.
I liked this solution because its the only way that really lets people distribute plugins on crates.io. Plop the name and version of your plugin in Cargo.toml and cargo takes care of the rest. The build script and plugin_initialization macro make it basically plug-and-play. It does have the issue that all plugins have to use the same version of the crate where the trait is defined, but that is fairly manageable, especially since crates.io would store and serve old plugin versions for us. That said, trust is a big factor. It's all Rust code with the same access to the host as your own code. 
It's less an argument against MSVC than one in favor of the GNU tooling, I would say.
I've _once_ managed to build what appeared to be a binary-equal rustc stage3, but since (1.19.0) rustc's build system incorporates the system time (and other environmental factors) it's been hard to reproduce.
Okay thanks, I'm not entirely crazy. I wonder if the Rust community would value a reproducible build option.
I'm sure all your points are valid. Didn't intend to be condescending, but rather wondering why op needed to compile from source rather than use the provided binaries and release channels and thus save themselves the troubles they brought up in their post. You're all free to do w/e.
`hyper::rt::run` is a trivial wrapper around [`tokio::run`](https://docs.rs/tokio/0.1.7/tokio/runtime/fn.run.html), which, critically, does not immediately terminate when the passed future returns: &gt; Note that the function will not return immediately once future has completed. Instead it waits for the entire runtime to become idle. And Tokio defines idle state as the following: &gt; The runtime enters an idle state once all of the following occur. &gt; * The thread pool has no tasks to execute, i.e., all tasks that were spawned have completed. &gt;* The reactor is not managing any I/O resources. The former may be true once your future returns, but the latter is not as `Client` registers a connection pool with Tokio that isn't freed until all instances are dropped, which in this case will not occur until `run()` returns. My guess is if you add `drop(client)` before calling `hyper::rt::run()`, then it will terminate when the request is complete.
Thank you so much! I did not expect such a thorough answer, much appreciated. 
It is RustSym for sure in that case. RLS simply doesn't do what it does (which is to say, actually parse code.)
It doesn't really help you, but the issue was [reported a few months back](https://github.com/autopilot-rs/autopy/issues/8) to autopy. Unfortunately, the code in that repository seems to be a rewrite relative to the code that's uploaded to crates.io, so it's not really possible to track down when the issue was introduced or fixed. Somehow getting correspondence with the original author is probably the best bet. 
Making a disassembler (and plans for more!) for DirectX shader bytecode. Adding some neat things like [vector component coloring](https://i.imgur.com/Gvmrh7J.png) that isn't in Microsoft's version. So far only ~20 out of 230 opcodes implemented so there's some menial typing to be done, but it's a fun side-project to work on.
Great reading :) I like your discussions on the relevant crates and how you evaluate the different aspects. And I almost made it into orbit!
I love this! I'm playing around writing something game like and this was very helpful. I love all the stuff that is available as published crates. Rust and cargo is awesome.
Oh yeah I can't stand it. But it makes sense within C's (very weird) notation for declarations. It really wants the right hand side to look like an expression, and the right hand side to be a simple type that those expression evaluate to. This helps make sense of awful things like int *(**x[5])[2];
The other day I considered this and realized that with a special toml file parsed by a build.rs, it should be possible to integrate plugins at compile time via cargo into a framework where each plugin declares its other plugin dependencies. Such a thing would need an entry point besides initialization that is initiated by the core executable and could be an entity component system or something else that is simpler. This method requires an initial download and "rebuild"/"install" every time plugins are updated, but since the core application is so small, it should build almost instantly. What do people think about this? Should such a compile-time plugin framework exist?
IMHO declaring multiple variables or fields on a single line is just bad practice regardless of language. It's detrimental to readability (even if in some cases only minimally), and I just can't see any whatsoever advantage of doing it.
So last week I added stateful nodes to [vfin](https://github.com/axelf4/vfin). This week I'm thinking of adding remaining HTML attributes to the web backend, finally bringing it up to par with [yew](https://github.com/DenisKolodin/yew).
Started implementing a JSON schema validator called [juster](https://gitlab.com/silwol/juster) which will be available as a crate with a library and an optional command-line tool one I consider it good enough for general purpose use. It's target is to work on a \`serde\_json::Value\`, it is not a streaming validator which could be hooked into the (de-)serialization. Although that would be a fine project as well, I assume it is much more difficult to achieve. Many checks are already running in the tests, main deficits by now are: * Library API for users of the crate is not yet well thought * \`$ref\` entries in the schema are not yet resolved (need to work out a resolving strategy, because URIs don't always have to be available at the matching URL if there is one, and the user of the tool should be able to pre-load the schemas, e.g. from local files). * Some checks are not yet implemented at all: * Dependencies * String formats (hostname, date, e-mail…) * I would like to implement a self-check of the JSON schema, indicating properties that might cause problems (e.g. checking a format or a regex on a type which can \*never\* be a string, or checking the items on a type which will \*not\* be an array).
A quick idea on how to append the API key: #[derive(Serialize, Deserialize)] struct WithApiKey&lt;T&gt; { #[serde(flatten)] payload: T, api_key: &amp;str, } Haven't had the time to look at the code in detail, so I might have missed the point of the question :P 
I resonated a bit with your comments of `specs`'s docs. The book was a good starting point, but I found a lot of helpful code snippets within API docs too. I would love to help write more comprehensive docs for specs, I had to go looking through source a lot to get answers. It is really a great library too, amazingly easy to use once you figure it out 
Not ideal, but you could compile your .wasm into a literal Uint8Array and instantiate that instead.
misc notes first: - i wouldn't recommend using `Display` as the way to format the information about a roll. `Display` should be a human-readable but *compact* representation of the value&amp;mdash;anywhere your type is interpolated into `{}` in a format string, it uses its `Display` implementation. `Roll Result(+2/Success, +1/Threat, 1/Triumph)` would be a more suitable output than `Roll was a success with 2 successes, 1 threat, and 1 triumph`. i would probably just move the current `Display` impl into the struct impl and call it `pretty` or something. - re: better string handling, i would recommend you make better use of `match` and the fact that `if` is an expression, but i don't think you'll be able to make it drastically cleaner without using a template language or something - when you have `Vec` as a struct member, you generally don't need it to be `Option&lt;Vec&gt;`&amp;mdash;just use `Vec::empty()`. - casting is correct for creating an array, but i'm not sure about `u8` subtraction - i would say in this particular case you're correct to use `extend` so that the builder could be reused - there's no reason to mutate your dice, since you're not keeping any of the state around about which die rolled what. this ties into the next (main) point: builder patterns aren't idiomatic in rust (in most situations), and a `Roll` trait *would* help a lot. i'll write up how i'd do this to give you an idea: type Face = Vec&lt;Symbol&gt;; trait Roll { static FACES: [Face]; fn roll() -&gt; &amp;Face { thread_rng().choose(&amp;Self::FACES).expect("Die had no faces defined"); } } then just define the dice as empty structs with a trait impl, e.g.: struct SetbackDie; impl Roll for SetbackDie { static FACES = [ vec! [], vec! [], vec! [ Symbol::Threat ], vec! [ Symbol::Threat ], vec! [ Symbol::Failure ], vec! [ Symbol::Failure ], ]; } then when you want to roll a pool of dice, your computation can basically look like this (using `itertools` for `group_by`): let result: Vec&lt;(Symbol, usize)&gt; = dice .flat_map(|die| die.roll()) .group_by(|&amp;x| x) .map(|(key, elems)| (key, elems.len())) .collect(); this is off the top of my head, so there may be some rough edges (borrow checker, `group_by` + `map` is a bit redundant/wasting computation, etc.), but that should be basically the computation you want, and it avoids builders, a specialized result type, and storing or mutating state on your dice.
I have a problem that I often get into whenusing enums. I will start with defining an enum and then realise that each of the variants is logically an enum too. Sometimes I might go 3 levels deep this way. However, when I get around to using this in code I just end up writing very long lines specifying which of the enums of enums I want. I get around it usually by providing helper functions. Is my design wonky and i should avoid nesting enums or is there a good design pattern for handling this?
I'm writing a small library for writing trees (such as the ones printed by [cargo-tree](https://github.com/sfackler/cargo-tree) or [tree](http://mama.indstate.edu/users/ice/tree/)) to a terminal, with style. A short demonstration of printing out a `Config.toml` as a tree is [here](https://asciinema.org/a/197149?t=10). 
I'd love to see and example of this if you have a GitHub or snippet somewhere I could see?
Thanks!
Nice!
I would do this if it didn't involve signing up for yet another Slack account. Please consider an open alternative like Matrix.
&gt; String concatenation &gt; Does anyone have good examples of better techniques for more complex string concatenation? I'm just pretty straightforwardly generating a Vec of Strings and joining it, but it doesn't seem very ... clean, or scalable/maintainable. Seems fine to me, however an option (slightly less clean-looking but with less allocations) would be to just write directly to the `f` instead of buffering `String`: after the first conditional, every message necessarily starts with `, ` so you could just embed that bit in the literal. IIRC you can also `write!` to a `String`. &gt; Building a vec &gt; I ended up building a Vec&lt;Die&gt; with .extend() instead of .push()ing, should I have used .append() so the Pool takes ownership of the Die? An option I'd explore is to not allocate vectors for your properties, and `clone()` a `repeat(Die).take(n)` instead.
Rewriting my large scale free market simulation engine in my RPG game (www.github.com/holmgr/gemini). Currently the collective "AI" slowly realizes that demand is best met by killing all consumers... :P The new system will not only handle transportation costs but also worker migrations. Just hoping it scales good enough :)
No spaghetti is not accessible by me at least :-(
Haha no worries, it happens to the best of us, it’s an easy mistake to make.
For me it belongs right in formatted comments 
Unfortunately *No spaghetti* is not accessible by me at least :-(
This is great. I think I could add support for tuples, tuple-structs and enums.
I think this explains it: &gt; Always keep in mind that values in a scope are dropped in the opposite order they are created. https://doc.rust-lang.org/stable/error-index.html#E0597
declare somewhere: const fs = require('fs'); function readFile(path, type) { return new Promise((resolve, reject) =&gt; fs.readFile(path, type, (err, data) =&gt; err ? reject(err) : resolve(data)) ); } then: let buf = await readFile('path/to/mod.wasm'); let mod = await WebAssembly.instantiate(buf, {env});
I agree with you that we should have `NonZeroI32` etc too! As for the answer to your question, if the API always return negative error codes (and never positive ones), just negate the number to get something that is positive and non zero :-) 
Why not make the separator an `Option` type so that you could pass in either `Some(separator)` or `None`?
I would say that `Empty` reads fairly well among your suggestions. Similar alternative could be `Nothing`. From automata/language theory nomenclature, `Epsilon` suits the bill also.
Got the link from [github](https://github.com/quodlibetor/lasagna-demo)
All kinds of reasons: - Backwards incompatible, since `Option` doesn't implement `Display`, and there's no need to incur the check of `Some` vs `None` at runtime. - I already accept any type as a separator, so it makes sense to just have a zero-size type that `Display`s to nothing
Yeah. Normally I don't like such generic names but with namespacing it's okay (as in `joinery::Empty`)
Personally I like NoSeparator; it reads well in your example: parts.iter().join_with(NoSeparator) It's instantly clear what's going on :) 
Not much, reading the [rust-lightning](https://github.com/rust-bitcoin/rust-lightning) and see in what can I help there.
Why *don't* all the things get dropped simultaneously, anyway? Do they with NLL?
Playing video games.
They do not. https://github.com/rust-lang/rfcs/blob/master/text/1857-stabilize-drop-order.md
Is compiled wasm close to native? Is interpreting it really that slow? I thought browsers do that and it is supposed to be pretty fast there. Or are does JIT compiling not count as interpreting?
Despite drop order at end of scope supposedly being the issue here, manually dropping `foo` at the end of the scope doesn't satisfy the compiler; that is, the code below still will not compile. `{` `let foo;` `let bar = 5;` `foo = &amp;bar;` `drop(foo);` `}`
Originally browsers were doing JIT compilation through the JS engine, but now they AOT compile WebAssembly. This results in roughly 2x slowdown compared to native.
Not simultaneously, because things depend on each other and their destructors need to have certain guarantees. But with NLL they'll get dropped as soon as possible. And yes, this works with NLL: https://play.rust-lang.org/?gist=27c6ffd7c148c3fea35b3420e4fd111d&amp;version=nightly&amp;mode=debug&amp;edition=2015 (So, OP, in the future this will no longer be an issue)
[removed]
[removed]
Rust beginner here. Writing a small multiplayer Tic Tac Toe CLI game
You got it backwards. \`bar\` is dropped first, because it was created \_last\_ (reverse order!). And \`bar\` can't be dropped, because \`foo\` still depends on it.
The `drop` function just takes its argument by value. For non-Copy types, this effectively means that they get dropped here (inside drop(), actually), but &amp;i32 is Copy, and thus within drop(), only that copy is dropped, the original `foo` lives on.
Glue (from TeX)? Void?
It was my the very first contribution to the Rust ecosystem last week - added normalized versions of Levenshtein and Levenshtein-Damerau metrics. It was a trivial addition, but anyway :-)
That might not be a bad solution. It might add more complexity than using the type system, though. Take the example I gave, where you want to partially initialize one field, and only drop that field on panic. You could potentially re-implement all of that logic, but the type system already provides it all, if you can just re-use it. Also, it's not clear to me how that approach would extend to enums. Or to *very* large structs that have fields that can't fit on the stack and thus require recursive partial initialization of their fields.
While we’re at it i would love a version of it containing all but all bits set. 
&gt; Take the example I gave, where you want to partially initialize one field, and only drop that field on panic. You can't drop what you haven't initialized. If a field isn't fully initialized, you can't drop it. But if you have partially initialized some sub-fields, those can be dropped. All of this already work out of struct fields, and I don't see how the logic for struct fields is any different. &gt; Also, it's not clear to me how that approach would extend to enums. You would have to initialize the discriminant first, the rest works like for structs. &gt; Or to very large structs that have fields that can't fit on the stack and thus require recursive partial initialization of their fields. You can initialize data directly on the heap already using `box`. Whether the struct is on the heap or the stack doesn't really make a difference from the point-of-view of an uninit checking.
If the database is concurrent (most databases, excluding sqlite in journaling mode), you're probably better off having a separate process (i.e. application) polling it for messages to process. That way you can stick it on a different server if need be.
I'm working on getting [TimeTrack](https://github.com/JoshMcguigan/timetrack) ready for initial release. Time track automatically tracks how much time you are spending on each of your projects by watching the file system, and I've already got one user who really wants this (*I'm the user*).
That has a meaning that wouldn't be applicable in this case.
To my understanding NLL only improves the borrowchecker and will not influence the behavior of your programs. I.e. The destruction sequence will remain as is
&gt; so it can't be used to break up initialization of very large structs, You can't create references to uninitialized memory, so you can't use `&amp;self`/`&amp;mut self` methods on partially initialized structs (because to do so you would need to create a `&amp;mut Self`, and that's UB). Also, since that `new` method returns uninitialized memory, it should probably need to be `unsafe`.
See: Hematite
Exactly.
Well I guess you could flip the sign and cast to unsigned, if that's not too hacky for you...
As an aside, this particular way of formatting currently breaks on [old.reddit](https://old.reddit.com/r/rust/comments/98silh/bikeshedding_name_for_a_zerosize_no_separator_type/) :(
... and it doesn't sound like one now that it's been announced, unfortunately. 
I am aware of the (terrible) consequences, but that that contradicts what /u/killercup said, depending on your definition of "as soon as possible" :-)
Writing a gui to search the states of a LCRNG to aid in rng manipulation in pokemon emerald. Next todo is run the generator in a background thread, and then calculate frame offsets for each pokemon and see if their consistent across languages. Screenshot: https://i.imgur.com/jFoN4ce.png
A couple weeks ago I saw that the RSoC project was using [my fat32 library](https://gitlab.com/susurrus/fat-rs) to get [FAT32 loading of the Redox kernel working](https://www.redox-os.org/news/rsoc-fat32-3/). I had stopped working on my crate about a year ago, but now I'm inspired to get back to it. The Redox folks have reported all the problems they ran into and I hope to get them upstreamed this week. It's unclear to me the value in me releasing this crate given that [fat-fs is already more featureful and on crates.io](https://crates.io/crates/fatfs). One benefit my crate will have though is that I plan to support a no-allocation version for microcontrollers, who is actually my target market. So maybe I'll keep moving forward with this project. And since there's always people looking for Rust projects to have on, I have [some issues tagged as easy listed for fat-rs](https://gitlab.com/susurrus/fat-rs/issues?label_name%5B%5D=d-easy) that would be good projects for people looking for something to hack on.
Yeah absolutely. I've added that as an issue to the repo so it's not forgotten :)
Should new_unchecked be this instead? It doesn't compile for me otherwise. NonZeroI32(NonZeroU32::new_unchecked(n as u32))
I haven't but I'm going to look into it more and test what kind of serialization memory overhead it has 
You are basically asking a project with literally hundreds of members to open a special channel for you. I hate Slack much as the other person, but it’s perfectly feasible to sign up an just have emails for notifications and only hop on when needed.
Is this a case where it would be more idiomatic to use io::Error?
Interesting! I'll check that out
Working on setting up CI for [artifact](https://github.com/vitiral/artifact). It’s the first time I’ve set up a CI service, so I’m kind of fumbling around at the moment. It’s fun though :)
In python: "".join So, just join: parts.iter().join().to_string() this is similars to sets and relational joins.
I'm working on a framework agnostic view layer ***\*generator\*,*** where the generated view layer is modeled after react (well, after [didact](https://engineering.hexacta.com/didact-learning-how-react-works-by-building-it-from-scratch-51007984e5c5)). To generate the view layer, one defines the gui primitives in an inline module and annotates it with the proc\_macro I've written. Then one can implement a backend that renders diffs emitted by the view layer. And consumers of the view layer (well, users) can implement custom components. Thus far, I have user defined custom components with custom state working. I have a jade (jade-like template syntax instead of html, because it's a lot easier to write completely safe macros in that because of enforce matching (),\[\],{}) template for building component definitions prototyped, but not complete. After I polish that macro, I'll be adding in component keys &amp; handles, state update methods and event definitions and passing. I'll try to release something once I clean up the dumpster fire of repo (lots of exploratory code). 
How about `join(Directly)` and `.join_directly()`?
Sorry that was a very simplistic summary. Real NLL is [more complicated](http://smallcultfollowing.com/babysteps/blog/2017/07/11/non-lexical-lifetimes-draft-rfc-and-prototype-available/).
Wxcited to go through this, thanks for sharing :)
I've been struggling to progress with my [cyptocurrency simulation](https://github.com/pierre-l/Pierre-s-Distributed-Experiments) lately, because of a probable bug in my network simulator and because I think I found a great solution to a problem I've been working on for years: hosting high-density virtual worlds in a low latency environment like MMORPGs, and my mind is almost entirely focused on this :/ It has been a few months since I've learnt of the [LMAX architecture](https://martinfowler.com/articles/lmax.html#InputAndOutputDisruptors) (which I recommend for every back-end engineer to know) and I am convinced I now have the right ideas to solve this issue. As usual, Rust will be a great tool for this :) I'm also still looking for my dream job, ideally a remote Rust/Java developer position. I would welcome any advice! Have a nice week everyone!
Rather than writing `.join_with(ActuallyNothing)` I'd prefer `.concat()`, like the std library does it. Even if it's just sugar for `Join&lt;I, EmptySep&gt;`.
OP's code block reformatted: &gt; extern crate joinery &gt; &gt; use joinery::{Joinable, NoSep}; &gt; &gt; let parts = vec![1, 2, 3]; &gt; let result = parts.iter().join_with(NoSep).to_string(); &gt; assert_eq(result, "123");
Well, it *is* what you're supposed to do on windows. or any platform for that matter. Use the ABI defined by that platform, on that platform. You don't see people trying to use msvc on linux, do you? Or trying to use gnu on ones that use musl? Use the platform ABI. For standalone programs, *maybe*, ***maybe*** gnu makes sense, if you're a masochist.(and you want to make debugging harder for yourself), but what about libraries for example? Using or making them. Using windows libraries, or making libraries intended to be used by windows programs through a C or even C++ api, especially precompiled ones. What about actually doing anything using the windows api or other system libraries? Does mingw just duplicate everything? I hear the gnu toolchain is less than the most up to date, so what about newer windows systems with new functions? Windows insider? How long until i can use the newest and greatest windows apis? Why spend so much time fighting against the platform's ABI?
Say that crate `A` defines a trait `TraitA`. Now crate `B` says extern crate A; use A::TraitA; If crate `C` now says extern crate B; use B::*; should you be able to use `TraitA` from within crate `C`? Assume that `A` is in the `Cargo.toml` of `B` and `C`.
Good-day friend! I've used and loved [this library](https://docs.rs/newtype_derive/0.1.6/newtype_derive/) which as far as I can tell does exactly what you want without having to write any code.
I'd love to know the answer too here. Having to write a bunch of boilerplate (instead of just `#derive[..]`) for type-safety is annoying. Is there a Rust equivalent of Haskell's Generalized Newtype Deriving?
Crate B would need to say `pub use A::TraitA;` for consumers of `B` to be able to import the trait from `B`.
Would you be able to make a minimal example on the Rust Playground and link it here?
If you're trying to get the nth element in the sequence you can try recursion: use std::io; fn main() { println!("Which element do you want?"); let mut elem = String::new(); io::stdin().read_line(&amp;mut elem) .expect("Could not read"); let elem:u64 = elem .trim() .parse() .expect("Not a number!"); println!("Fibonacci value: {}", fibo(elem)); } fn fibo(n: u64) -&gt; u64 { if n == 0 { 0 } else if n == 1 { 1 } else { fibo(n - 1) + fibo(n -2) } } It reads in the index as a String , then it converts it to u64 (trim the \\n from the end of the string, parse it, and handle the error if the conversion can't be done) and the fibo fn returns the result.
Is this something easily fixable or is there an inherent issue with the concept?
I've started working on a basic Lisp implementation! I'm interested in studying programming languages and have been eyeing this as a fun side project ever since learning Lisp for an AI course this year. Had a good amount of down time during the start of my internship so I read thru the Rust book (which is absolutely amazing) and got hooked. Maybe a little ambitious for a first project but I've found that I learn well by immersion and it's been very educational so far. The hardest part has been trying to move away from my C++ development mindset and practices.
Hi, Electron Forge co-maintainer here! I'm happy to see someone trying out using Forge and Rust+wasm. You may want to try out using Forge v6 (now in beta) which has first-party support for Webpack. See https://v6.electronforge.io for the docs (also in beta).
Nice find! `RefCell` has been intensely discussed during the `Pin` design, and it has subtle interactions with pinning indeed. However, I cannot see an unsoudness in your code. What is happening is that we could soundly add `impl&lt;T&gt; Unpin for RefCell&lt;T&gt;` -- we chose not to do that yet as there seemed no point, but even without that extra `impl`, it is the case that *the contents of a pinned `RefCell` are not pinned*. Every contained can make the choice of whether pinning "propagates" to their content or not. For `RefCell`, as you have observed, there is only one sound choice -- not propagating pinning. But that does not break the soundness of pinning as a whole. If you could use this to move a *pinned `Unpin` type*, there would be a soundness problem. But your `Foo` was never pinned. This matches the fact that you cannot obtain a `PinMut&lt;Foo&gt;`. Basically, the safety guarantee is that *once there exists a `PinMut&lt;Foo&gt;`*, the `Foo` will not move again -- and that guarantee is not broken in your example. This is another aspect of the subtle distinction that `!Unpin` are *not immovable* -- all types remain movable in Rust. `!Unpin` types *cannot be moved out of a `PinMut`*.
Cool! Now go get going with the Pong clone. ;)
What is the proper Rust pattern for: 1) Run magic detection code immediately at start of main. 2) Depending on result of detection, select a certain appropriate set of functions, globally, thread-safe, for the rest of the program execution. For example: 1) Detect whether this machine has 32GB ram free or not. 2) Redirect compute() function calls globally in the code either to compute_conserve_mem() or compute_has_lots_of_mem(). 
How do add stuff into my vector? I tried doing this: guessedLetters\[x\] = line.chars().nth(0); But i had no luck. 
Why is it `!Pin`, but `?Sized`?
This week I'm going to be doing a bit of a deep dive into x86-64 assembly to improve coverage in [tarpaulin](https://www.reddit.com/user/xd009642/) and maybe start prototyping some ideas for branch coverage (or just reviewing the notes and resources I've already gathered). If I have time over the bank holiday weekend I'll also try and sort out a nice timer interface for my [embedded-hal](https://github.com/xd009642/stm32f469xx-hal) crate. But timers are complicated enough and this chip has a ton of them so I might have to mull it over some more.
This is awesome and hilarious.
I haven't, but now that I see there is an issue there for a TreeView, I'll see what I can do. 
Thank you for explaining! &gt; it is the case that &gt; *the contents of a pinned &gt; `RefCell` &gt; are not pinned* This will definitely need a good documentation. It seemed quite confusing to me now and I can see authors of unsafe code being bitten by this. I simply assumed that just as `!Unpin` propagates, so does the moving guarantee. Although, I can see now where I've been wrong once I read that `!Unpin` != `!Move`.
I actually specifically chose *not* to use `join` as my entry point, because I figured there's a decent chance that Rust will gain this functionality into the standard library at some point, almost certainly with that function, and I didn't want to overlap / conflict.
One warning I see on the SO post is `WARNING: the sysroot can't be built for the Stable channel. Switch to nightly.` You need to be on a nightly compiler for `xargo` to work.
Also, fun fact: I specifically added an [extra trait](https://docs.rs/joinery/1.0.0/joinery/trait.Separator.html) which provides the Python-style separator-first join, in case people prefer it.
Thanks, yeah after looking at the warning and actually regarding it seriously, I realized that I needed to switch to nightly! This was as simple as \`rustup default nightly\`.
The error message isn't great but the formatting here *really* isn't helping. Could you indent the whole error message with four spaces? It keeps Reddit from screwing it up.
C is a pretty decent first programming language. I might recommend MIPS assembly or something as an alternative for learning low-level programming, but C isn't a bad choice either. C++ is actually bad. It's way too complicated, too high-level, and too quirky to recommend it.
My guess is that !Unpin, !Send, and !Sync are all Not Unpin, Not Send, and Not Sync, while ?Sized means May or may not be Sized. So !Send types will not include Send types, but ?Sized types will include both Sized and Unsized types.
Not built into std, there are crates with proc_macro derives written for you though.
https://doc.rust-lang.org/std/vec/struct.Vec.html#method.push Or https://doc.rust-lang.org/std/vec/struct.Vec.html#method.insert
I'll echo this as well. I'm completely new to rust and systems programming in general so was a bit apprehensive of attending the conference. I was happily surprised by both my experience with RustBridge and the community in general being so welcoming. Very much inspired to dig into rust and contribute to the community! 
I've got a case where I apply several operations to a mutable reference, and I want to return if they succeed or fail. I'm using Result&lt;(),()&gt;, and the ? operator. I'm finding my code is nice, but it feels weird to use Result&lt;(),()&gt;. Is there something else I should be using? Do other people use the same thing (it's hard to google for!)
I think that must be it. My init process was doing \`open\_in\_dir\` multiple times. However, I tried to recreate my issue in a more minimal way ([https://github.com/kardeiz/tantivy-example](https://github.com/kardeiz/tantivy-example)), but wasn't able to get it to fail.
Hi, I'm trying to run through the class, but have gotten stuck on `executor.rs`. Here's what I have so far https://gist.github.com/tbelaire/cbe73a2f21757e73438dc9e169d0e921 I'm pretty sure it's stuck because I'm holding the lock on line 34, and then I try and acquire it again on 106. I'm not sure how to get around that though :/
Woah woah woah. What is: ``` trait Roll { static FACES: [Face]; fn roll() -&gt; &amp;Face { thread_rng() .choose(&amp;Self::FACES) .expect("Die had no faces defined"); } } ``` In particular the `static FACES: [Face]`? I tried googling but could only find 'static lifetimes. From the expect text it seems to refer to something the impl provides. I might be missing something obvious but this isn't like anything I came across while learning rust from the book.
To rephrase Ralf's comments, here is a litmus test for finding unsoundness in the pin API: * Can I move this value AND * Have I previously had a `PinMut` to this value AND * Does the type of this value implement neither `Unpin` or `Drop` All three of those things have to hold for it to be unsound.
I found this really interesting as someone (slowly but surely) learning rust. Thank you for taking the time to ask good questions with explanations of your reasons behinds your decisions. And congrats on building an app in Rust! Let us know if you build on any of the suggestions here or want suggestions for your next app.
Because `!Unpin` means "may not be `Unpin`", whereas `?Sized` means "needs not be `Sized`". The latter also encompasses `Sized` Objects, because most things you can do with unsized objects, you can also do with sized ones.
Just the first part in a series of merges, but really exciting! varkor seems to be working hard on pushing things further forwards. Thanks for all your work varkor!
Anyone able to explain the benefits of const generics? I've heard the term, but never really understood...
or write it out `concatenate`
You can be generic over `[T; n]` arrays for example (currently partially solved by implementing traits for n until x with a macro).
What do you mean by crash? You can test macros the same way as functions. It does require some [fiddling](https://doc.rust-lang.org/rustdoc/documentation-tests.html#documenting-macros) to get the imports right, but this should go away in the 2018 edition. 
So, to confirm my understanding, you previously weren't able to have a generic type as the type for an array? And this is a stepping stone towards fixing that.
Cryptography is a great example of where it’s useful. Often you’ll have something that’s fundamentally the same algorithm (or algorithm family), but parameterized for different sizes. Some examples: AES-128/AES-192/AES-256, SHA-224/SHA-256/SHA-384/SHA-512, NIST P-256/P-384/P-521. Const generics allow you to express these algorithms generically by making the numeric part a generic. You can even abstract across hash functions at a given output size. The Digest crate already does this (albeit using a hack: generic_array/typenum)
No, you can be generic over types, just not over constants like the n in my example. It's about the size of the array.
&gt; Hi, &gt; &gt; I'm trying to perform a topological sort using Petgraph. &gt; &gt; let dependencies = generate_schema_dependency_graph(&amp;f.schemas); &gt; let sorted = toposort(dependencies, None).unwrap(); &gt; &gt; I didn't expect it to give me the following nightmarish errors when using the toposort function: &gt; &gt; error[E0277]: the trait bound `petgraph::graph_impl::Graph&lt;std::string::String, ()&gt;: petgraph::visit::IntoNeighborsDirected` is not satisfied &gt; --&gt; src\entity_factory.rs:302:22 &gt; | &gt; 302 | let sorted = toposort(dependencies, None).unwrap(); &gt; | ^^^^^^^^ the trait `petgraph::visit::IntoNeighborsDirected` is not implemented for `petgraph::graph_impl::Graph&lt;std::string::String, ()&gt;` &gt; | &gt; = help: the following implementations were found: &gt; &lt;&amp;'a petgraph::graph_impl::Graph&lt;N, E, Ty, Ix&gt; as petgraph::visit::IntoNeighborsDirected&gt; &gt; = note: required by `petgraph::algo::toposort` &gt; &gt; error[E0277]: the trait bound `petgraph::graph_impl::Graph&lt;std::string::String, ()&gt;: petgraph::visit::IntoNodeIdentifiers` is not satisfied &gt; --&gt; src\entity_factory.rs:302:22 &gt; | &gt; 302 | let sorted = toposort(dependencies, None).unwrap(); &gt; | ^^^^^^^^ the trait `petgraph::visit::IntoNodeIdentifiers` is not implemented for `petgraph::graph_impl::Graph&lt;std::string::String, ()&gt;` &gt; | &gt; = help: the following implementations were found: &gt; &lt;&amp;'a petgraph::graph_impl::Graph&lt;N, E, Ty, Ix&gt; as petgraph::visit::IntoNodeIdentifiers&gt; &gt; = note: required by `petgraph::algo::toposort` &gt; &gt; error: aborting due to 2 previous errors &gt; &gt; I'm really confused, doesn't the &amp;'a in the generic parameter mean that its implemented for all lifetimes 'a, and the code itself looks fine.
Taking a guess here: instead of spawning a new task in `wake`, try just sending the `Arc&lt;Task&gt;` you already have to the executor: `self.spawner.task_sender.clone().send(self)`.
&gt; Allow types to be generic over constant values; among other things this will allow users to write impls which are abstract over all array types. https://github.com/rust-lang/rfcs/blob/master/text/2000-const-generics.md I haven't taken the time to grok it, but if you want to take a crack at it, there you go.
Yeah let me try that. Thanks
`static` is like `const` except a `static` takes up memory at runtime, where `const`s are inlined. I actually shouldn't have used a `static` here—I was thinking it would be initialized at runtime (you can't create `Vec`s at compile-time), but I keep forgetting you actually need `lazy_static` for this situation (which will do runtime init for you). And you're right that it's implementation-defined—it's not assigned a value in the trait, so the implementor has to define it. The `expect` is just because `Rng::choose` returns an `Option` which is `None` iff the vector it was passed is emtpy.
No that's not quite right. You weren't able to be generic over the *size* of an array. So if I wanted to write something like f&lt;N&gt;(int_array: [i32; N]), there's currently no way to do that. Crates like arrayvec work around this with custom traits, but the results are slightly awkward. (Nonetheless I find arrayvec super useful, and I'm excited for const generics to land.)
I'm worried that a macro_rules macro I've written will fail to expand during a test (I'd in fact love to test that scenario too!). But if it fails to expand, then that compilation unit won't compile. So there's not a good way to test expansion failures, or to keep expansion failures from interfering with the rest of the compilation unit. My best solution would be to stick expected compilation failures in separate integration test files.
If one doctest fails to compile, it doesn't prevent other doctests in the same file from running. And if a macro in a test fails to expand, the test will fail, so you'll have to fix it... I'm not sure what you are worried about, really. 
&gt; Anyone able to explain the benefits of const generics? "Benefits" is a weird word to use here. Its a language feature. Without it, there are some things that you just can't do, e.g., like being able to be generic over the length of an array. You might want to do that if you want to, for example, implement a trait `Foo` for arrays of some type (like `i32`) but for all lengths: `impl&lt;N: const usize&gt; Foo for [i32; N] { ... }`. Since the `N` in `[i32; N]` is not a type, but a `const`, without "const generics" there is no way to be generic over it.
wait, does this mean we can finally be generic over n? i.e. struct Vector&lt;T, u32&gt; {..}
Great! Could someone explain, what exactly this merge contains?
Please leave out your memes in the slides
Looks like `IntoNeighborsDirected` is implemented for `&amp;Graph`, so you need `&amp;dependencies`.
Going away to read. I do hope the syntax is good, not hobbled by the way it has evolved from type-only arguments. I hope it has leather from the good and bad of other languages. E.g we don't want to have to say "typename" everywhere like c++. We do want type and const-value parameters to act the same Naming the type of type is a good start start. Off to read, I'm currently commenting from a position of absolute ignorance 
I have been working on a project with the same goal in mind. Initially I wanted to make everything safe using zero-cost abstractions but I learned that the OpenGL API is weird enough that doing so is literally impossible. Since there is already a decent library out there (https://github.com/glium/glium) that caches the OpenGL state and puts resources behind asynchronous reference counted pointers. So instead of creating a duplicate library, I focused on providing better type safety by introducing more enumerations and functions taking those enums. You can view it here https://github.com/mickvangelderen/blocks-rust/tree/master/glw. I try to keep the opengl naming intact so it is easier to read and compare with examples and tutorials in other programming languages. In some places although I changed the casing to be more Rust friendly. I wonder if your library lets me call those functions without acquiring an OpenGL context, it looks like they do. Don't think that the unsafe abstraction is sound in that case.
Generally speaking ^(pun not intended), const generics allows you to parametrise types by values. Other have already talked about the arguably most useful use case - abstraction over array size - but I'm going to illustrate a somewhat different example. I'm using a completely made-up syntax here, and some features that are probably not going to be implemented in the near future. You could^1 have a type like `struct Between&lt;const L: i32, const U: i32&gt;(i32)` where type parameters `L` and `U` are _constant values_ which respectively mark the lower and upper boundaries of the value. For example, you could represent a number between 0 and 100 as `Between&lt;0, 100&gt;`. As long as the "constructor" function for `Between` is implemented correctly, you can be sure the value is in the expected range. This could for instance allow you to omit bounds checks, and encode business rules into your type system (a rating is always between 1 and 5 stars, a pile of cards in Solitaire is always up to 13 cards tall). So, what's so interesting about it? Nothing by itself. You could implement a similar type today, just without the type parameters. You would have to implement a separate type for each number range, but you could always generate those with a macro. But you can't do this today: impl&lt;const L1: i32, const U1: i32, const L2: i32, const U2: i32&gt; Add&lt;L2, U2&gt; for Between&lt;L1, U1&gt; { type Output = Between&lt;L1 + L2, U1 + U2&gt;; fn add(self, other: Self) -&gt; Self::Output { ... } } // Later.... let x: Between&lt;5, 10&gt;= Between::new(7); let y: Between&lt;-2, 3&gt; = Between::new(-1); let z: Between&lt;3, 13&gt; = x + y; The type system now knows about specific mathematical properties the numbers have, and the compiler can infer their range from the sum. You could theoretically detect that a certain sum can never overflow, so you can omit the overflow check. The boundaries have to be constant, but the values don't. You can expand this in so many ways - you could implement an implicit cast from a lower range to an upper range, so you could convert a `Between&lt;1, 3&gt;` to `Between&lt;0, 100&gt;` with zero runtime cost.
&gt; you previously weren't able to have a generic type as the type for an array? You were, you couldn't be generic over the array's *size* so you could be generic over `[T;2]` or `[T;5]` but not `[T;k]`.
They're a more generic "non type template parameter" from C++. One thing that I've used this for coaxing the compiler into vectorizing for loops in templates, without needing specialization. Like this: template &lt;class C&gt; class Foo { public: void outer_loop (C* buffer, int M) { inner_loop &lt; 8 / sizeof(C)&gt; (buffer M); } private: template &lt;int N&gt; inner_loop (C* buffer, int M) { int m = 0; for (; m &lt; M; m += N) for (n = 0; n &lt; N; n++) do_something (buffer[m + n]); } }; Doing the same thing is currently impossible in Rust, you need to optimize things by hand. 
Has anyone ever proposed moving a big chunk of `std::io` into core? I often find that a mostly-`no_std` crate will take an optional dependency on `std` just to implement `io::Write` for some of its types. The main obstacle to exposing `io::Write` in core might be that `io::Error` depends on `Box`, but I wonder if we could paper over that somehow, since it has some constructors that don't allocate. Or maybe `core::io::Write` could be distinct from `std::io::Write`, but there could be a blanket impl between them?
For an actual case, I would use sized vectors (see the [`ndarray`](https://docs.rs/ndarray) or [`nalgebra`](http://www.nalgebra.org) crates perhaps). Otherwise, yes, you'll need to implement this stuff yourself. Think about it: what if I wanted to write a `Vec` newtype representing [cyclotomic numbers], where the addition operator meant addition in that ring?
Why is something other than Slack "a special channel?"
You could cast them to "ptr as *const u8 as usize". I don't know if *const u8 hast PartialEq so I assed usize.
The first thing that comes to my mind is trying `fn_ptr1 as usize == fn_ptr2 as usize`, though i'm not sure if there's a more elegant way or not.
Yes, this is exactly what it means :)
As a hack, you could cast your function pointers to a type like `*const fn(foo) -&gt; bar`, and then compare those pointers for equality. But I don't know whether any specific behavior is guaranteed if you do that.
Thank you for your beautiful suggestion! I would not have come up with it myself because I havn't read the last chapter of the Rust book yet, I don't know yet about Send+Sync etc. - guess I have to do that now and unpack your code - :-)
I believe it's the most correct way. It's also the solution recommended to me early last week: [https://www.reddit.com/r/rust/comments/96w29j/hey\_rustaceans\_got\_an\_easy\_question\_ask\_here/e4arzyn/](https://www.reddit.com/r/rust/comments/96w29j/hey_rustaceans_got_an_easy_question_ask_here/e4arzyn/)
This worked! Thank you.
Faced the same problem, that's because I was following setup instructions from TheBook. To prove it won't work type \`$ which rustup\` and it won't answer. So to avoid that in IDEA you should uninstall Rust first: 1. run \`/usr/local/lib/rustlib/uninstall.sh\` as root to uninstall Rust 2. follow installation instructions on [https://www.rust-lang.org/en-US/install.html](https://www.rust-lang.org/en-US/install.html) or just \`$ curl r/https://sh.rustup.rs \-sSf | sh\` 3. now \`$ which rustup\` should work, copy that path to IDEA. 4. now it will loose the toolchain, which is here: \`/home/username/.cargo/bin\` 5. and the standard library, IDEA will tell it can download it Now it works.
Does anybody know how to make `line-by-line v3` example? (engine from `loop v3`, look and feel and behaviour from `line-by-line v1`)
I personally haven't seen `Result&lt;(), ()&gt;` before but I think it's not bad but descriptive: Whenever I see a function returning a Result, I'll know it performs an operation than can either succeed or fail. On the other hand, `Result&lt;(), ()&gt;` is isomorphic to both `Option&lt;()&gt;` and `bool`. IMO, the latter shouldn't be used to signal errors. I like to use `Option&lt;_&gt;` if the failure carries no extra (useful) information. It also implements the try operator `?`, so you don't lose that.
What happens with your example if L1 and L2 are both -1073741824? or any other values that would overflow on addition?
Is this feature gated?
Cool! Again thanks for spending time digging in the issue. The behavior is very confusing. Everything will be simpler once we add a proper IndexReader.
Schweet.
[Thinking in Rust – Nicholas Cameron](https://github.com/nrc/talks)
I'm using [rust-sfml](https://github.com/jeremyletang/rust-sfml) bindings for my Pong. I tried Piston, but the docs felt a little lacking IMO. Will probably check it out again later.
Cool :) I saw another comment which kinda' has what I'm looking for.
I'm using [rust-sfml](https://github.com/jeremyletang/rust-sfml) bindings for my Pong. I tried Piston, but the docs felt a little lacking IMO. Will probably check it out again later.
I'm glad I'm not crazy. The regular sfml c++ docs are incredible and I can get a lot done. Piston just has generic rust docs, which are good if you need to know about a function for example, but in order to find out what you actually need to use? Impossible. I was just wondering if there was a pure rust library to use as it would likely be more idiomatic, rather than some bindings for sfml or sdl2
Thanks for reply, using push gives me this error: [https://gyazo.com/5306c9bcc50236b35fbc5b094c8f3d6c](https://gyazo.com/5306c9bcc50236b35fbc5b094c8f3d6c) Do i need to import a libary to use the function?
Today I made a little crate with some macros that patch up some Rust paper-cuts that I ran into recently. https://github.com/peterjoel/bandaid It was mostly for fun, but I might expand it to include more macros in the future. It's not really production code, but I'll put it on crates.io if anyone wants to try it.
Won't that end up generating a ton of code, increasing compile times and binary size? Or are there some clever tricks being employed to mitigate that?
Yes you are.
Hi I'm having difficulty with the executor.rs part of the slides. I've gotten it to poll once but I can't get it to poll multiple times. I'm calling wake in "Pending" part of my executor to put it back in the stream but that doesn't seem to work https://gist.github.com/robert-snakard/34b32e8df85a1c8607c53a1de44c91b8
So how does one write documentation for code in the `examples/` directory in the crate. `cargo doc` doesn't seem to make it and I'm looking to make larger examples than the inline `///'''` versions can comfortable handle. 
Hi! So looking at the code it looks right, but you shouldn't need to call wake at all in your executor. Waking should only be used in the poll implementation, which in this case is done automatically. The issue I see is that you call `take()`which takes the value out and replaces it with a None. However, if it's none you're returning early! Try putting the Future back in to the Task as this will probably solve your issue. If you look in the secret folder we have a solution there as well.
I'm interested in contributing to this. Do you have a git repo some place?
There are like 6 different acronyms on that page that are unexplained and don't link to anything. It's sooooo frustrating.
So ... I need figures. How many of those tweets actually compile?
I saw this about an hour ago and I'm still upset. I could respond to this in many ways, but here's my response: Short answer: no Long answer: I see no point to your criticism and it only made my day suck at the end of it. You didn't provide any reason, just "leave out your memes". Why? Because it's what, unprofessional? The slides exist as is, how I gave the presentation. I'm not gonna change that because someone I don't know said remove them without a reason. Consider this, the class when given was 3 hours long. 3 hours is a long time and keeping people engaged is good. Laughter is good. Anything that's not code is good. The slides were made for a class, not something to be consumed in 5 minutes at home. However, people might enjoy going through them and learning so I put them up. Now if you said something like, "On slide 5 it was unclear as to what you meant by PinMut and here's why" or whatever then sure yeah that's valid criticism and sussing out better ways to teach things is good. Feedback from the the first day when this was taught at the Mozilla office was incorporated into the next day. This is good. However, coming out of nowhere just to say "remove the memes" is not and all it serves to do is put someone in a foul mood and in this particular case, me. These slides are part of a context in which I speak, all things are, including presentations given at RustConf where memes and jokes were also involved. When I teach I want it to be fun and engaging, not like my CS classes in college that were dreary and dull. That's not fun, no one learns anything, and the money they paid to take the class is wasted. I'm presenting it to you here free to use. Time I spent many many many hours on and late nights working on all so people could have fun and learn. I didn't have to do this, I didn't have to put this up and share it, and I sure as hell didn't have to put it on Reddit, and this right here is why I rarely come to the sub any more, because frankly in the 3 years I've been on this subreddit it's the fact that the Reddit attitude finally came here that I don't like posting or interacting with people here anymore. But all you have to say to all that, after all the time I spent on this, to a presentation I am providing to you for free to maybe learn something new is the equivalent of spitting in my face. Why? Why should I ever help others if this is the attitude I get back? Either be constructive with your criticism or don't say anything at all. You could have just shut up and not said anything, but instead you demand from me my time and service to remove images you did not care about, and a presentation you'll probably never read again and frankly screw that. I'm not changing that.
You're trying to pass a value somewhere where you should be passing a reference to that value. So, while I don't have the API docs in front of me, try let sorted = toposort(&amp;dependencies, None).unwrap(); Note the '&amp;'.
Possibly! The class is about 3 hours but most of the presentation stuff can be done relatively quickly. The extra time is people working on examples. I have some more time this week so maybe I can do a recording to pair with it :)
Also if you get stuck the answers are provided in the secret folder :)
No. This was just some internal reworking. varkor will be merging a few more PRs before we see feature gated const generics.
Could try ggez
Hey mgattozzi, the guy's trolling so don't take it personal. Thank you for your enormous effort with the work you put in and for the slides. 
I'm probably messing up something really basic, but I'm having trouble running `cargo run --bin timer` even though it appears I'm on the correct nightly version: https://gist.github.com/yaymukund/389cf470c0f9987c440a5a32e4f67310
Indeed, this behavior of `drop` is a regrettable consequence of not being able to say `!Copy` when defining the trait bounds on a function, IOW, we have to write `fn drop&lt;T&gt;` rather than `fn drop&lt;T: !Copy&gt;`. This was brought up prior to 1.0, but there wasn't any easy path forward for making such a feature generally available (negative reasoning like that is apparently quite difficult) and so the decision was made to live with it. If we ever do get the ability to bound on the lack of a trait, I'd be in favor of deprecating `drop` (doubly so considering that it's easily confusable with the `Drop` trait) in order to improve the experience here.
Don't let the naysayers ruin your day. You made something great and should be proud of it. *hugs /u/mgattozzi*
But `setTimeout` takes a callback, not a future.. --- I wish we could use futures in a yew app, in Components' `update` methods, e.g. for doing ajax fetch calls inline, like with [affjax](https://github.com/slamdata/purescript-affjax), and similar things that now require breaking up the pre and post handler code into separate `Msg` cases &amp; handlers..
I think `std::io` has some os specific things as part of it, making it not likely to be able to be moved to `core`
First-party support for webpack is nice, but does this help with the issue of loading WASM files when the blob is on-disk? I'm planning to try this out soon because I'm interested, but I'm concerned that I'm going to run into the same issues as detailed above.
The whole module, yes of course. But I'm wondering if the core traits could be shared. For example, if I'm implementing an incremental SHA-512 hasher or something like that, it might as well implement `Write`, even though it's totally independent of the OS.
Ah. That's interesting to know that the types have to be fixed at compile time. I feel like that precludes a lot of interesting use-cases, though. But at least the types can't get too crazy.
You might have `guessedLetters[x].push` which is not correct.
The most immediate benefit is being able to do `impl&lt;T, n&gt; Thing for [T; n]` instead of the current solution to make a few dozen of those with a macro and hope nobody asks for a different number.
It's not the cleanest thing at the moment but I uploaded it [here](https://github.com/fkaa/dxbc/). It's currently depending on a winapi branch which will hopefully get merged soon.
My understanding is that per [RFC 2000](https://github.com/rust-lang/rfcs/blob/master/text/2000-const-generics.md), it doesn't do any unification except for literals. That is, it isn't even able to understand that \`{N - 1}\` and \`{N - 1}\` refer to the same value if \`N\` is the same. This is to avoid type check depending on constant propagation that is done in the monomorphization phase, as said in the RFC. However, taking into account the recent developments, constants are able to be interpreted by MIRI. Will this change the equation? Would it be able to calculate and boil down two \`{N - 1}\`s to the same constant value and then be able to unify them? Now that I think a bit more about it, there's two cases, right? If a constant is dependent only on other constant expressions, then MIRI will be able to "boil it down". But what if it's dependent on associated constants and type projections? Does MIRI support that much?
Thanks for the fix I just merged it :D
Thanks :)
Thanks :)
Presumably it also doesn't generate code that doesn't get called, among other optimizations. I don't see any reason for an array which just gets looped over to actually generate any "extra" code beyond the compiler either unrolling/vectorizing a loop or inserting the correct length into the loop's bound check.
Thanks :)
What are you wanting to do? Do you want to have the examples included in the docs where you would normally write them, but not have them take up a bunch of space inline, or have `cargo doc` generate documentation for the code in the examples? There is an unstable feature that lets you do the former, the one drawback currently is that doctests may not report correct line info: https://github.com/rust-lang/rust/issues/44732
Hey, thanks for the hint! I'll take a look at this tomorrow and see if I can apply and if it to mvdb.
Yes, there are ton of requests like this. \`usize\`-but-not-\`usize::MAX\` would be great for indexes (the compiler would like to use these internally), \`usize\`-but-without-the-high-bit as the size allocations can actually be, \`iN\`-but-not-\`iN::MIN\` so it's symmetrical and that's the least useful value anyway, \`f32\`-but-not-the-\`NAN\`s, etc. They're all reasonable, but unfortunately adding add them is unreasonable, thus the const generics plan instead.
Your understanding of traits is kinda lacking :T My correction is indeed right, but you're not using the traits properly. You can't have `type Ret = T;` because T is a trait, not a type. 
are you sure you want to cast, not transmute there? Casts will not let you store negative numbers.
Note that there are no guarantees about getting the same function pointer twice - you'd need to be within the same crate *and* codegen unit, when casting the function to a pointer, to have a chance. Oh and LLVM will happily combine two different functions into one, if they happen to have identical bodies, so watch out for that too.
I can't speak for anything Piston related, since I've never used it. SDL2 by far has the best and most mature Rust bindings. It should be enough if you just want to get some simple graphics on the screen, like for a simple pong clone. Drawing text will be the thoughest part (you'll have to write your own text renderer). If you need something more powerful and/or easier, SFML is probably better. As an alternative, you might want to check out NanoVG, especially our [Rust bindings](https://github.com/KevinKelley/nanovg-rs) (we're having some problems with publishing the crate, so just use it from github directly). It's basically an OpenGL accelerated vector graphics library. You can get some awesome stuff drawn with it, check out the screenshots. I'm currently using it for a project of mine. Generally I recommend using GLFW (or anything that uses GLFW under the hood) for window handling if possible, since it's by far the best designed library for it's purpose. There are idiomatic Rust bindings, but IIRC they're a bit outdated and also have some design flaws. [I made a crate](https://github.com/Lisoph/glfw_ffi) for raw FFI bindings to GLFW, if you're down with using the raw GLFW C API.
`as` casts on integer primitives of the same size act like transmutes. So`-1i32 as u32` becomes `0xffff_ffffu32`, and then going back `0xffff_ffffu32 as i32` becomes `-1i32`. Quoting from [the reference](https://doc.rust-lang.org/reference/expressions/operator-expr.html#semantics): * Casting between two integers of the same size (e.g. i32 -&gt; u32) is a no-op * Casting from a larger integer to a smaller integer (e.g. u32 -&gt; u8) will truncate * Casting from a smaller integer to a larger integer (e.g. u8 -&gt; u32) will * zero-extend if the source is unsigned * sign-extend if the source is signed
Slightly on the punny side, but since your main entry point is `join_with`, you could call it `join_without`.
Does it have any relation or feature overlap with chalkification?
It seems a hash\_map is lacking a drain\_filter which would immediately give you an iterator over all past\_dates and also remove them. If you store your past\_entries in a vector of somethings you can just pop those elements which should be movable? I don't get the and\_modify().or\_insert api here? Totally different idea: Why not have a sorted vector of your dates with their content? then its just a matter of taking the correct (upper\_bound/lower\_bound) slice out of the vector and accumulating that? For searching a certain date you could do binary search if needed. Depending on how you sort the vector you either need to remove all past dates at the front and push the new date at the back. Probably best to create an abstraction for this, such that you don't mess up the sorting.
We don't have const generics yet, so it is not defined(or is it?). But anyway you should be using something like saturating_add in this case. And it leads to question: are there any plans for something like concepts/constraints/generic-time conditionals?
If L1 and L2 are both -1073741824, then L1 + L2 is -2147483648, which is a valid i32. I think you meant if both L1 and L2 are -2147483648; in that case L1 + L2 is not well formed. The [const generics RFC](https://github.com/rust-lang/rfcs/blob/master/text/2000-const-generics.md) does speak a little about well formedness in its [Unresolved questions](https://github.com/rust-lang/rfcs/blob/master/text/2000-const-generics.md#unresolved-questions) section. 
Thank you. Yes, a `drain_filter()` would help with removing the past entries. But then i still would have to clone and store them so that i can re-add them? The clones make me sad since the values (and keys) come from the HashMap and should go to the HashMap.
Hi! Is there a way to specify a target to compile to? I have a software that need to be compile to i686-pc-windows-msvc only (for registry access reason, to let Windows manage the `Wow6432Node` alias). Can I put something in Cargo.toml to avoid `--target=i686-pc-windows-msvc` every time without changing my toolchain's default?
Maybe I'm just dumb, but even these examples are way beyond me in terms of how they actually work. This stuff is changing way too fast, what was best practice months ago for async is now already out of date. I wish I could use Rust instead of node.js, but alas, until we get some stability in terms of compiler features and APIs, that is completely out of the question...
This is really awesome since it has been one of the things I've always felt was missing in Rust.
I liked the presentation's content very much, but I also found the amount of gifs somewhat overwhelming (despite the fact that I'm a big Doctor Who fan). It's not a big problem though. No need to get upset over it. I'm basically just saying. 
[removed]
Just tested it, it does not :) and it's ``` [build] target = "i686-pc-windows-msvc" ``` (target, not triple :D)
I have recently [blogged](https://medium.com/@shnatsel/how-rusts-standard-library-was-vulnerable-for-years-and-nobody-noticed-aebf0503c3d6) about this vulnerability and what it means for the safety of Rust
Why would it be n^2 ? Pretty sure it's linear: iterate through one hashmap and look them up in the other O(1) * O(n), right? See [impl](https://doc.rust-lang.org/src/std/collections/hash/set.rs.html#1208)
&gt; i am curious to see the final solution Thank you. Me too. In real life the performance difference is probably not measurably, but it bothers me a bit.
Really good work on raising awareness! :)
More or less finished the rust bindings [https://github.com/varlink/rust](https://github.com/varlink/rust) for the [varlink](https://varlink.org) IPC protocol
As long as `n` is known at compile time. i.e., you will not be able to do this: ``` fn foo(n: u32) { let a = [0; n]; } ```
Thanks, I was confused by his given example but now its all clear. I wonder what is the reason behind this? Wouldn't it be easier to understand if values dropped in the same order of their creation?
Not as far as I'm aware. Which is exactly what I'm trying to change by attracting attention to this vulnerability.
&gt; Is there any effort to increase fuzzing and correctness of the unsafe parts of rust to prevent this in the future? This would probably be much more useful with [sanitiser support](https://github.com/rust-lang/rust/issues/39699) no?
And it was close because there are still remaining ambiguities.
Fwiw, I thought people were so crabby on that thread. I enjoyed reading the article and found it informative. 
I can't blame them. After all, Rust's mascot is literally a crab!
That's probably unsafe as heck and very evil. I love it.
*clicks link* &gt; Your connection is not secure I have to say, I appreciate the irony.
That's reddit's fault. `out.reddit.com` has an expired certificate.
Huh? It shows up as secure for me. Are you getting MitM'd? Cert displayed in firefox: https://i.imgur.com/UTyHrwU.png Exported certificate file: http://cryptb.in/zXAHAh#804730f0b76324038abe40fcb9853778
As another user noted, it's reddit's fault because out.reddit.com is using an expired cert.
You can already eyeball the output of [cargo-tree](https://github.com/sfackler/cargo-tree) to get something similar. As long as my dependency chains do not involve more than 20 crates, I would not be looking for a specialized tool.
What else should i use then?
Once you start using methods defined on `&amp;MyStruct` (or on `&amp;self` in `impl MyStruct`) what should the compiler do? The only reasonable thing seems rejecting this as unsafe which means that all your additional initialization needs to happen in the method you are initializing the struct in. That seems to limit the usefulness of such a feature (it wouldn't allow the builder pattern as the most obvious example).
You probably forgot to install the Windows SDK component when installing the Visual Studio Build Tools. That's the second most common reason for that `linker 'link.exe' not found` error (the most common being people not installing any sort of VC++ at all)
Yes, but only *statically* dependent types. That is, types can be parameterized with compile-time values but not runtime values like in a fully general dependent type system.
&gt; This is a good thing. Try disaster.
Wait a second. Is this an unsafe function. Or is this a synthetic overflow. I thought we weren't supposed to have those. Anyway Vecs have Always had scary features that could lead to things like this so I'm not surprised nor all that worried. It'll get patched out real fast. 
No, this is not a CVE for the existence of an unsafe function. There was a logic error involving some unsafe code that could be exploitable (I don't think I saw a demonstration of it being used). It was a bug in VecDeque, not Vec. It's already patched, and has been since 1.21.
Yes, async world (especially async fn) is rather new and somewhat incomplete now. That's why I also included old async fn examples. If you want I can comment what happens in an example.
I am pretty sure the rust internals team uses a tool called `cargobomb` to test new releases. It pulls down all of crates.io compiles it with the new version and compares errors with older versions. 
Thanks so much, that was it.
Thanks, that was it. Wished the compiler error message was less verbose.
Right now nothing. It is only being used for traits atm and it seems to ignore const generics. Chalk's API seemed to operate on generic parameters though, so I assume they will need to support const generics in some capacity. Check wg-traits in the Rustlang discord to see what is up with that and/or the associated RFCs. Keep in mind there are two Rust discords currently, which is a bit confusing.
I'm working on a project called Spacebar it's a very special anti-plagiarism tool. I currently need some help squashing little bugs and updating my UID generation function. You can read more about it in the read me here: https://www.github.com/LogoiLab/spacebar
What /u/hummingly suggested: without the [x]. Please make sure you understand what the difference is...
&gt; are there any plans for something like concepts/constraints/generic-time conditionals? Rust has had where clauses since 1.0.
`error-chain` fell out of fashion, `failure` is the new standard.
More details here : https://github.com/rust-lang/rust/pull/53562/commits/6b664fa0b8d19c1c157c865a7f21ecbfa2573b28
If I had to pick, I'd rather see [`cargo-outdated`](https://github.com/kbknapp/cargo-outdated) built-in.
Have you filed issues against those crates? If so, could you point me to them? The bugs that Address Sanitizer points at often turn out to be exploitable security vulnerabilities. I'd like to add them to [RustSec database](https://github.com/RustSec/advisory-db) so that cargo-audit would tell you if your crate depends on a vulnerable version.
I have not yet opened upstream issues. I just started playing with Rust + ASAN last week and haven't had time to further investigate them. BTW I created RustSec 😅
I gave it another shot, i now removed most of the overhead.. Just one clone remaining :) [https://play.rust-lang.org/?gist=011a219dbcc307ec078b9dd267e0a93b&amp;version=nightly&amp;mode=debug&amp;edition=2015](https://play.rust-lang.org/?gist=011a219dbcc307ec078b9dd267e0a93b&amp;version=nightly&amp;mode=debug&amp;edition=2015)
It failed. But basically it's to allow calling generic code easier. For example: let vec = Vec::&lt;i32&gt;::new(); They were trying to allow writing: let vec = Vec&lt;i32&gt;::new() But it failed because it's hard to parse, and there can be misconceptions with the operators &gt; and &lt;.
As others said, Failure is the new thing. However, I've ripped it out of my projects and just use Results. I don't need backtraces personally. 
What makes electron better? Like what is useful to do that a web-view wouldn't solve. Even for VS Code and Atom.
Huh, thanks
I don't think there's anything that's perfect here, and no universal suggested style guide. Personally, I'd favour the rule of simplicity here and use `bool` as the simplest type. I also see the advantages of using results, namely the must use must use lint and ? operator. Ideally, arbitrary functions would be allowed to be marked `#[must_use]`, but i'm fairly certain this isn't "a thing" at the moment.
Actually, I think you can safely cast between pointer types, no `transmute` or even `unsafe` needed.
Thanks for the tip. I will take another look. I tried to cast the type originally but it didn't work... so I reached for the sledgehammer.
Note -- this may not work on Windows, the one place where it might be safe, due to setjmp/longjmp being implemented as "normal" exceptions. I'd link the GitHub issue around this temporary change breaking rlua but I can't find it trivially right now. It's a good read, though! -- and I see you have a `#![cfg(not(windows))]` on the whole thing. Nice.
I rather suggest PR-ing such a feature to `cargo-tree` and `cargo-outdated`. Besides that: I'd love having such a tool. &gt; and that [crate-style DLL hell] is a good thing IMHO whichever good reasons there might be, the downsides outweigh them for me.
I'm not that familiar with Cargo, but are you not able to just match dependencies? e.g. if crate `a` demands crate `x = "1.2.3"` and crate `b` demands crate `x = "1.1.5"`, is there a way to at least test if `b` will work with 1.2.3 before resigning yourself to needing both? I know this won't work in all circumstances and isn't entirely relevant, but is this possible?
I have tried to make all of the examples in the book cross-portable but I definitely got stuck here. My workaround was the Dockerfile. Was actually a great motivation to learn how to build static Rust executables in a minimal container.
Rust n00b, checking in. I thought the turbofish was only when types that are qualified with the resolution `::`? But this test case only uses the angle brackets in `&lt;woe, is&gt;`. Also, what's the real background here? It's too subtle for me. We don't need turbofish anymore because `rustc` is good at deducing what I meant most of the time? Except maybe this case couldn't be deduced w/o turbofish?
I didn't use the original \[x\] method, i copied his line that looked like this: guessedLetters.push(line.chars().nth(0)); But i'm getting an error from the push method...
&gt; I don't need backtraces personally. In my case, it's a user-facing project, so I need good error system to report precise failures to my not-so-technical users.
So, the entire point of this is that you can't actually get rid of the :: from the turbofish context because what you're seeing is valid syntax. To see how it's valid, here's what you see: (oh&lt;woe, is&gt;(me)) And this is how the compiler processes it ((oh&lt;woe), (is&gt;(me)) In other words, :: is required for turbofish syntax because otherwise the &lt;&gt; can be interpreted as greater than and and less than symbols. Context: There was an RFC to make the :: in the turbofish syntax optional, but died when this ambiguity was pointed out.
Holy Dennis Ritchie, you cannot imagine how much you have just improved my Reddit experience.
All of them! With a few caveats. * There are two tweets that are not code from the beginning of the account. Those don't compile and are thus blacklisted. * Many, many of the tweets have addition or multiplication overflow, which is a compile error by default, so that has to be explicitly allowed. * There are lots of warnings for dead code and non-camel-case variables. :)
I'd argue that user-facing programs shouldn't get backtraces. At least in my code I found that errors come from 3 sources: 1. Data errors on the API. I eagerly desalinize data on my API, so errors here will only ever be 1 'deep'. 2. Infrastructure errors. If my database is down, things aren't going to work anyway. I prefer to translate my error into something meaningful and say "don't panic". 3. Logic errors. These ones are my fault, and where having a backtrace is useful. I'll be honest, I mostly rely on logging and unit tests here. I'm not working in anything particularly complex though. If you're project is going to be large with lots of moving parts and user provided data, then you might be more interested in a proper backtrace. 
Yeah, cargobomb was crater, and has been renamed back to crater. A conversation about it was the inspiration for this...uh...'tool'.
The main problem is that working on the std library (compiling it, testing it, adding new tests, changing docs, etc.) has a **horrible** development experience. My edit-compile-test cycle is basically edit, `./x.py test`, check the results the next day.
Fantastic, I’m happy to hear its working out! If you ever wrote a blog about the experience or put any projects online, feel free to link me :)
No experience with the approach, but it stood out to me when I ran across the project. The technique doesn’t appear to be well known, so it would be hear more about the advantages and disadvantages of the approach.
I'm not sure that “backtrace” is the correct word; but I mean is that I want than rather getting a `Error: can't parse file` message, I'd like my users to get a `Error: can't parse xxx.abc: line 45: unexpected Z`. So they can precisely understand what's failing and why, so they can fix it.
&gt; There are some issues with Memory Sanitizer, Some issues is an understatement: it only works with `no_std` crates, on Linux, with a particular memory allocator, the `std` library is not tested with it (or any of the other sanitizers), etc.
Last hope : deprecate comparison operators in the next Edition and replace them with `lt` and `gt` like in bash. 
If you write an app, just use `failure:Errror` everywhere. If you have an library, you can think about something more elaborated (enum + `failure::Fail` maybe).
And delimit them with dots! Like if a.lt.b ... It's more readable that way! And looks much more elegant!! And nobody else every did that!!!
Here, you dropped this: `)`
Yeah, that's what I meant by "wrap the crate in a macro". Just wondering if there is a more idiomatic option, but probably not...
Here you go: #!/usr/bin/env python3 import json import subprocess from collections import defaultdict def main(): metadata = json.loads(subprocess.check_output(["cargo", "metadata", "--format-version", "1"])) deps = defaultdict(list) for dep in metadata["resolve"]["nodes"]: name, version, _ = dep["id"].split(" ") deps[name].append(version) for name, versions in deps.items(): if len(versions) &gt; 1: print("{} has multiple version: {}".format(name, versions)) if __name__ == '__main__': main()
I have gotten a lot of value out of this exercise in the past. Sometimes once it's in plain code it's like, wow, what was simple. And it may be faster to write in bumpy but it will run a lot faster in rust. 
The bug: https://github.com/rust-lang/rust/commit/f71b37bc28326e272a37b938e835d4f99113eec2#diff-979c1a655fad39145d845c370df61f4fL561 if new_cap &gt; self.capacity() { Subtle. So basically this bug is the result of VecDeque having the concept of two different capacities. There's the capacity number it reports to the public facing API (`VecDeque::capacity`). Then there's the real, internal capacity (`VecDeque::cap`). They're off by one. You can see this yourself (https://play.rust-lang.org/?gist=c5bddf9833f03e0f9efb69ba6f454ac0&amp;version=stable&amp;mode=debug&amp;edition=2015). VecDeque's internal capacity is (generally) always a power of two. But it reports `7` in that example, because the public capacity is one less. So, `reserve`, in that line, is comparing `new_cap` which is "internal capacity" to `self.capacity` which is "public capacity". Oops. The patch: if new_cap &gt; old_cap { Where `old_cap` is "internal capacity". In hindsight I believe this would have been prevented by being more aggressive with Rust's typing system. `VecDeque::cap` was defined as `fn cap(&amp;self) -&gt; usize`. But what if it were defined as `fn cap(&amp;self) -&gt; InternalCapacity`? And we had `struct InternalCapacity(usize);`. While you'd define the typical math operations for `InternalCapacity for InternalCapacity` you wouldn't between `InternalCapacity for usize`. Which means `new_cap &gt; self.capacity()` would throw a compiler error. Can't compare "public capacity" (of type usize) with "internal capacity" (of type InternalCapacity). You'd of course go even further and make sure, throughout the code, all functions that expect internal capacity numbers would only accept `InternalCapacity`. Doing this means that it'd be exceedingly difficult to mix things like this up, now and in the future. The bug in question seems to have been added later in VecDeque's lifetime. i.e. someone was refactoring the code. When you're designing any kind of system the first time you become intimately familiar with it. So bugs like these are less common. It's when someone has to go back in and modify the code later that bugs creep in, because they won't know all the invariants that you originally had in mind. Using the newtype pattern, like I describe, can encode these invariants in the type system and make the compiler catch these bugs for you. And as always, that "other someone" could be you in a few months; the code will look just as foreign. Obviously we have 20/20 glasses on now. I doubt I'd have the foresight to design VecDeque with this kind of aggressive defensive coding. But I figured I'd mention it, as food for thought, for those designing things in the future. AFAIK the compiler will optimize all those types down, so we can eat our cake and keep it bug free too.
In fact, I started in on QuickChecking Rust stdlib on my way back from RustConf: [bughunt-rust](https://github.com/blt/bughunt-rust). The project is still a meager skeleton but I'm intending to do a little work every day or so. Looking forward to what gets kicked up, especially in the less well-tread bits of the API. 
 &gt; A retroactive CVE may not do much, but at least it will give ammunition to package maintainers and ops teams to upgrade regularly. Or cherry-pick the actual patch. Unfortunately, updating rustc is not enough - many packages written in Rust will need a full rebuild too, to avoid faulty code in end programs.
🔥 🔥 🔥
You're missing context I think. The bug was fixed a long time ago. What's changed is that a CVE was filed for the old affected versions. That's a "good thing". (Though I don't know what you imagined anyone meant otherwise?)
While failure has a lot of hype, especially in libraries it is problematic, not only because of its [performance concerns](https://boats.gitlab.io/failure/use-error.html#caveats-on-this-pattern) (also see [this post](https://www.reddit.com/r/rust/comments/7te8si/personal_experience_can_cause_hard_to_notice/)) (failure generates a backtrace on every `?`, whether you use it or not) but also because it brings in a slew of dependencies and in most cases it's simply overengineering. I've ripped out failure from projects and ended up with less or roughly the same amount of code than before. Just because it's the new hot thing doesn't mean it's automatically appropriate for your project. What failure seems to be good at is CLI tools / user-facing binaries - if you don't need raw speed or something like that. I do not recommend error-chain, it looks cool, but bites you in the ass if you need to do custom conversions between errors - yes, it makes it so that you have to type less code, but that comes at a huge readability disadvantage. "Less to type" does not equal "easier to maintain", debugging macro errors because of a stray semicolon is a pain. My form of error management is rather simple: I just use enums and the built-in `From` conversions. I have a 4-5 line macro to generate the `impl From&lt;...&gt;`, but that's it. I've made the discovery that it makes a difference on error handling how your code is structured: For libraries, it often makes sense to batch everything into one large error enum for the public API, but for binaries, I often use per-function error enums with `.map_err`, since writing `From` conversion is too much code if you only use that conversion once. I also don't implement the `Error` trait because in my opinion, that trait is completely useless in its design - since you can't return dynamic error Strings, so many people simply return the same string in the `description()` method that they do in the `Display` impl block and `None` for the `cause()` - so in the end you end up with something less flexible than the `Display` trait (since you can't return a dynamic String in the `description()` function). I've simply given up on trying to implement it, implementing `Display` is usually good enough. Once you drop the `Error` trait, you also drop a lot of boilerplate that you needed to write and suddenly crates like `failure` look a lot less attractive, that's all I'm saying. And please, please, do not use Strings as error types (or casting a string to a `Box&lt;Send + Sync + 'static&gt;` or even worse `Io::Error::Other("thing failed".into())`). Please, for the love of god, don't do it. You will run into issues with cloning errors, problems with wanting to access the type information, but now you can't because it's a string, performance issues, unable to translate error messages, etc.
Cargo will unify those already -- `1.2.3` is *supposed* to be compatible with everything since `1.0.0`. They would only be separated if crate `b` required `x = "=1.1.5"` for that *exact* version only, or if it required `x = "~1.1.5"` for any `1.1.n` where `n &gt;= 5`.
&gt; if you don't need raw speed From what I understand from your links, it only slow things down when allocating the `Error`, right? And thanks for the detailed answer!
The same could be said about a lot of `std` to be fair. There is a lot of legacy code where new features introduced into the language would have made the code much clearer and probably more concise and performant, but no-one seems to want to spend *that* much time cleaning up legacy code in the various parts of the Rust toolchain, instead focusing on new features.
That sounds good, I am sure PR are welcome.
I mean where clauses for consts. Something like ```rust struct Foo&amp;lt;const N: i32&amp;gt; where N &lt; 10 ``` And AFAIK where clauses support only type constraints. Am i mistaken?
Is this one of those things where in retrospect a different delimiter might've been better? Maybe square brackets don't have the same issue? Then again I type the turbofish so rarely that maybe it's not really a downside for the more familiar syntax.
Can't you use xargo? 
For what I could see, this is mostly about generalizing the *parser* to handle values, not only types, for generic parameters. It's a necessary step, but there's a whole lot of work remaining.
This is actually the very first goal, yes.
I think that the consensus is to *iterate* on const generics, rather than try to solve everything immediately. The first step is to allow generic value parameters for types so that arrays can finally have traits implemented for all capacities. This will already unlock a number of usecases. There will probably be some debates about syntax, some corner cases will appear, some unanticipated difficulties rear their ugly heads, etc... Once this is settled, the experience gathered by compiler developers and users will help get a clearer picture of what is possible and what is desirable. *Note: the fact that MIR can technically allow something does not mean that it seems desirable. For example, MIR could technically allow I/O during compilation, yet uncontrolled I/O could wreak the soundness of the type system.*
Its not integrated into the `std` library build system, so no, AFAIK you cannot. 
Yeah; using \`\[Type\]\` as in Scala might have worked; tho it is possible that it would have opened up other problems wrt. array access instead, but less likely :)
I think that TL;DR completely misses the point. This bug was found and fixed ages ago. The testing and verification is better than almost any comparable project. There is always room for improvement, but it's not a weakness of rustc specifically, it's a weakness of the software development industry in general. The article did have a legitimate point that there wasn't a CVE for the bug to tell people that they should upgrade off of vulnerable versions, but that point is lost in the TL;DR.
Could you give some examples of outdated code? I'm sure some of us would be willing to take a look if we knew where
BTW, can I just say, I love what you are doing here! I love the thought of having someone actively looking for vulnerabilities in it and standard libraries. Even finding some is great! The language as a whole will do well to be more security minded. Making rust even safer is great and the more effort we can get to making that a thing, the better.
This particular bug is a symptom of a larger problem: the implementation of data structures in the Rust standard library did not get any systemic verification, and most likely there is much more memory safety issues lurking in there. There are historical examples of this as well: the Map data structure in Erlang seemed to work fine (just like Rust stdlib currently) until people actually started verifying it with QuickCheck, at which point they have discovered lots of bugs, some of which were quite serious. There is an excellent series of articles detailing that: [part 1](https://medium.com/@jlouis666/breaking-erlang-maps-1-31952b8729e6), [part 2](https://medium.com/@jlouis666/breaking-erlang-maps-2-362730a91400), [part 3](https://medium.com/@jlouis666/breaking-erlang-maps-3-f008b5f714c5), [part 4](https://medium.com/@jlouis666/breaking-erlang-maps-4-4ebc3c64068c).
Failure looks great and I'm looking forward to it. Right now in our code base we aren't using anything on top of standard results for most projects. We moved a couple projects to error-chain, but as that lost steam we lost interesting in moving others over to it. From what I've seen failure is on the verge of hitting 1.0 and once it does we will start moving over towards it. I'm pretty skittish on taking something that touches so much code if I'm just going to be facing a breaking change in a month or two.
Binary infix operators! By surrounding them with back ticks! You heard it here first!
Hyper depends on h2, which depends on fnv.
All keywords and operators should be replaced with emoji.
That's the first 90%. Ideally, the UX should be a little better -- e.g. if a single outdated/duplicate dependency brings in other duplicates, they shouldn't be reported.
Cool! I'm going to spruce up the README this evening and write a proper introduction to the project, shop it around on the forums. 
Clippy has a lint for the first part: [https://rust-lang-nursery.github.io/rust-clippy/master/index.html#multiple\_crate\_versions](https://rust-lang-nursery.github.io/rust-clippy/master/index.html#multiple_crate_versions)
Thank you! Still great to see this happening.
&gt;I think that TL;DR completely misses the point. This bug was found and fixed ages ago. The testing and verification is better than almost any comparable project. There is always room for improvement, but it's not a weakness of rustc specifically, it's a weakness of the software development industry in general. It was found about a year ago, and existed for longer than that. In what way is it better than almost any other comparable project? Serious question .- I don't know what goes into rustc's testing, or other compilers.
And it even kinda makes sense. Square brackets are indexing operator, and you'd _index the space of possible types_. But angle brackets are way more recognizable, so there's that.
`cargo tree -d` is pretty much what I'm asking for :/.
When you're right you're right 
Don't forget about the builder pattern: if a().lt().b().expecto_patronum() ...
&gt; You can't create references to uninitialized memory, so you can't use &amp;self/&amp;mut self methods on partially initialized structs (because to do so you would need to create a &amp;mut Self, and that's UB). This is how I'm currently achieving recursive delayed / partial initialization. I write `unsafe fn init(&amp;mut self)` methods. You're probably right that this is technically UB, but it does work. I suppose I could/should go back to writing `unsafe fn init(*mut Self)`, and then accessing the fields inside the the function, but I haven't needed to, yet. It requires _a lot_ of `unsafe`, though. ---- &gt; I don't really know how far you wanted partial initialization to go, but if you want to pass partial initialized state across methods via references, then none of that is going to work and you should probably just use Options and a builder and call it a day. As mentioned previously, my primary use case is for initializing very large structs. Options and a builder won't work; the stack will overflow. Making the compiler detect uninitialized fields within a single function might be nice, but it doesn't help with the large struct use-case, since it's unreasonable to stick all initialization logic in a single function. If it were combined with some special write-only linear pointer type that had to be written to exactly once, then I think that would work. --- I see now what you mean about enums. Yes, that would work perfectly, particularly if combined with a write-only linear pointer type.
Yeah sorry, misread the example.
How about compromise, use angle brackets for generics: (oh⟨woe, is⟩(me))
Please show the exact code you compiled and the full error message. 
I was hoping to get a job there to open a banana stand. Now I'll probably have to sell lemonade. Crap.
There's even a [clippy lint](https://rust-lang-nursery.github.io/rust-clippy/v0.0.212/index.html#transmute_ptr_to_ptr) for transmuting between pointers!
I have a trait that must be object safe: pub trait Foo { fn children(&amp;self) -&gt; Vec&lt;&amp;Foo&gt;; } (In reality it's slightly more complicated than that, but anyhow.) Is it possible to express that the lifetime of the borrows inside the children are the same as the parent? I e, if I have `&amp;(Foo + 'a)`, the function would be `fn children(&amp;self) -&gt; Vec&lt;&amp;(Foo + 'a)&gt;;`, and if I have a `&amp;(Foo + 'static)`, the function would be `fn children(&amp;self) -&gt; Vec&lt;&amp;(Foo + 'static)&gt;;`? 
If I'm not mistaken, adding a special `&amp;uninit T` pointer/reference type (modulo the syntax), that was write-only and linear (must be used exactly once) would make it possible to keep the analysis intraprocedural. The analysis would need to ensure the `&amp;uninit T` was used prior to allowing access to `&amp;T` or `&amp;mut T`, of course. I don't know how hard this would be to add, though. Perhaps with the new NLL chalk-based borrow checker implementation, it wouldn't be too hard. I don't know how exactly the syntax would work around taking an unitialized reference. I suppose in order to match mutable references, it would look something like this: ```rust let i: usize; init_i(&amp;uninit i); ``` I suppose there could also be a method call that would implicitly convert into an `&amp;uninit Self`, similar to how `&amp;mut self` methods work.
*beep beep* Hi, I'm JobsHelperBot, your friendly neighborhood jobs helper bot! My job in life is to help you with your job search but I'm just 337.8 days old and I'm still learning, so please tell me if I screw up. *boop* It looks like you're asking about job search advice. But, I'm only ~25% sure of this. Let me know if I'm wrong! Have you checked out Forbes, LiveCareer, TalentWorks? They've got some great resources: * https://www.forbes.com/sites/karstenstrauss/2017/03/07/job-hunting-tips-for-2017/#794febea5c12 * https://www.livecareer.com/quintessential/15-job-hunting-tips * https://talent.works/automate-your-job-search
For the future, you can highlight code for reddit by indenting every line by four extra spaces. You've annotated `guessedLetters` with the type `char`, whereas it should be `Vec&lt;char&gt;`, so the compiler is getting confused. You shouldn't need to give it a type at all, as it will be inferred from what you put in it. 
Nice it worked! Now i have a new issue right after the push method: The program expected a char but found an Enum. Is there a simple fix for that? 
You can parameterize the trait with a lifetime which then has to be bound in the impl: pub trait Foo&lt;'a&gt; { fn children(&amp;self) -&gt; Vec&lt;&amp;(Foo + 'a)&gt;; } If you get a "conflicting lifetime requirements" error then you might need to ensure '`a` outlives the anonymous lifetime of `&amp;self`: pub trait Foo&lt;'a&gt; { fn children&lt;'b&gt;(&amp;'b self) -&gt; Vec&lt;&amp;(Foo + 'a)&gt; where 'a: 'b; }
I'm also not clear exactly what you're trying to do. If you want the examples to show up as separate crates when you run `cargo doc`, you can enable documenting an example by setting the `doc` flag in `Cargo.toml` like this: [[example]] name = "my_example" doc = true
Bad bot
Thank you, iEzhik, for voting on JobsHelperBot. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://botrank.pastimes.eu/). *** ^(Even if I don't reply to your comment, I'm still listening for votes. Check the webpage to see if your vote registered!)
Even then, a CVE gives the enterprise maintainer a reason to consider backporting a particular patch at all. Obviously we don't backport every bug fix that goes upstream, but a security issue gets more attention.
With the proposed syntax, (oh&lt;woe, is&gt;(me) is ambiguous it can be both parsed as - a (bool,bool) tuple: `((oh &lt; woe) , (is &gt; me)) ` - a function call : `oh::&lt;woe,is&gt;(me)`
&gt;I really hate working on the std library (compiling it, testing it, adding new tests, changing docs, etc.), the development experience is pretty horrible. God, yes. It's the reason I've never done anything beyond minimal changes.
I'm not publishing any of this as crates. Anything reusable would be much smaller and not require partial initialization. I'm not sure how it could break in the future, since I'm careful to use `ptr::write` inside of `unsafe fn init(&amp;mut self)`. But perhaps I'll change them all to `unsafe fn init(*mut Self)` prior to pushing to production.
Why not use the `ᐸ` and ` ᐳ` from the [Canadian Aboriginal syllabics](https://www.reddit.com/r/rust/comments/5penft/parallelizing_enjarify_in_go_and_rust/dcsq64p/) ? :p
Just remove the `Some`. You're wrapping the character in an `Option` which is unnecessary and causes the error. 
I applied a couple of days ago and also did not get any response (also would be interested in remote), maybe they reply just to people who qualify for an interview.
No fear! even if they don't allow lemonade, you can always fall back to freshly-squeezed orange juice
Yes. Having symbols that sometimes have to be balanced and sometimes don't was a mistake. It's a headache for macros too -- it would be great if you could match an entire `&lt;...&gt;` as you can `(...)`/`[...]`/`&lt;...&gt;` (as a token tree). At least we learned from C++ that `Foo&lt;Bar&lt;Baz&gt;&gt;` should parse without writing `&gt; &gt;`, but turbofish is the same flavor of kludge. But in time, one can learn to [be at peace with the turbofish](https://turbo.fish/::%3C%C2%AF%5C_%28%E3%83%84%29_%2F%C2%AF%3E). 
Wow, thanks a lot! I am currently implementing a program where I sometimes access items by their (usize) id and sometimes by their index in an array. Reading your commenr, I now think that creating an ItemId(usize) type will free me from some future troubles.
I believe this is mistaken. `*const fn(foo) -&gt; bar` is a pointer to a function pointer. If you tried to deref and call it, you'd segfault. `fn_ptr1 as fn(foo) -&gt; bar` is how to get a function pointer. It doesn't always impl Eq however (IIRC it doesn't when HRTBs are used, i.e. arguments that are references), so coercing/casting it to a usize is what I would suggest. This can be done in one step from fn item directly to usize.
Yeah and lets rename them to gonerics.
People would need to manually run \`cargo audit\` to find out about vulnerabilities in their dependencies. Most people don't even know \`cargo audit\` exists, and absolutely no-one runs it every day on all of their crates. &amp;#x200B; However, since [crates.io](https://crates.io) index is [public](https://github.com/rust-lang/crates.io-index), is should be possible to use that database to write a crawler of that index and spam people to update their vulnerable crates.
I don't think compilers typically optimize multiple generics that produce identical machine code. If you need to deduplicate you can make one function that takes an array with generic length and passes it as a slice to the real function.
This is another good argument for why I think newtype should be more than a pattern. There should be first class support for making newtypes and specifying their interactions with minimal boilerplate, imo. (Is this already a thing?)
Oh! Fancy meeting you here! This is interesting to me because I've never managed to get an actual exploit by fuzzing obvious high-profile targets under ASAN, and [I've tried](https://www.reddit.com/r/rust/comments/8zpp5f/auditing_popular_crates_how_a_oneline_unsafe_has/). So I'm really curious to see how Rust breaks in practice. It would help me better direct my fuzzing efforts, and highlight some cases where better language or library abstractions are needed. FWIW I've seen ASAN report "ODR violation" which didn't seem relevant to Rust, and which I've suppressed using the following code in main.rs: const ASAN_DEFAULT_OPTIONS: &amp;'static [u8] = b"detect_odr_violation=1\0"; #[no_mangle] pub extern "C" fn __asan_default_options() -&gt; *const u8 { ASAN_DEFAULT_OPTIONS as *const [u8] as *const u8 } So that might come in handy. But admittedly I have no clue whether it's actually an issue or not.
I completely agree. I didn't see any existing RFCs for newtypes, so not sure if there's any work being done there compiler side. Digging a little I at least found this crate: https://github.com/JelteF/derive_more I didn't vet it or anything, but from the looks of it it certainly would make these kinds of newtypes easier since you can `#derive` operator implementations instead of implementing them all manually.
/r/playrust my friend. Wrong subbreddit. 
Hi, is this position full-time only, or is working part-time an option at TagniFi?
&gt; x.py Strong agree. I feel like there have been overtures in the direction of making it better, but I haven't seen anything concrete. I still don't have a strong enough grasp of the build phases to be able to know even a little bit what needs to be changed. However, I also don't really understand why you need a fresh compiler build in order to compile the standard library. Aside from ensuring that you have a nightly compiler, shouldn't the standard library be treated just the same as any other library? If so, there shouldn't really be any issue building it separate from the compiler, right?
Yes! I'm very new to OSS as well, and my contributions have been pretty limited to fixing documentation. I've had nothing but support from the Rust community. When I did PR some code that the maintainer wanted done a different way, he just let me know and gave me a chance to fix it. In general, just make sure to run rustfmt and possibly clippy on your code. Specifically to rustfmt, there are their [contributing guidelines](https://github.com/rust-lang-nursery/rustfmt/blob/master/Contributing.md) and there is wg-rustfmt on Discord if you want to talk to people directly. 
Is this a demonstration of trait-guided, generic monomorphization? Could you post your code?
Bingo. I was used to the old default behavior that `cargo new` produced a library, and `cargo new --bin` produced a binary. Didn't even notice my file was `main.rs`. Thanks!
I like D's syntax: oh!(wo, is)(me) However, this conflicts with macros... I can't really think of anything else reasonably common that won't be ambiguous, so I guess I'm satisfied with the syntax as is.
I think I actually have a use case for that :)
FNV is for a fast (non cryptograhic) hash function.
Context: Hi, I almost finished my first [program](https://github.com/martinber/noaa-apt) in Rust and gtk-rs. I do all my development on Linux. Now I'm trying to cross-compile for Linux and Windows. I was able to cross-compile to Windows succesfully, with GTK bundled and all!. Question: I want to build a binary for Linux to share, so it should work in at least the most popular distros. AFAIK the recommendation is to build the target `x86_64-unknown-linux-musl` - I was able to build for `x86_64-unknown-linux-musl`, but I can't run it, when I run it I get `bash: ./target/x86_64-unknown-linux-musl/release/noaa-apt: No such file or directory`. Do I need to install something? I've installed `musl`, `musl-tools` and `musl-dev` - Should I target something else? I don't really know what static linking means, maybe I can target `x86_64-unknown-linux-gcc` and do something else. I tried to copy an executable built on the default target but I had problems with the libc version of the other computer I think. - I don't want to use the docker image [rust-musl-builder](https://github.com/emk/rust-musl-builder) but if I don't have another option I will try it. Just in case: ldd target/release/noaa-apt linux-vdso.so.1 (0x00007fff06bee000) libgtk-3.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libgtk-3.so.0 (0x00007f4b2fff0000) libgdk-3.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libgdk-3.so.0 (0x00007f4b2fcfa000) libpango-1.0.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libpango-1.0.so.0 (0x00007f4b2fab5000) libcairo.so.2 =&gt; /usr/lib/x86_64-linux-gnu/libcairo.so.2 (0x00007f4b2f798000) libgio-2.0.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libgio-2.0.so.0 (0x00007f4b2f3fa000) libgobject-2.0.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0 (0x00007f4b2f1a6000) libglib-2.0.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libglib-2.0.so.0 (0x00007f4b2ee8e000) libdl.so.2 =&gt; /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f4b2ee89000) librt.so.1 =&gt; /lib/x86_64-linux-gnu/librt.so.1 (0x00007f4b2ee7f000) libpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f4b2ee5e000) libgcc_s.so.1 =&gt; /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f4b2ee44000) libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f4b2ec87000) /lib64/ld-linux-x86-64.so.2 (0x00007f4b30a04000) libm.so.6 =&gt; /lib/x86_64-linux-gnu/libm.so.6 (0x00007f4b2eaf1000) libgmodule-2.0.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libgmodule-2.0.so.0 (0x00007f4b2e8ed000) libpangocairo-1.0.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libpangocairo-1.0.so.0 (0x00007f4b2e6e0000) libX11.so.6 =&gt; /usr/lib/x86_64-linux-gnu/libX11.so.6 (0x00007f4b2e3a2000) libXi.so.6 =&gt; /usr/lib/x86_64-linux-gnu/libXi.so.6 (0x00007f4b2e192000) libXcomposite.so.1 =&gt; /usr/lib/x86_64-linux-gnu/libXcomposite.so.1 (0x00007f4b2df8f000) libXdamage.so.1 =&gt; /usr/lib/x86_64-linux-gnu/libXdamage.so.1 (0x00007f4b2dd8a000) libXfixes.so.3 =&gt; /usr/lib/x86_64-linux-gnu/libXfixes.so.3 (0x00007f4b2db84000) libcairo-gobject.so.2 =&gt; /usr/lib/x86_64-linux-gnu/libcairo-gobject.so.2 (0x00007f4b2d97b000) libgdk_pixbuf-2.0.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libgdk_pixbuf-2.0.so.0 (0x00007f4b2d955000) libatk-1.0.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libatk-1.0.so.0 (0x00007f4b2d72f000) libatk-bridge-2.0.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libatk-bridge-2.0.so.0 (0x00007f4b2d4fd000) libxkbcommon.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libxkbcommon.so.0 (0x00007f4b2d2bb000) libwayland-cursor.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libwayland-cursor.so.0 (0x00007f4b2d0b3000) libwayland-egl.so.1 =&gt; /usr/lib/x86_64-linux-gnu/libwayland-egl.so.1 (0x00007f4b2ceb1000) libwayland-client.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libwayland-client.so.0 (0x00007f4b2cca2000) libepoxy.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libepoxy.so.0 (0x00007f4b2c9a1000) libpangoft2-1.0.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libpangoft2-1.0.so.0 (0x00007f4b2c78c000) libfribidi.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libfribidi.so.0 (0x00007f4b2c76d000) libfontconfig.so.1 =&gt; /usr/lib/x86_64-linux-gnu/libfontconfig.so.1 (0x00007f4b2c52a000) libfreetype.so.6 =&gt; /usr/lib/x86_64-linux-gnu/libfreetype.so.6 (0x00007f4b2c275000) libXinerama.so.1 =&gt; /usr/lib/x86_64-linux-gnu/libXinerama.so.1 (0x00007f4b2c072000) libXrandr.so.2 =&gt; /usr/lib/x86_64-linux-gnu/libXrandr.so.2 (0x00007f4b2be67000) libXcursor.so.1 =&gt; /usr/lib/x86_64-linux-gnu/libXcursor.so.1 (0x00007f4b2bc5d000) libXext.so.6 =&gt; /usr/lib/x86_64-linux-gnu/libXext.so.6 (0x00007f4b2ba49000) libthai.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libthai.so.0 (0x00007f4b2ba3e000) libpixman-1.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libpixman-1.so.0 (0x00007f4b2b798000) libpng16.so.16 =&gt; /usr/lib/x86_64-linux-gnu/libpng16.so.16 (0x00007f4b2b763000) libxcb-shm.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libxcb-shm.so.0 (0x00007f4b2b560000) libxcb.so.1 =&gt; /usr/lib/x86_64-linux-gnu/libxcb.so.1 (0x00007f4b2b336000) libxcb-render.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libxcb-render.so.0 (0x00007f4b2b128000) libXrender.so.1 =&gt; /usr/lib/x86_64-linux-gnu/libXrender.so.1 (0x00007f4b2af1e000) libz.so.1 =&gt; /lib/x86_64-linux-gnu/libz.so.1 (0x00007f4b2ad00000) libselinux.so.1 =&gt; /lib/x86_64-linux-gnu/libselinux.so.1 (0x00007f4b2aad8000) libresolv.so.2 =&gt; /lib/x86_64-linux-gnu/libresolv.so.2 (0x00007f4b2aabf000) libmount.so.1 =&gt; /lib/x86_64-linux-gnu/libmount.so.1 (0x00007f4b2aa61000) libffi.so.6 =&gt; /usr/lib/x86_64-linux-gnu/libffi.so.6 (0x00007f4b2a858000) libpcre.so.3 =&gt; /lib/x86_64-linux-gnu/libpcre.so.3 (0x00007f4b2a7e4000) libdbus-1.so.3 =&gt; /lib/x86_64-linux-gnu/libdbus-1.so.3 (0x00007f4b2a791000) libatspi.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libatspi.so.0 (0x00007f4b2a55f000) libharfbuzz.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libharfbuzz.so.0 (0x00007f4b2a4a9000) libexpat.so.1 =&gt; /lib/x86_64-linux-gnu/libexpat.so.1 (0x00007f4b2a277000) libuuid.so.1 =&gt; /lib/x86_64-linux-gnu/libuuid.so.1 (0x00007f4b2a26e000) libdatrie.so.1 =&gt; /usr/lib/x86_64-linux-gnu/libdatrie.so.1 (0x00007f4b2a066000) libXau.so.6 =&gt; /usr/lib/x86_64-linux-gnu/libXau.so.6 (0x00007f4b29e62000) libXdmcp.so.6 =&gt; /usr/lib/x86_64-linux-gnu/libXdmcp.so.6 (0x00007f4b29c5a000) libblkid.so.1 =&gt; /lib/x86_64-linux-gnu/libblkid.so.1 (0x00007f4b29c08000) libsystemd.so.0 =&gt; /lib/x86_64-linux-gnu/libsystemd.so.0 (0x00007f4b29b7b000) libgraphite2.so.3 =&gt; /usr/lib/x86_64-linux-gnu/libgraphite2.so.3 (0x00007f4b2994e000) libbsd.so.0 =&gt; /lib/x86_64-linux-gnu/libbsd.so.0 (0x00007f4b29737000) liblzma.so.5 =&gt; /lib/x86_64-linux-gnu/liblzma.so.5 (0x00007f4b2950f000) liblz4.so.1 =&gt; /usr/lib/x86_64-linux-gnu/liblz4.so.1 (0x00007f4b292f2000) libgcrypt.so.20 =&gt; /lib/x86_64-linux-gnu/libgcrypt.so.20 (0x00007f4b28fd6000) libgpg-error.so.0 =&gt; /lib/x86_64-linux-gnu/libgpg-error.so.0 (0x00007f4b28fb4000) 
The most stable right now is probably [rust-openssl](https://github.com/sfackler/rust-openssl) which is rust bindings to the systems C openssl library. There's also [ring](https://github.com/briansmith/ring), which is a mix of Rust/C/Assembly. I think there are Rust only implementations libraries, but I don't any are considered hardened enough or don't run on stable. One issue is that constant time functions (to avoid timing attacks) often require assembly, and inline assembly is only in nightly Rust. 
It's the only crypto related crate that hyper/h2 depends on according to crates.io so...
&gt; already functional on Nightly What's preventing it from adding it to the releases then? Looks like it is in Nightly for 1.5 years by now...
I think the issue is primarily that libraries are the wrong layer to add backtraces/etc. What I want is something equivalent to what we have with exceptions- let a debugger break on any error return, filtered by error types and variants. And any hook that enables that functionality could also be used to take a backtrace, do debug logging, etc. without inserting itself into a program's source code the way any library solution must.
What are you trying to achieve? Sometimes the scope of a project is just too big.
`struct.0` is the first 'anonymous' field. 
Thanks for working on Rustfmt! It's totally fine to open a PR to get feedback, just be explicit that that is what you are doing. I have a massive backlog of PRs right now because of Rustconf, but I'll get to yours soon.
That would not work. In general, if `a` is defined after `b`, it can depend on `b`. And if `b` were dropped before `a` bad things would happen. As a trivial example, OP's second version would not work: { let bar = 5; let foo = &amp;bar; }
It might be useful to have some type of tool which can report the average age of code based on git blame. You could try to find the oldest files, functions, maybe even types.
Hi, I'm a bot that links Gyazo images directly to save bandwidth. Direct link: https://i.gyazo.com/70d83c6ef130fd8988f18d807d5e4a6f.png Imgur mirror: https://i.imgur.com/7pnBfpC.png Direct link: https://i.gyazo.com/70d83c6ef130fd8988f18d807d5e4a6f.png Imgur mirror: https://i.imgur.com/yzXXyzx.png ^^[Sourcev2](https://github.com/Ptomerty/GyazoBot) ^^| ^^[Why?](https://github.com/Ptomerty/GyazoBot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/u/derpherp128) ^^| ^^[leavemealone](https://np.reddit.com/message/compose/?to=Gyazo_Bot&amp;subject=ignoreme&amp;message=ignoreme)
Is this 2011?
I’ve been using this crate and shrinkwraprs heavily whenever I need to wrap something. It’s great.
This means you were trying to index into an array past its last element, for example: let my_arr = [0, 1, 2, 3]; let my_val = my_arr[4]; Remember that array indices are zero-based, so the valid indices here are 0 through 3. Without seeing your code it's impossible to say more than that.
 #![cfg(not(windows))] meme
H2 doesn't handle crypto, since TLS is listed as a non goal in it's readme. The thing using H2 (like hyper) can add crypto.
C++ has features that make it nicer as an application programming language, but if you're trying to learn low level programming, C is better just because there's less to learn. C++ literally requires you to know more stuff to be productive, plus it has a bunch of concepts that don't map very well to assembler, making it monotonically less approachable. C++ is better for the long-term maintenance of large code bases, but if the question is "which one's better for long-term maintenance", then the answer to that question is: Rust.
No, because it has a bunch of unstable features. Iterator needs to hook into `for` loops, and Box needs to have deref-move turned on, and `size_of` is completely implemented in the compiler, and auto traits like `Send` and `Sync` are unstable, and I think specialization is used in a few spots even though it's also unstable, etc.
[removed]
Looks like my synchronous code that I ported to asynchronous futures could be revived with async await syntax. I hope that futures isn't ever deprecated...
Okay, i'm not too sure what to do then. Here is my code: &amp;#x200B; extern crate rand; use rand::Rng; use std::io::stdin; fn displayWord(correctGuess: &amp;\[char\]){ let mut currentWord = String::new(); for x in 0..5 { println!("test"); currentWord.push(correctGuess\[x\]); } println!("Current guesses: {}", currentWord); } fn main() { let mut isRunning: bool = true; 'outer: loop { let w1 = vec!\['m', 'o', 'm', 'm', 'y'\]; //the answer let mut guessedLetters = vec!\[\]; //the current correct guesses Vec&lt;char&gt; let mut userGuessedRight = false; let mut maxWrongGuesses: i32 = 0; let mut howManyRights: i32 = 0; println!("Guess a Character"); loop { let mut line = String::new(); let input = stdin().read\_line(&amp;mut line); //the guess let char\_vec : Vec&lt;char&gt; = line.to\_string().chars().collect(); for x in 0..5 { if line.chars().nth(0) == Some(w1\[x\]) { guessedLetters.push(line.chars().nth(0).unwrap()); displayWord(&amp;guessedLetters); howManyRights += 1; println!("You guessed {} characters correctly", howManyRights); userGuessedRight = true; } else if line.chars().nth(0) != Some(w1\[x\]) { println!("Not available {} ", maxWrongGuesses); userGuessedRight = false; if maxWrongGuesses == 7 { println!("You lose!"); break 'outer; } } } if userGuessedRight == false { maxWrongGuesses += 1; } } } } &amp;#x200B; &amp;#x200B; &amp;#x200B; 
LMAO sorry
It's up to the code that defines the struct. If the field is anonymous, then you can't access it. If it's public, then you can and there shouldn't be a problem with it.
In a sane community just open a PR and ask for help.
You can write c style code in c++ no problem, you can't say it requires you to know more stuff to be productive; in reality, c++ allow you to learn more effective techniques and concepts with things like oop or the stl for example, but that is by no means required. However I agree with your final deduction of rust for long term maintenance. 
This CVE is misleading. There was not a buffer overflow in `std`: there was an API that could be used to create a buffer overflow. This is a bug, since Rust guarantees that safe APIs cannot be used to create buffer overflows, but it is not the same as having a buffer overflow "in" `VecDeque::reserve`.
Edited post \^\^
C++ decided to use angled brackets for its templates, which sounded fine, as this wasn't used anywhere, unlike `[]`, `{}` and `()` which are used elsewhere. Oh wait they are used as operator symbols for comparisons `&lt;`, `&gt;`. This leads to ambiguous parsing, which can be taken one or another way: (T &lt; a, B &gt; (c)) Is that `(T&lt;a), (B &gt; (c))` or `(T&lt;a, B&gt; (c))`? We could maybe guess knowing what exactly each value is but this is expensive. And sometimes we can't know, there's things that can be both a type and an instance, such as `()` and static function names. Different languages have solved this in different fashions. Many functional languages simply use `[]` for generic/macros instead, but outside of these languages `[]` almost always refers to lists. D uses `!` to begin it's functions but that's used for macros and there's a desire to separate between macros (which write code uniquely) and generics (which simply give you a different item), that is there's no guarantee that `T!(X) == T!(X)` but we can guarantee that `T::&lt;X&gt; == T::&lt;X&gt;`, also macros were in a limbo that generics were not on the 1.0 days and it made sense not to mix that. So a compromise had to be made. The solution was that application of a generic template would be done through the turbofish `::&lt; &gt;`. This works well enough. I do agree though that it's a sign that probably we are not being consistent enough with code. IMHO generics, const fn and macros should all be the same things: a function that creates an output at compile time, and therefore should look alike. This point of view might be extreme, but we could look at generics and macros as the same thing: functions that generate instances of code automatically (with memoization). The first step would be to switch generic functions away from angled brackets into using `!()` as macros do (also as D does). I would still like for const fns to be able to use `!()` to enforce at call-time that their parameters are known at compile time, while the normal `()` would still work for any value, known at compile time or not. Once generics use the `!()` pattern, we can phase angled brackets, and turbo fish out. For now, as far as I can tell, without getting rid of angled brackets or comparison operators there's no way of getting rid of turbo fish without replacing it with an equal or worse kludge.
Can this class be taken online?
You can impl Deref, Borrow and AsRef, which should cover all needs at callsite.
Yea I think you're on the right track. Where does it show up though? I added the following to my cargo.toml file (its different because my example depends on my crate) but I can't find the docs, neither online or when checking \`target/doc\` \`\`\` \[\[example\]\] name = "my\_example" \[example.dependencies.my\_crate\] path="../my\_crate" doc=true \`\`\`
Maybe use a procedural macro like `#[foo_plugin]` on the struct which will automatically generate the functions. If they use it more than once, it will error with redefined function.
Most of the acronyms are explain in much earlier blogs, but if you follow the github [https://github.com/tikv/tikv](https://github.com/tikv/tikv) you can find more info on it. I think the author was correct in not rewriting the definitions to the acronyms since those who have interest would dive a little deeper.
Alright, I got it working but now my executor never returns from run. Instead I just sit and wait in the `receiver.recv()` for another task that'll never come. My solution was to mem::drop the spawner to close the channel. Is there a better way to do that though? I dunno, even the safe std::mem functions seem hacky to me. https://gist.github.com/robert-snakard/60e7c13480fd39174deaee3648553f6b
!remindme 24 
**Defaulted to one day.** I will be messaging you on [**2018-08-23 02:24:33 UTC**](http://www.wolframalpha.com/input/?i=2018-08-23 02:24:33 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/rust/comments/998etj/upenn_rust_programming_course_this_fall/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/rust/comments/998etj/upenn_rust_programming_course_this_fall/]%0A%0ARemindMe! 24 ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
The use case is a crc algorithm which performs both wrapping mult and bitwise exclusive xor, I'm porting code from c to rust
Welcome to reddit! Please make sure that you check the description of the subreddit before posting. You wanted /r/playrust, this is the subreddit for the rust programming language.
So we did it that it wouldn't close for this. It'll just keep waiting. We mentioned it in the class but not the code comments. So as long as you ctrl-c you should be fine here.
I think that’s it. When I’m learning other languages I tend to feel comfortable a lot quicker then when learning rust. It forces a lot on you right out of the gate.
Thanks for pinging me. I created a ticket and will do that tomorrow morning.
Ah, looks like a bug. If you'd like, you can file an issue at https://github.com/rust-lang/cargo/. As an alternative, I know some projects put examples into separate projects (either in the same directory, or as part of a workspace). 
Most of the FCP/RFC GitHub links seem to be to \`api.github.com\` instead of \`github.com\`
I recently ran into a problem with not being able to perform bit wise operations on wrapping values. I would like to add this functionally but have no idea where to start so I was hoping someone could point me in the right direction.
As a beginner I write a simple ratio calculator 🙈
Sorry for the confusion. What I mean is, is there any particular reason behind this reverse ordered value destruction in Rust? I mean the thought process on the design, not how it works (because the one I first replied to already explained it). 
That just shifts the potential ambiguity from the less-than operator to the indexing operator. `foo[bar](baz)` is already valid syntax.
I mean, that’s exactly the reason. It *must* be reverse order, otherwise the most natural way to write code could not work. If `b` depends on `a` then `a` *must* outlive `b`. This is fundamental and not unique to Rust either.
Using `[Type]` as in Scala wouldn't have worked, because if you wanted to call a function stored in a vector `foo` at index `bar` you'd already be writing `foo[bar]()`, which is just as ambiguous without something like the hypothetical `foo::[bar]()`
\+1 for mentioning the book. I love how the author explained things deep down to the metal. 
If I recall correctly, those are defined in `src/libcore/nun/wrapping.rs` (on mobile right now). Feel free to pm vor comment if you have any further questions.
Thanks, I am reading the rust book now, it would be great to have someone teach it to me.
Writing a bluetooth 5 driver for use with futures, but I have a long way to go as I've only got the basic HCI commands for LE implemented. Unfortunately, I don't expect this to get done for a quite a while (especially for BR/EDR) since most of the driver is from scratch.
I see, thanks for the handsup. Originally, I though this was the definition of an alias type.
You don't need to rebuild the entire compiler if you are just making a change to libstd. `x.py test --stage=0 --no-doc src/libstd` will just build and test std. Rebuilding with a small change takes about 10s for me (incremental and codegen-units might help, too). (Just beware there is a [bug](https://github.com/rust-lang/rust/issues/50481) that requires removing some files first.)
Do you already have a repo up?
There is no parsing ambiguity, only lexical one as in parser you can treat both of them the same way. Additional pro is the fact that Vim matchit plugin is working better. 
 I have run into the same problem, except with a different project (I'm storing a large number of blockchain transactions on disk), although the general concept is the same. I've been looking for some library for direct binary storage, but haven't found one. so far i've been using https://github.com/TheNeikos/rustbreak that and it's been working OK. Im definitely interested in what anyone else has used, though.
The solution would be to use parenthesis for indexing
As a beginner I'm working on a chip8 emulator. It was nearly finished. Some cleaning up is ongoing. So I'm wondering if you guys can give suggestions on my next side project in Rust (as a beginner). Any feedback will be appreciated :)
I'm not really speaking from experience, but I've noticed on other PRs I've seen that maintainers often ask for the PR to include a test, to make sure the bug does not reappear in future versions. This is a good practice in general, so if you don't have such a test yet it's probably a good idea to make one.
Cheers, as someone who has been slacking off at finding time to continue learning Rust, maybe this will give me a swift kick in the butt....I mean motivation. 
Sorry, this would be one of the first times I've contributed to open source, what would the process be? Fork the repo, make changes then pull request? ​ Edit: Actually, found this [https://github.com/rust-lang/rust/blob/786ccc336dc684cdb00402e84abe4a9bc53857cf/src/libcore/num/wrapping.rs#L262](https://github.com/rust-lang/rust/blob/786ccc336dc684cdb00402e84abe4a9bc53857cf/src/libcore/num/wrapping.rs#L262) &amp;#x200B; Now I'm wondering why it didn't work for me? Am I missing something obvious?
The only way that you could treat both of them the same way would be if you were content to not be able to distinguish whether `bar` was an expression or a type by the time the parsing phase was done, which would be an undesirable situation akin to C's lexer hack.
That would introduce a new ambiguity by way of no longer being able to identify whether `foo(bar)` indicated an invocation the `Index` trait or one of the `Fn` traits.
Interesting thanks, will look into it in more detail later. Aren't you modifying the "wrong" calendar?
I ám interested in this, even the dumpster fire version. Just to look at the examples.:)
That might be the case. Can you copy your code to a [playground](https://play.rust-lang.org) so we can have a look at it?
Here you go: https://play.rust-lang.org/?gist=ecd950cc73f634dd229710ac1e81122b&amp;version=stable&amp;mode=debug&amp;edition=2015 There's a couple of things wrong with it (assign of Wrapping back to u8) but the main error is the first one about not being able to do ^=
It's untested and you are probably right that I'm shadowing there. The other calendar is mutable so it should be possible to do something similar without shadowing
Thanks, I didn't even think of writing to the formatter directly, and I didn't know about `repeat().take()`, very cool!
I'm glad you found it fun, and thanks for sharing your implementation!
If matrices are static, my first thought is to concatenate all serialized matrices into a huge binary blob and create an index (start, end), which can be stored in a separate file, hardcoded, or can be part of the same blob. Now you can [memmap](https://crates.io/crates/memmap) this file, and when you need a matrix you'll simply slice `&amp;[u8]` for further decoding. OS will handle loading/freeing data from the file for you.
So that makes UVirginia, UMaryland, and now UPennsylvania. Any other schools? If not, good job, eastern USA!
They also support lifetime constraints. Since const generics are not implemented yet, they don’t support const... but there is no reason they couldn’t once const generics become implemented. I guess someone would just have to write an RFC for that.
Thanks for the advice and your work on Joinery! I see what you mean about a stateless die, I'm not really reusing it anyway. Time to roll up my sleeves and get more acquainted with traits.
Yeah, go open it ! A PR is just work in progress asking for reviews. So don’t overthink it, it will mature over time :) It’s responsibility of reviewers to accept it as-is or to request changes. Or to dismiss it. If you make “mistakes” in opening a pull request, it will hint them that their documentation might have some clarity problems, so you already helped them ! In case you’re really worried about doing this overthinking right.. : But it’s responsibility of the PR maker to make it as clear as possible : to do so, I have a somewhat unofficial checklist I try to fit in : - Does the project have a contributing file ? Read it. - Does the project have other pull requests ? Read some - explain how the idea of making this pull request occurred to you : a bug, a feature, a specific use case ? - if related to code, if you cannot/don’t know how to add a test suite, try to link to source code of a minimal reproduction case. - If you thought about problems about your proposition, list them. If you think you lack knowledge in something and it’s impeding you from making a better PR, write about it, someone might help you, or do it instead of you, either case, it’s positive. - If you thought about alternatives but dismissed them, list them. - that’s a lot of informations, put some titles and formatting. - you can self review your changes to comment specific details if need be. More specific to code: - The project definitely has commits, try to mimic them. - The project has some code, try to mimic it - Think about impact on existing stuff, how examples might be affected, tests, API, end users, other developers... Last one: - Don’t follow my guide, just open that PR, without thinking too much, *they* will tell you what to do! 
With an `&amp;uninit T` type you are throwing away all information about what parts are uninitialized, which means it's still impossible to build up your `T` in other methods. Unless you force a function that receives `&amp;uninit T` to initialize it completely the compiler only knows that your `T` was uninitialized before the function call, and that it's possibly uninititialized after the function call, so it still has to treat it as uninitialized.
Wow, that's a lot of great feedback, thanks! I'm going to be mulling over these for a while.
Here's some other cool alternatives from the neverending supply of Japanese bracket arsenal:（）, ｟｠, ［］, 〚〛, ｛｝, 〔〕,〘〙,〈〉, 《》, 「」, 『』, 【】, 〖〗
Is there a similar way to rebuild just libstd and use it to compile rust apps? Things involving syscalls and user interaction need to be tested manually. 
No one wants to spend that much time recompiling rustc.
failed to compile :/ "error\[E0599\]: no method named \`description\` found for type \`()\` in the current scope" "error\[E0277\]: the trait bound \`(): std::convert::From&lt;std::io::Error&gt;\` is not satisfied"
https://github.com/cmr/this-week-in-rust/pull/696
Trying to learn Rust.
Like /u/fpgaminer said, `derive_more` is great. When custom derive doesn't work, there's an RFC for [Delegation](https://github.com/rust-lang/rfcs/issues/2393) that'll start moving again once Rust 2018 has shipped. 
Thanks for starting some work on this! So this is about reviewing a project's code? What about release packages — do these inherit code reviews? I feel they deserve some kind of special attention, but don't have an idea for how that could work. I guess an extension that may eventually be wanted would be a restriction to Cargo to *only* use reviewed dependency releases.
This doesn't answer your question, but I would consider an alternative uploading scheme where the client POSTs directly to S3. This can be done with [presigned URLs](https://docs.aws.amazon.com/AmazonS3/latest/dev/PresignedUrlUploadObject.html) It usually ends up being faster than going through your server, and of course it saves the resources that would have been used for relaying it.
What does it do?
I don't think so? As far as I'm aware, 1.29 has already been branched off, so this will hit stable as part of 1.30.
Isn't it possible to prevent implementing both trait?
&gt; I definitely don't want a separate file for each matrix. Out of curiosity, why not? "serialize each matrix separately and keep track of its offset, and put that somewhere in the file" is basically describing a very simple filesystem, so why not just use the one that the OS already provides? I don't know how big "a large number" of matrices is, but `ext3` and `ext4` keep an index of files in each directory so accessing a file by name is fast even with thousands of files in a directory, and even without that feature it's pretty easy to make a directory structure that will let you quickly access a million files by name.
Attaching a tag of approval to package content/version is only one step, the Rust program dependency on a zillion crates and its infrastructure also brings other known problems: https://www.theregister.co.uk/2016/03/23/npm_left_pad_chaos/ For software development the approach of defined, reproducible builds needs to be a first class citizen and supported by the tools. That means I have a certain set of compiler, rust crates, and my program, and I can check that I use and setup the exactly same setup again and again to obtain the same output. With the modern "always on" availability of internet development it is all too often a "sudo curl ... | sh", then install "current" dependent packages as they are available at that point in time, and then build and ship. That's insanity, auditability is something many developers maybe not care about, but it's an important feature that needs to be a core value of the ecosystem. a) setup a dev environment, b) be able to identify what pieces are in there, c) be able to check each download first if it is the correct one before using/executing it, d) be able to reproduce the dev environment with all its dependencies solely from locally downloaded packages, without an active internet connection, maybe also years later 
web-view uses 3 different browser engine for each of the 3 major OS. Electron, still have advantage of letting developers use webkit-only specific features, and not worry about how their apps might look with the other browser engine.That's why web-view is slim because it doesn't bundle a specific browser engine with it. It just uses the OS stack browser engine.
You can also intercept the fetch and ajax calls, and delegate the call to the rust app instead using stringified json, without actually using a server.
Yes please. If it could make a tree out of it or even better an upgrade plan it'd be awesome !
One idea would be let x = loop { // Do somethint if let Some(z) = my_option { break z; } } // Do something with x
Developing a graph partitioner in Rust for my bachelors thesis. 
I recently discovered GitHub's [improved issue flow](https://github.com/yoshuawuyts/github-templates/issues/new/choose), and thought it'd be useful to create a tool that can help you generate the boilerplate needed to enable it. I hope this comes in useful for someone!
Oh yeah I read you could return values from loops, but not for and while. &amp;#x200B; This looks a bit better thx.
Why avoiding `String` as error type?
My two cents on the topic. Sounds a little ranty, but that's not my intention (the limitations of the written word): So far I've written 5k lines of Rust at work and some more for private projects, and never ever did it even cross my mind that `Result&lt;_, MyErrEnum&gt;` was not fullfilling all of my error handling needs. Rust already comes with, imo, the best error handling a programming language can have, out of the box. To me, `failure` just looks like a placebo bandaid for imaginary wounds. It doesn't appear to solve any actual problems. I seriously cannot imagine a single situation where it would be benefitial over vanilla error handling. But hey, maybe I just don't get it. The nail in the coffin for me though, is that `failure` poisons crates. If one of your dependencies uses `failure::Error`, you also have to use it, if you want to or not (citation needed?). So it spreads.
One very esotheric way to achieve that would be to allow dependant crates write and run test suites easily to test if the dependancy still conforms to their expectations. The motivation to write those test would rise with the usage of each dependant or dependency crates, and if the dependency is withdrawn or mis-managed, a lot of knowledge will be retained regardless of original code. It would also allow crates authors to have a hint of the breakage theirs changes might bring. 
What are some things that Esqueleto can do that Diesel can't? Btw, how fast is Haskell's fastest web server (warp?) compared to actix-web? I'm interested in trying Haskell for server development (have been using PureScript in the frontend and Rust in the backend so far)..
For me, the advantage is to automagically bubble deep down errors up to the users while keeping the context.
Sorry, you're looking for /r/PlayRust. This sub is about the programming language!
I'm not really working on it anymore (although I have another feature in mind that needs a bit more preparation), but I wrote a brainfuck interpreter: [rustf_ck] (https://gitlab.com/rnxpyke/rustf_ck)! It can run brainfuck code and emit corresponding c or rust code that can then be compiled with gcc / rustc -O respectively. And it does all that with no dependencies exept the standard library. Currently it is hard-coded to interpret eof as -1 and you only have acess to 30000 cells and I don't plan to change that, but other than that suggestions to improve my code are very appreciated. 
I really really like this proposal, but there is one part that sets alarm bells ringing for me: (I'm on my phone, so paraphrasing - I'll insert the actual quote from my desktop) &gt; The review is separate from the code, so to stop maintainers silencing negative reviews, users should be able to host their own reviews in "empty" repositories separate from the source. I (personally) think that this is a recipe for disaster, and a potent harrassment tool. Consider, for example, a developer D who has created a well used, but under examined tool. It would be a simple matter for a group of users U (who are opposed to D in some way) to independendently verify each other (thereby increasing their trustworthiness/reputation), and then publish multiple negative reviews of D's work. I would suggest that reviews should only ever be a *positive* marker for a repository, or at worst, a neutral marker. A lack of reviews should (I think) only signify that the code *cannot be recommended*, be that due to lack of exposure, or due to poor code quality.
&gt; I'm not sure how it could break in the future, If e.g. `cargo test` would start trying to run your tests under miri to catch undefined behavior, then miri would panic when you create a reference to uninitialized memory. We could actually even add checks for this in the compiler in plain normal debug builds since undefined behavior means we are allowed to do anything, including, just panicking. That is, you might have to disable all of that machinery (and loose undefined behavior checking) just because you designed your code under the assumption that this particular form of undefined behavior was never going to be a problem. It might not end up being undefined behavior in the end, but doing that is a breaking change at this point since the Rust reference specifies that if you get an `&amp;T`, then the value behind it is always properly initialized, so people writing functions can rely on that. If we change it, we would change it so that you can have an &amp;T to an uninitialized value, but that the value must become initialized before leaving the scope (e.g. because you pass it to another function), which also applies to methods. So I am very skeptical that this will ever be defined behavior for your use case :/ 
&gt; someone had written a cargo helper which would automatically obey a metadata file provided by the project which acts as a lockfile for toolchain versions. [`rustup` supports this natively.](https://github.com/rust-lang-nursery/rustup.rs/blob/master/README.md#the-toolchain-file)
Thanks for your feedback! What would be an alternative to `Result&lt;R, String&gt;` when I just want to keep an error message and not the full error? I know, I could implement `Error` or use something like `error-chains`, but that seems overkill since I really can't do anything about errors except reporting them to the user.
I recall seeing a generic project for authenticating packages against such attacks with the involvement of Tor project, but I cannot find it now for whatever reason. If it exists, it's worth a look.
Well nightly says feature proc_macro was stabilized in 1.29.
I did the same when I started with rust. My implementation is very simple, and you can find it [here](www.github.com/flofriday/tictactoe). If you want to make a better UI than I did you could check out [rustbox](https://github.com/gchp/rustbox) or [termion](https://gitlab.redox-os.org/redox-os/termion).
Even if the multiple negative reviews get published to spread FUD, the original code is still where it is, available for people to see. Of course, the onus is on the greater community to be vigilant and not just jump on the bandwagon with pitchforks in hand. Perhaps the negative bit could be replaced with suggest X improvements.
I think part of the problem is type inference. Often the code that determines types is written *after* your current line of code, so code completion has no way other than heuristics and guessing to work out what the results should be. You're basically back at Python-level code intelligence (ok maybe not quite that bad) and only two IDEs that I know of have even vaguely good code completion for Python, and that is after many many years. It's almost like you need an ML-based solution.
A tuple struct has the same ability to encapsulate as one with named fields.
Cool! Too bad the wellington meetup hasn't done anything in 2 years.
I used to think the same. My head would feel like it would explode after a while and I just didn't seem to grasp some of the concepts. So I let it rest a bit and tried again about a year or so later. In the meantime I had learned Elixir, no idea if that made a difference. I started reading the 2018 edition of the Rust book and so far so good, concepts seem to stick more with me this time around :).
I'd recommend https://github.com/ggez/ggez
Can conrod be used with ggez? &amp;#x200B;
But /u/parabol443 said above: &gt; And please, please, do not use Strings as error types [...] 
Trust bootstrapping is kinda hard IMO. WoT is fine. It would be best to centralize it a little by providing significant extra weighting to contributors to `rustc`/`libcore`/`libstd` etc. These are language/library stewards that deserve implicit trust.
Well then, the only remaining solution is to use ⌈ and ⌋ for indexing. Sorry, that's just the way it is, I don't make the rules
IMO, it's usually expected that a PR isn't perfect and there will be back-and-forth with the project maintainers to get it into a state that they will accept. It's also usually acceptable to open a PR when you're stuck and just need advice on how to get un-stuck. For those kinds of PRs, I usually make the PR title something like "[WIP] - Foo bar" so it's obvious that the PR isn't in a state that can be merged.
I'm doing the cs140e from stanford class assignments. They've been great fun so far. It took a few weeks to source the cp2102 usb-uart module they use in the class (the exact one) but I managed to find it on amazon. link for the interested: https://web.stanford.edu/class/cs140e/
congrats!
I think that maybe the point you are getting at is that `clz`'s "undefined behaviour" is not really the same as C's "undefined behaviour". With `clz` on 0, it might return any number sure, but no nasal demons. So it's entirely local reasoning, hence friendlier.
I would love a platform for easily hosting and disseminating the security review work already being done by the most professionalized members of the Rust community. Ideally what you want is to be able to trust reviews from people who actually have skin in the game. For example, I would only be interested in reviews/approvals done by or endorsed by Mozilla, the Tor project, Microsoft, selected other high-profile companies running Rust in production, people from various distro security teams, etc. Basically I think it would be best to cater to people who are already doing this work and doing it at a high level of professionalism, and make their job easier while sharing the benefits with the community.
While it might prevent mistakes, it will do little against intentionally malicious code.
&gt; All keywords and operators should be replaced with emoji. `(oh🐠&lt;woe, is&gt;(me))`
Thanks!
I think removing negative reviews _might_ be ok, but I don't think I buy the harassment bit. Assuming that this system integrates some kind of WoT facility, leaving bad faith reviews should have a high enough cost that they won't be effective. You'd need to be willing to invest time in garnering enough trust that your attack would be effective and be willing to burn that trust when it turns out that your review isn't justified. A community that can't defend itself from this kind of attack on this kind of system can't defend itself from similar attacks outside of this system (reddit comments claiming unsafety, github issues of the same kind etc).
It would definitely be good to weigh reviews by some some number of parameters. But I also think there are many different indicators of trust beyond big corps. The previously mentioned rust contributors, dedicated reviewers, etc. 
cargo install is still failing to compile: \`\`\` error\[E0277\]: the trait bound \`(): std::convert::From&lt;std::io::Error&gt;\` is not satisfied \--&gt; src/platform/unix.rs:6:18 | 6 | let result = Command::new("feh").arg("--bg-fill").arg(path).status()?.success(); | \^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^\^ the trait \`std::convert::From&lt;std::io::Error&gt;\` is not implemented for \`()\` | = note: required by \`std::convert::From::from\` &amp;#x200B;
&gt; Still great to see this happening. Yep!
Note that you _can_ do this today with the type system. See [typenum](https://crates.io/typenum). Const generics gives you the ability to parameterize arrays by constants and increases the ergonomics in all these other cases. That said, I eagerly await the arrival of const generics and the deprecation of typenum.
These are good points. The main reason I'd prefer one file is that the analysis will fail if any of the files are missing, and logically they're all one "thing". I feel having multiple files implies that they're not tightly coupled. The target audience is also expected to be novice computer users and simplifying the outputs of the application will make it easier for them.
Any material available for outsiders? 
This assumes that only community members participate in harassment. Across a certain threshold, there's enough people on 4chan that just join in for the fun, having maintainers deal with that. "Putting it on the community" is not a strategy, as long as you can't ensure the circle of people to hold responsible is well constrained.
Makes sense, I had not thought of that possibility.
Fuck, you are right.. The problem is that the compiler doesn't check these functions when compiling on windows. I will fix it this evening. 
From what I've experienced so far, I must say that I agree with you here. I posted this on the [Announcing Rust 2018 Preview 2!](https://internals.rust-lang.org/t/announcing-rust-2018-preview-2/8218) post, but I think it's worth reposting my experience here, as it somewhat got lost in all the other posts: \--- &amp;#x200B; As a (very) new Rustacean, it's awesome to see the speed at which the Rust community moves forward, while also still keeping backward compatibility in mind. I had one question about this quote: &gt;Both rustfmt and the RLS have reached 1.0 “release candidate” status. Look for more information about that soon. I'm eagerly awaiting the "more information" part, but until then, I wonder what "1.0" means for these tools, specifically for RLS. As a developer, I enjoy learning new programming languages (and especially the standard library) by exploring. Building small utilities in my editor, creating a variable of one type, and allowing code completion to guide me towards the capabilities of each type and how they function. In Rust, this hasn't been such a great experience so far, unfortunately. Specifically, RLS (and Racer) hasn't been able to complete quite some code that I've been playing with. Maybe it's just my set up, but from what I've read, I'm not the only one experiencing this, and this is because the compiler - for now - can't give RLS (all) the information it needs, having it fall back to the less accurate Racer, resulting in no code completion to show up at all, or a "goto" action going to a similarly named, but differently namespaced type. Specifically, here are two GH issues I replied to: * [https://github.com/rust-lang-nursery/rls-vscode/issues/338#issuecomment-412271590](https://github.com/rust-lang-nursery/rls-vscode/issues/338#issuecomment-412271590) * [https://github.com/rust-lang-nursery/rls-vscode/issues/391#issuecomment-413446850](https://github.com/rust-lang-nursery/rls-vscode/issues/391#issuecomment-413446850) The biggest problem with this is that it interrupts the workflow. When no auto-completion shows up, you start to wonder "did I do something wrong? Or is this an RLS issue? Should I report it, or is this known because of the lack of compiler support?" The next step then is to go open the (awesome!) Rust docs to find more information about that type and the methods it supports. So my question/remark would be: if my findings are accurate, and RLS isn't that reliable yet, what's the main reason to already move it to 1.0, instead of letting it bake a bit more until its reliability is high enough?
They're not robust and can't contain further info. An enum would be better.
I don't think this difference between capacity and cap is necessary. From what I can see, the difference is used here: fn is_full(&amp;self) -&gt; bool { self.cap() - self.len() == 1 } Where len is computed as `count(tail, head, self.cap())` with this function: fn count(tail: usize, head: usize, size: usize) -&gt; usize { // size is always a power of 2 (head.wrapping_sub(tail)) &amp; (size - 1) } If `tail` could become equal to `head` by appending elements, then this formula would incorrectly return `0`. Therefore, an element goes unused to distinguish `head == tail` because empty from `head == tail` because full. Funny thing is, I was just implementing a circular buffer today, and there's a difference choice, often used for atomic queues implementation: no wrapping. That is, instead of wrapping `head` and `tail` in `[0, self.cap())`, instead, let `head` and `tail` grow unbounded and simply apply `% self.cap()` (that is `&amp; (self.cap() - 1)`) to turn them into indices. With this configuration, the new definition of `len` is `head - tail`, and the new definition of `full` is `self.len() == self.cap()`. No shenanigan.
Because `NonZero*` are used for space optimisation (specifically, so that `Option&lt;T&gt;` is the same size as `T` for non-zero types), and there's nothing (that I'm aware of) for any other values. Zero is special because null references are special (in that they can't happen).
The insight, of course, is that `Index` would simply become a particular case of `Fn`. Indexing into an array is really just a function taking an array and an index and producing a value :)
Depends if you just want to display or to actually do something with it I assume.
I suppose since you can just do gfx-rs code along with ggez, you could just integrate it that way. 
The "adversarial" mindset is actually sometimes pretty explicit. \[Embedded in Academia\]([https://blog.regehr.org/archives/970](https://blog.regehr.org/archives/970)), one of the blogs linked a couple of times in the OP, is often quoted: \&gt; The point is that these problems are real, and they’re nasty because the problem can only be seen by looking at the compiler’s output. Compilers are getting smarter all the time, causing code that previously worked to break. A sufficiently advanced compiler is indistinguishable from an adversary. 
Does it mean that we have NonZero types just because they are implemented in the same way as NonNull?
I like the idea of "suggest X improvements" - it means that reviews always have to be constructive, focused on the code, qualitative and semantic - rather than a negative "score" that could be gamed. 
Can you show the code? The OP's code is creating the `Vec` with a capacity based on the file size, which should help even it out.
Sure, here it is: #![feature(test)] extern crate test; use test::Bencher; use std::fs::File; use std::io::Read; #[bench] fn read_to_end(b: &amp;mut Bencher) { b.iter(|| { let mut f = File::open("file.txt").unwrap(); let mut buffer = Vec::new(); f.read_to_end(&amp;mut buffer).unwrap(); println!("{:?}", buffer); }) } #[bench] fn read_sized(b: &amp;mut Bencher) { b.iter(|| { let mut f = File::open("file.txt").unwrap(); let mut s: Vec&lt;u8&gt; = Vec::with_capacity(f.metadata().unwrap().len() as usize); f.read_exact(&amp;mut s).unwrap(); println!("{:?}", s); }); }
Yes, that is almost certainly nothing to do with `read_exact` vs `read_to_end`, and everything to do with the pre-allocation. Also, I think you actually want `f.metadata().unwra().len() as usize + 1` to avoid a realloc.
&gt; I (personally) think that this is a recipe for disaster, and a potent harrassment tool. Consider, for example, a developer D who has created a well used, but under examined tool. `crev` model is not Yelp. It's more like PGP web of trust, when nothing is trusted by default. Anyone can produce as many reviews proofs as they want, but any user has to either directly, or by transitive trust, trust the IDs that signed review proofs. The community will build around reputation and trustworthiness, so attempts like that will be ultimately futile. 
All help is appreciated. :)
That's a good idea. Thanks!
Yes, it is almost certainly faster due to needing to only allocate once. But that is kind of the a good goal, isn't it? `read_to_end` has to re-allocate a lot, so if your goal is to "read this file to the end", since `read_exact` is going to be faster, I don't really see why one should use `read_to_end`?
Definitely listen to him. That was bad advice on my part. I do it because I'm still prototyping, but he is entirely correct. You should instead be more specific in your error enum. pub enum Error { ParsingError(FileName, ErrorDetails), IOError(io::Error), //etc. } Basically, only convert to a string when you're ready to display. The biggest benifit is that when you need to localize your errors to other languages you only have to fix it in one place. 
You could do that with `crev` if "professionalized members" were using it. Steps: * Create a repository `crev-rust-professionals` * gather and verify IDs of Rust professionals * sign them with your own ID * publish in the repo * maintain it with help of other users Now all the people that want to trust reviews by rust community professionals, can just include your repo on their dependency and sign your ID as trusted. Anyone can create their own repo, communities etc. and the ones that make sense and gain traction, will become widely used.
finally, it should compile. that being said i didn't have a chance yet to test is on an other os than windows so it may very well not work atm.
OP is asking about the type literally called `Wrapper`, not newtypes in general.
Well, if we're trying to give advice here, then you should probably just use `fs::read` instead of either of these. In any case, no, I would actually not recommend the use of `read_exact` here. Firstly, it is incorrect, because there is a race between the time you get the file size and allocate your memory and the time in which you actually read the contents of the file. Secondly, both routines require you to go out and pre-allocate based on the size of the file, so there's really not much ergonomic difference. So given that both are equally easy to call and given that `read_to_end` is correct and `read_exact` is not, I would choose `read_to_end` between them. But `fs::read` is both easier to use and correct, so it's the best of both worlds.
&gt;Also, I think you actually want &gt; &gt;f.metadata().unwrap().len() as usize + 1 &gt; &gt; to avoid a realloc. &amp;#x200B; Ok, this is really unexpected and a bad default behavior in my opinion! I thought a reallocation only happens when the buffer isn't big enough. How is this solved in C++ `std::vector`?
https://play.rust-lang.org/?gist=4bcfb418d893a978711064bbf53d0180&amp;version=stable&amp;mode=debug&amp;edition=2015 It's not always that `None` ends up being 0. For example, Option&lt;bool&gt; has a special optimization where Some(false) = 0 Some(true) = 1 None = 2 So I'm pretty sure that this is possible with a u32 as well. ^((This also means that if you're _really_ sure that you're not gonna get a `None`, you can unwrap it by transmuting, although how good of an idea this is, I'll leave as an exercise to the reader)^)
Yeah, it's not a Forge specific problem. I've seen the MIME type error somewhere for a different reason, but I can't seem to find a reference to it at the moment. The best thing that I can think of is one you already mentioned - use a custom protocol.
The plan is to have default per-language trust repositories, maintained by the `crev` project.
East coast is at least 3 hours into the future.