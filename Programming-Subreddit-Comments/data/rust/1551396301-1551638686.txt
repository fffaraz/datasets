I hear ya. I suspect I have a higher than normal frequency of need with Date Time structures over the past 7 years or so (backend web/app dev/consultant). They feel essential day in and out.
Human brain is an amazing organ that can autocorrect "but if a bummer" to "bit of a bummer" based on QWERTY keyboard layout where U, I, O are consecutive keys. :)
One of the issues they have is that console SDKs don't support Rust natively so it has to be hacked in. If that support comes it will be easier for game makers to pick rust.
Thanks for catching that!
Has anyone followed along with the write a toy OS blog and remembers the sections that required lazy\_static? Does this fix that?
It should [https://github.com/mvdnes/spin-rs/commit/7449733a84e06e67cb50a6d7803fb35cac3e02a6](https://github.com/mvdnes/spin-rs/commit/7449733a84e06e67cb50a6d7803fb35cac3e02a6)
Hmmmm...Thanks for bringing this up. I recently wrote a gui program in Rust using the `winapi` crate. Do you think this change will affect me? If so, any advice on what I should test?
How about: &gt; Can we use logical `and` (similarly, logical `or`) yet in const fn?
Did you skip The Book?
Just so everyone understands, this was as much a staffing decision as it was a technical one. I left Chucklefish in the middle of last year, which has a lot to do with this decision. My decision to leave had really nothing to do with anything technical, Rust or otherwise, and it was amicable, and we're still all friends etc (Chucklefish is a very small company, I still think they're all amazing!). It didn't make a lot of sense for them to continue without me involved, which made perfect sense to me. I don't want anyone to get the wrong impression from this decision re: rust's viability in game development. Don't get me wrong, I'm not advocating that everyone in game development should stop what they're doing and move immediately to Rust, far from it, I just don't think this decision should change your view at all really either way. There are other factors at play here. In order to use Rust for game development you have to be in a very particular situation re: tolerance for missing pieces and willingness to do some dirty low level work yourself, and also the kind of developer that doesn't really want to just use an existing huge technical stack like Unreal or Unity. It works for me, but it might not work for you, YMMV, etc. I still use Rust exclusively, but as I am the world's slowest game developer, I am not really ready to talk about anything I'm working on atm. Anyway, sorry for not being more forthcoming about this previously, it is a combination of 1) me being a very private person generally, and 2) not wanting to say more than I should have said about Chucklefish's plans regarding Witchbrook which were not my place to say publicly.
Reading as much as I can while doing. If I had to read from beginning to end before doing I think I may have never begun
Thanks for saying this. I'm quickly becoming a fan of you and your technical "stuff" (the talks you've given, blog posts, explanations of decisions, etc)! 
I tried to modify the closure to my needs, but didn't work. let iter = RightRecurseSplit::new(data, |source| { let split_pos = vec![5, 6]; // from splitclassifier let r = split_part_at_nth(source, ' ', split_pos[n]); n += 1; r }); But the last part is lost. The sentence: "I was having a decent day until I saw Elliott start crying here, which lead me to start crying as well." Must be split into: "I was having a decent day", "until I say Elliott start crying here,", "which lead me to start crying as well." A sentence like: "I am hungry" would be splitted at second occurrence of ' ' which returns None. Therefore no split.
Huh, how do you like that. I would probably accept a PR with that code. The idea of being able to switch between very lightweight and real shaping with a single feature is appealing.
It does; we had issues with the first cable. The laptop was on a chair behind myself, so it was facing the wrong way, and recording from a bad position: [Imgur](https://i.imgur.com/NnJMBjR.png)
Also feel free to file issues against skribo, where the immediate target is making a requirements doc. Vertical text is an interesting question, and I have to find out from the Servo people where that is on their roadmap. My guess is that it'll be part of the design but probably get low priority in the initial implementation. I'll be working out the types, skribo probably won't by itself give you the outlines, but definitely will interface with the font loading code and renderer to connect access to the glyph shapes. Again, variable fonts complicate this. Another somewhat intimidating document is the [W3C recommendations for Japanese text layout](https://www.w3.org/TR/jlreq/). It's a great document, the first time all that has been captured in English, but there's a *lot* of stuff in there.
That's very kind of you to say, thank you so much! I don't feel like I've done very *much* publicly, but when I do I've gotten really good feedback, so I'll try to do more! *goes off to actually work on finishing next blog post*
Yeah. I wouldn't bat an eyelash if someone referred to tools like ack and ripgrep as grep alternatives and they're certainly not drop-in replacements.
I haven't tried to set up DNSSEC. It's worth asking, I get the impression actual people work on their support desk, unlike Google. (There, it's an instance of AlphaGo, so they may or may not be able to help with your DNS problems, but can play a mean Jōseki).
With \`Pin&lt;T&gt;\` are we now able to have a \`struct\` which contains a \`CharIndices&lt;'a&gt;\` and its original \`String\`? struct Please { input: String, indices: CharIndices&lt;'?&gt;, } &amp;#x200B; I really need an owning \`CharIndices\` but I just can't figure out the way to do it. 
That is just not a helpful comment. Someone a few weeks into using a language has not had enough time to completely internalize every single feature covered in the book.
Wasn't that always possible using tuples? 
I was wondering if he read it at all or just went with tutorials and stackoverflow. The book is a great shortcut into getting an explanation of what the language is and why it's like that.
Could also just be? "logical AND and OR"
Small suggestion about the syntax: round brackets for co_sort!() would be more natural. If it can be a function it should be a function. But it supports arbitrarily many arguments, so that would be the next best thing.
The compiler doesn't make any difference if you call a macro with ( ), \[ \] or { } use the one you prefer.
There's a panic since the closure is called three times but split_pos only has 2 values. Here's one way to fix it. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1e4d9c95fe2e8960b02217443effd2cd
Good server no chap
[208.167.235.148](https://208.167.235.148) this is the server ip if you aren't able to find it
&gt; if is not allowed in const fn Why not? It seems that this should be the easiest thing to put in? It's const time and always const result? 
This clarification means a lot for Rust’s fledgling gamedev ecosystem, thank you very much! &lt;3 So happy to hear you’ll still be around to carry on the grand experiment alongside the rest of us.
Tuples give you conjunction; this feature gives you disjunction.
Still! The fact that it will be there Someday is good, as long as Someday actually arrives.
It's *not* const time, based on branch prediction. My uninformed opinion is that the easiest thing to make const are first all the things that *don't* require branches, which is what is being worked on now, and then after that things regarding decision-making will get handled. Keep in mind the six weeks between releases is not a large amount of time for a project this size. :-)
or “logical and/or”
Rust just makes you be explicit about what you are doing. &amp;#x200B; Yes. I really am doing this. Yes. I know what I'm doing. Yes. I get it. Ok. \[shoots self in foot\], well...that's on me I guess.
I should have mentioned it, Rust by Example is where I'm getting about 90-95% of my information from, with stackoverflow and posts being the other 5%. It's a pretty strong signal that the community embraces it as the canonical source of info, as not many other sources have shown up in my searches.
Why can't CharIndicies just be a Vec&lt;usize&gt;? Seems a lot simpler than having references
&gt; It's not const time, based on branch prediction. I don't get it. So sure, `if a {do_thing()} else {do_other_thing()}` will run `do_thing()` a bit faster than `do_other_thing()` because of branch prediction, but what would be the problem to do `const fn const_fn(arg: bool)-&gt;bool { if arg {true} else {false}`? Or even `const fn const_fn(arg: bool)-&gt;bool {let b = blah_blah_const_fn(); if b {true}else{false}`? There's no need for branch prediction as the compiler will just insert a `true` or `false` wherever `const_fn` appears?
Would I be able to do this with a procedural macro? Because this will be a bit of work (I'm passing about five arguments, so I'll need to manually make 120 combinations). 
https://stackoverflow.com/questions/1710922/how-to-install-pkg-config-in-windows Installing pkg-config on Windows is such a large rabbit hole that it's only cross-platform in the technical sense.
So... like `tar --delete`? Although I don't think tar has an option to extract *and* delete at the same time.
[You can also mutate fields.](https://play.rust-lang.org/?version=beta&amp;mode=debug&amp;edition=2018&amp;gist=c52c6819afd9a74338c0d34c3ba25f64)
What exercises or project(s) are you using to get practical experience with the language?
Fields are fine, whatever. But I mean that anything else with Index doesn't actually work
&gt; so far I'm having too much fun reinventing the wheel. IMO this is such a great way to learn and it really helps a person develop an appreciation for just how round some wheels are.
Dear internet user that stumbles upon this post from via google search, only to shake their head at the frustrated, abusive OP: here's a workaround that seems to work on my computer running macos 10.12.6 with 0.12.0 of rustc. $ sudo rm /usr/local/bin/rustc $ sudo rm /usr/local/bin/rustdoc $ curl https://sh.rustup.rs -sSf | sh Cheers.
I have a Futures stream and I was wondering how to execute code on on the first message ex. stream .once(|msg| println!("This is the first message: {:?}", msg)) .inspect(|msg| println!("These are the other messages: {:?}", msg)) .collect()
What was the design decision around recreating tar parsing, as opposed to using \`tar-rs\` ? I'm assuming it's because you couldn't stream it out in a constrained way? Is there much memory overhead in this method?
*rustup update* my toolchain. I still need some free time to do something else with Rust than updating it lol.
Wasn't the whole point of *if let* to have a shorthand for match extensions with only one pattern?
It's another allocation that will probably end up being bigger than your String and you would have to use something like CharIndices to construct that vector in the first place. 
const fn does not mean const time 
Is there somewhere in the docs or rustbook that goes over const fn yet?
As of the time of this post, the [official standalone installer page](https://forge.rust-lang.org/other-installation-methods.html#standalone) incorrectly lists 1.33.0 as the latest stable release. For users who prefer or need standalone installers, please use the URL templates bellow or the following concrete links to download your packages until this issue has been resolved. The URL template for normal rust installers is: * `https://static.rust-lang.org/dist/rust-1.33.0-{TARGET-TRIPPLE}.{EXT}` * `https://static.rust-lang.org/dist/rust-1.33.0-{TARGET-TRIPPLE}.{EXT}.asc` The URL template for additional compilation target installers (`x86_64-unknown-linux-musl`, `wasm32-unknown-unknown`, ..etc) is: * `https://static.rust-lang.org/dist/rust-std-1.33.0-{TARGET-TRIPPLE}.{EXT}` * `https://static.rust-lang.org/dist/rust-std-1.33.0-{TARGET-TRIPPLE}.{EXT}.asc` ## Some Standalone Installers (Standard Toolchain + Host Target) * [aarch64-unknown-linux-gnu.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-aarch64-unknown-linux-gnu.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-aarch64-unknown-linux-gnu.tar.gz.asc) * [arm-unknown-linux-gnueabi.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-arm-unknown-linux-gnueabi.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-arm-unknown-linux-gnueabi.tar.gz.asc) * [arm-unknown-linux-gnueabihf.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-arm-unknown-linux-gnueabihf.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-arm-unknown-linux-gnueabihf.tar.gz.asc) * [i686-apple-darwin.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-i686-apple-darwin.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-i686-apple-darwin.tar.gz.asc) * [i686-apple-darwin.pkg](https://static.rust-lang.org/dist/rust-1.33.0-i686-apple-darwin.pkg) [asc](https://static.rust-lang.org/dist/rust-1.33.0-i686-apple-darwin.pkg.asc) * [i686-pc-windows-gnu.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-i686-pc-windows-gnu.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-i686-pc-windows-gnu.tar.gz.asc) * [i686-pc-windows-gnu.msi](https://static.rust-lang.org/dist/rust-1.33.0-i686-pc-windows-gnu.msi) [asc](https://static.rust-lang.org/dist/rust-1.33.0-i686-pc-windows-gnu.msi.asc) * [i686-pc-windows-msvc.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-i686-pc-windows-msvc.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-i686-pc-windows-msvc.tar.gz.asc) * [i686-pc-windows-msvc.msi](https://static.rust-lang.org/dist/rust-1.33.0-i686-pc-windows-msvc.msi) [asc](https://static.rust-lang.org/dist/rust-1.33.0-i686-pc-windows-msvc.msi.asc) * [i686-unknown-linux-gnu.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-i686-unknown-linux-gnu.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-i686-unknown-linux-gnu.tar.gz.asc) * [mips-unknown-linux-gnu.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-mips-unknown-linux-gnu.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-mips-unknown-linux-gnu.tar.gz.asc) * [mipsel-unknown-linux-gnu.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-mipsel-unknown-linux-gnu.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-mipsel-unknown-linux-gnu.tar.gz.asc) * [mips64-unknown-linux-gnuabi64.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-mips64-unknown-linux-gnuabi64.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-mips64-unknown-linux-gnuabi64.tar.gz.asc) * [powerpc-unknown-linux-gnu.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-powerpc-unknown-linux-gnu.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-powerpc-unknown-linux-gnu.tar.gz.asc) * [powerpc64-unknown-linux-gnu.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-powerpc64-unknown-linux-gnu.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-powerpc64-unknown-linux-gnu.tar.gz.asc) * [powerpc64le-unknown-linux-gnu.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-powerpc64le-unknown-linux-gnu.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-powerpc64le-unknown-linux-gnu.tar.gz.asc) * [s390x-unknown-linux-gnu.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-s390x-unknown-linux-gnu.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-s390x-unknown-linux-gnu.tar.gz.asc) * [x86_64-apple-darwin.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-x86_64-apple-darwin.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-x86_64-apple-darwin.tar.gz.asc) * [x86_64-apple-darwin.pkg](https://static.rust-lang.org/dist/rust-1.33.0-x86_64-apple-darwin.pkg) [asc](https://static.rust-lang.org/dist/rust-1.33.0-x86_64-apple-darwin.pkg.asc) * [x86_64-pc-windows-gnu.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-x86_64-pc-windows-gnu.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-x86_64-pc-windows-gnu.tar.gz.asc) * [x86_64-pc-windows-gnu.msi](https://static.rust-lang.org/dist/rust-1.33.0-x86_64-pc-windows-gnu.msi) [asc](https://static.rust-lang.org/dist/rust-1.33.0-x86_64-pc-windows-gnu.msi.asc) * [x86_64-pc-windows-msvc.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-x86_64-pc-windows-msvc.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-x86_64-pc-windows-msvc.tar.gz.asc) * [x86_64-pc-windows-msvc.msi](https://static.rust-lang.org/dist/rust-1.33.0-x86_64-pc-windows-msvc.msi) [asc](https://static.rust-lang.org/dist/rust-1.33.0-x86_64-pc-windows-msvc.msi.asc) * [x86_64-unknown-freebsd.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-x86_64-unknown-freebsd.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-x86_64-unknown-freebsd.tar.gz.asc) * [x86_64-unknown-linux-gnu.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-x86_64-unknown-linux-gnu.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-x86_64-unknown-linux-gnu.tar.gz.asc) * [x86_64-unknown-netbsd.tar.gz](https://static.rust-lang.org/dist/rust-1.33.0-x86_64-unknown-netbsd.tar.gz) [asc](https://static.rust-lang.org/dist/rust-1.33.0-x86_64-unknown-netbsd.tar.gz.asc) ## Additional Compilation Target Installers Due to reddit's post limit, I can't post every link to all target installers supported by rust. Refer to the complete list of supported platforms in https://forge.rust-lang.org/platform-support.html. The extension for these installers is `.tar.gz` (or `.tar.xz`) for all targets including Windows. ## Browsing other standalone installers Due to a [known bug](https://github.com/rust-lang/rust/issues/56971), browsing the index of all available installers is no longer possible on https://static.rust-lang.org/. It is however still possible to access dated repositories via the following URL template: `https://static.rust-lang.org/dist/YYYY-MM-DD/` Installers for the current stable release of rust can be browsed at https://static.rust-lang.org/dist/2019-02-28/ **If you have any questions regarding stand-alone installers or additional compilation targets, please don't hesitate to post them bellow. ** Cheers!
As someone who has written a *lot* of Python over the years, professionally and not... Immutable by default, **please**.
Julia has... Like, 2.5 of those? And is kinda state of the art. It's a talk order.
There is a little bit here: https://doc.rust-lang.org/nightly/reference/items/functions.html#const-functions
From [Gouchester Catholic High School](http://www.southjersey.com/article/33086/Gloucester-Catholic-High-School) it seems.
Just spend 5 releases messing with the CI/CD config (switch to a new one for no reason!) and the auto formatting + linting setup. Definitely... Haven't... Uhm. Done that sort of thing before.
Java with using the JNA library ([https://github.com/java-native-access/jna](https://github.com/java-native-access/jna)) interfaces with Rust nicely without needing the stubs that JNI requires. I have a proof of concept with the following Rust code is compiled as a "cdylib": extern crate libc; use libc::{c_int, c_float, c_double, c_char}; #[no_mangle] pub extern "C" fn contrived_multiply(oper1: c_int, oper2: c_int) -&gt; c_int { return oper1 * oper2; } #[no_mangle] pub extern "C" fn void_function() -&gt; () { println!("rust here"); } #[no_mangle] pub unsafe extern "C" fn byref_function(int_ref: &amp;mut c_int, float_ref: &amp;mut c_float, double_ref: &amp;mut c_double, arr: *mut c_char, arr_len: c_int) -&gt; () { *int_ref += 1; *float_ref += 1.0; *double_ref += 1.0; let slice: &amp;mut [c_char] = std::slice::from_raw_parts_mut(arr, arr_len as usize); for x in 0..slice.len() { slice[x] += x as i8; } } Can be accessed using JNA in Java: import com.sun.jna.Library; import com.sun.jna.Native; import com.sun.jna.ptr.DoubleByReference; import com.sun.jna.ptr.FloatByReference; import com.sun.jna.ptr.IntByReference; public class Main { public interface RustLibrary extends Library { RustLibrary INSTANCE = Native.load("rustddl", RustLibrary.class); int contrived_multiply(int oper1, int oper2); void void_function(); void byref_function(IntByReference intRef, FloatByReference floatRef, DoubleByReference doubleRef, byte[] arr, int arr_len); } public static void main(String[] args) { System.out.printf("contrived_multiply(6, 9) = %d\n", RustLibrary.INSTANCE.contrived_multiply(6, 9) ); RustLibrary.INSTANCE.void_function(); IntByReference intRef = new IntByReference(42); FloatByReference floatRef = new FloatByReference(3.14f); DoubleByReference doubleRef = new DoubleByReference( 6.28); byte[] arr = new byte[] { 4, 8, 15, 16, 23, 42 }; RustLibrary.INSTANCE.byref_function(intRef, floatRef, doubleRef, arr, arr.length); System.out.println("intRef = " + intRef.getValue()); System.out.println("floatRef = " + floatRef.getValue()); System.out.println("doubleRef = " + doubleRef.getValue()); for (byte b : arr) { System.out.print(b); System.out.print(" "); } System.out.println(); } } I don't have any experience with invoking Java from the native code via JNA, but for simple Java -&gt; Rust communication, it is fairly simple.
The canonical way to learn Rust by reading The Rust Programming Language book (free) and/or Programming Rust by Jim Blandy. 
Yes, but it's also not quite the same. `tar --delete` will just white-out whatever file you delete from the archive. So the archive will still take up the same amount of disk space in the end, even though you've removed a file from it!
:) nylon or TPU95 printed blocks are immortal. We built an autonomous 1:10 drift car and.. https://driftcar.pelablocks.org/images/DonkeyCar-Maiden-Voyage.gif
I've considered it, but I haven't researched how well it performs in terms of collisions. The hashing is performed only in the derive macro and during the template preprocessing, so it actually doesn't affect rendering times.
It's a stock image, you can buy rights to use it. I've avoided doing reverse image search to find out who else is using it for reasons like these :D.
Correct, `tar-rs` works at a pretty high-level and doesn't expose any parsing primitives. Finer control is important because `taro` needs to work with one block at a time, first forwards and then in reverse. To your other question, `taro` doesn't actually keep the archive contents in memory. It writes to the filesystem as extraction progresses, using just an extra 512 bytes of disk space as protection against unintended interruption. I haven't done an in-depth analysis of memory usage, but I'd be surprised if it was more than a few KB.
You might need a crate like `owning_ref` to fix this.
I think it's supposed to be interpreted as adding to the list (the internal HList) of results
r/playrust
/r/playrust?
That's kind of the point - `sd` would not be appealing if it was simply a carbon copy of `sed`. However, it would be a stretch to say it is not "anything remotely like it then". Based on my observations and experience, `sed` is mostly used for finding &amp; replacing text/regex. `sd` zeroes in on this and delivers a much more intuitive interface for this very common task.
Sidenote: [istanco.rs](https://www.istanco.rs/) it says: &amp;#x200B; &gt;Local presence is no longer required for .RS domain registration. &gt; &gt;It is not required to have a local presence or admin contact, in order to register a .RS domain. No additional specific requirements. Anyone can register any amount of Serbian .RS domains. &amp;#x200B;
Always look forward to your posts. Thanks for the tips.
Forgot to come back and thank you for your help. So- thank you very much, this pushed me in the right direction!
Sorry didn't mean to ignore your question - I thought reddit would send me an email to notify, but apparently not, so I didn't see your question until I opened reddit just now. Either way, /u/short_sells_poo answered your question, so all is well. But just to elaborate - Arc's cloning behaviour is same as Rc, they are all smart pointers (cloning would produce clones of the pointer itself, but they all share the same underlying object), with the difference that Rc is not `Send`.
RBE is just as legit as the book.
There is nothing inherently wrong with a short name for a commonly used command. In case of `sd`, there are no conflicts with other binaries at all.
`recursive data that may have mutable references to its parents` is basically a tree structure, which indeed is a bit tricky/awkward in Rust. `parent: Rc&lt;RefCell&lt;T&gt;&gt;` is the goto solution for that situation.
I could be way wrong, but I think that's because most types with Index are heap allocated (read dynamic), which would be inherently non-const. That said, a Vec can be used in a const-ish way when arrays don't cut it, syntactically speaking (const generics when?), so I feel your pain.
No it's because all traits are incapable of const, and Index is a trait. A non-heap index type would be something like a Mat4 value.
A subset of chrono is definitely something I think should go into the stdlib in the medium term though, since it's required for such a large amount of projects.
Here are nice examples for using JNA in Rust: https://github.com/drrb/java-rust-example However, j4rs gives the control to Rust, rather than Java, focusing to Rust -&gt; Java direction with the ability to have callbacks for Java -&gt; Rust. I feel JNA is the other way round...
I'm exited to hear about more Rust jobs but, and I may have missed it, after spending \~10 minutes looking on their site, I still have no idea what they are trying to sell and what the value proposition is?
Oh yeah that's true. I actually ran into that problem recently in a project. It really is an annoying limitation beyond just Index :( Coming from a C++ background, I have pretty much equated const in rust with constexpr in C++ (for better or worse; they obviously have their differences), and with constexpr the rule is pretty much no dynamic memory, and everything else is fair game. So that's why I jumped there.
Const traits soon enough! We just gotta let it grow slowly.
The types get a bit wordy. You can't have null pointers, and if you want multiple ownership, you're using Rc or Arc, and if you need to be able to mutate things through all the various references to them, you'll mix RefCell or Mutex in. So you'll end up with a bunch of `Option&lt;Rc&lt;RefCell&lt;Node&gt;&gt;&gt;` or `Option&lt;Arc&lt;Mutex&lt;Node&gt;&gt;&gt;`. But, on the up side, there are broad classes of bugs that you just can't write easily. No null pointer dereference issues. No data races. No use after free. You don't have a garbage collector, so you have to write your recursive data structures like you would have in C or pre-GC C++. Since you're probably creating reference cycles, you even have to concern yourself with memory leaks (though std gives you the tools do deal with it if you're careful). That is legitimately more work than it would be in a GC language. The real reason that the standard library mostly avoids recursive data structures though is performance: CPU cache management is key, and contiguous allocations are easier on the chip's cache manager than nodes allocated all over heap with a more or less random access pattern. 
I don't think it will affect you. In any case, if something goes wrong you'll get a link error (at compile time).
Not OP, but thanks for linking this, I hadn't seen it before, and it's really helping to reinforce a lot of the topics in The Book that I only kinda understood.
Yeah, my issue is that I want to feed characters with indices into my tokenizer. With a str I can have the indices and still slice parts of the string for out put from the tokenizer (based on the charger indices). But if I have a String then I have to have char indices and the string or construct owned strings for every token.
Though (perhaps rightly) offers much less insight into why a design decision was made. In my experience, RBE is really good for showing you how to use a feature, where as the book is good at telling you what to use and why, as well as surrounding context. Having read the book, I reference RBE much more often, but while learning I _definitely_ found the book to be more informative. 
It’s legitimate and turned out to be accurate. They mention several examples that are directly addressed by the book, leading to the accurate suspicion that they’re getting their info elsewhere. 
I highly recommend reading the rust book. It’s not just “here’s the syntax to do the thing”. It addresses reasoning behind design decisions, solutions and work arounds to common problems (it specifically addresses self referential structs and data structures that hold references to each other, eg trees and doubly linked lists), as well as detailed explanations of concepts (it shows you with examples the reason lifetimes exist, and why closures move by default. Trust me, it’s the right choice). It’s always a drudge to relearn control flow and what a function is, but if memory serves, it doesn’t beat that into the ground, as the Rust Book is explicitly not a “how to program” book, but a “how to program in rust” book. 
While interesting, this is only *very* tangentially related to Rust. It's not even about something that the Rust safety guarantees prevent, it's just a bug in a compiler.
Well, to make it work you must have protoc reimplemented in rust. In case of protobuf it's possible, but it's not always possible. You get the idea.
For that thing you can just collect resources into `Arc&lt;Any&gt;`. Could be little slower on drop because of virtual call though. But should OK. Unless you find out this is a bottleneck )
Yes. The field that is not `#[repr(C)]` will not have defined layout, but where the field is will be well defined.
thank you very much. that's pretty close of what I need I'll try to add that to my code in the afternoon.
I think it depends on your use case. At work I was writing a Rust library which would only ever be called from our (non-Rust) GUI application, so it made sense to add a `ffi` module to the crate and compile everything from there. Alternatively, if you're working on a general Rust crate and want the ability to expose it to other languages, I'd create a second crate called `blah-ffi` which just contains the FFI bindings. That way you can keep your main crate completely free of `unsafe` and independent of any FFI bindings written on top of it. **(shameless plug)** A while back I made a bit of a guide on doing FFI in Rust ([The (unofficial) Rust FFI Guide]([https://github.com/Michael-F-Bryan/rust-ffi-guide](https://github.com/Michael-F-Bryan/rust-ffi-guide))]. Let me know if you find it, or [the not-yet-completed rewrite](https://s3.amazonaws.com/temp.michaelfbryan.com/index.html), useful.
I used to use IStanCo when I first created amethyst.rs. I found that the experience was pretty straightforward and pleasant, without any special prerequisites for domain registration.
Why does [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=5f7473763c43d961040a56ea21e14a57) not work? I want to append a vector to another consuming the second. Why do I have to borrow the second vec and pass it as a `&amp;mut`? Is the compiler not smart enough to realize that consuming the argument is the same thing as passing a mutable borrow (and more, as I'm guaranteed never to use this vec again)?
Author: ZOMG!!! 0 day back door! Compiler writers a backdoor! Everyone else: Just a compilation bug mate.
I have used grpc-rs and it seems to work really well in our small simple use case. I also used this https://crates.io/crates/protoc-grpcio to build the protobuf definitions into rust implementations using a build script. Don't know what the performance was like compared to other languages though, but it was pretty snappy in simple use cases, few milliseconds a request or so.
No, the shorthand is for having match with an empty catch-all.
Not directly related to Rust, but my pain points with Riot are unreliable notifications on some phones (opening a notification after switching from WiFi to mobile data or the other way around left Riot hung and I had to restart it) and lack of support for editing messages.
&gt; but what would be the problem to do const fn const_fn(arg: bool)-&gt;bool { if arg {true} else {false} A nitpick, but one obvious problem is that it's not a useful use of if. It's equivalent to `const fn const_fn(arg: bool) -&gt; bool { arg }`, so it wouldn't really be a reason to allow if expressions in const-fn.
One problem with that approach is that it might depend on other functions that could be const but aren't yet. So you'd need to run that tool on every function repeatedly until nothing changed anymore. Alternatively you could build a dependency graph, but in that case you need to analyse the code, so you might as well throw in the "can-this-be-const" analysis in your tool
The empty pattern (\_) is kind of implied since the language forbids omitting it. And even though it may be clearer about your intentions to use \*if let\*, it was still made for a specific use case. Allowing multiple patterns per \*if let\* is just redundant.
I remember I saw a discussion about maybe getting rid of the install script in the tarballs, making it more readily usable when extracted to a subdirectory. Do you know if that went anywhere?
Completely agree as well! I really hope that they will not outrun themselves and make choices that they did not think carefully enough about.
From the README, it's a little unclear to me how the run-time processing and the use of proc macros relate to each other. Are there basically two rendering modes? 
Hum. we’re not aware of bugs around missing push notifs on mobile atm - please can you submit debug logs from Settings next time it happens? And missing messages on riot/web sounds *really* strange and hopefully an easy bug to hunt down - again, submitting debug logs from Settings will show us whatever exception is fireing and swallowing the timeline update. Editing msgs is on the roadmap within the next few months.
This seems to be a commonly requested thing, so I'll put it on the roadmap :)
While it's clearly wrong to transmute a `Vec&lt;!&gt;` to `Vec&lt;u8&gt;`, is it safe to transmute `&amp;[!]` to `&amp;[u8]`? `&amp;[!]` is guaranteed to be empty, so there would be no way to read out-of-bounds values from it.
&gt; I still use Rust exclusively, but as I am the world's slowest game developer, I am not really ready to talk about anything I'm working on atm. I'm a lot more suspicious about the competence of people telling me they're rockstars. ;)
Looks like Diesel uses [Beotel](https://www.beotel.net/hosting/domainreg3): https://whois.domaintools.com/diesel.rs
&gt; we’re not aware of bugs around missing push notifs on mobile atm - It was only happening on my old phone (Nexus 5 with Lineage OS). I'm using low detail notification. Anyway, the issue wasn't really that the notifications were missing, but that opening them showed a Riot with a spinning wheel until I killed the app. This seems to have been reported [in 2017](https://github.com/vector-im/riot-android/issues/1172). &gt; Editing msgs is on the roadmap within the next few months. Cool :-).
9 minutes from scratch to my usual dev cycle (stage 1 + compile error tests aka src/test/ui). This is on a desktop I built literally optimized for Rust build speed (and cost) and nothing else.
Is there any lib with additional combinators for options and/or results, like `map2(Option&lt;A&gt;, Option&lt;B&gt;, Fn(A, B)-&gt;C)-&gt;Option&lt;C&gt;`? And also, is there any analog of Haskell's [Hoogle](https://www.haskell.org/hoogle/) (search by type signatures among crates)? Thank you.
Const generics Oh bby
I cannot think of anything wrong with that transformation, tho it doesn't seem useful. That said, I'm not going to give any guarantees here and now. :)
Then say it like that. Your comment reads as "reading the book is mandatory, if you didn't even do that, don't expect us to take you seriously" (exaggerating slightly, of course).
No you don’t. You can literally just shell out to protoc. Make it output to a tmp file, read that file.
In fact, there's a [whole chapter on smart pointers in The Book](https://doc.rust-lang.org/book/ch15-00-smart-pointers.html). I'd recommend reading all of it if you haven't already - it's a great read!
No, there is just one mode. The derive macro is basically fulfilling the same purpose a `Serialize` would do, except instead of making the type serializable to things, it allows the renderer to render fields from the type by hash(name) into it's buffer/writer. Preprocessing is just "compiling" the source into a structure that can iterated over quickly, eg. `"Foo {{ foo }} Bar {{ bar }} tail"` becomes internally something like `[("Foo ", hash("foo")), (" Bar ", hash("bar"))]` (simplified here, but you get the idea) + `" tail"` stored separately. So once you have your preprocessed `Template` and your struct with derived trait, rendering is pretty snappy.
There is also https://github.com/tower-rs/tower-grpc although it's not recommend for production usage yet
This makes sense. I dig it.
Also, what about Rust's "we use Rust’s powerful built-in data structures" lends itself to unifying ordering and property data, as opposed to C++? What about Rust improves data encapsulation? To me, this seems more like "stuff to do when rewriting a component", not "Rust led us to doing it this way"
Oh I hadn't realized I was reading the book (have a bunch of bookmarks to https://doc.rust-lang.org/book/ ). I'll make sure to give it a full read this weekend
I think there is just confusion between "constant time" and "compilation time". Const functions are executed at "compilation time" even if the execution takes constant time or not.
The problem is that it does not do bound checking by default : the more convenient syntax is not bound checked. In Rust, if you want to escape bond checking, you will have to use an unsafe block at some point.
There is a recent post (January) about the choice of a gRPC library for TiKV: https://medium.com/@siddontang/use-tower-grpc-for-tikv-6109cf8c61
`println! { "Oh ... never seen this before, thanks :)" };`
Yes, workspaces are a perfect fit here. Just wanted to mention, that when using workspaces you will have a single `target` directory for all crates in the workspaces. This is a huge optimization, because dependencies that are common to different crates wouldn't be compiled multiple times.
You can do that in proc macro and it won't be expensive? 
Happy cake day, by the way.
Are you referring to https://internals.rust-lang.org/t/the-state-of-rust-tarballs/9141 ? I've never seen an RFC come out of it and can only assume that it died off, unfortunately. 
About a 'simple' memoize/cache: actually this isn't simple at all! Rust having a focus on safe concurrency means that invisible caching behind a function which doesn't declare this up front (by not taking `&amp;mut` argument to the cache somehow) is simply required to do the heavy lifting itself such as wrapping things in a Mutex. Initializing a static Mutex on first use is also surprisingly complex (hence crates like lazy_static). This is less of "Rust doesn't let me build a simple memoize/cache" and more about "memoize/cache strategies aren't as simple as other languages make it look". That complexity has to go somewhere and Rust makes it show up front. Leading to the question... Why? How did these other languages manage to make it look so simple? The answer lies in how these other languages handle parallelism. It's interesting to analyze exactly what it is that languages do to avoid these issues that Rust protects you against: Python does not support threading nor does it support references like Rust, the garbage collector fixes any remaining issues such as reentrancy. There we go, solved! (Javascript solves its problem in a similar fashion). C#/Java do something interesting: All data types have a valid representation of all zeroes. Eg. reference types can be null, primitives can be zero, structs contain either references or primitives and thus also have a valid representation of all zeroes. All values are initialized before they can be shared. Further concepts like fat pointers do not exist. On x86 all aligned read/writes of size less than a cache line are 'atomic' (sorry, using the wrong word here), meaning that a data race won't shear a read/write in half. This doesn't stop concurrency bugs but it __does__ prevent you from eg. reading a reference and while reading that reference a write in another thread gives you a pointer consisting of two halves of two different references. This means that while you can have concurrency bugs you won't cause memory unsafety (eg. access violations)! Try as I might, I cannot get C# to produce an access violation with just using these primitives (not using unsafe or native code ofc). Or you can simply forbid shared mutation more common in functional languages. For those functional languages without immutability reentrancy can still be a problem but that is solved by a garbage collector. I am fascinated by these stories, why are these 'common' scenarios so easy in these languages while Rust suggests that no, it is not easy and if you get it wrong you get memory unsafety. Rust is obviously correct and yet these languages get away with things that are wildly unsafe in Rust without causing the same issues! 
&gt;oh man, this compiler is REALLY PICKY about declarations. I feel a little bit more like a compiler than a dev Type inference allows you to simplify 95% of your declarations :) &gt;proper error handling looks messy Well, I have picked the following approach: * First of all I try to process an error in place without propagating it any further. This is the best practice for every language that doesn't have exceptions (Go, C, Rust, etc). * If actually need to propagate your errors to the calling functions, then you have a couple of options here: * If all errors you cannot handle in place are of the same type, then just use this type as the error type of this function and use the question mark operator. * If the case is more complex: create an enum to represent your error type and convert errors when doing pattern matching or by combining `map_err` and the question mark operator. For me error handling is one of the most favorite things in Rust. It is easily combined with the match operator and you are **forced** to process every single error. &gt;building a simple memoize/cache is tricky with globals and a mutex/Rc (I couldn't get a popular cache macro lib to work for me) This is mainly because of the borrowing rules. In general, if you need something to be mutable and global (e.g. `static mut`) the compiler will treat that as unsafe code. Not a big deal, but writing unsafe code is discouraged and it needs special attention to prevent data races.
I just tried this and it worked perfectly. But why does a move on this closure work, but doesn't change anything when applied to the closure inside `with_config`?
My deeper frame of reference would be c++ where I can initiate a single thread global cache without anything fancy. As soon as you add mulltithread you need mutexes and potentially more advanced timing tools to avoid read or more commonly write races. It's a shame that concurrent program safety + complexity affects single thread development, which is much easier to reason about. The way Rust handles Arc vs Rc references is the type of solution I'd love to see for single vs multithread shared memory where the only complexity the developer has to keep in mind is the type of Reference and the tradeoffs (speed vs multithread safety). I guess I could build a generic which is a mutex + Arc combination and handle the guards internally on access. I need to learn more about Rust before I tackle it.
Super curious: Do your functions that have 3-4 different error types have their own match cases or do you combine them with custom inherited error types and chain them? So far I've taken the Erlang (and Elixir) approach to error handling and am crashing and it makes for much more readable code flow. I would love to add the question make syntax and return Results with shared error types (just need a string description to log). There will be cases where I need to skip the error and keep on processing so my current approach will need to change
It looks like my documentation sources are rbe, stack overflow, blog posts, and looking at popular cargo module source in that order. My favorite instructor so far is the compiler.
To be honest, *Rust By Example* is the one part of the official Rust docs I've never found too useful. Everything there seems really incomplete and kind of odd compared to what I'm used to. I just glanced through RBE again since it had been so long. I was kind of excited to see an index entry for the "Benchmarking" section, but it doesn't look like it exists yet? I then glanced at the FFI section, and the example wraps `libm`'s `ccosf()` as `cos()`, which name seems a bit like an invitation to future collision. I next looked at the `Path` section and puzzled over how I'd get/write a path that started with a drive letter on Windows and not on UNIX/Mac. None of the examples seem to be hyperlinked to the rustdoc or the Book, so it's kind of inconvenient to go from the example to the full story. I also noticed that the (only) example used a `match`/`panic!` where an `expect()` would be more idiomatic error handling. Honestly, that whole example seems kind of messy to me: `display()` is invoked to produce a `Show`able which is then discarded rather than showing what one would do with such a thing (and then `to_str()` is invoked to get a value to display); the produced path at the end may or may not start with `./` depending on `Path::join()`'s canonicalization rules, which aren't shown or explained (it does). I guess RBE is a good resource if you just want basic starter examples. However, I'd encourage anyone trying to learn / improve their Rust skills to use the Book and/or *Programming Rust* as the primary text and RBE as just a kind of supporting illustration of how stuff is fit together. I don't see it as a shining example of Rust greatness in its current state. (Yes, I know, patches welcome. I wish I had time to work on it. I'd probably start by building some scripting to link each example to &lt;http://play.rust-lang.org&gt; so that folks could get a one-click way to play with the examples, and to properly link identifiers into the rustdoc so that they could look at that.)
To complete the field, there is also [grpc-actix](https://github.com/tokenio/grpc-actix) based on Actix.
I'd personally avoid Stack Overflow, as it tends to have a lot of outdated answers.
Well, I think I have to give an example here. I have a function that does the following stufF: * Decode a protobuf message; * Validate its fields against the business rules. Those two steps produce different errors and those errors need to be propagated. So I have the following enum: `pub enum MessageLoadError {` `ProtobufError(ProtobufError),` `ValidationFailed,` `VerificationFailed,` `}` When I decode the protobuf I do the following: `message_pb.merge_from(&amp;mut input_stream).map_err(|e| MessageLoadError::ProtobufError(e))?;` And for business logic error I do `return Err(MessageLoadError::ValidationFailed);` For the return value I do the match when it is required. You can match in very different ways: * Use a separate pattern for each error type (`Err(MessageLoadError::ProtobufError(e))`, `Err(MessageLoadError::ValidationFailed)`) * Or use broader patterns like `Err(e)` * Or combine patterns with or-like statements: `Err(MessageLoadError::ValidationFailed) | Err(MessageLoadError::VerificationFailed)` Did I answer your question?
[The documentation shows an example of using it in order to associate a lifetime with a pointer](https://doc.rust-lang.org/std/marker/struct.PhantomData.html) Imagine I have a representation that only stores an integer id. Using that id, I can retrieve an object of type T. Using PhantomData allows me to pretend that object is referenced by the struct when it isn't See also: http://troubles.md/posts/why-phantomdata
The fun is that the concept of non-owning references require _the same_ checks as multithreaded programming. The same checks that prevent data races allow safe use of non-owning references in a single thread. The problem is that aliased references where at least one reference is mutable causes memory unsafety _even in single thread programs!_ This problem is made trivial through the use of `enum` eg. `Option`: let mut opt = Some(42); let opt_ref: &amp;i32 = opt.as_ref().unwrap(); opt = None; // Quiz: What does opt_ref point to? Again the same questions: Why does Rust hit these issues that it has to work around them where as other languages like C++ have absolutely no issue?! Here the culprit is `enum`. Using `std::variant` in C++ will hit you the exact same issue like Rust. Other languages may simple not support Rust-like enums. GC languages can work around it forcing enums to be 'heap allocated' such that overwriting the `opt` value just makes the underlying (heap allocated) `i32` to be garbage collected later. You may think that even though the issue is with `enum` and not with primitives like `i32` why am I forced to pay the price at all times? Here Rust actually provides the `Cell` and `RefCell` types which allow mutation of shared references. Of course these wrappers aren't thread safe (but you cannot annotate a stand alone function as not being thread safe so you are still forced to put memoizing/caching behind a Mutex)! C++ just lets you do wildly unsafe things that probably hopefully won't be violated by a user which doesn't know how you've internally implemented your functions. Other languages simply forbid the constructs that Rust wants to enable. Rust _does_ have a focus on safe guaranteed concurrency and parallelism in which does require a price to be paid even for programs that think they won't ever need parallelism.
I needed to pick up a gRPC for one of our projects, so took a brief (but incomplete) census. grpc-rust is definitely the most mature and popular, but the API is clunky and un-idiomatic. grpc-rs is bindings for a C library, so if you prefer native Rust this is not the one to use. There are two gRPC library projects in development using [prost](https://crates.io/crates/prost) for the protobuf implementation, which is the best protobuf implementation I've found for Rust. These are tower-grpc and grpc-actix. I have settled on tower-grpc, but it has not yet been released under any version one can lock onto in a Cargo.toml, so you have to deal with git dependencies and occasional breaking changes. It's also on the higher end of the complexity scale, using abstract traits to achieve static implementations as much as possible. I have not looked extensively at grpc-actix, as I've only became aware of the project recently. It's likely to follow Actix's pragmatic approach of making things simple for the application writer, at the cost of some potential inefficiency due to extra allocations and dynamic dispatch.
I'm not sure if this is the reason but looking at the documentation for both those functions, the ``App::resource`` method takes in a closure that returns a generic type ``R`` with the lifetime of ``'static`` whereas the ``Route::with_config`` has no such restrictions. So I'm assuming some struct with a lifetime of ``'static`` takes in the ``limit`` variable however the compiler complains since the ``limit`` variable has a shorter lifetime than the struct. However I have no idea how ``actix-web`` works and only understand very little about lifetimes so I'm probably wrong.
Roger that, will do.
This comment is really helpful, I'll prioritize reading on RefCells as I have seen them referenced a few times but not fully understood their behavior.
Very interesting approach, I'm wondering if I can use some of that for Tera! From a local clone, Tera v1 is about 10x slower than Ramhorns and a big chunk of that is serializing to JSON.
I think so, I'll need to see it in a full function after reading a bit more (afk until this afternoon). I like the idea of a common/shared Error handling interface and then the caller deciding on error what to do - in my case the default will be syslog'ing an error and exiting
In that case just use the `unwrap_or` function and call `exit` from the closure right after you have logged your error.
Cool thanks
Hello! I have a server that will receive a u64 from the client. So it converts the array of u8 to a String but when I try to parse it to a u64 with `parse()` I receive the ParseIntError. The String converted matches the u64 I want.
Hey author here. It's truly disappointing to work on a blog post / guide to only have the feature I praised the most (cross platform jobs) to be broken within the last 24-48 hours. Regardless of whether this can be solved with templates is besides the point, as one shouldn't trust their CI when such a breakage occurs. &amp;#x200B; Hopefully there will be a quick fix (along with the other bugs I mention), as I am still holding out hope to unify future projects under a single CI / CD.
Someone actually wrote a small book about this topic: https://cglab.ca/~abeinges/blah/too-many-lists/book/
Is there a big ol list of the missing pieces? Not that I think I’m qualified to build them, but I am curious.
In general ownership in Rust is "do what I say" not "do what I mean." The compiler checks that you're saying something that's valid, but doesn't fix it if not. `append` says that you want the source Vec to continue to exist ith the same capacity as before. You mean `v2.extend(v1.into_iter());` so that's what you have to say.
There is no other sub. That is what this one is about. You're not real and just lying to fuck with me because you're part of the simulation and I am all there is
I know that, I was wondering why OP brought that up.
Happy Cake Day icefoxen! If I had a flower for every time I thought of you...I could walk through my garden forever.
Yeah, that's it. Shame it didn't go anywhere :/ Thanks anyway :)
Ahhh this explanation was very elucidating. Thank you!!
Can you show your code? You might have forgotten to declare the receiving variable as u64, in which case parse will pick i32 by default I think (not 100% sure). 
&gt;If we’d had a time machine and could have written this component in Rust from the start, 51 (73.9%) of these bugs would not have been possible This number is also coherent with [microsoft's results about the origin of security vulnerabilities](https://www.zdnet.com/article/microsoft-70-percent-of-all-security-bugs-are-memory-safety-issues/).
Hello, would you mind speaking on your view of the state of Rust gamedev libs? Eg, I'm a primarily web backend engineer working with Rust these days. I've been starting writing a game on the side, but still mostly in mechanics planning phase. I've been looking at Amethyst for the ECS performance _(as my project _might_ need that?)_. Do you have any thoughts on the popular frameworks out there? Perhaps you think we should avoid frameworks all together? Homebrew a combination of Piston and Specs? etc. Would love to hear experienced thoughts on the matter. Thank you :)
Just FYI, you appear to be escaping everything. You probably want the markdown mode of the new comment editor, there's a button at the bottom of the text box.
&gt;This includes gdi32.dll, **which** could cause hangs when creating/destroying lots of processes. Just checking - this means that it is a good thing that Rust does not depend on it anymore? Or do you mean that since Rust no longer loads gdi32.dll, software that relied on it may crash?
If you want to learn error handling from first principles in Rust, you might want to give my blog post a read: https://blog.burntsushi.net/rust-error-handling/
what editor has the best support? I tried the intellij plugin, but it seems to miss a lot of things I do wrong.
Parse is just a thin layer between type inference (the compiler filling in type parameters) and trait method dispatch (i.e. overloading). Type inference automatically picks `i32` as the default type of integer literals unless there is a conflicting requirement. It's good practice to explicitly say what type you want from `let i: Type = s.parse()`, since you won't always gets errors if the compiler does something confusing.
Here the code: `let mut buffer = [0; 512];` `stream.read(&amp;mut buffer).unwrap();` `let plain_string: String = String::from_utf8_lossy(&amp;buffer).trim().to_string();` `println!("value read {}", plain_string);` `let plain_u64: u64 = plain_string.parse().unwrap();` `println!("{}", plain_u64);` I specified the plain\_u64 is a u64.
I've used battery-ffi as a reference for my own FFI layer, really helped me to come with terms on how to make my own ffi crate not too painful to look at. My word of advice is, always double check the crate names in configuration files, I accidentally made a type in my crate name in cbindgen.toml, which resulted in me having undefined types in my C header file.
I'm always curious about how games are developed, and if you can't answer me for whatever reason, I understand. Specifically, I am curious: Was Rust used for any of the stuff you released on the Switch (I am thinking Wargroove, specifically)? Is it possible to do so? What about the other Nintendo products, like 3DS? I have a Nintendo 3DS dev kit lying around somewhere and I'd love to play with it, and the chance to do that in Rust is pretty darn attractive to me.
I specified the type.
\&gt; but from what I could gather the memory lifetimes and ownership rules make having child nodes with mutable references to parents problematic &amp;#x200B; Look up a concept called "interior mutability" and \`Ref\` and \`RefCell\`. You need interior mutability to be able to do cyclic data structures (parent pointers) to work around the lifetime restrictions in safe Rust. Unsafe is another option but should be wielded with caution.
Have you tried a [linear feedback shift register] (http://pramode.in/2017/12/10/lfsr-ti-launchpad/)?
.trim() does not remove nullbytes, only whitespace.
or "∧/∨"
I admit when I saw that I specifically wondered how you felt about it, not realizing you had left Chucklefish. Hopefully everything goes well for you in your future endeavors, your talk from RustConf was fantastic and gave a lot to think about.
It means "it is a good thing that Rust does not depend on it anymore".
That's a good catch and probably the root of the problem, thank you!
Will do, thanks again. Super glad I posted
Ok I removed it but as you may know it didnt resolve my problem with the parse.
Well of course you can't just remove it, you have to replace it with something that does remove the nullbytes. Search for the first nullbyte and then pass &amp;buffer[..index] to parse.
You'll need to learn unsafe Rust too. You'll need to interact with FFI libraries, operating systems, memory mappings and all that stuff sooner or later. Unsafe is not bad by itself, it's just an indicator you need to exercise more caution when writing, reading and reviewing code.
You can _eijebonginize_ crates! Just update the dependencies, open a PR: done!
Statically sized arrays are bounds checked. Vec's are not.
Cheers
Looks like a lot of manual work, why not use something like https://github.com/dushistov/rust_swig
It works thank you for the help!
&gt; So you'll end up with a bunch of `Option&lt;Rc&lt;RefCell&lt;Node&gt;&gt;&gt;` or `Option&lt;Arc&lt;Mutex&lt;Node&gt;&gt;&gt;`. You can use a [type alias](https://doc.rust-lang.org/book/ch19-04-advanced-types.html#creating-type-synonyms-with-type-aliases) to reduce some of the noise. ``` type NodeRef = Option&lt;Rc&lt;RefCell&lt;Node&gt;&gt;&gt;; ``` 
For me it is also not clear. I understand for example implementation of GUI via Java and core with Rust (I did it my self for Android). But this looks like some mix of Rust and Java for GUI. This should be slow for not hello world case?
I think a better approach is to introduce [cargo templates](https://github.com/rust-lang/cargo/issues/5151) and add a date/time library to the templates that often need it.
Thanks for the great write-up! :) &amp;#x200B; Observation: You, sir, are an example of a good open-source citizen. For practically every issue you note here, you talk about a mitigation or issue you've put time into! Props to you.
Is there a way to pass a partially applied function to a macro, which can then apply the rest of the parameters and call the function? &amp;#x200B; Say `foo(a:i32,b:i32) {}` and I want to pass that with b already applied to a macro which will provide a and then call it. Is this possible? &amp;#x200B;
&gt; That’s why I’m going to hide structs’ implementations behind the opaque pointers — basically I’ll return a pointer to some chunk of memory at the heap and will provide functions to fetch needed data from that pointer. Wouldn't it be safer to create an ID and use a Vec or HashMap or something similiar to keep your objects?
Here's an example of it being used in the wild. https://github.com/rust-osdev/x86_64/blob/master/src/instructions/port.rs The Port struct represents low level CPU I/O. An individual Port can be used to read or write any of u8, u16, or u32, but it must be defined on Port creation (cannot change the size of a Port object at runtime) so you can't write a u32 into a Port that should only accept u16. Since the Port struct has no internal concept of whether it's a u8, u16, or u32 Port, it is tacked on as a type parameter and therefore must also use PhantomData to tell the compiler that this is okay.
https://doc.rust-lang.org/std/iter/trait.FromIterator.html or https://doc.rust-lang.org/std/iter/trait.Extend.html + https://doc.rust-lang.org/std/default/trait.Default.html would be the traits to use here (and is what combine uses for it's equivalent functions https://docs.rs/combine/3.6.7/combine/fn.many.html, the need to annotate can give some really confusing errors however).
We should update that warning. We and others already use it in production with no regrets! It's just that the API is actively being refined...
Hi! John here - Azure DevOps Engineering Manager and resident Rust afficionado. Is there a GitHub issue you can at mention me on? johnterickson Does this syntax work? ``` pool: vmImage: $[ variables['imageName'] ] ``` e.g. https://github.com/johnterickson/cargo2junit/blob/master/azure-pipelines.yml
Thanks for the write up! I'm in the middle of working on transitioning from Travis (company changes) and Appveyor (never been happy with it) and this has information I'm going to need in the transition. Would you be interested in contributing your knowledge to the [`crate-ci` book](https://github.com/crate-ci/crate-ci.github.io)? A while ago, I realized the community had a program, with CIs being my main frustration point, where evergreen documentation was in blog posts. The problems I had: - stale information - blog posts giving different recommendations without any explanation - Bugs So I started `crate-ci` as a way to consolidate best practices and provide a home for CI related tool development to help with things like the bus factor for projects.
Random thought: I really dislike it when crates have examples with `use foo::prelude::*`. Please name the structs and traits you're using.
VSCode with the Rust RLS extension is probably the best experience, but it isn't perfect. &amp;#x200B;
No dice with the alternative syntax. Thanks for bringing this up internally, as I don't know where to report the issue.
I've been exploring FFI programming for the first time. I've been using Rust with both Ruby and Python, and it's been an absolute joy. I'm going to start pitching to write new code in Rust for our Python app. I love the Rust community. Keep up all the good work, lads.
For those interested, I've started development of [pipeline templates](https://github.com/crate-ci/resources) and would love contribution or feedback, including - What kinds of step or job templates people would like to see - Trade offs between a template being a step, job, or not having the policy in a template at all - Anything I [already have an issue about](https://github.com/crate-ci/resources/issues) My experience with Azure Pipelines in writing these templates Good - Template support is powerful for jobs (no longer need `cargo-when`) and cross-platform support - Love that collapsing of sections. I found it annoying to dig through Travis logs. - In general, the most pleasant CI I've worked with. - I look forward to taking advantage of JUnit reporting (cargo-suity) Bad - Error reporting is sub par. Some errors were reported. Other errors caused the job to not even be queued which made me think that AzDO had a bug, was backed up in polling github, etc - Multiple template languages (`$() vs `${{ }}`) without clear documentation on the syntax on where they can be used and why you'd use on or the other - Turns out I can't do a `${{ if eq(variables["Agent.OS"], "Windows_NT" }}` but could only do `condition: $(...)` - Variable, especially built-in variable documentation, is terrible. - They support `variables["name"]` and a short-hand of `variables.name`. When seeing a variable name `Agent.OS`, you'd think that would turn out to be `variables["Agent"]["OS"]`, with `variables.Agent.OS` as a short hand, but instead it is `variables["Agent.OS"]`. - The documentation for how variables are turned into environment variables is buried - In general, the documentation is scattered, not providing a nice central, technical reference for how everything works.
Can you share a link to before and after builds?
FYI, it is also used in a large number of pastries, such as [Mochis](https://en.wikipedia.org/wiki/Mochi)
http://arewegameyet.com The list of crates has grown a lot since I last looked. Obviously this isn’t going to show you everything missing but does give you a decent overview of the lay of the land.
I'm not sure I understand what to are talking about. In C++ statically sized array are absolutely not bound checked, and dynamically sized arrays too. The vector class is not bound checked if you are using the natural square bracket syntax. If you want bound check you have to use the at() function. In Rust both statically sized array, dynamically sized array and vectors are bound checked. If you want to avoid bound check you have to use an unsafe block. 
I'm just guessing without being able to see the code. If you type `let () = my_var;` the compiler should give an error that lets you confirm the type.
The parent previously had Witchbrook running on the Switch, and all of the current gen consoles. Wargroove uses C++; thats' what the link is about. I've heard of some people doing 3DS homebrew but have no experience with it.
\&gt; It's a shame that concurrent program safety + complexity affects single thread development &amp;#x200B; Two things. First it's not just about threads: [https://manishearth.github.io/blog/2015/05/17/the-problem-with-shared-mutability/](https://manishearth.github.io/blog/2015/05/17/the-problem-with-shared-mutability/) &amp;#x200B; Second, while I totally get where you're coming from, the fact that everything is threadsafe means that when someone writes a Rust library, I can use it, and not worry that they're doing something that breaks my program that \*is\* multithreaded. This is a huge boon.
For what it's worth, a lot of people in this thread reference types (rc/arc/refcell/mutex) that I find to be beginner traps, that is, I almost never use these types in my day-to-day writing Rust. People hear "oh that's the equivalent of other languages", and that's true, but then that leads you to believe you need to use them a lot. You almost never do; there's almost always a better way. Of course, sometimes you \*do\* need them, which is why they exist, but I find that beginners tend to over-use them and make things more complex than they need to be.
I prefer the book too, but many people really love RBE, and since I'm biased, I just want to make sure that people know that it's also a good thing. Your points are all valid, and mostly stem from there not really being someone who works on RBE like I do the book.
I don't mind - *as long as the prelude is well designed and documented*. Examples which use a prelude force me to understand the prelude before I can understand examples. Since a *lot* of people learn best by example, the prelude should be a very low barrier to understanding. Otherwise I agree: if there is any friction understanding a prelude, it puts an awkward bump at the beginning of the difficulty curve. So my gut feeling is it's not a good idea to `pub use .... as _`. Too much magic.
Agreed on examples for functions. Module or crate examples may use the prelude, if the use statements would be more than the actual code. However, the traits have to be properly documented.
Yeah [last success](https://dev.azure.com/nbabcock19/nbabcock19/_build/results?buildId=98) / [first failure](https://dev.azure.com/nbabcock19/nbabcock19/_build/results?buildId=133)
Feel free to use &amp;T, &amp;mut T and Box&lt;T&gt; (where T: Sized) in your FFI as well. Those have normal pointer ABI (with null not being allowed and &amp;T / &amp;mut T additionally having restrict). So they might not always be suitable, but often are. Unfortunately stuff like Option&lt;&amp;T&gt; / Option&lt;Box&lt;T&gt;&gt; spits out warnings, even though that has pointer ABI too.
No, Vec's are not checked. Try out this example. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=45b74bd99ddb75cc1e2d538cd993f425
Cool thanks Steve, your evangelism over the past few years is what lead me to take a deeper look. Will keep in mind that I may not need to leverage RefCells etc. So far I've touched Rc for some shared data (2 different data structures for fast retrieval and ordering) and a Mutex on a global cache. 
&lt;3
I hear ya will check the link - it may be some blissfully ignorance that I've had for a while or the way I managed data lifecycles in c/c++. 
At least in Web APIs, the company I work went so far as to list DateTimes as a primitive alongside numbers and strings, they are used so much.
I can give you the short version: rust prevents iterator invalidation at compile time. No threads needed to cause issues like that.
FWIW, I've been using azure pipelines w/ cross platform builds and I have not notice any breakage. https://github.com/tokio-rs/tokio/pull/926 (all the failed builds are bugs w/ the CI config as I experiment).
I'll just jump in here... I've been migrating Tokio and Tower to azure pipelines (more projects will come). Everything is pretty good. I really really really would like some level of FreeBSD support :) Besides that, my biggest feature request would be some way to define nested jobs. i.e., i would like a job to be comprised of multiple sub jobs. This is pretty brittle: https://github.com/tokio-rs/tokio/blob/azure-pipelines/azure-pipelines.yml#L106-L115 I would like to define a single "Test" job that has many sub jobs for all the various aspects to test. Thanks!
Rust 3DS: https://github.com/rust3ds/rust3ds-template
Note that you'll need `nightly-2018-08-18` for this since I haven't updated it in forever.
I hear ya will check the link - it may be some blissfull ignorance or an old lesson I learned about data lifecycles in c/c++. 
I don't know anything about the official nintendo tools/sdk, but we do have rust (kinda) working with a homebrew sdk called devkitARM. The repo is [here](https://github.com/rust3ds/ctru-rs) and there's a template project [here](https://github.com/rust3ds/rust3ds-template). I say it only "kinda" works because reimplementing libstd out of tree means relying on every unstable feature under the sun, so right now it's stuck on `nightly-2018-08-18` until I get around to updating it for recent versions one of these days.
Hi again, Carl! The rust build itself runs a CI inside a FreeBSD container IIRC (https://dev.azure.com/johnterickson/rust-lang/_build/results?buildId=393) but that definitely isn't as seamless as I'd want. Send your vote here: https://developercommunity.visualstudio.com/idea/449932/support-freebsd-andor-other-bsd-systems-vms.html
This is bounds checking; Rust panics on OOB Vec access instead of either segfaulting or returning data from something adjacent in memory.
There are libs for both JWT and CORS in Rust that can be integrated into any web framework. But at this point I'd say that ActixWeb and Rocket have the most complete ecosystems and documentation. There are examples for CORS support, JWT and others. Actix Web [https://gill.net.in/posts/auth-microservice-rust-actix-web-diesel-complete-tutorial-part-1/](https://gill.net.in/posts/auth-microservice-rust-actix-web-diesel-complete-tutorial-part-1/) and Rocket [https://github.com/marcocastignoli/rust\_rocket\_api\_authentication](https://github.com/marcocastignoli/rust_rocket_api_authentication) &amp;#x200B;
Ok I'll give that a try! The intellij plugin is pretty good, but i feel like everytime i run cargo check it finds tons of errors.
Yes it panics but the point I was trying to make is that is not checked at compile time.
Thanks, I shall.
The RLS extension should find all the same error, but it can be slow and crash sometimes. There isn't yet an experience as nice as what you might be used to from things like Visual Studio or Java IDEs. &amp;#x200B;
&gt;Error reporting is sub par. Some errors were reported. Other errors caused the job to not even be queued which made me think that AzDO had a bug, was backed up in polling github, etc Hello I am a PM on the Azure Pipelines team. &amp;#x200B; I would love to get some more concrete examples of this issue so we can see how we might address it
Got through about 3/4 of it while munching on lunch. Will come back to it later. My takeaways -&gt; 1) Enums in Rust can act somewhat like unions in c, and (in c/c++) you can segfault or read memory incorrectly by mistreating the values held by two different references without additional checking. Would you believe I haven't read up much on Enums in Rust yet? 2) You can really mess things up by modifying the size of thing you're iterating through -&gt; this I've run into in c++ and worked around with either reverse iteration or looping up to a dim where in a single threaded process you have to keep the size of the thing you're iterating over in mind. These are things a c/c++ dev has to learn not to do but it's a best practices, hey don't screw up memory pact. You break it, you buy it. I can def see the appeal of the compiler saying "NO. That ain't gonna fly" instead of getting a runtime error. Honestly in a score of years (working closely with c++) I haven't seen much in the way of single threaded memory read/write errors like those mentioned in the post, but I haven't worked on HUGE teams. The largest was 10-15 system engineers at a time, and of those only a handful setup and managed the shared data interfaces. After I fell in love with Ruby, Python, NodeJS, Swift, and finally even PHP it's hard going back to c++ so I was looking for something close to the metal fast and relatively new.
Super cool feature.
My 3-yo kid says "I have wa!" when I leave the house.
I'm working on porting the Sundials IDA differential algebraic equations solver from the original C using `ndarray`. https://github.com/jondo2010/ida-rs
I was working on crate-ci/resources last night. In my PR, I'd sometimes mess up the YAML syntax and the job would get triggered and [show me an error](https://dev.azure.com/crate-ci/resources/_build/results?buildId=23&amp;view=results), nice. I can't quite remember what error I had that caused the job to not even get queued. A manual queue did show me the error. I know it was from a malformed `${{ if ... }}`. I think it was from `variables.Agent.OS` but am unsure.
I mean, there was a small attempt at a title that made any sense.
Are you sure? Navigating to the [latest build](https://dev.azure.com/tokio-rs/Tokio/_build/results?buildId=57), I see "Test tokio Windows" using "Agent: Hosted Ubuntu 1604", which is probably not what you intend!
* the keyword return is not very idiomatic, it's optional, and I almost never se it anywhere.
Thank you so much for kicking this off! You'll see me chiming in on some of the issues and creating new ones over the weekend. I do think creating a one stop shop for CI needs would be a huge resource to the community
Ah yep :(
Ok thanks for those details. I will see if I can repro based on what you have provided here.
Hmm looks like the cross-gnu on the success ( https://dev.azure.com/nbabcock19/nbabcock19/_build/results?buildId=98 ) is landing on a Windows VM ("Hosted Agent"), too. I'm on parental leave from work, but will check in with that team later today.
Nitpick: I think it’s a bad idea to handle percentages programmatically. They’re for humans and represent a [proportion](https://english.stackexchange.com/a/286524/12955) in the interval \[0,1\]. If we want to display them as percentages, that’s a job for the formatter (sadly rust doesn’t have the `%` specifier for things like `format!("{:.1%}", 0.1221) //12.2%`). Luckily Rust has newtypes, so we could define this type: We wrap an integer, only that its interpretation is integer\_value/max\_integer\_value, so for a `P8`, the possible values would be {0/255, 1/255, …, 255/255}) In other languages there’s floating point numbers that can be used, but we sacrifice bits that could be used for precision.
I don't know if this is an easy question or not, but I'm looking at the documentation about std::env::current_exe() and there is a security warning, but it is still unclear to me what counts as safe vs unsafe (in the general sense, not the Rustacean sense) usage.
It is not. The regression is recent. The link you pointed to is for a build that is a few days old. A recent build is showing the regression: https://dev.azure.com/nbabcock19/nbabcock19/_build/results?buildId=146
I'd like to point out that the answer you're linking to is from 2012. These days, various Linux distributors have moved to [pkgconf](https://git.dereferenced.org/pkgconf/pkgconf) as their implementation of pkg-config, which is less messy to install on Windows.
In Rust you'll often hear something like "oh hey I parallelized my program and it now runs 4x faster just by adding Rayon as a dependency and changing `iter()` to `par_iter()` in this one spot". The reason that can just work is because of Rust's focus on being correct. This applies to many other things that would require a deep study of existing code in C++.
I submitted an issue here: https://github.com/Microsoft/azure-pipelines-yaml/issues/134
For the last one I'd iterate over the words in "add Sally to sales" Then you could assert stuff the first word has to be "add" the 3rd has to be "to" and there can't be more than 4 words. This should be easy with an iterator that splits on whitespace. 
If not, let me know and I can try to take another turn at it inbetween the other things I'm doing.
A good place to start for idiomatic code would be to run "Clippy" (under tools in the Rust Playground) and look at the suggestions in the feedback. For Exercise 3 you could possibly split by whitespace and collect the contents into a Vec. That will allow you to reference the user in v[1] and department in v[3] within a single arm of a match statement. I think a check on the command argument to make sure it contains "Add" and "to" early in the function would be handy for an early return. Apologies I would share an example if I wasn't on my mobile. Hope that helps.
&gt; An initial object of a category C is an object I in C such that for every object X in C, there exists precisely one morphism I → X. Would I be correct in saying that for Rust's never type, that morphism would be `match x {}`? It could never be called, so it could never return anything other than nothing. 
Def def love to hear this.
C's `void` type is closer to `()` than `!`, so it makes sense to represent a type with values as a type with values.
 &gt;So you'll end up with a bunch of `Option&lt;Rc&lt;RefCell&lt;Node&gt;&gt;&gt;` or `Option&lt;Arc&lt;Mutex&lt;Node&gt;&gt;&gt;`. This annoyed me a lot in the beginning. In practice, after a while, it has rarely been a problem. I often instead realize that only one or two fields in Node needs mutability, so the Mutex is moved inside (interior Mutability, apparently it applies literally). And often I find ways to change the model to avoid at least some Options, improving other aspects in the process. In general, Rust forces me to really think about the problem. It's frustrating, and completely awesome.
For exercise 1, I wouldn't use the hashmap if you sort the vec anyways. On a sorted list you can get the most frequent element by iterating once over all elements. You just have to remember the maximum and the current value. Pseudocode: Maxelement = list[0] Maxcount = 1 Element = Maxelement Count = maxcount For i = 1 upto list.length If (list[i] == Element) Count++ Elseif (Count &gt; Maxcount) Maxelement = Element 
I'd suggest you get some ARM Cortex-M based hardware. STM-32 uC (for example a discovery board http://www.st.com/en/evaluation-tools/stm32f3discovery.html) are a good start and have good support in the Rust ecosystem. The discovery book (https://rust-embedded.github.io/discovery/) is a good starting poin. 
An [archived copy](https://web.archive.org/web/20190301191722/https://svartalf.info/posts/2019-03-01-exposing-ffi-from-the-rust-library/) available from Russia.
Thank you very much, looks promising!
[Awesome Embedded Rust](https://github.com/rust-embedded/awesome-embedded-rust) I personally haven't messed with Embedded Rust yet (still waiting on my dev boards from AliExpress), but there seems to be many guides on how to start with STM32 boards ([Using Rust with the "Blue Pill"](https://medium.com/coinmonks/coding-the-stm32-blue-pill-with-rust-and-visual-studio-code-b21615d8a20)). &amp;#x200B; If you're not using any analog input pins on your Arduino projects, consider trying out a Raspberry Pi ([There's a great Rust GPIO library](https://github.com/golemparts/rppal)) since it's got multiple CPU cores and built-in networking. There are many guides on how to cross-compile your Rust programs to run on the Pi (it's relatively easy).
And unfortunately, since SDKs tend NOT to be open-source, there's not much the community can help with apart from lobbying console companies :/
Thanks, yes stm32 sounds good, probably that will be my course I do have raspberry, but it's too bulky and probably not the best power consumption due to full blown os. Still could use it for bread boarding though
It's even worse, you need to sign a non-disclosure agreement to access them. So no studio can go "here's the rust compat layer that we developped for the SDK". If you want it, you build it from scratch.
https://gcc.godbolt.org/z/9ZU6vw I don't think that this is true. They don't spit out warnings.
&gt;recursive data that may have mutable references to its parents &gt; &gt; is basically a tree structure, Perhaps I'm misunderstanding, but isn't the lack of references to parents are fundamental part of the definition of a tree or DAG?
Bound checking usually refers to the runtime check of the bounds. Your example is the demonstration of the bond checking at work : the program fail cleanly with a panic, while [in this C++ exemple](http://tpcg.io/yjk24P) fails to detect the problem and corrupt surrounding variable without warning. The Rust compilers can perform some sort of compile time checking, but it will always be very limited. In this [very simple example](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=2d332c79ccb94f0907c2acb010d2dbbe) you can see that Rust can't detect the overflow at compile time, even on a statically sized array, as soon as the index is not a constant value.
Huh, maybe it was clippy that complained then? This just happened very recently, so I'm surprise I can replicate it here. 
This is very well written good job OP
Wrong sub reddit 
In example 2, I would consider it better to represent logic inside of the match expression, instead of returning early from the \`None\` case and handling the happy path after the match expression. ex: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=79b9b2038635e3b468f1f8bb88b4252a](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=79b9b2038635e3b468f1f8bb88b4252a)
It is more idiomatic to use &amp;[T] than &amp;Vec&lt;T&gt; in a function signature because Vec implements the Deref Trait which means it is automatically converted. In most cases this is better. For the first task I would split each operation in one method but that is only an exercise. I rarely see expect on an Option. You could use instead match or if let to destructure the Option. However, in this case I would check at the beginning of the function if the Vec is not empty and either panic with assert! or return an error (the return type must be an Result then). You can dereference an element with pattern matching. for &amp;i in l { // i is of type usize } Calculating the mean could have been done with Iterators. let mean = l.iter().sum() as f64 / l.len() as f64; or let mean = l.iter().fold(0, |acc, x| acc + x / l.len()); The median could have been also calculated with the HashMap because it is in essence similar to an histogram. The code for mode could have been simplified with it too. let bucket = HashMap::new(); for &amp;i in l { *bucket.entry(i).or_insert(0) + 1; } // calculate where the middle is in the list let len = l.len(); let middle = if len % 2 == 0 { // handle case } else { len / 2 }; let mut median = 0; let mut counter = 0; for (number, count) in &amp;bucket { // find biggest value if count &gt; mode.1 { mode.0 = Some(i); mode.1 = count; } // add count to counter until the middle is reached if counter &lt;= middle { median = i; } counter = counter + count; } The median is the value of an element in the list which is why you should at least cast it to the type of the elements and not return a float in this case. I will check out the other exercises later.
You should try using [Criterion](https://github.com/japaric/criterion.rs).
I'm considering that idea for the last few days, actually, but still don't have a final decision -- while it looks better to introduce meaningful types instead of, say, `f32`, I'm not sure yet how these types should look like. Maybe you can suggest something to read about it?
About as often as credit card numbers, phone numbers, and email addresses, I would imagine.
Winapi-rs ([https://github.com/retep998/winapi-rs](https://github.com/retep998/winapi-rs)) readme gives an example: ``` #[cfg(windows)] fn print_message(msg: &amp;str) -&gt; Result&lt;i32, Error&gt; { use std::ffi::OsStr; use std::os::windows::ffi::OsStrExt; use winapi::um::winuser::{MB_OK, MessageBoxW}; let wide: Vec&lt;u16&gt; = OsStr::new(msg).encode_wide().chain(once(0)).collect(); let ret = unsafe { MessageBoxW(null_mut(), wide.as_ptr(), wide.as_ptr(), MB_OK) }; ``` What if I wanted to use `MessageBoxA` so ASCII instead of UTF-16? I cannot figure out how to do it. `MessageBoxW` requires `*const WCHAR` while `MessageBoxA` uses `*const CHAR`.
 &gt; proper error handling looks messy. Why can't I question mark all over? (does this count as a pun) I'm unwrapping until I get a rock solid understanding of what's going on between Error conversions. I'll reread the section a few times in rust by example, multiple error types. I definitely tripped over error handling a bit when I started rust, but now it's one of my favorite parts of the language and I miss it dearly in others.
I just committed support for RUST debugging in `dap-mode`. You may be interested - https://github.com/emacs-lsp/dap-mode/blob/master/screenshots/rust.png . (Also `(add-hook 'lsp-mode-hook 'lsp-ui-mode))` and `(push 'company-lsp company-backends))` are not needed).
The two of you are correct and I had misread while checking quickly from my phone. I've confirmed that the right people are looking into this and you can track in the issue created by Carl: [https://github.com/Microsoft/azure-pipelines-yaml/issues/134](https://github.com/Microsoft/azure-pipelines-yaml/issues/134) 
Ideally we'd also develop [guidelines for preludes](https://github.com/rust-lang-nursery/api-guidelines/issues/140) so we can help people have higher quality preludes. Personally, I avoid using or creating preludes though I do have a couple of crates that use them for exposing traits (assert_fs, assert_cmd, predicates)
or "logical `and` and `or`" or "logical `&amp;&amp;` and `||`"
If you're writing functions that take borrow's when possible and return `Result` when necessary, you're probably not going to do badly. We can nibble around the edges of style all day, but in the end your code is somewhat brute-force but generally fine. Clippy is a very good resource for suggesting improvements.
Of course you can do that, but you need to understand what are you doing at first :) As for me, I've barely used FFI before and it was a good learning step both in FFI and unsafe Rust. But you are right, I should have mentioned other tools too, I'll add a link to `rust-swig` into the post.
Thanks so much for your help (here &amp; twitter).
What sold `npm` folks for Rust over node.js was reliability, not performance. They were delighted that they didn't have to debug sporadic exceptions in production anymore.
I believe it. One major benefit that I've discovered with Rust is that after a while you gain this intuitive understanding of what the compiler's doing, and I've found that after fighting with it to get it to build you end up with much more confidence in the final product. Which _also_ has the added benefit of increasing one's trust in the entire ecosystem. While there's nothing to prevent a crate from doing something malicious, there's an entire _class_ of issues and bugs that you don't have to worry about coming from 3rd party libraries.
That's so cool! I'm glad Rust is making your life better too :)
I'm guessing that `MessageBoxA` takes nul-terminated ASCII? If so there are a few ways to go about this. The key thing to realize is that the `MessageBoxW` example involved turning the `msg` string into a sequence of 16-bit code points, whereas the ASCII version wants an 8-bit sequence. Now Rust strings are already 8-bit sequences by default so you're already halfway there. But Rust strings are not nul-terminated, so if you try passing a pointer directly to `msg` then you will have Problems. An easy way to avoid that problem would be to turn the `msg` string into a `CString`, which will copy the message into a new type with a nul-terminator. Then you can use `as_ptr()` which will give you a `*const c_char`. It would look something like this, assuming that the `MessageBoxA` function call is similar to its W counterpart: #[cfg(windows)] fn print_message(msg: &amp;str) -&gt; Result&lt;i32, Error&gt; { use winapi::um::winuser::{MB_OK, MessageBoxW}; use std::ffi::CString; let nul_terminated = CString::new(msg).unwrap(); let ret = unsafe { MessageBoxA(null_mut(), nul_terminated.as_ptr(), nul_terminated.as_ptr(), MB_OK) }; }
Awesome, thank you! I think i got close to that at some point when trying out CString, but Intellij-Rust keeps displaying `expected *const i8, found *const u8` when using `nul_terminated.as_ptr()` in `MessageBoxA()` so I got really confused. Turns out running \`cargo run\` from command line doesn't display such errors tho. 😅
So it's still not working then? `c_char` is an alias for either `u8` or `i8` depending on which version C uses for its `char` type on your platform, so I'm surprised that you're running into an incompatibility there.
Yeah, I really should have asked this. I posted the link first because I was curious if a bug in llvm or so could ever nullify the safety of Rust in the general sense. How does anyone verify something like this preemptively?
It works great. Earlier I just assumed it didnt since Intellij-Rust keeps displaying the errors. 😅 
I would really go with a blue pill I think. It got really good support and works fine.
&gt; Which also has the added benefit of increasing one's trust in the entire ecosystem. While there's nothing to prevent a crate from doing something malicious, there's an entire class of issues and bugs that you don't have to worry about coming from 3rd party libraries. I think that's an underappreciated benefit of Rust. Not only does it help improve your code quality, but that of all your dependencies too. I obviously wont use just any library, but I'm a lot more willing to use a random obscure library in Rust.
I haven't watched it yet, but I think the docs are talking about `arg[0]` as an attack vector, so this, about getting into the multi-user game group on a typical desktop unix-like, would be the kind of thing it's talking about. 
I see. However after a small look sound like not exist anything alike Flask(python). &amp;#x200B; &amp;#x200B; P.D: Any reason to expect it to fail on iOS/android?
I would still consider `A | B` to be a single pattern, the same way that `/A|B/` is a single regex. If it fits in a single match-arm, why not let it work in an `if let`?
An easy way to "expand" a prelude might come in handy too. 
Somewhat related: `version-sync`
We have a similar impression over at ThreatX too. Reliability of code and engineer productivity have been the biggest selling points. We love that it's fast but in the end hardware is always cheaper than engineer time and production issues.
Yep, Dropbox is using it in production, too. 
Sweeeeet! Not used Rust other than evaluating it for a week but of that doesn't convince them, go work somewhere that appreciates your talents mate.
Interesting! Do you have data of latencies and error rates?
/r/playrust. Also, what's with the link?
Uhm, cpu and memory utilization is based of the actual reservations you have set for the service in your task definition. Without equal values for them, the graph will give you a skewed reality. I don't know what the default is if it wasn't specified, maybe total of what's available on the container, meaning that the ec2 type will affect it in that case. 
We removed the warning given the large number of successful production deployments.
Who knows what weird virtualization stuff is going on. You need to go back and test max throughput.
Avg response time looks like it's hovering around 70ms Error rate is almost entirely due to invalid `Content-Length` request headers, which cause `actix-web` to return a `400`, and those happen roughly 2-3 times per minute (so an error rate of 0.02%)
Question as someone new to Rust code. That first code blob looks, to be frank, disgusting. Is there a way to write "idiomatic" code that doesn't put the entire expression on a single line?
&gt; I tried to keep it as close to an identical rewrite as possible. How did you compare API responses before deploying? Whatever the case, sounds like it was a success!
Well, the link should have been https://users.rust-lang.org/t/low-fps-need-help/25802, but..
Rust has two great value propositions. * Give safety to systems programmers. * Give speed/control to programmers using safe languages. The original motivation for Rust was the first. This is a great example of the second.
You don't habe to write everything into one line if you don't like it. self.deps .entry(department.to_string()) .or_insert_with(Vec::new) // note: ::new not ::new() .push(tokens[1].to_string()) &amp;#x200B;
You can use `let` to create intermediate local variables. Those long chained expressions get easier with time and experience, but sometimes I find them a bit much.
To be fair, you're also comparing a stack of components to each other, not just languages. I've benchmarked Javascript and it is very fast.
How would you rephrase that block of code using that form? Without performance loss?
Yes, that is absolutely fair.
Same goes for type inference, examples should annotate types even if it's not strictly necassary
Both implementations are meant to be as absolutely fault-tolerant to calling code as possible: any recoverable errors are logged, and the response is always a simple `200 OK`. It's solely an ingest API
To be clear by "one line" I meant "one phrase between start of expression and the finishing ';'". I'd never write it in one phrase like that if I could avoid it.
Great article but no idea how to use those charts. They don't even render in a single window forcing you to scroll to see them, they don't appear to be labeled either.
Although that library requires Linux, I believe there is also support for running Rust directly on a Pi without Linux. 
[https://benchmarksgame-team.pages.debian.net/benchmarksgame/faster/node-gpp.html](https://benchmarksgame-team.pages.debian.net/benchmarksgame/faster/node-gpp.html)
You either have to use lots of if elses, or you use the feature of chaining fn like here. Both ways are available in rust.
A quick warning: If you build trees with `Rc`, you need to ensure one side of the parent/child relationship is `Weak` or you will leak the entire tree.
one additional note from the docs &gt; The `Arc::clone(&amp;from)` syntax is the most idiomatic because it conveys more explicitly the meaning of the code. In the example above, this syntax makes it easier to see that this code is creating a new reference rather than copying the whole content of foo.
That was interesting. The version of Node seems very recent. But I wonder why the Calc Pi had bad output, there's no reason JS can't calculate Pi if a correct algo is given.
Try compiling with --release?
What?
Well, this is when a **Benevolent dictator for life** (**BDFL**), is needed. If something like this is too democratic, then will be stuck forever. &amp;#x200B; Let's be honest, somebody decide a function in rust is called "fun" and that is. &amp;#x200B; Never forget: &amp;#x200B; "If you allow the customer to choose.. IT WILL CHOOSE!"
Have you rolled this into production yet? Or is it still in the development/testing phase?
&gt;The first thing we should do is to ensure that passed pointer is not NULL: `assert!(!ptr.is_null());` You really should do it each time for each passed pointer, because your input is not safe and you should not always expect a valid data, so it is better to panic earlier expectedly than do some undefined behavior. Doesn't unwinding across FFI boundaries lead to undefined behavior? If `ptr` is null, this will panic, which often means it will unwind. From the [nomicon](https://doc.rust-lang.org/nomicon/unwinding.html): &gt;You must absolutely catch any panics at the FFI boundary! What you do at that point is up to you, but something must be done. If you fail to do this, at best, your application will crash and burn. At worst, your application won't crash and burn, and will proceed with completely clobbered state.
Just gotta audit how many unsafe usages there are. But even in that case, the compiler still does a lot for you.
FYI actix-web has a build in \[http client\]([https://actix.rs/api/actix-web/stable/actix\_web/client/index.html](https://actix.rs/api/actix-web/stable/actix_web/client/index.html)) so you don't really need reqwest even though its a nice library anyway :)
I would say the benefit is that you can have a portable, consistent UI that can be used by Rust code regardless what is installed in the system.
The best part is those random errors that you'd see, because you never programmed in the expectation of a random undefined or some random type other than the one you expected, never happen. All the previous faff you'd do to avoid error checking is just built into the way you build your apps. &amp;#x200B; I've been running rust for a high performance ad and analytics situation for over a year now and its saved me countless hours of operations headaches.
You wouldn't normally count 400 as errors, as it's the clients sending incorrect requests to the server. Unless you want the server to ignore the header and try to handle them some other way.
This is true. There's been a few efforts to make panics simply abort when used over FFI (one such effort [got pulled out](https://github.com/rust-lang/rust/pull/58795) of yesterday's release at the last second!) but for now the behavior is considered undefined.
There is always a hidden cost when you buy into a Microsoft product.
There are good reasons for each of the arguments at play here. Someone “just choosing” isn’t going to lead to the best outcome; it just leads to an outcome. Too much pressure for “just pick a thing” means a significant degradation in quality, especially over time.
You can convert the stream into a future which yields the first item and the rest of the stream. It's not quite as nice as a single combinator though stream.into_future() .map(|(msg, stream)| { println!("This is the first message: {:?}", msg); stream }) .flatten_stream() // this turns it back into a stream // use rest of stream
Amendment to the println of the department. Actually, yo do not need the print function for this particular excercise, sind HashMap and Vec and String and all that impl Debug you can just do: for dep in company.deps { println!("{:?}", dep); } [https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=98daa846af63d82174832d0e679bf520](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=98daa846af63d82174832d0e679bf520)
Thank you for the help.
[Average response time is not a great way to measure latency.](https://youtu.be/lJ8ydIuPFeU) Of course it depends on exactly what your system could be bottlenecking. I'd be quite curious to know what happened to your 99% or max, if you have that information.
just needs someone to submit a fix. or faster implementations. 
The most common issues here have to do with SUID binaries, like the `sudo` binary. The problem is that code in such a program might want to re-execute itself for some reason, and as part of doing that it might assume that `current_exe` refers to its own path, when in fact the calling user has arranged for it to point to something else (maybe through a complicated race condition). That can allow the user to execute programs as root that they're not supposed to be able to. The solution is usually to assume that `current_exe` is arbitrary user input, just like any other command line argument is, and to validate it (or ignore it) appropriately.
Then the error rate is currently zero
I didn't know that, looks like it's async too. Nice! Always happy to rip out a dependency
The graphs are from the production deploy, yes.
That's a surprising reduction in CPU usage. Can you share at all what kind of data transformation the API does? 
I highly recommend starting with an STMF32DISCOVERY and reading/working through the \[discovery book\]([https://rust-embedded.github.io/discovery/](https://rust-embedded.github.io/discovery/)).
How would one validate it?
JavaScript is very fast in specific, contrived examples. Like doing a lot of pure integer math in side-effect-free functions. Try some floats and degrades 100x. Call the same function sometimes with integers and sometimes with floats and it degrades even further. Source: spent a while optimizing both a real-world computation-heavy JS codebase as well as small, isolated functions written from the ground up. The 100x difference figure is against asm.js running in Chrome, native code would probably be even faster.
and you can stream the actix_web::client request to a server response https://github.com/actix/examples/blob/master/http-proxy/src/main.rs#L27
Awesome! I recently try to port my graphQL API with Rust. How did you deploy Rust API to aws ec2? Did you use docker? or any other way?
Compare the binary at the path to the one currently running, somehow. Either with signatures or hashes of the executable segments, I imagine.
I have some similar graphs from a nodejs service I ported to Rust just recently. An added benefit is my latency became a lot or consistent and average latency dropped as well. Essentially the same Rust stack except for external requests I'm using the built in HTTP Client in Actix-web.
Indeed, but as I said in every parent comment, that's transmuting pointers, not values. I definitely agree that transmuting pointers can be problematic, but given the definition of: pub unsafe fn transmute&lt;T, U&gt;(e: T) -&gt; U checking the alignment of `T` against the alignment of `U` is *not* helpful. Of course, it is useful if it checks the alignments of `X` and `Y` when `T = &amp;X` and `U = &amp;Y`.
How easy did you find the rewrite? Especially from an FP perspective, there's a lot I find cleaner and more expressive in rust so far, e.g. the iterator syntax and everything being immutable by default (the idea of immutable.js seems ridiculous to me now), so I can think of a lot of extra noise I could do away with completely in many of my projects. On the other hand, js objects are incredibly easy to work with, and it's so easy to pass around/spread into props. Did you go with thread-based parallelism, or did you use something like Futures to keep it close to the js promises way of handling concurrency on a single thread?
Yes! If a child has a reference to a parent, then you have a two node cycle which clearly violates the acyclic property of a DAG. _Actual_ trees are pretty nice to work with in Rust.
When it runs it's Rock solid. The samurai had an old saying. Cry in the dojo laugh on the battlefield. The idea being if training is hard combat will be easy. Rust very well makes you cry in the dojo. But your app will work, barring logic bugs.
One more thing: Vey idiomatic would be to implement the trait Default. When you implement Default you get an additional fn default() -&gt; Self {..} Since you are instatiating Company with no arguments, that would be a case to create an instance with default and let the new function create a company with a pre-existing departments collection: [https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=ced1874931dfe6fb46bbc5a98899a640](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=ced1874931dfe6fb46bbc5a98899a640)
You could just use inode numbers. The problem is that doesn't actually tell you anything about the path. Anyone can make a path point to any inode.
Damn, I think you found the Achilles heel of my benchmark tests, I did simple sorting or both integers and strings. Damn it was impressive!!! I'll take a deeper dive now based on your guidance.
Could you please elaborate what missing features are we talking about? 
Ironically I’m in the process of building a simple but high volume web server/proxy replacing a Koa app. I too have been looking for a good Rust project, will definitely be looking at this for inspiration.
I think stabilizing `await!(...)` is the best short term and in the long term the optimal solution will become evident.
Nice!
I've been working with the unstable async/await/futures 0.3/etc. for a while now, and constantly rant about how frustrating the whole system is on Twitter. I'm really glad to have an update from a Rust team member on this issue as there's been nothing for months on what seems like a major priority to me. Sadly, other than confirmation that the team is paying attention, this update doesn't excite me, and in fact worries me. Stabilization for "early adopters" seems like a very unfortunate outcome. I would describe the nightly compiler's unstable features as being for this purpose. The fact that not even Tokio, the premiere async runtime for Rust has bothered to offer true integration with futures 0.3 makes no sense to me, and if Tokio is not the prime candidate for early adoption of an unstable feature, I can't imagine who else would be. To suggest that something that hasn't been put through the ringer on Tokio should be _actually_ stabilized makes no sense to me. I don't want to see a crappy compromise on stabilizing async/await just cause of public pressure. But I do want it to be a priority _across the async ecosystem_. I personally don't care at all about the await syntax, and have been very unhappy with that bikeshed being such a focus of time and discussion. The real problems I have with the unstable async system are how difficult it is to reason about. Compiler errors are still largely indecipherable. `impl Trait` didn't really help here. Documentation is still sparse, so I spend a lot of time banging my head against the wall, trying many formulations of my programs to get just the right incantation of futures wrapped in futures wrapped in futures to get things to compile, only to get page-long type mismatch errors that are near impossible to read, and multiple closures/functions deep of nested futures being returned where any of them could be the culprit. I'm also very frustrated by the lack of progress on "abstract types" that are required for using async functions (and returning `impl Trait`) from trait methods. Traits are the cornerstone of Rust's type system and yet I haven't seen any activity on this for months. And now we're talking stabilization with this glaring hole. Async streams are another thing I've seen almost no progress on, aside from a blog post from withoutboats on how to deal with the `?` operator within async for loops. As much as I want the future where this all works and is stabilized to be now, I much more want serious buy in from all the major parts of the async ecosystem. Libraries like Tokio, Hyper, etc. should be all-in on the feature's suitability and ergonomics _now_, while it is unstable. I'm happy to keep using nightly Rust, as I've been doing that for Rust's entire post-1.0 existence anyway. Give me something to be excited about. Not something I fear is going to stabilize in a form that will turn me off for good. (This is pretty ranty, but I hope it's valuable to get my real feelings about my experience out there. I mean no disrespect to any of the people who have been working on this stuff. Thank you for your work and the one-day-to-be-great system you're preparing for us all.)
What I really want is Knuth-Plass text layout. I have a project that I tried to work on a couple of years ago that will be benefiting enormously from all this work, and someone other than me implementing Knuth-Plass would be the cherry on top. (I implemented it simply, but it’ll probably need another full rewrite on top of Skribo and the rest of the ecosystem when I get back to the project.) Then eventually apply that to Firefox too, and the few that notice will rejoice as https://bugzilla.mozilla.org/show_bug.cgi?id=630181 is closed RESOLVED FIXED.
The pattern grammar needs to not include `|`, because some places that take patterns would not work with it. Consider function argument binding: it doesn’t make sense to allow multiple patterns there. You could allow it syntactically but deny it from compiling, but that would be messy. But the real nail in the coffin: consider *closure* argument binding. Due to the use of `|` as the delimiter around the argument list, `|` in an argument binding would be syntactically ambiguous.
I tend to think that it should use “or” instead of “and” anyway: &gt; Can we use logical and or or yet in const fn? Or just “`&amp;&amp;` or `||`”.
In **exercise 1**, you use tuples, and get elements inside tuples with the dot syntax (e.g. line 7). A much better way is to use destructuring: let (mean, median, mode) = data(&amp;foo); println!("Data: {:?}\nMean: {}\nMedian: {}\nMode: {}", foo, mean, median, mode); Descriptive variable names are almost always better than numbers. This also applies to the `mode` variable in line 15: There's no good reason to use a tuple here. Just use two separate variables with descriptive names. In **exercise 2**, you pass a mutable reference of a string to a function that modifies the underlying string. However, there are good reasons why everything is immutable by default: Pure functions without side effects are much easier to reason about. So, a more idiomatic solution would be to pass an immutable string to a function that returns a new String. Here's the corrected code: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=440a3d93194363d41a12f764cc8751f4](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=440a3d93194363d41a12f764cc8751f4)
I have a read through this, looks like they haven't started using it yet though. I was originally put off by tower grpc because of the "don't use in production" warning and thus didn't mention it in my original post, but this warning has since been removed.
Having had a brief look at the API documentation for tower-grpc I would certainly say tower-grpc looks far less awkward to work with than the other rust gRPC implementations. I'll definitely be taking a serious look at bringing tower-grpc to production at work. Did you experience any gotchas or difficulties when using tower-grpc for your production project? &gt;Edit: poor wording, written late at night after a long day of hacking. Still, not as bad as the title I wrote after a long day of hacking :P &amp;#x200B;
Even if you *do* buy something else like an STM32 Discovery, you can order a blue pill for under $2 US (with free shipping) from AliExpress and a programmer for it for about the same amount, so you might want to order one anyway, just to play with. (Just search "stm32 board", check "Free Shipping", and sort by "Price: Low to High", then do the same for "stlink v2".) There are just a few minor caveats to keep in mind: 1. It can't be programmed via the USB until after you've loaded a bootloader onto it using another programming method. 2. They pinched pennies by not including proper power isolation, so never plug in both the power line from the programmer and a USB micro cable at the same time unless you want to fry it. 3. They [populated too weak a pull-up resistor](http://wiki.stm32duino.com/index.php?title=Blue_Pill#Hardware_installation) on the USB data line, so, depending on how much of a spec lawyer your motherboard is, it might not recognize the device reliably until you run a second resistor from the 3.3V pin to the A12 pin. (The USB data lines are broken out on A11 and A12 and, when you wire two resistors in parallel, you [drop the total resistance](https://www.allaboutcircuits.com/tools/parallel-resistance-calculator/). I just stick it in a breadboard and then stick the resistor into the breadboard.) Here's [STM32Duino's page on it](http://wiki.stm32duino.com/index.php?title=Blue_Pill), complete with pinout diagrams and info on the resistor problem.
Yes check out Stanford’s cs140e of last year !
I think it was the "you'll regret it" part of your warning that really put me off even bring up tower-grpc in my post. :P Do you have idea of what companies are using it in production right now? &gt;It's just that the API is actively being refined... I'm assuming this could mean some breaking changes in the near future, is there an aim for when this project will release its first version? &amp;#x200B;
I have had a look at the API documentation for grpc-actix, and whilst I'm leaning towards tower-grpc I will still be writing a POC in both grpc-rust and actix-grpc.
DMA and ADC support in HAL (though there are PRs).
Do I still get a participation medal? &amp;#x200B;
I see, I guess as long as these are software problems, that's fine. In meantime I already bought a pack of 5 blue pills. 
Curious of this as well. We're using graphQL + .net core 2.x hosting on an Azure VPS. So I'm curious if there's an advantage of porting over to Rust and replacing the system.
I have a small snippet of unsafe code which boils down to [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=51dd854194d14672ee985b0d8025cf09). I would like this to run on embedded, but I don't have any way to test at the moment. I've read that alignment can be a big issue on some non-x86 platforms, so to my question: is the code linked above correct, at least as far as guaranteeing I always have a properly aligned Header?
Try \[clippy\]([https://github.com/rust-lang/rust-clippy](https://github.com/rust-lang/rust-clippy))
To use it right now, do I need to include the crate locally? It doesn't look like there are any versions on crates.io.
Dependencies not all showing on melpa/GNU. Where did you source the other bits from?
Hey, thanks for responding! &gt; return statement is optional This I already knew, but it's really hard to break old habits! Luckily, someone else mentioned this linting tool called "Clippy" which I think will really help me with catching these sorts of things. *** &gt; I don't understand what the fn list_user_by_department is for that is called from print_users_by_department. An alternative could be the following. You basically just want to print the entire department I always code programs with modularity in mind. If I only wrote a function to print the users, it wouldn't be reusable for other functions. Of course, I'm not going to use this program in the future as it's just for an exercise, but this way to thinking was taught to me when I first started coding and now it's a strong habit. I wrote a printing function for the company because it was a lot of boilerplate in the main function to need to use a `match` on the option every time I wanted to print out a company's department. *** Making `add_user()` return a `result` is a great suggestion. So is splitting the command on `' '`. I'm stuck in my C programming ways and spoiled by `scanf()` so I tried to sort of fudge around missing `scanf()`. *** &gt; Just figured you want the employee names sorted. So after adding I am sorting the vec where you already have a mut reference available instead of in the print fn, which does not need a &amp;mut self I had thought about sorting the list after adding elements. The issue with that is that it's very inefficient. Assuming you know about "big o notation" here. Let's say we want to add `n` employees to the `Sales` department. ### Just adding employees, then sorting when listing: When adding employees, we just push to the end of the `vec`. This is a very inexpensive operation, being only `O(1)` time complexity. So if we add `n` employees, `n * O(1)` gives us an `O(n)` time complexity for the adding portion. Then when we want to list, we sort. The usual time complexity for the [sorting algorithm used by sort_unstable](https://github.com/orlp/pdqsort) is `O(n log n)`. That's a high order than `O(n)` so **the final time complexity is `O(n log n)`** ### Adding and then sorting right away First we push to the end of the `vec`, which is `O(1)`. Then we sort the whole `vec`. In this specific case where we sort the `vec` everytime and only 1 item is unsorted at the end, the time complexity of the sort is `O(n)` [\(Source\)](https://github.com/orlp/pdqsort#the-best-case). So adding an employee has a cost of `O(n)`. If we add `n` employees, **the total cost is `n * O(n)` which is `O(n^2)`**. The past 3 paragraphs could've been summed up simply as "we sort only once when we print vs sorting `n` times for adding `n` employees... but I've already written it up so I'm not deleting it. To drive home the point, if you plot `y=n * log(n)` and `y=n^2` on a graph, the difference is stark: https://www.desmos.com/calculator/rceqoaqwxd For a vec with just 10 employees, it's a cost of 10 vs 100. And that'll only get larger. For `n=20`, it's 26 vs 400. To put it simply, it's not just a small optimization. Sorting every time you add is *much much* more inefficient.
Very useful! Thanks!
&gt; A good place to start for idiomatic code would be to run "Clippy" That's very useful! &gt; For Exercise 3 you could possibly split by whitespace and collect the contents into a Vec. D'oh! So simple yet I overlooked it. I was too focused on the `scanf()` mindset. &gt; I think a check on the command argument to make sure it contains "Add" and "to" early in the function would be handy for an early return. 👍
Just use it as a git dependency: tower-grpc = { git = "https://github.com/tower-rs/tower-grpc" }
Aside from the standard wrestling with the borrow checker and type inferrence, it was actually pretty straight-forward. I went with Futures, as `actix-web` supports `Future&lt;HttpResponse&gt;` out of the box. And yeah, it looks a bit more like Promise chains than I'd like.
Now that you mention it, a hashmap really isn't needed. I assumed that I needed it because the exercise recommended to use it. Then again, it was good practice with using hashmaps, which was part of the point of the exercise. Still, a good suggestion!
Yes it's a docker image.
Not a ton, actually. It's primarily performing base64 encoding to the incoming payload and wrapping it in a json object with some other metadata. I was surprised at the CPU reduction considering it's mainly just waiting on I/O most of the time.
Using an array of `char`s instead of `&amp;str`s is a great suggestion. The type conversions seemed janky to me but I assumed it was something I just had to deal with. At first, I liked my version where I return early from the `None` case better than yours. But I think it might be a good idea to minimize uses of `return` as it's not considered idiomatic. Maybe the way you wrote it will grow on me after use.
As mentioned, Dropbox. The Linkerd2 proxy uses it, which various companies already uses in their production environments. The main design is probably pretty solid. There's been some recent work to clean up loose ends.
 Some notes: * Try using deoptigate to see where your code is deoptimized / constantly being deoptimized/optimized. Eliminate both of these things. * Try to ensure your code is (monomorphic)[https://mrale.ph/blog/2015/01/11/whats-up-with-monomorphism.html] * Absorb all the knowledge you can from mrale.ph to help you with these things!!! He's been my #1 source for improving my JS perf. Secondary resources: * A very good resource for improving perf: https://github.com/thlorenz/v8-perf#inspection-and-performance-profiling * A good introductory document to perf checking in Chrome: https://developers.google.com/web/tools/chrome-devtools/evaluate-performance/ * Some summarized / easy to digest good advice: https://www.smashingmagazine.com/2012/11/writing-fast-memory-efficient-javascript/ And finally, 
Sure, can't wait !
as a binary after compile?
&gt; It is more idiomatic to use &amp;[T] than &amp;Vec&lt;T&gt; in a function signature because Vec implements the Deref Trait which means it is automatically converted. In most cases this is better. Nice! This is similar to using `&amp;str` instead of `&amp;String` in function signatures too. &gt; You can dereference an element with pattern matching. Helpful to reduce clutter. &gt; Calculating the mean could have been done with Iterators. Haven't gotten to the iterator chapter yet, but it's interesting to see what's coming up. &gt; However, there is no need to first convert it to a String. You can instead leave it as it is and change your const VOWEL to an array of chars (single quotes). In hindsight, it seems kind of obvious. Another person suggested that too. &gt; Also, the format! macro is helpful with creating Strings. It works similar like the println! macro. Looks a lot better than what I had. &gt; Like most said, using split_whitespace would be reasonable. You can if you like though use slice patterns. I love it. Works exactly the same as `scanf()`. &gt; A lot of my recommendations are a little bit advanced but I hope it will help out later in your journey. That's fine. I also jump around a bit in "Rust by Example" so going a bit out of order isn't a big deal to me. These tips were very helpful. Thanks for responding!
Tokio has refused to update until its stable, so. I’d love it if they were willing to help test things out too, but I also understand not wanting to commit to something early. It is what it is.
&gt; As mentioned, Dropbox. The Linkerd2 proxy uses it, which various companies already uses in their production environments. Amazon soon, technically, as part of the Lambda runtime. But that's just me being me :)
My code is only generally fine because the rust book is really great. :) Clippy is a great suggestion. But it's not enough for dealing with the brute-force-ness, which is why I came here. So far, the suggestions have been really helpful! P.S. Happy cake day!
&gt; A much better way is to use destructuring ... Descriptive variable names are almost always better than numbers. Agreed. &gt; This also applies to the `mode` variable in line 15: There's no good reason to use a tuple here. Just use two separate variables with descriptive names. Also agree. My thinking at the time was that the two variables are closely related and don't make sense without the other. But it'd be just as fine to use `mode` and `mode_counter`. &gt; a more idiomatic solution would be to pass an immutable string to a function that returns a new String. The reason I chose to make my life harder and modify the string was because the exercise said "**Convert** strings to pig latin" (emphasis mine). The exercise could be interpreted as both modify the string or return a new string, but I took it literally. I do get your point though about the benefits of not having side effects. Thanks for responding!
Wouldn't this pull the latest version of master every build?
I'm aware of the situation (but thanks for mentioning this in case others are not) but I think it emphasizes what I'm saying. Also, romio does not contain everything tokio does, e.g. the file system APIs.
Yes. I used a multistage build image and copied the resulting binary to a final image and deployed that. 
Tokio is pretty massive as is, so it makes sense that Tokio would prefer to wait for some stability before expending volumes of effort to rewrite everything to a new standard. When testing out a new technology, you often want to work with small projects that can easily be adapted to major breaking changes. Quick rewrites make for quick turnarounds.
This is just an initial version with basic working `glTF` model import and a physically-based direct lighting engine. Currently, only point lights are supported. Next steps: * HDR rendering with a tone mapping pass * Diffuse and specular environment mapping * Directional lights * More robust `glTF` importing
I mean, I guess what I'm saying is, I agree with you, but it's not the lang team's fault that this is the case.
Cool! Thank you for your replies!
Yes, but Tokio is the #1 most used and highest profile consumer of the futures API. If the API's "biggest customer" won't even spend the effort to ensure the path is paved properly, why on earth are we expecting anyone else to? Or even discussing near-future stabilization? There's lots of downstream projects that can't properly experiment with their projects under the new system because they depend on Tokio and Tokio won't play along.
Sure. And in that sense I'll reiterate that I am not intending any finger-wagging blame at any individual here (including people working on the language and relevant libraries, even tokio). It's all about expressing discontent with the system as a whole for me.
Totally, and I think that's fair, just trying to be exceedingly clear. As you are :)
No, cargo will generate a `Cargo.lock` file recording a commit sha. It won't pull again until you run `cargo update` (or toss the lock file).
The morphism in this case would be `for&lt;T&gt; fn(!) -&gt; T` but its implementation would be `match x {}`. Remember that in the category we're working with, the objects are types and the morphisms go between objects.
If training is hard, combat is easy. If training is easy, combat will be short-lived. 
Personally I haven't started using async-await so I can't say I share the same frustrations but something that does impress me is the level of thought and consideration that goes into an implementation like this. Understanding your target audience is important and its clear that was understood when Rust moved from system programming label to a more generic programming language as it's grown in popularity and the users have diversified. I think any decisions will leave some of the community disappointed and others largely excited. I would like to think taking your time to ensure you've thoroughly covered the impact of any change will put the community in the latter and enable more users both new and experience to hit the ground running when the API is stabilized. In short, thanks for the efforts and keep at it. You're a very impressive team.
Hm, it is present in melpa - https://melpa.org/#/dap-mode ?
That's a similar process to what I followed when learning Rust. I replaced a Java/Kotlin application in my instance. I had a process that used \~10GB memory at peak. Think of a behemoth gRPC service that serves 20-30 endpoints, and does a lot of background work. After a few weeks porting to Rust, the binary that I deployed is using \~350MB, and I haven't been woken up by a memory usage alert since last year.
Check out hawktracer. I’ve used it and its pretty great
Cool, thank you for the extensive write up, I'm pretty much sold on stm32 already, can't wait to start prototyping
How does it taste? I've only had taro bubble tea once, and I thought it tasted like butter cookies (biscuits).
Let makes it read more like English. `let x = 0` is read literally "let x equal zero". Both make sense to me, probably because I started with JS. 
Yes it is a sad sight esp. when youre lost... r/playrust is where you want to be.
RLS can expand a `use foo::*;`, I do it regularly in VSCode.
&gt; I would really go with a blue pill I think. It got really good support and works fine if you don't mind rough edges (aka missing features). You could also buy a "black pill" which cost almost the same price, but all those problems are solved :)
There's experimental support in Tokio available: https://tokio.rs/blog/2018-08-async-await/
This note at the bottom of that post is why tokio-async-await hasn't been helpful for me (emphasis Carl's): &gt; First, the `tokio-async-await` crate only provides compatibility for `async` / `await` syntax. It does __not__ provide support for the `futures` 0.3 crate. It is expected that users continue using futures 0.1 to remain compatible with Tokio.
I have tried to get in under the hood of async / await to get a grip of how I may use it for some embedded applications. At this stage, what I would really like to see is some simple executor / Waker patterns or examples. So far I have only been able to file bogus compiler bugs when exploring this area : https://github.com/rust-lang/rust/issues/58814 
As a huge PUBG fan, this hurts my soul
The platform is specialized for real-time (extremely low-latency) audio and sensor feedback, but I \[wrote a library called bela-rs\]([https://github.com/andrewcsmith/bela-rs](https://github.com/andrewcsmith/bela-rs)) for the \[Bela microcontroller\]([https://bela.io/](https://bela.io/)) that wraps the C code in safe stuff. Same as Arduino, basically, as it's got digital and analog pins, except the analog pins are (mostly) audio-rate at 44.1khz. I love the Bela, and though it's a little spendy it's fantastic. 
We have 5 years of track record of running at high speed without having a BDFL model. Also, you make it seem like there's only two options, while we definitely don't run a "the customer chooses" model.
once async / await lands in rust, it will be a lot less like promise chains, but that still takes a while. Always looking forward to new things though
Apparently you don't know what API means.
Can anyone point me to a good article which explains the uses of async/await? I realise it's very popular with servers which do very little work themselves, and mostly make requests to other programs, combine the results, and send out a reply. What other things is it useful for? 
&gt;Just adding employees, then sorting when listing: You are most likely correct. In a slightly more realistic scenario you could insert a struct Employee into the HashMap and impl Ord, PartialOrd to do more sophisticated ordering too. ie by first name, last name etc
If X is "stored on stack" is just means that it, by itself, doesn't perform any allocations. A `Vec` is a fat pointer that points to some data on the heap. When you put a `Vec` inside another `Vec` then you have a fat pointer that points to some heap memory in which there is more fat pointers that point to different heap locations. I always refer people to this cheat sheet: ![](https://i.redd.it/moxxoeir7iqz.png)
Can u please explain what a "fat" pointer is? I am new to rust. Please don't mind if it's a basic question
It's a hell of a lot harder to write a libc for a platform that hides all of its system calls from application developers. Even on Linux, the OS's system call interface is officially undefined and you're supposed to only use the system's libc to interact with the kernel. On Windows and Mac, developers don't even have the option of looking at the libc to determine the kernel's ABI.
Ok I think I am getting it. So does this mean that the fat pointer of the inner vectors are stored in heap, which again point to some other locations in heap for the actual data,( assuming only two levels of nesting of vectors)?
I use rental for that in fluent-bundle (see resource.rs)
That reasoning looks right
Oh ok thanks for the response
This project is/will be the perfect introduction to rendy for me! Thank you!
Thats neat. Would you mind to tell me any pointer to learn how to use rendy? I have already had some bg knowledge around gfx-hal but i want ot know more about the rendergraph and other stuffs in rendy.
Or the worst latency per day.
&gt; Let makes it read more like English. Being French, I don't see the benefit :P 
The "fat" means there is some extra data next to the pointer, in case of a `Vec` that's the capacity and length.
Point of order: a vector's pointer is never null. An unallocated vector has a dangling non-null pointer value.
Yeah, that's why I put it in quotes.
So according to the picture u have sent ( which is very helpful btw) the box&lt;&gt; pointer is not a fat pointer right?
I think as AWS is insanely expensive there are cases where some optimizations are certainly worth it. We had a couple of months with more than 10k$ for just some more intense calculations. Investing a couple weeks to bring that down to 50% allows to hire another person. On our local machines we don't care a lot if the calculations take a day longer, of course :). That special case wasn't really a case for Rust as the computations were done by specialized C/Fortran libraries anyway. So yeah, a couple stars have to align to really have Rust as a selling point for optimization :). 
But why is this not implemented inside the filesystem in this case? It makes little sense to require special handling by the application?
Here's a slightly different version: [https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=919675cf006ba0c7218df7e62b4613c0](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=919675cf006ba0c7218df7e62b4613c0) However, the sort result is empty. Maybe you can fix that :)
I would say that you have the basic knowledge down with the stack/heap breakdown... it's just a matter of better qualification. In memory, a data-structure can be broken down in two parts: - **Direct**: the part of the data-structure that is *right there*. - **Indirect**: the part(s) of the data-structure that is(are) behind pointers. If you use `std::mem::size_of::&lt;Vec&lt;T&gt;&gt;()`, the size you get is the size of the **Direct** part. For `Vec&lt;T&gt;`, the code representation is: struct Vec&lt;T&gt; { ptr: *mut T, len: usize, cap: usize, } In memory, this means: - **Direct**: `ptr` (the address itself, not the content it points at), `len` and `cap` are immediately available. - **Indirect**: the array of `T`s that `ptr` points to, if not null. When you instantiate a `Vec&lt;T&gt;` on the stack: - The **Direct** part is on the stack, occupying 12 bytes on 32-bits machines and 24 bytes on 64-bits machines. - The **Indirect** part is not. When you instantiate a `Vec&lt;Vec&lt;T&gt;&gt;` on the stack: - The **Direct** part of `Vec&lt;Vec&lt;T&gt;&gt;` is on the stack, with the same footprint as a `Vec&lt;T&gt;`. - The **Indirect** part of `Vec&lt;Vec&lt;T&gt;&gt;`, an array of `Vec&lt;T&gt;`, is on the heap. - Each element of the array has its **Direct** part directly embedded in the array: so an array of 4 `Vec&lt;T&gt;` has a size of `4 * std::mem::size_of::&lt;Vec&lt;T&gt;&gt;()`, or 96 bytes on 64-bits machines. - Each element of the array also has an **Indirect** part, an array of `T`, somewhere on the heap. This leads to a memory layout like so: +-----+-----+-----+ | ptr | len | cap | +-----+-----+-----+ | | | +-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | ptr | len | cap | ptr | len | cap | ptr | len | cap | ptr | len | cap | +-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | | | | | | | | | | +-----+-----+ | +-----+-----+-----+ | | T | T | | | T | T | T | | +-----+-----+ | +-----+-----+-----+ | | | +-----+ | | T | | +-----+ +-----+-----+-----+-----+-----+ | T | T | T | T | T | +-----+-----+-----+-----+-----+
Thanks for the detailed answer
That kind of depends. * For `Box&lt;T&gt;` where `T` has a size known to the compiler, then yes, it's just the pointer. * For `Box&lt;T&gt;` where `T` is "unsized", that is to say the length is not known to the compiler, the length of `T` will be next to the pointer making it fat. This is true for `Box&lt;str&gt;` or `Box&lt;[T]&gt;`. * For trait objects `Box&lt;dyn Trait&gt;`, you have another pointer, to the virtual table, that tells you where to find the specific implementations of the functions the trait requires. So that too would be a fat pointer. All of the above is also true for regular `&amp;T` borrows, they are plain pointers or fat pointers depending on whether or `T`.
Seems to me that futures 0.3s lack of a select2() function is a major blocker. It makes it hard (impossible?) to do stuff like timeout on async reads.
https://areweasyncyet.rs and https://jsdw.me/posts/rust-asyncawait-preview/
Eh, I think preludes are fine, sometimes. For instance, this is from one of programs I'm working on: ``` use diesel::prelude::*; use futures::prelude::*; use rand::prelude::*; ``` All those preludes are I would say well designed as they are mostly composed of traits or things that otherwise clear where they come from, like `thread_rng` in `rand`. I wouldn't say having to say `use rand::seq::SliceRandom` is an improvement for instance, when I want to simply use a `choose` method.
`a[0]` move String (which is non-copy) out of Vec.
You either do: fn main() { let a = vec!["Hello".to_string(), "World".to_string()]; let b = a[0].clone(); let c = &amp;a[1]; println!("{} {}", b, c); println!("{} {}", a[0], a[1]); } in both cases a still is owner of both items. b has got a clone of a\[0\] and c has got a borrowed reference to a\[1\], that's why the second println still works.
Thank you for your response. But I am searching for a way to make it work. I am trying to figure out what exactly is being borrowed and where? I am trying to improve my knowledge about ownership in rust. Please suggest me any resources or share any insights u have on the topic
1. &lt;http://play.rust-lang.org&gt; is an awesome place to put examples like this to play with. 2. You don't need debug format in your `println!()`. String-like objects and numbers will print fine without it. 3. As others as noted, the problem here is that you can't move an element of a `Vec` out of the `Vec`. Numbers are copied out, but strings are not. Yes, the error message is not ideal. "Cannot move value out of owner" or something like that would arguably be better. This is hard, though, because… The `Index` trait is what implements `[]` here, and the `Index` trait does this by implicit borrow. The expression let c = a[0]; gets desugared into let c = *a.index(0); where roughly Index::index&lt;Vec&lt;A&gt;&gt;(&amp;self, usize) -&gt; &amp;A So the error message is generated because the value is borrowed and then `*` is used to try to move it out.
I edited my answer, added a few things.
It also has some great modern tooling: namely Cargo and crates.io.
That example still seems to be just... Doing I/O. I still don't really "get it". I mean, I understand how this is useful for writing a server which glues a bunch of other things together and doesn't do anything really itself, but I feel there must be more than that, given how much people seem to care. 
I answered you [on Stack Overflow](https://stackoverflow.com/questions/54957905/implicit-borrowing-in-rust). Please be sure to post code as formatted text, not images. 
&gt;http://play.rust-lang.org &gt; &gt; is an awesome place to put examples like this to play with. OP is using the playground :)
So they are. I didn't look closely at the context of the screenshot. Thanks! Fixed.
The greater picture involves coroutines (yield) and streams. coroutines are closely linked state machines and event loops. I am exploring ways that Futures can be linked to the publish subscribe pattern. That would allow you to write: let event = await!( foo_events ); For me, this is especially interesting in a single threaded embedded context, as it can provide a nice framework for cooperative multitasking.
See my [answer](/r/rust/comments/awgovg/implicit_borrowing_in_rust/ehmdx74/) for some more details.
Okay I'll keep it in mind from next time:)
Excellent work, keep it up
Nice job! Brilliant tutorial code.
I hope u/termhn will create tutorial for rendy as amazing as those for gfx-hal :)
THe borrow checker must be on vacation.
Very interesting article! The proposed channels API seems so much simpler and more capable than the existing one; I wouldn't mind seeing it eventually replace `std::sync::mpsc`.
Awesome work! Given we've been somewhat aggressive with deprecating stuff in std, I personally like the idea of deprecating mpsc wholesale. And we should probably do that regardless of whether we move simplified mpmc channels into std. I think the API you proposed looks pretty good (although I still fairly strongly disagree with the decision for send to return an error). One other specific concern I have though is that I would assume the channels in std would not be compatible with channels is crossbeam-channel, which is important because crossbeam provides additional useful functionality such as selection. It's hard to say whether this will be an issue in practice or not. Probably not since channels generally aren't part of a public API unless you're providing utilities that deal with channels specifically (e.g. like chan-signal) did.
r/playrust
I think you want r/playrust.
Found a typo: &gt; But why is mpsc a single-consumer channel anyway? Why didn’t we go with multi-producer channels from the beginning? 
I'm curious as to why you think it's a bad idea for send to return an error. 
Is it possible to re-export crate in 2018? I'm crafting some structopt tool that requires `structopt`. But I would like *not* to force users of my crate to add also structopt to their Cargo.toml. As far as I understand, the problem is, that deriving StructOpt generates code like this: ``` impl ::structopt::StructOpt for Foo { ... } ``` Is it even possible in 2018 that `::structopt` may be resolved when `structopt` is not listed in Cargo.toml?
This sounds great! Maybe a `oneshot()` channel constructor would allow an optimised path for that use case.
I wonder: given the proposed API, could a crate implement `select!` on top of `std::sync::channel`? It seems that what is missing here is a `Waker`: - Selection by polling is fine for *receiving*, using `try_recv`. - Selection by polling seems difficult to implement for *sending*, `try_send` assumes the value is already computed, with all the side-effects that entail, and yet may fail to send it... and now what? - Selection with timeout seems difficult too.
This is neat! I did something similar at work and also was surprised with the results! The API is fairly small. All it did was receive a JSON request, verify the content signature, serialize it as protobuf and publish to kafka. I didn't want to bite off re-tooling APM, so I left the http server in node.js (express). I also left publishing to kafka in node, but moved everything else to Rust. The Rust code receives a buffer and returns a buffer. The endpoint handles about 500 req/s in production. We previously needed to scale to \~15 instances to meet the demand. The Rust/Node version comfortably handles the load on a single instance (benchmarked at nearly 4x that). Small plug for Neon ([https://github.com/neon-bindings/neon](https://github.com/neon-bindings/neon)) which makes FFI to Rust from Node easy, safe and seamless.
It's all right if you want to use a glob import. But in my code I prefer not, and my remark was that the documentation of crates who offer a prelude makes it unnecessarily hard for me to use or understand their examples.
Thank you for a good explanation. Syntactic sugar, though looks pretty, makes it very hard for beginners to understand what's going on under the hood. Answers like this make it easier to grasp the concept :)
Can someone give a high-level overview what "selecting over channels" means? Other than that, great post, I enjoyed the tour of terminology and it did indeed clear up things for me (esp. "closed" vs. "disconnected"). I find "bounded" and "unbounded" easily understood, btw. Another question: "Zero capacity" means basically "one capacity, blocking on sending until received", right?
For a quick start with the blue pill, you can also look at https://github.com/TeXitoi/blue-pill-quickstart
&gt; in Servo, senders are called *chans* and receivers are called *ports*. That’s because, once upon a time, the types were called `Chan` (short for channel) and `Port` and we never bothered renaming variables in code that hasn’t been replaced since. * https://doc.rust-lang.org/0.9/std/comm/struct.Chan.html * https://doc.rust-lang.org/0.9/std/comm/struct.Port.html
&gt;Other Zero capacity means that both the sender and receiver have to send/recieve at the same time. It's non blocking, if they aren't synced up at the same time send/receive returns nothing or something like that, not sure what the result type is exactly
Because the _vast majority_ of uses of `send` are like this: `ch.send(foo).unwrap()`. That is, you panic because you generally regard it as a bug if you're still sending values when all receivers have been dropped. Why? Because this is _generally_ a property of the program's organization. See https://github.com/crossbeam-rs/crossbeam/issues/314 for more details and trade offs involved. (I'm only presenting my side of things here for brevity.)
Thanks for clarifying! The chan/port thing confused me to no end when I tried contributing to Servo... Btw, very offtopic: The sidebar on the left in those old docs is prettier than the current one! And I love the subtle coloring. Can we have it back? :)
Thanks, fixed!
I was thinking the same thing the other day -- as counterintuitive as it is, a no-sugar capability or editor plugin for pervasive things like borrowing might be useful for absolute beginners to optionally toggle. This probably already exists and I just don't know. I live in python land, and often feel it's almost arbitrary whether a given action will get me a var or a &amp;var (sometimes even a &amp;&amp;var), so I end up guessing and letting the compiler complain.
Uhh really? How on earth are you going to arrange that they're both doing it at exactly the same time?
It's not much feedback, but here are a couple of cosmetic things: - you probably don't want to include a `Cargo.lock` file; these are supposed to be used by binaries, but a library crate should let the user choose which versions of its dependencies to use - you can simply do `use ndarray::prelude::*` instead of `use ::ndarray::prelude::*` - `ThreadRng` is probably a bit slower because it uses thread-local storage; you might want to use `SmallRng` or `StdRng` instead - I'm not sure how important it is, but would it be better to allow users to provide a random seed, in order to get deterministic results? - related, maybe allow the user to provide a RNG instance instead of creating one in `Lattice`? - you can probably use [`std::fs::write`](https://doc.rust-lang.org/std/fs/fn.write.html) to simplify the examples As a non-physicist, I'm afraid I can't offer more substantial feedback (something to do with magnets?), but I'd be interested if you could share if you are using this in a larger project.
That's an option! One thing to consider is what should happen when the message is sent - does the channel immediately become closed?
I also came across a crate with ancient docs a few weeks ago and thought to myself again just how drastically and *objectively* superior the old styling was. A few of us complained with sound reasons when it changed to the current design (too much white and use of whitespace, where background shading had better separated things), but we lost.
Maybe have a try_send for the uncommon case where somebody would like to check for errors?
/u/KillTheMule has it right. Zero capacity means a send is blocked until a corresponding receiver has retrieved the message. In the literature, these are called _rendezvous_ channels.
See the linked issue.
We could in theory do that, provided `std::sync::channel` implements the waking machinery necessary to implement `select!` on top. But this machinery is so complicated I doubt we want to maintain it in the standard library. And yes, you're right in that supporting *sending* inside `select!` adds a whole another level of complexity...
Oh my bad, I misinterpreted it then, thanks for correcting me
Are the channels linearizable? I had a quick look through the code and couldn't find the answer.
It tastes.... purple. That's the best I can describe it. Honestly it's a little flowery to me, maybe like lavender? It's definitely an acquired taste though.
They should just be called rendezvous channels then honestly
Just to mention the other side of the argument, there's precedent in the standard library for locking mutexes with `.lock().unwrap()` and joining threads with `.join.unwrap()`, despite the fact this pattern ocurrs in the vast majority of uses. Maybe there are some other similar patterns I'm forgetting at the moment. Personally, I have mixed feelings and would probably defer the final decision to the libs team.
I know right. I only came across this idea recently but it's been in Java for years. See their Exchanger [here](https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/Exchanger.html).
There's an example at the end of this page: https://stjepang.github.io/doc/new_channel/fn.bounded.html
They are, but I'm not sure if we want to guarantee that so there's no mention in the documentation.
Clever! Thank you.
Probably `checked_send`, given that's the terminology used for the arithmetic operations which panic by default when debug asserts are enabled.
Is the use of `unwrap` really that pervasive? I don't know, but if it's true, that really sucks. :'(
They're probably conditionally using it in their code but not conditionally including it in `Cargo.toml`.
I just finished reading The Book which teaches multithreading by using mpsc, while this proposal wants to deprecate it. Are there any other similar things in The Book that I should be aware of?
To me, it's in the same class as `mutex.lock().unwrap()` or `arc.clone()` - annoying but not a deal-braker. All those patterns could be simpler, but there is a reason the API is the way it is. There are tradeoffs no matter what you do, unfortunately :(
I really liked this writeup. Personally, I would prefer the blank slate apporach. Would it be possible to enable automatic migration from current implementations using \`mspc\` to the "blank slate" channels using \`cargo fix\`? I think enabling this is a really powerful way of advancing the language and deprecating stuff without too much worry about for existing implementations (actually I think it might be a necessity in the long run but let's leave that for another discussion.
You still gotta grep for `unsafe` to be sure about that.
The alternative to `arc.clone()` is an `AutoClone` marker trait which would be a horrible nightmare once people start using it, so I don't think that's in the same class. Servo used to do `.send(…).unwrap()` everywhere and it mostly caused issue because we did that in places where the code shouldn't panic ever, I think making send not return an error would only exacerbate that issue.
File an issue on rustdoc?
I wouldn't be too worried. It will only be clearer and easier to use. My experience reading the whole book 9 months ago is that all changes pretty much has been to make things easier - so if you get the what the book teaches today, most likely you will have no problem with the changes that come. I have yet to see a single point where the complexity have *increased* in any way so I am tempted to say you will be fine :)
The proposal is only to deprecate the current channels API that is provided in std::sync::mpsc. The new channel system would replace it and would be used for the same purposes as the current ones.
&gt; Servo used to do .send(…).unwrap() everywhere and it mostly caused issue because we did that in places where the code shouldn't panic ever, Hey, that's good to know! If you have a link to code or a Github issue where I can read more on this, it'd very helpful. Or if you like, come chime in the [thread](https://github.com/crossbeam-rs/crossbeam/issues/314) on this topic.
I mean, it's simply an explicit assertion. They would probably look a lot better with `expect` saying what's failing. Personally I'd prefer something like `.lock_or_panic()` or `.asserted_lock()`. In general I'd wish more of our normal APIs were returning `Result`s and more specific ones used for assertions. I know this is a reversal of how it currently is but it would at least not give me a new-sources-of-panics sting.
Or better yet, use something like [cargo-geiger](https://www.reddit.com/r/rust/comments/8ssjv2/cargogeiger_yet_another_unsafe_rust_finder/).
Shouldn't stack pinning be a blocker on [https://areweasyncyet.rs](https://areweasyncyet.rs)? Without stack pinning, don't we end up in a world where async functions are forced to allocate stuff on the heap?
This doesn't answer the question - why not stick with java all the way? What are the benefits of using Rust in this use-case?
I’m not 100% sure what specifically you mean by “stack pinning”, but async functions produce a future. You chain futures together. You submit that pile of futures to an executor as a “task.” That task (in many executors) produces one, single, exact sized allocation. Other executors may do something different in a no_std context, but that’s the default. For example, a simple executor which runs one task at a time would not need to allocate at all.
I too have been experimenting with async/await/futures-0.3, but my usage is fairly straightforward (HTTP calls to a server) within an API lib and does not involve streams, or traits with impl Trait. For my usecase things have been rocky but workable. Things I do agree with: - Compiler messages are indecipherable, and in some cases incorrect. I chalked that down to no one (understandably!) willing to polish the messages before a final async/await implementation is set. - It is incredibly frustrating to switch between futures-0.1 and futures-0.3. This is absolutely necessary is you’re using tokio and hyper. If it weren’t for an incredibly helpful example (now out of date) someone else had made, I would have given up. - Stabilization for early adopters seems...unnecessary and not worthwhile. Isn’t that why nightly is for? My perception is the “stabilization” in that case is targeted at the compiler team because now they’re willing to spend time on these UX nuisances without worrying about it being wasted effort. - Documentation is a major problem. That’s because we have multiple components at play: you have to understand futures-0.1, futures-0.3, how to compat() between the two, Pin, async/await and Tokio. That’s...a lot. And, since a lot of it is still WIP there’s not a lot of high-level info one needs to dig in. What I don’t agree with: I can _totally_ understand why the Tokio and Hyper teams would not want to build in async/await/futures-0.3 support. These are production code bases and it’s a lot of effort to support an in-flux API. The ground is forever shifting under you: each nightly build can break you, you’ve to constantly be on top of changes the team is making... It’s a mess. I absolutely believe that the lang team creating their own inefficient, toy implementation using the latest components is the best way to prove out the API. Yeah, that’s frustrating for us experimenters, but either we buy in or we wait.
I meant [stack pinning as defined in the original pinning RFC](https://github.com/rust-lang/rfcs/blob/master/text/2349-pin.md#stack-pinning-api-potential-future-extension).
That’s the Pin type that was stabilized this release.
That’s all library stuff, and doesn’t require a language feature. With Pin stable, this stuff is too. I think https://crates.io/crates/pin-utils may have these impls? I forget.
There were quite a few commits that did this, e.g. [https://github.com/servo/servo/commit/01b6e4a2c110a5ec5f8651a257edc98ba76ccb85](https://github.com/servo/servo/commit/01b6e4a2c110a5ec5f8651a257edc98ba76ccb85), but mostly they replaced \`....unwrap()\` by \`if let Err(e) = ... { return warn!(...); }\`. My feeling is that a lot of code is written using \`unwrap()\` on the basis of maintaining some invariant of the program, and normally we got that right during steady state, but not always during startup, and quite often not during shutdown. Servo still panics a lot during shutdown, due to code that assumes the other end of a channel is still alive, but the shutdown order ended up being an unanticipated one. Sigh.
There is probably a bit of education needed for anyone that's not familiar with async/await. Rust has strength in concurrency and I can see how the benefits of async may be confusing. I may stand corrected but I think the some of the benefit comes from the lower overheads and scalability that async/await provide through futures and coroutines. Multiple tasks can be "parked" in a sense then polled for a result until it's ready. Most mature languages have this one way or the other now days. I would compare asking what async/await is useful for to asking why threads are useful. I'm sure with threads you can see the benefit as it's less about the specific application and more what it enables.
In that code, do you avoid the use of slice indexing too for the same reason? If so, this seems like a fairly specific scenario, and it would be better to have `send` do the right thing by default (panic) for the vast majority of cases, and then relegate the non-panicking API to some other name for cases such as yours.
The name unfortunately can't be fixed because it would literally break *everyone's* code. Vec is one of the most pervasive types in Rust programs. I agree that it is confusing and I was even annoyed by it at first. If it's any consolation, you do get used it and most math libraries work around this by calling the type `Point` or `Vector`. It's not perfect, but it's certainly livable given the consequences of changing it. As for why it was named that way, I haven't been around long enough to know that, so maybe someone else can address those questions. I'm pretty sure it was just legacy from C++ influences. 
Ah, neat.
Yes, the standard library isn't terribly consistent on this point. I would probably argue for making `lock` and `join` panic by default, and add `try_*` methods for the non-panicking version, if we could go back in time. There are certainly other cases where do make panicking the normal thing. For example, the most convenient way to index a slice panics by default, where as the more verbose `get` method provides the non-panicking API. We do the same thing for `RefCell`, where the "normal" API panics. You need to go out of your way to get the non-panicking version.
Following on this, apart of ndarray-like crates, is possible to make vector of vectors linear in memory? ie: I mean, if a struct is also linear yet look like disjoint, what stop to to the same to vectors?
I think this error message used to be preempted by the more meaningful error message help: consider using a reference instead `&amp;v[2]` cannot move out of indexed content What the old message means is, according to the Orielly book, which is a few years old so who knows, is by assigning c = a[0] you are moving ownership, just as x = y assigns ownership of the value of y to x, which puts variable y on the scrap heap, and no longer accessible. but doing something like c = a[0] creates an ownership hole in the vector, and rust doesn't know how to deal with it, because vectors must own all their elements, because how would it know what to drop if the vector went out of scope, it cant keep track of the ownership of everything in it. I notice that your vector isn't mutable, so lets assume you wan't to keep it unmodified. Well then you obviously need a reference to the elements because the vector is not going to give up ownership of its members without a fight. So here you go let c = &amp;a[0]; Unless you want to clone let c = a[0].clone(); What if you don't care about the vector and what happens to it? Then you can start moving the elements out. First change it to mutable let mut a = vec!["hello".to_string(), "world".to_string()]; Then use things like this, which will pull stuff out, but will have to reshift everything after i to avoid holes in the vector let c = a.remove(i).unwrap(); My fav so far is if you wan't to move stuff out, but don't want to have to remove the holes, you can leave fake holes let mut a = vec![Some("hello".to_string()), Some("world".to_string())]; let c = a[0].take().unwrap(); 
Selecting over channels means waiting until one of many send/recieve operations is ready, then doing it. A simple implementation would be to `try_send`/`try_recv` in a loop until something succeeded and then breaking. For an example use-case: I'm spawning jobs onto a threadpool and collecting results. Jobs are sent into a channel from the main thread and recieved in worker threads (SPMC), and results are sent from worker threads back to the main thread (MPSC). I want to pull results out of the channel whenever they're ready, and insert new jobs into queue when there's space (meaning one just got taken out). I don't want to be stuck waiting to insert a job while results are piling up in the other channel, and I don't want to be waiting on an empty result channel while jobs are getting emptied out - whichever one happens first. This is the role that select fills. `crossbeam_channel`'s [select!](https://docs.rs/crossbeam-channel/0.3.8/crossbeam_channel/macro.select.html) macro has examples and more details.
&gt; it seems Rust has just repeated the C++ mistake of confusing naming &gt; Why did they choose Vec for their dynamic array type name? "A rose by any other name". C++ has `std::vector`, C# has `List`, Java has `ArrayList`, Python has lists, JavaScript has arrays. `Vec` is just as good as any other name, and is pretty much instantly recognizable. Why is it in the standard library? Because it's immensely useful, probably more than any other data structure. Why aren't mathematical vectors included? Because their design is much more contentious: - you have to choose between game dev-style vectors with 2-4 dimensions, and ones of arbitrary length - you have to decide whether to also add matrices and other tensor types - you have to pick how to call the elements and whether to pass the vectors by value or reference Because of these and other reasons, there are multiple crates offering such types, with different trade-offs. It's not worth adding something like this to the standard library, when you know that one size won't fit all. &gt; Are there any std types that do make use of AVX or other processor vector acceleration in Rust? The compiler can generate vector instructions in easy cases, but there's no guarantee that the auto-vectorization will kick in. They're also used by some intrinsics like `memcpy`, but that's probably not what you mean. For SIMD, you can take a look at: - https://doc.rust-lang.org/std/arch/index.html - https://github.com/rust-lang-nursery/packed_simd - https://github.com/adamniederer/faster , which off various degrees of portability (not all Rust code will run on x86, and some platforms have no SIMD support) and generality. &gt; Any chance they can still fix the naming? Probably not.
I don't denied that. But soon o later a paralyzing situation arise and is necessary to take an option. Considering how in this case exist many possibilities that are not truly (enough) worse or better than the others is a indication that is the case.
Naming is hard. Calling it Array would be confusing since Rust also has (fixed-sized) arrays `[T; size]‘. Calling it List would be confusing since this has associations with linked lists as in functional programming. Calling it sequence is confusing since sequences are usually ordered. Calling it DynamicArray or ResizableArray is an option but it ks somewhat long compared to just Vec. In the end, Vec is just one of those types that you need to learn and are not immediately obvious (same goes for Cell, Rc, Box, Sync, str, Ord).
I’m no expert on Rust channels, but I believe select comes from the POSIX function select. The way that works is you give it a list of file descriptors (often network sockets), and tells you whether you can read from or write to one of them without blocking. Basically, it’s a tool to find a file descriptor that is “ready”. I’m guessing that when we talk about this with channels, we’re talking about something that can take a list of channels and give me one that is ready to read from.
Ahh thanks a lot, so it's one of the things that are easy to say (like an extended `match` I gather), but probably hard to to, but generally desirable... thanks!
&gt; `Vec` is just as good as any other name, and is pretty much instantly recognizable. I wouldn't agree unless the programmer is not coming from maths, but from C++, because C++ made the same mistake. I think List is a better name in that regard, because if anything it isn't a vector. &gt;For SIMD, you can take a look at: So it's not even platform agnostic in native Rust? Bummer. I'll look into other vector math for rust. the rust naming isn't helping with finding what I'm looking for. :/
Did you miss the definition labeled "computers" in your link? :) Also: https://en.wikipedia.org/wiki/Row_and_column_vectors
Then I get the idea they chose one of the worse names. It is technically all of the above names: list, sequence, dynArray, resArray but not a vector. I'll have to get used to it (or more likely make my own List&lt;&gt; type).
But "checked", in contrast with the regular one, makes it seem like it's the one that won't panic and will instead return an error.
Doesn't that require duplicating a lot of the code? Is is a common enough case for it to be in std?
&gt; I wouldn't agree unless the programmer is not coming from maths, but from C++, because C++ made the same mistake. My guess is that the majority of programmers don't feel too strongly about the naming conflict between dynamic arrays and vectors from algebra. Every app will use a `Vec`. Not every app will need some sort of tensor, and those that do won't have the same requirements. &gt; So it's not even platform agnostic in native Rust? `packed_simd` might get stabilized in the future, but it's not there yet. At least Rust is trying to offer SIMD in a principled and portable manner, and there's not much prior art, so it will take some time. &gt; I'll look into other vector math libraries for rust. the rust naming isn't helping with finding what I'm looking for. Try `ndarray`, `nalgebra`, `nalgebra-glm`, `euclid` or `cgmath`.
Right. `checked_send` returns an error, and doesn't panic. `send` wouldn't return an error and instead panic, under that proposal.
I usually see “List” refer to a linked list. The Vec name is probably largely influenced by the C++ vector, which most rust programmers would be familiar with. Conventions can be bad ones but the consistency they bring is still useful. If you’re writing a math paper you wouldn’t insist on using tau instead of 2pi just because you don’t like the convention. 
Great write up. Re your clean slate proposal &gt; "Change the guts of mpsc to use channel behind the scenes, but otherwise don’t change it." I wouldn't bother. If the old channels are going to be deprecated this seems like nugatory effort. And it helps motivate the migration to the new channels, since they will be easier and faster. 
I guess you need nalgebra
I don't think it's that specific, it's common to have an overarching manager thread that should never crash (plus some other related singleton services). Slice indexing is something that really only crops up in some kinds of code, in other kinds iterators work, and in yet others you have arrays that never shrink so it's usually okay.
I am sorry, I really cannot describe better the benefits that I see. Generally I didn't post any use case here. I just shared how someone that codes in Rust (with all the goodness that the language implies) can use java if he wants. Whether to use Rust or Java all the way is a different discussion and depends on the use case.
My feeling is that if we're going to put a crossbeam implementation in std, it ought to be the whole lot, select api and all. Surely the whole point ia that Rust comes batteries included witha channel API that does everything. Otherwise we might as well leave crossbeam-channel as an external crate like regex, rand, etc.
Oh, I misunderstood, then.
When moving between domains, one should not assume that words mean the exact same thing in different ones. In all my years of programming, I’ve never used the math version of vector. YMMV. That’s the point, in fact!
To be completely honest, I'd probably be open to this possibility in the future, but let's move forward one step at a time. Even this small API has already started heated bikeshedding so including select at this time would derail the whole proposal very quickly :) The good thing is, the proposed API is small and conservative so it'll be easy to build on top anything we deem necessary later on.
They should also consider renaming the language, as there is a video game called 'rust'. Confuses me every time
Except not RTC crystal.
I guess it just seems to me like the manager thread should be designed so that the `send` itself never panics, and if it does, it's regarded as a bug. At least, that seems like the natural case. If this is difficult to do _in general_, then I'd find that interesting and might motivate the notion for `send` to return an error. But I've never written a channel send operation that ever handles the error other than by panicking (or similar). And that's not just for Rust, but for every instance in which I've used similar style channels over the years. So from my perspective, handling the error is super uncommon.
plus I don't know how much effort v8 has put into the ARM architecture, which is what ec2 is. Lol, you got downvoted for wanting a good comparison. So much for the integrity of this crowd.
Which tutorials for gfx-hal are you referring to in specific?
This is a dream come true for me. They're integrating all three of the libraries I always import. Not gonna lie, I read the first paragraph and started giggling because it made me so happy.
I think I've definitely written a lot of `let _ = ...send();` myself, when the sending failing is less of a big deal.
Normally your deps won’t have to be recompiled unless you are getting rid of your `target` directory. Are your builds being executed in a container or something?
what's making the little white specs everywhere, just a specular reflection + image was blown up + weird anti-aliasing? &amp;#x200B; Also, is this realtime, &amp; what GL / DX api version is it on?
Just by looking ad the definition you linked to, vector has a highly domain specific meaning though, so I guess it's not a thing one can expect to mean the same in different domains. But I agree, it's one of my least favourite names for a list of continous segments in memory, but it's not the end of the world. &amp;#x200B; You can, for sake of clarity in a piece of code with lots of other vectors with a different meaning, just use a [type alias](https://doc.rust-lang.org/book/ch19-04-advanced-types.html?highlight=type,alias#creating-type-synonyms-with-type-aliases): \`type List&lt;T&gt; = Vec&lt;T&gt;\` and you can use \`List&lt;T&gt;\` just like you would use a \`Vec&lt;T&gt;\`.
The language is probably going to outlive the the game, so this problem will solve itself eventually 
&gt; But this machinery is so complicated I doubt we want to maintain it in the standard library. I was wondering if there could be some synergy with *futures*, which also have this `Waker` requirement. The standard library has standardized futures without providing any executor, so maybe the standard channels could do something similar: they could *optionally* be registered with an executor, and therefore register wakers. Do you think this could substantially simplify the machinery? Or is this a pipe dream? &gt; And yes, you're right in that supporting sending inside `select!` adds a whole another level of complexity... I was afraid of this. --- I would say that regardless of `select!`, faster and more ergonomic channels would already be a tremendous improvement over what we have. As such, I would support moving to the minimal API for `std::sync::channel` now, and defer "improvements" for latter RFCs if need be. Given the presence of `crossbeam` for more advanced usecases, there's no pressure having them in `std`.
I think it would be a good addition to beginner documentation to list the situations which can implicitly borrow: - Method calls may borrow the argument in `self` position. - Closures, without the `move` keyword borrow their upvalues - Indexing kinda-sorta borrows. The error the compiler gives is "cannot move out of borrowed context" because a more specific error hasn't been written. But I'm not sure indexing should logically be a borrow. Logically, the way it's described in the language reference, indexing is an operation that transforms a location-value. It's in the same family of operations as addressing a field of a `struct` and dereferencing a pointer-like type. Fundamentally `let c = a[0];` isn't too much different than `let c = a.id;` However, the compiler isn't smart about subdividing ownership when you use the index operator. If you own a `struct` you can take one of the fields out of the struct. (From that point on, you don't actually have the complete `struct` anymore. You have a collection of variables that look like the struct. The crucial difference is that Rust will not invoke `drop` when you are done with a partially disassembled struct.) You can borrow the fields of a struct individually too. And you can re-borrow the target of a pointer. (expressions like `&amp; **x` drove me crazy at first, but it's not so bad once I realized that `&amp;` and `*` are *not* inverse operations in Rust.) The reason why the compiler doesn't try to subdivide arrays is that indexing is very generic. You can index by *any* sized data type, and the compiler doesn't have any general and foolproof way to tell if borrows overlap or if you're duplicating a non-Copy element, etc. At best the compiler could have special rules for arrays and slices which only work in special cases. 
https://github.com/lokathor/learn-gfx-hal My tutorials inspired by those will live at https://github.com/termhn/learn-rendy
Cheers!
The main use is “anything where your program spends time waiting for something else to finish.” The majority use case is I/O over a network. I’m sure there are others as well, but that’s the primary use-case by far. So why write a feature for just this? Well, two things. First of all, the performance is *drastically* better. Second, it’s not just for those network calls. You know how, when you use Result, it bubbles up in your function signatures? Async is the same. So it’s not *just* the networking call, it’s everything involved in processing it, from start to finish. Does that make sense?
The white specs are an artifact which I’m investigating. I think they are because of the strong rim lighting but it also might be a bug in my shader code somewhere. I am running it with Vulkan, but it should also be able to run perfectly with DX12 on windows and Metal on macOS since it is built on top of gfx-hal.
The thing is, I use threads all the time. I write Rust programs that run 256 threads on a 256 core computer. It's amazing and I love that Rust makes this easy, safe and efficient. Async seems however to be about having lots of things waiting. As I understand it if I have a function which just needs to do 5 minutes of computation, it wouldn't fit well in an async system, as it would hold up everything else.
Bela looks great for audio. In Rust- nice job!
It feels like something with a huge mindshare, where the major application is waiting for many network connections to finish. I suppose its just something I never do, and therefore I'm surprised by just how much time and energy it seems to consume :) 
It really depends what kind of programming you do. The majority of my time programming professionally has been writing systems like these. :)
Also from the linked definition: &gt; 4 - Computers: An array of data ordered such that individual items can be located with a single index or subscript. Which `Vec&lt;T&gt;` fits perfectly.
The language also predates the game.
Hum... if you introduce two failure modes (full vs no receiver), then you have *4* combinations: - `send`: panic if no receiver, blocks if full. - `try_send`: panic if no receiver, returns if full. - `xxx_send`: Err if no receiver, blocks if full. - `try_xxx_send`: Err if no receiver, returns if full. I think I'd prefer `try_send(T) -&gt; Result&lt;(), TrySendError&lt;T&gt;&gt;`, which handles both error cases in one API. The `TrySendError` can be extended to cover more bases.
"Just because we can, doens't mean we should"? ;-)
The [rigorous definition](http://www.math.niu.edu/~beachy/courses/240/06spring/vectorspace.html) of a vector only requires that the operations of vector addition and scalar multiplication satisfy certain properties. `Vec` doesn’t even define these operations, so I think it would be hard to say that it is explicitly **not** a vector. That’s similar to saying “this set is not a group”. It would be more natural to first ask “Well how do we define the required operations on it?”. The answer is that you can define the operations yourself in a new type that uses `Vec` under the hood. Then it will have a more complete definition, and it will be easier to talk about whether or not it is a vector. 
Why wouldn't it be? If you find the API to your liking, go for it. It's built on top of the fastest and most tested/correct HTTP implementation in Rust.
Interestingly, I'm pretty sure that C++ picked `vector` *precisely* because of mathematics: after all, a vector in mathematics a one-dimensional list of n Ts index by [0, n).
Mmmm, yeah I was hit for a mistake in the build process that hit cargo clean. 
You should not parse it at all; the calling shell already takes care of that for you. `args[1]` will be the command you need to run, and `args[2…]` will be that command's arguments, already properly split.
I was just about to say this same thing. Anyway, dictionary definitions are descriptive, not prescriptive. The computer science vector even works in a mathematical sense, as an array of elements denoting a point in a multi-dimentional space, though in our case with dimensions of the same type and varying dimension count. A fixed-size array is the same, but with a constant number of dimensions, and a tuple is the same, but with each dimension being the possible values of another type. The dimensions are discrete, rather than continuous, but it all can be related back to the "pure math" concept of a vector.
Can't argue with that. Just wanted to see if I was missing something before starting. Thanks.
To me the difference here is the scope of the upheld invariants. If I access something by an index, I'd panic if I got the index inside the function (upholding a local invariant) but I'd return a result if the index is passed in as an argument (an external invariant) and defer that decision/description of the invariant to the using code.
Probably, I misused the word "parse", sorry for my English, but \`time\` command itself has some arguments and I thought there could be a way to get them and interpret everything else as a command to run.
I did this recently. Let me know if this helps you. fn build_app_context&lt;'a, 'b&gt;() -&gt; App&lt;'a, 'b&gt; { let x = App::new("an app") .version(env!("CARGO_PKG_VERSION")) .about("about this app") .arg(Arg::with_name(ARG_ACTION) .index(1) .case_insensitive(true) .required(true) .possible_values(&amp;[ ACTION_HELP, ACTION_NEW, ACTION_VALIDATE, ACTION_VAL, ACTION_SEARCH, ACTION_LIST])); return x; } And then at some point, whatever called this function can access the arguments passed in (in this example, the argument at index 1( the first user inputed arg) let app = build_app_context(); let _args = app.get_matches(); let f = { let action_value = match _args.value_of(ARG_ACTION) { Some(_val) =&gt; _val.to_uppercase(), None =&gt; String::from("NONE"), }; match action_value.as_str() { ACTION_NEW =&gt; actions::entry::new, ACTION_VALIDATE | ACTION_VAL=&gt; validate_entries, ACTION_SEARCH =&gt; search_validated_entries, ACTION_LIST =&gt; action_list_entries, _ =&gt; action_help, } }; f() Take note of the line let action_value = match _args.value_of(ARG_ACTION) this will give you the value of that first argument. Any questions, let me know and I can make a gist with other options. If you are looking for short commands (like -c -a) or something and I am way off on what you are seeking, Clap also supports those very easily.
I suspected that such was probably the case. Glad you were able to fix it. 
Ah. In that case, yes, using an option parsing library, and passing the remainder to `Command`, is your best bet. `clap` seems to be the most popular and recommended one (though personally I consider it bloated and do not like its design).
The key is that it allows you to do useful work with the CPU on another task while you're waiting for I/O to complete. With async, Task A can get useful CPU work done while task B is waiting on I/O. This works because Task B can "yield" to Task A, allowed task A to take over until I/O is complete ask task B can "wake up" and carry on with it's work now that it's finished whatever I/O it was doing. A good async system lets you do this sort of things on a single thread, while at the same time having code "look" very sequential while in fact it's doing all sorts of things at the same time. 
The fact that they are using Hyper 0.12 is a good sign. I am interested
https://readrust.net/ is an aggregator of interesting Rust blog posts.
I am currently working on a black-pill with a RTC crystal, maybe there are multiple versions out there ? Mine is from robodyn.
One thing I'd give a hard look at is if the \`\*\` dependencies are truly necessary -- with that many dependencies, you may unexpectedly need to recompile simply because somebody pushes a new patch version. It won't happen often, but since we're talking about flow you might want to write explicit versions and then use something like \`dependabot\` to keep your deps up-to-date automatically.
That’s correct, if your thread is doing a bunch of CPU work, using async would only add overhead. Both are useful tools for different purposes.
no gl 3.3 fallback for my shitty intel 3000 hd then?;)
Thank you.
Unfortunately no, not yet at least :)
What about `send`: panic and blocks `soft_send: panic, doesn't block `try_send`: doesn't panic, blocks `try_soft_send`: doesn't panic, doesn't block
That is a good advice. I put "\*" because I'm checking what crates cross-compile to iOS/Android, so I'm adding/removing to the list to see what can I use.
I'm sure you didn't mean it in an accusatory way, but it can read that way. The situation is a lot more complicated than "not being willing to help". I wouldn't associate bad intent to anyone involved, it's a huge amount of juggling research, design, experience, preferences, time, commitments, and more. In the end, we *all* want to get async/await working and available to production users. Things just be hard. ♥️
Absolutely! To be clear, I don’t assume any malicious intent here. It *is* unfortunate. That’s not really anyone’s fault.
Right, `TrySendError` already covers both cases. I don't think we need to add the fourth variant (panic if no receiver, returns if full) as a separate method.
Though, thanks to 0.3's compat feature, it should be pretty straightforward to use async/await. For example, a hyper server can be created with a tiny `service_fn` that swaps the bodies for compat bodies, and the response future for compat. Then, the rest of the user code can be asyncs and awaits everywhere.
I don't think there's any issue with pushing invariants like these outward. Many of the slice (and str) methods do this, for example, and require the caller to provide valid indices. That's not to say I'd never take your route, I just think there's a lot more than just scope that determines this stuff.
Thank you!
This is great, thank you!
There is a select! macro that can take any number of futures to select on instead.
Holochain is a FOSS framework for distributed apps that turns your apps into a sort of network protocol that upholds security and data validity. Holochain is written in Rust, and currently so are Holochain apps. Holo is a (perhaps confusingly named) company under the same umbrella project as Holochain (Ceptr). They offer pre-configured computers for serving Holochain apps to people on the regular web via HTTPS, and maintain a Holochain app which distributes work to these hosts and rewards them in a cryptocurrency for doing so.
Thank you very much for the response! Does the index(1) means that ARG\_ACTION will be the first positional argument (in my case COMMAND name), after all the keyword arguments were specified?
See how [cargo-fuzz](https://github.com/rust-fuzz/cargo-fuzz/blob/dd1de87a47ac21914256e477e953ad781609ed5c/src/main.rs#L59) implements such functionality for reference. Specifically there is an `.multiple(true).last(true)` argument somewhere in there.
So glad to hear improvements are brewing for `mpsc` - I'm working on a project that uses it extensively and have run into several of the pain points mentioned here. I ended up hackily wrapping it in my own project to smooth over some of them. Reading this now I'm also realizing I think I've run into [the mentioned bug](https://github.com/rust-lang/rust/issues/39364), explaining my unexplainable once-in-a-blue-moon `recv()` panic. Looking forward to seeing this progress!
Any time you have two implementations of what you *think* is the same program, one in JavaScript and one in *any* non-interpreted language, if the JavaScript one is even close to as fast it means that the two programs are not *actually* doing the same thing.
Awesome! Looking forward to the learn rendy stuff as well. 
[removed]
Yeah, I think there's just a difference in approaches here as well. I should clarify that I don't write that much Rust, so having all these invariants that are outside of the current scope explicitly spelled out is really helpful. Everytime I don't do that, and come back to work on something a month or two later, I trigger panics all over the place before I figure out what invariants I left off with. Worse is when there is a leftover invariant in a design that's only starting to be triggered once the thing starts to be finished. So to me, that ergonomics hit is tiny compared to the advantages of writing it out. So these days I `.expect(...)` as much as I can, even if there is a panic version available. And I mean, it would not be *too bad* for me. If I'm writing code using lots of channel communication, I can always make my own wrapper types to be more explicit.
oh my god you weren't kidding. I'd run my own docs offline just to have that better styling.
Thank you! will check it out
I think your counterargument suffers from ad absurdum. He didn't advocate for consistently "just pick an option" being the solution, he was talking about a BDFL being able to break a deadlock when there is no clearly best option. For example, with the await syntax, there is no "best" option. It would be like having a human discern the difference between infrared wavelengths with just their sight. In the end, someone will be unhappy with the outcome, and I think that breaking a deadlock, even randomly, is just as good as any solution in that case. 
That assumes there is an actual deadlock. There is not one yet. The team all agrees that shipping is more important than getting exactly what they want. They’re also committed to making sure that the options are discussed thoroughly. And there is more objectivity/intersubjectivity to the syntax than you’re giving credit for, here. You can enumerate the upsides and downsides of the options. It’s not a random thing.
Thank you so much! I'm gonna fix those things soon. This fall I've joined a tutoring project at a university (I'm still in school). I'm working on a [Sociophysics](https://en.wikipedia.org/wiki/Social_physics) project under a supervision of a Physics PhD. The Ising model is probably the simplest model featuring a phase transition. The lattice represents a physical body. The `J` constant determines whether this body is ferromagnetic, antiferromagnetic or none. If it is ferromagnetic, a spontaneous magnetization occurs at low temperatures (below the [Cure temperature](https://en.wikipedia.org/wiki/Curie_temperature) of this body). We're trying to correlate the results of the simulation (especially the occurence of a phase transition) to how people clap. As you've probably observed, people usually clap together for some period of time and then they stop almost all at once. We can draw an analogy between the behavior of a physical system and of a social system - sociophysics doesn't give a f, to it you're just a tiny particle. The thing we're interested in is if it's possible to model the intensity of clapping over time using Ising model and how to adjust the parameters. There is some variety in how people clap, for example a small group might have really enjoyed the music or whatever and they keep clapping after everyone else stopped, and then maybe other people joined them again (I have such a recording). There are also very distinctive patterns visible when people clap rhtymically. These are the two main challenges in recording analysis. We also got a recording from a proffessional orchestra, which is kinda funny. It's 3 minutes long (recordings I did were 20 seconds at most).
Checkout cargo-add, allows you add a dependency quickly without having to look-up the latest version manually 
"linked" is an example of an implementation of a list. there are many different implementations of list. most non-trivial functional programming language implementations do not use 'linked list' for their list implementation.
The syntax was just example, my main point was that your comment was not a good counterargument against the OP's point about a BDFL (although he somewhat poorly advocated for it).
Rust also gives you the tools to avoid logic bugs: 1. Strong type system - you can't add inches to meters. 2. Code reuse through generics: you *can* add meters to inches and the answer will be correct 😁 3. Panic framework for good debug info when you have bugs 4. Lifetimes/ownership/RAII so you can't use stuff at the wrong times.
The lock file means that you won’t update to those versions until you explicitly update.
Async/await makes it very easy to write code that waits on a lot of different I/O at once without the overhead of having a thread blocked on each piece of I/O. A server that is handling a lot of different connections will typically have a lot of different I/O operations going on at once. Async/await makes it much easier to have a reasonable number of threads in use at once instead of one per I/O operation, which represents a big performance improvement for a typical server workload that consists mainly of waiting around on a lot of different I/O to complete.
This naming convention bothers me to, but it's not a big deal in the end because you just memorize it. When I think of a vector, I think of arrows on a 2D plot or force calculations, so geometrical or mathematical ideas. But definately not as a collection of data of an arbitrary type. The argument that a mathematical vector can be thought of an n-dimensional list of numbers is valid, but it feels counter-intuitive. Furthermore, inverting that transformation works with `Vec&lt;Number&gt;` but I would never think of eg. `Vec&lt;String&gt;` as some mathematical construct (even though all bytes are numbers). A good type name **aligns with the intuition of users, and \`Vec\` doesn't** do that, if you don't come from C++ or computer science. But it is definately to late and not worth it to change the name to eg. `List&lt;T&gt;`.
It's definitely an issue where there are multiple generalizations of vector. The more math-y one is kind of what you suggest, but there's also the physics-y generalization which has to do with the effect of spatial transformations. Of course the best definition is as follows: &gt; A vector space is a set `V` such that, for each `x ⊂ V`, x has an arrow over it. 
Have you looked into percolation? Ising phase transition is far too simple for something like this.
&gt; The shorthands for sender and receiver are tx and rx. Why not just use s and r instead? I like `tx` and `rx`. Once you know about the convention, it makes it easy to pick variable and field names for senders/receivers when writing code, and to figure out the type when reading code. `r` and `s` are not distinguishable; `receiver` and `sender` are long.
Really nice article, can't wait for these proposals to get approved and stabilised.
Rust is very promising for security-critical applications, but there currently are gaps in the ecosystem that prevent it. One of them is the lack of any infrastructure for security updates. Linux distros alert you if you're running a vulnerable version and you can opt in to automatic updates. Cargo not only has no update infrastructure, it doesn't even know which libraries or library versions went into compiling a certain binary, so there's no way to check if your system is vulnerable or not. This project attempts to remedy that. The idea is very simple: embed contents of `Cargo.lock` into the compiled binary with a special start and stop markers so it can be programmatically recovered. This allows auditing production binaries for security vulnerabilities, tracking and mitigating use of untrusted or deprecated libraries, etc - all with zero bookkeeping. This is a proof of concept implementation, the main goal is to demonstrate the viability of the idea and gauge community response. The long-term goal is to get such functionality into Cargo and enable it for non-embedded platforms by default.
I wouldn't say much about the author without really knowing about his contributions. If I understand correctly Yarte's author contributed to askama improving more than 30% in performance and worked pretty hard for dochtman in this project in crucial parts. Crate askama\_derive was written by Yarte's author and gave it to dochtman and I don't see any acknowledgement there (your most downloaded crate). Rust is about working together to create the best programming community. And free software programming is about getting the best of everything out there to generate fast, optimized, and well written code. Acknowledgement to everyone/everything that inspired you in the code should be written, I agreee (sometimes is not that easy) and Yarte will do so. Last point. Before accusing someone of plagiarism read the code because the code use in Yarte doesn't come from Askama and that's why is not forked from it. Licensing is relly important and should allways be respected, I understand people acting upon what they think is unfair, but be careful to not believe something that is not true. Sorry for my English and reddit skills.
How much have you actually used those languages?
I've been using actix-web in production for several months now without a problem. I haven't yet used it for websockets, but otherwise it has just worked. 
OneShot channels are super simple and don't even involve a lock-free CAS queue. You can look in futures-channel or tokio-sync to see how much less is required than a full channel.
Have you read this? https://doc.rust-lang.org/book/ch20-03-graceful-shutdown-and-cleanup.html
&gt; It's my *personal* opinion that nothing requiring mingw has any business in the Rust ecosystem. Absolutely agree.
&gt; (But not `try_send` because `try_send` is already a thing that does a non-blocking send.) That's just another error though. In Unix terms, `EWOULDBLOCK`. 
I don't understand what you're saying, sorry. `try_send` covers both cases: it's non-panicking and non-blocking. `checked_send` is only non-panicking. `send` would be neither (under the proposal).
/r/playrust
Hi and welcome. Please consider to ask the question on either a subreddit dedicated to game servers in general or to r/playrust in specific – i guess you confused this subreddit – that is dedicated to the programming language Rust – with the game with the same name you love to play :) 
`pub use crate::structopt` should work, I think.
Thank you both! Sorry about that. I will move it.
Recently output checking for pidigits was made more restrictive [for N=27 output should be](https://benchmarksgame-team.pages.debian.net/benchmarksgame/download/pidigits-output.txt) 3141592653 :10 5897932384 :20 6264338 :27 If you can, [please contribute a fixed program](https://salsa.debian.org/benchmarksgame-team/benchmarksgame/blob/master/CONTRIBUTING.md).
Sorry; I edited it a bunch of times because it wasn't clear. The expanded proposal: * `send()` is blocking and panics if the channel is closed * `try_send()` is blocking and returns an error if the channel is closed * `send_timeout()` is blocking and panics if the channel is closed, and returns an error if the timeout elapses * `try_send_timeout()` is blocking and gives an error if the channel is closed or the timeout elapses Calling `try_send_timeout()` and `send_timeout()` with a zero value for timeout would be the way to do non-blocking calls. If a non-blocking send is not possible immediately you get a timed out error and do whatever you want with that.
Is it not possible to use `use SmallVec as Vec` within scope of the use of the macro? Or does hygiene prevent that?
As I understand it, this would leave the old complicated code in `std` as redundant code that would have to be maintained in the future. One motivation for the replacement was to clean up `std` a bit.
&gt; Tokio has refused to update until its stable Can't lang team introduce some sort of semi-stabilisation? In other words it will be announced that nightly feature will not change unless some serious flaw will be discovered and everyone is encouraged to play with it. So `tokio` team will be fairly confident that they will not have to rewrite everything once again, but we will get a certain protection against unforeseen design issues. Yes, many will feel that we again have foundational libraries which require nightly, but I believe we should be more conservative here if we don't want to get bitten in a longer run.
Could it be specular aliasing? 
I kind of like it sure. There's definitely an established pattern though in that the `try_send` variants of channels almost always correspond to the non-blocking send.
It’s sorta a contradiction in terms. If a major flaw is found, then things *will* change, and tokio would still have the maintenance burden.
Not only using it but written by the same author, afaik
V8 is probably pretty well optimized for armhf, but why do you say that ec2 is arm architecture? It's only one instance type that runs arm, and it's fairly new. Either way, I don't trust the validness of this exercise unless someone verifies that it indeed runs with the same docker settings. Also, reported memory usage also is skewed in node.js if you run in-memory transpiling, like babel-register or ts-node. 
Even then, in all the years of Rust development, we’ve never had a true deadlock. So the help would be purely theoretical. 
Having implemented asynchronous channels on top of \`Waker\`, I think it might be possible to use those as a foundation for asynchronous as well as synchronous selects (and channels). However the current design of Wakers might not be the most effective one for synchronous operations: Wakers must be guaranteed to live forever (have no lifetime), which means they are always implemented as some kind of \`Arc\`. For synchronous unblocking that't not necessary. The Waking element must only live long enough for the select block to finish, which should make it possible to have it purely on the stack. &amp;#x200B; Some thoughts on the original discussion: \- I think if channels get improved in \`std\`, I would really like to see \`select\`, or at least the ability to add it later on. It's simply such a powerful mechanism, that unblocks a lot more use-cases. In the same fashion as e.g. a \`ManualResetEvent\` on Windows isn't that powerful, but combined with \`WaitForMultipleObjects\` it's very powerful. \- I also think having a more generic synchronous \`select\` (which can not only wait on channels) could be useful. E.g. ConcurrentML seems to have had a few good ideas for that. It's totally possible to do those kinds of things in the Futures world with \`block\_on(async { select! {}})\`, but maybe it's possible to get simpler versions of that (doesn't require pinning or cryptic types) running for synchronous code. But not sure whether that's actually possible, or whether we would just reinvent Futures.
I remember experimenting with such an augmentable tree a few years ago. The idea was to combine three traits: * A tree implementation * A payload that has "callback" methods for node splitting/merging. * A searcher that chooses how to traverse a tree (and even what to return) I didn't even got to the point in having any reasonable tree implementation (with O(log n) insertion/deletion), but "get i-th element" and the reverse query "get index for element x" had worked :) Unfortunately, I think I've lost the code, as I'm getting _warning: remote HEAD refers to nonexistent ref, unable to checkout._. Anyway, as it now seems to be non-zero interest on this topic (at least two people), I'd be interested in creating such a library! 
Hello all. I'm trying to use the mysql crate ([https://docs.rs/mysql/15.0.0/mysql/](https://docs.rs/mysql/15.0.0/mysql/)) It works fine, but I'm a little confused on how to do proper error handling and/or avoid using unwrap. All of the best examples of error handling I see revolve around using a Result or an Option type, but this crate seems to rely on a MysqlResult type which as far as I can tell behaves differently. I want to do this in the most clean and idiomatic way
Is there any chance of adding some sort of channel trait to either std or crossbeam-channel to make it easier to swap out channel implementations? Right now I'm using the notify crate, where the [watcher](https://docs.rs/notify/4.0.9/notify/trait.Watcher.html) depends on an std mpsc sender. It would be nice to be able swap that out with a crossbeam-channel without needing to change the library itself.
Can u please explain &amp;**x notation it seems interesting :)
There may be better resources, but I've written a blog post about this: [https://iandouglasscott.com/2018/05/28/exploring-rust-fat-pointers/](https://iandouglasscott.com/2018/05/28/exploring-rust-fat-pointers/)
yes
I believe that's exactly what it is, yes
Yeah it's unfortunate. But I think the `try_foo` pattern is also fairly established for non-panicking methods. And as long as we're overhauling the API to make things clean... And it does seem kind of nice to use a zero timeout to indicate non-blocking. However, the systems programmer in me knows that the first thing the implementation is probably going to do is check whether the timeout is zero and go down a completely different code path in that case. Which makes me a little less happy with the API proposal, maybe.
Vector has many definitions in math. One of those is "a one dimensional array".
Are you talking about MyResult (not MysqlResult)? That is simply a type alias where E is fixed to Mysql::Error.
I'm currently working on a Websocket server with Actix-Web and it's been great. The websocket echo and chat examples in the repo have been very useful.
Or use IntelliJ Rust which will autocomplete the latest versions of crates while editing Cargo.toml
I still don't think BDFL or something similar is a good tie-breaker in those situations.
The entire poisoning I'm not sure is a good idea. I have seen more bugs happen because mutexes ended up poisoned and nobody handles it leaving a server in the situation where it needs a restart than code that actually manages to recover from a poisoned mutex.
yes, you're right of course! So assuming that conn.prep\_exec returns a MyResult which aliases to Result, then I *should* (I think?) be able to do result = conn.prep_exec(query,params!{"blah_id" =&gt; 1})?; but when I try this, I get: cannot use the `?` operator in a function that returns `()` So does prep\_exec return MyResult or does it return an empty tuple?
I think you're (slightly) misunderstanding the ?-operator. In the case of `Ok(val)` it simply unwraps the value. But if it's an Err(err), it does an early return - returning the error (still wrapped). So to support the ?-operator, your function has to return a Result&lt;T, E&gt; where T is of your choice but E has to be compatible with the error types that you use ? on (either same type or implement `From`).
Depends on what other languages you mean. They're the same as in C and C++, but not as in Perl. Also note that the compiler sometimes automatically adds a `*` when it's appropriate. This means that C/C-++'s `.` and `-&gt;` are both just `.` in Rust.
ohhhhh So the issue I'm having is that *my* function returns ()! I see now that the error message says &gt;cannot use the \`?\` operator **in** a function that returns \`()\` and not **on,** which is how I was reading it. So if I want to use ? I need to update my function to return a Result&lt;T, E&gt; with all of the correct types etc. I think that gives me enough to get back on the horse. Thanks very much for your help &amp;#x200B;
Agree; not a great choice for the reason you listed. Check out the \[[https://github.com/rust-ndarray/ndarray](https://github.com/rust-ndarray/ndarray)\](ndarray lib)
I agree. I am new to Rust and loving it, but I admit this is a bit over my head. What got me on this example is the &amp;Debug reference from the Vector. I can't wait to understand this.
I have added some more content to my question. Please take a look at it
Yeah this automatic dereferencing is a pain to understand what's going on as a beginner can u give some more insights on this?
&gt; I wouldn't agree unless the programmer is not coming from maths, I think a lot of them actually don't come from math.
Thanks for the new post! That optimization for the Watchlists is very clever! How does the “blocking literal” work? &amp;#x200B; I look forward to hearing how you intend to do backtracking. You menchen doing "carefully benchmarking" how do you plan to do that? Do you have a standard input set you indeed to use? (can I recommend [criterion.rs](https://criterion.rs)) How are you testing you work? (can I recommend proptest)
You didn't hear it from me, but if you really don't want to type Vec everywhere, you can write: type List&lt;T&gt; = Vec&lt;T&gt;; You should probably stick with Vec though to be consistent with other Rust code though. By the way. I agree that it's a shame they overloaded Vec from its math term. It probably comes from c++'s std::vector&lt;T&gt;
The `&amp;**x` thing is also the same as in C/C++, it's just a chaining of the dereferences/references. It's probably really better to think of it as a reference rather than a memory address. In C++, you have types like `int&amp;`, which is a reference to an integer. This behaves very similarly to Rust.
When you write `foo.bar()`, the compiler looks at the type of `foo` (which I assume is `Foo` for the rest of this explanation). If there is no function `bar` on that type (`impl Something for &amp;Foo`), it also looks at `*(&amp;Foo)`, which is the same as `Foo`. I assume that this was done because nearly every variable is a reference in Rust, so it doesn't make sense to make this a special case. The language also tries to support the programmer. Note how using `.` on a reference in C++ always results in a compiler error, so this could never be what you actually intended, and `-&gt;` on a non-pointer non-reference type is also always a compiler error (unless you did some overloading). The compiler can easily tell what you actually intended, the C++ standard just chooses to not do that.
The type `Vec&lt;u64&gt;` is a superset of types `Vec&lt;u64&gt;` (itself), `[u64]`, and `Debug`. The last two subsets exist because the traits `Into&lt;[u64]&gt;` and `Debug` are implemented for type `Vec&lt;u64&gt;`.
&gt; It's going to be a hard sell to get an entire ecosystem to devote serious resources to supporting older compilers though, unless there are a lot of situations like yours I suppose every year the number of people with the same as my situation will grow. The more code on Rust will be in each company, the less likely that they will change the compiler every thee months. After all, only the end result that is important for users is the functionality provided by the program / library, and a compiler change automatically leads to the fact that every assembler instruction must be checked. 
It’s not always completely up to date but I also publish an OPML file of the blogs I subscribe to for Read Rust: https://readrust.net/rust-blogs.opml
Vec&lt;u64&gt; pointer is a pointer to the original vector directly. [ u64] is a pointer to an array of u64 elements. This is able to be taken from a vector as the vector explicitly has a method to allow a reference of that type being taken from it. It can allow that as it knows the borrow checker will keep it safe. It can easily do it as that is how it stores its data under the covers. Debug is more complicated. If you’ve come across generics or templates in other languages then it is that. If you haven’t: a Debug pointer is a pointer to any object that implements the Debug trait. This is useful as you may want to be able to have a function that takes as an argument any object that implements the required traits. E.g. if you had a function that just printed an object using a Debug format (say a log function) then you could accept anything that implemented Debug. This saves you having to have a log function for each object.
Think about the 3 different types this way: `&amp;Vec&lt;T&gt;` - this is simply a pointer to the vector data / the internal buffer inside the vector. `&amp;[T]` - this is the same as the previous, except it also stores the length of the slice, which is an extra usize. `&amp;Debug` - this is a trait object. Thing about a trait object is that it represents "some object which satisfies the requirements specified by the trait". Because this "some object" is dynamic, the runtime needs to know exactly what kind of object this is so that it can call the correct methods on it. The way it finds this out is with another pointer to a table serving as a kind of type directory, known as a vtable. Does that help??
Could not agree more. It should be as safe and as straightforward to use channels across threads as possible, taking hints from Go. I have almost no use cases where I'd use std::mpsc, let alone choose it over crossbeam-channel. I can think of an infinite number of use cases for single producer, many consumer, can't really think of many for many producer, single consumer. I'm a big fan of your proposal: add std::sync::channel, port std::mpsc to use it internally, then deprecate std::mpsc at the language level. Will keep an eye out for the RFC!
You should try graphics programming. It's fun!
Some. But I was driving at performance, especially in desktop computing. In that case java is not that far-off (and using jvm is implied in original post so sluggish starup comes either way).
Been using it since October in production. No issues and I'm using websockets and pretty much the framework has to offer. Also great performance. Can sustain 1M RPS without a sweat.
Well it's not really a bad thing since you shouldn't be using \`async\` / \`await\` in production before Node 12.x. The implementation is kinda problematic right now, see here on the v8 dev blog: [https://v8.dev/blog/fast-async](https://v8.dev/blog/fast-async)
It is a vector! A vector has a magnitude, and a direction. Its magnitude is the value, and the direction is the pointer forwards to the next element. Okay not a perfect fit, but it's not as silly as it sounds.
They’re not long! For god’s sake, stop abbreviating things unnecessarily. It increases the cognitive burden of programming, which is high enough as it is. With abbreviations programmers have to remember not just *which* the word is used “receive” vs “accept” vs “take” vs whatever, but *also* the specific shortened form being used. This API is particularly asinine because it contracts “recv” but not “send” in some futile effort to do what... align then vertically if they’re adjacent?! They never are though in real code because they’re in different functions running in different threads! So please. Just stop.
JVM isn't even close in performance
&gt; The distro maintainers are paid by their customers to do that maintenance themselves. Sometimes, but not always. Depending on the distro, the maintainers may be volunteers. &gt; Distros understand that asking library maintainers to do unpaid work to help them is unreasonable They can't really expect you to go out of your way to help them, but when it doesn't result in too much of a burden, it is generally considered courteous for open source developers to consider the requirements of distro packagers (and more generally, users). Many people writing open source software want to see people using and benefiting from their work. I think most people are quite happy to see distros packaging their code, which furthers this goal. In some sense the project's developer could see the distro packager as doing them a favor, not the other way around (of course, it's ultimately to the benefit of users). Sometimes software ends up not being packaged at all, despite distro maintainers wanting to, because upstream has made decisions that make it too much of a hassle. If it's not a priority for you, that's fine; but to many people, it is. And it depends what kind of software you're developing.
`try_send` is semantically almost identical to `Future::poll`. I'd be tempted to use the futures nomenclature and call it `poll` (or `try_poll` if it returns a `Result&lt;&gt;`).
Watching this thread - please update us if you get this working. I'd love to implement UoW on some of my own projects. 
Someday! I got started with programming with text adventures, so text just kinda stuck :)
The only difference from C is that you can overload * via the Deref trait. But even that only overloads what you deref to, it’s still a dereferencing operation.
As somebody who has come a little way along in understanding rust, I think this is one of the things that makes new users give up, especially one's that already know c, which can be a burden. If you take a "reference" of an variable, you could be getting a simple address, a fat pointer(slice I think), and who knows what else, trait object?, sometimes you get a reference without even asking for one (smart pointer like Box). Can you get a smart pointer from a &amp;? I'm going to have to think about that one. But you *do* know you don't own it, and the compiler needs to be sure of that too. The founders mashed up the concepts of ownership and addressing. Was this being overly clever? I don't know yet. 
It's also worth noting that `*` must return a reference type, unlike in C++ which can return anything. Which is mildly annoying for some RAII patterns. 
Do u know any resources that can help with my doubt here? 
I like that idea! Regarding the implementation, I think using something like an ELF section instead of "special start and stop markers" would be a more sound solution, but probably more challenging to implement.
If by challenging you mean organisationally, then sure. But the actual compiler change to support this would be pretty straightforward to implement.
Ah, interesting idea. So far, no, it doesn’t.
&gt; it is very fast. No, it's not. It's very, very, slow compared to compiled languages. Which makes sense. There's no logical reason whatsoever anyone should expect that not to be the case.
&gt;newer standard If you're referring to the actual ISO Standard for Pascal, AFAIK it's completely irrelevant. What Pascal "is" nowadays is basically just a combination of whatever Embarcadero decides to implement in Delphi, and what the Free Pascal developers decide to implement in FPC. (To be clear, no, Delphi is not a language, it's an Object Pascal compiler and IDE. As are FPC and Lazarus respectively.) [Take a look at this tutorial](https://castle-engine.io/modern_pascal_introduction.html) to perhaps get a better idea of things.
Can you give an example?
Do you mean like this? println!("Hello World!") vs: let s = "Hello World"; println!("{}", s); These are refereed to as literals. In both cases "Hello World!" is static to the entire program. These actually should compile down into the same code. The variable having a name doesn't matter. As far as the ownership semantics, "Hello World!" is a `&amp;'static str`. Nobody can own it, and nobody can get a mutable reference to it. Any number of people can look at and use that value, but nobody can ever change it. Hell, this should also generate down to the exact same code: let s = "Hello World!"; let r = s; let v = "Hello World!"; let v2 = v; println!("{}", v2); The compiler would optimize this code so that s, r, v, and v2 all point to the same value in the program. 
This was my first thought as well. This should be implemented as an ELF section and folks can have the option of stripping it out if they desire. 
My comment is perhaps a bit unclear (I use parentheses too much), but I was referring to Ada when I mentioned a "newer standard".
Yeah, I got that. Didn't the rest of my comment make that obvious?
&gt; Because the _vast majority_ of uses of `send` are `like this: ch.send(foo).unwrap()`. At Faraday, I mostly work with `tokio` channels, and this is definitely not my experience. The most common channel configuration I see works essentially like a Unix pipe: data_producer | data_transformer | data_sink The code in `data_producer` will normally contain something like: dest.send(Ok(bytes)) .map_err(|_| format_err!("broken pipe in data_producer")?; There's generally also a context struct: struct Context { error_channel: mpsc::Sender&lt;Error&gt;, // (plus structured logging context or whatever) } ...and a supervisor somewhere with an `mpsc::Receiver&lt;Error&gt;`. If an error occurs in, say, `data_sink`, then `data_sink` will report the error on `error_channel`, and drop the receiver of the channel it uses to read from `data_transformer`. This will cause the broken pipe to propagate back through `data_transformer` and `data_producer`. In fact, it's actually really hard to shut down a loosely-coupled pipeline like this without using something like `EPIPE` to propagate the error. There's no easy way to notify `data_producer` that all the consumers have errored out, and so `data_producer` is inevitably going to try to write to a pipe. I'd argue that in cases like these, panicking on `send` is a _terrible_ default, and almost certainly incorrect. I want `data_producer` to fail with a nice clean `EPIPE` error, and not `abort` the entire process by default. I have no intuition about which case is actually more common. I do know that much of the channel-based Go code I've had to debug has had weird channel shutdown issues. (See [this paper](https://songlh.github.io/paper/go-study.pdf) for an academic analysis.) 
I have edited the post to add one :)
All string literals are `&amp;'static str`, they are compiled into the executable, and loaded on startup with the rest of it. The `String` you're creating is, as far as the borrow checker is concerned, a local just like any other. 
All I've got is the 3 books that I keep referring to. I think because rust is both a high level and low level language it tries to hide some things from you, but at the same time the low level leaks through. It has the most difficult 'mental model' of any language I've used. Here are the books, you probably know most of them, they are all good in different ways. https://doc.rust-lang.org/book/ https://smile.amazon.com/Programming-Rust-Fast-Systems-Development/dp/1491927283/ref=sr_1_1?keywords=programming+rust&amp;qid=1551578981&amp;s=gateway&amp;sr=8-1 https://smile.amazon.com/Beginning-Rust-Professional-Carlo-Milanesi/dp/1484234677/ref=sr_1_1?keywords=beginning+rust&amp;qid=1551579001&amp;s=gateway&amp;sr=8-1
&gt; This is a proof of concept implementation, the main goal is to demonstrate the viability of the idea and gauge community response. We would definitely be interested in using this where I work. Thank you for working on this!
Yeah it's true that rust's concepts and working are difficult to model in mind. I think that the "the book" leaves a lot of internal working out wanting to make it easy on the beginners,I suppose. But in turn this makes it much more difficult for beginners who want to understand how the language works. Thanks for the resources :)
If anyone's renaming, it should be the game. The language was first.
Thanks for responding. But this doesn't answer my questions regarding who is the owner. Maybe u have answered it but I am too much of a noob to understand it :) can u please explicitly state the answer with related insights?
I mean, I wasn't trying to make any comments about Pascal standards. But let me paraphrase my original comment, which is somewhat unclear. * I have no experience with Pascal (though I've taken a look at Free Pascal since my first comment) * But I have ended up taking a look at Ada * Both languages seemed to generally be viewed as old languages that aren't used any more * But if you actually look into them, modern implementation support a decent set of modern features, with more continuing to be added * In Ada, the newer features are also standardized, for what that's worth Basically I wasn't aware that modern Pascal was a decently attractive modern programming language, though it's not surprising from what I've seen of Ada. And I appreciate seeing your suggestion of Free Pascal, which I was not familiar with.
The string isn't assigned to any lvalue, so in that sense it's not "owned" by a name. I would still call it an owned string because the string owns *its own* data, even though it's not assigned to any lvalue. Re: lifetime, we know that it needs to be live for the function call, so it must be created sometime before the function is called, and it can be dropped anytime afterwards. I don't know if it's actually specified when either of those events happens, but based on [this playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1e5971f2f69f84e6b05488321c7acb7c), the way this is currently implemented is that the scope of an inline value is its usage site, and it is dropped immediately afterwards. By contrast, bound values live until their enclosing scope ends (and are dropped in LIFO order). 
I don't see any difference between this list and the one in the comment you were replying to. Am I missing something or did you accidentally duplicate the same set of functions?
No, an important difference to learners is deref coercion, which allows you to write &amp;x where you had to write &amp;*x in C++. This is the source of saying "&amp; is for borrowing, not for taking addresses". The key to understanding, I found, is that deref coercion only happens with &amp;. You can't write x where you would write *x.
This is an awesome idea! We need a group of security minded people making sure rust is actually doing this sort of thing correctly. keen to see where this goes!
Only potential problem I see with that is that it won't work on platforms that don't use ELF (Notably windows), but they'll also likely have a way to section off data like this.
Sure, I was just specifying the xxx...
If a tool like that were to exist it would accelerate the learning phase of most newbies. I wish there exists one.
&gt; Note how using `.` on a reference in C++ always results in a compiler error, I think you meant "pointer."
Yes, right.
Coercions are different than what the operators do, which is why I didn’t mention it.
The the `&amp;[64]` reference demonstrates one of the few cases where Rust has implicit type coercion (which it tends to avoid). It is provided by the [`Deref`](https://doc.rust-lang.org/std/ops/trait.Deref.html) trait. The standard library implementations of the trait are listed in the documentation. `Vec&lt;T&gt;` implements the `Deref` trait with `Target = [T]`. Another one you commonly see is that `String` derefs to `str`. The language then provides deref coercion so `&amp;String` can be coerced to `&amp;str` and `&amp;Vec&lt;T&gt;` coerces to `&amp;[T]`. If you're familiar with any object oriented language with classes and inheritance, the idea of the `&amp;Debug` example is basically analogous to being able to pass an object of a child class to a function that takes the parent class (Class-based inheritance is quite different from traits, but in this particular regard they're similar.) A pointer to a trait is called a "trait object", and The Book has a [chapter](https://doc.rust-lang.org/book/ch17-02-trait-objects.html) on them. Though probably most Rust code tends to use type parameters instead when possible (static dispatch instead of dynamic dispatch).
I don't think there exists such a tool right now, but there has been some talk about it, such as [this blog post](https://blog.adamant-lang.org/2019/rust-lifetime-visualization-ideas/).
Assuming that by "other languages" you mean "C/C++", the answer is superficially yes. I'll elaborate: *X means to dereference something, just like in C/C++. This can be a pointer/reference dereference, or a smart pointer dereference via the `Deref` trait. &amp;X means to take a borrowed reference to something, which is superficially similar to taking the address of something in C/C++ (modulo all of Rust's borrow/lifetime rules). The main difference you need to be aware of coming from C++ is that Rust does NOT have any reference collapsing like C++ does. In C++, the type `&amp;(&amp;int)` is precisely the same as the type `&amp;int`; in Rust, you can have `&amp;i32` and `&amp;(&amp;i32)`, which are separate types. Automatic dereferencing happens at the method level. Rust doesn't have separate `.` and `-&gt;` operators; instead, the `.` operator automatically dereferences if necessary. This can lead to some confusion, if both the outer type and inner dereference type have the same method with the same signature (a common example is how `Rc&lt;T&gt;` and `T` can both implement `Clone`). This leads to patterns like `Rc` using only static methods, and `(*p). clone ()` being used to call methods on the inner object 
The code you provided won't work as-is, because 'some' expects an &amp;String and you have it a 'String'. If you added a &amp; at the call site, Rust would create a short-lived invisible variable (called a temporary) on the stack that contained the String, and it would pass a reference to that temporary. Many languages (such as C) won't create these variables so you'd have to pass a reference to a variable you created yourself.
Yes and no. 
Yes, but in my experience difference is mostly lost to learners. Also, OP specifically mentioned "&amp; is for borrowing", which doesn't make sense if you don't take coercion into account, so that's why I wrote the reply.
`&amp;Vec&lt;T&gt;` is a pointer to a `Vec&lt;T&gt;` and a `Vec&lt;T&gt;` itself includes a pointer into the heap to its first element (if it has one) as well as a length, capacity, and whatever else is necessary to manage it, but these are implementation details. `&amp;[T]` is what's known as a fat pointer (and there is one more like it, `&amp;str`). In rust, it's called a slice reference. It includes a pointer to its first element and a length. It can refer to data stored anywhere be it the heap, stack, data segment, etc. `&amp;Debug` aka `&amp;dyn Debug` includes a pointer to an instance of a struct that implements `Debug` in addition to a pointer to a table (the vtable) in the text segment of a program. The elements of the table are pointers to the functions the struct implements for `Debug`. This is called a trait object. When you call a method on it, it's determined at runtime which function to invoke based on the vtable. This process is called dynamic dispatch, which has a cost when the CPU predicts incorrectly. You typically want functions to take `&amp;[T]` as a parameter as opposed to `&amp;Vec&lt;T&gt;` because if the caller has a `&amp;Vec&lt;T&gt;`, they can cheaply get a `&amp;[T]`, but the reverse is not true. In other words, `&amp;[T]` is a more flexible/general receiver. The caller is also allowed to pass a smaller slice with `&amp;v[3..7]` for example whereas you can only ever pass the entire `Vec` with `&amp;Vec&lt;T&gt;`. What allows you to treat `&amp;Vec&lt;T&gt;` as a `&amp;[T]` is the `Deref` trait, which is implemented for `Vec&lt;T&gt;`. The `deref` method for `Vec&lt;T&gt;` gives you a `&amp;[T]` which points to the entire contents stored in the heap by the `Vec&lt;T&gt;` and the lifetime of the returned `&amp;[T]` is tied to the lifetime of the `&amp;Vec&lt;T&gt;`. That is, you can use the `&amp;[T]` only as long as you can use the `&amp;Vec&lt;T&gt;` (whose lifetime is determined elsewhere, possibly by the scope of the referenced `Vec&lt;T&gt;`). You can read more about `Deref` [here](https://doc.rust-lang.org/std/ops/trait.Deref.html). It's implemented for other types and can be used to simulate inheritance in OOP.
This is how I explain it, it may or may not help. Rust's * is same as C++. It can be overridden, just as in C++. The difference is, Rust's * can happen implicitly. There are two main cases, see below. C++'s .(dot) can't be overridden. Neither can Rust's, but Rust's dot has built-in implicit behavior: it calls * until type fits. That's why Rust doesn't have -&gt;(arrow). It's equivalent to dot. C++'s &amp; (surprisingly) can be overridden, but is not in practice. Rust's &amp; can't be overridden, but Rust's &amp; has built-in implicit behavior: it calls * until type fits. That's why &amp;**x can be written as &amp;x instead, and &amp; is better thought as borrowing operator.
...how do you override `operator&amp;` in C++?
Automatic dereferencing also happens for fields, so it's better to think it as happening at dot. Automatic dereferencing also happens for &amp;.
You're looking for /r/playrust, here we talk about the programming language called Rust
This post might be intended for a game called Rust?
This is one of those that I was on the fence about because of the title &gt;.&gt;
By implementing it... surprising, I know.
Yeah I was hoping for some deep-dive blog post
Eh, send/recv is inherited from socket API...
The terminal picture didn’t help neither. Thought it was the borrow checker there. 
Wait what? Since when? 
Cargo yes, although it does have the fairly major design flaw of encouraging you to use a Turing complete language to configure build tasks beyond the completely basic. The way cargo manhandles you into crates.io is not so great. It implies a *much* higher level of official curation than the site is staffed to provide, and I'm sure it's only a matter of time before a high profile case of it distributing a vulnerability which is either unintentional or even possibly malicious in original intent. And those two downsides play into each other synergistically. If you want to establish your own collection of reusable code - even something personal or in-house - you're not so gently nudged into publishing just so it's not quite such a pain to reuse. And that, well, first of all it's kinda rude. Not even the most zealous Free Software Foundation folks are saying "all software must be distributed." There *is* such a thing as "local modifications" and the GPL is *specifically intended* to protect that kind of development. Hate on autotools all you want (and for the record I *loathe* autotools) but it will *never* discriminate against a local library the way cargo does: cargo won't version your local libraries for you. But because of that pressure, and the gold-rush nature of package names, developers are encouraged to reach farther than they have time or skill to support. And I don't think there's anything wrong with sharing something that's unpolished or stretches the limits of personal skill, but crates.io certainly errs too strongly in the direction of accepting and rewarding bad code vs being critical. For example, my project today was "let's figure out how to write a helper function in C and get it to build." There's been some discussion of meson, so I figured I'd try meson/ninja. I came across `meson` on crates.io. it was published about two years ago. There is *one* commit in the git repo, but it's already "1.0.0" semver. The example clearly hasn't been tested because it uses `PathBuf::join` where `push` is necessary. It's not bad software for a first repository commit - there's never a bad first draft - but it's clearly abandoned and not what anyone with more skill and experience and time to give it would call 1.0.0. And it's not fair that some developers can pour lots of effort and skill into something called "meson", only for the "Rust community" to award that name forever to someone who abandoned a first draft. I strongly suspect that NPM-etc is a step backwards and crates.io is the front runner for being Rust's billion-dollar mistake.
Minikin has a pretty good [OptimizedLineBreaker](https://android.googlesource.com/platform/frameworks/minikin/+/refs/heads/master/libs/minikin/OptimalLineBreaker.cpp). It's not a massive amount of code, and I think could be adapted to native Rust without too much difficulty.
When you call a function that takes a parameter with type `&amp;T`, and you pass it a reference to some other type (like `foo(&amp;value)`), it will try calling `foo(&amp;*value)`, `foo(&amp;**value)`, and so on until it gets to something with the right type or something that can't be dereferenced. If you call a method on a value with any type (like `value.foo()`), it will first check if `value.foo` is a function, then `(*value).foo`, and so on. For a concrete example, if you have a function taking a `&amp;str`, you can pass a `&amp;String` to it (but not a plain `String`), and it will do the exact same thing as if you passed `&amp;**value` to explicitly get the `&amp;str`. More examples [here](https://doc.rust-lang.org/std/string/struct.String.html#deref).
&gt; barring logic bugs. Sadly, that's also true of assembly. There's no undefined behavior in assembly, after all. Your program does whatever you said - unfortunately that *does* include executing a ROP exploit from the stack - but if so that's a logic error. You didn't say what you mean, oops, sorry. At higher and higher levels of abstraction, humans are going to invent new ways to surprise ourselves with machines that don't do what we intended. Rust isn't a fools errand. It's a great idea. But if it gives a sense of security, *hubris* really, it's only a matter of time before those logic bugs have significant consequences. I love this video because it's about a bug that has *nothing* to do with technology and everything to do with human nature. https://youtu.be/LZM9YdO_QKk 
Traits are contracts between distinct parts of the code, they agree upon a list of functions that can be called. A generic function or implementation of a trait can take an arbitrary type in parameters and is generated for specifically that type when it’s used, substituting the the type it’s instantiated with with the placeholder defined between the angle brackets. So, those two concepts are nothing alike, one is a contract and the other is used for type substitution.
I can't give you a technical answer, but maybe some intuition. Sorry if I explain a bunch of stuff you already know. **Generic types** are just types that take one or more other types as parameters. So for instance, the type stuct Foo&lt;T, U&gt; { ... } is a generic type. It takes two type parameters, `T` and `U`. So whenever we use `Foo`, we have to specify those type parameters, e.g., `Foo&lt;i32, String&gt;`. **Generic functions** are similar — they're functions that take types as parameters in addition to values. The function fn foo&lt;T&gt;(x: T, y: T) -&gt; T is a generic function. We can call it like foo::&lt;i32&gt;(1, 2) passing the type arguments in `::&lt;...&gt;` and then the value argument in `(...)`. More likely, though, we'd just call it as foo(1, 2) because in this case Rust can infer the type argument from the value arguments and pass the type automatically. So generics — generic types and generic functions — are just things that take types as arguments. In these examples, though, we haven't specified what _sorts_ of types we'd like to accept, and so we accept _any_ type. This is where **traits** come in. Traits give you a way to describe a bunch of related types by describing what methods the type must define. For example, the trait definition trait Frobnicate { fn frobnicate(&amp;mut self); } says that any type that implements the `Frobnicate` trait _must_ provide a `frobnicate` method. So then, we can use this trait when defining generic types and functions. For example, fn foo&lt;F&gt;(frob: F) where F: Frobnicate { frob.frobnicate(); } This generic function takes one type parameter, `F`. But this time `F` has a **type bound**: the type passed for `F` must implement `Frobnicate`, and we can call `frobnicate` on the value. This is where generics and traits meet, and why they are so inter-related. There's a lot more to this story, but this is the basic idea.
Blocking literals were introduced in Minisat 2.1 "It can be observed that when visiting a watched clause during unit propagation, it is most commonly the case that the clause is satisfied in the current context. Detecting this without actually having to read from the clause’s memory turns out to be a big win" ([https://www.cril.univ-artois.fr/SAT09/solvers/booklet.pdf](https://www.cril.univ-artois.fr/SAT09/solvers/booklet.pdf) page 31). To understand how it works it is probably best to look at the actual code. When a clause is loaded, the first two literals are watched. This is done by pushing an entry to the watchlists of the two literals. This is handled by [watch\_clause](https://github.com/jix/varisat/blob/9f1533b3a3ce465f89bf417b17162a948a7627a0/varisat/src/prop/watch.rs#L76-L88). You can see that the entry consists of a clause reference and the other watched literal as blocking literal. So for the clause `a, b, c` the watchlist entry for `a` would have `b` as blocking literal and vice versa. The blocking literal for `a` doesn't have to be the other watched literal `b`, but can be any literal different from `a`. We want it to be a different literal from `a` though, as the watchlist of `a` is processed when we already know that `a` is false. So how does this help us? For that we can look at the code for [unit propagation of long (i.e. non-binary) clauses](https://github.com/jix/varisat/blob/9f1533b3a3ce465f89bf417b17162a948a7627a0/varisat/src/prop/long.rs#L19-L112). This takes as parameter a literal that was just assigned. It then looks at the watchlist for that literal to find clauses that could be unit now. The first thing it does for an entry in the watchlist (line 41) is to check whether the blocking literal is already true. In that case the clause is already satisfied, and we can just skip it, without even accessing it. This happens often enough to be an important optimization. &amp;#x200B; I'm using the benchmark sets of the yearly [SAT competitions](https://satcompetition.org/) to evaluate solver performance. Those are hundreds of benchmarks. Some can be solved instantly, some take seconds, some take hours, some take forever. A timeout of around an hour per benchmark gives useful results. Running these benchmarks then takes hundreds of hours of CPU time, a few hours of wall time and costs a few euros, so I'm not doing that too often. I'm not really doing any micro-benchmarking, as for sat solvers the results don't really transfer to realistic use cases. Instead most of the time I take a sample of the instances that take seconds to a few minutes. Using a sampling profiler to see where the code spends most of its time and optimizing that works pretty well for me. &amp;#x200B; I'm already using proptest :) [here](https://github.com/jix/varisat/blob/9f1533b3a3ce465f89bf417b17162a948a7627a0/varisat/src/prop.rs#L67) I'm using proptest to generate random formulas with a known set of implied literals to test unit propagation. Using proptest made it a lot easier to get a good [coverage](https://codecov.io/gh/jix/varisat).
That’s a really bad idea. You would have to do the same for Mach-O and PE and every other binary format that isn’t Linux/unix—which you could do—but then it’s a platform dependency nightmare. Make it as stupid simple as possible and ease of implementation and maintenance are corollaries. 
I thought Rust was supposed to prevent these kinds of issues. 
Agreed
This is the Rust language Reddit, not the game, but have you tried restarting your computer 😜
Is this meant for r/playrust?
My bad lol 
One API quirk I've been curious about, which applies to both the old API and the new proposal: Senders implement `Clone`, so I can make copies of them to pass to all my worker threads. But all the methods on them take `&amp;self`, so I could just as easily create a single `Arc&lt;Sender&gt;` and clone that to different threads also. Is there any difference between either of those approaches? Does this mean that channels are doing internal reference counting of their own? Could anything be simplified by _not_ making senders and receivers `Clone` and instead having all callers rely on `Arc` (basically like we do with `Mutex`)?
I have edited the post to add new example. Please take a look
How does all of this interact with `futures::channel`? Is it inevitable that that'll end up being a totally independent implementation? Or is it possible that a single implementation could bridge the two worlds? Could there ever be one thread blocking synchronously on a channel, another thread `select!`ing on the same channel, and a third thread running a `Tokio` event loop also waiting on the same channel?
Since C++98 at least [https://onlinegdb.com/ry8Y5yFIN](https://onlinegdb.com/ry8Y5yFIN) [https://godbolt.org/z/KoXAcO](https://godbolt.org/z/KoXAcO)
You could also do `use std::vec::Vec as List` I think
&gt; Java has &gt; ArrayList Java also has Vector https://docs.oracle.com/javase/7/docs/api/java/util/Vector.html
So because UNIX made mistakes in the 1960s, we must forever repeat them?
Aren't they both essentially contracts used for type substitution though? Couldn't trait definitions be shimmed into the generic part of a declaration, ie just a trait with scope that only applies to eg a function?
Good point. Though we don't talk about Vector any more :-D.
Example 1: The string you create lives on the stack in `main()`, so `main()` effectively owns it. It will be dropped (freed) when the call to `some()` returns. [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=3e717f5a6af18a65bc4454cefb4b79f5) If you get rid of the `\&amp;`s, then the string you create will be initially owned by `main()`. However, ownership will transfer to `some()` during the call: the string will be moved. It is the responsibility of `some()` to drop it (directly or indirectly). Example 2: The iterator `..` owns the values it passes out. Because integer types are copied, rather than being borrowed or moved, `n` also will own a copy of each integer in turn. If you iterate over some non-copy type, you can choose to either have the iterator give away ownership of each element as it is generated, or own the elements itself and give out references.
"recv" is a terrible name IMHO. My mind thinks "recording five" and pronounces it "Wreck V" which is nothing like "Receive". I say go for "receive" full out. Or since we are bikeshedding...would "take" be okay? We take one element out of the receive queue after all...
I am just pointing out recv is not made up word by Rust developers.
That *is* a good counterargument.
I feel like this is something that has applications outside of Rust as well. As /u/rotty81 said, it would probably be better to put it in its own ELF section. PE and DYLIBs both have ways of storing readonly data in special sections as well, so it would be mostly portable to Windows and OSX. This would make it much easier to write a common set of tools that can be used against any type of binary as long as it had a `DEP` (or whatever) section header. I'm somewhat surprised this hasn't come up in the go community since everything gets compiled down a statically linked binary (at least on linux, I'm not sure about windows). I think they would benefit a lot from something like this. 
I'm pretty sure the entire thing could be done with a linker script for ELF targets - not sure sure about PE files.
When you take a reference to a value, you get a thin pointer (a.k.a. simply the address of the value) if the type of the value is sized, a fat point if the type is unsized (pretty much just slices right now). You have to cast to a trait object to get a trait object, although it is the `&amp;dyn Trait` value that has the fields of the trait object - there's no double indirection here. You get a reference from smart pointers such as `Box` because there's an `impl&lt;T&gt; Deref for Box&lt;T&gt;` and the `deref` function gives an `&amp;T` and Rust will automatically add `deref` as needed in certain places. There's no mechanism for automatically converting an `&amp;T` into some other type (except `&amp;&amp;T -&gt; &amp;T` also via `Deref`). &gt; The founders mashed up the concepts of ownership and addressing. Was this being overly clever? I don't know yet. Consider addressing to be an implementation detail of how references work, and not something fundamental to the idea of borrowing. It makes it fast, but it's not core to understanding ownership. And not something to think about unless writing unsafe code. And I wouldn't call it being overly clever. When you take the address of something, you're giving information of its existence to something else to inspect and possibly modify. Without being able to take the address of an object, it's impossible to share it.
&gt; It's probably really better to think of it as a reference rather than a memory address. In C++, you have types like `int&amp;`, which is a reference to an integer. This behaves very similarly to Rust. While it's true you should not think of Rust reference types as memory addresses, it's easy to get into trouble thinking of them as C++ references. The behave much more like C++ pointers in every appreciable way: - C++ references can be collapsed, Rust references cannot. In C++, `int&amp; &amp;` is the same as `int&amp;`, but in Rust, `&amp;int` and `&amp;&amp;int` are different types. - C++ references cannot be rebound after initialization; Rust references can (assuming they're mutable). - C++ references can be used in place of the underlying value in all cases, and in both lvalue and rvalue contexts. Rust references must be dereferenced, except in the special cases where implicit dereferencing occurs. 
If you really want to understand the language's rules, https://doc.rust-lang.org/reference/ is mostly correct.
Thanks a lot. This is what I wanted. A clear distinction between the two. And yeah do u have any resources useful for understanding and the relationship between the two in greater detail? Thanks for an awesome answer :)
Ok but I get confused when these two are mixed. Like defining methods of a generic type. Can u please give an example. Thank you
deno is a front end to V8. It is no more a JavaScript interpreter written in Rust than Facebook is a web-browser written in React.
Only if you look at it in black&amp;white terms, but as often there are gray colors as well. In this case "semi-stabilization" means that lang team does not plan to introduce any breaking changes, so all interested projects can start using this feature while knowing that chances that breaking changes will be introduced are very small. As others have noted, I think it does not make sense to stabilize the feature while one the main users (`tokio`) haven't utilized it yet fully.
I disagree. ELF, Mach-O, and PE file formats are very well defined, and tools already exist for accessing section data in all of them. Injecting new sections I know for a fact is easy in ELF, probably similar in Mach-O, and probably "easy enough" for PE files. Utilizing standard binary features for this allows usage outside of just Rust. Now your C++, Go, Swift, C#, etc programs can utilize the same methods of specifying dependencies which allow for better, more consistent tooling support. If you spend more time laying the foundation, it will become significantly more useful and have a better adaption rate. Which will in turn lead to better standardization and wider support.
/s
I learned programming before I went to university. In my first linear algebra class, the professor introduced matrices. I raised my finger and proclaimed, "Why do you write A_12_ instead of A_1,2_? It *doesn't make sense!* Also, it is inconsistent, because you have to write A_10,20_ anyway!". He just answered, "wait and see, you'll understand". After the first homework exercise, I came back and said, "I understand".
[Take a look at the `Range` docs](https://doc.rust-lang.org/std/ops/struct.Range.html). Note the `Iterator` impl at the bottom. `Range`, as any other argument of a `for` loop, must implement `Iterator`. The loop effectively just calls `Iterator::next` repeatedly, running the body against each value the `Range` produces. Desugared, your loop looks something like this: 1 { 2 let range = 1..100; 3 loop { 4 let value = range.next(); 5 match value { 6 Some(n) =&gt; { println!("{}", n); }, // body of your loop is here 7 None =&gt; break, 8 } 9 } 10 } NB: don't interpret this completely literally&amp;mdash;I wouldn't guarantee that it actually exactly like this, but it should give you an idea of what's happening behind the scenes. Note that on line 4, we're calling `Iterator::next` to produce the next value. Based on some of what you said, I think you're under the impression that a `Range` holds all of the elements it iterates over in memory simultaneously and transfers ownership element-wise in that `.next()` function call. This isn't the case. [As you can see in its `Iterator` implementation](https://doc.rust-lang.org/src/core/iter/range.rs.html#207-263), `Range` only tracks its start- and endpoints, producing values by incrementing until start &gt;= end. There is a value moved out of the `next` function, but that value is produced from within the `next` function itself. 
r/lostRedditors
Hey, this subreddit is for a programming language called Rust that involves high memory security, and is a systems language, similar in usage to C++. You're looking for /r/playrust
I don't. I mean, I know what you're talking about, but it is exactly this kind of laziness that builds up insurmountable technical (or syntactic) debt. Modern physics is a great example of this, where I suspect that forward progress towards a theory of everything has been hampered very significantly by the baroque mishmash of syntax, the short-hand, the corner-cutting, and the "weak typing" where it's "just assumed" that certain letters have certain types, except in different contexts, but not in this case, except for when... because keeping that straight in your tiny limited squishy brain is clearly the best use of its finite capacity, right? Try any symbolic computer algebra system, like Axiom, Mathematica, or Maple, and you'll very quickly hit wall after wall of traditional maths syntax getting in your way. Underneath the hood, no CAS uses "maths" syntax, because it's weakly typed garbage that makes JavaScript look strict in comparison. Internally, they all use strict, systematic, strongly typed code because that's required to actually do something useful. Ask yourself this question: How much respect would *you* have for a programmer who insistent on only using single-letter identifiers in all contexts? No, seriously. Imagine coming across this: class A { a; b; c; x f( y ); } I have seen code like that, hundreds of thousands of lines of it, for real, in production software. It was worthless garbage. Why do mathematicians get a pass on this kind of thing, of programmers don't?
I don't think such a tool would help much for even an intermediate rustacean. When the borrow checker complains, without much trouble you can see why it doesn't compile. A lifetime visualizer will only show you what you already realize. "Fighting the borrow checker" means you're struggling to find the proper solution that satisfies the borrow checker and a visualizer can't do that.
Why doesn't \`rustfmt\` re-format [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b8315120ae30fa3e2b78c07cb69daf81) code properly?
to future readers: I'm pretty sure vivainio is being facetious
If you're not writing your text adventures in [Inform 7](http://inform7.com) you are *totally* missing out. This is what IF authoring was meant to be. (Sadly, Inform 7 is a huge amount of C code in a low-maintenance state. If somebody wanted to oxidize something similar, I would be more than excited…)
Temporal AA is the most effective solution to that, but then you'll have to deal with ghosting artifacts somehow.
"List" is even worse. Its meaning is as old as LISP, which is pretty damn old: it's supposed to be a linked list, not some kind of array. Of course "array" is also used in mathematics to describe a matrix. Honestly, as a computer model of a mathematical "vector" (1×n matrix) I don't see why the name is so inappropriate. What properties of a vector would you like `Vec` to have that it does not? Orientation, I guess? (row vs column vector) Don't get me started on Rust's lack of a native multidimensional array type. Yes, there are crates, but the ugly corners sometimes show, and lacking these types in the standard library is a bit annoying.
You should take a look at this: https://users.rust-lang.org/t/fearless-rust-bloggers/16770 I'm not sure it's still up-to-date but it's good start 
True, but it is pretty comparable to node, which could reasonably be called a runtime. V8 doesn't provide much/any access to the underlying platform by itself...
&gt; Consider addressing to be an implementation detail of how references work, and not something fundamental to the idea of borrowing. It makes it fast, but it's not core to understanding ownership. And not something to think about unless writing unsafe code. Ok, but its a very leaky implementation detail. Was there really a necessity to convey addressing outside of unsafe? I'm not sure myself because I haven't grokked the entirety of the language. How about this, (I hope I got this syntax right), (*o).get(); can be this o.get(); so I don't have to think about addressing, dereferencing, pointers, etc But why can this? *o += 1; be this? o += 1; 
V8 is a JavaScript *engine*, written in C++. Deno is a JavaScript *runtime*, written in Rust, that uses V8 as its engine.
Not really a nightmare. How many different exe/objformats are we talking about anyways, a handful at best.
That's some strong criticism — and I believe it's mostly accurate. I'm not affiliated with the Cargo team but have heard there are significant plans to improve it this year. &gt; Hate on autotools all you want Yes. Though to be fair, much of the complexity comes from trying to handle many different compilers on many different platforms, something Rust doesn't (yet) have to deal with — one compiler and most of the platform-specific stuff is hidden inside libs. Hopefully we'll see a full replacement for `crates.io` before it gets to the "billion dollar mistake" level. That said, building a large curated repository is no small feat, and switching to a collection of many small repositories is also not user-friendly, nor is the traditional "one lib to rule them all" (aka Java, Boost, etc.).
I would love to see something like that written for spidermonkey. Main reason being that SM will soon start using more and more rust and we could end up with a full stack JS runtime written in Rust.
How many elements do you expect the vector to have? Do you insert elements one by one (followed by searches after each insertion) or can you insert many elements at once ?
Elf sections may be compromised 
That does not surprise me, recovering from a poisoned mutex can be a lot of work. 
I think I'll just prefer to just deprecate mpsc channels and call it a day. I don't think we are doing us any favors by moving crossbeam into the standard library, nor by "repairing" the performance issues of the std channels. 
I wonder if it wouldn’t make sense to add a `lock_unpoisoned` which just ignores a poisoned mutex. I already have some code that does that or uses parking lot which has no poisoning. 
\&gt; One of the top results was [Deno](https://github.com/denoland/deno). This was interesting for a few reasons: &amp;#x200B; You are kind of missing that the author of Deno is the original author of node.js, which made it infinitely more interesting to me.
This is part 2. If you read part 1, he is using proptest!
Still, you can't do vector calculations with strings.
The std programmer did, but he grossly misunderstood the concept of vectors. He thought it was the same as an array, and to differentiate static arrays, he called it vector.
Doesn't matter for our discussion imo.
The burrow checker messages already contain visualization of the lifetimes and I'm always impressed how easy to understand they are. If you have any opposite examples, you should post them.
A difference that (I don't think) anyone else has mentioned is that `&amp;` can also be used in a destructuring pattern. So: match foo { &amp;bar =&gt; wibble(bar) } Is (usually) the same as: match foo { bar =&gt; wibble(*bar) }
&gt; he grossly misunderstood the concept of vectors This is veering pretty close to Ad Hominem territory. You are free to have a different opinion, but do NOT characterize people with a different opinions of "idiots".
Instead of storing the slices, you could just store the ranges of indices in the queue. Splitting a range like begin..end becomes begin..mid and mid..end. However, without code I cannot know for sure what you are trying to achieve.
I think it would be unfortunate if non-blocking send/recv needed a zero timeout. It's basically a completely separate use case from the timeout versions. It would force all users to also import the extra Duration type and the call would be noticeably longer. And as you say, would likely end up with more initial checks in the impl to go down different paths anyway.
This is cool. Knowing which exact versions of each dependency a binary / service is using makes it so much easier to exploit. 
Using a majority of proprietary software is detrimental to your freedom as a computer user, it makes you dependent on the developer's choice to how computing should be, and that's unacceptable. Developers are here to serve users not the contrary, I, as a developer, want to offer my competence to users who remain in power of their computing, as they deserve. Proprietary software should disappear, at least for the basics needs such as communication.
I have to disagree to an extent to this sentiment. I see it being thrown around as an argument often which sounds solid at the first glance, but doesn't stand to scrutiny when examined. The major for of the argument rests on the premise being implicitly suggested that code you write yourself doesn't suffer from same issues, when it obviously does and to an extent higher degree. Let me try to unpack: First of all it's important to note that I'm yet to encounter a company which would have more bug or security issues in their prod due to third party packages they use than the bugs they themselves bake into the code. You brought up NPM which you named as a catastrophe. But none of the characteristics of NPM which allowed it to cause major issues are not present to [crates.io](https://crates.io). People just like to throw the baby with the bath water when in reality the major problem was mutability of the packages in NPM. For example, the famous leftpad package issue. And I never miss the opportunity to point out how conveniently such sentiment leaves out how lack of any packaging system would stagnate the ecosystem as a whole which would result in less innovation and things being build. Progress not made which could possibly be made is also a major loss, however our brains tend to fixate only on existing progress which is being taken down by incidents. &gt;and I'm sure it's only a matter of time before a high profile case of it distributing a vulnerability which is either unintentional or even possibly malicious in original intent. This traces back into what I've previously pointed. Sounding like a solid argument but when examined not standing to scrutiny. The only risk free code is no code at all. Period. Your hire might just back security issue. The issue stands relevant regardless of the source of the code. However, only distributed code brings in community to solve the problem together rather than companies trying to solve the same problem individually rewriting reimplementing their solutions. Generally the first one covers more edge cases than one company or developer could think of or bring into scope. &gt;But because of that pressure, and the gold-rush nature of package names, developers are encouraged to reach farther than they have time or skill to support. That's lack of discipline and competence. To expect the developer to write one's own high quality code when that developer lacks any idea to inspect the code one brings in. And if package was long enough in the ecosystem you can rely that if it had some issues those were already encountered. So for example React as a view library for javascript. It's been distributed through npm. &gt;It's not bad software for a first repository commit - there's never a bad first draft - but it's clearly abandoned and not what anyone with more skill and experience and time to give it would call 1.0.0. And how's that different from code some previous colleage wrote 5 years ago. Some custom framework solution? I can tell you, it's absolutely worse. I do work with such system. Not only it's rotten as all code rots it also lacks documentation or people who already encountered problems with it to help you deal with it. &amp;#x200B; See what I did? I don't object to the fact that distributed code is risk. However, I'm a bit tired of people who implicitly suggest that your own code is somehow above that factor. It isn't. And in many cases it's actually even more risky. &amp;#x200B; I strongly recommend Kevlin Henney's talk I think he gave at GOTO conference. "Code as risk" which he dwells in depth on the subject. He covers packages as well as custom implementations. And how they fair. &amp;#x200B;
We have one and they're called [Secure Code Working Group](https://github.com/rust-secure-code/wg). And here's [this year's roadmap](https://medium.com/@shnatsel/security-as-rust-2019-goal-6a060116ba39).
I'm working on a playground link to more clearly illustrate the issue
Yes, this ^. I do `let _ = tx.send(...);` at least as much as I unwrap send operations. One use case where I have this is one thread managing a `hyper::Client` doing all HTTP for the program, then others can send requests via it and get the results back via channels. The thread doing all the HTTP should of course not panic if a single listener decided to not wait for its answer. We all code on very different types of code and for some types of code one default is very logical and for others another one is.
Have you read the book?
Apologies, I misspoke, i didn't mean we didn't have one, just that people doing this are awesome!
Could you point me to some tools for injecting an ELF section? It'd be nice to prototype something like that.
`&amp;` is for borrowing in C++ to since you can overload `operator&amp;`. If you want to take the address of a C++ object you need to use [`std::addressof(x)`](https://en.cppreference.com/w/cpp/memory/addressof). So AFAICT, all of this behaves pretty much the same in both Rust and C++.
Is that how compiler inserts its version currently? I guess that would be a better idea. Any pointers on the implementation would be appreciated.
Could you point me to some tools for injecting an ELF section? It'd be nice to prototype something like that.
I mean, you __can__. It would just be matrix math and probably wouldn't produce anything useful.
Cross-posted to stackoverflow at: [https://stackoverflow.com/questions/54968221/managing-multiple-slices-of-the-same-section-of-memory](https://stackoverflow.com/questions/54968221/managing-multiple-slices-of-the-same-section-of-memory)
wow thanks for that trait object definition. can't believe how much light you shed on me. Kind of embarrassed, that I didn't came to that conclusion by myself. (yes I read the book, yes I understood roughly for what it's used)
What crate are you using for gRPC?
Since C++98, that's why `std::addressof` exists. If you want to actually take the address of a C++ object, you need to either use `std::addressof(x)`, or write: ``` T&amp; x; T* x_ptr = reinterpret_cast&lt;T*&gt;( &amp;const_cast&lt;char&amp;&gt;( reinterpret_cast&lt;const volatile char&amp;&gt;(arg))); ```
I'm not using a cargo subcommand in the prototype, it's done in a `build.rs` Security through obscurity doesn't really work, so I don't think encryption is a good idea here. Encrypting the version data doesn't make the binary any less vulnerable, but it would prevent e.g. a cloud provider from scanning all your binaries for you. However, authentication sounds interesting.
Every time I thought I needed `select!` I worked around it by having an enum with variants for all the types in the channels I would have otherwise selected over. Then I just recv on a single channel to get messages from everyone. If I want to limit the senders so they can only send their designated type, and not everyone's types, I just wrap my `Sender` in something like `IntoSender&lt;T, MyEnum&gt;` that basically just does `self.sender.send(MyEnum::from(t))`.
&gt; Encrypting the version data doesn't make the binary any less vulnerable, No, but it raises the effort an attacker needs to put in to exploit the binary. The amount of work required to figure out all my binary dependencies, their versions, and whether they are exploitable, is significant. If I just give them the `Cargo.lock`, scanning for CVEs in a data-base is a one liner.
If someone can compromise you enough to modify an ELF section, they have compromised you enough to be able to run arbitrary code on your system (since they can, you know, also modify the other ELF section, the one containing the actual machine code of the program), so your security fucked anyway.
It makes some sense that Rust rejects the code. On line 38 and 39 you call make_smaller_slice that returns a Vec, on line 41 you borrow from this Vec, and on line 43 the loop ends and the Vecs get dropped, meaning the borrows are invalidated. Maybe you could store the Vec&lt;&amp;'a [u]&gt; directly in Split? Also, what is the purpose of `if true` in make_smaller_slice? Could it just directly return a &amp;'a [&amp;'a [u8]]?
I don't think it should be a constructor on the same types, rather a separate type. The `send` and `recv` methods should consume `self` to be a proper `oneshot` channel. So the compiler can give you errors if you try to use it in the wrong way.
A generic is a template for making types, such as "List of ____" (written as `Vec&lt;T&gt;` where `T` is a placeholder). Without generics, you have to either reinvent containers whenever you want to store a new type (eg. "B-Tree of integers" vs. "B-Tree of floats" vs. etc.) or write a "B-Tree of untyped pointers" and risk accidentally getting types mixed up without the compiler being able to catch your mistake. (The latter is what you get in C with things like "B-Tree of `void` pointers".) A trait is an interface that types can implement. That is, a list of things (eg. methods) that any compliant type will have. In short: * **Generics:** "List of ____" * **Traits:** "Thing which can do ____" Generics are concerned with what something *is* while traits are concerned with what something *does*. You use generics to build data structures because it needs to know the memory layout of the items at compile time. You use traits to build things like the `Display` and `Debug` machinery underneath `println!` because it doesn't matter what the memory layout is as long as it's guaranteed to expose the requisite functionality.
I was aware of that. I just forgot there was no tone of voice to make that clear when I interjected with a bit of trivia a surprising number of people seem to not know.
Wow, I didn't realize I could just return a slice. TIL. Thank you so much! &amp;#x200B; &amp;#x200B;
In c or c++, this &amp;**x would mean *x right? Assuming this is the case why do &amp;** instead of just *?
I haven't tried this sort of thing before, but, if I my understanding of borrows is correct, the problem is that `first_half`goes out of scope at the end of the iteration, invalidating all borrows descended from it.
[https://github.com/xi-editor/xi-editor/blob/master/rust/rope/src/tree.rs](https://github.com/xi-editor/xi-editor/blob/master/rust/rope/src/tree.rs)
In C it means that you get a pointer to `x`. In C++ `&amp;x` means that the `operator&amp;(x)` is called, which often means you get a pointer to `x` but it can actually do pretty much anything, so you can't in general say what that does without talking about a particular type. In Rust `&amp;x` borrows `x`, this often means that you get a pointer to `x`, unless the type implements `Deref`, in which case you need to take a look at the types involved.
Channels without select are basically toys.
Right, what I wanted was a way to have the inner borrows be passed along to the new item without worrying about the outer container's lifetime (since it just held references to the longer lived original slice). See u/_TheDust_ 's suggestion of just returning a slice, that fixes it and has the desired behavior. 
Thanks for responding. Are u referring to "the book" when you say rust books? If u mean any other book, please mention it.
The keywords you have to search for in the Rust book and the nomicon (both are linked in the Rust docs page) are "borrowing", "Deref", "auto-deref", and "coercions".
&gt; See TheDust's suggestion of just returning a slice, that fixes it and has the desired behavior. Ahh, yeah. I forgot to reload the thread before replying. (It took me a while to get to it because it was part of a batch I middle-clicked.)
Thanks a lot. :)
&gt; I guess it just seems to me like the manager thread should be designed so that the `send` itself never panics, and if it does, it's regarded as a bug. At least, that seems like the natural case. If this is difficult to do in general, then I'd find that interesting and might motivate the notion for `send` to return an error. As mentioned above, my experience is almost exactly the opposite: Perhaps 75% of `send` calls can fail (most typically during program shutdown, error recovery, or network connection failure/retry), and each of those calls to `send` need to explicitly decide what to do when that happens. Panicking is not acceptable or appropriate in those cases. See u/asajeffrey's [comment here](https://www.reddit.com/r/rust/comments/awh751/proposal_new_channels_for_rusts_standard_library/ehmpiz2/?st=jssv0113&amp;sh=3c4b2669): &gt; ...mostly they replaced `....unwrap()` by `if let Err(e) = ... { return warn!(...); }`... &gt; &gt; Servo still panics a lot during shutdown, due to code that assumes the other end of a channel is still alive, but the shutdown order ended up being an unanticipated one. Sigh. For me, too, this is an extremely common case. So the rule that I've learned is that all `send` calls may fail, and every caller _must_ have an explicit plan for dealing with that error (even if it's only "report the error to the coordinator's `error_channel`" or "log a `warn!` or `error!`"). I've seen several related bugs when fixing other people's Go code. I feel strongly enough about this that if there were a `send_and_panic_on_fail` function and a `send_and_return_error_on_fail` function, I'd actually go looking for a `clippy` lint that allowed me to `#[deny(clippy::send_and_panic_on_fail)]`, and make a it matter of company-wide coding style. This is because the Servo experience described above rings painfully true to me. But I think this may be because I work with two major kinds of channels: 1. Channels that are bound to a bidirectional `tokio` codec, where it's 100% normal for either the read or write ends to shut down when a network failure occurs. 2. Channels that emulate Unix-style pipelines between loosely-coupled processes, where `EPIPE` is a normal way to communicate a consumer shutdown to a producer. There's no easy way to notify producers 100% reliably about consumer shutdowns, because (a) the producer may have very complicated output code, and (b) there's a race condition when trying to shut down both sides of the channel. It's interesting that our experiences are so different. But I almost always use channels under circumstances where your proposal would lead directly to the same problems that Servo has encountered.
Thank for your input though, I really love the rust community and it's amazing to me how quickly I got feedback!
It's a great idea. Please let everyone know about any limitations you run into with rustc. 
`Into&lt;[u64]&gt;` isn't implemented (and can't currently be, since `[u64]` is unsized), it's `Deref` with `Target=[u64]` that makes the coercion work.
It's fucking cancer and people that do it are dickheads
Thanks for the good experience report! You might consider sharing/copying it to the issue ticket that is proposing changing `send` to panic by default. The comparison with Unix pipelines is interesting. It's hard to say exactly without a concrete example in front of me (and getting those are probably a ton of work, because they are difficult to separate from the systems they are embedded in), but my guess is that there is probably a cleaner way to do graceful shutdown instead of relying on channel hangups. This is kind of what matklad is expounding on in his comments on the `send` proposal, where relying on a hangup made it more difficult to see that there were bugs. This isn't a very good rebuttal comment on my part, sorry! I'm more or less expressing skepticism as a result of divergent experience. If I have time, I'll try to see about experimenting with your approach to using channels and see what I come up with.
Another one: [https://crates.io/users/swmon](https://crates.io/users/swmon).
* Claiming should be banned. If not within a grace period the compileable is pushed the crate should be automatically deleted. * There should be two channels for crates. a regular one and side "community" channel for, unused and crap. * At some point [crates.io](https://crates.io) will consolidate on one way or another, otherwise it'll be the rust version of an android crap store. Not sure about how to judge what's hot and what's not or what's considered crap and what's not. Calculating metrics could be difficult. Crates like serde or rand are definitly not crap. Maybe it's possible to move the 1,000 - 10,000 most popular to a main channel and the rest to the side / community channel, similar of how the playground allows the top 100 extern crates. Personally, I am more reserved at pushing to [crates.io](https://crates.io). I have programs and libs that "do things", but I know there isn't much use of it. That's why I don't push my things to [crates.io](https://crates.io) However, it would simplyfy things, when I re-install my system or if I could just do a cargo install on a different computer, instead of downloading, compiling from github. &amp;#x200B;
This has been discussed many times already: * https://www.reddit.com/r/rust/comments/9dole9/proposal_crate_squatting_on_cratesio/ * https://www.reddit.com/r/rust/comments/6u52po/name_squating_on_cratesio/ * https://www.reddit.com/r/rust/comments/6j0g9o/squatting/ * https://www.reddit.com/r/rust/comments/9aaanw/cargo_crate_name_reservation_spam/ * https://www.reddit.com/r/rust/comments/6r6lfs/abandoned_crates/ Let's collectively try to learn from previous discussions before repeating the same stuff again.
It's basically encouraged by the crates.io team, so it won't go away soon.
I found interesting: &gt; If you are embedding deno in a Rust program, see [Rust Deno API](https://deno.land/rustdoc/deno/index.html) From [https://deno.land/manual.html#apireference](https://deno.land/manual.html#apireference)
``` fn foo(frob: &amp;dyn Frobnicate) { frob.frobnicate(); } ``` You can also write it as above, which will result in dynamic dispatch rather than static dispatch via monomorphization. 
Encrypting the version data does not make the binary less vulnerable, but auditing dependencies doesn’t do that either (upstream can be compromised, audit database can be compromised, etc). Both things make the binary harder to attack though.
&gt;V8 is a JavaScript *engine*, written in C++. ... Deno is a JavaScript *runtime*, written in Rust Any "runtime (system)" can freely implement such engines. It's not really 100% precise term to be used here. Note that README of the project says: &gt;Deno is a browser-like command line program for executing JavaScript. which sounds more like a front-end, not a full-stack something.
I wish com.java.namespacing had caught on everywhere.
Use sccache
Georgist economics has something to say about this sort of hoarding of fixed-supply commodities (i.e: land, intellectual property, names): tax the b*stards until they either make good use of them or give them away to others that will.
So, I'm not sure I understand what this is solving. If I already have a Cargo.toml why wouldn't I just check \*that\* against a CVE database? Why would I check the binary?
I am currently binge-watching [Bryan Cantrill's talks](http://dtrace.org/blogs/bmc/2018/02/03/talks/). Only the latest ones are about Rust, but he is an amazing speaker an talks about interesting topics.
/lostredditors
This is the subreddit r/rust which is dedicated to the rust programming language, not the game. 
I'll write a claim-bot in rust that brute-forces every possible crate name available and claims it :)
When you call `Split::new(&amp;processed_first_half_0, &amp;processed_first_half_1)` you create a structure that stores references to the data contained in `processed_first_half`, then you push this structure onto another `Vec`, then the `processed_first_half` vectors go out of scope and the data they contain has to be dropped. Is [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=30d213e6d119631bb4a086d770e7796b) what you wanted?
It's like when I was in kindergarten and there were the people who calimed the sandbox but afterwards didn't use it. It's getting childish.
I am not characterising him as an idiot, I am saying it was not his field of expertise. I'm not calling people who don't understand quantum physics idiots either, but I do mind if these people spread misinformation. You're putting words in my mouth.
Damn.. that one's especially bad.
I'll check it out but the Ising model seems fine to me. We're like 5 months in and the topic of this project was chosen by my tutor, so I think we'll stick to the tools we already have.
I've just realised I can generate an array of neighbor indices at the beginning. They don't change during the simulation. No need for SIMD or any tricks. Thanks for your help anyway!
The only problem I see with it is that the crate index grows and it takes longer to update crates with cargo, but that problem doesn't disappear if people suddenly stop claiming crates. I suspect there are far more obsolete crates on [crates.io](https://crates.io) than there are empty claims.
We can avoid the subtleties and gray areas by banning/reclaiming the obvious bad actors.
I'm still thinking about solutions and will read ("Homesteading the Noosphere")[http://catb.org/~esr/writings/homesteading/homesteading/] again this morning, so I'd like to recommend it to you as well. The problem I see with NPM-like repositories - "one" repository with nobody ruling - is that it changes the gift economics of open-source software in a bad way. And I do think we should be thinking and talking about gift economics - not code-for-hire. I'm not enough of a zealot to say code-for-hire is immoral or shouldn't exist, but OSS or freedom software is going to play by different rules of economics. For example, you talk about hiring coders as if they're fungible - everyone makes mistakes and there's not much avoiding it - so why is it worth it to spend money (or your own time) to develop something you have for free. But that doesn't take into account the existence of highly skilled coders or - and this is really important - the virtues of collaboration and widely-read-and-loved code, which are where OSS really shines. Like, Linux isn't amazing because Linus is a genius. I'm not even sure he is. It's amazing because patches can't be written without them depending on the readability of the codebase and themselves passing review for readability and maintainability. Linus *is* a very good critic, even if he's not particularly tactful. So I think you're seeing code through the principles of intellectual property and not the principles of gift economics. That's why I'm re-reading ESR, because he *has* put a lot of effort into studying and communicating gift economics rather than taking European capitalism as the last word on the worth of things.
In Rust, `&amp;` can be found at different places. - In types: `&amp;T` is a reference to `T`. It implies borrowing a value of type `T`. It has the same meaning as with C++ but because Rust has lifetimes and an internal concept of borrowing, it brings you more features. A reference is _always_ tagged with a lifetime. `&amp;T` elides a lifetime because you don’t care about it, but remember the lifetime is always there, and it’s written with a tick: `&amp;'a T` is a reference tagged with `'a`. - In values / expressions: `let r = &amp;x;` is a reference to the `x` object. This will effectively borrow `x` for as long as `r` lives. `*` can be found in some places as well: - On references: `let r = &amp;x;`, you can dereference the content of `r` with `*r`. Same thing as in C++. - On pointers: `let p = *const x;`, you can also dereference with `*p`. &gt; Disclaimer: dereferencing a pointer in Rust is **unsafe**, so you need an `unsafe { }` block to do it. - On values which type implements `Deref`: the [`Deref`](https://doc.rust-lang.org/std/ops/trait.Deref.html) is a really cool trait because it allows you to get a reference out of a value. For instance, if you have a `String` and want a `&amp;str` on it, you can just call `.deref()` on the `String` value. However, we never really do this. Instead, we use _deref coercions_. If you have `x: T` and `T: Deref`, then `&amp;x` can either be `T` or `&lt;T as Deref&gt;::Target`, depending on what inference needs. This is especially useful as it’s automatically called when you call methods or try to access something in the value. If you do something like `x.foo()`, if `T` doesn’t have a `fn foo` available (from an `impl` or an `impl Trait` block), the compiler will see that `T` implements `Deref` and will try to see whether `x.deref().foo()` is available. This is a gross explanation but you have the idea here. If a value implements `Deref`, you have the `*` operator: `*x` allows you to inspect the value on `x.deref()`. - Finally, `&amp;**x` is just three operators combined: take the reference on the dereferenced value that is the dereferencing `x`. Think of it as `&amp;x.deref().deref()`.
I seem to recall that deno was written in Go, when did this change?
I really enjoyed working through the Advent of Code puzzles: [https://adventofcode.com/2018/](https://adventofcode.com/2018/) There are also many public examples of experienced Rust programmers' solutions, including BurntSushi, who (besides being really prolific) is the author of several well known crates, including ripgrep. [https://github.com/BurntSushi/advent-of-code](https://github.com/BurntSushi/advent-of-code) is his solutions, which are worth looking through for insights on how a fluent rustacean might do things.
He sure is a captivating speaker, I watched most of his talks, but they usually offer very little in terms of the actual technical value. It's kind of a technological stand-up comedy -- you have a good time watching it, but when the talk is over, you have not become a better programmer. This is actually a case in point about why I prefer blogs as a technical medium -- his post on [C vs Rust performance](http://dtrace.org/blogs/bmc/2018/09/28/the-relative-performance-of-c-and-rust/) is _amazing_.
I'm getting sick of this being brought up all the time at this point. Nothing useful ever comes out of these discussions
I like that idea! Hope rust team take a serious look at this problem.
I wouldn't be so sure. Time required to write a whole crate, then for it to become obsolete: A few weeks at minimum Time required to claim a crate name: 30 seconds
I think somebody did do this a few months ago and they got banned pretty quickly.
Cargo.toml is not sufficient because it declares "use the latest version compatible with this one". You need the Cargo.lock that points at *exact* versions used for the build. Also, you cannot just assume that the last production deployment used the exact Cargo.lock file you have now, so you cannot audit them and are forced to either rebuild *everything* or just ignore it. And if you find some binaries from a year ago running in production (which, at any real company, you will) there's absolutely no way to tell what they're running anymore, and good luck justifying rebuilding all *that.* This info is encoded in the binary so there's no way to lose it, and also so that you could install some pre-deployment hooks or a cronjob auditing all your binaries before deployment. Or cloud providers could also scan and flag vulnerable binaries for you automagically, and you would not even have to mess with any of that - Google Cloud already does that for Debian packages, for example.
Very clever, I hadn't thought of using a new type pattern here. However in my example I use the function make_smaller_slice to demonstrate that there is a little bit more going on than just splitting the slices, but I think this might still work. Thanks for the suggestion! 
I'm using tower-grpc
Not sure when exactly but it was done because they were worried about having two garbage collectors so switched from go to rust Source: https://youtu.be/FlTG0UXRAkE
I keep seeing this sentiment in these threads, and I don't understand it. Is it hyperbole because you are frustrated that the team isn't doing what you want? Or do you actually believe that the current policy on crates is tantamount to encouraging squatting?
&gt;During the search I was happy to see something called a Vec which I then assumed would be standard supported matrix calculation capable types, per the definition of vector, but not it seems Rust has just repeated the C++ mistake of confusing naming. You have single fields where this is not valid, such as control systems which in itself can use names/symbols for multiple things which can be confusing for newcomers. Going across domains such as from pure mathematics to programming, this especially does not need to be valid.
Whats the lesson we're supposed to learn? That it doesn't matter what we say on the issue because it's already been decided? Thats the TLDR of every thread on this.
&gt; However, it would simplyfy things, when I re-install my system or if I could just do a cargo install on a different computer, instead of downloading, compiling from github. `cargo install --git &lt;url&gt;` :)
Maybe [https://docs.rs/bytes/0.4.11/bytes/](https://docs.rs/bytes/0.4.11/bytes/) would help you? 
IIRC it was because they had crate names that could have resembled official rust crates, maybe purposefully i dont remember, so only those ones were removed for impersonation.
See this issue for embedding: https://github.com/denoland/deno/issues/1666
&gt; What would be useful is a way to prevent static variables from being removed from the binary. There actually is, the [#[used]](https://github.com/rust-lang/rfcs/pull/2386) attribute, which has yet to be documented, but is stable.
I think the author mentions it, but says that it doesn't work properly.
I love warp and use it in a few small projects, but it is still a pretty new library with a lot of parts that aren't fleshed out yet. Examples: * Errors are pretty awkward to deal with right now, IMO * You can't implement `Filter` for your own structs yet * it's generally missing extendability * there is a planned merge with tower-web that might entail some API changes actix-web is certainly the more popular and more fleshed out choice for now. But since warp is basically a different API for hyper, it should be solid technology wise. So if you are fine with potential churn in the future and having to do some hacky work-arounds where the warp API is lacking, go for it!
Just a quick note - you probably want to use a \`std::collections::VecDeque\` and the methods \`push\_front\` and \`pop\_front\` for your queue. Otherwise you will be shuffling all the items in the Vec when you are carrying out operations at element 0. Very curious as to what this would be used for if its not a toy example :)
[Here's one in an example program of mine](https://github.com/anlumo/Rust-Futures-Presentation/blob/master/demos/async/src/config.rs). This function takes a parameter of type `T`, where `T` implements the `std::io::Read` trait. Whenever you call this function, a new instance of it is created (internally by the compiler, you can never see it) for specifically the type you pass there. Unlike C++, you have to constrain the type, meaning that you have to at least demand that it `impl`ements one trait.
For the first example: You can say that a string literal is owned by the program process itself or nobody. Technically the data itself is in the executable data, which gets loaded into (or mapped to) a certain memory address by a component of the operating system - Loader - whenever your process is started or the shared library with your code is loaded. This kind of data is typically considered to be read-only. As far as a Rust program is concerned, the string data is not owned by any piece of your program code or the Rust runtime, and would be valid at any time when the process is =running. `String::from` creates a modifiable copy of the string literal on the heap, therefore its lifetime is not tied to the string literal itself. Suppose you add `&amp;` in front of `String` to make it compile, the `String` would be "owned" by the function `main`, valid from right before the call to the function `some`until right after the function `some` returns.
I'm surprised if that's really the only lesson anyone can learn. I haven't even been following this issue too carefully, but there are some really obvious things we can say without getting entrenched into divisiveness that you seem eager to perpetuate. Here are some candidates: * The issue is a staggeringly complex social problem that cannot be solved by pithy observations about fairness. So let's not keep repeating them. (It's totally reasonable that not everyone has followed prior discussions. But that's why I linked them, so that folks could skim them before participating in this thread.) * I imagine just about everyone frowns on large scale squatting done in bad faith. * Conversely, there is no consensus that all squatting is bad. * Discussions on this topic turn divisive at the drop of a hat. I tried to word my comment above very carefully so as not to provoke this, but even that failed. Squatting is a hard problem to solve, but divisiveness makes it impossibly hard. People will just stop engaging altogether when that happens. I know I would. * It is extremely easy to mistake "I am exhausted talking about this" with "I'm not listening to your concerns." * When someone has taken the time to [start addressing a related issue with an eRFC](https://github.com/rust-lang/rfcs/pull/2614), it has in turn received thoughtful and careful feedback. Let's please not turn this into a protracted meta-debate.
It seems [elfkit](https://crates.io/crates/elfkit/) might be suitable for the job. Note I have just arrived at this crate by searching `crates.io` for "ELF" and glancing at the crate descriptions and API docs.
Awesome tool, very useful. Hope it will catch python's easy of use.
The current policy [is](https://blog.rust-lang.org/2018/10/19/Update-on-crates.io-incident.html): &gt; Instead, we are going to stick to a first-come, first-served system. [...] We know that this means, in practice, that certain desirable names will be taken early on, and that those early users may not be using them in the most optimal way (whether they are claimed by squatters or just low-quality packages). _Other ecosystems have addressed this problem through the use of more colorful names, and we think that this is actually a feature, not a bug, of this system._ (emphasis mine) It's an admission that the current policy is doing absolutely nothing to prevent squatting. It also suggests using "colorful" (if opaque) crate names as a solution to the squatting problem, as if shifting the blame from the squatter to the author who is expecting to be able to use a reasonable name for their crate. But compare names like `tar`, `cc`, `http`, `deflate`, which happened to be available to well-intended actors with something like `upnp`, which was taken by a squatter. What's even worse is that the current implementation of searching on `crates.io` is pretty bad, meaning it's often impossible to find what you are looking for. So yes, my reaction might be part frustration. But I think saying that the status quo is good and replying in every thread about it that there are no plans to deal with squatting actually encourages that behaviour.
but breaking conventions is how the mathematical operators and symbols invented in the first place.
Like /u/zesterer says, it's an economic problem. Right now we're caught in a prisoner's dilemma or tragedy of the commons type situation. Either you squat crate names you like and might want to use, making everything worse for everyone but minimizing your own vulnerability, or someone else might get them in the future and you have no way to effectively cooperating. The root problem is basically that the crates.io team is overworked and can't serve as police. It sounds like we need police, or at least *some* sort of system of resolving disputes. Right now the process is incredibly awful, because it basically amounts to "I want crate name X, email the person who owns it and ask for it, and if they agree they talk to the crates.io team and get it swapped manually". I've tried to use this system and it is a) a pain in the ass, and b) not very effective. So we need to make that better, *without* asking the crates.io team to solve everything for us by hand. I'd rather they spend their time solving actual technical issues rather than baby-sitting ownership conflicts. Frankly, an open crates "market" of some kind that makes it *easy* to swap crate ownership might be very useful. Even if there's no money involved, a "want to buy" and "want to sell" list and a system that automatically matches them would be nice. People could still squat crates, and if they do so maliciously it won't change anything... but if someone just says "man I should write a crate called [`rivet`](https://crates.io/crates/rivet) sometime" and never gets around to it, instead of squatting it forever they could just put it on the "want to sell" list and if someone else wants it they can get it automatically. The prisoner's dilemma problem still exists, but cooperating suddenly becomes far more *convenient* than it used to be.
&gt; author of Deno, Ryan Dahl Which funnily enough can be deduced from the name Deno, which is an anagram of Node!
&gt; Claiming should be banned. If not within a grace period the compileable is pushed the crate should be automatically deleted. The problem with technical rules to social problems, is that they attempt to solve the symptom, not the problem. And this leads to gaming. If claiming a crate name is as simple as pushing a `hello-world` binary, then it's what claimants will do. If it takes some documentation, some tests, etc... then one can just script a random generator before claiming. Distinguishing legitimate from illegitimate is a hard problem to solve, and leads to an escalating game which ends up hurting legitimate users too.
Whoa, I thought this project was using Go initially. Guess that replaced with Rust. 
/u/Tmath I choose you to win the book! I'm going to send you a PM. :) Please follow-up within 1 week (March 10th before EOD) or I will choose someone else. Cheers.
Thanks for the tip! Someone on SO also mentioned the same thing (was that you?). I've adjusted the larger project to reflect that feedback. As for what that larger project is, I'll be posting a separate thread for it shortly :)
Ooh nice. I used to use mocp back in the day and I loved it. I've tried setting up various terminal music clients to work with spotify and it's always a subpar experience since they're not really designed for loading playlists/etc off the network. Maybe I can set this up to work! It's great to see something like this designed specifically for Spotify! I may contribute at some point if I start using it and want to fix things.
Thank you for your response! I've written up a [long experience report on the GitHub issue](https://github.com/crossbeam-rs/crossbeam/issues/314), with multiple examples taken from my employer's open source releases. (We have more examples, but they're in private code.) Basically, I think the key factors in my experience is that a lot of my channels tend to be used as streams, and that they're ultimately attached to either a network socket or a Unix pipe. And network sockets can fail with `ECONNRESET`, and pipes can fail with `EPIPE`, both of which map directly to an error on a `send`. Usually there's no way to hide this fact, and in some cases the underlying data-producing process is an opaque C function that's passing data buffers to a Rust callback. So the only way to shut it down gracefully is to map `send` errors into `std::io::ErrorKind::BrokenPipe` or `EPIPE`. But it you're using channels in more tightly-controlled circumstances, maybe nothing like this ever happens. But for me, the rule of thumb is "plenty of `send`s can fail, and the caller needs to carefully think through what should happen, and `panic!` is almost never what we want."
That's come from someone else but I'm glad to see the advice is consistent! You have my attention lol look forward to the post.
I wish the Rust team will one day consider doing a trusted repository, and a playground. What the point of having such a safe language, when in the meantime you can mistakenly download crappy (or worse : dangerous) libs because of there isn't any kind of control on what people can upload, be it on the content of the lib as much as on its name. That's a shame, really. 
&gt; Distinguishing legitimate from illegitimate is a hard problem to solve Hard as in "Riemann hypothesis" hard – and quite possibly even much harden than that. So basically one should not count on that there ever is a solution ever.
This might be just what I've been looking for for a while. I tried mopidy + ncmpcpp, but I missed being able to use Spotify-specific features like managing playlists. If that's supported eventually I might finally be able to remove another electron app from my system. I also didn't know about librespot, that's pretty neat. I would love a NC spotify client that has vim-style commands (like `:search xyz` or `:new_playlist foobar`) that could then be assigned to keys. Is that is something you'd be interested in I might start contributing.
Agreed. Tried std channels and was really confused about lack of select. IIRC I rewrote that code using some library based on futures.
We should expect that behavior to emerge from crates.io and policing it by criticizing people is both non-productive and destructive to community spirit. Crates.io itself needs to change. Key observation: crates.io is a specialized search engine bundled with cargo. When you declare a dependency, that declaration tells cargo to perform a search and automatically accept the first answer. That immediately leads to two fundamental flaws: - there is no resistance to search-engine manipulation designed into crates.io, likely because the designers didn't think of it as a search engine - this flaw is analogous to typing what you want into a URL box and adding .com to the end vs using a real and reputable search engine - insane and nobody does it. - cargo does not support alternative and competing search engines as well as crates.io is. AFAIK there is no way to do a semver search on a git URL without hacking it in using branches or tags. No integration with Cargo.lock or `cargo ship` - this flaw is analogous to shipping an operating system that makes it very convenient to search but only if you use Bing
I like it, but obviously it would be good to be able to surf my saved library and playlists. Is it possible to make that a higher priority? Also you might want to publish to `crates.io` in case there's someone malicious who decides to squat your name.
Yeah I'm also interested in vim binding style. For curses style terminal applications, it has always been the easiest to extend and implement in my experience. I would also be interested in contributing for this interface.
I understand what you're saying. I think it's important to make a distinction between what's allowed and what's encouraged. So I'm going to disagree with you on 2 points: * I don't think anyone is saying the status quo is good * I don't think that the current policy is encouraging squatting (neither implicitly, nor explicitly) &amp;#x200B; In fact, I would encourage the community to collectively make it clear that squatting is very much frowned upon and discouraged. I didn't see your original comment as helping with this, which is why I brought it up.
&gt; it doesn't matter what we say on the issue because it's already been decided I think some people who put things this way, don't realize how much that would be considered a failure by the people who make decisions. It ends up coming across as either "you failed" (which could certainly happen, but hurts to hear) or "I completely misunderstand your values" (which means the following discussion is going to be really annoying unless everyone has really good listening skills).
&gt; I actually don't even know why the std library had to have channels in the first place beyond being able to say "Rust like Go has channels to". Rust was always designed to be an actor language. Channels were part of the Rust design from the very beginning. In fact, they were built in to the language for quite a while.
It was worth it for me
Nice! I like that it handles very small terminals well, I just tested it in a 40x11 tmux pane and it worked beautifully. As you build out the UI, it would be great to to see it still be an option to keep this in a small window. I'd love to contribute at some point if the need arises!
I think that if crates were namespaced by users or orgs, then this wouldn't be a problem. 
This seems like exactly what I want (assuming the performance penalty is minimal). I wanted to love colorls but my mantra of "basically everything is a file" would cause it to think for long long chunks of time in some folders.
That would be induction rather than deduction, technically.
Because `o += 1;` is sugar for `o.add_assign(1)`. &gt; Was there really a necessity to convey addressing outside of unsafe? No. Which is why I say to think of it as taking a reference or borrow, and not think about addressing as it's more an implementation detail.
The cargo docs on how to specify a git repo with a branch or even a specific commit is too hard to find. All the possible sources, not just the one pulling from crates.io, should be mentioned in the Cargo.toml documentation.
&gt; two channels I'd just namespace these just like github does, and those which are actually used get moved to the toplevel namespace (/u/someone/dog -&gt; /dog). Searches should also prioritize toplevel crates. But yes, this crates.io mess needs fixing, soon.
I think it's worth being clear why the phrase "basically encouraged" is hard for me to get behind. The situation is that of course no one likes squatting, but either 1) some people dislike it more than others or 2) some people disagree about the downsides of the various anti-squatting options we have. Those are perfectly reasonable and good-faith disagreements. But if one side describes the other as "encouraging" squatting, that's just a hair away from saying they're "pro-squatting". Which is of course no one is. And then when people feel like their values just got totally misrepresented on the internet, discussion tends to shut down. (Or worse, it's their job to have the discussion anyway, and they end up getting super burned out.) So yeah, being frustrated makes a ton of sense. It's an inherently frustrating problem, and when a crate name that you deserve is being squatted by some jerk, it feels really personal. But if we're not careful with how we describe other people's positions/values on the problem, that frustration ends up getting in the way of progress rather than motivating it.
Sure, `binutils` has everything you need - which is just `objcopy`. # Insert Cargo.lock into a new '.dep-list' section objcopy --add-section .dep-list=Cargo.lock --set-section-flags .dep-list=noload,readonly mybinary mybinary.withdeps # Extract Cargo.lock objcopy -O binary --set-section-flags .dep-list=alloc --only-section=.dep-list mybinary.withdeps Cargo.lock.extracted The only funny thing we have to do is the `--set-section-flags` in the extract - that tells `objcopy` that we want to load a section that's not generally loaded.
104! Most with "WIP. Contact me if you want to use this name!" - whatever is "in progress", it is not Work.
actix-web is probably more mature, and probably also has a larger developer ecosystem. Having said that, I'd give both a shot and pick whichever one you like better. I gravitated towards actix-web because of my Erlang background; actors felt more natural.
JavaScript is "safe" as in it makes you believe that you don't have to worry about memory management because the garbage collector will take care of the problem. Then somebody notices a memory leak in your app and you spend a week trying to track it down. JavaScript gives you a false sense of safety coupled with poor performance. Rust is honest, it doesn't try pretending that making software is easy but rather gives you the tools to make it easier.
For what it's worth, I think the perl6 cp6an AUTHORITY metadata could help with this problem. As I understand it (I don't use perl6) Anyone can name a module anything, even if it's already used. When importing a module, it will use the default one (not sure how that's worked out) unless I specify which AUTHORITY to use. Basically, the authority becomes part of the package name like the version. Here's a link the spec https://design.perl6.org/S11.html#Versioning
Actually, I like the Filter approach more than the alternatives too. Which is what attracted me towards it. I am thinking of just starting with warp, we will see how it pans out.
Actually, the actor framework is one thing that is keeping me from picking actix-web confidently. I feel like I should spend some with understanding the concept of actors before using it in production. 
That's nice.
I see where you're coming from, but to me the official stance boils down to: - we believe that making crate authors pick more creative names is a good thing - we will not take any action against squatters That doesn't encourage name squatting in the sense of "you should go and squat", but rather "if you're planning to squat, we won't do anything about it". I consider the latter to be a form of encouragement, too.
ah didn't know that :) thanks.
&gt; Distinguishing legitimate from illegitimate is a hard problem to solve, and leads to an escalating game true not even an admission fee of 9.99 stopped crap being loaded on the play store. What if users can report a crate to be reviewed, if n reports for a particular crate and issue are received the crate will be put under review and manually yanked by ops if reports are valid?
I was more than ready to have stood corrected on this but from the looks of things it seems like deduction in colloquial use absolutely covers my use of the word. I'm not talking about formal logic, here.
If you don't do any database calls then there's no need to implement your own actor. If you do, there are lots of examples to learn from. Honestly, if you think as actors as small servers that implement a request/response interaction you'll be good to go. There's nothing fancy about them.
The other solution to the tragedy of the commons is to make sure that there aren't any commons in the first place. Something like crate name-spacing would make it so users don't have to compete and removes the need to get your crate blessed by the crates.io gods before you can publish.
Fair, I may have a misunderstanding about the colloquial use of induction and deduction myself 😋. Thanks.
That's fair. Perhaps my use of "encourages" was misleading, but see my answer to your sibling. PS: I didn't downvote you.
This is a very nice announcement message. I really like that you give reasoning, explain when it's useful and also link directly to code samples. This is a great example to follow when making a crate announcement. 
I understand. Thanks for the discussion
Imports are only made available in the module they are imported in. You import Fail in your lib module and then try to use it in your error module. Try moving the use statement into the error module.
To be clear `evmap` is specifically tailored to read-heavy workloads; as mtak- observed, it does _not_ do scalable writes well. It is a single-writer-multi-reader map at its core, and trying to use it outside of that use-case is probably not a good idea. I am glad to hear it makes the lookup graph look ridiculous though, since that means it's doing its job correctly there!
You could probably just store the tuple you get from `split_at()` as is. I don't see any real need for a wrapper type here. Also, if you need a queue you should probably be using a [VecDeque](https://doc.rust-lang.org/std/collections/struct.VecDeque.html) instead of Vec.
Having a good CLI Spotify client would be amazing, thanks!
I wasn't expecting this! Congrats, looks like you've been hard at work for a while.
OK so it's for the case where you deploy binaries to production and you forget about them and then can't trace the dependencies back. That's totally reasonable - thank you for explaining it to me.