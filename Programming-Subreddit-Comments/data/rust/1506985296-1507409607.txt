I don't think release mode checks indices, but I might be wrong. Test it.
Where is the tutorial? No tutorial, no usability. Do the other cross platform GUI libraries for Rust have bad performance, non-composable widget system, or huge APIs?
Are you talking about JS implementation or is that what you're doing with Rust for a React applicaton?
What do you mean by tutorial exactly? There are examples in the repository, which i usually find to be enough. That having been said, screenshots would obviously be nice.
What task are you trying to accomplish? Aside from making ASCII post slugs (for use in URLs) more meaningful in the presence of non-ASCII titles, there aren't many places where stripping diacritics is the right solution. ([Dark corners of Unicode](https://eev.ee/blog/2015/09/12/dark-corners-of-unicode/) gives some concrete examples of the subtle brokenness that naively stripping diacritics can introduce and is something I'd recommend that everyone read.) Anyway, there are proper Unicode algorithms for these sorts of things. For example, if you're trying to deal with spam that's working to bypass word filters with strings like "mùí∂k‚Ç¨ m√∏n‚Ç¨·ªø", you want an implementation of the TR39 skeleton algorithm for unicode confusables.
Awesome, thanks for the fast response on that! I'll give that a try hopefully tonight.
It didn't even post an [animal gif](https://i.imgur.com/m6EeQPR.gif), for shame.
Oh nice, thanks for the added info!
A BTree that will have at most two elements... (Of course, your underlying point of being able to use them in generic algorithms, like easily sorting a `Vec&lt;(String, i32, bool)&gt;`, is correct.)
I'm working on my first Rust project (still trying to get used to Rust's error handling :P), called [Koi](https://github.com/feddasch/koi), which is a dotfiles manager that will make use of libgit2 (via the git2 crate) and support things like encryption (as yadm), conditions and templates (guess I will use Rustache with this) EDIT: Code review and recommendations are welcome :)
Is this a raster GUI for games (like conrod), a wrapper around native toolkits (like libui), or a custom toolkit that impersonates the native toolkit on each platform (like Qt)?
I think this probably wouldn't work too well with a "smart builder" pattern where the builder type changes at every step.
Depends on WebRender, it's a completely new toolkit.
You should probably add a hello world example in the readme. 
Huh, that's rust lingo? I just assumed we inherited that from somewhere else.
Hi, author here, sorry there's not more documentation at the moment. I've been putting off writing up a blog post introducing the project, it's only just starting to reach a point where's it's ready for people to look at. That said, I'd be happy to answer any questions and get feedback on the overall design. A lot of the code is still little more than prototype quality, so I wouldn't recommend building anything with it yet, unless you're happy with API breakage, major bugs, and having to implement basic functionality yourself. If that's alright the examples would be a good place to start. My current todo list includes: * Fixing bugs * Expanding the included widget library * Adding high level constructs to bind data to widgets * Benchmarking/improving performance (integrate better with webrender) * Make the drawing/styling system more composable
There's a guide to good readme's that talks of good examples: https://www.makeareadme.com/#usage But also screenshots: https://www.makeareadme.com/#visuals
Examples should be inlined in the readme.
I'd like to take that as a chance to talk a little about how the program got together. RustFest usually reserves one keynote slot for the Rust project to fill. This is less set in stone as it is just common practice over the last three events. With the amount of Mozillians that work on Rust, chances are high that this person will be a Mozillian. The other keynote slot is filled at our discretion and we are willing to fill it by just inviting a person we feel for being a good fit. This person _still_ has to submit a proposal. Still, we usually look at CFP submissions first and see if there's something we feel like being keynote material. For Z√ºrich, that turned out a bit interesting, as we actually had one submitting a very good Tokio talk. That speaker was accepted on the keynote slot, but later dropped out. Which is how it came to be that we were suddenly looking for a replacement Tokio talk, which Alex Crichton filled. So, suddenly, we had two Mozilla people speaking ;). Finally, all other slots are filled with CFP submissions. I fundamentally believe that most slots in a conference that _has_ a CFP should be filled through it. So, most of the slots at RustFest can only be gotten through applying with a proposal and being voted in. I know there are conferences which even invite many of the other (or all) speakers, but I think that's unfair to those that submit.
Its a library for a visual interface so it would be very useful to have some nice screenshots available to assess the general state of the library.
"Don't roll your own security" is more than just "don't write your own crypto primitives", although that is a very important part. In any case, an even more important rule than that is "be humble when writing security-critical code": there are numerous examples of unconventional/outside-the-box side-channel/algorithmic attacks (not just in the crypto primitives), and calling anything that might be of interest to a motivated attacker "not that hard" is a red flag. (Note that this is independent of whether joining the parts together yourself is the right choice, which it could well be: recognizing the downsides/dangers of that choice is important.)
&gt; Where is the tutorial? No tutorial, no usability. What part of "early stage" don't you understand... It's not created yet. &gt; other cross platform GUI libraries for Rust More or less don't exist. At least not any good ones ready for real use. There is no established competitor in this space.
It's a custom toolkit built on webrender, sort of comparable to Qt or Conrod. It's not built on any native UI toolkits, nor is it trying to emulate exactly the look and feel of a given platform, but there is no reason it couldn't eventually be themed to do that. Personally I think good visual design is a good substitute for looking exactly like a native app. On the desktop, the only native UI components I think are really important to include are file select dialogs and the menu bar, similar to Electron. It can be compared to Conrod in it's intended use, the main difference being that its API is "retained mode" and event driven, rather than declarative and "immediate mode". In short, this means it should have much better performance, at the cost of making it more difficult to keep data in sync with views. Right now it's necessary to have components be in charge of syncing state with the view. There's room for experimentation in this area, and there may eventually be a declarative interface built on top of the retained mode core, similar to how Flutter works. It's a hard problem but I think it's easier to do and will ultimately result in a better design if it's done 'bottom up', rather than how Conrod is trying to do it, which is more 'top down', ie. starting with an immediate mode interface, and making it retained mode underneath.
I don't know, but the answer might be "test it." Rust doesn't have a spec like C/C++.
Nitpicking: &gt; You may know that c# normally treats the int as a 32 bit signed integer, however, when dealing with foreign functions, it is MUCH safer to be explicit in exactly what data type you're expecting on both ends, so we declared, explicitly, that we're expecting a 32 bit signed integer returned, and that the inputs should be 32 bit signed integers. There is no need to do this. `int` in C# is a language alias for the BCL type `System.Int32`, it is not going to change in width under your nose like it could in C/C++. I'm guessing you did this in 64-bit, but you may want to specify the calling convention on the C# side `DllImport(..., CallingConvention = CallingConvention.Cdecl)`, because the default otherwise in 32-bit is stdcall (since P/Invoke was meant for WinAPI), and that will blow up in your face once your code uses the stack.
Unfortunately, just because it works in one instance doesn't mean it will work in all instances -- such is the nature of undefined behaviour.
The documentation for using TLS/SSL is pretty straightforward, so I don't think there's much that can go wrong. On the client, with `native_tls`: let connector = TlsConnector::builder().unwrap().build().unwrap(); let stream = TcpStream::connect("google.com:443").unwrap(); let mut stream = connector.connect("google.com", stream).unwrap(); And for the server using `tokio-proto`, with `tokio-tls` + `native-tls`: let der = include_bytes!("identity.p12"); let cert = Pkcs12::from_der(der, "mypass").unwrap(); let tls_cx = TlsAcceptor::builder(cert).unwrap() .build().unwrap(); // Wrap up hyper's `Http` protocol in our own `Server` protocol. This // will run hyper's protocol and then wrap the result in a TLS stream, // performing a TLS handshake with connected clients. let proto = proto::Server::new(Http::new(), tls_cx); // Finally use `tokio-proto`'s `TcpServer` helper struct to quickly // take our protocol above to running our hello-world Service on a // local TCP port. let addr = "127.0.0.1:12345".parse().unwrap(); let srv = TcpServer::new(proto, addr); println!("Listening on {}", addr); srv.serve(|| Ok(Hello)); So yeah, it's not that hard, as you can see. I would just wrap my `ConcurrProto` type within `tokio-tls`'s `proto::Server` type, then use the wrapped type as the protocol for the `TcpServer`.
I've done it in 32 and 64 bit, the production code I pulled this example from works fine so long as it's a 32-bit C# app + 32-bit rust, or 64-&gt;64. I'll keep that in mind though, if I start coming across any errors. As far as 'int' goes, you're totally right, I was using it more as a point that it's safer to always specify the type Thanks for reading!
Rust doesn't have strict aliasing rules for raw pointers. Here's a code snippet that demonstrates this: https://play.rust-lang.org/?gist=ea1f4c7f551660f7075bb352760889f1&amp;version=stable We are able to coerce the pointer in safe code, and safe code can never cause undefined behaviour ‚Äì only dereferencing it requires unsafe, as it usually does. (However, there's still leeway for argument ‚Äì one could say that dereferencing a pointer coerced to a different type might be UB ‚Äì but I don't know if anybody that has the power to define "UB" in Rust supports that viewpoint.) Here's the thing though: Rust *references* have way more stringent aliasing rules than C and C++ pointers ‚Äì having two references that mutably alias is undefined behaviour. (Edit: Just noticed that the compiler doesn't protect you at all from coercing to pointers with targets that are of different size and alignment, so caution is warranted!! Dereferencing that kind of a pointer is most certainly UB. I wish it at least warned about that :( )
For the people loving to see a [screenshot](https://i.imgur.com/g73zyQc.png)
I don't think that snippet supports the argument. The general model behind pointers in Rust is that they're basically just numbers, and the unsafety is usually concentrated around dereferencing them. Rust doesn't run type based alias analysis currently so IIRC this basically isn't a problem. currently.
The power of Cargo crates.
You can't prove the negative, but you might prove the positive.
OT Do you mean rust doesn't have something like this: https://golang.org/ref/spec ? Or do you mean otherwise?
Do you happen to know is there any consensus / general stance about type based aliasing between the compiler developers? Just my two cents, but I'd be happy if that would be specified to be only implementation defined behaviour for primitive types (to allow different memory representations on different platforms), not UB.
When I say spec, I'm thinking more like [this](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4296.pdf). I don't know how formal or comprehensive the Go one is, but, yeah, I don't think Rust has even that. 
I know you can safely convert the pointer; the question is whether you can safely dereference it. &gt; (However, there's still leeway for argument ‚Äì one could say that dereferencing a pointer coerced to a different type might be UB ‚Äì but I don't know if anybody that has the power to define "UB" in Rust supports that viewpoint.) That's the question I'm asking. In C/C++ the answer would be that it's UB, but what's the answer in Rust?
From the Rust compiler's POV, raw pointers are just numbers. Its strict aliasing rules only apply when you dereference the pointer into a Rust reference. You just have to ensure `1 &amp;mut` XOR `any &amp;` at any given point in the program control flow.
Rust compiler devs? "we don't need it" IIRC. C/++ compiler devs? I think folks are in favor of it. There is very little information about aliasing that the compiler knows beforehand, it's nice to at least not have to deal with it across types. This isn't something that is in the hand of compiler devs fwiw, it's in the hands of spec writers.
Rust has approximately all the stuff the Go "spec" has in the reference or scattered across the book; but Rust is a far more complex language and needs a lot more stuff. The Go spec isn't as formal; for example it doesn't lay out inference rules entirely.
thanks! didn't add one to the README because I don't want to give the impression it should actually be used yet. Btw most of what you are seeing here (perf. data) is straight from webrender.
Some additional research turned up this [Rust reference page](https://doc.rust-lang.org/reference/behavior-considered-undefined.html), which states that the following behaviour is undefined: &gt; * Breaking the [pointer aliasing rules](http://llvm.org/docs/LangRef.html#pointer-aliasing-rules) on accesses through raw pointers (a subset of the rules used by C) &gt; * &amp;mut T and &amp;T follow LLVM‚Äôs scoped [noalias](http://llvm.org/docs/LangRef.html#noalias) model, except if the &amp;T contains an UnsafeCell&lt;U&gt;. Unsafe code must not violate these aliasing guarantees. I've tried reading the linked LLVM documentation, but I don't really understand it. Can anyone else make sense of it?
Thanks for clarifying. I know it's apples and oranges but it would be great to see rust define this someday.
4 months since this thread has cooled off, and most of the crates I use are still requiring the use of the nightly, which says it's not something you want to chuck onto production if it's stability is even slight important - that's before you get to security etc. The more I've read this thread and thought about it, the more my answer has become a no. I hope it becomes a yes soon though, as I'd love to finish building some things and get them live.
"testing it" is essentially useless with UB, it can and will completely change based on computer settings, versions, race conditions, system time, size of files, alphabetic ordering of filenames, machine architecture and you name it. It is UB when they tell you it's UB‚Äîthere is no reference implementation here. Though with Rust ignoring bugs in reverse if it goes wrong I guess then it is UB.
The word "formal" is really misused in these things. English isn't formal; it's formal when you write the spec down in Coq.
Oh! That's new information for me! Thank you! I always wondered how `wait` is supposed to work. I think a global function such as `task::current` makes the API and its intended use harder to understand. I skimmed the documentation multiple times but I wasn't able to connect all the dots. Still struggling with all the concepts involved, though.
All the unsafe keyword does is enables you to call functions/actions marked as unsafe. Rules for unsafe scopes are the same as safe scopes.
&gt; A future in Rust is just a state machine, and you can use them without callbacks/closures, and just poll them instead. Uhm ... I may be missing something (I probably am, I'm still struggling to understand Rust's futures), but isn't a leaf in a tree of futures supposed to use some kind of callback mechanism to notify the task if that leaf future is not yet ready?
And dereference raw pointers
Or I'm speaking regular English, where "more formal" is totally acceptable as a relative term independent of the level of formal verification. Words have meanings. Sometimes multiple.
&gt;Though with Rust ignoring bugs in reverse if it goes wrong I guess then it is UB. That's my point (kinda? Not sure what you're saying, tbh.). You can't prove it's not UB with testing. But, if you can find two contradictory examples, you can prove it is. Or you could just read the code, since the implementation is the spec. 
The leaf future should take a reference to the current `Task`, and it can decide some way to call `task.notify()` at a later point. An executor can use that signal to `poll` that future again. A naive executor could just call poll in a loop. Now, that'd just spin the CPU, so it's not efficient, but it could work (note, it wouldn't work if that future actually required another to be polled concurrently, such as on the same thread, if you only polled the first one in a loop, but that's not the point I was making).
&gt; That's my point (kinda? Not sure what you're saying, tbh.). You can't prove it's not UB with testing. But, if you can find two contradictory examples, you can prove it is. Unspecified behaviour is not the same as undefined behaviour. Evaluation order in sub expressions is often _unspecified_ but it's definitely not undefined. UB means that absolutely anything can happen: &gt; Or you could just read the code, since the implementation is the spec. Absolutely not, the implementation currently for instance is coded such that the first word in a Vector's three words is always the pointer to the heap but the documentation is very clear that the order of these words is not defined and can change at any moment, relying on that the first word is the pointer is absolutely a window to UB. https://doc.rust-lang.org/std/vec/struct.Vec.html#guarantees There are a lot of things that are currently in the code that the documentation is clear about are not guaranteed and can change in between versions or even on different architectures and optimization levels.
Yeah I don't know; "formal" is not any more degreeable than "true" is in mathematics. It is formal or it isn't. 99% true is false. I think the word you are looking for is _rigorous_ which is degreeable. When people say something is formally specified (and verified) there are no degrees to it; it either is or it isn't. This just seems like massive abuse of terminology.
&gt; When people say something is formally specified (and verified) there are no degrees to it; it either is or it isn't. I'm not talking about formal verification, though. Formal in the sense I'm using it is certainly degreeable.
Well you have the code but how do you want to target beginners with this? just say look at the code? if you want this to be more useful as learning resource, add code explanation. doesnt have to be video. also you need to decide beginner definition cause beginner is also a person who cant code at all
Yes, and that is a misuse of terminology. It's like defending calling `Vec` a "higher kinded type constructor" with 'that's just how I use it', formal is a technical term and you're using it wrongly.
The term "Undefined Behavior" is a term defined by specification. It means "If your program would perform this behavior, then the specification doesn't place any obligation on the compiler and it can do whatever the compiler developer decides without it being a violation of the specification." Most things classified in C as Undefined Behavior are things that, at least on some platforms, are erroneous in ways that would be expensive to check for at compile time or runtime. Or they are things that behave differently on different platforms in ways that would place a performance burden on the other ways of doing things if you picked one as the "defined" way. So the programmer is told that portable programs just aren't allowed to do those things, and it's up to them to not write programs that do them. And the compiler is allowed to pretend that those things never happen and not bother checking for them, although nice compilers will generally check some of them if they can do so tractably, and some compilers just pick an implementation-specific behavior that makes sense for the platform. They're under no obligations by the standard, but they may be under obligations from their customers! As a consequence of that, you can't tell what "Undefined Behavior" is just by examining an implementation's output. If you see weird output (i.e. your "contradictory examples"), it could be a bug in the implementation, or a problem with the specification, or it could be something mentioned in the specification as specifically being Undefined Behavior. But if it's not explicitly listed in a specification as Undefined Behavior, that's not what it is. :) 
"formal" is a regular English word as much as it is a technical term. You don't get to dictate which sense I use it in. [Take a look](https://en.wiktionary.org/wiki/formal#Adjective). Most of those meaning work perfectly well in this context, and most are "degreeable". Sure, it is a bit ambiguous, but in context I wasn't talking about formal verification, and the actual specs were linked right there and you can see that no formal verification is involved. It's abundantly clear what I meant. You're just being overly pedantic here for the sake of it, please stop.
I‚Äôve also wondered about this before, and having just read that linked LLVM documentation, I guess probably this would be the third time, I THINK I understand most of it haha. It is my understanding that LLVM imposes size and alignment restrictions, but no actual type aliasing restrictions ala ‚Äîstrict-aliasing. Also, like /u/manishearth said, the rust compiler doesn‚Äôt do type based alias analysis, and since LLVM isn‚Äôt doing it either, I don‚Äôt think it‚Äôs happening currently and thus would be unspecified behavior rather than UB. I also know that there is not currently a formal spec about what is and isn‚Äôt UB, so the lines between what is currently unspecified or platform specified or undefined behavior etc is not really clear right now, I have run into this sort of discussion before calling C code which longjmps. I IMAGINE that in the case of type alias analysis, there‚Äôs not a huge push to even include that in rustc? You mostly deal with refs, and refs are already aliasing xor mutable, so you don‚Äôt really need it right? It seems like it would be a weird thing, once such a spec materializes, to explicitly be UB in the same way as ‚Äîstrict-aliasing, plus there would need to be magic rules about pointers to c_void and u8 to match the magic c/c++ rules about char as well. I THINK all that‚Äôs right, but please chime in if you know better than me, I‚Äôm feeling a bit out of my depth and like I probably got some of that subtly (or not so subtly!) wrong. Also apologies for repeating things already explained elsewhere in the thread.
We're operating under the assumption there is no spec. I'm offering an alternative, informal definition of undefined behavior under that assumption. Under the usual definition, there can be literally no undefined behavior in Rust, hence the usual definition is of no use, hence an informal one could be more useful than the usual. But thanks for the informative response. You are correct.
So what crates are you using? To me, four months don't seem particularly long, but I don't know the exact circumstances. Working in Java has taught me a lot of patience in that regard.
A useful metric is that we consider type punning in unions to be UB (like C), which kinda makes this something likely to be UB when we decide what UB is.
Why do you need to know? The example you gave could transmute the value instead, but I assume you have some other need for it.
Actually, union type punning in C was never undefined behaviour. It was implementation-defined in C89 (3.3.2.3) and is explicitly allowed in C99 TC3 (6.5.2.3) and C11 (6.5.2.3).
Ohhh, I didn‚Äôt think about that, thank you for mentioning it, that‚Äôs really interesting. I‚Äôd actually probably should go read the rfc discussions for untagged unions, I‚Äôm sure it‚Äôs discussed in there and would probably be pretty educational.
Huh maybe I'm thinking about C++ then, sorry.
At one point I think I had this in my head, but it‚Äôs been a while.. I believe you‚Äôre correct about it in c++, and there‚Äôs some really lawyerly language in the spec about only accessing types you previously wrote, and explicitly forbids punning. Edit: yeah, this stackoverflow answer explains it pretty well for anybody who is just super interested in c++ language lawyering: https://stackoverflow.com/a/11996970 it is of course more subtle and weird than I remember.
That worked perfectly, thanks! I've now got a todo app built but I'm not a huge fan of the code or it's looks so I'm going to hold off for the moment before releasing it. I did submit a diff for your review adding remove_rows. Thanks for showing me how that is done.
Maybe should use `cdylib` instead of `dylib`
It's easy to just inline a snippet, but I do wish people would make it easier to look at examples....
go.twitch.tv/kare3 awesome streamer
And access or modify a mutable static variable. And implement an unsafe trait. :) https://doc.rust-lang.org/book/second-edition/ch19-01-unsafe-rust.html#unsafe-superpowers
I mostly finished writing the doc site for [Gutenberg](https://github.com/Keats/gutenberg), now is the time to work on its design so I am mostly waiting for inspiration. I'll probably release a new version fixing inconsistencies/bugs that appeared tomorrow or the day after.
Scala.JS, sorry should have been more clear about that.
Why not? It would simply have to change from: let foo: Foo = { let builder_handler = BuilderHandler::new(); let mut builder = builder_handler.builder(); builder.x(1); // updating the mutable builder builder_handler.build(&amp;builder) }; to let foo: Foo = { let builder_handler = BuilderHandler::new(); let builder = builder_handler.builder(); let builder = builder.x(1); // move the builder into the method and rebind the result under the same name builder_handler.build(&amp;builder) }; 
Honestly, this is exactly the GUI library I was waiting for someone to write.
The LLVM documentation seems quite clear about this: &gt; LLVM IR does not associate types with memory. The result type of a load merely indicates the size and alignment of the memory from which to load, as well as the interpretation of the value. The first operand type of a store similarly only indicates the size and alignment of the store. &gt; &gt; Consequently, type-based alias analysis, aka TBAA, aka -fstrict-aliasing, is not applicable to general unadorned LLVM IR. Metadata may be used to encode additional information which specialized optimization passes may use to implement type-based alias analysis. I'm pretty sure that says that you can freely cast pointers, as long as you don't screw up alignment.
The fact that we have to wrap the parameters in a struct is an implementation detail - we only need it because Rust does not support named arguments. Ideally they would be named arguments of `accepts_foo`, and will be documented in `accepts_foo`'s documentation page. I can't do it, so I have to settle for having to wrap my arguments with _something_ and for having to click on _something_ in `accepts_foo`'s documentation page to see them. I consider that _something_ a boilerplate. I agree about the `unwrap()`. It may make sense with the regular builder pattern, but anything that needs it as `Result` is probably too meta to be using the macro... But building a macro specifically for creating `Foo`? How would that solve my problem? Instead of naming `Foo` I'll have to name that macro, and I'll have to create a macro for every other arguments wrapping type. I'd much rather have one macro and use the type system to define types...
We do? The unions RFC says: &gt; [In addition, since a union declared without `#[repr(C)]` uses an unspecified binary layout, code reading fields of such a union or pattern-matching such a union must not read from a field other than the one written to. This includes pattern-matching a specific value in a union field.](https://github.com/rust-lang/rfcs/blob/master/text/1444-union.md) That implies that for unions that *are* declared with `#[repr(C)]`, you are allowed to read from a field other than the one written to. edit: It also says: &gt; In particular, Rust code must not use unions to break the pointer aliasing rules with raw pointers, *or access a field containing a primitive type with an invalid value*. (emphasis mine.) Since the only way to "use unions to" put an invalid value in a field would be via punning, banning only invalid values suggests that punning is allowed if you access valid values.
Thank you!
This is glorious, I was about to start a project that has most of the work done in the backend in Rust and using C# for a desktop app. Thanks!
Having `insertRows` that actually passes the new rows would be nicer and simpler. The current code requires that the rust list items implement `Default`. However, the list items do not have corresponding classes on the C++ side. We could introduce classes for the list items to make this nicer. That's quite different from the basic QAbstractItemModel API. If you have more questions or would like me to have a look at your todo app, let me know.
I found some more information [here](https://github.com/christolliday/limn/issues/1).
You can't run those examples trivially like you can with examples in the example directory.
In addition, at least [one of the core compiler devs seems to have a very clear opinion on the matter](https://internals.rust-lang.org/t/should-it-be-possible-to-translate-transpile-a-rust-program-to-c11/3183/4).
Agreed. Beautiful &amp; ergonomic beats native. 
Holy shit ‚Äî just looked at the code, it uses both WebRender *and* Cassowary! That's *two* parts of my idea that I posted on this subreddit a while ago somewhere :D Amazing!! All that's left is a "QML-ish" thing based on [Dyon](https://github.com/PistonDevelopers/dyon) that works as a standalone sandboxed "player"/"browser" ‚Äî only displays GUI and communicates to a script over a pipe for doing actual stuff on the system. UPD: wow, looks like it also recognized my screen's DPI/scale (thanks to WebRender I think). It's *only* set in `Xresources` as `Xft.dpi`. This is very nice. Simple GL based toolkits (imgui, nanogui) usually draw everything very small on my screen.
(Not that we'd want you to)
definitely should put more info about the library in the readme. maybe it will get outdated a little but will be more welcoming.
That's pretty cool! Some feedback: For the `crate-type` you probably want `cdylib` instead (note the 'c'), [rfc](https://github.com/rust-lang/rfcs/blob/master/text/1510-cdylib.md). String handling (basically, working with pointers) across FFI is tricky. Here however the `free_string` could simple accept a `*mut c_char` (and IntPtr on the C# side) to avoid this whole global mutable state thing. Your string handling is also very iffy... You are trying to turn an utf-8 rust string into a null terminated ansi string which sounds all kinds of wrong. A [google](https://www.google.com/search?q=C%23+marshal+utf+8+string) search reveals several relevant stackoverflow results. They mostly seem to say "go through `byte[]` then `Encoding.UTF8.GetString(buffer)`".
Thanks for the feedback. The criticism utf8 to ansi is fair, I'm mostly following the example in the ffi cstring documentation here. I thought about having free string take in the pointer, but decided against it as I do something different in the production code I modeled this after and wanted to talk about using static variables. Thanks for reading and the feedback! Edit: I'll also check out cdylib. Thanks 
&gt; Event Machine's http decision tree It's a very neat interesting concept, but kinda unpractical. I've tried making "frameworks" based on it [in Python](https://github.com/myfreeweb/rapidmachine) and [in Clojure](https://github.com/myfreeweb/octohipster) in the past‚Ä¶ never done anything with these :D Turns out web development is‚Ä¶ more app-centric than HTTP-spec-centric I guess? The "type/annotate a function to turn it into a request handler" approach is *winning*. [JAX-RS](https://en.wikipedia.org/wiki/Java_API_for_RESTful_Web_Services)/[Jersey](https://jersey.github.io), [Servant](https://github.com/haskell-servant/servant), and now Rocket. &gt; Dropwizard has a large emphasis on handling the non-http part of building a web app. Speaking of Dropwizard, I made a [little Dropwizard-ish "framework"](https://github.com/myfreeweb/magicbane) for Haskell's Servant. I can totally see something like this being built for Rocket‚Ä¶
So you are telling me about some awesome blog posts, but not providing a link? What kind of monster are you?
&gt; The "type/annotate a function to turn it into a request handler" approach is winning. I'd agree with this but I'm not sure that the two are exclusive. In my mind the requests go through a defined flow implicitly and the app author can tap into it via traits but that's a fuzzy idea and I haven't thought through a concrete mapping.
Thanks. I hope the audience had at least half as much fun as I had. üòÇ
How does state management work? Would really love something that emphasizes a more reactive, unidirectional-dataflow approach like [relm](https://github.com/antoyo/relm), but without the gtk dependency...
Eh, I feel like that about const generics. To me, they are a lot more important than this. I've almost never had complicated fights with the borrow checker, and usually all that is needed is to introduce a small, clearly-defined block and the problem goes away. I agree that it is a somewhat ugly and sub-optimal workaround, but it really isn't a major problem with Rust. Yes, I am excited about NLL, but I don't think it is quite as impactful as you make it sound. Wouldn't call it *the single biggest* improvement. Const generics to me are much bigger and a much more significant improvement to the language. I would compare NLLs to when the `?` operator was introduced. Did it make Rust much more ergonomic to write for everyone and reduce the overall amount of headaches/papercuts? Yes it did. Did it make Rust syntax cleaner and more readable, with fewer hacky workarounds? Yes it did. Was it a major change that really impacted the language (either enabling more flexibility and new ideas, or fixing large classes of existing problems)? Not really.
&gt; It's a hard problem but I think it's easier to do and will ultimately result in a better design if it's done 'bottom up', rather than how Conrod is trying to do it, which is more 'top down', ie. starting with an immediate mode interface, and making it retained mode underneath. Yeah I totally agree with this, it's crossed my mind a few times as over the years conrod's innards have become what is basically a big graph of retained state. I can imagine it might be possible to create a nice, efficient general "immediate" layer over an existing retained gui lib in this sense, but likely not the other way. Looking forward to where this is going! Will be keeping an eye on this :)
I think one should do both. A hello world example in the readme and then more complete examples in the examples folder.
It's also nice to keep the UI consistent, looking the exact same on every platform.
If you only want to strip accents, you can do it by converting the string to one of the Unicode normal forms (typically NFD) and stripping the modifying characters (of category Mn). Essentially, you want to do [this](https://stackoverflow.com/a/518232) in Rust which is pretty easy with the [unicode-normalization crate](https://crates.io/crates/unicode-normalization). The "unidecode" procedure is something different as it also transliterates alphabets to Latin.
This looks pretty good. Too bad it doesn't offer anything new in terms of dependency management (so that you don't have to introduce traits &amp; build object graphs yourself), but the mocking solution seems decent. I hope it is conducive to both styles of it, too, since the example only shows the expect-verify flow. (I personally prefer to only stub out behavior and stick to explicit assertions about return values rather than verifying mock interactions).
I see plenty of legit use-cases for this, where the pitfalls described in your link aren't fatal. Any search functionality on unicode strings, for example. You probably won't type out the right characters if you don't have the keyboard layout for it, but this allows a search engine to index in an easily searchable way. Or I don't know, tab-completion when trying to fill in file names in a shell?
The snippets in the readme are not there so you can run them - they are there to give you a quick glance on how code that uses the library looks and feels.
I don't disagree that there's a place for snippets in READMEs for this reason, but I wouldn't put all examples in it.
I would love to see an electron-like GUI framework along this line that allows for coding HTML/CSS in the GUI layer but give DOM access to rust without having to resort to using a JS engine. This could expose C bindings allowing other languages access as well. Alas, I still dream
Is it safe (in the long run) to use i32 in the exposed Rust API, versus something like `libc::int32_t`?
I thought some people actually made this a thing a while ago and it was called either graphite oder graphene (and I think it didn't go as far as you hope) or something similar but I cannot find anything so I suppose it was discontinued.
2.66 fps? Does it only count the frames where something changed?
Edit: On Windows, yes it is safe. https://doc.rust-lang.org/libc/i686-pc-windows-msvc/libc/type.int32_t.html https://doc.rust-lang.org/libc/x86_64-pc-windows-msvc/libc/type.int32_t.html ======= My guess is yes, but it's exactly that, a guess. I'll have to take a look though. Thanks 
It's deleted; what did it do?
You're still thinking in too anglocentric a way. The article gives direct examples of where stripping diacritics would either miss a desired equivalence (eg. √¶ as "ae" and √ü as "ss") or set up an undesired false equivalence (eg. turning "bu" and "pu" into "fu" in Japanese). My point that there are more proper algorithms still stands. In this case, you'd do it as part of the same pass where your full-text search system does its [stemming](https://en.wikipedia.org/wiki/Stemming) and [lemmatisation](https://en.wikipedia.org/wiki/Lemmatisation). (Stemming is the process of finding root words like "find" from inflected forms like "finding" or "finds" and lemmatisation is the generation of an index which groups them together so you you can type any one of them and find a match across all of them. Lemmatisation is the generation of the actual index, which would also apply to equivalences generated through different means, like "tsch√ºss" and "tsch√º√ü") Dictionary-aware stemming and lemmatization can also produce mappings like "better ‚Üî good". (Search systems then use sorting based on accuracy scoring to recovery the kind of precision that this process sacrifices.)
**Stemming** In linguistic morphology and information retrieval, stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root form‚Äîgenerally a written word form. The stem need not be identical to the morphological root of the word; it is usually sufficient that related words map to the same stem, even if this stem is not in itself a valid root. Algorithms for stemming have been studied in computer science since the 1960s. Many search engines treat words with the same stem as synonyms as a kind of query expansion, a process called conflation. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
Perhaps you mean /r/playrust
Perhaps you should advertise your server on /r/playrust ‚Äì unless your maps are hash maps and you want to use the Rust programming language on the internet.
This is only technically correct, because derefs of raw pointers behave differently from derefs of references.
For instance `if (a, b, c) &gt;= (x, y, z)` where they are all boolean expressions is actually something that can replace a complex web of if statements or weird logic. I've not done this yet in Rust but I have some python code that did that. Remember that non-strict ordering on booleans is actually material implication in boolean logic. `x &lt;= y` is the same as the logical syllogism `x -&gt; y` `x &gt;= y` on Bools is a shorthand for the common `(x || !y)`
Servo guys are saying they plan on doing something like this.
On my phone so I haven't run the code or anything, but it looks like `req.get_url()` returns a `&amp;'static str`, which might be causing the `+ 'static` bound on the Future?
I suppose everyone has use cases that are more important to them. I don't think debating whose favorite new feature will be the most impactful is a very productive thing to do, so I won't comment on const generics (and I guess I can't anyway, because I just learned that that's even a thing). But I will say that you shouldn't underestimate the impact of things like this. When people are trying to learn a new language, when they run across issues like the compiler telling them they can't access the same variable they're using from inside a method call‚Äîwhich is a perfectly reasonable thing to do, and is allowed in most other languages‚Äîthey will just get frustrated and quit. As more experienced developers, we learn the workarounds for things like this and we move on, so they don't seem like a big deal to us. But if we really want the language to become more popular, I believe removing these kinds of barriers will really help.
The first point means that you can't pointer-arithmetic your way out of or into an allocation that LLVM knows about. No sane program would do that anyway. The second means "thou shalt not break the assumptions upon which Safe is optimized." When a function gets a `&amp;mut` reference, it is free to do *anything* with that memory until it returns. (It may, for example, stash temporary values there.) If it gets multiple `&amp;mut` references, they must be disjoint. When a function gets a `&amp;` reference, it is free to assume that memory won't change - `UnsafeCell` marks any exceptions. That's basically all we have to go on. I've found weaker assurances that raw pointers are not optimized much at all and are basically like assembly. More subtle stuff like "what happens if you alias a `*mut` with a `*const`?" are currently up in the air.
I have two python scripts that I wrote recently for work. Combining their functionality would be quite useful. I'm always trying to learn new stuff, so I decided to write the new, improved version in Rust and learn it as I go.
Huh, this is interesting. Thanks.
I actually don't know that it'd be right to call it a pushdown automaton, since I'm not really using a stack, but that does remind me of some important considerations for if/when you do implement the arbitrary block order: 1. Determine how you're going to handle duplicate blocks. The way I have things implemented, duplicate blocks are possible, and right now it's controlled by simply denying a new block when the previous block wasn't empty -- this is because the default accumulated value for the block contents are `{}`. That means: contract! { fn foo() { // This compiles. pre {} pre {} pre {} pre {} } fn bar() { pre { something(); } pre {} // This does not. } } 2. Get ready for a lot of redundant code. You only have to create a single entry for processing the content of each block you want, but it's annoying to have to add integration for EACH block in EVERY block processing entry -- it's an NxM explosion for the patterns you have to use. I've been considering trying to find a way to either get arbitrary block parsing into its own macro library or a less redundant technique for arbitrary block parsing. I'm totally new to a "by-example" text transform, so there's at least some interesting design patterns I imagine might be out there for common macro parsing problems that I simply haven't heard of yet.
I agree. You've a matter of seconds to convince the casual reader to stick around, and that happens in the readme.
If you call them "examples" rather than "snippets" than their place is definitely not in the readme.
Sorry...I sometimes forget that not everyone checks this sub daily. Here's the ones I'm referring to: * [Non-lexical lifetimes: introduction](http://smallcultfollowing.com/babysteps/blog/2016/04/27/non-lexical-lifetimes-introduction/) * [Non-lexical lifetimes based on liveness](http://smallcultfollowing.com/babysteps/blog/2016/05/04/non-lexical-lifetimes-based-on-liveness/) * [Non-lexical lifetimes: adding the outlives relation](http://smallcultfollowing.com/babysteps/blog/2016/05/09/non-lexical-lifetimes-adding-the-outlives-relation/) * [Non-lexical lifetimes using liveness and location](http://smallcultfollowing.com/babysteps/blog/2017/02/21/non-lexical-lifetimes-using-liveness-and-location/) * [Non-lexical lifetimes: draft RFC and prototype available](http://smallcultfollowing.com/babysteps/blog/2017/07/11/non-lexical-lifetimes-draft-rfc-and-prototype-available/)
&gt; Stemming is the process of finding root words like "find" from inflected forms like "finding" or "finds" and lemmatisation is the generation of an index which groups them together so you you can type any one of them and find a match across all of them. Multilingual stemming is even [available in a crate](https://crates.io/crates/stemmer)!
&gt; Personally I think good visual design is a good substitute for looking exactly like a native app. Text widgets have all kinds of funky platform-specific behavior, including keyboard accelerators, input methods and accessibility. Does Limn inherit whatever support WebRender already provides for these features? I'd be happy with "My UI works at least as well as Mozilla's HTML widgets", but I'm less interested in a solution that lacks these features.
&gt; Any search functionality on unicode strings, for example. Any search functionality on Latin strings. This gets much wackier as you step into other scripts.
By "tutorial" I mean "Application Programming Guide", i.e. a way to learn how to make use of such library. Examples are useful, but they are not enough to learn how to use a piece of software.
Yes. If you move your cursor over the Windows its 60 FPS .. it gets confused if you only partially move the mouse sometimes (while making the screenshot) ... and that makes sense ‚Äì its not a game and only redraws to the buffer if necessary :)
&gt; It's not created yet. I believe that the best way to create software is to write the user manual "before" the software itself. Of course, as requirements change, both the manual and the software must change. &gt; More or less don't exist. At least not any good ones ready for real use. There is no established competitor in this space. There are at least the following projects: * http://gtk-rs.org/ * https://github.com/rust-qt * https://github.com/PistonDevelopers/conrod * http://relm.ml/relm-intro * https://github.com/yue/yue Possibly they are not usable enough, but probably their design and implementation can be compared with that of Limn. I asked for such a comparison.
Is there an annotation that allows one to export a function (for linking, preferably dynamically) with a different name then it is in the Rust Source File? The goal is being to export symbols in formats the no_mangle/rustc doesn‚Äôt support but the linker _does_.
For those of you unfamiliar with SGX, it's a memory encryption technology implemented in newer Intel CPUs. It allows the creation of "reverse sandbox" applications which operate inside of encrypted memory regions. It's sort of like a "TEE", except there is no trusted kernel / TCB beyond the CPU itself: SGX runs entirely in userspace.
I think this is actually the best introduction to ownership, borrowing and lifetimes that I've seen so far :)
Just FYI, the music playing over the guy talking is annoying but **does** stop at about 1 minute in. 
I just read some of the wiki and this seems extremely anti-consumer. Will try to avoid buying any chip with this capability. But cool i guess.
For the removal I had to do some weird stuff to implement the sweep feature I wanted. Basically the user marks items as complete and then presses a button to sweep them all away. Because I can only remove contiguous ranges I had to call remove a bunch of times from the JavaScript. Is there a better way to do this? Normally I'd just write a sweep function in rust that filters out all completed items from the vector. However there's no invokable bindings. Are there any plans to add those in the future or is there a better way to do this? I'll try to clean and upload my to-do for you to look at today. Thanks.
An important thing to keep in mind is you can't actually use it without a license from Intel; without the license you can only use the "debug" mode that has *zero* security as the OS can read and write to memory within the enclave at will. Getting a license is an onerous process that requires you to essentially propose a use-case to Intel, and applications are frequently refused. Individual devs certainly aren't getting one. SGX is a highly proprietary technology, with access to it tightly controlled by Intel; it's anything but Open Source.
It would be really neat if there was a `Reflectable` trait or similar that could be automatically derived for all component types using a procedural macro. This trait would implement constructing instances of the component and setting/getting attributes by name, among other things, not dissimilar to the serialisation traits from `serde`. Now it would be possible to load UIs from XML or other formats in a standardised way, and to create a UI designer on top of that.
[`cedar`](https://github.com/jtomschroeder/cedar) is currently in the works to do just that. I'm still breaking things while trying to find the best architecture to support platform-independence, but it's getting there! :)
I also learn by doing and I am bored reading the rust programming language. I tried to follow a guide about making an AI that recognizes Spam couldn't do it. If you find something that you find will help you learn rust or is interesting please tell me.
There are a few experimental wasm rust dom libraries. Check out https://github.com/cramertj/domafic-rs and https://github.com/anowell/quasar.
OT: stop buying hardware that is "anti-consumer" is very hard, the intel management engine and amd platform security processor is problematic enough in my opinion. 
&gt; and applications are frequently refused Do you have an idea what the reasoning behind this is? 
I guess its an example for how hard it is for the human brain to digest concurrency (listening to music and David Sullins ‚Äì funny though music is a really good example because you can look away but you can't hear away, that's also the reason to increase the priority to music/audio playback than to video playback. Stutter in audio is more annoying than stutter in video ... I digress) 
There seems to be something weird going on in this thread, I can see your comment in my replies inbox but not on the post itself. The original link was here if that's what you need: https://play.rust-lang.org/?gist=5be7fae07fb83b034eaf86aa51c0c14a&amp;version=stable
Has anybody written something allowing COM DLL implementations in Rust, would unsafe code allow adding a vtable to a struct or trait that meets the requirements of IUnknown?
Doesn't exist yet, sounds like a perfect place for you to jump in and help.
Will this be a library or only a CLI? Would you cansider exposing checksum information through the API if so? I'd like to implement a transparent caching npm client for my template langauge project.
The amethyst game engine organization has published a progress blog post after a year of silence: https://www.amethyst.rs/2017/09/16/twia-10.html Development is still ongoing! We're working around the clock on this engine. Note: this was only published today, despite the date being from last month.
The sword may cut two ways here: could you use this on a cloud server to prevent the host from inspecting you?
Doesn't seem to be that, I've changed it to a String and it doesn't make a difference.
I don't see how. Maybe im wrong. I don't know the exact details of SGX, but i can think of three options. * Unencrypted code: The cloud server can just be running an emulator. * Universal private key in hardware: Somebody will extract it -&gt; emulator. * Unique private key in hardware: the cloud can MITM the public key -&gt; emulator
There's quite a few theories, ranging from wanting to avoid applications that actually need high security (embarassing for SGX to get hacked), to desire to maintain a monopoly over business applications of SGX, to government pressure to ensure computing remains insecure in certain ways (SGX would be an *excellent* tool for certain privacy applications like Tor, and part of the Snowden leaks indicated that the spooks are keeping very close tabs this tech). I've talked to SGX team members in person, and the ones that are willing to talk about this have all said the problem is a clash between the more "open source" side of the company, and the business-driven side that wants to extract maximum value from SGX with exclusive licensing. But it's hard to know.
I merged your patch: thanks! When a user marks functions as `done`, the model knows what information is done, so a function `removeDone()` on the model would be convenient. Exposing a Rust implementation function with no arguments besides the object pointer is easy. The question is how to make work with the code generator which is data based and not function based. Either the JSON would need to be extended to let you specify member methods, or you'd register the `removeDone` helper function outside the generated code. For that to work, you need access to the private pointer to the rust struct that is encapsulated by the object. That's no so pretty. So, I would prefer to expand the JSON binding description with member methods. "MyObject": { "type": "Object", "functions": { "removeDoneItems": { "arguments": [], "return": "void" }, "removeLargeItems": { "arguments": [{ "name": "thresholdSize", "type": "quint32" }], "return": "void" } } } edit: formatting 
Awesome, it goes hand to hand with the stuff I'm working on.
This is a really important question and one I think I'll be thinking about a lot more soon, I really like React and unidirectional data flow in general and I think ultimately something similar will be enforced and encoded into the library. State is stored in EventHandlers which are attached to widgets, application state should be attached to the root widget, whereas component state or 'ephemeral' state should exist lower down in the tree. Right now, however, there is very little restriction on how data flows through the graph, it's possible to create cycles and generally create an unmaintainable architecture with it. I think of it sort of as the low level building blocks on top of which a more opinionated event system will be built. I've stayed unopinionated in part because I'm not sure yet whether it will be necessary to have an 'escape hatch' from a unidirectional flow for low level components for performance reasons, and in part just because building a UI library is a huge project and I haven't yet had the proper time to design it carefully. My plan is to build up the core components and examples to the level of complexity where you can really see the impact of different designs and experiment with it from there. Also I'm planning on significant refactoring of the 'draw state' to make it more generalized and minimize the work done in redrawing which will likely have an impact on the design.
I think the json would be the right place to put it as well. I think the way you proposed seems good to me. I assume the argument types would need to be qt types just like properties? Also, is there another place for these kinds of discussions? I'm not sure how kde projects normally discuss things but itd probably work better than an ever growing Reddit thread haha. Also, is there a place set aside for documentation? I think documenting the json features would be really helpful for anyone going down the same path as me. If there's a place for docs I don't mind taking some time to write them out.
Eh, it's nice, but it makes text harder to see on tabs. I use the standard dark theme on Firefox Nightly and it works for me. Good work though, I'm sure a lot of people will love it :)
I would like to make it a library too, but I'm not sure how far I'll get with it!
Here's a working version: [playground](https://play.rust-lang.org/?gist=4c9fc63b9e18663b7743e6b758784640&amp;version=stable) In your version, the type of `map` is being inferred as `HashMap&lt;&amp;str, {integer}&gt;`, which causes `word` to be borrowed. Creating a `String` from `word` and putting it in `map` gets rid of the borrow (by copying `word` into a new `String` instance).
The browser.html project README references something called "graphene", but I can't find any more info about it.
References to the contents of `l` is being inserted into the map. Try doing `map.entry(word.to_owned())`. I also strongly recommend you come hang out at #rust-beginners on IRC if you want more help. Usually there are _a lot_ of follow up questions when you're getting started with a new language, and chat is a better format for that.
I mean... either your first comment is right or this one is: either it's trivially easy to bypass, in which case it doesn't matter, or it's not, in which case you should be able to hide from the cloud host. A quick search shows that apparently Intel removes this functionality from their server CPUs, so I'm inclined to think it's the latter!
Was it deleted? I see 17 upvotes but the link yields 404..
[This](https://www.amethyst.rs/2017/10/03/twia-10.html) seems to work.
`#[export_name="..."]`?
Qt types are what we use for the properties, so let's be consistent. There is no inconsistency between type names between Rust and Qt, so at some point we could support either. It's just a lookup table, so easy to add. Rust types are simpler and more precise. I think I chose Qt types because I worried that there might multiple Qt types corresponding to particular Rust types. I've create a bug to track the issue: https://bugs.kde.org/show_bug.cgi?id=385341 KDE normally discusses on bugs, review requests and mailing lists. There's no mailing list for this project yet. When contributions go up this makes sense. Adding docs in code or .md files would be much welcomed. Entry point to read the docs is README.md. If you write separate files, `doc/` would be a good place. 
We accidentally broke the link, we've already reverted the commit that caused this and we're just waiting for travis to rebuild the site. Sorry! Check back in ~~15~~ 30 minutes. EDIT: Travis is taking a while to boot for some reason. EDIT: Link is back, thanks for your patience!
yep, I'm a big fan of Cassowary, the `layout` subcrate is one of the more mature parts of this library right now, might be useful to anyone else working with Cassowary. It basically makes it easier to work with Cassowary on the level of rectangles instead of just variables, and has some useful container types, like linear_layout which is essentially like flexbox. When it's more mature I'll split it into a separate repository and publish it. Also yeah I'd love to see a high level, interpreted interface and/or "QML-ish" declarative language be built on top eventually, going to need to wait until at least a few more lower level design questions get resolved first though. I might not have time to do it myself and get the lower level library where I want it at the same time, but maybe some brave soul will step up ;)
Oh that makes sense. Thanks
Yeah, thanks for pointing me to IRC. garbage collections really hides all of this away. But yeah, it keeps a reference, which is then gone. Well then, thank you
I disagree with them being exclusive. In my first comment i was mostly referring to the 'default' and perceived capabilities of computers , and the ever more widespread illusions of privacy , security , and control. In my second comment i was trying to focus on the natural limits that I'm aware of. P.S. ( semi rant ) I'm **guessing** your cloud use-case is not the use-case this was developed for. The big bucks are likely in DRM. And fuck that. This is why my initial reaction is 'anti-consumer' and what i mean by 'perceived capabilities'. In 10 years time, lawmakers will think in terms of "Clearly its possible to force all consumer computers to behave like X. So we need them to behave like Y in the interest of ...." 
That's true, native UI is more than just visual. Unfortunately WebRender isn't responsible for that, but it is the kind of thing I would want to include. Some of it might be built into `winit` or another layer on top of it, other parts will have to be built into limn directly. These are the kind of things I see as the baseline of a useful app though, so I do consider them higher priority than many other 'nice to have' features, like making the API as expressive as possible. Still they probably won't appear until limn is used in at least one large-ish app. I'm considering writing a text editor in this library so that might be the time these features get added.
&gt; Java does not have named arguments(and neither does Rust!) *Puts down learn rust book and walks away* Admittedly I'm still on page one for learning rust but I like what I see, but named arguments is so nice.
Yes, it's not a full push-down automaton but the storing of the encountered blocks in the macro and the later unrolling reminded me of the [Little Book of Rust Macros](https://danielkeep.github.io/tlborm/book/pat-push-down-accumulation.html) though you used a "fixed size" stack. The redundant code is actually what I want to avoid, though so far I've found no way around the combinatorial explosion. These are things which would be quite easy with procedural macros.
kinda like how flutter is responsible for drawing all the pixel on screen? (thus having the ability to preview ios look and feel on android)
What do you mean regarding the dependency management? Do you mean that you wouldn't want to specify the mocked traits? Or that if you have a mocked object which should contain another mocked object, you'd have to compose them yourself? If you just want to stub the behaviour you only have to specify a `given!` block, maybe be I could add an alias if there's a good phrase for it. If you don't specify any `expect!` blocks, you may verify the return values with simple assertions, `galvanic-assert` or any other assertion framework of your choice.
Do all we have to do is add the label hacktoberfest to the issues to make them qualify? Is that something the Working Groups could do to the impl-period labeled issues?
All pull requests qualify for hacktoberfest; the label just makes issues show up on their site. I've already mass tagged easy issues from most impl period crates I have access to.
How can I help if I don't know how it works? It would be reverse engineering. (Direct) engineering goes from design to implementation.
Not that I know of, but that's a wicked good idea
I've also tagged work in my github-rs crate for Hacktober. It should just show up on the site.
When did `..=` become the replacement for `...`? It looks gross---was there some technical reason for this change? EDIT: also, I'm surprised at the number of RFCs now in the pipeline. I thought this would be much less during the impl period, as the announcement said "During this time, the subteams will not plan to merge any RFCs, except if absolutely needed for implementation." https://internals.rust-lang.org/t/announcing-the-impl-period-sep-18-dec-17/5676
See these two frameworks: https://github.com/cramertj/domafic-rs/ https://anowell.github.io/quasar/
Because "word" is just a reference into "l" and you are adding "word" into the Map. So, when you try to print the map, it is trying to reference back to "word". Try changing, "map.entry(word).or_insert...." to "map.entry(word.clone()).or_insert....".
I made this boilerplate to mirror my original [Python based one](https://github.com/svenstaro/python-web-boilerplate). Essentially I tried to write a 100% idiomatic and well-tested boilerplate that would get me off the ground quickly when starting new projects. What you get is: * Only the bare essentials that you need for a modern application * [User login and registration](https://github.com/svenstaro/rust-web-boilerplate/blob/master/src/api/auth.rs) * [Validation](https://github.com/svenstaro/rust-web-boilerplate/blob/master/src/validation/user.rs) * [RESTful design](https://github.com/svenstaro/rust-web-boilerplate/blob/master/src/responses.rs) * [Integration tests](https://github.com/svenstaro/rust-web-boilerplate/tree/master/tests) * [A little bit of rapid prototyping convenience](https://github.com/svenstaro/rust-web-boilerplate/blob/master/watch.sh) * [Database connection pooling using R2D2](https://github.com/svenstaro/rust-web-boilerplate/blob/master/src/helpers/db.rs) * [A test route that shows off convenient user authorization](https://github.com/svenstaro/rust-web-boilerplate/blob/master/src/api/hello.rs) Hopefully this is useful to someone. Please let me know if you find any problems!
Yes there is a reason there are no tutorials yet, this library should not be considered usable at this stage. It should probably only be of interest to people who want to get there hands dirty hacking on the library itself. This does also require more documentation than already exists though, consider it a work in progress. There is currently no established Rust GUI library that emphasizes performance or has a particularly composable widget system, I'm talking specifically about those written 'from scratch' in Rust, not those that are a layer on top of some other toolkit. I updated the README to say 'small core API' rather than just small API, to be more precise, since a large API is often a function of having more features. The goal is to make a distinction between the API for building components, which should be small and easy to learn, and the API of the components themselves, which should have a standard structure and be somewhat replaceable, so that components can be replaced by better alternatives over time, without bloating existing APIs.
Nothing really complex. Just a little search algorithm that considers `√≥timo` and `otimo` equal words. 
Note that several of the RFCs listed under "Final Comment Period" are actually already done with final comment period. The PRs just haven't been merged yet.
I've been working on a space sim game using ggez. It's been fun so far, although coming from a Java background, it's taken a while to wrap my head around some of the borrow checker issues.
Some random thoughts perusing this, as I read each line. Some of these thoughts may be incorrect as I read more code: - [Is this assuming API access? Or is this for password resets? The latter is usually a separate table](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/models/user.rs#L22) - [A bit of a stretch (and overly track-ey) to assume all apps want this by default](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/models/user.rs#L23) - [This looks more like a debug impl to me. Not sure why this needs to implement Display](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/models/user.rs#L33-L37) - [Can't the database do this for you?](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/models/user.rs#L53) - [This should definitely be done in the database](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/models/user.rs#L55) - [This whole function looks like it should just be `*self = update(self).set(currrent_auth_token.eq(sql("DEFAULT"))).get_result(conn)`](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/models/user.rs#L52-L58) - [`users.find(user_id)`](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/models/user.rs#L85-L86) - [Why not just do this in the database?! `users.filter(current_auth_token.eq(auth_token))`](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/models/user.rs#L89-L95) - [This sure looks like it's deserializing, not serializing. And it looks like it's deserializing a `Login` (or `Session`), not a `User`.](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/validation/user.rs#L12-L56) - [Having this function panic is needlessly restrictive. You could easily return `Box&lt;Error&gt;` and just unwrap it at the callsite if you really want to panic](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/helpers/db.rs#L13-L18) - [This is the actual boilerplate I want (and as a dev I want to get rid of...)](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/helpers/db.rs#L20-L45) - [Just pass a reference. No need to clone](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/api/auth.rs#L27) - [Why are you not doing this in the database? `users.filter(hashed_password.eq(hash_password(password)))`](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/api/auth.rs#L36) - [This should 100% be done in the database.](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/api/auth.rs#L58-L63) You cannot replicate a unique constraint in app code. - [Even if we want to pretend that select-then-insert is the same as a unique constraint... You aren't doing this in a transaction which throws any hope of atomicity out the window](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/api/auth.rs#L55-L76) - [`diesel print-schema` is the preferred way to do this](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/schema.rs#L1) - [Is this really just a bunch of definitions of JSON bodies that have `"message": "exact HTTP status code definition"`? WAIT ARE YOU RETURNING A 200 FOR ERRORS? WTF?!?!?](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/responses.rs#L77-L138) TL;DR: Trust the database more, mate. You want less boilerplate? Stick it in the database.
I have no clue what union type punning is, and google isn't helping. Help?
Where you use a union to treat a value of type X as if it had type Y. Most commonly used for `union Foo {float: f64, int: u64}` so that you can inspect the bits of the float directly. IIRC this is safe in C, but might be UB in C++. But for two general types in C++ this is unsafe, even if you do things to ensure their layouts match meaningfully.
Here's the reasoning on the syntax change https://github.com/rust-lang/rust/issues/28237#issuecomment-304145654 I actually kinda like it its very clear what's intended `...` is just to typo friendly.
Aren't most of the spec writers compiler devs?
Consider the expresssion `(a&lt;b,c&gt;(d))`. Is it a function call with two generic parameters wrapped in parentheses, or a tuple of two comparison results?
Wait seriously? That's the only way to do that? Damn, we take the ability to `mem::transmute` into ` [u8; 4]` for granted then
&gt; But I get the impression that Rocket adds new dependencies on nightly faster than the compiler team stabilizes features. This is the impression I get too, and I don't understand it at all. Diesel chased nightly for nearly 2 years, and it was *exhausting*. After about 6 months we started looking for every way that we could work purely on stable (and always had a stable option, even if they were usually a bit worse than the alternatives). TBH Having looked at Rocket a bit, I don't think there is very much that *needs* to be nightly if they put their mind to it. If the file needing attribute macros were wrapped in a `rocket_app!` invocation, I suspect you could do everything you needed in a normal macro, and if not then moving to a macros 1.1 hack (I seriously doubt there's a need for that, though. `macro_rules!` is surprisingly powerful if you know how to use it). Generally I think the lack of time spent working on this is disappointing, and it sucks that the most talked about Rust web option is unlikely to work on stable Rust within even the next year.
I've actually been wondering what's up with this. It's been 20 days and it's still not implemented? Did Alex escape again?
Oh shit, i'm super glad this is still being worked on! I had a look at it a while ago and was super prepped to start a game on it, maybe submit a few PRs, but there hadn't been any activity recently. Keep this up, would love to contribute!:D
Thank you for the detailed feedback! Certainly didn't expect someone to read all of it so quickly. I think your agitation on the last bullet point is uncalled for but I'll still address all of the points: &gt; Is this assuming API access? Or is this for password resets? The latter is usually a separate table This boilerplate currently doesn't do password resets and these are for API access. I know that you can do a separate table for each of these (which for instance would give you the ability to de-authorize particular devices) but I wanted to just allow a single token across all devices for the boilerplate. It should be easy to extend, though. &gt; A bit of a stretch (and overly track-ey) to assume all apps want this by default True, it's opinionated here (but then again the whole boilerplate is). The reason is not to track but to refresh the token. &gt; This looks more like a debug impl to me. Not sure why this needs to implement Display Could be that I misunderstood the intention behind Debug and Display. I'll look into it. &gt; Can't the database do this for you? Yes, but I didn't find a clean way to do that with Diesel without raw SQL. That would also make refactoring a little less obvious if you want to use a token that is not a UUID. &gt; This should definitely be done in the database Same as above. &gt; This whole function looks like it should just be `*self = update(self).set(currrent_auth_token.eq(sql("DEFAULT"))).get_result(conn)` That would certainly be shorter (though you omitted updating of `last_action`). I'll look into it. &gt; users.find(user_id) Cool, didn't know that worked. &gt; Why not just do this in the database?! users.filter(current_auth_token.eq(auth_token)) Are you sure that this will result in the same timing characteristics? I don't claim to be an expert in this but I thought that my solution at least stands a chance against timing attacks. &gt; This sure looks like it's deserializing, not serializing. And it looks like it's deserializing a Login (or Session), not a User. Mh, yeah looks like it. My original intention was to also use this for serialization but then it turned out that I couldn't use serde in quite the same way that I can use marshmallow in Python for. I'm going to rename this to better reflect its purpose. &gt; Having this function panic is needlessly restrictive. You could easily return Box&lt;Error&gt; and just unwrap it at the callsite if you really want to panic True. I'll change this. However, in all fairness, there is not a lot useful stuff to be done if this fails but I certainly see that this should be handled at the callsite. &gt; This is the actual boilerplate I want (and as a dev I want to get rid of...) Anything you think should be done about this? &gt; Just pass a reference. No need to clone Alright. &gt; Why are you not doing this in the database? users.filter(hashed_password.eq(hash_password(password))) Again, I'm not an expert on this but I thought that using `argon2i_simple` is likely a safer choice here. &gt; This should 100% be done in the database. You cannot replicate a unique constraint in app code. &gt; Even if we want to pretend that select-then-insert is the same as a unique constraint... You aren't doing this in a transaction which throws any hope of atomicity out the window Yeah, that bothered me as well. At the time (and maybe still), using Diesel with transactions was really raw. I'll definitely revisit that. Keep in mind, though, that database consistency will still be kept in this case because there _is_ a UNIQUE constraint on the database. The thing with the duplicate error is just for providing a nice error to the user. There is a short window of opportunity for generating a server error if you register the same email at the same time. You seem to also dislike the database transaction idea in preference of doing this whole thing in SQL. How would you do this in SQL (making best use of Diesel) while still providing a good error for the user? &gt; diesel print-schema is the preferred way to do this Is it nowadays? I'll look into that. I don't think it existed at the time. * Is this really just a bunch of definitions of JSON bodies that have "message": "exact HTTP status code definition"? WAIT ARE YOU RETURNING A 200 FOR ERRORS? WTF?!?!? Yes, the defaults are the HTTP status code. The way you are meant to use these is like [this](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/api/auth.rs#L62). Basically, you are meant to overwrite the default error message (which is the HTTP status code definition) and otherwise you'll just get the latter. Can you think of a cleaner way here? What do you mean by "WAIT ARE YOU RETURNING A 200 FOR ERRORS? WTF?!?!?". I believe you probably spotted a bug and I haven't. Can you point that out to me? Also, I'm a bit taken aback by that last seemingly hostile sounding point. I'm sharing this because somebody at RustFest told me that it might be useful for others. I'm thankful for your thoughts. In general, I like and trust the database but Diesel is just not yet on the level of SQLAlchemy and there were trade-offs to be made between raw SQL and timing guarantees. I couldn't find reliable sources on how to prevent timing attack with postgres comparison operators. Would be glad if you could show me some resources that goes into detail about that.
 trait Foo { fn print(a: i32, b: i32); } struct Bar; impl Foo for Bar { fn print(b: i32, a: i32) { println!("{}, {}", b, a); } Foo::print(1, 2); // should print "1, 2" Foo::print(a: 1, b: 2); // what should this print? 
Looks like someone tried to, don't know if it works/how well it works: http://eljay.github.io/com-rs/com_rs/index.html
Depends on the application. For games, yes, but for desktop and mobile apps its often nicer to be consistent with the OS‚Äôs gui toolkit.
Note that this is slightly different; unions work with values of different sizes, but you also need to put the value in the union beforehand. C++ has nothing like `transmute` though. In both languages you can pointer-cast to get this same effect (but you lose the safety of it dealing with the size); transmute just has the added benefit of letting you "retype" a stack variable (instead of retyping a reference), which is basically impossible in C++.
Not for C++, no. There's overlap.
I wrote a library a few months back called `snaek` which intended on marrying Python and Rust via CFFI. This ran into a few hurdles, the biggest being that it really could not decide if it wants to be highlevel or lowlevel. I constantly ran into issues actually using it in production and this week I got so frustrated that I decided to the most lowlevel approach possible. It doesn't even do anything Rust specific but just extends the setuptools Python toolchain to lets you compile anything into a dylib and then to load it via CFFI and an already existing header. This is perfectly used in combination with `cbindgen` for now (which atm requires nightly for many users). My goal now is to make *that* stable and then to later build a separate Python library to make working with Rust nicer. Here is how we use this at Sentry: * [setup.py](https://github.com/getsentry/symbolic/blob/master/py/setup.py) which compiles a rust library and then constructs a cffi module * [some utilities](https://github.com/getsentry/symbolic/blob/master/py/symbolic/utils.py) for error handling between rust and python nicer * [an example python module](https://github.com/getsentry/symbolic/blob/master/py/symbolic/symcache.py) that works with the rust lib The actual CABI is defined like this: https://github.com/getsentry/symbolic/blob/master/cabi/src/symcache.rs Would be curious to see if people find this interesting.
&gt;So, when you want to call a function with a specific type parameter, you have to use ::&lt;&gt; instead of just &lt;&gt;, which seems to be standard in languages like java / c++ Haskell is probably the only language where type signatures are given by `::` but using `:` to separate type signatures is from math and it's common across other functional languages (Elm, Idris at least). I'm not sure why Rust went with the turbofish approach but that would be my guess.
I thought pointer casting was UB?
Sorry, the last bullet was a bit harsher than I intended it.
&gt; (though you omitted updating of last_action I'd do this with a database trigger personally &gt; I don't claim to be an expert in this but I thought that my solution at least stands a chance against timing attacks. Timing attacks aren't really an issue when you're dealing with network IO. There's a reason virtually every authentication library does it this way. &gt; Anything you think should be done about this? No, it's something I need to fix in Diesel and/or work with R2D2/Rocket on. &gt; How would you do this in SQL (making best use of Diesel) while still providing a good error for the user? match insert_result { Error(DatabaseError(UniqueViolation, _)) =&gt; useful_user_facing_message, _ =&gt; ... } The second field of `DatabaseError` will let you filter by constraint name on PG if you're worried about more than one unique constraint. Sorry again for the last bullet, it was not the tone I intended (long day, should have read it over before submitting)
thank you :D
Then my second question would be what context it will be used in. 1. On the one hand, reinventing search as a concept risks evolving into a "Regretfully, I really did wind up needing most of those features after all... but I only realized this after I reinvented them in a less mature way" situation. 2. On the other hand, if it's not something you intend to share, and you're certain it won't wind up growing new needs over its usable lifetime, and its use will be limited to a small set of known languages, using Unidecode and storing both versions really might be the most efficient way to get what you need.
Working on [actix](https://github.com/fafhrd91/actix) actor library. just added sync actors. thinking about adding http server support or remote actors.
kind of, but so is transmute. I'm just saying that even type punning via unions is not the same thing as `transmute`, they each have pros and cons
Am working on SSL-based encryption and authentication for the Concurr server + client at the moment. I have a prototype working, but it will take some time to get it production-ready, and thus committed to the repository. I'll provide a script that makes it easy to generate the required certs and keys for each node. The client will need to have a local copy of the certs for each node for authenticating the SSL certificate of each connected node. Authenticating the client with SSL is currently blocked by [this issue](https://github.com/sfackler/rust-native-tls/issues/48).
Nice. I just opened it up on github, feel free to take a look. https://github.com/azuqua/redis.rs Still needs more tests before it goes up to crates.io, but hopefully that'll be later this week.
Unless I'm mistaken, using `transmute` to go from `f32` to `[u8; 4]` is not UB.
I didn't say it wasn't? I think you have misunderstood what I was trying to say.
&gt; kind of, but so is transmute. in reply to a thing that said another thing was UB Implies that using `transmute` is UB (I'm probably being pedantic, I'm guessing you were trying to say that you can cause all kinds of UB with `transmute`)
I was saying that transmute is as much UB as pointer casting is, which was the context.
I think you're being confused by generic statements about the UB of unions/pointercast/transmute for type punning and specific statements about float/int punning.
Maybe I just don't understand UB in C that much. But my understanding was that taking something of type `*float` and casting it to `*int` and dereferencing it was UB. If that's the case, this statement implies that using `transmute` to convert `f32` to `u32` is also UB.
I don't think that's not UB in rust or C if used for type punning for those two specific types. transmute is slightly safer in that it does a size check for you and provided your data is `'static` (wholly owned) you don't need to worry about aliasing UB. Edit: mistype, meant "i don't think that's UB"
Oh its cool to see the work you presented at PyConCZ progress!
... and TLS/SSL encryption support is implemented now. Took about 2 hours. Hostname verification is performed by the client. Client authentication on the server is not yet implemented due to the blocker mentioned above. https://github.com/mmstick/concurr/commit/42dfc8406bd1bf2419a0836fd5c7a6c9f32974a9
.. [and it's done](https://github.com/mmstick/concurr/commit/42dfc8406bd1bf2419a0836fd5c7a6c9f32974a9). TLS/SSL support has been integrated very easily. Only took about 2 hours to fully integrate with the application. Client performs hostname and cert verification when connecting to each node. Only thing left to do is to wait for `native-tls` to implement server-side client certificate authentication.
So I've got SSL support integrated with `native-tls`, with hostname and cert verification on the client-side. Only missing piece is that the `native-tls` crate doesn't yet offer support for verifying client certificates yet. May look into implementing it myself if I have the time.
My best guess about the problem without having run your code: Your `future` object contains the `work` object, and `work` contains a closure that refers to `req`, which is itself a reference scoped to the current `send` function. I notice that you made it a `move` closure, maybe trying to solve this problem, but I'm not sure that has any effect here. References are `Copy`, and anyway moving them doesn't change their lifetime. You might be able to solve this by doing something like `let url = req.get_url().to_owned();` at the top of the function, and then using the `move` closure you already have to snag that value.
Amazon jobs listing Rust as a plus: https://www.amazon.jobs/en/search?base_query=Rust&amp;loc_query=&amp;job_count=3&amp;result_limit=10&amp;sort=relevant&amp;category%5B%5D=software-development&amp;cache
I'm curious what problems were you having with `snaek`? As a fan of `snaek` (but not having used it in a real project yet), I appreciate the even simpler looking approach of `milksnake`. And making `milksnake` (optionally) compose with something ergonomic on top at a later date sounds good to me.
I agree, `..=` looks to me like an assignment operator (similar to `+=` or `&lt;&lt;=`) every time.
This all looks very nice, thank you publish it. &gt; In particular you will most likely only need two wheels for Linux, one for macs and soon one for Windows independently of how many Python interpreters you want to target. Why two for Linux? What‚Äôs a set of wheels you might want to publish to make a library easily available to many people? Does `pip install foolib` work when a wheel is not available but appropriate versions of Cargo and rustc are in `$PATH`? Assuming that Cargo (or whatever toolchain produces the native dynamic library) supports cross-compilation, can setuptools produce wheels for platforms other than the one running?
Biggest issue is that it now needs nightly for me for header generation and that it is just in a weird spot. For instance it does very little to make actual rust nice so far but to make it higher level there is a lot more work necessary I don‚Äôt have the resources for atm. 
32bit and 64bit x86. That‚Äôs why you need two. Also you can‚Äôt cross compile well with setuptools :(
Oh, that makes sense. I suppose it‚Äôs because 32bit OS X is now mostly unused? What about Windows, aren‚Äôt both 32bit and 64bit in use?
On OSX you have fat binaries containing more than one arch. Windows you need the same but I did not care about it yet. 
Why does UserSerializer have an id member that is never used? And why is UserSerializer only used in deserialization? And why not use .env / dotenv for the DATABASE_URL (because more configuration options will be needed for a real app)?
If you use [NaiveDateTime](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/models/user.rs#L23), shouldn't you also always set the postgres session timezone to UTC? So that all timestamps will always be in UTC? impl&lt;E&gt; CustomizeConnection&lt;PgConnection, E&gt; for MyCustomizeConnection { fn on_acquire(&amp;self, conn: &amp;mut PgConnection) -&gt; Result&lt;(), E&gt; { conn.execute("SET TIME ZONE 'UTC';").unwrap(); } }
It's been under discussion for an incredibly long time and I promise every corner of every objection and alternative is in that thread. Unfortunately syntax questions seem to be uniquely consensus-proof. Finally the lang team just had to make a decision.
Btw, why are you doing the [lowlevel db queries](https://github.com/svenstaro/rust-web-boilerplate/blob/f3afced25b513d99786fc0fc058f29eeccce1c54/src/api/auth.rs#L26-L29) in the controllers instead of calling [model functions](https://github.com/TheNeikos/furry.cafe/blob/master/src/models/user.rs#L348-L354) that do these queries?
Not particularly targeted to you but I encountered a small pattern I came across several times that makes my life harder. Returning { "status" : "...", "data" :&lt;cool_object&gt; } in the case of success and { "status" : "...", "data" :{"message" :"the error message"} } in the error case is extremely hard to parse on the client side if you're using JSON to object parsers like gson (maybe serde Idk) because you can't just prepare a class /struct for parsing this because your "data" is either one class /struct or another or you pollute every data class /struct with a message. What is essentially a union type. In the case of swift, basically every attribute needs to be optional against the initial intention. I changed that for my API by putting the message on the same level as status and data. I did not encounter the need to put anything else than a message in the case of an error. What is your opinion about it? EDIT: [never use UUIDs for authentication tokens!](https://github.com/svenstaro/rust-web-boilerplate/blob/11cca61526c62bf429fd1f8c5f5ce693ff85eee5/src/models/user.rs#L53)
Two strings walk into a borrow checker. There's something broken with my mental model as I think that I've given a reference to the title string to the assert. I was kind of hoping that the assert wouldn't hold onto the string reference past the call and that I could move the string into the HashMap. Mostly I have a real problem with the the use of the word 'after' in the error message, because I'm pretty sure line 769 is before 770... Can someone please explain what's wrong with my mental model? error E0382 use of moved value: title assert_ne!(&amp;amp;title, &amp;amp;k); --------------- value used here after move alias_map.insert(title, k.clone()); ------------------- value moved here 
You moved `title` into the hashmap to use as key, so you no longer have it. You can insert a `title.clone()` instead, so you'll still have the title. Without seeing your code, I can't tell what your other options are. Also I really expected a joke. And if you put four spaces before each line, reddit will layout a paragraph as code, which you may want to try for the error message you pasted.
Is this in a loop? Hard to say for sure without the actual code but it may be telling you that you move the value at the end of the loop and try to re-use it on the next iteration. If so, it could indicate that it's worth having some loop-specific wording in such error messages to reduce this kind of confusion in the future.
Who is responsible for merging them?
Is there a crate that provides a circular buffer that fulfils the following conditions: * It must be growable. I don't want to overwrite anything; I want to explicitly remove items from the buffer. * It must be type-safe, so no byte/text-oriented stuff. * It must be thread-safe. Preferably `sync` so I can store it in a `lazy_static` and write to it from anywhere without having to wrap it in a mutex myself. * The whole buffer must be iterable without consuming the contents. It doesn't have to be lock-free or highly performant, but these are of course desirable properties. I guess I could quite easily implement one myself by wrapping up a `VecDeque` in a newtyped `RwLock`, but if a crate exists already, I'm happy to use a used and tested solution. My use case: I want to store messages sent from multiple threads for a specific time, and remove them when they get stale. I want to be able to read the whole message history sometimes when I need to.
It seems to be this line: `let serialized = result(serde_json::to_string(&amp;req).map_err(From::from));` If I remove that and change `type ResponseType: DeserializeOwned; to `type ResponseType: DeserializeOwned + 'static;` it compiles. So I've narrowed it down but still not quite sure as to what the solution should be so that I can still serialize the json. This is the code that compiles: pub fn send&lt;R: Request&gt;(&amp;self, req: &amp;R) -&gt; TelegramFuture&lt;&lt;R as Request&gt;::ResponseType&gt; { //let serialized = result(serde_json::to_string(&amp;req).map_err(From::from)); let work = /*serialized.and_then( move |json| {*/self.client .post(req.get_url()) .header(ContentType::json()) //.body(json) .send() .map_err(From::from) .and_then(|mut res| { let body = mem::replace(res.body_mut(), Decoder::empty()); body.concat2().map_err(Into::into) }) /*})*/; let future = work.and_then(|bytes| { result( serde_json::from_slice(&amp;bytes) .map_err(From::from) .and_then(|value| match value { Response::Success::&lt;R&gt;(raw) =&gt; Ok(raw), Response::Error::&lt;R&gt;(err) =&gt; Err(err.into()), }), ) }); TelegramFuture::new(Box::new(future)) }
You should always go for a good low level first.
The team that accepted the RFC.
There's https://www.redox-os.org/ which isn't complete but much farther along. There's also [Phil Opperman's blog series](https://os.phil-opp.com/).
how can I compare usize and i32.
[Fatelf](https://icculus.org/fatelf/) if you want fat binaries for Linux if I'm not mistaken.
Fatelf is dead. Never went anywhere and the linux guys were heavily against it.
you convert one of them to the type of the other's using the `as` keyword.
Redox OS is awesome but I feel like it's far too advanced for someone just starting. The blog series looks more like what I want though, thanks.
Where can I find the repository hosting the env_logger source code?
&gt; Does pip install foolib work when a wheel is not available but appropriate versions of Cargo and rustc are in $PATH? Yes, this worked for me with either snaek or milksnake.
Oh, I'm actually a little disappointed.
I'm very interested in the error handling utilities. I would prefer if all of those extensions for rust were in the same package (perhaps even part of milksnaek if they don't really have extra dependencies), since I would probably impose this setup on distro packagers.
That only works for numbers in a limited range, since conversion between `usize` and `i32` is destructive. Conversion between `usize` and `i64` is also destructive on 64-bit platforms, so even that is not a guaranteed solution. If you're on nightly, you can convert both to `i128` and compare those: #![feature(i128_type)] (a as i128) &gt; (b as i128) Or you can make use of the `TryFrom` trait to catch incorrect conversions. #![feature(try_from)] use std::convert::TryFrom; // If conversion from `i32` to `usize` fails, the number was negative, and `a &gt; b` would be false. usize::try_from(a).map(move |a| a &gt; b).unwrap_or(false) If you're on stable: Sorry, it can't be done through the standard library. I think you can use the `num` crate, but I must admit that I don't know exactly how you would do it. 
Not just you! https://twitter.com/mitsuhiko/status/910916749444419584
If I like the setup I was thinking of putting it into a library. However ideally you can use a compiler plugin to aid that. Right now it needs quite a bit of manual glue. Also TLS for error handling is not very fast which might be not ideal for quite a few interesting use cases.
Thanks it worked. Now can you tell me what has to be the type of the variable that is used to index a vector?
A reason was package managers solved this problem long ago. Fuck, it could be nice with some of the bundling solutions that popped up recently.
&gt; Also TLS for error handling is not very fast which might be not ideal for quite a few interesting use cases. Could you elaborate on those usecases?
Bounds checks are kept in release mode (although optimizer might get rid of them, if it can prove the indices are always in correct range). So in most cases, if they are correct, they will be removed, but still wrong usage of indices will end with a panic, even in release mode. (A thing that actually is different in behaviour between debug and release in rust is integer overflows ‚Äì arithmetic in debug is checked and panics on overflow, but there are no checks in release, so it just happily overflows there.)
Anything that calls functions very frequently (eg: math libraries etc.). My function calls are very infrequent and the functions itself are reasonably slow so that is not a concern for me.
Yeah, sadly `native-tls` doesn't have a cross-platform way to handle client certificates. It is possible to have a linux-only/openssl-only solution with `native-tls` though : use native_tls::backend::openssl::TlsAcceptorBuilderEx; let builder = TlsAcceptorBuilder::new() builder.builder_mut().builder_mut().set_client_ca_list(calist); But sadly, it doesn't seem possible to access the internal builders for security_framework (MacOS) or schannel (Windows). If we could access them, it'd make it fairly easy to implement (albeit a bit verbose). If you're going to implement this, here are some hints: For security_framework, you can [call some methods](https://github.com/sfackler/rust-native-tls/blob/9c09ec6/src/imp/security_framework.rs#L380) on the [SslContext](http://sfackler.github.io/rust-security-framework/doc/v0.1.14/security_framework/secure_transport/struct.SslContext.html) to make it do client cert validation, namely `set_client_side_authenticate(SslAuthenticate::Always)` and `set_certificate_authorities(calist)` For SChannel, I went down the rabbit hole and came out mostly empty handed. Documentation surrounding client certificate authentication using SChannel is almost non-existant, and the little that exists mostly talks about how you can map a Client Cert to an ActiveDirectory User (which we don't really care about...). You might glean some info from [this mail thread](https://groups.google.com/forum/#!topic/microsoft.public.platformsdk.security/J0zS0HJKEyc). Anyway, good luck :D.
usize
You can perform a couple of `if`s instead of just one. _i32 &gt; 0 &amp;&amp; _i32 as usize == _usize
--nevermind--
&gt; Yes, but I didn't find a clean way to do that with Diesel without raw SQL. That would also make refactoring a little less obvious if you want to use a token that is not a UUID. You always want this to be not a UUID. UUID for auth-tokens are potentially an attack vector. 
I'm somewhat a beginner at this, so excuse my naive questions: Even for math libs, wouldn't I attempt to minimize the *amount* of FFI calls anyway if I really cared about performance?
Blockchain company TenX is also hiring! Have been following /r/rust for a while on my personal account :-) http://www.tenx.tech/careers.html
Sure. But one `rustcall` in my linked library involves 3 ffi calls for a sucessful function call and 5 ffi calls for if an error occurred to get the TLS error data. If you find a different mechanism you could get 1 ffi call for success cases and 2 ffi calls for error cases.
Well now I feel a bit daft. That's pretty obvious, and a lot simpler than what I'm doing.
Wrong sub, try /r/playrust
Please elaborate. I don't see why they would be unsafe given that the underlying implementation uses a good source of randomness. I think UUID4 should be as good as any other non-uuid 128bit of randomness from /dev/urandom but maybe I'm mistaken.
No reason. I felt that at least for now the ORM-level queries didn't get in the way.
Good hint, though I never had a problem with this while not explicitly setting the time zone to UTC. What's the default on this?
I had it like you suggested some time back but someone complained that I didn't always need the message (as is the case when 'success'). I do see your use case as well, though. I'll think about it. 
The reason the UserSerializer is the way it is right now is that I tried really hard to DRY on data serialization and validation the way I can in Python with marshmallow but I failed. Now it seems like I have to bite the bullet and just give it one struct for serialization/deserialization respectively.
To me `0..n` means `i &lt; n`, so `0..=n` is quite logical. But hey, that ship has sailed.
yeah, i think there is pretty much nothing you could do about, after all its a boilerplate ‚Äì people can easily change this to their specific needs.
&gt; A quick search shows that apparently Intel removes this functionality from their server CPUs, so I'm inclined to think it's the latter! Well, no. https://azure.microsoft.com/en-gb/blog/introducing-azure-confidential-computing/ The technical details of SGX are quite interesting -- [this paper](https://eprint.iacr.org/2016/086.pdf) is an excellent technical description. edit: remove snark
Full support for i128 and u128. Very nice!
i thirst for weasels.
&gt; Or that if you have a mocked object which should contain another mocked object, you'd have to compose them yourself? Yes. I realise dependency injection is probably out of scope for this project, but wanted to point out how a richer ecosystem in this domain would make Galvanic even more useful. &gt; If you don't specify any expect! blocks, you may verify the return values with simple assertions, galvanic-assert or any other assertion framework of your choice. Sweet! That's what I meant by the "other" style of mocking where you only stub the API and _don't_ verify the exact interactions of production code with it, just the outcomes of it. I think it makes for less brittle tests and I'm glad Galvanic supports it.
Searching for it on crates.io and following the Repository link leads to https://github.com/rust-lang-nursery/log. But that seems to be the wrong link... maybe [this is it?](https://github.com/sebasmagri/env_logger)
Rust macros are absolutely Turing complete.
Too much text, too little information. Anyway, `assert_cli` is a great tool.
Assuming named arguments the first call one wouldn't work and the second would print "2, 1". Alternatively (if you wanted named arguments that are positional as well) the implementation should be rejected because it switches the first argument and the second around.
wait what, i thought it was too lol
Farewell, brave traveller.
It's dangerous out there, take [this](https://doc.rust-lang.org/nightly/nomicon/) 
Both solutions are sound - and both will break existing code.
huh, I could have sworn I just read something yesterday about it not being included on some of the server processors, but now I can't seem to find it. Anyway, yes, your link seems to indicate that protecting your server from the cloud host is indeed an intended use case. Cool!
Right, but that isn't an argument against named arguments, merely at introducing them without a different syntax.
I didn't use .env and dotenv because I usually use a few separate environments such as production, staging, testing, local. I didn't find a way to make that play nice with dotenv so I usually opt for environment variables which I import from a bunch of local shell scripts which just export variables. Is there a way to get what I want with dotenv nowadays?
I use `sneak` for a pet project of mine. Do you recommend migrating right away, or should I wait for `milksnake` to mature? 
I'm unlikely to continue maintaining snaek in the current form.
Thanks for the quick reply. I assumed that you would not maintain `snaek` anymore. To clarify my question: I am not asking "if", but "when" I should migrate to `milksnake`.
In combination with manually invoking a recent version of `cbindgen` milksnake and snaek are at feature parity. No reason not to switch.
If it's UB, the example doing that should be removed from the docs and we should probably fix the byteorder crate
And it choose the worst possible IMO. Even doing nothing would have been better.
Thanks, both for the response and for providing the library. It helps me a lot!
[parity](https://parity.io) mentioned they are hiring at RustFest. They have offices in Berlin &amp; London, but are remote-friendly as I hear. It appears the Rust job market is on the verge of taking off. 
I'd like to use this chance to ask for feedback on what assert_cli needs for its 1.0! [Chime in here](https://github.com/killercup/assert_cli/issues/41)! :)
All sorted now. It was the lifetimes of both the client and the static str that were causing the issue. Thanks guys.
Why was this submitted here? 
What alternative would you suggest? I'm not a fan of `..=`, but it is probably less likely to be confused with an assignment operator than `...` is likely to be confused with `..`.
I think on it's own, like presented in TWiR, it kinda reminds you of an assignment operator, but when used in a pattern `3..=10`, it doesn't actually look that bad.
Someone is always going to be unhappy. At the end of the day it's just syntax.
Probably because there could be multiple traits in the same module implemented for the same type that have a method with the same name.
It's a (raw) pointer cast in both languages. connect(LocalSocket, (struct sockaddr *) &amp;SockAddrBthServer, sizeof(SOCKADDR_BTH)); becomes connect( local_socket, &amp;sock_addr_bth_server as *const SOCKADDR, mem::size_of::&lt;SOCKADDR_BTH&gt;() as c_int); Note that Rust will assume the borrow at `&amp;sock_addr_bth_server` only lasts long enough to take the address.
Hello! Do I have any chance to join you as an internship backend (Rust) developer? I'm not experienced with blockchains (although I have a basic knowledge of this technology), but I think I am quite good in Rust (although I participated in gamedev projects mostly). 
Because it's consistent and simple. That's it. I have long requested "inherent trait impls" which don't need to be imported because they're providing functionality that is core to the type (e.g. `inherent impl Writer for BufWriter`), but alas, no progress.
If that were the case, wouldn't you just disambiguate with a turbofish?
You implement traits ad-hoc. How do you expect rustc to figure out how many and where traits are implemented for this type out there and which one you want exactly?
If new syntax is the solution, I would have preferred to put `pub` on the functions: mod foo { pub trait Bar { fn x(self); fn y(self); } pub trait Baz { fn x(self); fn y(self); } pub struct Qux; impl Bar for Qux { pub fn x(self) { } fn y(self) { } } impl Baz for Qux { fn x(self) { } pub fn y(self) { } } } use foo:Qux; fn main() { Qux.x(); // will use the Bar implementation Qux.y(); // will use the Baz implementation } Behind the obvious advantages(no new keywords, ability to solve ambiguity when multiple traits have the same methods), this style has the advantage of being orthogonal and consistent with non-trait `impl`: 1. If we make a method `pub`, it'll be usable outside the module - regardless of whether or not the `impl` was of a trait. 2. If the `impl` is of a trait, the methods will be usable when the trait is imported - regardless of whether or not they are `pub`. 
Because it‚Äôs Wednesday.
Yeah, but isn't it better to not have all traits in scope so you *use* the ones that you want to use and don't need a turbofish? How do you know if the trait is implemented in the same module? I think it's more consistent this way. **But** a good editor should suggest to *use* a trait if you call it's method. Hope RLS does this sometime.
‚Ä¶ on the other hand ‚Ä¶ there are just two possible places where a trait can be implemented for a type: together with the type and together with the trait definition. It wouldn't be that illogical if all those, that are together with the type, are *use*d automatically.
You know what github is intended for right? You jump in there raise an issue about any concerns or if there is anything you could do to contribute, owner may respond and go from there. Your other response about write a manual before the software thing, sure it sounds nice and like it might make sense at first but have you actually tried that much? And if so have you done it witha reasonably sized/challenging project before? It's not always practical if you want to get things done. Tutorials/Guides are nice to haves, they're not required to learn something, there are examples which can help plenty. I understand where you're coming from and the more docs and info out there the more it can help pick something up, hence why popular projects like React/Angular and such in the web get big communities as learning becomes more accessible. You can't really expect/compare that to this though, the same amount of resources are just not there. Give it time. I've learned to use/write software for some projects just by going through their codebase(one was a popular game with a very large codebase, no docs, no tutorials). It's definitely not a fast or fun process getting started, still access to the code was enough to start learning how to make things happen.
If the second trait gets implemented afterwards, then code just importing the type would break, because now there's an ambiguity.
Another article I found is [this](http://www.loekvandenouweland.com/content/using-rust-code-from-csharp.html), but that one didn't show how to use strings. It would be cool if the binding code could be automatically generated.
Right, that's sort of what I was humoring in my head. I'm not actually expressing an opinion of the current system either way -- I was just curious if what I proposed COULD resolve pains with the auto-using route. :)
&gt; If the second trait gets implemented afterwards Hmm...the initial argument that came to my head was that this was really only a library writer's problem, but after thinking more about it I realize that this is a good point. It seems far more beneficial (in terms of backwards-compatibility) to libraries not having to worry about breaking their own code, and, more importantly, client code by adding another trait with the same method name...
The module is a unit - so in any language, when I import something from the module, I expect the compiler to know everything the module has to say about that something. In Rust's case, that includes all `impl`s for that type in the module where it is declared - whether these `impl`s are standalone `impl`s or trait `impl`s.
Uh, sorry, i mistyped. "I don't think that's UB for rust or C for those specific types". Generally type punning for poking bits and memcpying is ok.
My interest is in the high-level stuff but I'm excited about the potential this holds to make a really solid foundation for a PyPy-compatible alternative to rust-cpython and PyO3. (When I say my interest is in the high-level stuff, I mean that, if, for a given problem space, rust-cpython isn't sufficiently close to just writing the whole thing in one language, I fall back to working in pure Python. I use Rust for its stronger type system and something lower-level than rust-cpython puts a massive hole in it, worse than just relying on Python+MyPy+PyLint+Flake8.)
That link‚Äôs a little broken.
Works on reddit.com but I rewrote it to be a proper markdown link.
Odd. It‚Äôs still broken on my iPhone... I notice this a lot on reddit, misrendering things on mobile, but properly on desktop.
I'm a little sad the blog hasn't been updated in a while.
We already have this problem when we use the struct in the same module we declare it: https://play.rust-lang.org/?gist=837da124128fca2313092740192d2a2b&amp;version=stable
One key point that the OP got wrong is that the coherence rules apply at the *crate* level, not the module level. So they don't help *at all* when importing names.
I wrote a python script which automatically converts rust structs into c# and C++ structs for specific data types. It is SUPER dirty at the moment which is why I didn't share it. If you're interested I can give you a gist, but know that it's definitely rough
&gt; It's ~~dangerous~~ unsafe out there, take this
I'd love to take a look at it. I was thinking about creating my own in Rust as a research project.
Your spacemacs simulator is nice and all, but as someone who uses the spacebar to scroll down by a page, I would very much appreciate it if it had an option to deactivate it.
Yes, that‚Äôs fair.
sent you a PM.
The immediate red flag here is that you need one connection for each channel. Is there a reason for this? Subscribers often connect to multiple channels. I certainly don't want 10 open connections for subscribing to ten channels. A channel subscription should be a distinct concept from connections.
He explained paging so well, I‚Äôm quite sad he never did a tutorial on moving the kernel somewhere else in virtual memory. It‚Äôs the thing I‚Äôve been struggling with, and there seem to be literally no proper tutorials on how to do it in long mode :(
Top of my head: * Common cli tools: * ls * tree * find * cp * Grep * ‚Ä¶ * Games: * Breakout * Tetris * Sudoku * Tower Defense * Snake * ‚Ä¶ * CHIP-8 Emulator * Brainfuck Interpreter * Brainfuck Compiler * Game Of Life * Raytracer * Webserver; Find this at the end of the new book 2.0 * WebSocket chat server * GH or Reddit bot 
That is how it works on client role, the authentication relies on it. This is also what makes the message processing fast as we do not need to authenticate frames after the first one. I personally do not see handling separate connection per channel as a burden for a client, using a socket per channel is quite straightforward. Nevertheless, if you need to optimize here, Mles may not be the best choice for your use case.
Pretty much anything that would be amenable to C++ would also be amenable to Rust, with the added benefits of memory safety (security) and speed (comparable to C in many cases).
Think about the kind of project you would choose C++ for. Game, daemon, service, emulator, compiler, tool, database, etc. - there are plenty of possibilities. C++ is usually reached for when there is a need for complete control over the memory and performance, and the exact same niche is targeted by Rust.
I whipped this up to be potentially useful when setting gdb substitution paths for `std` sources in `rust-gdb`: https://github.com/rust-lang/rust/pull/44558 Its also a nice little example of how to use [`gimli`](https://github.com/gimli-rs/gimli)
Molten now parses and reproduces any TOML file correctly (AFAICT - it will have to be fuzzed). Next steps are to try out variations of the API, and consolidate error reporting!
Now I want a *llimeriq* about two strings walking into a borrow checker...
So as a rust newbie I have to basically know which types implement which traits ahead of time?
Is there a Rust port of cucumber yet?
Thank you! I've been looking for something like this :)
This feels like too much magic to me: depending on where a trait is implemented, it becomes special in yet another way. I would need to read a full RFC about this with all the corner cases to know how I feel about it, but the feature I dislike most from C++ is actually overloading + ADL, and this brings Rust a little bit into that direction. I am not saying this should not be pursued, but rather, that the RFC must be very convincing. 
Hold on... Do you mean to say rust has support for web services ? Like std library support ? Wow. This should be fun.
I know this is not how it works, but is there a place where developers can advertise themselves into willing to work in some Rust projects for companies/research institutions?
Not that it likely matters, but when I saw this in TWIR, I thought it was some kind of a tuple syntax, where you could assign part of a tuple and leave the rest. E.g. let tup = (1, 2, 3); let (x,), rest ..= tup; It seemed a bit odd, but I was intrigued. Then it seemed like it was just an argument about `..` vs `...` and I was underwhelmed and really dislike the syntax. However, I doubt we'll want to use `..=` for anything else, so I guess I don't care too much.
And of *course* only one of them is an internship.
See the [std::net](https://doc.rust-lang.org/std/net/) module for the primitives required to build a basic web server. Like I mentioned, the last chapter of the [new book](https://doc.rust-lang.org/book/second-edition/) contains a great walk-through on how to make one. Beyond that, you can use an external crate like Hyper for more serious applications. Note that since pulling in dependencies via Cargo is such a breeze, it's not that big a deal whether something is included in `std` or not: Experimenting with a new crate is just one copy/paste away. Something you should quite enjoy as a C++ dev!
it's helpful to compile all your switch code with -fPIC so it works both at the new location and the old.
Oh that looks nice. I've been learning openGL using Gfx. Are you using Gfx or doing direct graphics API calls? 
Thanks, i'm doing it directly as its what i've learned (plus I started this a while ago)
And they can be added later as well breaking code without breaking SemVer. Rust has honestly kind of worked itself into a pickle here which is also why specialization still is not super satisfactory with its whole module system but a lot of languages do this. I wouldn't mind a module system which is designed like this: - every binding a module exports _must_ be explicitly imported individually. Importing `*` is not allowed to avoid this - however modules can export sets of bindings with a name so that you can easily import all useful things at once - but adding any elements to such a set counts as a change in the public interface of the module and requires a major version change - adding a new set however does not because the set has to be explicitly imported again. The result is that new bindings can be added into a module but they can never silently be introduced and break things. Right now in Rust say you have `foo.bar()` with `Foo : Deref&lt;Target=Baz&gt;` and `Baz::bar` existing with `foo.bar()` actually being `Baz::bar(&amp;foo)`. Let's say that `Foo::bar` is actually added than which is a completely different method that shares a name but the same signature and boom without SemVer updating the code breaks‚Äîpretty undesirable.
But that has its own problems, and all the switch code is in assembly anyways, so it would be me keeping it PI. Instead, I‚Äôm trying to place a bootstrap with physical memory addresses in the ELF that sets up identity paging and enters long mode, then sets up the real page tables for the higher half (doing it in PM is a PITA because the addresses don‚Äôt fit in 32 bits :() and jumps to a proper virtual memory address. It seems a bit hacky and doesn‚Äôt work yet but oh well üôÉ
Fwiw I work for a fortune 500 company and we have 4 devs working on a Rust project - with more on the way. All of the hires have been internal so far - and a number of folks internally are already queued up for future work. It's my hope that we continue to expand and start hiring from outside the company in 2019. I know that seems like an eternity, but large companies sometimes change so very slowly... 
Sure, why not. In a Rust program, two `String`s Of varied upbringings Wandered recklessly Into `borrowck` Which stopped compiling all things.
Never change.
LALRPOP, [pest](https://github.com/pest-parser/pest), [combine](https://github.com/Marwes/combine/) and [rust-peg](https://github.com/kevinmehall/rust-peg) are all good options. I found the latter the easiest to get my head around, but that's probably cause I like PEG grammars. [nom](https://github.com/Geal/nom/) is another very popular parser crate (possibly the most popular?), but I kinda feel like it suits binary formats better than language parsing. There's definitely more choices out there, but those are the ones I've tried :) Also, here's some example projects: * [Gluon](https://github.com/gluon-lang/gluon) * [Dyon](https://github.com/PistonDevelopers/dyon) * [Ein](https://github.com/17cupsofcoffee/ein) (this one is mine, excuse the plug :p very early in development)
Have a look at https://github.com/flosse/rust-os-comparison/ :)
&gt; they can be added later as well breaking code without breaking SemVer But if you make such a change that introduces a problem/ambiguity in the interface, then you _are_ breaking semver aren't you? (because you _are_ affecting the existing interface)
I've personally found `larlpop` a joy to work with; would wholly recommend.
A question: a time ago someone mentioned on this sub that LLVM currently doesn't use the noalias information from rust, because of a bug in LLVM. This should have been fixed (supposedly) and should ship with LLVM 6.0 (which isn't released yet). Any news on this? Is there a way to use Rust with the latest LLVM version? I just wanted to ask this because it says LLVM 4.0.1, but LLVM 5.0 has already been released. I am not a pro in how these things connect together - is LLVM installed as a seperate library when you install the compiler or is it built into rustc itself?
Won't do.
That particular issue is [rust#31681](https://github.com/rust-lang/rust/issues/31681). For Rust and LLVM 5, see [rust#43370](https://github.com/rust-lang/rust/issues/43370), but it sounds like the noalias *might* actually be feasible with 4.0. The timing of LLVM 5 was just too close for us to feel comfortable packaging it right away in these toolsets -- and Rust doesn't support it yet anyway. :) edit: Oh, and yes we're shipping LLVM as a separate library used by rustc. When you get rustc from rustup or rust-lang.org, LLVM is statically compiled into `librustc_llvm-*.so`.
I think trying to replace `toml` in any other crate would help straighten out the API. I'd suggest [cargo-edit](https://crates.io/crates/cargo-edit).
[This thread](https://www.reddit.com/r/rust/comments/6w6vak/writing_a_pl_in_rust_lalrpop_or_nom_or/) from last month has tons of good comments. I suggest you go through them first and then make a decision. I think that the choice boils down to personal preference more than anything else; many people seem to be happy with LALRPOP and it can definitely work for writing a PL.
Indeed - that's always been the plan!
Is your company on the Friends of Rust page yet? https://www.rust-lang.org/en-US/friends.html If not, please consider doing so, as it's up to almost 100 companies and I'd like to break that milestone. :)
I had a very light overview of how the BN syntax works and I found LALRPOP pretty easy to get into once I learned some of its quirks. Definitely better than rolling your own parser!
Do you know if this is mentioned anywhere or if we can ping someone who knows? This would be big if it happened!
Are you involved with getting Rust packaged for RHEL? If so, thank you and your colleagues so much for your efforts! I have a roommate who works at Red Hat, and he says that there's tons of internal pressure against adding any new toolchains, and that Rust might only have a chance due to the next Firefox ESR requiring it. :P
Which existing code?
Are channels implicitly single topic in the protocol? I know there are a fair number of pub-sub implementations where you can multiplex multiple topics into a single subscription entity. That tends to resolve any issues with having to make many subscriptions for a given purpose (though it obviously creates a configuration burden at some level and maybe the reference implementation doesn't support it).
Yes, I'm the primary toolchain engineer for this rust-toolset. I'm glad you're excited, and I hope we'll get some good customer feedback to convince management that this is worth our time! And yes, Firefox ESR was a big motivator to get this ball rolling. :)
for the final bullet point, I think your `APIResponse` struct is almost entirely redundant since you're using it to contain rocket `Status` consts, _and_ http status code explanations. The `Status` consts already contain the explanations, which means maybe you don't even need the `APIResponse` to begin with.
Most likely database timezone should always be UTC, this allows you easier timezone conversions later.
can someone explain what the `.first::&lt;UserModel&gt;(&amp;*db)` part does?
Unless you specifically want to get experience with a library, I recommend hand-writing a recursive descent parser.
This is great, devtoolset is an amazing tool for getting access to newer libraries on old RHEL versions. couple questions: 1) Will Rust eventually make it in to the SCL version of devtoolset, for use with CentOS? 2) Will Rust be in the RHEL 6 release of devtoolset?
You might want to give [pest](https://github.com/pest-parser/pest) a look over, since one of its main purposes is to be beginner friendly.
I think it is worth your time! I've been maintaining [LLVM builds on Copr](https://copr.fedorainfracloud.org/coprs/alonid/llvm-5.0.0/) for CentOS and I've noticed quite a few users of them in the wild. 
It returns the first row of the results. `optional()` turns it into an Option.
1) CentOS SCLs are on my TODO list, yes. 2) For now, the product release of rust-toolset is only for RHEL 7. But we do have to get *something* in RHEL 6 for Firefox's sake, at least, and I'll make sure CentOS is covered here too.
Thanks, but i meant syntax wise. Why not just 'first().optional()'? 
Hmm... The more I think about this the more I find myself unsure whether to agree with you. If we have to use the language as it exists now, library writers (or really anyone who writes a public interface) should probably think about supplying a prelude, similar to `std::io::prelude`. But on the other hand I think Rust *is* doing the right thing by making each trait its own namespace. I wrote a quick singleton crate recently for my own and didn't hesitate to name the `init` method. In downstream code it's disambiguated from any other kind of initialization by being `singleton::Init::init`. It might be convenient to include the methods of a particularly core interface within the inherent `impl` of a type. (Can this be done with a `use` splat? That seems the most natural syntax. I can also see this confusing the compiler or being not allowed at all.) I suppose the question is whether downstream code should have the option of using a particular trait or not. It might be nice if there was a way for downstream code to import a trait for use on a specific type, rather than being imported for all types that implement it. . .
Can this please be in the next one? https://turbo.fish/
I would also add Bitfury to this list: https://jobs.dou.ua/companies/bitfury/vacancies/42171/ Location: Kiev, Ukraine
until someone introduces behavior that is `unsafe` per "The Rules"...
When calling a method you need a bit more awareness of where that method comes from than you would in other languages. For example, to call the `read_exact` io method, you need to have `Read` from `std::io` in scope where you make the method call. Alternatively, If you write a generic function with `&lt;R: std::io::Read&gt;`, then the methods of `Read` will be available on anything with type `R`. Same if you use a reference to a trait. If `r` has type `&amp;mut std::io::Read` then `r.read_exact` is clear enough for the compiler. Basically, to call a trait method you need to have an overt connection to the trait. Knowing that a value has a type `T` and that `T` implements `Tr` isn't enough to make the compiler assume that `value.trait_method` is referring to `Tr::trait_method`. Either the value must have a type that includes `Tr` or you must have `Tr` in scope. Remember that `use` is legal within function bodies. In practice this is only a minor rough spot. I promise. I can give examples too if you'd like.
Just looking at that tiny corner of the API, I would have made networks and hosts variants of a more abstract address enum.
I love LALRPOP for writing language parsers. I haven't tried out the alternatives, but LALRPOP makes for some very intuitive and (imo) self-documenting parsing code that can be shared easily between projects. Here's what I've used it with: * [Oasis](https://github.com/tcr/oasis), an example Lisp written in Rust using LALRPOP that should be a quick read * [Hoodlum](https://github.com/tcr/hoodlum), a Rust-like HDL which compiles to Verilog * [parser-haskell](https://github.com/tcr/corollary/tree/master/parser-haskell), A Rust library to parse Haskell code into an AST None of these are "stable" projects but I haven't outgrown the constraints that LALRPOP has yet.
Is punning UB or merely `unsafe`?
/r/rustjerk
This is on topic for /r/rustjerk/
Having a library shipped within the `std` namespace doesn't mean anything to Rust, because we have Cargo. Many critical libraries aren't included in Rust's `std`, but are officially sanctioned by the Rust team and distributed on Cargo, which is much more flexible than what could be done if it shipped in the standard library. If you install `cargo-edit` via `cargo install cargo-edit`, you can add dependencies from your command line just by executing `cargo add &lt;crate&gt;`. The latest version of the discovered crate will be automatically added to your `Cargo.toml`. If you want to develop web services, there's a number of different projects that you can look into. From highest level to least-highest: [Rocket](https://rocket.rs/), [Hyper](https://hyper.rs/), [Tokio](https://tokio.rs/). There's also some big things happening in this space regarding generators, await / async: - https://doc.rust-lang.org/nightly/unstable-book/language-features/generators.html - https://github.com/alexcrichton/futures-await
Standard library is minimalist but look at https://crates.io and http://www.arewewebyet.org
To specify the return type.
Beautiful. How did I come so close and yet still miss that? :-)
Are there any fun &amp; informative youtube channels focusing on Rust? Similar to how justforfunc focuses on Go
are there any benchmarks?
http://perf.rust-lang.org/compare.html?commit_a=0253d98382fa351d53880605a346d0ea2e941a07&amp;commit_b=b669ce1863e5451453545f892d1014eb16b9a878&amp;stat=instructions%3Au
Using the data structures from [`arena-tree`](https://github.com/kivikakk/comrak/blob/2b7a877406b58e788e585cbb750093e7d4dc42be/src/arena_tree.rs#L26-L33) as an example of a tree, something like the following could work. use serde::ser::{Serialize, Serializer, SerializeStruct, SerializeSeq}; impl&lt;'a, T&gt; Serialize for Node&lt;'a, T&gt; where T: Serialize { fn serialize&lt;S&gt;(&amp;self, serializer: S) -&gt; Result&lt;S::Ok, S::Error&gt; where S: Serializer { struct Children&lt;'r, 'a: 'r, T: 'a&gt;(Option&lt;&amp;'r Node&lt;'a, T&gt;&gt;); impl&lt;'r, 'a, T&gt; Serialize for Children&lt;'r, 'a, T&gt; where T: Serialize { fn serialize&lt;S&gt;(&amp;self, serializer: S) -&gt; Result&lt;S::Ok, S::Error&gt; where S: Serializer { let mut seq = serializer.serialize_seq(None)?; let mut cur = self.0; while cur.is_some() { let child = cur.unwrap(); seq.serialize_element(child)?; cur = child.next_sibling.get(); } seq.end() } } let mut node = serializer.serialize_struct("Node", 2)?; node.serialize_field("data", &amp;self.data)?; node.serialize_field("children", &amp;Children(self.first_child.get()))?; node.end() } } This gives you a straightforward JSON representation: { "data": "A", "children": [ { "data": B", "children": [] }, { "data": "C", "children": [] } ] }
If it builds without errors - assume some code uses it.
The kernel is farther along than the book, but not a ton. intermezzOS is a long-term project for me, so there's long gaps of time where I can't work on it. Hoping to get back to it soon.
Oh this is amazing! I was slowly starting to figure it out, but this helps tremendously. Also, thanks for your help on irc the other day. It's really appreciated. Wouldn't the `serializer.serialize_struct("Node", 2)?;` result in something like ``` Node: { "data": "C", "children": [] } ``` At least, that's what my experience has shown me it does so far.
/r/rustjerk for low signal posts.
http://perf.rust-lang.org/compare.html?commit_a=417ffc98dfc770c27f7f2d7430f0edf975576591&amp;commit_b=d7e73e4b1abe120520d1894b89c0e25469f41e69&amp;stat=instructions%3Au
I started writing a Fortran parser using it a week or so ago. Knew very little about parser generators before starting the project, but was able to get Hello World! parsing in no time. Would recommend.
I have to say the downvotes you got for this disappoint me. -9 is definitely excessive.
I'm not aware of one.
I've wondered this a few times when seeing changes merged but then not yet reflected in nightly: how long between something being merged to master and appearing in nightly via rustup? Also - does using master instead of nightly mean a 1-hour compilation process? Or is it easier than that? 
 float* x = 3.0; int* y = (int *)x; *y; // ub This is indeed undefined behaviour in both C and C++ as it violates the strict aliasing rule.
Seems to be down with an application error.
New builds are released each night that a build can be built.
This is the best explanation I've seen so far. Thanks! 
Must have X years experience or know someone üòâ
Is it comfortable placed lower on the phone like that?
This subreddit is for the rust programming language. You're probably looking for /r/playrust
&gt;The **Go language** (golang 1.8.3) is expressive, concise, clean, and efficient. Its concurrency mechanisms make it easy to write programs that get the most out of multicore and networked machines, while **its novel type system enables flexible and modular program construction.** Hmmm. 
&gt; Also - does using master instead of nightly mean a 1-hour compilation process? Or is it easier than that? Generally the compilation process takes long, yes, although e.g. LLVM doesn't need to be rebuilt very often so most times you don't need to spend time on that. Whether its one hour or more or less greatly depends on your hardware. There are builds created for every merged PR. Its in fact the same mechanism that creates the nighlies: once every night the latest build is chosen and made available via rustup. In order to allow to find out what commit caused a regression, the builds are additionally uploaded to another place (its one build per merged PR, that allows very good bisectionability!). You can get the binaries from there, but there is no tool available that does this for end users, so you'd have to do stuff manually. I'd say its probably easiest to just wait until the new nightly contains the commit. If you are still interested, I suggest you read this source code: https://github.com/Mark-Simulacrum/bisect-rust/blob/master/src/sysroot.rs
Not even type systems are safe from newspeak.
&gt; "Red/Green dependency tracking" is what we call the improved tracking algorithm for incremental compilation. The main difference to the algorithm used at the moment is improved accuracy because it can recover from "false positives", that is, it can stop cache invalidation short if a potentially changed value turns out to not have changed after all. https://github.com/rust-lang/rust/issues/42293 For those of us not following rust development _that_ closely.
&gt;I want to implement a language as a project to learn both about Rust and how the various parts work together to make an interpreter or compiler for a language. Rust may not be fully suitable for this project for a variety of reasons. Of course, if you'd like to learn Rust *and* something of language design at the same time then it's your only option :) LALRPOP is pretty theoretical, heavy-duty solution from what I understand. I've used [nom](https://github.com/Geal/nom) in the past and it would be practical for a small toy language project (I just used it to write a JSON parser).
I belive nowadays it's the last successful build of the day. That was the plan at least.
Fascinating, I didn't realize such a thing was even possible! Why does Rust's producer line pretend to be clang, is it some sort of User Agent-esque shenanigan? The C lines in the example output include compiler flags, which is incredible, but I don't see any flags in the Rust lines, is that a problem with Rust or were no flags passed?
Remote attestation is designed to detect such emulation/simulation. Only real hardware can do that.
https://github.com/keeslinp/qml_todo Here is the todo app. I'm not sure good at QML yet so I didn't worry about the UI too much. The rust part is the same either way. I'll take the time to figure it out when I have more time. Any thoughts you have would be appreciated :).
Should be back up now. It looks like someone visited the compare page with an invalid commit, which unfortunately seems to crash perf.rlo today. I've filed https://github.com/rust-lang-nursery/rustc-perf/issues/155 to track fixing this. Thanks for noting!
https://www.reddit.com/r/rust/comments/71cs0a/prealpha_of_libservo_available/ 
Since the server with the benchmarks seems to be crashing: [[benchmark details](https://hastebin.com/orubegepej.erl)] crate | before | after | % change -----------------------------------|----------------------------------|-----------------------------------|-------- futures | 17573116553.00 | 17402068961.00 | -1.0% hellowo | 1186197581.00 | 1174191003.00 | -1.0% html5ev | 17065296934.00 | 16992053554.00 | -0.4% hyper.0 | 23191014628.00 | 22965195061.00 | -1.0% inflate | 23442009453.00 | 23400602191.00 | -0.2% issue-2 | 14478534393.00 | 14429109593.00 | -0.3% issue-3.. | 11841046753.00 | 11391884260.00 | -3.8% issue-3.. | 1775828807.00 | 1752115129.00 | -1.3% issue-3.. | 8347429265.00 | 8343713836.00 | -0.0% issue-4 | 2762321229.00 | 2741184463.00 | -0.8% jld-day | 6811722976.00 | 6747061948.00 | -0.9% piston- | 48055888314.00 | 47617025110.00 | -0.9% regex-0 | 29276791183.00 | 29129886431.00 | -0.5% regex-0.. | 51182823071.00 | 44365257326.00 | -13.3% regex-0 | 22570828582.00 | 13957205209.00 | -38.2% regex-0.. | 16522003186.00 | 8022758267.00 | -51.4% regex-0 | 18678741487.00 | 10657879049.00 | -42.9% regex-0 | 25922419444.00 | 17967531352.00 | -30.7% regex-0.. | 16454506456.00 | 8396347335.00 | -49.0% regex-0 | 50207176798.00 | 32279230790.00 | -35.7% regex-0 | 50721134308.00 | 31954708380.00 | -37.0% regex-0.. | 16529778244.00 | 7687935193.00 | -53.5% regex.0 | 11292762032.00 | 11237820355.00 | -0.5% rust-en | 9429165663.00 | 9374309550.00 | -0.6% syntex- | 125446725632.00 | 124752975587.00 | -0.6% syntex- | 269069610913.00 | 254968926284.00 | -5.2% syntex- | 116783795929.00 | 48568072847.00 | -58.4% tokio-w | 27410841630.00 | 26838708207.00 | -2.1% tokio-w | 52364463021.00 | 47325822137.00 | -9.6% tokio-w | 18075499177.00 | 9465158480.00 | -47.6% tokio-w.. | 52776409405.00 | 45139987308.00 | -14.5% tuple-s | 24328814426.00 | 24333958984.00 | 0.0% Commits Commit A: 0253d98382fa351d53880605a346d0ea2e941a07 Commit B: b669ce1863e5451453545f892d1014eb16b9a878 Submit Updated as of: 10/4/2017, 1:14:41 PM 
Yes, a channel is a single topic at the moment. When I think about it, there could be a possibility to inform e.g. a list of channels during subscription which would multiplex several channels on a connection. This would also provide the possibility really have several channels on one connection. This could be an extension for the current implementation and for the Mles protocol itself too, if it is seen as a valuable feature to have. In practice this would be a significant change in the protocol logic and cause major processing load to the Mles server handling. So I do not see this really as a feasible extension at the moment.
It was likely me. The commit I copied had an additional space at the end. :P
What would you suggest instead of Rust? Haskell?
It could be 24 hours from the time it is merged until the next nightly is released with the changes integrated, assuming the build doesn't fail. Each merge isn't released instantly into the current nightly. The changes were only merged 5 hours ago, so hopefully tomorrow!
ah - ok thanks - just wanted to make sure it wasn't something longer ... I think I can wait until tomorrow haha
Worked well for the Ion Shell.
It appears to a user agent shenanigan for gdb: https://github.com/rust-lang/rust/issues/41252 Source is [here](https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src/librustc_trans/debuginfo/metadata.rs#L796), looks like Rust doesn't give the flags.
Ha, I even commented on that issue, I thought this seemed familiar... :P
Haskell or OCaml are the only languages I've seen used to implement compilers, besides those that are self-hosting. I have experience with Haskell so I'm partial to it, but really if it's been successfully used to write a compiler for anything other than itself it's fine. The canonical implementation of Perl was actually written in Haskell for a short time.
6502/65CE02 emulator and monitor. First more-or-less *real* Rust project. Development platform: Ubuntu 17.04, VSCode. 
Yeah, I saw some threads recommending Haskell or OCaml while researching for resources. That's why I asked. But when you say rust may not be fully suitable, what do you mean? What are the limitations or drawbacks of using Rust for writing a compiler?
Not std support, but the next best thing. Rust's std lib is kept intentionally small to support APIs evolving and finding the best solution independent of the language's growth. There isn't even random number generation in the standard library, that's in the 'rand' crate. The good part is that rust's package manage, cargo, ties everything together nicely - and manages dependencies sanely (no package upgrades until you ask for it, and then keeping to backwards-compatible versions unless you change your package config).
Is encoding really faster, or does the tool simply have a higher output per second because it generates three bytes of output for every byte of input? 
Thanks for your work on this!
From the co creator of emotifuck, I fully support the continuation of Emoji programs written with Rust.
As a nightly user what do I do to take advantage of that? (e.g. what parameters to pass to Cargo?)
Well, from a learning perspective, there are a lot of things that Haskell has very good libraries for (e.g. trifecta - parsers w/ good errors, recursion schemes, optimization) so you get to see various paradigms done *well*, which I think can be valuable. Compilers are also one the few places where the bulk of the difficulty is not in performance or IO but rather manipulating complicated discrete data structures. So things like "separating pure/impure code" matter a lot more. 
how do I collect the results of a future vector without blocking? (just a wait for ALL to complete async... then check values sort of thing)
Hmmm, I have been trying to find good resources on trifecta that is suitable for someone not that advanced with Haskell. Couldn't find much, megaparsec though seems to have good docs. 
I wrote a prolog parser using lalrpop. It's pretty simple. Here it is: * The parser: https://github.com/dagit/rust-prolog/blob/master/src/parser.lalrpop * The lexer: https://github.com/dagit/rust-prolog/blob/master/src/lexer.rs
Hey OP, my work finally open sourced the binary analysis tool we've been developing. Ours is written in Haskell. I think I mentioned it when you first did your announcement: https://github.com/galoisinc/macaw Just figured I would pass on the link.
The first performance test puts pv after encoding, so that measures the output as per you second suggestion. The second performance test measures after both encoding and decoding and the emoji encoder is still faster (not 3x though, 223 MiB/s vs 176 MiB/s).
Are you referring to the `Node:` in the front, or to the empty array of children? The `Node:` part is not valid JSON so serde_json would never give you that. Maybe it is from printing with `"Node: {}"`. The children are handled by the inner Serialize impl which starts with `first_child` and iterates through the chain of `next_sibling` references to serialize each one.
With the exception of GUIs I'd probably say. 
You want /r/playrust
Really? Is that due to libraries or is there something about C++ that makes it better.
You might check and see if some of the primitives in [crossbeam](https://docs.rs/crossbeam/0.3.0/crossbeam/sync/index.html) meet your needs.
GUI libraries have for a long time been designed around classical inheritance, which is a language feature in C++, but not in Rust. I'd say we as a community are still searching for how we want GUI code to work in Rust. That, and C++ has multiple mature libraries for GUIs :)
I have seen some experienced developers try out Rust the way they have been trying out all kinds of languages over the years, and this has been by implementing some data structures. It should be noted that many data structures are _not_ good starting points to get to know Rust, because borrowing and circular references do not work well together. Famously, doubly-linked-lists are considered easy to get right in C++, yet difficult to express in Rust.
Hello! Somebody knows how to get screen width/height using Rust?
Is the thread local rng (used by the uuid lib) cryptographically secure? The rand docs tell you to [use OsRng for crypto](https://doc.rust-lang.org/rand/rand/index.html#cryptographic-security), and that "The other random number generators provided by this module are not suitable for such purposes." I know thread_rng is seeded from /dev/urandom, but this doesn't mean that calculating the next/previous value in a sequence of UUIDs isn't trivial.
Next step, a procedural macro to code in emoji inside .rs files.
I was expecting semantic substitution based on the meaning of the text and was disappointed :(
Found it! https://docs.rs/winit/0.8.2/winit/index.html
I solved the 18th project euler problem with rust. I think I am getting hang with rust. Here is how I solved it. https://pastebin.com/CqKBk2wR If anybody has any crates recommendations for beginners like myself, please tell me.
Cool!
&gt; What alternative would you suggest? Given people's concern over `..`, my suggestion would be to just kill the syntax for inclusive ranges. Coming across code of the form `a..b+1` once every so often is less of a mental burden than having to learn an additional magic sigil that kind of makes sense, maybe, in the context of a discussion on inclusive ranges, but looks totally weird in code in the wild. We're not in a race with C++ to have the most syntax, after all. Perhaps we're getting a bit too merge-happy. I feel this is a case where conservatively sticking to the status quo might have been the best option. It's also noteworthy that, judging by the comments, this flew under the radar of a lot of people. Why wasn't this issue's RFC in the TWiR for the entire duration between inception and final decision?
`CARGO_INCREMENTAL=1 cargo &lt;command&gt;`, same as before. What‚Äôs changed are compiler implementation details.
Worth noting that emojis aren't valid tokens in Rust, so quoting would be necessary.
This only works with integers and has overflow issues.
I've only used Rocket and Iron for toy projects, but my most extensive experience was in writing the "library" or "business logic" part of the code in Rust, then using Neon to have an interface fronted by a Node.js server. In my experience, building the server with Node afforded me a lot more flexibility and tools/components were just ready-made. Rust does not quite have that level of community libraries yet, so a lot more has to be done manually. Once my project has settled and I am certain of what I want, I do plan on rewriting the front server in Rust without Node.js at all.
Sounds like you are looking for the [`JoinAll` future](https://docs.rs/futures/0.1.16/futures/future/struct.JoinAll.html).
Also, for a follow-up to that chapter, I've been taking the code and making it a bit more production-ready over at https://github.com/steveklabnik/simple-server/
Oracle just derided open source in a letter to the US government, so you'll forgive me for not being excited right now. Maybe I'll regain my enthusiasm someday.
Bummer! :(
The Rust-relevance appears to be [Railcar](https://github.com/oracle/railcar), a replacement for the standard `runc` Linux container runtime that's written in Rust instead of Go.
Companies like Oracle are so big that you find different opinions throughout a wide spectrum. There are often internal battles regarding many subjects ‚Äì like open source. There is often a legit group of people supporting stuff like open source even if other groups/departments and/or the hole company is against it. At the end we're all just people trying to push our own (possibly open source) agenda to make things better. I have a neutral view on it, after all i don't see bad things happening if big companies adopt Rust and appreciate every knowledge that flows back (maybe as feedback etc.) there are mostly highly skilled people working at this stuff and possibly do not agree with everything the company does. 
Crates to *use* or to *work on*?
To use. Something that I will have fun working on and learn at the same time(not that project euler problems are boring).
vem_ is known to be a *very* strong Haskell supporter. Haskell *is* a mature, excellent functional programming language, but Rust has advantages in many areas. Being a more traditional, imperative language tremendously lowers the barrier to entry compared to Haskell. Rust also gives you maximum performance, since you can control allocations and everything else on a hot code path, but you can still use `Rc` any time you want to reduce the burden of the borrow checker. Among other things. There are many great things about Rust, from the documentation to the crates ecosystem. Haskell now has Stack, which is a huge improvement over what they had until recently, but it has some "gotchas" in my experience, particularly regarding each project directly managing the installed version of Haskell. Haskell is an old language, which brings logistical baggage, and Stack reflects that. I personally find that Rust strikes a better balance than Haskell. vem_ will *never* say that a language has a better overall balance than Haskell, in my experience having discussions with them on Reddit.
I'm not using these libraries much, so there may be better solution... Note that Tokio-dependent futures need to be spawned into Tokio's executor (`tokio_core::reactor::Core`) so that their IO actions are performed by its event loop. They cannot be magically parallelized with `CpuPool`, nor completed by using `.wait()`. extern crate curl; extern crate futures; extern crate tokio_core; extern crate tokio_curl; use tokio_core::reactor::Core; use futures::{Future, Stream}; use futures::sync::mpsc; use tokio_curl::Session; use curl::easy::Easy; use std::fs::File; use std::io::{BufWriter, Write}; use std::sync::{Arc, Mutex}; use std::thread; use std::mem; fn make_file(x: i32, data: &amp;[u8]) -&gt; usize { let f = File::create(format!("./data/{}.txt", x)).expect("Unable to open file"); let mut writer = BufWriter::new(&amp;f); writer.write_all(data).unwrap(); data.len() } fn collect_request( x: i32, url: &amp;str, sess: &amp;Session, ) -&gt; Box&lt;Future&lt;Item = i32, Error = tokio_curl::PerformError&gt;&gt; { let buf = Arc::new(Mutex::new(Vec::new())); let mut easy = Easy::new(); easy.get(true).unwrap(); easy.url(url).unwrap(); { let buf = Arc::clone(&amp;buf); easy.write_function(move |data| { let mut buf = buf.lock().unwrap(); buf.extend(data); Ok(data.len()) }).unwrap(); } Box::new(sess.perform(easy).and_then(move |_| { let buf = buf.lock().unwrap(); make_file(x, buf.as_slice()); Ok(x) })) } fn main() { let url = "https://www.example.com"; let (tx, rx) = mpsc::channel(20); let threads = (0..4) .map(|n| { let mut tx = tx.clone(); thread::spawn(move || { let mut core = Core::new().unwrap(); let session = Session::new(core.handle()); let reqs = futures::stream::futures_unordered( (n * 5..n * 5 + 5).map(|x| collect_request(x, url, &amp;session)), ); core.run(reqs.for_each(move |x| tx.try_send(x).map_err(|e| panic!("{:?}", e)))) .unwrap(); }) }) .collect::&lt;Vec&lt;_&gt;&gt;(); // drop an excess Sender so that `rx` don't wait forever mem::drop(tx); rx.for_each(|x| { println!("Done {}", x); Ok(()) }).wait() .unwrap(); for t in threads { t.join().unwrap(); } } 
I've definitely seen C and C++ used to implement non-self-hosting compilers. I think I've seen C# and Java used as well. OCaml is absolutely a favorite of compiler writers, but I've never heard of Haskell being favored for use in that capacity. I'm sure it's *capable* of it, of course, but it's hardly a common pattern that I've observed. What non-toy languages have had their compiler written in Haskell?
Not that I'm aware of, no... Would be nice though!
PureScript, Idris, Agda, Ermine, off the top of my head (sure these are all pretty "Haskell-like", but I don't think that should disqualify them any more than a C-family language compiler implemented in a C-family language)
I don't think that should disqualify them, but they should be taken with a grain of salt. Someone who is building a better Haskell is likely motivated by their existing love for Haskell, which means they would use Haskell to write the compiler for their language. OCaml was used to write Rust, Facebook's Hack language, the venerable Haxe language, the Opa language, Coq, the Flow type analyzer for JavaScript (not quite a compiler, but 95% of the way there), and other compilers for non-ML-family languages. If you're writing Haskell-but-better, you're obviously going to reach for Haskell. If you do a good enough job cloning Haskell, it'll even make porting the compiler to your new language super easy, so there's extra motivation. What's really interesting is if someone is writing something that *isn't* heavily influenced by Haskell, and they reach for Haskell to write the compiler.
You're looking for /r/playrust.
Why do you say never to use UUIDs? Are you aware that uuid4 is a completely random number?
If the claim is "OCaml is unusually popular for writing compilers", sure. If the claim is "Haskell is unusually unpopular for writing compilers", I'm not so sure. (Not like it's a super-important point either way.)
FYI, this is likely for [Exonum](https://github.com/exonum/exonum).
If I'm reading that correctly, you're comparing two commits neither of which have red-green in them.
/u/vem_'s original quote was as follows: &gt; Haskell or OCaml are the only languages I've seen used to implement compilers, besides those that are self-hosting. Which is clearly (to me) making the claim that Haskell is unusually popular for writing compilers, when there is no forthcoming evidence to support this. OCaml *is* unusually popular for that task, and vem_ seems to have wanted Haskell to be viewed that way too, so they lumped Haskell in with OCaml, and then somehow decided that no other language is used to write compilers, when many compilers are written in C or C++ or Java or whatever. I would argue *many* more popular compilers either are or were written in C or C++ than have ever been written in Haskell. But, definitely, Haskell has been used to write some compilers. It's just not an unusually popular choice. Swift, PHP, Python, Ruby, Go, and many other very well known languages have been written in either C or C++. I just don't want to see /u/lostPoncho deceived into believing Haskell and OCaml are the only languages used to write other languages, because they absolutely aren't, and Haskell is not even some popular choice for compiler writers like OCaml, if it's a popularity contest that OP is interested in.
I realized this about ten minutes after posting üòÖ. I guess I could throw rayon at the problem to give me a little more speed when dealing with larger files. I'm still pretty happy I was able to get a UTF-8 based algorithm in the same ballpark as GNU base64 in a weekend or two.
That's great! I was waiting for twitter to give me 280 chars but I guess I'll use this for longer tweets in the meantime
It should work if you don't build the Rust libraries with LTO. At least it did when I tried it. I opened an issue about it a month ago: https://github.com/rust-lang/rust/issues/44322 (Looks like I forgot to link a way to reproduce it, I guess I'll do that later today) So yeah, anyone releasing any static / shared(?) Rust libraries on apt or similar package managers should probably deactivate LTO for the time being (looking at you librsvg).
I'm curious about that too. If a UUID is generated with cryptographically-secure random number generator, is it still something you shouldn't use for authentication tokens?
damn, it doesn't allow for longer tweets :( still way cooler than rot13 though
Meh, I‚Äôll wait for base 256 to provide a one-to-one mapping between bytes and emoji.
They were sponsoring RustFest Kyiv and the colleagues there were pretty great folks.
Yeah but when the leadership of the company derides it is kind of hard to get excited about anything they do. Oh cool maybe this one project will happen, then they'll kill it off like they did Solaris. Look I bet there's great engineers passing this stuff, but it won't matter if leadership is against it. Oracle has a terrible track record and it doesn't look like they're going to change so I can't get excited about any of it. They have a huge image problem amongst engineers.
Looks good! Builds and runs fine and the code's easy to read. I guess next step is load/save and indeed some QML tweaking.
As someone who hasn't spent any time with rust, is there an easy way for me to install this in order to test it out?
It's sound advice. Use a crypto library if you want secure tokens, not one that's just supposed to create unique ones. Unless the UUID library makes explicit guarantees, you can't assume that the author chose to use a CSPRNG. They might care a lot more about e.g. performance than whether the generated UUIDs are predictable.
[The RFC about UUID](https://tools.ietf.org/html/rfc4122#section-6) is very clear about that topic in section 6 &gt; \6. Security Considerations &gt; &gt; Do not assume that UUIDs are hard to guess; they should not be used as security capabilities (identifiers whose mere possession grants access), for example. A predictable random number source will exacerbate the situation. &gt; &gt; Do not assume that it is easy to determine if a UUID has been slightly transposed in order to redirect a reference to another object. Humans do not have the ability to easily check the integrity of a UUID by simply glancing at it. &gt; &gt; Distributed applications generating UUIDs at a variety of hosts must be willing to rely on the random number source at all hosts. If this is not feasible, the namespace variant should be used. in [Section 4.4](https://tools.ietf.org/html/rfc4122#section-4.4) it is also very clear, that UUID version 4 is not completely random!
This is pretty awesome, I just rebased my rust -&gt; spirv compiler and the built times for an incremental change went down from 21s to 9.7s. 
I hadn't even noticed. One of the benefits of using a JavaScript whitelisting extension like uMatrix, I suppose. It kills off most silly attempts to break browser UX consistency.
I think you need to install rust. These commands might work (didn't try it myself) curl https://sh.rustup.rs -sSf | sh # ... go through rustup setup.... git clone https://github.com/AdamNiederer/base100.git cd base100 cargo run # note: IIRC, cargo install would install it to your system
So you're objecting to the fact that there are 122 bits instead of 128 bits of randomness in a uuid4?
You have `impl Bar` twice in your example. The second is meant to be Baz, right?
This will install it for the current user. Be sure to add `~/.cargo/bin` to your path: ```` $ cargo install base100 ````
Yeah, I imagine loading and saving will be easier once we've got the function binding working. Have you already started that or would you like me to take a crack at it?
The build is available -- ~~see the top-level reply by /u/MaikKlein~~. EDIT: Whoops, should have paid attention to "rebase" there! I just did some commit log hunting, nightly from 2017-10-04 is d7e73e4b1abe120520d1894b89c0e25469f41e69, which is ahead of the red/green final commit at 0454a41bec547b28526cdb511f05372c80cb7277. Valid, but not for the reasons I originally thought.
cc /u/CompSocChris You don't have to `git clone` or anything, just install rust (with the `curl` command) and then `cargo install base100`
Just getting started on making a charting / graphing crate for rust. I'm just getting started, so there isn't much (yet!), but I think it'll be fun and help me learn Rust, since I'm still pretty new to the language: https://github.com/saresend/Grust
I actually do have a 1:1 mapping between bytes and emoji right now - I'm working on using the full 1024-character emoji spectrum to achieve an 80% reduction in printable characters for any given input.
By all accounts, Oracle has been a good steward of OpenJDK. So Oracle has both bad and good track record. I agree Oracle has a image problem. I don't agree it is entirely justified.
No I don't use nightly, I rebased from the current master. I use my own fork of rustc.
How do I get the panic message with a catch_unwind? use std::panic; fn main() { let err = panic::catch_unwind(|| { panic!("message"); }).unwrap_err(); println!("{:?}", err); } My code runs an infinite loop and watches for certain processes to be created (Windows, if it matters). In response it creates a thread to monitor this process. This monitor itself runs an infinite loop to do some processing and checking for certain events in the process. However occasionally my code panics but I've no clue how to get it to print a stack trace (remember, it's not on the main thread, I don't even have a console attached at that point so logging to file is what I got). I attempted to solve my problem with a catch_unwind, but all I get from it is the message "Any", which isn't helpful. Any help?
I've been using a swagger server generator for my API server written in Go and _fully_ endorse that sort of workflow. It's a lot easier to keep your API documentation up-to-date and accurate if your workflow is: 1. Write/update API spec 1. Generate valid, correct HTTP server boilerplate from spec 1. Wire up the generated code to your actual native functions
It's a nice article, but I cannot find any (explicit) mention of Rust. Would linkerd be in Rust?
See [set_hook](https://doc.rust-lang.org/std/panic/fn.set_hook.html) which will pass a [PanicInfo](https://doc.rust-lang.org/std/panic/struct.PanicInfo.html) to the closure it calls; you can then use its `.location()` and `.payload()` methods for your logging. Edit: The reason you get `Any` is that a trait object is being returned; to get a useful message from it, you have to downcast it - convert it back to a known type. The second code example on the PanicInfo page shows you how to do this 
Linkerd is not in Rust, but they have a related project that is, as well as another Rust library: https://github.com/linkerd?language=rust In general, Boyant is making great moves to be contributors to the Rust ecosystem; they've been hiring Rust devs, hacking on well-known open source libraries, etc. That said, the explicit lack of a Rust mention makes this story borderline-offtopic IMO, but hearing that Boyant is doing well is nice.
It's always nice when there's no trade-off: improvements only all across the board!
wow thank you! have been trying to wrap my head around the executor part and your answer makes a lot of sense. The only part that confuses me is the channel. So I thought about this the other day as a means to collect the values but doees rx.for_each block other threads? Or its the same as in go where it just waits around until a message is available THEN spits out a result?
Can you make a single Rust crate that depends on both of the libraries, compile *that* to a staticlib using Cargo, and link that single staticlib into your app? This is what we do for linking multiple Rust libraries into Firefox.
As an alternative to u/l-arkham's solution: you can try downcasting the `Any` value you receive to a `&amp;'static str`: https://play.rust-lang.org/?gist=25fabfd1baa3d4b7ebef1f116dc12844&amp;version=stable If you are managing panics in your own code, you can make sure that you'll only panic with a `&amp;str`. Although even in 3rd party code, `&amp;str` or `String` is the most likely value to panic with. Check the documentation for `Any` for more useful stuff: https://doc.rust-lang.org/std/any/trait.Any.html
Ah! I knew I was probably missing some context, thanks.
Thanks, I saw it returned a boxed `Any`, but the docs doesn't tell me what it's actually returning so I don't know what to downcast it to. I wonder why this API is this way in the first place? Surely the Rust team can decide to return a concrete type (eg `PanicInfo`). The docs for `PanicInfo` even say that its payload probably `&amp;str` or `String` but doesn't say when it'll return either one. Can you even downcast_ref to `&amp;str` on a boxed `Any` containing a `String` (edit: no, you cannot)? (I know you can't `Any` to see if it implements a trait eg `Error`). Any more information on this?
You can use the `.is()` method provided by the [Any trait](https://doc.rust-lang.org/std/any/trait.Any.html) to check what you can downcast it to before trying. You can also chain `if let`s on `downcast_ref()`. I agree it could be more ergonomic, not sure what the initial motivation was. Maybe someone knows?
That's quite broad, but maybe [rayon](https://github.com/nikomatsakis/rayon)? It makes for very easy parallelization, one of Rust's strengths and may be relevant to speed up some Project Euler solutions. (Do they tend to run for long? I assume some do)
No, i am objecting because the RFC is very clear about the Security Considerations. You don't get this kind of clear hint very often when not to use something in a specific security context. But if that's the case you should definitely follow such instruction. 
Cool! Quick tip: In idiomatic Rust we like to avoid using strings as parameters when only some values are acceptable. The label of an axis could be anything, but colors and units are usually well-defined things. You could represent those with an Enum or another custom type, it lets the compiler catch any typos, is more expressive, and gives you some nice things like exhaustive match statements and all that.
Tangentially related, but how would people recommend that one would do codegen w/ LLVM in Rust? I've seen llvm-sys, but I'm wondering if there are any safe LLVM bindings that have any sort of pulse
Thanks, that makes a lot of sense, I'll make sure to update that!
Eh I was not going to use Haskell anyway. This is a personal project for learning purposes, I don't think it matters much which language I use.
You're looking for /r/playrust
Right. Thanks. Fixed.
Also Elm, Clash, Perl (temporarily), Idris, Agda, and Futhark. 
You laugh, but look at the swift example code here: https://swift.org/blog/dictionary-and-set-improvements/ 
This is what I did for parsing aterms. It took much less time than learning a library, though I did look into a few before settling on rolling my own. At some point I would consider it good for maintainability and rigour to use a framework. There's too many things you can cram into what started out as some simple parsing code. 
&gt;I've definitely seen C and C++ used to implement non-self-hosting compilers. I think I've seen C# and Java used as well. I think the key question there is "how did it work out?" I realize Ruby is written in C but the code is... not elegant to the point you wonder where exactly something went wrong. &gt;What non-toy languages have had their compiler written in Haskell? Mainly Elm, Frege, Perl (temporarily), and PureScript, though if you count research languages then many more. There's also a Python interpreter written in Haskell, though it's not the canonical implementation obviously.
I really dislike Swagger's model of "generate once" code. I build up a service definition, and I want to be able to modify it later and add to it without blowing out any changes. I ran into issues with it generating Flask (Python) services and JAX-RS (Java) services. I ended up rigging up a really awkward set of shell scripts and Maven hacks to get it to integrate nicely with the rest of the toolchain. They should really take some inspiration from Protobuf and generate a generic chunk of code that's ready to be used with whatever you want. That way you can regenerate the code whenever you want and the only things that break are what was directly affected by the change. I haven't tried out this new Swagger generator for Rust, but it seems like it might be closer to this. This is a problem I see a lot more than I want to. 
&gt; Swift, PHP, Python, Ruby, Go, and many other very well known languages have been written in either C or C++. I haven't seen this at all. Self-hosting is a good decision, writing a compiler in Go or Ruby is not.
The compilers or interpreters for Swift, PHP, Python, Ruby, Go were (at least initially) written in C or C++. I never said they were written in Go or Ruby. Go has become self-hosting, but it was initially written in C. There's a distinct lack of non-Haskell-like popular languages with their first (or current) compiler written in Haskell.
&gt; Being a more traditional, imperative language tremendously lowers the barrier to entry compared to Haskell. For writing a compiler this largely shifts the work from "learning Haskell" to "debug impure code, learn various paradigms anyways for the compiler" etc. &gt;Rust also gives you maximum performance, since you can control allocations and everything else on a hot code path Well yeah but for a compiler so much of it is CPU-bound that Rust is going to be less advantageous than it would be otherwise. &gt;There are many great things about Rust, from the documentation to the crates ecosystem. Docs for Haskell aren't that bad if you stick to established libraries, and it has hackage which is basically comparable. &gt;I personally find that Rust strikes a better balance than Haskell. It's a systems programming language. I wouldn't really use Rust for a compiler any more than I would use Haskell for writing a disk usage tool. They each have their domains.
People (myself included) often assign more weight to the bad things done than good things done. If you save someone's life, you're a wonderful person. If you subsequently kill someone, you don't go back to being a neutral person: you're a murderer. And unless your name is Robin Hood a gift usually does not excuse a theft. Good and bad acts don't just cancel out (although computer games that model morality like this can be a lot of fun... :-D). So when a person or a company has both a bad and a good track record, the latter had better be much more impressive than the former, or people are going to focus on the negative.
Depends on which algorithm you think of. But in theory you can solve every problem under a minute 
Rust is heavily stanced against global, mutable state. You practically have to use the `unsafe` keyword to even have global, mutable state, at which point you're no better off in Haskell. In Haskell, you can do `unsafePerformIO` just as easily as you can use `unsafe` in Rust. It's an obvious code smell, and it is frowned upon. I consider Rust a very pure language compared to most other languages. Just about the only impurity that Rust makes it easy to invoke anywhere in your code is file system access, network access, and console access, but that stuff is easily siloed. With the existence of `unsafePerformIO`, I consider Haskell to only be slightly more pure than Rust. It is, of course, but for practical purposes, it isn't that much more pure. I don't think I've ever written Rust code that used explicit, global, mutable state where I actually declared a global variable. I was reading [an example of a Recursive Descent Parser in C](https://en.wikipedia.org/wiki/Recursive_descent_parser#C_implementation), and I was horrified that it used a global, mutable variable to store the current Symbol being parsed, and then it had a function "nextSym" to mutate that global. Why would anyone write code like that?
That's roughly 100%!
I think it may depend on the language/generator. I've had no trouble modifying and updating with [go-swagger](https://github.com/go-swagger/go-swagger/). But I've definitely ran into the sorts of issues you're talking about in the past w/ python.
I'm a little surprised Swift isn't self-hosting yet, since it's intended as a general purpose programming language. Is it just missing complete bindings to LLVM?
https://github.com/killercup/assert_cli/pull/44 Trying to get stdin support merged into `assert_cli`. I'll be happy to stop maintaining my own crappy `std::process` binary test runner (I wrote about it [here](https://sevagh.github.io/post/pqrs/)).
Elm and Clash are both designed to *be Haskell*, but for some specific purpose. Futhark is quite possibly the first language I've seen where the compiler was written in Haskell that is not meant *to be* Haskell. It's an ML-family language. So, now we have one example to work from. It still does not put Haskell anywhere in the same class as OCaml for being a compiler-writing language.
Is that an issue? My understanding of LTO is that it invasive alters both(all) object file generation. Part of why it works is that it reduces down the symbol table to a minimal representation, and replaces various hooks with in-line solutions instead. But I guess I'm not entirely sure about all that, since I'm not sure if Rust takes use of whole-program IPO or not.
What you probably actually want is an enum with all your variants of T in it, or to define a trait T that defines the operations you want to do on your types and then storing them as trait objects. The general case of "store an arbitrary data type in a collection" is not something Rust really does in an ad-hoc manner; if you know what types T will be then you need to tell Rust what the options are. There is the `Any` trait which lets you do dynamic typing but you still have to, at some point, say "turn this `Any` object into a specific type, and do something if it ends up being the wrong type."
Hmm. Yes I did use LTO, because it reduces the binary size in half...
That would work as a workaround, yes. It's not ideal though.
&gt; Security Considerations UUID is basically a serialization format for some numbers. There's nothing wrong with using a UUID format for your keys, if you've generated the random data in the UUID appropriately. For example, this has a long history in databases (such as Postgres). I don't know if rust's UUID4 generator is secure or not, but it's totally reasonable to put some random data into the format of a UUID and use it as a key if you have some good random data. edit: as an example, there is a long history of using https://www.postgresql.org/docs/9.4/static/pgcrypto.html to generate UUIDs to be used in postgresql UUID primary keys.
It's roughly 50% :)
The uuid crate uses the `rand` crate's `gen` function. Is that secure?
Sweet. I was just talking to someone about how this would be a nice-to-have. Thanks.
Nope, moved it to the center after a few days lol
This is why Perl 6 is the superior language.
Commit B is the red-green PR's merge
Idk what primary keys for databases have to do with the topic, anyway. I don't want to argue about that topic any longer, if you find UUIDs suitable for your cryptographic scenarios its sad to see them wrongly used, despite the warnings. &gt; I don't know if rust's UUID4 generator is secure or not, That's the point, you can't. The specification allows for insecure implementations so you better stay away from it. Sry for sounding rude or anything but i just don't have the endurance for arguing about this any longer. Why bother with the high risk of insecure UUDIs if there are so much better choices out there? 
Thanks for the feedback /u/the___duke and /u/DannoHung! As you really seem to expect multiplexing support even though Mles is a bit different, I decided to add a new "Why Mles?" section and finetuned use case description to http://mles.io which hopefully clarify this part of Mles in more detail: that you cannot multiplex on a connection by design and if you need to do it on large scale, you may need to look elsewhere for a pub/sub service.
&gt; This is a custom derive that creates a builder for you class. You mean for my struct and not for a trait, right?
Going full off topic, is there a java generator that dosen't suffer from this?
It has the advantage that you only end up with one copy of the standard library and any other shared dependencies. And shared dependencies are compiled only once, instead of for each library that uses them.
Yes, fixed. Doesn't make much sense to have a builder for a trait...
The panic system and dynamic typing systems are both very minimalistic. You can guess the concrete type of an Any object with this if let Some(s): = a.downcast_ref::&lt;&amp;'static str&gt;() { ... } You can only generate a backtrace before unwinding, so it must happen within the panic hook. The standard library backtrace isn't stable, so I would consider `backtrace` for this task. A complete logging crate should have a panic hook for you, but I can't recommend one yet.
What does rustc do? Seems like a natural place to start looking.
(They fixed the link already but haven't published a new version.)
I actually created [crate](https://github.com/WaDelma/bob) for this, but never got around publishing it to crates.io for some reason. Don't currently have time to look how you did things or what the differences are, but you are welcome to pilfer any ideas (if any) that I have done better.
FYI, Diesel doesn't shy away from complex or engine-specific things. We don't try to abstract away your backend at all. You may also be interested in [this PR](https://github.com/diesel-rs/diesel/pull/1221)
If every character is outside the BMP, wouldn't UTF-32 be more efficient than UTF-8?
Honestly? Just use Cap'n Proto RPC. Capnp fixes a bunch of issues with Protobuf without straying far from the original vision (as it's originally by the same guy) and is *much* more comfortable to work with. The syntax is a bit more rough around the edges but it has implementation advantages that make it worth it.
The time spent is roughly 50%. The speedup is roughly 100%.
I also had a quick play around with the idea a bit ago here: https://github.com/daveallie/encoji/ It uses 256 emojis so each byte is represented by a single emoji and follows the same encode/decode map provided by https://github.com/pfrazee/base-emoji
&gt; if anyone knows how I can create custom error messages when the builder is used incorrectly(missing field or field appearing more than once) I would love to implement it Just `panic!`, the panic message will show up as a compilation failure with your message.
Just released lasted version of my on file storage https://crates.io/crates/persy 0.2.0 with a few evolution and fixes, after some months of work, hoping someone else would get involved for get some feedback, also in the left over of my free time playing with some mails+Bayesian to get some auto-tagging software. 
How so? A `panic!` in my macro code will be triggered when the struct is defined regardless of how it is used, and a `panic!` in the generated builder's code will only show at runtime.
Your approach looks similar to mine - except instead of using specific marker types for "has value" and "doesn't have value" generic parameters I just used `(T,)` and `()`. This allows me to use them as generic parameter values, ridding me of the need to put them in `Option`s.
I'm *very* busy with ODF related things for a few weeks so I will not start that, but I'll review it if you take a crack. 
I didn't actually know whether this was possible, but I've wanted something like it for a long time! Thanks :)
Oh I misunderstood, I thought you meant that you wanted nice errors if people mis-used your API, not if people miss-used the builder. The only thing I've seen for that is embedding the errors message into the generic parameters, so the user sees something like `error: expected Built&lt;SuccessfullyUsedAllParameters&gt; but got Built&lt;YouNeedToUseEveryParameterCommaYouDope&gt;`. It's not great, but it's better than nothing.
You're a terrible person. Keep up the good work!
What's wrong with rust-derive-builder? https://github.com/colin-kiegel/rust-derive-builder
That's a good start, but it doesn't really help me specify the missing parameters in the error message, so I'm not sure if it's worth the trouble...
What you want to do is encode your ascii as 3 characters into 21 bits, which can then be encoded as a char Edit: [created.](https://github.com/serprex/asciipress) Turns out there's a hole in the char-is-21-bits rule, so instead I pack 5 7-bit ascii characters into 36 utf8 bits (5 ascii characters per 2 utf8 characters) Slight modification could have it handle arbitrary binary data. Something like mapping either 2 bytes to 1 utf8 char (16:18) or 9 bytes to 4 utf8 chars (72:72). Like some tuning would be desired to not include nul characters. See [base65536](https://github.com/qntm/base65536) for that
derive-builder is checking for missing fields at runtime - typed-builder is doing it at compile-time.
They even had a whole workshop and a raffle which was cool
Is there a way for a Rust program to look at its `stdin` and determine if it's going to deliver data? I want a program that, when run without a pipe or shell redirection to `stdin`, does not attempt to read from it and block, but if there *is* data piped or redirected into its `stdin`, it will consume it until `stdin` closes, and then exit. $ myprog consumes command line arguments #=&gt; The result of operating on ["/path/to/myprog", "consumes", "command", "line", "arguments"] $ echo "consumes stdin" | myprog #=&gt; The result of operating on "consumes stdin" $ echo "and also stdin" | myprog consumes cli args #=&gt; the result of operating on ["/path/to/myprog", "consumes", "cli", "args"], then "and also stdin" The unpiped variant should not try to read from `stdin` and block, but the piped variants should, is the gist.
The emojis the tool produces all fit in 4 bytes, so there would be no difference. Also UTF-8 is *always* the right choice :p
So I've been [experimenting](https://github.com/Thiez/base100) a little, and it seems you can make the encoding quite a bit faster by avoiding the nice UTF-8 encoding and just doing it all by hand: fn to_emoticon(byte: u8) -&gt; [u8; 4] { let mask = if byte &lt; 9 { 255 } else { 0 }; let byte = byte.wrapping_sub(9); let (third_add, fourth_add) = (byte / 64 | mask, byte % 64); [240, 159, 144u8.wrapping_add(third_add), 128u8.wrapping_add(fourth_add)] } Of course it's a little evil.
creepy xd
If you're dealing with tuples, you're almost certainly going to have to do something like this [`@inc_ord_ident`](https://github.com/DanielKeep/rust-parse-generics/blob/master/parse-macros/src/parse_macros_util.rs#L35-L66) rule. That produces both an index ordinal you can use for direct access, and an identifier you can use for pattern matching. I don't know how you'd *use* this in your case, but maybe do something at the top level to turn the list of matched element types (*e.g.* `$($tys:ty,)*`) into a list of types *with* indices and identifiers (`$(($tys:ty, $ord:tt, $ids:ident),)*`). If you're not sure how to do that, see [this page on push-down accumulation](https://danielkeep.github.io/tlborm/book/pat-push-down-accumulation.html). If that *still* doesn't help, you might want to avoid macros entirely for this.
You fundamentally cannot rerun a value from Index, it's true. There's no way to work around it. I don't have any specific advice for you other than that, but wanted to at least let you know that there's no direct way to accomplish that via index. Obviously if you just make it a function you can return whatever you want.
No need for the intermediate struct, you can index with a tuple like `tilemap[(x, y)]` with an impl like this: impl Index&lt;(usize, usize)&gt; for TileMap { type Output = Tile; fn index(&amp;self, (x, y): (usize, usize)) -&gt; &amp;Tile { &amp;self.data[x + y*self.w] } } 
My instinct would be to use a different index type, rather than chaining index operations: impl Index&lt;(usize, usize)&gt; for TileMap { type Output = Tile; fn index(&amp;self, (x, y): (usize, usize)) -&gt; &amp;Tile { let idx = y.overflowing_mul(MAP_WIDTH) .and_then(|tmp| tmp.overflowing_add(x)) .expect("coordinates exceed maximum possible backing storage"); &amp;self.storage[idx] } } Then it's just a matter of `mymap[(x, y)]` Another option, of course, is to return a slice of the backing storage: impl Index&lt;usize&gt; for TileMap { type Output = [Tile]; fn index(&amp;self, y: usize) -&gt; &amp;[Tile] { let base = y.overflowing_mul(MAP_WIDTH).expect("coordinates exceed maximum possible backing storage"); let end = base.overflowing_add(MAP_WIDTH).expect("coordinates exceed maximum possible backing storage"); &amp;self.storage[base..end] } } However, this requires indexing it as `mymap[y][x]`, which may violate the Principle of Least Surprise. A third option is to return a slice, but organize your backing storage in column-major order rather than row-major order. This would allow indexing as `mymap[x][y]`, but may have performance implications (depending on your access patterns). A downside of both slice-based approaches is that they expose more of the internal implementation of your `TileMap` to the user - an upside is that a user could iterate over each tile in a row (resp. column) much more efficiently. However, that same upside could also be obtained by supporting indexing by `Range&lt;(usize, usize)&gt;`, and returning a slice of the backing storage between those points (that is, the "tail" of the first row, all rows between, and the "head" of the last row) - albeit at a similar cost of revealing implementation details. This is, in fact, strictly more powerful. Note also that I used `usize`, rather than `i32` - this matches the backing storage, and avoids unnecessary casts. As a result, it's generally considered idiomatic. `i32` also has the problem of being able to represent negative numbers which cannot possibly be valid, introducing a _new_ source of potential error - whereas using usize merely maintains the same potential for out-of-bounds access as the underlying `Vec&lt;Tile&gt;`.
Work smarter not harder!
Thanks! Op here on my phone, different account, this solutions seems very elegant! Thank you very much, I‚Äôm going to try this after dinner!
That is true, a package manager is really the best part of a stable language Sometimes I think pip might be the only reason I like python üòã
Thanks again, this turned out perfect!
You wan't /r/play_rust. Please take a look at what subreddit you're in before posting. :)
I'm guessing you're looking for /r/playrust
Yes! https://crates.io/crates/cucumber I LOVE cucumber, but haven't personlly tried the rust implementation yet.
Thanks for posting the reason. It's useful for those of us who are gradually phasing out C from our codebases. Since most people encountering this issue will likely find the stackoverflow post first, could you add this as a note there so that others will know what to look for?
Completely agreed. Mutating an object using multiple mutable pointers at the same time is almost guaranteed to be shit.
Why on facebook?
compile-time builder was on my to-do list for a week or two but I was thinking about adding #[builder(required)] to the rust-derive-builder type. It has 300 commits and 14 releases - I guess this crate fought a lot of bugs and edge-cases over the time.
Temporary home maybe? What do you suggest? Thx
I just published a sample API using Iron a few hours ago. Ours are very different. Pretty neat though.
I thought I'd share a sample web application I've been working on. Its current state is a basic foundation I can live code enhancements to. I'll start that in the next few weeks once I catch up on things. I would be keen for any feedback though to build up a nice backlog of things to do and get thoughts on other people's approaching to building web apps in Rust!
Cool! I'll check it out :)
Just a thought. If a field is mandatory then you could add it as an argument to the builder method. This could save a few keystrokes. Foo::builder(1).y(2).z(3).build() // returns Foo { x: 1, y: Some( 2 ), z: 3}
[Here's the link](https://github.com/alexanderbanks/rust-api)
Nice! I think there are some similarities between `services` in your app and `commands` / `queries` in mine and `types` in yours and the `model` folders in mine. Is the idea that a service encapsulates everything you need to handle a single interaction with your application?
I've had a few cases (in C++) where a badly visualized bounds check function was taking ~80-90% of the run time. The work was trivial, so the function call was nearly all overhead.
AFAIK, `cargo bench` generally compiles a release build. My local machine shows similar numbers: $ cargo bench Finished release [optimized] target(s) in 0.0 secs Running target/release/deps/dynamic_dispatch_benchmark-bcd4e4b9f8d261fa running 2 tests test tests::using_box_dispatch ... bench: 1,050 ns/iter (+/- 469) test tests::using_enum_dispatch ... bench: 121 ns/iter (+/- 2)
My mistake. `cargo test` doesn't compile for release by default (it accepts a `--release` flag) ... but it appears `cargo bench` does compile release builds by default (and doesn't have a flag to disable it). Sorry for the confusion - I'll remove this comment in a few minutes.
This isn't really Rust specific, but in most languages the function you want is called "isatty" ("is this a teletype?"). I think think there are some crates that expose it?
Ah, sorry ‚Äî yeah, I mistyped and actually meant to write `cargo bench`. Fixed.
On my computer (7th gen i5), I got: running 2 tests test tests::using_box_dispatch ... bench: 600 ns/iter (+/- 168) test tests::using_enum_dispatch ... bench: 106 ns/iter (+/- 65) test result: ok. 0 passed; 0 failed; 0 ignored; 2 measured; 0 filtered out So I think it's probably safe to say this is a real slowdown. I'm not sure if this matches my expectations though. For example, adding a couple of benchmarks that just try to target memory indirection slowdown ([playground link](https://play.rust-lang.org/?gist=adda27430b43aa33e74af95cf8414e2a&amp;version=undefined)), I get: running 5 tests test tests::no_indirection ... bench: 52 ns/iter (+/- 4) test tests::one_pointer_indirection ... bench: 71 ns/iter (+/- 4) test tests::two_pointer_indirection ... bench: 100 ns/iter (+/- 2) test tests::using_box_dispatch ... bench: 494 ns/iter (+/- 19) test tests::using_enum_dispatch ... bench: 106 ns/iter (+/- 1) test result: ok. 0 passed; 0 failed; 0 ignored; 5 measured; 0 filtered out So I would guess that there is definitely more than one or two layers of indirection caused by `Box`ing? I'm not sure, it would be great to hear from someone that knows more about the implementation of dynamic dispatch in `rustc`.
All your "sum over 0..N functions" have a simple closed form that the compiler can work it out at compile time, and should at a high enough optimization level (goldbolt shows that opt-level 2 is enough on nightly). If you make a different const N for the inner loops you can test this. So all those loops could be removed and the functions only return the right answer with no loops. Next the compiler can tell that all the branches of the enum match statement do exactly the same thing, so it can entirely remove checking which enum you're using. So the match statement can be replaced with just a return. So you could be comparing dynamic dispatch vs a single return. Note that the compiler was able to do these massive optimizations since the enum form (static dispatch) allows for inlining. Often the major overhead of dynamic dispatch isn't calling the function, it's the optimizations that couldn't be performed due to lack of inlining. I messed around a little bit and oddly the box dispatch doesn't use the closed form, which makes it far worse. I would argue that might indicate some bug in the optimizer (I just downloaded the nightly).
AFAICT There are two layers of indirection when talking about fat pointers: * vtable pointer -&gt; fn pointer * object pointer The question is if `Box&lt;Trait&gt;` adds another layer that points to the fat pointer or not. **Edit**: It seems that actually there's some [magic involved](https://play.rust-lang.org/?gist=62195127051519e7795ee4eaf1e2b34d&amp;version=stable). So my guess is that `Box&lt;Trait&gt;` is the same amount of indirection as `&amp;Trait`
The enum_dispatch loop is optimized to (note there's no calls): 106f0: 48 c7 85 58 fc ff ff movq $0x1356,-0x3a8(%rbp) 106f7: 56 13 00 00 106fb: 48 03 85 58 fc ff ff add -0x3a8(%rbp),%rax 10702: 48 ff c9 dec %rcx 10705: 75 e9 jne 106f0 &lt;dispatch::tests::using_enum_dispatch+0x100&gt; The box_dispatch loop is optimized to: 11010: 48 8b 3b mov (%rbx),%rdi 11013: 48 8b 43 08 mov 0x8(%rbx),%rax 11017: ff 50 18 callq *0x18(%rax) 1101a: 48 89 85 20 fc ff ff mov %rax,-0x3e0(%rbp) 11021: 4c 03 bd 20 fc ff ff add -0x3e0(%rbp),%r15 11028: 48 83 c3 10 add $0x10,%rbx 1102c: 4c 39 f3 cmp %r14,%rbx 1102f: 75 df jne 11010 &lt;dispatch::tests::using_box_dispatch+0x1d0&gt; Each of B::f etc are optimized to: 105c0: 55 push %rbp 105c1: 48 89 e5 mov %rsp,%rbp 105c4: b8 56 13 00 00 mov $0x1356,%eax 105c9: 5d pop %rbp 105ca: c3 retq Edit: without debuginfo, B::f etc are: 105b0: b8 56 13 00 00 mov $0x1356,%eax 105b5: c3 retq 
Here is one approach that gives you `tilemap[x][y]` but requires one line of unsafe code. The idea is to evaluate `tilemap[x][y]` as `tilemap.storage[x..][y * MAP_WIDTH]`. use std::mem; use std::ops::Index; const MAP_WIDTH: usize = 4; #[derive(Debug)] struct Tile(u8); struct TileMap { storage: Vec&lt;Tile&gt;, } struct Strided([Tile]); impl Index&lt;usize&gt; for TileMap { type Output = Strided; fn index(&amp;self, x: usize) -&gt; &amp;Self::Output { let slice = &amp;self.storage[x..]; unsafe { mem::transmute::&lt;&amp;[Tile], &amp;Strided&gt;(slice) } } } impl Index&lt;usize&gt; for Strided { type Output = Tile; fn index(&amp;self, y: usize) -&gt; &amp;Self::Output { &amp;self.0[y * MAP_WIDTH] } } fn main() { let tilemap = TileMap { storage: vec![ Tile(0), Tile(1), Tile(2), Tile(3), Tile(4), Tile(5), Tile(6), Tile(7), Tile(8), Tile(9), Tile(10), Tile(11), ], }; println!("{:?}", tilemap[1][1]); // Tile(5) println!("{:?}", tilemap[3][2]); // Tile(11) }
Oh but I think you're right, it's just that the vtable pointer can be stored in some static location for all of the impls of A. This is approximately what I think is happening: [rust-playground](https://play.rust-lang.org/?gist=da8ac1fd3da172b658c1a77d1e0bc3f5&amp;version=undefined), and it seems to produce results similar to the real thing: running 4 tests test tests::my_idea_of_dynamic_dispatch ... bench: 531 ns/iter (+/- 35) test tests::my_idea_of_enum_dispatch ... bench: 204 ns/iter (+/- 18) test tests::using_box_dispatch ... bench: 600 ns/iter (+/- 39) test tests::using_enum_dispatch ... bench: 107 ns/iter (+/- 7) test result: ok. 0 passed; 0 failed; 0 ignored; 4 measured; 0 filtered out Edit: Oh you know what, I'm completely confused, disregard my point about this. Edit 2: Yeah my idea of dynamic dispatch was quite a bit off, I always thought that `Box&lt;Trait&gt;` was a pointer to the object and an object tag that you could use to index statically-included tables of information, but it's actually an object pointer and groups all of the type's information together (which makes sense). As in, I thought it was this: const STRUCT_B_INDEX: usize = 0; const STRUCT_C_INDEX: usize = 1; const STRUCT_D_INDEX: usize = 2; static STRUCT_SIZES: &amp;[usize] = &amp;[size_of::&lt;B&gt;(), size_of::&lt;C&gt;(), size_of::&lt;D&gt;()]; static STRUCT_IMPLS_OF_TRAIT_A: &amp;[fn(*const ()) -&gt; usize] = &amp;[ b_impl_of_a_f, c_impl_of_a_f, d_impl_of_a_f, ] .... let b = Box&lt;A&gt;(B, STRUCT_B_INDEX); let c = Box&lt;A&gt;(C, STRUCT_C_INDEX); let d = Box&lt;A&gt;(D, STRUCT_D_INDEX); But it's actually (and this is all explained in the [Rust book](https://doc.rust-lang.org/1.0.0-beta/book/static-and-dynamic-dispatch.html), it's just been so long since I read it that I completely forgot): static STRUCT_B_IMPL_OF_TRAIT_A: VTable = VTable { size: size_of::&lt;B&gt;(), f: b_impl_of_a_f, ... }; static STRUCT_C_IMPL_OF_TRAIT_A: VTable = VTable { size: size_of::&lt;C&gt;(), f: c_impl_of_a_f, ... }; static STRUCT_D_IMPL_OF_TRAIT_A: VTable = VTable { size: size_of::&lt;D&gt;(), f: d_impl_of_a_f, ... }; let b = Box&lt;A&gt;(B, &amp;STRUCT_B_IMPL_OF_TRAIT_A); let c = Box&lt;A&gt;(C, &amp;STRUCT_C_IMPL_OF_TRAIT_A); let d = Box&lt;A&gt;(D, &amp;STRUCT_D_IMPL_OF_TRAIT_A);
With only skimming over the code I'm gonna go with: cache misses. For every item in the `using_box_dispatch` bench you have an extra layer of indirection, the Box. --- In each bench, the CPU will try to load as much of the vector `xs` into it's cache as it can. In the `using_enum_dispatch` bench, since the vector holds the data directly, we have all of our `B`, `C` and `D` in cache. Great! Cache hits all over the board! In the `using_box_dispatch` bench, all that we really have in cache is a bunch of pointers. The CPU has to request the memory behind every single pointer to get the data, while in the previous bench we already had all the data. This is waaay slower than having the needed data in cache, because the CPU has to wait a really long time for the data to arrive. Memory is slow. This is where I think the performance difference comes from. I could be wrong though. If anyone's more interested in this, I recommend [this read](http://gameprogrammingpatterns.com/data-locality.html) - a fantastic guide to data locality and optimizing for cache hits. By the way, I don't think enums count as static dispatch. Isn't branching on them dynamic dispatch too, since it happens at runtime?
While others have given more specific answers (especially Cocalus's answer), I'd add that this benchmark is really set up to be the worst case for dynamic dispatch, in that the code you've written is highly optimizable in the static case and the allocation will be relatively expensive compared to the work being done. I wouldn't consider this representative (unless you're performing dynamic dispatch around highly optimizable, inexpensive computations in the hot path of your program - try not to do that!).
It's a known bug in Clippy - https://github.com/rust-lang-nursery/rust-clippy/issues/2048. Honestly, I would just tell Clippy to ignore this lint here.
To make the test fairer, you can add `#[inline(never)]` to B::f etc, giving: test tests::using_box_dispatch ... bench: 482 ns/iter (+/- 17) test tests::using_enum_dispatch ... bench: 616 ns/iter (+/- 26) Inspection of the assembly shows a much larger loop for enum dispatch in this case.
I'm not aware of any docs stating that rand's default generator is suited for crypto uses.
/u/Cocalus and /u/phoil already provided great answers, so I'll just add this... We have a nice little saying in Germany for such things: &gt; Wer misst, misst Mist. In English the nice homophony is lost, but it translates to: *"Who measures, measures muck." (muck as in bullshit)* The idea behind this saying is not that you shouldn't measure things first - indeed, you should. It is rather that you should be very, very careful about what you are measuring, as it is extremely easy to measure the wrong things that just happen to support whichever point one is trying to make. This is partially the reason why most scientific studies end up in the trash can.
Or in other words, trait objects are slow not because of an extra indirect function call cost, but because that "virtual" function call prevents inlining, which prevents 99% of all other optimizations that LLVM knows how to do. How much slower are trait objects depends on how much faster would the code be without them. There isn't a hard number answer. 
If you do go the webservice way. You should probably avoid async stuff until you have a good grasp of the language.
A service encapsulates chunks of core functionality, passing around types. The handlers just coalesce HTTP info to and from services.
Yes it just waits for every new message available. Same as `std::sync::mpsc`.
For any interested readers: According to [this post](http://aravindavk.in/blog/isatty-in-rust/), pre-1.0 this was in `std::io`. Dtolnay provides [a crate](https://github.com/dtolnay/isatty) that implements this cross-platform ... on stdout and stderr, but not stdin. There's an [open issue](https://github.com/rust-lang/rust/issues/33736) about it, which led to the above crate. Best result is [atty](https://github.com/softprops/atty), which supports all three standard streams. Personally, I think it'd be nice if `std::io` had this, since it's closely related to working with the standard streams, but w/e.
Dank
&gt; This is partially the reason why most scientific studies end up in the trash can. If only they ended up there. Attempts at reproduction are super low and even if you attempt it you do the same measurement and conveniently say that what you measure actually leads to what you conclude. I read a peer-reviewed and accepted sociology paper a while back where people investigated something based on human attraction. How did they measure attraction? They asked one participant to join the other at a table and measured how closely the former put his chair next to the chair of the other‚Äîthe closer, the more sexually attracted... urgh.
There was a similar but opposite controversy with Haskell and the language benchmarks game: since Haskell is lazy, it never bothered computing anything at all since the result of the expensive benchmark computation was never used, thus trivially winning the competition.
But dynamic dispatch means deciding what method to call at runtime. Once the enum is matched, which you could desugar to a 'case break;', there's no ambiguity or indirection regarding what methods are available on its payload.
Minor remark: When the body of a method is the same for all implementations, you can put that body in the trait and omit it in the impl blocks so you don't repeat yourself 
Sure. I guess one my main blockers with diesel still are: 1. https://github.com/diesel-rs/diesel/issues/399 2. Now that I've learnt the postgres protocol, I know how to minimise the number of synchronisation steps. This is probably one of the main reasons why the Nest responds so fast (along with the Hyper, which is surprisingly fast).
Technically it was in a loop, though it would never go round the loop more than once. (Don't ask - still on a learning curve with rust) I guess what your trying to say is 'how would the compiler know that'? It's a good point, I guess it couldn't. Would be great to point out that this was a 'loopy' error message rather than some other cause. (Loving the limeriq)
you can use enum dispatch with traits using this crate. https://github.com/DanielKeep/rust-custom-derive I consider box a design mistake of rust. There is hardly any reason to use a box over an enum. 
Cap'n Proto is awesome. There is a good talk available on using it with Rust: ["Cap'n Proto and Rust: Type Systems for Sharing"](https://www.youtube.com/watch?v=A65w-qoyTYg)
I wish Rust would support named arguments in the future. Like in scala def printName(first: String, last: String): Unit = { println(first + " " + last) } printName("John", "Smith") // Prints "John Smith" printName(first = "John", last = "Smith") // Prints "John Smith" printName(last = "Smith", first = "John") // Prints "John Smith" 
With unsafe all sorts of horrible impossibilities are possible. Add a value cache to the parent structure within a cell or mutex. Push the desired return value to this cache and return a reference to it. The lifetime of this reference will be bounded by the borrow on which `ops::Index` was invoked. This means the cache may be cleared whenever a `&amp;mut self` method is called. I don't think this is a good hack, but it's not impossible.
That sounds like unsoundness, but I did just wake up.
Why do you need it to specifically be `String`s? 
not sure to be honest. I come from Java, so every String naturally needs to be a String to me :) Is there any difference to OsStr or String? str seems to be fixed sized (aka "hello world") and String should be dynamic.
not sure to be honest. I come from Java, so every String naturally needs to be a String to me :) Is there any difference to OsStr or String? str seems to be fixed sized (aka "hello world") and String should be dynamic.
not sure to be honest. I come from Java, so every String naturally needs to be a `String` to me :) Is there any difference to `OsStr ` or `String`? str seems to be fixed sized (aka "hello world") and `String` should be dynamic.
I mean, what are you going to do with the paths that requires them to be strings? `PathBuf`, the thing `.path()` returns, is a string-like struct that's specifically designed for dealing with paths. Why not use that?
I basically need the name to go deeper into the file tree. Might be a better idea to use `PathBuf` I guess. Not sure, Rust is by far one of the harder languages I am trying to get my head around. Traits, Lifecycle (I still didn't get that)... `String` is one of the more familiar concepts I know from other lanbguages. So that's probably why I thought it might be a good idea. So you would use `PathBuf` instead of `String` when dealing with paths?
Sounds good, I'll see if I can squeeze in some time this weekend.
I wouldn't call any of these forms "static" dispatch. It's dynamic in both cases. It's more of an "automatic (virtual?) vs manual" dispatch situation. The latter allows inlining, the former does not.
Yes. You can just pass a `PathBuf` as an argument to `read_dir`, as it implements `AsRef&lt;Path&gt;` (i.e. can be converted to a reference to a `Path`).
Boxes are just slightly fancier c style pointers. So the things they point to could be anywhere in memory. So cache misses galore. Whereas enums have a defined size and can be stored directly in the vec without any direction so way fewer cache misses. Sometimes one can be used sometimes you need to use box. Tldr you're mostly testing cache misses.
22x slower than static dispatch - yes that sounds possible. 10x is the ballpark I'd expect, maybe stretched to 22x for compiler issues in an evolving language. (the worst cases I've seen in gamedev on pathalogical machines were up to 50x slower for code using dynamic dispatch) rule of thumb: few instances of many types - dynamic dispatch might be suitable, but if you have few types and many instances, static dispatch will win, and re-working problems to compose behaviour from 'fewer types' is a great overall strategy. 
This defeats the purpose of having a builder for explicit named arguments in a constructor.
I'm far from an expert on this manner, but I spent a little time looking into this. On first glance, it wouldn't look like cache-locality should be much of an issue here, since everything likely fits in the L1 cache. A `Vec` of 300 enums of 0-sized structs probably doesn't take much more than 19.2K (with a 64-bit discriminator) or 2.4K (with an 8-bit discriminator). the 2.4K could fit in the [Pentium 2s](https://en.wikipedia.org/wiki/Pentium_II#Core_specifications) or [Pentium 3s](https://en.wikipedia.org/wiki/Pentium_III#Core_specifications) ~16K [L1d] cache. The 19.2K could fit in the 8th-gen Intel's [32K](https://en.wikichip.org/wiki/intel/microarchitectures/coffee_lake#Memory_Hierarchy)'s cache. (which was likely here earlier) Busting that cache shouldn't be too hard. I went ahead and [updated](https://play.rust-lang.org/?gist=0cffa86e720009ba942eabb444281f03&amp;version=nightly) version: * Bypass the compiler's [inline optimizations] here with `[inline(never)]` * Use a different constant `LEN` for the `Vec` creation loop. * Use `Vec::with_capacity(LEN * 3)` On my system (an old i7-2760QM), `LEN=100`, `LEN=1000`, ran box_dispatch roughly ~40% slower: test tests::using_box_dispatch ... bench: 1,194 ns/iter (+/- 481) test tests::using_enum_dispatch ... bench: 845 ns/iter (+/- 39) `LEN=1000` and `LEN=10000` seems to allow box_dispatch to consistently run more quickly-- only ~20%-30% slower. I even re-ran the other tests, re-ran this one several times. This range seems consistently quicker. test tests::using_box_dispatch ... bench: 10,039 ns/iter (+/- 4,621) test tests::using_enum_dispatch ... bench: 8,188 ns/iter (+/- 443) test tests::using_box_dispatch ... bench: 107,597 ns/iter (+/- 55,431) test tests::using_enum_dispatch ... bench: 80,867 ns/iter (+/- 4,047) `LEN=100000` begins to get out of my caches with memory usage stabilizing around ~5M. box_dispatch seems roughly 56% slower: test tests::using_box_dispatch ... bench: 1,258,835 ns/iter (+/- 179,429) test tests::using_enum_dispatch ... bench: 801,947 ns/iter (+/- 36,504) With `LEN=10000000`, `LEN=100000000` (~50M, ~500M and ~5G of memory) boxed dispatch seems roughly 70% slower test tests::using_box_dispatch ... bench: 14,687,453 ns/iter (+/- 1,613,899) test tests::using_enum_dispatch ... bench: 8,191,636 ns/iter (+/- 436,532) test tests::using_box_dispatch ... bench: 146,115,366 ns/iter (+/- 9,211,998) test tests::using_enum_dispatch ... bench: 81,972,768 ns/iter (+/- 3,662,737) test tests::using_box_dispatch ... bench: 1,463,031,055 ns/iter (+/- 42,668,904) test tests::using_enum_dispatch ... bench: 817,701,268 ns/iter (+/- 12,100,517) I didn't have enough memory or time available to scale it up further (another scale of 10 would need 50G and 110 minutes), but it could be interesting to investigate further: * Is the optimizer prefetching boxed values? If so, why is it still slower? * Are there tweaks that can be done to help the processor optimize the code run-- either with prefetching or with something else? * Why does the LEN=1000 and LEN=10000 tests consistently run more quickly? * How predictable is this behavior? Is it mainly limited by the memory bus speed or something else? 
My mudder always said "Everyone belongs with their own, Chipper."
In this example, the data is small enough to fit in many L1 caches, so cache locality probably isn't the issue here. Cache locality is less about the the runtime decisions, and more about the data needed to make those decisions. Not having the data in the registers or L1 cache significantly affects fast the processor can make decisions. The amount of time it takes to get the data is very [different](https://i.imgur.com/k0t1e.png) for different types of memory. From that slightly old graph; L1, L2, and Memory references take roughly 0.5ns, 7ns, and 100ns. The exact numbers may be different today, but the scale is roughly the same. When the processor expectantly needs information from the memory, that's ~100ns that it can't make the decision. Some other optimizations are available, like [cache prefetching](https://en.wikipedia.org/wiki/Cache_prefetching). Prefetching data that's all together (n, n+1, n+2, n+3, n+4) is generally much easier than pre-fetching randomly organized data (e.g: all over the heap). Realistically, indirect access is fast enough that the processor can *probably* do some cache prefetching of those values-- but [my very unscientific tests](https://www.reddit.com/r/rust/comments/74llky/trait_objects_22x_slower_than_static_dispatch/dnzn84p/) suggest that sequential access is still up 50% quicker
**Cache prefetching** Cache prefetching is a technique used by computer processors to boost execution performance by fetching instructions or data from their original storage in slower memory to a faster local memory before it is actually needed (hence the term 'prefetch'). Most modern computer processors have fast and local cache memory in which prefetched data is held till it is required. The source for the prefetch operation is usually main memory. Because of their design, accessing cache memories is typically much faster than accessing main memory, so prefetching data and then accessing it from caches is usually many orders of magnitude faster than accessing it directly from main memory. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
It's not just bugs and edge-cases(though every non-trivial project is guaranteed to encounter many of those) - derive-builder also has a nice list of features that were gradually added over the time. And this is why I'm skeptic about adding compile-time checked builder to derive-builder. The concepts of runtime checked builder and compile-time checked builder are very different. The only shared code is the one extracting the settings from the attributes list - the rest of the features will have to be implemented separately. Also, some of the features are not feasible for compile-time checked builder, because it's internals are much less human-friendly than those of a runtime checked builder. I'm talking about the ones that allow customization of the builder struct: * A compile-time checked builder type is packed with a long list of generic parameters. In typed-builder these are always generated by macro, but if you allow the user to write `impl`s for the builder type these lists will be in human code, and will break whenever they add/remove struct fields. * The _Pre-build validation_ makes great sense for runtime checked builder - you already get a `Result` from `.build()`, so just put error messages from the user into that `Result`. With compile-time checked builders it kind of defeats the purpose - now we have to deal with a `Result` again... * _Builder derivations_ - super simple to implement for compile-time checked builders, but make little sense since you are not going to pass the builder type around anyways(not with such a complex type...) typed-builder does not need to support all these features. I may add, in the future, the ones that make sense - but their implementation will be completely different from how they are implemented for the runtime checked builder-derive.
It may help to think of converting to `str`/`String` as "losing type information" when working with types in Rust. (Similar to how an `enum` carries more information than a `bool`.) In this specific case... 1. `Path` and `PathBuf` are wrappers around `OsStr` and `OsString` with extra methods for path manipulation. (They're single-element structs, so the overhead of the "wrapper" part will compile away, leaving it equivalent to calling free functions on `OsStr` or `OsString`.) 2. You don't want to use `str` or `String` with paths for anything other than displaying them to the user, because they enforce stricter requirements than the underlying OS. (It's possible to for the OS to return a path that isn't valid Unicode.) 3. `OsStr` and `OsString` are special alternatives to `str` and `String` which are guaranteed to have the same in-memory representation as `str` and `String`, but relax the "must be valid Unicode" requirement to allow anything the OS might throw at them. (The "guaranteed to have the same in-memory representation" part makes it hyper-efficient to turn `str`/`String` into `OsStr`/`OsString`.) 4. Rust uses traits like `AsRef` so that standard library functions can accept a wide variety of types as long as they're convertible into the desired form. Finally, if you "need the name to go deeper into the file tree", you might want to look at crates like [walkdir](https://crates.io/crates/walkdir) or [ignore](https://crates.io/crates/ignore) (which is built on walkdir).
# Opinions needed I currently use a `#[default]` attribute I can share with my [smart-default](https://crates.io/crates/smart-default) crate(except smart-default does not support `#[default]`, only `#[default="..."]`), but I think about changing it to `#[builder(default)]` that can be shared with [derive-builder](https://crates.io/crates/derive_builder). The idea is that users can use both derive-builder and typed-builder and then `#[derive(Builder, TypedBuilder)]` their type and use typed-builder's `Foo::builder()` as constructor replacement and derive-builder's `FooBuilder` as a flexible factory. Should I: 1. Just do it - it's a new crate in version 1.0.0 so little damage done? 2. Support both styles?
Save a few keystrokes - at the cost of no longer having named arguments for the mandatory fields... Still - your approach has another advantage. If all the mandatory fields are in `::builder()`, the builder type does not need to do any checks, and we can use a simpler runtime checked builder - except it doesn't need to check anything so it does not need to return a `Result`. This can be great for types that have few mandatory fields and many optional ones - like components/widgets in UI libraries. But... that's for another crate.
Por curiosidad, hay alg√∫n argentino oxidado que viva en Nueva York?
I believe Ticki did some benchmarks as part of the 'dyn' proposal around this. Dynamic dispatch, in those benchmarks, was considerably slow. But I'm going by memory so don't take that too seriously - I looked it up quickly and couldn't find them. RFC for reference: https://github.com/rust-lang/rfcs/pull/1603
this is definitely interesting but I'm not sure if it's "fairer". I expect there are many cases in real-world code where substantial inlining would occur that would be prevented by a trait object, even if the benchmark is perhaps too simple. 
true - I did it this way because I was trying to make it so the program called each struct's implementation, but realize now the compiler probably laughed at that and optimized down to a simple return. 
Voy a NY en Febrero/Marzo '18, pero a turistear con mi hijo.
&gt; I expect there are many cases in real-world code where substantial inlining would occur that would be prevented by a trait object, Of course! Not using trait objects also leads to code bloat, which could possibly make your hot code not fit on the cache. Perhaps the default should be not using trait objects in libraries, and perhaps using it in applications? I dunno.
This is very helpful because highly optimizable, inexpensive computations is actually my use case. 
AFAICT, the basic difference between `tokio` and `mio` is that `mio` is a low-level **library** and `tokio` is a **framework** for writing protocols implementations and applications. https://en.wikipedia.org/wiki/Library_(computing) https://en.wikipedia.org/wiki/Software_framework
`tokio` is `futures` on top of `mio`. The idea is that `futures` provides a *zero-cost* abstraction to `mio`: a well-crafted facade that hides the low-level details without sacrificing performance. If you need access to the low-level bits or want to use an abstraction other than futures, then using `mio` directly would be a good choice. The docs are great, with a lot of examples: https://docs.rs/mio
`OsStr` handles whatever encoding the OS uses, while `String` is required to always be valid Unicode. If they were the same type, you'd either need to be able to create malformed strings or have some files that you were incapable of accessing from Rust.
It would be polite if people explained _why_ they were down-voting you, rather than just doing it. FWIW I think that often the distinction between a library and a framework gets blurry when you're talking about micro-frameworks (which, if tokio is a framework then it's definitely still in the micro-phase) and the distinction doesn't add that much in this case. I didn't downvote, though.
Just think of mio as a library to provide a generic OS-independent API to working with OS-specific IO event-waiting functions like epoll on Linux and IO completion ports on Windows. It's pretty low level. The mio API consists of things like registering multiple sockets for events that you care about, and then being able to wait until one (or more) of those events happens, then being able to determine what happened. That's it.
To be fair to OP, I did ask about the basic difference. So they have my upvote. :)
So... there are multiple differences between the two versions. **Enum** An enum is closed, its entire set of alternatives is known exhaustively at the time code is generated. This means that: 1. The code can be optimized knowing that no unknown alternative will spring up, 2. In each alternative, the static type is known and therefore the call is static, 3. A static call is easy to inline. This is basically the best case for a compiler, and a very good reason to use `enum` versus traits whenever the number of alternatives is known beforehand. **Trait** A trait is open, it is unknown at compile-time how many implementations of the trait exist. This means that the (naive) code will result in: 1. Loading the v-table, 2. Loading the function pointer, 3. Executing the function pointer. There are 3 sources of slow-down: 1. The call cannot be inlined (compile-time), resulting in a lot of missed optimizations, 2. The call cannot be inlined (run-time), resulting in a lot of register spilling/restoring, 3. The call cannot be predicted (run-time), stalling the pipeline. At least, that's the statu quo. There are a number of circumstances which could be taken advantage of in the future: 1. Even though in general the number of implementations is unknown, in the particular case of a non-public trait all implementations are known, 2. Even though in general the number of implementations is unknown, in the particular case of a statically linked binary all implementations are known. When the implementations are known, then the virtual call can actually be transformed into a `match` statement, matching on the v-table pointer! In this case, we are back to the golden case of the `enum` above. There is one special trap to pay attention to: a statically linked binary can still load a DLL containing more implementations. Therefore unlike in case (1), in case (2) a generic fallback is necessary. Still plenty doable. It's also possible to go even crazier: GCC implements partial devirtualization. That is, it implements a partial `match` starting with the "more likely" candidates and ending up with a virtual call as fallback. This is possible even when the number of implementations is unknown a priori however it is only really beneficial in the case where the implementations pulled in the match are actually often the ones used. *Note: I believe that the JVM also has a special optimization for virtual calls through interfaces when it notices that the only one actual type implements the interface. It's a special-case of the match approach.* 
Have you considered a `[char; N]`? It's just an array of unicode codepoints, which is usually what you want if you want fast string character shuffling (caveat: it's not grapheme cluster aware).
Building a demo app with mio might help you understand what it does and doesn't do for you. If you have a bunch of pipes and sockets and you want to wait on all of them in parallel, mio totally does that. That's it's entire purpose. But often we want to do complicated bookkeeping on top of that. Like we want to run a big program that creates new pipes and sockets on the fly, that pauses gracefully when it's waiting on IO, and that resumes where it left off once the IO is ready. In the olden days everyone just used threads for this, and it often worked, but there was a fair bit of overhead. Now we want frameworks that make it kind of look like we're using threads, when in fact we're doing all this bookkeeping to keep track of where we stop to wait for IO, how to collect all the things we're waiting on at any one time (to hand them to mio / the kernel), and where we should resume. That bookkeeping is really involved, and totally determines how our programs are going to get written, and mio doesn't want to know about any of it.
Meetup? https://www.meetup.com/es Discord? A forum? 
What kind of code/memory layout does it compile to? Can it and does it compile to simple initialization code, or is there potentially a bunch of moves, either during the process or during the build? Does it deal with mutable/immutable lifetimes correctly? Can it copy/clone partial builders, according to copy/cloneability of the contents? Same with send/sync... basically, can you partially initialize builders and then reuse them or send them around?
How do i get the "POST" data from the incomming http request in the Hyper Webserver Service? impl hyper::server::Service for Hello { type Request = Request; type Response = Response; type Error = hyper::Error; type Future = FutureResult&lt;Response, hyper::Error&gt;; fn call(&amp;self, req: Request) -&gt; Self::Future { let header : &amp;hyper::Headers = req.headers(); //NEED POST DATA! } }
I've never used hyper, but are you looking for https://docs.rs/hyper/0.11.6/hyper/struct.Request.html#method.body_ref or https://docs.rs/hyper/0.11.6/hyper/struct.Request.html#method.body? Hyper is a pretty low-level library, it doesn't appear to have any convenience methods for accessing form data. 
https://www.reddit.com/r/rust/comments/736rmb/cannot_install_rls_nightly/
If you're familiar with Java, it might be useful to think of mio as the NIO API and Tokio as something like Netty. The analogy isn t perfect but it's not totally wrong either.
If you are OK with reversing the index order to `map[y][x]`, you could have `Index` return a slice of `&amp;map[y*WIDTH..(y+1)*WIDTH]`, which can then simply be indexed further by `x`.
Thanks. :)
This is also why benchmarking frameworks have [black holes](http://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-core/src/main/java/org/openjdk/jmh/infra/Blackhole.java).
Well, its possible to template something with a trait object, but the problem is that after you go another layer deeper the library gets to make the decision. One solution to this is to have a compact feature which optimizes the code for binary size for embedded platforms and the like, but retains the same behavior otherwise. With proper unit testing the code should operate the same. Edit: Just realized that any types explicitly used in libraries will only make one monopromorphization, and anything templated with the template argument will retain trait object status, therefore defaulting to monopromorphization in libraries is actually almost always ideal, except when the library itself is using trait objects entirely internally, in which case the compact feature would help.
&gt; What kind of code/memory layout does it compile to? Can it and does it compile to simple initialization code, or is there potentially a bunch of moves, either during the process or during the build? I fired up a local version of the compiler explorer with the flags `-O -C target-cpu=native` to have a look at that, using this example struct from the docs: #[derive(Debug, PartialEq, TypedBuilder)] pub struct Foo { // Mandatory Field: x: i32, // #[default] without parameter - use the type's default #[default] y: Option&lt;i32&gt;, // Or you can set the default(encoded as string) #[default="20"] z: i32, } I then provided the following code: pub fn test1() -&gt; Foo { let bar = Foo::builder().x(1).y(2).z(3).build(); bar } pub fn test2() -&gt; Foo { let bar = Foo { x: 1, y: Some(2), z: 3 }; bar } pub fn test3(x: i32, y: Option&lt;i32&gt;, z: i32) -&gt; Foo { let bar = Foo::builder().x(x).y(y).z(z).build(); bar } pub fn test4(x: i32, y: Option&lt;i32&gt;, z: i32) -&gt; Foo { let bar = Foo { x: x, y: y, z: z }; bar } The output of `test1` and `test2` did differ. It seems that when initialising with primitive literals the compiler is able to compress the data into fewer moves: example::test1: push rbp mov rbp, rsp mov dword ptr [rdi], 1 movabs rax, 8589934593 (encodes both the Some variant and the 32-bit value) mov qword ptr [rdi + 4], rax mov dword ptr [rdi + 12], 3 mov rax, rdi pop rbp ret example::test2: push rbp mov rbp, rsp movabs rax, 4294967297 (Encodes the value of x and variant Some for y) mov qword ptr [rdi], rax movabs rax, 12884901890 (Encodes the value of z and y) mov qword ptr [rdi + 8], rax mov rax, rdi pop rbp ret I didn't test a manually implemented builder pattern, so that may not do better. The output of `test3` and `test4`, however, show no loss: example::test3: push rbp mov rbp, rsp mov dword ptr [rdi], esi mov qword ptr [rdi + 4], rdx mov dword ptr [rdi + 12], ecx mov rax, rdi pop rbp ret example::test4: push rbp mov rbp, rsp mov dword ptr [rdi], esi mov qword ptr [rdi + 4], rdx mov dword ptr [rdi + 12], ecx mov rax, rdi pop rbp ret This is, of course, a simplistic test. More complex examples may vary.
Casting to `u32` and back with `char::from_u32` will let you handle all chars (aka Unicode scalar values, which are different to graphemes), although you'll need to be careful to skip the surrogate range of 0xD800 to 0xDFFF. I wrote https://crates.io/crates/char-iter a while ago, I don't/can't maintain it, but it sounds like it should be complete for your use case.
It's Apache 2.0 licensed, so if it's technically good and Oracle decides to be evil, it'll go the route of MariaDB. Life's too short to give corporate politics dominion over emotional state. :D
Thanks , i'll consider this :)
I wouldn't really call `tokio` a framework. The `tokio-proto` and `tokio-service` crates provide a framework for writing protocols and services, but I'd say that `tokio` is merely a merger of `mio` and `futures,` for providing a higher level, but zero-cost abstraction to `mio`. The tokio project as whole building on top of that with Tokio-based solutions.
Thank you for your response. I hope that this is possible, even with this "low level" webserver. The Post data should be somewhere in the header, I just can't get them out of there. 
Shouldn't the post data be in the body of the response?
For example: https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/POST POST / HTTP/1.1 Host: foo.com Content-Type: application/x-www-form-urlencoded Content-Length: 13 say=Hi&amp;to=Mom "say=Hi&amp;to=Mom" is the body of the ~~response~~ request. 
&gt; Does it deal with mutable/immutable lifetimes correctly? Should work. I have a test for immutable borrow, not for mutable one. [I just opened a ticket to add a test for mutable borrows](https://github.com/idanarye/rust-typed-builder/issues/1). &gt; Can it copy/clone partial builders, according to copy/cloneability of the contents? Same with send/sync... basically, can you partially initialize builders and then reuse them or send them around? No - I don't really see the point since I don't expect users to spell out the builder types. Still - if it's possible and not too complex I may add it. [Opened a ticket](https://github.com/idanarye/rust-typed-builder/issues/2).
Forcing user to deal with types in his own implementation of setters sounds like a only serious issue here. But I strongly believe there must be a way to overcome this.
This doesn't handle skipping the surrogate range.
I can think of two solutions, but I like neither: 1. Make my derive macro create a `macro_rules!` the user will have to invoke in order to customize their builder. But even a necromancer-type metaprogrammer like me thinks that's too much magic... 2. Make the user create a trait, and my derive macro will `impl` that trait for the builder type. The problem with this approach is that I can't feed the trait itself to the derive macro, so everything it does will have to be tightly coupled with attributes inside the struct...
That _will_ _be_ _epic_. I'm imagining a new language a'la 1337 speak or at least sms speak...
There's an [example of embedding Servo here](https://github.com/paulrouget/servo-embedding-example). 
ncurses
Wait is that why Atom shit the bed last weekend when I tried to update my Rust autocompletion to nightly?
Also, consider this: mod foo { pub trait Bar { fn x(self); } } mod baz { use foo::Bar; pub struct Qux; impl Bar for Qux { fn x(self) { } } } use baz::*; fn main() { Qux.x(); // no method named `x` found for type `baz::Qux` in the current scope } * I declare the method in `baz`. * I `use baz::*;` to import **everything** from `baz`. * I _still_ don't get the method - I need to import some **other** module to use it.
Very nice and lightweight. A little disappointed that it uses REST as the API instead of a lighter, lower-level protocol.
I really hate the idea of preludes - it means the system is so safe that it encourages people to break basic safety rules(the wildcard import antipattern) to sanely use it.
I would to provide in other ways also
ncurses has been out for a quarter of decade or am I misinterpreting the question?
We already have [cursive](https://github.com/gyscos/Cursive).
What about pancurses? 
Hi all! Project Fluent is getting ready for the initial release of our localization library in Rust. As a stepping stone, I'm releasing a library that is serving us for language negotiation purposes and may be useful for other cases where operations on language tags and locales happens. We're not very experienced with Rust, so any feedback or suggestions for improvements will be very appreciated. :)
It would be great to have full implementations of HDF5 and MPI. Sadly, for me, rust isn‚Äôt a viable option for my daily coding until then. 
From your username, it sounds like you do Astronomy. I do! I just started doing some supercomputer work, and I wouldn't mind looking into MPI if you're interested in collaborating. 
Bindings to [libdshowcapture](https://github.com/jp9000/libdshowcapture), which is a webcam capture lib, using DirectShow, written by the guy who also wrote OBS-Studio (Open Broadcaster Software).
Some sort of gpg interface. Haven't found anything I really like for that so far.
CLDR and/or ICU please! :) We're about to release a localization library, but would prefer not to reinvent the wheel when it comes to low-level intl (plural rules, date time formatting etc.)
/r/playrust please at least look at the sub before posting, ok?
Gracias, es much mas claro ahora.
You could also do `path.to_string_lossy().to_string()` or `format!("{}", path.display())`, depending on what you want to do. If you want to use the path for more path operations you shouldn't convert it to a string and back to path though.
Either of these would be nice: * TR39 skeleton algorithm for unicode confusables (Turns things like "ùî≠ùí∂·ªøùï°ùïí‚Ñì" into things like "paypal" so you can treat lookalikes equally in tasks such as blogspam filtering.) * A GNU gettext-alike that is complete enough to have a Rust version of the "parse source code to extract translatable strings" utility. I checked crates.io but couldn't find any candidates.
I'm using "fairer" in a relative sense. It's not completely fair of course, that's hard to do, but at least with this the enum dispatch exists. This is fairer because in general the compiler won't be able to completely optimize away the enum dispatch (otherwise why are you using the enum at all?). There's still many things the benchmark doesn't capture, but microbenchmarks aren't good at measuring all possible effects.
If you've read every last thread, how did you miss that none of them are about a video game? 
I'd like to see an SSL library in pure Rust, not bindings. I'm not sure if that's feasible at the moment but it would make things a little simpler.
FYI: your link 404s for me. Did you make the repo public?
A library to craft packets similar to scapy.
I think that'd be something for an entire team to plan and attempt, given how complex SSL is.
Web scraper framework
Yea I thought this was a different subreddit than it was
Not literally ncurses, but a modern ncurses like library (likely a ncurses wrapper) that allows people to write TUIs in idiomatic rust. 
I'm not at all convinced that wildcard imports are an antipattern compared to the alternatives. They express to me "the items of that module are a key part of the vocabulary I'm using in this scope." If that's in fact true, it really doesn't help to add `that_module::` everywhere or to have a dozen specific `use` statements reminding the reader what the public interface of `that_module` is. Both can be awful noisy compared to a tasteful wildcard. If I don't know how to use `that_module` *thoroughly*, I'm certainly going to have rustdoc open. Writing clear imports is a hard problem. It's hard because it's an extra stylistic touch beyond merely getting the module to work. And it's hard because it involves the interface between something encapsulated and the wider world. The antipattern instead is too many wildcards: bunch of imports at the top of the module, splat all the things. It means the writer didn't have a good view of what vocabulary is most important in each scope. It tells the reader "know what everything is and does" - the compiler can handle that but humans can't.
Qu√© la pasen muy bien
[rustls](https://github.com/ctz/rustls) is pretty much this. Admittedly, it depends on [ring](https://github.com/briansmith/ring), which is a mix of Rust, C, and assembly, but it's not currently possible to write a crypto library in pure Rust that's knowably safe from side-channel attacks, so that's the best you can do.
Cross platform Bluetooth LE library
are you aware of [libpnet](https://github.com/libpnet/libpnet)? It's not as ergonomic and not as feature rich than scapy though.
Some sort of library to interact (read and write) with /proc/ would be nice.
[removed]
Does the generated server code work with **any** Rust web framework? E.g. Rocket, Iron, Shio. Or only all synchronous ones?
Is there no way to eliminate the transmute? Maybe with `struct Strided&lt;'a&gt;(&amp;'a [Tile]);` and then `impl&lt;'a&gt; Index&lt;usize&gt; for Strided&lt;'a&gt;` and then returning `Strided(slice)`?
bad bot
Ah no, then it'd be `type Output = Strided&lt;'a&gt;;` but `'a` has to be the lifetime of self... It's sad that it's not possible without transmute :(
Sorry I deleted it, but I'm planning to use Rust on another project soon :)
It looks like that exists, at least somewhat: https://github.com/danburkert/procinfo-rs
bad bot
I tried to use this a while back but it wasn't quite what I was looking for. 
https://www.reddit.com/r/rust/comments/74rv6r/fluent_locale_library_for_language_tag/?st=j8gpoq6q&amp;sh=02572aff was just posted, might be of interest!
Out of curiosity, what is it about C that lets us know the compiler won't insert non-constant-time operations in there?
Bindings for libhdfs3
[termion](https://github.com/ticki/termion) is a good full-rust ncurses alternative.
Just curious, what were you looking for that this didn‚Äôt offer?
Thorough testing/vetting I would suspect. But I think the broader point might be that Rust doesn't enforce that kind of correctness by default, making new implementations a risky proposition. Even when written in Rust.
So an event loop is part of that book keeping? 
&gt; I'm not at all convinced that wildcard imports are an antipattern compared to the alternatives. That's what I'm saying - if an antipattern is the best way to do it within the boundaries of the system, that's a good indicator something is wrong in that system's design. Prefixing things with `that_module::` or having `use` statements for every identifier you use is not that bad if the module is designed around objects - and most libraries do(at least in languages that support that). So you only need to prefix/import if you refer to a type, create a new object or call a standalone function - but most of the time you will be calling methods of objects you already have(fields of your own objects or objects returned from methods), so in practice you won't end up with that many prefixed identifiers and `use` statements. Unless you are using Rust - where if a method happens to declared with `impl Trait for Type` instead of `impl Type` you'll have to import that trait into scope...
Hmm, maybe a Rust implementation of GMP?
Is there a single producer multiple consumer yet? There was a [multiple producer single consumer library](https://doc.rust-lang.org/std/sync/mpsc/) very early on in Rust's history but I wasn't aware of the other way around. It would be useful to generate a queue from which multiple workers could fetch items of work.
I'm also really interested in this but haven't had the time this year to spend on it. If you make a start I'd be keen to check it out!
Some things that would be useful in really polishing my NVR project: RTSP (as a client, and probably eventually as a server). I'm using ffmpeg now, but I'd rather use a modern, pure Rust library. I'd also rather use a RTSP library than an abstract video source library, so I can directly use concepts like the RTP timestamps vs the RTCP Sender Report timestamps. SOAP, because ONVIF uses it. Lots of other things do too. H264 and H265. Not necessary a full decoder (although I'd love that, particularly if it could take advantage of hardware acceleration like OpenMAX). Even just basic sanity checking of NAL boundaries, knowing when there's a new sps/pps, knowing precisely what frames depend on which others, and such. letsencrypt + hyper integration. I give it a hook for my certificate store (my project has a sqlite database, maybe eventually something else) and it keeps hyper using a good tls cert, and maybe updates a monitoring hook. Prometheus monitoring client library. A really good key/value embedded database. SQLite is a bit slow with its interpreted vm, and I don't need SQL anyway. The RocksDB crates seem immature (bare pointers in the API in some places). lmdb (and sanakirja) is inefficient with values ~4 KiB because it hardcodes that page size and uses one overflow page per entry. zeroconf/upnp to find devices and to expose a port to the Internet. Oh, and a dyndns client to publish an address. Motion detection, with a good algorithm (maybe one described at changedetection.net) and good performance (SIMD and/or GPU offloading). I'll likely make some of these eventually if no one else does, but I don't have a lot of time for this project, so I move slowly. 
It bothers me greatly that go currently ships with a native crypto/tls stack. Albeit written by brilliant security folks. To their credit, around 2013 they expressed that the TLS stack should not be used for production purposes until properly vetted/audited/tested. Obviously this has not hampered adoption by projects like caddy (14k stars on Github), who's niche is to provide a hassle-free https server. A use-case obviously targeted towards the web. This seems like a huge risk/reward. You don't want to become the language that causes the next global security incident. But TLS is a _huge_ use-case that drives adoption. I love Rust for putting safety first-and-center. But right now It's really hard to ship projects which use TLS.
I think so. A single future might say "I want to wait for this socket to be readable", and then it's the event loop's job to actually wait on the socket and re-poll the future when it's ready. There might be many futures waiting on many sockets at the same time, and in the case of `tokio`, I think that means the event loop needs to collect them all into a single `mio::Poll` object.
This can be maybe automated with a build script or something..
There's nothing. Even in C, the core primitives are almost always written in assembly and these are used as the constant time building blocks for higher level algorithms.
Very nice article but I don't really see how it is related to rust.
Ah alright makes sense. Thanks.
proj4 and GDAL reimplemented in rust. Recently there was an AMA on /r/gis where they admitted that memory allocation bugs and memory leaks are common in both libraries. Rust could definitely help here. Plus a font shaping library, a better font library (more formats than just TTF), a postscript library and something like ICU. I know, I can dream. EDIT: Link to the comment: https://www.reddit.com/r/gis/comments/72tj6t/i_am_anita_graser_open_source_gis_expert_mobility/dnlhmyu/
Look in the src/ directory ;)
There is [spmc](https://crates.io/crates/spmc) for a straight forward solution.
I've noticed this function in _ring_ before (not sure where it's from originally) and wondered about it: int GFp_memcmp(const void *in_a, const void *in_b, size_t len) { const uint8_t *a = in_a; const uint8_t *b = in_b; uint8_t x = 0; for (size_t i = 0; i &lt; len; i++) { x |= a[i] ^ b[i]; } return x; } I think all constant time comparisons in _ring_ are based on that function, but is there any standard anywhere that says the C compiler can't rewrite it with an early exit? How do we get away with not writing it in assembly?
as someone who imminently needs one: A complete ISO9660/UDF implementation.
No I am not. Will take a look at it when I get a chance. Thank you.
I do astrophysics and code in Rust on my free time. I'd like to join this party 
the finished runtime @.@ w/ a sick scheduler
What I mean with "breaing semver" is that you don't need to increment the major version number by exporting a new binding in your library while this can have breaking behaviour in the code that uses it and alter its semantics.
If I was to start hacking on a realtime mail syncer that made use of IDLE &amp; other IMAP extensions, how would I move forward?
Why GPG? Isn't sodiumoxide better? I avoid using GPG because it was designed as a command line tool, not a library, and embedding it sucks.
https://github.com/pingcap/rust-prometheus for prometheus. It works well enough for me 
I dream of the day there is a simple Rust API to embed Servo, to compete against Electron with much better speed, and much smaller package sizes.
&gt;I avoid using GPG because it was designed as a command line tool, not a library, and embedding it sucks. Why not use PGP that GPG uses?
Full HDF5 isn't easily implemented. Afaik there is a single full implementation and it has Rust bindings. Anything wrong with bindings? 
A CANbus library that works the same under Linux and under japaric's embedded framework.
An MQTT tokio library
Last I checked, none were very usable. I think one, for instance, had some writing support but no ability to read the files. Edit: [this one](https://github.com/stainless-steel/hdf5) writes but cannot read. [This one](https://github.com/aldanor/hdf5-rs) seems more featured but the documentation site isn't working, so I can't quickly check to see how much of HDF5 it supports. But it seems more thorough than the other one. Neither project has seen any activity in several months. I'd even be happy with a decent netCDF wrapper. [Here's one](https://github.com/mhiley/rust-netcdf) that had some promise but hasn't had a release in over two years, shortly after Rust 1.0. It has had some recent activity by another contributor though.
The [georust](https://github.com/georust) group is working on bringing rust to geospatial. 
Something like [unidecode](https://crates.io/crates/unidecode) for your first problem? I'm not sure it is doing the same thing but it looks similar:)
It's quite likely that Rust closures and custom derive will make for a *much* more ergonomic MPI API that feels like rayon but isn't.
Nothing; C lets you do stable inline assembly and it's the assembly that's important. 
No, I don't think there's anything preventing a compiler to do that "optimization".
How does this implementation differ from the existing Rust one mentioned in the PR?
Don't use GPG from within other programs, that's what GPGME is for. And that's a library 
I wrote https://GitHub.com/spacejam/void on termion, it gives you a lot of flexibility
I was already aware of Unidecode and it's not at all the same thing. [TR39](http://www.unicode.org/reports/tr39/) is a standard with [very specific](https://unicode.org/Public/security/latest/confusables.txt) official mappings and was crafted in response to a specific class of security exploits involving similar-looking characters. Unidecode is a transliteration (ie. "√ü -&gt; ss" rather than "√ü -&gt; B") library intended as a best-effort solution for presenting information to humans. Using Unidecode in place of a proper TR39 skeleton implementation would be like using `Path::to_string_lossy` as part of the round-tripping for a filesystem walker. (eg. The Python version of Unideode turns "ùî≠ùí∂·ªøùï°ùïí‚Ñì" into "papa".)
While the rocksdb library is a bit rough in some places, it is in production at several high scale places and is pretty solid. I'm also writing a pure rust high performance bw-tree, https://GitHub.com/spacejam/sled which should be production ready in a few months (don't use it for anything critical right now) but it's on its way
rust-derive-builder supports `#[builder(derive(...))]`. I think it could be possible to create separate crate that will decorate methods generated by rust-derive-builder with all those required type parameters. It will make implementing own setters near impossible and definitely impractical but I think it may be to say that this 'plugin' is not compatible with some use cases.
GPGME is just a wrapper that spawns GPG as a command line tool, drives it's IO, and parses output. See `_gpgme_io_spawn` in `src/posix-io.c` that is called from `start` in `src/engine-gpg.c`. It was slapped on top of gpg-the-binary because people got tired of doing that stuff manually. It's ridden with problems which you get to discover as soon as you start doing something non-trivial (just like gpg-the-binary does). I have a huge respect for all people involved in PGP/GPG, and I'm using it myself. I have Yubikeys with GPG support, "perfect keypair" with a master key in cold storage, etc. However, I would I just lie, telling anything less than that I consider it an underfunded, archaic, poorly designed, and barely usable turd. There is so much wrong with both PGP and GPP on so many levels... Fully aware of my arrogance, I am still thinking about writting my own, simple, replacement, probably based on libsodium that is Rustic, modern, modular, drops the web of trust, that noone uses in practice anyway, and replaces it with something https://ssbc.github.io/secure-scuttlebutt/ -like. Maybe even with some hardware-wallet support. But oh well, I don't have time to do it alone, and I'm aware that it's easier said than done. **Edit**: I forgot to actually make my point. Please don't use GPG, and just let it die in peace.
And DOM manipulation in rust
That would be the cherry on top. I'd settle for a good API to interface with JS.
The kernel is pretty good at that these days.
That would actually be quite unlikely: - 1) closures cannot be easily mapped to MPI operations. When they can, the mapping itself is expensive (you need to allocate and deallocate operations). Also, MPI does asynchronous communication in single threaded applications (e.g. by running the communication in the interconnect CPU), Rust futures would suck here (you would need to manually advance them, or add a thread that manually advances them which defeats the point of using futures). - 2) while custom derive could be used to improve how MPI data types are declared, doing so is really rare. So you could make MPI a bit nicer, but only somebody who hasn't ever used MPI would say that rayon like is possible. EDIT: where I said closures, I meant lambdas that decay to function pointers. IIRC closures would need you to make their state global because MPI does not pass operations a pointer to a context (e.g. So that they can access the captured environment).
hm, fair.
Thanks :)
Not gettext, but my team is gearing up for a release of fluent-rs which is a rust implementation of Project Fluent. You can think of it as a next-gen gettext based on Unicode MessageFormat https://github.com/projectfluent/fluent-rs http://projectfluent.io/
MPI is extremely flexible, performance oriented C library from an era of non-optimizing compilers designed by non programmers. It is extremely untyped (data types are integers, "operations" are integers, new data types are integers... integer types are not sized... ) and although it is a C library it does not follow a single C convention... Clang and clang-tidy actually have compiler plugins to "type-check" uses of MPI... The worst part is that it has become the lingua franca of HPC and we are forced to build on top of it... All MPI wrappers are doomed to fails because it is basically impossible to write a nice one... one can make MPI nicer to use, but from there to nice the road is long, all wrappers remain completely unidiomatic in every language. 
The inline assembly in C is not "stable": its not normatively specified by the standard. Its only available via pragmas, and [different implementations have different behaviours](https://stackoverflow.com/a/35959859). The difference between C and Rust is that in the C world, unstable extensions are available on stable compiler releases, while this is not the case for Rust.
To be honest. Maybe. Any idea how to get the POST data? it is possible to send POST data back to the client ... so I would be very surprised if it's not possible to get the received ones.
At this point in time RocksDB is the standard for high performance storage. It's used in production by a lot of people/places/humongous volumes of data. IMHO it's a complex beast though, kinda bloated and hard to tune.
Are you looking for a project to write in Rust? What interests you?
We have crates to put things into zip folders or tarballs, so the next nice step for me would be an ISO 9660 crate, creating `.iso` images from directories. I gave it a try, but that file system format is just too ridiculous, so I gave up on it. Needs braver devs than me.
I see no ncurses stuff like pads, subwindows etc in the documentation. Is it easy to implement such stuff in termion?
MPI is not so great. It has a weird mix of abstractions and it is not fault-tolerant whatsoever. If you can, I would try to rather use something like ZeroMQ (for which Rust bindings already exist).
In high-energy physics, some experiments (ALICE, FAIR) are using ZeroMQ instead of MPI, because they need the fault tolerance.
I'd like to see libraries you could embed into your `build.rs` that would install manpages and shell completions at compile time. Admittedly I could probably do this myself but I haven't had the time yet so :|
[removed]
A million times this. It's been great to see some efforts in this general area lately, with Limn and embeddable libservo, but we're not quite there yet.
In addition to the GUI stuff listed above, I'd like a matplotlib or Ggplot2 equivalent in rust.
Reimplementing a puzzle solver I wrote in python into rust to get a bit better at using rust as well as trying to use Rust's type system to help keep me honest and nudge me to make my puzzle solving methodology more formally clear (and maybe squeeze some better efficiency and effectiveness out for partial solutions in cases where formal clarity means not throwing any available information away in the solution algorithm). I'll get around to trying to parallelize some of the hypothesis testing next week for good measure I think.
It's not c. 
Ashley Williams gave [a talk at Rust Fest 2017](https://youtu.be/GCsxYAxw3JQ) that addresses your topic. Definitely worth a watch.
Video linked by /u/dotzak: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [Ashley Williams - How I Convinced the World's Largest Package Manager to Use Rust, and So Can You!](https://youtu.be/GCsxYAxw3JQ)|Rust|2017-05-12|0:37:34|247+ (96%)|12,087 &gt; I made one of my favorite pull requests ever on December... --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/dotzak ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=do13c4k\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v2.0.0
*C++
I don't do astrophysics or anything similar, but I'm hugely interested in it and I heard something about a party :3 üéâ 
I'd love to have game development libraries, such as Piston, get much more mature and feature-rich.
The generated code is aimed at hyper/iron. But the coupling to a particular server is quite weak: the models and the trait representing the API could easily be reused with other servers. Indeed it seems as though [a move to Rocket might be on the cards](https://github.com/Metaswitch/swagger-codegen-not-forked/issues/3).
The existing generator is client-only. Also see [this comment](https://github.com/swagger-api/swagger-codegen/pull/6105#issuecomment-320300513)
I am, I tend to be more interesting in the more security side of things and also communications and concurrency.
It's an awesome game &lt;/sarcasm&gt;
The thing I don't "like" about ZeroMQ is that one must "manually" handle process start and the lack of job system support. Overcoming these issues is possible, but it is a lot of work (spawning 100k processes efficiently is non-trivial). MPI handles this for you and this convenience is hard to beat.
[removed]
I'm glad to see people working on language support for Rust. Just a quick bit of feedback: you generally shouldn't be taking `Vec&lt;_&gt;` as an argument like you are with `negotiate_languages`. Unless you *need* to own the elements (which you don't appear to), or you *need* resizable storage (which you don't appear to), you should be taking `&amp;[_]` instead. It's like asking for an IKEA shelf specifically, when really any brand will do. **Edit**: for bonus points: if all you ever do is iterate over the elements once, you could also take an iterator for maximum client-side flexibility.
Well, there's [stdweb](https://github.com/koute/stdweb), but it's definitely not complete, and it's arguable whenever it could be called good... (:
- localization (gettext/qtranslate alternative) - 2d rendering (cairo/qpainter/skia alternative) - GUI, obviously UPD: text rendering library (fonts, layouts and all the magic) (like freetype, harfbuzz, pango)
I'll be honest, the reasons why I switched to rust are not related to memory safety. It's a nice-to-have, but was not required for my application. You can get a lot of "safety" with modern (C++11 and C++17) features. I can't say that Rust is the language for all development. If you want quick prototypes, for example, Rust is not for you. There are a lot of libraries still missing. The first reason why I switched to Rust was (in my case) because I discovered the `glium` library. I needed a language that is fast and has some form of access to OpenGL, for application development, not game development. Plus, I must be able to distribute it as a single binary without jumping through hoops. I did write regular OpenGL code in C++. However, doing so was error-prone. With `glium`, I could draw a triangle in less than half an hour. With OpenGL, I spent days configuring GLFW and wading through - sometimes outdated - tutorials. In Rust, the documentation is always up to date and contained in a single place. This ties into the second reason why I used Rust: I can use other peoples libraries. This was not (reproducibly) possible in C++ - let me explain: Let's say I wanted to unzip a file. I need to use the zlib library (example, for most libraries, "zlib" is just a stand-in). How do I get it? Go to the authors website, find the download link, copy it all into my repo, include the headers and find the documentation link (if you're lucky and it's not a 404), and discover that nobody bothered to document it because "we all know how it works". Find an email address to a mailing list, complain to the author that there is no documentation, get a response a week later that this mailing list is dead. This example is exaggerated, but highlights the problem I mainly had with C++ - no standard build system means that I can't use the code from other people in a reproducible way. Also, I used CodeBlocks for development and CodeBlocks sucks. It constantly corrupted my source files or forgot settings. Many people work around the dependency problem by adding the original repository as a sub-repository in git. But this is a workaround and git was never meant to do dependency-tracking. Or writing custom makefiles and shell scripts or whatever. Yet other people use linux for dependency management, but linux dependencies suck, too: Usually, the package is called "libxxx-dev" , the library is called `libxxx.so` and installed in `/usr/lib` and the headers are in `usr/include`, right? Well, in zlibs case, the package is called `zlib1g-dev` (wtf?), the library is called `libz.so` and it is installed god-knows where. It sucks. Constantly have to google "where is libz installed?". I have better things to do. With Rust, I know what to do: put `zip = "0.2.6"` into my dependencies, import the library, go to docs.rs/zip and look at the /examples folder. Bam. I can get shit done within 15 minutes. Good dependency management was really the tipping point for me. Also, headers. I hate having to copy-paste the function into the headers, it's just duplicated work, really. All in all, it took me three weeks to transition from C++ to Rust. This is a reasonable investment and Rust has taught me to think differently about memory. It is not a silver bullet - ex. you can still have deadlocks in safe Rust. But Rust is at least a step up from C++.
[related discussion](https://www.reddit.com/r/programming/comments/73vua5/benchmarks_showing_electron_apps_are_super_slow/dntjo4r/?context=3)
Thank you! I will look into it.
i also do astrophysics in rust. keep me updated if yall do something, i can help
Goood ... i may use this as introduction ;-) 
... befor google knew that i want the real Rust ... it was really a pain ... "rust list" =&gt; a list of RUST game servers ... wtf? edit: Spellin! who exposed me as an Austrian
Thank you for for you Answer! May I ask how many years of C++ experience do you have?
IMO it would be much nicer to have old libraries not be abandoned.
I would love to see an image processing library (OpenCV like) to be written in Rust.
The worst part is that they got "public" around the same time, we regularly have Rust players posting on this subreddit ;)
Is `mio` essentially a Rust version of `libuv`? (I'm only glancingly familiar with `libuv` as well, so I'm as interested in clarification about that half of the equation as about `mio`!)
Could easily have just used a `Arc&lt;Mutex&lt;VecDeque&lt;T&gt;&gt;&gt;`. That's what I use for implementing work-stealing, and having workers re-insert failed jobs to retry later.
I would love to see some async database drivers
I had never heard of this project but apparently it has been [funded on Kickstarter](https://www.kickstarter.com/projects/njones/imageflow-respect-the-pixels-a-secure-alt-to-image/description) to the tune of $60K! That page has a useful FAQ if you'd like to learn more.
- Sane build and dependency management. - Low-level language with modern ergonomics. - Nice helpful community, emphasis on making things documented and accessible. - Memory safety guarantees + expressiveness is very enabling: I try many new things in Rust I didn't feel motivated to do/learn in other languages. This is the big one for me. (I guess this is Fireflower vs. fire Mario again) - ^(It's not C++)
Or some html to pdf/png functionality
There are different reasons depending on your background, but let's not talk about THAT. The most interesting point of Rust, for me, is that Rust is a clean slate, free of the shackles of backward compatibility that bind the current mature crop of programming languages (at any level). This in turns means that Rust can leverage the last 30 years of programming language research to propose new alternatives to existing issues. It even innovates, actually. By comparison, all current top programming languages are mostly similar. There are mostly superficial differences between the type systems of C, C++, C# and Java; nothing "ground-breaking". The best known example of this breath of fresh air in Rust is of course its ownership/borrowing system. A crystallization of Affine Type Systems and Regions which allows memory safety and data-race freedom checking at compile-time. Still less known is the fact that the very use of Affine Types allows modelling State Machines in a way that the compiler can ensure that only proper transitions are made *at compile-time*. This may sound rather theoretical, until you realize that most specifications of the form "if A do X else do Y" and indeed most "data flows" can be modeled as State Machines! Citing from [Munksgaard and Laumann's thesis on Practical Session Types in Rust](http://munksgaard.me/papers/munksgaard-laumann-thesis.pdf): &gt; Specifically, we replace parts of Servo‚Äôs internal communication infrastructure with session-typed channels, and demonstrate that the use of session types allows us to provide compile-time guarantees, without incurring any significant run-time penalties. None of the current top-10 programming languages have anything remotely available for such enforcement of correctness; the best you get are C++ move semantics and their correct use is only enforced at run-time. And none of the other new kids on the block (Go, Swift, Nim, Kotlin, Ceylon, ...) come anywhere close, they mostly slap pretty syntax on top of well-trodden semantics. *Note: Ada, and notably Ada Spark, does not make it in the top-10, but offers a lot; if you are interested in this topic you may want to seriously check it out.*
Still the overhead is just not worth it
In a general sense, yes.
You want r/playrust, this is a programming language!
Sounds like there is an opportunity to make Cross Machine Rust, extending channels across [rdma links](https://en.wikipedia.org/wiki/Remote_direct_memory_access). I could also see something like [Fork Join](https://en.wikipedia.org/wiki/Fork%E2%80%93join_model) with cross machine borrows. I don't know how fault tolerance would work. Traits for incrementally saving state for an in-process [checkpoint](https://criu.org/Main_Page)? Seems like it might be helpful to steal a bunch of ideas from Erlang, Pony and Eiffel.
**Remote direct memory access** In computing, remote direct memory access (RDMA) is a direct memory access from the memory of one computer into that of another without involving either one's operating system. This permits high-throughput, low-latency networking, which is especially useful in massively parallel computer clusters. *** **Fork‚Äìjoin model** In parallel computing, the fork‚Äìjoin model is a way of setting up and executing parallel programs, such that execution branches off in parallel at designated points in the program, to "join" (merge) at a subsequent point and resume sequential execution. Parallel sections may fork recursively until a certain task granularity is reached. Fork‚Äìjoin can be considered a parallel design pattern. It was formulated as early as 1963. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
Why "optimization" in quotes? That would be a valid runtime improvement, although a very specialised one that it'd be hard to pick up on in practice. (And obviously the compiler wouldn't know that we wouldn't want a runtime improvement here)
Some way to properly write unit tests and mock MySQL stuff. I've tried hackin' around the current implementation, and the lifetimes just don't seem to allow it:( Honestly, feel like the lack of good unit testing really is the last thing stopping rust being 'properly web', most other things are covered - any 3rd party APIs are easily done with HTTP clients, mysql + mysql_async is great, async web frameworks etc etc... Maybe an async logging lib?
&gt; Why "optimization" in quotes? That would be a valid runtime improvement It may or may not, depending on how large the buffers are, how random is the data and so on. But you're right, the quotes weren't really warranted. &gt; although a very specialised one that it'd be hard to pick up on in practice [Well...](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=56888)
What do you think of [this](https://crates.io/crates/mpi)? It's not a native implementation, but I'd think that was preferable because it lets you use C MPI libraries that have been much more thoroughly developed.
Some folks at Cambridge (UK) looked into this at one point and had some thoughts (they stopped working on it, for some reason). I'll see if I can reconstruct what issues they had and report back! Edit: also, while not exactly what you probably would want, the [timely communication crate](https://github.com/frankmcsherry/timely-dataflow/tree/master/communication) allows you to mint up typed point-to-point channels between workers as long as the types implement its `Serialize` trait (and many `Send` implementors do). The underlying serialization (Abomonation) is pretty light, and you get the experience of moving owned data around between workers.
Wouldn't it be best to have both? A library and then a GPG compatible command line API built on top of it.
Saving state is another thing zeromq doesn't cover. Writing to a single file from 100k processes is also pretty hard to do efficiently :/ You need to cooperate with the hardware at the node level, the cluster level, the parallel file system...
The main appealing feature of MPI is that a very large body of already-written software targets its specific API, and approximately none of that software is ever going to be re-targeted at a more modern API. Either you implement MPI and get access to all the scientific codes using it, or you implement "a more ergonomic API" and get access to none of it. If you are interested in more ergonomic interfaces to cluster compute, I recommend at least considering something like [timely dataflow](https://github.com/frankmcsherry/timely-dataflow).
&gt; setup.py which compiles a rust library and then constructs a cffi module &gt; &gt; some utilities for error handling between rust and python nicer &gt; &gt; an example python module that works with the rust lib Page not found
Fixed the links.
It is totally valid to [answer your own question](https://stackoverflow.com/help/self-answer) on SO. 
Localization: Yep, it would be nice if there would be a proper implementation, that feels rusty and at the same time uses some standard, so it could easily be used with existing infrastructure (translation software, web services). 2D renderer: Have a look at webrender. GUI: That's a difficult one which I hope will be solved by the end of 2018.
[removed]
&gt; It may or may not, depending on how large the buffers are, how random is the data and so on. But you're right, the quotes weren't really warranted. I actually misread the code earlier, and there is something that stops the compiler exiting early. `x` is an `int`, not a `bool`, so you can't just exit early whenever it becomes `&gt;0`, you have to check that it's `!= INT_MIN`, which is presumably going to consume all the speed savings you'd get for all but the longest lists. 
Without at least partially-automated conversion, this would be a seriously daunting undertaking. Geo is niche (in terms of developers) ‚Äì I work on [rust-geo](https://github.com/georust/rust-geo), and we have a tiny number of regular contributors. You'd need several regular, experienced contributors, working for long periods of time, to port something like GDAL, and although it pains me to admit it, there just aren't enough interested Rust users at the moment. Maybe if Map{box, zen} got interested in switching and committed paid devs, but the reality is that even if these libraries are a bit buggy and leaky, they're nowhere near buggy and leaky enough to warrant a move like that as it stands.
Oops wrong subreddit haha, thank you!
Holy shit, a rust to spirv for vulkan? That would be awesome!
Relevant section "Is it accurate to say that imageflow is "Rust-based"? No. Version 1 of imageflow will not be 100% Rust. We mention Rust in the specs because people would be upset if we promised vanilla C11 and delivered them Rust. That's why we say C + Rust. Imageflow-server should be 100% Rust unless we hit a major blocker; but it will call into libimageflow, which is *NOT* 100% Rust. Obviously, we hope to reach a high percentage of Rust in the codebase for security reasons. No, we are not guaranteeing a certain percentage. We'll do our best, but we have a long list of things to work on, and porting to Rust will fall behind most of those in terms of priorities. Last updated: Sun, June 5 2016"
Yes but SPIR-V is relatively limited which means that I can only translate a subset of Rust. Expect a blog post in a couple of days. :)
Rust code was 47% as of 4 days ago https://github.com/imazen/imageflow
That's super cool. Keep it up. Would love to write shaders in rust with proper includes and everything. 
Thank you! Filed an issue: https://github.com/zbraniecki/fluent-locale-rs/issues/1 :)
Yeah, RocksDB would likely work out well, I just think the crates' APIs could use some polish. Nothing that can't be solved but I haven't had time to contribute.
Traits are a new concept, a new part of speech that doesn't exist in traditional OOP. They represent encapsulated behaviour abstracted from data representation. This is different from a class, even an abstract one, because it has no fields. This is different from an interface or superclass because it's not a declared supertype of any concrete type. (The `Type: Trait` notation is a bit misleading. It's also used for Rust's subtyping; however, Rust only allows a true subtype/supertype relationship when the bytewise representation is identical.) In OO languages, interfaces and mix-ins allow the declarer of a type to extend it. In Rust, Traits allow *user* code to abstract over different types and thus users may take a trait or leave it. I agree it would be useful to allow a type's inherent `impl` to export methods from a trait. (`BufReader` has no public methods of its own.) The most natural syntax for this would imo be `pub use Trait::*;` within the `impl` block. It shouldn't be automatic. (The change would break existing code.) In Rust as it is now, if a Trait is necessary for using a library, it should be in the library prelude. User code still has the option of not importing it. I believe the Rust Book *should not* say that Trait inheritance is like OO inheritance. Trait inheritance is like abstract algebra: given basic operations which obey certain postulates, other operations are defined which obey certain theorems. For example, If you define an inner product, that automatically defines the angle between two values. Rust will only expose those methods to code that cares about inner product spaces and their properties.
It depends what you count as "experience". I started programming six years ago in C++, however I am self-taught and have had other hobbies in this time, so I can't really count it as "six years of experience". I also forgot a lot about C++ because I couldn't use it at my job. I used it once for a CSV converter. [This](https://github.com/fschutt/dbflib) is sort-of the level of C++ I wrote. I have not written C++ professionally or on contract. My (non-programming) job sucked, because the work wasn't automated enough. I left the company and started writing cartography / automation software in C++ at first, [here](https://github.com/fschutt/mapedit-old/tree/master/src/common) are the remains of my last efforts to use C++ productively. After that, I rewrote this application in Rust (since I quit my job, I used Rust in full time). [This](https://i.imgur.com/nwX92FN.png) is the service and [this](https://i.imgur.com/zc796rl.png) is the rust application for it. The application basically handles all the cartography and management / version control / data loading + rendering, font and PDF management and export. Current software solutions for cartography suck, so I started from scratch and it's going quite well. I usually open-source the libraries I make to build a portfolio of sorts. In these six years of learning, I've also used PHP and JS to build websites. I actually wrote a full customer management system for my old company, but it got rejected by management because "you are not a professional programmer". 
I have been using [pingcap's fork](https://github.com/pingcap/rust-rocksdb) in [Sucredb](https://github.com/arthurprs/sucredb) for a while now. Works mostly well.
yes, I know this. Not saying everything has to be in Rust. A lot of proj4 is just math, though and math is easier to port. GDAL, however... It would at least help to have bindings to these libraries. The last bindings to proj4 are two years old, GDAL bindings are one year old, only -sys bindings. Would be nice to have at least better wrappers for them.
I should've mentioned that in my previous comment, the main thing I was missing was an interface to /proc/&lt;pid&gt;/maps or /proc/&lt;pid&gt;/mem
Feel free to open an issue about specific things you would like improved.
A full-featured, compliant OAuth library. That's not a trivial undertaking.
&gt; I love Rust for putting safety first-and-center. But right now It's really hard to ship projects which use TLS. It's much less annoying that you might think! The two key pieces are: 1. Use `native-tls` so that you use the OS TLS framework on OS X and Windows, and resort to OpenSSL only when absolutely necessary. 2. Use `musl-libc`, a statically-compiled OpenSSL, and `openssl-probe` to develop 100% static Linux binaries that work cross-distro. I've automated this with my [rust-musl-builder](https://github.com/emk/rust-musl-builder) crate, which comes with setup instructions for Travis CI. Using this approach, you can use TravisCI and AppVeyor to build distributable Rust binaries for OS X, Windows and Linux x86_64 with only a small amount of fussing around. Of course, an even better approach would be to have a 95% Rust, 5% C/assembly implementation of TLS that required no external dependencies and which supported cross-compilation using a custom `build.rs` and the `gcc` crate.
Yeah, I'm aware, but you don't need to use a trunk compiler for it is what I meant. Carried over rust terminology into the C world, oops.
I know exactly what it entails; I [ported](https://github.com/urschrei/lonlat_bng) a survey-quality projection to Rust, and gave a talk about it at [Rustfest](https://urschrei.github.io/rustfest/#/). My point is that lots of people want to use Geo libraries, and not many people want to write the maths-heavy code (which, incidentally, I would never describe as "just math" ‚Äì I'd describe it as "just read this 20-year-old computational geometry paper, then remind yourself of all the ways that geometries can be degenerate, and floating-point calculations can go wrong"). I was under the impression that the GDAL bindings were limited, but in good shape ‚Äì they're certainly in use in at least one [production project](https://github.com/t-rex-tileserver/t-rex), and they're getting regular attention. Maybe send some patches?
Sometimes I like to program without thinking too hard. I watch TV and write out some code. I get distracted and forget exactly what I left off with. So I run 'cargo check', find the errors for where I was when I was halfway through refactoring, and move forward. I don't have to keep the entire program in my head - when dealing with concurrency and memory management that's a big deal, I couldn't do it even if I were paying attention. Refactoring would 100% guaranteed lead to bugs and vulnerabilities. Rust helps me when I just want to program. A language without rust's type system would force me to have to reason about my program, to never forget about one piece of code. I don't want to do that every single time I program. I don't get stuck on adding a dependency, I can just write code. I don't get stuck writing tests to validate basic behavior - I just write my types, write basic component or integration tests as I work for validation. The long compile breaks give me time to focus on TV. Rust is perfect for letting me be a lazy programmer when I want to be, but digging into the code later to optimize it, refactor, clean it up more seriously later.
I'd argue that it is - writing cross platform desktop apps is a nonstarter for many products unless there is a way to achieve high levels of code sharing, and being able to leverage existing skills from existing web teams is a huge bonus as opposed to hiring additional devs.
`Segmentation fault (core dumped)`
`webrender` has a totally different concept. All I need is an ability to draw geometric primitives and text(which is a huge pain by itself) on image. &gt;I hope will be solved by the end of 2018. I hope it will be solved by 2028. It's a very complex task.
Servo currently uses Firefox's JS engine, which is already plenty fast. There's not really that much optimization potential is there, and the costs to writing a new JS engine are massive. It's absolutely possible to write a JS engine in Rust, but that won't inherently make it lighter or faster.
I'm not sure there would be much point in rewriting a javascript engine in Rust, since a JIT compiler and garbage collector necessarily uses so much unsafe behavior. There is [Cretonne](https://github.com/stoklund/cretonne), which is written in Rust and aims to be a code generator for use with Webassembly. But WASM deliberately avoids those aspects of Javascript that makes it require garbage collection and JIT (re-)compilation, and it's mostly intended as an output format for non-dynamic languages like Rust and C. In fact there was some talk of using Cretonne as a code generator for debug build in Rust, though I'm not sure if that is being actively pursued. 
Equivalent of scipy's signal module would be amazing.
For me that would be. - No such thing as a null pointer (`None` is not it, you need to explicitly handle `None` case with `Option` types). No random "undefined is not an object", NullPointerExceptions, segfaults/memory corruption, [deadlocks due to forgetting to make a channel](https://dave.cheney.net/2014/03/19/channel-axioms) (to clarify, I otherwise like Go, just this one thing is silly). - Type system detecting real errors (even concurrency errors!). Borrow checking legitimately helping - if you have a reference to a value, you can know it cannot suddenly change no matter what, there is no possibility of a mutable reference still being held somewhere else due to a bug. If it compiles, it will very likely work - I cannot say that about many languages, that said, I definitely like type system in Haskell and Flow (JavaScript type checker) too. - Great package manager. Using external dependencies is really, really easy. The package manager is packaged with a language (as opposed to something you have to download yourself) and automatically handles dependencies. - Speaking of modules, crates like `rayon`, `serde`, `diesel`, `nom` or `rocket` are legitimately amazing. The alternatives in other programming languages just aren't that great due to missing features (in case of `serde`, `diesel` and `rocket` that would be procedural `derive`s as well as plugins in case of `rocket`, in case of `rayon` that would be thread safety traits, in case of `nom` that would be macro system). - No exceptions. I honestly don't know how it is an improvement to replace `goto` from C with `goto` that goes through multiple functions and anything can unexpectedly `throw`. I'm thankful that Rust doesn't have that however. There are `panic`s, but they aren't meant to be caught in Rust. - Sum types (called `enum`s in Rust). I regularly miss those programming in other programming languages. - It's possible to implement new traits for standard library types if needed. - Sane iterators. It's surprising how often iterators are implemented wrong in programming languages or don't exist at all as a concept. In Rust, iterator is just a single function returning next value, nothing more, no need to implement `hasNext` or whatever else. Sure, this loses flexibility of C++ iterators, but implementing a C++ iterator is crazy, so cannot say I miss it. Also, implementing iterator gives access to neat functional iterator adaptors. You can easily use iterators whenever convenient, it's not a pain to use them - sure, I guess `yield` is often convenient, but I didn't really miss it in Rust, as `Iterator` API is really good. To give credit where it is due, I feel like Python, Swift and C#, Haskell got iterators right (Haskell strictly speaking doesn't have iterators, but laziness is just as good). JavaScript and PHP (when using `yield`) sorta got it right, but there is nothing like iterator adaptors in those languages.
Did you quit your job and are now running your own business using Rust? Are you doing it alone or with others? I want to do that too, but I'm not sure which products the market needs..
I would *love* to have an integrated IDE environment that comes with a debugger and has completion as good as intellij-rust.
I care about Rust because it compiles to fast native machine code. That's why I started looking at Rust; without that feature nothing else matters for my line of work. The reasons I stayed... * Cargo is a sane cross-platform build system, and even better it installs effortlessly with Rustup. * The type system catches so many errors at compile time, that by the time my code compiles it's much closer to correct than in any other language I've been able to use. * A very polished central library ecosystem and automatic documentation tools. Polished... not complete. Yet. * It's easy to get help; in general the Rust community is pretty good but specifically the Rust IRC is a one-stop-shop. * No header files (or "it's not C++" ) * Combining Rust's enums with `match` lets me express ideas way better than I can with any other language I've used. * After working with `Result` I never want to see another exception. Especially with `?`, the difference between handling and forwarding is just one character away. * The borrow checker lets me add threads without fear of discovering a race condition when I scale up. "Fearless concurrency" is real. And perhaps most importantly, * The team knows where the language isn't ergonomic and are working on improving it. I doubt they'll be able to do much about the learning curve, but some basic niceties like `?` in `main` go a long way.
I did a cursory examination of those links but couldn't find a concrete answer on how to make it interoperate with non-Pontoon translation GUIs. Is the `.ftl` mentioned by [l20n2po](http://docs.translatehouse.org/projects/translate-toolkit/en/latest/commands/l20n2po.html) the same format?
You can just add one header that includes all other headers of your project. Bindgen will resolve all includes and generates all the required bindings. 
looks like a great crate, nice work! a little while ago, I started [my first ever graphics-y project intended to be a geospatial data viewer](https://github.com/frewsxcv/rgis). from what i understand (i don't understand that much lol), to properly transform the geometries from spherical to screen coordinates, i'd need to use ECEF, so maybe i'll incorporate your crate and give it a shot. thanks!
Yes, I quit my job in February this year. I have a registered business and do Rust as my main work (but no income yet). Product launch will (hopefully) be in a few months / end of this year for a basic map / cartography service. After that I'll be part Rust developer and part cartographer / map designer. I work alone, but I do not recommend other people doing this - work together with friends, if you can. Depression gets to you really, really fast if you work alone. Saved up roughly 8000 ‚Ç¨. I have to pay (mandatory) health insurance each month and calculated that I need roughly 900‚Ç¨ per month, which gave me a rough time frame. also have to say that I wasted time with useless stuff. One month for writing the website, one month for writing it again because I fucked up. Wrote a stupid osm.pbf-to-postgres converter just to find out that imposm3 is better than I expected. Rust didn't have a decent PDF library, so another 2-3 months down the drain (and I'll probably have to rewrite printpdf, too). My parents inherited, so I moved back to them to be financially stable. And my daily life has been a lot better since. I don't recommend making a startup if you have no idea. I already worked a year at a company making maps plus three years of education in GIS. I simply recorded how many customers are coming in per month and how many customers they lost due to high prices, how much money they spend on ads, etc. Based off of that I estimated how much money I need to make monthly and what things I already know (web design and C++ basically), wrote a business plan and said goodbye. I had this planned roughly a year in advance. I figured, if I fail, I can still learn Java or C# or something else and get a job that way. Right now it doesn't look this bad, though. I wrote a prototype in my free time (the C++ thing), then looked for other languages (options: Rust or Go). Tried Python + QGIS, but couldn't get the necessary frameworks running due to bad documentation. Go is .. I don't know. So, Rust it was. 
&gt; But WASM deliberately avoids those aspects of Javascript that makes it require garbage collection and JIT (re-)compilation This is the just the current iteration of WASM. Long-term wasm will need to have GC-interop and a JS-compatable object ABI so that the [DOM can be accessed natively in WASM](https://github.com/WebAssembly/design/blob/master/FutureFeatures.md#).
There definitely is plenty of optimization potential. The limiting factor here is that the few who have the knowledge to write a competitive JS engine are already busy with spidermonkey. It would take so long to write a new engine from scratch that it's not clear (at least to me) that it would be worth the risks inevitably associated with projects of that size.
yeah, I have done this too, but for UTM: https://github.com/fschutt/lyon-testcase-openstreetmap/blob/master/src/conversion.rs Use f64, otherwise you run into problems with buildings / small scale things. Try getting attention on #rust-geo and don't hesistate to publish. I'm trying to put some sort of coordinate transform library together because there are lots of projections already implemented in Rust, but in various repos, not in one place. Basically something where you have a trait with two functions: `from_lat_lon()` and `to_lat_lon()`. This way you could transform between arbitrary coordinate systems, similar to proj4.
What I'm saying is that there isn't a lot of optimization potential in rewriting the engine, the current architecture/tech is fine, generally.
List of libs that lack of stops me for using Rust in many places: - _good_ SNMP implementation with read/write/trap - good XML de/serialization into structures and XML namespaces handling. Especially second option is stopping Rust anywhere where XML with namespaces is used like SOAP/Netconf/IPDR and many other ‚Äúbuses‚Äù/protocols used in enterprises. Serde seems to focus mainly on JSON. 
Thanks! I'm going to try and publish on crates.io today at some point.
Have you compared the performance between using coordinate slices + Rayon and using nalgebra? Coordinate transforms are fantastic candidates for parallelisation, and I don't know to what extent nalgebra can take advantage of that.
Try googling for rustlang too. That tends to help.
Hmm, UTM isn't a bad idea either. Yeah, that's something I've noticed and inspired me to start this repo. The math doesn't change, so having these functions in one place are useful for geospatial applications. The trait route is a good idea - the helper functions seemed an easier entry barrier for people developing applications imo (and thus the route I took). Edit: Was also considering supporting f32 for people who don't need that extra accuracy. Maybe. 
A few people have been throwing around the term library vs framework. I think it is a good, very basic distinction that is worth noting. My overly simplistic definition is this: In a library, you build and control the program's main event loop. A framework runs the event loop, and you provide input into how it manages the events. In Mio, you actively poll the collection of sockets that are waiting to send or receive data. And you do so at your leisure, usually in a loop. See : https://github.com/carllerche/mio/blob/master/src/poll.rs#L113 In Tokio, the tokio_core::reactor::Core::run() method looks very similar : https://github.com/carllerche/mio/blob/master/test/test_echo_server.rs#L284-L305 Obviously this is just the very beginning of the distinction. Tokio provides futures (See : Promises if you're familiar with Javascript) They're composable state machines which are basically callbacks waiting on (usually) IO. Core::run() expects a future to execute. Typically that future is a composition of many futures managing many IO sockets. 
&gt; bevor Sehr gut, ja!
1337 commits, damn!
*FORTRAN
This is not something I've considered yet. I'm not sure if the actual helper functions would be the most advantageous place for using Rayon, but it would definitely be within the geospatial application using the crate. If you need to perform many coordinate transformations quickly, Rayon would be of use - I would think. That being said, I have not tested that at all - I've never used Rayon, but have heard of it. 
&gt; I doubt they'll be able to do much about the learning curve Is Rust that difficult to learn? What specifically?
Thanks for the details, I appreciate it. Good luck with your business! I don't want to derail this thread too much offtopic, so I'll send you a pm :)
In general it's tricky to make one struct field contain pointers into another field of the same struct. The error you're getting is because `add_item` takes `all_objects: &amp;'a mut ...`, but `add_closure` doesn't have a `'parser_lifetime` bound on its `&amp;mut self` argument. This basically means that it can't guarantee that the arena and objects in it won't be destroyed while the ObjectSet still contains pointers into it: processor.add_closure(0, 0); processor.all_objects = TypedArena::new(); do_something(processor.objects.ready[0]); // points into the arena, but we dropped the arena above You can add the `&amp;'parser_lifetime mut self` bound to `add_closure`, but then you also won't be able to do anything else with the `Processor` after a call to `add_closure` because it will remain mutably borrowed for the rest of `'parser_lifetime`. While this does indeed prevent anything from touching the Arena, it makes it pretty useless. What you can do is use internal mutability to retain the ability to mutate the object in ways that are safe. The `Arena` already only requires an `&amp;` pointer, not `&amp;mut` to call `alloc`, so you can change `all_objects` from `&amp;'a mut` to `&amp;'a` in the `add_item` signature. You can wrap the `Processor::objects` field in a RefCell. Then, `add_closure` can take `&amp;'parser_lifetime self`. Unlike a `&amp;mut` borrow, you can have multiple concurrent `&amp;` borrows, so you call the method multiple times, but the `&amp;` borrow still prevents other mutation that would be unsafe, like moving the `Arena`. Another option is to pull the Arena out of the `Processor` and pass it as an argument to the Processor methods that need it.
LOL! :-D
No, termion is indeed more low-level, leaving window management to higher libraries.
`assert_approx_eq` is nice, but it's implemented in a wrong way. You should prefer `float-cmp` crate. PS: I'm not a IEEE 754 guru.
&gt;writing cross platform desktop apps is a nonstarter for many products unless there is a way to achieve high levels of code sharing What's wrong with Qt?
I'd like a bidirectional (render, parse) forms library as I don't like writing SPAs.
Quite a few patterns that are permitted by a garbage collector or manual memory management are forbidden in part or entirely by the borrow checker. Linked lists are the classic example; some people try to learn new languages by implementing common data structures and for Rust that's usually a bad time. There's also quite a few other oddities that take getting used to. If your intro project involves I/O, you'll have `Result`s everywhere; and if you're working in `main`, you can't use `?` so you'll have `.unwrap()` scattered all over your code. Which looks gross and obfuscates the actual logic. Rust is expression-oriented, which means you don't have to use `return` to get a value out of a function. Function definitions have a block, and calling a function just evaluates the block. Rust doesn't have inheritance. That's actually not a weakness of the language, it just means that you need to learn how to think with traits and enums to model the relationships between data. People say Rust favors composition over inheritance, but that's not actually my experience. If you have a single level of inheritance from a pure virtual class, that's often better expressed with a Rust enum. As soon as you start using enums, you need to understand how Rust's pattern matching syntax works, and that can be quite mind-bending for beginners. The book covers it decently, but IMO you just have to live it for the code to make sense.
If my experience is more in languages like Python and Haskell rather than Java and the likes, is that an advantage? It kind of sounds like it.
I don't know. I came in knowing Python and a bit of C and C++. I never really liked OOP, so that wasn't a blow. I suspect any language that has pattern matching would make the transition easier.
API clients for various web services. I just ran into this today: there are some tools which I'd be more comfortable to write in Rust, but I would need API clients for services like mailgun, etc. There's a lot of low hanging fruit there, libraries that are easy to write.
Good point, that's a solid choice. Honestly I don't have any in depth experience, just have seen plenty of discussions. I think my second point - reusing existing web skills - is probably the biggest factor in choosing something like Electron, which is going to lose out on performance every day of the week
Any recommendations? I'm using ncurses-rs for now for a "big" application. Is there something mature and high level?
How is this related with https://github.com/way-cooler/way-cooler ?
An Ethereum contract abstraction like https://github.com/trufflesuite/truffle-contract
For a JS engine to be fast it needs JIT and GC. It's possible to build those features in Rust but doing so either requires `unsafe` or building a virtual machine with enough freedom that some kind of virtual unsafety exists. To use Java as an example: a Java program should never cause a segfault by dereferencing a null pointer. But there *is* the NullPointerException meaning the same thing at a different level of abstraction. Likewise, you could write a C abstract machine interpreter and emulate *all* of C's craziness without a single line of unsafe. That's what /u/rebootyourbrainstem is getting at. Even though safe Rust is Turing-complete and amenable to optimization, carving out the freedom required to interpret JS fast would introduce a lot of overhead compared to just using unsafe. I think it *could* be worthwhile to write a JS runtime in Rust (I really like unsafe Rust; it's easier to get right than C.) but it will be hard to beat Spidermonkey or V8. And Node.js is *already* built on V8, which is state of the art. So why is Node.js heavyweight? It's not the engine, it's the JS. JavaScript makes it *really* easy to use expensive abstractions without even knowing that that's what you're doing. Rust and older "fast languages" are fast because the restrictions placed on programmers makes them less likely to choose expensive abstractions. Conversely it's possible to write fast JS if you understand those restrictions and have an engine that will take advantage of your code's CPU friendly design. This is why Node doesn't do too horribly at the [benchmark game](http://benchmarksgame.alioth.debian.org) but may seem a lot slower in real applications. 
Way Cooler is my compositor that is currently made with wlc. Fireplace, the other big Rust made tiling Wayland compositor, is also made with wlc. Fireplace is working with others in the Rust community that work with Wayland to make Smithay, a framework for making compositors (basically a replacement for wlc). Way Cooler is going with wlroots (a C library, as opposed to Rust), another attempt at a library by the developer of Sway the i3 clone for Wayland. 
Thanks for your in depth response. I've been doing all I can recently to boost the performance of my Node.js apps, as the performance isn't up to scratch anymore. The built in HTTP server can only handle up to about 2000 requests/sec by my benchmarks. I would really like to switch to Rust, but there doesn't seem to be any support for HTTP2, and I've heard that the benchmarks can also be a bit disappointing due to it still being early days.
For a vector `v` of some struct `Foo`, I would like to make a function like this (but this does not compile): pub struct Foo(i32, i32); fn compute_recursively(v: &amp;mut [Foo]) { for i in 0..(v.len() - 2) { do_something(&amp;mut v[i], &amp;v[i + 1], &amp;v[i + 2]); } } fn do_something(a: &amp;mut Foo, b: &amp;Foo, c: &amp;Foo) { a.0 = b.0; a.1 = c.0; } I tried the following. This is almost what I want. But I have to swap the first (resp. second) element with the last (resp. the second last) element. Is there a better way? fn compute_recursively(v: &amp;mut [Foo]) { let mut itr = v.iter_mut(); let a = itr.next().unwrap(); let b = itr.next().unwrap(); while let Some(c) = itr.next() { do_something(a, b, c); ::std::mem::swap(b, c); ::std::mem::swap(c, a); } } 
I've been keeping an eye on Smithay, I think it's awesome that it has come this far. wlroots is almost complete, so I'm going to be writing my bindings soon and use that instead. I'll be interested to see how the designs of the two frameworks diverge over time.
Just tried at it seems that bindgen isn't resolving them. Do i need to pass any extra argument? Thanks
*standard
Thanks for your answer. I know it's tricky, but I thought I had it figured out... &gt; add_closure doesn't have a 'parser_lifetime bound on its &amp;mut self argument. Does it matter? I mean, the lifetime is just a name, isn't it? And whatever the lifetime of self, it's also the lifetime of self.objects and self.all_objects. Am I missing something about the meaning of ``impl&lt;'parser_lifetime&gt; Parser&lt;'parser_lifetime&gt;``? However, changing the lifetime of self to 'parser_lifetime did change something and indeed it turned out that I cannot borrow self anywhere else, which is indeed pretty useless. I will try interior mutability.
So I should preface by saying I'm still a beginner when it comes to Rust and most of the programming world in general. Most of my previous experience is with Math students scripting in Matlab/Python and then later experience at an Aerospace firm where a considerable portion of the staff still writes in (Fixed-form) Fortran. My reasons for trying Rust are pretty simple, I liked static languages and I wanted to try something fast and modern that wasn't C++. People like to say Rust has a steep learning curve, but I found it much easier to jump into it (The Book is amazing) over C++. After graduating, one of the first projects I worked on involved implementing some new features to a Fortran program. And this experience helps define why I stay with Rust. When I found the code, it didn't compile and the (very very senior) author couldn't remember which directory he stuck the latest version in or why it didn't work. Some of the work that followed: - The scripts had no tests and it looked like all debugging had been done by many print statements. Or in this case, writing to a directory full of fort files e.g., fort.66, fort.908, fort.909, etc. Writing and running unit tests(+ other tests) is very easy to pick up in Rust, not to mention customizing your errors. - There wasn't a shred of documentation or even commenting in the code. In general, this felt like two separate activities where I worked, and often one or the other was neglected. I love how nicely Cargo Docs works in transforming your current commenting into nice standardized documentation. - The scripts called other functions by copy and pasting large chunks of code from other files. The core functionality existed verbatim in 3 different files. In addition, a smaller group of helper matrix functions were called from some even older fortran code, but different function names conflicted. Running this code was as simple as compiling and executing each file manually. But of course, it didn't run. Cargo overall, as a tool, is my favorite thing about rust. From building a new directory, managing dependencies, compiling, and running the code. - These particular files had a standardized style, all code 6 spaces in (yay punchcards), and all variable names 6 characters. Unfortunately, this made it very difficult to understand what any of the functions or variables actually meant. In general, my experience with engineers and mathematicians, is they don't really have a concept of style guides when it comes to coding. What everything is named or how it looks is very arbitrary and it starts to become a problem when people start sharing and sending around their scripts. From the get go, I appreciate how Rust seems to come with a very set style/naming convention for things (even the compiler barks at you!) such that everything is readable and consistent. Add in the great job they're doing with rust fmt and it so much easier to get consistent looking code from people who aren't software engineers for a living. - Last of all, even after moving and reformatting and commenting and documenting and testing this code for a couple months, I still ran into quite a few SegFaults in this code that was "Working last I checked". The types of errors I ran into, never would have happened in the first place with Rust :) TL;DR I tried Rust for the look and the speed. Stayed for the memory safety, but more importantly how easy the ecosystem makes running a small project. The Book, Cargo, rustup all do a great job of helping someone with no real software background do better at writing software.
I thought you didn't recommend actually using Abomonation?
You want /r/playrust
Hmm, I have some low-level experience working in BLE. That sounds like a good idea to add to my ever-growing queue of project ideas.
A good socket.io library. I found one on crates.io but it's old and doesn't compile anymore.
Really nice that you are working towards improving the ecosystem! The thing that makes it hard still are that transitive dependencies decide which TLS solution to use. Like hyper at the time only pulling in native-tls instead of a more flexible solution. But it applies to any lib. I think integration testing uncovered issues with OSX over native-tls as well (different sonames). But I might be mistaken. Anything outside of static linking/shipping libs does require careful integration testing.
Just curious, what do your Node.js apps do that they need to handle more than 2k requests per second?
I really wanted a thing with a [sandboxed](https://github.com/myfreeweb/rusty-sandbox) binary, optimized encoders, and a declarative mini-language for common operations (resize, crop, rotate, watermark, etc.). I actually [started bolting on `mozjpeg-sys` and `kamadak-exif` to `image`](https://github.com/myfreeweb/imagespells) but gave up. Could it be another one of my dreams coming true (after [Limn](https://github.com/christolliday/limn))?? Seems like‚Ä¶ not really. [No Exif metadata support](https://github.com/imazen/imageflow/issues/131), for one :(
No, it's great! But until the Rust folks nail down their UB definitions, it is still UB. And, it could become actual UB any moment if Niko wakes up in a bad mood. :)
https://github.com/superscale/worm/blob/master/build.rs here I'm using bindgen. As you see I don't use any special arguments. For me, including multiple headers works flawlessly. 
It doesn't. I'm guilty of being gluttonous for performance. I like having the peace of mind that my site can handle as much traffic as possible. It's not even that, it's an obsession. Same occurs with frontend frameworks... gah... hours wasted finding the fastest one...
Clearly nothing as mature as ncurses. [Cursive](https://github.com/gyscos/Cursive), mentioned in another post, is one such high-level libraries. [tui](https://github.com/fdehau/tui-rs) is another one.
What you are describing is basically a compositor. 
As meekstadt said: it is possible, but you need to do it youreslf since hyper is a low-level library. You can use [`url::form_urlencoded::parse`](https://docs.rs/url/1.5.1/url/form_urlencoded/fn.parse.html) to parse request body into name-value pairs. impl hyper::server::Service for Hello { type Request = Request; type Response = Response; type Error = hyper::Error; type Future = Box&lt;Future&lt;Item = Response, Error = hyper::Error&gt;&gt;; fn call(&amp;self, req: Request) -&gt; Self::Future { let fut = req.body() .fold(Vec::new(), |mut a, b| -&gt; Result&lt;_, hyper::Error&gt; { a.extend_from_slice(&amp;b); Ok(a) }) .and_then(|body| { let mut res_body = String::new(); for (name, value) in url::form_urlencoded::parse(&amp;body) { write!(res_body, "{}: {}\n", name, value).unwrap(); } Ok( Response::new() .with_header(ContentType::plaintext()) .with_body(res_body), ) }); Box::new(fut) } } 