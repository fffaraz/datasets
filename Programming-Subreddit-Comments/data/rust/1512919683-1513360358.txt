&gt; I'm just pointing out the looming danger that it poses...So let me at least voice my disagreements in the few areas where I think the walking direction is utterly wrong. You're doing a thing here that's making it hard for people to give you feedback. I don't know what to call it...it's kind of like "putting words in people's mouths", but that's too harsh I think. The problem is that when you say "let me voice my disagreements", you're assuming people don't want you to do that. But they do! We like disagreeing with each other! So when you say "let me voice my disagreements", it can feel like you're misrepresenting the people that you're talking to. Maybe you could go back and reread the feedback you were getting, but with the assumption that everyone likes you and thinks the ideas you have are valuable. That changes the meaning of the feedback a lot, right?
Thanks! I'll take a look.
&gt; Come again? u32 can definitely not represent all values of i16. How could it represent -1? I meant `i32`, apparently I edited while you were posting. &gt; Do you propose we also make the cast from i32 to u32 automatic? No, since neither can represent all the values of the other.
*Disgression: honestly, in both cases I'm more bothered with the *Primitive Obsession* issue than I am with the poor choice of primitive ;) I might be willing to forego a strong type for `port`, but the lack of unit in `timestamp` really tugs at my heart strings.* Back to your comment; would not the symmetry of the API lead to type bubbling anyway? I find the idea of type bubbling interesting. I am not sure whether I prefer it to auto-widening or not.
&gt; &gt; There is a portability issue in allowing auto-cast from `i32` to `usize`: this isn't guaranteed to work well in non-64 bits platforms. &gt; &gt; Beyond the portability issue, there is also a "negative indices" issue. Code like `let idx = -1i32; foo[idx]` shouldn't be allowed to compile. I meant `u32`, sorry. 
I think it uses `LocalName` and `Namespace` for good reason, and you probably shouldn't be using `String` for it. (`selectors` needs to compare between names quite a lot, and using `String` likely makes it much slower.) So I guess the best bet would probably be using `kuchiki` directly.
Oh, I didn't realize that `kuchiki` doesn't yet support XML. Then, probably you would need to write your own based on that example...
Yeah makes me suspect they didn't work out a nice way to actually do it in Rust...
The comment I was replying to literally consisted of two sentences, one of them being "Please stop.". To me that comment seems like it wants me to stop commenting on the ergonomics initiative altogether.
I have my own tree with my own `LocalName` (no `Namespace` for now). So I can't use `kuchiki` or `xml5ever`.
Could you talk more about your workflow and debug setup? I looked at developing for the Kobo too but couldn't really get started. 
I wanted to use html5ever for something, and got distracted documenting it :). If you do figure out how it works and submit a docs PR with examples, it will get merged!
I am using rosc. By OSC decoding I meant actually understanding the messages / converting them to enums.
TIL that Kobo is so open for changes. I had bought an E-reader myself but got disappointed at how restricted it was and about the requirements for tracking. I might buy a Kobo now and install Plato on it :).
&gt; unless the POLLING thread issues a lock or a barrier+atomic, there is no guarantee the new value of currenttime will be seen in any other thread. All that's necessary to fix that is an atomic. The barrier/lock is only necessary to order observation of effects relative to each other, which is not applicable here.
I second this! I also have a Kobo and would love to make my own apps for it.
Ah. In that case, I'm with you. I find myself casting u8s to usizes quite a lot and it's a bit inconvenient.
[Two screenshots](https://github.com/koreader/koreader/issues/2614#issuecomment-350564058) of the *home* view.
There used to be. It was called `std::thread::Scoped`. However, it was discovered to be [unsound](https://github.com/rust-lang/rust/issues/24292); that is, it was possible to cause undefined behavior if you leaked the scope guard structure. In that discussion people discovered a different pattern for having safe scoped threads, which has been implemented in libraries like [crossbeam](https://github.com/crossbeam-rs/crossbeam) and [rayon](https://github.com/rayon-rs/rayon). It works by introducing the scope as an argument to a closure, so it's owned by the library and not user code and thus can't be leaked.
It relies on language features that haven't been stabilised, and as such can change or even be cancelled. So it's possible that future compiler updates will break Rocket and projects depending on it.
He's writing code that's parameterized over type constructors, but he hasn't implemented HKT. Code generation via file includes is very fragile. If I found myself doing something like this, I'd write it as a macro: macro_rules! generate { () =&gt; { pub mod stmt { use super::{Node, Block}; pub enum Stmt { Expr(Node&lt;Expr&gt;), While(Node&lt;Expr&gt;, Block&lt;Stmt&gt;), } pub enum Expr { Ident, Literal, Break, Continue, } } } } pub mod test1 { pub type Node&lt;T&gt; = Box&lt;T&gt;; pub type Block&lt;T&gt; = Vec&lt;T&gt;; generate!(); } pub mod test2 { use std::rc::Rc; pub type Node&lt;T&gt; = Rc&lt;T&gt;; pub type Block&lt;T&gt; = Rc&lt;[T]&gt;; generate!(); } 
I think that addressed a different use case. This construct just packages up a stop condition with a normal handle to tie the thread's lifetime to the fat handle's, in an "advisory" sort of way.
&gt; why is there no crates that defines a convenient thread type that ties the thread to the struct lifetime ? I think it's because that's not exactly what the struct is doing. That's one use for it, but strictly speaking, what the struct ties to the handle's lifetime is the state of a flag. It's up to the thread to react appropriately when the flag's state changes. Since the object can't encapsulate anything about the thread's behavior, the API could be more general: an object providing an owning handle and a (cloneable) observing handle to just a flag. The observing handle can poll the state, which is changed when the owning handle is dropped.
&gt; why is there no crates that defines a convenient thread type that ties the thread to the struct lifetime ? I think it's because that's not exactly what the struct is doing. That's one use for it, but strictly speaking, what the struct ties to the handle's lifetime is the state of a flag. It's up to the thread to react appropriately when the flag's state changes. Since the object can't encapsulate anything about the thread's behavior, the API could be more general: an object providing owning handles and observing handles, that just tracks the count of owning handles. The observing handles can poll to find out whether any owning handles survive. Incidentally, this is almost exactly `Arc&lt;()&gt;` -- an `Arc` to nothing! You could almost get this behavior by creating an `Arc` in the parent thread, and giving the child a `Weak` reference. Unfortunately, `Weak` doesn't expose any interface to check whether it's dead without attempting to upgrade it, which is a more expensive operation than necessary.
I've found the problems so far are simple enough that I can just `trim/spit_whitespace` and manually parse tokens from an iterator. For instance, day 8 looks like this (With `Op` being a custom type with a From`&lt;&amp;str&gt;` implementation): /// Parses an input line into a (name, weight, [child_name]) tuple. fn parse_line(line: &amp;'static str) -&gt; (Register, isize, Condition) { let mut iter = line.split_whitespace(); let register = iter.next().unwrap(); let inc = iter.next().unwrap(); let mut val = isize::from_str_radix(iter.next().unwrap(), 10).unwrap(); if inc == "dec" { val *= -1 } // discard the if field assert_eq!(iter.next(), Some("if")); let cond_reg = iter.next().unwrap(); let cond_op = Op::from(iter.next().unwrap()); let cond_num = isize::from_str_radix(iter.next().unwrap(), 10).unwrap(); let cond = Condition { register: cond_reg.into(), comparison: cond_op, other_side: cond_num }; (register.into(), val, cond) } some other examples on [github](https://github.com/cmyr/advent-2017).
https://github.com/rochacbruno/py2rs 
Interesting - doesn't the JoinHandle join the thread when it is dropped? I've done multithreading like this [here](https://github.com/fschutt/LudumDare40/blob/master/src/audio.rs#L18-L28) but now I'm not sure if this actually joins the thread. The music ends when the program is terminated, so I guess the thread is joined (?). Also, isn't there a [park](https://doc.rust-lang.org/std/thread/fn.park.html) and unpark method to start and stop threads? This may be better suited - just start the thread and immediately park it. The start method then simply unparks the thread. Or you can use a channel and send a message to the thread to poll contiouusly when it should start. This would avoid the struct being borrowed, but be a bit more inefficient.
How long have you browsed this subreddit? Some of the highest upvoted posts have been lengthy criticisms.
`ErrorsScope` is an extremely dangerous feature. It basically means - if someone **logged** an error, I want to **do** something differently later. It's usually a bad idea to do something inside log commands or inside assert commands, because developers tend to associate these with debugging, and while they are useful to have even in the release product we usually assume we can safely comment them out. So doing anything inside log/assert command(other than writing the log or checking the assertion, of course, and generating - without side-effects! - the values needed for them) is very risky - even when one can see the expression inside the log/assert. With `ErrorsScope` you can't even see that - the actual side-effect will happen somewhere else!
and what did I say?
It also makes it easier to build a stable API. If the compiler looked past the type signature of a called function, then (in principle) almost any change you made to the *implementation* of a function could be breaking. By only looking at the function signature, the compiler leaves you free to make whatever changes you want to a public function, so long as you don't modify the type signature (with the exception of `impl Trait`+ autotraits).
JoinHandle doesn't join on Drop. If the main thread finishes executing, the program terminates on many (all?) platforms. It's not that the other threads are joining (running to completion), they're just being terminated.
came here to comment a similar thing. OP is wanting a scoped thread, which crossbeam conveniently provides.
Unless you can store `Scope` in a struct I don't see how this solve my problem. What I would like to do is to be able to tell the compiler that it's okay if the closure is not `static but just `a because the thread will live only for `a where `a is the lifetime of a struct (not a scope).
There is no general solution to what you're describing, then. You want a self-referential struct on an advanced level, which just isn't supported. For basic self-referential structs, there are crates like `rental` which can help. For the *specific* code listed above, we can defeat the compiler error by simply switching from `Rc` to `Arc`, [as shown here.](https://play.rust-lang.org/?gist=00f3cc6895f8ec40c05edfc1af38d913&amp;version=stable)
There is no general solution to what you're describing, then. You want a self-referential struct on an advanced level, which just isn't supported. For basic self-referential structs, there are crates like `rental` which can help.
&gt; #[derive(Foo)] &gt; #[foo(bar = "Barlike")] &gt; struct Quux; Would be awesome if we could do this when deriving: #[derive(Foo(bar = "Barlike"))] struct Quux; Like, pass parameters to what you're deriving.
If you need to cache the time (in a thread-safe way) to avoid syscalls, take a look at the coarsetime crate: https://github.com/jedisct1/rust-coarsetime
&gt; My previous Rust projects are: &gt; &gt; * Z: From the [linked repo](https://github.com/baskerville/Z): &gt; Go 85.8% Makefile 14.2% 
Thanks for the feedback, I've taken your advice and implemented it in the rename_file function!
What's with the thought policing? /u/est31 said something that got an interesting, useful (to me) conversation going. Yes, his first post was low-effort, but the relevance of that is approximately zero.
Oh, come on. It's fine to criticize the ergonomics initiative, but not by just making things up. Can you please criticize things that have actually been proposed?
&gt; In fact, I think it is already very bad that due to being a type alias, c_uint doesn't need a cast to u32. This makes your code less portable. Can you name a relevant supported system in which `unsigned int` is not 32 bits? ILP64 is extremely uncommon.
&gt; I'm just pointing out the looming danger that it poses. No, you're making things up and attributing them to the ergonomics initiative. Would you like it if I said, say, "or-patterns are really nice, too bad one of those 'safety' and 'readability' fans is going to propose killing them one day"? Please don't do the same to others.
I imagine that's very useful in tests however. Often people want to know their tests run without emitting error logs.
&gt; Compared to a scheme which stores usize (the index type), I end up with a struct that is 3x as small (YEAH!)... and a whole load of as sprinkled everywhere to get things to compile (BOOO!). When this happens I usually make a new type wrapper for whatever my index type is. Then implement Index and IndexMut for that wrapper. This both makes my apis safer and limits casting significantly. This can create more boilerplate but is often worth while. I bet you could encapsulate this pattern in a macro pretty easily though.
This is indeed an interesting potential use case for rental that I'd never even considered before. Perhaps I'll explore this further to see what potential it has.
I'd consider that a code smell. Your timestamp type should be wrapped in a struct. The fact that it uses a u32 under the hood should be an implementation detail. That way you can change the underlying representation in a single place, and still guarantee correctness.
I'm sure you'll find people who want automatic narrowing casts as well. Digging them up won't help the discussion though, because they are only fringe opinions. One of my problems with the ergonomics initiative is that when some proposal to add some new invisible (in the syntax) behaviour to the language becomes an RFC (most ergonomics initiative RFCs were of that kind), the text doesn't really clearly explain why the feature is limited to only one part, and doesn't go "all in" like auto-casting everything would be. It doesn't give confirmation "verbosity here is *good* and should be kept in the future as well". And I mean C apparently has the issue, so its not like nobody would do narrowing casts at all. I'm not saying that Rust should become less ergonomic in general. I actually quite like Rust being ergonomic, like the local type inference it has. But I don't have that feeling that it needs to get more ergonomic than it already is, and especially not so badly that you need a big year-long initiative.
Very impressive project. Thanks for sharing
I saw this too. Wat?
&gt; Can you name a relevant supported system in which unsigned int is not 32 bits? ILP64 is extremely uncommon. AVR (where it is 16 bits instead), but its probably not relevant I guess. I have used `u32` in making the point, but it scales to all the other `c_*` types. Take `c_long` as another example which is 32 bits on LLP64 (Windows) but 64 bits on LP64. The C standard doesn't define the final width of any of these types. &gt; Except that it's very frequently unavoidable. In the real world, you often deal with, for example, file formats that use u32 for offsets everywhere. Definitely, and I am a big believer in presenting APIs of serialized formats close to the format so e.g. not seeking to the end of an ogg stream to find out its length (that's the only way with some formats) unless the API user asked, or presenting different CAF format types not as enum but as a number with predefined constants attached. Every time you need to cast, you should ask yourself: can I do this? Is this allowed? Am I meant to do this? If you have a struct with u32 fields for offsets, you could have a set of getter functions that return you the usize casted versions of the offsets, then you'd need to write the cast function only once per offset, and for things that are no offsets you wouldn't have a getter function so when someone wants to use something that's no offset as if it were one, they'd notice immediately.
[removed]
I don't know what you mean in your first question. Why would an `A` that impls `From&lt;B&gt;` mean that `MyVector&lt;A&gt;` should impl `From&lt;B&gt;`? You could always implement it yourself, a la `impl&lt;A: From&lt;B&gt;&gt; From&lt;A&gt; for MyVector&lt;B&gt; { ... }`. But I can't see how that would be done automatically, how would the compiler know what to do to convert `MyVector&lt;B&gt;` into an `A`? I don't know what you mean by a compile-type `unimplemented!()`. If you mean stopping the compile if that macro is reached, any invalid syntax should work?
For a stronger unimplemented, you might be able to do something [like this.](https://play.rust-lang.org/?gist=8dd03f2ce581651c854124ddf5bf8386&amp;version=stable) Compile it, then change `true` to `false` and compile it again, and see what happens. If Rust can statically determine that it will not be executing that branch, then the code can be optimized out, so the linker doesn't ever have to worry about finding an implementation of that `extern` function.
Thanks for the link. That explains why it never became popular. I used the Enlightenment WM years ago and read a few of their articles about the EFL. They seemed to have some interesting ideas, but it sounds like the actual architecture is a mess.
&gt; You could always implement it yourself, a la what I mean is making a generic conversion for the container, which will give you conversions for the whole container for any pair of types that have a conversion.. e.g. MyVector&lt;F32&gt; -&gt; MyVector&lt;MyBigNum&gt; would automatically work if you had F32 -&gt; MyBigNum etc &gt; how would the compiler know what to do to convert MyVector&lt;B&gt; into an A? e.g. you write the generic conversion as you show it, then you write MyBigNum:From&lt;F32&gt; etc and it will work for vectors of .. &gt; I don't know what you mean by a compile-timeunimplemented!(). If you mean stopping the compile if that macro is reached, compile_error!("message") should work. what I mean is the function will compile just fine - but it will give a compile time error if you actually call it. I'd want to fill this in over-estimated trait defaults, where I am currently using unimplemented!(). I'm looking back at my vector maths libraries... I bounce in exactly how to organise the traits, and what is most pleasant or useful is not immediately apparent. Ages ago I remember talking to long_void ( the piston chap) and he had chosen to do fairly simple 'c-like' vector maths with explicit function names because (amongst other things) he didn't want to figure out the traits (now what he's doing today, I dont know, but the point is "figuring out the traits is not always easier straight away" ... rust has a lot of this sort of thing) &gt; The easiest way to cause an compile error if a certain function is called is to not define that function. sure; .. the issue is having it in a trait (e.g. default implementation), such that you can use an 'over-estimate' of function grouping, and still have compile-time errors where you tried to use something un-implemented. I workaround by using "unimplemented!()" which is ok but gives the undesirable side-effect that it might be a runtime error, and code it being emitted .. I might not know if something is hidden away there. Even if you had the goal of perfect traits, I think it would be a useful tool (I'm big on malleability, I dont like having to make decisions and commitments upfront) 
ah, generate a link-time error? that's certainly an interesting halfway house. (I'd still request an inbuilt way of doing it i.e. the error messages would be more useful, but thanks for the practical suggestion)
Towards your first question, Rust still wants you to be explicit about the costs. Doing that kind of conversion requires allocating an entirely new Vec. [This is one way.](https://play.rust-lang.org/?gist=babfd2ac2dada497a83510c0ef959fb8&amp;version=stable) It's only a single line of code, but it's not as straight forward as `vals.into()` or anything. If this is something you do frequently, then you could define a macro [as shown here.](https://play.rust-lang.org/?gist=7d0f144752ad8967c6a2bc7816f1eef9&amp;version=stable) Yes, I'm one of the more macro-friendly members of the Rust community. Maybe I enjoy them too much.
It seems to me that testing logging messages is a terrible idea. It matches the definition of "testing implementation details", which is widely considered a bad practice. If you test logging messages, then you, in essence, make logging a part of the API. A part that is dynamic, untyped and not checked at compile time. The need for a such feature seems to indicate a poorly structured code. Then again, every rule and best practice has exceptions, and it's just my opinion. :)
Mostly just missed the "cancelled" part, which is the biggest risk. If a feature's just changes syntax, Rocket's author can change their code and end users won't have to do much except upgrade to the latest version. If a feature is cancelled, it probably gets messier, depending on if there exists an alternative way to provide the functionality. Certainly in the worst case people would have to rewrite their use of a feature without the syntactic sugar it formerly had.
On line 123, you are passing a reference to a reference, which is the source of the current error. When you fix that, you get to a more sensible error describing the problem. [Here's](https://play.integer32.com/?gist=b9a18b6402172bbb7146136bcc35581f&amp;version=stable) the fixed link. Now, the problem you have is not a technicality; it's an issue with your current design. I'll try to walk you through why it's happening and suggest some possible fixes. The main issue is that `Sequence::run` returns a tuple of references which are tied to the lifetime `'a`. However, on line 121, you are creating a new `Sequence`. The lifetime of this `Sequence` is not `'a`‚Äïit will live only as long as the `Sequence::run` stack frame‚Äïlet's say that's `'b`. Because of that, the tuple of references it will return, which are tied to its own lifetime (`'b'`), will live shorter than `'a`, which is why you're not able to return them. The borrow checker rightfully complains‚Äïif this was e.g. C++, you'd end up with a dangling pointer at the end of your function. One simple fix I see is to get rid of the recursive definition of `Sequence::run` (it can be heartbreaking, I know). Simply iterate through all parsers and run them sequentially. That way, the lifetime of the refs will remain tied to the lifetime of the parsers, which you've defined to be `'a`‚Äïthe same as the lifetime of the `Sequence`. Another fix, which is better in my opinion, but would require a bit of an overhaul of your code, is to separate the lifetime of parsers and the strings. `Parser::run` is a pure function, and there's no reason you shouldn't be able to pass a `Parser&lt;'a&gt;::run` a string with the lifetime `'b` and have it return a result-remainder tuple with the lifetime `'b`. Unfortunately I don't have time right now to fix these issues in the code right now (maybe some of the other kind souls could help). But basically, your course of action would be to add a new lifetime, `'b`, to the signature of `Parser::run` and all impls. With that, your `Sequence` will life shorter, but that wouldn't matter, because you don't really need the `Sequence` to live after you've called its `run` function, as you've passed it a string and it should return two slices of that same string‚Äïwith the same lifetime. I think fixing this would actually clean up your code quite a bit and make the lifetime definitions easier to follow. More importantly, don't give up! Everyone's had their borrow checker fighting period, and trust me, it gets better with time. Nowadays, I get the same amount of borrow checker complaints in my code as when I started, but I always manage to address them without much issue, and they have often helped me avoid shooting myself in the foot. Good luck! 
it's not the explicit cost I'm worrying about - I'm happy with that; - it's just allowing the generic implementations to follow from having their components, without having to manually write MyVector&lt;F32&gt;:From&lt;MyVector&lt;F64&gt;, MyVector&lt;BigNum&gt;:From&lt;MyVector&lt;F32&gt; etc . r.e. macros .. Rust macros are great, but I do prefer the generic system to do as much as possible: I dont like mixing macros &amp; generics to achieve one goal; when I see macros I really think of a different layer of use-cases (e.g. rolling bindings/the sorts of things you might do with reflection, rolling your own object systems, debug/asserts, etc ). I know there's cases where we might be using macros still in anticipation of a better way being available eventually (e.g. parameterising on 'a number', all the Foo&lt;T,N&gt; stuff that's great in C++)
&gt; A part that is dynamic, untyped and not checked at compile time Unless I'm missing something, logging in Rust *is* typed and as such *is* checked at compile time. I agree, however, that testing logging is silly (well, except testing logging libraries).
First, you are passing a reference-to-a-reference, the error message gets better if you remove the &amp; from right Then it becomes clear right doesn't live long enough, because the result of p.run outlives the stack frame
Finally, congrats on the release! UI looks great, impressive work :)
Any screenshots of it with an epub open/reading a book? The homepage looks nice, certainly better than the slightly clunky koreader.
Nice, I really wanted this kind of framework and I really happy that you have written it u/fitzgen! 
&gt; And I mean C apparently has the issue, so its not like nobody would do narrowing casts at all. That was 1978. We figured out since then that automatic narrowing casts are a bad idea. For example, Java in the '90s didn't have them.
* `drop(&amp;mut self)` expects to have *exclusive* control over `self` (that's what `&amp;mut` means). If your child thread is running, it must be holding a reference to some of its contents, which violates the expectation. If you somehow found a way to bypass this, then you would be able to get away with just a non-atomic bool, leading to undefined behavior. * Lifetimes (in the technical sense that the compiler understands) are tied to lexical scopes. There is no inherent "struct lifetime" to speak of. To extend this idea one would need to consider the highly experimental self-referential lifetime proposals.
And [I fixed a bug](https://play.integer32.com/?gist=06f094a2f716d9b891558b386ed18ba4&amp;version=stable): on L35 ParseChar's `run` must return the matched char on the result. `And` and `Sequence`s still fail because, AFAIK, `And` cannot return a `&amp;str` made from two different `&amp;str` (even if they have the same lifetime). - If you want to remain zero-allocations and the result is always going to be a continuous slice of the input (RegEx-like) I would just return the number of characters parsed instead of the slices themselves. - You can also return a `String` from `run` and mutate it in subsequent calls, since `String`is growable.
Is [this](https://play.rust-lang.org/?gist=13f0fdfcb364b6983ae2f31c2c7f532f&amp;version=stable) what you want for [1] ?
&gt; drop(&amp;mut self) expects to have exclusive control over self (that's what &amp;mut means). If your child thread is running, it must be holding a reference to some of its contents, which violates the expectation. If you somehow found a way to bypass this, then you would be able to get away with just a non-atomic bool, leading to undefined behavior. Thanks a lot for you answer that now makes a lot of sense ! Yet it is still sad that we can't express such things with the langage.
You tyrants* of niceness need to stop using your false moral aspirations as attack vectors on members of the Rust community with opinions *you need to hear* but obviously *don't want to*. Whether you like /u/est31 delivery or not, the message is sound, the demographic attracted to Rust doesn't want anything to do with magic. /u/est31 defined that pretty well in "One of my problems with the ergonomics initiative is that when some proposal to add some new invisible (in the syntax) behaviour to the language". You also project your passive aggressiveness on to /u/est31 but it's you who's passive aggressive and intolerant of /u/est31 expressing themselves. As well intentioned as you may be, shame on you. https://www.youtube.com/watch?v=YTIdmCwAPpg * /u/matthieum /u/urschrei /u/oconnor663 /u/burntsushi /u/pcwalton
Yeah, it's not you can't come up with a deterministic thing to do. IT's that bugs can arise by seemingly simple changes switching things from floating point to integer math. The truth is you almost always want floating point or integer math, not a mix of both. Rust makes you choose explicitly and makes it very clear where the boundaries are.
There is `compile_error!` which causes a compilation error when expanded.
Sapper(https://github.com/sappworks/sapper) is what you want. We are developing some production with it.
I write website and forum with this framework. https://github.com/sappworks/sapper
Upon further reflection, while this would be possible to do with rental-style infrastructure, I don't think it would actually gain any expressive power. For a self-referential struct to exist, one of two things must be true: 1. Any fields within it that are borrowed by other fields must be behind a `StableDeref` container so that it can safely survive a move. 2. It must be immovable (not yet possible, but likely will be eventually). For the first case, that means we'd have to put the borrowed data behind an indirection, which is what we were trying to avoid in the first place. We may as well just use the `Arc` approach outlined in the crossbeam docs. We still pay for the Arc bump, but the overall cost of the computation will likely overshadow it anyway. For the second case, the struct would be confined to its local stack frame, which is what crossbeam scopes are for. Even if the immovable type was heap allocated, you still need to follow the indirection to reach its contents, so once again we're left with similar performance characteristics, with only the Arc bump as the difference. In either case, we don't really gain any expressive power I think.
sapper is very nice for web service development. And it is compiled with stable rust, comparing to rocket.
what website and forum?
I'm just going to type a very brief and incomplete overview here, as much to verify my own understanding as to help you :) Box uniquely owns the thing it points to. The thing is freed when the box is freed. Rc has shared ownership, i.e. you can copy Rc and then you have more than one pointer to the same thing. The thing will be freed when all the Rc's that point to it are freed. One tricky thing is that the counting done by Rc is not thread safe, so you can't send one of the Rc copies to another thread. If you want that, use Arc which does thread safe atomic counting. Cell is not a pointer, it holds its data inline. It's just saying "this bit of data can be changed even if I only have a read-only reference". It's a hack for when you need to get around the borrow checker. However, like Rc, Cell has some limitations. It works by just copying a new value in. This is not threadsafe, and it also means the thing must by copyable / moveable. So we have RefCell, which *is* a pointer (as opposed to Cell, which simply holds a value inline). RefCell simply does borrow checking at run time, so you will get a panic at runtime when you would normally get a borrow checker error when you compile. 
Take a look at Julien Assange's Marutukku It may be a better path for very large repos, IMHO
Logs are often used to track the internal state of applications whose executions must be recorded for the purposes of audit.
I see. What about Malbolge, then?
Pretty sure `RefCell` also holds the value inline to itself. It just allows access to the value via a reference (whereas `Cell` only allows copying data out / moving data in). 
There's not a lot happening in your program, but it doesn't look "too C minded" to me. My one criticism is that since you're writing to stdout a lot in a loop, consider acquiring a stdout lock, and using the `Write` trait for faster output.
This comment isn't a lot of fun to write, but I think its important for people to read it. I worked very hard this year on the ergonomics initiative, which I think made enormous improvements to the productivity of Rust for users. Comments like est31's original comment are genuinely hurtful to me, because they are sarcastic and mean-spirited attacks on my hard work. While I think the ergonomics initiative accomplished very good things, my personal experience of the RFC process was very negative. I recently opened the RFC template to organize my thoughts about something (not at all related to ergonomics or even the language) and felt a rush of anxiety and stress just looking at it. Comments like this one are a continuation of that very unpleasant experience. Comments which are mean denigration of other peoples' work should never be acceptable in the Rust community; I would hate to imagine a potential user get the impression that this is how we talk about one another.
[Wrapper Types in Rust: Choosing Your Guarantees](http://manishearth.github.io/blog/2015/05/27/wrapper-types-in-rust-choosing-your-guarantees/) is a great article that really cleared things up for me.
&gt;I was surprised about how it was quite similar, so I'm wondering if I'm thinking too much like a C programmer. Probably not, since you're not using `unsafe`. Rust has some nicer features (maps, filters), but you'll probably end up using them anyway, because they're nicer :)
Thanks for the correction, this makes a lot of sense. 
Toml seems to be more common as cargo uses that format. Serde works well enough for either though, so coin flip!
Your program is too simple and small to be more Rusty. Having said that, myself having years of embedded C experience, I find Rust being a perfect combination of C explicitness, with modern abstractions and convenience. 
[removed]
Definitely TOML, for the following four reasons: 1. YAML is [underspecified](https://ciaranm.wordpress.com/2009/03/01/yaml-sucks-gems-sucks-syck-sucks/) and is handled [inconsistently](https://github.com/cblp/yaml-sucks) between parsers. 2. YAML's syntax is much more complex and subtle than TOML. (I can write TOML and trust that it'll parse as intended the first time. With YAML, I often just have to experiment until the parser outputs the intended structure.) 3. TOML was specifically [designed](https://github.com/toml-lang/toml#user-content-comparison-with-other-formats) to be easier to hand-edit than JSON, not as overcomplicated as YAML, and better suited to structured data than INI files. 4. TOML is more popular in the Rust ecosystem as far as I can tell.
GNSS calculation? Probably a ton of lab experiment/research. High speed manufacturing maybe?
You are worrying about the wrong things. What you should be worrying about is (in this order) 1. Is my code understandable. 2. Does my code perform well enough. 
This line_str.as_str().chars() Is no different than this: line_str.chars() This println!(""); Is the same as this; println!(); And you could use this, instead of a loop: print!("{}", " ".repeat(8 - (num % 8))); Or because we know what we are writing (up to 8 spaces), do something efficient like so: const tab = b" "; let _ = stdout.write_all(&amp;tab[..8 - (num % 8)]);
I think your code is just fine. There are a couple performance things you could do, as mentioned in other comments. Overall, it looks quite straightforward, and that's good. I see this comment: /* Was going to do it recursively, but it seems string are meant to be * iterated over. The reasoning is that if they contain unicode * characters, you can't as easily determine which is the next char */ Let's imagine you use `.bytes()` or `.as_bytes()` instead of `.chars()` to remove this concern. You'll expand to the wrong number of spaces if there are non-ASCII characters in there, but let's just ignore that for a second. By using bytes instead of chars, you can get the length of the string and index into it at arbitrary positions. What would you do differently? Could you show me the recursive version you'd prefer? I'm curious to see it.
Are you willing to spearhead the effort? Talk is cheap and people pestering successful open source projects about rewriting in Rust is being an asshole.
[removed]
Off-topic: are you the author of bspwm?
How about [RON](https://crates.io/crates/ron)?
TOML. It's recommended/common for good reason. YAML has a lot of "gotchas" such as: * YAML config files are in theory all supposed to start with `---` * Repeated nodes are denoted with a `&amp;`, and they can later be referred back to. 
&gt;Serde works well enough for either though, so coin flip! There are still reasons you wouldn't want your users using YAML in some cases. 
I'm doing it right now, it's great, I took some time learning Rust and the tools, but after that learning curve it's very productive, beautiful code, I also love the asshole compiler and how easy it is to run tests. I'm much more productive, having less bugs, better debugging tools, and I am liking the language a lot. I'm using Iron, I don't know if it's the best choice, when I decided I didn't know shit so I used the first ok thing I saw.
Can't you just use 'html5ever' directly? You just need to use another scope. use html5ever; html5ever::LocalName;
I pretty much finished the [NanoVG bindings rewrite](https://github.com/Lisoph/nanovg-rs) last week. I have a pending pull request for merging the changes back into the original repo, but KevinKelly doesn't seem to be active much. If it doesn't get merged this week, I'll publish it as it's own crate (I suspect this is going to happen). Maybe I'll also achieve some progress on rewriting the UI for [Chorus Studio](https://github.com/Lisoph/chorus_studio) (with NanoVG). So much code to write, so little time.
If it's for humans, use Toml. If for machines, use yaml. 
A week late, but I finally got around to putting up Windows and macOS binaries for my team's Ludum Dare game, [Cat Chaser](https://ldjam.com/events/ludum-dare/40/cat-chaser)! Four of us worked through the weekend to make the game. We used my game framework, [Midgar](https://github.com/mystal/midgar-engine), cgmath, and ears for audio (though I considered switching to rodio to be more pure Rust). Overall using Rust went really well. Two of the four of us hadn't written much Rust code in the past, yet they were easily able to write large chunks of the game. We ran into a couple of borrow checker issues, but quickly got past them. Honestly I never expected Midgar to be used for a complete game, yet here we are. I for one definitely plan to keep using Rust for games :)
/u/est31's comment (for reference): &gt; Until the next "ergonomics" initiative comes along that auto-casts ints to each other... I don't think that this comment is stating an opinion on any previous ergonomics initiative. He's merely making a prediction about a future (negative) change that might be accepted in the name of ergonomics. To the unbiased third party (that I assume myself to be) this reads as a massive overreaction. I think that if you see this as an attack or as mean, you need to simply grow a thicker skin, stop assuming the worst, and also recognize that a (potential) attack on some person's work is not an attack on the person. No comment on your RFC process experience, but that's a separate issue from this.
The fact that we still use a language that lets you do this sort of things blows my mind every time. And I do C++ for a living...
To assert `true` or `false` at compile-time, I recommend perhaps using [static-assertions](https://github.com/nvzqz/static-assertions-rs)'s `const_assert!` within your macro.
If you don't do any error handling, you can just use `let line_str = line.unwrap()` or `.expect()`
If for machines, use Flatbuffers, Cap'n Proto, MessagePack?
Ideally releasing version 1.0 of [my glicko2 library](https://github.com/DenialAdams/glicko2) anyone want to look over the API and make sure it is sane? :) Other than that, I've been working on a custom log parser that stashes data into a database, where it can be later read by a Rocket site I'm also working. The current problem I'm trying to tackle is that in production I actually want to parse from many different sources in parallel, and each source should be streamed over HTTP. So we'll see how that goes :)
machines aren't able to understand toml?
False dichotomy. Why only those two choices?
&gt; To the unbiased third party (that I assume myself to be) It might be better to regard your viewpoint as *decontextualized* rather than unbiased. This is not the only comment est31 has made on the ergonomics initiative.
I'm curious: what about YAML seems good for machine-to-machine communication? I can understand liking it better for humans, but for machines it has inconsistent parsing of edge cases, and a much more complicated syntax. Why not use JSON or a binary format for machine communication?
What else do you suggest then? YAML and TOML are the two most popular "languages"/notations for configuration settings, being more powerful than `.ini` or `.desktop` files and less verbose than JSON and XML. 
[removed]
Honestly, I think everyone should be using [UCL](https://github.com/vstakhov/libucl) for anything complex and TOML for simple things. Definitely not yaml. I don't know what's worse yaml or json. Both suck from a human perspective, both suck from a machine perspective. 
Shouldn't the application be tracking its internal state rather than relying on parsing its own logs to do that? Maybe I'm wrong, but I've always been of the opinion that logging libraries should have one purpose, and one purpose only - to log any errors and other events of interest going on in the code for the purpose of being able to figure out what's failing (and where) at a later time by reading the logs.
&gt; bspwm https://github.com/baskerville/bspwm pretty sure yes
[removed]
&gt; I don't think that this comment is stating an opinion on any previous ergonomics initiative. He's merely making a prediction about a future (negative) change that might be accepted in the name of ergonomics. It's hyperbole, and that's why the comment is not constructive. *Nobody* wants narrowing integer conversions. It's a strawman of the ergonomics initiative, plain and simple.
&gt; I'm just pointing out the looming danger that it poses. No. That is not what you were doing. You created a strawman of automatic coercion and tied it to the ergonomics initiative, and used it to further bash the initiative. Your comments have long crossed the threshhold of constructive disagreement to nonconstructive ranting and this helps _nobody_. Folks will stop listening to you, and angry comments are _worse_ at conveying whatever point you wish to make. I'll discuss this further in PM.
reallllyyyyyy????? whahhhhyyyyy? is that better than sex or whatttttt????
With this release comes a few changes: - `assert_eq_size!` no longer relies on `unsafe` - Added `assert_cfg!`, which makes use of `compile_error!` to display a message if the given configuration is not supported - Added `assert_fields!`, which asserts that an `enum` or `struct` type has the given fields
To be fair, your link does not talk about yaml being 'underspecified'. Quite the opposite, it points to the relevant section of the specification to which one parser does not conform. So it's rather "bad implementations of yaml exist".
It might be good to add some examples to the readme :)
Hi all, I am starting to get familiar with thinking about borrowing, but I can't think of a neat solution to the following scenario: I have two `VecDeque`s storing `f64`s. I want to subtract the minimum of the two front values of both values and then pop the one that became 0. This should be repeated until one of the vectors is empty. I was inclined to type the following code: while let (Some(x), Some(y)) = (vec1.front_mut(), vec2.front_mut()) { if x &lt; y { *y -= x; vec1.pop_front(); } else { *x -= y; vec2.pop_front(); } } The issue here is that `pop_front` requires a mutable borrow. Does anyone have a clue how this can be done elegantly in Rust?
There's lots of examples on the entry page for 0.2.3. I felt as though it was getting cluttered and moved it all to the individual macros. Maybe I'll add some minimal examples. https://docs.rs/static_assertions/0.2.3/static_assertions/
Nah. When I entered the page that's the first thing that caught my attention, so I posted, and then I skimmed to the macros and was happy to see lots of examples (nice job!). So maybe just add a line saying that for examples one should look at the docs of the independent macros and be done with it :)
The mistake is fixed. The [Rust version](https://github.com/baskerville/fdb) handles concurrent access to the DB and is the only version worth using.
TOML is nicer overall, but I have a super hard time reasoning about nesting in it.
Will do! Also, I just found out that you can test against having doc tests fail to compile. Adding this for better documentation :) Example: https://i.imgur.com/ly4qKce.png
how do you do that??? this should be in the rustdoc book!
I'm not a SQLite expert but I'd suggest to focus on your actual business/concept first. If you really hit a performance problem then do some measurements and proof that the DB is the bottle neck. If so, you could optimize your queries or switch e.g. to PostgreSQL :)
It required a bit of digging through the Rust repo but I found it [here](https://github.com/rust-lang/rust/blob/dbeb5bf890211608bff5d28c3801c1a217a78d81/src/test/rustdoc/codeblock-title.rs) :P Example: ///```compile_fail /// /// // Code that fails to compile /// ///```
Right, I figured that would most likely be the case. I guess from a style point of view, the first one is more readable.
It was only added to stable last week ([with 1.22](https://blog.rust-lang.org/2017/11/22/Rust-1.22.html)), which is probably why it's not that commonly used yet :)
Took a shot at writing [my version](https://gist.github.com/anonymous/6e06b0941cc61edb064f921329285836).
This so much. Drives me nuts. Everyone in this tread saying toml is for humans but it‚Äôs so much harder to read and, conceptually in my head, doesn‚Äôt easily map into my idea of the data structure it produces compared to yaml which almost maps directly onto a dictionary/map/json object etc. 
&gt; consider acquiring a stdout lock, and using the Write trait for faster output. It's a reasonable advise for performance optimization, but I'm not sure newcommers should be taught to use this by default : in multi-threaded scenari you can have weird dreadlocks occuring when you add logs in other parts of the code afterwards.
&gt; stdout.write_all(&amp;TAB[..8 - (num % 8)]); This is veering off topic, but I can't help it. How about the following? üòÅ stdout.write_all(&amp;TAB[num % 8..]);
It seems to be fairly easy to hack about with it. The best source of information is the mobileread forums where all the real serious ebook nerds / hackers hang out. With my Kobo Aura One I did the following: * Install Kobo Start Menu - this is a boot menu that lets you choose which reading application to launch. * Installed koreader - I can then choose to launch it from KSM. I find koreader a bit nicer purely because of the progress toolbar showing you chapter markers and no-fuss ability to reduce all margins etc * There's also a large patch database enabling you to patch nickel, the default kobo reader app. On the kobo aura one, Nickel by default wastes loads of margin space at top and bottom so you can patch that out, but there's tons of miscellaneous patches and tweaks for it. I suppose I will try this plato reader and see how it is.
Why people are downvoting me? Jesus..
&gt; /u/est31's comment (for reference): There are many more comments like this than just one.
&gt; Interesting - doesn't the JoinHandle join the thread when it is dropped? https://doc.rust-lang.org/stable/std/thread/struct.JoinHandle.html &gt; A JoinHandle detaches the associated thread when it is dropped, which means that there is no longer any handle to thread and no way to join on it.
Same for me. TOML seems super easy for "flat" configurations, but every time I have to construct something with a couple of nesting levels I find it very difficult.
I mentioned the [building process](https://github.com/baskerville/sketch#building) in my previous *Kobo* project. But it would seem that things have changed in the latest firmwares (4.6.x and above) and the requirement for an *old* GLIBC version can probably be dropped. Also, I'm guessing that `crosstool-ng` could be used instead of having to install *Ubuntu* inside a VM. 
[CBOR](http://cbor.io/) :)
This is possibly the most hostile to strong typing project I can think of, IIRC it was all opaque pointers and random explosions if you looked at one sideway... This is both one of the hardest mapping one could do, and one that would bring the most benefit.
for [2], there's also don't panic https://crates.io/crates/dont_panic
1) TOML is easy to write if you want to have some amount of complexity, but once you need stuff like nested objects there's a steep difficulty curve in writing it, validating and parsing it. 2) YAML is easy to write if you want something easy and the complexity of writing it increases somewhat linearly, it allows you to achieve files that are much more complex than what you can do with TOML (e.g. recursion and referencing other nodes). 3) YAML enforced indentation, whether this is good or bad it's debatable. In my opinion it's a net positive which we will see more and more languages do in the future, but the arguments for and against are long. 4) YAML is slightly more popular, so there's a higher chance you will be able to find a parser for it if you need someone else to parse these files. But it depends on the ecosystem (e.g. basically all rust users would have used TOML and most Ruby users would have used yaml) Overall I'd make my decision based on 3) and 1). 3 Is subjective and up to you and your team, 1 depends on how complex the data you want to express is and what the complexity consists of.
[EFL is quite infamous for horrible code](https://what.thedailywtf.com/topic/15001/enlightened). Maybe they've improved a bit since that thread was started (3 years ago)‚Ä¶ If you "rewrite" it in Rust, you'll probably end up with something completely different.
&gt; The mistake is fixed. The Rust version handles concurrent accesses to the DB and is the only version worth using. Great, thanks for posting.
A couple of weeks ago I started work on a Selenium-based scraper, for downloading thousands of products listings from a website. It started life as a quick and hacky script but is steadily becoming more pythonic as time passes. It is also now efficiently multithreaded, making the process even quicker than previously. One thread performs URL discovery (select a particular product from a search page) and adds that information to a queue, multiple threads process that information (downloading the title, description, image URL, category and other data) and queues that up for the final thread which writes it all to a CSV and validates it. The biggest hurdle I'm facing right now is the fact that the website I'm importing these listings into sometimes chokes - it tells me that perfectly valid CSV data (verified by hand, as well as several automatic tools) is invalid. That's a big on their end though, and out of my control. I'm currently working on producing a minimum reproducible test case to submit to them and hopefully get this fixed.
thanks. 
Coercion of integer types is no done decision I think? Only thing I recall is upcasting around comparison operators which I actually agree with. Similar for whether 2018 will get an ergonomics initiative as well. 2017 is over and so is its ergonomics initiative -- it was less bad than I thought when I read the initial RFCs.
Damn dreadlocks!
Good to know, thanks.
XML while verbose has very mature tooling. I would not dismiss it as a candidate for storing configuration. For the OP's use case (nested configuration files), I'd argue that XML is even more relevant.
I would dismiss it immediately if users are expected to manually edit configuration files. If it's read and written only by machines, then it's OK. 
It's not difficult to allow both, since serde can parse different formats to the same structure with one line of code. Personally I'd go for TOML as long as you only need it to be generated by humans and you don't need more than one or two levels of nesting and YAML otherwise. The Rust community seems to massively prefer TOML (probably as a result of it being used by cargo) but personally I quite like YAML too since it's both easy to machine-generate and easy to human-generate (since it's a superset of JSON, you can just use JSON serialisers to write it).
Hi, crate author here. The `selectors` crate is definitely intended to be usable without Servo, but it is true that documentation is severely lacking. The project is also a bit of a mess right now in that it was forked into the Servo repository for enabling rapid changes with Stylo. Now that Stylo has shipped in Firefox Quantum, it should change much less frequently and we should fold everything back into the dedicated repository and publish a new version on crates.io. Hopefully I‚Äôll be able to take time to do that and more polish at the start of next year. As to `PrecomputedHash`, I think that despite the name it doesn‚Äôt actually need to be pre-computed. You should be able to implement it in terms of `Hash`. We should probably make it optional, IIRC it‚Äôs only used in the bloom filter optimization. In the meantime, consider using an older version. 0.17 doesn‚Äôt have `PrecomputedHash`, for example.
Modifying a container while iterating over it is generally unsafe, that's why Rust doesn't allow it. I would divide your algorithm into two steps: 1. Modify the deques in-place but keep a list of which one to pop from. 2. Iterate over the computed list and pop from the deques accordingly. Perhaps something like: enum Pop { Left, Right, } // Modify the deques and simultaneously compute a list of // which deques to pop from. let pops: Vec&lt;_&gt; = vec1.iter_mut() .zip(vec2.iter_mut()) .map(|(x, y)| { if *x &lt; *y { *y -= *x; Pop::Left } else { *x -= *y; Pop::Right } }) .collect(); // Pop according to the results. for p in pops.iter() { match *p { Pop::Left =&gt; vec1.pop_front(), Pop::Right =&gt; vec2.pop_front(), }; } This is just a quick solution, so I don't know if it implements your algorithm exactly.
&gt; e.g. MyVector&lt;F32&gt; -&gt; MyVector&lt;MyBigNum&gt; would automatically work if you had F32 -&gt; MyBigNum You can write `impl&lt;A, B&gt; From&lt;MyVector&lt;A&gt;&gt; for MyVector&lt;B&gt; where B: From&lt;A&gt;`, but unfortunately the compiler won‚Äôt allow it because it overlaps with the identity conversion `impl&lt;T&gt; From&lt;T&gt; for T` from libcore. When `A == B`, two impls would apply and the compiler doesn‚Äôt want to pick one. There are proposals for trait specialization where you could make this work by adding a third `impl` for exactly the intersection: `impl&lt;T&gt; From&lt;MyVector&lt;T&gt;&gt; for MyVector&lt;T&gt;`. It would be picked since it is "more specific" that either of the other two. I don‚Äôt know whether this already works in Rust Nightly.
With JSON the problem isn't so much that it's verbose, but that it doesn't allow comments, which is somewhat of a problem for config files.
How well would it perform against other known frameworks?
I used a while-loop right because iter-and-edit should be avoided. One crucial element that your solution misses is that we can't assume that `vec1` is consumed at the same rate as `vec2`. If the elements in one vec are consistently larger, that vec will be consumed more slowly. Also, I want to be able to implement this with `BinaryHeap`s as well, and then doing additional iterations will cost significant time.
First of all, congratulations on your project! And, as the owner of a kobo aura one, thank you so much! (fun fact, I live in Brazil and we don't have kobos here - I asked for a friend of mine who works in the Kindle department at Amazon to bring a kobo for me from USA. Oh the irony) I've got some questions for you: 1. How would I install your document reader? The instructions for koreader are somewhat hard. 2. I didn't see your post in /r/kobo, I think the people there would appreciate it as well. 3. Can Plato control the yellow light on Kobo Aura One? At least until the last I checked, koreader couldn't. Again, thank you! 
I agree and this is where I switch to yaml. With that said, I use the nesting "problem" in toml to encourage me to find ways to simplify my data model.
After a busy week I got a bit of time to work on [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis). Tests are now compiling for nearly all underlying storage types. I *think* I just need to remove +=/-=/... tests for `BigInt`. I ended up writing a [wrapper struct](https://github.com/iliekturtles/uom/blob/003e6799ab14af8166346217463c0636f4102572/src/tests.rs#L108) for `quickcheck::Arbitrary`. Am I crazy here? Any better way to do this as `quickcheck` itself doesn't implement Arbitrary for types from `num`.
Wrong order in my opinion. Is there a case where you prioritize an understandable code to a code performing just well enough?
I would solve this by using two counters to indicate the number of elements removed. At the end, you perform one operation to remove that many from the Vec. Your loop will start with making an iter_mut of each, and only call next on the one you "drop". You can have the iter API make your counter for you too, using enumerate.
You... linked to my gist? I think you forgot to hit the "share" button :P
&gt; And you could use this, instead of a loop: &gt; print!("{}", " ".repeat(8 - (num % 8))); You can also do something like this: print!("{:width$}", "", width = (8-(num%8))) There's lots of ways to [format](https://doc.rust-lang.org/std/fmt/).
&gt; I can write TOML and trust that it'll parse as intended the first time. Lucky you! I always struggle with subtables because one cannot "end a subtable" and continue one level further up. But I agree with you. TOML it is. OP: there's also the toml-query crate which can be used to extract single values from a toml document, if you cannot simply use the derive features from serde in your environment!
&gt; Let's imagine you use .bytes() or .as_bytes() instead of .chars() to remove this concern. You'll expand to the wrong number of spaces if there are non-ASCII characters in there, but let's just ignore that for a second. They're probably expanding to the wrong number of spaces regardless since they're assuming one place per codepoint and thus don't handle decomposed diacritics.
Yes: almost everything. Reducing the maintainance burden is, for most codebases, the biggest optimization you can do. Of course it's all about striking a balance, but 99% of the time there is a choice between performance and readability, readability is the right answer. Performance should only be chosen if it is necessary.
There's another way though: just open an issue [here](https://github.com/ansuz/RIIR) !
I deduce that I won't be able small projects faster? I feel like what you say is more for bigger projects where things like spaghetti code can eat your time.
https://www.youtube.com/watch?v=7RJmoCWx4cE
It‚Äôs all about context. The performance of grep is very important, for example. In that codebase, good comments replace any and all readability if you can shave a millisecond off a common case. Same is true for some tight loops in huge projects, I‚Äôd argue. In general tho, readability and maintainability comes above all else 
Lol, I wasn't fully awake at the time of writing, the post was full of typos. I fixed most of them, but I'm keeping the dreadlocks because it's a cute one. 
Thank you for your answer, sounds reasonable! I will probably make naming of all associated types mandatory. That being said I'd love to be able to write something like this: impl Foo for Baz { type Bar = struct { /* type definition here */ }; }
We have our own Rust-based UI TK from the Redox OS project[1], so it's probably better that more people gather together to build that out. [1] https://github.com/redox-os/orbtk/
Except that grep is slow as hell
Fair enough, never looked at its performance or codebase. But abstractly, you can imagine writing a readable but naive grep implementation that turned out to be as slow as hell, but a bunch of really obscure optimisations would increase performance to the detriment of readability
In that case, yes, I would say yaml may have an edge. That is because yaml has anchoring (see https://learnxinyminutes.com/docs/yaml/) whilst TOML doesn't seem to have such a feature (But maybe someone should correct me here ?) That being said, as /u/ssokolow mentions, some YAML parser may mess up these kind of features... hopefully not though. The other argument here is that a static file format shouldn't have features such as anchoring. In the end it also comes down to whether or not you like the idea of indentation being used to express nesting, which I think is great, if you don't then UCL may be better than both YAML and TOML for you.
Code that is performing "well enough" is, I think, a requirement not an optional thing. If you need to run Y under X +/- external factors, it should be able to always run under X +/- external factors. However improving that performance (say, to account for when the external factors are becoming very slow out of a sudden), that should be a secondary requirement to code that is understandable. Code that is understandable can be made to preform better without even touching it (e.g. more resources, compiler options, different libraries, compilers improving over time, speeding up external factors). Code that runs fast but is not understandable is frozen and any modifications would involve a full refactoring or wasting a lot of time understanding it and re-writing it.
Working on my [advanced data structures class project](https://github.com/JustAPerson/rads). Past few days have been spent trying to implement [strict fibonacci heaps](https://dl.acm.org/citation.cfm?id=2214082) and I'm hoping to also have time to implement maybe one more structure before it's due Wednesday. Gotta get started on writing the 10 page report though :(
How long until full-fledged `constexpr` in Rust? :D
&gt; Code that is performing "well enough" is, I think, a requirement, not an optional thing. Then you agree it should be 1st priority no?
[Not too long](https://github.com/rust-lang/rust/pull/45002#issuecomment-350732000)
Thanks! Really helpful to get to read through other people's solutions and maybe learn a thing or two :)
I guess my thought for recursion after understanding how strings are worked with would be to pass the iterator, and instead of having a mutable int you'd have a mutable iterator but the assignments to num = 0 and num += 1 would be replaced by function calls. But I was also under the impression that Rust tries to be more functional, in which case that's something I _might_ want to do. If loops like this are what's commonly used then I can see how there's no problem though ;)
_This_ is beautiful
I also use logging for alerting itself (`error!` means I get paged), in that situation verifying that an error log is triggered is (AFAICT) actually the most legitimate thing to verify that the sad path is handled correctly.
Is this any worse than the write_all suggested bu /u/maggit?
Oh yeah that'd be amazing for codegen purposes. I think that there are a couple anonymous struct RFCs floating around that would end up supporting something like this. IIRC they're all mostly motivated by C-compatibility, it's probably worth pointing out the codegen use-cases on them as well.
&gt; upcasting around comparison operators Is that a thing? I can only find a closed RFC: [RFC#2021](https://github.com/rust-lang/rfcs/pull/2021).
Looking at the STD source and Godbolt, I would say maggit's would be faster, as that doesn't do any formatting before calling `write_all`, while my suggestion would. How much faster it would be is more difficult to judge, as now we're dealing with IO.
&gt;In typical lovecraftian C fashion, EFL disregards any notion of memory ownership. It frees *some* data you pour into it, and it doesn‚Äôt free other. Which is which? You‚Äôll only know when your process crashes on double free. Or when your memory fills up. Or never. Rust of course highly discourages the design of something like that, and porting anything designed that way would drive a Rust developer to quit. Also notable: that entire rant is about the *API design* of EFL, not even its source code. Bad code could be replaced, bad API design can't be fixed without replacing all the apps that use it. At that point you'd be writing a stylish light-weight GUI framework in Rust and, yes please, that's a *good* project idea.
Wow, somebody ought to write Windows and or Wayland backends for that, said Claire impulsively, unaware that she was placing a geas on herself.
&gt; Build times where quite short too: while an order of magnitude slower than C++, think about this: This blog is made in Haskell, and I had to rebuild it from scratch when starting to write this post because I had deleted the ~/.stack/ folder ‚Ä¶ well, it just finished building right now. That‚Äôs almost 2 hours. I didn't know Haskell build time where that high, but I'm surprised by Rust's build time described as *slower* than their C++ counterpart. I always read that Rust build time was slower than C, but quicker than C++ due to the lack of header files and the relative simplicity of Rust generics compared to templates. Is there a relevant comparison of Rust and C++ build time somewhere ?
I was able to work today on my learning project which shows information about a Linux server over http by parsing various files in /proc: https://github.com/abhijat/system_snapshot_server I added an endpoint to show CPU related information. Next I will add filesystem and memory related information, but I guess I need to make the options a bit configurable before that. I also want to look into logging a bit more as soon as I can, I just threw something up together using fern but I want to look into other options like slog as well. 
No. Did you read the rest? If you start with performance, you might sacrifice readability and maintainability you will never get back. If you start with clarity, you can always add performance later--perhaps even without sacrificing much clarity. The fact that performing "well enough" is a requirement determines when you stop, not how you start.
Grep isn't slow as hell by any sane measure. A naive grep would be orders of magnitude slower than grep. If you're thinking about ripgrep, it optimizes one use-case of grep (Searching for a string recursively in a folder) and optimizes it as much as possible. Grep is used in a very wide variety of scenarios, and doesn't have that level of optimization for each of them.
There's no easy way to build an apples-to-apples comparison of build times in different languages.
Exactly
There's no easy way to build an apples-to-apples comparison of build times between different version of the Rust compiler either (some project becomes slower to build whereas others become faster), that doesn't stop anyone from establishing a comparison methodology, which will not be the objective truth but can still be useful.
Join https://discord.me/rust-lang instead!
An advanced stage of spaghetti code basically‚Äîit's really just the most natural state of code and nothing wrong with it.
Consider handling errors at write better: &gt; let _ = stdout.write_all(&amp;TAB[num % 8..]); If any error occurs here, it will be silenced and the loop will continue regardless. I guess you wrote `let _ = ` to silence the compiler warning about an unused result. A better way would be to either explicitely panic without a message: &gt; stdout.write_all(&amp;TAB[num % 8..]).unwrap(); or provide a message with `expect()` instead or any other error handling logic (I don't know what `expand` does in this case, probably do something similar).
Can anyone recommend a good open source project to enhance your understanding of language and best practices via reading &amp; learning other people's code? Jumping into servo or similar codebase size and complexity-wise projects is rough.
In other words, it's not that you prefer recursion, but that you think that'd be more idiomatic Rust or better suit the language in some unknown way? Recursion doesn't seem common in the Rust I've read. One likely big reason: Rust (unlike purely functional languages) currently [doesn't have](https://github.com/rust-lang/rfcs/issues/271) guaranteed [tail call elimination](https://en.wikipedia.org/wiki/Tail_call). So the recursive way may be less efficient, and may even overflow the stack if the depth is unbounded. So I'd say your current approach suits the language better in a concrete way. Rust is a more functional language than C in the sense that it supports lambdas and there's lots of stuff in the standard library (and common crates) that accepts them. This is handy sometimes, but if you have straightforward code without using them, there's no reason to feel bad about it.
**Tail call** In computer science, a tail call is a subroutine call performed as the final action of a procedure. If a tail call might lead to the same subroutine being called again later in the call chain, the subroutine is said to be tail-recursive, which is a special case of recursion. Tail recursion (or tail-end recursion) is particularly useful, and often easy to handle in implementations. Tail calls can be implemented without adding a new stack frame to the call stack. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
If you don't need sort stability, use `sort_unstable_by_key` instead: sorted_pixels.sort_unstable_by_key(key_fn); This reduces the time needed to sort pixels in my wallpaper from 580 ms to 490 ms. It also avoids an allocation: `sort_by_key` allocates an auxiliary buffer half the size of the original just for sorting. Also, you can use `zip` instead of `enumerate` to avoid indexing into `sorted_pixel` (indexing incurs some cost due to bound checking). This shaves additional 30 ms off the running time: for (a, b) in buf.pixels_mut().zip(sorted_pixels.into_iter()) { *a = *b; }
Not really. What I meant is: Performance, as a requirement (e.g. I want this parser to parse these files with a minimum speed of 20MB/second), is not a "priority", since it's part of the software. As in, you write the software and if it doesn't have that performance it's similar to it not having the correct output. Performance as a "bonus", e.g.: This implementation of `find` is 42% faster in case X, is in my opinion a much lower priority than readability.
[mio_httpc](https://crates.io/crates/mio_httpc) was just published to crates.io. It is an async http client built on top of mio only. It has websockets, streaming calls, http authentication, chunked transfers (only receiving for now) and keep-alive connection pools. 
&gt; I can‚Äôt imagine it [argument parsing] being simpler or clearer, props to the team behind clap. Check this out then, it builds on clap: https://github.com/TeXitoi/structopt 
What are the human/machine disadvantages of JSON to you?
The question is about "config". Yaml has a compact, human readable format, which is nice to read, maybe not as easy to write. And for typical config file which is just a bunch of string keys and values with a bit of nesting, the undrerspec. doesn't matter (at least in my applications od the word "config"). So if users don't spend time writing them (they are mostly machine generated), and only sometimes inspect them or slightly tweak, yaml works better for me in config files. 
Is stdout.write faster then println? If I need to write a lot of lines to stdout should I not be using print macros?
Sure. while let (Some(&amp;x), Some(&amp;y)) = (vec1.front(), vec2.front()) { if x &gt; y { *vec1.front_mut() -= y; vec2.pop_front(); The machine code will have to load the f64 values from memory anyway. Or from a Rust-only perspective, assume that the cost of copying a Copy type is negligible. 
Hey thanks for the feedback! Ido want stability though, found the effect to be quite amusing sometimes (for example for vectorial art with homogeneous colors). Gonna try zip now üëçüèº
RON FTW!
Well that ignores the original problem, so it's not really an answer.
Yeah the comparison is very complicated. Specially because C++ has a complicated history of dependency management. Also templates, damn.
Do you have benchmarks to prove that? I used iron a while ago and it was quite slow (although another commenter gave numbers that were around 2.5x the speed of express.js so maybe it's improved).
Woops. Basically the idea was to do this : ```rust impl&lt;T,U&gt; FromVec&lt;T&gt; for Vec&lt;U&gt; where U : From&lt;T&gt; { fn from(&amp;self) -&gt; Vec&lt;U&gt; { //conversion } } ``` You have to define a new trait `FromVec` because otherwise due to the orphan rules you can't implement From for Vec.
&gt;Cargo is love True. 
The only thing I would do differently is build the string in memory before printing. Current code is doing more I/O than necessary and that's hurting performance.
Working on a library for interacting with the GDAX crypto exchange API using reqwest. The existing unofficial Rust client library for GDAX is relying on an old nightly rust build so I figured I would make one that is compatible with the latest stable build. 
`while` and `while let` are inherently impure: they reevaluate their control expression between iterations. (`for x in expr` only evaluates `expr` once) This "iterator invalidation" is normal, expected behaviour for `while` loops: the loop body is *supposed* to leak side effects. It doesn't confuse the optimizer and shouldn't confuse the programmer. Lexical borrowck is too simple to understand that `vec2.pop_front()` should be allowed once `y` is dead. 
Well, nobody wants narrowing integer conversions *yet*. While I agree that some of this is not constructive in itself, I hope core takes a look at why some people end up in a frustrated place. I still think a big part of the problem is procedural. I've personally deinvolved myself from the language design discussions now, but you'll find some similar sounding last-try-cynicism in my history. And one point that solidifies my belief that the issue might be the process is that I have a similar reaction to /u/desiringmachines' for the RFC process, but instead for me it's *This Week In Rust*. I used to look forward to it, now I dread it due to the new RFCs, and what removals they might propose.
Writing documentation for [actix wen framework](https://github.com/actix/actix-web)
I see. Make sure to check out [`par_sort_by_key`](https://docs.rs/rayon/0.9.0/rayon/slice/trait.ParallelSliceMut.html#method.par_sort_by_key) if you'd still like performance wins while keeping sort stability. :)
almost as bad as dereferencing a dreadnaught.
Oh, sorry. It was late (around 1AM), I didn't have time to re-read them to refresh my memory, and I got overconfident about how well I remembered the root causes.
Looking at the yaml.org webpage of implementations and the situation looks even worse. http://yaml.org/ Very few Yaml 1.2 (2009) implementations. Peering at a few languages shows, mostly unmaintained, decade old implementations of 1.0 or 1.1. In actual practice the cross language support looks pretty bad, but people don't seem well informed or realistic about this when talking about yaml.
&gt; 3) YAML enforced indentation, whether this is good or bad it's debatable. In my opinion it's a net positive which we will see more and more languages do in the future, but the arguments for and against are long. As someone who considered Python the be-all and end-all of programming until Rust came around, I have to say that you can do significant whitespace well or poorly. In my opinion, YAML (and CoffeeScript) do this poorly compared to Python because it's significantly easier to silently produce incorrect output rather than failing with an error.
I'd go with TOML if it's simple. One application I develop uses YAML though because the ability to use merge keys is necessary to keep the configuration file to a sensible length (it's 901 lines now and there's a 43-line subconfiguration used 13 times explicitly and it's embedded in other usages that are also merge key'd). I'm not worried about it being underspecified or inconsistent between languages because we're using it as basically "JSON with merge keys" and not doing anything fancy like type specification or the like.
It's not for the application's benefit. It's for the purposes of post-hoc auditing. Manual auditing especially.
That is also true, and in my opinion even python's implementation of this is not perfect. Personally I think it's a step forward from the approach of having a different form of token for the computer to determine the structure (e.g. {, ", ',:, [) than for the human to determine the structure (we largely use spaces, indentation and the way symbols look, even punctuation sign are often ignored by human beings, spaces are the easiest way to communicate a change in pace or meaning to us). Again, here the discussion get's a bit into psychology and language design and I'd rather not discuss it in depth because it's a very subjective topic where I have written essays arguing one way or another before and, in the end, it's a very bikeshedy topic.
https://docs.google.com/presentation/d/1q-c7UAyrUlM-eZyTo1pd8SZ0qwA_wYxmPZVOQkoDmH4/edit
I suggest ripgrep; if you google around, someone had done an overview of the code that was very interesting too.
&gt; And I do C++ for a living... Same here. And for my current job the answer is at least in part legacy: it's already written in C++ and it mostly works. A full rewrite would require significant effort, it's easier to keep going with the current stack. *Note: another part would need convincing my colleagues that Rust is better ;)*
I appreciate the goals of UCL, but I would honestly prefer *less* syntactic sugar, not more. It also doesn't have any proper format for date-times, and I expect textual macros are *seldom* actually going to make life better. [json5](https://github.com/json5/json5)? I dunno. ¬Ø\_(„ÉÑ)_/¬Ø
Why was this downvoted? From what I've seen, CBOR is a perfectly reasonable binary encoding. It may not be the *best at everything always*, but it's Usually Good Enough, extensible, and standardized. Are there disadvantages of it I'm not aware of?
Author, can confirm - contributions welcome!
I think you're right that some of the limits here are just what the syntax of the language is able to express. However, even if we could kind of invent whatever syntax we wanted, the safety requirements of self-borrowing would turn out to be really onerous. For example, you can't move a struct while any borrow exists of any of its members. So for a self-borrowing struct, would it be impossible to move it after it's constructed? Or maybe you could move it, but only with an `unsafe` function? You can make this easier in specific cases, like when you know a data structure puts all its contents in a stable place on the heap. [`owning_ref`](https://github.com/Kimundi/owning-ref-rs) takes advantage of that. This is kind of related to [a different answer from a few days ago](https://www.reddit.com/r/rust/comments/7hffz6/hey_rustaceans_got_an_easy_question_ask_here/dqweaoz/).
also, /u/clrnd could use Rayon, which is already a transitive dependency. With these small changes, the processing time for my wallpaper is cut from 2.4 seconds to almost exactly 1.2 seconds. $ git diff diff --git a/Cargo.toml b/Cargo.toml index ba5916e..39608a5 100644 --- a/Cargo.toml +++ b/Cargo.toml @@ -8,3 +8,4 @@ authors = ["clrnd &lt;welcometothechango@gmail.com&gt;"] image = "*" clap = "~2" palette = "~0.2" +rayon = "0.8.2" diff --git a/src/main.rs b/src/main.rs index e37bc59..5aed6f8 100644 --- a/src/main.rs +++ b/src/main.rs @@ -1,5 +1,8 @@ extern crate image; extern crate palette; +extern crate rayon; + +use rayon::slice::ParallelSliceMut; use std::env; use std::process; @@ -51,7 +54,7 @@ fn sort_pixels(img: &amp;image::DynamicImage, mode: &amp;options::Mode) let buf2 = buf.clone(); let mut sorted_pixels: Vec&lt;_&gt; = buf2.pixels().collect(); - sorted_pixels.sort_by_key(key_fn); + sorted_pixels.par_sort_by_key(key_fn); for (i, pixel) in buf.pixels_mut().enumerate() { *pixel = *sorted_pixels[i];
With the small changes required to use Rayon, the processing time for my wallpaper is cut from 2.4 seconds to almost exactly 1.2 seconds. $ git diff diff --git a/Cargo.toml b/Cargo.toml index ba5916e..39608a5 100644 --- a/Cargo.toml +++ b/Cargo.toml @@ -8,3 +8,4 @@ authors = ["clrnd &lt;welcometothechango@gmail.com&gt;"] image = "*" clap = "~2" palette = "~0.2" +rayon = "0.8.2" diff --git a/src/main.rs b/src/main.rs index e37bc59..5aed6f8 100644 --- a/src/main.rs +++ b/src/main.rs @@ -1,5 +1,8 @@ extern crate image; extern crate palette; +extern crate rayon; + +use rayon::slice::ParallelSliceMut; use std::env; use std::process; @@ -51,7 +54,7 @@ fn sort_pixels(img: &amp;image::DynamicImage, mode: &amp;options::Mode) let buf2 = buf.clone(); let mut sorted_pixels: Vec&lt;_&gt; = buf2.pixels().collect(); - sorted_pixels.sort_by_key(key_fn); + sorted_pixels.par_sort_by_key(key_fn); for (i, pixel) in buf.pixels_mut().enumerate() { *pixel = *sorted_pixels[i]; I used v0.8.2 because it's already a transitive dependency, but they could certainly use the latest version instead.
This smells very OOP-Y, where you want to overwrite a destructor. This is simply not the kind of abstraction the rust core offers. But if you have to , i don't see the problem with a wrapper struct that handles this logic. But maybe i'm overlooking something here. 
&gt; You almost certainly will not reach the maximum number of requests/sec of any framework in Rust, my goal isn't speed, but ram being consumed.
Thanks for the reply.
&gt; It‚Äôs cool to have testing directly built on the build tool, but it‚Äôs a little awkward to use and extremely dependent on file and folder names It sounds here like you are saying that you need to put your tests in specific folders and files, but that is not the case, you can put them anywhere you want(you don't even need #[cfg(test)], it mostly just disables warnings and some errors from marked code in normal builds). All you need is to put #[tesst] above the functions.
If you‚Äôd like to vent, feel free to message me privately. I‚Äôd like to hear more.
There‚Äôs no serious proposal for any of this stuff, or a time least, not ones that I‚Äôm aware of.
I ported my ORM [tql](https://github.com/antoyo/tql) to procedural macros and it now works on stable! This is an alternative to diesel which provide a better syntax and better error messages. Tql is inspired by the Django ORM, but generate the SQL queries at compile time. I plan to write a blog post about this soon, but I cannot publish it right now because it depends of the master branch of the `syn` crate.
I would like to start a project with WebAssembly and Rust, but I am having trouble finding recent documentation. Has native wasm compilation been added to LLVM with Rust support? If so, where could I find documentation/tutorials?
Ah yes, self-descriptive like MessagePack, BSON, UBJSON, etc. =) I prefer the static typing of FlatBuffers and Cap'n Proto, but sometimes that's just not what you need.
This is too short to say. In general expect two things: * Resist the urge to store/return things by pointer. 90% of time Rust references are *not* the kind of pointer that you want. Remember that `Box` is a pointer too (and `Rc`/`Vec` are close enough), and Rust doesn't do any expensive copies automatically (thanks to `Copy`/`Clone` type distinction). * Completely opposite from C, plain arrays are the least usable type in Rust. Use `Vec` and slices. 
if the tests are in a separate file, then you will still have to use the `mod` directive to tell the compiler that the file exists, just like any other module. But, most people write their unit tests in the same file, not a separate file, and then use cargo's integration test support for the other stuff.
Perhaps someone didn't like it being self-descriptive and missed MessagePack in my enumeration.
Not the person you replied to, and I think JSON is a good format for machine consumption, but less so for humans. Lack of comments is a major shortcoming, especially for a configuration file format. I also think JSON is a little too inflexible and verbose for simple cases (though I think it handles complex structures better than the alternatives).
I have not read this yet, but here is an interesting trail of links on the topic of errors in software: 1) http://250bpm.com/blog:68 2) http://danluu.com/postmortem-lessons/ 3) https://www.usenix.org/conference/osdi14/technical-sessions/presentation/yuan
This is a really, really great talk. I've given and heard countless talks on Therac-25, and couldn't be more enthused about this one. Thanks huge for sharing it.
I once worked on a system that stole someone's rent money with a trick like this. Took two weeks to track down how that happened.
I'd personally use YAML and `serde-yaml`.
JSON is good for parsing and human eye debugging of data on a wire. For configuration, I think it's bad. Too chatty and yet has no comments. 
Be honest, when is last time you had to enter date-time into configuration value? For me, it's about 3 years ago. How many times I needed to merge two sections and enter a 64bit integer in integer in scientific notation way more often. l ibUCL also provides great library to work with those files. 
thanks for the detail .. that was it. I remember having to do some workarounds that allowed a subset of cases (again I forget the details of exactly how.. good to know there are proposals at least, )
After reading that... /u/tuxmanexe, could you elaborate on exactly which part of EFL you "very much like"?
I'll be working on supporting the PLY format in [Plexus](https://github.com/olson-sean-k/plexus), my 3D mesh crate. Lately, I've been experimenting with ways to save and restore mesh data. PLY seems like a great fit, because Plexus supports arbitrary geometry and PLY's notion of properties supports this easily. I've even experimented with serde support too, though I'm not sure that will be useful. I'll also be working on polishing [Decorum](https://github.com/olson-sean-k/decorum), a crate for normalizing (hashing, comparing, etc.) floating point values. I'm hoping to get Decorum ready for a stable `0.1` release soon. It's similar to ordered-float, but provides better support for conversions, implements traits from num-traits, monkey patches additional traits for constrained floating point values (i.e., `Float` is equivalent to `Real + Nan + Infinite`), exposes functions to operate on raw floating point values, and a few other features I prefer.
Even better, projects like [clippy](https://github.com/rust-lang-nursery/rust-clippy) have easy mentored issues. What better way to learn a language than to lint it?
A closure is a function that captures part of its environment. A string is a piece of data. Closures are run just like any function... what are you expecting would happen when someone tries to run a String? It's data, not code.
Simply that the compiler would compile the "string". Think of it like a compile-time "eval". I'm just sure I learned about this feature.
[removed]
Yes, and that would be the correct choice. As the commenter you're responding to said already.
The closest thing is [include](https://doc.rust-lang.org/std/macro.include.html), but I'm pretty confident that nothing like what you're describing has ever existed in Rust. I've only been heavily involved for the past 3 years or so... maybe there was something in the far history of Rust that did this. `include` will treat an external file as a single Rust expression and compile it into the code.
What's the best Rust UI lib for Windows right now? 
Cool! You might want to consider removing the inner `unsafe` in `assert_eq_size_ptr` so that users have to write it themselves. As it is, a user could perform a `ptr::read` of a bogus address by passing it to `assert_eq_size_ptr` (they can't see the results, but the `ptr::read` still occurs [here](https://docs.rs/static_assertions/0.2.4/src/static_assertions/lib.rs.html#142-152)).
We used YAML for [peru](https://github.com/buildinspace/peru). I think the result was good for the most part, but still I'm not sure I'd use it again. The big benefit was that, in a file designed to be mostly written by hand, you don't need to insert quotes around all your keys. That's _really_ nice for the human, but of course it comes with some downsides. One downside is that if you accidentally write a string that looks like something else (like a float, say), the parser might not read in a value that matches the characters the user typed. (Can a valid email address ever look like a float? _Probably_ not. But once you start asking questions like this, you go down a black hole of complexity and corner cases.) YAML still doesn't have a format-preserving parser that I know of, so any automated edits you try to do to a YAML file have to be hacks, and you have to worry about these sorts of cases showing up in what you emit. It looks like TOML [has a format-preserving parser](https://github.com/joelself/tomllib), which is awesome. I'd consider that a strong argument for preferring TOML in new applications, unless you're absolutely sure you'll never need to edit a config file programmatically.
Cool thing. I got bored, and modified it to take any number of pictures at once. It's a little hacky and explodes in disk space if you're not careful with your wildcards, since it generates the output filenames with the same extension as the inputs. I've put the patch [here](https://pastebin.com/b9bAtuXB), so that it doesn't take up the whole thread. 
Where can I found examples for simple a `#[bench]` usage?
Lua would be another good choice. Sqlite is also a condender if users won't be modifying the config files by hand.
&gt; Has native wasm compilation been added to LLVM with Rust support? [Yes!](https://www.hellorust.com/news/native-wasm-target.html) However I'm not sure what resources are available for it yet; maybe someone else can point those out to you.
To be clear: what you are looking for is a "document" model of JSON, XML, etc... I mean, the fast XML parsers are generally SAX parsers: they avoid instantiating anything and just call-back into user code. However, while this work well for *parsing* this does not work well for *manipulating* or *producing* XML, at which point you use a "DOM" instead. The `http` crate seems to have a rather easy choice here, as the header/arguments are mostly a *list* without nesting, easily implemented with `Vec`, however JSON and XML are inherently more complicated. A naive implementation (sprinkling `Vec` everywhere, or using `HashMap`, etc...) will result in a whole lot of individual memory allocations and negatively affect performance; at which point some crates will prefer to use a faster implementation and the benefits of a "vocabulary" crate are lost. Do you have some specific suggestions/guidelines to architect those crates?
Wouldn't the SDL2 backend cover Wayland, at least?
There is no eval in rust, but you can probably write a macro to do something like it, of it's compile-time known string.
I wrote a library for things like this a while ago, and it‚Äôs also what I‚Äôm using (a java like scanner) [input-stream](https://crates.io/crates/input-stream) 
I try to learn from history. I've seen a lot of C(++) code where types were incorrect, that likely wouldn't happen if auto-casting wasn't there. I've recently worked with my colleagues on a task to remove as many such problematic cases as possible. We turned on `-Wconversion` and next few weeks we were cursing at whoever wrote such mess. Since the code contained non-negligible amount of callbacks, I realized that even if type casting to narrower types was disabled, it'd still be an issue.
Are you sure you're not thinking of D? It has exactly that. 
It might just be that you're representing more complex data than I am.
Well, [I don't think so](https://github.com/matthiasbeyer/imag/blob/master/imagrc.toml)!
Working on [libzfs](https://github.com/inner-heaven/libzfs-rs) and [libwhisper](https://github.com/inner-heaven/libwhisper-rs). Later one is blocked by tokio revamp. First one is coming together very nicely. Got a little way to into testing ‚Äî so little code, so many tests. 
got a link? that just sounds unpleasant.
There are no good docs yet; https://www.hellorust.com/setup/wasm-target/ is the best we've got. We're working on it actively, which is why there aren't really docs; as stuff shakes out I'll be writing a ton of docs.
https://doc.rust-lang.org/nightly/unstable-book/library-features/test.html
I don't remember this ever being in a Rust, at least in the last ~5 years. Maybe, maybe before that? Or maybe you're thinking of D's mixins? https://dlang.org/mixin.html
Didn't you mean `Arc` instead of `Rc`? I'm pretty sure `Rc` isn't `Send`.
&gt; Ruby I think favours yaml way more than toml. Definitely, but my experience with Ruby and YAML is part of why we ended up choosing TOML for Cargo.
One of the worst days in my life: https://tenderlovemaking.com/2013/02/06/yaml-f7u12.html
FYI AVR (which Rust targets) is 8-bit (but has 16-bit addressing if I remember correctly - didn't work with it for a while).
You can implement your own trait to do that. I like how `core` does it.
These days SDL most often just sets up an OpenGL context for you. It has a *ton* of legacy code for non-GL windowing environments, but it wouldn't surprise me if Wayland support is GL-only. I don't much care for it. Glfw ftw. (Okay, the SDL audio API is pretty good for quick and dirty stuff.) 
I don't know of one. From what little I've seen of the Windows C APIs, they'd actually be reasonably easy to rustify. But they very much do their own thing and don't feel like *nix.
Hello, I recently discovered the [adventofcode.com](http://adventofcode.com) website. Since I have been curious about Rust I decided to use this as an opportunity to learn the language. On Day 6, I have gotten stuck. The situation is that I have to save copies of an array, so that after mutating the array, I can compare the mutation to previous versions. I am running into issues with the borrow checker. fn solve_day6_1(){ let mut cycles : u32 = 0; let start = [0, 2, 7, 0]; let mut current = start; let mut history : Vec&lt;&amp;[u32]&gt; = Vec::new(); loop { let old = current.clone(); history.push(&amp;old); //other code } I get an error at the end of the function that old does not live long enough, as it is borrowed when the reference is pushed to the vector. I think I understand the error, but I don't know how to solve it. How do I let the compiler know that I am not interested in retaining ownership of the copy after it is in the vector?
RON looks like what you'd get if you wanted something as similar as possible to JSON, except with much more complex syntax. I don't know why you'd ever want that.
Why is reuse/DRY a gotcha?
Yep, my bad.
Yesterday, when I was serializing transaction data into JSON to transfer between two services. I confess it's not a configuration file though, so, point to you there.
Neat! Thanks for sharing this.
As a learning exercise, I tried fixing the compile without removing the lifetime from Parser. https://doc.rust-lang.org/book/second-edition/ch19-02-advanced-lifetimes.html helped me here.
EFL's features are nice but stability hasn't been a feature. They've done a lot of work to make Coverity happy, but I don't know if and how that translated to crash-free operation of EFL applications.
That's exactly what I was looking for, thank you!
Gave it a look and seems very useful, thanks!
Of course they've been rustified: https://github.com/gabdube/native-windows-gui // [limn](https://github.com/christolliday/limn) is very promising for a cross-platform library, pretty early though.
Thanks a lot, this was what I was looking at :)
Ah, thank you for explaining that! That makes perfect sense.
Ok, let's go over what's happening in that loop body loop { let old = current.clone(); At this point, you have a copy of your array which is *local* to the loop body. history.push(&amp;old); You have now added a *reference* to your copy to `history`. Note that you haven't added the copy itself to `history`, so the `old` variable still owns the copy. //other code } At this point, all the variables local to the loop are dropped, including `old`, meaning the copy no longer exists. However, you still have a reference to the `old` variable, which must live as long as `history`. You now have the conflict, because the reference is living longer than the data it points to. What you need is for the copy itself to live longer than the loop body, can you see how that could be achieved?
Fantastic
You'd probably need to use your operating system's packet filtering facilities to stop the egress, but you could route outbound web traffic through a proxy and play with it there? Maybe https://crates.io/crates/shadowsocks-rust has some code that would be useful.
By far the easiest way to do this would be to manipulate your [hosts file](https://en.wikipedia.org/wiki/Hosts_(file\)).
Cool, I'll check it out :)
That makes sense. There should be a way to temporarily modify it with Rust, right? Modify the hosts file for the duration of the program's execution, restore when program terminates?
If you want to block URLs, you'll have to do it at the application layer, which means one of the following: 1. Block all HTTP traffic which does not flow through a proxy you write and that proxy can inspect the HTTP requests. 2. Write some kind of deep packet-inspecting helper into your OS's packet filter. (ie. Write something which inspects every packet your machine tries to emit and understands enough HTTP to act as a proxy despite the application trying to to connect directly.) Now, that's only for HTTP 1.0 and below. For HTTPS or HTTP 2.0, you'll need to install a new root certificate into your system's cert store and generate a cert which is valid for `*` so you can man-in-the-middle all encrypted traffic without the browser pitching a fit. (Just be **very** careful that your intercepting proxy replicates all of the browser's certificate validation logic and applies it to the certificate returned by the *real* destination server.)
[removed]
[I posted in the other thread.](https://www.reddit.com/r/programming/comments/7j3k51/jorendorfftalks_what_really_causes_software/dr3zi0r/) IMO this misses the point. The ultimate reason the Therac-25 tragedies happened is that companies don't make secure software because customers don't value it. No change can happen until there are strict government regulations or these sort of issues are made transparent to users.
I wouldn't recommend it. Some applications (Chrome, if I'm remembering correctly) cache hosts file lookups and it's not a guarantee if they bypass local DNS, as Chrome can be configured to do if you set the right performance-enhancement flags.
I have been writing a crate for [persistent data structures](https://github.com/orium/rpds/). This week I will finish the red-black tree implementation (currently only missing `remove()`).
Well, *almost.* The string has to be in a constant context: a literal, a global const, or a template parameter. You can't `mixin` a runtime string parameter like in the example.
So I can compile non-thread safe programs? And with some datatypes even have programs that won't panic at runtime if a race condition happens? I mean, I know I can do that with unsafe, but I didn't know the stdlib allowed that.
I thought the hosts file blocked the ip, so its already after the dns.
Hmm. But if Chrome/other applications have their own internal DNS cache, why would that be affected by the hosts file? Do they get updated/modified when the hosts file changes? If that's the case, couldn't I save the hosts file as it currently is, then run the program that modifies it as I'm intending to, then when I'm done just restore the hosts file to the previous state?
No, it's all constructed so the compiler catches the potential problems. For a specific example, you can't pass one of the copies of an Rc to another thread because Rc doesn't implement the Send trait. You *can* pass one of the copies of Arc to another thread, because it *does* implement the Send trait. 
Its postponed (which means the issue should be discussed at a later point, in this particular instance sometime after the impl period). Postponed is different to being closed (which means rejection of the issue). Thanks for pointing out though, I had thought it got accepted.
Isn't that recognized by projects like Rust, though? The problem that you (implicitly) point out is "it's easier to make insecure/unsafe software than it is to make secure/safe software". Projects like Rust (or Haskell, etc.) aim to make it just a bit easier to write safe/secure software. They don't make it *as easy*, and it's not clear that that's possible, but I think they do lower the bar. Or to put it another way - they make it so that the bar is *more visible*, and you (often) know when you're shipping something that doesn't measure up.
Nope, the hosts file maps domain names to IP addresses. The standard system DNS resolver will check it first before making a DNS request to an external DNS resolver, but if a program uses its own custom DNS client that doesn't check the hosts file, then adding an entry to the hosts file won't do anything.
The hosts file is a local override in OS-provided DNS lookup functions like `getaddrinfo(3)`. Nothing more and nothing less.
Why would those people use Rust or Haskell in the first place though? Rust is in the top 43 of the [TIOBE index](https://www.tiobe.com/tiobe-index/). It's simply easier not to use Rust.
Because they query the system DNS (which means they listen to the hosts file) but then they cache the result in memory for a limited period of time so that, if the OS doesn't provide a DNS cache of its own, you won't be blaming them for the delay of doing a DNS lookup every time you click a link within the same domain.
See? You don't think about using toml as a wire format to use between services? Why you thinking about json for manually created configuration? Now, if configuration is done entirely in UI and user doesn't have to update it by edditting file in 99% of time - sure, use json.
That's fair. "You can lead a horse to water" and all that - point taken that regulations need to put pressure and force companies to "drink".
Routing the outbound traffic seems more like what I'd like to do, I don't really want to mess with DNS caching so I think I'll look at this approach. Thanks!
Regulations are one part but not enough. I'm sure everybody is familiar with the concept of highly restrictive regulations that don't actually do anything. In [my blog post](https://blog.sstewartgallus.com/enough-about-php-already/) I identity three things needed. 1. Transparency. Bugs are quite often non-obvious. You often don't know you've got a security hole until it has been exploited. Normal users are completely in the dark in this and cannot prioritize buying less buggy software because it is impossible for them to tell. 2. Regulations. 3. Make a more compelling case for reuse. Rust helps to solve point three for creating a stable foundation that is easy to build on top of. And government regulations can make companies go through the motions. But companies will simply cheat if they feel they can profit more than the fines they are hit with. There needs to be some form of user-education and objective consumer review of security track records. The free market model simply does not work if customers do not have perfect knowledge.
I recommend checking out the official guide, as it is fairly high quality. You may also just want to read the docs as well. There are also some talks on YouTube. Some example projects also exist as well that show how to use it. I think they have everything you mentioned in the guide, so that might be a good place to get started. https://rocket.rs/guide/
Why does it have to be in the middle of the day? :'( I work during the day
Am I the only one that would have exactly expected the current behavior? To me, right shift of a negative number has no real meaning. It makes me think of the internal representation of the number and then decide what the meaning probably is, and then verify it with the documentation. I would never assume it always affected values in the same way as two's compliment primitive numbers.
Testing is expensive. Software companies prefer to gamble that they won‚Äôt get sued. There‚Äôs a reason that most software licenses include a clause like ‚Äúno guarantees lolol‚Äù.
I was finally able to port my ORM written as a compiler plugin to procedural macros, to make it work on stable. I hope you will enjoy the simplicity of doing SQL queries with TQL. Any suggestion for improvement are welcome!
A nice way of understanding cells is to think of them as metadata. For example, say we have our own array implementation: struct MyVec&lt;T: Copy&gt; { data: Vec&lt;T&gt;, last_accessed_index: usize, last_accessed_data: T } fn get(&amp;Self, index: usize) -&gt; T { if self.last_accessed_index == index { self.last_accessed_data } else { self.last_accessed_index = index; self.last_accessed_data = data[index]; self.last_accessed_data } } MyVec is intended to cache the most recent access, so accessing the same element over and over again is faster. By the normal rules, the borrow checker will not allow this code to compile. Why? We're not modifying self.data, so everything _should_ work. But we _are_ modifying the last used index. Even though the get() method doesn't need mutable access to the data, _updating the metadata does_. This is where cells come in. This will compile and work as expected if we wrap our metadata in Cells: struct MyVec&lt;T&gt; { data: Vec&lt;T&gt;, last_accessed_index: Cell&lt;usize&gt;, last_accessed_data: Cell&lt;T&gt; } Now our get method will compile! [Try it in the playground.](https://play.rust-lang.org/?gist=63d735c996474e5b75e69a716cc4d4f6&amp;version=undefined) This is not the _only_ purpose for cells. There are many different ways to use it. But in my experience, you use it most often with metadata that should mutate _even if the structure is being treated as immutable_.
I wrote a page detailing the data collection and analysis for [Criterion.rs](https://github.com/japaric/criterion.rs) (a statistics-driven microbenchmarking library). I'd appreciate it if folks would read over it and send me any comments or questions. https://japaric.github.io/criterion.rs/book/analysis.html It's also possible to run the benchmarks with the standard `cargo bench` command (rather than `cargo test -- --bench --no-capture --test-threads 1`, which nobody can remember). I'll probably publish this version to Crates.io tomorrow and then start working on a stable-compatible release.
The problem is that some people expect it to work a certain way while others expect it to work the way it does now. I personally would never use a shift on big-int because the way we expect shifts to work relies on 2's compliment.
Thank fucking God, some actual sensibility. I occasionally see it in this sub. Enforced standards are what create secure software. So many Rust people like to point to Toyota's big blunder, and they immediately blame C. What they don't realize is that there are safe standards and automated tooling to circumvent this, *for C*. The amount of MISRA violations in the audit was astounding. People who have strictly followed MISRA haven't had these kinds of issues.
I tried [avoiding the extra allocations](https://github.com/binarybana/imgsort/blob/master/src/main.rs#L51-L67) using some unsafe code but can't figure out how to avoid segfaulting. Maybe due to alignment?
Awesome work, i especially love the Django ORM its actually the only reason i still use Django ü§î Does your library have support for m2m and how about annotating queries? How about F() I saw you mentioned Q() Hmm, also query Windows are useful some times. .. this i did not see mention.
at first glance, very clean and easy use as a orm for Rust. Thanks for your work, i am going to give it a try on my side project. anyway how to use array or jsonb type with TQL?
I agree that right shifting negatives is weird. In C99 it's even *implementation defined*, even though most will use an arithmetic shift. I feel that `BigInt` ought to be semantically interchangeable with primitive integers, only different in the expressible range, which means mimicking the primitive behavior is better.
&gt; Interesting detail: Rust doesn't allow mutable static globals. Yes it does. Updates have to be marked as unsafe, but it does allow them.
Language/technology selection matters some but it's only one piece of the product. The entire software development process has to build quality and risk into it. Many of the regulations in place exist to address what's listed in the linked blog and more. 
If you're not aware, the Therac-25 did kick off a bunch of FDA involvement and regulations around medical device software. There are standards/regulations around software development processes (IEC 62304) and also quality/risk management (IEC 13495, CFR title 21 pt. 820).
I recently addressed this in 0.2.5 [here](https://docs.rs/static_assertions/0.2.5/src/static_assertions/lib.rs.html#198-208) :)
This is a beautiful API! SQLite next? :P
Arithmetic shift on signed numbers is a very useful operation as it is the same as floored division by power of two. The compiler can't rewrite divisions by powers of two on signed numbers into this as the rounding semantics are slightly different, which is a shame. I would prefer all divisions were floored instead of rounded towards zero.
True, corrected readme
How far away is sqlite support?
Yes! You are correct. I mixed up the two.
Also, the example seems to run very slowly. If you hold a direction it lags visibly and then tries to catch up. Is there some way to fix this?
The syntax looks cleaner. I've been wanting to use `==` or `&gt;` `&lt;` in an ORM syntax, but i didn't think it was possible. Now, i know it is possible. &gt; id: PrimaryKey, A few ambiguity here. Does primary key only supports Integer types? how about the case for String or Uuid primary keys. How about having generics in primary keys like: PrimaryKey&lt;T&gt;, and support most common primary key data types: PrimaryKey&lt;i32&gt;, PrimaryKey&lt;String&gt;, PrimaryKey&lt;Uuid&gt;. 
That still doesn‚Äôt allow for multi-column primary keys, though.
Nice. Just please do not claim that Vector has O(1) operations (like Clojure and Scala does). It is not true.
To add to the choir, my favorite format would be [lua](https://www.lua.org/pil/12.html). There are lua bindings available for rust, so I guess this would be doable. Might be a tad overkill, though :)
I'm so confused by your number 1. I am reading it like an answer to the OP's 1, and the link I am interpreting as a link to more information on the "rvalue static promotion" ‚Ä¶ problem. But it links to right here?
I remember doing things like this in Lua, basically to avoid typing `function` too much. Given how lightweight Rust lambda syntax is, this feels unncessary. Also, it isn't really a closure - just a pure function that does not borrow from the environment.
Well each loop iteration must create a new copy. So in order for the copy to live longer than the loop, ownership must be transferred to the outer scope, where the vector lives. So I am going to try to move the copy rather than have it borrowed. [This](https://play.rust-lang.org/?gist=2e2e1e5d338e038235cc3c7d859ec798&amp;version=stable) *does work*, but it creates a new issue: let mut history : Vec&lt;[u32;4]&gt; = Vec::new(); For the example, specifying the array size in the type is fine, but what if I wanted this function to work on an array of arbitrary (but still fixed) size? Is there a way to get Rust to infer the size of the array in the vector from `start`?
I think it's impractical to add a requirement that the programmer must manually implement a conversion every time for Vec&lt;Q&gt; -&gt; Vec&lt;T&gt; where T: From&lt;Q&gt;. I think into() is sufficient to infer that the programmer knows there is a type mismatch and consents to it taking place. The main reason I can see not to do that is that it may not be unambiguous how that conversion should get done. A program already making heavy use of threads might want to iterate over the elements sequentially (but still using SIMD), but a program not making use of threads might want to par_iter() the conversion along with SIMD. However I think the practical requirement of expecting the programmer to remember all of this for each time a conversion takes place is unreasonable. I'd use a best-guess heuristic that works well in 90% of cases in the standard library - probably the equivalent of rayon and faster since IIRC both do detection of whether single-threaded would be faster and what the CPU features are respectively. And if and when specialization comes available, I'd go ahead and use a template to implement these automatically for types depending on whether they implement From, Clone, or are effectively an integer type (eg something that's just using dimensioned or wrapping the elements for serialization reasons). I'd expect this would give better performance than C++ for basic conversions without losing any type safety, and most programs would probably come out better off for it (most people not realizing they should use a crate like rayon).
But even with support for only 1 primary column pk, there are many possible data types.
&gt; Why does it have to be in the middle of the day? :'( That's when they work. It obviously isn't a good time for everyone, but what is? &gt; I have a hard time seeing why bringing up Rust would be relevant though. I think it makes more sense to focus on WASM itself [...] Because Rust wants to be a first-mover here. Rust has a pretty good chance to becoming one of _the_ languages to target Wasm. It still needs integration, features, ... Wasm is designed to be a target from other languages, so it makes sense to see what features Wasm needs to get and how those features can be used from other languages. And given that we're in /r/rust here, asking about Rust seems reasonable.
This is not a YAML behaviour though. This is Rubies YAML implementation being too clever and triggering object construction when seeing certain tags. The XML parser had similar bugs.
Would it be possible to make it handle tuples?
Each element of the tuple would have to have a column mapping defined then. Perhaps this could be done with a specially crafted custom struct.
Of course you can blame C, the language is just plain unsafe by default. MISRA is basically restricting you to painfully cumbersome subset of C. It's a necessary evil when you write software with any security requirements in C. But if you would have chosen Rust instead you wouldn't need MISRA at all, just restrictions of unsafe usage and possibly heap allocations.
This is my first crate that is published on crates.io and essentially first library written in Rust by me, so I will be glad to see any comments and proposals how to improve it.
It seems like the crate has been yanked ? What happened ?
Typo in readme. And exactly now windows decided to install updates.
Yup, that's nonsense. [Here are the complexities](https://docs.rs/rpds/0.1.0/rpds/sequence/vector/struct.Vector.html).
What's the main difference to diesel? When should I use TQL and when diesel?
Now it is there again.
I'd like to counter the notion that JSON is simple. In fact there are some edge cases around keys, null vs. undefined, numbers and Unicode, which may lead different parsers to return different results. RON on the other hand is much more regular and maps nicely to what you would write in Rust, so you can `include!(..)` it when you no longer need to change it.
Ping me if you need help with stable-compatibility.
Or you can set a proxy in your app (browser), and write a proxy. You may be interested in Squid (a web proxy), and the url_rewrite_program directive : http://www.squid-cache.org/Doc/config/url_rewrite_program/
Good question, I don't think I can change when keypress events occur, but I can probably optimize character updates. It blasts many calls rust to js right now.
I love the idea, one nitpick is that I kinda want a really good jooq replacement in Rust. What this in my humble opinion lacks is: * Join on non-foreign key * Multi columns keys I have a bunch of legacy tables in following form: struct Country { ctry_code: String, tenant: String, description: String, primary_key: (ctry_code, tenant), } * Defining unique constraint on multiple fields. Many to Many tables need this, especially struct UserRole { id: PrimaryKey, user: FK&lt;User&gt;, role: FK&lt;Role&gt;, }
I don't think that you can make a generic XML structure. Interface - maybe. There are just to many way of representing a DOM. As an author of SVG libraries (xmlparser -&gt; svgparser -&gt; svgdom -&gt; resvg) I understand you, but I can't imagine what can be done. For now, all I want is a generic tree structure. Currently, for svgdom I'm using `Rc`, but it's too painful, especial when you need cross references. Basically, a vector of nodes (aka id tree), but with ability to borrow two or more nodes mutably (obvious unsafe) and with a very simple API.
In my view, shouldn't a person be first coming up with an understandable strategy for addressing a problem? Then, they should be figuring out the most minimal implementation of that strategy which adds as little language-idiosyncratic cruft as possible. I see the worrying of performance *and* cognitive ease as something that should happen at the phase of designing a solution to a problem. 
Ah so, not numeric hex literals (which Rust already has, somewhat sadly with C-style syntax) but rather *bytes* hex literals. I feel that, while not completely uninteresting, the "paste hex from &lt;source&gt;" argument is underwhelming and it falls way short of Erlang's bit syntax for building non-trivial binaries. Further: * why the support for a single base? * why use a different base denotation than numeric literals * in fact why isn't the base a modifier on the `b` prefix? e.g. `bx` for hex binaries, `bo` for octal ones, `bb` for binary, or `bN""` where N is the base (between 2 and 36 included?)
Note that you shouldn't be yanking a crate just for typos. Yanking a crate is typically reserved for when you want to prevent new crates from depending on a specific version of your crate. For example, maybe you accidentally introduced a breaking change or the crate had a serious security vulnerability. For simple bugs though, just bump the version and re-release. :-)
I personally haven't seen a need for different bases in real codebases, but have seen a lot of `0x` and `\x` noise. (contr-examples are of course welcomed) While it definitely could be interesting to have capability to use different bases, I think it will make implementation of the proposal way more complex, without substantial profit. Although I will add `bx` proposal to the "Alternatives".
&gt; However, this then requires that I bring a trait from an external crate. This appears to me as the program now being dependent on that crate, even if I ever split my library portion into a separate crate. And this leaves me with a sense that some abstraction or encapsulation is being broken. No, I don't think anything is broken. A public type that implements a public trait is fundamentally part of your public API. Let's say you published a crate with a `Foo` type that implements `Debug`, for example. If you removed that impl in a future version, that would be considered a breaking change. That's because the fact that that impl exists is itself part of your public API. If you *don't* want said impl to be a part of your public API, then you have choices. For example, if you impl a public trait on a *private* type, then that is not part of your public API. For example: use some_crate::SomeTrait; pub struct Foo(InnerFoo); #[derive(SomeTrait)] struct InnerFoo(()); impl Foo { fn some_method_with_same_name_as_method_on_some_trait() -&gt; ??? { self.0.some_method_with_same_name_as_method_on_some_trait() } } You can then call `some_method_...` from your `main.rs` without ever needing to care about `SomeTrait`. The downside of this is that you might lose some the advantages of what `SomeTrait` gives you, but that varies on a case by case basis. The bottom line is that you should choose the right abstraction level for the job. I can't answer that question for you though because I don't know enough about the problem you're trying to solve. (And even then, reasonable people might disagree!)
Thanks! This is fantastic! I love that the examples are so short, it's easy to understand what's going on. It actually got me to try and port my game. Unfortunately, the rand crate (which I depend on heavily) does not compile under wasm yet :-(.
Well, as I said it's my first crate. BTW the typo was in sample code in Readme.
Ah, I misspoke! Turns out, the master version of rand on github compiles with wasm. It's just not on crates.io yet.
You can publicly re-export trait using `pub use trait_crate::Trait;`, this way users of your library will be able to write `use your_crate::{Foo, Trait};` without specifying `trait_crate` as an explicit dependency. [Inherent trait impl](https://github.com/rust-lang/rfcs/issues/1971) will hopefully one day will make it easier to work with such code.
Wow! I'm definitely bookmarking this to look at later.
It's all good! I actually used to use D long, long ago.
Uh... yeah I don't know what that's about. This was like a week ago. I think I meant to link to the PR? Anyway, https://blog.rust-lang.org/2017/10/12/Rust-1.21.html is a good explanation; see &gt; First up, a small change to literals. Consider code like this:
b itself is already for `&amp;'static [u8]` literals. using `bb`/`b_` would be confusing.
b itself is already for `&amp;'static [u8]` literals. using `bb`/`b_` would be confusing.
Split puts into **word** variable a reference for the substring wne you're doing it like that; to copy substring values you should map() the results (with to_string()) and iterate with results of that.
You need to use a `BTreeMap&lt;String, usize&gt;` When you use a borrowed `str`, the callee can only store strings that live at least as long as the map itself - there's no way for it to do this, because everything will go out of scope at the end of the function. To solve it, the map needs to *own* the keys it contains - that way the callee can create a new `String` and pass ownership of it to the map, and there are no additional lifetime constraints to worry about.
Wouldn't it be better to define all constraints at the table, or in this case struct, level? That way you can support arbitrary overlapping constraints, including the common case of having a foreign key from a subset of the columns of the primary key.
As in do `let word = word.to_string()`, or are you suggesting the to_string() go somewhere else?
Ah, yes -- I tried doing that by doing `let word = word.clone()`, but now I see that I was just cloning a reference which didn't help. Thank you so much for your help!
By annotating queries, do you mean doing aggregation? If yes, then it is already supported. Please take a look [at this table](https://github.com/antoyo/tql#syntax-table) to see the supported syntax. The support for ManyToMany will come soon as I need it for my web browser [titanium](https://github.com/antoyo/titanium). It does not support `F()` expressions, but I will add this feature. For these expressions, what do you think of a syntax similar to the following: Table.filter(field1 == $field2) I don't know the `Window` feature, but I'll take a look a it. Thanks a lot for your suggestions!
Unfortunately, it is not started yet, but since I need it for my [web browser titanium](https://github.com/antoyo/titanium), it is one of my priorities.
Yes, `SQLite` support is coming.
Only `i32` si supported, currently, but I will make it generic in the future. Thanks for the idea!
Yes, I will add the support for these types (I didn't know [the crate postgres][https://docs.rs/postgres/0.15.1/postgres/types/trait.ToSql.html) supports this). Thank you for the suggestion.
Carnix allows to share build products between different crates and releases, and to integrate Rust crates with non-Rust dependencies (such as external native libraries).
I will add these features in the future. Thanks for the suggestions. Yes, I need help. The documentation is obviously the most important thing missing now: if you're interested, we can discuss [in this issue](https://github.com/antoyo/tql/issues/1). I also created a bunch of issues on GitHub, so of which are tagged as `easy`, so you might want to start there. Also, when there are multiple solutions or designs, please discuss it before implementing it. Thank you!
Awesome! Great work and thank you for writing a blog post!
So even less reason to yank since it has no effect on users of the crate
Seems to be reasonable. 
&gt; Interesting detail: Safe Rust doesn't allow mutable static globals. So you have to create a global mutex that holds a mutable value. That way all your library entrypoint functions sharing that global data are thread safe. Turns out there is a cargo package lazy_static that makes this easy. There are arguably better tricks you can use to get around it than constructing a global mutex, like 'pass the world around'.
I love having a django like syntax for a orm in rust! I'm a bit worried though that we now have a well tested, nearly stable ORM (diesel) and one that has great syntax but otherwise lacks features and testing (TQL). Is there any chance there will a django/TQL like API extension for diesel?
[removed]
I assume bsandro meant `for word in l.split(|c: char| !c.is_alphanumeric()).map(|s| s.to_string()) {}`
So since the map contains references, the data those references point to must live at least as long as the map (otherwise you could get a pointer from the map that points to invalid data). `word` is a pointer to a section of `line`, and so only lives as long as `line` does, which is for the scope of a single iteration of the `for line in ... {}` loop. Once that iteration is finished, that value of `line` is destroyed and `word` points to invalid data. What you want is to use owned data, so `map` would be a `BTreeMap&lt;Cow&lt;str&gt;, usize&gt;` (so you can store either a reference or an owned value) and you'd change the `insert` call to `map.insert(word.into(), wcount)`.
Good job.
Oh yah? I'm interested in better ways
The link should be https://nest.pijul.com/pmeunier/nix-rust.
&gt; Wasm is designed to be a target from other languages, so it makes sense to see what features Wasm needs to get and how those features can be used from other languages That's a good point, thanks 
&gt;Why does it have to be in the middle of the day? :'( Only available time for the panelists. Always a bit tricky to find time (optimal time in US ET = bad in Europe/Asia). The session is being recording, transcribed, and translated, though :) &gt;I have a hard time seeing why bringing up Rust would be relevant though. @badboy_ is spot on. There's been active curiosity in the rust community (interesting rust-internals thread: https://internals.rust-lang.org/t/state-of-webassembly-and-rust/6077) about wasm/rust use cases, support, adoption, etc. 
Looking at the code, you seem to be going from rust -&gt; js for every character. Would it be quicker to keep a copy of the game matrix in Rust, update that in the loop and then only make one call over to JS by passing in the entire matrix of characters to draw?
what exactly does the `sql!` macro do? and how does it unhygenically use the `connection` variable? I thought Rust macros were more hygenic than that.
I'm missing something, why would stability change anything about the resulting image in your program?
Remove the type specification: let mut history = Vec::new(); The compiler is usually smart enough to figure out what the type needs to be when you first use it.
This is not broken, and it actually solves the following issue: when you want to use traits from different crates, implemented for the same type, that might have methods with the same name. This is an unfortunate situation, but it might happen. Example: suppose crate A exposes trait Ta, and B exposes trait Tb, both with a method called "method". Now you create a new type S, and for some reason, you want it to implement both Ta and Tb. When you call `s.method()` from your main.rs, how do you know which version of `method` (from Ta or from Tb) the Rust compiler will pick? Forcing you to import the trait into scope fixes that problem. Moreover, it could be the case that Tb doesn't implement `method` at the time you write your project, but the authors of Tb, unaware of the existence of Ta, decide to add that method later on. Your code would then become ambiguous, and would (hopefully) be rejected by the compiler. 
Would be nice if was also asynchronous.
I never felt the need to have a static guard. Could you explain where you need it? As for the code, the first concern that comes to my mind is how you map the cell to a lock. The way you do it, you could have two cells use the same lock (if their memory location is 16 KB). Admittedly, this is rather rare, but feels like a hack and could (in rare cases) cause hard to track dead locks.
That's confusing, since `bb"1010"` and `b"1010"` mean different things despite both being "binary literals"
you can't get access to keypress events inside of wasm...
I think the issue is, we're still stuck talking about "ORM" when afaik this is pretty well known to be an anti-pattern now. What we actually want is statically verified SQL (which we can, potentially, use in more appropriate patterns). Personally, I'm wondering if it even makes sense to expose a datatype representing the tables. They are needed for the system to detect errors in the SQL but as a consumer of the API, I generally just want ad hoc queries which return an N-arity "tuple" or list/array of them. If I happen to have some struct of the same shape as the table (which, if you're doing proper 3rd normal form, you probably shouldn't!) then I can assign the tuple result to that myself. I don't see why the "ORM" would need to know about my struct.
Not sure this is really necessary. For large(r) binary blobs to be included in the source code, there is already `include_bytes` which works with actual binary files.
Try rand from git, it has wasm support (you'll have to seed yourself though).
That is not normal, it should really be seamless. RLS component changed the name a few times already in the way to stability, so this may be the source of your issue. Take a look at this post I've written a while back, this should be up-to-date and at the end there is a powershell script to do all the job for you: https://fungos.github.io/blog/2017/08/12/setting-up-a-rust-environment-on-windows/ 
Ha, that probably should have been more obvious, but I suppose that's what happens when you feel you are 'fighting' the compiler. Thanks for your help!
OMG! Amazing work. I've been following this issue and intending to get involved in Nix development but a million issues keep popping up. I'm so happy this finally exists. I'll hopefully give it a spin soon and (eventually) help with developing it. :) :) :) :) :)
Window function or [`PARTRITION_BY`](https://drill.apache.org/docs/sql-window-functions-introduction/) is a way to aggregate data over a subset of all data.
[removed]
Working with small byte ranges, `include_bytes!` is not very handy because as a reader you cannot see through the macro to know what's included, and it requires a plethora of small files for your unit test... ... on the other, any other kind of macro which just takes the bytes as argument should work all right.
Where do regulations succeed where a software branch of Underwriters Labs would fail?
It landed! This is going to make deployment of my Rust webapp so much smoother! Thank you so much for this awesome work!
Are there examples of linking native libraries or otherwise obsoleting build.rs scripts? It looks like buildRustCrate runs the build.rs, but doesn't leave space to declaratively provide native dependencies. Do you think rust should follow haskell in having nix as the underlying infrastructure of cargo? 
Great to see some progress! `mdbook build` creates an epup but not html anymore :(
&gt; 99% of the time there is a choice between performance and readability, readability is the right answer Readability, with a comment explaining what the optimization might be and why it wasn't chosen.
This is great. I think your wording regarding `rustfmt`is confusing. Do you want people to install the crate or the rustup component?
JSON is certainly underspecified and prone to errors as a result, but the actual syntax is nonetheless simpler in practice and hence, in that regard, easier to use and less surprising. Most JSON does not invoke parser corner cases. There's more to having a user-friendly data encoding than a well defined grammar.
This looks cool! The error message in your example is a bit odd, though: error: mismatched types: expected `i32`, found `String` --&gt; src/main.rs:87:39 | 87 | let table = sql!(SqlTable.get("id")).unwrap(); | ^^^^ | = note: in this expansion of sql! (defined in tql) "id" isn't a `String`, it's an `&amp;'static str`. How are you constructing these messages? Proc macros don't have access to Rust types-- are you doing some kind of analysis of the tokens themselves? Anyways, keep up the good work!
I‚Äôm interested in the log parsing and stashing stuff! When you have something to show, please page me! Thanks!
Implementation of `Send` for `Thex` looks invalid.
buildRustCrate indeed runs build.rs, and there are examples in the documentation (the webpage for the nixpkgs manual has not been updated yet).
Nice! Thanks :)
This is the very point of this type, if you look in the tests you'll see that Thex&lt;Rc&lt;T&gt;&gt; works just fine, the thread-exclusivity is guaranteed by the locks.
The motivation was basically that it's more or less impossible to use RwLocks for tree structures, if you want to be able to return references to the leaves of the tree. And in your exmple, the two unrelated cells would just have to wait for each others (unrelated) writes (this is the tradeoff of having a finite set of locks) 
Nix runs only on Linux and MacOS. It doesn't work on Windows. As such, it's not portable enough.
I'd like to see Cargo evolve into a more general package manager though. Or maybe if someone found the time to rewrite the non-portable parts of Nix in Rust‚Ä¶
Well as I said, this can also lead to a dead lock which would be bad. I'd recommend using an atomic counter for the mapping.
My bit level packing library has received a bunch of quality of life improvements, including arbitrary bit widths and full support for arrays. Great for various structures that hardware drivers or low level network stuff deals with all the time. Getting close to releasing it on Crates. https://github.com/hashmismatch/packed_struct.rs
I found another issue: if your cell gets moved, the pointers become invalid, thus will cause UB. Regarding the the Send / Sync implementation, /u/Omniviral is right. It seems you misunderstood the basic concept how those work. If a type isn't `Sync`, its implementation can rely on that fact and may be incorrect if used from multiple threads. `!Sync` is not restricted to parallel access.
Daniel Griffen has implemented a Visual Studio extension using the RLS (nb, not Visual Studio Code). It is early days in development, but it already supports all the core functionality. This is very exciting! If you're a Visual Studio user, please try it out and let us know what you think!
Hi everyone! I'm the author, so if you have any questions about the extension don't hesitate to ask.
This is basically exactly Diesel's design philosophy and current implementation. It just has convenience traits to convert tuples into structs.
Maybe we could write about this somewhere?
That would be cool, but why? Are you mostly hoping to avoid JNI?
awesome, one thing I haven't yet seen but would be interested in is a trait browser, as an extention to the usual 'class views' that IDEs tend to have.. imagine if it actually let you browse from a struct to all it's impl'd traits, and vica versa (I know rust-doc has that available but it's just that little bit smoother when it's available in the IDE, responding directly to 'jump to def' etc)
No questions, just thank you! So excited to see this.
The RLS does have gotten implementation support. It's not part of the standard language server protocol so it's not in the extension yet but it's definitely something I'll be looking into!
As someone who's never used Visual Studio but who's heard good things about its C++ support, how does this extension's features compare? Are there any features from the C++ editor that you don't expect this extension will ever provide, either because of the difficulty of implementation or because of RLS limitations?
I'm not familiar enough with the c++ support to give a complete answer (I use c# much more than c++). Support will continually evolve as more and more LSP support is added to VS. One main missing feature will be debug support since that isn't part of the protocol. It may eventually be supported by this extension but that is a long term goal.
How are you retrieving table information (column names + types, foreign keys, ..) inside a `sql!` macro?
In that case, can you compare the limitations of RLS/LSP with what VS provides for C#? I admit that as someone who tends to just use stock vim I'm curious as to what sort of potentially exotic abilities I'm missing out on in IDE land. :)
When you say debug support what do you mean, I can already debug rust programs in visual studio by just attaching the running process.
Microsoft should rename Visual Studio Code to just "Code". Such weird branding.
I was not aware that it was so easy. My only experience with Rust debugging was in vscode where there is some work to set it up. If you really can just attach to the process then it shouldn't be too hard for me to implement support in my extension for the f5 scenario.
The missing features can be split into two categories: those which are missing due to early LSP support in VS and those which are not part of the protocol. The former set of features should be added as LSP support matures while the latter will need work that isn't part of LSP support Major missing LSP features: - rename symbol - code actions (lightbulb) - hover text Features not part of LSP which are in C# - Auto implement interface (trait) - this could potentially be added via code action - IDE-integrated tests - passed tests will be marked in the editor - IDE has a list of tests and their status - Integration with relevant languages package manager - Nuget for C#, cargo for Rust - View call hierarchy - Code graph (can create a graph of function calls, class inheritance etc.) There are probably some features that I'm missing but hopefully that list helps!
Yes, it should be quite easy to implement. We have it working in [VisualRust](https://github.com/PistonDevelopers/VisualRust) (which unfortunately is not maintained any more) ... feel free to look at how things are being done there, if that helps.
You also have to at the natvis for rust to the correct folder. Heres the guide I used to get it to work with visual studio 2017. http://www.jonathanturner.org/2017/03/rust-in-windows.html
Visual Studio Code already has 'find all impls' for a struct or trait. It's not as complete as Rustdoc's yet (doesn't include blanket impls or deref coercions, for example) but it is still useful.
Hey, i'm not sure what you mean by the cell getting moved. This works for example: ``` fn moving() { let thex = Thex::new(Box::new(0)); let read = thex.shared(); let mut a = None; a = Some(thex); assert_eq!(**read, 0); } ``` The whole point of this type is to ensure that any writes to the underlying type is made in a thread-exclusive way, so that you can wrap types that don't expect concurrent access.
Microsoft has a long history of launching new products on the coattails of successful older products. I sympathize with the frustration over their naming practices, but I don't expect Microsoft to change. Off the top of my head, here is a list of products pairs where the two products are vaguely in the same space, but actually quite different from each other: * Outlook / Outlook Express * Outlook / Outlook.com * OneDrive / OneDrive for Business * Skype / Skype for Business * Visual Studio / Visual Studio Code 
1) In your example the value doesn't actually get moved, since it's allocated (so it works in that case) 2) My concern is still valid for a dropped value.
How good is it compared to Intellj Rust plugin?
To make matters worse, OneDrive for Business used to be called Groove and also SharePoint (or were related in some fashion), and Skype for Business use to be called Lync. They don't just launch new products, they even rename existing products to "integrate" them into other more successful brands.
The IntelliJ Rust plugin is likely more feature complete at this time. This is mostly due to the fact that IntelliJ leverages their own code analysis technology to provide better results. This extension uses the RLS for support and does no extra analysis of its own. In my opinion the two advantages that this extension has over the IntelliJ one are: - Does not lay down extra project files in your folder - It is possible today to debug Rust binaries in Visual Studio. Right now the steps are a bit involved but its doable. As far as I am aware debugging is not currently possible in IntelliJ
I'm looking into it now. My one concern is that VisualRust works via a project system where this works via Open Folder. Open Folder has different extension points than a project system does and they don't have the best documentation at this time.
I'm having the same issues. [This](https://imgur.com/JWqLsHN) is what my VS Code looks like after installing the rust-lang plugin. I have rustup installed and working, I can run cargo from the command line, and it runs my hello world project.
Yep, deadlocks is a real issue, but you have that risk with locks in general.
If I'm not mistaken, you have debugging support on CLion.
Difference is that "locks in general" won't deadlock if you do it right, while these locks will randomly deadlock.
This isn‚Äôt the right subreddit. 
CLion is a paid IDE though.
and I add: * Windows / Windows NT * Visual Basic / Visual Basic .NET 
SDL is supported on Wayland (see [here](https://wayland.freedesktop.org/toolkits.html))
You are right about dropping though, thank you, i will need to add a lifetime parameter after all.
And the Windows 10 music player is called Groove Music.
Nice library! I tried to implement a simple SSH server, but I couldn't get the client socket from the `Handler` methods (data, or auth_password for example). I tried to play around the `server::run` function, where I can simply `println` the socket. Do you now how this could be done, or if it even possible? Thanks!
That's what I was referring to in point #1. A block/redirect isn't very effective if an application can silently neglect to follow it.
If something like this works, I think that would make for a powerful syntax. Table.filter(field1 &gt; $field2 + $field3) and let mut x = $field2 + $field3 Table.filter(field1 &gt; x ) 
&gt; Skype for Business This is hilarious naming, as it don't allow you to use skype at all. But rather their old "lync" shitbag
Just thankyou, this is great!
Finally, found some time to work on [rust-keepass](https://github.com/raymontag/rust-keepass) and developed some nice ideas around it with a colleague (more about that in the coming weeks hopefully). First result of this is [indextree-ng](https://crates.io/crates/indextree-ng).
Yep right. And I don't know how good is the debugging support...
https://crates.io/crates/rand/0.4.0-pre.0 should work
Because when you're sorting the pixels by say just the blue component, the order of the red and green components will potentially be different than the order in the original image. 
which used to be called Xbox Music
The "Implement Debug, Eq, PartialEq, and Hash for libc structs" link points to https://github.com/rust-lang/rfcs/pull/2237, but I think it should point to https://github.com/rust-lang/rfcs/pull/2235.
Don't forget about Microsoft Surface (the table) and Microsoft Surface (the tablet).
and Visual Basic for Applications
I always assumed final comment period meant a week to add any final comments. Those RFCs have been there for months... Should they not just be merged, and any changes needed can be part of the stabilization, like all previous new features?
While solving a new [advent of code](https://adventofcode.com/) problem every day, I add useful functions to my [pathfinding](https://crates.io/crates/pathfinding) library. In the last few days, I have added topological sorting and disjoint connected sets computatiojn.
I think a software branch of Underwriters Labs or similar thing would be a great idea. I understand why people would be concerned about choking regulations that don't actually do anything but for example one thing regulations could do is put pressure that would encourage companies to get their products certified by that kind of organization.
http://lmgtfy.com/?s=d&amp;q=blackhat+medical+devices I know about such standards. They bite hardest in medical related software and have done some good there but have not really penetrated into nonmedical software and in any case are not up to date with the latest technologies such as formal verification. The problem is that there is no profit to innovate past such regulations and raise the bar on quality assurance and safety. I think part of the miscommunication is that I have very high standards on this sort of issue. People bring up coding standards like Misra-C and think I should be satisfied with that. I am not. The fundamental issue is that I don't believe it should be difficult to create a vulnerability. I believe processes should be changes such that creating a vulnerability is impossible (or at least for medical devices and basic computing infrastructure such as commonly used OS kernels like Linux.)
Lync used to be Office Communicator.
Thank you Mozilla, for giving us reader view which makes such websites bearable.
&gt;Enforced standards are what create secure software. I feel this goes too far another way. Often times standards can be a red tape that don't actually do anything and that can prevent using newer and better processes and technology. Regulations can help but I think they can only ever be part of a solution.
&gt; or these sort of issues are made transparent to users Ultimately I want insecure software to make less profit then well tested software.
Yeah, at this point it is hard for me to explain exact points of i like, since it requires more C experience that I possess, however, if you look just at ideals that EFL goes for (like unified style/theming, scalability, libraries to reduce burden of developing code for specific tasks, full wayland support, etc.) and and then add strengths of Rust to it (memory-safety, concurrency and crates, just to name a few), then what is not to like about the idea of (at least) a spiritual successor to EFL written in Rust, to ease and improve GUI development for all those programmers out there?
I'm excited for the new const rfc! At least it's getting people talking and thinking about the problem. I agree with what a few people in the comments there have said. We'd want everything possible to be const, but specifying "const" everywhere seems distinctly un-rust-y (in that variables are const-by-default, so methods and functions and traits should be too, right?). I doubt it's reasonable to try to infer const-ness for every method and trait without massively increasing compile times. This might just have to be one of those things that seems weird at first glance, but actually turns out to have a good reason.
It is exciting. One quick nit: &gt; variables are const-by-default This is a common confusion-- variables are _immutable_ by default, but they are not `const`. In some languages (Javascript), `const` means "immutable", but in Rust, `const` means "at compile time", sort of like `constexpr` in C++.
I'll do what I can do about the dynamic query construction, but since I generate SQL at compile-time, it might be impossible to do.
The impl period means that teams are generally ignoring RFCs, that said, I thought none were in FCP.
&gt; I doubt it's reasonable to try to infer const-ness for every method and trait without massively increasing compile times. The bigger issue here is that making a function `const` is part of its public API. Whether or not a function is `const` determines whether or not it can be used at compile-time. A function could start out as`const`, but in the future you want to add, say, a C FFI call. By doing that, you'd be remove its `const`ness, which is a breaking change, since users of your API can no longer call that function at compile-time.
That should not be too complicated. Thanks for the suggestion.
This is a know issue, I just forget to change `String` to `&amp;str` when I generate the error message.
Ah, you said what I meant. Thanks, since what misleading. And saying that distinction makes const fn seem a lot more rust-y.
I'd say the main difference is in the implementation: `diesel` is built with normal Rust functions and methods, while `tql` is a procedural macro doing semantic analysis to give nice error messages and generating the SQL query at compile-time. Also, `diesel` provides a CLI utility to do things like migrations, which is not available in `tql`.
Right, but how would you actually say, for example, that the following code was invalid: ```rust let id = 6u32; let table = sql!(SqlTable.get(id)).unwrap(); ``` You don't have enough information to say "expected `i32`, found `usize`".
I mean my quality bar is fairly high, ideally in the verified algorithm territory, but there is something to be said for balancing perfection with the good enough principle, when the environment is not one of medicine or critical infrastructure but closer to Facebook bullshit.
Which used to be called Zune Music.
No, Zune Music was completely different (and much better) than Groove.
Visual Basic for Applications is Visual Basic. Same language, same IDE, same runtime, just hosted inside another application.
The lineage is there. Zune became Xbox became Groove. [First bit of the wiki page](https://i.imgur.com/mg8LMMC.png) I rocked a Zune for years and remember the app updating itself to be Xbox branded when they mp3 players died out. 
The wiki page is wrong. Until recently I had both on my computer and the only thing they've got in common is that they play music.
When I used it for the last time about 20 years ago, the IDE was integrated in Excel and the language was a bit different than the regular Visual Basic.
You might be thinking of Excel Basic (XLM), a BASIC-like language that it used prior to, and overlapping with, VBA.
Yes, that might be it. The worst part was that the language was freaking *localized*. We had the German version of the program, and every single BASIC keyword was translated in a literal fashion into German. At that point I had programmed BASIC for ten years, but had to look up every single keyword every time, because it was totally alien.
Ugh, that sounds horrible. I don't know if they localized VBA or not.
A `Handle` a same-thread reference to the `Core`. You're cloning it to `h2` so that it can be moved into the `for_each` closure, so that new connections can be spawned into the same `Core` when they are received. Tokio is being refined right now so that you won't need to worry about handles any more, unless you want to use non-defaults.
Safari too!
If you dig into the windows app folder or view Groove's properties in task manager you'd find the files and folders for Groove are still called Windows.ZuneMusic
Thank you, really excellent explanation! Will this be any more efficient than just creating a new string by making the reference into a string and inserting that?
It's designed to default to the `html` renderer if no renderer is specified in `book.toml`. If you specify *any* renderer then `mdbook` will only use those, meaning if you want *both* EPUB and HTML your `book.toml` will need to look something like this: ```toml [book] title = "My Awesome Book" [output.epub] [output.html] ``` It's kinda like how in your `Cargo.toml` if you specify one `[[bin]]` then `cargo` will stop trying to guess what binary to create and *just* make what you told it.
It works, but watching variable values can get a bit involved (slices are shown as pointer and length, for example).
I don't know in which universe the C++ support of VS is good. OK, perhaps they have made further progress in VS 2017 - there wasn't even any refactoring until 2015er version. And even thus works only brittle and is limited to renaming. Intellisense isn't able to jump correctly to the corresponding implementation / header file quite often (``DoModal`` overwrites for MFC for example - really annoying if you work on a large legacy project). I know that C++ is much harder beast to tame than for example C#, but never remember that this commercial product has been around over 20 years now! And it costs money to use it commercially. Imho your product should then offer more than *free* alternatives. 
[removed]
I can confirm it is very much alive and actively being developed. 0.2 will come in early 2018 (for some definition of early!). To anyone who is interested, please come and have a look at the PR for our new router builder at https://github.com/gotham-rs/gotham/pull/70 and help shape the future of a key piece of Gotham.
Thanks very much for the kind words. We're very happy with how the API docs are working out and the result at https://docs.rs/gotham/0.1.2/gotham/ this will continue to be a focus. The book itself does need more work. We really want this to be a useful resource for folks and lets be honest, right now it isn't. We'll do better here for the 0.2 release.
Oh, right, I misread what the thing was doing in the first place.
You still can't wrap some types and send or share `Thex` between threads. `Rc` for example. Basically any type with interior mutability. Look at `Mutex`. It implements `Send` and `Sync` only if underlying type is `Send`.
When we eventually get number-constant generics, could we implement this more efficiently? Having to pay for 3 elements of size T for so little benefit strikes me as a bad idea. Runtime panicking is a little scary too, though I suppose rust's builtin types probably panic on underflow/overflow. 
I'm pretty excited to be seeing someone working on VS support again! I might wait until it is easier to set up though, we'll see.
It works in tests because you wrote tests that way. Tests never guarantee you have no bugs ) Consider next usage scenario: let x: Thex&lt;Rc&lt;Foo&gt;&gt; = ... let y: Rc&lt;Foo&gt; = x.shared().clone(); spawn(|| { let z: Rc&lt;Foo&gt; = x.shared.clone(); }); Whoops, y and z points to the same location and they are in different threads which is invalid for `Rc`. `Foo` may be `!Sync` as well.
Not trying to detract from the point you are trying to make, but this is only the case iff there is a subset of the language that cannot be used at compile-time. For example, if we were to allow C FFI calls at compile-time, your example would not hold.
From my personal experience, IntelliJ Rust plugin works much better than rls at the moment. rls still crashes a lot, and often refuses to provide completions when there are compile errors in the source code.
Why do you need to get the client socket?
I'm pretty sure every browser has that now.
I thought it could be useful for login purposes. For example : "client xxxx logged in using password from ip 192.168..."
&gt; though I suppose rust's builtin types probably panic on underflow/overflow. Fun fact: they do in debug mode, but not in release mode.
Can anyone (not just the person I replied to) elaborate on the benefits of a `const/constexpr` specific extension to the type system? It seems useful to designate functions which are trivial for the compiler to run and helps enforce a strict subset, but if you have an evaluator like miri that can handle the entire language semantics, why bother complicating the type system substantially?
thank you for the explanation, a new question: why clone is needed? in my understanding, the whole thing is running in one thread? is it not OK to share the handle reference ?
&gt; for so little benefit Reducing the state space of your program is a huge benefit. It's exactly why all strong static type systems (including Rust's) exist.
Eclipse + RustDT still works perfectly.
Can we do that in our own libraries (like this one?) If so, bonus!
I understand that, I just don't think it is worth 3 usize values (or whatever type you pick) being placed together in memory when you could have one and do the checks yourself.
https://users.rust-lang.org/t/compiling-to-the-web-with-rust-and-emscripten/7627
You do realize doing the checks also means you're storing the other two `T`s, just somewhere else, right?
Alright, I was planning on releasing a new version of Thrussh today, so I included this: instead of cloning the handler, I'll let the user provide a custom method taking a `SocketAddr` and a "server" type (in order to share things between sessions) as input. This will allow you to generate unique IDs yourself: one of the goals of Thrussh is to be as small as possible to make it easy to audit. Any feature that can be implemented elsewhere should be.
Good point. I think in this case you should keep two implementations of the function (or trait), one reference implementation callable at compile time and the runtime optimized version. This is also useful for testing purposes. I wouldn't be comfortable with being able to make C FFI calls (or unsafe code) at compile time. Basically you have no control over what they will do to your computer. If you restrict compile time functions to only safe, pure Rust functions the worst thing that can happen is that they stall the compilation for a long (or infinite) time.
Is there something like scala doobie FRM in rust instead of ORM? Just simple combinators to work with driver results and write plain queries.
Why do the binary operators require the operands to have the same range? It seems more useful to also apply the same operation to the range bounds.
I find it fascinating how a radical shift in thinking has occurred over the decades, as Moore's law progressed. Back then, they thought that simplifying the hardware was more important, even if it meant that software was more error-prone and programmers had to be extra careful not to shoot themselves in the foot. Today, we go to great lengths to make programmers' lives as easy as possible and the complexity of the hardware doesn't seem to matter. So many architectural quirks and complexities are being done in CPUs to help catch and prevent software errors and to support high-level languages better.
We can: https://doc.rust-lang.org/std/macro.debug_assert.html
Depending on the application, they might be hard coded, which gives you optimization opportunities that storing them in the struct stops 
I admit I'm by no means an expert on how things are layed out in memory, but in my minor excursions into Java bytecode, I seem to recall their being separate instructions for loading constants to accessing variables. I guessed that machine code has sinilar instructions for constants. If I have a function that for some reason required values between 3 and 7, I would hard code an "if &gt;7 {panic!()}, and the like. It is my (perhaps false) understanding that the constant 7 gets pushed into a register without being on the stack or heap. To be honest I really don't care if I am wrong about constants being stored in a variable when these comparisons are being made. Regardless, if we were to store the current implementation inside another struct, we pay the cost on a larger struct than of we had just stored a single T value and checked its values in any functions that require it. Honestly, the cost of this implentation might be worth it in some situations. I prefer to avoid unnecessary costs if I don't need them though.
Add .NET in all its variations to that list
And there is a wrapper type to always wrap and never panic but strangely no wrapper type to always panic but never wrap. I'd really like to see: - a numeric type that always wraps - a numeric type that always panics - a numeric type that always saturates - a numeric type where overflow is unspecified but not undefined which can be interpreted as panic in debug and overflow in release.
Isn't the point of Ada-Like range types that defining a range defines a _type_ itself. As in different range types are different types in and of itself. This seems to mean every range is the same type but keeps runtime data on the range with it. For instance say: define_wrapping_range!(Month, 1...12) Which would define struct `Month` and implement `From&lt;i32&gt;` and all the other goodies on it and ensure you can add two months together and stuff and that adding months til overflow wraps.
I'm sure /u/manishearth's blog post [How Rust Achieves Thread Safety](https://manishearth.github.io/blog/2015/05/30/how-rust-achieves-thread-safety/) will explain this better than i ever could. I'll give it a shot, though. I would say that the key guarantor of thread safety is the ownership rule: at any time, an object (struct, enum, whatever) can *either* have *one* owner/mutable borrower, which can mutate the object, *or* *one or more* shared borrowers, which can read it but not mutate it. For thread safety problems to occur, you need, at minimum, to have one thread writing to an object and another reading from it. Rust doesn't let you get into that situation in the first place. Now, enforcing that rule completely strictly would make programming really hard, so there are some escape hatches. The rest of the complexity in Rust's thread safety story is about making sure those escape hatches are watertight.
The first step of integer generics won't be enough. If all the features of the [ticki RFC trilogy](https://github.com/rust-lang/rfcs/issues/1930) are implemented, it might be possible. The current work is only focused on the first part.
Definitely, but still not a compromise of "so little benefit".
It's not built-in in Chrome. There are plugins, but they are all unreliable. I have three, and at least one will usually work.
Everything you said is correct. Sometimes constants are even stored in the instruction itself. However, the storage and performance cost isn't as great as you make it out to be unless you're doing very very very special things (embedded, HPC, etc...). Also, there's convenience and less proneness to errors in `3..7` as opposed to `if &lt;3 and &gt;7 then panic`. Lastly, with a feature like what this crate offers, you end up doing the checks once each time you change the value. In your if condition you do the checks every time you need to pass the variable to a function, and you have to sprinkle that everywhere in each function that expects some range of values as opposed to only needing to check the invariant every time you update the variable. Of course, you can be careful and do the check in some parent function, but that's not resilient to future changes in the code. Someone else might come along and mistakenly insert a call to a function that doesn't do the check *before* the top-level check you introduced.
Look mate, I don't really disagree with you, and as a junior dev, this may very well be a case of me caring about something that doesn't actually matter for the sort of stuff I'll be writing. All I really meant in my first comment was that storing three values seems rather poor, and unnecessary. I'll feel a little better once we can encode that info into the type (as a numeric constant generic), but in reality I probably was never going to actually use this anyway, and maybe this will be useful to others who are willing to accept the "unnecessary" cost.
I'm trying to use an unsized struct in rust. The compiler is happy with my type, but I can't figure out how to actually instantiate it. I want each node to have some data and an associated array of next pointers, with a size only known at runtime. Something like this: struct Node { data: u32, nexts: [i32], // Ideally [*mut Node]. Array size will be fixed at allocation time. } fn main() { let arr_size = 10; let n = Box::new(Node { data: 123, nexts: [/* arr_size zeroes? */], }); println!("{:?}", n.data); } But I can't figure out how to make it work short of using nightly and calling the allocator directly. Any tips? And before you suggest it, I don't want to use a `Vec` for my next pointers because I want to traverse my data structure using one pointer dereference per step; not two. I'm trying to reimplement [this C data structure](https://github.com/josephg/librope/blob/master/rope.h#L70-L81) without losing any performance. It allocates the structure [like this](https://github.com/josephg/librope/blob/master/rope.c#L176-L188).
To clarify, this is using the emscripten target, not the new pure wasm target. The new one doesn't have emscripten's emulation of libc and SDL so you can't run an SDL-based game using it currently.
Since I also struggle a bit with the current Tokio. Is there any single place to track the status of the Tokio reform? I read PRs and issues in the specific repositories but I didn't find a tracking issue for the reform as a whole.
Interesting, I wasn't aware you could do something like that in Diesel. I always wanted to either have direct access to a Python like Tuple, much like SQLAlchemy, or a `Record` like object, in vein of jOOQ.
/r/playrust
Yes! So a `Cow` is a really simple data structure, it's just an enum that can either be a reference or an owned value. For a string, creating an owned value from a reference involves copying the characters out of the slice onto the heap (which, obviously, takes some CPU time and uses up heap memory). The thing is, although the reason you need to use an owned value is that some of your strings don't live long enough and so need to be copied to the heap, you also have strings that _do_ live long enough (for example, string literals live for the entire length of the program, `'static`) and so the references to them will live as long as the map. Using a `Cow` means that you can take ownership of the ones that don't live long enough and take the penalty of having to copy, but only take a reference to the ones that do, which saves copying those strings.
Thanks for this clarification! I wasn't aware. But writing HTML5 games is already possibile with emscripten 
What I did was to build a tree on top of the stash crate, using linked list for the children of a node.. So each node holds an index of a sibling and a first child. I used a newtyped u16 for index, and implemented a null method on that type to signal end of list. The whole thing was really quite simple and nice I think. Who knows, maybe one day I can polish and publish it. But yeah, nothing really difficult about it, anybody could do it :)
However, how do you reference to parents? From my understanding that‚Äòs the root of the problems everybody has. 
Thx for your reply! So does that mean there shouldn‚Äòt be a problem with HashMap either? 
Interesting - thanks for sharing this. May I suggest a little improvement to the implementation? Add the type constraint `T: PartialOrd + Display` to the struct and not just the impl since that seems to be part of the contract of using the struct?
Thanks for the very quick response! Yes, I understand that you want to keep it small, this is good design.
Since the indexes are just integers there's no ownership from the rust type system involved. So just store index to parent in every node if you need it.
Ah, I see. So similar to what I/Sascha did :)
Surely a build.rs and/or compiler plugins can already run arbitrary code at compiletime? Why be afraid of the same in this specific instance? 
Huh. I never noticed that. (I've been using the clippy lints together with the `wrapping_`, `checked_`, and `saturating_` methods.)
I've got the point, but I never quite understood why they're called "security" bugs. They are potential bugs for sure, but why "security" bugs?
Ah, that's encouraging to hear. Was there a lot of setup required?
Ah, I see. I didn't try it because it was listed as discontinued. That puts me off trying it even now, since it will presumably break in the near future.
Those also always give you that semantics I guess but `x + y` is nicer than `x.wrapping_add(y)` but to do that you need to first make x and y a wrapping version of i32 which you can do but there are no saturating and panicing versions.
Ahh.. I see, thank you :)
Actually, there's almost no setup needed, just install rust from rustup as usual and install the clion plugin. Thats basically it... Maybe you will need to point the rustup instalation to clion if it's not in the default path. [I'm using linux, windows should work the same way, but i haven't tested.]
See also: ActiveX and Active Directory.
Can't say I'm a big fan of those features either. I understand why they exist, but being able to run arbitrary, unrestricted code at build/compile time is a potential security problem. At least the compiler plugins require an explicit attribute (if I'm not mistaken), but if any `const` expression could run arbitrary, side effecting Rust code it would be virtually impossible to track and control this.
That sounds more like what I would be looking for.
What this means is that you can create a std `HashMap`, mutate it, freeze the variable, and share references to that across threads. Rust will prevent you from sharing *mutable* references across threads, though, in order to do that you'd need to get some way of getting `mut` access (which with threads probably means a `Arc&lt;Mutex&lt;HashMap&gt;&gt;`). So the type system should enforce that this works (warning, written from memory and untested and I haven't actually ever tried to do this with a hashmap): let mut map = HashMap::new(); map.insert("key", "val"); let map = map; crossbeam::scope(|scope| { for i in 0..10 { scope::spawn(|| println!("map key {}: {}", i, &amp;map.get("key"))); } }); but that this fails to compile: let mut map = HashMap::new(); map.insert("key", "val"); // let map = map; // required to prove it's immutable crossbeam::scope(|scope| { for i in 0..10 { scope::spawn(|| println!("map key {}: {}", i, &amp;map.get("key"))); } }); You can do things with arcs/mutexes to make the second one work and allow you to insert things in threads.
Yeah Diesel views result sets (and insert sets!) as tuples. It's really much more of a query builder with convenience codegen to make it easy to convert query result tuples to your structs than it is an ORM. It never does magic query execution the way that something like hibernate does. Other than error messages, compile times, and docs (all of which are being worked on, with docs being dramatically improved on the way to 1.0) it's amazing.
It's a matter of taste. I don't use an IDE and using `wrapping_add` lets me see exactly what's going on at the site.
Mapping a C struct straight to rust, when it uses raw pointers and seems to be kind of a linked list, is probably not going to be very ergonomic. Furthermore, you might get even better performance by [not using a linked iist](http://cglab.ca/~abeinges/blah/too-many-lists/book/#an-obligatory-public-service-announcement). That said, custom DSTs are still realy awkward to construct. As far as I know, this is the only way: let n = unsafe { let vec = vec![123u32; ( mem::size_of::&lt;(u32, [*mut (); 0])&gt;() + mem::size_of::&lt;*mut Node&gt;()*arr_size) / 4]; mem::transmute::&lt;_, Box&lt;Node&gt;&gt;(vec.into_boxed_slice()) }; And this *still* may involve some unwarranted assumptions about memory layout.
Truth be told I can see few situations where a raw i32 or whatever is actually good. I would almost always use a newtype idiom and derive the standard arithmetic operations on it. The type itself will tell you whether it makes sense to wrap or to panic or saturate but I just like wrappers for that. Like the famous Ghandi nuke bug due to wrapping. I would almost certainly use a newtype `struct Aggression(Saturating&lt;u8&gt;)` for that. instead of a plain `u8` which wrapped like they did.
&gt; I think in this case you should keep two implementations of the function (or trait), one reference implementation callable at compile time and the runtime optimized version. The problem is that then generic code breaks, for example, you can't write generic code that can run at both compile-time or run-time. C++ is trying to work around this by allowing a context to detect whether it is being executed at compile-time so that you could call one implementation or the other depending on that and write generic wrappers around these.
Oh great, thanks! I imagine `#[repr(C)]` should make that pretty safe to use so long as alignment matches. &gt; Furthermore, you might get even better performance by not using a linked iist. I did some benchmarks in C to test that. I compared my implementation of skip lists to the performance of a simple array using a random-insert-and-delete loop. My skip list outperformed an array for anything longer than 500 characters, and was still performant well up to documents 5mb in length. I'm pretty pleased with it and want to replicate that feat in rust.
And so double-buffering was reinvented again :-)
Almost every compiler in practice ends up allowing this because compiler backends are not usually written with security in mind. I'm sure if you fuzz LLVM you can find exploitable crashes quickly.
True, but I've mainly been using Rust as a more reliable alternative to Python for my shell scripting so far. I'm still getting into the flow of things like that. (...and I was using Python over Bourne shell script for things like quoting without footguns, proper arrays, `os.walk`, `try`/`except`/`finally`, and the `subprocess` module's metacharacter-agnostic, list-based argument support.)
Yeah, but as far as I know, you can't really use the tuples directly, you have to go via `table` or a `struct` deriving said table.
"pass the world around" basically means having a parameter of type `World` that just gets passed around between functions, and whose only real storage is a local variable just outside your top event loop. I suppose if we can pass whole objects back and forth to JS you could maybe do this by constructing and returning a `World` value from `start()`, store that in a JS local, and then pass it back in via `key_down()` If you can't pass objects like that then I suppose my backup plan would be to try do something along the lines of: * the JS keypress just pushes the event details onto a queue * a worker thread created by `start()` loops taking values from this queue and doing the handling currently done in `key_down()` * the `World` value sits in a local variable just outside this loop so that it can be passed in to `key_down()` as above ...but I don't know what the threading capabilities are like here either :-)
&gt; If you follow this line of thought you will conclude that you need to forbid FFI calls from all Rust code. &gt; If you forbid them from constant expressions, they will still happen during compilation because the Rust compiler makes a lot of FFI calls. Also, once your binary finishes compiling, you are one shell command away of running c I don't buy this argument. It's a big difference between just trusting the compiler and trusting **every** library which you directly or indirectly depend upon.
I made this point on the RFC. But why don't we treat `const` like any other target? Adding a `const` evaluator is effectively adding a tier-1 compile target to the compiler. Rust reify `cfg!(windows)` in the type system, but removing a target's implementation (even transitively) is still breaking. Interestingly, if `const` is approached this way one could imagine users being able to whitelist certain ffi calls for `const` or even binaries supplying their own `const` evaluators that have looser guarantees about ffi, in the same way that Rust allows one to override the global allocator.
TDLR for clarity: There's no problem with using HashMap from multiple threads because Rust won't *let* you use a HashMap from multiple threads (unless you wrap it in stuff like a Mutex). 
That there might exist a potential security exploit in the LLVM backend is a pretty poor excuse for adding support for them in the Rust compiler frontend. A backend written in Rust could be potentially be very secure, especially if FFI calls are limited and easily audited.
Interesting. I started something like this using the type system, so it would incur no cost in release mode and panic in debug mode. It's really just a proof of concept at this point, but it's here if anyone's interested: https://github.com/paholg/ranged/blob/master/src/lib.rs
&gt; For example, say somebody wants to use malloc or memcpy at compile-time (e.g. because they just want to use a Vec, or copy a Copy type...). Those are FFI calls, so following your argument they should not be allowed because " you have no control over what they will do to your computer". Wouldn't these not be ffi calls and would instead be `cfg!(miri)` Rust implementations? Also `malloc` and `memcpy` are already special in that LLVM knows about them.
I'm not actually using rust, but faced with the same decision I picked just the simplest and most brain-dead regex solution; the parsing needed isn't all that complicated and I wanted to concentrate on the algorithmic portion of the question, so I stuck with what I'm familiar with.
This may also reflect the improvement and evolution of techniques for designing hardware and making it do more things. Just like we can do more in software using modern Python than old school C, I can see hardware designers also becoming productive and be able to construct chips of much higher complexity and vastly richer functionality than it was possible in the past.
It's pretty trivial to get panicking-always behavior with `x.checked_add(y).unwrap()`. Would that fulfill your use case?
How many new grey hairs did you acquire over the course of development?
`#[repr(C)]` may help. The dodgy part is using that `(u32, [*mut (); 0])` trick to get the padding right, and assuming the whole size is divisible by 4 (I could have used `u8` for the calculation but then the alignment might be off).
That's what I use now if I want it but I want a nice wrapper type like the `Wrapping&lt;T&gt;` type does. Having a wrapper type is not only ergonomically but also improves type-safety. If you know "this should never ever overflow and if it does this is a bug" it's just nice to have this assurance at the type level.
There's tql, but it's fairly new. Apart from that I'm not aware of any. What in Diesel is harshing your groove? Might be able to help.
You might want to mention why you're looking for an alternative. Is there something that Diesel doesn't do, or does differently than you'd want? [TQL](http://antoyo.ml/tql-easy-orm) was recently posted and looks interesting, though less mature than Diesel.
Yeah you do need the output of the `table!` macro to be able to do things like `insert_into(my_table).values((name.eq("q"), likes_diesel.ea(true))`. But the derives are just conveniences for converting to/from those tuples, and in some cases (`belonging_to` is the only thing I can think of) generating part of the SQL fragment for you.
nothing in particular
Does anyone know why `NaN != NaN` is part of the standard? Or why there's positive and negative 0?
I agree. Maybe that would be a great RFC? :)
I am responding to you and /u/phazer99 here because the next thought is exactly the same: You both now argue that some FFI calls at compile-time are OK "in some sense", either in the compiler, or because they are special / white-listed. That is, you need to be able to do FFI calls at compile-time anyways. /u/phazer99 also talks about trust (e.g. trusting the compiler). This makes IMO the point even more moot. Whats the difference between trusting a run-time FFI call from trusting a compile-time FFI call? Or why is trusting a Rust library that does an FFI call at run-time less dangerous than trusting a Rust library that does an FFI call at compile-time?
SIMD and transmutes are easy to implement in miri (if they aren't already). C FFI and global state are *impossible*, for both cross-compilation reasons *and* typesystem soundness (breaking determinism at one point easily destroys type safety of anything it touches) reasons.
I think the reason positive and negative 0 exist is because of expressions such as `1 / eps` where `eps` is extremely small (think `|eps| &lt;= 10^-300`). When you evaluate this expression, you should get an extremely large number. However, what if `eps` is so small that it is closer to 0 than any other representable floating point number? Well, in that case, you should expect to get an infinity, correct? But there's a catch: For `f(x) = 1/x` it's true that: lim {x -&gt; 0^- } f(x) = -‚àû and lim {x -&gt; 0^+ } f(x) = +‚àû So depending on the sign of `eps`, we should get either a positive or a negative infinity. But if we can't store the relevant sign, we can't get a proper result. So this is probably why the IEEE 754 committee added both kinds of 0. As for the `NaN != NaN`: It's probably because a `NaN` doesn't store its origin (e.g. it might have come from a call to `sqrt` with a negative argument or because you wanted to divide two infinite values (regardless of the sign). So it's meaningless to compare these two `NaN` values, because the former represents a complex number, while the latter probably represents a value that is really close to 0, but that can't be represented. Hope that makes sense.
Negative zero is due to having a signed bit in the standard. Integers avoid this by negating the first bits value, making negative zero the smallest possible number and simplifying the math (since you don't have to normalize the sign bit to do addition). I believe NaN != NaN is to ensure that two differently created NaN don't accidentally compare equal. i.e. 1/0 = 2/0 kind of thing.
&gt; ... iff there is a subset of the language that cannot be used at compile-time. What if your code is cross compiling? For example I have some code which which runs on the game boy advanced. I compile the code on x86, but run it as ARM. It would make no sense to expose access to which buttons are down for example as a `const` function. Or even any of my functions which are written in ARM assembly. So we can't really get around the fact that the compile environment is (or could be) different from the run time environment. So there definitely is a subset of the the language/libraries which cannot be used at compile-time.
Isn't that already the case with send and sync? I think a Const marker is a really good idea. The requirement could be that if all its inputs are marked Const, the output will also be marked Const. Ideally I'd like to see it integrate with some kind of Safe marker that would get applied to code that doesn't have unsafe blocks, but I don't know if this would apply to enough of the standard library for it to make sense (since many data structures need heap allocation) As far as ffi is concerned, it should become less of a problem with time as more libraries are ported to pure Rust. The things you can't port to rust, namely syscalls, are the sort of thing you don't want running in a compiler anyway. As far as public interfaces are concerned, I would consider something that works with pub that would also work for send, sync, other markers. The nice thing about markers is that they can be handled consistently and don't continue to enlarge the number of different types of language features. It would also transparently enable compile-time optimizations even if you weren't thinking about it and without requiring additional work (there would probably have to be some care applied to this in the event that a call would expand to a huge value). This probably isn't going to happen at this point, but it sounds really cool to me.
Good point.
This seems much nicer than my attempt :P
Seriously, that said, I think I'm going to allow varying sized arrays to be passed to Js side, so more like you can patch small portions of screen or the whole screen.
&gt; I compile the code on x86, but run it as ARM. This could work by having miri run as though it was ARM. &gt; It would make no sense to expose access to which buttons are down for example as a const function. yes, agreed. Though some languages do do this; Jai for example. I don't think it's a good idea.
Like /u/icefoxen asks, what's your use case? It's hard to give a good recommendation without knowing what you're looking for -- and this community definitely wants to help you figure out something you'll like, if possible. :)
I see heap allocation, SIMD etc. basically as implementation details that doesn't affect the externally visible results of a program. They produce side effects which are locally contained in the running process. However, for example IO operations (file, network, IPC etc.) are in general not. In terms of security this is a very useful distinction, and I don't think it's very hard one to make. You can start with a small white list which expands over time to include more functionality. I see building/compilation and program execution as two separate activities which might be done in environments with totally different security considerations. Building/compiling a program/library should really just be a function from a given set of input files to a given set of output files. It shouldn't have any other effects. Allowing other, arbitrary effects means you basically can't trust the build process from a security point of view. However, sometimes it might be practical to make this trade, but then it should be explicitly enabled in the build specification, not by default. 
I always thought that the signed zero was to increase the chances that, if you were working with small values, you would have less chance of an unrepresentably small negative value comparing equal to an unrepresentably small positive value.
Diesel is designed to be terse in terms of syntax, and it is good for use in applications that uses common database construct, such as 1 primary key. In my case, I am building a really complex application which diesel lacks features such as composite primary key (a primary key which involves more than 1 column), composite foreign key( a foreign key which involves more than 1 column). Dynamic database connection, where you be able to connect to a completely different database than the one you developed against with, but that is also outside the scope of an ORM. https://github.com/ivanceras/rustorm. The development of rustorm is very slow, since I focus on building the app rather than the ORM.
Development for this extension was surprisingly easy. The LSP API is very well documented. I do dread adding extra functionality though. Especially since the extensibility docs for open folder are all but non-existent.
Just finished up another semester at university, so now I have finally gotten a chance to get back to working on some of the projects I didn't have time for. Right now, I'm trying to finish up my graphing / charting library [Grust](https://github.com/saresend/Grust), and add documentation so that people are actually willing to look at it and give me feedback, since I'm still new to rust.
Modern effect systems FTW!
RawTable is just a fancy Vec. Vec is Sync and Send. So RawTable is too. So HashMap (which is also just a _really_ fancy Vec, implementation-wise) is too. Sync and Send do not by themselves enforce synchronization. Send says that it's okay to transfer ownership to another thread. This is true for most types (this is _not_ true for `&amp;RefCell&lt;T&gt;`), because transferring ownership usually transfers everything. Sync says that _references_ to this type are thread safe. Interior mutable types are where stuff breaks down, because they let you mutate behind "immutable" (shared) references. So they're not Sync. But for things like HashMap the reason they're threadsafe is that they are ok to access behind an immutable reference (they don't mutate in that case), and borrow checking ensures you never mutate twice anyway.
&gt; Building/compiling a program/library should really just be a function from a given set of input files to a given set of output files. Independently of how you think this should be (and many agree that it should be this way, although I disagree), my main point is that it already isn't this way. You can already write a procedural macro in Rust that opens a network connection, queries a data-base via this connection, and generates code depending on this. You can also do the same thing with a build.rs and an `include!` macro. So I think that: &gt; start with a small white list which expands over time to include more functionality. is extra work that doesn't add any value. Those who want to / need to do this already will, and there is nothing that you or anyone can do to change that without breaking backwards compatibility. So we might just accept that and try to make the language simpler instead of more complicated by just saying that "everything is allowed in a `const fn`" and trying to get rid of the `const fn`/non-`const fn` distinction if we can.
You are welcome to take it and turn it into something useful. I'm unlikely to have time for it.
Is this extension open-source? I don‚Äôt see any links to a repo here or on the VS marketplace page. Others may want to help contribute üôÇ
Maybe the IO code (`const` or compiler plugin) should have IO calls that can cause non-reproducable binaries should be an opt-in feature flag. This would still give a lot of a lot of power to the `const` evaluator/plugins but make the "dangerous" behavior opt-in, like we do today with `unsafe`.
You already know this because you are cross-compiling code for the game boy advance and running it on that system, but I cross-compile a lot of code too and if I want my code to be portable and cross-compile properly I already need to be extra careful. Or in other words, it is already possible (and quite easy) to write non-portable code in stable Rust today, and many crates in crates.io cannot be easily cross-compiled to many targets because of this. Allowing all code to be executed inside `const fn` doesn't obviously solve this problem, but it doesn't introduce any new problems either. 
Do you have a link to the impossibility discussion / proof / data ? IMO miri should be able to just dynamically perform C FFI calls, as in opaquely pass arguments, opaquely receive return value. This will probably make detecting UB in Rust programs that do this through miri harder, but impossible? I don't know.
Are you sure you need a deque? If the only use for these datastructues is to write once and read once, then maybe you can just use normal vectors? Build the vector by iterating, then consume them into iterators, and then you can use peek to merge. 
What features do you think are missing that prevent it from being useful?
I'm not sure. It's not something I've ever had a need for, and I don't know how people use it in Ada.
good to see so many new contributors! 
I like this idea.
I didn't knew about rustup with rustfmt, so I can't say. I think it shouldn't change anything but I prefer using cargo for things that is not rust toolchain.
do you have many recommendations on the alternatives of diesel? tens or hundreds?
The reason is that anything passed into the `Core` will live as long as the core does, and its valid for the core to be returned from the function constructing it. In your simple example, perhaps, the `Core` does not outlive `h`, but if you returned your core, `h` would be dropped. Making another handle, `h2`, which is fully owned by the closure allows Rust to guarantee that your closure will be valid even after the outer function is dropped.
I'll be happy already with the first part ;)
Fixed. Thanks!
There‚Äôs a Tokio RFC for it; I‚Äôm on mobile or I‚Äôd link you.
That's very odd. The marketplace should have a link to the repo in the side bar under project details. Is that not there for you?
I thought typically 0 = -0 but it is unavoidable with a sign bit.
Because `const` is not a target in itself. Imagine the case of `size_of`: it can easily be `const`, however its result *depends* on the target. This transitively changes the output of any `const` function using `size_of`, or the layout of types once non-type generic parameters kick in, etc...
It's a matter of *guarantees*, aka SemVer. Imagine that I have a matrix-multiplication function implemented with the naive algorithm in Rust: MIRI can run it, should it be allowed in a compile-time context? Well, tomorrow I change the underlying implementation because it was really inefficient and instead link with LAPACK and delegates the work. The API didn't change, and my users get a real performance boost, certainly they'll be happy! Except *that guy*, who complains that my non-API changing interface broke his library. How is that possible!? Oh... he was using the function at compile-time...
Do you have a concrete proposal for how to detect this across crates and generic instantiations? If you "just" use a C FFI call to initialize a static and later read that static from a different crate, how will you know how not to allow it to end up in a type? And no, other than problems with the tooling *around* the compiler, it should be impossible to make Rust code not cross-compile *assuming* it can already compile on the target. That is, I'm not talking about cross-platform compatibility but host != target vs host == target (see also [the main discussion](https://github.com/rust-lang/rfcs/pull/2237#issuecomment-351473363)).
Have you even used Diesel?
I see it now, thank you for pointing it out. The page layout on mobile for the marketplace has those links to the ‚Äúright of the fold‚Äù so they‚Äôre not visible without scrolling right or zooming out.
Actually the second example will also work. It doesn't really matter if `map` variable is mutable or not. If the closure uses only *shared* operations on `map` (`get` takes `&amp;self`), the closure will just capture `&amp;HashMap`. If the closure was using eg. `map.insert` then you're right, it woudn't compile). PS. You've almost nailed writing the example from memory! [Here's a playground](https://play.rust-lang.org/?gist=8a173774e43de80769d9e295ee8392a8&amp;version=stable). The only fixes needed were changing `scope::spawn` to `scope.spawn` and removing the usage of `i` in the closure's body (unfortunately, to make it actually capture the `i`, you'd need to make a `move` closure and capture the `map` manually, [like so](https://play.rust-lang.org/?gist=32cd1ac45d96735b7cfd922587b767aa&amp;version=stable)).
[exercism.io](exercism.io) is pretty good, although not *exactly* what you asked for.
Here's what I was missing as a beginner. At first, you need to read about the traits `Sync` and `Send` and know that they're automatically implemented and you shouldn't have to mess with them. If you did mess with them, it would be unsafe code. The next thing you need to realize is that in most languages, how thread safe a method is, is determined by manual checking and documentation. In rust, how thread safe a method is, is determined by it's type signature. Look at the `is_empty` method on `HashMap`: `pub fn is_empty(&amp;self) -&gt; bool` The fact that it takes in a `&amp;self` reference shows that this is a method that can be called with a "shared" borrow of the Hashmap, which means that there might be many other borrowed references outstanding at the same time, and this method will work fine. If your Hashmap is `Sync`, which it almost certainly will be, this means that the Hashmap can be shared among threads, and you can call the `is_empty` method on several threads at the same time, with no locking whatsoever! Now look at another method, like: `pub fn clear(&amp;mut self)` The fact that it takes in a `&amp;mut self` reference shows that this is a method that must be called while having exclusive access to the HashMap. If you've shared this HashMap among different threads, each thread will only have a "shared, non-mutable" `&amp;` reference. How would a thread ever call this function? As you might have guessed, you need synchronization, such as a `Mutex` or `RwLock`. `RwLock` will end up wrapping your type, such as `RwLock&lt;HashMap&lt;u64,u64&gt;&gt;`. The important thing to realize is that if you only have a shared reference to the `RwLock`, `RwLock` can "upgrade" this reference to an exclusive `&amp;mut` reference to the data inside of the lock, if you acquire a write lock. This is how you can go from a `RwLock` that's being shared among threads, to being able to call the `clear` method on the `Hashmap` inside of it. So the end result is: you don't have to worry about how thread safe each individual data structure is. The signatures on each method will show you. If you need a synchronized version of the data structure, just wrap it.
I implemented a somewhat similar [clamping type](https://github.com/olson-sean-k/bismuth/blob/21293c40462c4f8b1b4416876c69925d13ec07a8/src/clamp.rs) a while back that uses a trait with associated functions to store the bounds (definitely not polished). A `Clamped` only contains a single `T`. I wonder if something like that could be used here instead; since this already uses macros, perhaps it could implement such a trait with associated constants or some such.
I would personally *only* implement `Index` and `IndexMut`, and implement both of them for both `usize` and `(usize, usize)`, but that‚Äôs just me; I don‚Äôt know what the convention ‚Äúshould be.‚Äù
If you feel alright writing Rust code that people (including me) will end up using as example code, maybe improve or create some examples on Rosetta Code? (https://rosettacode.org/wiki/Category:Rust).
`HashMap` implements `Sync` because methods that mutate anything take `&amp;mut self`, which means you have exclusive access (perhaps through external synchronization like `Mutex`). Having `Sync` only means that `&amp;self` is safe to share across threads.
&gt; With that, it would be possible anything short of I/O; or even allow a modicum of I/O, such as reading files from a dedicated "in-resources" folder and writing files to a dedicated "out-resources" folder. I've joked in the past about providing an "IO monad" style for compile-time side-effects and *it would be sound*, in its own weird way: non-deterministic values would end up wrapped in `IO` and as such would be accessible at runtime, but not from the typesystem. And you can't have `unsafePerformIO`.
And so curses was reinvented again :-)
Ah, that does make sense. Variables themselves don't have a type, it's actually doing things with them that can violate type constraints. Thanks!
&gt; How would you, though? &gt; That is, when cross-compiling, how do you call the C library for the target when running on the current host? We compile x86, x86_64, arm, arm64, mips64, powerpc64, sparc64, ... all from a x86_64 machine (cross-compiling for all non-x86 targets) and run all our tests which do involve C FFI calls to libraries on the target from a x86_64 system using qemu-system. 
&gt; Do you have a concrete proposal for how to detect this across crates and generic instantiations? Sure, add a `#[readnone]` attribute. &gt; If you "just" use a C FFI call to initialize a static and later read that static from a different crate, how will you know how not to allow it to end up in a type? metadata &gt; And no, other than problems with the tooling around the compiler, it should be impossible to make Rust code not cross-compile assuming it can already compile on the target. I did not say compiling, I say "working". Currently, if your code cross-compiles correctly, that doesn't imply that it works (otherwise we wouldn't need tier 2 platforms). If you allow all of Rust at compile-time, then code that exploits that, might not compile, but that code wouldn't have run anyways. 
The new wasm32-unknown-unknown doesn't. The old wasm32-unknown-emscripten does, here is an example: http://og.tn/projects/rust-wasm-experiment-1/ I think it is probably better to invest in wasm32-unknown-unknown, &amp; since lightweight is an important factor for web builds, we need to create bindings to webgl directly &amp; other web apis.
&gt; Sure, add a `#[readnone]` attribute. How is that relevant? I'm not referring to something like type-checking, but dynamically (during CTFE) detecting the situation even if unsafe code was used to reach it. &gt; metadata I'll have to guess here... do you mean something like taint-tracking? &gt; I did not say compiling, I say "working". Currently, if your code cross-compiles correctly, that doesn't imply that it works (otherwise we wouldn't need tier 2 platforms). My point was that compilation, at least in terms of types and other semantic analyses, depends on the target *not the host*, i.e. cross-compilation and compilation on the target should behave the same.
`as_vec`, `as_vec_mut` and `into` are only applicable if your container represents _exactly one vec_. Since it doesn't, I would not use those. `get` / `get_mut` are for mappings, things which have generally a single input and output. In your case, the input seems to be an integer index, and the output is a float vector? These generally return `Option&lt;&amp;T&gt;` / `Option&lt;&amp;mut T&gt;`, while `Index` and `IndexMut` are implemented to panic when out of bounds. If you do want to provide operations for both float vectors, and indexing into the float vector, I would recommend not using `get` or `get_mut` (these would be ambiguous). However, I'm not sure why you want to support both of these: if you're getting an item from a vector in your ManyVectors, why not just first get the vector, then get the item? This would greatly simplify your API I think. If this were my library, I would implement: fn get(i: usize) -&gt; Option&lt;&amp;[f32]&gt; fn get_mut(i: usize) -&gt; Option&lt;&amp;mut [f32]&gt; fn set&lt;T: IntoIterator&lt;Item=f32&gt;&gt;(i: usize, vec: T) impl Index&lt;(usize, usize)&gt; { } - `get(i: usize, j: usize) -&gt; &amp;[f32]` - `
&gt; If you need to cross-compile to very different targets there are already some things that you can't do in Rust. Like what? Do you mean in terms of the pre-existing toolchain lagging behind Rust itself? Because other than that, Rust should be as good of a cross-compiler as they come.
A couple observations: 1. `set_single(i, j, x)` is the same as `get_vector_mut(i)[j] = x` 2. Likewise, `get_single(i, j)` is the same as `get_vector(i)[j]` 3. The argument to `set_vector` could be any iterator, not just a slice Based on this, I would write methods named `get` and `get_mut` that return slices, and a method named `insert` that accepts any argument that implements `AsRef&lt;[f32]&gt;`. I might also implement `Index&lt;usize&gt;` and `IndexMut&lt;usize&gt;` as a syntactic convenience. If you‚Äôre able to return a slice, you don‚Äôt really need more than that. 
Thanks! The reason for having both scalar and vector setters is I use the same structure very differently at two points in time: 1) When parsing a file, the values are stored sort of (but not quite) "transposed". I therefore set them one-by-one as I read them in the wrong order. 2) When processing the data real time, I'm only interested in the final vectors, which I want SIMD-ready.
You have to adapt this for whatever you're using: rustup toolchain install nightly-2017-12-01 rustup default nightly-2017-12-01 rustup component add rls-preview I don't have VSCode installed here, so I can't help, but bassicly - use nightly from 2017-12-01.
Ah, interesting! I'm not entirely sure what would be best in that case. Have you considered making two structs which have the same internal layout, and can be freely turned into eachother via `From` / `Into`? One could be a 'sparse' one which provides operations for setting individual values like you do when parsing the file, and the other could be pure vector-based access.
That might actually make sense since I have parsing functionality anyway. I could create a `MatrixParser`, and then turn this `Into` a `ManyVectors` .... Thanks!
Diesel does support composite PKs just fine. I think up to three keys are supported.
Diesel does support composite PKs just fine! I think up to three columns are supported.
&gt; Like what? Like using `u32` instead of `usize` for storing pointer widths.
&gt; Interestingly, rust is actually smart enough to realize if that using a map just once in a thread is fine, this compiles just fine Nice! Although I do understand how this works, it does indeed feel like Rust is magically smart. A little nit: You don't actually need `Arc&lt;Mutex&gt;` and `arc.clone()` when using `scope`. Just a `Mutex` should be enough! (Although it may surprisingly end up being slower due to false sharing! But that's a topic on its own, so I'll just mention the existence of [`crossbeam::CachePadded`](https://docs.rs/crossbeam/0.3.0/crossbeam/struct.CachePadded.html)).
&gt; How is that relevant? I'm not referring to something like type-checking, but dynamically (during CTFE) detecting the situation even if unsafe code was used to reach it. I am saying that if a C FFI function has not been manually marked with, e.g., the `#[readnone]` attribute, then you know that it can, e.g., have certain side-effects. &gt; I'll have to guess here... do you mean something like taint-tracking? I am saying adding a meta-data field to the variable in the ABI stating that its value was produced (or not produced) from a C FFI function call. &gt; My point was that compilation, at least in terms of types and other semantic analyses, depends on the target not the host, i.e. cross-compilation and compilation on the target should behave the same. Sure, doing the same on the target in a `const fn` would also fail.
Cool! I may have to try it out yet again - having GHC on redox would be phenomenal and definitely a good way to push my skillset. 
None of that has anything to do with the distinction between cross-compilation and compiling on that target. You're talking about *cross-platform compatibility*, not cross-compilation.
Excel function names are localised too, quite annoying when you've been using Excel and Google Sheets for years in English and the university IT certification exam expects you to do everything in French... Localisation isn't even consistent. "LEN" becoming "NBCAR" among others.
One thing that you cannot do on some CPUs of a target is use some SIMD instructions. That is, executing those instructions at run-time fails, but you can generate them while compiling on the target and while cross-compiling to the target. To get consistent behavior while executing it at compile-time on both the host and the target you can: - emulate the behavior of the intrinsic at compile-time, e.g., in miri, so that compilation on the target and cross-compilation from the host to the target succeeds, but if the const fn is executed at run-time on the target, you get a segfault. - emulate the target on the host, that is, miri does not emulate the intrinsic, but miri cross-compiles the code in the host to the target, and runs it in a virtual machine that emulates the target (e.g. qemu), this will make compilation fail on both the target and the host. 
no need for an insult...
Well there are a few problems where dependencies of build.rs affect dependancies of my cross compiled code (features!!) I‚Äôm mostly saying that it makes sense to consider const part of the API. I am curious what happens when you have const fns which act on structs which are different size on host vs target.
Very cool. I was planning on writing a chip8 interpreter a while back, but I never got around to it.
[Hackattic](https://hackattic.com/) has looked very interesting -- maybe those more practical problems are up your alley? :)
The work can kind of be tracked here: https://github.com/tokio-rs/tokio/milestone/1
It's because you need some sort of reference inside the closure, but `handle.spawn` requires the closure to be `'static`, since it cannot reason about how long a task will live inside versus how long some references the closure needs may live.
Interesting, thanks!
Can you explain the difference between what I asked for, and what exercism.io provides?
Not entirely, because it's not whether the problem is practical or abstract that's the issue: it's that if a problem, in its own right, has language-independent implementation details that need to be straightened out, then one needs to do so before attempting to implement it in any language. This is fine. This is great. But if one is learning a new language, it might distract from figuring out how to best implement XYZ idiomatically in a particular language (e.g. Rust)
I'm pretty sure the go run time in now in go. It's fully self hosted.
Does it still take an unnaturally large amount of RAM to even initialize the kernel? I remember it was like 1GB, anything less and the VM couldn't even initialize... Even though surely Redox uses almost no RAM for anything.
There should be a "wasm-ready" flag for crates - or at least a way to filter by architecture / OS. Either that or a seperate host - like crates.io, but specifically for wasm. So that wasm-ready crates get "promoted" to be both hosted on wasmcrates.io and crates.io at the same time. Just an idea.
&gt;. . . ¬ø seperate ? . . . I THINK YOU MEANT **separate** ^^I ^^AM ^^A ^^BOT^^^beep^boop!
I modified examples, all of them runs in multiple threads now
How do you feel about tokio revamp? I'm wary of settling with tokio as the foundation for my thing...
But those just cosmetic and ergonomic changes. Concept will stay the same. Migration should be painless.
crates.io already has two such mechanisms: keywords and categories. Not sure whether there is a wasm category yet but you can do a wasm keyword.
Curious what you all think of this library I made. I could see making modules for canvas, webgl, etc. for this. Basically I'm trying to make web assembly development as easy as possible for Rust people who never want to touch javascript. I think emscripten is a noble cause, but its monolithic and this is more in alignment with the future-forward wasm32-unknown-unknown and trying to create minimalistic websites.
Haha ... shhh.. let me have my fantasy i'm not reinventing the wheel ;P
`Sync` was named `Share` at one point, I forget the motivation for renaming it.
tuna :))))))))))))))))))))
tuna :))))))))))))))))))))
I don't understand why this was downvoted, it's perfectly fine to be interested in other potential libraries.
I think `cargo target` is a mistype. The command you need is: rustup target add wasm32-unknown-emscripten 
thanks - I'd definitely recommend giving it a go. It was a lot of fun, and a good way to start learning a new language.
thank you, I am not familiar with tokio/futures, but I am familiar with libuv, the concept of libuv is very simple, loop and io handle, the Core of tokio can be thought as loop of libuv?
The best alternative now might be abusing the `let ref var = ...` pattern (which I learned from [rust-autograd](https://github.com/raskr/rust-autograd) ). For example let ref a = 1; let ref b = 2; let ref c = a + b;
You need to use rustup to add the target, not cargo. If you still don't have success with wasm32-unknown-unknown (it's very new), there's a tool called wargo that makes using wasm32-unknown-emscripten. wargo: https://github.com/lord/wargo guide for wasm32-unknown-unknown: https://www.hellorust.com/setup/wasm-target/
I think you all would be especially interested in my tic tac toe board demo: Play: https://wasmblock.github.io/WasmBlock/tictactoe/index.html Source: https://github.com/WasmBlock/WasmBlock/blob/master/tictactoe/src/lib.rs
I like it, and if we combine this and a few other examples, such as the webGL example that was put on rust_gamedev today, things are looking very up for rust. * https://www.reddit.com/r/rust_gamedev/comments/7jpb3w/simple_wasm_glutinwebgl2_triangle_sample/ **Question:** `fn timing_request_animation_frame(fnName: *const c_char);` What's this and how does it work? If the goal is to make things for people who don't want to touch javascript, you need to document enough that a person doesn't need to have learned javascript.
Something like this should exist. There should also be an effort to somewhat standardize common operations from JS to WASM, like allocating and deallocating memory. Put together, implementations for the WASM side code could be done in multiple languages, all compatible with the different JS side Web API exposing modules. With small enough footprint, the overhead (both in application size and developer headache) of creating a new WASM application could be reduced to a tolerable level. Small modules like you have done, not huge cover-all solutions like emscripten's.
This is very cool, and hopefully the start of something substantial. It does occur to me that at the very least `export_string` could be brought in with a Rust crate, and maybe even `dealloc_str`. I think 'fear of Javascript' is more nuanced than 'I cannot write that shit' - it's more like 'Oh no! I need Gulp/webpack/npm/...'. It would be good if Javascript could be the handmaiden of Rust in these applications, and not take center stage.
Totally :) this stuff is literally hot off the presses tonight. that function tells the browser to call a publically exposed web assembly function of your wasm model on the next render frame. It's used in games mostly so that you never try to draw faster than the browser game (60fps ideally). It's like the heartbeat of the render loop. #[no_mangle] pub fn start() -&gt; () { run(); } #[no_mangle] pub fn run() -&gt; () { unsafe { // draw something here! // call me again next render frame timing_request_animation_frame(export_string("run")); } } 
Totally agree.
Yah, totally agree with you :) I tried to create these examples with as little magic as possible, but perhaps a crate could make it even easier.
TIL!
Yes, you made the minimal requirements for a little wasm program explicit, which is very Rust-like. It's all very much like embedding Rust in a big C program!
ah ha! a very important function indeed then. vsync/timing + webGL + keyboard/mouse events = games. This is very good for rust. As we all know, games is the best way to get fresh talent working in your programming language. Let's not forget that many browser windows won't have keyboard/mouse at all, because they're running on a phone. We want a good story for how to interact there if we can come up with one.
Very interesting, love it! I think the wasm32-unknown-unknown target has a bright future ahead :). I have thought about the general issue of exposing web APIs to Rust myself and the idea I had was similar. I haven't done an implementation of my idea though (yet), so its all just a concept for now. I'd love if you could just simply push a crate to crates.io and be able to use its rust API, the framework (or hopefully eventually cargo) figuring out the rest. So on the wasm target, every crate would be able to provide a js file either via build.rs or by hardcoding it and then the framework would take all the js files and combine them in a fashion so that it is one single file per wasm library. The final user would then have multiple different ways to do the "combine" operation, e.g. using one of the tools from the js world to do it, or also just using concatenation (for anyone who doesn't want to buy into the npm/bower ecosystem and worry about multiple tools). The hard part is the implementation. One idea that has floated around my mind was to publish a tool and then tell people to use it as a "linker" in .cargo/config for the wasm32-unknown-unknown target. The tool would then wrap the real linker (binaryen I think? or maybe there isn't even a linker at all? you see, I still need to do some research :p) and do its operations afterwards. It could also do other steps like converting the wasm to asm.js (or to base64 inside a js file because that is the only way right now to use wasm over the file:// protocol on chrome) or even copying all the relevant files for the project (including html) into a directory inside the target directory to directly allow you to view it via your browser without having to copy .wasm or .js files around first (or using one of the js written tools for this). I saw that the rocket game had a post build script to do precisely this copying step and this feels like a hack to me... you need to invoke it manually, after cargo. I guess your project is a proof of concept for now and probably you had the same ideas (they are pretty obvious) and want to do them eventually. In any case, wishing you luck!
There are still *some* aspects of "you need to figure out how to solve the problem first" present in some of the exercises, there, but it's much less so, and much less prominent, than anything else like it that I've come across.
Oh dear - I hit the Demo link and got the following compiaints (Firefox 57): 'TypeError: script is null - wasmblock.js:42' and 'TypeError: WasmBlock is not a function wasmblock-console.js:1'
I'd be very careful here. I think the fact you can customize any C++ type as you like (defining custom move operators, how it acts in this or that situation) is one of the worst parts of C++ ‚Äí you never know what nasty thing an unknown type will do to you. There's nothing you can take for granted. And I don't see people complaining about `$` in front of each variable in perl and PHP. So, is it a problem to have `&amp;` from time to time?
It seems to be using custom html elements which are not supported in Firefox yet. I see some code to invoke a polyfill but maybe its not working? Even though I hate saying these words, try opening it in Chrome :/.
Thanks! I just committed some fixes thanks to your comment. https://wasmblock.github.io/WasmBlock/tictactoe/index.html Tested in Firefox :) may have to hit refresh to uncache. 
Just let you know, Zbox can support Windows now.
Just fixed this in firefox! https://wasmblock.github.io/WasmBlock/tictactoe/index.html and try refresh 
I complain about the `$` in front of each variable in PHP. I just haven't done so publicly (until this comment).
Note that you will be leaking memory on each iteration if you do this (`export_string`)
Yay, she works! Reminds me of a former colleague who was a relentless Chrome fan and left me a Polymer project to maintain (probably some old karmic debt getting repaid). This caused us to have to recommend Chrome for everything, but FF caught up nicely. 
Typing $ when coding php gives me arthritis,
It's not really cleaner than let a = &amp;1; let b = &amp;2; let c = &amp;(a + b); In fact, [clippy lints against this](https://rust-lang-nursery.github.io/rust-clippy/v0.0.175/index.html#toplevel_ref_arg).
Maybe they added it already, but why up to 3 columns only though? I know that it would be silly for a dev to use 3 column composite pk, but I think the ORM shouldn't force that.
Good to know. I got busy with other stuff and totally forgot about this. :-(
Thanks for your explanation. Indeed, I never dealt with threads in Rust and your post clarifies some missing parts. 
Thanks for the insights. Seems I have to correct something in my crate^^
Crate to hear!
Great work here! The TQL crate looks very interesting. I am hoping for sqlite and mysql implementation. Thank you very much!
&gt; I'd love if you could just simply push a crate to crates.io and be able to use its rust API, the framework (or hopefully eventually cargo) figuring out the rest. So on the wasm target, every crate would be able to provide a js file either via build.rs or by hardcoding it and then the framework would take all the js files and combine them in a fashion so that it is one single file per wasm library. FYI, *something* like this is already coming (as in - I'm actively working on it), probably this week, as part of my [stdweb](https://github.com/koute/stdweb) and [cargo-web](https://github.com/koute/cargo-web) crates. (: You'll be able to use the `js!` macro from `stdweb` to put snippets of JS in your crate, and it will also work for any crates you get from crates.io. Everything then will get compiled into a single `.wasm` and a single `.js` file. For example, you should be able to do something like this: ```rust fn exported_function(string: &amp;str) { ... } fn main() { stdweb::initialize(); js! { Module.public.exported_function = @{exported_function}; }; } ``` And then you can drop the generated `.wasm` and `.js` files in your JS project and just use it, e.g.: ``` &lt;script src="js/your_module.js"&gt;&lt;/script&gt; &lt;script&gt; Rust.your_module.exported_function("Hello!"); &lt;/script&gt; ```
Yeah I am pretty sure, I needed a FIFO queue.
I never tried it, but you can probably control which VS version is used by running the "vcvars" script of your VS installation, prior to calling cargo. You can find it in places like: * C:\Program Files (x86)\Microsoft Visual Studio\2017\Professional\VC\Auxiliary\Build\vcvarsall.bat * C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\vcvarsall.bat
The first half of each problem for me is solving it. The second half is refactoring to make use of all the fancyness I can find. I have been playing with nightly only feat urea (including generators), isolating a minimal difference between the two parts of the problem to maximize code sharing with functional patterns, and learning how to use 3rd party libraries like petgraph. If anything, I find the problems a bit too simple, because there isn't really any motivation to engineer them heavily... the datasets and computations are small, and usually even a dumb brute force, inefficiently implemented, will get the job done, so optimization feels like it would be wasted.
Interesting, but cargo builds successfully even when there is no "cl.exe" in the path (i.e., I haven't run any vcvars). I always assumed that cargo was somehow determining what MSVC build tools were installed, choosing one if there's more than one, and then setting up the path itself. I will try running the vcvars of my preferred Visual Studio version before I run cargo, and see if that makes a difference. 
Not him (obviously), but from what I've found when trying out Diesel (still fairly new to it, so I may be wrong) there doesn't seem to be any way of executing SQL directly with it. It seems the only way to execute queries is via the generated dsl. This is a bit inconvenient, because (as is the case with every other similar ORM I've seen in the past as well) such dsls tend to be incapable of doing some things, or making it difficult to do them. For example, I couldn't find any way to execute a stored procedure via Diesel, if that's even supported at all. What I'd personally like is if I could use Diesel's migrations and convenient method of connecting to the database, but hand-coding all the SQLs and executing them through Diesel so that it only does the materialization (conversion from SQL results to a model struct instance). (as an example, this is what the .NET "micro-ORM" Dapper does)
Hey, wheel-reinvention is traditionally a big part of any roguelike project!
&gt; I am curious what happens when you have const fns which act on structs which are different size on host vs target. I have some code that changes the layout of structs depending on the arch, and if you are cross compiling, the archs of the target are used on the host. Or what do you mean?
I'd implement for the Range variants rather than `(usize, usize)` but that aside yes.
Oh boy. &gt; -webkit-touch-callout: none; /* iOS Safari */ &gt; -webkit-user-select: none; /* Safari */ &gt; -khtml-user-select: none; /* Konqueror HTML */ &gt; -moz-user-select: none; /* Firefox */ &gt; -ms-user-select: none; /* Internet Explorer/Edge */ &gt; user-select: none; /* Non-prefixed version, currently &gt; supported by Chrome and Opera */ I don't really know what this is about, but this is why I've stayed clear from web development all these years. Anyway, congrats on the PoC, it looks pretty encouraging.
Normally you only write "normal" CSS and then you have a postprocessor as part of your build chain that takes care of expanding it to fit all the browser quirks
I've been playing around with Rust/WASM recently and I have a few comments: - Why do people keep using C strings?! Why can't we pass slices both ways? It's so much easier! https://github.com/m1el/wasm-asteroids/blob/714fc07c3412/demo/demo.js#L4-L19 https://github.com/m1el/wasm-asteroids/blob/714fc07c3412/src/lib.rs#L20 - It's possible to make a Rust-driven event-loop-like interface, and I have a WIP project using this interface: https://github.com/m1el/wasm-asteroids/blob/714fc07c3412/demo/demo.js#L31-L148 https://github.com/m1el/wasm-asteroids/blob/714fc07c3412/src/eventloop.rs https://github.com/m1el/wasm-asteroids/blob/714fc07c3412/src/lib.rs#L40 Please note the project is still WIP - there problems with project structure that I know about. There's also no Readme yet.
I believe it has reduced but still uses a disproportionately large amount. (500MB?)
This code works only because old value isn't get overwrited. `Shared` reads from old value location. Because instead of saving pointer to the boxed integer it saves pointer to box itself.
&gt; const BYTES: &amp;'static [u8; 4] = h"00 aa cc ff"; Is this much easier than hex!("00 aa cc ff")?
I found it hard to create a generic trie in whatever language, since the algorithm using them usually need some speciality (eg. compressed paths with splitting on addition). However, this one looks as a good start for some ‚Äûnormal‚Äú trie. However, I noticed few things: * It's more common to place the trait bounds only on the impl, not on the struct itself. * Do you really need the values to be `Clone`? Can't you just move them into the structure on call? * I believe it makes sense to try to match the API of eg. HashMap ‚Äí not having `add`, but `insert`. Not having `has_key`, but `contains`. Being able to iterate over the content. Being able to borrow content out of the thing. Etc. I guess this is mostly because it's still work in progress, but doing the same thing as someone else (the `std`) makes it more familiar to readers and is then easier to use.
These bots really should go back and check if the correction has occurred, and delete its message if it has. 
A big a-ha for me, which hit me while reading up in an attempt to write a much longer answer, was that the only effect of making T Sync is to make &amp;T Send. None of the inter-thread communication machinery cares about Sync, only Send. But if you can't send a reference to T between threads, there's no way for T itself to be shared by multiple threads!
Is there a nice crate for game networking? In C# I have used Lidgren.Network, which was pretty nice for games - It automatically maintains connection status, allows to select what should be packet delivery guarantees (unreliable, unordered, reliable), and overall was pretty convenient to use. Is there anything similar in Rust?
One thing I would change: those functions which take a function name to use as a callback should also take a "user data" pointer, otherwise it can be severely limiting. You would also need them to provide a "destructor" function to deallocate the user data object safely.
Well, that's what you get for using such a backwards, inferior browser. :P /s
Here's a solution. It involves cloning (but cloning f64s should be negligible in cost). It also has some unwraps, not sure how else to go about it. while let (Some(x), Some(y)) = (vec1.front().cloned(), vec2.front().cloned()) { if y &gt; x { *vec2.front_mut().unwrap() -= x; vec1.pop_front(); } else { *vec1.front_mut().unwrap() -= y; vec2.pop_front(); } }
&gt; I think the fact you can customize any C++ type as you like (defining custom move operators, how it acts in this or that situation) is one of the worst parts of C++ ‚Äí you never know what nasty thing an unknown type will do to you. I find this a very unconvincing argument. In practice nobody does insane things within move constructors (or custom operators), even though it's possible. It takes a really undisciplined programmer to try to be clever and it should never pass code review. What really makes the situation bad is the super complex rules about which constructor/operator is invoked when. Also, this argument can be applied to Rust, too -- you can write unsafe blocks in any function and do nasty things without the compiler complaining. You can overload operators to do surprising things. It's just that everyone agrees not to do these insane things as a convention. &gt; And I don't see people complaining about $ in front of each variable in perl and PHP. So, is it a problem to have &amp; from time to time? First of all, perl and PHP aren't exactly model citizens in the programming language world. Plus, it's not just a &amp; in front of variables from time to time. You have to do it for every intermediate too, and it becomes unwieldy very quickly: ``` let result = &amp;(&amp;(&amp;a * &amp;b) + &amp;(&amp;c * &amp;d)) / 2; ```
There is an RFC about this (https://github.com/rust-lang/rfcs/pull/2147) that's been closed but kept sort-of alive in "experiment mode": https://github.com/rust-lang/rust/issues/44762
That sounds awesome! It requires eval support I presume?
&gt; I have to press Alt Gr with my left thumb and then with my left index finger I have to push number 4 key. [OT] PSA on how to avoid finger cortortions: train yourself to press the modifier key with the opposite hand, if possible. For '$', AltGr with the right pinky, and '4' with the left index finger. This won't work for the right half of the keyboard and AltGr, since you don't have one to the left of the spacebar, but "thumb + key" works better in that case. [Massively OT] So, from what I see, the Finnish keyboard lets you additionally write in Swedish, Danish, Norwegian, Icelandic, and... Sami? Cool.
Sorry about that! It was late night, and I indeed mistyped. Somewhat surprising, that it's the only mistype I did :) Anyhow, README is fixed now.
Shit, I meant to write I use my right thumb. But yeah, the layout of the keys is pretty much the same since the differences in the alphabet are minimal. Finnish and swedish are identical pretty much while danish and norwegian swaps √Ñ -&gt; √Ü and √ñ -&gt; √ò (I think).
Yeah. So the const fn doesn‚Äôt return the same value 
&gt; It requires eval support I presume? Nope; it works in a similar way as to how Emscripten works. In a nutshell `cargo-web` scans the wasm bytecode for any JS snippets, extracts them to a `.js` file and replaces the snippets in your wasm with calls to those snippets which are now imported from your JS file just as if you would pass them yourself manually when the wasm module is instantiated.
Probably because there‚Äòs no const generics yet, so at some point your trait implementations will just run out
I don't understand bots like this one in the first place. Usually all they do is spam random, useless stuff. If someone is keen on their spelling, they'd use a spell checker anyway. So what's the point? ^^/rant
I'm forever tripping over the difference between `$x` and `@x` in Perl, and `$foo` in PHP seems to be just a completely unnecessary wart that only exists due to some Perl/shell ancestry.
&gt; `let result = &amp;(&amp;(&amp;a * &amp;b) + &amp;(&amp;c * &amp;d)) / 2;` Yikes, that's horrifying :-(
Actually it has nothing to break, unless the lang syntax or environment tools (cargo, rustfmt, compiler message format) dramatically changed. All errors and warnings to show are taken from the compiler. Syntax highlight and type resolution rely on the source code (no MIR dependency, which still heavily changes and breaks RLS). Absolutely live option, especially if you need an out-of-the-box GDB. If debugger is not relevant, I'd suggest IDEA or CLion + Rust plugin, which is already bellz'n'whistled pretty good.
IANAL, but the MIT license reads: &gt; The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. It seems some big companies do mention the copyright notice: https://daniel.haxx.se/blog/2016/11/14/i-have-toyota-corola/ It cannot hurt anyway, isn't it?
Well, I think your demo shows why, your code is sending length where c strings are already opinionated on how to do that. I try to keep my even loop structures really close to JS interface. It's really tough though at the moment, but surprisingly useful. Also, Thank you for posting your code. It helped me a lot when first learning. :)
If it were up to me a sigil or something like that would be in front of every variable in Rust simply to create a different namespace between keywords and variables so you can later add keywords. I find how easily people design languages around the idea of "we accept that the introduction of any new keyword would potentially break existing variable names" to be baffling. Being able to introduce new keywords without breaking backwards compatibility seems like a very important thing to me.
I always find this to be extremely confusing and weird abuse of notation. `=` there is no longer the assignment it normally is.
Unless I‚Äôm misreading, the chapter specifically mentions that error and explains why it‚Äôs happening 
Correct me if I'm wrong but , when JS receives the string it calls dealloc_str, is that not good enough?
Welcome to the jungle :)
For nest.pijul.com, I use pleingres (asynchronous/tokio SQL driver), and a simple migration script using SQL scripts + an extra table saying which migrations have been applied.
Does it? Can you point me to where the error is explained? I was referring to listing 20-21, after which the code should compile according to the book. I however get the aforementioned compiler error. 
I'm certainly curious for feedback :) could you tell me a more concrete example of how you'd use this?
Can you show your code? Did you implement the FnBox trait?
Perl and PHP are basically examples on how not to design a programming language. PHP $ sigils are basically useless syntactic cruft and a remnant from the time it was just a set of Perl macros and string literals didn't need to be enclosed in quotation marks. Perl sigils, although semantically relevant, are just... weird.
All of the listings in the chapter include comments like // ...snip... which indicates missing code. I pieced together most of the code into one place [here.](https://play.rust-lang.org/?gist=7f3c15ef0ce8650381975bf8a3c86bcb&amp;version=stable) It compiles just fine. If you could share whatever code you pulled together from that chapter, that would be helpful.
Pretty advanced, wow.
Just use `include!` (to include as source code) or `include_bytes!` (to include as a slice of bytes). 
thank you!
or `include_str!()` to include a String literal, which is explicitly what you asked for. I guess /u/K900_ isn't familiar with that one.
I just found that :) perfect
http://docs.diesel.rs/diesel/dsl/fn.sql.html
When cross-compiling it should return on the host the same value that it would return if you were compiling on the target, but this is already the case, or when is this not the case? 
Actually, it may even be possible you don't need a database, or the fanciness of an ORM, at all -- some applications people have told me they want to make seem not to need the complexity of those solutions. For instance, a blogging platform with hundreds of posts (but not tend of thousands) may only need a static site generator like `gutenberg`. If you don't need a full transactional database, there actually may be tens of options, yes. :) The Rust ecosystem isn't totally mature, but there's few interesting libraries in most domains I know of! I'm not saying that's not your case, but it's hard to actually know and help you with that kind of response. :/ Sounds like you're not interested, then?
That uses the emscripten target though.
To help you debug, [here is](https://github.com/alexcrichton/cc-rs/blob/88c3a69b27a931b474e98c79eee9589216d6b3bd/src/windows_registry.rs#L587-L633) the logic used to locate msbuild. It uses registry keys, you may want to check that they are set as expected.
Somewhat amusingly, Stroustrup originally added references to C++ mostly because using pointers as operands to overloaded operators was so syntactically ugly.
Oh well, turns out I did in fact make a mistake when copying parts of the code. Instead of *type Job = Box&lt;FnBox + Send + 'static&gt;* I wrote *type Job = Box&lt;FnOnce() + Send + 'static&gt;* which threw errors. Thanks everyone for helping me out!
Great! :D
You want to avoid using null terminated strings though, as Rust's strings are usually not null terminated, so the FFI may force you to allocate some buffer just so you can null terminate the string. Considering this target isn't compatible with C anyway, might as well move the proper Rust strings through the FFI.
`O(log32(n))` isn't `O(1)` but when you have a maximum length of 2^32 it's close enough from an engineering perspective, even if it isn't mathematically precise. That's why they say "effectively constant time" rather than claiming it's literally `O(1)`.
My guess would be that `String::from_utf8` does not copy the contents of passed `Vec&lt;u8&gt;`, it just reinterprets it. `String::from_utf16` needs to copy anyway, so taking owned memory would be useless.
I expect that this is the reason as well. If you want to copy the bytes (for instance, if you have a slice instead of an owned string), you can use [`str::from_utf8`](https://doc.rust-lang.org/std/str/fn.from_utf8.html), and then call `to_owned()` on the result to clone it to a `String`.
self.iter.by_ref().skip(1).next() https://play.rust-lang.org/?gist=902f0f4308fb1470599d6c13607cc0d3&amp;version=stable
This is possible because `&amp;mut T` implements `Iterator` too. So you call `&lt;&amp;mut T as Iterator&gt;::skip` rather than `&lt;T as Iterator&gt;::skip`.
It is not just about it "being so fast it doesn't matter", it is also about stating that if you have a vector with 1K, 1M, or 1000M elements it is all the same, and operations take aproximatly the same time, which is not true. Haoyi has a nice blog post about this (["Scala Vector operations aren't 'Effectively Constant' time"](http://www.lihaoyi.com/post/ScalaVectoroperationsarentEffectivelyConstanttime.html)).
One of the invariants of the string class is that it's *always* valid Unicode, and it encodes that in UTF-8 internally, yes.
One easy-ish option to comply with the requirement to distribute a copy of the license(s) could be to add a "--legal-notices" flag to your program's options, and then for each crate/library print out its name, version, and license text (adhering to the best practices from the link I supplied on my previous reply - https://reuse.software/practices/2.0/). As for including the license text *in* your application, [this reddit post](https://www.reddit.com/r/rust/comments/7jrzz7/rust_string_literals_populated_from_files_at/) has some suggestions. Ideally, though, with the sheer number of licenses that are required, you'll probably want to include_bytes! a gzipped version of them, and uncompress them at runtime when you output them. Seeing as how a very simple application can easily wind up including 50+ crates, I think it would be relatively easy to exceed 100k worth of license text. If you figure out a way to automate looking up the version(s) of crates you use from within your code - please share it. 
Arguably the worst IM ever created. It is such a pain to use.
This is not always the case, because sometimes the puzzles get pretty rough, but the easy puzzles (posted on Mondays) at /r/dailyprogrammer will often be what you're looking for. I'd suggest rifling through their backlog. You might also take a look at their prospective and pending items at /r/dailyprogrammer_ideas.
yes
Oh I misunderstood then? I don‚Äôt know what happens, do you know?
The blog basically just repeats what you said and what I agreed with. Calling these `O(1)` is wrong but that's not what they're doing. They're talking about the performance from a practical usage standpoint and the argument you're making against that goes back to the mathematical definition. It just looks like pedantry to me.
There it really is `impl&lt;'a, I&gt; Iterator for &amp;'a mut I `. Thanks a lot (: Though, with all the extra characters it's actually hard to look for using ctrl+f on the site. Is there by any chance a better approach if I ever encounter such a question again? 
Hi, all there is a construct in the golang type Context map[string]interface{} context := Context{ "field1" : "value1", "field2": 2, "field3": true, } How can I write the same in rust?
&gt; you never know what nasty thing an unknown type will do to you. you make types do the most sane thing for their most common use case. if the types are doing something nasty, choose a different library. vector maths libraries in C++ have been great for decades. I've been experimenting with rust on and off for years, and I always run into this: I prefer how this goes in C++. But designing a new language without cruft, it should be possible to do *better*. &gt; And I don't see people complaining about $ in front of each variable in perl and PHP I dont use perl or PHP. Rust is comparable to C++, not those.
You can even transform the error value back into the Vec you tried to use.
For the crates I develop, cross-compiling returns on the host the same value as on the target, so everything works fine. If for you it does not, you should file an issue.
that makes sense.. whilst people complain about 'the complexity of pointers / references' ... it is making my core tool - vector maths types - more pleasant to use, and I miss it in Rust.
`from_utf8_lossy` is still missing out on some potential for optimization by not taking `Into&lt;Cow&lt;[u8]&gt;&gt;`. Right now if you have a `Vec&lt;u8&gt;` with all valid utf-8 and pass it to `from_utf8_lossy`, it will still make a new allocation even if you were willing to give it the existing one.
What I would have done is over-estimated the keywords in 1.0, e.g. reserving all the keywords from the most popular languages even if the language didn't use them, then if they prove unused later *freeing* them. (e.g. personally i think they should have kept 'new' as a potential keyword and done the 'box' stuff as an extension to that, and used ::init() ) anyway thats a different story
&gt; EDIT: you can have an opaque fixed-size handle in the IO&lt;T&gt; type itself that only the evaluator understands, and it could treat accessing the true value as an IO side-effect, and still disallow global state, therefore isolating everything up until runtime. I was thinking of allowing the regular types, but not the regular *operations*. That is, MIRI would have a tight-grip on what kind of I/O it accesses, even possibly using the `gaol` crate to prevent plugins from intervening, and the read-only and write-only directories would be separated to avoid state-sharing.
People are already complaining about the amount of identifiers and variables you can't use like it being impossible to have fields named `type` If `class`, `new`, `throw`, `try`, `catch`, `except`, `union`, `intersection`, `begin`, `end`, and what not were reserved that problem would only increase. Rust's grammar in general feels somewhat "fragile" I guess in the sense that a minor type often tries go parsing in a completely different direction. Like `(0, ||0)` is a pair of a number and a closure but `(0||0)` is a logical or and thus a type error.
Agreed. From the `README`: // Will panic since the two numbers have different ranges let x = range!(5, 0..10); let y = range!(10, 10..128); let z = x + y; // panic! I would have expected this to not panic, and instead have `z = range!(15, 10..138)`.
thats not worth complaining about IMO. use variables with a preceding underscore, use Capitalization, use compound names that mean more (let new_pt=make_a_point()) instead of let new=make_a_point()). &gt; Like (0, ||0) is a pair of a number and a closure but (0||0) is a logical or and thus a type error. (yeah that does look a bit weird, but rust having a very compact closure syntax is one of it's superior tradeoffs IMO ( the alternative might have been ```=&gt;``` but that is used for pattern matching). Rusts closure syntax is on my list for praise rather than complaint.)
What about [cargo-license](https://crates.io/crates/cargo-license)?
&gt; &gt; &gt; &gt; &gt; Rust's grammar in general feels somewhat "fragile" I guess in the sense that a minor type often tries go parsing in a completely different direction. This sentence made a lot more sense when I realized you meant typo. At least it's an improvement over C++ not even needing the typo to confuse the compiler.
I am trying to time a function and pretty print the result. I could roll my own, but there has to be something out there. Any help is appreciated. What I have tried. I think `chrono` is the current recommended solution. 1. I can get a `chrono::Duration` from an `std::time::Duration` from a `std::time::Instant`. But then `chrono::Duration` has no pretty printing functions that the rest of chrono have, nor do I see how to convert to the other chrono types. 2. I can get a `chrono::DateTime&lt;Utc&gt;` with the `Utc::now()` but I don't see how to get the elapsed time from two of them. (`signed_duration_since` returns a `chrono::Duration` leaving me in attemped 1.)
Ah, neat. However, unfortunately, it doesn't seem possible to load the results into a struct when using an SQL query, so it's not as convenient as it could be.
You could make your framework take the user data as a Box&lt;T&gt;, store it locally, turn the address into an integer, send it across (I assume that's cheap), and turn it back into a Box&lt;T&gt; whent the callback is triggered. Would require unsafe code but would be a nicer abstraction for the callers.
I like this idea :)
The example shows that, I thought? Unless I'm misunderstanding. 
Yeah, my bad. I tried the sql_query function that was linked, as it said to use that for full queries. It is possible with the sql function, though it requires specifying each field's SQL-type in a tuple type parameter.
Agreed. One of the main philosophies of C++ has always been that user-defined types should be true first-class citizens, as performant and ergonomic as builtin types. That‚Äôs one of Rust‚Äôs selling points as well, but in this case perhaps the situation could be improved. On the other hand, having to manually annotate your functions to take (const) references just for the sake of optimization feels superfluous and especially with Rust‚Äôs strict aliasing semantics it should really be the compiler‚Äôs job to elide unnecessary copies. C++ does and these days it‚Äôs recommended to pass value types by value by default. I don‚Äôt know how sophisticated rustc is currently regarding that.
I agree, you should *always* distribute the license text since it's not that hard to do. However, there are plenty of cases where you don't have to, such as: - accessing it over a network, like a web server (you're not distributing the "software", you're just giving access to it) - using it on an embedded system, like TiVO (similar to above) There's an argument that 'Software' applies to the source code, so derivative works don't have to, but it's really easy to just throw it in somewhere, so why not. I try to do this even when not required to because it's easy and I'd prefer to not have to worry about it. You don't even have to say *which* software you're using that's covered, just include the license, so if you depend on lots of projects all covered by the same license, just include it once (though make sure they haven't modified the license).
Yes, I need to serialize this data. So, I will try Value. Thank you
I browsed through your repository a bit, and I already find it really informative because there are some bits of code that I have trouble reading....and not because you've written unreadable code! There is simply stuff going on which I don't know about/patterns I didn't expect to be used. Browsing through people's puzzle code might be a good way to build "mechanistic understanding" of how Rust fits together!
Any chance miri will allow for a proper repl in the future?
I don't see how const functions eliminate the need for lazy static.
Does it work for cross compilation? If so, how does it emulate qualities of the target CPU, such as the size of certain data types?
To be clear, I'm sure lazy_static is still useful for more complicated stuff, but 90% of the time I see it used is somthing like: lazy_static! { static ref MUTEX: Mutex&lt;i32&gt; = Mutex::new(0); } which could trivially be replaced with static MUTEX: Mutex&lt;i32&gt; = Mutex::new(0);
I agree with you. Lazy static allows for everything you can write in rust. Any limitations imposed by constant function evaluation will mean lazy static will still have a necessary place in the ecosystem. I'm curious how heap allocation will work if their goal is a complete replacement.
Why do we need `const fn`? Can't we just allow any function in a const position and speculatively evaluate it, failing with a compiler error if it tries to do something non-const? Is it just a matter of the locality of checking?
Because you can initialize your hash map at compile-time and compile it into your binary instead of executing when required at run-time? Why wouldn't that work?
I think MIR is already specific to the target architecture, so e.g. usize is already translated into a specific size integer.
How does a hashmap help me when I need to make a database connection or use a return value from a system call?
Most of the time I see lazy_static used is something which can be trivially replaced with a const fn invocation: lazy_static! { static ref MUTEX: Mutex&lt;i32&gt; = Mutex::new(0); } // becomes.. static MUTEX: Mutex&lt;i32&gt; = Mutex::new(0); I believe miri could also be used to create frozen versions of more complex structs which would then need to be allocated before main: const fn create_static_map() -&gt; HashMap&lt;i32, &amp;'static str&gt; { let mut m = HashMap::new(); m.insert(0, "foo"); m.insert(1, "bar"); m.insert(2, "baz"); m }; static HASHMAP: HashMap&lt;u32, &amp;'static str&gt; = create_static_map(); Don't know if that would ever be allowed, though.
Fair enough.
I believe this takes place before translation to native code. I'm not an expert about the compiler internals, but MIR is going to be identical across platforms at that point - it just needs a "virtual machine" (if you want to call it that) to execute it, which is what it sounds like miri does.
That would be very annoying when you update something and suddenly you couldn't call a function anymore
I was literally just explaining miri to my friend and telling him how much I wanted this. Have a good miri based REPL/debugger is my main reamining wish for Rust as a language. I know that this does not quite get us there, but it seems like a step in the righ direction. Awesome work for everyone involved!
Actually there are several more problems on top of Haoyi blog. Update is actually not O(log_d(n)) where d = 32, but O(d*log_d(n)), since you have to replace every node during update. That's far from any intuitive understanding of effectively constant. Second problem is that Scala also says that HashMap has effectively constant operations (http://docs.scala-lang.org/overviews/collections/performance-characteristics.html). Which is something completelly different, since there is big difference between "effectivelly constant" in Vector and "expected constant time" in HashMap (which is regular theoretical term). The "effectively constant time" is complete nonsense term, which does not have any practical or theoretical meaning.
Right. My question is just about whether any operations in MIR are meant to behave differently depending on the target. Sorry, I don't know very much about Rust internals. But this is an issue that has plagued GHC for years, and makes cross compiling Haskell very painful. Just wondering if Rust has the same problem.
That's good. There are no behavioral differences between CPUs to worry about other than sizes?
From what someone told me, miri understands heap allocation. So hash maps may be possible!
Ah, I've only ever seen the claim made for queries on the 32-way trie (in talks and such). If they're also claiming the same thing for updates and for their HAMT that's a whole different thing.
It's a promise that that function will always be able to be used in a constant context. Removing `const` is a breaking change, basically.
This is great!!!
Huh. Well, I just checked it out, and it's certainly mostly .go files, but there are some big chunks of assembly here and there. It doesn't look like an excessive amount compared to kernels or C runtimes though. Thanks for pointing that out!
&gt; which is what AGPL is for And to an extent the GPLv3. As for the curl license, I'm guessing they just didn't want to mess with it even if they thought they were in the right. What's the point of being right if you have to fight a court case over a trivial thing?
True, but I don't think people are taking about empty hash maps.
It understands heap allocation, so it can handle heap allocated collections internally. The issue is how to have a heap-allocated structure at compile-time that carries over into a heap-allocated structure at runtime. Something like that is always going to need some sort of lazy initialization.
Floating point arithmetic is also different, especially how different NaN patterns are handled.
I guess, is it not necessary because mutex itself is send and sync, and guarantees the data is safe? You only need the Arc if you want to be able to use it in a move closure or non-`crossbeam::scope`d closure and rust is therefore unable to determine how long the object survives. Neat.
I'd guess that those operations either wouldn't be `const`, or they would return a different result than in the target. For example, what should `coresimd::vendor::__cpuid(0, 1)` return in miri when running on an aarch64 host cross-compiling to `x86_64` ? 
Mostly just playground stuff. Checking to see what works and what doesn't in real time is really valuable.
A Rust interpreter would be great too. While I love Rust's current lack of a costly runtime sometimes being able to instantly evaluate changes in a running process can be useful. I'd love to be able to write Rust where I can immediately see the impact of changes in a running program and then later compile it out to full speed code.
Step 6: deprecate `static mut` in favor of `UnsafeCell`, thus further narrowing the set of language-level operations that require the `unsafe` keyword.
&gt; I'm curious how heap allocation will work if their goal is a complete replacement. Heap allocation at compile-time is no problem as long as the heap location is irrelevant to the final result; i.e. `static FOO: Box&lt;i32&gt; = Box::new(0);` would be a problem, but `static FOO: i32 = vec![1,2,3].iter().sum();` would be fine.
&gt; When usize is u32 on the target platform for example, Miri will use u32 internally for usize values even if usize is u64 on the target platform. I think there's a typo here, implying that usize is both u64 and u32 on the same platform?
Is that just by virtue of the unknown target not generating source maps?
&gt; Is there by any chance a better approach if I ever encounter such a question again? Yes! `rustdoc` has a search bar at the top of all generated pages that indexes the entire generated ‚Äúsite;‚Äù this applies to the Rust standard library‚Äôs documentation just as much as it does to any third party crate, including your own. EDIT: Never mind; while what I said was entirely true, it was also entirely useless, because the search bar apparently doesn't index `impl`s at all. :(
I believe so; I haven't dug in. All I know is that this was using the emscripten target.
Ok i see, thanks a lot for the link, i think it was exactly what a needed !
What do you mean by "crash"? A panic? A segfault? What error do you see?
Rust is generally pretty good at cross-compilation :)
I would start rust with normal applications until you get used to it. There's a lot of fine details to get used to with rust. 
you want r/playrust
Doesn't a mutex need to be initialized at runtime?
I don‚Äôt think so, there‚Äôs `PTHREAD_MUTEX_INITIALIZER` for example [std lib unix mutex source](https://github.com/rust-lang/rust/blob/master/src/libstd/sys/unix/mutex.rs)
RustDragon's answer is great. From a Common Lisp perspective, the REPL additionally doubles as a long-running compiler which gets used for incremental compilation and some language-server like features such as jump to definition, auto-complete, and documentation lookup. 
thread 'main' panicked at 'no Task is currently running', C:\Users\User\.cargo\registry\src\github.com-1ecc6299db9ec823\futures-0.1.17\src\task_impl\mod.rs:44:8 note: Run with `RUST_BACKTRACE=1` for a backtrace. error: process didn't exit successfully: `target\debug\async-files.exe` (exit code: 101)
If you are using a nightly compiler, segfaults when running the code can happen from time to time. Update the rust compiler and try again. Otherwise, post your error.
But the opposite is not the case, right? Is there *any* way that adding `const` to a function would be a breaking change?
Did you follow the advice and run the program with `RUST_BACKTRACE=1`?
I'm a bit surprised by this, why can't it be?
&gt;they are quite expensive to generate That's exactly why you'd want to computer it at compile time :)
&gt; you won't need to use lazy_static as much and some other fun things Is this some sort of supercompiler? Or do you have to specify what you want it to compute at compile time. 
I'm just recently learning rust, and wrote a quick blog post on [how to make http requests with reqwest](https://chase.pursu.es/http-requests-in-rust-with-reqwest.html). It's pretty simple, but I couldn't find many beginner friendly posts and guides when I was trying to figure it out, so I wrote one.
&gt; I hope if I'm too off the mark someone will come along to correct me Lol. I'll have to pay a bit more attention to the issue tracker and perhaps join in the party :)
I don't know why, but I find it entertaining. I suppose it's less of a waste of time than reddit.
I was assuming that two things are the case the same time: expensive to generate (so you can't just generate it always at program start... that's where the lazy in lazy_static helps you), large (you can't put it into the binary). Another use case for lazy_static: anything that requires I/O. Rust's const eval will never get IO (it would violate the soundness of the language) (but you *will* be able to do IO and other fun inside the parsing phase e.g. via include! or include_bytes! and use those data later on). And even if you had IO, most likely if you need IO you'll only have the data available at runtime.
&gt; 'no Task is currently running' Yeah, you're getting bit by an annoying subtlety in `Future`'s implementation. When you call `poll()` you must be in a context that specifies a task (it's thread local, which means you can't see it). Instead of calling `.poll` which can return NotReady anyways (and you definitely don't want that), call `.wait` which drives the future to completion, and then returns a `Result`.
I made a blog post about getting started with Rust a while ago and updated it recently. It might be helpful to you! http://matthewjberger.xyz/rust/Getting-Started-With-Rust/
Python mostly has replaced bash as my shell any time I can help
I added some unscientific benchmarks https://github.com/actix/actix-web#benchmarks
I opened up my sandbox and caused a panic in main, and I got this: [trace](https://i.imgur.com/ti4luh7.png) I'm pretty sure `__rust_maybe_catch_panic` and `lang_start` and the outer `main` count as "life before main", right? or am I missing something?
Wait, does this mean one could execute tests during the compilation phase and do some sort of PGO to re-order the arms of a match statement, or construct perfect hashing functions over a set? Compile time bloom-hash with no collisions?!
why can't _every_ operation be const? If I want to download files during compilation, it's probably a bad idea, but I don't see why it should be disallowed?
On Windows, you would run $env:RUST_BACKTRACE=1 on its own line to set that environment variable for the session.
Should be "... even if usize is u64 on the **host** platform"
&gt; always separate to the generated artifact and don't just contain file name and line number info, but the full source code Neither of these is true; source maps can be inline via `data:` URLs (e.g. `//@ sourceMappingURL=data:application/json;charset=utf-8;base64,‚Ä¶` with the original code included inline through the `sourcesContent` property), and the source map itself typically only contains a reference to the source file rather than inlining the source file. Inlining the source maps is useful for debugging, and is commonly done with webpack; for production purposes, external source maps are definitely what you want.
See, you always learn stuff :).
I suspect you're missing the context of the deleted comment. "Life before main" in popular parlance doesn't refer to intercepting the start function, it refers to what is known in C++ as "the static initialization order fiasco" https://isocpp.org/wiki/faq/ctors#static-init-order
Nah. As I understand it, const fns can still be evaluated at runtime of their arguments are non-consts
My understanding though is that miri can handle allocation just fine. I get the impression that it's not enabled right now in rust, but that in principle miri can compile every rust program. So, it's more a matter of marking the appropriate functions const all the way from `core` through `std` and all the libs up to regex and then we'll be able to build regexs at compile time. It'll definitely take time, but, again AIUI, it's possible in principle.
Out of curiosity, why beta?
I'm having a problem installing clippy using cargo. When I try to install it via `cargo +nightly install clippy`, it fails during compilation of `clippy_lints v0.0.175` with the following error message: error[E0004]: non-exhaustive patterns: `ItemTraitAlias(_, _)` not covered --&gt; /home/______/.cargo/registry/src/github.com-1ecc6299db9ec823/clippy_lints-0.0.175/src/utils/inspector.rs:361:11 | 361 | match item.node { | ^^^^^^^^^ pattern `ItemTraitAlias(_, _)` not covered error[E0004]: non-exhaustive patterns: `TraitAlias(_)` not covered --&gt; /home/______/.cargo/registry/src/github.com-1ecc6299db9ec823/clippy_lints-0.0.175/src/utils/mod.rs:928:11 | 928 | match def { | ^^^ pattern `TraitAlias(_)` not covered error[E0004]: non-exhaustive patterns: `ItemTraitAlias(_, _)` not covered --&gt; /home/______/.cargo/registry/src/github.com-1ecc6299db9ec823/clippy_lints-0.0.175/src/missing_doc.rs:124:26 | 124 | let desc = match it.node { | ^^^^^^^ pattern `ItemTraitAlias(_, _)` not covered error: aborting due to 3 previous errors error: Could not compile `clippy_lints`. warning: build failed, waiting for other jobs to finish... error: failed to compile `clippy v0.0.175`, intermediate artifacts can be found at `/tmp/cargo-install.CQkBsYdy44tv` I have the latest versions of both stable and nightly installed on my machine: `stable-x86_64-unknown-linux-gnu unchanged - rustc 1.22.1 (05e2e1c41 2017-11-22)` `nightly-x86_64-unknown-linux-gnu unchanged - rustc 1.24.0-nightly (0077d128d 2017-12-14)` Any ideas how I can resolve this? 
Yes, thanks.
&gt;Rust's const eval will never get IO (it would violate the soundness of the language) What? How? I don't understand 
It seems that miri can understand what's being done with an allocated intermediate value. From what others are saying, it can't output a heap-allocated value.
Yes internally rust uses utf8. len() btw returns the size of the string utf8 representation in bytes, as opposed to the number of chars.
I learned rust thanks to exercism.io and it did not feel "puzzly".
Design document: https://webkit.org/blog/6161/locking-in-webkit/ Rust implementation: https://crates.io/crates/parking_lot
The difference is that it's very easy to teach "removing const, just like pub, is a baking change". It's not that easy when everything is implicit, especially when the library author doesn't consider it necessary for the function to be const in the first place. 
Hopefully your definition of "giant" blob isn't 60 GB. That wouldn't be so wise ;) https://stackoverflow.com/questions/47729960/why-shouldnt-i-put-a-60gb-tar-into-a-byte-literal
Hi all. I just started learning Rust last week for a new project (coming from a fp Scala background), and I have what might be a trivial question, but I haven't been able to wrap my head around a solution. I have a struct: GenericClient&lt;T: Transport&gt; { transport: T } This struct has something like the following implementation: impl&lt;T: Transport&gt; GenericClient&lt;T&gt; { fn api&lt;A: Namespace&lt;T&gt;&gt;(&amp;self) -&gt; A::new(self.transport.clone()) } fn methods(&amp;self) -&gt; methods::Methods&lt;T&gt; { self.api() } } So, this is just a wrapper type around some set of other methods that need to be aggregated. Now, let's say that this generic client contains a set of methods that are uniform across specialized clients; however, those specialized clients themselves have additional modules: struct SpecializedClient&lt;T: Transport&gt; { transport: T } impl&lt;T: Transport&gt; SpecializedClient&lt;T&gt; { fn specialized_methods(&amp;self) -&gt; specialized::Specialized&lt;T&gt; } What I want is for `SpecializedClient` to have all the methods of `GenericClient`. The simplest way to accomplish this is to just reimplement all of the methods wrapped in each client implementation; however, that just seems needlessly boilerplate-y. My current solution is to have a trait containing all of the common methods: trait Common&lt;T: Transport&gt; { fn transport(&amp;self) -&gt; &amp;T; fn api&lt;A: Namespace&lt;T&gt;&gt;(&amp;self) -&gt; A { A::new(self.transport().clone()) } fn methods(&amp;self) -&gt; methods::Methods&lt;T&gt; { self.api() } } And then `impl&lt;T: Transport&gt; Common&lt;T&gt; for GenericClient&lt;T&gt; { *methods and such* }` for each client. Other things that I thought of were to write a macro for the implementation, but that doesn't sound like a parsimonious solution either. Am I completely overthinking this, or am I missing something painfully obvious? I have a suspicion that this is probably really simple, and I'm going to feel very dumb, very soon. 
Const functions probably need to be referentially transparent so the compiler can verify that it can actually be const, is my guess
Is this posting a way to get players to the game?
&gt; nor do I see how to convert to the other chrono types. What type do you want to convert `chrono::Duration` to?
To further clarify, this only applies to powershell, for the regular cmd it'd be `set RUST_BACKTRACE=1`
But why? How does that affect soundness? Is it possible to show an example or is it complicated?
IIRC, const in rust means that "computable during compilation". What does it matter if it is not referentially transparent?
Yes. The contents of the file may change between executions. This is like constant evaluating println so that we print at compile time &amp; not at runtime
Thanks! Awesome!
If it isn‚Äôt, you can‚Äôt predict how the execution of that function will affect its surroundings, and so it can‚Äôt output to a file, or use network resources, or produce different results with the same inputs if it‚Äôs executed multiple times. If it does do any of these things, it can‚Äôt be executed at compile-time, because then those things happen differently than if they‚Äôd have happened at run-time, which probably isn‚Äôt what you want to happen
/r/playrust
For `Index` it would actually look like `manyvectors[i]` and `manyvectors[i..j]`.
ok I started messing with asmjs myself and discovered i had confused rustc versions lying around, and there was another step (cargo env..) I've managed to get some of my own Rust experiments running in a browser, and just managed to get that compiled under wasm32 too. 
Hm, I wonder if a possible solution to this might be "borrowing" operator modifiers. Eg, instead of having an operator borrow automatically, have a second operator that has the semantic to borrow its arguments. Eg, based on a example in this thread: &amp;(&amp;(&amp;a * &amp;b) + &amp;(&amp;c * &amp;d)) / &amp;2; =&gt; (&amp;(&amp;a * &amp;b) + &amp;(&amp;c * &amp;d)) &amp;/ 2; =&gt; ((&amp;a * &amp;b) &amp;+ (&amp;c * &amp;d)) &amp;/ 2; =&gt; ((a &amp;* b) &amp;+ (c &amp;* d)) &amp;/ 2; 
Java has had 'const' and 'goto' as keywords since 1.0, and never used them for anything. "[This may allow a Java compiler to produce better error messages if these C++ keywords incorrectly appear in programs.](https://docs.oracle.com/javase/specs/jls/se6/html/lexical.html#3.9)"! 
On the other hand, features like F# type providers allow for arbitrary IO when generating types, which permits for many useful patterns. There are certainly very good reasons to restrict IO, but allowing IO doesn't always lead to madness, particularly if the compiler is allowed to cache the produced value. Even with weakened guarantees of currency there are still a lot of practical uses.
String literals are references (well, slices) so basically there is no code that thinks it owns the backing memory. If you have code that allocates then it creates an owned value which Rust may attempt to free at some point. I guess you could store the data in the program binary and convert it to heap allocations at runtime (sort of the equivalent of calling "to_owned()" on a string literal), but then there is not much benefit over lazy_static. 
It's at the Mozilla all hands.
Ah! Interesting. So... the way I want to handle my image loading, I REALLY want poll() instead of wait(). The busy-loop you see was to test poll() - I know I could have used wait(). wait() blocks (which I don't want), and poll() unavoidable (which I need). Would you recommend that I create my OWN Futures if I really wanted to avoid wait()? The purpose of how I am loading in images is to solve the duplication issue. For example, If 10 threads are currently accessing text.png, I REALLY only want to load it 1 time. Each thread will do it's own poll() to see if it's loaded, but the software will only create memory for 1 instance of that image. If you have an alternative for what I'm trying to accomplish, please let me know.
All the other types have a `.format("fully custom thing %d:%H:%M:%S")` So I thought If I could convert to any of the other types, it may work.
`TrustedLen` is used via specialization, for example: https://github.com/rust-lang/rust/blob/1.22.1/src/liballoc/vec.rs#L1800-L1801
&gt; As these guarantees can't be ensured by the compiler, `TrustedLen` is an `unsafe trait`. Nit pick, it is an unsafe trait becaus if the guarantees that can't be ensured by the compiler are broken then you can get memory corruption. I.E. the code that uses `TrustedLen` is unsafe and is **only** correct if the guarantees hold. 
I like your proposed Rustler :P now I want to see Ferris with a cowboy hat.
&gt; the struct generator doesn't work because emscripten doesn't yet generate bindings for WebGL 2 functions Emscripten does support WebGL2 in general, all you need is `USE_WEBGL2=1` as indicated in my [wasm-triangle README](https://github.com/kvark/wasm-triangle#preparing), so you might want to check it out ;)
&gt; "{}:{}:{}", d.num_hours(), d.num_minutes(), d.num_seconds() If it wore only that simple... But it is not. :-( https://play.rust-lang.org/?gist=2ee0144b259fbe20003af755b8d715e3&amp;version=stable
In the true spirit of RIIR I rewrote probably my most used javascript web development tool: http-server. While i've been doing WASM development in Rust, I found I kept needing a simple static file hosting tool to test my work. The hope is that this project can serve others as well as it served me in all my JS work.
Does it have any additional features over `python -m SimpleHTTPServer` or `python3 -m http.server`?
Why would locking/unlocking a mutex (the standard library mutex, mind, not even [the fastest Rust mutex](https://crates.io/crates/parking_lot)) not be slower than allocating (which is, relatively, fast).
The main feature is that you don't have to have to have python ( windows ), you don't have to know about the python ecosystem ( like many new developers ), its idiomatic rust tool , and has simpler command line args.
The advantages are it doesn't require python (windows), doesn't require knowledge of rust ecosystem ( that new developers may not know ), is an idiomatic rust tool, simpler arguments. In future I'd like to add https support and directory viewing.
Because `Mutex` on the WASM target is [literally just a boolean switch with sanity checks](https://github.com/rust-lang/rust/blob/master/src/libstd/sys/wasm/mutex.rs#L14) (no threading so no need for synchronization). I couldn't begin to explain the actual issue but it's definitely not that. Maybe all the bookkeeping that `Once` does as utilized by `lazy_static` (which is also unnecessary without threading).
Check also this older project: https://github.com/thecoshman/http
Neat!
* conservative_impl_trait: this is a priority; even though it doesn't require Chalk I'd guess it won't stabilize until Chalk lands in order to provide confidence in the design; my guess is stable in the second half of 2018 * const_fn: less of a core priority but benefits from highly motivated contributors; relatively little language design work to be done but the implementation will need a lot of testing; guessing that at least some aspects of this will be stable in 2018 * custom_attribute: part of a larger feature, procedural macros 2.0, that is not an especially high priority at this time and which will need significant implementation and design work; I don't expect this in 2018 * custom_derive: this feature was deprecated in favor of macros 1.1 and will never be stable; Rocket will need to remove this feature, but hasn't yet because for Rocket's specific use case macros 1.1 provides a mildly less ergonomic interface * i128_type: not a very high priority, but quite near to being stable; I expect this in early 2018 * macro_reexport: this was intended as a stopgap convenience feature until macros 2.0 arrives, but flaws were discovered and this was deprecated; will never be stabilized * never_type: not a high priority, but seems to be coming along nicely regardless; expect in 2018 * plugin: another macros 2.0 thing * specialization: a priority, but also a huge feature with far-reaching ramifications for the type system and lots of open questions; don't expect this before Chalk, and don't be surprised if an initial conservative version is stabilized before the entire feature is, which may or may not satisfy Rocket's needs; don't bet on any sort of stabilization in 2018, but don't entirely rule it out either * try_trait: status unclear, but should have reasonable priority as part of the ergonomics work; could easily land in 2018 if the language team decides to push on it * decl_macro: again, macros 2.0 TL;DR: plenty of those features should be stabilized in 2018, but macros 2.0 is the big one that lets Rocket do its magic and that has no clear timeline currently.
Well it just needs a tiny bit of elbow grease: https://play.rust-lang.org/?gist=003478933e479a3d7b23b94ee0a8c745&amp;version=stable Here is a somewhat convoluted way to get access to chrono's formatting, by creating a "zeroed" `DateTime`: https://play.rust-lang.org/?gist=f8b913eb26a2929ab2adfb4c8a2b6139&amp;version=stable