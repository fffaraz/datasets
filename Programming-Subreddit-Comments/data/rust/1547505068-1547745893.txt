pls do, am beginner, am confuse
It has to be in its own crate.
I haven't written up a proposal, but there are a few things I can think of to keep these compatible. Each has its own tradeoffs of course, but I'd be in favor of any of them rather than getting rid of the ability to evolve traits. The best one I can think of is to make const impls opt-in at the trait declaration. A trait declared `const? trait` would allow `const impl` as well as non-`const` implementions, while one only declared as `trait Xxx { ...` would only allow non-const impls. This would be an opt-in way to guarantee the trait would never add new non-`const` default methods. The other thing I would really want, for this though, would be a full effect system. Something like `default [const if other_func const] fn new_default_func`. Or any other system with the ability to have a default function only const if some other function is const. This might be best if designed in tandem with default groups (https://github.com/rust-lang/rfcs/pull/2532), I think. I don't have a concrete proposal, but I don't think this is impossible either. I was mostly wondering if you had any solutions in mind.
A system language that isn't able to handle 100 % of the required use cases will loose against the existing OS official system languages, regardless of your personal opinions. Same applies to macOS and IO Kit, Metal Shaders, XPC and other system level features.
So I'm a bit confused about that. Futures themselves are async, right? If so, what exactly does Tokio do for them?
&gt;This makes b'a' evaluate to 61 (once again pretty sure, someone correct me if I get the actual value here wrong). [Yes](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=adfa85e139bcfbec9dec46a17ce24993), if you mean 61 in hex. : p In decimal, it's 97.
Where can we find the stream? 
As a means to not only learn rust but also learn more about systems programming, I'm making a shell in rust while also using the nix crate. I've done this already in C, so my only issues lie in rust syntax. One question though: if the user calls \`exit(x)\`, how do I pass \`x\` through and call \`::std::process::exit(x)\`? I tried something similar to this: `match user_cmd { "exit({x})" =&gt; ::std::process::exit(x)}` But that obviously doesn't work. 
I haven't pushed this set of changes to Github yet, but never mind. Doing it this way works but it triggers a logic error. If `poll` returns `Pending`, the next call to `poll` runs the `Future` again *from the start*. I'm writing a database driver so my async code was sending requests to the database server. In short, previously successful requests were being resubmitted to the database over and over again, effectively DoSing the server. Hence the connection problems. I was worried that this might happen and this confirms it. I have to rethink my API. Thanks for your help.
&gt; which if I recall correctly Rust uses UTF-16 for its character encoding If you're talking about the `char` data type, it's UTF-32. Though strings are encoded as UTF-8.
Well, what does the locate program take? An array of patterns and a set of flags; it seems to me that the simplest function call should be (in Rust) `locate(patterns: &amp;[String], flags: u16) -&gt; Vec[String]`, or in C `locate(char **patterns, uint16 flags, char **found, int *count);`
This does indeed work, thanks. However, I don't know whether or not it's safe since it requires `unsafe`. In any case, I've discovered that polling async code from a poll implementation like this [can result in unexpected behaviour](https://www.reddit.com/r/rust/comments/ag06qq/manually_implementing_a_future_that_calls_an/ee2wd3r/) so I have to look for another way to accomplish what I want to do.
`'a'` is of type [`char`](https://doc.rust-lang.org/std/primitive.char.html) which is four bytes in size. `b'a'` is of type [`u8`](https://doc.rust-lang.org/std/primitive.u8.html) which is one byte. For a non-ASCII character, you can have `'â˜º'` but you cannot have `b'â˜º'` as it is not one byte. In that case you can have `b"â˜º"` which is the byte slice of the utf-8 representation of the character(s). In this example, the smiling face has codepoint `0x263a` and utf-8 encoding `0xe2`, `0x98`, `0xba`, so that `b"â˜º"` is the byte slice `&amp;[0xe2u8, 0x98, 0xba]`.
Wow, that is indeed a pretty gnarly signature! Thanks for sharing!
That sounds fun! What's the best way to get involved with Arrow development in Rust?
Thanks for the tip! Is there any specific document that you recommend reading?
Exactly my response. It turns out that paging technology has changed in the 30+ years since I learned about it! Who'da guessed? :-)
To start off, yes, `&amp;` in a pattern dereferences and copies. `BTreeMap&lt;K, V&gt;.iter()`'s items are `(&amp;K, &amp;V)`, so line 24 works because it is dereferencing the `&amp;K` into `K`. On the other hand, `Vec&lt;T&gt;.iter()`'s items are `&amp;T`. Your `updates` vector on line 30 is returning a `&amp;(Point, Point, Cart)`, so you'd have to put the `&amp;` in front of the tuple. However, there's another thing to keep in mind. The function parameter of `filter` adds another reference, so that you can filter without consuming non-copy types. On line 24, I think it works as-is because of some convenience rules, but to explicitly write it out would be `filter(|&amp;(&amp;p2, _)| p2 == new_point)`. On line 31 you have to double deref the tuple like `.filter(|&amp;&amp;(_, p2, _)| p2 == new_point)`, once because `iter` returns a reference and once because `filter` expects a reference.
Neat project. Please share a link when you can. :) Also, where are you getting that 85% performance figure? Is that your NFA against Rust regex's DFA? Also, beware of DFAs and large Unicode classes. :)
[Here's the diff in Godbolt](https://godbolt.org/z/lQOlcI), just because I was curious and I enjoy using it for this sort of thing.
I just posted my first crate, dlarm the alarm for [dwm](https://dwm.suckless.org/). I'm just getting started with rust, so I would greatly appreciate any feedback anyone has on the style or substance of the code (and it's only ~200 lines). Also, if any of you use dwm, please let me know if you have feature requestsâ€”this is very much v0.1.0 of the crate and I'm happy to add more (while staying minimalist, of course)
I've just re-uploaded the course and all associated content to [https://cs140e.sergio.bz](https://cs140e.sergio.bz). Enjoy!
Both of your examples can be worked around in Rust (because the allocation is explicit), but not in C++ (because the allocation is implicit/invisible). For your first example: `dyn Generator` does not imply an allocation, unless you're putting it in a `Box` (in order to transfer ownership). If you're just passing a generator to a function that has `&amp;mut dyn Generator` as an argument, no allocation will happen. For your second example: Yes, `Vec` will require an allocation, because its contents must be `Sized`. However, there are other data structures like [DynStack](https://guiand.xyz/blog-posts/unboxed-trait-objects.html) that do not have that limitation.
As someone who is learning rust at a very slow peace... What the actual bananas is going on here?
I read the documentation for `get_result` [here](https://docs.rs/diesel/1.3.3/diesel/query_dsl/trait.RunQueryDsl.html#method.get_result). But it also appears in the error message, albeit cryptically: note: required because of the requirements on the impl of `diesel::query_dsl::load_dsl::LoadQuery&lt;_, Model&gt;` for `diesel::query_builder::insert_statement::InsertStatement&lt;Table, Values&gt;`
Using existential types, I'm giving names to unnamable types. Unfortunately, that only makes sense if you already understand how rust implements closures. Not just how to use them, but how they're implemented.
By reading chapter 2 of the book ;)
Thanks, that makes a lot of sense. I looked through a few different sections for an explanation but it wasn't very clear where that would be (might also help if I finally just read through the whole thing...). Will definitely give that section a read, though. I actually knew about filter adding a reference, and kind of wondered about that, since in the Vec, `filter(|(_, p2, _)| p2 == &amp;&amp;new_point)` doesn't work, while in the BTreeMap it does. It still feels really weird, in my opinion, considering I can do this `filter(|&amp;&amp;(_, p2, _)| p2 == new_point)` and `filter(|&amp;(_, p2, _)| p2 == &amp;new_point)` but not `filter(|(_, p2, _)| p2 == &amp;&amp;new_point)`, instead it must be `filter(|(_, p2, _)| p2 == &amp;new_point)`, so it's like the first dereference happens automatically, whether you want it to or not, and the corresponding `&amp;` just poofs into non-existance. But I'll get used to it now that I understand it at least.
Make a particle system. :D
A Future is just a type with a method that does some work and says if it has finished or needs to be continued later. Tokio adds the runtime that figures out when individual futures are ready to run again. For example if your future is reading from a TCP stream, the Tokio runtime uses system APIs like epoll to ask the operating system to tell it when there's data available on the socket.
I'm currently trying to write a hobby kernel as well. Did a bit of it in C++ until now, but I'm considering switching that project to rust now, mostly because - having the borrow checker is such a great thing - having a portable libcore (and collections once I have a heap) is much better than having to muck around with libstdcxx or ustl or something similar I'm still thinking about how exactly I'm gonna do this, but resources like your blog series are super helpful :) I kind of don't want to use the bootloader crate since I want to use GRUB and multiboot2, but I'm still thinking about how to integrate the early 32bit bootstrapping code. I also really appreciate that you reported the LLVM bug with the x86-interrupt calling convention :D
I'm trying to read in a line such as: 5 4 and store these two numbers into two different variables
Which I'm sure internally just calls transmute though.
As an interested party who absolutely has no relation to the project, what's impractical about ggez? :D
Nothing in computer science evolves very fast. It's just some fields like to reinvent wheels at a much faster rate than others. And generally, the less important is backwards compatibility, the more reinventing is done. OS must be extremely backwards compatible compared to other software, so reinventions happen there the least. At the other end of spectrum, you have frontend webdev.
Can you share code that you have tried, and any error messages you are getting? The best way to share code is the [rust playground](https://play.rust-lang.org/).
If you go with Unity, could you write up a post or such about how it goes? ... actually, please do it either way. I don't feel like Amethyst has enough user stories.
What do you mean by terminal prompt? If you're looking for something like readline, check out rustyline.
I've written compilers and spent five years in higher academia and I still only actually understand about 3/4 of that. But what I do understand sounds like the intersection of awesomeness and madness. Keep it up. :D
Something like [inquirer](https://www.npmjs.com/package/inquirer) [Example](https://cdn.rawgit.com/SBoudrias/Inquirer.js/28ae8337ba51d93e359ef4f7ee24e79b69898962/assets/screenshots/list.svg)
Not so much these days, afaik. A lot of the broad strokes are pretty well worked out, and since people are now used to things working that way it doesn't change fast. Similar to how you can probably get into a car from the 1950s and drive it mostly ok. The research and progress is mostly in the fiddly details, which add up over decades. Also, the osdev wiki is great for intro stuff and broad concepts imo, but for technical details you are indeed better off with technical manuals. The associated IRC channel is full of smart and interesting people though. I need to start playing with osdev again.
This example does floats but it should get you started. If you look at commits in the lc3 branch you can see step by step live coding. https://github.com/focusaurus/rust-cli-basics/blob/lc3/src/main.rs
I added a small example; but I'd still love to see yours!
It *is* orthogonal, but the long and short of it is that if you have a program with reproducible builds you will want it's shared libraries to also be reproducible or else it defeats the purpose.
Yep
I found the issue: https://github.com/rust-lang/rust/issues/22590
[Yep!](https://docs.rs/static_assertions/0.3.1/src/static_assertions/assert_eq_size.rs.html#62)
So a Future is like a JS Promise while Tokio is like Async Await?
(reposted from last week) ORIGINAL TEXT FOLLOWS BELOW --- I have a struct `DirectoryChange&lt;'a, 'b, 'c&gt;`. I'm having a problem in `DirectoryChange::new`: pub fn new(old: &amp;'b Dir, new: &amp;'c Dir) -&gt; self::Result&lt;Self&gt; { /* omitted for brevity */ /* Dir::get_directories(&amp;self) -&gt; Vec&lt;&amp;Dir&gt; */ let os_dirs = old.get_directories() .into_iter() .collect::&lt;BTreeSet&lt;_&gt;&gt;(); let ns_dirs = new.get_directories() .into_iter() .collect::&lt;BTreeSet&lt;_&gt;&gt;(); let created_directories = ns_dirs.difference(&amp;os_dirs) .map(std::ops::Deref::deref) .collect::&lt;Vec&lt;_&gt;&gt;(); /* omitted for brevity */ } I am getting the error: error[E0495]: cannot infer an appropriate lifetime for autoref due to conflicting requirements --&gt; src/lib.rs:58:27 | 58 | let os_dirs = old.get_directories() | ^^^^^^^^^^^^^^^ | note: first, the lifetime cannot outlive the lifetime 'b as defined on the impl at 47:10... --&gt; src/lib.rs:47:10 | 47 | impl&lt;'a, 'b: 'a, 'c: 'a&gt; DirectoryChange&lt;'a, 'b, 'c&gt; { | ^^ note: ...so that reference does not outlive borrowed content --&gt; src/lib.rs:58:23 | 58 | let os_dirs = old.get_directories() | ^^^ note: but, the lifetime must be valid for the lifetime 'c as defined on the impl at 47:18... --&gt; src/lib.rs:47:18 | 47 | impl&lt;'a, 'b: 'a, 'c: 'a&gt; DirectoryChange&lt;'a, 'b, 'c&gt; { | ^^ = note: ...so that the expression is assignable: expected std::vec::Vec&lt;&amp;'c dir::Dir&gt; found std::vec::Vec&lt;&amp;dir::Dir&gt; I think that the problem is that `BTreeSet::difference` uses a late bound lifetime argument in the form `pub fn difference&lt;'late&gt;(&amp;'late self, other: &amp;'late Self) -&gt; Difference&lt;'late&gt;` edit: I believe the problem is that Rust infers `'late` to be `'c` not `'a` Is there a way to fix this?
Sort of, but not really. Futures only describe a task to be executed. Tokio provides things called _executors_ that will allow you to actually _run_ futures. So if there isn't an executor running, the futures are just sitting around, not being executed. But if it is running, they will be used like a promise, run concurrently.
I wasn't aware before, but it seems like rust has some form of reference collapsing. I can't seem to find any documentation on it. [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=7be3edc1d39d124f81f27cc300fc9a8a](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=7be3edc1d39d124f81f27cc300fc9a8a) I'm not exactly sure this is the same sort of thing happening in your example but its interesting. Btw, an easy way to test the type of something is to assign it like \`let \_: () = p2;\`, and then when you compile it will tell you that \`()\` is the wrong type and it should be whatever \`p2\` is. Of course, if you have RLS set up with your editor you can also just hover over it.
&gt; This feature [user accessible flag] can be used to make system calls faster by keeping the kernel mapped while an userspace program is running. May I ask why system calls can be faster in the presence of kernel page mapping in userspace programs?
It makes sense that the code would be different. The two versions have an observable difference when i+n overflows usize. The two index operations version sidesteps the overflow case by splitting the out-of-bounds check into two operation.
Looks fun, but I'm very confused. Why does the c in the second move not need a type constraint but b does?
That example doesnt read them from stdin though, it reads the from the arguments to the process.
Here's another program that reads from stdin: https://github.com/focusaurus/cody/blob/5c7c4e095aaa576adfc3776c29eb089f3e025513/src/main.rs#L14 Sorry I had already replied before I re-read your post and realized you wanted stdin not args. Was on phone and couldn't be bothered to repost right away.
`b'a'` is a u8 containing the ascii value for the character `a`. &gt; A byte literal is a single ASCII character (in the U+0000 to U+007F range) or a single escape preceded by the characters U+0062 (b) and U+0027 (single-quote), and followed by the character U+0027. If the character U+0027 is present within the literal, it must be escaped by a preceding U+005C (\) character. It is equivalent to a u8 unsigned 8-bit integer number literal. â€”https://doc.rust-lang.org/reference/tokens.html
It lets you see what a file with macros gets expanded to.
who downvoted me, I love Rust.
r/playrust
Okay so it's lower level then... And what is the difference between futures and threads? I'm a bit confused about an event loop vs threads. So you use both? Are they two totally different use cases?
Instead of `BuildTag{}.get_build_timestamp()`, `BuildTag.get_build_timestamp()` should work, I think. Which is neater. Using custom derive for this seems like a bit of a hack. Custom attributes and function style proc macros are stable in the latest Rust version; one of them might be better. I'm not sure what would be the best practice for this... 
It's great, but frankly, for an explanation of modern OS and hardware interaction the section on segmentation is mostly a distraction. The x86 segment registers are irrelevant in x86_64, the explaination of them is incomplete for understanding x86, and if you want a general overview of segmentation in the abstract the x86 segmentation model is awful anyway and you're better off not talking about it at all. :/ :/
You could try something like this: fn main() { let cin = std::io::stdin(); let mut s = String::new(); cin.read_line(&amp;mut s).unwrap(); let values = s .split_whitespace() .map(|x| x.parse::&lt;i32&gt;()) .collect::&lt;Result&lt;Vec&lt;i32&gt;, _&gt;&gt;() .unwrap(); assert!(values.len() == 2); let var1 = values[0]; let var2 = values[1]; println!("var1: {}, var2: {}", var1, var2); } If you don't understand how it works, the [second chapter of the book](https://doc.rust-lang.org/book/ch02-00-guessing-game-tutorial.html) builds a little program that has to deal with I/O, and it explains some of these things in more detail.
That is not safe (in terms of it will lead to memory corruption if the async function actually makes use of !Unpin and does cross await borrows). If a pin is handed to a poll function, the reference in the pin must never ever move again. Since in this example the pin is created on a stack address, it wonâ€™t hold up to that guarantee, and might be different the next time poll is called. However there is another issue, which prevents this issue from being visible: The future is actually not sores between poll invocations, and would always be destructed after the first poll call. Whether it returns ready or not. That means complex async functions might never. And it across the first await point. The reason why it works in this example is that the function doesnâ€™t await anything and is always ready. A solution which should work is storing the future that the async fn returns inside a boxed future inside the wrapping future, and call poll on that. 
So threads are actual, OS-level threads, at least in Rust. They're not green threads or anything. Event loops will process events as they come. Executors are event loops. What executors do internally looks something like: while (true) { do nothing; if a future awakes { check state of future { ready(some value) =&gt; run queued actions not ready =&gt; continue loop } } } where queued actions are things like `.and_then`, `.then`, `.map`, etc.
[https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=ce17f46409da5603d47849230d915447](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=ce17f46409da5603d47849230d915447) No `for` loop, but you get your vector of Strings anyway. More documentation about `BufReader` here: [https://doc.rust-lang.org/std/io/struct.BufReader.html](https://doc.rust-lang.org/std/io/struct.BufReader.html)
I'm working through this series as a pure hobbyist and I've already learned so much from it. Certain things have gone far above my head but I suppose that's part of the learning process. 
I'll give you a follow ðŸ˜Š
[Are we async yet?](https://areweasyncyet.rs/) Two recent posts from withoutboats: - [What does a waker do?](https://boats.gitlab.io/blog/post/wakers-i/) - [Waking across threads](https://boats.gitlab.io/blog/post/wakers-ii/)
What's the double :: syntax do before the function call? 
twitch.tv/walterpi
&gt; I am not sure about this, but I think having a &gt; Mutex &gt; in a future is a antipattern because it could stop the entire "event" loop if the &gt; Mutex &gt; is locked from another place. For very short operations (like inserting something in a vector) using a `Mutex` is in most scenarios fine. The task and eventloop would block only for a view nanoseconds. Other interactions in the futures ecosystem (e.g. with a channel or executor) might also involve Mutexes under the hood. 
Hovering over it is what I do, but what really threw me was not realizing the implicit &amp; before the whole tuple, especially knowing that in filter I should be getting &amp;&amp;. Also the error message when you write it incorrectly as `filter(|(_, &amp;p2, _)|` is only somewhat accurate, as it says it expects a Point (not &amp;_), which makes sense, but then suggests using `p2: &amp;Point` which is just invalid syntax. I actually knew about the reference collapsing as well. I think one day I noticed I was passing a &amp;&amp;T from a filter into some other fn expecting a &amp;, and was surprised that wasn't an error. You can seemingly collapse as many &amp;'s as needed (down to 1 at minimum), but cannot implicitly add references the same way. I decided the reason was that collapsing a &amp;&amp; to a &amp; (even recursively) is just cpu cycles, but building a &amp; to a &amp;&amp; actually requires space in memory for each additional reference, and therefore can't (or, won't\shouldn't) be done implicitly. I have no idea if this reasoning actually has anything to do with this behavior being in the language.
It's funny, I just got done building a similar tool for my media collection, also to better learn rust!
I would suggest: 1. Join the dev@ mailing list ([http://mail-archives.apache.org/mod\_mbox/arrow-dev/](http://mail-archives.apache.org/mod_mbox/arrow-dev/)) and introduce yourself 2. Checkout the current code and run the Rust examples ([https://github.com/apache/arrow](https://github.com/apache/arrow)) 3. Look at the open JIRA issues ([https://issues.apache.org/jira/browse/ARROW-4263?jql=project%20%3D%20ARROW%20AND%20component%20%3D%20Rust](https://issues.apache.org/jira/browse/ARROW-4263?jql=project%20%3D%20ARROW%20AND%20component%20%3D%20Rust)) and see if anything looks interesting to you 4. Try and use Arrow for a use case that interests you and report bugs and/or submit PRs for fixes + improvements This is a great community and we would welcome new contributors!
That's actually a compound syntax with the `&lt;str&gt;` bit, to prevent a parsing ambiguity which might otherwise read `f&lt;str&gt;("a")` and parse it like a chained comparison: `f &lt; str &gt; ("a")` If you're asking what the whole `::&lt;str&gt;` bit does, it's explicitly specifying the type of the `Q` parameter. You shouldn't normally need it in a case like this where the type information is available from the `"a"` argument, but it's useful for calling a generic function that's expected to produce a value itself: fn foo&lt;T: Default&gt;() -&gt; T { T::default() } let val = foo::&lt;u32&gt;(); println!("{}", val); // prints "0"
It specifies a generic type of the function. For instance, the parse() method on &amp;str takes a generic type as part of the function signature. https://doc.rust-lang.org/std/primitive.str.html#method.parse So you could call that with either `let x = my_str.parse::&lt;i32&gt;();` or `let x: i32 = my_str.parse();` which is the exact same thing. You can similarly call a method like `Vec::new` like either `let v = Vec::&lt;usize&gt;::new();` or `let v: Vec&lt;usize&gt; = Vec::new();` Although in many cases you don't need them since the compiler is pretty good at figuring out what you want on its own based on other argument or return types.
This could be simplified a bit, like this &amp;#x200B; https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=199e6992238873014dd8180c5964bdf8 
That was a relic from when I tried to get 2 arguments of different types to work. When switching to all the same type, I just left the type constraint and changed it from `B` to `A`. It's completely unnecessary in this version.
So you were able to get different argument types to work! Thank you! Now I want to try compiling an ML-like syntax to this kind of Rust.
FYI, I'm proposing using Signals to a certain extent. They are similar to Qt's signals in design alone, not implementation. This means things like mouse enter, exit, click signals will be implemented as algebraic data types (enums) and widgets can easily override them, implementing their own versions of whatever slot mechanism they want. They'll most likely just be FnOnce calls, I'm still working on the design.
On mobile here. Ugh. Sorry for formatting. I wonder if anyone will take issue with my comments. 1. I could see there being an enum for cmd in the Args struct instead of three bools. 2. naming_function could pattern match with 'match' rather than all the if and else if's. 3. I'm curious about all the let name's at the bottom. Better to have one let mut? Something else? That said, I'm impressed!
We create a type named `Curried` that can wrap a function (`F`). In this case, we wrap `f64::mul_add`. We give `Curried` an extra trick if `F` takes three arguments of the same type. Rewritten in pseudoRust, with potentially fewer type parameters: impl &lt;Arg, Func&gt; FnOnce&lt;(Arg,)&gt; for Curried&lt;Func&gt; // Curried can be called as though it was a function that takes a single parameter of type Arg where Func: FnOnce&lt;(Arg, Arg, Arg)&gt; { // in cases where we're wrapping a function that takes 3 args, all of type Arg fn call_once(self, (a,): (A,)) -&gt; impl FnOnce(Arg) -&gt; impl FnOnce(Arg) -&gt; Func::Output { // This isn't valid Rust syntax. It's closer to Haskell, but it's what we want to express // The parameter `a` passed in to `call_once` is our first argument move |b: Arg| // This closure is our return value; when called, it provides us with our second argument move |c| // And the `b` closure returns this closure self.0(a, b, c) // We finally have enough arguments to call the function, so do so. } } The problem there is the return type from the function. It's invalid Rust, so we need to find a way around it. The first thing we do is defer naming the type to an associated type named `Output` fn call_once(self, (a,): (A,)) -&gt; Self::Output { ... } The next step is where things get trickier, and we need to rely on existential types. The problem is that we *can't* give a proper name to the type of the closure that we return. Closures in Rust are implemented using structs to hold the closed-over values, and don't have proper names. What an `existential type` does is lets us give these types a nickname so we can refer to them later, and the compiler will know what we're talking about. The way we do that is by first telling the compiler defining characteristics of the type (i.e. what traits it satisfies), and then using the existential type in a context where the compiler can connect it to a concrete type. This is important, since multiple types could satisfy our constraints, but we want the type we just named to refer to only a single type. Here, we have existential type Output: FnOnce(Arg)-&gt;CurriedTwice&lt;Arg, Func&gt;; which says "There's a type that we're going to call Output. It can behave like a function that takes an argument of type Arg, and returns a `CurriedTwice&lt;Arg, Func&gt;`", `impl FnOnce(Arg) -&gt; CurriedTwice&lt;Arg, Func&gt;`. Then, when we refer to `Output` on the next line as the return type of the function, the compiler can check that the value returned satisfies these constraints. What's `CurriedTwice`, then? It's defined a few lines earlier as existential type CurriedTwice&lt;Arg, Func: FnOnce&lt;(Arg, Arg, Arg)&gt;&gt;: FnOnce(Arg)-&gt;Func::Output; which looks worse than it is, and is probably clearer if written as existential type CurriedTwice&lt;Arg, Func&gt;: FnOnce(Arg)-&gt;Func::Output where Func: FnOnce&lt;(Arg, Arg, Arg)&gt;; moving the type constraint on `Func` out of the way. This just says that there exists a type `CurriedType` that should be callable with a parameter of type `Arg`, and return a type that matches the output type of a function that can be called with three arguments. These constraints are met by the `move |c| self.0(a, b, c)`. Ignoring the type parameters a bit, this is kind of like giving a formal name to `impl FnOnce(Arg) -&gt; Func::Output`. Substituting it back into the definition for `Output`, we get `impl FnOnce(Arg) -&gt; impl FnOnce(Arg) -&gt; Func::Output`, which is how we described the return type of `call_once` in the pseudoRust above. Hopefully this makes things a bit clearer. Existential types are actually really handy since not only does it let you name unnameable types, but it also lets other parts of the code use your names, and be confident that they're referring to the same types as you.
[Are we async yet?](https://areweasyncyet.rs/)
It seems that you need a dlarm process running in background to trigger the alarm. Did you consider using [at(1)](https://linux.die.net/man/1/at)? &gt; future plans include allowing for current-time relative alarms (e.g. dlarm --set +25 to set an alarm for 25 minutes from now) You can use [humantime](https://docs.rs/humantime/) to support more ways to write durations.
I would prefer for this to look like: use rbtag::{build_commit, build_timestamp}; fn main() { println!("commit={}", build_commit!()); println!("timestamp={}", build_timestamp!()); } similar to [`file!()`](https://doc.rust-lang.org/std/macro.file.html) where the invocation expands to a simple string literal.
I really should. But given the limited hours I have, Iâ€™ve been spending them on making progress over writing. So the client in this case can be really dumb. The rules engine on the server will handle all rules and provide state and changes to the client and even a list of all possible moves. So all it has to do is present those to the user and offer a good way to interact. 
Kyosuta gave a much clearer and better version that simply defined a function rather than a wrapper type that implements `FnOnce` manually. They also managed to get different parameter types to work.
Great blog. Can't appreciate enough to make this material available for free.
This is the best blog ever. 
Hi, I really like this crate and use it in command-line tools, it's very pretty. &amp;#x200B; but there is an issue when I copy this program to another machine and run it. the styles is shown as followed. I run it in same secureCrt. I don't know what issue is it.
Thanks!
I am a fairly new Kakoune user, and I was discussing some details of `x`/`X` handling in Kakoune with its author. To demonstrate my ideas... I basically wrote a simple kakoune-like text editor in Rust. Note: tons of important things are not implemented. But you can open a file and move around in a kakoune-like modal way. I post it on r/rust, just in case anyone is interested in collaborating / playing with the idea.
I really like this crate and use it, it's a very pretty crate. but I have an issue that the style isn't good working when I copy my tool to another machine. the issue is shown as followed, and I don't know how to fix it, I log in both machine by same secureCrt and run it. here outputs **$&lt;2&gt;** on new machine. &amp;#x200B; \+-----------+------------------+-----------------------------+ | Ratign Tariff **$&lt;2&gt;** | \+===========+==================+=============================+
Downvoted. This was posted here a month ago. If you search for `va_list` on this sub, you will get it among the top hits. 
Embedding build dates into the generated code is exactly what we shouldn't be doing, since that breaks reproducible builds. See [ripgrep (a Rust project) achieving reproducibility](https://www.reddit.com/r/rust/comments/afscgo/ripgrep_0100_is_reproducible_in_debian/) [Reproducible builds](https://reproducible-builds.org/) A git commit hash as a substitute for the build date is perfectly good, however. See also [git describe](https://git-scm.com/docs/git-describe) which gives you a string like "T-N-H", where T is the latest tag on the branch, N is the number of commits since T, and H is an abbreviated hash. That's a decent way of naming development versions, IMHO.
Can you provide a playground example? Without having your type definitions and parts that were "omitted for brevity" I cannot replicate the error myself.
Do you have any good project examples?
Note that `test::black_box` is also a fudge, just using `asm!` instead (and using it in a way that likely results in a write anyway).
If kernel pages are mapped in the userspace program you don't have the extra overhead of loading them every time you switch back into the kernel and then dropping them and loading the userspace mappings when you switch back out.
RLS compiles in clippy, but will use the same version. The rust-lang/rust build uses the clippy git submodule for both. It depends on your code, but perhaps the difference comes from enabling --all-features etc differing from the rls config. Also enabling the `clippy_preference` rls config may help for workspaces.
I've never watched the screencasts, but I browsed the screencast catalog and it would certainly not pay 29$ per month for this content. &amp;#x200B; [https://www.destroyallsoftware.com/screencasts/catalog](https://www.destroyallsoftware.com/screencasts/catalog)
[`SOURCE_DATE_EPOCH`](https://reproducible-builds.org/docs/source-date-epoch/) would fix the problem with build timestamp. However I don't think that having a timestamp provides much value to anyone.
I wonder whether you can come up with a virtual memory and paging scheme on modern hardware in the spirit of ye olde exokernel. Ie do just enough to securely multiplex the underlying resources, but don't provide any abstractions in the OS kernel. All abstractions should live in eg unprivileged library code.
irc channel is simply not active whenever I connect there's no one active 
Perhaps practical is not the best word to use, 'production' would be more appropriate. I personally couldn't find an elegant way to get transitions between states (e.g. when trying to make a main/pause menu). This isn't a unique problem to me ([case in point](https://dale.io/blog/rustris-post-mortem.html) who edited the source of `ggez::event` to do such a thing), but it may be a bit outside the scope of ggez. I liked how quick it was to get started with it, which makes it ideal for game-jams etc. but now that I have a good idea of how the code in the back works I can invest more time into getting a more complex, but ultimately more powerful engine like amethyst working for me, which will result in a more polished-looking game.
&gt;... so once itâ€™s confirmed to \*\*match the C++ code\*\* ... &amp;#x200B; [sss\_dragon.png](https://www.janwalter.org/assets/sss_dragon.png) &amp;#x200B; The image rendered by **Rust** matches the C++ version 100% :star\_struck: &gt; imf_diff sss_dragon.png ~/Graphics/Rendering/PBRT/pbrt-v3-scenes/sssdragon/f15-7.png sss_dragon.png /usr/people/jan/Graphics/Rendering/PBRT/pbrt-v3-scenes/sssdragon/f15-7.png: no differences. == "sss_dragon.png" and "/usr/people/jan/Graphics/Rendering/PBRT/pbrt-v3-scenes/sssdragon/f15-7.png" are identical The **scene** can be downloaded from [here](https://gitlab.com/jdb-walter/rs-pbrt-test-scenes/wikis/pbrt-sssdragon) (`pbrt/sss_dragon.tar.gz`) ...
Thank you !
Is there an ide that allows ctrl+click navigation to definition? Particualry into rust's libstd. vscode can't do this.
You mean its super-annoying behavior on empty lines?
Don't hesitate to ask if something is unclear!
Just as a curiosity, is there something fundamentally hard about the shape of the cursor? Personally it doesn't seem like that big of a feature, but from the title it seems like the selling point if this editor.
At first I thought the title was a pun targeted at async/await and futures ðŸ˜‚
It's still useful since, the last link was to the slides, not the video. 
It's still useful since, the last link was to the slides, not the video. 
Since this is a CLI application the [https://rust-lang-nursery.github.io/cli-wg/](https://rust-lang-nursery.github.io/cli-wg/) has the state of the art way of building your cli application, for instance args parsing using the recommended crate (structopt) is miles better than what you are using as it generates help text as well. There are a bunch of instructions on how to write tests as well which is IMO the biggest flaw in your app. &amp;#x200B; That said, nice work :)
Neat! Curious to hear why you didn't build this on top of [Xi](https://github.com/xi-editor/xi-editor/issues/302).
I wrote that section mainly to introduce and motivate virtual memory first, before introducing the more complicated paging related concepts later. Yes, segmentation is no longer relevant on x86_64, but I like to start with the simple solution, explain its problems, and then introduce the advanced solution that solves them. I used the x86 variant of segmentation because there are still some parts of it left in 64-bit mode, mainly the segment registers. We saw them in the "Double Faults" post and we will use `fs`/`gs` in a future post for implementing thread local storage. But I'm open to a different example of segmentation. Do you have any recommendations?
That sounds fine. And good luck. Iâ€™ve had no end of trouble trying to grok GUI libraries and how to set it up properly in Rust without needing to have tons of wrappers or weird global data layouts or something. Iâ€™m okay with signals for the most part, actually. Just learning it in the first case was weird because of the magic hand-wavy nature of how Qt does it (using an internal callback mechanism or whateverâ€”Iâ€™m more used to supplying the callback function more like event delegates or subscription).
Does anyone familiar with Async Iterators understand the magnitude of work that is required to enable them? Is this a 12-month, 1 FTE assignment?
How does he know that there is leadership fatigue? 
I never had that experience
Same thought.
Thank you all for your kind comments! This post was a bit experimental as it mainly explains OS theory and only contains very little code, so I'm very happy about the positive feedback :).
*hovers over the "Wrong sub" button* Wait a secondâ€¦
A reference to the unexpected (to me, anyway) departure of Steve Klabnik, perhaps?
There is a lot of simple stuff that makes that non-trivial. For example, the easiest way to generate usable debug-info is to just "link" each line of assembly to a source file in your machine. If the path of the source file changes, the binary changes, so if you want reproducible binaries with debug info, then you need to do something cleverer. Basically, creating binaries that do not have any kind of hard-coded path, time, etc. in them can be done, but it isn't super straightforward, nor a good default. 
At first I thought you were confusing the language with that survival game. But its actual rust code. So... what game is that?
I agree, that is cleaner, I'll see if it's something I can implement.
I 100% forgot about the reproducibility. This is a really going point. luckily, if you don't call get_build_timestamp() it shouldn't effect the build. I might consider what /u/mtaon suggested and use the git commit timestamp
Thanks for you explanations! It makes a lot of sense.
Oh, my bad then. Un-downvoted and upvoted, then. That's indeed useful. &amp;#x200B; Sorry about the noise.
Yeah it's prey, great game too
You actually made me spit out my tea in laughter.
I know optimizing Compilation Speed is a long trip, but I want it the best. Really exciting to see performance improve on each release: https://perf.rust-lang.org/dashboard.html
Works for me reliably with `alt+click`. Whether it's a crate-local definition or from an imported crate like `std` or from `crates.io`.
So, I guess this is as good as any occasion to ask: &gt; Rust is radically open for participation, and this is a wonderful thing in many cases. However, this year it has become increasingly obvious that the Rust leadership is starting to feel the effects of managing a radically open project while still delivering features and growing the community. What do people mean with things like "radically open"? Because lots of languages are equipped with a certain degree of community involvedment, and with the ability for outsiders to make proposals. To me, it seems quite hard sometimes to get your point in there, acknowledged and accepted as real and not made up. I know Rust was once very community involved, Around 1.0 the community was very, very important and everyone knew this. But by now, it's no longer such a necessity and the teams no longer have to stand in the avalanche of comments. Disclaimer: I'm not assuming bad faith on anyone's part. But to me, there's friction and a certain systemic disfunctionality that's been there for years now. Though I'm quite relieved I'm not the only one who thinks like that.
I remember when this happened. It is the first use of rust in an AAA game.
How web APIs work changes every few years, as does the preferred architecture of website backends, as new tech becomes available for scaling and larger degrees of scaling become necessary. Web frontend changes weekly it seems, but web backend changes yearly just about.
So amazing to read this. I'm sad Rust is positioned as system language alone, and this myth is cultivated but rustaceants themselves.
Thanks for the link to humantimeâ€”that does seem like a great fit for including more ways to write relative durations. On the first point, unless I've badly misunderstood something, dlarm doesn't result in an extra running process. The typical way to set the dwm status line is with a running process that updates the status line every few secondsâ€”and it needs to run that frequently so that things like a clock can stay up-to-date. dlarm just hooks into that same process, so it doesn't add its own. (I guess it does add a very minor bit of overhead in terms of file IO and an extra conditional check in that process. at(1) could be a way of avoiding that overhead. But I don't *think* that overhead is noticeable enough to make any real-word differenceâ€”but please feel free to let me know if you think it would be.
Yeah, I mostly meant that you can still define `f :: a -&gt; b - c` with `f a b = a + b` instead of having to write `f a = \b a + b`.
I have written thousands of await's in C# and I never had to implement custom futures (`Task`-like objects in .Net, if you wonder), and it wasn't only echo servers you know. With async/await you can do combinators in 100% of cases and be happy with them. No need to implement custom futures ever.
Well, I don't \_know\_ that there is leadership fatigue, but it is my interpretation. Apart from the linked blog posts in the Rust2019-series (starting with withoutboats post and all the subsequent ones), I'e gotten the feeling from reading discussions on the RFC process, from discussions on working groups, from the co-key-note by Aaron Turon, Niko Matsakis, and Ashley Williams, from social media comments, and so on.
To be *that guy*, it's actually [a mention, not a use](https://en.wikipedia.org/wiki/Use%E2%80%93mention_distinction).
Does Prey use Rust in it's code or just reference it?
With radically open, I personally meant that most of the direction of Rust in practice is very much driven by open discussions without barriers to entry. I did not mean that everything was fully open, that everything should be fully open, or that the formal model is fully open, where by fully open I mean some for of participatory democracy (as opposed to the current model with actual formal decisions from a small non-open group of people). &amp;#x200B; I am not advocating for more openness, for less, or for keeping the current level. I am merely trying to make an observation that the current origanizational structure seems to be grinding lots of people down, and that is not sustainable.
Ah, I was sort of hoping to make it more punny, since I do think async and futures are hughely important.
I couldn't quite tell from the OP: does this stream have a rust focus or is it programming in general (maybe with some rust thrown in)?
Time to rewrite Rust in Rust!
Sorry for not making it clear. It'll be Rust only for the foreseeable future.
Sure, I can see that. I'm just unsure what's radical about it. &gt; With radically open, I personally meant that most of the direction of Rust in practice is very much driven by open discussions without barriers to entry. That one I have to slightly disagree with. I do agree that that's what the leadership wants, I just don't think it worked out fully in practice. I have seen discussions shut down more than once, bad faith assumptions made by leadership, even experienced "punishments" for disagreeing.
Very cool! That code is in *bad* need of rustfmt, thoughâ€”it looks like line 3 in the last block is indented ~3Ã— as much as the standard indentation (judging from the two lines above)
Those screenshots of the terminal output are syntax-highlighted, is cargo-expand doing that, or something else, or was it added after the fact? I'd love to have that in my terminal!
Your code looks good, nice! &amp;#x200B; As far as functionality goes, a pretty obvious feature would be using regexps. But I'd like to beat on a horse I've mentioned at similar projects in the past: Getting file renaming right is not easy. Here are some thoughts of mine: * Did you take care not to rename a directory before you rename the files in it? Otherwise, the result might be unexpected. * Note that \`std::fs::rename\` overwrites the target. Did you take care not to overwrite files unwarrantedly? * Take care, you might rename old1 to new1, and after that rename old2 to new1. * You might also rename old1 to old2, overwriting old2 before it could be renamed to new2. * The whole renaming thing depends on order, in particular wrt overwriting things. That's strikes me as an implementation detail that should not surface to the user. * In particular, files might be renamed "out of the way", so the operation as a whole might work if you discard the order you tried at first. * In my book, the second worst possible result (after losing data) is a partial operation, i.e. some files have been renamed, others haven't. Did you build in a way to recover from that? In particular in the face of a lot of files, this might be as bad as losing data. * The solution to the points above is probably compiling a list of old names first, then make a list of new names, check for problems, and then do the renaming using smart temporary names or something. I haven't thought this through, though. * This is a point where I definitely feelt that performance comes second after correctness. * Did you think about what happens if a string match is nonunique or even ambiguous? \`rename\` determines what happens, but I'm not sure it's the behavior people expect. * Things that modify file names need a \`dry-run\` option, and that should be the default. * Please bail out with an error message if you encounter any option you don't recognize (maybe docopt does this). I don't mean to be rude, but I'm being bitten a lot by command line tool from people that don't think enough about this :) &amp;#x200B; Oh yeah, one feature I'd think totally cool: Don't rename, but output a shell/batch/whatever script that does the renaming.
Traditionally, terminals always draw the cursor as a big block covering a single character, or maybe a small block covering the bottom half of a character, or a blinking underline, due to restrictions of early video hardware. It works well enough, but if you're used to GUI editors with a vertical-bar cursor, it can be a bit surprising. These days modern terminals support switching the cursor shape between block/underline/bar, but many terminal editors don't bother for reasons of backwards compatibility.
If you're building a separate langauge (as opposed to an embedded dsl) I'd advise not trying to embed the language type-system in the Rust type-system directly, since that leads to \[combinatoric explosions of boilerplate\]([https://github.com/jamii/imp/blob/3f442d30bd845a39f5cbeb7f5360529af068bc69/src/interpreter.rs#L660-L793](https://github.com/jamii/imp/blob/3f442d30bd845a39f5cbeb7f5360529af068bc69/src/interpreter.rs#L660-L793)) when implementing operators. It's much easier to store a type tag and some bytes, and cast at the point of need.
Thanks! The next post is already in progress and should be ready soon. 
Take a look at the first edition of the blog then. It uses grub and multiboot2. Instead of nasm you can use inline assembly to avoid the additional dependency, like it is done in the `stage_*` files in the bootloader repository. But be aware that there are some unexpected differences between nasm and inline assembly that can cause strange bugs.
How can I type alias a slice and add a `Sized` constraint? Currently I have something like the following: ``` type Statement = ...; type BasicBlock = Vec&lt;Statement&gt;; fn process(block: &amp;BasicBlock) { ... } ``` Clippy doesn't like that the function parameter type is a vector instead of a slice. But I can't just change the type alias to `[Statement]` because sizing information isn't available. I can silence clippy, but is there a better way to deal with this?
Just a reference. Some of the developers were fans and hang out on this sub sometimes
I don't think so. Prey is made on void engine which is based on id Tech 6. id Tech isn't open source but Wikipedia says it's in C++ and nothing I can find on it mentions rust
Another of those "what datastructure" question :) &amp;#x200B; I need to save highlight data for lines. It consists of a line number(u64), two column numbers (u8), and a highlight specification (Hl, a C-style enum value). I need to save \_a lot\_ of those, and performance matters. I can easily work under the assumption that two different highlights are disjoint (i.e. either the line number is different, or the column intervals don't intersect), and if helpfull I could put a bound on the highlights-per-line. &amp;#x200B; Here's what I need to do: &amp;#x200B; 1. Create it. It falls out naturally that I create the highlights in ascending order wrt to the lexicograpical ordering on (u64, u8, u8). I do know how many lines I have to deal with before creating it, but the number of highlights isn't clear (as noted though, I could put up a reasonable upper bound). 2. Update it. I get a range of line numbers. All the highlights for those lines need to be deleted. I get replacement lines, and the highlight data for the new lines needs to go into the structure. Note that I need to "splice" in the new data, i.e. the highlight data with line numbers higher than the last deleted line needs to be shifted upwards/downwards (i.e. if lines 1-3 are deleted and 10 lines are put in instead, all lines numbers beginning at 4 need to be shifted upwards by 7). 3. Read it. I get a range of line numbers, and I need to iterate over the highlight data for those lines. No particular order necessary. So, at first I tried \`Vec&lt;(u64, Vec&lt;(u8, u8, Hl)&gt;)&gt;\`, but that meant allocating a new \`Vec\` for each line, and that wrought havoc for performance when creating it. I've also tried \`BTreeMap&lt;(u64, u8, u8), Hl&gt;\`, which made creation feasibly fast (somewhat...), but updating was unbearably slow (note I need to modify the keys here). I'm giving \`Vec&lt;(u64, u8, u8, Hl)&gt;\` a shot now. &amp;#x200B; Any better ideas? I don't mind trying out things just for the sake of it, so if you have an idea, but aren't sure it's good, just let me know, I have time and curiosity :) Thanks for any pointers!
4 years ago Nice
This is so cool! I love Kakoune, it's my daily driver, but man do I want some things to be different. I've been waiting for the Xi editor to implement modes in hopes to emulate a Kakoune-like editor. I'll give this editor a shot! Though I'll have to figure out LSP before I can actually use it though.
Xi doesn't yet support mode editing that Vim/Kakoune need - so that would be my guess. I too am waiting for a Kakoune version of Xi, but based on some tickets, it seems not possible yet.
I looked the value up really quick and forgot to check the base. Thanks for the correction. 
So the char encoding is different than string encodings? That seems strange. So does that mean if I index a UTF-8 string I get a UTF-32 character? That doesn't seem very intuitive. Is UTF-32 compatible with UTF-8?
I don't think that it's possible to give unprivileged library code direct page table access without compromising the safety of the kernel. The problem is that page tables use physical addresses, so the userspace library could just map the kernel frames into its own address space and access them subsequently. Hypervisors solve this problem either through special hardware support (an additional layer of addresses: virtual -&gt; guest physical -&gt; hypervisor physical) or through a technique called _shadow page tables_, that simulate a similar thing.
I thought it used CryEngine, which is also what Wikipedia says. Even so, almost *certainly* no Rust involved.
Following the sys-info example, to parse only the first 13 lines you would do something like ``` for line in s.lines().take(13) { ``` For the other question, I'm not quite sure what you mean by "I can't seem to return the hashmap value into the field as anything other a[sic] str," but I assume that the value is in the hashmap as a `str` and you are trying to turn the value into one of the numerical fields in your struct? To do this, retrieve your value from the hashmap as a `str`, then do this: ``` let cores = map.get("cpu cores").unwrap(); let cores: u16 = cores.parse().unwrap() ``` (obviously you should eventually add better error handling than what I have there) You can also call `.parse` using the infamous turbofish: ``` let cores = cores.parse::&lt;u16&gt;().unwrap(); ``` Hope that helps!
First of all congratulations of being organized. Documenting all of this stuff is a big step to learn! It would be nice not only have categories but have tags as well. Because over time you will have a lot of pages and this is a easy way to find what you have. About the content, I am new as well, but seems to be ok. Depending on what do you want, you can separate the content in several more specific posts, more easy to find.
&gt;store a type tag and some bytes You mean a Rust Enum? Or how?
It's not `b'`, it is a `b` followed by the ASCII character `'a'`. `b'a'` is a **byte literal**. This is similar to a char literal (e.g. `'a'`), but the character is encoded in ASCII instead of UTF-8, and its type is `u8` instead of `char`.
You're prematurely optimising something that will be called infrequentlyâ€”possibly only onceâ€”so stop looking for the "fastest" way and start looking for a correct and easy-to-understand way. I would approach this by applying [derive\_builder](https://crates.io/crates/derive_builder) to your `CPUInfo` structure so that I can incrementally build the object before constructing it. Then I would write the ordinary code to open `/proc/cpuinfo` and read it line-by-line until I got the blank line at the end of CPU 0. (This assumes that I'm not wanting to create one `CPUInfo` per CPU.) For each line, I'd use `.splitn(2, ':')` rather than the `.split` in your example in case the value contained a colon, then `.trim()` on the results to get a key/value pair which I would then pattern-match on and update the builder. Something like this (untested, and error-handling elided!): #[derive(Default, Builder, Debug)] pub struct CPUInfo { ... } fn parse() -&gt; CPUInfo { let file = File::open("/proc/cpuinfo")?; let mut buf_reader = BufReader::new(file); let mut builder = CPUInfoBuilder::default(); for line in buf_reader.lines() { let line = line.unwrap(); let kv: Vec&lt;_&gt; = line.splitn(':', 2).map(|s| s.trim()).collect(); builder = match kv.as_slice { [ "model name", v ] =&gt; builder.model_name(v), [ "vendor_id", v ] =&gt; builder.vendor_id(v), ... any other fields you want to parse [ "" ] =&gt; break, // stop parsing on the empty line ... a robust parser may wish to look for other parsing oddities } } builder.build().unwrap() }
Make Rust host a Rust compiler and then you could compile Rust in Rust... IN Rust.
AFAIK, it's compiler code, so... check if it still needs it and PR? :D
Great stuff! I stream Rust as well, but I focus on game development
UTF-8 is backwards-compatible with ASCII, but not with UTF-16 or UTF-32. UTF-8 means that characters have different sizes: ASCII characters are always 1 byte long, other characters can occupy up to 4 bytes. This is also the reason why it is impossible to index the n-th character in a UTF-8 string in O(1). That's why Rust has iterators for UTF-8 strings. Many languages, like Java or Javascript, use UTF-16, but that has some issues: Characters _usually_ occupy 2 bytes, except some characters that need 4 bytes (emojis, for example). This means that UTF-16 needs more memory than UTF-8, but still doesn't always support O(1) indexing (if you do it anyway, you will run into problems with emojis).
In the English article, it clearly states id Tech 5 is used and I see no mention of CryEngine. "The game runs on Arkane's internal "Void" engine, as opposed to [Unreal Engine 3](https://en.wikipedia.org/wiki/Unreal_Engine_3) that was previously used in [*Dishonored*](https://en.wikipedia.org/wiki/Dishonored). The Void engine is based on [id Tech 5](https://en.wikipedia.org/wiki/Id_Tech_5), " The page for id Tech 5 lists Dishonored 2 but not id Tech 6 [But the art director says id Tech 6](https://www.gamereactor.eu/news/438783/Void+engine+allows+Arkane+to+push+the+boundaries+in+every+corner/). He could be confused but as an art director he should be close to the tools they use. I'm gonna try to email Arkane and see if they can clarify. 
What is you channel?
So I would assume UTF-32 always occupies 4 bytes which is why that's what is returned when you index a string. If it was any other encoding the size wouldn't be fixed and wouldn't be known at compile time. 
twitch.tv/walterpi
I'd say to use some sort of B-tree (linked leaves). I'm assuming that you might also need to change stuff within a single line and not only full lines, and that a single highlighting might go beyond line-endings (e.g. from `(line 1, col 5)` to `(line 3, col 20)`). I'd go for the following optimisations: With highlighting being disjoint, you can make the optimisation to have a `NoHighlight` highlight value. That way you don't need to store `(line, from, to, highlight)`, but only `(line, from, highlight)`. The former values `(1, 10, 20, red), (1, 30, 40, blue)` would then be `(1, 0, NoHighlight), (1, 10, red), (1, 20, NoHighlight), (1, 30, blue)`. You can use `(line, start_column)` as key into the tree and `Highlight` as value. You can use here, that tuples are compared from left to right, meaning that `(2, 1) &gt; (1, 100)` and `(1, 5) &gt; (1, 2)`. That way if you want to query the highlighting of lines 5-12, you make a range-query of the tuples (5, 0) to exclusive (12, 0). Create is trivial, normal B-Tree creation. For updating you need to: 1. Find the maximum leaf smaller or equal to your tuple 2. Update its length to the new value 3. Instead of deleting all overwritten leaves, update them with new values 4. Add new leaves for further highlighting or delete leaves, if there are more to-be-deleted leaves than there are new highlights 5. Update the start of the start of the next node correctly. For reading you need to find the maximum smaller or equal value, then follow the linked-list of leaves of the B-Tree until you find a larger one. Runtimes: Create: `O(n Ã— log(n))` with `n` being the number of highlights. Update: â‰ˆ`O(m Ã— log(n)` with `m` being the number of consecutive new highlights and `n` being the number of highlights in the tree. Read: `O(log(n) + m)` with `n` being the number of new highlights and `m` being the number of highlights in the section you're querying. 
what plugins do you have?
Thanks :) Is there a way to specify in what section a rust global is placed? (akin to `__attribute__((section(".foo")))` in C)
Thank you for the feedback. I will definitely start using tags and I like the idea of more focused posts. I appreciate you taking time to reply.
intellij Idea with its Rust plugin also supports this.
[I have no idea where you're getting this from.](https://i.imgur.com/8L0eCpe.png) From [Prey (2017 video game): Technical Development](https://en.wikipedia.org/wiki/Prey_(2017_video_game\)#Technical_development): &gt; **Prior to Prey**, Arkane had just released **Dishonored 2** which used the studio's internally developed **Void** game engine. [...] **[Prey] was developed using CryEngine 4**, an established third-party game engine, eliminating many issues related to performance. From a [PCGamer article on Prey](https://www.pcgamer.com/arkane-says-prey-will-be-flawless-on-pc-at-launch/): &gt; "Also it's a different engine, so the constraints are different. In the case of Dishonored, we created a new engine, really, even though it's based on idTech, most of it has been redone ... **In the case of Prey we're using the CryEngine**, so it's an engine that has already shipped things before. [...]"
Per your question about tail call optimization: Rust doesn't do it itself; it relies on LLVM for that. LLVM is pretty good about it in simple cases, but it's not hard to make it fall over and fail to recognize an optimizable tail call. One thing Rust was at one point planning to do was have an explicit alternate version of the `return` expression that would enforce tail call optimization at a higher level than LLVM (*e.g.*, in MIR); the `become` keyword is still reserved for this eventual purpose.
Rust (rls) `rust-lang.rust`
Oh, and I set `editor.multiCursorModifier` to `ctrlCmd`. When I reset it to the default, go-to-definition works with `ctrl+click`
I really wish big open source projects, especially the size of Rust, had some form of mentorship for people who want to partipate. Utopian or not, Rust will never be equal to Go without getting a larger adoption. In this case, it wouldâ€™ve been as simple as getting some quick feedback about your direction. I would welcome the worst feedback over silence anyday. If there was an issue that you claimed and it was referenced in your PR, then lame on the person who provided the accepted solution. They couldâ€™ve help nudge your PR along by either providing feedback or copying mainters that they approved of your solution. Keep trying. Sometimes itâ€™s like going to a bar for the first time. It feels awkward but people eventually recognize your face as a regular. If Cargo is your goto bar itâ€™s going to be crowded â€” so it might take time. Maybe try a smaller project next time? Thereâ€™s hundreds of smaller, really useful Crates, dying for contributions. 
We really need to make a mod for Rust-the-game that adds something like this...
Alas, no. I keep meaning to write up a good tutorial someday, but...
Thanks for your answer! Yes, the highlights do never cross line boundaries, I'll add it to the OP as well as another thought I had. Your optimization does make sense, but applies to all structures, that save this data. I've use a BTreeMap before, and updating was really bad. As far as I can see, updating requires modifying the keys, which isn't really possible, is it? I had to split off the map, and copy over the old keys into the new one, modifying them in the process. Did I miss something? I'll have to read the rest more carefully later, but wanted to throw this out ASAP :)
Is there a method for filling a mutable slice from an iterator? I'm unable to find one from stdlib. I'd imagine such a method would make sense because in some cases it's easier to code some optimisations in that way, instead of using a loop.
But https://github.com/rust-lang/cargo/issues/4497#issuecomment-399110405 Looks like ppl waited for half a year and decided to come up with a solution instead of waiting for you?
Not my full response, but for now, I am sorry. The team did not do a good enough job communicating with you, especially in not answering your question.
I finally made a pull request a month ago
Can't wait. These have been some of the most helpful and illuminating inroads into Rust in general and kernel work in specific that this very non-systems programmer has come across.
I'm not belittling your experience, but I'd like to say that progress is messy. Sometimes it's not your PR that gets accepted, but that doesn't mean that your contribution wasn't valuable. Your work may have been the inspiration for the PR that was accepted. In open source, I think that the normal rules of recognition don't apply. Because everything is free, it's enough just to know you helped make something, even if your name isn't on it. Thinking like this helps to feel like your work has purpose (it does!) and keeps you motivated and satisfied.
Yes, there is the [`link_section` attribute](https://doc.rust-lang.org/reference/attributes.html#miscellaneous-attributes) (see the [test case](https://github.com/rust-lang/rust/blob/master/src/test/codegen/link_section.rs) for examples).
I would like to quote /u/burntsushi from the last thread with tensions that was posted: &gt; Before piling more opinions on a topic that already has a plethora of them, I urge you to give Evan Czaplicki talk, ["The Hard Parts of Open Source"](https://www.youtube.com/watch?v=o_4EX4dPppA) a whirl In that same thread, OP had directly linked github comments of mine where I shared design concepts before the issue was subsequently closed. Yet, although there was a misunderstanding, I can fortunately say that in general the Rust members and contributors I've had the luck to witness have been incredibly welcoming and patient. It's unfortunate that your first attempt to contribute did not go as warmly as planned, and I would implore you to give it a second chance if you ever decide to. Another unfortunate part about this is that the timeline does appear to match up with the issues linked: the comment in the issue about your a progress was overlooked at first, but when you opened a PR, it was responded to in a day. The first comment was about the feature freeze, but the second comment asked you a series of questions, which were never answered. Months later (26 days ago) you post in the issue again asking about the freeze, and that's where a discussion with ehuss began with an explanation of another ongoing solution due to complications, where more questions were ignored. A couple weeks went by without before the PR was closed in favor of the discussed alterative solution. It does not seem possible to see the full picture from these issues, but does appear to be a few different miscommunications.
I would like to quote /u/burntsushi from the last thread with tensions that was posted: &gt; Before piling more opinions on a topic that already has a plethora of them, I urge you to give Evan Czaplicki talk, ["The Hard Parts of Open Source"](https://www.youtube.com/watch?v=o_4EX4dPppA) a whirl In that same thread, OP had directly linked github comments of mine where I shared design concepts before the issue was subsequently closed. Yet, although there was a misunderstanding, I can fortunately say that Rust members and contributors I've had the luck to witness have been incredibly welcoming and patient, often offering mentoring. It's unfortunate that your first attempt to contribute did not go as warmly as planned, and I would implore you to give it a second chance if you ever decide to. Another unfortunate part about this is that the timeline does appear to match up with the issues linked: the comment in the issue about your a progress was overlooked at first, but when you opened a PR, it was responded to in a day. The first comment was about the feature freeze, but the second comment asked you a series of questions, which were never answered. Months later (26 days ago) you post in the issue again asking about the freeze, and that's where a discussion with ehuss began with an explanation of another ongoing solution due to complications, where more questions were ignored. A couple weeks went by without before the PR was closed in favor of the discussed alterative solution. It does not seem possible to see the full picture from these issues, but does appear to be a few different miscommunications.
In addition to the fact that most of your comments on the issue thread and the PR seem to imply your solution isn't finished, you did in fact receive feedback from the maintainers. Eh2406: &gt; As someone without much of the background context, I would like to see more documentation. What dose it do? How can it be used? How can it be configured? &gt; If my guess about what this does, I'd love to see an extenuation that let us take a resolution bug report and tern it into a reproducible test case. You never answered this or added documentation. ehuss: &gt; At this time I think we'd like to experiment with index-related commands out of tree. He's telling you very clearly that they don't like your solution because they don't want this merged directly into cargo until they can experiment with it more. dwijnand &gt; Closing in favour of the conversation in #4497 and the out-of-tree experimentation in https://github.com/ehuss/cargo-index. Again, very clearly saying that they prefer this implemented as a separate crate until it is stable. I get that this feels bad that your first time contributing to open source didn't go so well, but in my opinion the cargo maintainers did nothing wrong. Remember that everyone involved is volunteering their time, not just you. If you want your contributions accepted, you need to complete them to the satisfaction of maintainers. Next time I would suggest gathering clearer requirements from maintainers before working on a PR for a new feature. Or since you're new to open source, maybe focus on smaller changes like bug fixes that are more easily accepted.
&gt; I really wish big open source projects, especially the size of Rust, had some form of mentorship for people who want to partipate. Utopian or not, Rust will never be equal to Go without getting a larger adoption. I'm confused why the comparison with Go. In 2016, Go had 750 unique contributors among their main repositories and 260 for the compiler. Rust had already reached those numbers at that time, currently being at &gt; 2600 contributors for the compiler alone! I found no newer numbers for Go, so the comparison is a little inaccurate, but for reaching even rank 300 in Rusts contributor list, you need 20 patches! (Sources: https://dave.cheney.net/2016/03/25/go-project-contributors-by-the-numbers, https://thanks.rust-lang.org/rust/all-time) Much in contrast, we have a _huge_ number of individuals to deal with. But let's also consider the Rust team is _smaller_ than the Go team when discussing our performance in this area. Yes, we need to always improve, but that won't work with the wrong context. Also, comparing to Go: they have pissed multiple full projects off big time by not taking their input into package managing systems and instead implementing their own, so I think they are a really terrible example to compare this situation to. To be clear: I don't want to take away from the OPs bad experience, I can very much understand the annoyance!
"Exokernel: An Operating System Architecture for Application-Level Resource Management" mentions some cool stuff they did about virtual memory. But I need to reread the relevant sections to get the details.
Wow, tons of new stuff in this release. The syntax changes are quite welcome and also the improved error messages. I can't think of any other language that cares so much about the user experience. 
Thanks for the pointer.
You're right that updating needs to modify the parents (which I failed to make clear in my comment in steps 2 through 4). Updating a single node in a B-Tree is still armortized only `O(log(n))`, thus changing / adding / removing `m` nodes results in `O(m Ã— log(n))` (armortized). Using std's `BTreeMap`, you'll likely need to first delete and then add new nodes, which has worse performance than a manual implementation. A manual implementation of a BTree is pretty hard to get correct, though, and even harder to also correctly include optimisations for batch-updates.
From a quick glance it seems like they're working with an architecture that allows software TLB miss handlers, i.e. does not do automatic page table walks. This is not possible on x86 unfortunately. 
Yes. You could think of UTF-8 as a "text encoding" and UTF-32 as a "character encoding." UTF-8 is not optimal if you want to think of a string as a sequence of characters, but it is optimal if you want to think of a string as an arbitrary block of text.
Thanks for looking! I think the idea to port to x86 for virtual memory might probably similar to theirs for securely downloading network packet filters into the kernel. (Google's native client might also have usable techniques.)
&gt; But I can't just change the type alias to [Statement] Why not? Is it used elsewhere as a Vec?
&gt;write programs that run without an allocator (Rust can only run with a different one, mind you) Nope, `no_std` programs by default do not have access to any allocator and there is a lot of crates which a written with `no_std` support in mind. &gt;precisely control memory alignment of structs We already have `#[repr(align(N))]` which [works](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=be06ca2431a5d1608436984f1ac72e86) on stable.
&gt; You want to do math with that? Lol have fun with impl Add&lt;Velocity&gt; for I suppose new conception on language level is overkill for this. It is possible create macro for this.
&gt;write programs that run without an allocator (Rust can only run with a different one, mind you) You are quite wrong here, `no_std` programs by default do not have access to any allocator and there is a lot of crates which a written with `no_std` support in mind. Also see [developments](https://github.com/rust-embedded) on the embedded front. &gt;precisely control memory alignment of structs We already have `#[repr(align(N))]` which [works](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=be06ca2431a5d1608436984f1ac72e86) on stable.
Sorry, I suppose I left some context out. I don't use them as a `Vec`, but I do want to pass around collections of `BasicBlock`. So, I have something like the following: ``` type BasicBlock = [Statement]; // Changed from: type BasicBlock = Vec&lt;Statement&gt;; fn first(blocks: [BasicBlock]) { ... } fn second(blocks: Vec&lt;BasicBlock&gt;) { ... } ``` Neither of these cases work because `BasiceBlock` doesn't implement `std::marker::Sized`: ``` error[E0277]: the size for values of type `[Statement]` cannot be known at compilation time . . . help: the trait `std::marker::Sized` is not implemented for `[Statement]` note: to learn more, visit &lt;https://doc.rust-lang.org/book/second-edition/ch19-04-advanced-types.html#dynamically-sized-types-and-the-sized-trait&gt; note: required by `std::vec::Vec` ``` On a side note, it looks like there's a couple issues to file here. The linked to document is effectively dead. And I don't think "seeing through" the type `BasicBlock` and reporting the error on `[Statement]` is intuitive.
Thanks for the link. I was following a nursey recipe at first, but then found that the book had it's own CLI example. structopt looks like a good alternative to docopt, I'll refactor into that soon. Also will try to figure out using temporary files to test.
This was a great project for me to work with, and I actually use it now!
Nice write-up. Will probably help lots of people trying to join the Rust community. After skimming, I could not see your "optimization" section mentioning `cargo run --release`. It's usually worth to check before deciding whether optimizations are really worth the time.
No, the enum is also pretty bad. I started with something like: ``` enum Value { Int(i64), String(String), ... } type Row = Vec&lt;Value&gt;; type Rows = Vec&lt;Row&gt;; ``` And then for efficient columnar representation I added: ``` enum Column { Ints(Vec&lt;i64&gt;), Strings(Vec&lt;String&gt;), ... } type Columns = Vec&lt;Columns&gt;; ``` But then I can't get an `&amp;Value` out of a `&amp;Column`, so I also need: ``` enum BorrowedValue&lt;'a&gt; { Int(i64), String(&amp;'a str), ... } ``` And when it comes to implementing operators for the language I end up with these huge pattern matches for all the way I can combine these types. And it's hard to make this extensible so that I can define new types within language. Plus having all of these pattern matches around gums up the inner loops. Instead, I found it much easier in the long run to erase the types in the storage layer and do dynamic checks in the outer loops of each operator: ``` type Database = HashMap&lt;String, Box&lt;dyn Relation&gt;); trait Relation: Any { fn size(&amp;self) -&gt; (i64, i64); fn get_column(&amp;self, column: i64) -&gt; Box&lt;dyn Column&gt;; } trait Column: Any { fn get_value_type_id(&amp;self) -&gt; std::any::TypeId; fn get_row(&amp;self, row: i64) -&gt; Box&lt;dyn Value&gt;; } trait Value: Any { } ``` Then you can easily write operators that just operate over boxed traits, or also add fast paths for specific combinations of types: ``` fn fast_add_column(a: Vec&lt;i64&gt;, b: Vec&lt;i64&gt;) -&gt; Vec&lt;i64&gt; { ... } fn slow_add_column(a: &amp;dyn Column, b: &amp;dyn Column) -&gt; Result&lt;Vec&lt;i64&gt;, TypeError&gt; { if a.get_value_type_id() != std::any::TypeId::of::&lt;i64&gt; || b.get_value_type_id() != std::any::TypeId::of::&lt;i64&gt; { return Err(TypeError()); } } 
Would these work? ``` fn first(blocks: &amp;[&amp;BasicBlock]); fn second(blocks: Vec&lt;&amp;BasicBlock&gt;); ```
Read the official rust book, nicknamed "The Book": https://doc.rust-lang.org/book/
The contents\_first option on WalkDir yields the contents of a directory before the directory itself, so this should take care of your first point. &amp;#x200B; Docopt does handle unexpected arguments. I'll verify structopt does too when I move to that. &amp;#x200B; As for most of the rest, there is no safety built into this application right now. Partial operations are possible, no "dry-run" is available. &amp;#x200B; One possible way to handle most of this is to consume the WalkDir iterator, while checking exists() on the files and directories. The documentation says this will return false if the entity doesn't exist OR if there are permission errors. So that could yield arrays of valid and invalid paths, allowing the user to decide if they want to continue. Could also be an opportunity for second chance yes/no and present statistics on the number of files to be renamed.
https://old.reddit.com/r/rust/comments/aft2xm/whats_everyone_working_on_this_week_32019/ee2wv7v/ /u/elfsternberg misplaced their reply
I don't think docopt will convert the commands into an enum, but I could certainly do that myself. Enums are new for me coming from Python, so I'm not as quick to use them. I also am now pretty sure I could use closures to avoid having my own struct type to pass to every naming function.
Your journey is similars to mine. Do you have the code open source? I'm also in the hunt for build a relational API and language. Maybe even join forces?
Glad you found the error. When writing `impl Future`s manually, it might help to write your futures as state machines. When something calls a future's `poll` the first time, the future does some initilization (e.g., `let mut future = foo();`) and then updates its internal state to reflect that it has completed its first state (e.g., `self.state = State::Initialized`). When something calls that future's `poll` the second time, it will see that it has already completed its first state and then execute its second state, after which it will again update its internal state accordingly. It continues to do this until it has completed all of its steps, at which points it finally returns `Poll::Ready(..)`. This prevents the same future from calling `foo()` multiple times and starting its internal operation over from the beginning. The compiler actually converts `async` functions into state machines like this, generally. I don't know if it will help you in this case, but it's a good way to go about writing future implementations manually.
Recently switch from VSCode. Very happy with the IntelliJ for Rust.
I'm not working on anything like this at the moment, I'm afraid. But I can still infodump :) http://scattered-thoughts.net/blog/2016/10/11/a-practical-relational-query-compiler-in-500-lines/ http://scattered-thoughts.net/blog/2017/11/22/staged-interpreters-in-rust/ http://scattered-thoughts.net/blog/2018/08/16/julia-as-a-platform-for-language-development/ https://github.com/jamii/imp/ http://incidentalcomplexity.com/ https://github.com/witheve/ Also, if you're ever in London I'd more than happy to grab a coffee.
i read it.Am confuse... Where i start writing my code?? any editor ??
Thank you for this information. I was having a hard time following all of the various threads about this. I was actually not expecting the tail call to be optimized, and was surprised when I did not get a stack overflow.
Let me shamelessly also point you to [\`built\`](https://crates.io/crates/built), which has similar functionality.
I love this blog. So damn interesting. Thanks for writing it.
Thanks for this blog series. Do you recommend these articles in a specific order to follow? I do see different categories e.g. \`bare bones\`, \`testing\`, \`exceptions\`, \`memory management\` and each contains a few posts.
Thank you, I will try using the release optimizations on both versions and see the impact. I had seen that cargo defaults to build the debug target, but had not looked at how to change this yet. I am definitely still learning cargo and the build environment in addition to the language.
Cool, I didn't know this existed before
Not currently in the plans, but there's access to OpenGL, so I may create an OpenGL widget that allows full control to the 3D libraries there-in without an overriding draw routine. Each widget may also be an OpenGL layer, that way the GPU can handle the rendering rather than software. I'm still toying with a few ideas.
Thanks for the recommendations, I am going to try these suggestions and report any success.
A Future is a thing that needs to be "run". A Tokio Reactor is a thing that runs Futures.
What amount do you mean with "a lot"? 10^4? 10^6? 10^9? And what memory overhead you expect compared to 16 bytes for `(u64, u8, u8, Hl)` for each highlight? 
`va_list` is arguably the single most horrifying aspect of C (which, on the whole, is a pretty good language for it's intended use cases under the design constraints at the time it was created). But nevertheless, it's great to be able to use this in Rust, since it is sometimes necessary when implementing C APIs.
Can you briefly describe why is that?
Makes me wonder how I managed to miss that... I'll correct it ASAP. Thank you for the heads up :)
There is the `derive_more` crate which contains just that, but it doesn't really help with the (bad) ergonomics of tuple structs.
Any editor you are comfortable with could work. When I began learning Rust, I mostly used the [playground](https://play.rust-lang.org/) to write small exercises along with the book and documentation. It let me avoid setting up tooling while grasping fundamentals. Eventually, I moved back to editors I was comfortable with: nvim on linux and vscode on windows. That said, everyone learns differently and prefers different tooling. Check out [https://areweideyet.com/](https://areweideyet.com/) for some overview of editor choices and supported plugins.
Thank you for your help! fn parse() -&gt; Result&lt;CPUInfo, Error&gt; { let file = File::open("/proc/cpuinfo")?; let mut buf_reader = BufReader::new(file); let mut builder = &amp;mut CPUInfoBuilder::default(); for line in buf_reader.lines() { let line = line.unwrap(); let kv: Vec&lt;_&gt; = line.splitn(2, ':').map(|s| s.trim()).collect(); builder = match kv.as_slice() { ["model name", v] =&gt; builder.model_name(v.to_string()), ["vendor_id", v] =&gt; builder.vendor_id(v.to_string()), ["cpu cores", v] =&gt; builder.cores(v.parse::&lt;u16&gt;().ok().ok_or(Error::Unknown)?), ["siblings", v] =&gt; builder.siblings(v.parse::&lt;u16&gt;().ok().ok_or(Error::Unknown)?), ["cpu MHz", v] =&gt; builder.cpu_mhz(v.parse::&lt;f32&gt;().ok().ok_or(Error::Unknown)?), ["cache size", v] =&gt; builder.cache_size(v.parse::&lt;u16&gt;().ok().ok_or(Error::Unknown)?), ["flags"] =&gt; break, // stop parsing at the end of cpu 0 } } Ok(builder.build().unwrap()) } This is where I've gotten but ... builder = match kv.as_slice() { ^^^^^^^^^^^^^ patterns `&amp;[]` and `&amp;[_, _, _]` not covered My assumption is because match is exhaustive. Do you think this is a correct assumption and if so how would I go about making `_ =&gt; do nothing,` nothing happen. If not what do you think I can do to fix it? &amp;#x200B;
Thank you for your help!!
[removed]
With all respect, I think Xi is solving problems that I don't really care about at all, at the cost of great complexity. I just want want to open couple KB files at most and have a pleasant editing experience. :) . I think people get so fascinated by Xi, because of it's technical fanciness, while Kakoune is beautifully showing that simplicity is the right way.
What do you mean by lossy ?
Check the wonderful [uom](https://github.com/iliekturtles/uom) crate
`cargo-expand` does that, using the awesome prettyprint crate!
For a very good (possibly comprehensive?) summary: https://rust-lang-nursery.github.io/edition-guide/rust-2018/index.html.
That at the center, yes. It annoyed me so much, I made a fork where I changed it: https://github.com/dpc/kakoune . But also the fact that it has so many weird key-bindings, focuses on selection instead of the cursor too much, and sacrifices (IMO) a lot to be get a little better Vimgolf score than Vim, which is something I don't care about at all. I just want it to be easy and natural to use. I typically do `llllllll` and don't feel bad about it at all.
depends on what you want to actually happen, but you could do `_ =&gt; continue` to just skip to the next loop iteration
It talks about it in the [Disclaimer section in the README](https://github.com/dtolnay/cargo-expand/blob/master/README.md#user-content-disclaimer): &gt;Be aware that macro expansion to text is a lossy process. This is a debugging aid only. There should be no expectation that the expanded code can be compiled successfully, nor that if it compiles then it behaves the same as the original code. Follow the README link to see an example of where it can go astray.
thanks :)
What game is it?
Bump to v0.2.0, which adds colorized output thanks to the great `colored` crate (It also adds unit tests with the `assert_cmd` crate and fixes an off-by-one error in guessing whether the user meant "am" or "pm" when they didn't specify) 
&gt; I'll give this editor a shot! Though I'll have to figure out LSP before I can actually use it though. Oh man. Breeze is nowhere close to run with LSP, sorry. It doesn't have even way, way basic things implemented yet.
/u/sasik520 I apologize. That is not the kind of experience we want contributors to have, and we did a poor job of communicating with you. I will do my best to improve my communication and coordination. The Cargo team has restructured quite a bit within the last few months, and I would really like to see Cargo make good progress this year. If you have any questions, please feel free to reach out to me. 
&gt; Terminals can do |-shaped cursors now, people! We don't have to use the blocky cursor anymore! Am I really the only one to figure it out? neovim supports cursor shaping for quite a while already.
First, thanks for taking the time and effort to contributing. I've also worked hard on contributions, only to have them refused for a variety of reasons. It stings. In every case with my rejected PRs, in the end I was able to see that the judgment was a good judgment, even if it means that my change wasn't accepted as-is, or even at all. Sometimes there is a decision-making process which has been going on for a long time, and when I show up I don't have that context. As someone who has participated in design processes, I can appreciate that it's difficult to find the right balance between informal discussions between a few people that know each other, and bigger discussions with a larger community. There isn't a single, obvious, best way to do this. Mainly, I try to assume good intent on everyone's behalf, unless or until I have evidence that someone really is acting maliciously. Fortunately, I've found that everyone in the Rust language design process has been *enormously* supportive of good design work and open communication, even if that communication system occasionally falters or fails. I have never encountered anyone that I thought was acting with bad intent. &gt; Silence for a couple of weeks because [...] This is frustrating, but it's also one of the most common reasons for communications failures in distributed and OSS projects. I would encourage you to write an occasional "ping" message, on something like a 4 or 5-day cadence. It shows that you're interested in pushing your work forward, that you're willing to wait until the appropriate time, and it helps remind people. After all, nearly all of us are juggling overflowing mailboxes (and often, day jobs). Please keep contributing. It may be hard to see at the start of the process, but it is literally people like you that make all of this possible. But it is a long road. One more thing: I realized a while ago that most work in large groups is people-engineering, and not technology-engineering. I don't mean manipulating people, but I do mean finding productive arrangements and communication patterns between people. It takes time. It takes learning and building relationships and building trust. I know that can be frustrating at the beginning, but -- keep going. Your contributions are welcome, even if PRs are rejected initially. Look at those as practice runs. 
It may not be solving problems you care about, but that doesn't mean it wouldn't make sense to use it as a backend on top of which you'd build your modal editing system.
According to u/chriskrycho's [latest New Rustacean episode](https://newrustacean.com/show_notes/news/rust_1_29_1_30/index.html), they're aiming to have it stabilize "sometime in the first half of 2019". No idea of the details, though. 
For this reason, I use this kind of helper function: // somewhere in util.rs or some such: pub fn range_len(start: usize, len: usize) -&gt; Range&lt;usize&gt; { start..start + len } // somewhere in code &amp;some_list[range_len(i, n)] I totally agree that your idiom looks nicer, though! 
More complete tooling platform overal. Few examples would be precise local history cache. Excellent code versioning management tools. SQL DB integration. Etc. Plugins help, but they don't tend to hit close to the target. 
Be aware that you can unintentionally create a *lot* of code bloat, this way, when this code is monomorphized. It doesn't take much to create a combinatorial explosion of function specializations. Personally, I would choose to type the parameters as `&amp;str` and to accept whatever burden was necessary at the call sites to coerce my args to `&amp;str`. 
Alright so I tried that. This is how I call it from my main.rs let cpu = lib::parse().expect("error"); println!("CPU: {}{}", cpu.model_name, cpu.cores); and when I run it I get... thread 'main' panicked at 'error: Unknown', libcore/result.rs:1009:5 &amp;#x200B;
How does this differ from winit's event loop?
This is basically how [JUCE](https://github.com/WeAreROLI/JUCE) and Qt are designed. They're pretty damn popular so it seems like a good idea. I work with these regularly, and they are good at what they do. However, my opinion has shifted (albeit inspired by the [Xi editor project](https://github.com/xi-editor/xi-editor)). I'm of the believe if you want native (not "native") UI, then you should be writing your application UI in the language/toolkit of the platform. If you want the same look &amp; feel everywhere, then use whatever you want. But IME the biggest issue with this approach is MacOS and iOS. You can't trust anything to be stable with Apple, and they don't want you writing anything but Swift for UI. 
I'm fine with my changes being rejected. I've got triggered because this new solution immediately shut down mine, while 1) it is not what is described in the issue, 2) it is something that I was considering but got no feedback. Anyway, I'm not going to give up with contributions.
whaaaat that's awesome!
When you enter into insert mode, yes. But why not in normal mode? :)
Also, when you insert or delete new lines, you need to update all following highlights (move memory in case of `Vec&lt;(u64, Vec&lt;...&gt;)&gt;`, modify line indices for `BTreeMap&lt;(u64, u8, u8), Hl&gt;` and `Vec&lt;(u64, ...)&gt;`). Don't all these approaches become too slow for you bevause of this reason alone? 
Does it require `unsafe`? I don't see anything `unsafe` in the above code.
I actually like that differentiation between the modes. Insert mode works like most common editors, so cursor looks the same. "Normal" mode is quite vim specific, so cursor is different. At least that's how I see it. But you can configure it any way you want.
What does the two index operations version do when i+n would overflow?
Can this crate help with our issue? https://docs.rs/owning_ref/0.4.0/owning_ref/ I've used it to return a reference to data from memory mapped file, together with the file itself to keep it open.
The "Rust Distribution" you mention could likely be done using the [rust-lang-nursery](https://github.com/rust-lang-nursery) repository.
Pick any editor (need a suggestion? I hear vscode is good). Open up your terminal/command line app. Run `cargo init myrust`. That will make a directory called `myrust`, run `cd myrust`, and then open the `src/main.rs` file and start writing code. Build using `cargo build`, run using `cargo run`.
\&gt; Also, if you're ever in London I'd more than happy to grab a coffee. I wish :) I'm in Colombia. &amp;#x200B; I have already read most of the links you give me (sadly most of the useful stuff is in Julia!), and stagging is one of the things I already have in mind (however, in Rust is kinda hard to do, IMHO) . My plan is try to build something like [https://www.cs.purdue.edu/homes/rompf/papers/tahboub-sigmod18.pdf](https://www.cs.purdue.edu/homes/rompf/papers/tahboub-sigmod18.pdf) and only do staging for the part of the query evaluator (imaging restricting to this will make life easier for me). &amp;#x200B; I will try to rebuild the concept using Any. Thanks for the input. 
And then keep having to fix everything anytime upstream changes anything? No, thank you. :) . Right now Xi doesn't even have support for modal editing in the first place. I have mentioned kakoune-like modal editing in March 2017. We now have 2019. https://github.com/xi-editor/xi-editor/issues/85#issuecomment-290822058 and the issue is still open under https://github.com/xi-editor/xi-editor/issues/302 with 50 comments . I'll try to add kakoune modal editing in 2025, when it's finally ready in Xi. :D People are just addicted to complexity. While I've literally spent couple of short evening to put Breeze together, and I can already test my ideas, Xi has 15.5 starts on github, 117 contributors, and years of development and still can't do modal. If I was to keep hacking Breeze together, I would try to make it (the editing engine) WASM-compatible and available as a reusable io-less library with C bindings, so people can embedded it in both their Web UI, and normal Apps, while keeping the core goal small: terminal editor. Complex systems can't be created from scratch. They have to evolve from simple systems. Just my 2 satoshis. :)
&gt; I'm curious about good options for storing data that will sometimes be very sparse (e.g. an empty or one-color bitmap, a few dots in a large area, etc...) Do you think you would run into that case often? In general, images stay uncompressed in memory (like your vector idea, but there's often a bit of unused space after each line for interesting, but not very relevant reasons). On disk, they're usually compressed, e.g. JPEG for photos and maybe PNG for icons and other art. If you really need sparse bitmaps at run-time (not on disk), there's a neat compression technique called a [quadtree](https://en.wikipedia.org/wiki/Quadtree). There might be better alternatives, but I haven't researched the subject.
Basically you assume that system calls are made fairly frequently and always keep the kernel page around, even while in user mode, so it doesn't have to be loaded when you make a system call.
Oh shoot, I frankly forgot that you actually still need to use segment registers for some things. Sorry about that. I also, alas, can't think of any particularly better examples of segmentation besides like... the PDP-11 or something. Never really thought of it this way before, but I guess it kinda went out of style in the 80's when the world divided into "small computers that will never have more RAM than they can address" and "big computers that support paging". I thought the Cortex-M's memory protection unit did segmentation, but you mention it already and it turns out it's not *actually* segmentation.
Possibly. I'll have to try that out later. But it's honestly getting into territory I'd rather avoid. Sometimes the return value is `Vec&lt;BasicBlock&gt;` and I don't want to have to juggle lifetime parameters. I'd rather just silence clippy in that case. Having said that, I'll try out your suggestion at some point just for my own edification.
"Therefore, it would be necessary to backport security updates and bugfixes to older versions." No. No, no, no. Either you use the current version or you go fellate a running chainsaw. You have no right to demand that people double or triple their workload just so you can have the convenience of not updating your dependencies.
There's a method like this in [itertools](https://docs.rs/itertools/0.8.0/itertools/trait.Itertools.html#method.set_from) (their example): !use itertools::Itertools; let mut xs = [0; 4]; x s.iter_mut().set_from(1..); assert_eq!(xs, [1, 2, 3, 4]);
In release mode, i+n will wrap around and produce a slice with that ends at (\`i + n) % usize::max\_value()\`. That may or may not be out of bounds.
`|` doesn't work in normal mode because `|` is on the left of the position, while Vim/Neovim, consider cursor to be part of the selection. So yeah ... it just won't work the way it should, until you change the mechanic underneath.
I think the order they're presented on the main page is the intended read order, the categories are just to separate different sections.
Iâ€™m sorry, youâ€™re correct. Itâ€™s not fair to compare the two projects without more context. I do recognize, with the existing userbase, that the core Rust team is much smaller (compared to Go) and isnâ€™t able to react to each and every change. From what Iâ€™ve seen in the last 6 months, Rust has so much momentum right now. With the 2018 release, I suspect growth is going to explode this year. Not sure how the core team is prepared for this. Anyone whose been in OPâ€™s position knows this stuff happens in OSS. Itâ€™s just the way it works. You canâ€™t please everyone. One thing Iâ€™ve seen recently on some Rust projects are issue labels for beginners. That might be a nice direction to follow.
&gt; Anyway, I'm not going to give up with contributions. I'm glad, and I hope your next contribution goes better.
 Calling all RUST players, we have opened a brand new server! JUST FULL WIPED! If your new to rust or just looking for a relaxed place to play come and check out #1 Rusty North UK! Active Helpful Admins 2x Gather Rate! Max 4 Players in team. Join the Discord here : [https://discord.gg/HRAsKjW](https://discord.gg/HRAsKjW?fbclid=IwAR0t2rUR_AC5bGVMrK8kGaqNHYucgtnBndxfKO4lJTbKfAkD4-nqcVNG2bY) Direct Connect @ client.connect 37.187.156.154:28066 
I understand that this is a joke (and don't get me wrong, I'm not talking about this comment), but I think that the Rust community suffers from programmers who want every giant codebase to be rewritten in Rust (this is how the RIIR meme was born) but then they don't do anything to accomplish that. It's okay to start a new project completely written in Rust (e.g. Servo and Redox), but rewriting, say, Linux or Tor (there's a request on Tor's bugtracker saying that they should rewrite it in Rust), would literally take either decades or a giant corporation
&gt; One thing Iâ€™ve seen recently on some Rust projects are issue labels for beginners. That might be a nice direction to follow. The rust project has the `E-` class of labels for that since... before 1.0? https://github.com/rust-lang/rust/labels?page=3&amp;sort=name-asc https://github.com/rust-lang/rust/labels?page=4&amp;sort=name-asc Project growth luckily is usually more linear (I know this is counter-intuitive, but all numbers I could ever get my hands on are rarely "exploding"). We have the issue on our radar, and core is _certainly_ prepared, but core a) is not responsible for doing the teams work, it's a moderating council, b) we have to work with what we have. Community growth is _definitely_ a big subject currently. 
You are describing Qt. The reason it has all batteries included is because the C++ package management situation was nothing for a long time and only now has some very limited attempts. This can be a start of a libui type framework and it is the right place to start from. 
&gt; while Vim/Neovim, consider cursor to be part of the selection I always reconfigure that. set selection=exclusive " don't include the cursor in the selection
&gt; What amount do you mean with "a lot"? 104? 106? 109? 10^7. Most I've seen is 4*10^6, but the tendency is upwards. &gt; And what memory overhead you expect compared to 16 bytes for (u64, u8, u8, Hl) for each highlight? So `Hl` easily fits within a byte. Not sure what the compiler makes of it. Does that answer the question?
Something in the last couple of updates changed and now it works amazingly. I managed to get into the flow I normally experience with IntelliJ using java where everything worked perfectly and felt fantastic. Great work! Has a great future ahead of it! 
I mean, Kakoune's entire thesis is that visual selection is a more intuitive way of editing text that has a better curve towards approximate expertise. If you reject that, I'm not sure why you'd favor Kakoune over one of the other modal editor options.
So it is possible? I am happy to hear that. I'll try it out sometimes. :)
Yes, pattern matches must be exhaustive. You need to make the following changes: * If you want to stop parsing on "flags" rather than an empty line as in my original example, you need to match `["flags", _]` since `["flags"]` would only match a line that contained just the string "flags" (plus whitespace). My example matched on `[""]` since that matches a line that contains nothing (but whitespace). This is brittle, as /proc/cpuinfo might change sort order in future and so you'd be stopping before reading all of the fields you're interested in. I would just read them all and end on the empty line (or end of file). * You should skip any keys you don't want by matching and doing nothing, using `[_, _] =&gt; builder,`. Since the result of the match is assigned to `builder`, you need to return a builder even if you didn't change anything. * Similarly, lines which do not contain a colon will have a single-element vector. `[_] =&gt; builder,` will deal with those. I'd probably log a warning in that case since it's unexpected input. * Although `splitn(2, ...)` can only ever return one or two items, the pattern-matcher doesn't know this and you will still need to match all other sizes. A final `_ =&gt; unreachable!()` (or perhaps `panic!`) as the final entry makes it clear that this condition can't happen, and it is a bug if it does.
Slightly longer scope than "this week", but I'm reading the excellent [Game Engine Black Book Doom](http://fabiensanglard.net/gebbdoom/) and implementing stuff in Rust as I go. So far I have created [tools for working with WAD files](https://crates.io/crates/wad), generated an SVG of [E1M1](https://magnushoff.com/blog/e1m1/) and created a tool that extracts [flats](https://magnushoff.com/blog/flats/) (ie. floor and ceiling textures).
I don't reject that " visual selection is a more intuitive way of editing text t (...)". I agree with that wholeheartedly. But visual selection does not mean playing Vimgolf all the time. That's all I'm saying. :)
&gt; Don't all these approaches become too slow for you because of this reason alone? Not sure. I might be able to find a way to postpone updating the following highlights until there's time, but first I want to find out if I really need to :) But of course, this also would lend itself to the first case, because there's somwhat like 1/5th of elements to update compared to the other structures.
I apologise to you, /u/sasik520, as it would appear my closing of your PR triggered this. I should've been clearer in my message: closing your PR wasn't to reject it - my interest was in avoiding having parallel conversations on the same topic. Perhaps I should've waited a bit to see how things progressed.
I also haven't thoroughly researched the topic, though I've been reading about some potential solutions for the last day or two. I'm not sure that this is really a practical concern, but just started thinking about the problem and got curious about it! &gt; Do you think you would run into that case often? Depends what you're doing, I suppose. If you have a whole bunch of one color rectangles or something then you'll hit the case, but a better solution is just a simple vector rectangle shape that defines a common trait so it can be drawable as a bitmap -- I'll definitely implement that. &gt; there's a neat compression technique called a quadtree Yeah, I considered a quadtree. My first quick implementation to speed up compositing nested bitmaps was to add simple space partitioning, which uses a similar concept to a quad tree. Maybe I'll go ahead and test out a quadtree implementation and see how that compares. My concern with a quadtree is that although it'll be much more memory efficient, and faster to create the structure, it'll be slower to access individual pixels, so I think a `get_pixel` call will be `O(log n)` instead of `O(1)`. It might still be a reasonable tradeoff for some situations. I think a simple `HashMap&lt;(x, y), Pixel&gt;` actually might not be the worst answer, but you'd still have the overhead of hashing the key, whereas with a vector you can just directly access an index. 
I've also done a couple Rusty streams! I'll show you mine if you show me yours: twitch.tv/panthalassadigital
&gt; the fact that it has so many weird key-bindings, focuses on selection instead of the cursor too much Sorry, I thought from that you meant you didn't like the selection part, because I feel like most of it's differences come down to the primacy of selection.
Please don't actually do `.take(13)` because some day they'll add another line and maybe not at the end.
`Future` is just a trait that anything can implement, which says "I'm doing some work, and you can poll me to see whether the work is done." There's an implicit contract behind this of "...and if the work isn't done yet, I'll make arrangements to notify you in the future so you know when to poll me again," but the `Future` trait/crate itself doesn't make very many assumptions about how that should be done. `tokio` is an implementation on top of the `Future` trait that knows about the standard OS facilities for async IO, like Linux's epoll and Windows' IOCP. It provides a bunch of different futures for things like network IO, and it includes all the plumbing for those futures to register themselves for wakeup with the appropriate OS facilities and for the calling thread to re-poll them after wakeup. (Many of the OS-specific details are handled in a lower level library called `mio`, so it can also make sense to think of `tokio` as the "combination of `Future` and `mio`.)
Unless there is any major change to UIKit and Cocoa, Apple APIs are still going to have a mostly unified runtime between swift and Objective C. At this point, writing Objective-C classes in Rust's high-level [bindings to libobjc](https://github.com/SSheldon/rust-objc) aren't much more pain than native ObjC/ObjC++ code. The main thing you're missing with writing an Apple app outside of the standard Objc/Swift environment is Xcode's tooling, particularly code generation and binding class methods to Interface Builder callbacks.
I meant what overhead do you expect from the data structure itself. Plain `Vec&lt;(u64, u8, u8, Hl)&gt;` is basically no overhead - just 16 bytes for each highlight. `Vec&lt;(u64, Vec&lt;(u8, u8, Hl)&gt;)&gt;` seems heavier if you have a lot of lines that just have one highlight (24 bytes for the vector itself, and also possibly 4 or 12 more, depending on the allocator). And some sort of tree would possibly add even more because of allocations and extra pointers. I guess you could answer this by saying what memory usage you would expect when you have to store those 10^7 highlights (when just the raw data would take up 10^7 * `size_of::&lt;(u64, u8, u8, Hl)&gt;()` bytes - 160 MB).
Re-conciliating Win32, GTK, Cocoa into a single coherent framework is likely impossible. Identical GUI code for all platforms is not an achievable goal when you are trying to use native UI libraries. Every desktop has its own way of doing things. Starting with a minimal core like an event loop could maybe work. Then split the various system wrappers into their own crates. In my opinion what is needed is some coherence, but not too much as the complexity would be too large. Just look at the winit complexity for something that is trying to wrap the most basic thing across all platforms. 
The biggest difficulty with vim in general, are behavior defaults that are very different from the vast majority of editors today. It's a historic artifact. Good thing is, much of that can be changed through configuration.
It would be nice in some cases to have something like that in Rust. Something like C++'s variadic templates but taking advantage of tuples being a first-class feature would be a better design than `va_list`'s "guess what types I passed you" design.
As fellow Rustaceans pointed out, use "The book": [https://doc.rust-lang.org/book/](https://doc.rust-lang.org/book/) If you haven't installed Cargo, make sure you do. It's not just dependency management, but also serves as basic cli tool for the language. You'll probably want to use some sort of code editor. Currently there is VSCode (Visual Studio Code) from miscrosoft which is free, very popular and works quite well. I'm sure you'll find proper Rust plugins so the editor could help you to code a bit better. If you're not sure how to install the plugins, search google by "setting up VSCode for rust" or something in those lines, I'm sure you'll find better put together guides than what a common Rustacean could do in a swift reddit post. And when just go though the book. Not skipping anything. And if you're new to programming in general, make sure to do all the exercises and perhaps look up [https://doc.rust-lang.org/rust-by-example/](https://doc.rust-lang.org/rust-by-example/) for reference. Rust is not most newbie friendly language to start with, but it's doable.
Ahh ok. Memory is of no concern basically. I can easily invest 20GB if it helps speeding things up (I wouldn't expect using that much memory to speed things up, though). Most lines will have 2-8 highlights, I'm pretty sure the number is capped at 10 or 12 (would have to check).
Rust compiler is self-hosting and also has a Rust interpreter... ugh, wait, which Rust?
Joke's on you, Tor is oxidizing: https://github.com/torproject/tor/tree/master/src/rust
Awesome! Followed ðŸ˜Š 
I hereby greet all the other 49.999 r/rust subscribers â¤
The [former version](https://github.com/pcwalton/sprocketnes/blob/8be11de7bad5a54ad62f5894f725950a6fe849d4/src/gfx.rs#L282-L283) of the `Gfx` struct used `Box&lt;Texture&gt;` (a _boxed_ `Texture`). You could use `Box` in yours as well and use the `'static` lifetime. However, you might not want to store them plainly together in a struct like that. I haven't sifted through enough of the documentation or code to wrap my head around everything the sdl2 crate does, but the [changes](https://github.com/Rust-SDL2/rust-sdl2/commit/19c5d126028ab443b0d2ae2935ecaad1e5944653#diff-bb47d7c2333e425325fbe29dd77595ffR1122) that added the lifetime to the `Texture` struct also added a line in the struct's doc comment that "A`Texture` cannot outlive the `TextureCreator` [that created it]", though the [current documentation](https://docs.rs/sdl2/0.32.1/sdl2/render/struct.Texture.html) no longer has that remark. Personally, I find it difficult to confidently determine what functions in the sdl2 crate are safe, so I would probably take a more cautious approach and create a wrapper for textures that stores references to the `TextureCreator` that created them. (That might not fit your needs though, especially if it degrades performance.)
Really didn't know, thanks for link
Storing your scene in an abstract way (for example, a set of objects that know how to rasterize themselves instead of a monolithic raster image) could be useful. Depending on the interface of the image compressor you want to use for output, you might have trouble avoiding rasterizing everything in the end anyway, though.
It is not about convenience. As I wrote in my post, many companies cannot use third-party libraries, at least not without formal verification. That's obviously not the problem of library authors, but if Rust wants to be taken seriously in the industry, the Rust team has to come up with a solution, because they chose not to maintain a comprehensive standard library. I proposed one such solution, and please do note that I wanted to let a specialised working group do the majority of the (admittedly rather uncomfortable) work, not the lib maintainers.
Yeah, Iâ€™ve hit the brick wall of self-referential structs a few times and owning_ref saved me. In this case, you should be able to create a `OwningHandle&lt;Arc&lt;TextureCreator&gt;, Box&lt;Texture&gt;&gt;` which behaves just like a regular `Box&lt;Texture&gt;`. It still requires one line of unsafe code to set up, but it is very managable.
Yeah, that was one of my next steps -- to make it so that a drawable object can be either a bitmap or a shape that knows how to describe itself. I just got curious if there was a structure that would gracefully work for either of those scenarios! 
One can not build a native gui on top of winit because the event loop is inaccessible. Only the events it supports are returned.
Already happening: https://github.com/rust-analyzer/rust-analyzer https://github.com/rust-lang-nursery/chalk https://github.com/rust-lang-nursery/polonius
Something like this? builder = match kv.as_slice() { ["processor", _] =&gt; builder, ["vendor_id", v] =&gt; builder.vendor_id(v.to_string()), ["cpu family", _] =&gt; builder, ["model"] =&gt; builder, ["model name", v] =&gt; builder.model_name(v.to_string()), ["stepping", _] =&gt; builder, ["microcode", _] =&gt; builder, ["cpu MHz", v] =&gt; builder.cpu_mhz(v.parse::&lt;f32&gt;().ok().ok_or(Error::Unknown)?), ["cache size", v] =&gt; builder.cache_size(v.parse::&lt;u16&gt;().ok().ok_or(Error::Unknown)?), ["physical id", _] =&gt; builder, ["siblings", v] =&gt; builder.siblings(v.parse::&lt;u16&gt;().ok().ok_or(Error::Unknown)?), ["core id", _] =&gt; builder, ["cpu cores", v] =&gt; builder.cores(v.parse::&lt;u16&gt;().ok().ok_or(Error::Unknown)?), ["apicid", _] =&gt; builder, ["initial apicid", _] =&gt; builder, ["fpu", _] =&gt; builder, ["fpu_exception", _] =&gt; builder, ["cpuid level", _] =&gt; builder, ["wp", _] =&gt; builder, ["flags", _] =&gt; builder, ["bugs", _] =&gt; builder, ["bogomips", _] =&gt; builder, ["clflush size", _] =&gt; builder, ["cache_alignment", _] =&gt; builder, ["address sizes", _] =&gt; builder, ["power management", _] =&gt; builder, [""] =&gt; builder, // stop parsing on the empty line [_, _] =&gt; builder, [_] =&gt; builder, _ =&gt; unreachable!(), } This panics as well
50 004 :-D
Right, thanks for your thoughts. I'm guessing that long term the solution could be some kind of a hybrid; some common crate for what they all do: just creating a window and a button with a text on it, could be done in a common crate. And then make it easy to get whatever API handles you need should you need to do something more advanced. As wasm/browser is a possible target, that will probably split off earlier; not even windows work the same way there (what would that be? A `&lt;div&gt;`?), you don't have the same control over the main loop, etc. But you can still create a button :-)
Winit includes an event loop, and the crate has the purpose of creating windows. The event loop is not callback based, but enum based (every Event is an enum, which you need to dispatch yourself). Winit's focus is more on getting a window and custom drawing (through OpenGL, Vulcan etc) rather than drawing native GUI widgets, but nonetheless has some common ground with this crate.
I approve.
Thanks! The link goes to the github for the pre-0.0.0 alpha DO NOT USE version, so... The 85% is an estimate based on a few preliminary iterative tests using criterion on very short DFAs, so don't take it as gospel. Not that worried about Unicode classes; there's a paper that shows that replacing the "is a char" node with a basic `Char -&gt; Bool` predicate is theoretically sound, so the "scan the whole set" thing from Thompson doesn't come up. And if your input symbol supports Ord, you basically get range testing for free. I haven't dug too deep into Unicode ranges and criteria yet; I'm sure it's a snakepit, from the conversations I've had with some friends who contributed to the Perl 5 implementation.
This is a ridiculous excuse. If you cared at all about not having parallel topics then why would you close the older PR? Seems to be a simple matter of some people being more equal than others, and a more equal person had a new PR.
&gt; However, my opinion has shifted (albeit inspired by the Xi editor project). I'm of the believe if you want native (not "native") UI, then you should be writing your application UI in the language/toolkit of the platform. If you want the same look &amp; feel everywhere, then use whatever you want. It's an interesting question. I guess it's easy to get stuck in questions like: "okay, so these three backends do things this way, but the fourth one does it that way, to what degree do I write something to compensate for that - making things more coherent but less native?" Still libui seems to be doing good enough, although I haven't looked into every detail of that library.
I'm not aware of details in how kdb+ is made (and I also have search for it) but in the other hand, J have this: &amp;#x200B; [http://sblom.github.io/openj-core/ioj.htm](http://sblom.github.io/openj-core/ioj.htm) &amp;#x200B; You can think of kdb+ as alike J + mmap(??) storage layer + sql-alike sugar. &amp;#x200B;
The only way I see that happening is if these internal processes that companies use are publicized. What, exactly, is it about the standard library that is seemingly not a problem, but a third party dependency is problematic? That doesn't just get solved by a bunch of people banging their heads together. The people saying they can't use third party dependencies need to step up and say the criteria that needs to be met and why we should go out of our way to do it. I mean, there are plenty of companies using my crates, so the system seems to work fine for at least some subset of companies.
&gt; Not that worried about Unicode classes; there's a paper that shows that replacing the "is a char" node with a basic Char -&gt; Bool predicate is theoretically sound, so the "scan the whole set" thing from Thompson doesn't come up. And if your input symbol supports Ord, you basically get range testing for free. I don't think I understand this. Large Unicode sets can't be waived away with predicate functions. You need to deal with them somehow. If you're building a byte oriented DFA (it sounds like you aren't), then you need to contend with DFA size and compile times. If you're building a corepoint oriented DFA, then you need to contend with large alphabets, and you still need to test membership of those Unicode classes somehow. Either way, I don't think enough practitioners have pushed regex derivatives to their limit yet, so I'd be very curious to see how this turns out. Also, for a parser, you might consider reusing [`regex-syntax`](https://docs.rs/regex-syntax). It will save you a lot of trouble.
The problem with the extensive library is pretty obvious, no matter how you approach it you always fall into the same problem, because the problem is not in the std, is in the users who don't (or can't) keep up with the changes. The underlying problem is programmers relying on an API while the language and libraries keep going forward. If the library dies, now the hole package dies unless another library can emulate that same API and keep up to date. And while doing so they are expected to backport security fixes... You might look at the situation feeling that that is out of the language control, but that the proposed solution might be better. But think about the library paradigm in a language like Python: Either there are multiple homogenously distributed libraries or there is a Big do all have all library (okay, maybe two, but you get the point). What kind of library do you expect to make it into these packages? Small libraries that canâ€™t handle the load of backporting? Or reliable big libraries with a lot of contributors going out for them? Eventually people just rely on those packages like they rely on std. It may be better because we may see â€œcompetingâ€ packages with different approaches. But when it comes to long term maintenance having it in the std or having it as an external package is, I believe, a matter of semantics. Either the creators of the language are in control of the ecosystem or they are not, but that is a matter of responsibility, I doubt that will change the final outcome.
That's what I thought too. Furthermore, what if I want to customize my newtype, by eg. not implementing multiplication, because it doesn't make sense for this specific type? Having dedicated syntax for newtypes seems to be a step backwards for me..
Wow, +10k subscribers for \~6 months.
It seems that we've just barely overtaken /r/ruby, which would make us the eighth-largest programming language subreddit.
does cloning an existing struct instance take the same time as creating new one?
I have had the opposite experience with 2018 edition crates. Since the edition 2018 changes started landing, the experience was quite sub-par for me with auto completion failing regularly, faulty highlighting of syntax errors, etc. It's slowly been getting better again though. (it's understandable that it takes some time to catch up to the 2018 changes, though)
I think to decide on the best data structure I would need to know what is the expected distribution of queries would be. For example, if there are a lot of unrelated insertion, deletion, and iteration queries then some sort of tree would be the best because it has good worst case performance if you do any queries with it. However, if you iteration queries come rarely and in batches then you might indeed get good results with a simple vector and batching modifications because of data locality and basically no allocations. Maybe you could provide a typical set of queries, or a program that could generate one? I'd have quite a bit of experience implementing various data structures, so I'd love to experiment with this.
One thing I feel is lacking in the WASM ecosystem is mature runtimes for WASM which are easy to embed in your application. Most of those i looked at, e.g. WAVM, Wasmer and Wasmtime, are unstable and under heavy development. I hope some embeddable runtime will stabilize in 2019.
Depends on what's in it. For plain data structs which are also `Copy`, both `Copy` and `Clone` will be roughly equivalent to creating a new one: in other words, extremely cheap. Cloning a `Box` will take pretty much exactly the same time as making a new one. If you have a `Vec` or other allocated data structure, cloning might be faster or slower, depending on how you're initializing it. Creating an empty vec and cloning an empty vec are both very cheap. Cloning a non-empty vec will mean allocating new memory for all the elements - that's roughly equivalent to a `vec![]` macro call or collecting from an exact-sized iterator, and faster than adding each element with `.push()` since pushing usually means reallocating at least a few times.
My favorite game referenced my new favorite programming language!?
&gt;"...and if the work isn't done yet, I'll make arrangements to notify you in the future so you know when to poll me again," I think this is a key point. When I first learned about the concept of futures in rust, my mental model was of a for loop, polling the computation every millisecond or so to see if the job was done.
[removed]
When someone sincerely apologizes for something, the polite thing to do is to assume good faith, and *not* to accuse them of being insincere. Please try to be more polite in this subreddit in the future.
&gt; What, exactly, is it about the standard library that is seemingly not a problem, but a third party dependency is problematic? I don't have any exact information, either, but I think the official libraries are created or at least vetted by the organization governing the language. It is reasonable to assume that official code is safe to use because the organisation has no reason to do anything shady and every reason not to lose its good reputation. Compare that to a third party, which could be anyone, and you have no real way of telling whether their intentions are good short of verifying the source code, which is cumbersome at best and expensive at worst. &gt; The people saying they can't use third party dependencies need to step up and say the criteria that needs to be met and why we should go out of our way to do it. What I had in mind were companies in the government/avionics/defense area, which would be "high-profile" users of the language, but probably prefer to keep their criteria to themselves. My line of thought was, if Rust wants to compete with Ada or the verified C subsets like MISRA, this would be the best way to go given the current situation. &gt; I mean, there are plenty of companies using my crates, so the system seems to work fine for at least some subset of companies. Certainly, I mean you wrote the quasi-standard regex crate :D They just probably are a different kind of company than I had in mind.
Macros have been super problematic. I actually think many Rustatians overuse macros, especially as the IDE support just isn't there yet. Similarly good IDE support in Haskell, especially for automated refactored, has been delayed because CPP macros make it *so* hard. I certainly gave up, as a Haskell IDE plugin author. I worry about this situation in Rust (although [the intellij-idea folks are trying to make it work](https://github.com/intellij-rust/intellij-rust/pull/3015)). I think for me the performance seems to have improved for the small crate I'm working on. For a while it was unusably slow. It's still slow for a big library for me, but at least my small library is tolerable.
Do you have a list or something?
&gt;Re-conciliating Win32, GTK, Cocoa into a single coherent framework is likely impossible. libui (C) did it well enough. But development is slow.
OK, well, I think the companies using Ada or MISRA C are a substantially tiny niche from my perspective. It would be helpful if you could be more explicit about this, because your commentary here is, comparatively, quite broad. e.g., "but if Rust wants to be taken seriously in the industry." This is not a dismissal of the importance of targeting that niche, but it undoubtedly is going to impact priorities and resource allocation. I'm not sure exactly what kind of vetting you have in mind, honestly. Are you at one of these companies that explicitly bans third party libraries but not the standard library? Because that's what I'd like to hear about. If not, then I'm not sure we can really solve that problem without specific concrete use cases in front of us. So the first step, I think, is to collect those. &gt; Certainly, I mean you wrote the quasi-standard regex crate :D Yes, but I'm otherwise just some individual. I'm not affiliated with Mozilla or any other large organization. I have my own reputation to consider, certainly, but so do a lot of other volunteers in the Rust ecosystem. So it sounds like a substantial part of your vetting process is already complete if my work is considered vetted.
I joined July 2017 and at this point there were 27k subscribers. That's pretty impressive...
If many have separate work and personal accounts and are subscribed to both, then the actual count is less. Congratulation with 25k Rustaceans on Reddit!
I just wrote our company's first Rust program! It's not shipped yet, but I'm excited that we are considering it for new development
Awesome explanation. Thank you!
What would be very interesting is a DSL, kind of like QML or HTML + JS where you use a markup file to describe the UI/layout. Then write a parser to generate the necessary Swift/C#/whatever with hooks into your Rust code, compiled as a library. 
The original title I wrote on /r/itsaunixsystem begins with `[Prey]`. I guess your view of reddit doesn't show crossposts :) (should've crossposted myself, but I thought it would be against the "no memes" or something)
&gt;If many have separate work and personal accounts and are subscribed with both, then the actual count is less. Congratulation with 25k Rustaceans on Reddit! little bit skeptic about u idea, for what use 2 reddit accounts &gt;?
As another person in here noted, reconciling every UI platform out there is not simple. You'll get the basics (list views, labels, etc) and then you'll quickly see how insanely difficult it is... and then you'll see why people converge on Electron (or WebRender as a goal, as you see in Rust). This will get downvoted for even mentioning Electron, but whatever. [I've experimented with this kind of thing](https://rymc.io/blog/2018/rust-or-whats-the-deal-with-guis/) and I've been doing UI work (in native, web, and so on...) for literally 10+ years now. It's not straightforward, contrary to what people think, and I'm (controversial opinion) not sure the Rust community has the necessary expertise to even go about this correctly without building a UI solution that doesn't work for the 90% of real-world use cases. OrbTk gets the closest of anything to an ideal system.
It's made worse by different platforms not just having different toolkits, but different design guidelines as well. It's sort of a lose-lose situation. Make your app more native, and it becomes easier for users of that platform to learn. Make it more consistent across platforms (and thus less native), and it becomes easier for users of your app to use across different platforms. It seems to me like most popular applications generally choose to be consistent across platforms and forgo trying to make it seem "native".
/r/programming does: https://www.reddit.com/r/programming/wiki/faq#wiki_what_language_reddits_are_there.3F
Ah, the ever-familiar [rabbit hole](https://youtu.be/AbSehcT19u0)
I have a ~50 line program that is one of the first times I've had to annotate lifetimes: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=4098df8d43c23a255cd8d22135d770d1 I am trying to echo back the last three lines of user input in a loop, and understandably the borrow checker is asking me for some lifetime information, but I have three questions besides 'where and what do I annotate?'. 1. If I only have one function (main()), is the smallest lifetime I can annotate 'static? 2. If I have a growable/shrinkable Vec&lt;&amp;sometype&gt;, how can I say "drop this as soon as the Vec no longer references this data?" 3. Should I be using an arr[&amp;str; 3] if I know I just want 3 references at any given time? Thanks y'all
&gt;Re-conciliating Win32, GTK, Cocoa into a single coherent framework is likely impossible. Guess someone should let the Free Pascal/Lazarus developers know that something they've already done is actually unfortunately impossible, then
Presumably, for using `assert_eq!` to do this when you could do it at compile time with `transmute`.
For one, IntelliJ Rust is the only IDE with working rust support, because they use their own (proprietary) solution to parse and index Rust code. Everything else uses the Rust Language Server(RLS), which is buggy, incomplete, and not suitable for much actual use. &amp;#x200B; That said, i like VSCode better than IntelliJ so.. i'm stuck with RLS and it's lack of working autocomplete, frequent crashes, and high CPU usage. :(
Because the people currently involved in the discussion arenâ€™t in the older thread. â€œWe have some older discussion that can be referencedâ€ is so much more effective than â€œI found an old thread about this, everyone move there. If you have comments here remember to move them overâ€. Yes, itâ€™s unintuitive. But it happens a lot, in a lot of places, and imo itâ€™s often a better method. Especially if you donâ€™t catch it immediately. 
So suppose that people make three different frontends for three different platforms which all look native. Would they still not benefit from sharing code for everything that is not the foremost frontend? And then that requires interacting with the main loop.
1. `'static` is the largest lifetime. It's for references that exist before your program starts and exist past its end (stuff like string literals.) 2. Are you talking about dropping the elements of the Vec? Only the owner of a piece of data determines when it's dropped. 3. As long as all the references have the same lifetime, that's probably fine. For this program specifically: You want `messages` to be of type `Vec&lt;String&gt;` (or `Vec&lt;Cow&lt;'static, str&gt;&gt;` if you want to be fancy), but it's currently trying to be a `Vec&lt;&amp;'a str&gt;` for an `'a` that can't exist. The simplest way to solve this is to `map(str::to_string)` right before the second `collect`, and to have the else block be a list of `String`s (by calling `to_string` on everything.) If you then just remove the `&amp;` from `input` when you're inserting it, your program compiles.
I'm using IntelliJ with a Rust 2015 project - how does IntelliJ work with 2018? Can I convert without any fears of it not working in Clion? (I'm afraid of switching to 2018, working on my project a bit more and then intellij magic dying on me which would force me to convert in back to 2015.)
Ouch! *it moves the input.* Not as useful as the usual *eprintln.*
You win this year's (absolutely authentic) alliteration award!
There is no single answer that will tell you the truth, always, when it comes to performance. Measure. Measure again. Make sure you understand what you're measuring. Make sure you measure something big enough that the measurement is meaningful. Don't measure 100000000 iterations of a loop that adds two numbers. That tells you almost nothing useful. Measure something realistic. Measure more. Measure datasets that are too large for your CPU cache. Cache Rules Everything Around Me. Until you are measuring datasets that are large enough that they matter, you're not really measuring much at all. Imperative loops ("for" loops) and iterator-based loops will often produce very, very similar code in Rust. But don't assume *anything*. Start looking at the assembly code differences, even if you don't understand much yet about assembly code. Look at the difference (in the generated assembly) between relatively small source code changes. Look for loop unrolling. On x86/x64, you'll usually see this as use of vector instructions, which operations on %xmm or %ymm (or %zmm, etc.) registers. Loop unrolling is not magic, though. 
It makes intuitive sense to me. Typing in insert mode squeezes text in right where the |-cursor is, but typing e.g. "rx" in normal mode manipulates the character inside the box cursor.
I love this advice. I really dig high performance stuff. I started in java where the common wisdom is "don't optimize, the compiler will just fuck it up". however, I'm not building anything substantial, yet. I'm essentially learning assembly along with this DSP stuff because I'm really interested in this field, and I have a music background already. another question if you don't mind: what is your assembly toolset? there seems to be a lot of expensive tools aimed at security professionals. I'm spoiled by free software, but I could be willing to pay for something if the features are there. 
You don't need anything more exotic than `cargo rustc --release -- --emit asm`, and then read the generated assembly file. To learn what the opcodes mean, grab the [Intel Software Development Manual](https://software.intel.com/en-us/articles/intel-sdm#combined). Obviously that's for x86/x64, so you'll need the equivalent when you're working on ARM. Assembly code is surprisingly easy to learn. Dig in. Write decent benchmarks. So far, I'm enjoying using [Criterion](https://crates.io/crates/criterion). 
amazing. thanks
And you seem to get downvoted heavily for it. The oh-so-friendly Rust community can have a mean streak sometimes. :-)
And by extension, [IUI](https://github.com/LeoTindall/libui-rs) for Rust.
Thanks /u/pftbest and /u/_TheDust_! I got closer. But what lifetime would I use for `Texture&lt;'?&gt;` in `OwningHandle&lt;Arc&lt;TextureCreator&gt;, Box&lt;Texture&gt;&gt;`? I feel like I've tried everything.
I think you're misunderstanding what ````std::io::Result&lt;O&gt;```` is. Have a look at the documentation: https://doc.rust-lang.org/std/io/type.Result.html It's simply `std::result::Result&lt;T, E&gt;` where E is pre-defined as `std::io::Error`. Tip: You can click on basically any type in the rust doc and get to its definition immediately, even (especially) in function signatures :)
A lot of people have 2 or more Reddit accounts for separating certain things, let's say. One possible reason is to separate stuff you do for work from personal stuff - this way you don't get NSFW content or really any content that isn't related to your work at all if you so wish. Another possible reason is to separate an account in which your name and face are known from actions that are seem as weird or unsavory, such as certain political views, fetishes, shows and interests, etc. And of course there are also people that have multiple accounts for sidestepping bans, sockpuppetry, "forgot credentials and making a new account is just easier" and etc. That said while I'm sure there's some overlap and not every subscriber is active, it's probably not as big an amount as half the total number.
How would you compare this with what [IUI](https://github.com/LeoTindall/libui-rs) does [with an event loop](https://github.com/LeoTindall/libui-rs/blob/master/iui/examples/inputs.rs#L107)? It's also has both [an exposed event loop](https://docs.rs/iui/*/iui/struct.EventLoop.html) and [callbacks](https://docs.rs/iui/*/iui/controls/struct.Button.html#method.on_clicked). Granted it is not native Rust, since it is built on [libui](https://github.com/andlabs/libui).
thanks for all the help!
https://github.com/gnzlbg/cargo-asm is quite a bit nicer than just dumping assembly from compiler.
Oh, so it's actively developed nowadays, nice. I thought that track was abandoned.
Damn Iâ€™m \_dÃ©ception\_. I thought it was a Rust snippet inside Rust the game. &amp;#x200B; Please someone do that.
&gt; I'm (controversial opinion) not sure the Rust community has the necessary expertise to even go about this correctly without building a UI solution that doesn't work for the 90% of real-world use cases. I respect your opinion but I hope that it's wrong :-) and if it is not, that we learn from trying it out.
&gt; the teams no longer have to stand in the avalanche of comments. Then why are so many blog posts this year all about how to mitigate this problem?
IIANM not all platforms allow you to get control of the main/ui thread. In WASM the browser controls the main loop and we get access through callbacks and promises. I've been toying with the idea of building UIs around async code as the 'bottom abstraction'. Instead of setting callbacks I spawn tasks and `await!()` events on them. Tasks can then be dispatched on a main loop where I can have them, or promises / GCD / Handler / whatnot on platforms that control their own main loops.
Reading through that list is fascinating and a little bit sad. For example, the second-from-top post on r/loke (118 subscribers) asks [Is Loke Done For](https://www.reddit.com/r/Ioke/comments/20lizl/is_ioke_done_for/) â€¦ and is from 4 years ago.
Hold up, I'm retarded.
Typically, in many places, you have to get the customer, or internal legal team, to sign out every library used because every line of external code used is a potential legal liability. Saying "we're going to use language X and its standard library, written by this vendor" is quite different from "we're going to use language Y, its standard library, and a few dozen other libraries all with different licenses, written by different people". Not to mention that usually you don't know which libraries you're going to need before you actually need them.
Option should typically add about a byte of overhead. It seems unlikely to ever cause a performance bottleneck. That said, signed Nonzero numbers have been proposed to be added to the stdlib, complementing the existing Nonzero unsigned numbers. This should remove the byte overhead entirely, if there's no need to express the number zero.
FYI I already started working on integrating Reducer with the upcoming async/await features, you might be interested in checking out the WIP on this PR: https://github.com/brunocodutra/reducer/pull/11
`Option&lt;i32&gt;` is typically twice the size of `i32` (because of alignment). This means that you can fit half as many in a cache line: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=d3f5776cdd832fdd25cc53a7dd74e2be
&gt; Measure. Measure again. &gt; &gt; Make sure you understand what you're measuring. &gt; &gt; Make sure you measure something big enough that the measurement is meaningful. Can't agree with this more... Non-representative benchmarks are often worse than no benchmarks at all (assuming at least some basic awareness of what makes things slow).
Have other people solved this problem? Rust isn't the only one with an ecosystem of third party libraries. Do these companies use Python, Ruby or Javascript development, for example?
Use `Box&lt;Texture&lt;'static&gt;&gt;`. Since you cannot refer to lifetime of the `TextureCreator`, using `'static`is a hack which bypasses the compiler checks. 
&gt; had some form of mentorship for people who want to partipate We do! It's something we need to grow more, and not all parts of the project regularly do mentorship. E.g. this is a classic example of something falling through the cracks because the team doesn't have the bandwidth to follow everything, let alone mentor. Even if explicit mentorship isn't offered, pinging a team member asking for help shepherding stuff usually works. We need to provide explicit pipelines for this.
And because in rust you can get a reference into the array (in some languages you cannot) it cannot pack-away the alignment of the Option-variant value in arrays. That is, in some languages, Option&lt;i32&gt; might be 8 bytes but [Option&lt;i32&gt;; 4] might be 20 bytes (as it might choose to use unaligned access of elements and store each array-element as 5 bytes) - worse it might only do so if the total array size and element count pass some threshold. 
Not so, with integer types adding an Option later ends up doubling the size because of alignment.
Ah, guess I should have included a link to clarify. From the first paragraph of the NonzeroU32 docs: &gt; "For example, Option&lt;NonZeroU32&gt; is the same size as u32 (...)" https://doc.rust-lang.org/std/num/struct.NonZeroU32.html
Right, I meant with basic integers. A nonzero integer is the same size when you add an option layer, a basic integer is double size when you add an option layer.
Back in 2015 there weren't even that many! Kind of amazing to see where it's come since then!
I do have 2 Reddit accounts for similar reasons, but only one (this one) is subscribed to /r/rust.
"I met a traveller from a /r/random, Who saidâ€”â€œTwo vast and trunkless legs of stone Stand in the desert. . . . Near them, on the sand, Half sunk a shattered Snoo lies, whose frown, And wrinkled lip, and sneer of cold command, Tell that its OP well those passions read Which yet survive, stamped on these lifeless things, The hand that mocked them, and the heart that fed; And on the sidebar, these words appear: My name is /r/ozymandias, Subreddit of Subreddits; Look on my Top All Time, ye Mighty, and despair! Nothing beside remains. Round the decay Of that colossal Wreck, commentless and archived, The lone and level posts stretch far away.â€
&gt;this you can get the log of update using change data-capture see: [https://github.com/confluentinc/bottledwater-pg](https://github.com/confluentinc/bottledwater-pg) I also believe you could also query the original table when the required row are missing from the materialized view because of eviction. Is that correct or Noria need to query a storage that look more like a log than a table? &amp;#x200B;
I think the barrier for new syntax (newtype, anon enums in this article) should be set very high. The gain you get from writing a few less keystrokes can easily be offset by increased cognitive load. If I had my way, async/await would look like async!(pub fn myfn() { ... }); Since a macro means we are going to transform the source code. There's no need for new keywords/etc.
It was also mentioned in a [Batgirl comic](https://twitter.com/chasinglogic/status/850115493923086336)
Something like that could be nice, and certainly seems possible. But I'm not sure it would add all that much to the current method used in Rust: variadic macros, like `println!` and `vec!`.
Ooooo, thanks for the pointer!
By default it's just the same flat white Windows 10 look for both WinRT and WinAPI. WinRT apps might have a tendency to use additional extra styling, I suppose, but that's just a design choice.
Firstly, IIRC in Bingo you don't use 0, so you can use `Vec&lt;Option&lt;NonZeroU32&gt;&gt;`. It will use only 4 bytes per element instead of 8. Secondly, why do you need `i32`? Why can't you use `u8` (or better `NonZeroU8`)?
I was on the train and just used the first integer type that came to mind. Youâ€™re right; I am using `u8`. 
I'm not too sure I totally agree with introducing more syntax in the type system., which is pretty complex for newcomers already. There are workarounds, and while it's clunky to write `Velocity(f64)` it's pretty apparent what it's used for, and readability is there. For instance if the compiler can guess the type based upon later usage, this is ambiguous (from user point of view): let accel1 = 0.0; By reading this code, is this an `Acceleration` or an `f64` ? Also, what would this print: println!("*shrug* {}", my_anonymous_attempt); Would it print `*shrug* 0(T)` ? I don't know, but you would want to differentiate between the variants? I'm not sure I quite get this example, you're just shifting the destructuring elsewhere as far as I can see? &gt;A common point of critique against Rust is the standard library, which is commonly perceived as too smallâ€”a sentiment to which I very much agree I have the opposite opinion, a lean std lib is great! Have a look at java, which is heading in this direction too with [jigsaw](https://openjdk.java.net/projects/jigsaw/). The features you mention (json, xml etc..) all have pretty robust crates from the community already, but could obviously be polished. &gt;They often have to run formal verification on all their dependencies or straight up disallow the use of third-party software except for the standard libraries. I would love to know what companies are this strict with their third party dependencies. I don't even think the big boys (facebook, google, etc..) try to formally verify all their code. Good luck with javascript! 
Rust the game has electric circuits now, so theoretically we could add it as an llvm backend and cross-compile to it
If you need to manually unroll an iterator, the [`chunks_exact`](https://doc.rust-lang.org/std/primitive.slice.html#method.chunks_exact) function can help. [Playground](https://play.rust-lang.org/?version=nightly&amp;mode=release&amp;edition=2018&amp;code=%0A%23!%5Bfeature(test\)%5D%0Aextern%20crate%20test%3B%0Ause%20test%3A%3Ablack_box%3B%0A%0A%23%5Binline(never\)%5D%0Apub%20fn%20sum_iter(nums%3A%20%26%5Bi32%5D\)%20-%3E%20i32%20%7B%0A%20%20%20%20let%20mut%20acc%20%3D%200%3B%0A%20%20%20%20for%20%26val%20in%20nums%20%7B%0A%20%20%20%20%20%20%20%20acc%20%2B%3D%20val%3B%0A%20%20%20%20%7D%0A%20%20%20%20acc%20%2B%201%0A%7D%0A%0A%23%5Binline(never\)%5D%0Apub%20fn%20sum_index(nums%3A%20%26%5Bi32%5D\)%20-%3E%20i32%20%7B%20%20%20%20%0A%20%20%20%20let%20mut%20acc%20%3D%200%3B%0A%20%20%20%20for%20i%20in%200..nums.len(\)%20%7B%0A%20%20%20%20%20%20%20%20acc%20%2B%3D%20nums%5Bi%5D%3B%0A%20%20%20%20%7D%0A%20%20%20%20acc%0A%7D%0A%0A%23%5Binline(never\)%5D%0Apub%20fn%20sum_index_unrolled(nums%3A%20%26%5Bi32%5D\)%20-%3E%20i32%20%7B%20%20%20%20%0A%20%20%20%20let%20mut%20acc%20%3D%200%3B%0A%20%20%20%20for%20i%20in%20(0..nums.len(\)%2F4\).step_by(4\)%20%7B%0A%20%20%20%20%20%20%20%20acc%20%2B%3D%20nums%5Bi%5D%3B%0A%20%20%20%20%20%20%20%20acc%20%2B%3D%20nums%5Bi%2B1%5D%3B%0A%20%20%20%20%20%20%20%20acc%20%2B%3D%20nums%5Bi%2B2%5D%3B%0A%20%20%20%20%20%20%20%20acc%20%2B%3D%20nums%5Bi%2B3%5D%3B%0A%20%20%20%20%7D%0A%20%20%20%20for%20i%20in%20(nums.len(\)%2F4\)*4..nums.len(\)%20%7B%0A%20%20%20%20%20%20%20%20acc%20%2B%3D%20nums%5Bi%5D%3B%0A%20%20%20%20%7D%0A%20%20%20%20acc%0A%7D%0A%0A%23%5Binline(never\)%5D%0Apub%20fn%20sum_iter_unrolled(nums%3A%20%26%5Bi32%5D\)%20-%3E%20i32%20%7B%20%20%20%20%0A%20%20%20%20let%20mut%20acc%20%3D%200%3B%0A%20%20%20%20let%20mut%20chunks%20%3D%20nums.chunks_exact(4\)%3B%0A%20%20%20%20%2F%2F%20for..in%20consumes%20the%20iterator%2C%20but%20we%20need%20it%20afterwards%0A%20%20%20%20%2F%2F%20to%20get%20the%20remainder%20out.%20You%20can%20skip%20that%20step%20if%20you%0A%20%20%20%20%2F%2F%20know%20that%20the%20slice%27s%20size%20is%20a%20multiple%20of%20the%20chunk%20size%0A%20%20%20%20while%20let%20Some(chunk\)%20%3D%20chunks.next(\)%20%7B%0A%20%20%20%20%20%20%20%20for%20val%20in%20chunk%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20acc%20%2B%3D%20val%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%20%20%20%20for%20val%20in%20chunks.remainder(\)%20%7B%0A%20%20%20%20%20%20%20%20acc%20%2B%3D%20val%3B%0A%20%20%20%20%7D%0A%20%20%20%20acc%0A%7D%0A%0Apub%20fn%20main(\)%20%7B%0A%20%20%20%20%2F%2F%20The%20compiler%20was%20smart%20enough%20to%20optimize%20these%20to%20just%20%22return%2015%3B%22%0A%20%20%20%20%2F%2F%20black_box%20prevents%20this%20by%20forcing%20it%20to%20assume%20that%20the%20data%20could%20be%20different%0A%20%20%20%20let%20nums%3A%20%26%5B_%5D%20%3D%20black_box(%26%5B1%2C%202%2C%203%2C%204%2C%205%5D\)%3B%0A%20%20%20%20assert_eq!(sum_index(nums\)%2C%20sum_iter(nums\)\)%3B%0A%20%20%20%20assert_eq!(sum_index(nums\)%2C%20sum_index_unrolled(nums\)\)%3B%0A%20%20%20%20assert_eq!(sum_iter(nums\)%2C%20sum_iter_unrolled(nums\)\)%3B%0A%7D) example. In this case the compiler was able to vectorize all four options (see the repeated `movdqu` and `paddd` opcodes in the assembly output), but if it can't, iterating over exact-sized chunks (and maybe calling `get_unchecked` multiple times if it doesn't elide the bounds checks on the inner iterator) will give it the necessary info.
My assumption was that the capitalized "Nonzero" meant the optimizable wrappers, just as my two cents.
/r/playrust
I definitely will and thank you for writing this series! If you don't mind, what would the appropriate place be to ask questions?
&gt; Youâ€™re right; I am using u8. NonZeroU8 will be the same size as Option&lt;NonZeroU8&gt; and smaller than Option&lt;u8&gt;
That's pretty sick! Thanks for the treat
Itâ€™s exactly the solution I was looking for. Thanks!
Ohh sorry, I didn't even know that was a rule! Just wanted to share the excitement
I am reviewing some of the synchronization primitives in `std::sync`, and I can't figure out how the `wait` method on `std::sync::Barrier` doesn't deadlock, with a single thread getting the mutex on line 142 and all others getting blocked on that line. How does this actually work? https://doc.rust-lang.org/src/std/sync/barrier.rs.html#141
Oops, forgot gp commenter is more equal than I am, since I regularly get accused of insincerity on this sub. That's some grade-a double standards.
can wee change this subreddit name to r/thisistherustprogramminglanguage ?
Make sure to try to have a life outside of open source before contributing. Like, if all of your interest lies in this one contribution getting merged, you're not going to be happy long because open source can be really frustrating. &amp;#x200B; Contributing has to be a side gig unless you're a heavy contributor with privileges. Unless you communicate with the maintainers frequently, don't bank on getting huge responses more frequently than once a week. Pinging weekly or every few days because they're likely to just miss stuff. Try to keep it casual because otherwise, you'll just get really frustrated. This is just kinda how it works.
This is why I don't contribute. I usually build my own fork. Take it or leave it. If you want to use my code then clean it up yourself
This is the subreddit for a programming language named rust.You should post in /r/playrust instead Good luck getting you stuff back.
Wut? How could I miss that?
r/ThisIsRustTheProgrammingLanguageNotTheGameSoDontPostHereWaitStopThisIsNOTTheGamePleaseWaitFuck
This is the right solution for me. Thanks!
What I find weird is why wasmtime only works with text form .wat files. 
This reddit is for the programming language. You probably want to post your question to [https://www.reddit.com/r/playrust](https://www.reddit.com/r/playrust).
What kind of performance do you *need* for this Bingo simulator, anyhow? To be honest, I'm a bit bemused. Anyhow, if it's that performance-critical you should probably try to find a more performance-friendly data structure. How is the `Option` being used by your code?
&gt; not sure the Rust community has the necessary expertise to even go about this correctly without building a UI solution that doesn't work for the 90% of real-world use cases People have been getting plenty of very advanced things done in Rust. WebRender certainly seems to work pretty well in Firefox. Can't see GUI development being anywhere close to as advanced but I'm just some guy
I'm trying to create a `Cache` struct that wraps a (possibly recursive) function and a hash map, and caches all previous results. Having written the exact same thing in Swift I thought porting it was going to be easy, but I ran into lifetime issues. Specifically, allowing recursive functions is what's causing issues. The goal is to be able to write something like let fib = Cache(|n: usize, fib| { if n &lt;= 1 { n } else { fib(n - 1) + fib(n - 2) } }); println!("fib80 = {}", fib(80)); I'm wrapping the recursive closure in a `Box` and I annotated it with a lifetime because otherwise it will have the lifetime `'static` if I understood correctly, but the compiler is telling me it still can't infer an appropriate lifetime. Could someone point me in the right direction? [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8aead95a88e1336dedd375622da4db26)
Wow nice trick! I did not know about chunks\_exact
You can use u8 and treat 0 as None
Seriously wish this was in the game of Rust. 
&gt; What kind of performance do you need for this Bingo simulator, anyhow? To be honest, I'm a bit bemused. Cool your jets, man! It's a student asking a question, that's what they're supposed to be doing!
Is that exactly what react native does?
It's the same where I work. I've maintained a fork of cargo for internal use at my workplace because a nasty bug existed in cargo that prevented us from compiling certain crates. I submitted an issue complete with instructions on how to reproduce the bug which rust developers acknowledged and accepted. A short while later, I was surprised to find that the bug was closed in favor of another unrelated one, and that newer issue fixed and merged without addressing the original issue. As far as I know, the issue can still be reproduced on current versions of cargo by following the instructions listed in the original issue. &gt; Take it or leave it. If you want to use my code then clean it up yourself Perhaps doing it this way is truer to the open source spirit.
I legitimately have no idea 
Mmm, not really. Firefox is not the sort of cross-platform victory people should be touting for Rust, as much as Mozilla puts behind Rust. Itâ€™s noticeably laggier on Mac, and to boot beyond that, thereâ€™s no huge Rust GUI app victory story out there. Furthermore, WebRender is still its own path - itâ€™s not emulating native system controls, all of which have varying differences and nuances across platforms. Itâ€™s easy to dismiss this as important until you start considering the needs of things like Accessibility (voiceover, etc)... at which point, Electron or pure native start to look pretty appealing. Thereâ€™s also, comparatively speaking, very few people out there who truly know these differences on the level that matters to put out a compelling project, and Iâ€™d put money on there being less using Rust. I donâ€™t think Qt is amazing, personally, but if the Rust world wants an easy non-browser-engine target for the GUI story, they really should target that or building a better situation around GTK to beef it up across platforms. Lastly, if you downplay how difficult a good GUI solution is... well, that attitude is what led to Electron becoming incumbent. Itâ€™s the one to beat, like it or not. If itâ€™s not compelling out of the gate itâ€™s not worth doing, IMO.
[Abomonation](https://github.com/TimelyDataflow/abomonation) is another approach where one use case is exactly what you describe (memory mapping a file for read-only access). It has for example the `Abomonated&lt;T&gt;` type that wraps any `S: DerefMut&lt;[u8]&gt;`, and `MemMap` is one of those. That being said, if you get a good answer about CapnProto (it should be up for doing what you want as well), you might be more comfortable with it. Abomonation makes a few sketchy trade-offs for performance that appear correct at the moment, but could be broken in the near future as the Rust folks solidify semantics for unsafe code. The main distinction between the two is that Abomonation lets you use Rust types, whereas CapnProto introduces new types in order to interpose on accesses and such (and Abomonations assumptions in order to support that are more sketchy than CapnProto's assumptions).
No offense was intended, and I hope OP took none. I know I learned a lot from folks' answers to OP's question. I do a lot of state-space search, and can imagine building a Monte-Carlo bingo statistical simulator that wants to do 1M games per second, for example. I'm wondering if it's something like that? That's why the second part of my question was about the use of the data structure. We might be able to help speed things up better if we know a little more about what's going on here.
Or [dimensioned](https://crates.io/crates/dimensioned). ^(Full disclosure: I am the author of dimensioned.)
Edition 2018 could be announced as 2019, that's right. But if they decided to call it `Edition 2018`, then it is very good that it has been delivered in 2018. It is trustworthiness.
[Here's a possible solution.](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=a55d3228f48ee43f5ca1986d0e688474) It was almost working when I just used an `&amp;mut dyn FnMut` instead of `Box&lt;dyn FnMut&gt;`, with removing all type annotations. The only problem was that you use borrow the struct both mutably and immutably, once for the compute closure and once inside for the getting closure. I modified it a bit to get around this by splitting up the cache and closure.
Could you briefly explain your approach using `cargo-xrustc`?
That's what the compiler will turn `Option&lt;NonZeroU8&gt;` into, but with the benefit of making programmer error less likely.
/r/rustjerk is leaking
*"Don't create branded silos"* Oh my yes. I'd like there to be a broad general mature base of libraries for working with WASM instead of the JS style cornucopia of overlapping ones with minor differences and quirky names with zero information value. The higher up the abstraction layers we can push the parallel implementations by building a stable quality generic common base the better. For this to happen the base layer of libraries and tools needs IMO to be zero-cost. It needs to be able to allow the lightest of workflows (no requiring webpack and stuff to build) but have optional integrations to support being a part of larger systems. The resulting code should be close enough to what you'd get with hand-crafted JS and coding the WASM in C. I'm not saying this as an argument for optimization, but as a way of removing an excuse to create parallel low level implementations that fracture the code base and create these branded silos. Because of this I'd propose creating a code-level separation between what is considered zero-cost and what isn't. Anything new can be built at least on top of the zero-cost part of the common base, which can be broadened and expanded as new opportunities to do so present themselves. Choosing to use the common base libraries shouldn't be about if you absolutely need them or not.
Amazing, I didn't know that was possible! By the way, it looks like `dyn` can be left out here (I guess it's not necessary because `&amp;mut Trait` is of fixed size already?). Thanks a lot! I see that you also had to make `F` less general by changing it from `FnMut` to `F`, I wonder if that's a fundamental limitation of what I'm trying to do here, or if there's a way around it...
I would like to have a simpler stdin, so I would like to start working on RFC. It would be great to hear your thoughts.
Still working on [Eko](https://github.com/ravernkoh/eko), a fast and simple scripting language for Rust. I just added external functions, which will allow Eko to directly call Rust functions. Next thing to work on is adding strings (and string interpolation), which is actually surprisingly difficult to add.
Try https://github.com/sn99/brainhug
https://crates.io/crates/text_io #[macro_use] extern crate text_io; fn main() { let mut sum = 0; while let Ok(num) = try_read!() { sum += num; } println!("Sum: {}", sum); } (note: I haven't used this library or run this code)
Reminds me of a mailing list post where someone asks if they are the only user of SNOBOL4 left
&gt; While I've seen people expressing their personal frustration with a project decision get quickly moderated, Hm, could you send all instances where you think that happened to the mods team? I know we had heated debates recently, but we take great care _not_ to shut down frustrated opinions. Please keep in mind that we _still_ expect levels of respect, especially personal one.
The problem with this solution is that if you teach someone the first steps in Rust you have to start with adding text_io into Cargo.toml and "use text_io::{read, try_read, try_scan};" (this is required with edition 2018, which is the default for new projects). The Rust book examples around stdin is horrifying because they avoid topics about external crates at the beginning.
Where can I buy a "Wrong sub button"? Are there keyboards featuring it yet?
Mmmm, I've done this... and it's not as simple as you'd think, once you get past the basics. There's also (slowly) a trend of releasing things as Swift-only, which I wouldn't be surprised to see change over the coming years.
Always Rust!
`dyn Trait` is actually identical to `Trait` (as a type). `dyn` was added somewhat recently to mirror `impl Trait` and is currently optional. It should be preferred though, since it makes it clear that you're using dynamic dispatch. It may become mandatory at some point, but that would be a breaking change. [See the docs for slightly more info.](https://rust-lang-nursery.github.io/edition-guide/rust-2018/trait-system/dyn-trait-for-trait-objects.html) I forgot that I had changed that. I believe it is a problem to have recursive `FnMut`, since you could hold a mutable reference to something and then make a recursive call, in which that call would also be able to have a mutable reference to it. You should be able to work around it by either passing mutable references as parameters (which thus lets Rust makes sure you can only have one of them) or if really necessary, using a `Cell`-like.
If Java can get away with "don't worry what `public`, `static`, `void`, `main`, `String[]`, or `args` means, just copy this", we might be able to work with I/O boilerplate. It looks like [`TRPL`](https://doc.rust-lang.org/book/ch02-00-guessing-game-tutorial.html#processing-a-guess) starts off using `io::stdin().read_line(&amp;mut guess).expect("Failed to read line");` in its chapter 2 code example. [Latest info I can find](https://github.com/rust-lang/rfcs/pull/67#issuecomment-46376512) on including something like your proposal is from 2014, saying that "a feature such as this should bake in a library before being accepted into the main repo". Since that appears to have happened, that would be a good place to bring this up.
There is a comment form at the end of each post, that's probably the easiest way. 
Well, but Rust is ~~better than~~ not Java. Since the introduction of \`fs::read\_to\_string\` it looks like a sane idea of baking a similar helper for stdin into std. I think that \`get\_line\` would cover most of the introductory needs of working with stdin.
Great to hear that you like it!
They also maintain Tor Browser which is based on Firefox, which is using more and more Rust anyway. So I guess it makes a lot of sense for them.
Ah, I didn't realise I hadn't opted into that lint in this particular project. I'll definitely include `dyn`.
Arguably the last thing someone should be learning as the first steps in any given language is interactive IO streams. I'd go further and say that if you're still early enough in your programming learning curve that easy access to stdin is a tipping point, then Rust isn't the first language for you. The std lib of Rust is intentionally lean and so very early on a learner must pick up external crate usage... deferring stdin until they've got that down isn't actually a bad idea.
Got it, thanks
No worries :). Yeah, it seems like there are either systems with a MMU and paging, or small (e.g. embedded) systems with only physical memory today. I can't think of another segmentation example either, I think x86 is the most common. So I think we can just keep the blog the way it is. 
&gt; are all different, regarding #1 if you ever looked at a SQL query execution plan you have seen the data-flow the database engine is executing. Similar query will have similar data-flow where some operator will perform the same table scan or the same table join. The result of those operator is then passed to other operator that would be different. In Noria operator inside the data-flow have it's own cache and since those operator would be reused a lot those cache would also be reused a lot.
After having a look, they do have a lot in common. Apart from being an extra abstraction layer, I also have a hard time seeing how it's possible to integrate futures with IUI, which is something I think would provide quite an advantage if I get it right (and futures/async/await becomes more stable). But maybe it is possible, and I'm just not seeing it. I've added a section to the Readme that compares thin_main_loop with IUI.
How many of subscribers still thinking that they subscribed for rust game subreddit?
Amazing, great job. I had a good laugh. One tiny nitpick is I believe pest isn't actually faster than nom. https://pest.rs/ look at the benchmarks on the pest site. Not hating on pest though, I think it's pretty cool
 &gt; IIANM not all platforms allow you to get control of the main/ui thread. In WASM the browser controls the main loop and we get access through callbacks and promises. Correct. For those platforms only parts of the API will be available. &gt; I've been toying with the idea of building UIs around async code as the 'bottom abstraction'. Instead of setting callbacks I spawn tasks and await!() events on them. Tasks can then be dispatched on a main loop where I can have them, or promises / GCD / Handler / whatnot on platforms that control their own main loops. Right, so that is a type of library that is meant to be able to build on top of this library. Because callbacks is what the native libraries offer (in general), we first build a thin main loop + callbacks that is cross platform. If you then build something more rustic on top of that, you get cross platform support for free.
I think a simple "map this page to this frame" syscall would suffice. The authors only mention this: &gt; If the underlying hardware defines a page-table interface, then an exokernel must guard the page table instead ofthe TLB. [...] As dictated by the exokernel principle ofexposing kernel book-keeping structures, the page table shouldbe visible (read only) at application level.
A topic with more than 100 comments was simply removed: [https://www.reddit.com/r/rust/comments/adfyhq/dude\_has\_100\_empty\_crates\_with\_the\_most\_common/](https://www.reddit.com/r/rust/comments/adfyhq/dude_has_100_empty_crates_with_the_most_common/)
Haha! I was expecting tons of downvotes for the post but not for this comment ;)
Oh man. This is fantastic. I might actually refer back to this page, specifically the parallel and error handling stuff.
Ok, let's see if I can answer that properly. I'll try to be exhaustive, but that'll probably be a bit of text. For reference, the code in question is \[here\]([https://github.com/KillTheMule/nvimpam/blob/impro/src/folds.rs#L64](https://github.com/KillTheMule/nvimpam/blob/impro/src/folds.rs#L64)), but it's generally a mess right now, I've just implemented that feature and noted performance isn't what I need. In particular, lots of things have names that don't quite fit... The updating function is \[here\]([https://github.com/KillTheMule/nvimpam/blob/impro/src/folds.rs#L103](https://github.com/KillTheMule/nvimpam/blob/impro/src/folds.rs#L103)), the comments delimit the part that deals with the highlights. &amp;#x200B; The program is an editor plugin. After loading a file, the editor starts the plugin. The plugin firstly grabs the file on the disk again, reads it into memory, and parses it. That would be the "create" step. I keep the file in memory. There are mainly 2 events the plugin deals with: &amp;#x200B; 1. If the file is changed in the editor, the plugin gets an update event (line-based, sends the line range that was deleted, and the new lines to be put in; if 1 line was modified, the range consists of that line, and one new line is sent in full). In that case, I update my copy of the file, run parsing over the necessary subset (maybe a bit larger than the updated range), and then update the highlight data (I also keep other data around that needs updating, but don't mind that). When the update is done, I need to read the highlight data for the freshly parsed range and send it to the editor (an easy optimization here is to send the new highlight data directly, before updating the internal structures; this doesn't help as much as it seems though, since the user might be typing somewhat fastly, and I need the updates to finish before the next keypress, roughly). 2. The user sends a highlight request (by pressing a key). In that case, I need to read a range of highlight data and send it to the editor. I don't expect this to happen interwoven with updates often, and if that happens for some reason, some delay is not a problem. So, "updates" are really "updates followed by reads" and can come in pretty frequently (as fast as one can type). Some throttling might be feasible here... The reads that happen out of updates are infrequent, and mostly not interwoven with updates. &amp;#x200B; Is that the info you needed? Otherwise, let me know :) Thanks for thinking about this!
Thanks for your engaging on this! \&gt; Hm, could you send all instances where you think that happened to the mods team? I know we had heated debates recently, but we take great care *not* to shut down frustrated opinions. Just FYI, this notion of "sending things to the mod team" as in taking them out of public view is also something I dislike (and doesn't seem to square with this notion of radical openness that people also mention). The example I had in mind was the moderation happening on this internals thread: [https://internals.rust-lang.org/t/followup-on-website-concerns/9018](https://internals.rust-lang.org/t/followup-on-website-concerns/9018). \&gt; I'm wondering where this feeling comes from. We *have* had aggressive behaviour of groups in the recent month, but this implies that the whole community has been painted as such. My feeling is still that groups get aggressive when the project (or even the mods) give them reasons to get aggressive -- by moderating without communicating well about what the expected behavior is, or by not listening, or not responding to the community's concerns. That's actually what I'm trying to get at here. I watched the video from Aaron &amp; Niko's presentation at Mozilla's June SF all-hands, and it really elucidates this problem in the first 10 minutes or so, where the project acts in a way that the larger community disagrees with, and when confronted with that feedback from the community the first response from the project seems to be (in several cases) to double down on the decision, to be defensive about why the process/decision is okay. Only later (sometimes), there's a more of a sense of, "hey, we might have actually gotten this wrong", let's rethink the process that led us here. So again, in that vein, I think the website episode, or the cratesquatting threads, all really follow this pattern where some ingroup thinks they have consensus but they miss the point that the community is trying to made, and turning that back into something constructive is hard and painful and therefore sometimes doesn't happen.
Works fine over here.
Not sure what you mean by this? Doesn't seem like a very nice comment on the face of it.
I wonder if some rust programmers started playing the rust game just for being curious.
Too bad you take credit for the original post (by the author of the article) from /r/programming. Next time, please make a crosspost or at least mention it in your title.
For reference, I think the joke is based on https://www.willamette.edu/~fruehr/haskell/evolution.html.
You can also use [https://rust.godbolt.org/](https://rust.godbolt.org/) it could be enough for your need.
https://github.com/KappaDistributive/rs2048 was built specifically for those new to Rust to contribute to. It's got some interesting issues posted. A 2048 game won't change the world, but it's fun to play with.
I want to see the equivalent of the last solution [here](https://chrismorgan.info/blog/rust-fizzbuzz.html).
Yeah. I have a PIM hobby project where I need to develop the grammar experimentally by iterating on 20+ years of outline notes that I habitually structured using a homegrown syntax that's vaguely reminiscent of a less freeform Markdown and I'll definitely be choosing pest for the better error messages. I can only imagine it would be very painful to use nom's errors for feedback when experimentally developing a grammar for an organically grown syntax which probably has the occasional spot which will be a legitimate syntax error (to be corrected in the source files) once the grammar is worked out.
I.. can't, actually. I don't remember what exactly I did and I've never made any scripts to help, but I'm pretty sure that I just did `cargo xrustc --emit=llvm-ir` or something of that sort.
I used nom to make a binary file parser, which was quite pleasant. I had a bigger struggle with a text-based parser in nom, again with error messages that left me scratching my head. At the end of the day, for the binary format parser, to parse files many 100's of megabytes, speed was nice. To parse a few kb of source files, you might as well choose what you like, because the difference will pretty much be trivial. 
You wouldnâ€™t deref `Nums` into a `Vec&lt;i64&gt;`, why would you when you can deref into a slice `[i64]`? :)
"Outdated Rust Programmer" should use "try!" instead of "?" in my opinion.
I don't understand the problem. Rust gtk already exists, what isn't it doing that we need something like relm for? 
I have no idea how you can casually laugh at this. To me this is taken straight out of a nightmare about work.
source: https://www.reddit.com/r/programming/comments/agh8dh/the_evolution_of_a_rust_programmer
I remember an article about that : [https://www.reddit.com/r/rust/comments/9lc6tg/no\_pest\_is\_not\_faster\_than\_nom/](https://www.reddit.com/r/rust/comments/9lc6tg/no_pest_is_not_faster_than_nom/)
I've never had a single problem with rls, using it from both vim and vscode. What did you run into? 
I can't help but notice this has some similarities with [calloop](https://github.com/Smithay/calloop), that we use in smithay, and I plan to use for the wayland backend of winit for its eventloop rewrite. Though calloop is meant to handle not only GUI events and callbacks, but also events from other sources (as is needed in a wayland compositor). 
This is pretty cool. The fact that Emil SjÃ¶lander is behind makes it even more interesting. I would love to have a technical overview of their build system. A lot of people are interested in using Rust on mobile but the toolchains/build process can feel clunky (xcodebuild/gradle/cargo) at times. Thanks for sharing!
&gt; I know we had heated debates recently, Yeah thats tru- &gt; but we take great care not to shut down frustrated opinions. ...you at least read those debates, right? Before they were removed, i mean. &gt; I'm wondering where this feeling comes from. ---- &gt; Please keep in mind that we *still* expect levels of respect, especially personal one. feeling this even needs to be said doesn't imply a great view of the community, &gt; We have had aggressive behaviour of groups in the recent month, thats just another way of saying "angry mob", so i'll take a guess and say thats where "angry mob" feelings are coming from. &gt; but this implies that the whole community has been painted as such. Not really the implication i would go with. Maybe significant parts of "the community". Or at a bare minimum, at least the one on this subreddit, and counting heavily upvoted opinions in said "heated debates" to represent community consensus, and likewise for downvoted ones.
The site uses too much "fearless" which is actually a meme on that subreddit
&gt; I donâ€™t think Qt is amazing, personally, but if the Rust world wants an easy non-browser-engine target for the GUI story, they really should target that or building a better situation around GTK to beef it up across platforms. In the GTK+ 2.x era, I would have agreed with you. Given the opinionated stance on UI design that GNOME has been pushing into GTK+, and that, last I checked, the [gtk3-mushrooms](https://github.com/TomaszGasior/gtk3-mushrooms/wiki/Screenshots) patchset had no *buntu PPA, I'm not going to target GTK+ 3.x for anything where I'm using the provided widgets. (I do have a Python project where I just use the mainloop and libwnck without actually drawing windows of my own that I'm migrating from PyGTK and GTK+ 2.x to PyGI and GTK+ 3.x... because there's no PyQt equivalent to libwnck.)
&gt; in my experience, it's only hard when they actually aren't. 100% this. The new website design in particular got next to no community feedback, except a week before it's apparently super important deadline(so much for no deadlines), with no time to implement any changes even if they wanted to, and then they immediately went on holiday and said "don't open issues with improvements" The website is *almost* good, and i'm a fan of the better color scheme that was mocked up in one of the github issues, though thats by no means the only major issue.
I believe the [relm intro](http://relm.ml/relm-intro) does a pretty good job explaining why it was created, no?
or wxWidgets, for that matter... though I wouldn't point to the wxWidgets APIs as an example of comfortable API design.
You've never had a *single* problem? So it always gives you perfect autocomplete for every type, all the time? It never crashes, or hangs, or gets in some loop uselessly using up CPU? It doesn't occasionally fail to update it's index and need restarting? Because i highly doubt you havnt experienced any of this on all but the simplest of projects. It may also be a case of not knowing what you're missing. As a VSCode user myself, i take it for granted that rls won't reliably provide autocomplete, especially, for some reason, for Result/Options, but thats still to be considered a bug, and something that IntelliJ does much better at. Though IIRC, technically RLS doesn't provide autocomplete period, it forwards to a project called Racer, so no compiler type information or anything. Yay.
&gt; However, my opinion has shifted (albeit inspired by the Xi editor project). I'm of the believe if you want native (not "native") UI, then you should be writing your application UI in the language/toolkit of the platform. If you want the same look &amp; feel everywhere, then use whatever you want. Unfortunately, I don't trust myself to write reliable C++, so "native (not "native") UI" for my KDE desktop means PyQt.
&gt; Finance without fear Is it possible, i wonder, for rust to setup an organization not to accept money as commonly suggested, but to facilitate companies paying specific people for specific features? Company X wants Z, so Rust Org asks around and finds community member Y and helps connect them with Company X and may assist in contracts and the like? Rust Org never has to touch any money or deal with the complicated legal pitfalls of figuring out how to spend it, it simply exists to connect companies with people. Does this even make sense?
&gt;(should've crossposted myself, but I thought it would be against the "no memes" or something) Not every image is a meme though.
Actually, disregard my earlier comment; I used `cargo xrustc --release -- -Z pre-link-arg=-nostartfiles --emit=llvm-ir`
It looks like the Haskell Rust programmers are the cleanest writers of code :D *totally_not_biased.jpg*
To be clear, I lumped GTK in to avoid someone coming out of the woodwork saying it works fine. I don't really believe it does, hence my "beef it up"... but whatever. Neither Qt nor GTK really look or feel native across platforms (someone will inevitably respond to this saying Qt is native, [but it's not always - it often draws custom controls, or reimplements what should be standard yet happens to be buggy](https://bugreports.qt.io/browse/QTBUG-72406)), they're just the closest you can get without having to do the insane amount of work yourself. Also, hell, none of this is even touching on the other reason people use Electron: sometimes you'll have an upstream UI framework (Apple/Cocoa) just rip shit out in a new OS release, and you're left wondering what happened. Electron is a black box that "just renders the damn content wherever it needs to run". This alone is a challenge I don't see discussed too often. (Cocoa's also got an absolutely astonishingly bad level of linkrot in documentation, where it can be very difficult to figure out how to do something in the framework unless you've worked extensively with it before)
hey there (:
If you're sure you want it to last forever, you can `Box` and then [leak](https://crates.io/crates/leak) it to get a `&amp;'static` that you can put anywhere. You don't even need to retain the `Memmap` reference itself; just the reference to the memory allocated by the kernel, so there's no extra indirection because of this approach. If not, I'd use `Arc` or `Rc`. You could use `owning_ref` or `reffers` to avoid the indirection on use.
Thanks man!! 
Yeah... no, this isn't _entirely_ accurate. [According to this page, the working widget set for Lazarus is Carbon-based, _not_ Cocoa based](http://wiki.lazarus.freepascal.org/Roadmap#Status_of_features_on_each_widgetset), and the last release I know of (v2.0?) had Cooca support as a beta that you had to compile from trunk. Last I tried it myself, Cocoa was a bug-ridden mess in Lazarus; Carbon is limited to 32-bit applications, which are being phased out on macOS, so this really isn't as clear cut as it sounds on the surface. In many cases you'll just get recommended to fall back to Qt5 on macOS. I know some people have managed to get Cocoa compiling with Lazarus, but it's not a bug-free or even remotely full experience (Cocoa in general is neglected by Apple, sadly). Lazarus is very impressive, but it's not as accurate as people portray - this stuff isn't easy, and acting otherwise downplays the significance of the task.
I'm pretty sure that all of this can be done without any macro.
&gt; Since the introduction of fs::read_to_string it looks like a sane idea of baking a similar helper for stdin into std. The value proposition of `read_to_string` is that it takes an `AsRef&lt;Path&gt;` though, so you don't have to manually open the file from a path. &gt; I think that get_line would cover most of the introductory needs of working with stdin. That seems completely unnecessary given `BufRead::lines`
[https://github.com/mimblewimble/grin](https://github.com/mimblewimble/grin)
It can, but not this concisely.
&gt; Just FYI, this notion of "sending things to the mod team" as in taking them out of public view is also something I dislike (and doesn't seem to square with this notion of radical openness that people also mention). The example I had in mind was the moderation happening on this internals thread: &gt; https://internals.rust-lang.org/t/followup-on-website-concerns/9018 &gt; . What moderation are you referring to? The closing or the flagging? Flags are community action and _not_ moderator action. If a post gets &gt; 3 flags, it's automatically hidden. If your posts gets hidden, you face community backlash. The only moderation that happened is closing the thread and the reason that is given is in the thread. You are free to open new threads, we don't shun the topic. &gt; My feeling is still that groups get aggressive when the project (or even the mods) give them reasons to get aggressive -- by moderating without communicating well about what the expected behavior is, or by not listening, or not responding to the community's concerns. That's actually what I'm trying to get at here. We've had harrassment cases around the website. People got massively insulting. Are you arguing that they are okay or that _we_ did give reason for them? I think you are making it to easy by saying that there's not community responsibility. Yes, there's cases where we have to later come back and say that we made a wrong decision. But we're humans in a very unique situation and I have to stand in for the right to eff up. &gt; Whew, that got long. Does this resonate at all for you? No, actually not. You're putting the blame squarely on the team, without showing ways how we should deal with communicating to a project with 4700 contributors and an even larger community, with a very small team.
&gt; And as the OP mentioned, there seemed to be a lot of "shutting down" of criticism on the terrible new website design, with critisisms, better suggestions and improvements, and discussion in general being shut down, issues closed, even explicitly called to "not be reported period until after the holidays", because thats a great way to foster discussion and openness and 100% not saying "shut up, we don't care, maybe we'll consider caring after X date. You'll probably forget by then so we win." Most PRs to the website are actually merged, I recommend you to scroll through https://github.com/rust-lang/www.rust-lang.org/pulls?q=is%3Apr+is%3Aclosed GitHub issues have an interface problem: they can only be "closed" and there's no indicator if they are closed as "solved" or as "not accepted". I don't accept the story of "shutting down" criticism, without also accepting that the page is the work of all project working groups and presents their needs and the huge pains that the old website has brought. That wasn't reflected in the community discourse at all and also a huge source of frustration to us as project members.
And *that* joke is based on the Evolution of a Programmer: https://web.archive.org/web/20040812114808/http://www.cse.ogi.edu/~diatchki/jokes/programmer.html
I would love to see usage examples and better [documentation](https://docs.rs/stretch/0.1.7/stretch/).
From what I've heard, this problem is rarely *solved*, it's just not as bad if you have a big standard library. Getting things approved is hard, so you can usually get away with, say, boost for C++, but not much more. Maybe a domain-specific library or two, where even legal can see the value proposition. Everything else you implement yourself, perhaps with "major inspiration" from another library. Now look at the dependency tree for `rand`. Think of all the ad-hoc RNG implementations that will get written because the famous, well-maintained package must not be touched. &gt; Do these companies use Python, Ruby or Javascript development, for example? I'd say unlikely.
Something like this? use std::{error::Error, io::Read, str::FromStr}; fn read&lt;T&gt;(mut read: impl Read) -&gt; Result&lt;T, Box&lt;dyn Error&gt;&gt; where T: FromStr, &lt;T as FromStr&gt;::Err: Error + 'static, { let mut buf = String::new(); read.read_to_string(&amp;mut buf)?; let result = buf.parse()?; Ok(result) } fn read_stdin&lt;T&gt;() -&gt; Result&lt;T, Box&lt;dyn Error&gt;&gt; where T: FromStr, &lt;T as FromStr&gt;::Err: Error + 'static, { read(std::io::stdin()) } fn main() { let input = b"123"; let x: i32 = read(&amp;input[..]).unwrap(); assert_eq!(x, 123); // Read an int from stdin: let x: i32 = read_stdin().unwrap(); }
To avoid rehashes: any other instances, or only the website? We have a public apology about that out, but I'd also like to see some reflection about the community about their behaviour around that.
Your original idea of having a ref and the owned data in the same struct is possible with the `owning_ref` crate: https://kimundi.github.io/owning-ref-rs/owning_ref/index.html 
I'm not sure that Haskell programmers would be using `unwrap` so much though. Returning a `Result` for anything that could fail feels more Haskelly.
&gt; Most PRs to the website are actually merged, I recommend you to scroll through https://github.com/rust-lang/www.rust-lang.org/pulls?q=is%3Apr+is%3Aclosed I havnt checked recently, but it was true at the time, and a quick skim now shows it's still true. The ones that are peoples primary problems with the site remain closed and locked. Quick skim and most of the closed seem to be low hanging fruit or objective bugs(Which raises further concern about the process, by the way. Fun Fact: The initial release didn't bother to include redirects, so broke SEO and existing links to the site. Fun! But wait, a [PR to fix](https://github.com/rust-lang/www.rust-lang.org/pull/597) that got merged relatively quickly. But wait again! It didnt actually get deployed until over a week later, so no redirects!) &gt; I don't accept the story of "shutting down" criticism, I'm not sure how much more clear you can get than "literally don't give us any criticism until after the holidays". [The thread i was quoting from](https://internals.rust-lang.org/t/followup-on-website-concerns/9018) As i understand it, peoples primary concerns with the website are the mismatched garish colors, and the process that led to this all in the first place, which i'm sure by *pure coincidence*(/s) are specifically the things that shouldn't be discussed. About the process specifically, the idea that Rust is the only programming language that knows what it's doing and everyone else is wrong that [was the forefront of the new design](https://github.com/rust-lang/www.rust-lang.org/issues/431#issuecomment-442985053), which when you consider every *other* mainstream language site and compare it to Rusts, either Rust is the one enlightened language and ux designer and everyone else is wrong, or the design is bad, and it can't be the latter because the team says the design is fine! Who needs silly stuff on the site like "listing the features", "code examples"([another issue thats closed, notably](https://github.com/rust-lang/www.rust-lang.org/issues/396)), "saying you're a programming language" If the rust core team very clearly, point blank, saying not to criticize the process or suggest major improvements, and [removing discussion on the subreddit](https://www.reddit.com/r/rust/comments/a5fw5u/two_things_about_new_website/ebmuin0/), isn't enough to count as "shutting down criticism", nothing is, and theres no further point to this conversation.
Note that it's the uptenth rehash of a repeat discussion that always sparks the same comments and moves into aggressiveness quickly.
I'll just link my [response](https://www.reddit.com/r/rust/comments/a6cz6o/every_software_project_should_have_a_hello_world/ebvd0mw/?context=3) from the first time that followup came up. TLDR: "seeing a lot of retrospectives on listening to the community but not a whole lot of "doing" and, well, "listening""
&gt; Fun Fact: The initial release didn't bother to include redirects, so broke SEO and existing links to the site. Fun! But wait, a PR to fix that got merged relatively quickly. But wait again! It didnt actually get deployed until over a week later, so no redirects! Could you please get wound down a little? And not rehash _all the things_? We've been through it and I know this wasn't stellar. &gt; If the rust core team very clearly, point blank, saying not to criticize the process or suggest major improvements, and &gt; removing discussion on the subreddit &gt; , isn't enough to count as "shutting down criticism", nothing is, and theres no further point to this conversation. Kibwen is not core, and there have been _tons_ of discussions on this subreddit which drowned out other relevant design. &gt; I'm not sure how much more clear you can get than "literally don't give us any criticism until after the holidays". The thread i was quoting from That's perfectly fine feedback. We have lives, families, holiday, kids. We're not a 24/7 shop, we're a project mostly staffed by volunteers. &gt; Who needs silly stuff on the site like "listing the features", "code examples"(another issue thats closed, notably), "saying you're a programming language" You are basically saying that these things should be no-brainers, but these are actually relevant and valid decisions. 
Interesting app, thanks for sharing it! Some stuff off the top of my head: take it for what it's worth: * The README needs to be fleshed out. That makes it easier to see what the code is going to do. * You have a LICENSE file in the repo, so a short description of the license in the source is probably plenty. * 800+ lines is pretty long for a single Rust file: it makes it harder to read. Find some way to break it into modules. Splitting out the argument parsing would be a good start. * The error handling in `read_file()` looks like you are returning an empty file when you can't open a file. Probably make `read_file()` return a `Result` and use `?`. Also, `collect()` the lines rather than pushing them one at a time. * There are several places where you could use `collect()` rather than a loop. * `parse_graph()` takes rather a lot of arguments. Probably pass `&amp;config` rather than all those parameters. * There's a common pattern of creating structs with empty containers and then filling them in later. This isn't bad, but it can lead to more awkward code. Try to collect all the data before building a struct if you can. * `main()` should be at the end of the program. It makes it easier to find: I think most code readers like to start or end there. * That "dedup files" code near the start of `main()` is a bit strange. I think that let set: HashSet&lt;String&gt; = config.files.into_iter().collect(); let args: Vec&lt;String&gt; = set.into_iter().collect(); would be more idiomatic; I don't think efficiency matters here. * Use pattern matching with `&amp;` to get rid of the `*`s in your program * The calls to `Arc::clone()` look like they could be replaced with `.clone()`. * Why is an `unsafe { transmute() }` needed here? * A lot of things look like they could be impl struct methods rather than functions. It's way past my bedtime, but hopefully this is a start. I'm sure someone will correct me on some of this.
I think I'd prefer to hear concrete use cases instead of speculation. At least, it sounds like you're speculating on the needs of companies. It would help to make that clear. Given the speculation on your part, I think your previous commentary is enormously hyperbolic.
Actually nearly everything, however most things are still not "quiet there". First thing is network services - Rocket does excelent job with creating REST apis. Doing in-browser applications looks promising with WASM support and helpers crates. Some game developers also are looking towards Rust (not without reason), but there is still no good and mature engine. Desktop applications is something, which in my opinion Rust is the most behind, just because of lack of reasonable GUI library. 
Noted. As you want to see action and change, and the website is your only point, I don't see any reason to further discuss. I'm willing to take the action part and expect you to closely monitor and give positive feedback when something works the way you want. Thank you.
&gt; Could you please get wound down a little? And not rehash all the things? We've been through it and I know this wasn't stellar. We have? When? Where? What? &gt; Kibwen is not core, and there have been tons of discussions on this subreddit which drowned out other relevant design. [This should help clarify for you.](https://i.imgur.com/q7cIWBc.png) &gt; That's perfectly fine feedback. We have lives, families, holiday, kids. We're not a 24/7 shop, we're a project mostly staffed by volunteers. [I believe what i said in my original comment will help clarify.](https://www.reddit.com/r/rust/comments/agdkwm/rust_2019_ownership_without_fear/ee6nu72/?context=3) "Noting that theres a difference between "FYI, we're not dealing with issues until after the holidays" and "Don't make any issues until after the holidays", the latter of which is what the thread OP linked says" They are not saying "We're busy over the holidays and won't have time to look at issues", they're saying, very clearly, in plain English, "do not make an issue at all". Those are two *very* different things. They have no obligation to look at it over the holidays, but that doesn't mean people can't/shouldn't make them. &gt; You are basically saying that these things should be no-brainers, but these are actually relevant and valid decisions. They are no-brainers, and they are things that *everything else does just fine*. What kind of product doesn't tell you what it does, or even what it ***is***?! Why do you think those isnt a no-brainer? Would you have used Rust if it didnt tell you what features it had? Or that it was even a programming language?
&gt; The calls to Arc::clone() look like they could be replaced with .clone(). That's probably https://rust-lang.github.io/rust-clippy/master/index.html#clone_on_ref_ptr.
Just for clarity: I'll stop responding here, I'm not the punching bag for your anger.
The website is brought up often because it's the latest and most notable issue people are having right now. Dismissing it out of hand because of that is the other notable issue, so luckily for you, eventually people will stop bringing up the website and start bringing up how concerns(mainly about the website) are dismissed out of hand if too many people share them.
I'd like to think I'm "Functional Rust Programmer", but... hmmm.
I'm not sure why they needed deref at all in that example? 
Well you shouldnâ€™t be subjected to those sorts of comments either. It sucks if you did and I hope people call it out. That said, this doesnâ€™t justify rudeness on your part. 
Iâ€™m not sure either. Because newtypes typically deref into inner types I guess.
[Oh the punching bag comment again](https://snew.notabug.io/r/rust/comments/a55o1o/error_404_when_coming_from_a_search_engine/ebk8f4x/) This is the second time i've seen you throw that out of nowhere for no discernible reason in response to criticism. Stuff like this is why people are having issues with the rust team.
Perhaps a Haskeller would use `unwrap` just out of spite because there are no proper monads or `do` notation.
@sunfishcode says that wasmtime works with both.
The state of play in a few non-systems areas: * http://areweguiyet.com * http://arewegameyet.com * https://www.arewewebyet.org * http://www.arewelearningyet.com * https://arewedistributedyet.com And a catalogue of such pages: https://wiki.mozilla.org/Areweyet
Fair enough. I just find it a bit off-putting that recent GTK+ versions feel less native on a KDE desktop than Windows or MacOS apps would if you configured Qt to mimic their theming. (I have to say it. When GTK+ on a KDE desktop feels more alien than MacOS, something's gone horribly wrong.)
As far as the language itself goes, you can do anything in Rust. That's what makes it so exciting. It's fast, gives you low-level memory access when you need it, it provides great tooling and a great standard library, and it's hard to find a better language to write multi-threaded code in. The ecosystem still has some work to do, though. For example, bindings to GUI toolkits are still a work in progress and the web development ecosystem won't be something I'd recommend until async/await has stabilized and been picked up by the frameworks. I like to use it comfortably and easily write: 1. Really efficient command-line tools that start up instantly and can be easily built against musl-libc so that, like Go, they have no external dependencies. 2. Memory-safe compiled libraries to be imported from runtimes like [CPython](https://github.com/dgrunwald/rust-cpython), [Node.js](https://neon-bindings.com/), and [Ruby](https://usehelix.com/).
Thanks for drawing attention to this! When I read these docs the first time, after seeing it in 1.31 release notes, I must have missed this part: &gt; Due to each chunk having exactly `chunk_size` elements, the compiler can often optimize the resulting code better than in the case of `chunks`. 
I think the thing with most open source projects is it's easier to start simple: Like childishly simple. Even though you're contributing your time and effort, there's still some trust to be built up. I personally don't really have the patience so tend to just build my own things or fork them.
&gt; As far as I know, the issue can still be reproduced on current versions of cargo by following the instructions listed in the original issue Sounds like there's been a mistake/misunderstanding about what the original bug was, and someone needs to test it to make sure and either re-file or re-open the original. Could you post a link to it? I think any software development works best as an iterative process: communication is hard, humans make mistakes, and bugs might not be fixed when they're labelled "fixed". None of these are malicious, and helps a lot when people point out when they see something that looks like it's not quite right.
I was very seriously considering it because it's very similar to one I envisioned (funnily enough, Rust is a very similar language to the one I envisioned :D). I don't have that much time, though.
Wasmtime works with both; I'd be interested in what problems you encountered.
I'm pretty sure back in 2009 we used `~[T]` instead of `Vec&lt;T&gt;` also... and backslashes for lifetimes ;)
Right! This was probably the eventloop I vaguely saw somewhere and then forgot about it. Glad you brought it up, API wise it looks quite similar to what I'm envisioning. Although it seems tied to mio rather than having many different native backends, which makes it unusable e g for building a native Win32 GUI. Right?
thatsthejoke.jpg
I like how in Perl6, the parameters of `main` are the implicit command-line args: https://docs.perl6.org/routine/MAIN This *significantly* reduces the time a beginner needs to get the command-line args out of the way and get to the actual thing they want to do. I can't recommend this approach enough.
I don't know enough about Win32 to answer that. The way I use it for wayland is that it uses mio to wait for readiness on the wayland socket, and once events occur there it triggers a callback that starts the mechanism of actually reading from the socket and parsing/processing the events, and triggering the callbacks. &amp;#x200B; So yes, it makes the assumption that the connection from the window server is a resource that can be pooled for readiness using mio (as on linux it's an unix socket connection), so that it's the event loop that triggers the calling of callbacks (this gives the interesting guarantee that no two callbacks are ever called concurrently, which helps with state sharing), and not the OS directly. I don't know how Win32 works, so I have no idea of adaptable to it it would be. 
Oh ok. I did not get anywhere as I had no idea how to use it. There is no obvious starting point.
Waiting on I/O readiness would certainly be something that would go into thin_main_loop, but rather than waiting on `mio::Evented`, it would wait on fds on linux, handles and sockets on Win32, and so on. 
I was hoping \`mio::Evented\` was a general abstraction over all theses...
Coming from Haskell, the just-unwrap-it culture feels like cocaine. 
No offense taken. You may be right about premature optimization. At a high level, hereâ€™s my project. If you assume that every possible board of bingo takes part in a game, the odds should work out such that there are three times as many horizontal wins as there are vertical wins. This assumption obviously isnâ€™t very good. There are many possible bingo boards, and usually fewer than 100 people playing. Thereâ€™s a big discrepancy between those numbers. I would like to test (using Monte Carlo simulations) the behavior of the ratio between different types of wins (horizontal, vertical, diagonal) as a function of the number or boards in play. I figured that I would be able to to further out on the line toward all possible boards with a more optimized system. Also, optimization is fun. Initially, I used a 2D array for the board. I was checking for bingos naively. I thought it would probably be better to, on creation of the board, to extract all possible winning sequences (there are 12) into a list. So, I ended up with a vector of twelve vectors, each with five elements representing a winning sequence. As an example, the five rows are each their own sequence. The five columns are their own sequence. The two diagonals are their own sequence. I figured this would be easier to check, and would be more cache friendly to have no more sequences stored in columns. Everything is now a row. My idea now is to start with this vector of sequences and â€œfeedâ€ in number picks from an rng. Each pick would be checked against the members of the sequence. The members of the sequence would actually be Check&lt;num&gt;, where Check is an enum with variants Found and NotFound. Once a sequence is full of Found variants, it constitutes a win. I said high level, and then immediately gave you everything I was working on. Oh well. If you have a better idea for a data structure, I would be very interested. 
From the "cli"? [https://docs.rs/tui](https://docs.rs/tui) or its examples might help? 
Haha, thatâ€™s all right. u/po8 may have a point about unnecessary optimization. Iâ€™m probably a victim of it more than most. Itâ€™s just often more interesting than actually working on the problem. 
thank you very much.
Also coming from Haskell, partial functions are just something I instinctively avoid.
Also why not throw in some @T for GC references! 
Look into OpenGL wrappers.
As a fake functional programmer who graduated from the Java streams school of functional programming, I'd definitely at least just `unwrap_or_else(|| {eprintln!("bad input, adding zero"); 0});` those parse statements (I mean it's a sum, it seems legit!). Maybe try and stick everything in map/and_then calls for instead of just unwrapping the stdin lines.
It's definitely nice and expressive for writing grammars. I just wish it could generate contexts for each rule instead of a global enum of _all_ rules. I don't buy idea that unwrapping _everything_ is "idiomatic pest". I am quite used to using Antlr with Java, and I wish it could be more like that :(
No! Don't @ me!
For Linux it mostly works because of `mio::EventedFd`, but on other platforms I'm not so sure...correct me if I'm wrong but it seems like mio only accepts its own tcp and udp socket abstractions on other platforms.
As far as I know, BufRead::lines will block the program execution until EOF. Introductory use of stdin, in my opinion, requires interactive mode.
I'm not sure. The documentation says ([https://doc.rust-lang.org/std/sync/struct.Arc.html#method.clone](https://doc.rust-lang.org/std/sync/struct.Arc.html#method.clone)): &gt;The Arc::clone(&amp;from) syntax is the most idiomatic because it conveys more explicitly the meaning of the code. &amp;#x200B;
As someone who learned a little Rust and stepped back for a while and is learning again, is there an example in there that is "good" code? Is there something for Rust that is like Pythonic for Python?
We're aware. That's why we make these jokes. :) I think (hope?) most of the RiiR madness in this thread, if not in general at this point, is poking fun at the RiiR zealots.
As someone who is really thinking of learning Rust, is there already tons of ways to do the same thing like in C++ without one being "the best" or most common? PS. JavaScript newb studying CS online
If you're worried about binary sizes, then sure. Nothing I've written so far needed to be optimized to small binary sizes.
Is there a way to embed files into the binary generated by the Rust compiler? I've been toying around with making some sort of installation framework/library for rust as a toy project and was wondering if there was a macro that could embed necessary files at compile time into the binary so that they could be copied to whatever location was necessary on the running system.
I think you misunderstood. The `clippy` lint is about using `Arc::clone(&amp;foo)`, just like you're doing. The `x.clone()` example is code that would trigger the lint. So I was replying to /u/po8 that using `Arc::clone()` instead of `.clone()` is fine, and might have been prompted by the `clippy` lint -- it's now allowed, but I think it used to be denied by default.
Is hermit-crab Ferris the mascot for embedded Rust? If not, it should be.
&gt; It may become mandatory at some point, but that would be a breaking change. Well, they could have done this breaking change for Edition 2018 similar to promoting the identifier `try` to a reserved keyword: The code below is only legal in Edition 2015: fn f() -&gt; Result&lt;(), ()&gt; { try!(Err(())) }
Thank you for your feeback. &amp;#x200B; &gt;The README needs to be fleshed out. That makes it easier to see what the code is going to do. &gt; &gt;You have a LICENSE file in the repo, so a short description of the license in the source is probably plenty. &gt; &gt;800+ lines is pretty long for a single Rust file: it makes it harder to read. Find some way to break it into modules. Splitting out the argument parsing would be a good start. I just created the repository to ease the review, but I will split the code. &amp;#x200B; &gt;The error handling in read\_file() looks like you are returning an empty file when you can't open a file. Probably make read\_file() return a Result and use ?. Also, collect() the lines rather than pushing them one at a time. Yes at this point there is no error handling. Just standard error logging.... &amp;#x200B; &gt;parse\_graph() takes rather a lot of arguments. Probably pass &amp;config rather than all those parameters. The config struct was added later, and when trying to do as you suggested the borrow checker hit me with a **'static** lifetime to be applied to config. I'm working on it. &amp;#x200B; &gt;The calls to Arc::clone() look like they could be replaced with .clone(). I'm not sure. The documentation says ([https://doc.rust-lang.org/std/sync/struct.Arc.html#impl-Clone](https://doc.rust-lang.org/std/sync/struct.Arc.html#impl-Clone)): **The Arc::clone(&amp;from) syntax is the most idiomatic because it conveys more explicitly the meaning of the code.** **In the example above, this syntax makes it easier to see that this code is creating a new reference rather than copying the whole content of foo.** &amp;#x200B; &gt;Why is an unsafe { transmute() } needed here? because u64::to\_be\_bytes() is a nightly-only experimental API. &amp;#x200B;
Iâ€™d say the â€œFunctional Rust Programmerâ€, if you replace the unwraps with actually meaningful expects. (this is just a tiny one-off thing, no need for error handling) If you immediately want to build something bigger, â€œYet another senior Rust programmerâ€ is where itâ€™s at regarding error handling (Iâ€™d still prefer the functional style for the rest)
&gt; Last I tried it myself, Cocoa was a bug-ridden mess in Lazarus; Carbon is limited to 32-bit applications, which are being phased out on macOS I only recently became aware Lazarus existed at all, however the Cocoa support in the development branch works generally pretty well, I found. It's good enough that Lazarus itself can be built for 64-bit against Cocoa, at the very least.
ok, thank you for your feeback.
Seconded on the build system. Would love to see more details on their setup.
See https://doc.rust-lang.org/std/macro.include_str.html and https://doc.rust-lang.org/std/macro.include_bytes.html.
Yes please! I teach an algorithms class and, while otherwise Rust would be an extremely good language to demonstrate alogs in general, the amount of ceremony you need to read the input is annoying. The typical input looks like this: &gt;The first line contains `n` and `m` \-- number of vertices and edges in the graph. Next `m` lines contain two numbers each, where `u v` describes and edge from `u` to `v`. It would be cool to be able to write this as: ``` fn main() -&gt; Result&lt;std::io::Error&gt; { let graph = { let mut tokenizer = std::io::WhitespaceTokenizer::from_stdin()?; let n: usize = tokenizer.read()?; let m: usize = tokenizer.read()?; let mut graph = vec![Vec::new();n]; for _ in 0..m { graph[tokenizer.read()?].push(tokenizer.read()?) } }; } ``` In the classroom context, using external crates is not really convenient, and its also less then trivial to add them to a testing system. 
You may want to look into `rayon` for data parallelism. It looks like you're sharing a `HashMap` to store the results of all threads. That's probably fine for this case, but a "better" approach is to avoid that synchronization completely: - spawn a number of threads and distribute the items to be processed to them - on each thread, create some state and process its associated items while storing the results to the current thread's state - when the threads finish, take all the thread states and combine them into one For example, if you want to sum up some numbers, you could: - have a single `i64` and wrap it in an `Arc&lt;Mutex&lt;i64&gt;&gt;` or similar - use an `AtomicI64` (better, but not great) - have each thread compute its local sum, then add up these sums Or, in functional terms, you can do a parallel map, followed by a parallel reduce, if the problem you're solving allows you. You'll also want to start a constant number of threads (not necessarily one per file). As an aside, you should take a look at the `HashMap::entry` to avoid some double lookups.
I read it as, "the OO programmer is (ab)using the way that you can kinda-sorta mimic inheritance in rust"
Very happy that this exists! There has been more than one time that I wished that Yoga would be available in Rust.
It requires you to manually implement \`mio::Evented\` for other types you want to use, which is done using the platform-specific apis of mio (like \[this one\]([https://docs.rs/mio/0.6.16/i686-pc-windows-msvc/mio/windows/index.html](https://docs.rs/mio/0.6.16/i686-pc-windows-msvc/mio/windows/index.html)) for windows). I don't know if this can be applied to the Win32 GUI stack though.
[glsl](https://crates.io/crates/glsl) author here. The crate is written with nom 3. It was interesting to do but Iâ€™m trying to switch to something else. I have an [experimental branch using pest](https://github.com/phaazon/glsl/tree/feature/pest-parser) andâ€¦ Iâ€™m not completely convinced â€” itâ€™s not as type-safe as I want a library to be so far. However, the PEG-like grammar file is something that I strongly prefer over macro_rules-based nom way to go.
[glsl](https://crates.io/crates/glsl] author here. The crate is written with nom 3. It was interesting to do but Iâ€™m trying to switch to something else. I have [an experimental branch using pest](https://github.com/phaazon/glsl/tree/feature/pest-parser) andâ€¦ Iâ€™m not completely convinced â€” itâ€™s not as type-safe as I want a library to be so far. However, the PEG-like grammar file is something that I strongly prefer over macro_rules-based nom way to go.
/u/sasik520 two quotes I've fortunately heard in life.. &gt; fall down seven times, stand up eight &amp;&amp; &gt; you learn more about someone's character in defeat than in victory
&gt; It is amazing what you can accomplish if you do not care who gets the credit.
I'm working on pest 3.0 that should help exactly with this. One will be able to write a consumption function for every rule that will be completely type-checked. Everything is still in the design phase, though.
Currently experimenting with eliminating the rule enum and having something closer to a type-checked visitor pattern in pest 3.0.
That sounds great. I've been experimenting myself but, as should have been expected, there is a lot more complexity than appears on the surface.
&gt; That is the Minotaur's noise," whispered Ariadne, closely grasping the hand of Theseus, and pressing one of her own hands to her heart, which was all in a tremble. "You must follow that sound through the windings of the labyrinth, and, by and by, you will find him. Stay! take the end of this silken string; I will hold the other end; and then, if you win the victory, it will lead you again to this spot. Farewell, brave Theseus.
That's exactly why it takes so long. I have the design layed out for an API that understands pest grammars and the shape of the visitor pattern, but I'm not completely sure whether this can work with procedural marcos or whether it will require libsyntax.
Thanks. I had forgotten about include and include string.
So you can't post a regular windows message to an IOCP, but maybe it's possible to use MsgWaitForMultipleObjects to wait for either a message or the IOCP, and then use GetQueuedCompletionStatus or PeekMessage depending on which type of event happened...? And for Cocoa I have no idea because I have never used that.
Hey all! OxdizeConf is a conference for embedded systems in Rust! It's run by [Ferrous Systems](https://ferrous-systems.com). Let /u/fgilcher or I know if you have any questions!
Have you tried it?
The question or problem with this from my perspective is (as i wrote in [areweguiyet](http://areweguiyet.com/newsfeed/2019-01-13_rust2019.html) blogpost) if we want this team to be official (whatever this means) or do we want to build this naturally. The problem i see with an official approach â€“ what does the team even do and what do they decide? I mean currently we have many different approaches (OrbTk/OrbGL, Druid/Piet, Azul/WebRender ...) with mostly a handful of people trying things out (no one knows the "right approach" anyways) so there is nothing to decide from such a team. You don't write up tasks and hope that others are implementing this. The only thing i see here is to strengthen communication among those parties so it comes clear among those who do the work what could be shared. But i don't think this needs to be an official part of rust governance (this is time consuming) The question is, if we want to have something outside of this. I did setup a discourse server at [discourse.areweguiyet.com](http://discourse.areweguiyet.com) but it is not an official part of the website yet. I would love to see people discussing things in here and happy to provide the space. But its not clear if this is really helpful. We already have some discord chats about GUI and i don't know if there is a need of such a forum-based approach. 
I haven't had a chance to reach my laptop yet. I am sorry if I was wrong.
&gt; As far as I know, BufRead::lines will block the program execution until EOF. In a for loop yes, obviously, but you can advance it manually at any point by calling the `next()` method on it. So you can create the iterator, store it in a local variable, and call `lines.next()` any time you want to check for / use a new line.
Still, be aware of it. It can also be a factor of seriously long compilation times. Personally, I would object to this technique in any code review. 
Yeah, probably. That's a shame, segmentation is neat and there has to be *some* application space where it's still useful. Maybe in GPU's or DSP's? Where in the world these days do you have small pointers, large amounts of memory, and a tight transistor budget? Â¯\_(ãƒ„)_/Â¯ Something for me to research, maybe.
CFP is open immediately :) https://cfp.oxidizeconf.com 
Glorious!
Many fewer, since C++ (and JS for that matter) are old languages that have evolved and mutated a lot over time. Rust's design is more consistent. Rust also, more or less accidentally, follows a lot of the [Zen of Python](https://www.python.org/dev/peps/pep-0020/); particularly "Explicit is better than implicit", "In the face of ambiguity, refuse the temptation to guess", and "There should be one-- and preferably only one --obvious way to do it."
I'm, a bit bummed that it's not called `mispell`
in that case you measure the (percentage) delta and report that, no need for a graph even
Actually, IntelliJ Rust plugin is free, not proprietary. So everyone is welcome [here](https://github.com/intellij-rust/intellij-rust)!
As an outsider-- this is exactly the wrong way to handle frustrated users with genuine concerns in their comment. * Yes, their frustration often turns into anger. * Yes, it can be frustrating to deal with an issue like this at scale. * Yes, it can be hard for users to direct that energy into something positive. Yes, it can be Stopping discussion at this point just builds onto the on-going frustrations (especially as _this_ particular one is because of stopped discussions). Some better alternatives: * Sorry, I'm having trouble seeing the point you're trying to make-- could you help clarify what we need to do? * Sorry, we do think we could've handled that situation better, we have a public discussion about it-- but we need to move forward. Any ideas on how we can do that better? Those don't even need a "Sorry", but when dealing with frustration or anger: its very useful. Its not necessarily an apology for _Why_ one angry or frustrated, but because they _are_ angry or frustrated... at least I generally don't like seeing people angry or frustrated. Fueling a fire of frustration and anger with more frustration or anger leads to a bigger fire. Looking at the conversation in here: that can definitely be better handled.
Wouldn't Servo also have a flexbox implementation? Is it harder to extract that than porting a C library?
That sounds quite nice. I'm not the target audience at all, just two small (probably overly pedantic) comments: * It might be nice to add some form of "This ticket also gives access to the activities on the two Impl. Days" mention to the two other respective sections, so people who are mainly interested in one of those don't miss that they can mingle afterwards as well. I know it's written below at the Impl. Days section as well, just thought this would make it harder to miss. * The abbreviation "Impl." is never expanded. Yes, I know this is very nitpicky :) On a more selfish note: Any chances of some materials making it out to the public, like talks or slides? I'm not the perfect audience, but would still be interested in the embedded Rust space and how it is coming along.
To be fair, I don't think I understand this either, but that's the point of the exercise: to *learn Rust*, to *learn Haskell*, to *learn Racket*, and to *learn lots of other things*. I'll take a look at regex-syntax and certainly learn from it, but I won't use it for once simple reason: parsing with derivatives can be made recursive. To a first approximation, my library should be self-hosting: parsing regular expression syntax should be done entirely with regular expressions (which is *theoretically* possible with Î¼-regex support). My aim is to make it trivial to support any pattern-matching dialect: BRE, ERE, PCRE, PSIX, Rosie, or PEG. Hell, maybe I'll thrown in SNOBOL as a joke. The PEG one is where I get to study procedural macros, so I'm looking forward to it.
Why is the macro necessary?
Servo's current implementation is incomplete and likely quite difficult to extract, yes. I would not recommend anybody spend time trying to do that. If there is some way for Servo to reuse Stretch in the future that would be exciting for us!
TIL that `Arc::clone()` is "idiomatic". Huh. Makes little sense to me. Seems like by the same token `Rc::clone()` would be idiomatic, and neither Clippy ([playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=10c1e5e86fc4b615906dfbe39186adf9)) nor the [`Rc` docs](https://doc.rust-lang.org/std/rc/struct.Rc.html) seem to say so. Still, "A foolish consistency is the hobgoblin of little minds." If that's what we're doing, I will switch my practice forthwith. Thanks much for the correction!
There's various solutions to deal with this. When you want to transform from one error type to another, you can implement `From` for the target error, which `?` will use for conversion before returning. If you can't implement the `From` trait (for example because the target type isn't yours), you can use `Result::map_err`. If you want to go from having a `Result` to returning an option, you can do `result.ok()?`, since `?` also works on `Option` types. And of course you can always make your own extension traits for `Result` to provide convenient funcionality if you require something more specific to your project.
No, you want a bit vector (to encode the options), and a vector of i32.
Hi! Pedantic comments are very welcome! I'll check up on that later. Materials: yes, given funds, there will be videos and slides.
&gt; Materials: yes, given funds, there will be videos and slides. Excellent, thanks! I'll keep an eye out.
I'm okay with dealing with frustrations and do this on a regular basis, but am _not_ okay with people not taking feedback on their approach and tone to heart. Especially as this person jumped right into anger mode on a small inquiry to a different person. I do appreciate your answer, but I don't feel like this situation merits this response. I intentionally chose it.
I made a naive Bayes machine learning algorithm. I'm looking for critique on my code style to improve my Rust skills. If you have any feedback it would be appreciated &amp;#x200B; [https://gist.github.com/benjaminmcdonald/cfe813329951918a8681a47436c1a488](https://gist.github.com/benjaminmcdonald/cfe813329951918a8681a47436c1a488)
This is a problem that is *strongly* faced in implementations of John Conway's Game of Life. Large games need to efficiently handle immense bitmaps that are constantly growing, where huge chunks of space are empty. They need to both efficiently access rectangular regions (for drawing) and quickly access values by coordinates (for calculating subsequent generations). http://www.davidkinder.co.uk/xlife.html This was one of the first life implementations that moved beyond naive bitmap-based calculations. http://dotat.at/prog/life/life.html This was another, that talks about xlife's implementation and how his compares - his is basically a flat per-scanline list of the xcoordinates of lit cells, prefixed on each y scanline by the y coordinate. Finally, https://en.wikipedia.org/wiki/Hashlife is an algorithm that uses hashing not of the coordinates (as in coordinates into the map), but of the contents of chunks of the bitmap, which makes for efficient storage of replicated regions within the larger bitmap.
&gt; Why is an unsafe { transmute() } needed here? &gt; &gt; because u64::to_be_bytes() is a nightly-only experimental API. I'm guessing [this](https://stackoverflow.com/a/29482767/364875)? I would instead suggest the [byteorder](https://docs.rs/byteorder/1.2.7/byteorder/) crate and using the safe window_digest.write_u32&lt;BigEndian&gt;(h) 
It's not out of nowhere. Your tone is incredibly aggressive. It's an unproductive and juvenile method of discourse. If you want to be listened to, clean it up. Stay focused on one issue at a time. Work with the person you're talking with to find actionable solutions to problems. Understand that you may have misunderstandings. Understand that the person you're talking to often can and will leave the conversation if they feel you're not a good use of their time, and that it's on you to make listening to you worth the effort.
Good to meet you! &gt; At a high level, hereâ€™s my project. If you assume that every possible board of bingo takes part in a game, the odds should work out such that there are three times as many horizontal wins as there are vertical wins. I'm already lost :smile:. The standard game of Bingo is symmetric as far as I can see. I don't understand why horizontal would be favored. The classic high performance solution here is to use "bit boards" (which is what I thought you were doing). Make a collection of 12 `u32`s, where each `u32` has a one bit exactly where its winning squares are. For example, a diagonal win might be represented as 0b1000001000001000001000001 since squares 0, 6, 12, 18, and 24 are marked. If you make another bit board for the current game state, you can check for any win using 12 bitwise-and operations. There's probably a way to go faster than 12 instructions per win check, but this should be a good start.
Yes it does. `Pin::new_unchecked` [is unsafe](https://doc.rust-lang.org/std/pin/struct.Pin.html#method.new_unchecked) so it can only be called in an unsafe code block. If you mean the code in the original post, it doesn't use it.
Thanks for the explanation. It's really insightful.
And that joke is based on the Evolution of Dance https://youtu.be/dQw4w9WgXcQ 
I am a fan of the text_io crate that makes this really easy: https://crates.io/crates/text_io
In fairness, they did link to OP's blog. It's very possible they found it independently.
Putting `#[async]` on a for loop looks pretty handy. Now I'm just missing `#[pragma(omp(parallel = "for"))]` ;)
I wasn't able to get `Arc` to work -- I still get lifetime complaints when I dereference a particular clone of the Arc to get the `&amp;[u8]` to pass into the Reader constructor. Will look more at owning_ref and reffers though. Thanks!
I have a lot of thoughts on this, probably best expressed in a blogpost. I'll touch a few points here though. A good GUI working group could be amazing and sounds like something I'd want to participate in actively. A bad GUI working group is definitely not something I'd want to burn time and energy on. My biggest concern is that it's dominated by bikeshedding in a Reddit-style discussion. Between the various groups, we have a tremendous amount of knowledge and skill, but coordinating it is a hard problem. I refer to Evan Czaplicki's, "[The Hard Parts of Open Source](https://www.youtube.com/watch?v=o_4EX4dPppA)". Many of the discussions I fear are of the "why don't you just" and "let's get somebody from the somebody store to do this." Also see the excellent [blog post](https://boats.gitlab.io/blog/post/rust-2019/) by boats - I'm not eager to participate kind of discussion of that Pin issue. (There are a lot of other excellent points in that blog, it's worth re-reading) So I basically look at a potential working group as something that can create positive or negative value. Here are some examples of positive things a group could do (as opposed to backseat driving the work done by the individual GUI teams). 1. Quantitative measurement. In my opinion, one of the main reasons you'd want to write a GUI in Rust is performance. If performance were not a goal, Electron is mature and easy. There are a *lot* of things that should be measured, not just FPS in an artificial benchmark: how long does a hello example take to compile? What's the executable size? How long does it take for the window to pop up? Then of course there's [latency](https://danluu.com/input-lag/) measurement. 2. Care for core infrastructure. The *idea* of winit is compelling, a single cross-platform crate that handles window creation. But I found some limitations of winit and so created druid-win-shell instead. This was good for prototyping, but for the health of the ecosystem it would be best to document those limitations and see if they can get fixed in winit. Or if not winit, because the scope and goals may not match, then identify crates that can be used as common infrastructure. There are a lot of other components to a UI that can be considered common infrastructure. 3. Education. There's a lot of folk knowledge out there in GUI and 2D graphics, but it's not readily accessible. And a lot of it needs to be updated for the modern world. I personally believe that old-school blogging is one of the most effective formats for conveying this information (and that Reddit-style discussion is not). A GUI team could provide discoverability of such blogs, and encourage followups in blog form. Ideally the Rust GUI effort in 2019 will have themes of exploration, trying things out, and learning from each other, rather than a horse race in which one lucky team will win. I'm still trying to decide exactly what scope my personal efforts will have - I'm mostly doing it for passion, and need to be realistic about what is sustainable.
They probably would benefit. It just seems to me like applications usually opt for having consistent design across platforms, than having a design that is consistent with the platform, but this could just be due to a lack of tooling/path of least resistance rather than a conscious decision.
Oh neat. So with Abomonation, if I'm encoding/decoding a `Vec&lt;Vec&lt;u8&gt;&gt;`, and I just want to operate on the 1000th element of the outer vector, I still call `decode` on the whole encoded thing, right? What, if anything, gets copied when I do?
Unless they use a NonZeroi32, which reserves the least significant bit for the option and takes no extra space. It shouldn't anyways.
I was looking at the [sprs](https://docs.rs/sprs/0.4.0-alpha.4/i686-pc-windows-msvc/sprs/sparse/vec/index.html) sparse vector crate, and Iâ€™m curious how itâ€™d do with a Game of Life implementation. Iâ€™ll give it a shot and report back at some point. Itâ€™s fairly similar to the dotat implementation above. I donâ€™t know that any of the options that work well for sparse dara would translate well into dense bitmap data, but itâ€™s a fun puzzle. 
I looked at this crate, but I'm not sure it solves my problem. The capnproto reader expects a `&amp;[u8]` as input, and I don't see how OwningRef gives me access to a bare slice that has the appropriate lifetime. OwningRef seems only to work if I can pass around a full OwningRef as a unit, but that's not the input the library expects.
conrod seems to already deliver something fairly complete that is pure-rust non-native. For bindings gtk is probably in good shape but qt isn't because C++ bindings are harder. What is the actual end-state that we need and don't have yet? Personally I'd love just for polish on those things (conrod being finished and gtk/qt having full bindings). What else are people missing?
Thanks for this response, it's awesome.
For the following code snippet: ``` fn my_func&lt;'a&gt;() { let x = 5; let y: &amp;'a i32 = \&amp;x; } ``` I get error `x does not live long enough`. I wonder what is the lifetime of `y`. Doesn't `y` also live till the end of `my_func`? Why does `y` live longer than `x` in this case? If I remove lifetime parameter the error is gone.
Pretty much agreed, lol
One of the distinctions in Rust's governance is between "teams" and "working groups". The main difference is that teams have decision-making power, and working groups do not. I think your post rightly points out some problems that a GUI team would run into, but "strengthen communication among those parties so it comes clear among those who do the work what could be shared" is exactly what a working group does.
&gt; If performance were not a goal, Electron is mature and easy. Totally agree with this. And I think a key metric is going to be battery life impact. This particularly concerns with webrender approaches as chrome and firefox are *not* battery life friendly...
[Oh GitHub, you so silly sometimes](https://i.imgur.com/eSPcwoJ.png)
Coming from PHP, `unwrap` feels like par for the course.
Thanks! :)
Yeah lemme compile real quick for all rust versions and all platforms.
That's what I'm getting at I think. I feel like it's communication that's needed during the experimental phase.
miri is finally available via rustup! Great news! ðŸ˜ŽðŸ¦€
Why not pistol shrimp? They are small, hard and damn fast...
In a... bad way?
Can someone publish a Hyper-Functional Rust Programmer + proper error handling? It's not that difficult, and that's what I would aim for personally.
That was both funny and terrifying.
Oh wow, I never knew! How deep does this go?
Nothing to do with the core team members though; r/rust is not an official space, although it strives to adhere to the CoC, and not overviewed by the Rust team at all.
Haha, It's because I use client9's dictionaries ([https://github.com/client9/misspell](https://github.com/client9/misspell)) which are embedded in a 31159 lines go file :,)
So honestly guys which one of these versions is the â€œbestâ€?
The evolution of homo sapiens.
&gt; Just FYI, this notion of "sending things to the mod team" as in taking them out of public view is also something I dislike (and doesn't seem to square with this notion of radical openness that people also mention). I don't like it much either, but I don't see any way to operate in the open. --- De-escalating is *much* easier in one-on-one. It's hard to admit mistakes, it's even harder to admit them in front of a belligerent crowd. As a moderator, it's thus much easier to help people understand the issues with their behavior, and correct it, in private. There's no fear for them to "lose face" in front of the whole community. It's the difference between: - Whispering: "Just to let you know, the tag of your t-shirt is peeking out from your collar". - Shouting: "GUYS CHECK THIS OUT! THIS DUDE'S GOT THE TAG OF HIS T-SHIRT PEEKING OUT!", followed by a symphony of "OLOLOL!", "IT'S ON YOUTUBE!", "WHAT AN IDIOT!", ... Both may lead to correcting the issue; one will leave a sour taste in the mouth.
Oh? I thought they explicitly *were* battery friendly.
So much good stuff!
What would be the challenges of Qt/C++ exactly? How difficult would they be to solve? Not that anyone would or should care, but as a user I've always found GTK to integrate poorly in whatever environment I use at the time and have lots and lots and lots of usability quirks, so I can't help but shudder at the idea of the Rust community unintentionally standardizing on GTK widgets instead of Qt as a result of C vs. C++ bindings.
&gt; Rust is finally approaching a level of maturity where itâ€™s suitable for use in â€œhigh assuranceâ€ software applications, including mission critical embedded security and cryptography applications. I think this may take some effort, but I do believe 2019 could be the year where Rust finally is capable of such use. Specifically, I'd say that 3 things are necessary for this: - Precise semantics for `unsafe`, to guarantee that the code adhere to the type system: RustBelt, RalfJung. - Proof that the type system itself is correct: ?? - Formal verification, built on the type system: https://internals.rust-lang.org/t/rust-2019-correctness-and-stabilizations/8991/6. Combining all 3, you can prove that a Rust program indeed respects a given specification. I have a hard time imagining that it would be possible to verify the emitted assembly does indeed match, not without building something like the CertCompiler. However, a specific version of the toolchain could be certified without going to such length: C and C++ compilers regularly are, after all.
Shameless plug: I'm working on a crypto project at: https://github.com/brycx/orion. If you're interested in that sort of stuff then I'd love contributions. There are a few things on the issue-tracker atm, most of them don't require anything advanced. If you wanna talk about it more in detail, feel free to pm me. 
The lifetime `'a` is filled in by the caller of the function is thus refers to a lifetime which must be longer than the function call. By explicitly using `y: &amp;'a i32` you prevent taking a reference to any local variable. But you could use `&amp;5`, for example.
This is why we need empirical measurement! I have a [watt meter](https://www.amazon.com/gp/product/B071GTVFG4) I used while working on the xi-mac text painting layer, and learned some interesting things.
I think he was replying to the first part of the comment that talked about mod decisions, not the second one about the core team.
&gt; What would be the challenges of Qt/C++ exactly? How difficult would they be to solve? Qt is very large. The Qt documentation contains rules on how to use Qt safely. E.g. you should not delete QObjects unless they are the top object in the hierarchy. You can translate to rust by passing the object to Rust by value, but then you lose the reference to the object. You could put the object in an `Rc` and pass it, but that `Rc` would be overhead that the pure C++ version does not have. Some functions are thread-safe, others are not. Capturing all of that safely in an idiomatic Rust API requires consideration. That is why I'm using Rust Qt Binding Generator. I keep the UI in C++ and QML and write the logic in Rust. This works out great and allows me to switch to another UI later or create multiple UIs on top of a shared core. 
&gt; neither Clippy I think it used to warn, but it was allowed for the 1.0 release. You can try it with `#![warn(clippy::clone_on_ref_ptr)]`. &gt; nor the Rc docs seem to say so. [They do. ](https://doc.rust-lang.org/std/rc/index.html#cloning-references) The idea is to make it easy to distinguish between bumping the reference count and `Clone::clone()`.
So I work for a company that does this and can provide a little perspective. In general, there isn't any development using ruby, node, or python here. (Although that is beginning to change a little, mostly with Python). Large enterprises are mostly optimized for buying things, and making sure they do that legally and securely. How does this end up working? Each dependency introduced gets reviewed (and each update to that package is reviewed as well). This is not fast and causes a couple of things to happen: first, the organization generally prefers large dependencies that don't have a large tree of dependencies themselves. A large part of the review is legal, not technical: stuff like "are we legally allowed to use this and what do we need to do to do so?" This includes things like "if an algorithm in this lib turns out to be patented, what is our plan to respond". These things aren't really harder to do for a million LOC dependency than a hundred LOC one (yes, seriously). This may seem like an insane way of doing things, and to some extent it is. But hopefully thinking about it from a risk management perspective can help she'd some light (for example, we have to vendor every crate right now in git repos and build from them because we don't have a crates.io that is air-gapped from the Internet). When particular versions of a package are signed off on, they are individually mirrored onto our network.
Based on the name I expected it to intentionally misspell the given text to foil linguistic fingerprinting. Now I'm bummed.
Yes, you decode the whole thing, which does 1000 pointer corrections and copies nothing (but does touch those 1000 pointers). This is in contrast with a capnproto approach which would not even do the 1000 pointer corrections (but which also wouldn't pretend to be a `Vec&lt;_&gt;`, if that is something you need).
We tend to call that Rustic/Rusty, the RFC is not yet stabilised.
Think defense and avionics. Javascript is... not a thing. At all. Modern development is mostly now C++, and you can use STL, boost, sometimes Qt, and with a lot of paperwork sometimes one or two domain-specific dependencies (for example, one image processing project was able to use OpenCV).
I think it isnâ€™t right now because it doesnâ€™t do partial paints or use the OS compositor, but those are planned features. Disclaimer: I donâ€™t work on WebRender Iâ€™m just an observer
What does it mean in a few words, please?
Yeah I was really looking forward to dbg! and and the byte conversions.
Welcome to the community! Maybe you should try to utilize [`rust-phf`](https://github.com/sfackler/rust-phf) because then you could construct the map of word-pairs at compile time? You already use `include_str`, which includes the content of the specified file at compile time, so `phf` will probably increase the speed quite a lot because then you don't have to parse the included data every time you run the binary. 
I'd love to see some bechmarks (also where's the SSE programmer?)
Rustic sounds like a fine cabin for relaxation. Rusty sounds like my early cars that I worried about the frame breaking. :)
To be honest, I'd go much more brute-force than you did, simply doing multiple passes over the data and enjoying the fact that `sort` is stable by default. It'd be quite less efficient, but I'd be more likely to believe it's done correctly. That is ([link](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=885dc2067b6cedb918d279e4da81f768)): fn sort_by(f: &amp;mut [Foobar], field: Foofields) { f.sort_by(|a, b| match field { Foofields::Foo =&gt; a.foo.cmp(&amp;b.foo), Foofields::Bar =&gt; a.bar.cmp(&amp;b.bar), Foofields::Oof =&gt; a.oof.cmp(&amp;b.oof), }); } fn main() { let mut f = vec![ Foobar { foo: 3, bar: 1, oof: "B", }, Foobar { foo: 1, bar: 2, oof: "B", }, Foobar { foo: 2, bar: 2, oof: "A", }, ]; // Apply sorts in reverse order. sort_by(&amp;mut f, Foofields::Foo); f.reverse(); sort_by(&amp;mut f, Foofields::Oof); f.reverse(); f.reverse(); sort_by(&amp;mut f, Foofields::Bar); f.reverse(); println!("{:?}", &amp;f); } *Where a bit of cleverness would avoid two reverses in a row ;)* Output, with fields re-ordered to make it more obvious; it's the same as yours, though the data-set is too small to conclude much from it: [ Foobar { bar: 2, oof: "B", foo: 1 }, Foobar { bar: 2, oof: "A", foo: 2 }, Foobar { bar: 1, oof: "B", foo: 3, } ]
I've been meaning to write a source code spell checker in Rust after finding [scspell](https://github.com/myint/scspell) too slow to be useful. Thanks for doing this! I'll definitely be noting ideas for scspell or ideas I've been ruminating on.
If a working group or something similar is created, I'd be interested in participating. One thing I'd say a working group should make sure is widely understood is that GUI libraries are _not_ easy work. There's a pervasive mentality in non-web communities that GUIs are a solved issue, and it's really just... not true. When the significance of the work is downplayed, it leads to subpar solutions.
Follow up question: in my mind Miri and Cranelift have similar goals, what might I be confusing between the two?
Is `git checkout -` the same but with a stack size of 1? :)
Crane lift is a code generator, Miri is an interpreter.
Miri is an interpreter, this means you can easily install it to run your code inside of it.
I'm not sure. The current prototypes (like azul) seem to use some CPU even in the background (when they shouldn't be doing anything!) and 6-9% when they're in the foreground. Maybe this is just normal, but it doesn't seem right to me...
That may be other parts of Azul, and not webrender itself.
Love the byte conversions
The `dbg!()` macro is the kind of thing where once you discover it, you begin wondering how it is you survived without it. 
If you don't know already and you're interested, you can fix Github's reporting for vendored dependencies by creating a .gitattributes file in your project root with something like: `static/thirdparty/* linguist-vendored` Where the directory before linguist-vendored is what you want excluded from the stats.
We really need that imo. For my recent swc2 rust port I rolled my own rust installer with a embedded tar file. Not the prettiest thing but it works. 
I have a macro that prints println!("{:?}", );
bpac, a universal package manager for bedrock linux. 
`let s: String = myvec.into_iter().collect();`
&gt;static/thirdparty/\* linguist-vendored I wasn't thanks! It looks better now :)
There are few crates out there for using DRM, it might be what you want: https://crates.io/search?q=drm
correct!
Could you say that again, but with more words? I'm so confused. 
&gt; I only very recently became aware Lazarus existed at all, however the Cocoa support in the development branch works generally pretty well I found, and seems to be getting worked on a lot recently (see for yourself on the Github mirror if you want.) &gt; &gt; The devs definitely seem to recognize they need to get it stable sooner-than-later. It's advanced enough that Lazarus itself can be built for 64-bit against Cocoa, at the very least, which to me is a relatively strong indicator that it's at a pretty good point now. I've been writing desktop apps for a few years now (Cocoa included), and I even just re-downloaded Lazarus to make sure I'm not missing something. This is nowhere near a complete enough port for significant apps. The most advanced thing here is an `NSTableView` wrapper, which doesn't even support some of the features needed - e.g, group rows are a subtle distinction for list headers that will scroll differently on the platform. It also lacks significant pieces (`NSCollectionView`, customizing cells for things like `NSTextField`, not even touching on significant other frameworks like `AVFoundation`), and there's certain things in here you really don't want to do (e.g, you shouldn't touch the `scrollWheel` event generally - it will disable responsive scrolling in many conditions post-10.9). Dimitry does amazing work, but this is what I've been saying elsewhere... you simply cannot, under normal circumstances, one-man-army a GUI framework in 2018. There's way too much here that you'd need in a complex app that Lazarus doesn't offer (e.g, let's say Slack was built in this... good luck with embedded videos/gifs/etc, which people love). &gt; They even have language level support for interfacing with Objective C! Considering Apple has tested the waters on Swift-only frameworks, I'm not sure this is a great thing. It's the same reason I have reservations about rust-objc. &gt; There's also the existing QT5-based backend like you mentioned (which AFAIK has been stable for a while now) as a secondary option for 64-bit Mac. &gt; &gt; Overall though the simple fact that all the backends on every platform are at least good enough to build the IDE itself against with the end result being clearly the same (complex, featureful) application everywhere is the biggest thing. That's a crazy achievement if you ask me. If you have to fall back to Qt, then this is a feat for Qt, not really Lazarus. ;P
Edited my previous comment
Hello, I can't seem to compile my code using this suggestion. Do you have any suggestions for how to fix this bug. This is my code. [https://play.rust-lang.org/](https://play.rust-lang.org/) Thank You
Would it be possible to allow usage of any type which implements `syn::parse::Parse` for metavariables instead of the same set that proc_macro supports?
The link doesn't work. It's just a link to the playground. You have to click share
Well, sort of. Noria needs to observe the log of changes to efficiently compute the changes to any materialized views that it maintains. It's probably possible to back-compute those updates from regular tables, but it sounds pretty painful. It might be that you'd then rather use _delta queries_ to maintain the materialized views instead (that a look at the DBToaster paper if you're curious!).
Sorry here is the link: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=a10cfd5e58378f7d830dc98c9929ee43 
line 6 is the offender. Nothing seems to be using word later. Remove it
I think that 2009 was even pre-`try!`: Rust was likely still using conditions for error handling (similar to https://lispcookbook.github.io/cl-cookbook/error_handling.html), or maybe an even earlier scheme. 2009 is *very* early in Rust's history.
In addition. s = blablah should be replaced with let s: String = blahblah
&gt; I've been writing desktop apps for a few years now (Cocoa included), and I even just re-downloaded Lazarus to make sure I'm not missing something So you actually rebuilt the IDE for 64-bit against Cocoa after downloading it, you mean? &gt;This is nowhere near a complete enough port for significant apps. Don't you think an IDE *is* a "significant app" though? &gt;you simply cannot, under normal circumstances, one-man-army a GUI framework in 2018. I mean, his work is just specifically the Cocoa interace aspect of it, which is big but hardly a whole "framework" by itself. &gt;If you have to fall back to Qt, then this is a feat for Qt, not really Lazarus. ;P It's still impressive that they're able to wrap it in such a way that they can use it homogeneously alongside all of the other backends (and again, build the IDE against it), I'd say.
Evolution of the Hamiltonian
I still have a bug on line 6, but I don't know why the bug is occuring. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=558a9e87031f3be5b104af2f312e9cfb 
Well both industries have websites. I doubt they formally prove them! I think it's less about formal verification, and more about convention and politics. They have established processes for existing languages, and there is no compelling event that would mean they would adopt rust, which is entirely understandable.
Fun and fun read, thank you! But where are benchmarks of all provided code? ;-P
First: You need a semicolon after your `use` statement. Second: `sort` has [no return value](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.sort), so you can't use it in a method chain like that. The compiler error is a little confusing, because taking the return value of `()` (that is, the unit type, or "nothing") and assuming you meant to turn that into an iterator, which of course is nothing like what you wanted. You need to call `sort` on its own line and then do the collection into a string on the line after.
&gt; So you actually rebuilt the IDE for 64-bit against Cocoa after downloading it, you mean? Cloned the repository (the 15-minutes-synced-to-GitHub variant) and rebuilt it, yeah. Also re-read most of the source inside `lcl/interfaces/cocoa` to make sure I was up to speed on the current implementation. &gt; Don't you think an IDE is a "significant app" though? It's significant, but not in a way that matters for consumer apps, no. An IDE is not representative of the major portions of desktop apps out there today, as it's not making use of any of the more complex tools and structures for intricate layouts, media, and so on. This is table-stakes for most companies in 2019, and acting like it doesn't matter is why Electron ends up with huge marketshare. &gt; I mean, his work is just specifically the Cocoa interface/wrapper aspect of it, which is big but hardly a whole "framework" by itself. Cocoa (AppKit, related frameworks) are a massive footprint that even writing a wrapper is still a monumental task for one guy. There are intricacies littered throughout there that I still find years later that most people wouldn't think should be an issue, and so much of the knowledge is buried/lost at this point. It's also trivializing the work to say a wrapper isn't difficult in comparison, as there's so much that a proper wrapper needs to do to mask the oddities, bugs, and otherwise mind-bending stuff present in some of these older frameworks. This attitude is dangerous and should be avoided in these discussions if people want a GUI solution that doesn't repeat the issues found elsewhere.
Interesting. Thanks for sharing your perspective! It _sounds_ like you all figured out how to solve this problem though. Is there something the ecosystem could be doing that would make it easier? (Other than cosmic level changes in philosophy, e.g., "don't make so many crates.")
Probably? That's a great idea!
He took credit for... the link being posted on Reddit? He stole karma? Why does that matter? He's not stealing credit for writing it... I'm sure the author wrote it to have it read....
Why would I want to run my rust code with miri? Genuinely curious - is it try to achieve the same thing as the cranelift backend, fast dev builds? 
One thing that Iâ€™m not sure what the status is, but thereâ€™s an idea for an â€œunsafegrindâ€, kinda like valgrind or ubsan, that can help detect when you have UB in your unsafe code.
&gt; It's significant, but not in a way that matters for consumer apps, no. An IDE is not representative of the major portions of desktop apps out there today, as it's not making use of any of the more complex tools and structures for intricate layouts, media, and so on. This is table-stakes for most companies in 2019, and acting like it doesn't matter is why Electron ends up with huge marketshare. Be that as it may, based on what experience I have with it I feel like it has a lot more functionality under Cocoa than you're saying it does. &gt;It's also trivializing the work to say a wrapper isn't difficult in comparison, as there's so much that a proper wrapper needs to do to mask the oddities, bugs, and otherwise mind-bending stuff present in some of these older frameworks. I wasn't trivializing it, I was just saying the LCL and the IDE itself both already exist, and all the logic/e.t.c. is there and maintained by a number of different people, so I don't think it's quite accurate to make it out like it's a one man project in general.
FWIW, I used the ST monad for many such problems this year. It is much better than writing it "idiomatically", but I thought about using rust instead a few times!
I added a sentence or two about calloop in the readme now. FWIW, I did search on crates.io for "main loop" and "event loop" and calloop doesn't show up until page 4, behind a lot of other irrelevant things - maybe that says more about crates.io than calloop but perhaps a keyword or two in Cargo.toml would help?
I guess I could get behind that. Hermit crabs are cuter, though.
Does anyone know whether you can use the `dbg!` macro in conjunction with the `log` crate?
&gt; Be that as it may, based on what experience I have with it to date I feel like it has a lot more functionality under Cocoa than you're saying it does, and what isn't there seems like it likely will be in not too long. At this point, without knowing how deep into Cocoa you've gone in the past, there's not much more to say. I personally feel confident in my knowledge on the matter and would put money on this being incorrect; it's simply nowhere near what it needs to be.
&gt;let s: String = myvec.into\_iter().collect(); I'm trying to sort the string lexicographically like this: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=cbc42dbb644cb563dffe344c398e0f3b After I do the sort, I want to take the char vector and turn it into a new string.
Depends on what you mean by "in conjunction with." In one sense, yes, they're not connected at all, so you can use them both at the same time. In another sense, no, you cannot log to log's stuff via `dbg!`.
This is pretty funny, and I know I've only ever read the book and done a tiny amount of Rust, but it does highlight to me how fundamentally unreadable it is in comparison to some other languages. Sure some of the examples are way over complicated and that's part of the joke, but even the Freshman right at the top isn't particularly clear IMO. As someone who doesn't know the language well I couldn't even say what the 'standard' approach would be to this problem in Rust (i.e. no crazy abstraction or future proofing, just split the string and sum the parts). 
I don't think anyone will be calling it out since it's been a mod and popular members of the community that have done it. Like I said, some are more equal.
Exploring using Rust+WebGL+Websockets to make a browser-based online game. Still learning the ins and outs of each, and how to use `wasm-bindgen` with JS code.
Great Job! For CLI tools, I recommend: https://github.com/clap-rs/clap It provides a standard interface for argument usage ;)
The link to syn is broken, it shows the raw markdown: https://i.imgur.com/GUHrwXB.png
Moreof if I can direct the output of `dbg!` not to stderr, but to a log entry.
Like u/xacrimon posted, you can use an iterator method with `.collect()` to turn it back into a vector. One subtle point is that you need to specify the type that `collect` returns because it supports many collecting into many different collection types. [Here is a link to working code.](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=7f49b65386f1dfc344daf159d989251d) 
Also, I'm pretty sure there is a `String::from_chars(chars: &amp;[char]) -&gt; String` method aswell
I've also been trying to figure this out, and would also like some guidance. The solution seems to be to have an error struct that implements the `std::error::Error` trait and also implements `From` for all the library specific errors you might be dealing with. So say you are parsing ints from strings in your application, then your error struct needs to implement the conversion from the `std::num::ParseIntError` struct. So for each type of error you might get, you need to implement the conversion to your crate specific error type. There are also libraries like `failure`, which come with an error struct that seems be able to convert all types that implement `std::error:Error`, though I'm not quite sure how as for my own error structs I need to explicitly implement each conversion. I keep meaning to splunk into that source code to see how it works. 
Create it and call it Mispell! 
If you import the [FromIterator](https://doc.rust-lang.org/std/iter/trait.FromIterator.html) trait, then you can write this as `String::from_iter(chars)` where `chars` can be an iterator, a Vec, a slice, or any other iterable container.
already implemented ;)
&gt; You can now run `cargo c` as an alias to `crago check` Yes! I almost never used `cargo check` but only because `cargo b` and `cargo t` were faster to type.
I donâ€™t believe so.
I confess I haven't tried it, but [the `rayon-attr` crate](https://crates.io/crates/rayon-attr) implements `#[parallel]`.
Cheers!
Is there no way to save the output of `dbg!` into a string? There must be some internal macro or something, right?
I don't think so: https://doc.rust-lang.org/stable/src/std/macros.rs.html#329-341
I think we need more people working on Azul, personally I think it's great because WebRender is extremely fast and allows people to use HTML and CSS to **design** their application and then use **Rust** where it counts. More people working on Azul, more people working on WebRender, it badly needs docs to be honest that's the only big issue with it. There's even a crate now. The whole HTML + CSS design thing really appeals to me as both a web dev and a software dev, as it means I can prototype quickly and effectively. It's also extremely fast! Unlike Electron which uses tons of RAM and CPU time too (Lookin' at you two, Discord and VS Code, yes you!) This next part is just fiction from my brain: Implementing something like gfx-rs, under WebRender, powering Azul, would be amazing to me, no idea if that's possible or if I'm talking rubbish, but I think being able to write code once, to enable WebRender to off-load it's rendering to GPUs through Vulkan OpenGL, DirectX or Metal would be an amazing thing for WebRender and therefor Azul too, making it extremely fast and widely compatible across platforms. That's what I see as the end-game here. Fast GUIs that work cross-platform cross-API, that are quick and easy to prototype through a markup language and style sheet.
It should be in the book that when people say RIIR they're generally not serious.
thank you for hint! I will explore this path 
Wonderful! I've been wanting to make this for ages, but found the cliff to be too much. Is macro hygiene still unimplementable/irrelevant?
I like and use web tech a lot, but it does have a lot of cruft. Like all the different min-width width flex-basis etc. etc. and all the possible combinations thereof. We can do better - for example I really like the layout strategy of flutter. I think there should be space to experiment with different parts of the stack, which means it needs to be modular. But making all the modules fit together requires coordination.
Hehe, that's awesome!
Oh well, then it can be trivially implemented: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=fe02965882ad9344cd81b08277866ab5 
I agree, there's a lot of different stuff like you said, min-width flex-basis etc, perhaps you could even leave them out of a project like Azul, simply remove them from the CSS parser for example. I also agree there needs to be room for experimentation, modularity is important and necessary these days, it can require a lot of coordination but in the end it works out better for everyone. I haven't used flutter but I do see from the docs there's bits of CSS, C++ / Java, Python, etc. style code in there. Looks pretty cool but I doubt it would be for me heh
There's a really cool video about the internals that's worth a watch even if you never use the product. Sadly I'm on mobile or I would find the link.
Actually, `std::error::Error` isn't required just for propagating things up in a `Result`. The complication comes probably from the fact that some individual parts of the language interact: * `std::convert::From&lt;T&gt;` is the trait you implement for all general (infallible) conversions to your own types. * When using `?` the propagated error will be converted with the `From` implementation. * `std::error::Error` is a trait your error types can implement. This provides an interface for a causal chain. For example: if your own error somehow contains the raised `ParseIntError`, the `cause` accessor gives a way to provide that inner reason for the outer error. * `std::fmt::Display` is required by `std::error::Error` and is how error messages are typically provided. * `failure` is a crate providing convenience methods and general error types that are commonly found in applications. It also makes it easy to very simply add more context to errors with its own `failure::Error` type. Personally, I tend to implement all of the `std` traits above. Either manually, or if there are a lot of similar ones by making some macros. I use `failure` only for applications, and only sometimes. It depends on what requirements I have for my errors. It provides some awesome stuff, I just don't mind the boilerplate myself. If you don't have specific requirements on your errors outside of its scope it's certainly worth a look.
Oh my god, I could've set that up ages ago. Now in my .vimrc: autocmd FileType rust nmap &lt;Space&gt;p iprintln!("{:?}", );&lt;C-O&gt;h
/u/pftbest /u/_TheDust_ /u/jesseauswright Thanks everybody, it's working! If you're interested, this is what I ended up doing: ```rust pub struct Gfx { ... pub texture: Texture&lt;'static&gt;, _texture_creator: TextureCreator&lt;WindowContext&gt;, } ``` `Gfx` now holds the `_texture_creator` so that `texture` doesn't point to invalid memory when the function ends. I also had to make the compiler think `Texture` has a lifetime of `'static` as mentioned by several of you guys. To instantiate the `Gfx` trait I used a pretty ugly workaround: ```rust let texture_creator = ...; let texture_creator_pointer = &amp;texture_creator as *const TextureCreator&lt;WindowContext&gt;; let texture = unsafe { &amp;*texture_creator_pointer } .create_texture(...) .unwrap(); Gfx { ... _texture_creator: texture_creator, texture, } ``` Basically, `create_texture` borrows the `texture_creator` which means I can't pass it to `Gfx`. To avoid the borrow I first convert the `texture_creator` into a `*const TextureCreator&lt;_&gt;` to relax the borrow checker. Just how bad is this?
OH SHIT WRONG RUST
Eh, I have bigger fish to fry.
Hope You Enjoyed The Video! Subscribe For More!
Wrong subreddit
Is it really that hard to read the subreddit's description before posting? (hint you need r/playrust)
Well, I'm glad the Servo multimedia framework actually has support for multiple backends in the design. Last time I poked GStreamer with a fuzzer I was *not* impressed with its memory safety, and fuzzers do not find all the bugs. Sadly there is no VP8 or Opus decoder in Rust yet, but at least we have [lewton](https://github.com/RustAudio/lewton) for OGG and [claxon](https://github.com/ruuda/claxon) for FLAC. Hopefully rinimp3 will become usable sometime soon as well.
I was waiting for the equivalent punchline but it never came. :-(
Isnt That Link This Was Posted On r/rust Sorry If I Hurt Your Feelings Mate! 
It's very much not solved in the large. There's a fair bit of process hacking that goes on right now - things like getting a contractor to bundle up a set of libraries and their dependencies into a single fork that merges all the repos and sell it to you. So the enterprise has guarantees that someone else is attesting that all the licenses are compatible with one another, etc, etc. And there's only one set of paperwork to deal with. This means that versions tend to be frozen and upstream fixes may not happen. I'm currently trying to fix this and looking at tooling that can help. This is very much not a Rust-centric problem, but there are ways that the library ecosystem is currently structured that do make things more difficult than they could be. At some point it may be helpful to have a way to build larger libraries out of sets of crates, for example. (I don't want to make crates bigger just because, but it's really hard for me to visualize how this currently scales to 1-10M LOC projects). 
Thanks for the correction! I missed that note in the docs somehow. I get the idea, but I'm still thinking about whether I buy in. If your `Rc` is embedded in some data structure and you derive `Clone`, for example, it's still gonna be cheap, but you aren't going to get this hint about it. Maybe the right thing to do would be to add a `.clone_rc()` method to `Rc` and `Arc` and encourage calling that for these one-offs. Easier to read, communicates the same information, allows not explicitly naming the trait. (I think as it stands if you change the type of some datum from `Arc` to `Rc` you might have to go find all your `Arc::clone()` calls and edit them?) Anyway, I try to write idiomatic Rust, so I guess I'll follow the recommendations in the docs. Thanks again!
&gt; "embedded Rust programmer (s/he doesn't need no stdlib)" [This is a silly example](https://gist.github.com/glasswings/a7aaa52dfb63c74d88ef209acdb6306e) because almost any embedded system that has Linux would have `std` too, but I got a little nostalgic for PC-BIOS interrupts and it's remarkable how well Linux still supports that style of programming. I'd love to see a more serious example using, say, /u/japaric's [crates for embedded microcontrollers](https://japaric.github.io/stm32f103xx-hal/embedded_hal/index.html).
https://github.com/zbraniecki/annotate-snippets-rs - A library for formatting code snippets. I wrote it because I needed to display elegant error snippets similarly to what rustc does (but rustc code cannot be reused). I'm using it in fluent-rs, and recently ag picked it up, but I believe that the crate has much bigger potential to be useful for all kinds of command line apps that deal with some multiline, textual data. The crate is not actively developed, despite there being a lot of neat features and cleanups that we could do. It should be easy to start with because the code is not big and test coverage is good. I wish someone would add cool features like multiline annotations etc. and refactor the code so if you're looking for a standalone, "visual" project to play with, maybe this will catch your interest!
I hope one day to be good enough at Rust to understand the humor in about half of these. Amazing work!
I like your solution a lot! However, your fold goes through each ordering regardless of whether it actually needs to do so. Instead, you could do this: /// Multi-level sort a slice of Foobars according to [(field, reverse)] fn sort_by_names(f: &amp;mut [Foobar], orderings: &amp;[(Foofields, bool)]) { use std::cmp::Ordering; f.sort_by(|a, b| { let mut cmp = Ordering::Equal; for (field, reverse) in orderings { if cmp != Ordering::Equal { break; } cmp = match *field { Foofields::Foo =&gt; a.foo.cmp(&amp;b.foo), Foofields::Bar =&gt; a.bar.cmp(&amp;b.bar), Foofields::Oof =&gt; a.oof.cmp(&amp;b.oof), }; cmp = if *reverse { cmp.reverse() } else { cmp }; } cmp }) } You could also use something like itertools' \`fold\_while\`, but I find this implementation pretty clear.
Nice, finally we got `?` repetitions in macros. Don't have to copy things around anymore
Thats what command history is for, no typing at all!
&gt; You can now use the ? operator in macro definitions. Sweet, it's finally here. I was looking forward to this in 2018 edition, since.. it was in the edition guide. But wasn't in 2018 edition. :( 
While electron is mature and useable, it's only really valid imho for desktop applications. I can't take electron and run it on my iPad for example. I feel we need something in rust that is more like QML and can be run anywhere.
The education part of your list sounds really great. I don't know why but finding good write ups on GUI (particularly desktop) seems like finding rare gems. Maybe it's because GUI frameworks have been so heavily platform dependent with a lot of secret sauce cooked into every layer. 
Wow, that does look extremely useful.
Qt should be considered in two parts. QtWidgets doesn't fit rust well. It is heavily object based and a lot of design patterns involve inheritance and overriding methods to customize a widget. This could be modeled with traits but just an example. It also only really runs on desktop. QML + QtQuick is the other part. This would fit rust much better. It's far more declarative and you don't have a lot of the issues because the UI layer actually runs with an embedded JavaScript engine. This in turn, I believe, is exposed to even Qt itself with a CFFI so you'll see early bindings in many languages that can take advantage of that. Qml also runs on mobile too so is a lot more interesting. However it's under more active development so is less mature. Imho I'd like to see more active development with bindings to QML.
I wrote: &gt; I'm already lost :-( . The standard game of Bingo is symmetric as far as I can see. I don't understand why horizontal would be favored? I really didn't understand Bingo. Having reviewed the rules of the game more carefully, I see why you think that rows might be more common than columns: more tokens per column. Still not sure it's right, though? The probability of a column win in 5 turns is 5/(74 5) ["five divided by seventy-four choose five"] while the probability of a row win in 5 turns is also 5/(74 5). (This is about 1 in 80M.) Or am I doing something dumb? Anyway, that's why we write the simulator: to check our math. :-) I also need to modify my recommendation for bit boards a bit. You might want to use `u128` for at least some of the bit boards (74 Bingo tokens, as I now realize), which means they'll be twice as slow. Still pretty fast compared to looping over things, I think?
Oh, sorry, I got the threads mixed up. I was referring to Matthias247's code. You are right that \`Pin::new\_unchecked\` is \`unsafe\`
You could also setup logging in your code. :P
[This](https://crates.io/crates/dialoguer) looks pretty close. I played around with it for a little while and it seems nice.
Wow! Just stumbled upon this thread and mongodb driver! I'm having trouble using ssl. I'm getting this error: `configure: error: You must install the OpenSSL libraries and development headers to enable OpenSSL support` I already installed openssl via `brew` and set the env vars. Have you had any success using SSL? 
Another shameless plug: Linux project I've been working on that mimics the functionality I use in ShareX on Windows. [https://github.com/ShareXin/ShareXin](https://github.com/ShareXin/ShareXin) Uses GTK for a GUI dialog. Sends either a message or a message and a screenshot to Twitter or Mastodon, and can send just a screenshot to Imgur.
Iâ€™m pretty confident about the math in the asymptotic case. The part of the project that I have discussed in this post was inspired by [this paper](https://www.maa.org/sites/default/files/pdf/Mathhorizons/pdfs/The_Bingo_Paradox_MH_Sept17.pdf). Your thinking is on track. Itâ€™s good to start by considering the case where a win occurs in five turns. I think 75 choose 5 is not quite right. Iâ€™m not completely following the logic. The paper I linked has a really cool calculation for the probabilities if you assume that every possible board is playing. This assumption simplifies the calculations such that, if five numbers are chosen from the same column (nums 1â€“15, 16â€“30, etc.), then this constitutes a win. If numbers are chosen such that, in five draws come up and no column is chosen twice, this constitutes a row win. I highly recommend reading the linked paper for a much more cohesive explanation. I really appreciate your suggestions. First thing I will try is extracting all of the winning sequences for a board into a vector of 12 vectors of `Option&lt;NonZero&lt;u8&gt;&gt;`. I will also give further thought to using a bitvec. 
To be fair the status quo is sufficiently battery hungry that you can get some serious improvements and look pretty friendly by comparison while still lagging behind native GUI frameworks.
Use contains_key(&amp;my_string) instead of contains_key(my_string)
Ooh, thanks for sharing! As a Pythonista, I'll trust pretty much anything published by Armin Ronacher.
Hello, I still get the same error even when I put the &amp;.
Can you reproduce the error in the playpen? 
[Miri](https://github.com/solson/miri) helps (semi-informally?) define rust semantics and detect violations of them. In short, it helps unsafe code find Undefined Behavior. Among other things. See [these blog posts](https://www.ralfj.de/blog/categories/rust.html) if you want to get down into the details
Instead of electron there's always webview, that has rust bindings, and wasm :)
No, but it's a very very simple macro to make. ``` macro_rules! logdbg { ($e:expr) =&gt; ({ debug!("{:?}", $e); $e }) } ```
I think `my_string.as_str()` should do the trick.
I think the types are the other way around than usual: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=26d4961cd297d4e787ebcab2f8150471
Haha! [The Evolution of a Rust Programmer](http://antoyo.ml/evolution-rust-programmer) was a very entertaining read! Actually informative *and* entertaining! I guess I'm a `Senior + Functional Rust Programmer`, according to the article! :) Thank you Antoni Boucher for posting. You put a big smile on my face...
Thatâ€™s true, but you should still be able to get a &amp;str out of that String
Ah yeah, maybe &amp;*my_string...
"idiomatic for Rust" is fairly common. I've seen "rustic" too.
&gt; At this point, without knowing how deep into Cocoa you've gone in the past, there's not much more to say. I personally feel confident in my knowledge on the matter and would put money on this being incorrect; it's simply nowhere near what it needs to be. You're entitled to your opinion, but I feel like you're ignoring the fact that outside the specific LCL controls/widgets that have been specifically implemented in Cocoa so far, there are still the complete usable bindings for Cocoa itself and all the other Mac APIs available in the Free Pascal standard library, and again language level support for using them. You mentioned videos/gifs for example before and I'm quite confident that would be very doable currently. The main graphic-related LCL controls [*are* implemented](http://wiki.lazarus.freepascal.org/Roadmap#Status_of_TGraphicControl_based_controls_on_each_LCL_Interface) in Cocoa already, also.
Huh, really? Honestly i didnt know that. Thanks.
Vastly different experience than the OP of that thread. The book has some meticulous elements I haven't seen in a technical book before - it's literally my favorite rust book (possibly favorite tech book in general). Posting this here three months later because people search forums for opinions before buying and this book clearly doesn't seem to have gotten a far shake.
Signed up but can't receive confirmation mail...
Hmm, the `str` value which you borrow should have longer lifetime than Hashmap. Otherwise, when `str` goes out of scope, the borrow `&amp;str` will be invalid.
I have been plugging cargo-nono everywhere possible. It's great! https://twitter.com/bascule/status/1083020269478850562
Could someone direct me to resources for writing tests for functions/programs that principally manipulate the filesystem?
I've personally observed it a lot in non-ironic contexts. IMO, the meme reflects reality.
It's a candidate logo for the [Rust Secure Code WG](https://github.com/rust-secure-code/wg/issues/1)
Iâ€™m overlooking it because none of that matters when your competition is Electron, a browser engine that renders the same code visually everywhere. This entire discussion is about a cross platform GUI approach that renders everywhere, and youâ€™re now veering into just writing custom code. Thatâ€™s not useful, especially in Pascal since itâ€™s in no way a dominant language today. My entire point is that yeah, sure, you could hack support for stuff for MacOS, but itâ€™s not default, itâ€™s not straightforward even in standard Cocoa, and itâ€™d be different than how you would do it on other platforms. If your UI engine of choice requires platform-specific code for day one stuff, itâ€™s not a great solution. This is why Lazarus isnâ€™t what itâ€™s billed as; Qt is probably the closest in â€œjust worksâ€ to the browser. Lazarus is admirable but nowhere near complete enough for modern apps. And sure, you have NSImage. Now figure out proper caching support for network downloaded images, or rendering something non-image (e.g an SVG, a chart). These are all very necessary things for modern applications that make people just go to Electron. Any new GUI solution needs to make these things â€œjust workâ€, otherwise it wonâ€™t matter beyond niche stuff.
Perhaps! I'm not really qualified to judge that - I can only measure the usage of the overall solution!
I'm trying to read in words as standard input and check to see if they are keys in a hashmap. When I am iterating with a for loop I create a string that stores the word and then looks up the word to see if it is a key in the hashmap. So how could I initialize the str before initializing the hashmap? Would it be like let str = String::new() and then make it mutable so that str can store a new string every time multiple strings are entered with standard input?
[Here](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8cebab9c46c2f2b8c375f58b17d25c0c) is a Senior (proper error handling) + Functional Rust Programmer (didn't need to go to `IterTools` to get `fold()`. 
The general intuition is that you shouldn't be taking a borrowed value and stashing it somewhere long term. The whole premise of the term "borrowing" is that you intend to give it back at some point! When you use a value as a key for a hashmap insertion it gets stored inside the map and the borrow checker assumes that it will stay there until the map is destroyed. Instead you need to get an owned value to insert into the hashmap, perhaps by cloning the key value. &amp;#x200B; \*In more advanced usage it is actually possible to use borrowed values as hashmap keys, however you have to convince the borrow checker that the borrow will live long enough (this is what the error message you got is talking about). The first step to doing that is of course actually having the key live long enough. This generally involves destroying the map quickly after it is created.
Yeah, but only if deref coercion applies and the target expects a `&amp;str`, but `Borrow` is generic and can't make that decision, right? Like you noted below, `&amp;*my_string` as explicit deref should also work.
&gt;My entire point is that yeah, sure, you could hack support for stuff for MacOS, but itâ€™s not default, itâ€™s not straightforward even in standard Cocoa, and itâ€™d be different than how you would do it on other platforms. You're missing my point though. I'm saying the underlying cross-platform technical capabilities are all there (with direct support from FPC as a compiler), meaning everything (as all the specific LCL controls Lazarus usually makes available) *can* be implemented and eventually will be. Again, there *is* also an existing QT backend, as you know. Lazarus is an *IDE* that implements a framework for which the whole point is to wrap native frameworks in a same-everywhere way. It's not a framework itself, so I think it's somewhat disingenuous to say it isn't what it's billed as.
You won't be able to use `&amp;str` as the keys in this case because the strings you are inputting will live shorter than the hashmap. Instead, you must use `String` as the keys. Here's a simpler example of what you are doing. use std::collections::HashMap; fn main() { let mut map: HashMap&lt;&amp;str, i32&gt; = HashMap::new(); { let my_string: String = String::from("testing"); let my_str_ref: &amp;str = &amp;my_string; map.insert(my_str_ref, 42); } println!("{:?}", map); } The problem is that the map will hold a reference to `my_string`, but `my_string` has too short of a lifetime because it gets dropped at the end of the block. Then, that reference will be pointing to memory that no longer represents a string.
I think your problem doesn't lie in the actual String â†’ &amp;str but in the inferred generic \`contains\_key\` function. &amp;#x200B; TL;DR: You need to enforce the usage of \`contains\_key::&lt;str&gt;\`, not \`contains\_key::&lt;String&gt;\`. &amp;#x200B; Source: [https://stackoverflow.com/questions/37521043/dereferencing-strings-and-hashmaps-in-rust](https://stackoverflow.com/questions/37521043/dereferencing-strings-and-hashmaps-in-rust)
How would you use Strings as the keys? Also what is the difference between String and string? Thank You
Cool stuff. I remember playing moonstone alot. Nice that its rustified 
https://github.com/nimiq/core-rs Rust port of Nimiq (Blockchain that runs on browser)
I never knew these aliases existed! 
A `String` is what you would normally expect from a string, you can modify it, add, remove, etc. A `&amp;str` is basically a "view" of a string. You cannot change it, and the contents it is looking at live somewhere else. When that somewhere else goes away, the `&amp;str` must have also gone away. I might not be explaining this super well, so I'd recommend reading the rust book. You should through all of it if you haven't, but this chapter is especially important and unique to rust. [https://doc.rust-lang.org/1.30.0/book/second-edition/ch04-00-understanding-ownership.html](https://doc.rust-lang.org/1.30.0/book/second-edition/ch04-00-understanding-ownership.html) I assume you're doing something like this. for word in input.split_whitespace() { // ... } In this case, `word` is a `&amp;str`, and to turn it into a `String` you can do `word.to_owned()`. What this does is make a new `String` and copy the contents that the `&amp;str` is viewing into the `String`.
I'm trying to do something like this: for word in input.split\_whitespace() { let str = word; if !hashmmap.contains(str.as\_str()) hashmap.insert(&amp;str, some valu) } Using your recommendation I got something like this: for word in input.split\_whitespace() { let str = word.to\_owned(); if !hashmmap.contains(str.as\_str()) hashmap.insert(&amp;str, some valu) } Even after the change I get an error message saying borrowed value does not live long enough. Should str be declared outside the for loop? Thank you
Gotcha. Thanks again. 
Is it considered good practice to call it directly, considering that `collect` already calls it?
You are still trying to insert a reference into the map. Try this. for word in input.split_whitespace() { if !hashmap.contains(word) { hashmap.insert(word.to_owned(), value); } } &amp;#x200B;
For some reason, the rust compiler keeps on telling me to add &amp; in front of word for the if statement. I'm trying to do something like this: let str = foo(str) - foo is a function that returns a string if !hashmap.contains(str) { hashmap.insert(str.to\_owned(), value) } Once I add the &amp; in front of str in the if statement I get a trait is not implemented for &amp;str. Is this something to do with references or ownership? Thank you
liquid-rust is a string template engine with a lot of [good first issues](https://github.com/cobalt-org/liquid-rust/labels/good%20first%20issue)
I've actually encountered this recently. I'm writing a toy programming language (sounds interesting and doubles as a good way to learn rust), and for a symbol table i wanted to use &amp;str because the text of the input will live for the lifetime of the program. so *i* know it is safe, but i couldn't figure out how to convince the borrow checker. i wound up using boxes, then rc as they wind up getting handed around like crazy. at this point i recognized how a gc allows you to not have to particularly care about ownership. an interesting aspect of the gc i hadn't really thought much about. 
If you really want something to live for the lifetime of the program, then [`Box::leak`](https://doc.rust-lang.org/std/boxed/struct.Box.html#method.leak) gives you a `&amp;'static`.
you should install openssl version 1.1: ``` brew install openssl@1.1 ``` and set the following environment variables, for BASH shell: ``` export LDFLAGS="-L/usr/local/opt/openssl@1.1/lib" export CPPFLAGS="-I/usr/local/opt/openssl@1.1/include" export PKG_CONFIG_PATH="/usr/local/opt/openssl@1.1/lib/pkgconfig ```
You keep changing what you claim you're trying to do, so no one is going to be able to help you. Iterating over `split_whitespace()` is going to be different than using the return value from a different function. You can't just go switching those around willy-nilly. Maybe read [the book](https://doc.rust-lang.org/stable/book/ch04-00-understanding-ownership.html)?
Not sure of any concrete resources, but some tips I've learned: * The [tempfile](https://crates.io/crates/tempfile) crate is really useful for generating directories and files that are automatically deleted when your tests are finished * If you need files to populate your tests, a data folder in the root of your project is easily accessed by joining the path on `env!(CARGO_MANIFEST_DIR)`.
Trying to figure out an "elegant" way of providing inheritance. Given the following code: impl BaseWidget { pub fn get_origin(&amp;self) -&gt; Point { ... impl ... } pub fn get_size(&amp;self) -&gt; Size { ... impl ... } pub fn draw(&amp;self, graphics) { ... impl ... } } I want to create a widget that extends that: impl BoxWidget for BaseWidget { pub fn draw(&amp;self, graphics) { super.draw(graphics); (or) super::draw(graphics); (or !!) BaseWidget::draw(graphics); } } I'm not sure how to do the implementation, or even if the language has facilities for this (yet). I'm wanting to create a base widget library that I can extend from, so I can add things like a draw loop that fills a widget with a certain color (defined in the base), and other things of that nature. Things like "origin" and "size" will be stored in the base. Any assistance would be much appreciated!
Would I do something like this: pub struct BoxWidget { parent: BaseWidget, } impl BoxWidget { pub fn new() -&gt; Self { Self { parent: BaseWidget::new(), } } pub fn get_origin(&amp;self) -&gt; Point { self.parent.get_origin(); } pub fn get_size(&amp;self) -&gt; Size { self.parent.get_size(); } pub fn draw(&amp;self, graphics) { self.parent.draw(graphics); ... draw graphics here ... } } I _think_ I can do something similar with traits if I were to create a trait and use a struct, but I'm not sure what that would look like...
like how "current year + 1" cars are released in "current year"? it doesn't matter.
How is iterating over split)whitepsace() different than using the return value from a different function? &amp;#x200B;
I'm facepalming so hard here. Lets try this again. **You posted on the wrong subreddit.** Delete your post and go post on r/playrust which is the subreddit for the Rust video game. Eventually an admin will come around and delete your post for you if you don't get to it since you're violating the posting guidelines since your post has nothing to do with the rust programming language. In the meantime you're just going to continue to receive downvotes since people are **really** tired of the constant posts on here by people not spending 5 seconds to actually look where they're posting things.
I glanced over a few, but does any of them handle overflow of the sum? (none of those I looked at did)
The checkerboard is the least realistic part of the image. Without it I would have just wondered why they had a photo of a slightly grease-stained plastic dragon. As it is, I'm honestly having trouble convincing myself it's not a photo. It's the stains that really sell it...
Only because I am currently looking into this with a test application that I plan to build with a few different GUIs, what would you suggest is a good base app for testing GUI battery life? Also, how would you test it?
And shell aliases.
More senior: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=381b4d3b09df0c30e11e4a0e21b097cc :P
The greatness of `dbg!` is that itâ€™s an identity function, ie. evaluates to its argument, so you can wrap a subexpression within a more complex expression and everything stays the same except you get the debug output,
Itâ€™s such a shame glium isnâ€™t maintained much anymore. Any effort towards that, or helping out the Azul-Glium fork Iâ€™m sure would be appreciated. And people from Mac and non Ubuntu people contributing. 
Neat! If you want this thing to be truly crash-safe, your dump should `std::fs::write` out to a temporary file in the same directory as the target path, and then `std::fs::rename` the temp file into place. Otherwise, you're not actually guaranteed the entire pickle file will be written out atomically. You could end up with a truncated file on system crash that is not valid JSON and will refuse to load.
You want [r/playrust](https://www.reddit.com/r/playrust) , this is for the programming language.
Thanks for the tip! Why do you think it's safer to write to another file and then rename?
or even shell autocomplete
Write syscalls do not guarantee all or nothing, some leading fragment of the file may be on the backing medium, but not the entire file, after a e.g. power loss event. Rename is atomic on the same file system in most cases. Ergo renaming a fully written temporary file in the same directory will (more or less) guarantee the content update at that path either entirely succeeds or fails. This is a slight simplification of why, but this is the method thatâ€™s idiomatic. 
&gt; I'm saying the underlying cross-platform technical capabilities are all there (with direct support from FPC as a compiler), meaning everything (as in all the specific LCL controls Lazarus usually makes available) _can_ be implemented and eventually will be. _Can be and eventually will be_ is literally saying it does not exist right now. The entire point of this chain of comments is that Lazarus is not what people portray it to be for building true cross-platform modern UI apps. I'm pretty sure we've run the course on this discussion.
WebRender doesn't contain a full CSS/Layout/DOM implementation. You're quite a ways from being able to use HTML+CSS to do your UI, I think you'd need a pretty big chunk of Servo to make that work.
I would use `cargo --version` to check for availability. 
split_whitespace is an iterator over `&amp;'str`, but a function without arguments is almost certainly going to return a `String`.
Stop downvoting people who are asking for help. Seriously.
That makes sense. I'll make this change, thanks!
Not equivalent, but for some use cases, have a look at git worktrees. I use them heavily when working on larger projects / repositories (especially monorepos, where I work on multiple things at the same time). 
I hadn't seen try_fold before now--nice!
I seeâ€¦ There's a lot more going on here, probability wise, than my naÃ¯ve version counted on. Thanks much for the link: I'll try to give it a careful read and think about where I went wrong. That's the usual story with probability calculations â€” the Monty Hall Problem is a really simple example. I'm going to try to replicate your project as a C program for the class I'm teaching right now: it will be good to show the students bit manipulation. I'll show you when I'm done if you like. In the meantime: Each time a marker is drawn, set the corresponding bit in a bitmap representing the list of drawn markers. Then, for each board in play, bitwise-and the bitmap of drawn markers with each of the 12 bitmaps representing markers needed for a win on that board. (Those bitmaps can be calculated at the beginning of the game.) If any of those win positions have been achieved, the bitwise-and will yield the win position, and so you'll know the board has bingoed (and which bingo). All of these operations are pretty fast: you should be able to play out millions of games per second, at least. If that's not clear, I can write some pseudocode. Like I say, I should have C code to show you shortly. (The C is more annoying, as I don't have access to a 128-bit integer type. But I'm supposed to teach my students C in this class.) Thanks for sharing a nice problem!
The post is unreadable on my phone (iPhone) when using the reddit app. The first couple of characters on the left are cropped, and one canâ€™t drag the screen horizontally to read them.
Great article. It clearly shows rust as general purpose language, unlike common "better cpp" talk
Thanks for your explanation. Now I know `y` outlives scope inside `my_func`. But do you have any idea of exact lifetime of `y`? Does it live as long as the scope where `my_func` is defined?
Rip OP
\&gt; Well, I'm glad the Servo multimedia framework actually has support for multiple backends in the design. Last time I poked GStreamer with a fuzzer I was *not* impressed with its memory safety &amp;#x200B; Please report any such bugs, I'd be happy to look into them. &amp;#x200B; \&gt; and fuzzers do not find all the bugs. &amp;#x200B; Yes, all software has bugs so let's fix them? :) &amp;#x200B; \&gt; The push for Rust in GStreamer is admirable, but AFAIK nothing in the actual decoding pipeline for e.g. VP8 is oxidized. &amp;#x200B; That's true, but all the hard work for decoding VP8/Opus (for example) is done by the corresponding reference implementations (libvpx and libopus) in this case. While there's of course still some code in GStreamer that could explode (the WebM demuxer for example, for demuxers GStreamer generally uses its own implementations), in your example this is the same code used by all other browsers out there currently so at least for that the situation shouldn't be worse than for, say, Firefox. &amp;#x200B; \&gt; Sadly there is no VP8 or Opus decoder in Rust yet, but at least we have [lewton](https://github.com/RustAudio/lewton) for OGG and [claxon](https://github.com/ruuda/claxon) for FLAC. Hopefully rinimp3 will become usable sometime soon as well. &amp;#x200B; I have a prototype for a Vorbis decoder plugin around lewton (using rust-av), but there's only so much I can do alone. &amp;#x200B; If someone is looking for something to do, writing GStreamer plugins around the already existing Rust implementations for various codecs we have would be very useful and I'd be happy to help. Or demuxers for container formats, e.g. I already have a half-finished FLV demuxer around the flavors crate.
Very interesting. The libraries are all on GitHub too.
"On the origin of species" by Charles Darvin
I am currently writing a path tracer, both as a way of learning Rust and rendering algorithms. Sadly I left my copy of Physically Based Rendering at home when I moved to a different country, so I'm writing everything my own way and the results are not optimal, but it's a fun learning experience. Code in case anyone is interested: [https://github.com/josefrcm/rspt](https://github.com/josefrcm/rspt)
[`static_assertions::assert_eq_size!`](https://docs.rs/static_assertions/0.3.1/static_assertions/macro.assert_eq_size.html) already does this
Very interesting indeed :) Any other language you say? Well then, I shall try it with JavaScript :D /s
Looks like it was moved to https://www.reddit.com/r/rust/comments/agvho5/a_bot_for_starcraft_in_rust_c_or_any_other/ 
Great article. It clearly shows rust as general purpose language, unlike common "better cpp" talk
Yes please! If creating a Dll with JS will be an issue you can try to build it as a [Client](https://github.com/RnDome/bwapi-c/blob/master/example/Client.c). Feel free to contact me on [https://gitter.im/kpp](https://gitter.im/kpp) 
I was mostly kidding. I would love to try something like that but have 0 time. However I'll send that to people who might be interested!
I am sorry to hear about sour struggles. Thanks for sharing them. It opposes the feeling that one is the only one struggeling from time to time.
I suspect people are downvoting not because the question is too easy, but rather because it doesn't have [any specifics](https://stackoverflow.com/help/mcve). It is rather poor that people are doing this without asking for more info or otherwise giving feedback.
... or Misspel :)
Ok, thanks! I wasn't aware that WebRender was missing a full CSS/DOM implementation. I thought that it was just a full HTML + CSS renderer, however I guess it wouldn't be that hard to use the pieces of Servo? You are right! Azul does contain a subset of that using different crates for CSS, however as you said I'd be skeptical they can maintain performance. Atleast Servo is proven to be quick. I'd love to see some kind of stripped back HTML &amp; CSS (no js) rendering, I don't expect compatibility for every tag and every option, but just enough to build the UI portions of everything. Alternatively you could go full-blown Electron in Rust if you want! Thanks for the reply :)
Thanks! I'll take a look for that
Glium is safe, which is nice, however I think gfx-rs is much more powerful, even if it's unsafe. The power to write once, run anywhere is too great to pass up! I didn't see the Azul-Glium fork, seems interesting but with Glium no longer being maintained I guess it's not really going anywhere :/ Thanks for the comment :)
The only big language change coming in 2019 so far is async/await. Also, keep in mind that Rust 2015 code is fully ABI-compatible with Rust 2018 and will work just fine within the same project.
It may work but it also limit the emergence of design patterns and the ability for a newcomer to learn by reading other's source code (or worst, learn things that are no longer relevant).
Wouldn't the overhead of an Rc be trivial to accept for the GUI parts of your code for almost any arbitrary project? I imagine Qt itself would have a far greater overhead than a mere Rc anyway. The Binding Generator solution sounds fairly elegant, but I can't help but expect that the Rust community would shun it in favor of GTK at its first real opportunity.
Good point, thanks for pointing this!
I'd really want to factor out the combining of predicates into its own function, not a huge nested lambda.
Are there any documentation about these cargo's aliases? 
I wrote [a little](https://rust-lang-nursery.github.io/cli-wg/tutorial/testing.html#generating-test-files) about this in the CLI book. The *tempfile* and *assert_fs* crates will probably help you a lot, as well as writing some helper functions for common setup tasks between tests. (Look at cargo's test suite for an example of that.)
Iâ€™m sorry if I wasnâ€™t clear enough but Iâ€™m mostly afraid to have in 2 years an over complex language with too many features. As I plan to use Rust professionally (for full time open source projects) I need some stability to focus on the business logic and not to worry much about language changes (and thus spend most of my time re engineering libraries instead of shipping new features to users). I think one of the reason which explains the Go success is the stability, thus community can build on stable foundations and libraries progress to a 1.0 version faster. Go hadnâ€™t a major change in ~10 years. For example, as an enterprise I choose rust to power my new backend or IoT project. Is there guarantees that in 5 years my collaborators will be able to understand the code put in place today ?
Thank for the quick reply! I was missing the third env var: &gt; export PKG_CONFIG_PATH="/usr/local/opt/openssl@1.1/lib/pkgconfig" I set it and followed the instructions to install de C driver too, available [here](http://mongoc.org/libmongoc/current/installing.html) Made some progress but now I'm getting this error: `dyld: Library not loaded: @rpath/libbson-1.0.0.dylib Referenced from: /usr/local/opt/mongo-c-driver/lib/libmongoc-1.0.0.dylib Reason: image not found` Thanks again! 
Such a guarantee is literally impossible, and even if it were possible, _I'm_ definitely not in a position to give you one. 
Thatâ€™s an awesome suggestion. I look forward to trying it. I always wondered if bit operations on bitvecs were performant. I guess they are. Time to write some benchmarks. 
awesome. I cut my teeth on the Amiga and am still very nostalgic about the platform, although not an active 'amiga OS user' in 2019 or anything. I wonder how hard it would be to re-write D-Paint in Rust..
I was under the impression that c++ does not have a stable abi, so surely interacting with its vtables isn't possible unless you restrict the choice of c++ compiler?
I want to multi-thread an euler problem-style mathematical search on a very large space. My idea is to do a normal search until a certain depth is reached, and then hand over the subproblems to a thread pool/job queue. I'm thinking of using `threadpool` for this, but is there an easy way to block the producer so it only pushes jobs at the same rate as consumers finish them?
Of course they will. The rust core language will not change. Just some syntax changes probably. 
Does this post cut off unexpectedly for anyone else during the build sandboxing discussion?
I'm using Rocket to build an API, but I have a lot of endpoints. I can't figure out from the guide / docs if there is any way to handle them all more tersely. I tried using globbing, but evidently `routes!` doesn't accept that. Is there some Rusty way I can separate all my routes so I don't have to list every single route for my API in one huge list in main?
That is correct. And not just restricted to a specific C++ compiler, also to a specific version of that C++ compiler and compilation flags as nothing is guaranteed.
This isn't necessarily valid syntax, but it should help. The blocks give you the exact lifetimes of each declaration. 'a is a lifetime that outlives the function entirely by some duration. fn my_func(i: &amp;'a i32) { 'b: { let x = 5; 'c: { let y = &amp;'c x; } } }
go to does work, press F2 click not processing has to do with particular editor widget for plaintext
Have you read the book? From going through your comments in this thread, it does not appear to be the case. Reading the book would help you significantly.
If you control the environment and have the source of both its not too bad; one could package an "SDK" for others to re-create software that way. Very Windowsy.
Wait, so you can define custom aliases? :O
Is there an easy and legal way to obtain a copy of the game to extract the assets?
Thanks! Glad you like it! If you have any suggestions on how `cargo-nono` could be improved, feel free to open an issue :)
I'm looking for a good NAT transversal crate. Can anyone recommend one?
So to summarize: OP, use a C API between C++ and Rust? :-)
Is there a â€œPragmatic Rust Programmerâ€?
Or an IDE :p
Wait, ABI compatible? Rust doesn't have a stable ABI. Calling editions backwards-compatibility kind of bothers me. It's more a form of "inter-version compatibility"
Well, true. It's not really "ABI compatible", it's more "compiler level compatible" or something like that, but the core idea is the same - you can link 2015 edition crates to 2018 edition crates and things will work just fine.
Personally, I'm also worried about stability, as are other people in the community. I wouldn't say Rust is quite there yet. Many parts are very stable, other things have still to emerge (like async and const generics) and some others are functionality there but still somewhat in flux (modules, patterns, etc.). It seems that stability and maturity will be a focus for many people in the 2018+ edition, so I would suggest to "watch this space" and follow along. And never mind the downvotes, there is currently a bit of a drift between those who want Rust to keep it's speed of development and those who want it to calm down a bit.
Doesnâ€™t C++ explicitly position itself as a general purpose language? Wouldnâ€™t â€œbetter C++â€ necessarily imply being general purpose?
`hyper` is the go-to low-level solution, flexible, but somewhat difficult to use. `rocket` is high-level, but works only on Nightly right now, and will go through some changes in the next year or so. There's also `tower-web` and `gotham` -- both based on `hyper`, easier to use, not necessarily complete. The last major one would be `actix-web`, which does its own thing. It's very full-featured, but doesn't use `hyper` like the rest of them do, and brings an [actor model](https://en.wikipedia.org/wiki/Actor_model), which some feel is unnecessary. Personally I could never grasp its examples, but I hear the author is very responsive when asked for help. All of the above (and others) can do what you're asking, but you might find that some things are still lacking. It also depends on what your experience and expectations are: do you know how HTTP sessions work? Would you miss the middleware models from other frameworks?
&gt;split\_whitespace [https://doc.rust-lang.org/std/primitive.str.html#method.split\_whitespace](https://doc.rust-lang.org/std/primitive.str.html#method.split_whitespace) In the documentation for the method, it says an iterator, and that iterator returns string slices (\`&amp;str\`).
You can compile 2015 code with 2018 and there's a very good chance it will work. But you can't use a compiler from 2015 and 2018 and link the code together. Sorry to be pedantic, vague backwards compatibility issues in Rust are kind of a pet peeve of mine.
Thanks for the answer. I don't know much about HTTP sessions, I only did a course in Computer Security which defined some of the protocols used, but I am open to learning. 
Real GUI Capability for rust is a challenge to provide as it is for golang also. Ideally we would like to expect to building gui and binaries to happen without risk without feeling anxious/nervous that it would break: -build and run on ubuntu touch i.e. older arm 32-bit hardware and older and essentially frozen os distro libs. -build and run on centos/redhat legacy os running default legacy gtk distro libs. These are also essentially frozen os distro libs. -build and run on archlinux/clear linux/qubes from default/latest distro libs. All the distros are not synchronized to the same versions of source for all their distros. That's life, but adds to the complexity. Older 32-bit os has legacy gtk/legacy qt since it's easy to understand everyone has moved on to newer 64-bit hardware for better performance and battery life and END-OF-LIFE(no longer manufactured/sold). So the level of commitment from developers to maintain older hardware isn't there for those reasons. The only way to expect new features/new libraries/new compilers is by cross-compiling rust/newer gtk/newer qt onto older os/older hardware but there is no clear commitment in terms of older hardware/older software repos servers and time from anyone for that. Everyone just wants to make it run on what they have rather than make it run everywhere/every hardware. That's a problem. In order for everything to co-exist we need to point to different libraries in different directories using special compile time linker switches that tell the out binary where to find the newer non-default qt/gtk libraries at compile time and at run-time. It makes it really complicated to build/maintain in these scenarios. QT is committed to C/C++. GTK is committed to C/C++. All the other language bindings are provided by other parties trying to interoperate with the gui after the fact. The only way to prevent this from happening in the future is to ensure there are tools in place to automate generate any changes to qt/gtk api to all the other languages from within the qt sdk/gtk sdk itself. It would also require similar tools could be backported to previous versions of qt/gtk and and especially to the different hardware and os'es. That's very hard to achieve manually, but it could be a task for AI to achieve. 
&gt; For example, as an enterprise I choose rust to power my new backend or IoT project. Is there guarantees that in 5 years my collaborators will be able to understand the code put in place today ? It might look a bit different. but it shouldn't be too different to figure it out. I think the stability you're after will only come after an externel ecosystem of tooling has developed. Currently, many parts of the toolchain like `rustfix`, `rustfmt`, `clippy` and so on are made by the Rust team, or hook into `rustc`, or made by Rust developers closely following the development. Once the language is understood by more external things it will be harder to make big changes often.
https://medium.com/sean3z/building-a-restful-crud-api-with-rust-1867308352d8 is a nice writeup of building a web service in Rust. It happens to use Rocket, but the same principles apply to the other crates I mentioned.
Yup. Just I don't know any useful aliases to define, Cargo makes it easy to build Rust.
Yup. Just I don't know any useful aliases to define, Cargo makes it easy to build Rust.
Thanks again for taking the time to write such a thorough response and explaining your thoughts so well. Sorry it's taken a while for me to make time to sit down and give it my full attention. &gt; I would probably go with the reference-based one, since it gives me the most flexibility and puts the fewest constraints on the caller But doesn't the reference based one (`-&gt; List&lt;&amp;'a str&gt;;`) put more constraints on the collar than one that makes an allocation and returns a copy (the first signature)? Since the returned reference then has a lifetime contingent on not changing the input, whereas if you returned a copy, the caller could then mutate the input freely (later in the calling code) without concerns about the reference? That would seem like the situation with the fewest constraints on the caller (though obviously requires an allocation). &gt; And if you notice, in my last implementation of argmax, I did use "move" semantics. But the only thing I moved was the iterator, not the thing the iterator points to. &gt; i.enumerate().max_by_key(move |(_i, n)| *n).map(move |(i, _n)| i) I need to review closures and move semantics (for the hundredth time). There are *two* `move`s there; isn't the only reason that you're not moving "the thing the iterator points to" due to this case having a `Copy` type? I thought `move` should move everything in a closure's environment. Anyway, if you don't have time to continue teaching me, I'll continue reading on my own, but thanks for such a helpful exchange so far.
I would say it took me 3 weeks to learn Rust with the book. I'm the slow learner.
You are not a slow learner, even if you can read the book in one day, ownership and borrowing often take a couple of weeks to sink in. Skipping the book does not speed that up: there is no shortcut.
huh, interesting, i'd not heard of them. Thanks!
Any reason you couldn't just pass the `&amp;str`s around and make the hash map contain `&amp;'static str`s?
I am not sure this will work: &gt;The traditional model for this kind of work is to decompose the interface into widget objects, and have them interact by calling methods on each other. Each widget object encapsulates its fragment of the world state, but all this state is effectively available to all other widgets at all times. Further, all widgets are reachable from all other widgets, as a widget will store references to its parent and children. That doesn't really work in Rust. In Rust, access to mutable state is very controlled; only one mutable reference to an object can exist at a time. [https://raphlinus.github.io/personal/2018/05/08/ecs-ui.html](https://raphlinus.github.io/personal/2018/05/08/ecs-ui.html)
Where did you hear Rust isn't a general purpose language?
This is a forum for a programming language, named Rust, not a video game.
This is not really correct any more. GCC, Clang, and others on Linux and other Unix-like systems have standardized on the [Itanium C++ ABI](https://itanium-cxx-abi.github.io/cxx-abi/). Microsoft uses its own proprietary, undocumented C++ ABI, which has traditionally changed between compiler versions, and they have recommended using C or COM to provide ABI stability, though they are now [supporting compatibile ABI versions between major releases of their compiler](https://docs.microsoft.com/en-us/cpp/porting/binary-compat-2015-2017?view=vs-2017). However, even though it is proprietary and undocumented, it has been mostly reverse engineered and [Clang offers support for the Microsoft C++ ABI](https://clang.llvm.org/docs/MSVCCompatibility.html), both their 2013 ABI and the 2015 ABI which is supported backward compatibly in Visual Studio 2017. So at this point, there is precedent for C++ ABI compatibility between compilers, which means that a project for direct C++ ABI interop in Rust would be possible, though a lot of work.
" ... Like any ordinary people, we decided to start with ~~hello world~~ writing a dynamic library for Windows that could be loaded into StarCraft's address space and manage units." Rust tends to attract these types. I wonder if it does so more than other languages?
No problem! Just for extra fun, it's interesting to chase things down the rabbit hole of yes-I-really-meant-write-that-to-disk. 1. Without calling `fsync()` on the file descriptor before returning from the dump method, the data could sit in a kernel buffer and then a system crash could lose the update. 2. `FUA` SCSI/SATA command needs to be conveyed to the disk, and then the disk needs to actually obey it. Not all disks do. 3. The disk is probably doing caching as well. Is it write-back or write-through? So, the disk cache settings need to be set appropriately or disabled. 4. If you have a "fancy" disk controller like a RAID controller, there's a good chance the FUA ack is coming from *it* instead of a the actual disk. Does its cache have a supercapacitor or a battery to ensure that the ack'd writes are actually eventually flushed to the medium? If it's a battery, is the battery (still) working properly? And then there's integrity/consistency errors... 1. Without writing a checksum out with your file, you're vulnerable to uncorrected bit errors coming back from the disk. They do happen. 2. Is everyone's system using ECC memory? Do you keep the checksum with the data for its entire lifetime in memory to detect ECC failures? 3. Do you deserialize the bytestring back to the object after serialization and make sure you can recreate the original? Sometimes bit flips happen *during the serialization process*, and then you save the bytestring and checksum, but the bytestring (which is valid acc'd to the checksum) is actually bit flipped and corrupt. I'm involved in projects that store exabytes of data on millions of disks using custom storage engines (built in rust!), and at that scale all these problems (and more I'm probably forgetting) actually do happen. But... for the purpose of a library, I think it's reasonable to say: 1. Definitely atomic move after write temporary, otherwise even program crash can corrupt the data. `::std::fs::write` is build on `Write::write_all`, which issues multiple write syscalls in a loop. (https://doc.rust-lang.org/src/std/io/mod.rs.html#1066) 2. Consider fsyncing (https://doc.rust-lang.org/std/fs/struct.File.html#method.sync_data) before returning from dump to protect against the most common type of system-crash related data loss. This has a big performance hit, so you might want that to be an option the user can choose when they initalize `PickleDB`. Example from well-known project: https://github.com/facebook/rocksdb/blob/master/include/rocksdb/options.h#L1203 
I object to your objection.
Noted. Thanks for the tip!
&gt; but works only on Nightly right now The latest release is likely the last one that requires nightly. The next one should work on stable.
True, but itâ€™s nice to be able to chose to go lower level if appropriate, instead of having that decision forced on you because what you did rely on got dropped. And the azul-glium fork exists because there are some bugs in glium that effect azul, but as itâ€™s not really maintained, pull requests to fix those bugs arenâ€™t getting processed. So the decision was made to just fork it and fix the bugs there. 
Better than general purpose, maybe?
It can be a different lifetime in each location where the function is called. You can think of it like another generic type parameter. The caller will fill in the specific lifetime it needs. The implementer can only rely on the fact that it exists and any constraints on it, like whether it is longer than some other lifetime parameter.
Perhaps you meant /r/playrust
It's not going to be many people's first language. It seems likely that a lot of Rust learners are experienced C++ devs looking for a way out.
Just put it here because I haven't see any post on the last three days! Come on Rustaceans, where is that spirit?
&gt; Not that anyone would or should care, but as a user I've always found GTK to integrate poorly in whatever environment I use at the time and have lots and lots and lots of usability quirks, so I can't help but shudder at the idea of the Rust community unintentionally standardizing on GTK widgets instead of Qt as a result of C vs. C++ bindings. I used to be a fan of Qt and not very fond of GTK, but in recent years GTK has gotten a lot better including platform support. For example on OS X, it used to require an X server layer, which was pretty horrible, but it's no longer the case and GTK now has native support. And some things are easier done in GTK, from my experience, for example, custom-rendered widgets are much easier to get done relatively well in GTK. As for why the Rust ecosystem currently leans towards GTK, I don't think the reasons are technical. I am an occasional contributor to the GTK bindings and I also tried to create a Qt binding library in the past and I think the technical challenges are fairly comparable. Perhaps the MOC is somewhat scary for would-be binding writers, but other than that, I think it's just that for some reason the community has greater interset/incentive in making bindings for GTK at the moment. 
&gt; But doesn't the reference based one (-&gt; List&lt;&amp;'a str&gt;;) put more constraints on the collar than one that makes an allocation and returns a copy (the first signature) Sure. It's always going to be a judgment call, right? Minimizing constraints on the caller is one goal. Minimizing heap allocations is another goal. Imagine that you're running `top_n` very, very frequently. Perhaps you're implementing a branch-and-bound algorithm, and you're using `top_n` to implement the "bound" step in the algorithm. Since performance is important, minimizing heap allocations is very important. For that reason, I would rule out returning a `Vec&lt;String&gt;`, even though (as you rightly point out) it does give the caller a lot of freedom. I would consider an implementation that returned `Vec&lt;&amp;'a str&gt;`. However, even that signature requires that the implementation perform at least one heap allocation, so I might change the signature to something like: fn top_n&lt;'a&gt;(n: usize, results: &amp;mut Vec&lt;&amp;'a str&gt;, map: &amp;'a HashMap&lt;String, usize&gt;); where `top_n` writes its output into `results`. If the caller re-used the same `Vec` instance over many calls, then this would never need to re-allocate during the main run of the program. (And, all those cache lines would still be in the cache.) Yet *another* approach would be to take a mutable reference to the `HashMap`, and for `top_n` to remove all entries *except* the top `n` most frequent: fn top_n(n: usize, map: &amp;'a HashMap&lt;String, usize&gt;); I want to be clear that I think what you propose is perfectly excellent, for some scenarios. It's rare that there's just one right answer for all situations. I mean, there's a million ways to skin this cat, right? That's half the fun of programming, for me, is just how infinitely variable it is. 
That won't happen overnight. I would expect that to happen in 6-12 months, especially if it includes async support. It's still a valid pick, though, and it's no longer as bad as it was in the past, when it got broken every couple of weeks.
I think this obscures each of the items here. Every question should stand by itself, maybe tagged \*easy\* or \*questions\* or \*beginners. Having them all in one questions makes it difficult to find, or even appreciate, the variety of questions and solutions posted. Please break this down. Additionally having the same post glued to the top for days, don't say months, makes checking the board boring. Hope for the best. And thanks for all the hard work.
[This was posted yesterday...](https://www.reddit.com/r/rust/comments/agj2ji/the_evolution_of_a_rust_programmer/)
My mistake. Everything is as it should. I was looking at "HOT", changed to "NEW".
cool post, enjoyed the puns! i also recently started a frighteningly overambitious botting toy project for another [battle.net](https://battle.net) classic, diablo 2, myself. it's just bits of codes here and there but my idea is fixed. maybe someone is interested in helping a total rust+reverse engineering beginner out! [https://github.com/dorianprill/d2re](https://github.com/dorianprill/d2re)
&gt; at this point i recognized how a gc allows you to not have to particularly care about ownership. an interesting aspect of the gc i hadn't really thought much about. The way I think about it now is that managing data lifetimes is something that's essential to all programming, but that there are two sorts of lifetime management: dynamic lifetime management and static lifetime management. Garbage collectors (including refcounting schemes like `Rc`) are an example of the former, whereas owned types are an example of the latter.
In general, you'll want to use `Box` for an AST. `Rc` only makes sense if you have multiple "owners" of a reference, and expression trees usually don't have that problem. I'll take a look through and see if there's anything to comment on. In the meantime, have you run clippy on it? That tends to take care of any low-hanging fruit.
It seems that there is an obvious interest in having good GUI libs on Rust, but I think different people have different things in mind, and that complicates it even more. My personal interest is in a low level, multi platform, library based mainly (only?) on the GPU. And I've been slowly working on it for a time now. For now, the best place I've found to discuss this things is the draw2d/rfcs repo from Nical: https://github.com/draw2d/rfcs and you can see a description and some tests of what I'm trying to do here: https://github.com/draw2d/rfcs/issues/1#issuecomment-431784347 I've been puting less effort on it than I would like, and this is hard stuff with details waiting to bite you in every corner, but I hope it can lead to something great. Finally, I'm all for a common place to discuss the different appoaches, but I prefer to focus on having a nice low level core we can test (as this is already really hard) instead of discussing high level details. And unless something better is created, I encourage you to join the discussion on Nical's repo.
I think Nical would be a good person to lead the forum/working group I'm thinking of, but it's a big ask to take on a leadership position in something that is essentially a hobby. Also I think his interest is high-performance 2D graphics for games.
If every small question gets its own post, the interesting news get lost in the noise. If you think your question doesn't fit in this thread, feel free to make your own post.
I consider `from_iter` more readable than `collect` in many situations. I even suggested [adding it to the prelude](https://internals.rust-lang.org/t/pre-rfc-add-fromiterator-to-the-prelude/4324) and got generally positive feedback. I was hoping for [default type param fallback](https://github.com/rust-lang/rust/issues/27336) to stabilize first though, so I havenâ€™t followed up on that yet.
I have some code that would ideally look like this let mut iter = some_iter(); if let Some(start_time) = start_time { iter = iter.skip_while(|x| x.0 &lt; start_time); } if let Some(end_time) = end_time { iter = iter.take_until(|x| x.0 &gt;= end_time); } if let Some(photon_count) = photon_count { iter = iter.take(photon_count); } // Most likely more options here. f(iter); fn f(photons: impl Iterator&lt;Item=(u64, bool)&gt;) { // Very expensive computation } I'd like to monomorphize `f` on each type of iter that might get passed to it. Is there a way to do this without manually building an exponential sized tree of if statements (automatic construction of an exponential tree is expected even). Sidenote: start_time is possibly a bad example of an option, since I can reimplement skip while in a way that doesn't change the type and probably has less overhead for the expensive function.
 for entry in walker { let entry_path = entry?; let entry_path: path::PathBuf = entry_path.into_path(); if opt.dirs &amp;&amp; entry_path.is_dir() { naming_function(&amp;entry_path.as_path())?; } else if opt.files &amp;&amp; entry_path.is_file() { naming_function(&amp;entry_path.as_path())?; } else { continue; } } This code gives me this error: error[E0597]: `entry_path` does not live long enough --&gt; src\lib.rs:66:30 | 66 | naming_function(&amp;entry_path.as_path())?; | --------------- ^^^^^^^^^^ borrowed value does not live long enough | | | borrow used here, in later iteration of loop ... 72 | } | - `entry_path` dropped here while still borrowed I don't understand why it is that the borrow needs to continue to the next iteration of the loop. I'm redefining entry\_path on each iteration. That combined with all the path types is confusing me. Can anyone help with this?
With ASTs, you can rely on `enum`s a lot. EG: ```rust enum Expression { FunctionCall{ fn_name: Ident, args: Vec&lt;Expression&gt; }, ... } enum Item { FunctionDeclaration(...), ClassDeclaration(...) } ```
Yeah I guess GFX-RS can be quite low level. It is somewhat abstracted, but still quite vulcan-ic. I'm sure abstraction libraries exist somewhere, or rather, I guess that's what Azul would do if it was using GFX-RS, it would be the abstraction there. GUI wise anyways, in a game engine sense I guess Amethyst is your go-to there for the moment, which looks quite promising! An editor for Amethyst built in Azul would be hella cool, if Azul was even close to prod. ready.
My impression is that WebRender has the right ideas, but it is not a good base for a rust GUI. It's goals are very different, and future evolution will follow what's needed for the web, not a GUI library. At the same time, they have done a really good work showing how to structure a rendering library around the GPU and nailing all the hard details, and this knowledge should be reused for the things that are applicable in a GUI library. I agree with gfx-rs, and I bet on a new development based on WebRender and Pathfinder ideas that uses gfx-hal to make it multiplatform. That being said, I've been working on this for some time (see my other comment) and working with gfx-hal is not easy and even if it helps a lot with portability across platforms you still need backend specific things (and to be really careful to only do things supported on all your targets).