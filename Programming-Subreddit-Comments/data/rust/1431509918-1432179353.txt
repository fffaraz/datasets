Not sensible? Let's say I come here to learn about rust, and I see someone's epic 'edgy' reddit username uses a racial slur that offends me. Am I 'not sensible' for clicking away, and leaving a community that has people like this? Your presumption that just because someone can be offended that they won't take criticism well is unfounded. If you insult me, I will be offended. If you tell me my code needs work, I'll take it as criticism. This is typical. In fact, this is literally the absolute norm - people get insulted when you insult them, and people respond well to constructive criticism. There is absolutely no reason to believe there's a correlation between being offended by something offensive, and not being able to take criticism.
I love to see how riled up people get when they're told they can't be outright offensive to people. Glad to see that the /r/rust community takes this stuff seriously. I can't tell you how many people I know who have felt turned away from CS in general due to what so many would consider 'non issues'.
Interestingly, in [another post](http://www.viva64.com/en/b/0320/) they mention how their business model targets customers with large software projects, where "[any] change in the code can cause unexpected side effects no one can foresee."
Also notice that the text selection is a glowing a bit.
`npm` is actually a seperate package since just some days. So I would gladly see a seperate official `cargo` package appear in the repo.
Nice catch!
Don't you dare play that melody
Probably I'm one of those people, who think of C++ as a terrible language despite only having used it in college/hobby projects. Got hooked on C++11 for a while though before I learned about Rust. That being said, does your view of C++ (or any language) really change that much, once you use it in production? That is, assuming you've done more with it than a beginner's course. I can imagine that you'll learn how to work around its limitations and thereby adapt to it. Certainly the criticism does not magically cease to be valid, once you've learned to cope with it, does it?
Oh, had not noticed that.
Seems like a no-brainer: cargo is a separate piece of software that could be updated more often than rustc.
This was a really helpful writeup! One small suggestion: My rust understanding is still very shallow so I don't know it's as important for this kind of doc or not or whether I might have misunderstood the issue, but in your #2 bullet "When an object passes out of scope, it is destroyed and is no longer usable" it says explicitly that Drop will always be run. It seems that after the thread::scoped issues, you might want to qualify that a bit to "when/if the memory is reclaimed, Drop is run" or something.
&gt; Sure. The first issue is that it becomes impossible to understand a file on its own terms. You shouldn't have to. The reason you have to for C++ is because it's impossible to get the AST. Leaving out access to the AST, tooling be damned, was something Stallman has been stringent on with GCC for a long time as it would allow you to build tooling around GCC without contributing anything back. He considered it a loophole around the gpl. This is one reason why tooling around C++ is good, but nothing like Java or C#. There is clang now, and other compilers will give the AST, but it's not standard. At least with Rust this is something they can build correctly from the start. Getting access to the internals similar to how Roslyn has opened up C# will be key to getting Rust tooling. Not macros. 
Functions are code. Macros are instructions to the compiler. This is the key difference. 
&gt; And then let go of both these views, the boosting and the fretting. It's just a language. There are many other things in the world worth appreciating the virtues of and struggling with the deficiencies of. Consider gardening, or political activism, or maybe call your family and say hello. You'll bring a healthier voice to the community and enjoy better peace of mind if you can maintain perspective. Everything is pointless from a certain perspective. It's weird to draw a line in the sand and say that everything to the left of that is worth worrying about, everything to the right is not. Some people spend a lot of time with certain things -- certain programming languages, certain people, certain family members, certain political beliefs and institutions -- and then they sometimes in turn care a lot about those things. It's as simple as that. Although others will think that their caring is misplaced. But that's *their* problem.
&gt; We're not perfect; I think we're obligated to admit that. The word "perfect" is used a lot in order to deflect criticism in general. "Well sure, it's not perfect, but nothing is". Perfection can already be accepted as being an ideal rather than an obtainable reality. And yet many people use it as a talking point in order to try to muddy the water and reduce any argument that has to do with quantities down to an uninteresting binary like Perfect/Not Perfect. And then they proclaim, "see? This thing isn't really worse than that other thing, because they are both imperfect, and nothing is perfect, so it's all a wash". Well, maybe not say out loud as much as imply it. Or just the exasperated "Oh sure! It's not perfect!" when they are uncomfortable with talking about the specific things that are bad and just want to silence the other party. tl;dr: the word "perfect" is annoying. In general. EDIT: About the downvote I have to say; I'm sorry, but I'm not perfect.
&gt; the main thread knows `&amp;mut x` was captured into closure Right, but this knowledge is forgotten after spawning a thread, because closure is moved into `transmute` call. (**Edit**: I was wrong, the borrow seems to last for *lexical* scope of `closure` in this case. I thought it would work like in [this case](http://is.gd/IDnII0), which is a race condition. Moreover, it's possible that in the future, when "non lexical borrow scopes" will be implemented (and they probably will), even in your version, the instruction `x = 5;` will be legal). That's the reason why `scoped`'s join guard uses a struct with a field with something like `PhantomData&lt;&amp;'a ()&gt;` – to convince rustc that the borrows last as long as the spawned thread is running. Plus of course there are other memory safety issues, which /u/minno explains.
You need to change it to `&amp;*arg`. Rust in this case does not understand that it needs to `Deref` the `String` into a `str` (I'm not totally sure why), so you need to explicitly tell Rust that.
Drat—somebody else is already styled as a doc comment. a.author.id-t2_d7udf:before{content:"/// "} **EDIT:** Oh, of course. That's /u/steveklabnik1.
I don't think there's a reason to include two projects in one package. Cargo is cargo, rust is rust. If one needs both, it's a matter of installing both. And what if one day some other manager will pop up? This will change the state of things, it will probably require cargo to leave the rust package, and people will cry.
That did it! Thanks!
This is extremely exciting! I've had to write some build scripts to run `gendef` and `dlltool` to generate MinGW compatible libraries for my current project and then on top of that my automated build system has to download a copy of MinGW-w64 every time it needs to compile the project (using AppVeyor for builds). I'm really looking forward to MSVC being natively supported by rust and hopefully simplifying my workflow on Windows. :)
I'd rather someone create a non-AUR cargo package. It's more 'arch'-ey that way.
Oh, I was thinking they belong together because the current binary installer installs them both (so the rust-beta-bin, etc. installed both rustc and cargo, just copying the files). But you're right, the actual [upstream of the rust package](http://static.rust-lang.org/dist/rustc-1.0.0-beta.4-src.tar.gz) is just the compiler, without Cargo. What's needed is a Cargo package.
:)
`from_utf8` simply performs a type-cast; doesn't require anything else. `from_utf8_lossy` replaces invalid characters in the input, which may require allocation, thus it can't be defined for `str`. 
Why not both?
Thanks - I had not understood that requirement from the docs.
Also by blocking css requests from *.redditmedia.com
&gt; If you want to get out ahead of everyone else, another place you might look for potential issues is the literature on adding associated types (type families, type functions) to Glasgow Haskell Thanks for all the advice so far! Looks like I get to ask around in /r/haskell as well (although the first [couple](https://wiki.haskell.org/GHC/Type_families#An_associated_data_type_example) of [results](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/type-families.html) about associated types in Haskell look pretty in-depth anyway, assuming I've gotten the gist of your meaning about how the concepts relate). In terms of how HKT gets used by the Rust community, I imagine they'd be more useful as 'code-factoring factoring' than as the guarantors of algebraic properties that they are in Haskell. But at the same time, I'm curious as to just how ```Functor```-ish ```&amp;'a _``` and friends could be made. It seems darn close to being a proper functor, except for the higher-order lifetime bound on whatever you pass to ```fmap```. Although, that's kind of like saying that Haskell's ```Set``` is *totally* a functor except for that little ```Eq``` thing.
Also by going to your preferences (link at top right), if you don't mind doing it site wide.
 let car = { Because you introduce a block here, the `let` bindings inside of it will go away at the end of the block. And so, you'll have a dangling pointer. By the way, a `usize` for years doesn't make too much sense: you should probably use a u32 or u64 instead. The kinds of cars you can describe shouldn't change based on architectue.
This doesn't work because `model` is being moved into `Car`, so any references to its `vendor` field will be invalidated because it's changing places in memory. However, if you want to have an easy way to get the `Model.vendor` field from `Car`, you can create a method on it that returns the reference: struct Car { model: Model, year: Year, } impl Car { fn vendor(&amp;self) -&gt; &amp;Vendor { &amp;self.model.vendor } }
It's funny how the article is about 'give up on Rust we have C/C++' without acknowledging we would not have C++ without first having C, or that they are different languages. 
Piston does something like this: See https://crates.io/crates/piston-viewport The package is called `piston-viewport`, but the crate's name is just `viewport`.
I think the point Graydon was trying to make is that a programming language isn't worth hurting people over, no matter how much you care about it. Graydon *created* Rust. He still cares deeply about it. If he can grasp that, so can you.
Does something happen in 3 days? :-)
Also if you are tired you can get some rest.
Who are the four giants of Rust?
The viva guys only translated the article. They didn't write it!
`vendor: &amp;'a Vendor` defines a pointer. That pointer will be invalid if the `Car` is ever moved. As far as I know, every type in Rust needs to be able to be moved, so having a pointer into itself is not allowed.
That's good news for Java developers!
&gt; Hmm, there is something watching over us today, from the screen's top left corner... [Link](https://a.thumbs.redditmedia.com/_MuD7UoVO1UNkn1IVO_tINRp89199HxyA4VZIqGfN90.png) for the lazy
It is not possible. Even if Rust would allow it, you would end up with a constant non-movable struct (to prevent pointer invalidation). If you don’t want to use an accessor method you have to use some kind of managed reference (e.g. `Rc`).
&gt; Fast integer overflow check The Mill CPU with its variety of operands could become really great on that side, each math operation is provided in 4 modes: - modulo arithmetic - saturating arithmetic - overflow trapping arithmetic - double-width result arithmetic See [PDF](http://www.ac.usc.es/arith19/sites/default/files/SSDAP3_ArithmeticOnTheMillArchitecture.pdf) page 8.
I have just a bit of FORTRAN code at work. Also R, python and lots of Java. Some things just work in that granddaddy of a language.
&gt; I'm pretty sure this should be okay, because any references that are inside closure will be alive until after the channel receive happens. I think you're right, but this is heavily dependent on the implementation details of the channel receive. Specifically, if it can panic for any reason before the other thread has actually finished with your values off the main thread, then memory safety will be exposed in any destructors that are subsequently called. I think the best way to for sure protect against this possibility would be to abort, rather than panic, if the `rx.recv()` returns an `Err` (I've heard this referred to as a "stack bomb").
Two things to watch out for: 1. This is heavily dependent on the implementation details of `recv()`. If it can panic for any reason before the first thread is actually done, then destructors can create memory unsafety by accessing data still in use by the other thread. To mitigate this possibility, you might consider aborting instead of panicking if the `recv()` call return `Err` (I've heard this referred to as a "stack bomb"). 2. Be very careful to make sure that no `drop` glue in the inner closure (which will run after the `send()` call returns) can access anything in the first thread. Maybe `FnOnce()` ensures this, but I'm not certain of that.
&gt; Graydon created Rust. He still cares deeply about it. If he can grasp that, so can you. I'm talking about *caring* in general. Not about Rust in particular. I don't care how detached *he* manages to be from his own creation, so to speak. I will choose myself what I will care about, without justifying myself or listening to what arbitrary lines in the sand *others* think are reasonable.
http://is.gd/hcm0xl
I see. I care about people and while I don't want to put too many words in his mouth, I think Graydon does too. Personally, I've found it more satisfying to see programming language work as a way to connect with people than to see people as tools to use for advancing my work. But you're right, it's up to you to decide what to care about. The flip side of that is that other people are entitled to decide who to work with, and while I no longer work on Rust (Graydon doesn't either), some people do prefer to work with people who prioritize concern for the feelings of others. That's something you should be aware of if you want to work on a collaborative project. If you prefer to work alone, it's less of an issue, but then I'm not sure why you would be having conversations on Reddit if that's truly your preference... why waste time talking to other people if you don't want to work with them or listen to them? The thing about building a programming language is that it's not a job for one person. You need to work with a lot of other people to make it work. Rust started out as Graydon's personal project, but it wasn't until Mozilla helped him to build a team to work on the language that it really started to take off. I was lucky enough to be on that team for several years. I can tell you that it wouldn't have gotten so far without a lot of interpersonal work. Part of working with other people is taking time to think about how other people think and feel. Personally, I find that not to be an unpleasant chore, but rather, the primary motivator for me to build and create anything that necessarily involves teamwork. Of course, you might choose differently, but then your work will probably take on a very different shape from that of a production-ready programming language and compiler that is widely adopted.
I've never heard of that book, sorry! No callbacks here. :)
The [Summoning of the Demon](http://www.reddit.com/r/unseen_programming/comments/32ggdo/the_demon_of_time_story/) has started. We better run.
This is the Moon, not Link. *puzzled*
I guess you missed this part (not to rain on your snark-parade): &gt; Perfection can already be accepted as being an ideal rather than an obtainable reality. So non-perfection can be taken as a given without stating it. It's fine to state it, but often it is used as a rhetorical device. Not in this case, that I've seen, but in general.
Or "The right tool for the right job" used to dismiss all sorts of problems, even when they're relevant.
&gt; honest criticism As an aside, I'd encourage you to watch the wording here. This implies that the criticism is dishonest which calls into question the author's motivation. Maybe a better word is "constructive".
&gt; Thanks for all the advice so far! Welcome. &gt; It seems darn close to being a proper functor I think it can't be a functor for a deeper reason. You have an `&amp;'a A`, and given a function `A -&gt; B` (let's gloss over which kind of `Fn` it is for now), want to get an `&amp;'a B`. But that's impossible in general. The only way you can go from `&amp;'a A` to `&amp;'a B` is if the `A` contains a `B` somewhere inside it. You certainly can't do it with an arbitrary `A`-consuming `B`-returning function. (That said plenty of other things could surely be functors - `Box`, `Rc`, `Arc`, `Option`, `Vec`, etc. Just not `&amp;`.)
To be honest, what I can't imagine the most, is few things. For starters, the purpose of explicitly annotating lifetimes. Why can't they be implicit? I mean, it should by impossible by default to allow something to be passed down the stack? Is it so that they're assigned lifetimes of the specific stack frame in which they're created, so to say? E.g. if you call b() from a(), passing something as a parameter, a Blah(passed_ref), will "have the lifetime of a", which couldn't be inferred by default? Also, how do lifetimes go along with heap allocations or static values? Can you put references to static values in a struct with a different lifetime? What is responsible for deallocating the references, with move semantics? How does that play with static or stack-allocated values? Are they incompatible between each other, so to say? And how can one struct have multiple lifetimes, e.g. for keys and values? What is the usefulness or that? Is it just a necessity because you, e.g. can't cast one scope's lifetime to another's? And then, I find it sorta hard to imagine the whole thing actually being particularly convenient to use. Safety guarantees sound cool, yes, but at this point, are they really worth it? Aren't you losing many of the benefits of manual memory management, and introducing incompatibilities between different types of references to the same object? And back to references... are immutable references to mutable objects essentially something that is statically checked to be entirely contained within some scope, and to disappear before the mutable reference/object is used again? Does this really not run into some weird edge cases? And why are values themselves move-by-default as well? For another thing, errors encoded in return types. Doesn't this end up needing all functions to be FP-style lifted? E.g. monads? For example, you can't really do `works_on_str(returns_result_str())`, can you? Idk... I just find myself feeling skeptical. I worked relatively little with non-gced languages, and while C++'s model is relatively simple, if not particularly safe, I find Rust's just confusing. It's more that I just can't form a working model of the whole thing in my head, than that there's anything specific about it that I don't get. Sorry for the spam x.x
I agree! I've recently been trying to set up AppVeyor integration for a lot of the rust-lang and my own personal crates, and I ended up hitting this wall quite quickly, and I figured it was about time we got MSVC support :)
I see. Thanks.
#BOOK#
You may file an issue against the docs. There are lots of places that need improvement, and steveklabnik can only do so much.
Didn't realize the posts were so old. Honestly, I don't agree with anything in your post, but neither of us cares that much to discuss it.
+1, as someone who consider switching from ubuntu to archlinux
This looks great. I work with contingency tables a lot and this work is slated to simplify my code considerably.
Cache: http://web.archive.org/web/20150513190529/http://blogs.s-osg.org/servo-the-embeddable-browser-engine/
&gt; For the matrix case, why not make [[T]] work? How is `[[T]]` supposed to work? - Is `&amp;[[T]]` equivalent as `((*const T, usize), usize)`? That would work for contiguous matrices, but the submatrices that you get from slicing are in most cases not contiguous and require an extra "stride" integer field. - How do you construct a `&amp;[[T]]`/`Box&lt;[[T]]&gt;`?
&gt; ad-hoc custom unsized layout I see this the other way, as a more general form of unsized types, as you can recreate `[T]`, `str`, `Trait`as normal types, whereas now those three are special cases in the compiler.
Also down, it seems.
This looks very promising! I'm excited about the nicer matrix types and reducing the special cases in the compiler.
&gt; reducing the special cases in the compiler I'll admit that removing them would likely be more trouble than it's worth, and may be a backward incompatible change because of namespace issues. (see [rust-lang/rust#19612](https://github.com/rust-lang/rust/pull/19612), which was a change of the same magnitude, which ultimately didn't get merged)
Unlike your package, the [multirust](https://aur.archlinux.org/packages/multirust/) Arch package doesn't "provide" cargo (through package metadata), as such packages like [racer-git](https://aur.archlinux.org/packages/racer-git/) fail to install.
&gt; Do you have any idea how to handle arbitrary indexing? I'm not sure what you mean by "arbitrary indexing". If you mean overloading `Index` on a generic N-dimensional array without incurring in a large number of manual `impl`s, then I haven't given it much thought.
Yes, and from `[[T; N]; M]`, `[[T]]` being its existential form. There is a potential extension to DST, allowing unsized types to be constructed directly in an in-place context (`&amp;expr` and `box expr`). With the right implementation, `Vec&lt;[T]&gt;` would also be usable.
Yeah. In particular, Emscripten delegates memory management to the "native" code, which means you won't see any JS garbage collector overhead on your Rust objects. asm.js also enables predictable start times, because a browser can compile the whole module on load, rather than discovering hot spots and compiling traces on the fly. This benefit is exclusive to asm.js-aware engines, however with [Microsoft Edge adding asm.js support](https://blogs.windows.com/msedgedev/2015/05/07/bringing-asm-js-to-chakra-microsoft-edge/), it's not a Mozilla-only technology. As I understand it, the biggest limitation of Emscripten today is that there's no support for conventional shared-memory threads, due to the unavoidably single-threaded nature of a browser's JS/content/"main" thread. But there is hope for threads based on message-passing, which you could compile as [web workers](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers). Because Rust heavily favors message passing over shared mutable state, it's possible that many multi-threaded Rust programs could be ported to the Web platform with minimal changes. In the future, workers may have access to [WebGL](https://blog.mozilla.org/research/2014/07/22/webgl-in-web-workers-today-and-faster-than-expected/) and the ability to animate certain CSS properties. Then apps based on the web platform can include sophisticated, multi-threaded, quasi-realtime, GPU-accelerated rendering and animations, implemented in Rust. Pretty excessive for an ordinary web page, but Mozilla is betting heavily that the same Web platform can sustain an ecosystem for sophisticated mobile apps/games.
It's worth mentioning that in reality, females are rare in the programming scene. The OP might actually not have had any debates with women, so why do you assume he did, and take his stance as ignorant or even offensive? Even if he did, then, depending on social background and context, it is absolutely subjective to exclude a social group from otherwise-general vocabulary such as OP's "chaps". The OP may very well have meant men and women alike, and used "chaps" without ill will, probably because he doesn't have to deal with these controversies on a daily basis which for my social background is *taking the whole PC thing too far*. It is a fact that in literature and history, male pronouns are often used as a generalisation for both male and female without distinction. Only recently has this become a very controversial topic, which - again depending on social background - can be seen as either nitpicking or absolutely necessary. That is all.
I'd never suggest that intense caring about a topic is misplaced. I only suggest that a sense of perspective concerning the topic's place in the world at large leads to a more healthy engagement with the topic, the community of other people engaged with it, the rest of the world, and beyond all that: with yourself. If your caring runs away with your sense of perspective, you'll be prone to extremes of high and low due to the vicissitudes of chance acting on the object of your concern. This will both cloud your thinking, damage your health and well-being, undermine your ability to apply yourself to what you care about, and very literally consume you as a person. Speaking from hard won experience here. Not trying to boss you around or shame you for having passions. Just keep them in perspective. Look up from time to time. Balance yourself a bit. It'll help.
Bear with me, I'm still pretty inexperienced with Rust. // `m: &amp;'array Mat&lt;i32&gt;` &gt; m = Mat::reshape(&amp;array, (3, 5)) I'm not sure I understand why you would make this a reference instead of by value and moving the array into m. Then maybe have an as_vec() method if you want to linearly index into a slice of the matrix, which you shouldn't need to do often.
Offscreen rendering support with Servo would be really nice for game UIs.
&gt; from [[T; N]; M], [[T]] being its existential form. Going from &amp;[[T; N]; M] to &amp;[[T]] via coercions would be nice. But, I think it's going to be more common to go from &amp;[T] + usize to &amp;[[T]], and I hope I won't need to call `mem::transmute::&lt;_, &amp;[[T]]&gt;(((slice.as_ptr(), ncols), self.len() / ncols))` and cross my fingers. &gt; With the right implementation, Vec&lt;[T]&gt; would also be usable. Personally, I find hard to grasp the memory layout of structures that involve nested unsized types like `&amp;(usize, [(T, [T])])`, but I have yet to sit down and play with the feature. On the other hand, I find `unsized struct`s easy to understand, because the memory layout matches the fields of the struct.
It's not just the fault of macros though - a lot of it comes from the complexities of the C++ syntax and semantics as well. I am sure the tarpit that is the template system does not help either. The amount of bugs filed in CLion (and still existing post 1.0) relating to non-obvious syntax issues just highlights the problem. There are similiar problems with Scala though - JetBrains had to write their own front-end to have a decent plugin. This is where Rust being a reasonably simple language syntactically is going to help (of course a standardised AST layout would be even better, as would a formal specification of the grammar).
Isn't the plan for libsyntax to be stabilized at some point? I mean as long as there is one front-end that is re-usable and the macro system is basically just a series of term rewrite rules, then *in theory* it shouldn't be too difficult to have nice IDE support, with refactoring.
Nice! It's much clearer now, with the "Run" button, and it feels more official. Also, the Tomorrow Night 80s theme is currently my favorite, so seeing it in the settings made me happy.
Possible, yes. Pragmatic or sensible, I don't think so. use std::cell::Cell; struct Car&lt;'a&gt; { vendor: Cell&lt;Option&lt;&amp;'a Vendor&gt;&gt;, model: Model, year: Year, } fn main() { let car = { let vendor = Vendor::BMW; let model = { vendor: vendor, model: "316".to_string(), }; Car { vendor: Cell::new(None), model: model, year: 1996, } }; car.vendor.set(Some(&amp;car.model.vendor)); } To access the reference, you have to call `car.vendor.get().unwrap()` every time. However, if you try to move `car` to another scope, you will get the same lifetime error. This is, again, because `car.model.vendor` is moving with it, physically changing places in memory, and references to it will be invalidated. If you want to get a `&amp;Vendor` from `Car`, I highly recommend creating an accessor method like I suggested originally. Don't worry about the cost of the function call; it can be inlined by the optimizer. The semantics will be almost the same but it places no lifetime or move restrictions on `Car`.
Hmm, I never noticed that since there's really only a few Rust binaries I build from source ([clog](https://github.com/thoughtram/clog), [racer](https://github.com/phildawes/racer), [exa](https://github.com/ogham/exa), and [icepick](https://github.com/felipesere/icepick))...and I guess I've just always been used to manually `git clone`ing + `cargo build --release`ing them, which is usually just a 3 step process (if you include copying the binary to `$PATH` :P) This is something the maintainer of [multirust](https://aur.archlinux.org/packages/multirust/) could address by adding a "default" download of stable during the install script?
Oh my god, I have been wanting user-defined unsigned types so much. You are my hero if this lands.
I really wanted that change to go through, too... sad that it didn't, especially since at least one of the concerned raised (requires extension traits) wouldn't be one anymore.
I fixed by editing the PKGBUILD and adding cargo under the provides array (it's currently `provides=('rust' 'rust-git')`).
~~As someone who *doesn't* care very much about design, I'm actually not a huge fan of this change. For actually editing code, it's not very nice because the top bar takes up half the screen. If there were an option to hide it I would be pretty happy.~~ ***Edit*** Still had a cached version, never mind :) Looks great.
&gt; which calls into question the author's motivation. While I didn't originally intend that, it has become apparent that the organization who provided the translation likely has a strong bias towards C++, as they create C++ static analysis software, which is basically what `rustc` does except it has a price tag on it. Thus, this article could be seen as dishonest in that it might intentionally paint Rust in a poor light in order to make it seem like less of a competitor, and thus, protect their bottom line. While I realize that this organization isn't the original author of the article, I don't read Russian, so I have no way of knowing if their translation is completely faithful or embellished for their purposes. And I have no information about the author so I don't know what their personal biases are, though it sounds still heavily sympathetic towards C++. C++ is a great language (when used properly), it has a very strong heritage and it will probably have a large presence in my future career. However, I do think Rust has a chance of supplanting it in many applications, and, to me at least, it feels very much like the author is threatened by this. Thus, I cannot take their criticism at face value.
&gt; My point is that there is a good chance OP has only talked to "chaps" (as in, male human beings) so why would he be gender-neutral in his comment? Male-centric and sexist language is deeply ingrained in the English language, and a fair chunk of the programming community is male, so yes, it probably did not occur to him that his comment excluded women (thus favored men over women, thus was—albeit unintentionally—sexist). But that is exactly *why* we need to make it clear that language like that does exclude others, and that it *is* a problem. By doing so, people learn to consider whether what they say excludes others, and the community becomes more inclusive, which is a good thing.
Great! Is it possible not to use the external url shortener when sharing the code? I prefer to use `https://play.rust-lang.org/xxxxxx` like `http://play.golang.org/p/xxxxxx` at [Go Playground](http://play.golang.org/)
Yeah, I'd have to say that the potential maintainability on large codebases is the biggest appeal Rust has for me. Lifetimes and traits make contracts on functions visible through their headers and adds static checking, so you don't have to spend as long reading through code before figuring out how to safely modify it.
I think Piston has provided an illuminating exploration of ways to structure Rust code in complex systems, and many of the libraries developed by the Rust gamedev community have been invaluable for Servo. Thanks to all the game developers pushing on Rust!
archlinuxcn's repository provides both cargo-git and rust-git
Awesome! Can crates.io be next? I'm really not a fan of that shade of green :p
I rather use multirust. It handles multiple versions of rust. It's so easy that caveman can do it. I personally think multirust should be default on arch. Dully noted, it also installs cargo.
Nah, it should be crate colored. [/crateshed (warehouse?)]
I like the control Rust gives not just over the code, but for planning into the future. It is delightful to be able of using it in a predictable way that makes it possible to work on that level, knowing that the code will run and just work. It almost never crashes, and when it does there is an above 50% chance it is caused by unsafe code. I would like to describe it as a "notorious effective tool for large projects" because the same reason it has a higher barrier makes it a rock solid language. Which means I can spend most of my time away from the computer and solve the problems in my head, and when I come back people have fixed and self merged stuff without much need to review.
Are you opposed to media queries? It would really help small viewports. Otherwise, wrapping #editor and #viewport within a positioned element would let them be pushed down by the floated elements on the header (which would also need to be positioned). This would force scrollbars on smaller viewports but at least the buttons wouldn't crumble up.
It does not look similar. Pulse is designed as one of the building blocks that could be used to build up something like STM. The goal of the library is not provide the queues or other thread safe primitives itself. Just give a tool so that others can build them.
([`cargo --release` is 3](https://github.com/rust-lang/cargo/blob/0d75eb6c8a41329181064618fc2ddeea80bdd380/src/cargo/core/manifest.rs#L434).)
No, I’m not opposed to media queries, but such design has to be done carefully. I also fear that adding links carelessly will damage the feel of the thing. In [my latest changes](https://github.com/rust-lang/rust-playpen/pull/93) I’ve switched to using flexbox where it is available, which handles tiny viewports better (avoiding collisions), and I’ve also tweaked the viewport configuration for mobile browsers so they will handle it better.
Melbourne’s proper meetup, scheduled for Monday, was cancelled due to venue unavailability, so the link you have there is dead. There may, however, be a meet &amp; greet on Friday evening: http://www.meetup.com/Rust-Melbourne/events/222404787/.
Updated!
Ping!
Is unsized an existing keyword? Perhaps we should use !Sized instead?
Yeah, I like this idea. I'll try it and see what happens.
I've been in contact with a few companies, and it seems no one wants to stay at work after hours on a Friday night :) Will have to reschedule for next Thursday. I am determined to give out these awesome shirts and stickers (thanks /u/brson!)!
*cough*/r/playrust*cough*
Is there one in Chennai?
Wrong subreddit mate - you're after /r/playrust.
This is not a sub about this game.
Also note that you can `for ch in self.chars.iter()`, too.
I haven’t observed that in my testing at all, but I have definitely had some issues with Chrome that I’ve had a little trouble dealing with. Its flexbox implementation is rather poor and buggy. (This is really pretty typical—Firefox and IE tend to do a good job of what they implement, Blink/WebKit tend do do more faster but tattily. I have wondered before with melancholy whether that’s why developers are often using Chrome—if it works there, it’ll almost certainly work in Firefox and IE. I develop in Firefox, and IE is rarely any trouble, but Chrome normally has at least one substantial problem.)
Haha, Chrome's new IE. /joke I'll try to find a fix for it. Be prepared for a PR!
That's a great point! Thank you.
Ok, me &amp; kralyk &amp; one more guy will be for sure tomorrow at La Casata restaurant at 12:00. There are at least 5 seats reserved. Anyone is welcome to join us. Coordinates are below. http://www.lacasata.cz/
I like the suggestion, and it’s part of https://github.com/rust-lang/rust-playpen/pull/94.
I don’t recall doing anything that should have changed the *functionality* on an iPad; I have optimised it so that it’ll be a bit nicer on mobile devices than it was before, but if it truly didn’t work before and does now I’m surprised. I do know that Ace causes some issues on mobile browsers.
Sorry, no. (Not that I know of anyway) There aren't many experienced Rust users in India that I know of; we're stretched a bit thin even to get one speaker each for the Bangalore/Pune meetups ;P
Exactly. It already gets nasty if you would limit it to 3D arrays which would require 84 'Index` implementations (using usize, RangeFrom, Range and RangeTo as possible indices)
(on the other hand the attendee response seems to be phenomenal -- people are really interested in Rust, but there's nobody around to help them :P )
So is "* In theory. Rust is a work-in-progress and may do anything it likes up to and including eating your laundry." going to be removed from the homepage?
btw, eventbrite link for Bangalore: http://www.eventbrite.com/e/rust-10-release-party-tickets-16908882924
I honestly wasn't even aware that we allowed options to be specified after the file name. :P What are you using Rust for, if I may ask?
I've had a look at `linalg.rs`, very nice work! I recently tried to implement a simple linear algebra library in safe Rust, just to see how painful it would be. I implemented a mutable matrix view and and LU decomposition, using lots of recursive `split_at_mut`. About the interface of matrix inversion in `linalg.rs`: I actually like eigen's interface a lot, you write `matrix.lu().solve(rhs)` instead of `matrix.solve(rhs)`. This has two advantages: 1. You can reuse the decomposition to solve for several `rhs`, or to calculate the inverse, or to calculate the determinant. 2. You can easily choose a different decomposition (e.g. `qr()`).
They didn't get very far. I was reading a lot of mixml papers around then and also some of the material in napier88, and ... some other language that experimented in this space. Basically it came down to my wanting to support hot code loading and dynamic compilation, which means having a lot more type information around at runtime and a lot more indirection in type based calculations. The mechanisms shrunk over time, first to static modules and dynamic objects, then to static (vtable) objects, then to static monomorphization as optimization, then as primary abstraction. Sometimes people use rust now without ever encountering an indirect call! How times change...
While it is possible to build without cargo, it isn't practical. Two of the projects you listed, both servo and cargo itself, use cargo for building. While servo does wrap cargo in mozilla's mach build system, it does issue build commands to cargo rather than rustc. AFAIK, rustc doesn't use it because of the staging required for building the language itself, and the preference to keep rustc and cargo more separated. That is a special case for the language itself though, not the norm.
Have you tried `impl&lt;T&gt; PartialEq for T where T: LiquidContainer`?
I believe you meant unsized?
Oh, turns out that `#[lang="str"] pub struct str([u8])` was an rfc that didn't merge. (In that rfc I think `ty_str` was still a thing, but it could be redefined, much like how `ty_uniq` behaves now)
Yes, because laundry eating has evolved to be a specific design goal now; and the initial portions of the planned laundry eating API have been landed behind the `#![feature(no_laundry)]` gate. `no_laundry` should become stable in 6-8 weeks, though the more complicated portions, including DRY cleaning, Higher Kinded T-shirts, Opt-in Builtin Detergent, and Rinse Time Optimization will not be stabilized until much later. We hope this benefits the Laundry as a Service community immensely.
Looks like this issue: https://github.com/rust-lang/rust/issues/18807
I highly suspect this bug is related to: https://github.com/rust-lang/rust/issues/25369 https://github.com/rust-lang/rust/issues/18807 They're both happening on Windows, trying to create a dynamic library, and being affected by the use of `println!()` in the former case.
I really want `ty_uniq` to die already, because a bunch of places where it's special cased, a `ty_struct` would be handled correctly, and the rest can keep being special-cased for now by checking its `DefId`.
It is already a problem in normals struct impls…I mediated it by using free functions I pass every field separately. Clearly not an optimal solution…
Can we have autoindent yet? That's the most annoying thing about using it at the moment.
This is awesome! Does anyone know who will be around for the meet up in Bangalore? Are any rust core team members going to be there? Thanks all!
That's a decent solution, but redirects are generally pretty slow. It'd be nicer if the playpen provided this service itself, I think. It's a trivial addition.
&gt; It's a trivial addition. Is it? Off the top of my head I can see several hairy issues. The top of issue is of course *state*. Today, the playpen is stateless. Stateful always introduces a lot of complications: - availability: switching from one machine to another is easy when stateless, not so when stateful - scaling up: sharing state is hard - cost: gotta store the related code somewhere - cost (2): any change to the storage format requires some migration process, adding development cost And then, of course, there is the issue of spam/DOS. Today, anyone can scribble something in the playpen, hit share, and push off the URL to anyone else. And the playpen does not care. It's up to `is.gd` to properly protect themselves from attackers. Now, if the playpen suddenly wants to store code/urls themselves, then they have to worry about those potential issues. Even if it uses a library, it will still need some monitoring to make sure there is space available still and a way of managing user reports of unsavory/illegal content being shared (imagine a list of torrents to copyrighted material?). Oh, and on the subject of attacks. Today the playpen can run entirely in a VM or on a hardened host, and can regularly be tossed out and restored from scratch, which prevents any hacker from getting a hold on the machine. Actually, it would probably be a good idea to schedule this at random (short) time intervals, even without having detected anything. However, if you store stuff, then you need a permanent storage, and that storage machine cannot easily be cleaned out/restored without also losing the materials stored. Maybe I am paranoid, but to me it sounds *far* from trivial. And to be honest, quite a lot of efforts for a volunteer's project.
Thanks for the explanation!
It doesn't for new blocks. I'd expect it to automatically indent after {s and undent after }s
I consider the primary purpose of the playground to be normal users—a fact which the redesign emphasises in my opinion; allowing one to set custom rustc command line arguments would be a nice thing to have in the future; *that* is the sort of place where such distinctions are valuable. Emphasising the debug/release divide is a good thing and will help in education.
Any such matters belong upstream in Ace; I haven’t touched it yet and have no immediate plans to.
You're my hero!
If that is the case then why give users so many options at all? Remove the ASM and LLVM IR options, and always compile as Release with overflow checks enabled. Emphasising the debug/release divide seems pointless to me because you can't really measure performance on the playpen; either something finishes before the timeout, or it doesn't.
You could simply use Rake for it: file 'func.so' =&gt; ['func.rs'] do sh "rustc func.rs --crate-type=dylib" end rake :run =&gt; 'func.so' do load 'script.rb' end
Reading my twitter not strictly advised ;) https://twitter.com/rustlang/status/598580514044317696
There isn't a lot of material out there on error handling in Rust, so this is my attempt to start to remedy that. I see a lot of questions from Rust beginners that suggest they struggle with figuring out how best to handle errors. With the temptation to just use `unwrap` everywhere, it's important to get good educational materials out there.
I really really want a Higher Kinded T-Shirt. Who wants to design it?
This is wonderful. Thank you so much! EDIT: reading, we don't actually have a unit type anymore, though, it's just a zero-sized tuple. There's some debate over if we should still pretend like it's a type. EDIT 2: oh, and I should say, if you have a desire to move this upstream, i'd love contributions. as you note, the handling chapter is a bit anemic at the moment.
Zero-element tuples are called "unit" for short, just like two-element tuples are "pairs". Seems reasonable to me.
&gt; implement an alternative string library on crates.io that coexists with std. Except that string literals would still be glued to the builtin `str`, so it wouldn't be as ergonomic. I recall seeing an RFC related to literals that may help with this though.
Haha, whoops. Yes, I did, thanks :)
A bit over a week. This is why I don't write many blog posts. They take so darn long!
&gt; Forgot to mention that target is 1.0 no beta stuff First off this is a great and awesome idea. I believe the majority of the resources on rust-learning are either out of date or working progress. E.g. rosettacode (doesn't compile), Rust for C++ Programmers (discusses Gc), Rust Guidelines (WIP), rustbyexample (not up-to-date), etc. I haven't had time to go through everything but a cursory look gives me that impression. also you may want to add this recent [blog post](http://blog.burntsushi.net/rust-error-handling/) about error handling. And again great idea. :)
&lt;3 i know that exhasusted feel. let's talk about it next week?
Oh my. Yes! When I sat down to write this, I had no intention of making it this long. But as I started writing (firmly putting myself into the perspective of "little to no experience with expressive type systems"---well, attempted to anyway), I realized that I had internalized *a lot of stuff* that probably should be explained. And it just... grows. If I had a few more weeks, I might be able to make it shorter. There's definitely lots of rough edges. Some of the section transitions are a bit jarring.
Yes!
In addition, I'll note that the module system comes off as being weird to many people, so struggling with it is a bit natural.
&gt; Does a file always define it's own module. Yes, a new file is always its own module. That doesn't mean each module has its own file, though. &gt; e.g. if I have src/view/text_label.rs does that mean no matter what my_library::view::text_label is defined? Yes. &gt; Say that within the text_label.rs file it defines a TextLabel struct. Should I as a library developer force the users of my library to access the struct as: This is entirely up to you. See the next answer. &gt; Or is there a better way? So, there's the internal verison and the external one. You should set up your own module system to facilitate how you want things to be laid out, and then, determine what you want the public interface to be, and then export that. In many libraries, the main `lib.rs` is largely re-exporting what the public interface is.
This thread has been linked to from another place on reddit. - [/r/austin] [Rust 1.0 Launch for Austin, TX USA? : rust](https://np.reddit.com/r/Austin/comments/35ylet/rust_10_launch_for_austin_tx_usa_rust/) [](#footer)*^(If you follow any of the above links, respect the rules of reddit and don't vote.) ^\([Info](/r/TotesMessenger/wiki/) ^/ ^[Contact](/message/compose/?to=\/r\/TotesMessenger))* [](#bot)
I would hang out. Let me know if you need any help!
A `&amp;String` can only ever refer to the *entire* contents; a `&amp;str` can refer to a subset of a string, since it's a slice of data *irrespective of how that data is managed*. You can't use `str` for an owned string because it is a dynamically sized type: there's no way for the compiler to know how much stack space to allocate for a variable of type `str`, for example. So `String` is used to allocate and manage a chunk of data; said data can be borrowed as `&amp;str`, but so can other things (you can borrow a `Vec&lt;u8&gt;` as a `&amp;str` under some conditions, for example).
I haven't yet read this properly, but this looks awesome! Also, I wonder if I could rig up a jekyll plugin that automatically generates a crate full of code examples. Should be fun!
Thanks! &gt; Also, I wonder if I could rig up a jekyll plugin that automatically generates a crate full of code examples. Should be fun! Been there, [done that](https://github.com/BurntSushi/blog/blob/master/scripts/rust-from-blog). :P Of course, it's just a hack, but it works OK. I should investigate literate programming tools more thoroughly...
So good. I posted a [PR to rust-learning](https://github.com/ctjhoa/rust-learning/pull/7) to add it.
https connection to https://play.rust-lang.org/ fails: &gt; Secure Connection Failed &gt; The connection to the server was reset while the page was loading. &gt; The page you are trying to view cannot be shown because the authenticity of the received data could not be verified. &gt; Please contact the website owners to inform them of this problem.
I don't really understand what the difference is? A zero-element tuple is a distinct type, after all. EDIT: I looked it up, it seems that the only thing that changed is the compiler implementation. Nothing changed in the behaviour of () and it's still a distinct type like before. No reason to stop calling it Unit just because somebody did some internal compiler refactoring.
I would be down, but I know nothing about rust. I've heard some good things though. Btw, I'm a student at UT
I wrote a comment on HN, reposting here: I am utterly thankful for new experience reports on Rust, especially for ones this well-written. Generally speaking, inaccuracies in such things are our fault, not the writers', due to a lack of documentation and or good examples. With that being said, a few notes: &gt; It runs about five times slower than the equivalent program I'd be interested in hearing more about how these were benchmarked. On my machine, they both run in roughly the same time, with a degree of variance that makes them roughly equivalent. Some runs, the iterator version is faster. It's common to forget to turn on optimizations, which _seriously_ impact Rust's runtimes, LLVM can do wonders here. Generally speaking, if iterators are slower than a loop, that's a bug. &gt; Rust does not have tail-call optimization, or any facilities for marking functions as pure, so the compiler can’t do the sort of functional optimization that Haskell programmers have come to expect out of Scotland. LLVM will sometimes turn on TCO, but messing with stack frames in a systems language is generally a no-no. We've reserved the 'become' keyword for the purpose of explicitly opting into TCO in the future, but we haven't been able to implement it because historically, LLVM had issues on some platforms. In the time since, it's gotten better, and the feature really just needs design to work. Purity isn't as big of a deal in Rust as it is in other languages. We used to have it, but it wasn't very useful. &gt; But assignment in Rust is not a totally trivial topic. Move semantics can be strange from a not-systems background, but they're surprisingly important. We used to differ here, we required two operators for move vs copy, but that wasn't very good, and we used to infer Copy, but that ended up with surprising errors at a distance. Opting into copy semantics ends up the best option. &gt; how that could ever be more useful than returning the newly-assigned rvalue. Returning the rvalue ends up in a universe of tricky errors; not returning the rvalue here ends up being nicer. Furthermore, given something like "let (x, y) = (1, 2)", what is that new rvalue? it's not as clear. &gt; I’ve always thought it should be up to the caller to say which functions they’d like inlined, This is, in fact, the default. You can use the attributes to inform the optimizer of your wishes, if you want more control. &gt; It’s a perfectly valid code, In this case it is, but generally speaking, aliasing &amp;muts leads to problems like iterator invalidation, even in a single-threaded context. &gt; but the online documentation only lists the specific types at their five-layers-deep locations. We have a bug open for this. Turns out, relevant search results is a Hard Problem, in a sense, but also the kind of papercut you can clean up after the language has stable semantics. Lots of work to do in this area, of course. &gt; Rust won’t read C header files, so you have to manually declare each function you want The bindgen tool can help here. &gt; My initial belief was that a function that does something unsafe must, itself, be unsafe This is true for unsafe functions, but not unsafe blocks. If unsafe were truly infectious in this way, all Rust code would be unsafe, and so it wouldn't be a useful feature. Unsafe blocks are intended to be safe to use, you're just verifying the invariants manually, rather than letting the compiler do it. &gt; but until a few days ago, Cargo didn’t understand linker flags, This is not actually true, see http://doc.crates.io/build-script.html for more. &gt; the designers got rid of it (@T) in the interest of simplifying the language This is sort of true, and sort of not. @T and ~T were removed to simplify the language, we didn't want language-support for these two types. @T's replacement type, Gc&lt;T&gt;, was deemed not actually useful in practice, and so was removed, like all non-useful features should be. In the future, we may still end up with a garbage collected type, but Gc&lt;T&gt; was not it. &gt; Rust’s memory is essentially reference-counted at compile-time, rather than run-time, with a constraint that the refcount cannot exceed 1. This is not strictly true, though it's a pretty decent starting point. You may have either 1 -&gt; N references, OR 1 mutable reference at a given time, strictly speaking, at the language level. Library types which use `unsafe` internally can provide more complex structures that give you more complex options. That's at least my initial thoughts. Once again, these kinds of reports are invaluable to us, as it helps us know how we can help people understand Rust better.
I wasn't involved in the internals at the time, but I'd imagine it's the same as let x = 5; is 5 an i32, or a u64? Inference.
No inference wouldn't help you at all in this case. "Is this a i32 or u64" is a meaningful question. "Is this a () or a ()" is not. I'm very curious about this now, do you perhaps have a link to a relevant PR where this change happened, or a hint of what to search for? EDIT: Found it: https://github.com/rust-lang/rust/pull/18752 EDIT: I think i know what's going on now. The special case for the unit constructor in the compiler was removed and the tuple code was generalized. But since `()` was a literal, and the tuple constructors are expressions there was a slight user-visible change since macros can observe the difference between the two. Outside of macro code, nothing changed. Whether or not the Rust community chooses to use the name Unit for a pronounceable name for `()` is unrelated question. Regardless of that, `()` is exactly the unit type so I see no reason not to call it that. 
There is actually one place where I suspect it would have been inferred (which probably led to this discussion). Namely: closures are always generic over a tuple type, so if there were two different types in the compiler internals they would probably have been selected there. I also wouldn't be surprised if that was the only place, though.
There never was two distinct unit types at the same time, one was replaced with another. See my edit.
I like [conrod](https://crates.io/crates/conrod)'s approach. It reexports most commonly used structs on the crate level (despite having internal structure similar to what you've presented). I don't know if it's idiomatic, but it's nice to use. In my personal opinion, related things should be exported on the same level (as window, text label, button, etc.) and utilities should live in separate modules (like `conrod::color` or `std::sync`). It also doesn't make sense to leave modules with one or two public items unexported – `std::collections` is a good example of such reexporting – each module usually have one main collection struct and a few helper structs (usually iterators).
When looking at the ASM difference of fn main() { let mut sum = 0.0; for i in 0..10000000 { sum += i as f64; } println!(“Sum: {}”, sum); } and fn main() { let mut sum = 0.0; let mut i = 0; while i &lt; 10000000 { sum += i as f64; i += 1; } println!(“Sum: {}”, sum); } at play.rust-lang.org, it seems like the main difference is that the second one gets unrolled 8 times. As they should be equal I wonder if this has something to do with the order of the llvm passes. Maybe rustc should let some passes run first that makes the code look more like llvm ir of C code?
They almost certainly forgot to turn on optimizations. [Heaven forbid we fix this.](https://github.com/rust-lang/rfcs/pull/967)
&gt; Iterators are a great and reusable way to encapsulate your blah-blah-blah-blah-blah, but of course they’re impossible to optimize. The *whole* point of slice iterators is to avoid bound checks and to obtain the **exact** same performance as C++ iterators have in clang by generating similar IR. The C++ iterators perform better than C-style `for` loops, even when you don't have bound checking overhead, otherwise nobody would use them. This has to do with the use of pointer range (start/end pair) instead of a base pointer and an integer range. You don't have to trust me, [check it for yourself](https://play.rust-lang.org/?code=%23%21%5Bcrate_type%3D%22lib%22%5D%0A%0Apub%20fn%20manual%28xs%3A%20%26%5Bi32%5D%29%20-%3E%20i32%20%7B%0A%20%20%20%20let%20mut%20i%20%3D%200%3B%0A%20%20%20%20let%20n%20%3D%20xs.len%28%29%3B%0A%20%20%20%20let%20mut%20sum%20%3D%200%3B%0A%20%20%20%20while%20i%20%3C%20n%20%7B%0A%20%20%20%20%20%20%20%20sum%20%2B%3D%20xs%5Bi%5D%3B%0A%20%20%20%20%20%20%20%20i%20%2B%3D%201%3B%0A%20%20%20%20%7D%0A%20%20%20%20sum%0A%7D%0A%0Apub%20fn%20iter%28xs%3A%20%26%5Bi32%5D%29%20-%3E%20i32%20%7B%0A%20%20%20%20xs.iter%28%29.fold%280%2C%20%7Cs%2C%20%26x%7C%20s%20%2B%20x%29%0A%7D)(select **Release** and press **LLVM IR**). The iterator version (which could use `.sum()` if that was stable) uses vector operations, processing **8** elements at once. LLVM can only do this optimization because it's seeing pointer ranges.
&gt; But why not just use `&amp;String` for references to strings? `&amp;str` is able to: * point to read-only part of your executable (`&amp;'static str`) (it happens every time you write `"string literal"`), * point to middle of other `str` (eg. when diving a string into words), * point to arbitrary part of memory (`str` is just utf8-checked wrapper for `[u8]`), * use only one layer of pointer indirection. `&amp;String` can none of these. Also, `&amp;String` automagically coerces to `&amp;str`, while not losing functionality (except maybe of checking capacity). &gt; or just `str` for an owned string? As others already responded, that's because `str` doesn't have length known at compile time. That's why you can use it only behind a pointer. Such as `&amp;str`. You could use `Box&lt;str&gt;` as owned string type, but: * it is ungrowable, * it is really hard to actually create a value of this type (and it most probably requires `unsafe`)
As much as I appreciate this it's still windows only :(
 pub fn version() -&gt; String { let c_string = unsafe { CStr::from_ptr(xls_getVersion()) }; str::from_utf8(c_string.to_bytes()).unwrap().to_string() } &gt; I found a variant of that code with a big green check next to it on StackOverflow. I understand what it’s doing, but five function calls (from_ptr, from_utf8, to_bytes, unwrap, to_string) just to convert a C string to a Rust string seems like an excessive amount of ceremony, at least for a language that keeps using the word “systems” on its website. It would seem useful to have `str::from_cstr_ptr().unwrap()`. Or maybe a bunch of similar functions in `ffi`.
Totally. I feel very split, myself.
You're right. Perhaps rename the 0 to "debug", the 3 to "release", and let the levels 1 ans 2 as intermediary levels.
It should work in any emulator that supports loading PS executables directly or by putting it in a disc image I suppose but I haven't tried it yet. My current setup was recommended by Ryphecha (mednafen's dev) so I'd be surprised if there wasn't a straightforward way to run those executables in mednafen. The whole point of this project is to write accuracy tests for an emulator. I've started working on the emulator itself but I can barely display the BIOS boot logo so far: https://github.com/simias/psx-rs I don't support loading executables in this emulator yet but I have partial GDB support so I *should* be able to use it to load the image and start the execution, I'll play with that soon. My Playstation is not modded, I use an Xplorer-FX module plugged into the console's parallel port. Originally it's meant to cheat (like a GameShark module) but you can use it to run custom code. It's pretty difficult to setup these days unfortunately, you need a parallel port on your PC and most of the flashing software is windows only and doesn't work well with modern windows versions. I suppose you could also burn it on a CD and run it on a modchipped console but that sounds tedious. I'll write a more complete guide on how to reproduce my setup at some point.
This is awesome. I'm guessing no auto-completion yet?
That was discussed in the linked issue. Or at least, it was in general, I didn't re-read that specific thread.
For sure. This type of stuff is easy to make solutions for in 1.x releases once the use cases are well known.
&gt; Move semantics can be strange from a not-systems background, but they're surprisingly important. We used to differ here, we required two operators for move vs copy, but that wasn't very good, and we used to infer Copy, but that ended up with surprising errors at a distance. Opting into copy semantics ends up the best option. This ship has sailed, but just to comment, I suppose that a move operator, like let a = move b Would be too heavyweight, but one of those alternatives: let a &lt;- b let a := b var a = b move a = b Could differentiate syntactically from an always-copying `let a = b`, and don't feel like too much noise. The downside is that whenever a type changes from copy semantics to move semantics, people would need to go back and change those assignments (assisted by tooling or just the compiler errors). Actually, I'm not sure this is a downside.
This doesn't work for patterns.: let v = vec![1, 2, 3]; let i = 5; let (v2, i2) = (v, i) See what I mean? EDIT: fixed to be actual code now that I'm back at my computer.
Cargo support?
not yet, [will be the focus for 0.2](https://github.com/PistonDevelopers/VisualRust/issues/3).
Ah okay. Does it matter that I'll be asking for a .dll instead of a .so file? Or does Rake figure that out for me?
I initially strongly disagreed with this, especially since pretty much no other ahead-of-time compiled language implementation I can think of off the top of my head builds with optimizations enabled by default, but the sheer number of articles, blog posts, tweets, stack overflow questions, etc. I've seen is starting to make me reconsider. I still wonder why it seems to be such a common issue with Rust. Maybe it's common in general, and it's just that Rust leans *so* heavily on optimization (to the point where it can make a 20x difference) that we can virtually always tell when that's the performance problem. Or maybe it's because Rust is positioned as a C++ replacement, so the first thing people do (before really investigating the rest of the language) is do a simple microbenchmark and compare with their favorite language. Either way, I'm pretty concerned if people are coming to conclusions like "iterators aren't an efficient abstraction" after several weeks with the language! After all, if something that common and that idiomatic were slow, Rust's claim about zero-cost abstractions would be pretty shaky (which I think was the gist of the article).
&lt;3
Go also only applies relatively simple optimizations in order to keep its compile time fast, and has far fewer abstractions to rip through than does Rust. Go also, as far as I'm aware, doesn't actually have a *non*-optimized mode, so it's kind of a tautology to say it defaults to optimized.
My poor use of colloquialism on the term Chap here does indeed extend beyond the barriers of gender. I'll use better inclusive language in the future though to be sure. Admittedly, while I have had little opportunity to converse with someone of the opposite identified gender about modern language development, I would welcome such conversations in equal enthusiasm. 
Verbal semantics in English are horribly broken imho... if only human language could develop as fast as software languages do. Anyway, I replied farther up on the topic at hand: http://www.reddit.com/r/rust/comments/35srjn/strive_to_make_the_rust_community_and_technology/cr9bntu 
The main difference is that C++ interactive compiler has options for stripping out some of the extraneous information that isn't really relevant. If you turn that off, you see the following: .file "example.cpp" .intel_syntax noprefix .text .Ltext0: .section .text.unlikely,"ax",@progbits .LCOLDB0: .text .LHOTB0: .p2align 4,,15 .section .text.unlikely .Ltext_cold0: .text .globl add(int, int) .type add(int, int), @function add(int, int): .LFB0: .file 1 "/tmp/gcc-explorer-compiler115414-66-gofm28/example.cpp" .loc 1 1 0 .cfi_startproc .LVL0: .loc 1 2 0 lea eax, [rdi+rsi] .loc 1 3 0 ret .cfi_endproc .LFE0: .size add(int, int), .-add(int, int) .section .text.unlikely .LCOLDE0: .text .LHOTE0: .section .text.unlikely .LCOLDB1: .section .text.startup,"ax",@progbits .LHOTB1: .p2align 4,,15 .globl main .type main, @function main: .LFB1: .loc 1 5 0 .cfi_startproc .LVL1: .loc 1 7 0 mov eax, 3 ret .cfi_endproc .LFE1: .size main, .-main .section .text.unlikely .LCOLDE1: .section .text.startup .LHOTE1: .text .Letext0: .section .text.unlikely .Letext_cold0: .section .debug_info,"",@progbits .Ldebug_info0: .long 0x9b .value 0x4 .long .Ldebug_abbrev0 .byte 0x8 .uleb128 0x1 .long .LASF0 .byte 0x4 .long .LASF1 .long .Ldebug_ranges0+0 .quad 0 .long .Ldebug_line0 .uleb128 0x2 .string "add" .byte 0x1 .byte 0x1 .long .LASF2 .long 0x4c .byte 0x1 .long 0x4c .uleb128 0x3 .string "a" .byte 0x1 .byte 0x1 .long 0x4c .uleb128 0x3 .string "b" .byte 0x1 .byte 0x1 .long 0x4c .byte 0 .uleb128 0x4 .byte 0x4 .byte 0x5 .string "int" .uleb128 0x5 .long 0x25 .long .LASF2 .quad .LFB0 .quad .LFE0-.LFB0 .uleb128 0x1 .byte 0x9c .long 0x81 .uleb128 0x6 .long 0x39 .uleb128 0x1 .byte 0x55 .uleb128 0x6 .long 0x42 .uleb128 0x1 .byte 0x54 .byte 0 .uleb128 0x7 .long .LASF3 .byte 0x1 .byte 0x5 .long 0x4c .quad .LFB1 .quad .LFE1-.LFB1 .uleb128 0x1 .byte 0x9c .byte 0 .section .debug_abbrev,"",@progbits .Ldebug_abbrev0: .uleb128 0x1 .uleb128 0x11 .byte 0x1 .uleb128 0x25 .uleb128 0xe .uleb128 0x13 .uleb128 0xb .uleb128 0x3 .uleb128 0xe .uleb128 0x55 .uleb128 0x17 .uleb128 0x11 .uleb128 0x1 .uleb128 0x10 .uleb128 0x17 .byte 0 .byte 0 .uleb128 0x2 .uleb128 0x2e .byte 0x1 .uleb128 0x3f .uleb128 0x19 .uleb128 0x3 .uleb128 0x8 .uleb128 0x3a .uleb128 0xb .uleb128 0x3b .uleb128 0xb .uleb128 0x6e .uleb128 0xe .uleb128 0x49 .uleb128 0x13 .uleb128 0x20 .uleb128 0xb .uleb128 0x1 .uleb128 0x13 .byte 0 .byte 0 .uleb128 0x3 .uleb128 0x5 .byte 0 .uleb128 0x3 .uleb128 0x8 .uleb128 0x3a .uleb128 0xb .uleb128 0x3b .uleb128 0xb .uleb128 0x49 .uleb128 0x13 .byte 0 .byte 0 .uleb128 0x4 .uleb128 0x24 .byte 0 .uleb128 0xb .uleb128 0xb .uleb128 0x3e .uleb128 0xb .uleb128 0x3 .uleb128 0x8 .byte 0 .byte 0 .uleb128 0x5 .uleb128 0x2e .byte 0x1 .uleb128 0x31 .uleb128 0x13 .uleb128 0x6e .uleb128 0xe .uleb128 0x11 .uleb128 0x1 .uleb128 0x12 .uleb128 0x7 .uleb128 0x40 .uleb128 0x18 .uleb128 0x2117 .uleb128 0x19 .uleb128 0x1 .uleb128 0x13 .byte 0 .byte 0 .uleb128 0x6 .uleb128 0x5 .byte 0 .uleb128 0x31 .uleb128 0x13 .uleb128 0x2 .uleb128 0x18 .byte 0 .byte 0 .uleb128 0x7 .uleb128 0x2e .byte 0 .uleb128 0x3f .uleb128 0x19 .uleb128 0x3 .uleb128 0xe .uleb128 0x3a .uleb128 0xb .uleb128 0x3b .uleb128 0xb .uleb128 0x49 .uleb128 0x13 .uleb128 0x11 .uleb128 0x1 .uleb128 0x12 .uleb128 0x7 .uleb128 0x40 .uleb128 0x18 .uleb128 0x2117 .uleb128 0x19 .byte 0 .byte 0 .byte 0 .section .debug_aranges,"",@progbits .long 0x3c .value 0x2 .long .Ldebug_info0 .byte 0x8 .byte 0 .value 0 .value 0 .quad .Ltext0 .quad .Letext0-.Ltext0 .quad .LFB1 .quad .LFE1-.LFB1 .quad 0 .quad 0 .section .debug_ranges,"",@progbits .Ldebug_ranges0: .quad .Ltext0 .quad .Letext0 .quad .LFB1 .quad .LFE1 .quad 0 .quad 0 .section .debug_line,"",@progbits .Ldebug_line0: .section .debug_str,"MS",@progbits,1 .LASF1: .string "/tmp/gcc-explorer-compiler115414-66-gofm28/example.cpp" .LASF2: .string "add(int, int)" .LASF0: .string "GNU C++ 5.1.0 -masm=intel -mtune=generic -march=x86-64 -g -O2" .LASF3: .string "main" .ident "GCC: (GCC-Explorer) 5.1.0" .section .note.GNU-stack,"",@progbits The other differences are that the Rust code, when you compile with release mode, actually compiles the `add` function out entirely, since you never do anything with it (in the C code you returned it from `main`), and that because Rust uses a different convention than C and name mangling, the `main` function in the Rust output actually calls to the real main function with the mangled name. Since you did nothing with the return value, the `add` call was optimized out entirely, and so you are left with: _ZN4main20h5596059186437411raaE: .cfi_startproc retq The wrapper `main` function just sets things up so that it can pass your Rust main function into a built-in function `lang_start`, which will then in turn call the Rust main function: main: .cfi_startproc movq %rsi, %rax movq %rdi, %rcx leaq _ZN4main20h5596059186437411raaE(%rip), %rdi movq %rcx, %rsi movq %rax, %rdx jmp _ZN2rt10lang_start20hab6db8aec209082eDgwE@PLT The real moral of the story? It would probably be nice to port the "Filter" options from the C++ explorer to the Rust Playpen, so you don't have to wade through a bunch of irrelevant internals to see what your code actually compiled down to. Other things that would probably help would be allowing you to compile a library rather than an executable, so you will actually have labels that correspond to your functions rather than having them inlined or constant folded. Here's a way to get it to actually compile the add function the way you expect in Release mode. Tell it to never inline the `add_one` function, then actually call it with something that is not a compile-time constant, and then print it out in `main` so that it can't be eliminated as dead: #[inline(never)] pub fn add_one(x: i32, y: i32) -&gt; i32 { x + y } fn main() { let x = std::env::args().count() as i32; println!("{}", add_one(x, x)); } Now you will see this get compiled down to: _ZN7add_one20h46dad46257c4547deaaE: .cfi_startproc addl %esi, %edi movl %edi, %eax retq Which is pretty similar to what you see in GCC; in fact, you can get the exact same thing (except for the name) if you switch to Clang for C (which uses the same compiler backend as Rust, LLVM) and turn off Intel syntax: add(int, int): # @add(int, int) addl %esi, %edi movl %edi, %eax retq 
&gt; the sheer number of ... Remember, you have survivor bias here: you only hear about this when it's a problem, not when it's not a problem. So perceptions can be a bit skewed. 
Yes. You'd need a `&amp;mut str`, and I'm not even sure you can construct such a thing.
Agreed. Also would be great if we didn't have to have a main() to see how functions would compile.
On the contrary, I assume only a small percentage of the people who see such performance actually write anything about it. My concern is that a much larger number of people are simply dismissing Rust out of hand because of its perceived performance. Hopefully I'm wrong.
Excellent, thank you for your hard work!!
I really like it. I always thought it looked a little plain. By the way, what happened to the `format` button? **** Edit: Nevermind, I see the pull request explains the "dodgy" rustc pretty printer.
Cool! * ~~PS1~~ * PS2 * PS3 * ~~[PS4](https://twitter.com/wickerwaka/status/479842553831776257)~~
[**@wickerwaka**](https://twitter.com/wickerwaka/) &gt; [2014-06-20 04:25 UTC](https://twitter.com/wickerwaka/status/479842553831776257) &gt; \#rustlang cross compiled and running on my ps4 devkit. Surprised stdout worked given how much of libuv I stubbed out [[Attached pic]](http://pbs.twimg.com/media/Bqi-Ql7CEAAfw1J.png) [[Imgur rehost]](http://i.imgur.com/5mtY44Y.png) ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://www.np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
I liked this article and found it useful. I do kind of wish there was a short companion article "here's how to do error handling in Rust" that skipped all "wrong" ways of doing it.
Have you checked out the case study? It's fairly long itself, but definitely skips over most of the motivation elaborated on previously.
Eh. I wouldn't call panicking in a separate thread and then catching the panic an alternative. It's certainly a tool in the box, but it's only useful for particular kinds of tasks. I use it in quickcheck to witness and shrink failures, and I know /u/pcwalton has use cases for it inside Servo, but it's certainly not appropriate for your everyday run-of-the-mill error handling. I'm pretty confident we'll be fine on this front. The standard library sets the rhythm for us all to follow, and it leans very heavily on the style of error handling in the OP. I see a bright future for Rust in error handling. :-)
Using Results in a library also enable the consumer of this code choose to unwrap and panic (and catch it in another thread). So this particular use case appear to be subsumed by Results as well, at least for library-generated errors.. yes that wasn't a good example. Still, there's some failure modes that don't map to Results (division by zero, etc). So panicking as a second (and more fundamental) error mechanism is unavoidable.
I believe the owned version of `str` *used* to be `~str`, but got swapped out for `String` early last year in an effort to reduce the density of sigils (non-word characters) in the language syntax. Similarly, `~[T]` became `Vec&lt;T&gt;`.
If you have any tips regarding what IDEs to use on Linux, I'd love to hear them.
Nope, sorry. Unix is my IDE, but I guess you want something graphical. I don't like those myself, so I can't help you.
Pandoc tends to be quite good for literate programming. I imagine one could use pandoc's markdown-to-html mode as the formatting engine in Jekyll.
I'm not sure what you mean. I'm not printing either foo or bar- simply comparing them.
There's an Eclipse plugin ([RustDT](https://rustdt.github.io/)), and a standalone IDE ([SolidOak](https://sekao.net/solidoak/)). Behind every attempt to improve editors/tooling for Rust, an important piece is [Racer](https://github.com/phildawes/racer), that provides autocompletion (even across crates boundaries). Both SolidOak and RustDT use Racer to autocomplete. Honestly I think you should use either Vim, Emacs or Atom - any of them can be used with racer ([here](https://github.com/edubkendo/atom-racer) for Atom). Emacs has the advantage (and the disadvantage, for some) of being Emacs, so that's what I use.
What browser and operating system are you using? I haven't observed that at all.
They follow the same rules as anything else, a plain `()` is a value, not a reference, so there'd be two of them. You can even call `clone()` on `()!.
No, but if you want to do character-level operations on ASCII strings you might as well just use `&amp;mut [u8]` and convert it to `&amp;str` after you're done.
The issue with `&amp;String` isn't quite so straight cut. Since it's behind a `&amp;`, you can't grow it, and the stdlib even [has a function](http://static.rust-lang.org/doc/master/std/string/fn.as_string.html) for going from `&amp;str` to `&amp;String`!
A `&amp;String` can point wherever it wants. It's no less flexible than `&amp;str`. [They're pretty much interchangable](http://static.rust-lang.org/doc/master/std/string/fn.as_string.html) as far as representation and flexibility goes. String is just 1 word larger.
You link to http://doc.rust-lang.org/1.0.0-beta.5/book/patterns.html, but perhaps it's better to link [here](http://doc.rust-lang.org/book/patterns.html) - after all that link will become outdated soon! (I think that eliminating the patterns chapter of the book will be rarer than releasing new versions)
No it can't; a `&amp;String` has to point to the start of an actual `String` value; `&amp;str` can point to an arbitrary subset of the contents of a `String`, a static `str`, or anything else that's dense UTF-8. Unless I've completely misunderstood everything about DST and slicing in Rust.
I wonder, does Firefox have any need to parse XML? If so, there might be demand to have its XML parser rewritten in Rust...
Well, Firefox does have a pretty XML view when you navigate to an XML document :-)
Oh, you're entirely right. But the actual `String` can live anywhere and point anywhere, if you muck with its internals (see the function I linked.)
Marked as unstable, doesn't count! :P
I'm sad there's nothing remotely close to where I am.
Where are are you?
This is cool stuff! A few questions: 1. How did you decide on the data structure to represent the DOM? 2. Are you using servo's string interning stuff, or are you rolling your own? Also, have you seen these? https://github.com/SimonSapin/rust-forest https://github.com/SimonSapin/kuchiki
Are there any rustaceans in Gent, Belgium? 
&gt;The Wikipedia page on Rust lists sixteen “influences,” or sources of linguistic inspiration, half of which I had heard of before. Rust’s influences, in alphabetical order, are: Alef, C#, C++, Cyclone, Erlang, Haskell, Hermes, Limbo, Newsqueak, NIL, OCaml, Python, Ruby, Scheme, Standard ML, and ***Swift***. Swift ? Really ??
I think there's an effort in html5ever to also parse a superset of xml called xml5. Similar to html5 it will parse everything and not throw errors when something is broken.
I'm interested. Whether it happens today or sometime soon I'd like to come.
Like any modern web browser it can display XML with XSLT stylesheet
Can't you just make optimization levels explicit? For example, you must either do `cargo build --release` or `cargo build --debug`. Just trying `cargo build` will prompt a question `Do you want optimizations with that?`.
I definitely think that's enough, for what it's worth. GCC also leaves optimizations off by default.
This is a really nice extension! I created a tiny demo that uses Rust's FFI to call a DLL. Currently, there's no direct Cargo support in VisualRust so you have to build it via console. Or you can extend VS2013 by adding menu entries under "Tools/External Tools". https://github.com/brakmic/IHaveNoClue
There are a lot of things that annoy me about switching to bugzilla... I hate having to sign up to search bug reports, the interface irks me, and I'm active enough on github that it would create a barrier for me to contribute. I probably wouldn't have been so quick to jump in and contribute had it not been on github...
Apparently, it's sourced too: * ["The if let construct is based on the precedent set by Swift"](https://github.com/rust-lang/rfcs/pull/160) * [rust documentation appendix, influences](http://doc.rust-lang.org/reference.html#appendix:-influences)
Doesn't bugzilla allow login with Github? Why not improve bugzilla until it matches Github closely? Or allow some hooks so cross-referencing stuff between Bugzilla and GH is seamless? 
All modern browsers support parsing xml. That thing that is used for ajax, the awfully named 'XmlHttpRequest' (that we nowadays use primarily for requesting json)? As the name suggests it was expected to be used for requesting xml documents. When xml was invented it was expected it would be a huge thing, and browsers added support for it. Sadly xhtml never really caught on, and the xml hype lost its momentum. For example, while the XSLT 1.0 standard is supported in most desktop browsers, support is not guaranteed on mobile devices. The XSLT 2.0 standard has been out for about 8 years, but as far as I'm aware *no* browser supports it. The exact same thing applies to XPath, where 1.0 is supported but 2.0 is not. I expect browsers to support parsing xml for the forseeable future, but support for the related technologies (e.g. XPath, XSLT) to slowly disappear.
Servo likes it too, we care a lot about the keeping the barrier to entry low. But...as the project grows, we'll have to manage more and more issues; so there is a tradeoff. At the moment we don't really need bugzilla; but we might someday.
Really. :) Rust and Swift have somehow managed to get a cyclic "influenced by" relationship before release.
Nope. Just nope. IMHO Rust doesn't need any inheritance as composition is in 99.999% better solution. Other cases are solved by traits.
Firefox is famously know for being very strict on XHTML content and strictly treating it as proper XML.
"Get away" implies subverting the borrow checker; I wouldn't recommend that. The *actual* problem is that values are destroyed in the reverse order they are declared. This means that when `main` ends, the variables are destroyed in this order: `byte`, `mybar`, `myfoo`. This means that `byte` *does not* live as long as `mybar` does. The solution is to simply ensure that it *does* live longer: reverse the order they are declared in.
The issue is that your lifetime specifiers indicate that the reference passed to `set_foo` has to outlive `Bar` (and hence the underlying object has to outlive `Bar` too). When you first make `mybar` you pass a reference to `myfoo` which was made before `mybar` and hence will be destroyed after it, so far so good. When you then try to `set_foo(&amp;byte)` you're passing a reference to `byte` which was made after `mybar` and will thus be destroyed before it (destructors are called in LIFO order), at which point `mybar.foo` would be a reference to destroyed memory, which rust won't let happen. Moving the declaration of `byte` ahead of the declaration of `mybar` (see http://is.gd/L7lfLn) ensures that it live long enough to be used in `set_foo`.
Thank you very much, I never thought this is as easy as re-ordering the declaration. I could have ask a few days ago, to save me from a lot trial and error. Here is now the working code: fn main() { let myfoo = MyFoo; let byte = 1u8; let mut mybar = Bar::new(&amp;myfoo); mybar.set_foo(&amp;byte); }
Thank you for the explanation, I'm sure there are a lot of beginners like me stumbled on this problem. It is maybe a good idea to put this in a document like 'common mistakes for rust begineers'.
Just to explain a little bit further: [javapoet](https://github.com/square/javapoet) is something similar to what I meant, but in Java world.
Why is the compiler not ordering the drops properly on its own? Is this the intended behavior, for explicitness? I've been coding in Rust for a while and I've never bumped into this.
Sounds like you are looking for something like [aster][1]. It's not beta/stable friendly, though. [1]: https://github.com/erickt/rust-aster
I think you could use [rust-handlebars](https://github.com/sunng87/handlebars-rust) for templating. It is possible that that is specifically for HTML
That would (presumably) change destructor order from the reverse of source order, which is a big no-no since destructors have side effects.
It's not like I put much thought into the idea. It's hard to *do* any serious thinking with that *giant ass moon staring at me seriously ohmygodwereallgonnadie*
Thank you very much to pointing me to it! It looks like it can suit me.
There will be a [stream](https://air.mozilla.org/rust-release-party/) of tonight in SF!
Might be best to link it from a separate library, implemented in asm, C or Rust.
We're gonna talk about adding it to the book next week, after the 1.0 celebrating is over. :)
Then go with abbreviations: `cargo b-db` and `cargo b-rl`. :-) There, I even saved you a letter.
That's what we talked about in the meeting, yeah.
There's also https://github.com/huonw/external_mixin
Hmm. I think Bugzilla suffers from UX issues, not necessarily, feature bloat. ~~For example as GP (justforporn) noted, you need to login to search bugzilla.~~ I've noted the fonts are plain ugly; searching issues, doesn't highlight text in them, etc.; Biggest GH advantage are: A) UX experience is smoooooth. B) Everything integrates with it. C) It can host lot of stuff, like docs, blogs, etc. 
Yeah that's too bad. I'm in Milwaukee myself, but I would've gladly driven down.
I think you'll love kuchiki. If you implement given `Sink`/`TreeSink` as interface, it provides search and manipulation of said tree, using css selectors or possibly even XPath. In theory, as long as parser implements the given interface it's searchible with kuchiki: whether it is`sxd`,`html5ever`, `RustyXML` or what not.
For example, loading up a page, I see 25! separate dropdowns for information. GitHub has one text box.
You assumed correctly. I could have made that more clear.
That definitely looks cool, but I'm making a tui with the ncurses bindings for now. I'll have to try that out later, though.
Only if you mark that section as unsafe.
http://www.reddit.com/r/rust/comments/35vyej/10_stable_is_nearly_here/cr8ogm7
Destructor order isn't actually guaranteed in Rust (and you can make it do weird stuff in edge cases, e.g. destructors in a `match` condition). That was one of the initial impetuses for `dropck`. I think with pnkfelix's work on code extents this may be less true now, though. (One nice side effect of Rust's memory safety being tied to the type system's correctness is that the guarantees Rust does make tend to be *actual* guarantees that you can always rely on; there's not a lot of wiggle room for "except"s. I think that was the unstated good part about the fallout from all the scoped discussion; it forced Rust to make peace with this nonguarantee in a more explicit way than it had before).
I've been trying to get other competitive programing sites/online IDEs (codeforces, codechef, ideone, etc.) to support Rust. They all say they'll consider it, but they'll need more interest from the community. If you have a site you want to support Rust, just go ahead and email them so they can see there is a lot of community support.
Enacs Rustmode
Your example rewritten with `try!`: print 2 * int(try!(open("foobar").map(|f| f.read()))) I like this because it's explicit exactly where errors can occur. I don't see this as verbose at all. In fact, most of my blog post is meant to be instruction for avoiding verbose error handling. :-)
Disappointed that there weren't redering screenshots with Servo, especially considering that two websites were specifically mentioned by name: Hacker News and the film website for Space Jam. Actually, what would be awesome is a web service were renderings of websites with Servo could be done. I know they exist for other browsers. I wonder if I could set this up for my Raspberry Pi 2 that's just sitting unused...
That's really not too bad. The 'map' is a bit obscure (since I usually think of mapping across many things, rather than using it for a case where I *know* there is only one thing). But not bad--maybe it's mostly my unfamiliarity. Wait, though--are you properly checking the integer conversion? Will that even compile? In any case, this is definitely cleaner than the mish-mash of checks required in C...
Ah, good point! let s = try!(open("foobar").map(|f| f.read())); print 2 * try!(s.parse()) :-)
IIRC it's because of the [Deref trait](https://doc.rust-lang.org/std/ops/trait.Deref.html). For such types the compiler will attempt automatically to dereference the binding and invoke the method on that instead.
This is the most exciting thing I've ever experienced!
[I made an early draft.](http://i.imgur.com/HoyedJw.png)
Congrats! Rusty Nail cocktail to all!
YEAAAAAAAAAAAAAAAAAAAAAAAAAAAHHHHHHHHHHHHH~!
Eh, let's not go overboard here. ... J/K ACTUALLY THIS IS A PRETTY BIG DEAL HOLY SHIT WE FINALLY SHIPPED **I CAN'T BELIEVE THIS IS HAPPENING**
So does this new theme not show usernames? [Edit] Enabling RES shows usernames, so that's probably how it wasn't noticed.
big congrats, a thank you to all the devs!!
[Hooray](http://3.bp.blogspot.com/-w564K_HybTA/TvpCadrbjqI/AAAAAAAAASs/roUE4Xrsb5A/s1600/NewYearsPoppers.jpg)
Any `&amp;Type` will automatically coerce into `&amp;(*Type)`, `&amp;(**Type)`, etc. Since `*Arc&lt;T&gt;` gives you a `T`, `&amp;Arc&lt;Table&gt;` can become a `&amp;Table`. I'm not sure where all of the implicit conversions are documented. There are relatively few of them, though. The only ones I can remember right now are auto-dereffing and trait object coercion (`&amp;T` -&gt; `&amp;Trait` when `T` implements `Trait`).
#![allow(laundary_ingestion)] #![feature(nomnomnom)]
This moment is something I have been looking forward to! Congratulations everyone!
Yes, these are indeed shenanigans, and not in any way the residual fallout of cobbling together an almost completely untested new CSS layout in the final two hours before release! Ha ha ha!
There's no tag on the repo for those of us who want to build it ourselves.
oh... thanks
Turns out he was a pretty nice guy! Just misunderstood, is all.
No. Rust has a machine-checked operational semantics that was specifically designed to allow easy proof of the Laundry Theorem: that is to say: "Well-typed programs don't eat your socks." You can read the entire proof script in an upcoming article in the Journal of Software Hygiene. (n.b. This is a lie.)
Congratulations to everyone! I'm wishing for a bright future for Rust! (Let's make it happen!)
Congrats to all core members and community!! https://crates.io is great but currently there is no way to understand the quality of these libraries. It would be good if we can add rating (stars rating like Amazon) support which will allow community to rate the quality of the libraries. This will help newbies to choose a crate when multiple options are found. 
We're going to do some kind of ceremonial tagging at the SF meetup tonight.
Congratulations Rust community. Where can i learn more about how rust deals with memory without using a garbage collector?
They are beautiful! Unfortunately I do not have a credit card :'(
... and now it is updated to use 1.0.0 stable!
There is an tutorial here http://doc.rust-lang.org/stable/book/
I'm hoping for a fungus of some kind.
I think the threshold for fanboyism requires a plurality of your wardrobe to be devoted to fandom. Do you own exactly three shirts?
Major congratulations on getting some interesting content in section 3. I look forward to going over it this weekend.
no, but I also have a sticker on my laptop... that's gotta give me some fanboy points, right? (brb, buying about 10 shirts so I'm the first official fanboy)
Thank you. I .... yeah. Lots of work. It's still a bit rough. Still a bunch more to do. But thanks :)
And, specifically, http://doc.rust-lang.org/stable/book/ownership.html and its associated chapters.
After and end comes a new beginning.
Did bugzilla land editing support for posts? In the past you always needed to repost. Is reviewing diffs better or worse in bugzilla. I think github does better than most git gui tools I've used.
 It statically links the entire standard library by default. 
Amazing work everyone, this language truly deepened my understanding of low-level programming and made me look at problems from a different perspective. Every minute I've spent with Rust was a minute well spent!
Congratulations to everyone who participated in the development effort! This is a great day indeed.
&gt; Mozillians will be gathering in Whistler, BC next month...We’re going to run Rust and Servo training sessions, as well as meetings with other teams to plan for the shared future of Gecko and Servo. I do hope there is a discussion of what a Mozilla-managed, Servo-based desktop browser might look like.
Good work to all of you!!
I have read many tutorials on borrows, lifetimes etc but some how I was still having a hard time putting this theory into practice. I had an epiphany today and it all clicked into place finally! I have written a short tutorial in the hope that someone else might benefit from my discovery: http://stackoverflow.com/a/30265809/39648 Please keep in mind I am a total noob when it comes to Rust. Please double check before you assimilate!
This is an awesome birthday present. Now I have an eternal bias for Rust, damn!
Looks pretty good, except the "login" button gets taller every time layout runs ;D The expanding sidebar using `:hover` + CSS transitions works, too! 
GitHub's PR interface isn't nearly enough to handle large reviews. But Servo has been using third-party review tools for a while now, first Critic and now Reviewable. Indeed, a major advantage of GitHub is that it already integrates with so many services. Bugzilla is open source so we can *add* integrations, but it takes real effort.
Biologically speaking, I think Graydon's first work is closer to the egg being fertilized. It wouldn't survived on its own without the protective environment around it. As it gestated, it went through many phases slowly transforming into what it is today. Gestation involves much more drastic structural changes than post-gestation.
I don't think so. HTML as used is based on filling in code from many different parties, e.g. Twitter serving you a widget. What happens when Twitter serves an invalid fragment, making the whole document invalid? Should it not be displayed?
Visual Studio Code doesn't support plugins... yet.
A sticky for introducing newcomers in order, too. With the new theme one currently must hover over "Learn"/"Install" to find information to use Rust.
I think four big stylesheets were enough to stop the moon from coliding
If you send me your address and what size you want, I will seriously buy you one &lt;3 carol dot nichols at gmail :)
Actually, is there a list of optimization (and other) flags somewhere?
Yay shirts! :D Boo my size being out of stock! :c This is a roller coaster of emotions.
Woohoo!
Reviewing is subjectively better. No editing yet; I don't think they intend to add it.
The current idea floating around is browser.html, but nothing planned yet.
[This post](http://brodoyouevencode.com/posts/how-to-write-a-rust-syntax-extension/) describes how to write a syntax extension (which generates code at compile time), but even if you're doing things at runtime it explains alot about how to work with the AST.
Wow, that design is awesome. I just ordered one! :D
A giant step forward for the software development world. A big congratz for everyone who made this possible!
http://doc.rust-lang.org/stable/book/deref-coercions.html
Maybe something like Go does, a dropdown box which lets you select different programs, ranging from very simple to .. not so simple.
Selected from rust-by-example, perhaps? (with link to chapter to get more info)
Now Rust is usual boring predictable post-1.0 language, it isn't even going to eat my laundry. Time to move to something less mainstream &gt;_&gt;
Are they planning to restock? Men L is sold out :(
I would also get one if they restock the large.
Thanks. This is exactly what I looking for! 
Yes. Most Mozilla folks don't have theirs yet either.
I saw this link in IRC yesterday: http://manishearth.github.io/Presentations/Rust/
I like how the docker registry does it, you just simply give a repo a star if you want to mark it. Acts as an upvote only type system for containers, might work well for crates too.
[**@DevSwagShop**](https://twitter.com/DevSwagShop/) &gt; [2015-05-15 22:08 UTC](https://twitter.com/DevSwagShop/status/599335624483557376) &gt; The rumors are false: we still have Rust shirts in EVERY size! Running low on Medium, so hurry… http://bit.ly/1FdLNDT ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://www.np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
This is taking a serious worry off my mind. My capstone project this fall consists of writing an OS kernel in Rust, so having a stable compiler is primordial.
That's disappointing. I think when I discovered that GitHub not only previews but also supports editing, I thought it was awesome. Going back to not having editing would probably seem like revisiting the 90s.
Thanks.
Quite exciting, impressive and an excellent and to the point book to accompany it.
I wish my cake day was the release of 1.0! :P
I've been following along since around 0.5, i've followed the mailing list, this subreddit, the rfcs on github, the conversations on discourse... As a card carrying member of the silent (well, fairly quiet) and hopeful masses all I can say is well done. This has been a mammoth effort from the core team and the community and this a great milestone to have hit. There have been disagreements and differences in opinion over the lifetime of the project, but everything has always been dealt with in a technically sound and equanimious manor, with little to no aquiesance to personal opinions or rivalrys. Rust has proved itself a model to which future langauges and open source prohects should look to for inspiration. The community leadership shown by those on the core team and by the community at large (especially, for me, the moderators and regulars of this sub) have done an excellent job and i'm profoundly thankful for all the effort that has been expended to make this "hobby project" (for the majority of contributors) as successful as it has been so far! Onwards and upwards!
Done!
If you run it you will find out why :)
Ah, the age-old question...
I agree, but that is still only expected to occur at the end of the current block, which the borrow checker making the statement above legal wouldn't change.
Is shipping cost lower if you get a bunch? We can setup a group shipment.
That's a pretty interesting attack vector to bring down a competitors site if you think about it. Poison one component, destroy all.
Python with pypi also has no rating system, , only downloads 
This comment is the bestest.
There are other nice places :) I think periodic Q&amp;As are nice, but I prefer something like /r/Piano's name, "There Are No Stupid Questions Thread - Monday 4/20" etc. Additionally, /r/LearnJapanese has "Shitsumonday" threads that get sticked every week. They're generally active all week long with several hundred comments. Maybe a stickied thread could replace specific question threads with a general discussion one. 
I'll have to give that a try, thanks! It is a minor annoyance that the interface is different between the two so that it's not a drop-in replacement. 
His name is [Ferris](http://www.rustacean.net/)? You can find graphics on the site!
&gt; What's needed is a Cargo package. I suggest you contact the maintainer of the `rust` package in `community` and ask whether he'd be interested in providing a `cargo` package as well.
The interface can't really be the same between them, since `Cell&lt;T&gt;`'s `.get()` returns `T`, `borrow_mut` and `set` work differently, etc.
Oh I get it, but it can still be a bummer :)
Wow, thanks! I didn't know about that site before, or where the mascot even came from originally. It's funny how close that site is to http://www.rustaceans.org/, which I was thinking of.
oh god no, I'm allergic to crabs why can't it be the [rusty spotted cat](http://smeegly.com/wp-content/uploads/2014/06/Rusty-Spotted-Cat-in-Tree.jpg)? 
It's always worked on mine, but I had to and still have to switch in and out of vim mode in order to scroll (using hjkl), and put the shared URLs through a URL encoder/decoder in order to copy and paste to/from external sources.
[rust-learning](https://github.com/ctjhoa/rust-learning) is a collection of useful links regarding learning all different types of Rust stuff.
I don't get why the calculator doesn't act like an actual calculator. I mean, fine, the example should be simple, but that's not any calculator I've ever heard of.
Thanks! Yes, that could have been left away. :)
That statement is so generalizing that it is very unlikely to be true. Frankly, it seems arrogant to dismiss *all* other subreddits. For instance, I think /r/askscience qualifies as not "terrible".
I've been using Option::take() to do this, because I wasn't aware of FnBox: fn with_once(s: String) -&gt; Box&lt;FnMut() -&gt; String&gt; { let mut opt_s = Some(s); Box::new(move || opt_s.take().unwrap()) } 
I like that I delved far enough into /r/all to see this after having just finished a programming assignment to make a rust compiler. From what I've seen, it's a pretty neat little language and I'd probably learn it more eventually, but I hope you'll forgive me for saying that right now, I could do with never seeing it again. Lmao Also, congratulations
I don't like that line of thought. I think rust it's far too conservative in its choice of syntax: `Box[Vec[u8]]` would have been so much better than using lower than and greater than signs. There are objective reasons¹ for that, yet the worse but more common syntax was chosen. ¹: fonts display operators ideally for them to be operators: smaller than upper case characters and with raised baseline. Which is horrible for enclosing characters that ideally should be taller than upper case characters and go below the baseline to visually frame the things they enclose.
The iframe would display a parse error
For anyone that's curious, here's the the [full list of implementors](https://doc.rust-lang.org/std/ops/trait.Deref.html#implementors).
https://crates.io/crate/fn_box
I don't think forcing diversity to appear is a good idea. Primarily rust should be about technology and only secondly about the community.
You can say the language design calls for an Oath to Order...
What you are suggesting is 1. Already possible by including some javascript that messes up the page, or including an element with absolute positioning that is 'before' the rest of the page and thus obscures it. 2. Probably illegal in most countries. So I don't see your point here. Yes, if you can include arbitrary html in a competitors website you can screw it up completely. Adding one more way to do so is not going to change anything. If instead of just putting stuff in the page you meant serving a broken document in an iframe, then of course only that iframe should not display.
I like how your life goals are mutable!
Because where CSS selectors aren't adequate, you can use JS to find elements via searching them all.
My fav: "... also seal on the downside to see Muslims ..."
I'd like the meme of "forced diversity" to vanish. Completely. All successful outreach projects I've seen (and I have and was involved in: a conference going from 5% to almost 50% attendance, a usergroup growing to the largest usergroup in my local town despite language being in a downswing and a a Rust usergroup having growing woman attendance) never coerce people into their roles. This announcement yesterday was a huge spanner in the works for those contributing to the Rust community through outreach work, not through code.
This statement makes me terribly sad. From the (surely unintentional, but still) false dichotomy between gender coded terms like community and technology, to describing outreach activities as "forcing"... I don't have energy to push back hard but at least, I dunno, please register my objection. The community ought to aim higher than this.
&gt;I don't think forcing diversity to appear is a good idea. I'm not sure anyone is doing that. From my reading of the post, it was more about making sure the community is as welcoming as possible so that anyone who can contribute feels that they are able to. In fact, the first post says this: &gt;This doesn't mean tokenism, or anything against the people who are on the team today On to your second point: &gt;Primarily rust should be about technology and only secondly about the community. The two things are very much linked though. For example, as the stdlib is so slim a lot of really important code - like http libraries - will be written by the community. A wider community brings more ideas and more contributions, and therefore better technology.
If you're getting errors about the shader version not being supported, I opened a PR to fix it: https://github.com/tomaka/glutin/pull/454
This talk was the reason why I started looking into Rust. I don't need Rust's performance for most parts; but when I saw how easy it was to integrate Rush with Python, I was sold. The idea of coding the hot loop with Rust while writing the boring but voluminous code with Python/Node is really tempting.
You might wanna add some more context.
Congratulations and thank you to everyone involved. This is the most excited I've been about something in the programming world in a long time.
&gt; I was more referring to the discussion there which brought up that there are no open non white cis males in the project. &gt; &gt;.... &gt; &gt;But please let's not judge the quality of the developers behind rust (or the community) by the level of diversity. I don't think that post was judging the quality of the rust developers. I would say that the lack of diversity suggests that we may not be as welcoming to certain groups of people than we could be.
This also seems complicated fwiw, not everyone knows what threads are. If it's in a dropdown like /u/vwim suggests it would work, but not on its own.
Is it wrong to keep thinking of HBO's 'Silicon Valley' and 'Pied Piper' all the time when watching the pre-canned video? :)
There is zero suggestion of enforced ratios, just that a ratio very close to zero is obviously wrong, and it doesn't seem controversial that correcting that might take explicit effort. &gt; That enforced ratios have the opposite behavior of contributing to what you mentioned should be pretty obvious from a mathematical and statistical background unless the ratio exactly matches the distribution of talent and skills. If we're going to argue mathematics, this is wrong. The distribution just needs to be closer than what we have now for it to be an improvement. And, it seems utterly ridiculous and even insulting to suggest that epsilon% is closer to "optimal" than even the tiny 10% (or, you know, 50%). &gt; But we never rejected anyone from contributing or participating in the community. An overwhelming preponderance of a single class of people can still be a *huge* discouragement. I know I feel very intimated when in an environment where there's a lot of people with whom I don't relate, I can only imagine how much worse it is when that general feeling is backed up by first-hand (and second-hand) negative experiences in similar situations. 
I feel similar to /u/graydon2 here. We're not forcing diversity. We want to spur outreach efforts to fix the diversity problem While the initial tweet being talked about was misguided about a few things (Rust is not Mozilla, the Rust "team" is largely a volunteer thingy, etc), it did get some things right. Whatever the reasons may be, we look like a "boy's club" from the outside. This is bound to turn non-men away. I like to think that the Rust community is fair and nice to women, but I'm mostly inferring that, and even if true, potential new community members do not owe us anything to dig deep enough to find this out and determine that the community is one they want to join. Very few people will join a community they see as having a significant chance of being (intentionally or unintentionally) toxic/excluding to them, and like I said nobody owes us anything for them to dig deep enough to get clarification on this.
To me, it screams "steampunk".
Rust 1.0 day is the day you don't care about shipping charges. Ordered!
A simpler thing that might work is a function that would return null in many languages, but an option in Rust. Most things I could think of (e.g. parse an int from stdio and do some computation with it) would not work though, because the playpen does not have input.
sounds good to me!
You mean, huon-dbaupp, Vladimir Matveev, Shepmaster and Chris Morgan? ([link](http://stackoverflow.com/tags/rust/topusers)) Look at the gap of points between Chris (4th) and Levans (5th), one of those 4 is on nearly *every* Rust question... 
oh god no, I'm allergic to cats ;) (i really am, though)
We're not excluding anyone. Being more inclusive does not mean being exclusive of the majority. See my comment below; we're not talking of forcing the ratio and even if we were it need not happen by deliberately excluding people.
Yeah. It may have "Rustacean" with R replaced by the Rust logo on the back. But it's still somewhat subtle which is why I made one for myself. :)
The absence of women on the governance team is mostly because of the dearth of them in the Rust community - I wouldn't like to bring someone unknown into the team just as a token member.
These are skills on Linkedin. Perhaps the poster is waiting for a recruiter to offer him a Rust-related position now that all companies are suddenly going to use Rust in production because it is not unstable any more.
I don't think it's the same line of thought. There's a big difference between '`a = b = c` compiles in both most of the Algol family tree and Pony but does something different in the latter, confusing readers' and 'syntax looks slightly unfamiliar'. While I respect Rust's conservatism, I happen to agree that `[]` would be better than `&lt;&gt;`, mainly because the former is easier to type on a keyboard. `Box Vec u8` would be an interesting alternative.
Agreed, but the larger issue is still one which we want to address. As I mentioned in the thread, as far as the mod team goes it's not tokenism; instead "Diversity on the mod team is very important, and I hope we can work towards a solution to that. Moderation involves empathy, and however perfect we may consider ourselves to be, it's harder to empathize with people who have different experiences and expectations as you.". We _need_ to be diverse to function optimally. I don't think it will involve adding someone unknown either.
If you use a plugin manager like Vundle or Plug, you can just add the git repo. See https://github.com/junegunn/vim-plug for more details.
This post really cleared up everything in my head, so now I know what to do and how to do it. Thanks! :)
So: Why are there no woman in the larger Rust community?
Also, why the percentage of bearded guys on the yesterday's 1.0 meeting I visited was so disproportionately high
Sorry about the bad initial impression! I thought reddit does some vote fuzzing, so it might look like you have downvotes even if you don't. One recently published review is Evan Miller's "[A Taste of Rust](http://www.evanmiller.org/a-taste-of-rust.html)." With that said, short intro tutorials are in short supply. For now, I'd recommend thumbing through [The Book](https://doc.rust-lang.org/book/) to get a feel for the language.
That was exactly my goal when writing it :) Glad it helped.
Apologies, that's a paraphrase of the objection to "forcing diversity to appear". I see you're clarifying some below. As it happens I'm ... totally fine with predetermined proportions/quotas as a form of affirmative action, but I know the tokenism threat risks are higher there and people have more reasonably nuanced objections to participating in such things. I see you're objecting only to that narrower sense, not all outreach activities.
Link to the sticker? :)
burntsushi makes a good point. I seem to remember that reddit does vote fuzzing too, so it's possible you only got a few downvotes from people predisposed to seeing the worse parts of reddit and had the bad luck to hit the lower end of the range fuzzing can produce.
Life! Don't talk to me about life.
hmm, but is’t it rather common that e.g. setters return the old value?
Can't depend on fn_box because it uses unstable features. :-(
It definitely took longer to write the code, I had to learn a lot more about Rust to get most of the parts working. Ray tracing always gives you really cool results, which is definitely part of why I like it so much :)
+1 to this.
Thanks. FnBox uses other unstable features so I chose this route. I combined this with RefCell so I could still use Fn -- using FnMut forces everything I capture to be mutable and I guess I'd rather localize my hacks. Anyhoo for your enjoyment... struct CapHack&lt;T&gt; { wrap_t: RefCell&lt;Option&lt;T&gt;&gt; } impl&lt;T&gt; CapHack&lt;T&gt; { fn new(t: T) -&gt; CapHack&lt;T&gt; { CapHack { wrap_t: RefCell::new(Some(t)) } } fn take(&amp;self) -&gt; T { self.wrap_t.borrow_mut().take().unwrap() } } So then, I can write: fn without_once(s: String) -&gt; Box&lt;Fn() -&gt; String&gt; { let hack = CapHack::new(s); Box::new(move || hack.take()) } Blegh...
Is it slow? 
Yes please!
Here are [the slides from my talk](http://kmcallister.github.io/talks/rust/2015-dependent-types/slides.html).
**About the logo, if you don't want some artistic criticism then please ignore.** I wish it were flatter. Crabs are flatter. This looks like the top half of a discount sticker or the sun, or the back half of a turkey. The color is too red, needs more rust. Often, large projects have a logo contest... Reddit is perfect for this, a mod could sticky a logo thread and offer a month long submission window. 
So clicking on the giant "R" in the upper-right isn't good enough?
I had this experience while trying to start learning Rust as I basically came to the language during the RC phase of marching toward 1.0 status. As I would search out information, inevitably some of it (a lot of it) had become dated with respect to where Rust is now. It does make for confusion for a newbie when they are not aware the various evolutions that have taken place during the birthing process of this new language. Retro cleaning the Internet seems like a daunting and not particularly promising thing to he to accomplish. Perhaps the best bet is for Rust home page and other prominent Rust sites to have a very noticeable warning side panel - aimed at newcomers - letting them know they need to look to more recent postings and documentation on Rust as a lot changed as the language crystalized into its 1.0 form.
Gotta value "merry safety". So Rust is basically harm reduction for systems programmers?
Rust isn't a pure actor language, you can use the shared memory model instead of the message passing model, but the roots of Rust are very much in the actor model of programming. The standard library supports a lock-free multi-producer, single subscriber queue, which serve as message queues into threads. It also guarantees that threads cannot reference items which aren't specifically made thread safe. (there is also https://github.com/mahkoh/comm for other queue options) In summary, if you choose to, Rust will help you write deadlock-free code when you use the message-passing model of programming. It won't guarantee deadlock safety, but since you're not locking anywhere, you should be good to go. http://doc.rust-lang.org/std/sync/mpsc/ 
Yes, its definitely tongue-in-cheek
In the run-up to 1.0 most team members focused on making improvements that weren't backwards-compatible, since those are much harder to make after adding that guarantee. So now is a much better time for this to get noticed. If there's no RFC for it, then go ahead and write one! I personally sort of like the idea, but I'm a bit hesitant towards adding more redundant features, since the Zen of Python is against it and it's how C++ happened.
yeah, not that type of flat :) I should have disambiguated. The shell of a crab is not hemispheric or turtle like, It's flat like a plump in the middle pancake [crab](http://us.123rf.com/450wm/johnkasawa/johnkasawa1402/johnkasawa140200134/25645997-crab-in-front-view-isolated-on-white-background.jpg) 
If you're interested in learning the language, try [the book](http://doc.rust-lang.org/stable/book/), it's not too long. If you're looking for a bunch of code examples, [Rust By Example](http://rustbyexample.com/).
I found the article to be a bit bland. Sure, being backed by Mozilla is a good insurance against the creators losing interest, but I don't think this fact is *the* reason why Rust is a new language to look out for. What I find especially refreshing is that earlier research (region-based memory management etc.) concluded that it's not usable enough in real-world code, yet Rust proved that with a twist, it can work very well.
&gt;People including me learns programming by 'searching', not by official manual. I hadn't realized this was even a problem, because I've been learning from the official manual like a chump.
Yeah, it's changing UI conventions for the sake of it. (another offender was /r/talesfromretail, but they fixed their inconsistent header already)
Thank you so much, Mozilla and the Rust team. I know I am being dramatic, but Rust really gives me hope. It's just so *right*.
Is there an example using Python 3's ints that are an arbitrary size from Rust? I assume that it would involve pulling in CPython code.
No, I don't suspect they will. It's pretty hard to distinguish a rustc-generated staticlib from a clang-generated staticlib, after all! One thing to note is that there's no wrapper for any of the SDK right now, so if you need to use any of the frameworks, you're going to be manually using https://github.com/SSheldon/rust-objc. While that's a wonderful crate, it's not so wonderful to use directly for lots of objc interfacing!
Interesting idea. I want a way to compile a Rust subset / variant into C++ (not necessarily human-readable or idiomatic C++, though) because I think it's the only way to implement a really good C++ FFI.
You're looking at documentation for 0.11. The newer documentation is [here](https://doc.rust-lang.org/std/primitive.str.html). Since 0.11 the newer slice syntax has been added, so you can use `&amp;s[1 .. 9]`. The `&amp;` is necessary, as the slice returns a `str`, where `slice()` returned a `&amp;str`. EDIT: [Here](http://is.gd/OdDOzO) is your code running in the playpen.
Not everything useful to know per Rust will be in the official manual and sometimes you need deeper [or clearer or just different] elucidation and additional examples on a topic than what official doc stuff provides.
I'm sure you've never even heard of stackoverflow ;)
&gt; And communities can grow themselves. But (online-)communities tend to go from nice to hatefull and full-of-drama while growing, if not actively opposed. I think there's a mechanism that if a group is very homogenous, it tends to be unwelcome to others, thus becoming more homogenous, getting more unwelcome, and so on. (see also: reddit / major subreddits). Until, at the end, you have a group that is either extremely homogen (major subreddits) or full of people that love to hate &amp; get hated (4chan). If you have a heterogenous group, narrow-minded and unwelcome behavour tends not to grow, I think....
A prominent sponsor can indeed be helpful and important. The Mozilla sponsorship for Rust has very much meant that Rust is far from being just another hobbyist-spawned new language. Such a sponsorship is not necessarily sufficient to propel a language into long term adoption/success. Google has garnered a lot of interest in their re-think web programming language, Dart. However, Google continues in this pattern of not really embracing their own innovations - despite how much these are built up in the public eye. They never really embraced Dart as their own internal flagship language - there are some non crucial Google web apps that are using Dart but nothing high profile. So many software development companies have been curious about Dart but stood back not willing to stake any more serious commitment than Google itself. Now Google has backed off of putting a Dart VM in their browser - one of the most touted goals of the Dart project from its inception. Now Dart is relegated to being yet another compile-to-JavaScript; however, Microsoft's Typescript has seized on this rationale of existence far more effectively than Dart and has emerged as the premier static typed, compiled language for JavaScript runtimes. Dart is really an unnecessary addition in this space that intrinsically has a harder gap to close in compiling to JavaScript. With a higher performing Dart VM no longer a prospect for Internet clients, the impetus for Dart very much evaporates. Golang experienced this Google timidity a bit too, but even as Google up take of using Go tended to remain so-so, the Golang community grew steadily none-the-less. And then Docker happened. Docker's success (very rapid, catapulting to the top of industry headlines success) and the fact it is coded in Golang, has been a shot in the arm invigoration and uptake of that language. Thanks to Docker, Golang has succeeded in being legitimized and assured a long term language life cycle independent of Google. The Servo project is certainly a big assist for Rust - it shows a kind of strategic commitment from Mozilla. It would be nice, though, if that Docker effect were to come along for Rust. What Xamarin has done using C# .NET for portable mobile device development is a model for a market niche and there is the Internet of Things where efficient apps for diminutive hardware might be welcome.
Incidentally, while the rule is somewhat dated, the giant R does push the subreddit description almost entirely below the 600px "fold", and (perhaps more importantly) the rules to nearly 800, possibly increasing the chance of people not reading them. Though I suppose it doesn't matter for anyone who, like me, has acquired enough 'banner blindness' from the web to instinctively tune out the content of sidebars altogether, making reading the rules a conscious action regardless of their location...
There is a convincing response to a comparison of program measurements -- [contribute](http://benchmarksgame.alioth.debian.org/play.html#contribute) better programs. Everything else can be (will be) read as making-up excuses. Meanwhile, as I don't remember seeing any announcement that performance was the main focus of Rust 1.0, maybe there should be a place on the development roadmap for a future Rust release that was intended to address performance issues? (Set expectations.)
Yeah, there are quite a few code representations that could be useful. * Token trees (aka S-expressions in disguise). We currently parse these only for macro invocation bodies, but they make sense as the syntactic basis for the entire language. (Lisp too has a layer of syntax above S-exprs.) * The "surface" AST that matches the language grammar, eventually stabilized for procedural macros. Macro expansion happens at this stage, and the type of an AST node (or some phantom parameter) indicates whether it's been expanded. This gets rid of a lot of ICE potential. * The compiler's internal AST, with lots of secondary metadata and implementation details. * A polymorphic IR like both of you described. Desugared but still typed. Types are explicit, and pattern matching can only look at one "layer" at a time. This is what library crates export in metadata. Over time, it too could be stabilized, which is a prerequisite for linking code built with different rustc versions. This is where type checking, borrow checking, and perhaps most of the miscellaneous checks happen. * A monomorphic IR, the output of monomorphization. This is still typed. In dev/debug builds of the compiler we type-check it again for extra ICE squashing goodness. All method calls use UFCS and traits impls are known. * An explicit control flow graph that can handle both polymorphic code (e.g. for borrow checking) and monomorphic code (e.g. for codegen). This should have a generic framework for dataflow propagation, similar to [Hoopl](http://research.microsoft.com/en-us/um/people/simonpj/papers/c--/dfopt.pdf) (although the idea is much older; see also the "monotone frameworks" in chapter 2 of [*Principles of Program Analysis*](http://www.amazon.com/Principles-Program-Analysis-Flemming-Nielson/dp/3540654100)). Naturally, you should be able to perform transformations / optimizations at any layer and then recompute only the things that depend on it (LLVM does this for intermediate results generated by analysis passes). In my wildest dreams this means I can generate additional items from a "procedural macro" that runs after name resolution and type checking, and then check/compile those items as part of the current crate.
Since it's going to be impossible to take down the material and it might be possible to still add material, at least to sites like stack overflow, then maybe a kill word or kill tag could be used, such as "cruftyrust". Any pages including that term could be excluded from a search with -cruftyrust. This is a neat problem. Also at stake are the historical insights of the old code and commentary. Wiping unwanted information off the internet puts more pressure on archive.org's way back machine. The problem is better addressed at the search engine level. Google should JustKnow™ the old rust code is less relevant without any help from humans. 
Very.
Old docs really should have a giant warning about how old they are.
I don't think that infix notation ist really useful. sortBy (compare `on` fst) is beautiful code but in many other cases the 'normal' haskell function is easier to refactor because you can easily use currying and remove elements from the right or see if the left side may be replaced by another expression. I also don't think that it is that much useful for rust to have more than one way of writing code because it may become too confusing over time. I would love to see currying and monads in rust but infix notation and custom operators are haskells design decisions that I don't want to have in rust.
Pulling your bigints from Python is probably not the best idea. The num crate has bigint implementations (but is not very perfomant). Another possibility is to call into the Gnu Multi-Precision (GMP) library. There are bindings available [here](https://github.com/thestinger/rust-gmp).
If you love PyLadies and RailsGirls then you should automatically love the idea of similar things in the Rust community. RustLadies, etc. These would then (over time) introduce minorities into the visible Rust leadership teams. So, seemingly you agree with the OP fully. Yeah?
This is a warning that is being added to Servo for pretty much the same reasons.
I don't believe that's the issue here. The issue seems to be that minorities are under-represented in technical roles in the Rust community. That's of concern, not because we believe technical roles to be 'better' than non-technical roles (they are equally important) but because we are potentially losing out on a lot of very valuable technical contributions from people. E.g. the Linux kernel had an internship program where it turned out that they ended up accepting patches from a lot of first-time contributors (especially women)--and if you got something accepted into Linux, that really says your technical skills are pretty good. I don't remember the details and you might have heard about this already, but for anyone who hasn't, Sarah Sharp has blogged about it.
My very first question in `#rust` came about because I was using MIT's old docs with a newer version of rust. They must be buried. What's their deal (with not wanting to remove them)?
What software did you use to make the slides?
I don't see pointing the reasons for lack of performance as making up excuses as long as we have the mindset to improve the situation – and knowing where to focus is important for improving it. Then again, I don't know much about projects improving the situation, but there has been some talk about better SIMD support at least. Would faster regex matching need a DFA-based engine? Is there any project improving that? Does OpenMP enable something that is undoable with normal OS threads?
"your surplus blows library"
Because beards are in fashion currently.
Where is the code for the old versions of the book? I haven't been able to find it.
I wonder if there should be an "outreach" subteam. Would you want to be on one?
&gt; I don't see pointing the reasons for lack performance as making up excuses Please [find the Rust regex-dna program down among the other programs](http://benchmarksgame.alioth.debian.org/u64q/performance.php?test=regexdna) and then say how relevant those comments about Tcl regex really are to the performance of the Rust regex-dna program. Please [find the Rust fasta program down among the other programs](http://benchmarksgame.alioth.debian.org/u64q/performance.php?test=fasta) and then say how relevant those comments really are considering the fasta C++ g++ #5 program doesn't use multi-threading or multi-processing. Please [find the Rust nbody program down among the other programs](http://benchmarksgame.alioth.debian.org/u64q/performance.php?test=nbody) and then say how relevant those comments about calling SSE intrinsics directly really are given those other programs that do not call SSE intrinsics directly.
Whoa, chill out! I see you are trying to say that the programs are improvable with the current feature-set we have right now, so instead of dreaming away, let's do something right know. Is that right?
It's not *quite* that easy since the old stuff is in an S3 bucket somewhere and relatively hard to change. I think brson or acrichto would have to do it manually.
I think this had been brought up (forgot where, could have been internal) as having a "community" subteam which deals with stuff like organizing events and whatnot. I think it was determined as a "not now" thing, given that subteams can be spun up later if wanted. Perhaps we should revisit that.
What's to chill about? I very nicely asked you to look at the published measurements and then re-assess `petermonsson's` remarks.
https://github.com/kmcallister/sliderust
Perhaps you didn't mean to, but your comment sounded like you were trying to make a point in a really passive-aggressive way. Sorry if I misunderstood you. (I didn't downvote you, FWIW)
I'll be interested in your informed assessment.
Good to know. So say I want to program an app in Rust and use the keyboard, share sheet, and today view extensions using Apple's official SDK/iOS API's I'd have to work around and write those bits in either Obj C or Swift? But the rest could be in rust, correct?
Yes, I tried to go back and find out the route I took to get to them (with no success). I'm not sure how I even ended up there.
You can write it all in pure Rust using the `rust-objc` crate, but it'd be easier to write that stuff in ObjC or Swift for sure (at least until there are nice high-level wrappers for the iOS SDK). I think Rust is a good candidate if you're writing a multiplatform game (like me) or have some heavy number crunching or networking you want to do. It's not a good candidate right now for UI-heavy stuff. For example, Dropbox uses a shared C++ core across all their mobile (and maybe desktop?) apps, with native code for the UI. We need Marmalade for Rust!
&gt; Would faster regex matching need a DFA-based engine? Is there any project improving that? It's on my list of things to do, but I want to nip some of the lower hanging fruit first. Here's the DFA issue: https://github.com/rust-lang/regex/issues/66 carllerche has written this, which I hope to find a way to use inside of `regex` for the DFA implementation, but I haven't yet investigated thoroughly: https://github.com/carllerche/automaton 
I like it, you just sound crabby.
Basically, unless you're willing to take both the Rust and C versions of the program and turn them in with your name on them saying, "this is a good comparison of these two languages", then what good is the benchmark in the first place? I think everyone who uses the site should identify discrepancies like this, as the results of the benchmarks is not actionable information until the comparisons are legitimate. Then again they do call it the "benchmarks game" -- perhaps there's something to that title. 
Nope, that's what I thought too. https://www.youtube.com/watch?v=IXuFrtmOYKg
Both your comment and another talk about documentation hosted at MIT. Can you point that documentation out to me? (I'm at MIT.)
Yeah, laundry eating can be pretty dangerous sometimes, not to mention embarrassing.
A mutable borrow can in general invalidate other pointers even when you can guarantee that accesses happen sequentially, like a vector being reallocated after exceeding its previous capacity when you push an element. And it's also not true when you have parallelism in play. So for these general situations, those rules are very reasonable. Neither are in play here, but rustc isn't aware of that. I will refrain of speculating how difficult or possible it is to add that. I guess the reallocation part won't happen at all when the data lives on the stack.
Agreed that all the safety flies out the window if data and its refs are not all on the same stack (which would also happen in a multi-threaded case as the stacks are separate). But you make a good point. It's almost like heap-safety rules are being applied to stack variables. In fact, that may be precisely what's going on that has me puzzled.
The problem is that you can't have two owned aliases to the same value in the same scope. That is, when you create `y`, you invalidate *all* uses of `x` for the remaining of the scope. [Here's a way to fix your program](http://is.gd/cr4gZm), by putting `y` into its own scope (at the end of the scope `y` gets dropped, allowing you to use `x` again). edit: perhaps this is a wart, and the compiler should be free to implicitly create new scopes, kind of a "scope inference"? -- but then dropping would be hard to predict (today it happens only at the end of the scope, which makes Rust code easier to read). Actually, it's a bit unclear to me, is this the so-called "lexical borrowing"?
Thanks! 
Good points. I may have misunderstood you before, sorry about that.
Thanks. For what it's worth, that went up in August 2014 when we deployed a release of Rust 0.11 for on-campus use. (There's also a v1.0alpha at http://web.mit.edu/rust-lang_v1.0al/ ) I know the guy who deployed it, and I can ask him about it. No promises, though. \[Edit]: We're experimenting with taking the docs down, and waiting to hear if there are any internal complaints.
Give it time.
Nope. There is at least 1 in AppStore already.
&gt; I don't remember seeing any announcement that performance was the main focus of Rust 1.0 From http://www.rust-lang.org : &gt; Rust is a systems programming language that runs blazingly fast Meanwhile its tests are on par with Java and Go. 
Yeah, it's kind of unrepresentative. Probably all languages could use SSE routines and if they did, the tests would become uninformative. 
A monomorphic IR sounds very interesting and useful!
The `objc` crate doesn't have support for ARM yet, so it'll work on the simulator but I don't think it'll compile for device. I've been meaning to get a cross-compiler set up so I could start testing it on iOS. As for wrapping ObjC's frameworks, I've been trying to wrap Foundation with a safe interface in https://github.com/SSheldon/rust-objc-foundation, but it's... a lot of work :P
This is .... this is .... .... .... I really can't find the adequate words to express my feelings about this. :D 
Cheers！Love this idea！
So will LLVM or GCC actually compile SSE intrinsics for non-x86/x86_64 platforms?
+1 for Frank's stuff. I am of the opinion that we can do much better than just porting Spark to Rust, Differential Dataflow is a great example of that. I do think that shipping .so's over the wire + dynamic loading is easy enough to manage, and can get us most of the way to distributed computation, but I don't think the benefits of remoting closures outweigh their costs :) 
Rust can certainly lend some performance to much of what Spark does, we don't even need a cohesive framework to do it. Here is a vague categorization of things that we can use for a distributed data ecosystem: * RPC - We have cap'n proto RPC which is fast and stable. * Database Interop - Right now this isn't horrible. we have a stellar Postgres API, decent MySQL, a great wrapper around a horrible C++ API for Cassandra, also there are young but decent HDFS bindings around libHDFS. I would also love to see bindings for libRADOS. There is some organization underway to provide more semantic support for relational databases (https://github.com/rust-lang/rfcs/issues/798). There are also bindings for HyperDex and LMDB, to name a few. * Tabular Data - I would love to see a Pandas/Dataframe clone in Rust, this would be one of the two things that I think we'd need to rip-off directly :) * Indexing - Lucene is the other thing I think we need a direct replacement for in Rust, not a trivial task. * Caching - an in-memory KV store would be a treat to build in Rust, I don't know if anyone has undertaken this. BtreeMap + Cap'n Proto RPC would get you 80% of the way there :) * Direct Data Storage - Frank McSherry's Columnar crate could be fleshed out into a more general system as well. Also we have fantastic CSV support via https://github.com/BurntSushi/rust-csv. Also there are a couple projects with current leveldb bindings. * Visualization - Web Notebooks are cool, but Rust can do realtime, native data viz as well :). I think something done in https://github.com/mitchmindtree/elmesque would be fantastic. Collecting some of my thoughts on this has made me realize that we probably do need a project based around enumerating potential components (both existing and imaginary) and gluing them together into something more cohesive. 
Actually, it's much easier to curry when you have functions in infix notation, compare map (\x -&gt; mod x 2) ls or map (flip mod$2) ls with map (`mod` 2) ls But, I digress. I feel as though currying would be more confusing in the long run as compared to infix notation, but I think we both need evidence for our claims.
But you can implement locks using actors...? How can this be true?
If by "its tests" you mean the arbitrary selection of microbenchmarks following an inconsistent and unenforceable set of rules on a site that advertises itself as a game, then yeah, sure. :P In the meantime, the Rust developers regularly test that their emitted bytecode is bit-for-bit identical to what Clang produces, and the language itself provides none of the fundamental barriers to optimization that Java or Go do. Furthermore, Servo is posting performance numbers which are two to five times faster than Gecko, despite the fact that Gecko is a highly-optimized and mature C++ codebase while both Servo and Rust have large swaths of optimization avenues they have yet to pursue.
Random aside, many linux distros have a similar problem and a good solution. If each major release is accompanied by a name which is a word that is uncommon within the domain then searching is a lot easier. Ie. Debian wheezy. This also requires blog writers to include that word on each post, but just having an official version name would help.
It would help a lot if SEO techniques didn't involve making google's impression of the age of your page completely wrong.
Hah, great timing. I 'upgraded' to a nightly today to get access to this.
Huge -1 on infix calling. It's very confusing and just another syntax for something you can already do anyways. I think it would just contribute to more wars about code style and makes grepping for function calls harder.
Rust will teach/force you to think about ownership. Once you program in Rust for a bit you will internalize the borrow checker, and maybe create fewer dangling pointers in C :D
True, it would make it harder to grep for funtions. I hadn't considered that. As for your other point, since this is a loose suggestion, it is not limited to what I decribed. It could be used for a different purpose to method calls. I said this on the OP, as well as three other comments.
I would love to know this - I wanted to try out building for android but it broke `make check` for me.
I'm not familiar with Ruby, but this *looks* incredibly dangerous: all of Rust's integer types (with the exception of `usize` and `isize`) have fixed sizes. From what I can tell, all of your examples on the Ruby side use integer types with *unspecified size*. A quick glance at what I assume is the documentation for Fiddle doesn't make the situation any clearer.
I agree that it's worth fixing them, but trying to draw any useful conclusions from the benchmarks game is massively reductive. In other words, we have a friggin web browser in this language that's faster than its C++ counterpart--currently hundreds of thousands of lines of code--and people want to claim that we're slower than C on account of a neglected 40-line microbenchmark? That's not reasonable doubt, that's willful ignorance.
This would be awesome! But thinking about proceeding steep by step, I really believe that it makes more sense at this point to: 1) get a nice MPI wrapper*, and 2) get a nice shared-memory linear algebra library. 1) Requires interacting with the C Preprocessor which is doable but not trivial right now. 2) Requires HKTs and type-level integers if it plans to at least compete with C++ shared-memory linear algebra libraries like Eigen and Blaze (by building an expression tree). These problems can be solved (e.g. 1) with a script run before hand and 2) with compiler plugins, but no one has found a nice solution yet. Without these building blocks the barrier of entry into HPC is pretty high, since anyone willing to use Rust will very likely need to build these low level components first, and e.g. reimplementing Eigen is a titanic task.
The only reason we have to claim that the browser is faster than its C++ counterpart is because of its performance on a variety of microbenchmarks, so it's not clear to me why a disinterested programmer (who probably hasn't heard of Servo, but let's postulate otherwise) would think those were more valid than the ones on this site. Especially since AFAIK those numbers aren't publicly available on a site maintained by a third party. Again, I am not saying that these microbenchmarks are a good way of measuring Rust's speed--and anyone who has a good understanding of Rust's performance model knows why most of us don't care about the benchmarks on that site--but for those who are trying to determine whether it's even worth learning Rust in sufficient detail to find out whether its claims are accurate in the first place, making the numbers good will go a long way.
&gt;Doing something like that in rust would be... tricky. The hard part would be writing the right DSL :p (Or maybe you could just send binaries across?
This was actually possible in the past I believe - or maybe it was restricted to copying out of `x` even when it was mutably borrowed. But that feature allowed for data races once fork-join multithreading started being supported, so it was removed. It's actually safe, I believe, to allow immutably reborrowing the original data when it is mutably borrowed *as long as* the mutable borrow is confined to the current function. This wouldn't be unsound with the new `thread::scoped` API, because passing a borrow to a sub-thread would make the borrow extend for the lifetime of the scope object, which is larger than the closure's scope - so this kind of reborrowing wouldn't apply. One way to see this is that you can *always* call `mem::forget` on all the variables in a scope and then exit that scope (e.g. `return`) to clear all the borrows confined to that scope, *without* executing any code. Afterwards, the original data behind each of those borrows is accessible and valid, while being *entirely* unchanged. It follows that the data is *always* valid, and as such, observing it is harmless (assuming the mutable borrow is restricted to immutability when used at the same time as the inner immutable one). Such reasoning wouldn't have been possible before `mem::forget` was safe, but now the following example couldn't go wrong: fn replicate&lt;T: Clone&gt;(v: &amp;mut Vec&lt;T&gt;) -&gt; Vec&lt;Vec&lt;T&gt;&gt; { let mut out = vec![]; for x in v.drain(..) { out.push((0..v.capacity()).map(|_| x.clone()).collect()); } out } Because the length is zeroed by the `drain` iterator *ahead* of time to avoid access to any of the elements being moved out, in case the destructor doesn't run, the only meaningful operation on `v` is querying the capacity. In other situations, this feature can be a bit more practical: fn attract(a: &amp;Entity, b: &amp;Entity) -&gt; Vec3 {...} let mut vec: Vec&lt;Entity&gt; = ...; for a in &amp;mut vec { let mut accel = Vec3(0.0, 0.0, 0.0); for b in &amp;vec { // inside this loop, *a is immutable aceel += attract(a, b); } a.velocity += accel * dt; } While this is potentially sound (and not just an unproven idea), it could also be a source of logic bugs, when the use of a mutably borrowed variable is accidental.
At the current state of things, I would tactfully refuse. The current team has already done major damage to my efforts. I also believe outreach and diversity subteams to be an antipattern. They isolate that team work. I'm happy to talk about that at some point. 
Fasta c++ #5 use metaprog for the binary search.
&gt; we have a friggin web browser in this language that's faster than its C++ counterpart I'm not sure that's a fair comparison. They are written in completely different ways, right? One is highly parallel and has been written in a very focused way over a fairly short length of time whereas the other one is a lot older.
As an additional question: how's it going to be done in terms of language compatibility? I assume all Rust 1.x code will be build-able with a new enough version of the compiler (e.g. to get features added in 1.2 you'd obviously have to use the compiler version that supports those new features), but I'm assuming backwards compatibility is also extremely important? I.e. any compiler version in the future will be able to build Rust 1.0 code. What about Rust 2.0 if that changes something significantly (not saying it will, but if) - would you specify a language version when compiling. Would Rust 1.0 still be build-able, or would you need to use an older version of the compiler?
Just want to precise that overflow is defined to produce an *unspecified* value: - contrary to *undefined behavior*, it means no nasal daemons - however, it also means that you cannot rely on the value being anything specific, and it might even be bottom (ie, `panic!()`) which it is in Debug mode
&gt; Servo is already one of the fastest browser engine around Well, it also has a bleeding edge research-y structure and set of algorithms, so it's a bit of an apples-to-oranges comparison. &gt; In general, we should keep in mind that micro-benchmarks are rarely representative of the performances of real programs. Agreed; but with 1.0 out and the resulting publicity lots of people are looking into Rust and taking the benchmark results at face value.
Thanks.
This is a good thing, and ironically it's a reason I hate using smart/shared pointers in C++ - in my experience of maintaing some C++ code written by others, using them lets people be lazy and not care about defining the ownership of items, as it's not needed.
You were trying to be funny, but the redheads that I've seen at Rust meetups outnumber the women. If you have nothing to add to the conversation, then content yourself with adding nothing.
Yes, but I find that apples and oranges compare just fine. At least it's not an apple-to-lawnmower comparison. Regarding servo, yes, it's highly experimental, uses novel algorithms to more effectively parallelize rendering and so on. But I think it's relevant to point out that all of this works *because* of Rust's strong static guarantees. To recreate those guarantees in, say, C++ would be prohibitively expensive and probably require a completely new way to write C++ code, along with extra analysis passes. Which would be akin to implementing a bug-ridden version of half of rust within C++, badly.
About compilation speed: IIRC it is one of the higher priorities for some of the core devs.
How up-to-date are these resources?
Rust by Example is pretty good if you want to go fast.
No idea.
&gt; Ideally this is a job for the compiler - you mark a function as constant_time, and the compiler makes sure it won't emit code that run time depends on its parameters (or exits with a compiler error if it thinks it can't do that). [nadeko (github)](https://github.com/klutzy/nadeko) implements a `#[const_time]` attribute as an AST transform that translates Rust code into constant-time `asm!()`statements and doesn't permit array access at non-constant offsets. The last commits were about 5 months ago though so it doesn't seem to be actively maintained, but the idea seems practical (even if it feels a little bit weird.)
*This is awesome*.
The only real issue I see is constantly copying and re-allocating `html_table`; here's a [version that uses `Write` instead](http://is.gd/hmoKEt) to try and avoid the allocations. I'm not aware of a simple way of avoiding the *two* re-allocations caused by `str::replace`; ideally, you probably want something that produces an `Iterator&lt;Item=&amp;str&gt;` instead. **Edit**: Switched to "fixed backslashes" link.
He's trying to say that there are many programs faster than the provided Rust programs, and that the cited reasons don't apply to all of them. So, for example, saying that the Rust program is slower because it doesn't call SSE intrinsics directly isn't completely convincing: There are implementations in the benchmark that don't call SSE intrinsics and are faster than the Rust program anyway.
We're faster while supporting less festures though. You kind of swept that under the rug.
The only difference I can see is you removed back slashes from my code?
Oops; linked the wrong one. Fixed.
Could you breifly explain `.unwrap` to me, I see it all the time but don't think I fully understand what it does.
I think the best way is to use GMP integers for both Python and Rust. They are faster than Python's integers as well.
`unwrap` takes a value wrapped in either an `Option` or `Result`, and returns it. If called on `None` or `Err(_)`, it instead panics, crashing the program. So, in the case of `Option`, it's roughly the same as: let b = a.unwrap(); // ... is the same as ... let b = match a { Some(v) =&gt; v, None =&gt; panic!("oh no!") }; See also the [Error Handling chapter of the Rust Book](http://doc.rust-lang.org/book/error-handling.html#upgrading-failures-to-panics).
Thanks :)
&gt; Rust has regressed on some of these tests At least for `regex`, one possible reason why is that it used to use `regex!`, which compiles the regex to native code. On Rust stable, this can't be used, so it has fallen back to the dynamic implementation. Of the regex implementations I'm familiar with, Rust's is probably closest to [Go's native `regexp` benchmark](http://benchmarksgame.alioth.debian.org/u64q/program.php?test=regexdna&amp;lang=go&amp;id=1).
I'm just riffing here, but maybe we can apply differential dataflow to rustc :) I mean, we've got the type system, which is a graph of contraints, then the control flow graph.. we just keep them live in RAM and make incremental changes to the graph as code changes. Should be easy, right? I'm thinking a Sunday afternoon project to get it working :P
Sorry for being a bit unclear. I'd like the link to reddit.com/r/rust on the top left to be unhidden, for the sake of site-wide consistency: while the giant hitbox on the right would certainly be enough (and better than the normal small link on the left) in isolation, it requires me to do something different to perform the same action depending on whether I'm in /r/rust or another subreddit, making it something of a UX papercut. Like other users, I've also had years to acquire a bit of muscle memory / mental association as to how to go to the subreddit home, which shouldn't prevent UIs from being revised in general, but makes the inconsistency somewhat worse. While other subreddits also have a link to the subreddits home on the right by default - something I didn't learn until yesterday - several subreddits I subscribe to hide it for whatever reason, so even if I tried to switch my automatic action to finding the link on the right and clicking it (but the big R here is in a different position anyway), it wouldn't work reliably.
Are we sure it's not? There has already been feedback on twitter about people rethinking the community because of this. starkat mentioned something similar on the thread above.
&gt; &gt; Collecting some of my thoughts on this has made me realize that we probably do need a project based around enumerating potential components (both existing and imaginary) and gluing them together into something more cohesive. Sounds like something to be done with the Piston model: loosely coupled components, abstracted away with traits, that are pluggable or can be used standalone. Eg. how you can select between [Gfx](https://github.com/PistonDevelopers/gfx_graphics/blob/89e506bb8242e1e5f4d9ce025c00fbfa6d80f2d9/src/back_end.rs#L220) and [Glium](https://github.com/PistonDevelopers/glium_graphics/blob/d9c00b391702afff2b482044d95071a69df3f77c/src/back_end.rs#L114), or [Glutin](https://github.com/PistonDevelopers/glutin_window/blob/4eed79ca7d8f278b02001bb9ad6cb114923d4189/src/lib.rs#L128), [SDL2](https://github.com/PistonDevelopers/sdl2_window/blob/d9dd95cadd5c8de09ddb163812761738b999b3f4/src/lib.rs#L244) and [GLFW](https://github.com/PistonDevelopers/glfw_window/blob/5c9140836df68bad87518e5a9e30f4cd5e45b3a1/src/lib.rs#L196).
I created this page a few days ago. I'll try to filter out all outdated info. Of course, if you have any good links, please help (us all) :) :) Best regards!
Yes, so Servo works because Rust has better type safety; but it does not help much to prove *performance*. I do think there is no reason for Rust to lag behind, and can actually foresee a bright future if one manages to: - build on aliasing information - build on const-ness information (`&amp;T` in Rust guarantees so much more than `T const&amp;` in C++!) but unless you compare the same algorithm, you are not comparing the performance of the languages themselves.
I keep thinking Rust could spawn some exciting infrastructure components - think Redis, dbus or the 'next mongodb'. That would be a good story to tell.
You'll probably wan't to use [the log crate](https://crates.io/crates/log), which is maintained by the rust team, for the actual logging. You can then choose between a number of different backend implementations, including [env_logger](https://crates.io/crates/env_logger) and [log4rs](https://crates.io/crates/log4rs). It should be very easy to switch to a different backend in the future should you find the one you start with unsuitable. It is also very likely, I think, that most, if not all, future logging libraries will be based on the log crate.
Yeah I tried to test it on a Linux VM. I also had it compiling, but got OpenGL errors when running it. I'm guessing (hoping) it was just because of virtualisation issues, but I can't know for sure.
Rust is probably one of the more challenging languages to use as a beginner; it's not really what I'd call a simplistic language. Luckily, the compiler is seriously good and will help you with a lot of the complexities. However, and I'm sure this is probably not what you want to hear, but as a beginner it's not really about the tool you use to learn it's more about getting stuck in to learning. If I was to make a recommendation (and this might fall on deaf ears in this subreddit), I'd say you should stick with C for learning OS internals stuff. Mainly because that's what most operating systems are written in and what most books about OS internals will be about. Once you've learned C you'll understand why the things that Rust provides are the way they are and truly appreciate the safety you get from them. But again, that's just my opinion. If you want to learn, get stuck in and learn and don't worry too much about the tools. 
I know c(from stephen kochan's book) and now have started learning from ritchie's book and also cormen's algo book,what should i learn after that to understand rust completely ?
Not that I've heard of so far but I don't find that overly surprising, given Rust's youth. I suspect, before we see a `c2rust`, we'll see more work put into making the FFI more comfortable since that has more immediate benefits for expanding the sphere of "comfortable to write in Rust" things as quickly as possible.
&gt;Side note: what's with all the redstone and pistons and all -- do they actually do things? Could be wrong, but I believe hematite only renders MC 1.8.* maps to a point and doesn't (yet?) have functionality. Still - its had amazing progress and can't wait to see where it goes.
&gt; there's this C static analyzer, Frama-C, that can verify whether a function is constant time[2] regarding certain parameters. Sadly that doesn't quite work either. Not due to that program, because even writing something in ASM won't necessarily make it constant time. The issue is that modern processors execute instruction massively out of order. See [this](http://blog.erratasec.com/2015/03/x86-is-high-level-language.html) link for more details.
At this point you're going to want to just start writing code, so here's my suggestion: Come up with a project, and first write it in C using the knowledge you've gained from those books. When you've finished, and are happy with everything, rewrite it in Rust. Then you can compare the two, and see what works well in each language and which bits you like or which bits you don't like. It should give you a good understanding of both languages because you've had to think about the project from two very different perspectives. Coming up with a project idea might be tricky, and you've got to make sure it's both interesting enough to hold your attention for many hours, but also complicated enough to experience the idiosyncrasies of each language. I had a quick google and there's some decent ideas at the links in [this page](https://www.reddit.com/r/learnprogramming/comments/2a9ygh/1000_beginner_programming_projects_xpost/) so pick one out and just get stuck in. 
Yeah, it seems like it -- I was wondering why they were there in the first place :P It doesn't seem to do water either; though when I was trying I had a -j4 rustc build running in parallel so that could just be my computer refusing to do it. It's still pretty awesome though! :D
[There is a very good criticism of that post on Hacker News.](https://news.ycombinator.com/item?id=9265613)
I hate to pick on you, but this would have been a very good time to talk about `Cell`. By far the thing that confuses people the most about "single-threaded shared mutability is dangerous!" is "but what about if I just have a plain integer?" and IMO it's important to explain to people that there is absolutely nothing dangerous about that, and Rust has a primitive to address that.
&gt;But that feature allowed for data races once fork-join multithreading started being supported, so it was removed. Oh wow. I haven't seen how this works for forking yet: without reading it, that does seem like a problem, but that's an inherently problematic design pattern for data-safe threading in general. I'll have to go check that out: I'm surprised it's supported. &gt;It's actually safe, I believe, to allow immutably reborrowing the original data when it is mutably borrowed as long as the mutable borrow is confined to the current function. Is this also true for multi-threaded scenarios such as you pointed out? I'm blindly guessing forked threads receive immutable references, which means the forked thread isn't actually identical, but I'll do some homework. Your final example looks to me like it should be safe. It will take a while to train myself to see the "what can't the compiler guarantee is safe" code. I'm thinking the call to attract() will fail though because there's already a borrow of `a` in the outer scope? Thank you a bunch for helping me wrap my brain around this!
I'll add a note about `Cell` in an edit block. FWIW one of my next posts is about the various pointers and wrappers in Rust, and the cell types were going to be featured there heavily :)
The funny thing is though if someone says &gt;All the leadership is males and presumably predominantly white males so I won't help or try to become leadership are they not the ones being racist and sexist or at the very least making those assumptions of us? (provided of course that there is no rust conspiracy to keep females out of leadership)
The compiler is correct; `barhi` takes `&amp;mut self`, and then you call `self.bar.hi(&amp;mut self)`, which means you are passing a `&amp;mut &amp;mut Baz` to `bar.hi`. If you fix that error (by simply passing `self`, e.g. `self.bar.hi(self)`) the borrow checker will complain; because you are borrowing `self.bar` immutably, you cannot use `self` until the borrow expires.
No, there's no water yet. Maybe now that we don't have to spend so much time chasing nightly more development will start again.
Sounds good! 
Re. SIMD instructions It's reasonably easy to convince llvm to use mulpd/addpd etc for two of the three coordinates rather than mulsd/etc, ~~but by my vague and rather noobish reckoning this will only save 1/3rd of the time for N_body. (i'm guessing half for mandelbrot without having looked at it)~~ ~~Where do the C++ implementations of n_body get their other 40% improvement from?~~ At the end of my fumbling I discovered that the implementation on your github seems to use SSE3 reasonably adeptly when compiled by 1.0.0 on my system (with core2 as target). The resulting binaries only differ by about 30% runtime on my system.
Isn't that a refinement from rustc though? I mean, from my understanding: - Rust: in case of overflow, the result is unspecified (and might be bottom) - rustc: in case of overflow, the result is either two's-complement OR a panic (with panic guaranteed in Debug) The latter is compatible with the former, but another compiler, or indeed a future version of rustc, could work differently.
Right, so such differences can't be explained in a couple of lines of code. However, inserting a few items into a collection or an array, and looping over them is such a simple construct that an experienced developer will just need to look at such code once and immediately start to develop a familiarity with the language. Here is an example I was thinking of: http://learnxinyminutes.com/docs/c++/ As a Java developer, I can quickly pick out the lines I need to pay attention to and lines which make complete sense to me. I don't have to read three or four chapters of a book to start to get the same feeling.
Looks like there is a rust entry on there. http://learnxinyminutes.com/docs/rust/
Wow, can't believe I missed it! Thanks.
I just (I think) found a bug in libcuckoo that is basically an instance of this same thing; it relies on a hazard pointer which is stored in a shared thread local variable. If the equality predicate that is passed in also calls a hash function, the hazard pointer can be overridden, leaving it unset--leading to use after free if something calls `remove_unused` before the first function is done. While people might initially believe that the problem here is multithreading, it's actually not. The problem is overwriting a *thread local* variable--the multithreading is actually totally incidental to this problem. If it used a `RefCell` style borrow flag, as would have been required in Rust, I think it would address the issue. I bring this up to point out that yes, this is a problem in actual libraries written in modern C++, and yes, it is subtle and easy to miss if you aren't looking for it. It's important to stress that examples in posts like this are toy examples-- in the real world things get way more convoluted.
Virtualbox doesn't support FBO's which almost everything uses nowadays, so it's probably that.
&gt; Note: Str and Int are variant names which I chose; they are not keywords. Additionally, I’m using “associated foo” loosely here; Rust does have a distinct concept of “associated data” but it’s not relevant to this post. What do you mean with *associated data*?
[The log crate](https://crates.io/crates/log) doesn't support method name yet. I was able to add support for file name and line number with custom logger [Rust: Custom Logger with time-stamp, file name and line number](http://joshitech.blogspot.com/search/label/logging)
Excellent article, I've linked it to some of my coworkers to whom I gave a talk introducing Rust on Friday. I like the in-depth explanation of why we should eliminate shared mutability even in a single-threaded environment. It's also interesting to the admission that Cell/RefCell can sometimes be an escape-hatch for working around the borrow checker. I had suspected as much previously, but don't yet have any practical experience using either in anger. One grammatical improvement that could be made: &gt; Mutable aliasing is important to fix, however because we can make a lot of assumptions about our program when there are no mutable aliases. You probably want to move the comma to after "however", or just remove "however" completely.
 fn main() { let mut file = std::fs::File::open("file.txt").unwrap(); let mut stdout = std::io::stdout(); std::io::copy(&amp;mut file, &amp;mut stdout).unwrap(); } Filesystem manipulation operations are defined in [std::fs](http://doc.rust-lang.org/std/fs/), core I/O functionality is defined in [std::io](http://doc.rust-lang.org/std/io/). In particular, look for [std::io::Read](http://doc.rust-lang.org/std/io/trait.Read.html) and [std::io::Write](http://doc.rust-lang.org/std/io/trait.Write.html).
Don't call unwrap on files. Except in very rare cases you don't want to let the program crash when the file is not present, not readable or has corrupted data and when it's about IO you can be sure that at some point there will be a failing operation.
http://blog.burntsushi.net/rust-error-handling/ can be read for understanding how error handling can be done in rust.
The reason the example code doesn't work is probably what you're looking at is based on an assumption that you are using them in a function that returns `Result&lt;T, E&gt;`. In that case, you can replace `try!(...)` in the example code with `.unwrap()` to get the similar effects. The former propagates the I/O error to the parent function, whereas the latter just crashes the program. In a small script-like program, I think just crashing is OK.
Log4rs sounds like exactly what you asked for. It's low downloads are likely because it's only useful in applications: libraries don't pick a Logger, they just use the log macros. 
Don't you mean [this?](https://doc.rust-lang.org/book/associated-constants.html)
Nice! PM me when you're ready to share, I'd be curious to take a look :) Heh, it's nice to know that the last few years of Ruby, Python, and javascript haven't been too damaging! 
I'd call it intended and correct. Buffering stdout also happens in C. That's generally a good thing, as you might be building up a line in parts (a common enough case). Either flush when you know you should or set buffering off.
&gt; but not print!(), which would require anyone who wrote (rather common) code like mine to add the line io::stdout().flush().ok().expect("flush() fail"); after all of their print!() calls. Others have commented on why the behavior is the way it is, but if you want "flush after print," then you don't need to write out an explicit flush all the time. You can [define a macro](http://is.gd/oInzPM): macro_rules! printfl { ($($tt:tt)*) =&gt; {{ use std::io::Write; print!($($tt)*); ::std::io::stdout().flush().ok().expect("flush() fail"); }} } fn main() { printfl!("Hi"); printfl!("Bye"); }
How about this? main.rs: https://bitbucket.org/iopq/fizzbuzz-in-rust/src/b5e7b36cdb2ac0e88e1802a0b3547f90184f7e09/src/main.rs?at=master lib.rs: https://bitbucket.org/iopq/fizzbuzz-in-rust/src/b5e7b36cdb2ac0e88e1802a0b3547f90184f7e09/src/lib.rs?at=master it had a trait in it too, but that trait only did what the new `Into&lt;T&gt;` does, so I just refactored it to use the new stuff
I think this is more likely a real problem. Python also flushes when `input()` is called. Rust may have to follow a similar strategy. EDIT: I opened an issue proposing this behavior. [See this](https://github.com/rust-lang/rust/issues/25555).
Ah okay I see what you mean. Well it wasn't my intention to present myself as the be-all-end-all of making Ruby work with Rust. These were just examples that work as a proof of concept.
Kate used to be my go-to editor, and I still use it on large files sometimes. I'm glad to see Rust support for it.
Thanks! (fixed)
Congratulation for the entire community and for the core developers in particular ! This is a very great achievement !
Thanks for this crate. This is exactly what I have been looking for.
Which one is it?
I found [Rust by Example](http://rustbyexample.com/) to be a very well-written intro and a fast read.
You should get a 3d view of some scene, actually.
something like this? http://learnxinyminutes.com/docs/rust/
to_string is strictly the slowest, because of its blanket implementation. However, if you're not doing it in hot code, who cares. 
There is also let e = format!("hello") 
While bugs (including crashes, hangs, etc) are bad, it doesn't follow that statically eliminating them is good. The case you have to make is that the cost of fixing it (ergonomics, complexity) is lower than the cost of the bugs. To me, the frequency and severity of bugs due to mutable aliasing is nowhere near the top of my list of actual, real world issues when programming. If you can do something simpler to ensure there's no memory corruption, but leave things wide open for hangs and crashes (like c# or java does), is that a better tradeoff than to require draconian restrictions to eliminate the bugs entirely? At some point you have to triage and decide how much you want to sacrifice in terms of usability and ergonomics in order to eliminate a particular bug. E.g. you could eliminate general looping and recursion in order to get rid of all hangs (but your language would no longer be turing complete). IMO the problems that are occasionally caused by mutable aliasing are just not that big of an issue to motivate disallowing them entirely. The cure is worse than the disease. 
&gt; You can't destructure a Box Unless I misunderstand, I'd say you are wrong here. While unfortunately behind a feature gate, destructuring a box is very possible to do. http://is.gd/DnnAvc
Yes - there are absolutely many problems with shared mutability. You listed some of them which can be found in many C++ beginners projects. But after a while you know how to do it correctly. However there are also some use cases where you want shared mutability. E.g. typical UI libraries use it a lot - e.g. they have widgets linked to each other in tree structures, they have events dispatched into event handlers which have references to their emitter, etc. Also the underlying eventloop have similar requirements. I would still find it nice when somebody would show how those things can be nicely handled in Rust instead of showing the most stupid errors all-over again. `Rc&lt;RefCell&gt;` is there, but I don't know if it's a good thing when this dynamically starts to crash because you have some recursion and it might still not work properly with Trait Objects :(
I agree with your general point, but just want to add thst turing completeness really isn't a positive feature in and of itself. Turing machines are a engineering impossibility so having a language be able to describe them is largely useless. Now, whether we can make another less general scheme that's still as easy to write programs under is an open research problem, but it just grates with me a little to see turing completeness lauded as a good thing.
Something about Rust that always gets me is my attempt to use `writeln!(stdout(), "foo")` without having the `Write` trait imported - it fails telling that a particular method is not supported. Then usually I start reassuring myself that I already did this, and look at other projects to find what exactly I have done to make it work (i.e. `use std::io::Write;`). Also whenever I want to work with borrows stored in a structure, or want to return borrowed values, an alarm goes off in my head warning me about possible clashes with the borrow-checker. Even though I think I have mastered it for general use, I still have trouble making my own APIs which use borrowed values for reasons of efficiency. Nonetheless I think that one day I will get around that as well :).
That was interesting, thanks for sharing! I've seen a lot of Fortran and C in theoretical astrophysics, but then a lot of new projects use C++.
Yeah, of course, there are legitimate uses, and in those cases Rust uses some combination of Rc, RefCell, Cell, Arc, and Mutex depending on your needs. Or you can use raw pointers or `UnsafeCell` and forgo the dynamic checks completely if you're feeling adventurous :) But in these cases too, you generally still want an rwlock pattern, even if it is dynamic. Which is sort of the point of RefCell and friends. Yeah, our story regarding trait objects needs to be improved. This is planned, iirc. Regarding dynamic crashes, more often than not that's a bug (at least, in Servo the ones I've seen point to a deeper problem). Invariants will get invalidated and stuff can take a bad turn. But if you're confident and don't want to crash; `UnsafeCell` is there for this. There certainly are legitimate casees when you have highly recursive code that needs to mutate a lot, with no invariants expected from the mutable object. That's why `unsafe` exists, if you think you know what you're doing, go ahead!
Note that if you're using a recent Cargo, the suffix should be [stripped automatically](https://github.com/rust-lang/cargo/pull/1540). (I notice that the binary is named `perceptron`&amp;mdash;not `perceptron-rs`&amp;mdash;so the patch is working!)
Since he is complaining about "unstable features", he is probably using the stable version. So no feature gate.
This won't work well when generics come into the picture. In my experience teaching Rust the _hours_ bit is not due to this specific feature, but the general ownership thing. A lot of people program the C way (returning pointers, etc) and that doesn't work well. IMO this isn't something Rust is bad at, it's something programming in general is bad at. There's a reason why the FP crowd is so pumped about purity. Mutability causes problems. Going the full FP way also restricts you (especially when you want to write zero-cost things), but Rust seems to have stricken a balance. IMO.
&gt; **No header files** That is indeed something I miss as well. The idea is probably to have just the traits in one file and all the details of the implementation can then be where ever you want. But I don't want to first specify a trait for a simple `struct Foo` + `impl Foo`, which currently results in all the interesting method definitions for `Foo` being in the middle of all the logic in the `impl` block!It would help if you could declare stuff in one place first, but it seems that is a not possible: struct Foo; impl Foo { fn abc(&amp;self) -&gt; bool; // Not possible fn bar(&amp;mut self) -&gt; u32; } That is the rust way of keeping declaration and definitions separate, without using a trait?
Because `ToString` serves a different purpose. `Into` and `From` are for types that are meant to be converted to `String` while `ToString` is for all values that are meant to be displayed. E.g.: i32 will probably never implement `Into&lt;String&gt;` while it already implements `ToString`.
**Cargo** should pass through all arguments which rustc suggests in error output, e.g. when a failure suggests `help: pass '--explain E0004' to see a detailed explanation` then `cargo build --explain E004` results in Unknown flag: '--explain' Usage: cargo build [options] And `cargo build -- args for rustc` does not seem to work
great to hear. Whatever official efforts there are, I was guessing the community might be able to get further too now that breaking changes are out of the way
That `Write` issue is actually something that can be fixed in the macro directly. EDIT: I'm preparing a patch right now.
* Cargo is created and maintained by the Rust team. Its development goes hand in hand with Rust. (Though, rustc does not depend on cargo.) * Speaking from experience, cargo handles almost everything. Interacting with rustc directly is really out of the question, you're much better off putting a makefile around cargo if you need it. * You can specify dependencies to crates on github directly, and you can also override the path location of dependencies independently of the repository if you'd like. The cargo guide has taught me everything I know about cargo; if there's a specific question I have.. usually I'll look at someone else's repo and see how they do it. It would be nice to have an "Advanced Cargo Guide" of some sort.
The distinction also exists in their functionality. to_string() always returns a String. into() returns... well, it depends on the context. You cannot parameterize like into::&lt;String&gt;() because it's not a type parameter for the function, it's part of the trait impl.
If it's a toy I would recommend using a nightly, you have far more features (including box destructuring) in the nightlies. If you're writing a library for others to use, then trying for stable is better.
&gt; Variant **enums** A nitpick I have is the need to derive from `#[derive(PartialEq)]` or implement it when using `==` on ONLY those parts of an enum which are flags only, i.e. the non-data fields. This will not work: enum Abcd { AllGood, BadData([u8; 100]), } let a = Abcd::AllGood; if Abcd::AllGood == a { // not working, and #[derive(PartialEq)] is not present for [u8; 100] } It is especially strange given that `if let` fixes it, but looks strange since there is no destructuring happening. if let Abcd::AllGood = a { } 
Thanks for the feedback :D I nearly sprayed hot chocolate all over the place on reading that Go comment :P That being said, Go is actually pretty nice, though I won't be using it in the forseeable future sicne everything I want to do can be done equally or better in Rust. &gt; There were a lot of unstable features that I wanted to use but couldn't. Use a nightly :) If you're writing a library, then try to stick to stable, but while learning I recommend the nightlies. &gt; I spent many bitter hours fighting the borrow checker. Hah. I used to hate this sooooo much at first. But I feel that eventually this made me a better programmer both in C++ and in languages like Java. &gt; No header files to look at and grep through. Rustdoc has hoogle-like search support IIRC. You can search for a lot of things easily. Not sure how much is supported though. &gt; crate install doesn't exist? Really? Plus I don't like that my directory structure is dictated by the build tool but maybe I'm just grumpy This would be a good addition though we need to decide what it does. Probably copy to bin. The directory structure can be changed; you can specify custom paths in the toml file. Similarly you can specify custom paths in the module substructure. Even do [crazy things like this](https://twitter.com/horse_rust/status/517408273750704128), though please please don't do that. &gt; All the type inferencing often left me forgetting what type a thing is I personally find it nice and clean, but I can see how it can be annoying. Of course, you can use explicit types (even explicit types with `_`s in them for partial inference) wherever you want. Once we have type ascription you can put types almost everywhere, though you don't want to. &gt; So many times I used a semicolon when I should have omitted it This is a diagnostics issue that should be improved. I'll try to work on it some time. I really want to fix Rust diagnostics and make them awesome, though amongst all my other things I hardly get time. &gt; The choice of Pascal-style varname: Type syntax baffles me when so much of the rest of Rust is C-like. Note that the C syntax sort of needs a type or a placeholder to be used in all such statements. Rust allows you to leave it off entirely, which is done often, so something that doesn't use `auto` or `_` is nice. Side note: While Rust looks like C/C++/Java, a lot of its programming style and design is functional. The C style is because you want C programmers to actually try it, and it helps that there's no additional barrier. &gt; Is it just me or is the I/O library missing a lot of features? Agreed, and I think improvements are planned. Otherwise libraries like mio are useful here. &gt; Can't return closures without boxing them Planned. Probably something about anonymous return types. &gt; Can't return a FnOnce closure Planned, and behind a gate. &gt; You can't destructure a Box, Gated (the `box` keyword). Hopefully once we get working placement new and stuff this can be ungated. &gt; I spent hours trying to convince the borrow checker that my read-only borrow from a RefCell Interesting; I'd like to see this situation. Borrow checker diagnostics are pretty good at fixing such things for you with suggestions, and I wonder why this failed. But yeah, it can be frustrating at times. &gt; My conclusion -- and this is where I'd be interested in your opinions -- it that Rust really doesn't strike me as 1.0 quality quite yet FWIW Rust 1.0 just meant the first release that would be backwards compatible. A lot of libraries are skimpy or nonexistent due to this -- there is work to be done on them but a stable API must be finalized. Same goes for many features; they can be added backwards compatibly. I totally agree that stable Rust is not really "complete" as far as actually using it goes; though this release lets some people use it depending on their needs. Unstable (nightly) Rust is actually pretty good; for example the features and libs come together pretty well in Servo, but it's .. unstable, so using it in production is ill advised unless you're confident you can pin to compiler versions and put the effort into upgrading as needed. Now that 1.0 has happened and there's constraints on what can be done (no more discussions veering off into "but what if ... &lt;something that changes everything entirely&gt;"), I expect that these APIs and language features will evolve more rapidly. Comments [here](https://internals.rust-lang.org/t/priorities-after-1-0/1901/) would be appreciated. &gt; I'm really excited to see what comes down the pike There goes my hot choc. _sniff_. I know this probably wasn't an intentional Go joke, but after reading your other Go bullet point this put Go on my mind :P &gt; TL;DR: Rust no one. Rust, but verify. 
Indeed. OP complains about macros (hygienic macros, no less), stating: &gt; Eschewing macros was one of the best trends in programming language design from the 90's. But then she/he wants *header files*, of all things?! I'm baffled.
This is why I kinda want custom literal suffixes. "This is a String"S "This is a &amp;str"
Maybe not (others have tried before). writeln needs to work on both a formatter and on W: Write.
Yeah, I'm having some trouble trying to make that macro call the `std::io::Write` method directly, due to `core` using a different trait and the `Formater` stuff. But having the macro include a import of the trait at least seems doable.
&gt;&gt; So many times I used a semicolon when I should have omitted it [...] &gt; &gt; This is interesting, usually we get initial complains about the leaving-off-the-semicolon feature existing at all, but this is the first I've heard about about complains about it being hard to use due to forgetting to leave of the semicolon. All I can say is that the syntax behaves very consistent and you'll most likely get used to it quickly. I've been using Rust for two years now and I still hit issues with this - the error messages need a lot of work, for example - https://github.com/rust-lang/rust/issues/22216
&gt; `ToString` is implemented for all types that implement `Debug` Not `Debug`, but `Display`. See: http://doc.rust-lang.org/std/string/trait.ToString.html
It is matching, yes, but you usually use `if let` for the destructuring part. And without it `Abcd::AllGood == a` is more intuitive and looks nicer, but of course I have no idea if it would be easy to implement or contradict some general language idea.
[As I pointed out elsewhere](/r/rust/comments/36ce52/reflections_on_a_weekend_with_rust/crctrxe) here, it is the best inline-documentation you can get and it separates the important from the irrelevant stuff. Also, no fighting with doxygen or hoping some external docs are up-to-date.
&gt; Semicolons are easily overlooked FWIW, I was also initially dubious around semicolons for this reason, but (as far as I can remember) have never encountered a bug caused by adding/removing a `;`: having strong static typing means any problems with semicolons are caught during compilation. The worst part of it is the diagnostics for them can get quite confusing&amp;mdash;e.g. [#22216](https://github.com/rust-lang/rust/issues/22216) and [#24889](https://github.com/rust-lang/rust/issues/24889)&amp;mdash;however this is something that will be improved (relatively soon, I hope).
Thank you for that recommendation. Part of my goal in using the official release rather than the nightly was to evaluate Rust's readiness for non-toy projects that I might want to work on, so I constrained myself in that way on purpose. But totally get your point.
&gt;being put on a project already using it ;) HA! That's the same reason I had to poke around with it. Now that being said, I just got done taking a class where we implemented a REST API in Python/Flask and Node.js. While they weren't sizable by any means, I did get a feel for their advantages. Even the Ruby project I was put on at work required me to slightly modify the data structure, and that was pretty easy thanks to dynamic typing. The thing that bothered me is I just kept finding myself saying "What can you do better than any other language except confuse me with your dumb syntax?" and not finding a real answer. To me it just seemed too similar to Python to justify using, but maybe that's bias getting in the way again.
Yeah, that makes sense. I personally use Rust as a Servo contributor, as a rustc contributor, and for personal fun projects. The first one uses most of the unstable features, the second one obviously uses unstable features, and most of my personal projects are compiler plugins and those primarily rely on really, _really_ unstable features (i.e. compiler internals). So I'm pretty content with running nightlies. It's more fun that way ^_^. But yeah, if you want to evaluate stuff you should definitely try stable first. But now that you've come to a conclusion, you can come to the ~~~dark~~~ nightly side and enjoy the cookies!
Thanks for your comments. &gt;&gt;Eschewing macros was one of the best trends in programming language design from the 90's. &gt; I'm not sure if this statement is true. There are a lot of new languages that has macros (Clojure (naturally!), Scala, Julia, Nim come to mind, but there are others). Of course you're right, placed an EDIT above. And I even know some of these languages. I was thinking Java, C# family of languages. &gt; Macros are a very useful tool to reduce boilerplate. It's C-style preprocessor-based macros which are being discarded, but not hygienic AST/TT-based ones. I'm all for reducing boilerplate but I still maintain that macros can be easily abused in practice, especially when you do things like place return statements / control flow inside of them, it becomes hard to reason about your function's control flow. &gt; I'm not sure what you mean but all references RefCell return are intentionally bound to the lifetime of the corresponding guard and not to RefCell itself. RefCell uses guards to enforce borrowing rules at runtime; "extending" lifetimes of produced references violates these guarantees. Using unsafe to circumvent this is bound to lead to panics in your code. I'll try to put together a playpen that captures my issue in greater detail. It was an issue where returning the borrowed thing was allowed until I simply added the RefCell immutable borrow, which should in principle be no different. But I concede that I'll probably end up learning that you're right and I'm doing something horribly wrong. 
Note that `rustdoc` Just Works(tm) for almost anything you feed to rustc. But valid point; header files give a good idea of the API in textual form. 
There is rustdoc which comes with the Rust distribution. It generates docs like these: http://ironframework.io/doc/iron/ and it's easy to update the docs on every successful build (this project does just that). 
&gt;Can't return closures without boxing them. This should do whatever type erasure magic that C++ std::function does In C++ closures can be returned from functions without "boxing" them: // Function from () -&gt; unspeakable type auto a_closure() { int a = 3; int b = 2; return [=, &amp;b]() { return a + b; // b will dangle, yay! }; } auto i = a_closure()(); // this will sometime crash :) I assumed that one can do the same thing in Rust but without the danger of returning a closure containing dangling references. Now that I think of it, one cannot write the return type of this function. What is the safe-equivalent code for this in Rust? (without boxing the closure in a std::function/without erasing the type of the closure). 
Now I wanna take an axe to choice parts of the rust name resolution code now... Guh, D never does anything like that! Thanks a whole bunch, awesome person.
&gt; You can't implement Copy for something that would be unsafe to just memcpy This is the key insight I was missing. Thank you. &gt; I believe the reason the box_patterns is an unstable feature is because the Rust developers are planning to rewrite that into something that will work not only Box, but also an Rc, etc, hence the unstability. I hope this is true because that would be *awesome*! &gt; I think that "1.0 quality" is not really black and white. Totally valid point!
There are two confusing things about Rust's module system: 1. what `mod` actually does, and 2. absolute vs. relative paths. They cause *so* much trouble, but come what may, we're kinda stuck with them now.
Like... How do you fuck this up? &gt;.&lt; I mean, I guess it makes sorta sense that default path is local, but D at least tries *both* and reports an error only when there's ambiguity. *Whose idea was this?!*
That looks great, I'd love having this feature available. I'm wondering if your design works if there are multiple raw pointers in the unsized struct? This would be great for sparse matrices or n-dimensional arrays.
Code: let _: () = 0u32; Error: &lt;anon&gt;:4:17: 4:21 error: mismatched types: expected `()`, found `u32` (expected (), found u32) [E0308] &lt;anon&gt;:4 let _: () = 0u32; ^~~~ error: aborting due to previous error
&gt; Like... How do you fuck this up? &gt;.&lt; By assuming Rust works the same way D does instead of reading the documentation? :D But seriously, Rust isn't different to be difficult; it's a conscious design choice. Using both absolute and relative with the same syntax is dicey at best; depending on the lookup order, you can end up with action-at-a-distance causing either global or local modules to just go missing with no recourse. It's one of the reasons Python ended up splitting the two into different syntaxes. It also fits with Rust's usual "explicit over implicit" attitude. At which point, the question is: why does `use` use global paths by default, and why does everything else use relative paths? The simple answer is: because all the alternatives are too inconvenient in practice, and this system works as expected *most of the time*. Really, once you're *aware* of the distinction, it's not that big a deal.
We just do `let x: () = thing;` or something.
That's probably the first time I read constructive, informed critique of the language.
`rustdoc` just failed me. I ran it on the main.rs of a little toy project (mostly one struct with 5 or so much-too-long functions implemented) and got no html or txt files in doc/, just generated js and woff files. I have no pub or mod annotations, and to be as good as header files it should have given me at least the function declarations which right now are sandwitched between all the implementation details. 
You could implement PartialEq, but it would make the code a little confusing, since `Abcd::BadData(foo) == Abcd::BadData(bar)` would then compile, but not do anything sensible (return false or panic, I guess, depending on the implementation). Pattern matching avoids that problem...
(For anyone who like me was surprised non-lambda functions with auto returns worked in C++: it's new in C++14.)
Oh, this is a fair point. "Internal rustdoc" (with private fields) would be nice. Filed https://github.com/rust-lang/rust/issues/25568
&gt; You could limit it for enums and slices, but not anything else **(or even insert runtime checks for those..** this is what most languages do in similar situations, it's not a big deal - see e.g. covariant mutable arrays in c#). This is just `RefCell` (and it doesn't work in multiple threads). If you don't think you make these types of bugs (but in my experience, you probably do), or don't think they're common enough to matter, that's always an option. Though I agree it would be nice to have a pointer type that allows shared aliasing as long as the representation doesn't change (and you stay single threaded, presumably, but that would be easy enough to enforce with OIBITs).
I know. And yeah. Just. It's... Not obvious that `std::*` could be a local path. Like, not when you look at it.
Wow rusti looks amazing, thanks! Gonna play with it :)
Yes, auto deduced function return types was introduced in C++11 but enabled for lambda functions only. C++14 removed this restriction and now all functions can have its return type automatically deduced. Since C++14 also allows functions with multiple return statements to have its return type automatically deduced, automatic type deduction can only happen when all return statements deduce to the same type (i.e. when the return type is not ambiguous). This allows a couple of new things. First to return objects of unspeakable type like lambda functions. It also allows to return objects of unspeakable type outside of the functions: auto f() { // we can't spell the return type here ! struct A {...}; return A{}; } And then it also allows to automatically deduce the return type without SFINAeing out the function: // C++11 template&lt;typename T&gt; auto f(T t) -&gt; decltype(std::declval&lt;T&gt;().a) // expression SFINAE { return t.a; } // C++14 template&lt;typename T&gt; auto f(T t) { return t.a; } // no SFINAE: hard error These things are "features" in the sense that they allow things that weren't previously possible, but also complicate the language because e.g. removing the `decltype`-auto return of C++11 doesn't maintain the semantics in C++14.
&gt; Rust really doesn't strike me as 1.0 quality quite yet Rust is indeed still missing a few things but I really think going 1.0 was the right choice. It was really getting annoying keeping your code up to date and waiting for others to update their libraries. Now you can program and be reasonably confident(im still using nightlies) most of your code will still compile next week, that's amazing :)
Isn't `mmap` unix-specific?
I was actually hoping after AST stabilisation we'd be able to easily have a `cargo inspect` like thing. So you could have `cargo inspect --methods` but also things like `cargo inspect --crate foo --type Foo --include-derefs into_`. I'm mostly after anything not requiring me to switch between the editor and browser.
Yes.
I agree, I still forget about that sometimes. I think the main reason it's not an issue for me is because Rust allows `use` in so many places that the only time I really ever use that syntax is in one-off examples where I'm in a hurry.
I believe Arch (pacman) has it. 
brew for OS X already has rust 1.0 stable :) For Ubuntu, I'd expect it to at least turn up here: https://launchpad.net/~hansjorg/+archive/ubuntu/rust
It's up to the distros. The more responsive ones already have packages, Arch, Gentoo etc. If your distro doesn't have it then it's time to go beg a maintainer :)
There's a [Debian package](https://ftp-master.debian.org/new/rustc_1.0.0~beta.4-1~exp1.html) that is currently in progress; it is currently in the new queue, which means that the basic packaging is done but it's awaiting review from the FTP masters team. This will likely be the basis for the Ubuntu package as well.
I thought `rustdoc` had a flag for this - was it removed at some point?
I had planned to launch the project today but I didn't know that Kickstarter reinstated the review process... when did that happen? Anyway, I welcome any feedback or comments.
Hey, lots of good responses here already, just wanted to say that I hope to see you around more NYC events in the future, and thanks for coming! We had a great turnout :)
Your post is a bit messed up, because in one place you've got ' instead of \` (second place where `to_string()` shows up. )
Note that even then, the docs would be one level deeper than `doc`, it'd be in `doc/mycrate`.
Except std::io::Write also has its own write_fmt method. The macro is purposefully 'generic' in that sense. 
I'd always include this disclaimer with that suggestion: 'Your using nightly means you accept that your code ~~may~~will no longer work in new nightlies.'
[It would appear so](https://github.com/Homebrew/homebrew/blob/4e7c9894676ffbaeea7efb926cd81894e7e8c640/Library/Formula/rust.rb#L13)
&gt; just to see it on large scale projects. Well, first, there aren't that many large scale Rust projects, because the language has been moving so much. Second, most new projects don't get super large by themselves, as Cargo makes it easy to split into smaller subprojects. See Piston for a great example of this. As a project, it's huge, but it's made of a ton of tiny projects.
&gt; You could limit it for enums and slices, but not anything else (or even insert runtime checks for those.. this is what most languages do in similar situations, it's not a big deal - see e.g. covariant mutable arrays in c#). That's `RefCell`. You can use it just fine. We spent a huge amount of time designing this system to get it right, and the borrow checker is the system that worked the best. We used to try automatically inserting runtime checks (`@mut`) and they triggered all the time, so we backed off to static checking.
&gt; If you can do something simpler to ensure there's no memory corruption, but leave things wide open for hangs and crashes (like c# or java does), is that a better tradeoff than to require draconian restrictions to eliminate the bugs entirely? You're suggesting a full, concurrent garbage collector? &gt; IMO the problems that are occasionally caused by mutable aliasing are just not that big of an issue to motivate disallowing them entirely. The cure is worse than the disease. There have been multiple zero-day remote code execution vulnerabilities in Firefox due to iterator invalidation.
&gt; As a result, it seems unproductive to try and speculate about what Rust 2.0 could be or mean. So, while I agree that in general this is true, I also know that many of us have been through several major language changes, and seen how painful they are. Ruby 1.8 -&gt; 1.9, Python 2 -&gt; 3000... What I _personally_ would like to see in a 2.0 is a "garbage collection release": all it does is remove deprecations.
Look for `rust-docs-*` at http://static.rust-lang.org/dist/
I've asked the programmer to respond to your comment. Meanwhile, that still leaves the gap between the Fortran #4 fasta program and the current Rust program.
I often use e.g. `grep 'fn foo'` to look for function/method definitions. In C++ I find it hard to grep for declarations as opposed to calls.
Whoops, thanks. I wrote this out too late.
Awesome! What's the best way to find out about events in the future? This sub?
&gt; You're suggesting a full, concurrent garbage collector? No. &gt; There have been multiple zero-day remote code execution vulnerabilities in Firefox due to iterator invalidation. Most likely it's really due to lack of memory safety, not due to iterator invalidation. If doing an operation that would invalidate an iterator immediately killed the thread/process (or at least threw an exception, like in C#) I have a hard time seing it would lead to remote code execution. It dynamically bails out before anything memory unsafe could happen (or in the case of C#, it bails out before any real bugs could even happen too).
&gt; That's RefCell. I disagree. RefCell still fires when you do any kind of mutable aliased writes, which is too restrictive. It should ideally fire ONLY when there's an actual problem that would lead to memory unsafety (e.g. when writing to an enum that would invalidate existing pointers, in other words changing the enum "kind", it would fire... When simply changing the value of the current "kind", it would not.).
&gt; Writing a linked list is something you generally shouldn't do to start out with; use the ones in the standard library. You can easily write linked lists with unsafe code, which is what the equivalent C++ would be anyway. I'm writing a language interpreter which means I have an AST that I need to traverse. I have something like: enum Sexpression { Id(String), Num(f64), Cons(Box&lt;(Sexpression, Sexpression)&gt;) } As part of that I need to have code which traverses a list of Cons'es. It's a Lisp thing and maybe not a great choice in retrospect for Rust... I used an enum with a recursive reference here because I had thought I would be able to write really cool AST pattern matching code like this: match sexp { Cons(Id("let"), Cons(defines, body @ Cons(_))) =&gt; ... ... } but not being able to destructure a Box foiled that plan. :-( &gt; `std::function` boxes too, I believe. It would have to, in order to be dynamically sized. I agree, but it doesn't make me do the boxing explicitly, so you have a great interface: you just return a std::function instance from your function and everything else happens under the hood.
One thing that header files are incredibly useful for are dynamic libraries. A header file makes sure my definitions and declarations are in sync. Currently, I have to have a separate "definitions" crate that is compiled into both my dynamic library and my binary, and then make sure to define functions inside a macro that type checks.
Cool. Are the sources for std library installed somewhere when I install rust? What directory to I `cd` into so I can do my `grep`ping?
I somewhat agree, but for `RefCell` or something like it to work you have to put the borrow flag somewhere, and know to check it everywhere the value is accessed, not just in the place you mutate it. So in practice, there are two ways of accomplishing what you want (allowing shared mutation without explicitly annotating the definition site) that I can think of: * Make `RefCell` the default. This would add extra overhead (both size and time) on every pointer access for something that is only occasionally necessary. For those of us who don't require it for safety (I rarely use `RefCell` myself) you're asking us to pay this cost anyway, which would be very much opposed to the rest of Rust. It also doesn't work with multiple threads, so you'd need some way to opt out, which just shifts the annotation burden from "has dynamic borrow check" to "doesn't have dynamic borrow check." * Include a special pointer type (distinct from `&amp;` and `&amp;mut`) which allows safe shared mutable access without additional overhead, and let it be used anywhere. It would be safe because it would disallow the "problematic" mutations (multithreaded ones, switching variants, or dropping through it), but other types of mutations would be legal. This is the option I would like to see. It is also essentially the same as the reference semantics in Java (all in-place mutations in Java are of this form, which is why Java allows unrestricted mutation). However, it doesn't exist yet, and it will probably take a while before the Rust community is willing to consider adding back more pointer types. I'm sure there are other options that allow safety without forcing performance compromises onto every program (e.g. special limited sections that allow unrestricted mutation that is known to be safe). But I can't think of anything concrete off the top of my head that wouldn't require extensions to Rust's type system.
You can get that functionality by just nesting RefCells or Cells inside your enum variant. I think this case is a corner case that has little to do with the problems people are *actually* hitting with the borrow checker. Adding more expressivity around enums isn't solving the problem you're complaining about. Most problems people hit with the borrow check are due to taking references into collections like linked lists and arrays, where the borrow checker is actually trying to protect against real UAF hazards.
Not really. Bootstrapping is a far bigger issue. (and, we don't inherently need a custom LLVM, exactly, and will not need one even more in the future, so that's pretty minor in the broad scheme of things.)
I am glad to see more long-form explanations come about. Congrats and good luck!
I thought it was just in the AUR, guess I need to move over. Is cargo there too?
What is HKT? Google search says Hong kong Time!
Higher Kinded Types. key to some functional programming idioms in haskell, and in Rust I think they'd be useful for generalizing over types of smart-pointers. in C++, its' called "Template Template Parameters" (as opposed to type-parameters or constant parameters).. and has horrendous syntax :)
&gt; but not being able to destructure a Box foiled that plan. :-( Yeah, we should be able to have custom destructuring for smart pointers. We used to have it hardcoded in the compiler for Box, but it was removed because we don't want to support that "magic" in perpetuity. &gt; I agree, but it doesn't make me do the boxing explicitly, so you have a great interface: you just return a std::function instance from your function and everything else happens under the hood. Well, one of the design decisions of Rust was to make allocation explicit. Adding an implicit coercion between closures and `Box&lt;FnMut&lt;...&gt;&gt;` would go against that design decision.
Joined. Thank you!
This functionality used to be in the standard library, long ago: https://github.com/rust-lang/rust/blob/0.12.0/src/libstd/os.rs#L1316 I don't recall the reasons for its removal, and I seem to recall someone moving it into a crate somewhere, but I can't find it. The code could probably be resurrected though if you want to use it.
It depends on how many people, but there's a small possibility I could find a space in Manhattan. PM me if you're interested and I can investigate.
* The first one (cargo running rustdoc automatically) would generate documentation, just automatically and maybe in txt for as well. Preferably with non public functions included, but still in the doc/ subdir. * The "Generate `.hrs`" option would place this documentation a) next to the .rs file and b) write it in a form which is very close to valid rust files and can be interpreted by a syntax highlighter. These generated rust header files (`.hrs`) are, well, header files, as in C++, just generated and any code editor can make use of them.
The analysis about aliasing could still run and simply elide any checks when it's safe to do so. 
Yeah, absolutely. There's a huge need for a plurality of resources, and especially more advanced Rust stuff. :) I myself originally started working on docs by writing an external thing. It's super valuable, and just compliments what's officially available. Official docs have to start at the beginning, but the freedom of being a non-official thing is that you can segment whoever you want as an audience, which lets you serve that particular one better.
So this is really a limitation of the RAII pattern. `.borrow()` returns a `Ref`, which is an RAII guard. When `Ref` is destroyed, the refcount is reduced. This works fine normally, but here you're just returning a pointer. You're not returning the RAII guard. The caller has to decrement the refcount when it's done with the borrow, but the caller only sees a function that returns a pointer to a string. It does not know that the function has cleanup associated with the borrow. Since functions can be handled with dynamic dispatch, a function call to something with the same signature should behave the same (inlining aside). One cannot have a function that has the same signature as another but requires extra cleanup. The RAII guard returned by `borrow()` (which has a signature `borrow&lt;'a&gt;(&amp;self) -&gt; Ref&lt;'a&gt;`, so the reference can't outlive the scope of the call) *has* to be cleaned up within the scope of `borrow()`, which is why you're having trouble here since you're returning a pointer but the guard that created it can't stay alive for that long. That being said, diagnostics here could be improved a lot. I don't know how.
You can just `"Hello".into()` rather than `Into::&lt;String&gt;::into("Hello")`.
Thank you much for taking a look. Yeah I kind of gathered that it had to do with the lifetime of the Ref, the problem is that I don't have a way of exposing the Ref without breaking my encapsulation? Or do I? How would you code this if you had to implement the GimmeAString trait but had a RefCell? 
Personally, I'd recommend [multirust](https://github.com/brson/multirust) which is also in the AUR.
You might be able to use associated types here if you're only doing static dispatch. Basically, say that implementors of this trait return something which derefs to a string, and that something should be set by the implementation. In this case a closure-based pattern might work better fwiw, where you pass in a closure that mutates/uses the string. Closures are generally zero cost with static dispatch.
This is amazing and horrifying.
True dat :(. Hopefully the KDE-stuff-on-Windows efforts will reform around Frameworks 5 soon. I've seen some cool R&amp;D demos of new standalone application installers in action.
You certainly *should* be able to transverse a `&amp;mut` reference to a linked list iteratively.
This is exactly what I am looking for [Advanced Rust Programming](http://www.reddit.com/r/rust/comments/35qqzv/rust_essentials_packt_books/cr7afle) May I ask how much experience author has with Rust Programming language? Has he submitted any PRs to the Rust ecosystem? 
By fixing on one obvious difference between one C program and one Rust program, and ignoring that the Rust program is slower than all those other programs (including other C and C++ programs), we miss the opportunity to see the different ways the Rust program may be improved. The convincing response is to improve the Rust programs.
Nothing wrong with that.
Quick comment about "move by default". I think a lot of the confusion is going into it with the C++ mindset that moves and copies are different things. In Rust, they're not. * `=` means `memcpy`. * Rust's borrow checker shouts at you if you keep on using the original because they could alias data. * `Copy` tells Rust to shut up by guaranteeing the struct will never have data that could be dangerously aliased after a `memcpy`. 
I think Cargo will only be able to be packaged once Rust is in the repository, as it will need to build from source; while Rust itself will of course have to be bootstrapped from binaries for the initial inclusion, Cargo will need to be able to be built from the Rust that's in Debian, so it likely won't start it's way through the new queue until Rust has landed. There is a [Rust Packaging Team](https://wiki.debian.org/Teams/RustPackaging) page, and they link to their [Git repos](https://anonscm.debian.org/cgit/pkg-rust/), which contain a preliminary Cargo repo. So looks like it's being worked on, but as I said, will probably need to wait until the compiler is in. That also may be delayed due to the fact that I don't believe that Cargo itself builds on the stable compiler yet; I believe that it uses some `fs` features that haven't yet been stabilized. So it may need to wait until. 1.1 or 1.2 are out and available in Debian before Cargo itself can make it in. Don't quote me on that, however, I haven't looked into it in detail.
There are Rust packages for OpenSUSE available from the devel:languages:rust repository of OpenSUSE Build service: http://software.opensuse.org/package/rust Cargo is available as bootstrap-package in the same repository: http://software.opensuse.org/package/cargo-bootstrap?search_term=cargo A simple first test with a small program using rust-gnome gtk3 bindings worked fine. 
Happy to help. I've been going through all of my dependencies to try to get them in line with stable. Coincidentally, the last one is /u/passcod's [notify](https://github.com/passcod/rsnotify) crate which needs access to the `modified` time of a file.
Doesn't that mean if a fundamental flaw is discovered, breaking this backwards compatibility will require a move to 2.0.0 due to semantic versioning?
 Something seems to be borked in their DNS, but after doing a little digging, I found this alias on their fifth nameserver: http://www.hashmismatch.net.s3-website-us-east-1.amazonaws.com/ That seems, at least for the moment, to go right to the article, where the main link just fails for me. 
That seems like a valid implementation. I've written a lexer before and I chose I slightly different route. I defined `Token` as an enum, which means that I was able to match on the Token type in the parsing phase. Here's what that looks like: pub enum Token { Unknown(char), OpenParen, CloseParen, Operator(char), Number(String), } It's a super simple Lisp-like language so there's only a few types of tokens. [Here's a link to the whole lexer as a reference](https://github.com/JamesOwenHall/rust_arithmetic/blob/master/src/lex.rs).
That doesn't work because the `LongerLivingStruct` that is returned is not in the same location as the one in the `make_foo` funciton. `m` in the `make_foo` function is allocated on the stack, and so that memory will be reclaimed and used for other things after `make_foo` returns. The `LongerLivingStruct` that is returned is a copy of the original one.
I have not yet written a single line of Rust myself but would like to thank you for your post nonetheless. I found it both interesting, informative and humorous.
Awesome. Please add comments too, even if it's just +1'ng nick.
Definitely will do once I have some time tonight to sit down and read the full document.
Just an idea, but would it be a good idea to put a book like this on Github? Not sure how that would affect sales (I'd still buy a physical copy if it's reasonably priced), but it would let people see and comment on sections as they're completed. Just a thought.
Awww... That picture is touching. We should have a time to look back on GC and take care of him. He looks so pitiful! ;ㅁ;
Thank you! I'll share a helpful tip that one very knowledgeable rustie slipped out on stackoverflow. [Using nested macros](http://stackoverflow.com/a/30293051/) to forward things you can't catch with the usual macro argument "types". For me this was the door open for how to pass a list of life/type parameters and a list of where bounds to a macro.
You cannot name the type of a closure.
Oh, yes; I forgot that one. Well, I guess the OIBIT approach wouldn’t work. But having two `use` statements in libstd should work fine.
&gt; it provides you with an impressive amount of power whilst not allowing for the sort of evil tricks you can pull in C/C++. Wait I thought C's macros were simple text substitution? what evil tricks can you do? For Science!
Have you read the [book](http://doc.rust-lang.org/stable/book/) yet? If not, you really should. The docs are the worst place to start off, especially if you don't know about traits or how they work. Also the [str module](https://doc.rust-lang.org/std/str/index.html) is not the same thing as the [str primitive](https://doc.rust-lang.org/std/primitive.str.html). This is kinda confusing, I'll admit, especially seeing as they look nearly the same in the search.
It's not in [community] along with rust because there's no official source releases yet; just nightlies and the binaries bundled with Rust from the website. Also, it doesn't compile (last I checked) on 1.0.0. &lt;_&lt;
Here PR to Rust ecosystem was not limited to writing code but blogs, documentation, RFC etc... E.g. Steve is known for his contribution for making Rust popular and easy to understand via writing. Here I used Rust Ecosystem and not programming language. Anyway....
Well I doubt I could contribute a better program than most here, so I picked one of the broken ones: https://github.com/Schroedingers-Hat/benchmarksgame-rs/blob/master/src/mandelbrot.rs Surprisingly the performance difference is only a factor of about 2.5 on my machine, given it's almost completely naive code (I did peek at the ASM output and jiggle some functions a bit until I started seeing SSE3 instructions, but that's about it).
Are you interested in writing a blog post on this? Your own blog, guest on my blog, or on a site like polyglotweekly.com. Recently I wrote a similar post regarding Go (http://www.polyglotweekly.com/2015/04/24/thoughts-of-a-rustacean-learning-go.html); and you might be able to get there using Rust. I'm more than happy to help with feedback. :) While in an ideal world everyone would be praising Rust and donating all their wealth to us so we can build an empire of &amp;-ptrs, I think posts like this are a good way to show others what to expect. Of course, many of these points would need explaining for non-rustaceans, elaboration on the Rust side of things (cf my first comment here), and/ or correction if mistakes, if any.
Maybe, but it’s not up to me. Feel free to file an issue on https://github.com/rust-lang/rust-www
You can't really fault them for not mentioning a feature that isn't available in the stable release.
I'm working on a Rust GC now, coincidentally :P
Thank you for implementing this! Awesome!
Kickstarter backers of the book will get draft chapters as they are completed. Unfortunately, when I made my last book free to read online, sales dropped significantly. Read "Dataflow and Reactive Programming" at https://deepfriedcode.com/books/darps/
All of the code can be found on github. The standard library seems to split into multiple libraries, which are pulled in by libstd. Here's the link to libcollections: https://github.com/rust-lang/rust/tree/master/src/libcollections edit: looks like libstd actually adds a number of collections on top of libcollections.
Mmm, though I believe that only works if you just need to literally paste some tokens into a "mistyped" position. What I really want is some kind of `eager_expand!` macro that forcibly expands its arguments so you can do things like construct identifiers in a macro instead of having to specify all of them up-front. :P
Agreed. I am but human, though, and reserve the right to let my genuine frustration leak out as a single exasperated onomatopoeia. :)
Oh, perfect. Thank you.
It [was](https://github.com/rust-lang/rust-playpen/pull/102) all whipsch! (They're awesome.)
Some forms of GC (e.g. RCU) can useful for certain types of nonblocking data structures. And unrestricted mutation becomes much easier with deferred destruction; for example, if resizing a vector doesn't destroy the old copy immediately, it's safe to push onto one through a shared pointer. I think a general GC is a pretty poor fit for a language like Rust (though the prospects for that should improve now that LLVM has support for precise stack maps), but a limited one that you have full control over can be very useful. Note that if you can eat the cost of waiting for destruction until after some stack-scoped region of your program, you can get many of these advantages with an arena today.
&gt; Of course it probably optimizes away any Copys too that it can guarantee won't be missed, so in this way you're right that it's pretty much the same. `Copy` is nothing like copy-constructors in C++, as nothing interesting can happen: using a value by-value (e.g. `=`, passing to a function, returning from a function) is always semantically a shallow byte copy (ala `memcpy`). The only difference between types that implement `Copy` vs. those that don't is whether the source can continue to be used. (I wrote a [stackoverflow answer](http://stackoverflow.com/a/24253573/1256624) that looks at this in a bit more detail, which seems to have helped many people and may help you too.)
Ah. That explains it. Thanks 
Thanks
From the post: &gt; Our project requires a 1.1 nightly build of Rust, as 1.0 doesn't support the unstable language features that we'll need. In that case, I'll give the parent some merit.
Oh, I had seen the docs but hadn't noticed the src. Awesome.
So is this the start of Teaching Tuesdays? :P
I believe the reasoning is that you can add methods to a struct, but you *can't* add methods to an enum variant. That is, you could write `Funghi::get(&amp;self) -&gt; i32`, but you *can't* write `Yeast::Yeast2::get(&amp;self) -&gt; i32`. The best you could do is write `Yeast::yeast2_get(&amp;self) -&gt; i32`, but that would then always require a dynamic check and can fail, so *blech*.
Oh, there's an issue tracker for the website. I didn't know that either. :-)
Let me see if I understand you correctly: Without `Copy`, the borrow checker will yell at me if I try something where the optimizer can't convert it into a move. With `Copy`, the optimizer will still convert to a move when possible, but the compiler will leave it a `memcpy` rather than yelling at me if that's not possible. (The effects of deriving `Copy` were something I was still unsure of after reading the docs and following this subreddit for a while.)
There's [rustc-serialize](https://github.com/rust-lang/rustc-serialize) for that :-)
I have never used OS X, and it doesn't look like the author of IUP has either, so maybe you shouldn't be surprised that neither of us knows what's good or what's not on it. :) I wouldn't blame the author for not trying; it's notoriously expensive to import electronics into Brazil. I've just never had a reason to use OS X. It looks like one person started work on [an IUP driver built on Cocoa][iup_mac], but it's been inactive for five years. Any Mac developers who want to help remedy this situation would be very much welcome. In the meantime, while GTK+ might look like arse on OS X, it's the only IUP driver that actually works there. Can't this be helped as well, though? https://wiki.gnome.org/Projects/GTK+/OSX/Integration [iup_mac]: https://github.com/phasis68/iup_mac
Thanks for pointing that out, I completely missed the target with that paragraph. ```allocate``` from ```liballoc``` absolutely can return a ```null``` when there's an OOM. Like you said, shimming the current non-core (```collections```, ...) leaves you with having to relying on ```abort``` to cleanup the situation, with AFAIK no safe option to return back to the problematic stack/thread. Some VM languages with exceptions (in my experience, C# on .NET) can trap OOM exceptions and handle them in-thread (which is usually abused by junior developers...). An OOM-safe collections library should probably return Option/Result type on every mutable operation, like ```VecSafe::new(u64::MAX)``` would typically return a None. But it's just too tempting to use the collections library in such "risky" environments as the productivity boost over C or C++ (at least for me) is awesome. Hence the pragmatic title :) A very similar discussion was in this previous thread: http://www.reddit.com/r/programming/comments/342082/cs_honors_thesis_reenix_implementing_a_unixlike/ Edit: I've rewritten the paragraph: &gt; Note that the current design of Rust's collections library (which we are using in an unstable, 1.1 nightly way) doesn't support graceful handling of out of memory situations, so allocating a large string or vector could lead to the runtime calling the abort function.
Hopefully it works now, I've configured the domain a few minutes before posting this. You can tell that I've had to setup a blog just to publish this first article :)
I'm gonna give this a try, but the support for the library this is based on (iup) seems a bit shaky. There are no official packages for it on Arch Linux, and the AUR contains outdated and broken packages. I took over maintainership of the relevant packages, but it seems I will need to patch the sources to make them build.
But I can coerce it (below). And sometimes it's just useful to know the type of it. `let plus_one = |x: i32| -&gt; i32 { x + 1 };`
I don't know how to redirect panics, but I *do* recall a problem with *some* language a while back where, by default, GUI applications don't *have* the standard IO handles. This causes errors every time you use them, but C and C++ just ignore those errors; presumably, Rust *doesn't*. This SO question ["Using stdout in a Win32 GUI application: crashes if I don't have a redirect to file in arguments"](https://stackoverflow.com/questions/12255543/using-stdout-in-a-win32-gui-application-crashes-if-i-dont-have-a-redirect-to-f) might provide more insight.
Unfortunately it seems the most well supported way of getting IUP on Linux is to install precompiled binaries from the author. Linux users will usually balk at this but it's not uncommon on Windows, which I figure is the author's primary platform. There's no Ubuntu repo for it either so I have to download and install the precompiled binaries in Travis-CI. It'd be nice to find a remedy for that situation as well.
I'm pretty sure that you can write methods on enums using impl can't you?
Yes, but not on enum *variants*.
Yeah, SO felt even worse for such a simple question.
For anybody interested in the related project he mentioned, [Zinc](http://github.com/hackndev/zinc), there is a much more updated version of zinc getting ready to be pulled [here](http://github.com/mcoffin/zinc/tree/new-build).
This looks almost exactly like what I do in [xml-rs](https://github.com/netvl/xml-rs). This is a perfectly valid approach for streaming parsers and lexers.
Huh, the solution from there to have a windowed application shim that spawns a process for the console application and redirects its stdout emissions is actually not half bad. I'm still interested in the Rust-side solution since I'd really like to keep my application as a single .exe instead of multiple files.
We want screenshots. Would be cool?
Nope. OSX integration of every toolkit beside wxWidgets is bad (if you want to use wxWidgets is another question). Even though Qt is okay-ish it occasionally hits some edge case. I would even go as far as saying that the Windows-integration of most toolkits is bad either but most people don’t notice because they don’t know how it is supposed to look like (I don’t know either). 
Given a vector of elements, and imagine these are more complex than numbers can can be cloned: let vals : Vec&lt;i32&gt; = vec![1, 2, 3, 4]; I want to filter these and place them, by value (i.e. clone them) into another vector: let even : Vec&lt;_&gt; = vals.iter().filter(|&amp;x| x % 2 == 0).map(|ref x| x.clone()).collect(); However even is not `Vec&lt;i32&gt;`, so just writing `let even : Vec&lt;i32&gt; = ..` will not work. Checking the type via ` let _ : () = even` shows it is `collections::vec::Vec&lt;&amp;i32&gt;` A work around I found is this: let mut even : Vec&lt;i32&gt; = Vec::new(); let _ : Vec&lt;_&gt;= vals.iter().filter(|&amp;x| x % 2 == 0).inspect(|&amp;x| even.push(x.clone())).collect(); * Can this be done without the clone? * What if I want to *move* elements from `vals` into `even` instead of copying? * In the work around, I am done after the `inspect()` step, but still have to run `collect()` because an iterator is lazy. Is there another way to consume an iterator?
Thanks! I finally understand ownership and borrowing in Rust. :)
Here's a somewhat [overengineered solution](http://is.gd/DfsWgh): it defines an extension trait with a `split_collect` method that drains an iterator into *two* collections simultaneously. Also note the use of `into_iter` instead of plain old `iter`.
What the heck does this do? #[path="/proc/self/fd/0"] mod input; fn main(){ input::run(); }
With `bincode`? I believe the parent comment is asking about something like the methods we used to have in the old IO, e.g. `read_u32_le`. I know `byteorder` lets you deal with endianness, but does it also extend `Read`/`Write` with such methods?
Well, given that `#include "/etc/passwd"` appears to work on &lt;http://ideone.com&gt;, I'd say so. :D
By the way, what's this thing called? "Type" of a closure, which is not the "true type" (because that would be something like `Fn* ...`), but the "semantic type"?
Hm, both the module and primitive type docs give the exactly same explanation: "Rust's str type is one of the core primitive types of the language. ..." I think that should be a lot clearer! There should be a clear distinction and the module documentation should link to the doc of the primitive type and vice versa. Edit: maybe the docs could show the trait implementations transitively too, to reduce unknown unknowns?
I'm not saying that `Z` itself should be private, just the contents/fields inside `Z` (if any). The end user would know that `Z` exists and can match on that, it just cannot read / write / capture whatever is inside the `Z` variant. Anyhow, Rust works the way it works and it's very unlikely that's going to change. It's just one more thing to keep in mind, that the fields inside structs and enums have different visibility.
&gt; I do think there is no reason for Rust to lag behind Let's make that no *intrinsic* reason, ok? &gt; but unless you compare the same algorithm At what point does the *algorithm* end and the low-leve-perf tuning begin? Also with the worst benchmark (regex_dna), it isn't even the same algorithm, because regex! uses an NFA instead of a DFA.
There is also https://users.rust-lang.org/ forum that could help.
Urgh. `modified` is going to be tricky. So much that I'm considering rewriting the poller to use some kind of content checking instead of the filetime.
So I build a Cargo.toml, write and build my app to a Windows exe. Copy it out of my VM to the host machine... And it fails to run as it's missing DLLs. Copy DLL, relaunch, repeat until it works. Is there some kind of dependency manifest cargo can generate that tells me all the lib. files I need to ship with my new exe? I assume a similar manifest would be handy with *nix .so files.
Not that I know of; I'd just run the executable through [Dependency Walker](http://dependencywalker.com/) and go from that. Honestly, what you propose sounds a little hard to do in practice... I mean, even if Cargo dumped a list of `.dll` files, that doesn't necessarily tell you anything about how you're legally or practically supposed to distribute them.
Thanks !! I am excited about your book and have already committed to purchase both of your books (See feedback by RohitJoshi on your Kickstarter campaign) 
What's happening in the list of implementors at the end of [this page](https://doc.rust-lang.org/std/vec/struct.Vec.html). It has this repeated over, from 0 to 32: impl&lt;'a, 'b, A, B&gt; PartialEq&lt;[B; 0]&gt; for Vec&lt;A&gt; where A: PartialEq&lt;B&gt; fn eq(&amp;self, other: &amp;[B; 0]) -&gt; bool fn ne(&amp;self, other: &amp;[B; 0]) -&gt; bool impl&lt;'a, 'b, A, B&gt; PartialEq&lt;&amp;'b [B; 0]&gt; for Vec&lt;A&gt; where A: PartialEq&lt;B&gt; fn eq(&amp;self, other: &amp;&amp;'b [B; 0]) -&gt; bool fn ne(&amp;self, other: &amp;&amp;'b [B; 0]) -&gt; bool I understand in general that it's describing a usage of `PartialEq` somewhere else. But why 32? Similarly, in `Eq`, there's: impl&lt;A, B, C, D, E, F, G, H, I, J, K, L&gt; Eq for (A, B, C, D, E, F, G, H, I, J, K, L) where G: Eq, B: Eq, E: Eq, L: Eq, H: Eq, I: Eq, F: Eq, J: Eq, K: Eq, C: Eq, D: Eq, A: Eq It goes from A..B to A..L. Why stop at L?
Good catch... thanks!
[#rust](https://chat.mibbit.com/?server=irc.mozilla.org%3A%2B6697&amp;amp;channel=%23rust) is one of the best IRC channels I have used. Members are very friendly and helpful. 
For now, /r/rust is used for asking questions, starting discussions, and posting links to interesting articles. If the traffic gets too high, it might be worth forking off a questions subreddit, but I don't think that's happened yet. [Stackoverflow](https://stackoverflow.com/tags/rust), the [Users forum](https://users.rust-lang.org/), and IRC (`#rust` on `irc.mozilla.org`, [web interface](https://chat.mibbit.com/?server=irc.mozilla.org&amp;channel=%23rust)) are other alternative places to ask such questions.
Copies and moves are the same thing. `Copy` doesn't change what assignment does. The *only* thing `Copy` does is tell the borrow checker that the old memory is safe to use. fn main() { let a = 1; // memcpy a to b let b = a; // i32 is Copy so the borrow checker // doesn't complain when a is used println!("{} {}", a, b); } # fn main() { let a = Box::new(1); // memcpy a to b let b = a; // Box&lt;i32&gt; is NOT Copy so the borrow checker // DOES complain when a is used println!("{} {}", a, b); } 
&gt; Can this be done without the clone? If you want to keep the original vector, cloning some of the elements is exactly what you want, isn't it? &gt; What if I want to move elements from vals into even instead of copying? You could use `into_iter` instead of `iter`. This will "consume" the original vector and transfer ownership of the elements to whatever you want to do with them. The resulting iterator gives you values of type `T` instead of `&amp;T` assuming you have a `Vec&lt;T&gt;`. But you can also reuse the already allocated memory: let even = { vals.retain(|&amp;x| x % 2 == 0); vals }; &gt; In the work around, I am done after the inspect() step, but still have to run collect() because an iterator is lazy. Is there another way to consume an iterator? Probably. But why so complicated? Wouldn't for &amp;x in &amp;vals { even.push(x); } be much simpler? :)
Quxxy answered your question, but in most cases checking whether a file exists is poor practice, because there's no guarantee the file won't be deleted right after you check (before you can do anything else), and if you don't need to do it it's a (tiny) waste of performance. Instead, assuming you want to open the file, blindly try to open it and, if that fails, handle the NotFound error as in their response.
AFAIK you can use a separate thread and `std::thread::JoinHandle::join` as a stable alternative to `catch_panic`.
As a linux user with xfce a ton of things match, but then sometimes I get a gnome or kde thing. TBH I'd just as soon use an ncurses gui for most things.
You mean `|i32|-&gt;i32`? It's not a type, it's a syntax error. It *used* to a "boxed closure" type, but those aren't in the language any more. I suppose you could say it's an informal shorthand. The *type* of a closure is completely unnameable and has no representation. It's also not `Fn* ...`; closures *implement* one of the `Fn*` traits, but that isn't the *type* of the closure.
Long time windows user. Really annoyed that no one bothers to make their apps work correctly. Especially tired of people forgetting about my jump list, but not a fan of things that don't behave well with snapping, windows key modifiers, etc., and also would much prefer the native look or some close facsimile (e.g. Visual Studio).
Because mutable borrows are fundamentally different from immutable borrows (also named *shared* borrows), in that if you lend away a value mutably, you can't lend it again while it's lent. This should be transparent to anybody lending a value, thus it has to be explicitely stated by the caller. The fact that owned values are immutable by default is independend from the whole *borrow-checker* stuff and doesn't have to do anything with the safety guarantees. edit: see http://is.gd/KuFVmQ
Because mutability is *not* part of a value's type. That is, `&amp;guess` is *not* a pointer to a `mut String`; there's no such thing. If you want a mutable reference, you have to ask for one. It's also important to remember that if mutable references were created automatically, as you suggest, that would make it *very difficult* to take multiple immutable borrows of any mutable variable, which would be rather inconvenient. Personally, I think it helps a lot that `&amp;x` is *always* immutable and that if there's mutability, it's explicit. Rust has quite a few technically arbitrary decisions that were made in favour of readability over convenience.
[`std::cmp` is a module](http://doc.rust-lang.org/std/cmp/index.html). In the case of [`std::cmp::Ordering`](http://doc.rust-lang.org/std/cmp/enum.Ordering.html), the components go module, module, enum. Also, remember that Rust doesn't *have* classes. Or packages, by any official definition.
That depends. Let's take `libc` as an example. You get it (typically) by adding a dependency in your `Cargo.toml` file; specifically, you add a dependency to the `libc` *package*. Cargo compiles it into a `liblibc.rlib` or `libc.dll` file; that's a *crate*. In your code, you link to it using `extern crate libc;`, which links to the aforementioned file (crate), and introduces the `libc` symbol within your code; that symbol refers to the `libc` *module*. So, Cargo lets you depend on packages. Packages are compiled into crates. Every crate contains *exactly one* root module (which may itself contain other modules). Or something to that effect, anyway.
So it's all abut being explicit, basically? Seems like a great idea.
&gt;For coding in rust, it helps me to think of references as owning vs. borrowing instead of values vs. pointers to values. Yup, that helps. Still getting used to the semantics.
Ah, this helps me draw a nice analogy with the way Java and gradle deal with this.
I'm not sure what you're asking; in order to compare the values they point to, yes, the pointers need to be dereferenced. If you're asking whether comparisons are done on pointers instead of values; no, they are not. For example, `Ord` is implemented for `i32`, which means you have `fn cmp(self: &amp;i32, other: &amp;i32) -&gt; Ordering`, which compares the *values* behind both of those pointers.
Yes, here is an example: http://doc.rust-lang.org/stable/src/core/cmp.rs.html#525-537 This defines the ord_impl!() macro, which is used to provide an Ord implementation automatically. Note that it dereferences both self and other when doing the comparison. The same would be done for any Ord implementation not using this macro, because the parameters are passed by reference and must thus be dereferenced in order for comparison to work.
**Very** nice! :) ~~Nitpick: in the chapter "Downside 2", in your second code example:~~ let expr = quote_expr!(cx, 1 + 1); let exprs = vec![e]; ~~I think you meant to write ``vec![expr]`` here...~~ I also *love* the renaming support! ~~Edit: also, you forgot the closing ``"`` on your e-mail addresses in the `Cargo.toml`...~~ Edit: fixed!
Even Microsoft doesn't know what windows is supposed to look like, really. Let's play "how many different ways to represent a use case can you come across" while browsing various windows menus, settings and Microsoft software.
Nice, thanks.
&gt; http://www.polyglotweekly.com/2015/04/24/thoughts-of-a-rustacean-learning-go.html I actually read that post when you first published it and really enjoyed your analysis! Thanks! I'm honored that you would ask me to write more, and I do have a more to say, but I hate to commit and not follow through. May I PM you after thinking about it some more? 
_That_ is a great name for it.
Oops thanks! I'll fix it right now. Also just remembered there are a couple other things that got merged in last night I'll add to the notes: * Improved bytestring support [#72](https://github.com/serde-rs/serde/pull/72) * Fixed handling json integer overflow * Changed `de::PrimitiveVisitor` to also depend on `FromStr` [#70](https://github.com/serde-rs/serde/pull/70) * Added impls for fixed sized arrays with 1 to 32 elements [#74](https://github.com/serde-rs/serde/pull/74) * Added `json::Value::lookup`, that allows values to be extracted with `value.lookup("foo.bar.baz")` [#76](https://github.com/serde-rs/serde/pull/76)
Not part of the language, doesn't count. ^^^^^^That's ^^^^^^my ^^^^^^excuse.
Thanks again, just fixed that too :)
Ahh. The docs really should explain it that way so people like me can clearly understand that there's no performance benefit to be had in deciding to withhold `Copy`ness. (ie. That the LLVM optimization pass for "make this code performant enough to earn the moniker of 'systems language' by removing unnecessary`memcpy`s will run just as well with `Copy` as without it.) Do you know of any documentation on general rules that can be followed by people who can't read assembly dumps to make their code as favourable to that kind of micro-optimization as possible?
Ah, you're correct. I always forget how closures implement traits. But, regarding that "semantic type": I meant `|x: i32| -&gt; i32` part of the `let plus_one = |x: i32| -&gt; i32 { x + 1 };` Closest I can think of is "signature", would that be correct?
Turns out that teaching is a distinct skill from programming :)
I'd just call it a part of the closure literal syntax. `|x|` is the arguments, with `: i32` and `-&gt; i32` being optional type annotations.
I'm personally finding it difficult to understand exactly what problem you're trying to solve? Could you maybe post some code to help me understand? More general bit of advice: if you really wind up with two choices between "exposing something that is fastest" and "exposing something that is ergnomic," then sometimes the right answer is to expose both. Depending on the situation, perhaps you implement the ergonomic API on top of the fast API, which would be good for code reuse. The downside, of course, is now you have two APIs. One way to mitigate that is with documentation. Stress the ergonomic API and put it front and center. Maybe even put the fast API in a sub-module or a separate crate so that it is really out-of-the-way. This advice may be way off the mark, but it seemed appropriate!
&gt; Do you know of any documentation Unfortunately not, seeing as my experience is mostly in interpreted languages.
&gt; The docs really should explain it that way so people like me can clearly understand that there's no performance benefit to be had in deciding to withhold Copyness. Maybe it just needs to be surfaced better: http://doc.rust-lang.org/stable/book/ownership.html#the-details &gt; It’s also important to note that optimizations may remove the actual copy of the bytes on the stack, depending on circumstances. So it may not be as inefficient as it initially seems. and the related stuff in that chapter. Thoughts?
If you're on OSX, Dash has a Rust docset which includes both the book and the std docs: https://kapeli.com/dash Not free, but Dash is really great. Has a pretty good search functionality, supports versioned docs, multiple languages/projects, etc.
This has become too much like quarrelling.
Why does this block work? File::open("test.txt").unwrap().read_to_end(&amp;mut buffer); But this does not? if let Ok(result) = File::open("test.txt") { result.read_to_end(&amp;mut buffer); } In the first the `File` is `&amp;mut`, while in the second it is immutable.
I'm confused at what you are saying. I think you are saying that llvm wont actually make the function call and will just branch instead of continuing with the ADd with Carry? I guess just because i marked the function as not inline-able might not be enough to keep it from getting inlined and optimized by llvm? I suppose that makes sense, I have a test to see what the behaviour is going to be in the common case. On the performance stuff: considering what people do to get things to run at constant time, I'm not sure I buy that performance is a particularly important tradeoff. I think you just need to assure base performance on common platforms. In general I distrust cryptography specific chip operations (seems to easy to hardware trojan) but they are always a reasonable optimization. None of what I am saying should be taken as a slight on any of the great work (written about above) which generates constant time assembler. My only concern is that we fully accept defence in depth and make our cryptographic primitives understandable by the largest possible audience. 
Before I get into the nitty gritty, let me say I find this really awesome: congratulations on making it work! How do you handle hygiene, if at all? I would generate one macro_rules macro for each expansion site and pass in just the idents. That way, the real compiler takes care of hygiene for you. Or you can perform renaming during pretty-printing, to prevent unhygienic name reuse. As for your `vec![quote_foo!(...)]` example, you can teach your `macro_rules` impl to parse the arguments of the macro according to the fragment specifiers. Then, expand anything that can hold a parsed macro invocation, i.e. `expr`, `stmt`, `pat`, `block` and `item`. Combine this with one `macro_rules` macro hiding each expansion and there should be no real chance of changing the semantics due to early expansion. I've just realized this assumes you have access to macros defined by other crates, which is not the case, as the metadata format isn't stable. Aggressively scanning for macro invocation syntax inside macro arguments is also a possibility - I'm not aware of any false positives in practice.
:) Sure, take your time! Note that I don't know if such a post would be suitable/accepted for Polyglot. It probably would be (if not you can just post elsewhere). Polyglot has the nice aspect of being community edited, so you get tons of feedback from all over the place! I think this has the potential to be a really good and useful post if done right. As important it is for everyone to love Rust and hate C++/Java and wage war on gophers (:P) it's even more important that people don't get the wrong expectations from Rust. Rust is totally awesome and magical and has sparkles coming out of all of its orifices. But it's not for everyone. At the same time, many posts that point out the flaws in Rust, but they get many things wrong just because the author may be new to the language and hasn't really gotten themselves rooted into it. If you notice I acknowledged in my Go post multiple times that I had not immersed myself into the Go way of doing things and was still thinking and programming like a Rustacean. I believe this acknowledgement was a big part of the good reception (from all sides!) that it got. There aren't any posts (that I know of) pointing out the flaws or shortcomings or even differences of Rust like that. But as I mentioned before, a post like that is useful. If you can do it without making the mistakes that the other posts made (I can help with that, along the lines of [this comment](www.reddit.com/r/rust/comments/36ce52/reflections_on_a_weekend_with_rust/crcscio). Note that many of my responses don't invalidate your points; and they shouldn't; they just mention important caveats that if not known might mislead). You have the perspective of an outsider, which is valuable, and a fleshing out of this post could become something quite amazing! :) Feel free to PM, or email at (username)@gmail.
Could `value["foo"]["bar"]["baz"]` be made to work? I guess a version returning `Option` would be less pretty. I prefer something like `value.lookup(["foo", "bar", "baz])`, mostly because I know nothing has to search for `.` in my string, at runtime. Or `value.get("foo", "bar", i, 0, "field")`, which is possible with a tuple around the arguments (or VG, but that is not exactly on the radar).
This article made ownership and borrowing clear for me. Maybe this should be included in the Rust Book?
Thanks! I got it to build with a few very minor changes, but I get a `glium::BackendCreationError` at runtime on my MacBook. I've got a "really old" version of Mac OS (10.7) so that might be part of it. Oh well, this just gives me something to do ;)
Thanks for sharing!
That does indeed let me catch the panic, and works on stable! Great. But, now that I tested it and made the spawned subthread panic, I see that the Rust runtime helpfully [prints out a message to stdout](http://is.gd/hIwewc) about the thread panicing before the panic reaches my handler. Which I imagine will again lead to my `mwindows` binary just silently dying before it can get around to popping up the helpful message dialog.
Both of those *are* somewhat easy to accidentally overlook, so surfacing them better would definitely help. Also, it feels like that second snippet is in the last place someone will come back to look if they miss it the first time. Were I looking for information on how Copy relates to `memcpy` behaviour, I'd probably start [here](http://doc.rust-lang.org/std/marker/trait.Copy.html#when-should-my-type-be-copy?), then check [here](http://doc.rust-lang.org/stable/book/ownership.html#copy-types)... but I could easily not think to scroll up from there in the book. I'd probably amend that rustdoc section to say something along the lines of "Please note that the `Copy` trait's purpose is to selectively enable new code patterns. It does not directly affect the machine-code representation of assignments and adding it will not alter the `memcpy` behaviour of code which already compiled successfully."
This is awesome! Do you have any tips for those of us with syntax extensions who'd like to get them working with syntex/stable Rust?
Just an additional incentive to writing on a blog: It really helps clear your thoughts! I've started blogging a lot more recently and almost every time I come out with a much more clear mind than I went in. For example, in the recent post I wrote about shared mutability, I started _thinking_ that I knew all the issues to talk about, and as I wrote the post I realized that there was much more to many of the points I was writing about. I came out of that having a much clearer idea about the topic with a much more structured way of thinking. So even if you don't make a blog post out of this, I highly recommend you start blogging :)
We are talking about the `iup` library not Rust.
Hi guys, it's a fresh new open source library I just started working on a couple of days ago in my spare time. Thought this might be a good place to share it, if any of you works with the Gradle build system.
I'm not doing anything special for hygiene beyond what libsyntax and it's pretty printer does, so it's quite possible I'm being unhygienic. Ill have to test that out. On parsing the macro rules, I was thinking that it might be possible to do what you wanted, but I decided to look into that later since serde and quasi only had a few minor changes to work around this limitation. You're idea of changing how `macro_rules` works is an interesting one. Want to do it? :)
I'll gladly trade you for my Romanian literature essays :P. Seriously though, I won't be writing much code for the next month or so (finally graduating highschool woo :D!), and I try to make up for it by interacting with the (nicest `&lt;3`) community here and there.
&gt; I'm personally finding it difficult to understand exactly what problem you're trying to solve? Could you maybe post some code to help me understand? I second this. The problem sounds like it might be relevant to my work on rust-gnome but I have no idea so far.
It's funny 'cause Gnome is has been going in the Mac direction for a while and it's becoming ever more sucky.
The way I see things is that glium is OpenGL-centered, and gfx is nextgen-centered. Gfx has an OpenGL backend, but it's mostly a proof of concept and a way for people to start using it right now, while the real benefits of gfx will come with Vulkan/DX12/Metal. Most of the commits on gfx right now are for the high-level interface. On the other side, glium tries to handle compatibility with all OpenGL versions, do extensive checks, provide all OpenGL features (including work towards the "zero driver overhead" paradigm), etc. It really dives into OpenGL. 
Yup, that is the flag I'm looking for. Unfortunately rust starts squawking with other errors. I was hoping it would be as simple as gcc's 32-bit switches under its 64-bit compiler, but that doesn't seem to be the case. I'll have to play around with setting my environment up with 32-bit rust for this special case. Thanks for your help. 
Yes, but can the memcpy be elided? Also, will the destructor only be called once after a move?
It prints it, but if you catch it that way it won't abort the entire process, so unless printing to stderr (or whatever Windows does) is actively harmful, it should be OK.
Coincidentally, I made a PR just hours ago that improves the memcpy elision behaviour. We still have things to do in that regard though. Non-zeroing drops will open up a few opportunities for further improvements (both in LLVM optimization as well as in codegen in rustc that avoids unnecessary copies, along with a few other smaller things). Edit: I'm dumb and forgot to link to the PR: https://github.com/rust-lang/rust/pull/25616
BTW here's a small-ish prototype of where I was going (please forgive all the unsafe transgressions... what I'm doing is gross): type VtablePtr = *const (); type ThisPtr = *const (); unsafe trait ComObject { fn get_vtable(&amp;self) -&gt; VtablePtr; fn get_this(&amp;self) -&gt; ThisPtr; } #[inline(always)] unsafe fn coerce_vtable&lt;'a, TVtable&gt;(src: VtablePtr) -&gt; &amp;'a TVtable { ::std::mem::transmute(src) } #[inline(always)] unsafe fn coerce_this&lt;'a, TThis&gt;(src: ThisPtr) -&gt; &amp;'a TThis { ::std::mem::transmute(src) } trait IUnknown : ComObject { fn do_something(&amp;self) { let vtable: &amp;FooVtable = unsafe { coerce_vtable(self.get_vtable()) }; let this = unsafe { coerce_this(self.get_this()) }; (vtable.test)(this); } fn as_unknown(&amp;self) -&gt; &amp;IUnknown { unsafe { &amp;*coerce_this::&lt;Foo&gt;(self.get_this()) } } } trait IBar : IUnknown { fn do_other_stuff(&amp;self) { let vtable: &amp;BarVtable = unsafe { coerce_vtable(self.get_vtable()) }; let this = unsafe { coerce_this(self.get_this()) }; (vtable.test2)(this); } fn as_bar(&amp;self) -&gt; &amp;IBar { unsafe { &amp;*coerce_this::&lt;Bar&gt;(self.get_this()) } } } struct FooVtable { test: extern "stdcall" fn(this: *const Foo) } struct Foo(FooVtable); impl IUnknown for Foo {} unsafe impl ComObject for Foo { fn get_vtable(&amp;self) -&gt; VtablePtr { unsafe { ::std::mem::transmute(&amp;self.0) } } fn get_this(&amp;self) -&gt; ThisPtr { unsafe { ::std::mem::transmute(self) } } } struct BarVtable { _base: FooVtable, test2: extern "stdcall" fn(this: *const Bar) } struct Bar(BarVtable); impl IUnknown for Bar {} impl IBar for Bar {} unsafe impl ComObject for Bar { fn get_vtable(&amp;self) -&gt; VtablePtr { unsafe { ::std::mem::transmute(&amp;self.0) } } fn get_this(&amp;self) -&gt; ThisPtr { unsafe { ::std::mem::transmute(self) } } } struct Ptr&lt;T: IUnknown + ?Sized&gt;(*mut T); impl&lt;T: IUnknown + ?Sized&gt; ::std::ops::Deref for Ptr&lt;T&gt; { type Target = T; fn deref(&amp;self) -&gt; &amp;T { unsafe { &amp;(*self.0) } } } extern "stdcall" fn test(_: *const Foo) { println!("Doin' Unknown stuff, dude!"); } extern "stdcall" fn test2(_: *const Bar) { println!("Doin' IBar stuff, baby!"); } fn do_unknown_stuff(src: &amp;IUnknown) { src.do_something(); } fn do_bar_stuff(src: &amp;IBar) { src.do_other_stuff(); } fn main() { let mut foo = Foo(FooVtable { test: test }); let ptr: Ptr&lt;IUnknown&gt; = Ptr(&amp;mut foo); do_unknown_stuff(&amp;*ptr); println!("-----"); let mut bar = Bar(BarVtable { _base: FooVtable { test: test }, test2: test2 }); let ptr: Ptr&lt;IBar&gt; = Ptr(&amp;mut bar); do_unknown_stuff(ptr.as_unknown()); do_bar_stuff(ptr.as_bar()); } In COM, every type contains a pointer to the vtable for that type. COM is inheritance based, so I've spent time in the past modeling that functionality (example here https://github.com/dx-rs/dx_core/blob/master/src/unknown.rs, note that I'm in the process of ditching the macros entirely for the sake of clarity). I've modeled the inheritance in COM as a series of traits that inherit, each trait has a default implementation that coerces the vtable pointer to the associated vtable type for that trait. Up until now I've been working with directly exposing the structs that contain their vtable pointer and holding those in smart pointers. I figured it could be of potential use to provide this via object-safety, as a way to hide away some of what I perceive as gory details, but when reflecting on it... I don't think I need to do that at all. I can do this entirely through the original direction I was going, using much of what I learned from my prototype to help really clean up the code and reduce the number of macros required.
 fn add(x: &amp;i32, y: &amp;i32) -&gt; i32 { *x + *y } fn main() { let mut num = 3; let double_num = add(/* ??? */); } If `&amp;thing` was a mutable borrow for mutable variables, there would be no way to call `add` with two references to `num`, since only one mutable reference can exist at a time.
&gt; I'm also surprised that glutin is so popular, even though its code is mostly a pile of trash (I'm the author) Well 1 of the reasons certainly is the fact that it's a pure rust implementation and isn't glutin being used in servo? Also, all the examples in glium seem to be using glutin.
Good catch, that would work. I usually forget about `DoubleEndedIterator`.
I trust the compiler to do these trivial optimizations, so that I can keep my code more readable. But sure, substitute ```&lt;&lt; 1``` if you wish.
Having source code freely available is a requirement in this day and age. I can't imagine why a publisher would make it so hard to get the example code. 
If you're embedding without an iframe, you trust their code not to inject cross-site scripting, but you worry they could break your layout?
Do we have defined behaviour for a bitshift that shifts more than the number of bits in a type? At least with the multiplication there is no chance of running into undefined behaviour.
The primary reason I'm using default impls here is because the way in which the call into the COM vtable occurs is the same for all types that implement a given type. So having default impls reduces the amount of boiler plate I need to spit out, at the cost of needing to call `std::mem::transmute` to coerce the vtable into the appropriate pointer type. Although when looking at your suggestion it looks like you're saying that I should implement `AsRef&lt;Vtable&gt;` for each `Vtable` a given type can expose, and then doing blanket implementations of `IUnknown` based on all types that implement `AsRef&lt;UnknownVtable&gt;`. Which that makes sense and would actually be quite clean looking (especially since each vtable has a field to it's base vtable for memory layout purposes). My only question here, and this is an area of rust I haven't had time to verify myself, but would that blanket impl of `IUnknown` for all `AsRef&lt;UnknownVtable&gt;` apply to those `AsRef&lt;UnknownVtable&gt;` types that exist in other crates? I'm splitting my library up into several crates along certain lines (Direct3D 11, Direct3D 10, Direct2D, etc) for the sake of modularity. Where as with a default impl I would typically just do `impl ::dx_core::unknown::IUnknown for Texture2D` in the source for the Direct3D 11 crate... so if a blanket impl will work across crate boundaries like that, that'd be absolutely fantastic and even better than the default impls. As for the checking aspect, I've been using generics like `&lt;T: IUnknown&gt;` to ensure that only those types which implement `IUnknown` can be passed in. These methods then assume that the type is actually an `IUnknown` on the COM side of things and just does unsafe coercions of the vtables into the vtable of that particular interface. This effectively means it is unsafe for users to implement their own versions of these traits, but as far as I can tell it is safe to consume these traits as long as they're used with the library's implementation of them.
Yay! This was the only thing I was waiting on for one of my next projects! :)
I'd be curious what they said. They don't respond when I ask similar questions. :)
Haha, yeah. And that typo made it into the commit message, too! Embarrassing!
Hmm. You certainly can! http://is.gd/cMKcen Maybe you had something different in mind though---could you share the problematic code?
I personally find `(x &lt;&lt; 1) | bit` much clearer in intent, compared to multiplications and additions. But not everyone internalizes bit streams the same way, so arguing about this is moss likely pointless. One thing to note, though: you probably want wrapping arithmetic, at least that is something you can expect to be optimized.
Not according to the error message. :) Here's [main.rs](https://github.com/archer884/num_filter/blob/master/src/main.rs): extern crate rand; use rand::distributions::{ IndependentSample, Range }; use rand::{ Rand, Rng }; fn main() { let mut rng = rand::weak_rng(); let range = Range::new(1u32, 21u32); let series = random_series(|| { range.ind_sample(&amp;mut rng) }) .take(10) .filter(|n| n &amp; 1 == 0); for n in series { println!("{}", n); } } fn random_series&lt;'f, T: Rand, F: Fn() -&gt; T + 'f&gt;(f: F) -&gt; Box&lt;Iterator&lt;Item=T&gt; + 'f&gt; { Box::new((0..).map(move |_| f())) } The error message reads: cannot borrow data mutably in a captured outer variable in an `Fn` closure I know it says "Fn" and I asked about "FnMut", but trial and error suggests that none of them work, so... meh. Edit: here's the original error message: cannot borrow captured outer variable in an `FnMut` closure as mutable Entertainingly, they both seem to highlight different parts of the code, and they're worded slightly differently. I'm not sure if that's significant or a result of ongoing work.
The likely problem probably is that your rustc doesn't have 32-bit versions of the various crates it comes with in compiled form, such as libstd. Maybe it'd be a good idea to have it ship with both 32-bit and 64-bit versions of those for 64-bit builds.
Wow. The error message is really confusing here. Try using: fn random_series&lt;'f, T, F&gt;(mut f: F) -&gt; Box&lt;Iterator&lt;Item=T&gt; + 'f&gt; where T: Rand, F: FnMut() -&gt; T + 'f { I changed `Fn` to `FnMut`, but as you said, that doesn't work. The key was changing `f: F` to `mut f: F`.
**EDIT** Wait this actually has those traits, and they are implemented for the primitive types, I just didn't look hard enough. Thanks!! :D *Old response* Not quite; the stdlib used to have traits named e.g. "Float" that were implemented for f32 &amp; co. So I could do something like... struct Vector2&lt;T: Float&gt; { ... } ...which would then allow you to create a Vector&lt;f32&gt; or Vector&lt;f64&gt;, but not e.g. a Vector&lt;Foo&gt;. The traits seem to have been removed... (That's a cool crate, though!)
That's good to know, thanks! Going to definitely be rethinking a bit of my design here. Pretty sure going the `AsRef` route will really clean up a lot of the unsafe transmutes I've been having to do.
This week in Rust: WE RELEASED RUST 1.0 BOOYAH
I think it should *mostly* build. I plan to get back to working on it again at some point, so we'll see.
Multiplying a number with 1 can never overflow so that did not worry me much :p
They are same. The `where` syntax is canonical, while the ~~former~~ `&lt;T: Trait&gt;` form allows for a simpler code. One case that `where` is absolutely required is bounding [associated types](http://doc.rust-lang.org/book/associated-types.html) of given type parameter. EDIT: Wasn't sure which one is the former :)
Ah, perfect. Thanks!
[`slice_chars`](https://doc.rust-lang.org/std/primitive.str.html#method.slice_chars) is not very efficient from the documentation (and not stable). Perhaps you could work directly with byte indices (as wrongerontheinternet suggested via the `CharIndices` iterator probably) ?
I'm surprised there wasn't a colorful banner and lots of celebrationary text up top about that tbh. /u/Gankro, you're slipping ;)
Thanks for correcting me!
I think that statement was about NRVO (named return value optimization), which may happen, but is not guaranteed in all cases (something because of conditional drops).
I'm pretty sure /u/brson has been solely responsible for twir for like the past 20 weeks.
FWIW, my emotions on 1.0 can be expressed through the following artisinal gifs, hand crafted by a Canadian teenager, preserved for several years on the finest cloud services, and served on a rustic static http server: * http://cglab.ca/~abeinges/misc/tc-archive/533tribalChallenge.gif * http://cglab.ca/~abeinges/misc/tc-archive/544codeslam.gif * http://cglab.ca/~abeinges/misc/tc-archive/215ohfuckya.gif * http://cglab.ca/~abeinges/misc/tc-archive/93husfruit.gif
&gt; Can this be done without the clone? You can do it using [`cloned()`](http://doc.rust-lang.org/std/iter/trait.Iterator.html#method.cloned) instead of using the manual [`map(...)`](http://doc.rust-lang.org/std/iter/trait.Iterator.html#method.map). ([playpen](https://play.rust-lang.org/?gist=41b4038e0dcc9cea1ba3&amp;version=stable)): fn main() { let vals : Vec&lt;i32&gt; = vec![1, 2, 3, 4]; let even : Vec&lt;_&gt; = vals.iter().filter(|&amp;x| x % 2 == 0).cloned().collect(); println!("{:?}", even); } &gt; What if I want to move elements from vals into even instead of copying? You can use [`into_iter()`](http://doc.rust-lang.org/std/iter/trait.IntoIterator.html#tymethod.into_iter) instead of [`iter()`](http://doc.rust-lang.org/std/vec/struct.Vec.html#method.iter) for this. ([playpen](https://play.rust-lang.org/?gist=2ab9fecbedbdd64860d1&amp;version=stable)): fn main() { let vals : Vec&lt;i32&gt; = vec![1, 2, 3, 4]; let even : Vec&lt;_&gt; = vals.into_iter().filter(|&amp;x| x % 2 == 0).collect(); println!("{:?}", even); } &gt; In the work around, I am done after the inspect() step, but still have to run collect() because an iterator is lazy. Is there another way to consume an iterator? There are a variety of methods that consume the iterator, by virtue of necessarily going through all of the elements, but none of them are all that idiomatic: * [`count()`](http://doc.rust-lang.org/std/iter/trait.Iterator.html#method.count) * [`last()`](http://doc.rust-lang.org/std/iter/trait.Iterator.html#method.last) * [`collect()`](http://doc.rust-lang.org/std/iter/trait.Iterator.html#method.collect) There has been a proposal for adding a [`foreach()`](https://github.com/rust-lang/rfcs/pull/582), that acts like `map()` or `inspect()` but is used explicitly for its side effect and thus consumes the iterator rather than just producing another one. It was deemed to be a bit redundant, as most use cases could just be replaced with a `for` loop. ([playpen](https://play.rust-lang.org/?gist=0b723a829ba5365d7857&amp;version=stable)): fn main() { let vals : Vec&lt;i32&gt; = vec![1, 2, 3, 4]; let mut even = Vec::new(); for x in vals { if x % 2 == 0 { even.push(x); } } println!("{:?}", even); } There [is a version in of `foreach` in the `itertools` crate](https://bluss.github.io/rust-itertools/doc/itertools/trait.Itertools.html#method.foreach) if you really prefer this way of doing things (and if enough people do use that, it might be reconsidered for inclusion in the standard library).
I'm not sure about the actual symptoms, but I should note that the last image (`93husfruit.gif`) has a quite visible flash. My calculation suggests that the flash itself (~10 Hz between `#00ff33` and `#99ffcc` on the white background) is marginal, but still be warned if you are prone to [photosensitive epilepsy](http://en.wikipedia.org/wiki/Photosensitive_epilepsy).
Would it be presumptuous of me to issue a PR to have my own project added to the "Project Updates" section?
Yes, multiple raw pointers in a unsized struct are allowed. However, if you are going to create a fat pointer like `&amp;'a Sparse` then *you* (not the compiler) must make that all the raw pointers are valid for the lifetime `'a`, which is why creating fat pointers is an unsafe operation.
I see. Thanks. I suspect I'm missing the right postgres dev package. It builds on my laptop at home, but not on my minimum install server at work. I'll compare what I've got installed tonight. Thanks again.
Can someone explain to me what that actually means for me and how I will program in Rust? I'm not sure exactly how this impacts me.
Sorry if this is not a programming language specific question. Can I use Rust to develop firefox plugins? Also, I have a Flame phone (Firefox OS) phone. Can I use it develop apps on it? I could not find anything online about this. Going through some talks and online articles, I am sold on Rust :) Just looking for some ways I can develop something useful for myself.
I don't think that this kind of thing exist but you could take a look at [rust-awesome](https://github.com/kud1ing/awesome-rust) and try to find out something that isn't created or up to date.
Thanks you for this clear explication! Great hack! 
Debian archive updates 4 times a day. At the moment, 1.0.0 release (not beta) was uploaded but is waiting for the next update. Time to next update: https://ftp-master.debian.org/dinstall.html
Nice! But cargo is still missing, I assume?
Yes. Since all official Debian packages must be built from source, packaging cargo requires packaging all dependencies of cargo, which will take some time.
`&lt;T: Trait&gt;` is former syntax.
IIRC, there is currently no way to tell LLVM to remove optimizations. Which is a pity, because Rust's static guarantees would be a boon to correct crypto implementations. Note that it should be possible to compile to LLVM byte code and use LLVM with a custom configuration to create a binary with controlled optimizations, but I don't know if this has been done yet.
I've yet to hear about either of these SQL-related essentials: * An abstraction layer to avoid manual code duplication when a web apps needs both PostgreSQL for large-scale installations and SQLite for "run your own copy without being a geek" downloads. * A schema migration system that is advanced enough to work around SQLite's limited support for `ALTER TABLE`. That latter one is especially important since "Use a good schema migration tool and don't fear rapidly iterating your schema" is the *proper* answer to the "schemaless" aspect of the NoSQL database craze. (ie. It's Rust's "comfortable static typing" to the NoSQL craze's Python/Ruby/etc. dynamism.)
`nadeko` does this with inline assembly - see more discussion in [a previous reddit post](https://www.reddit.com/r/rust/comments/3696wt/checking_that_functions_are_constant_time_with/).
Yes, but it only works on amd64.
There are a variety of volatile operations in [`std::intrinsics`](http://doc.rust-lang.org/nightly/std/intrinsics/) which will not removed. I'm sure this sort of functionality will be stabilised at some point, since it is useful and desirable.
Firefox has an API for C plugins, so yes. Servo actually runs on the Flame (https://github.com/servo/servo/tree/master/ports/gonk). Just compiling with the NDK toolchain that comes in a B2G build works. But this will run on bare gonk; making a Firefox OS app won't work. I've tried a bit (not sure though), but I don't think there's a way to have native FxOS apps without modifying the OS beforehand. Perhaps there will be in the future.
I'm not seeing any inherent difficulties to supporting ARM or MIPS. x86 on the other hand, has fewer registers than x64, maybe not enough for nadeko's usecases. But we won't know until it gains support for those architectures and it's tried on crypto algorithms with a lot of state to keep track of.
So since 1.0 is stable now, I guess the "Breaking Changes" section will disappear for the time being ... It's almost sad to see it go :)
That's great!
Great stuff, particularly the count_exprs bit. Been looking for something like that so I can stop giving element counts as macro parameters for defining static arrays.
You've got `path: &amp;'a str` in lookup which is an unnecessary restriction.
I wonder if old versions of rustc in stable distributions will lead to any problems in the future.
They don't make releases so it's a bit hard for distros to package it. Arch doesn't have it for the same reason.
C++ doesn't have a guarantee either, e.g. reference cycles will annul destructors in C++ in the same manner that they do in Rust.
Rc has been exposing soundness and design holes in Rust for *years*, it's part of the reason why the language looks the way it does. It's a very important abstraction to the community &amp; language designers, but also it's common in the compiler and in Servo and elsewhere.
Heck, Rust is not C++, why should it mimic C++? Also unsafe in rust is a escape hatch for memory unsafety not C++ish mode. Anyway this section raises a red flag &gt; Despite these things, at least there is a single way to violate every safety claims made by Rust. Please elaborate and/or file a bug report.
What's the story like now when it comes to dynamically linking packages that are normally built with Cargo? Relatively easy to achieve?
Prediction: the next 6 months introduces new rust features everybody comes to love and rely on, resulting in the Debian package being stale and useless for the next 2 years :P~ (of course I'm being flippant, this is useful and great to see.. it'll just take a few more rotations around the sun before 'apt-get install rustc' will do what we want)
You're probably aware that "ugliness" is not exactly an objectively measurable quantity. Talking about the compiler, you should note that its codebase has evolved over a number of fairly radical changes to the language itself and thus does not use state-of-the-art idiomatic Rust 1.0 everywhere. I assume that a large project written against a stable Rust from the beginning would evolve somewhat differently in this regard. Coming from a C++ background you're probably used to a certain way of doing things. Rust is pretty different in many respects. And the issues you mentioned start to make much more sense, once you understand the motivation behind. For instance, what you said about references: after having used both Rust and C++ for a while I find Rust's approach much clearer, as it effectively lifts references into the same mental category as other pointers. It's pretty explicit regarding the difference between references and values. On the other hand there are Deref-coercions to improve the ergonomics without losing this explicitness. Then again, the question is, of course, whether one likes explicitness.
Perhaps you want to join us at [rust-clippy](https://github.com/Manishearth/rust-clippy/)? It's how I'm learning Rust, anyway. Otherwise, a parser to create an [automaton](https://github.com/carllerche/automaton) from a RegExp would probably be most welcome (and could become part of the regex crate). Or perhaps you want to work on rustdoc? Even a partial solution to [#12466](https://github.com/rust-lang/rust/issues/12466) would be greatly appreciated.
If `to_owned()` is faster than `to_string()` for converting `&amp;str` to `String`, why does everyone, including The Book, use `to_string()`?
Rust has deref coercions ([book](https://doc.rust-lang.org/book/deref-coercions.html), [rfc](https://github.com/rust-lang/rfcs/blob/master/text/0241-deref-conversions.md)). It's midway between being fully explicit and having spooky action at a distance (like C++). As the RFC puts it, it conserves local reasoning in practice.
&gt; Why can't the single arena module be marked unsafe and be implemented the way it is done in C++? Maybe it still needs to be optimized. For example [LinkedList](http://doc.rust-lang.org/nightly/std/collections/struct.LinkedList.html) is using unsafe to avoid needing `Rc` and I think it looks pretty nice. 
He is talking about unsafe blocks. 
Will it lock out arbitrary IPs in case Bobby Tables tries to log in?
Thanks! This is much more elegant and simpler than what I had!
Sorry it's a Twitter thread, didn't have time to do a proper write-up. UPD: Also sorry for typos :|
[**@mkpankov**](https://twitter.com/mkpankov): &gt;[2015-05-20 14:06:47 UTC](https://twitter.com/mkpankov/status/601026285574455296) &gt;hahaha, the irony of building a large C\+\+ project: you do \`make \-j\`, it spawns a bit too many compilers and linkers, PC swaps out... ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/36mmfq%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
freakin' beautiful code. Thanks a lot.
Thanks, glad you like the slides! I don't have time to keep them up to date, but I'd gladly accept [pull requests](https://github.com/kmcallister/kmcallister.github.io/blob/master/talks/rust/2015-contributing-to-rust/slides.md).
Solution println!("{}", (1..).find(|&amp;n| (1..10).all(|m| n % m == 0)).unwrap());
It's being destructured. http://rustbyexample.com/flow_control/match/destructuring/destructure_pointers.html
Is that all that `plugin = true` does? I was under the impression that it also got built with some special compiler options. It would be nice to just have one macro crate. However, there is a cargo issue we'd have to deal with. Say one dependency used serde_macros that was compiled as a plugin and a `nightly` flag, and another serde_macros was compiled targeting syntex with a `with-syntex` flag, cargo will union the two features flag sets together, which would probably not work. At one point I actually had everything setup so both flags could be present at the same time, but it was unwieldy so I went with this current scheme. Cargo does let you specify the crate root file, but it doesn't let you dynamically pick the entry point based on feature flags. The only way really to have two entry points is to do what I did and have two crates that `include!(...)` the real library body.
That's because [`Rem`](http://static.rust-lang.org/doc/master/std/ops/trait.Rem.html)`&lt;i32&gt;` is implemented both for `i32` and `&amp;i32`, so you can destructure/dereference it or not.
&gt; New floating-point to decimal formatting routine. lifthrasiir completely rewrote Rust's floating point to string conversion to employ the Grisu algorithm. This causes some slight changes to Rust's formatting output. Is this kind of change legit for the 1.x series?
Is |&amp;n| more rusty than just |n|?
`|&amp;n|` emphasises the fact that iterator yields references and `n` is a `Copy` type (it's just int), so I think it makes code more obvious (there's also one more alternative – using `|n|` and then `*n`). On the other side, `|n|` is more generic (it would work for eg. `n: &amp;BigInt`), although (especially when auto-deref hides `&amp;`s from you) it's sometimes common to end up with `&amp;&amp;&amp;&amp;&amp;T` types without noticing it.
hey, you're cheating, that wasn't an *easy* question! :)
&gt; The guarantee that destructors are run seems like an extremely useful thing to have, not necessarily for memory safety, but for program correctness. This is the same misconception that /u/haberman had above. Nobody was talking about guaranteeing that destructors were run, full stop: that is impossible as long as you have the ability to do reference counting at all (without some sort of stop-the-world cycle collector or something like that).
Hmm, this bugs me for a reason I can't fully articulate yet (though I understand it's unrelated to this change). So if I'm understanding correctly, in the old world you would at least know that the struct is ultimately still owned by someone who will eventually drop() it (modulo the Rc problem), whereas in the new world it might get leaked completely.
It's probably just that `?Sized` is special cased, and so that's just missing, if I had to guess. You can't do `?Foo` for arbitrary traits.
A cycle of `std::shared_ptr` (or other refcounted smart pointers) will leak, but the destructor of `std::shared_ptr` itself is guaranteed to run if the scope it is allocated in is ever terminated.
&gt; Am I seeing results that are typical? Absolutely. &gt; If so, can anyone share some insight into why -O is so different? Well, I mean, turning on optimizations is just going to make things faster, by their nature. There's all sorts of things that can be done. You can read up here: http://llvm.org/docs/Passes.html (or maybe someone else more familliar with LLVM can give you a better link)
No no, using `unsafe` blocks should break nothing: &gt; And note, unsafe code isn't for violating Rust's invariants, it's for maintaining them manually [-ms2ger](http://this-week-in-rust.org/blog/2015/04/27/this-week-in-rust-79/) What happens is simply that rustc can't help you check it. Think of it as “trust me”. If you're used to C++ this is what it does, doesn't it? It's always in “trust me” mode.
perhaps you should google MSVBNR.EXE and reverse engineer it.
&gt; *363* minutes spent hitting Github’s API to get the comment numbers here I'm not sure about other numbers.
That's, uh, rather random. And three months after I posted this thread.
By using `-O` you are trading the compile time with the execution time. Depending on the number of compiles and executions you may or may not want to use `-O`. (Same for varying degrees of `-C opt-level=N`, where `-O` actually equates to `-C opt-level=2`.)
| turning on optimizations is just going to make things faster Well, yeah. :-) But 15x faster? I don't think of that amount of gain as typical for a language like C. If it's typical for Rust, that's interesting. If that gain is coming mostly from "stuff that LLVM is doing", rather than "stuff that rustc is doing before LLVM gets its turn", that's even more interesting. I think I need to dig deeper. Run valgrind/callgrind. Maybe read some IR.
OK sure, `unsafe` allows you to *temporarily* break invariants normally secured by the type system… I'd say it's extremely unintuitive that something like `mem::forget` shouldn't require a "trust me" block like that.
Partial answer: &gt; 363 minutes spent hitting Github’s API to get the comment numbers here
&gt; I don't think of that amount of gain as typical for a language like C. If it's typical for Rust, that's interesting. Rust knows _way more_ about your code than C does, and so we can be much more aggressive with our optimizations. One great example of this is that every `&amp;mut` can basically be the equivlanet of `restrict` in function arguments in C, as we know there's no aliasing going on. See `noalias` in http://llvm.org/docs/LangRef.html &gt; If that gain is coming mostly from "stuff that LLVM is doing", rather than "stuff that rustc is doing before LLVM gets its turn", that's even more interesting. It currently is. We've mostly been focused on language semantics, and feed LLVM sub-optimal IR all the time. 
&gt; (I'm a Rust newbie.) I should probably have started my post with a more precise intro, like "I'm a Rust newbie, but I've been writing C and assembler since Reagan was president, and I once wrote a C compiler that could build itself." :-) Or maybe I should have just remembered that you guys launched 1.0 a few days ago and you are drowning in questions and my non-urgent wonderings about the arcane details of the compiler can probably wait. If anybody who hacked on the rustc optimizer is dying to expound, I remain curious. Either way, no worries. Rust is awesome, yadda yadda yadda...
&gt; Perhaps the key is to understand unsafe not as something that breaks the type system, but something that specifically breaks memory safety? The only thing `unsafe` does is let you do three things: 1. Call functions marked `unsafe`. 2. Access or update a `static mut` variable. 3. Dereference a raw pointer. Through 1, all sorts of things can happen. But just adding `unsafe` around a block of code doesn't really change anything, if you get what I'm saying. `unsafe` blocks are still expected to uphold Rust's invariants, you're just vouching that you hvae checked them, since the compiler cannot.
A lot of it is probably boiling away iterators (which is a special case of inlining trivial functions). Iterators inherently require more optimizations to make fast than for loops do. This isn't a problem with Rust, though. One of the primary reasons why optimizers are great is that they allow you to use high-level constructs, like iterators, without paying a performance penalty. If we avoided abstractions because they required optimizations to make fast, we'd just be making our lives harder by denying ourselves the benefits of decades of compiler optimizations.
One thing to remember is that format expressions get compiled into some extra boilerplate code. An expression like `format!("{} {}", foo, bar)` is a macro, that gets typechecked at compile time, and turned into the equivalent of a special purpose anonymous functions that take objects of the types provided and calls `Display::fmt` on them. Without optimizations, all of this extra boilerplate and dispatch gets left in. Much of it is stuff that's trivial to optimize out, so when you do so with optimizations it will be, but without optimizations, there will be a lot of trivially optimized code sitting around. Contrast C, where `printf` is just a standard library function, and your standard library has been compiled with optimizations most likely. If you want to explore further, you can play around on [Playpen](https://play.rust-lang.org/) and generate ASM and compare what debug and release looks like. I recommend using `#![crate_type = "lib"]` when doing so so you can avoid having to look through the stub code used to invoke `main`; just remember to also mark you functions `pub` so they'll actually be exported and thus included rather than just compiled out.
I don't think that LLVM code is that elegant: http://llvm.org/docs/doxygen/html/ErrorOr_8h_source.html It seem to have much more boilerplate than Rust: https://doc.rust-lang.org/src/core/result.rs.html#245-253
That's great to hear.
If we add `...` as syntax for inclusive end ranges, then either your macro will break or the macro_rules extension has to mitigate it somehow.
Bahahaha; it's too late! It's stable now, there can do nothing, *nothing!* Honestly, though, that never occurred to me before. :P
Unsafe just says that by using it, you're maintaining the invariants instead of the compiler. It's like saying, "I know this looks funny, compiler, but treat me - I got this". 
Two compilers?
This is precisely the same as Rust. The `Rc` itself, when stored on the stack, will still have its destructor run. It's only when you move an object into an `Rc` (or any number of other things) that *that object's* destructor might not run.
The guarantee has only been clarified, not removed. The destructor of a value on the stack will still always run if and when its stack frame is unwound. The times a destructor will not run are the same as C++- reference cycles, infinite loops, etc. Technically one exception is values that have been moved, where C++ relies on the destructor to work on "empty" values and Rust just prevents it from running.
Too bad this isn't working: `(1..).filter(|x| (7..13).all(|y| x % y == 0)).take(5).map(|x| println!("{}", x))`
I stop listening after "gonna start with something retardedly simple" in the warmup video. I hope they get better. 
I guess, inlining makes the most of the difference. In Rust pretty much everything is a function call, all the trait dispatch is done through functions, loops are implemented with function calls (`next()`). Apart from generating a lot of code function calls prevent other optimizations. From the recent [blog post](http://hubicka.blogspot.ru/2015/04/GCC5-IPA-LTO-news.html) describing optimization improvements in GCC 5: &gt;Inliner is by far the most important inter-procedural optimization pass of every modern compiler. This is because most of optimization still happens intra-procedurally and inlining is essential to make it trigger. *Modern programs use a lot of function call based wannabe zero cost abstractions* that constantly bring new challenges to the inliner heuristic implementations.
&gt;&gt; I don't think of that amount of gain as typical for a language like C. If it's typical for Rust, that's interesting. &gt; Rust knows way more about your code than C does, and so we can be much more aggressive with our optimizations. The other side of that coin kinda is that Rust is designed to be optimized and idiomatic un-optimized Rust is really slow. 15x improvement might sound initially impressive until you compare the absolute numbers, or in other words it is easier to improve when your starting point isn't all that great.
I disagree completely. Gnome 3 is the prettiest desktop on Linux there is. If you don't like it, use KDE, or XFCE, or something.
&gt; Note that, as a consequence of this, there are some things you can't do with macros, such as have one which expands to the identifier for a function declaration. What do you mean by this? Would you mind clarifying?
In some benchmarks, we are / were faster, yes.
Some previous discussion at https://internals.rust-lang.org/t/stage0-in-a-post-rust-1-0-world/1119
But then, there's no need to choose an slower method if there is a faster one that is just as accessible. Whether the speed difference will be removed some day will be seen, but I'm somewhat skeptical for now. Use `to_owned()`. :)
Future improvements to the language should hopefully make it possible to "specialize" `.to_string()` on `&amp;str` such that it avoids the string-formatting framework that every other implementation of `.to_string()` requires. In the meantime (and until we're sure whether this specialization will be possible), I recommend `.to_owned()`.
So to make sure I'm understanding what you mean, using CharIndices would allow me to iterate a bunch then save off two byte offsets (one on the first char I want to save, and the second on the char after the last one I want to save), which would then let me do something like? Or am I misunderstanding mystr.as_bytes()[offset1..offset2].as_slice() // on my phone and can't check if this is right
This is totally why I never posted these here myself. :)
&gt; Why couldn't Rc have been modified to guarantee eventual freeing, even if very delayed, or compromised in some other way rather than breaking RAII for the whole language? Because delayed wouldn't work with what people want from RAII: known moments of deletion. Compromised would require converting `Rc` into just another form of RAII. That's what must be understood: `Rc` is an alternative to RAII and as such cannot be used. Rust doesn't have RAII at it's core, that is it doesn't require it (a way to do it, for example, would be to make all variables linear and require explicit dropping if not used) but this isn't what Rust is about, it's about a saner, but still unlimited system.
Except that the type system doesn't guarantee those invariant. A block promises that it will call the destructor of everything it owns (the closest type to that is a Closure), but this isn't something that's guaranteed by the type system or anything within the language, it's merely something that you are told. Lets look at `std::mem::forget`'s type pub fn forget&lt;T&gt;(t: T) Notice that it asks for ownership of the thing you give it, and it's moved in there. Once its "inside" there the only rules that apply to how to handle the resources are those that `forget` defines. Unlike most functions, forget doesn't free the resource nor call the destructor.
C++ doesn't guarantee that destructors will be ran all the time. Rust, like C++, guarantees that if a variable is removed from the stack, its destructor will be called before freeing the data. This is not guaranteed for everything else. So if I have something like: fn drop_rc&lt;T&gt;(r: Rc&lt;T&gt;) { // do nothing with the Rc, just drop it } Rust promises that `Rc`'s destructor will be called, but `Rc` doesn't promise that `T`'s destructor will be called. So don't make a piece of code that will crash your program if the destructor isn't called. Don't let objects enter an invalid state and only exit it when the destructor is called, don't require a destructor to ensure a thread still exists. To avoid leaks use `Rc` as little as possible. `Rc` leaks actually are hard and complex, so as long as your code doesn't have them everywhere it should rarely lead to leaks. If you really have to use `Rc` everywhere, consider waiting (or developing yourself) `Gc` instead.
&gt;182,267 lines added/removed by the single largest commit 5f066e0 (according to git show --shortstat) Ahh, I wonder if the commit message was "."
Unfortunately not: commit 5f066e06b991041f2c1d988f493d5b29f8e56b7e Author: Erick Tryzelaar Date: Fri Sep 23 16:13:14 2011 -0700 Update to libuv commit 3ca382. This patch changes libuv's gyp build system to make it's own makefiles. To generate them for rust, run these commands. They requires python 2.x to work: $ mkdir -p src/rt/libuv/build $ svn co http://gyp.googlecode.com/svn src/rt/libuv/build/gyp $ ./etc/src/gyp_uv
What's your issue with the arena module? Is it with `Arena` itself? `Arena` isn't really that useful (not just due to performance concerns; its API is limited in a number of ways due to safety reasons, and since nobody really used it it was almost removed entirely). People pretty much exclusively use `TypedArena` unless they have no other choice. `TypedArena`'s performance could certainly be improved, and there are lots of things its API could potentially support that it doesn't (but a lot of these things would be tradeoffs, not pure wins), but other than the `RefCell` and lack of placement new (which is just something Rust doesn't have yet) there's nothing about its implementation that's slow "because Rust." Regular `Cell`s are zero cost, BTW (well, compilers can't assume they're unaliased so that inhibits optimizations somewhat, but that's kind of the point). It's entirely possible to write very high performance Rust. If you really want to write a high performance library, safety isn't an obstacle: you just start with `unsafe`, then make the API safe when you're finished the initial round, then focus on using types to improve internal safety without compromising on performance. Steps two and three are the interesting part of Rust, but that doesn't mean it can't do (1). There are definitely a lot of features I would like to see that aren't there yet (I can spout off a huge laundry list), and it doesn't have all the highly optimized libraries C++ does yet, either. Mostly, these impact generic code, so you can work around them for the time being by writing a very high performance library that is limited to a few types, or uses macros where you'd rather use generics, and then transition it to be properly generic as Rust continues to gain useful features. Rust may have hit 1.0, but it is still very much a work in progress. You are comparing projects that have existed through wildly different versions of Rust, when it had *hugely* different syntax and semantics, to projects like LLVM which have been written by C++ experts over the course of over a decade. Even the Rust core team is still debating what good Rust code should look like; I particularly want to stress that a *ton* of proposals for syntactic sugar were postponed until after 1.0; as people gain more experience with using Rust in the large, we will have a much better understanding of how to improve development ergonomics without sacrificing Rust's goals (fast, safe, and concurrent). I expect tooling to pick up a lot of the slack as well: I suspect that an IDE that understood lifetimes would be an absolute gamechanger in terms of decreasing the slope of the learning curve. I guess what I'm saying is: be patient :) Rust 1.0 is the beginning of the road, not the end.
Very great! Really appreciate the walkthrough. Beer is on me if you're ever in NYC!
For the moment, write a method out manually: fn from_u8(n: u8) -&gt; Option&lt;MyEnum&gt; { match n { 1 =&gt; Some(MyEnum::V1), 2 =&gt; Some(MyEnum::V2), _ =&gt; None, } } Macros may be able to help with this. If you have a C-style enum with specified representation (e.g. `#[repr(u8)]`, you can use `transmute` if you like: fn from_u8(n: u8) -&gt; Option&lt;MyEnum&gt; { if n &gt;= 1 &amp;&amp; n &lt;= 2 { Some(unsafe { mem::transmute(n) }) } else { None } }
I am not saying that Rust should mimic C++. What I meant was why the `Arena` can't be written in the same way it can be done in other non-GC'd languages? And that includes C, C++, Pascal, Ada, Obj-C and even D. See how the `Chunk` type is implemented. Why can't the data be just a `vec` of `u8` or a statically sized array of `u8`? Why bother with this `Rc` of `RefCell` of `vec` of `u8`? Is there a need for `Rc` or `RefCell` here? Though I am not worrying about performance at all. The point I was trying to make is that there should be a facility to mark the module as unsafe and implement it in the standard way. This approach can be used for these things like memory pools, allocators. In the case of memory related bugs in the future, the source of the bug can be easily identified. 
Hi! I'm in the middle of an effort to add auto-reconnection and reduce the number of allocations that happen during message processing. As soon as the dust settles from that, I'm going to prioritize support for the stable 1.0 branch of rustc. PRs are welcome!
Is non-aliasing pointer info being passed onto llvm? I think I remember reading that the latter could do further optimization if rustc would provide it more details.
My experience has been that Rust's relative performance (with optimization) tends to improve as the program gets larger (probably a combination of "larger programs have more effort put into them", Rust's typically large module sizes and use of generics for basically everything, a general policy of expensive operations being explicit, and Rust having a way better default allocator than the OS default [I suspect this is responsible for a pretty large proportion of benchmarks where Rust outperformed C++, given how much worse most of the Rust libraries still are]). However, as the program gets larger I've *also* found the ratio between the unoptimized and optimized version gets bigger and bigger... I"ve seen 40x multiple times now.