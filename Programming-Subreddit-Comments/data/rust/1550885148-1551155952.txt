That does not change the fact that you are refusing to credit the original author, which is against the conditions of using that code. I fail to see why you're choosing this specific hill to die on. There are two outcomes: you finally add proper attribution, or - worst case - your code is removed and account possibly suspended. Why not just bite the bullet, license properly, and be done with the drama? You obviously are a skilled developer, I don't want that talent to disappear. 
### Random ideaüí° Start a Rust consultancy LLC, make n &gt; 1 times as much, work on a wider variety of real-world projects and be even closer to the action. Incorporation service I've used that's very [fast](https://www.incnow.com/), a commercial [bank](https://www.svb.com), [lawyers](https://www.orrick.com) and IT [insurance](https://www.thehartford.com/business-insurance/computer-web-it)... no need to do everything all at once. Worst case would be getting another job.
There‚Äôs already a few rust consultancies :)
How many of them have you? Right now, 0. Customers would pay a premium for Rust core team member(s) to help them out. Plus, Rust seems to be popping big this year (knock on wood), so it's a good bet that demand will outstrip existing consultancies' ability to hire staff and book work. That means, ka-ching! ü§ë üòâ 
Don't iterator trait objects suck badly?
I think you're lost. 
To be fair, rustc is pretty computationally intensive.
Ur lost
I like it, but the ? operator only prevents bloat if your function can only have one error type. The moment you make a call to a function with another error type, your code size significantly increases. 
It's not clear what you meant by taking too much time to execute. Are you talking about relatively long time rust binaries tend to need to load, or the execution speed once the binary has already started? If the former, look into reducing binary size as much as possible. Also keep your binary cached in memory (perhaps by executing a noop run periodically). If you aren't already, use the system allocator and dynamically link to rust's libstd if you're running more than one binary. If you're on linux, use `strip` to trim any unnecessary information from your binary (thereby reducing its size and decreasing load times). Unfortunately, rust tends to produce very fat binaries by default.
You are in the Rust programming reddit, I think you were after this one, https://www.reddit.com/r/playrust/ . I hope your computer can cope.
You wanted /r/playrust, this is the subreddit for the programming language. Please take the time to check the topic of the subreddit before posting.
I‚Äôm disappointed there was no UI working group. 
Sounds like Mozilla has some leadership problems but the Rust people love what they do. Not unlike most places I‚Äôve worked. 
What would UI working group do? I don't think there is acute needs for language features in service of UIs. An UI working group would belong to the libraries team, not to the lang team.
&gt; Rust seems to be popping big this year (knock on wood) You mean I might be able to get a job that doesn't actively make me long for the sweet embrace of death this year? Guess I'll knock on wood too.
These working groups were specifically about the language. ‚ÄúUI‚Äù isn‚Äôt a core feature of the language, but rather some part of the surrounding ecosystem.
RRT?
This was what I was referencing. https://www.reddit.com/r/rust/comments/agm23a/rust_2019_gui_team/?st=JSGXXPNM&amp;sh=a9644e5d
&gt;it conflict with our existing impression of `await` And why is that a bad thing? **People get used to things like this very quickly**. I assume, learning to write `let x: String` instead of `String x` didn't kill you either. You also survived returning `Result`s instead of throwing `Exception`s. You even managed to live without `null`. Rust doesn't *want* to be as familiar as possible. Rust doesn't carry on traditions, when there's a superior alternative.
I think there's something to my initial hunch. https://rust.godbolt.org/z/7DWJFz The slow version allocates a variable on the stack (at `[rsp + 0]`) and within the loop stores to that location (two instances of `mov qword ptr [rsp], rcx`) The less slow version allocates the same variables on the stack (`sub rsp, 72` since they are necessary for the call to the `print` function), but it doesn't store to the stack location for `s` until the loop exits. This certainly looks like a point of non-optimal llvm generation. There is no call to panic on overflow or anything like that which would require flushing the variable `s` back to the stack, but somehow llvm doesn't recognize and eliminate the dead stores or sink them out of the loop.
A better analogy is getting used to writing ‚Äòfn‚Äô instead of putting the return type first: it‚Äôs a minor syntactical thing that one gets used to practically immediately.
Not really true. \`result.map\_err(MyError::ThisError)?\` doesn't add much code. Still useful for functions that contain functions which only return the same error type, to give them context.
 A[learning management system](https://www.cerego.com/) is a software application for the administration, documentation, tracking.its very good learning.
&gt; 8GB RAM Sad to say that no, you won't fare well trying to link of you only have 8GB. And you can just forget about LTO. 
The ergonomics of the std error trait are horrible. Its impossible to downcast, you have to manually impl display over and over, and description() is just offensive. You can downcast failure to a standard error so its totally compatible. 
Vim-racer won't show you anything by its own. you need something like Deoplete to take advantage of it.
Yea - I'm working with a database where I had to enable 64 columns through diesel... fml
Ahh thanks didn't know
You can use it with Vim‚Äôs built-in completion mechanisms (`:help ins-completion`). Long story short, you should see it work with CTRL-X C
We have a compiler UI working group and we call it Esteban Kuber.
Correct me if I'm wrong, but the input and output buffers are not right next to each other in the C implementation. uint32_t* outBuffer = (uint32_t*) (inBuffer + imageSize); So outBuffer will be equal to (inBuffer + imageSize*4) since inBuffer is a pointer to uint32_t. I don't think it matters though.
So this is an... unfortunate user error that should probably be made into a special case in the compiler. If you try compiling on the Rust Playground, you'll notice the following warnings such as: warning: unreachable pattern --&gt; src/main.rs:13:13 | 11 | Penny =&gt; 1, | ----- matches any value 12 | Nickle =&gt; 5, 13 | Dime =&gt; 10, | ^^^^ unreachable pattern What this warning means is that the enum variant names are not in scope so you either have to explicitly name them (such as 'Coin::Nickle') or explicitly import them into scope with 'use self::Coin::\*'. Currently, Rust treats the left hand side as a plain [binding](https://doc.rust-lang.org/1.15.1/book/patterns.html) which will match on every variant of Coin. Since the first pattern is a plain binding and Rust matches top to bottom, the match statement always follows the first branch.
You are not using `Coin::Penny`, so it's treating `Penny` as a catch-all variable (and so they're all evaluating to `1`). If you prefer your match cases with `Coin::`, you'll get `36`. 
Awesome thanks!
No, it's an A* based method I describe [here](https://www.reddit.com/r/roguelikedev/comments/atk5i4/path_playground_experimenting_with_a/eh20t1o) that's used in similar applications.
Yes, it definitely does, but it's motivated by future plans to add teleporting to the monster's skill set. It's not immediately obvious how I would handle things like teleporting if I had cost distance optimal models so I plan in terms of number of turns. Furthermore, for ease of implementation, all costs are integers. When I get around to supporting floating point types properly (using a wrapper so I can put them in a binary heap, etc) I think I'll be much more able to address that.
There's a hit to what the compiler is doing in the list of warnings. Below the unreachable pattern warnings, there's also a series of these: warning: unused variable: `Penny` --&gt; src/main.rs:11:13 | 11 | Penny =&gt; 1, | ^^^^^ help: consider using `_Penny` instead | = note: #[warn(unused_variables)] on by default What you've done here is create a new variable named `Penny`. You've also done the same for `Nickle`, `Dime`, and `Quarter`. These variables have no restrictions on what they can match, so they watch everything. The reason it's returning 1 is because matching goes from top to bottom, and that was the first one that matched.
Ahhh ok. Thank you for the explanation and now I have learned about clippy. Clippy did highlight that `Penny` will match any value. Also pointed out I should use an iterator, this is going to be really helpful. 
Thank you. I didn't realize that anything could be a catch-all and not just `_`. 
Found the fintech.
Thanks. Coming from C# and switch statements I was expecting it to be an error since it wouldn‚Äôt match the type. But I guess since there is no keyword, like default, anything is the default. 
&gt;Furthermore, for ease of implementation, all costs are integers. When I get around to supporting floating point types properly (using a wrapper so I can put them in a binary heap, etc) I think I'll be much more able to address that. No need to use floating points. The ratio between your non-diagonal and diagonal cost just needs to approximate the square root of two. A non-diagonal cost of 2 and a diagonal cost of 3 is reasonably close and inexpensive to compute. You would also have to change your heuristic to [diagonal distance](http://theory.stanford.edu/~amitp/GameProgramming/Heuristics.html#diagonal-distance) or it would not be admissible and it would not actually find the shortest path. Also, assuming that your heuristic is admissible (which it should be, due to the above), you can boost the speed of your pathfinding by using a radix heap instead of a binary heap. There is a crate (by yours truly) for radix heaps: https://crates.io/crates/radix-heap.
As an aside, you don't need to use `extern crate` anymore with `edition = "2018"`.
Wrong sub
IMHO it is. Our cat sometimes keeps wandering around for days, even in cold wintertime and we began to suspect, she might have a second family. You can currently choose between big trackers targetting a dog/ maybe a cow or you spend lots of money. In both cases you are bound to the vendors apps and infrastructure. I recently bought some cheap LORA modules + serial gps modules with antennas but then i realized that in combination with a small arduino + Lipo battery this would be also to big and heavy.
Super excited to see specialization and GATs having a dedicated working group. 2019 looks very promising!
It's not just a catch-all, it's a _variable_ that you can use on the right hand side of the match arm. 
I have limited experience with Nordic products, but if it is anything similar to what I have seen previously, it can be a challenge to safely interface with the radio stack. The primary reason is that that the AP I is quite callback heavy, and callbacks can come from various other contexts, including such things as interrupt handlers. It would definitely be an advange to have a safe Rust layer on top of this. But I am not sure how easy that will be.
[FYI](https://words.steveklabnik.com/thank-u-next)
`match` in Rust is similar to C# 7.0's `switch`: https://visualstudiomagazine.com/articles/2017/02/01/pattern-matching.aspx
If you want to have a default outcome of a match statement, you can use `_` to match anything not matched by the previous patterns. This is pretty much the equivalent of `default` in C-style `switch`es. match coin { Coin::Penny =&gt; println!("Got a penny"), _ =&gt; println!("No penny"), }
wait, what? I don't get it, why is Penny (according to rust) a valid identifier but also matches anything?
The match arm is similar to a variable binding. You could reduce the match statement to: { let Penny = self; 1 } &amp;#x200B;
Rocket is easier to get into but both should be pretty easy to write the features you've described. Photo uploading is probably best left to S3 presigned URLs so you don't even need to handle file uploads on your own server. And for rich text editors, I'm sure there are plenty of good JS libraries for that already.
I do want to point out that letting cats wander around is somewhat controversial, chiefly because of the potential damage to bird population.
Ohhhhhh of course, yeah i see that now.
They cannot be inlined (and thus optimized so well as static iterators) and each new element in an iterator chain adds another layer of pointer indirection. And in case of boxed iterators ‚Äì each new element is a new heap allocation. So they definitely lose the attribute of being ‚Äòzero-cost‚Äô, and are much worse performance-wise. But they keep all the features and invariants of their underlying iterators ‚Äì they remain lazily evaluated, immutable values remain immutable, etc.
Unpopular opinion: This should be changed and be made an error. OP's mistake seems not obvious, but important enough for stuff like these to cause problems in the future. I'm not advocating for a radical approach like Go where unused variables should make the program not compile (although honestly I don't dislike the approach). But unused branching code on a match statement seems wrong.
I edited your code a little bit. Notice how I added ```Coin::``` in your match #[derive(Debug)] enum Coin { Penny, Nickle, Dime, Quarter } impl Coin { fn value_in_cents(&amp;self) -&gt; usize { match self { Coin::Penny =&gt; 1, Coin::Nickle =&gt; 5, Coin::Dime =&gt; 10, Coin::Quarter =&gt; 25, } } } fn main() { let coins = [Coin::Penny, Coin::Quarter, Coin::Dime]; let mut amount: usize = 0; for coin in coins.iter() { let value = coin.value_in_cents() as usize; amount += value; println!("This {:?} is worth {} cents", coin, value) } println!("I have {} cent(s)", amount); }
Introducing new names in pattern matching is mostly useful with more complex patterns. For instance, the ubiquitous `Some(e) =&gt; ...` where `e` is bound to the value inside the `Option`, whatever it is.
The data model doesn't really depend on Rust but on what you're going to do with the data If you only want to merge and display the data, just using a hash map could work. If you need something more, you could create a struct and fields with proper types like booleans, string, dates, enums and vectors. Instead of parsing command output, you could also look in the Pacman C API, libalpm, and available [Rust bindings](https://crates.io/search?q=alpm).
I'm quite new to rust too, but it appears to me as if waht you're looking for is this: [https://doc.rust-lang.org/book/ch17-00-oop.html](https://doc.rust-lang.org/book/ch17-00-oop.html) I'm unsure of the specifics of the question you're answering, so here goes a random guess of how I would approach this: A single struct with all the datafields that you need and different functions that print the specific information requested. That way I guess you have 'least fields' repeated. Naturally another way to approach this would be with a struct dedicated to every type of information request. This may be a good idea if there are only 2, maybe 3 possible request, more than that I would say the unified struct seams like a better idea.
Controversial indeed. I'd argue pro wandering cats because they fill the gap of missing natural enemies for small mamals like mice in our area. In my area (central europe) free wandering cats have been around in the traditional agricultural area for centuries. Our cats caught dozens of mice but only one bird (and one bat somehow) so far. Kind of of-topic though...
Are there any alternative HTTP clients that have support for client certificates during the TLS handshake? `libcurl` itself does, but from the looks of it that is not exposed in cHTTP. Reqwest supports this, but my beef with it is that it drags in the whole async ecosystem which blows up compile times in small applications a *lot* even if you don't actually intend to use anything asynchronously. 
&gt; But unused branching code on a match statement seems wrong. This. Also, shouldn't there by a style lint warning that the `Penny` binding should be written with a lower-case letter? It would also hint at the issue.
It's just as useful with simple patterns when mixing values and "holes e.g. `match v { 0 =&gt; ‚Ä¶, 1 =&gt; ‚Ä¶, other =&gt; ‚Ä¶ }`
Second question: I added the #[feature(i128_type)] and switched to nightly. The compiler kindly tells me warning: the feature `i128_type` has been stable since 1.26.0 and no longer requires an attribute to enable So I removed the feature declaration. Runs. I tried to switch back to stable, since it says the feature is stable since 1.26. The compiler says: error[E0554]: #![feature] may not be used on the stable release channel ....cargo/registry/src/github.com-1ecc6299db9ec823/speck-1.1.0/src/lib.rs:7:1 Why does it say that? Should the speck lib remove the feature declaration too? Is that something for a pull request?
Check the playground, the compiler emits warnings for all these issues by default: * it points out that `Penny` will match any input value (apparently `unreachable_patterns`) * it points out that the other branches are unreachable (`unreachable_patterns`) * it points out that the *variables* are unused (`unused_variables`) hinting that they're variables not values * it points out that one of the enum's values is dead code entirely (`dead_code`) * it points out that the variables in the match should be snake-cased (`non_snake_case`)
&gt; anything is the default. It's not that "anything is the default", it's that if your *pattern* is a name and there's no guard, any value will fit into the corresponding variable. Rust implements full-on structural pattern matching, so you're destructuring values and putting bits (possibly spanning the entire value) into variables.
It's not possible to use `#![feature]` on stable, even if the feature is already stable. When a feature becomes stable, you can safely remove `#![feature]` for that feature from your code.
&gt; Should the speck lib remove the feature declaration too? For it to be usable on stable, yes. &gt; Is that something for a pull request? Assuming they're interested in it running on stable?
&gt; Assuming they're interested in it running on stable? No idea. u_128 is the only formerly unstable feature used in the lib. There*s no reason to leave it on nightly. from my amateurish pov. But I am not working for the NSA. I have no idea if there are other reasons against it. 
ah thanks.
The easiest solution is to use a struct in which some of the fields are options struct Foo { release_reason: Option&lt;String&gt;, ... //more fields go here } If you need to express that some fields require other fields or if some fields cannot coexist with other fields then you probably have to write down the requirements before you can get further help.
&gt; Any advice? The cleanest way is to use the byteorder crate which has a method for doing exactly that. The slightly less clean way (though it avoids a dependency) is to convert your i128 to the proper byte order (using `#to_be()` or `#to_le()`) then transmute it to an `[u8;16]`.
Interestingly it's in fact the exact opposite on Windows: cargo new will only run \`git init\` and create .gitignore if the current working directory is NOT under a git repo.
&gt; But I am not working for the NSA. I don't think it's the NSA that matters, they created the cipher itself but /u/ticki_ implemented the Rust version as part of Redox's TFS apparently. I see somebody (possibly you?) already opened a PR to remove the feature from TFS/speck anyway: https://gitlab.redox-os.org/redox-os/tfs/merge_requests/87
`cargo new` will only run `git init` and create .gitignore if the current working directory is NOT under a git repo: [https://github.com/rust-lang/cargo/blob/c4572746e5ab51f39e01fb26a74afb7ef692121a/src/cargo/ops/cargo\_new.rs#L551](https://github.com/rust-lang/cargo/blob/c4572746e5ab51f39e01fb26a74afb7ef692121a/src/cargo/ops/cargo_new.rs#L551) Do you already have a git repo set up in the parent directory?
Sure. I am just surprised that `unreachable_patterns` is a warning, not an error. Although it may be a case of making refactorings easier... it's always hard to draw the line between warning/error.
Sweet! I've hear fibbonachFibonaccii heaps are better for thos sort of thing than binary heaps before but the radix heap seems pretty sweet. How does it work? Also that makes sense, the heuristic I use is the special case of the diagonal distance where the diagonal and horizontal costs are 1. Thanks for the advice!
Hello, I started a simple exercise, where I need to implement a simple Direction (N,S,W,E) and ability to rotate Left/Right (Left from North is West and so on.). Is there any simple idea or hack how to implement this nicely, without a two match statements? In C you could assign every direction an value from 0-3 and implementing rotation as increment/decrement, but was not able to somehow nicely implement this. Cheers!
I wonder how much different it is to the nRF52832 which Ruuvitag uses. Would be fun to tinker rust fw for ruuvitag, though I‚Äôm way to noob in embedded stuff to try it myself
`int_to_from_bytes` stabilised in 1.32, so you can just do [`to_be_bytes()`](https://doc.rust-lang.org/std/primitive.u128.html#method.to_be_bytes) etc.
I wrote `multi_try` to solve the problem of combining multiple Rust Result types in a safe way, in order to write validation logic which returns all errors rather than just the first. All feedback is appreciated.
Yep! That would be the reason!
&gt; I see somebody (possibly you?) already opened a PR no. my repository name is aspera-non-spernit. that's a case for the PR karma police. I am happy I could help nevertheless. :)
Cool! I checked the docs (faintly remembering something like that) but apparently missed it. I guess I looked for `to_bytes` and the fayt was not as fuzzy as I‚Äôd wanted. 
&gt; Although it may be a case of making refactorings easier... it's always hard to draw the line between warning/error. Yeah IME the rust teams classifies ¬´ that doesn‚Äôt sound right but you do you ¬ª as warnings, hard errors are almost only for ¬´ yeah that‚Äôs going to be a no ¬ª. Unreachable code and such being warnings is useful to putz around and check things out eg return from the middle of a method without having to comment everything afterwards. 
# Style #1: Inheritance by Composition pub struct PacmanCommon { name: String, architecture: String, // ... } impl PacmanCommon { pub fn name(&amp;self) -&gt; &amp;str { self.name[..] } } pub struct PacmanSync { common: PacmanCommon, repository: String, download_size: usize, // ... } impl PacmanSync { pub fn common(&amp;self) -&gt; &amp;PacmanCommon { &amp;self.common } pub fn repository(&amp;self) -&gt; &amp;str { &amp;self.repository[..] // ... } pub struct PacmanQuery { common: PacmanCommon, required_by: Vec&lt;String&gt;, // ... } impl PacmanQuery { pub fn common(&amp;self) -&gt; &amp;PacmanCommon { &amp;self.common } // ... } Inheritance by composition is a principle that isn't Rust-specific. Languages that support interface delegation (e.g. Kotlin) can arguably do this better, but Rust does it well enough. - Type for sync/query output: `PacmanSync`/`PacmanQuery` - Type for only common output: `PacmanCommon` - Type for only sync/query-unique fields, no common fields: none - Accessing package name (common field): `output.common().name()` - Accessing sync repository (unique field): `output.repository()` - Pro: simple types - Pro: minimal repetition (only `common` field and method) - Pro: "common fields only" is easily represented - Con(?): accessing common fields involves an extra `.common()` which is unnecessarily verbose (can be solved with a trait implemented for all three that requires `common(&amp;self) -&gt; &amp;PacmanCommon` and provides accessors that call `.common().xxx()` internally, although that adds complexity and repetition) - Con(?): no way of representing only command-specific fields without common fields (is this necessary?) # Style #2: Generics pub struct Pacman&lt;C&gt; { name: String, architecture: String, // ... command_extra: C, } pub struct Sync { repository: String, download_size: usize, // ... } impl Pacman&lt;Sync&gt; { pub fn repository(&amp;self) -&gt; &amp;str { &amp;self.command_extra.repository[..] } // ... } pub struct Query { required_by: Vec&lt;String&gt;, // ... } impl Pacman&lt;Query&gt; { pub fn required_by(&amp;self) -&gt; &amp;[String] { &amp;self.command_extra.required_by[..] } // ... } impl&lt;C&gt; Pacman&lt;C&gt; { pub fn name(&amp;self) -&gt; &amp;str { &amp;self.name[..] } /// Split out the common and subcommand-specific commands into different values. pub fn into_parts(self) -&gt; (Pacman&lt;()&gt;, C) { let common = Pacman { name: self.name, architecture: self.architecture, // ... command_extra: (), }; (common, self.command_extra) } } This style leverages Rust's type system in a neat way. The `into_parts` method is inspired by the `http` crate, specifically [`Request::into_parts`](https://docs.rs/http/0.1.16/http/request/struct.Request.html#method.into_parts). - Type for sync/query output: `Pacman&lt;Sync&gt;`/`Pacman&lt;Query&gt;` - Type for only common output: `Pacman&lt;()&gt;` - Type for only sync/query-unique fields, no common fields: `Sync`/`Query` - Accessing package name (common field): `output.name()` - Accessing sync repository (unique field): `output.repository()` - Pro: no need for `.common()` equivalent - Pro(?): can represent fields unique to query/sync without common fields - Pro: "common fields only" is easily represented - Con: more complex # Style #3: Options pub struct Pacman { name: String, // ... repository: Option&lt;String&gt;, // ... required_by: Option&lt;Vec&lt;String&gt;&gt;, } I'm not going to do the full list for this one. You know that either there will be a repository, or a required_by, and there will always be one of the two and not both. You also know that a function that calls `pacman --sync` will have a repository. Using options, you can't encode these facts in the type system, forcing users to `.unwrap()` everywhere. This is the only style I'd recommend against. TL;DR #1 is simpler, #2 is a bit nicer for users, #3 is unnecessarily hard on your users. IMO, either of the first two are good.
You might be interested in the [byte-slice-cast](https://crates.io/crates/byte-slice-cast) crate which can do that in both directions between slices of numeral types and bytes, in a safe way.
I wonder if warning that a binding matches a variant of an enum that's in scope "did you mean `Coin::Penny`?" Would help avoid this. Maybe combined with the variable being unused. Seems like a common pitfall for newcomers, especially since e.g. Swift uses `.Penny` to mean the same thing. 
This is very cool! I've been looking for something exactly like this. What do you think of making this into a `MultiTry` extension trait instead of just the function? Then you could expose a method `and_try` (since `and` is taken by Result) and chain everything together using an even more natural syntax: validate_address(email.to).map_err(|_| { EmailValidationErr::InvalidRecipientEmailAddress }).and_try(validate_address(email.from).map_err(|_| { EmailValidationErr::InvalidSenderEmailAddress) }).and( validate_subject(email.subject) ).and( validate_body(email.body) ).into_result()
/r/playrust
I'm an experienced Rust programmer but I didn't think this was obvious. To be fair, I rely a lot on the compiler to catch errors, so I'm surprised this one goes undetected.
Maybe a 'strict' mode should be a thing? No unused variables, no death code etc... That looks like something rust should have.
You mean custom certs? Hmm, feel free to open a GitHub issue, that can be added to cHTTP pretty easily.
It's a Cortex-M33 rather than a Cortex-M0 (so armv8m instructions rather than armv6m) but that doesn't make much difference to the code you write. I don't know how similar the peripherals are. Once the patches to the main embedded Rust libraries are in, it should be pretty easy to get started. It works like any other Arm chip.
AFAIK, Fibonacci heaps, although they have some nice theoretical properties, tend to be slow in practice. [This blog post](http://ssp.impulsetrain.com/radix-heap.html) gives a pretty nice overview of radix heaps. It is a [monotone priority queue](https://en.wikipedia.org/wiki/Monotone_priority_queue), meaning you cannot insert elements that come before the last popped element, but if your heuristic is admissible that should never happen anyway. They have great cache locality and O(1) insert. Extract is O(log m) where m is the difference between the popped element and the last popped element at the time the popped element was inserted. I think part of the reason why radix heaps are not more popular is that it needs bit scan functions to be fast (`leading_zeros`, `leading_ones`, etc). These are not available in most language's standard library, but they are in Rust!
TBH I thought the compiler was already pretty strict. A stricter mode would feel weird.
Also coming from C#, and it took me a while to fully understand the issue. It seems obvious now, but I didn't realize Rust would behave this way and it seems smelly. I [re-created this example in DotNetFiddle](https://dotnetfiddle.net/EZXT2Z), namely this block: ``` public static int ValueInCents(this Coin coin) { switch (coin) { case Penny: return 1; case Nickle: return 5; case Dime: return 10; case Quarter: return 25; } } ``` Sure enough, the compiler flagged each `case` line with an error that `Penny` does not exist in the current context. 
cc /u/freeky thank you very much for your efforts. However, I didn't really understand what you were suggesting, so I came up with another solution, It encrypts every single byte from the serialized struct SuperSecretDocument. I believe that's not the best solution, but I couldn't create a byte string from the vec that comes from bytecode::serialize. Below the struct serialized and chopped into chunks: 0: [25, 0, 0, 0, 0, 0, 0, 0, 72, 101, 108, 108, 111, 32, 87, 111] 1: [114, 108, 100, 46, 32, 72, 111, 119, 32, 97, 114, 101, 32, 121, 111, 117] 2: [63] So I guess it would be much easier to encrypt a chunk as u128 block, instead of what I did.. Second thing I always fall into a trap is borrowed content I cannot return from a macro. &amp;#x200B; I put the snippet on to the [playground](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=93b1deabfd1ecb25b0d042609529ffdf). compiles locally. Thanks.
You can `[#forbid(...)]` a whole bunch of warnings in your lib.rs, then you'll pretty much have that.
You can't get a length of an option because if it's None then getting the length of that makes no sense. You can look into \`Option::map\` for how to turn it into an Option of the length for example.
No need to ` as usize` anymore.
Get outta heeeer
You probably want something like: if let Some(a) = a { // a.len() } Which will rebind your `Option&lt;&amp;[f64]&gt;` as a `&amp;[f64]` inside the block. Also, using `assert_eq!` would be more idiomatic for these tests: assert_eq!(x.len(), y.len(), "X array length...", ...); 
For cases where you can't easily use combinators, you would generally deal with Options like this: match a { Some(inner_value) =&gt; println!("{:?}", inner_value), None =&gt; println!("Nothing!") }
Can you check if an option has a value and then return that value as an f64?
&gt;. So they definitely lose the attribute of being ‚Äòzero-cost‚Äô, and are much worse performance-wise. But it's not like there is a zero-cost alternative possible when you need dynamism.
The comment seems to indicate that you tried to unwrap a, but didn't use the result, e.g. a.unwrap().len() . There's also a nicer approach using if-let/pattern matching. You could look into that once you feel up to it.
It worked! &amp;#x200B; Thank you so much.
Is the a rust pattern or idiom for overloading math operators on a custom data type? especially for chaining operations. For example I have a Vec3 and I have ``` impl&lt;'a&gt; Add&lt;&amp;'a Vec3&gt; &amp;'a Vec3 { type Output = Vec3; fn add(self, rhs: &amp;'a Vec3) -&gt; Self::Output { Vec3 {} } } ``` My problem is when I have something like `&amp;v1 + &amp;v2 + &amp;v3` I need to wrap it in something like this `&amp;v1 + &amp;(&amp;v2 + &amp;v3)` and it looks ugly is there a better way. P.S. I am trying to avoid implementing the obvious add to a non reference. Should I maybe write a macro?
These both worked, thank you guys so much for the help üòÅ.
That's a nice addition! I've been increasingly using this tool to evaluate dependencies, so thanks for writing it!
I tried something similar and ran into a need for [generic associated types](https://github.com/rust-lang/rust/issues/44265). I'd happily consider a PR if you can figure out a way to make it work though. 
I'm not sure what exactly you're asking for, but fyi you can use serde\_json to deserialize into a \`HashMap\` directly.
Fwiw Haskell avoids confusion here since data constructors need to start with a capital letter while normal bindings need to start with lowercase. It seems this is just a convention in rust; would there have been a downside to enforcing it? Maybe interop with C would be clunkier?
Working on an FFI project (namely, hosting the .Net CLR in Rust in order to run and interact with CLR code). So proof of concept work helped me find that to make this work, I need: * .Net implementation of AppDomainManager with a COM-visible interface * C++ wrapper to import the .tlb of the implemented AppDomainManager interface * as well as all the necessary Rust bindings and code to interact with the relevant methods So my question here is, what is the preferred way to architect the project cleanly? Should I use meson build to manage the building of the C#/C++? build.rs script? Generate the C#/C++ code with Rust? Something else I'm not aware of?
Nice work. Have you checked how the performance compares between your async/await based implementation and the original direct implementation of the trait?
Is unreachable patterns triggered because there are two identical match patterns? *That* feels like it should be an error. I don‚Äôt really see how it being a warning helps for refactoring.
I mean, compared -Wall on C...
But what's the value of this variable? Is there an implicit "Penny = x" there? 
You might want a function like `ok_or`, or `ok_or_else` which converts an `Option` into a `Result`. You'd use it like: let ac_list = obj.ok_or_else(|| Box::&lt;Error&gt;::from("Obj didn't exist!"))?;
Yeah, but if unreachable patterns is triggered because there are two identical patterns, that doesn‚Äôt seem like it helps with refactoring or testing.
Here's my attempt: https://github.com/JoshMcguigan/multi_try/pull/1 Thanks for being open to it. I'm excited to use this crate. :)
You can implement both `Add&lt;&amp;'b Vec3&gt; for &amp;'a Vec3` and `Add&lt;Vec3&gt; for &amp;'a Vec3`. The compiler allows it. Also the lifetimes of the arguments should probably be allowed to be different. &gt; P.S. I am trying to avoid implementing the obvious add to a non reference. Is this running on a PC? The data paths within a core and to the L1 cache are 16 or 32 *bytes* wide. `Vec3` probably should be `Copy` and if you are worried about performance then you should be digging into SIMD stuff to ensure that you're using that full width.
Excited about both of these. Hopefully const generics is also part of a WG.
u/burntsushi addresses what I believe to be your question in his [blog post on error handling](https://blog.burntsushi.net/rust-error-handling). 
Yes. I had read that through the original link. That's why I was saying I didn't realize he had left. 
I guess you could use this trick, and do your addition with modulo. https://stackoverflow.com/questions/31358826/how-do-i-convert-an-enum-reference-to-a-number Beware that integer underflows might cause an error, so to be safe do (d+3) % 4. 
Yes. You have to use an appropriate `#[repr(u32)]` attribute on the enum to guarantee that the compiler agrees with what you're expecting. And because it's a hack you have to use an unsafe transmutation or pointer cast to modify or create a value of the enum using arithmetic operations. Also remember to use wrapping arithmetic or it will break in debug builds. An alternate idea is to just ignore type safety and use integers and constants. If you use actual `const` constants and not let variables, then match will work as expected. 
This looks really useful! Any reason why you created a separate ValidatedEmail instead of e.g., creating a Validated wrapper type? I guess that wouldn't work with types that have a different amount of lifetimes, though...
Yah performance is the main concern. I am trying to prevent copies but I was really asking out of curiousity. Does rust use copy elision optimization on rvalues? I am really just curious. I come from a C++ background
Unless the errors contain data, why not simply use [bitflags](https://crates.io/crates/bitflags) to represent each field being valid or invalid?
Wow, thank you for writing up such a thorough PR! I'll review and respond and/or merge soon.
There wasn't really a good reason for this. I think I was just in the separate struct mindset because the first couple use cases I saw for this looked more like [this](https://github.com/JoshMcguigan/multi_try/blob/master/tests/from_result.rs).
It is just `self`
&gt; my goal is actually to learn various ways of doing things There is no appropriate data structure without an algorithm operating on it. There is no appropriate algorithm without the data structures it must cope with. Humans have been using textual records, more or less formalized, [since forever](https://www.123rf.com/photo_37726235_cuneiform-writing-of-the-ancient-sumerian-or-assyrian.html). It *works* and it's hard to argue with 5000 years of legacy. Yes, you can spend a lot of effort designing an RDBMS. If you do a good job, you'll be rewarded with excellent throughput. But if you don't, it'll be a mess both for you and for the computer. The same is true about OO design, except that it's even easier to create a quagmire of poor performance and poor maintainability. `pacman` itself uses human-inspectable, debuggable text, sometimes with generalized lossless compression. There's a cost associated with parsing and marshaling data, but it's a well-behaved cost and it only makes sense to use an alternative representation when a specific goal necessitates it. I don't have an Arch system to look at, but if I recall correctly, each package has a directory and you can look in there. Or you'd use `std::process` to ask `pacman` directly, or get the data yourself, maybe with AWK. (It would be very cool if someone wrote an AWK-like interpreter that can be invoked from Rust.) Rust is very much like C and is weak at these general clerical tasks, until and unless you need to optimize a specific task. http://catb.org/esr/writings/unix-koans/ten-thousand.html
Errors often do contain data. I think the example was just to show the functionality of the crate, not anything specific to the error types involved. Using bitflags could certainly work for cases where you have no data in any of your errors. :)
I looked through your library btw, is it okay if I add a PR which adds iterators over the kv pairs, keys, and values of the `RadixHeapMap`? I currently iterate over the values in the `BinaryHeap` to show the visualization so it prevents me from using your library. I'm writing some tests as we speak.
Why wouldn't it make any sense to return 0 for none? 
Good catch! I just learned that we can actually `use` macros in rust 2018, pretty sweet.
Oh yeah, true. I would have run clippy, but I just tweaked it a bit on the website.
I disagree with that. Actually your examples are not good. `let x: String`: "Let x be a string", it makes sense in natural language. `future await` totally not. An example would be instead of `get_result()?`, you are getting `get_result() try`. imo it's really a bad syntax. That's why I'm saying a sigil probably doesn't introduce a shock to people coming from other languages.
I'm not sure. But we are currently using `await!()`. And I guess the brackets in `await {}` can be automatically completed? Just like in `fn f() {}`.
I'm relatively new to Rust and that is one of the most beautiful pulls I think I've ever laid my eyes on. Kudos!
You can: a.map(|a| a.len()).unwrap_or(0)
A PR adding that would be very welcome.
I have autocomplete in my editor for Rust.
The main problem is that IDE support for Java is *a lot more mature*, because Java has been around many years. I guess theoretically autocompletion for Rust can be as good as for Java (because both are strongly &amp; statically typed). But Rust is more difficult to parse because of macros. They need to be expanded to be able to know all the structs and functions and so on that are available. So eigher IDEs must pretty much reimplement parts of the Rust compiler (like CLion does) or the compiler itself must gain IDE features (the RLS project). 
Thank you for the nice reply! I've been following some of your work on github and the posts here on reddit and I'm very impressed as well as inspired by your work.
Might be a really tangential approach, but could some sort of continuation passing work a little better sometimes? I kind of think that returning vectors is a little inflexible, so I wonder if there's a nice lazy way to step through the errors instead of accumulating them. This might be a little better for things like parsers if they want to emit a lot of errors while processing a big input. 
I really like the interface you wound up with!
Even sticking to the example at hand, I can imagine pointing exactly which rule was violated for each field. For example, maybe `+` is not supported in the sender/recipient, despite being "officially" valid.
I don‚Äôt know `serde_xml_rs`, but in most dialects an attribute is ¬´ false ¬ª when it‚Äôs either missing or with an empty value. Maybe try these?
That's not the same, /u/ImKillua was arguing that it wouldn't make any sense to implement .len() for Option. 
Didn't realize this was controversial. Thanks for the resource!
With stackful generators you could generate a stream of error for an arbitrary data-structure without allocating. With a stackless generator, you'd have to maintain your own stack somewhere in the generic case, but the stack would be limited to the "depth" of the data-structure explored, which should typically be smaller than the number of errors, so it may be a good solution. And for a flat data-structure, no stack is necessary at all, only a "counter". --- On the other hand, it's not clear to me how easy it would be combine them in the absence of generators. I mean, [manually I got it working](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=aceb34e9114cff2572a825b4701bc9d2) but I don't see how easily you could generate code for it: #[derive(Debug)] struct EmailErrorIterator&lt;'a&gt; { raw: RawEmail&lt;'a&gt;, field: usize, } impl&lt;'a&gt; EmailErrorIterator&lt;'a&gt; { fn is_current_field_valid(&amp;self) -&gt; bool { match self.field { 0 =&gt; self.is_address_valid(self.raw.to), 1 =&gt; self.is_address_valid(self.raw.from), 2 =&gt; self.is_subject_valid(), 3 =&gt; self.is_body_valid(), _ =&gt; false } } fn error(field: usize) -&gt; Option&lt;EmailValidationErr&gt; { match field { 0 =&gt; Some(EmailValidationErr::InvalidRecipientEmailAddress), 1 =&gt; Some(EmailValidationErr::InvalidSenderEmailAddress), 2 =&gt; Some(EmailValidationErr::InvalidSubject), 3 =&gt; Some(EmailValidationErr::InvalidBody), _ =&gt; None, } } fn is_address_valid(&amp;self, _address: &amp;str) -&gt; bool { false } fn is_subject_valid(&amp;self) -&gt; bool { true } fn is_body_valid(&amp;self) -&gt; bool { false } } impl&lt;'a&gt; Iterator for EmailErrorIterator&lt;'a&gt; { type Item = EmailValidationErr; fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; { let error = self.field; self.field = self.field.checked_add(1).expect("Overflow!"); while self.is_current_field_valid() { self.field += 1; } Self::error(error) } } fn validate&lt;'a&gt;(raw: RawEmail&lt;'a&gt;) -&gt; Result&lt;Email&lt;'a&gt;, EmailErrorIterator&lt;'a&gt;&gt; { let mut error = EmailErrorIterator{ raw: raw, field: 0 }; while error.is_current_field_valid() { error.field += 1; } if let Some(_) = EmailErrorIterator::error(error.field) { Err(error) } else { let raw = error.raw; let (to, from, subject, body) = (raw.to, raw.from, raw.subject, raw.body); Ok(Email{ to, from, subject, body }) } } 
Debug code may not trigger that optimization at all. And right, in case you want to use assertion to hint the compiler, you need to use `assert` rather than `debug_assert`.
I agree. The more I think about it, the more this seems to be a mix of `and_then` and `or_else`. I'll have to think about it more, but I'll see what I can think of to make it easier. 
I'm not familiar with the low level details, but this looks like a complicated way of getting wasm-pack functionality in a less ergonomic packaging. Naturally you've learnt a lot on the way and that in itself is worth enough; but other than that; what differs and why are you doing this?
It requires no code generation, is not Rust specific, can be CDNed into any project.
I'm glad! I have two more projects to announce, I just gotta get around to actually writing up the docs and announcements.
Thanks for gimli! The example programs `dwarf-validate` and `dwarfdump` were extremely helpful when I was debugging a linker bug a few weeks ago (objdump was far less robust, the reported error changed seemingly randomly).
Oh nice. I barely use switch statements in my C# code, always felt like a code smell to me probably because of the lack of pattern matching, so I didn‚Äôt realize they‚Äôve updated them.
'-Wall -Wextra -pedantic -Werror' üò≠
For everyone arriving at this page: yarte is a fork of [Askana](https://github.com/djc/askama/) for which the author is [refusing to properly follow the License terms](https://github.com/rust-iendo/yarte/issues/5), calling it a [waste of time](https://github.com/rust-iendo/yarte/issues/5#issuecomment-465643428), which is especially egregious because Askana is MIT licensed and properly forking an MIT project is the easiest thing in the world.
I have a surprising number of problems with that statement. a) Someone actively advertising their core membership status in sales would be an extreme problem. That would open a run for Core positions out of business interest. We already _have_ a core member with a consultancy and I'm happy they are aware of the issues that come with that constellation. To be clear, I also don't believe those constellations should be avoided, but they come with a lot of responsibility to handle that in a fair manner actively. b) What would "core" achieve me, as a client? Most agencies currently in the market already have experience and access to language development, so if you want to sponsor a feature, you'd already have ample opportunity at very competitive prices. Examples: [Ferrous Systems](https://ferrous-systems.com), [i32](https://integer32.com/) and [Lyken](https://lyken.rs/) (eddy_b and friends). c) What makes you believe that existing companies could not scale up fast enough? What makes you believe Steve could do _better_? For most of the current agencies, it's not even the first time they are doing this. d) I agree with you that the Rust ecosystem will take of this year, but most companies will start adoption on their own first. There's areas where this growth happens differently, but I won't go into detail there. Also, we've got our ways to prepare for explosion, if we need to. e) Forming a company around a person is problematic. As an example: My old company is formed around me and my brother + later added people. The late realisation, especially in the training business is that people expect service by someone named "Gilcher". Not being served by us two makes people visibly confused. Strong personal brands don't make strong company brands. Would you buy a "Klabnik training" and Steve doesn't come? You are building yourself a company with an uphill battle built-in. For the reason above, [Ferrous](https://ferrous-systems.com) does promote a training crew and we actively stopped sending me to trainings for a while, though I'm the most experienced trainer. f) I value Steves work a ton, but the focus on his figure doesn't appreciate the work of others, especially his collaborators. The co-author of TRPL, Carol, [has a company](https://integer32.com/), together with the top contributor for Rust on stackoverflow. That's some damn credentials. 
Yes, ojo has antiquing. I don't think it has anything to do with descents in category theory, but I'm definitely not an expert in category theory so I could be wrong. Anyway, antiquing actually turns out to be very simple, and it will be covered in my next post.
Maybe it would be possible to implement `collect` for `Iterator&lt;Item=Result&lt;T, E&gt;&gt;` into `Result&lt;Vec&lt;T&gt;, Vec&lt;E&gt;&gt;`? It currently works perfectly well for collecting into `Result&lt;Vec&lt;T&gt;, E&gt;`.
I never said "advertise their core team status," that's implicit, you took that to an illogical, unreasonable extreme to manufacture a strawman inference. The way you come across is that no else can have a business or consult, because another group already does so. That comes across as trying to control other people, and most people don't respond favorably to that. Being extremely negative or shutting down others isn't a good way to advertise anyone. You don't seem to understand business, which is okay, but that's not something I can teach or explain to you in a post. If you have any constructive comments or feedbacks, rather than dripping animosity, please let me know.
Great! I'm looking forward to it!
async code infest everythin with async. When you write async call, then your function becomes async, your caller becomes async, his caller becomes async, .. and so on till the `main` function where you have to run reactor. Writing braces is tedious. Being depended on the IDE feature when you have no good IDE at all (rls is just broken, rust-analyzed hasn't been done) is not a nice way of doing things... async is just like error handling. You write it a lot, and you have to propagate it to the caller if you do it. I don't like idea having more than one sigil in the language, because rust is not perl. Beside that, having heavy-weight async syntax is what people using await usually want.
The language certainly allows copy elision and it's a desired feature but my understanding is that it's currently not fully implemented in the compiler. 
Thanks that is very helpful
I have a question about borrowing and closures that I've been banging my head against for the past day. Consider this code: pushrod_window.window.draw_2d(event, |c, g| { self.recursive_draw(pushrod_window, 0, c, g); }); Since I am given a closure, and I need to pass the current `pushrod_window` object that contains a `Vec` of widgets to process, I get the following error (and yes, I've looked at the explanations, and I don't understand them): error[E0501]: cannot borrow `pushrod_window.window` as mutable because previous closure requires unique access --&gt; src/core/main.rs:365:25 | 365 | pushrod_window.window.draw_2d(event, |c, g| { | ^ ------- ------ closure construction occurs here | | | | _________________________| first borrow later used by call | | 366 | | self.recursive_draw(pushrod_window, 0, c, g); | | -------------- first borrow occurs due to use of `pushrod_window` in closure 367 | | }); | |__________________________^ borrow occurs here error[E0500]: closure requires unique access to `pushrod_window` but it is already borrowed --&gt; src/core/main.rs:365:62 | 365 | pushrod_window.window.draw_2d(event, |c, g| { | --------------------- ------- ^^^^^^ closure construction occurs here | | | | | first borrow later used by call | borrow occurs here 366 | self.recursive_draw(pushrod_window, 0, c, g); | -------------- second borrow occurs due to use of `pushrod_window` in closure error: aborting due to 2 previous errors I hope I can get some help. I _really_ don't understand what I'm doing wrong. If anyone can provide a fix via a pull request, the code is in https://www.github.com/KenSuenobu/rust-pushrod/, and the branch (that currently has the bug) is 0.1.12. Thanks! 
It doesn't look like `assert` does that fully either. [Here](https://play.rust-lang.org/?version=nightly&amp;mode=release&amp;edition=2018&amp;gist=9a0193f548f9f96a5b9f18406d05dec7) are three versions. The first uses no assertion, the second uses `assert`, and the third uses [`unreachable_unchecked`](https://doc.rust-lang.org/std/hint/fn.unreachable_unchecked.html). If you have `main` call `version1`, the result after all of the inlining is five different potential jumps to the panic handler, one for each of the possible failures. It has to do this because the error message is supposed to tell you which one failed. If you replace that with `version2`, it does a single potential jump to the panic handler, for when the assertion fails. Faster, but it still hasn't removed the bounds check completely. You can get a similar result by using a plain `if` statement to do the normal addition after checking the array's length and then returning 0 or whatever in the other branch (since if you're willing to panic, I assume you expect it to never happen). Then for `version3`, there is no check at all. If you need it to be as fast as possible, and are ensuring somewhere else that the array is long enough, that will do it. It does actually do the check in debug mode, so it accomplishes something similar to `debug_assert`.
4 ways to solve your problem - return a boxed trait - return an enum you have to manually code - rewrite your function to take an object with a generic callback function. Call the function from within your functikn. It will generate code for all of your iterator types. The 4th one is rarely discussed... Create a buffering iterator. That buffering iterator will a boxed trait to a an intermediary trait that takes N elements and fill it into a buffer. The intermediary trait will be implemented in a generic struct that wraps your real iterator. That way you will have static dispatch everywhere except when you need to refill the buffer, and refilling the buffer itself will be static dispatch. 
If you are willing to use the nightly compiler (probably for the next year or so), then I would recommend Rocket (http://rocket.rs). It's definitely the most full-featured framework in Rust (with the least boilerplate). We don't yet have anything that competes with Rails/Django yet though.
It seems like that would work if all of your results return the same type, but one of the goals of this crate was to support different types being returned together (although the return types do all need to be the same in the current implementation). 
The second version is what we want, though. An assert doesn't omit the check entirely, it just adds a runtime check that allows the compiler to assume something is true at compile time for subsequent calls.
You are obviously misinformed about actix-web or are using Rocket from the future and are really spoiling your time traveling abilities. 
Simplest to use is Rocket. Most other categories lead to Actix-web.
Yeah, the `assert!` version will be very close to optimal performance. If you're consistently calling it with arrays that are long enough, the branch predictor will let it continue on past the check before it has even finished evaluating it.
Other than proc macros for endpoint registration, what other features have you found Actix-web lacked?
I'm probably more clueless than you but I think what the compiler is saying is that someone else is using that object (so you can't borrow and mutate it). Is cloning it a possibility?
The most straightforward framework that works on stable is [rouille](https://github.com/tomaka/rouille) (as far as I know anyways). What I particularly like is that handlers are just functions of type `&amp;Request -&gt; Response` which makes reasoning about them and testing quite easy. Most used and performant is probably [actix-web](https://github.com/actix/actix-web), but it is a little more complex and will confront you with the async ecosystem which is probably not ideal for learning Rust. On nightly compilers you can use [Rocket](https://rocket.rs), which attempts to use the type-system to the fullest. This is vaguely reminiscent of libraries like Haskell's servant; within the constraints of what Rust's type system can do.
Returning `Vec&lt;MyError&gt;` as the `E` in `Result&lt;T,E&gt;` is reasonable, but awkward since `Vec&lt;MyError&gt;` does not implement the `Error` trait. How about adding: ``` struct ErrorVec&lt;T: Error&gt;(Vec&lt;T&gt;); ``` that implements `Error` and `Deref&lt;Target=Vec&lt;T&gt;&gt;`?
Most full featured goes to actix-web, backed by Actix. This isn't even debatable by informed people.
`Result&lt;Vec&lt;T&gt;, Vec&lt;Box&lt;dyn E&gt;&gt;` ? (Totally have no idea if that would work..)
Does reversing the operation order and accessing `array[5]` first do what you want?
I don't necessarily have time to be a mentor, but you can always ask in the [nom gitter chat](https://gitter.im/Geal/nom) in case you get stuck, there'll usually be someone to help you out.
Why does Hyper's docs for `hyper::Request` show `use http::{Request, Response};` in the examples? I don't see `hyper` used in the example anywhere. https://docs.rs/hyper/0.12.24/hyper/struct.Request.html
VS Code, probably.
I'm trying to use `reqwest` to create a progress bar for downloading a large zip file. The only solution I've found online does an initial request for just the headers to find the `Content-Length` and then uses that to create the progress bar. However, I don't think the zip file I'm trying to download has a `Content-Length` header at all. How would I go about doing this? There must be a way, since Firefox knows how big the download is before it is finished, right?
I am using SublimeText with the Rust Enhanced package and running everything from my terminal. It works well. Cargo handles a lot of the pain. 
Yep, if I switch the order there's only one jump to `core::panicking::panic_bounds_check` in main.
1. Install rust using rustup (http://rustup.rs) 2. Use VS Code or IntelliJ (both require installing a rust plugin) as your IDE / text editor. IntelliJ has better autosuggestions, but is heavier-weight. VS Code is pretty good, and a bit simpler/lighter. Sublime Text, Atom and vim/emacs are also workable, but support is less seamless.
Warp gets my vote for simplest to use. Find a templating create you like and you will be all set with routing and serving in just a few minutes.
The `hyper::Request` type is the `http::Request` type, re-exported using `pub use http::Request`, docs and all. rustdoc should probably indicate this somehow.
What about text mate? 
Followed your tutorial and some reason this works fine when I run **cargo web start** and I open localhost:8000, but when I run **cargo web deploy** and I open the generated index.html doc I get a blank page. Any ideas whats going on here? Forgive me if I'm misunderstanding something simple. I'm not very familiar with web development.
`Content-Length` is an HTTP header, not a ZIP header, and it's added by basically any HTTP server - without it clients would have no idea how large a file is until it was completely downloaded. If you've ever downloaded a file in a browser and it said "unknown time remaining" that's why.
I kinda don't like doing reverse for this... An assertion is clearer.
You can turn warnings or a specific warning to error if you want...
&gt; ¬´ that doesn‚Äôt sound right but you do you ¬ª as warnings I would phrase that instead as "well, I don't think I need to keep you from running your unit tests for this, because you might add more stuff later that makes this correct". That's particularly true for unreachable code where for testing and debugging stuff you might have hacked some stuff in that you're definitely going to change. Also, for patterns in particular, it's intentionally not a hard error so that the detection logic can be made smarter without being a breaking change. Take for example the work to make `match x as u8 { 0..=255 =&gt; () }` legal -- any code that did that before was forced to have a `_ =&gt; unreachable!()` arm, which is now understood by the compiler to be unreachable.
It's already linted about -- including in this example -- which is plenty.
Note that rustc is _very_ careful with its warnings -- the less certain or more opinionated ones go in clippy -- so you should absolutely pay attention to them when they show up.
It wouldn't be used frequently enough to justify a special `len` method for `Option&lt;&amp;[T]&gt;`.
That accounts for differing Err types, but not differing Ok types. e.g. there's no way to join an `std::io::Result&lt;usize&gt;` with a `std::io::Result&lt;&amp;str&gt;` using this method. (And yeah, that doesn't really make sense with collections of homogenous types, but Josh clarified that that's orthogonal to the purpose of this crate above.)
It's hard to understand what you are trying to say, but I'm assuming you are asking whether there is a distro out there that lets you install all those packages with their package manager. In that case, Arch Linux has pretty much all those packages either in the core repositories or the AUR.
I would say CLion/intellij is the best setup on any OS. IntelliJ is free if you get the community version though I prefer CLion. Otherwise I think Visual Studio Code is alright but a distant second 
evmap is good I hear.
I [just posted](https://www.reddit.com/r/rust/comments/au3z5j/emacs_lately/) an Emacs setup to get autocomplete going. Racer + Flycheck + Company is also a really good combo on Emacs. I'm seeing Codelion talked up as another commercial entry. Obviously IntelliJ + plugin will be pretty strong. The common theme is either Racer (Rust autocompleter) or RLS (Rust Language Server using the LSP) will be backing up any autocomplete display system like company on Emacs.
I use CLion everyday for work (primarily cross-plat C++), and it's a dream for Rust. Easy to mix with C/C++ projects too. 
I'm not very familiar with the options in this space. How (through what mechanism/protocol) would you want the multiple processes to communicate with this in-memory store? 
Others have mentioned intellij/clion, but it's worth mentioning if you are comparing the two that clion has nice debugger integration out of the box.
Should be through memory directly (such as mmap)... without having to go with IPC as it might be too slow.
I'm incredibly happy with IDEA. Give it a try.
Thanks for this! My rust/emacs setup is super out of date, so I appreciate reports on the current state of the art
Sorry, I meant pre-installed, every time I install the os, I install the rust-based tool, so I wonder is there a distro that these tools are out of the box. There is no os that production ready written in rust, but there could be an os installed all the neat tools written in rust. 
If some of the fields require other fields to be present, then you can often express it using an enum. It looks like this. enum Kind { Sync { repository: String, download_size: usize, // ... }, // .. } pub struct Pacman { name: String, architecture: String, // ... kind: Kind, } 
That means to ignore the other fields. Without the `..`, the match would need to name all the fields of the struct. That's 1) annoying if you don't care about them, 2) something of a compatibility hazard, if the struct adds more fields later, and 3) sometimes impossible if some fields are private.
Awesome. Thanks, that makes sense! Cheers
Have you tried SQLite? It can make in-memory databases, and allows any number of concurrent readers. I don't know of anything it does that would help with usage between different processes.
I'll check but I think with SQLite we are nowhere need the millions ops
Since you brought up Django, Rocket is a good Flask analog.
Depending on how your data and queries are structured, one SQL query could get you the result of multiple "ops".
`piston_window::Window::draw_2d` has `&amp;mut self` which means you cannot access `self` for any reason while within the closure you pass it. I don't know why because that would require knowledge of how `piston_window` is implemented. On fact that knowledge breaks modularity. I just know from the signature that - whatever the reason - overlapping access isn't allowed. If you put `piston_window::Window` within some other structure then, by compositional inheritance, the same restriction applies to that structure. If `YourWindow` has a Piston `Window`, whenever I borrow `YourWindow` I would generally assume that borrowing `Window` is part of the deal. If you want to change the rules - loaning me `YourWindow` *without* promising that `Window` may be accessed - then you must change the declaration of `YourWindow` to enforce what the rules actually are. Most likely you want to isolate `Window` inside `RefCell` or maybe `Mutex`, meaning I can do anything with the other fields but if I access the Piston `Window` something bad (panic or deadlock) could happen at runtime. But even with those relaxed rules, you can't allow me to access Piston `Window` in the middle of a `draw_2d` call. Because that, for some reason which we don't even need to know, would break Piston. Alternatively, you may prefer to remove `Window` from `YourWindow`. I suspect that makes the most sense. A text document is meaningful whether you display it on a screen, pass it to a speech synthesizer, print a hard copy, or email it to a publisher. The output device is *not* part of the content. Analogously a virtual device for drawing things and accepting GUI events (piston `Window`) is *not* part of a tree of things the user might see or interact with, even though it's tempting to also call that a "window." And confusing the two makes it somewhat nonsensical to tell Rust, or a third human audience reading your code, "now, here's how to draw the window to the window". However the Rust compiler can't say "hmm, that doesn't make intuitive sense." The compiler only complains about concrete violations of its rules which are sometimes more pedantic than strictly necessary. It can't form a particularly good opinion of what the root cause is. But by making the rules a bit more pedantic than necessary, it is possible to reject code for reasons that can at least be be understood using local reasoning, without looking inside some other module. So, yes, I'd agree that a structure inheriting the property "not safe to recur" from one of its fields, is quite pedantic. But it's also very difficult to explain or test when recursion is safe in those situations. *It depends.* It depends on the behavior of other modules or the interaction between several functions and closures which is easily broken by a seemingly harmless change. 
So I was using vs code, until I think my project got too big or something, and it no longer will do completions. I tried eclipse corrosion to try to see if vs code or RLS, but it was so bad I couldn't tell. I had been avoiding intellij due to the lack of debugger (only works in clion). Upon trying out intellij, the completion worked kind of great immediately (after the initial index). However then I started running into odd things. I don't have nightly anything setup, however it completes things in nightly. It looks like it complies in IDE, until a build is run, then it doesn't. I can't figure out how it's getting those or how to disable it. Intellij does have tons of refactors others don't. It has things I missed in vs code that I have feature requests in for. However, it does have other issues like it will randomly say things don't compile that do. It will say missing method. However, if you delete the line, it will come complete it, then again say missing method. Then just a side note, intellij is by far the most heavy weight IDE. It barely runs on my laptop (which is really old in all fairness, and I should probably get another one), where the other ones "work" fine (whatever you want to define that for eclipse, and vs code was great until I did whatever to break completion). I think the real answer is we aren't IDE yet.
Hey everyone! We've been working on a design for structured logging in the \`log\` crate for quite a long time now and I think we're ready to start landing support. If you get a chance to take a look at what the plan is and leave a comment with any concerns you have that would be much appreciated!
In this context, we need about 8M of data inserted in less than a second and read in about 0.3sec after that. Deleted. Then doing it again
Not only has java been around longer, millions of dollars have been spent on java tooling. If anyone spent even a quarter million on rust tooling (or Haskell for that matter) it would be *far* ahead of where it is today. Some things have known solutions, but simply require tons of man hours of effort. IDEs/language servers are definitely in that category.
Sounds like redis fulfills your minimum requirements, I'm curious as to why you are rejecting it. You might try memcache also. Sqlite in memory could work. Postgres can also be configured to store in memory of you have to. Could try TiKV? I don't know much about it. There are lots of other ways to address this sort of problem, but most of them involve big data style solutions like hive which are aimed at big clusters and massive data sets. Maybe you could share a bit more about what you're doing?
Why not just roll your own in rust? It‚Äôs just key value... seems like all these other libraries are giving you better querying capability. If you‚Äôre writing then reading it all what‚Äôs the need for a standalone? 
In this context, we need about 8M of data inserted in less than a second and read in about 0.3sec after that. Deleted. Then doing it again Redis we tried optimizing it in any way but in reality I think the internal Network is the real bottleneck and we can't exceed 3M writing in a second.
Keys are about 30 bytes, Values 100 bytes (\*8M) every seconds
Yeah we can do it by ourselves, we were just wondering if a lib such as the one I posted existed, because this one actually meet our requirements in real life benchmark. No libs in Rust reach performances close to it (with auto sharding, auto lock and such).
Does that even exist in C?
Would it not rather be advantages to write an install script for all of the tools you want so it doesn't necissarly matter the distro?
I‚Äôm not experienced enough in rust to help it love that you‚Äôre doing this. 
This is the correct answer. Link: https://crates.io/crates/evmap However, even here you're going to have a challenge getting up to 8M read / write ops. You might think about using a different architecture entirely, something like channels instead of a shared key-value-store for passing values around. 
&gt;https://github.com/simonhf/sharedhashfile/tree/master/src Yeah: [https://github.com/simonhf/sharedhashfile/tree/master/src](https://github.com/simonhf/sharedhashfile/tree/master/src) It reachs better performances than any "DB" libs
Is that 8mb or 8million keys? How large are your key/value pairs? If you don't want to scale horizontally (across servers and processes) then you should go multithreaded and shared a hash map because the wire transfer/encoding/decoding is going to add overhead. What you are asking for might be possible on a single server, but we might be hitting ram read/write throughput limits depending on your key/value size.
I'm actually surprised this lib isn't known....
Hope you don't care about security... https://sqlite.org/whyc.html &gt; Safe languages are often touted for helping to prevent security vulnerabilities. True enough, but SQLite is not a particularly security-sensitive library. If an application is running untrusted and unverified SQL, then it already has much bigger security issues (SQL injection) that no "safe" language will fix.
I experienced the same thing. The IntelliJ Rust plug-in gave up completely after the project reached 200 lines or so. I‚Äôm on the latest MacBook Pro so it‚Äôs not a question of resources. I hope rust-analyzer magically fixes these problems while also being super quick and efficient but it might take a long time. 
8 million keys. 30 bytes/100bytes &amp;#x200B; It can't scale across servers because the overhead is too costly, timing is important. Multithreaded hashmap is what I'm thinking to be the fastest. i've tried doing a pure "variable" database but the CPU isn't going to handle it
That's quite odd. I've done several thousands of lines of code and CLion has kept up on my 2016 MacBook pro. 
&gt; Lagging internet reports indicate RLS is still raw, but I don't believe this to be very true at this time I'm using RLS within [Kakoune](https://kakoune.org/) editor, and it is super stable, however in Emacs I've encountered some hangs that made Emacs unresponsive until manually shut down. Knowing that it is super stable in Kakoune, and Vim, I suppose it is lsp-mode issue. Also, for Emacs I'm recommending you a cool package: [use-package](https://github.com/jwiegley/use-package) that can make your configuration much more easier and readable too.
This is super neat, I still have to port my init.el from racer to RLS. I too compiled emacs 27 from source, but for different reasons (TLS bug for magithub). Looks like it's time to switch now! Also since reddit is quite bad with code markdown, link to a github gist?
Yeah I'd try a multithreaded approach. You're looking at writing a gig in one second then reading it back shortly after. Should definitely be doable hardware wise, but you'll need to pay attention to other memory allocations happening concurrently and locking. Good luck and post another thread if you come up with some cool ways of doing this! I'd love to read a blog post on your trial and error process!
No sensitive datas, no worries about that here
Another crate that I think solves the same (or at least similar) problem but with proc-macro attributes is [`validator`](https://github.com/Keats/validator). 
Yeah, that's what I am doing, but a disto would be better for a true Rustacean, üòú
AWESOME! I had something like this in mind for quite some time. I'm glad somebody finally got to it üòÅ. And also nice ux design!
Good way to phrase it. Also excellent point I had not considered on the patterns. 
The radix heap improved performance by like up to 50% on the admissible heuristic, and 10% above the greedy heuristic! _Wow_, many kudos.
Spacemacs works great
What does this have to do with Rust?
That looks cool! Short, concise and easily readable source code! Once you think it's good enough, I'll happily work on getting it packaged for Debian. Won't be until after the upcoming Debian 10 release though, because we are in soft freeze for that already. &amp;#x200B; Minor nitpick: maybe the "action not found" and "unrecognized argument" messages should be written to stderr using `eprintln!` instead of stdout with `println!`.
Looks interesting! I've always wanted a reason to explore protocols at this level. Side note: I sat down, like, "today's the day!" Opened the video, 5 hours long. Look at the time: midnight... Tomorrow's the day!
Great, I hope someday it would be possible to use (`rls` is still too slow for real life projects).
I did the exact same thing on üòÇ
unreachable_unchecked does not panic, never will, and is 100% UB 100% of the time in release or debug mode. As the documentation says, plain unreachable is the safe version that *will* panic. [`unreachable_unchecked` will just give a core dump or wrong results.](https://play.rust-lang.org/?version=nightly&amp;mode=release&amp;edition=2018&amp;gist=ef867385aca5be979b3f3ef6634fc388)
There is also `eglot`, a simpler alternative to `lsp-mode` which is working really well for me.
That'd be fantastic, and thanks for the tip
I'll second Rocket as being the easiest one I've tried out.
Is anyone using spacemacs?
Why is everything public? 
I use spacemacs but haven't tried to switch over to RLS yet
I disabled some of the features of the layer because they were adding too much latency.
I guess it can be a input in the prefix/suffix debate for the await syntax in Rust.
I'm not looking to actually implement this (or even if I was...) my question was on OO design.
Read rules before you post, please. No memes allowed on this sub.
Do you use a GUI-library? If yes, which?
/r/rustjerk
As a newer developer trying to do something similar, do you think you could point me to some code examples? 
To me this seems like a 4th way (but with less type-saftey) 
https://crates.io/crates/evmap is good if you don't mix reads and writes. For example, if you have a lot of writes in a row, then a lot of reads in a row, then it starts writing again. If you mix reads and writes performance will degrade quickly. Other than that, Mnesia would be great for your use case, but it's Erlang-only.
Hi, Thank you for taking the time to write this detailed answer! You seem to have put a lot of thought in this. I suppose some of the Option 1 -&gt; Con 1 could be handled by a macro while Option 1 -&gt; Con 2 doesn't exist in my example but I am happy to hear if such a situation can exist (reasonably...) May I ask your github if it's not something you'd mind associating with your reddit? I'd like to read your code- you seem to understand rust well! Sidenote- and I know I shouldn't reply here but replying anywhere would be even more impolite than it already is, which is not my intention but given that only one reply seems to have actually answered my question in detail- I wonder if there is some usability concern with the ways Rust does this (seemingly enumerated by you here) and people aren't "getting it"?
That's true, good point. Style #2 is like this, but generics for the purpose of grouping fields instead of an enum. With subcommands as enum variants, if you know a function is going to return a `Sync`, you still have to do `if let Sync { .. } = results { /* ... */ } else { unreachable!() }`, which isn't great imo. But, if you don't statically know which variant you'll get, this does help.
Ah sorry, was about to mention MIME types. I will add that to the tutorial. Sorry I didn't reply sooner! For anyone else reading this, the wasm file needs to have the `content-type: application/wasm` HTTP header.
In Rust, passing by value usually\* means moving the ownership of the object in question. So, for example, this function: fn my_function(parameter: String) { println!("{}", parameter); } would take ownership of the String you pass to it, and after calling this function that string would no longer exist. (It gets dropped because it goes out of scope when the function body ends). In contrast, this function: fn my_other_function(parameter: &amp;str) { println!("{}", parameter); } only *borrows* the string. Ownership of the string is not moved into the function, the function only borrows it, which means after the function ends the value still exists in its original scope, and can continue to be used. Ownership of an object can only be in one place at a time. If you move it somewhere else (pass it by value), then it no longer exists in its original scope. Borrowing (taking a reference) allows a new sub-scope of the original scope to use an object, and then automatically return it to the original scope once it ends. \*(Types that are marked as `Copy` will not get moved, they will automatically be copied when you try to move them, so a copy will exist in both the original scope and the new scope.)
Thank you, but I want know, what will be better for perfomance
I can help. I'm not familiar with nom in practice, but I know other parsers. Can we talk over discord?
Perhaps this question from Stackoverflow will be useful: [In what scenarios are APIs that don't borrow preferred?](https://stackoverflow.com/q/53803915/493729)
Does Rouille have a static file server built in?
i detect rust zealotry.. 
Considering how well tested sqllite is, I think it is worth trusting. I don't think it's productive to play the "every non-memory safe language is garbage" game here.
That depends on the scenario. In some circumstances, you *want* to move ownership, such as when you're inserting the string into another data structure. In this case, it's necessary to move the original or clone it, and giving the user of the function the choice over which they do is better. In other circumstances, you only care about borrowing the type temporarily - in which case, `&amp;str` will be faster.
Contribute to one of the foundational libraries you use for your work. Everyone can use the help.
Why does `Iterator::try_fold` have a `Self: Sized` bound?
The [doc for clone](https://doc.rust-lang.org/std/clone/trait.Clone.html) contains: ``` impl&lt;'_, T&gt; Clone for &amp;'_ T where T: ?Sized ```` while following the link to the [source](https://doc.rust-lang.org/src/core/clone.rs.html#207-212) leads to: ``` impl&lt;T: ?Sized&gt; Clone for &amp;T {...} ```` Is there a reason for the '_ in the doc? I understand it's an anonymous lifetime, but does it add any information compared to the simpler form in the source? Or are they equivalent, but rustdoc is not able to generate the simpler form?
Wrong sub reddit 
Reminder: when posting topics with no obvious links to Rust, a comment, preferably in the post of the text, must be added explaining the relevance of the submission to r/rust.
As u/zesterer says, it's completely dependent on the scenario. General guidelines: 1. Pass by reference by default. Don't think about it too much - it's usually the right thing. 2. It may be _necessary_ to pass by value - in which case pass by value. 3. In [some situations](https://stackoverflow.com/q/53803915/493729), passing by value could result in better ergonomics or simplify either the API or its implementation. If you find a performance bottleneck after choosing either option, then you need to examine what is going on in your _specific_ situation. This might involve profiling, experimentation and trawling through LLVM IR or ASM for clues. If you make a decision on reference versus value for any other reason than following the 3 steps above then it's an optimisation, which should never be applied prematurely.
I had thought macros didn't work in impl blocks, but after a quick test I stand corrected. Yeah, a macro could definitely handle the repetion of defining those methods. I isolate this Reddit account from the rest of my online presence, so I'd rather not link other accounts here. I appreciate the compliment though! I haven't heard of this being a widespread usability concern for Rust, especially because this "repetitive definitions vs repetitive usage" trade-off isn't unique to Rust. Rust may actually be in a better place to tackle the issue because macros are so useful; I could see a macro like `properties!(name: &amp;str, get = name; architecture: &amp;str, get = arch)` that expands to `pub name(&amp;self) -&gt; &amp;str {}` and `pub arch(&amp;self) -&gt; &amp;str {}`. That said, I'm not omnipresent in the Rust community, and I can't speak for everyone. If some slice of Rust users aren't "getting it," one would have to identify what slice that is, how large it is, why it's not clicking for them, and how to address that. As a beginner/intermediate Rust programmer who is familiar enough with macros to avoid that concern, I'm not really qualified to answer any of those questions.
&gt; I would write a new version of our in-house CAD software Wow. How complex is the existing version? A CAD tool can be quite the endeavor for one developer so I'm curious what the scope is. I'm amazed and excited for you, just a little surprised (in a positive sense).
I'd recommend to look at GraphicsMagick for UI inspiration. They cleaned up the ImageMagick "mess" quite a bit. Other than that, I have to ask if you measured the performance of `image`. From my tests a while back things like scaling were quite slow.
I'd recommend to look at GraphicsMagick for UI inspiration. They cleaned up the ImageMagick "mess" quite a bit. Other than that, I have to ask if you measured the performance of image. From my tests a while back things like scaling were quite slow.
Do you know if anyone has figured out how to prevent eglot's on the fly checker integration creating a lot of temp files in the source tree? And is there a flag to disable auto-restart of the server? I liked eglot otherwise, but those two issues made it a non-starter.
Doesn't RLS still rely on Racer? Before I installed Racer, RLS didn't give me any completion suggestions.
Oops, there are no production-ready GUI libraries now :8
Why?
It's worth noting that there are sometimes reasons to pass `Copy` types by reference too. For example, `[u8; 4096]` is `Copy`, but it's unlikely you'd want to be hefting 4KB of memory around every time you call a function unless you can avoid it.
When you make such things errors a bunch of complicated use cases, like macros and use of cfg get much worse off. Not to mention the refactoring benefits. Usually a warning is enough.
I've been programming for a long time. When I'm at work I feel like a god, but then I come home and watch Jon G's Rust videos and realize I'm a moron.
So you insert in the beginning, read afterwards, and then clear it? If so, and ignoring multi-process for now, you could partition the data by its hash key into n parts and then build n hashmaps. A sort of multi-level hashmap. Could probably be done with rayon and a partitioning function like [partition](https://crates.io/crates/partition).
Ah okay! So what do I need to do to get the size of a ZIP file before downloading it?
Not sure about GraphicsMagick but i tried comparing the performance of ImageMagic vs Imagene by down-scaling an 4k image down to 1080p, and then up-scaling back up to 4k (which yes, doesn't look good i know). &amp;#x200B; I took benchmarks by using the `time` command comparing these commands. `./imagene void-wallpaper.png resize:0,1080 out.png` vs `magick convert void-wallpaper.png -resize 1920x1080 out.png` and `./imagene out.png resize:3820,0 out.png` vs `magick convert out.png -resize 3820x2180 out.png` &amp;#x200B; Combined imagemagick took \~3.7 seconds while Imagene only took \~1 second. &amp;#x200B; Seems like the rust's image library does the job quite well. I also have made it so all images mentioned in the commandline start loading asynchronously at init, and then gets picked up and reused whenever needed. Which could help with performance if you're using many *append:* actions lets say. 
Sublime Text with Rust Enhanced is my setup, it's simple and it works well.
I thought the exact same thing. He might do it using OpenGL as blender does it 
Is your system monolithic? If there are any natural boundaries, like separate DLLs or separate executables, it may be best to consider them as the entry point.
I'd rather get a normal distribution and quickly spin it up using pacman. All of them are available in the repos. I use yadm to manage dotfiles. It runs a bootstrap script and there I simply install rustup, latest nightly and all cargos I need. 
Well, I suppose &gt; I became a bit of a Rust zealot might have been the first clue.
Sorry aha ill take it down
There is also sled: https://github.com/spacejam/sled I'm not sure if it has a way to disable disk persistency, but it is fast and concurrent.
Even with Cargo I still need to look at licences, and the code of the crates. So may empty crates or stuff which doesn't work or at least not as advertised. Lot's of unnecessary unsafe, lot's of one time protoypes done as part of a research. Many crates are simply not fit for production use. Still it clicks better with me than conan did. Given that I already know Rust, most of the time it's a smarter choice to use it than anything else I learnt and used before, including C++.
In other comments it sounds like you have a "writing phase" separated from a "reading phase". If that is the case and doing all writes on a single thread is possible, maybe something as simple as `RwLock&lt;HashMap&lt;K, V&gt;&gt;` is what you need?
Are you able to give any more context? Why 8M exactly? is that something that may need to be larger in future if you find what you want? If so are the other constraints going to scale with that or remain at the same requirements? You mention in the comments that you need to do 8M inserts in &lt;1sec, followed by &lt;0.3sec to read and delete it afterwards and repeat the process..? You have multiple processes/threads along with the resources to scale vertically to perform this task, but during that insert stage, you need these processes to have shared read access to this KV store for all processes or only writing to a shared location at this stage? You state random read/write in the original post but it's not entirely clear if that's specific to the insert stage. You mention network latency rules out horizontally scaling solution? Not knowing what you're really doing, if you don't need to read(or only need to read a subset) data other processes are writing for that 8M insert stage, then scaling horizontally should be doable. Since the data appears to always be 8M entries repeatedly being updated/read and then deleted/refreshed, I guess the keys are fixed/constant? And with the timing constraints and usage pattern, it'd seem the reads/writes are predictable, doesn't seem like the parallel processes are going to try access data from a key/value that could be altered during that?(insert stage)
vscode with rust-analyzer is pretty great.
I do. It works really well right now, but it was kind of a pain to set up. Probably needs some polish still. (setq rust-backend "lsp") (add-hook 'rust-mode-hook #'lsp-rust-enable) (nconc rust-mode-hook (list (lambda () (add-to-list 'company-backends 'company-lsp)))) The first line is self-descriptive. After that you still need to start lsp each time. And I think there's some weird interaction where something in `rust-mode-hook` completely overwrites `company-backends`, so I had to add the lambda specifically to the end of the hook.
If creating key/value pairs involves some computation, that (plus hashing) could be done on multiple threads that send messages through [crossbeam-channel](https://crates.io/crates/crossbeam-channel) to a single hashmap-writing thread (that can use [`raw_entry_mut`](https://docs.rs/hashbrown/0.1.8/hashbrown/struct.HashMap.html#method.raw_entry_mut) from [hashbrown](https://crates.io/crates/hashbrown) to insert with a pre-computed hash.).
Where do you work that you get to do fast linear algebra and have the option to _choose_ rust? üòç Are you, by chance, hiring?
https://crates.io/crates/cargo-geiger is a very useful tool for evaluating potential dependencies
It might be a special purpose one, e.g. parametric design of gears or fasteners. That's a lot simpler.
I've been trying to [improve things](https://github.com/brotzeit/rustic) for a while. Contributions are very welcome!
&gt; Is your system monolithic? sort of; the core "module" that does the brunt of the work *is* monolithic, but all it does really is chain transformations on data that can easily be encapsulated with C structs, so splitting parts off it shouldn't be hard. I'm just trying to find general cases where doing so and working in rust provides benefits over just using C++. &amp;#x200B;
Yes, [see here](https://docs.rs/rouille/3.0.0/rouille/fn.match_assets.html). 
That's encouraging. My tests were a simple comparison of scaling the Xorg root wallpaper with a Rust tool using image vs a C tool that uses libjpeg-turbo and libpng (JPEG and PNG images were tested). I can imagine that GraphicsMagick's resizing method is higher quality and hence slower than libjpeg-turbo, but I wouldn't bet on that. In any case, your fresh benchmarks look a lot better than mine from a while back. That's great.
well, *choose* is a strong word. The project is with a small experimental thing with 2 other guys in my department, and we're building off c++ legacy code. I'm sure I can convince the other 2 guys to use rust *incrementally* if I find a compelling reason, but so far I'm not really seeing one.
Yeah. Makes sense to me though: XML itself has no notion of booleans, so that's going to be specific to each dialect. It would make sense for serde-xml-rs to provide an easily pluggable deserialiser for common options but it makes sense that the package doesn't make too many assumptions e.g. xsd's booleans (0/false and 1/true) are very much incompatible with xhtml's (absent/present).
I do, here's my config: On \`init.el\`: `(rust :variables` `rust-format-on-save t` `rust-backend 'lsp)` Then on my own lsp layer (I use lsp for rust and c++): `(defconst jv-lsp-packages` `'(lsp-mode` `lsp-ui))` &amp;#x200B; `(defun jv-lsp/post-init-lsp-mode ()` `(defun jv-lsp/setup-lsp-mode ()` `(setq lsp-remap-xref-keybindings nil)` `(setq lsp-navigation 'both))` &amp;#x200B; `(spacemacs|diminish lsp-mode " ‚ìÅ" " L")` &amp;#x200B; `(add-hook 'c-mode-hook 'jv-lsp/setup-lsp-mode)` `(add-hook 'c++-mode-hook 'jv-lsp/setup-lsp-mode)` `(add-hook 'rust-mode-hook 'jv-lsp/setup-lsp-mode))` &amp;#x200B; `(defun jv-lsp/post-init-lsp-ui ()` `(defun jv-lsp/setup-lsp-ui-mode ()` `(setq lsp-ui-doc-enable t)` `(setq lsp-ui-doc-include-signature nil)` `(setq lsp-ui-sideline-enable nil)` `(setq lsp-ui-sideline-show-symbol nil)` `(setq lsp-ui-sideline-ignore-dupliate nil))` &amp;#x200B; `(add-hook 'c-mode-hook 'jv-lsp/setup-lsp-ui-mode)` `(add-hook 'c++-mode-hook 'jv-lsp/setup-lsp-ui-mode)` `(add-hook 'rust-mode-hook 'jv-lsp/setup-lsp-ui-mode))` &amp;#x200B; &amp;#x200B;
As someone who is recently getting into the language, this was a great introduction to Vectors and ownership. Well done. :) I look forward to the rest.
I have a copy of The Rust Programming Language by Steve Klabnik and Carol Nichols that I no longer need and thought I'd pass it on to one of you rustaceans. I am located in Montreal, Canada and can ship this to anywhere in Canada or the CONUS. You're welcome to enter from another country if you're willing to pay shipping. &amp;#x200B; **Please upvote this post and comment below about why you're learning Rust. Any reason works, just having a comment since I can't see who upvotes. I will choose a winner in one week and will follow-up by sending the winner a private message through Reddit.**
 for (auto &amp;i: v) &gt;over &amp;#x200B; for i in &amp;v &amp;#x200B; yeah, big difference. means a world to me!
I'm starting to dip my toes into game dev. And I have a dream that Rust will replace c++ in most game engines at some point. I also like seeing the differences to Go, which is my primary language.
That is a nice keyboard. How do you find not having the keys where fn and ^ would usually be? 
Love it! The keyboard has layers so I just press the function key and another key to access anything that isn't on the base layer. 
‚ÄúI used to be a C++ zealot, but now I see the light and I‚Äôm a Rust zealot!‚Äù 
Always good to keep that Dunning-Kreuger in check
Cool thanks - subscribed!
&gt;My singular qualm is the time it takes for even incremental builds of a 25kloc codebase, but with the number of ways that the compiler tries to prevent me from doing something stupid, it is 100% worth it. How long is it? I've been curious about rust for a while, but the slower compile times have always been a show stopper. Are you talking like 10s or 1m or worse?
Interesting. I will keep an eye on this blog. I fiend scientific computing in rust somewhat challenging. I had to make simple bindings to libqhull to do some triangulation, and then get a guilty feeling for not doing it properly, and make a full crate out of it. Now I need to calculate some Eigenvectors, and am sorely tempted to just do it in numpy. Let me know if you find Eigenvectors in some Rust crate :-)
I freaking love python syntax, hut something about it doesn't make me want to write programs. I just always end up back at C++, and Rust seems to fill that void between the beautiful easy syntax and ease of use, with the control, structure and speed of C++. I've only just started the journey into Rust recently, but I think it's going to be a great relationship going forward.
&gt; I'm just trying to find general cases where doing so and working in rust provides benefits over just using C++. First of all you need a reason to use Rust. If your current application or parts of it do not have continuous serious issues with being implemented in C++, then I do not see a big reason for using Rust. Adding another language to a code base has also its cost and should be considered.
And why shouldn't you? It's a nice gesture and it's on topic. Thank you for doing this.
While I agree that rust done a lot of things nicer than c++, iterator loop syntax is fairly minor. What is big though is how much easier it is how much easier it is to implement iteration on a type and how you can be confident you're not using your iterator incorrectly (no more iterator invalidation bugs!)
No. Right now I focused on the implementation of all combinators. I implemented almost all Future combinators (except poll\_unpin/boxed/remote\_handle) and \~half of stream combinators with basic tests.
So far looks good! Thank you for makinging it! I do have some nits: &gt;&gt; // There is no return keyword in Rust! Yes there is, but it is not needed here and it is idiomatic not to use it. &gt;&gt; But we said that we do not want to allocate new memory ‚õî You did not say that explicitly. 
Conan?
Leave in Toronto Ontario and interested in Rust for embedded programming but currently learning the basics and would like to have a solid knowledge base of the language before jumping in to embedded. Thanks and appreciate what you're doing regardless of who wins. 
They‚Äôre equivalent, and rustdoc sees the desugared form, yeah.
Ops, I slipped on return üòÖ I'll fix it once I get home! For memory allocation: &gt; Let‚Äôs put down some rules: let‚Äôs say that, given a vector of integers, we want to sort it in increasing order without allocating a copy of its elements.
a C++ package manager, though it's not as ubiquitous or standard like Cargo. https://conan.io/
\&gt; async code infest everythin with async. That's not true. You can have a look at [https://docs.rs/futures-async-combinators/0.2.0/src/futures\_async\_combinators/stream.rs.html#122-137](https://docs.rs/futures-async-combinators/0.2.0/src/futures_async_combinators/stream.rs.html#122-137) , where there is async/await in a not async function returning impl Stream.
I've gotten away from programming, but want to start doing game development for fun. Write an open source rogue-like, and Rust seems like a good fit.
You might get more accurate results with hyperfine: https://github.com/sharkdp/hyperfine
I started learning when unemployed to keep myself busy, had to stop due to my laptop not being good enough but recently restarted after upgrading. Hadn't done anything like it since doing BASIC at school in the early 80s. I just really enjoy it and, because I do, my friend who's a software dev recently got me the companion book for NAND To Tetris to work through too.
I think it's highly unlikely that you will see this in the short/medium term, because there are (older) alternatives that already come with the OS and whose main advantage is that they are ubiquitous in all OS.
I can't help, but in case this is of any use for testing: org-mode has [some functions](https://github.com/ludios/org-to-json/blob/ee3ab4d361e3e59f877c8f39c0034728786c1649/org-export-json.el#L6-L8) that you can use to dump its own parse of an .org file, if you wish to compare it to your own.
\`cargo-license\` is a fantastic tool for reviewing licenses quickly in case it helps!
This is so generous of you, thanks! I'm an early career, self taught, frontend JavaScript developer. I don't have any CS background and I'm dipping my toe in Rust just to force myself to learn/think about things like memory management, which I don't need to touch with JS. I don't really have any practical ideas for how I'll use Rust in the future, though I guess WebAssembly is poised to to become more of a thing!
A lot of the people in the game dev scene seem to be losing faith in c++ It‚Äôs possibly just dramatics but if the industry starts moving towards rust I want to be ready. As well, I feel like in general I just like the forms of programming that rust encourages
Thanks, that looks helpful!
To borrow mutably, you make your function take a mutable borrow: `fn alter_array(data: &amp;mut Vec&lt;u8&gt;)`, and then pass a mutable borrow to it: `let done = alter_array(&amp;mut data);`.
Thanks for the suggestion! I've posted a few questions there, but haven't had much luck. I think once I have specific questions or blockers, it'll be a good resource for getting unstuck, but for now, I'm hoping to get some more generalized guidance and a better conceptual framework/plan.
/s?
Grab lsp-company mode off of melpa and configure it something like what I have. There's some way to use complete-code-at-point or something like that, built into newer versions of emacs.
The choice doesn't affect performance. In some cases you must choose to move, and in other cases you must choose to borrow.
I am a web developer learning rust for web assembly. But I am also pretty lost with rust
I was looking for a maximum performance, higher-level back-end language with web servers in mind. I tried Go but didn‚Äôt like how opinionated it was (or rather the opinions themselves.) Once I discovered Rust, I knew that it was the language I was looking for, and even more. It‚Äôs ‚Äúopinions‚Äù make a lot more sense and is superior to Go in every way. I only wish that I had more time to hone my Rust skills ‚ò∫Ô∏è
Started learning rust about a year ago, and am pretty confident it is the right choice to use in my hopefully potential startup :P
I don't have that issue. Did you consider filing a bug?
Roses are red, your spacebar is blue, you should give me that book, or I'll rip you to shreds &amp;#x200B; I'm bad at rhymes. With love &lt;3
If you've never touched an HHKB I might find someone who has one to try out this it feels. I just saw them at a booth at a developer conference and was surprised how spongey they felt. Apparently they use electro capacitive switches - which aren't actually mechanical 
After hearing about Rust for several years, I started really trying to learn it only last week. I'm learning it so I can play with a couple of Rust frameworks(I'm playing with multiple frameworks and languages in web to gain a feel for them). I'm also learning Rust, to become a better engineer. Rust is making me think about ownership and immutability when I declare and pass variables around, in all languages, not just Rust. And I think that's really cool.
Relatively new to programming as a whole, and trying to decide on any sort of language to learn. Having dabbled in python and c++ it seems like rust would be a cool combination of sorts and something newer to get stuck into 
I want to learn programming and Rust looks interesting.
im learning rust because c++ is giving me headaches and im hoping that bext year my FRC team will be able to use it for the robot
- Zero cost abstractions - Deconstructing - Compiler enforcing resource management and threading (somewhat) - `cargo` and a standard dependency management - How "easily" it integrates with other languages 
The HHKB Professional series uses Topre switches, which do use a rubber dome, but also a spring. &gt; Because the Topre switch utilizes a rubber dome, there is ongoing disagreement in the keyboard community over whether it should be considered "mechanical" or even "semi-mechanical". Some of this controversy comes from disagreement over whether this categorisation should be determined by its construction (the inclusion of a dome as well as a spring) or by some of its properties that distinguish it from conventional rubber-dome keyboards (crisp, light feel and mid-stroke actuation point). &gt; The switch's dome does provide most of its resistance and all of its tactile feel; but unlike conventional rubber-dome keyboards, the Topre's dome does not provide any "mushy" resistance near the bottom of the stroke. Its conical spring provides only around 5 cN of actuation force and is therefore critical only for sensing keypresses. It's definitely a different feel from typical mechanical keyboards, from what I've heard, so I would agree with the suggestion to feel one first.
Now I specify it in the README, [https://github.com/rust-iendo/yarte#wip-yarte-----](https://github.com/rust-iendo/yarte#wip-yarte-----) , as you see you were right it is a fork two have a configuration sheet!
One question which I hope will get covered is using (and if it's possible to do) heterogeneous SoA-layout with `ndarray`. For example when working with point clouds for performance reasons ideally I would like to have structure like this one: // all fields have the same length and // ideally fields also should share capacity struct Cloud { // coordinates x: Vec&lt;f32&gt;, y: Vec&lt;f32&gt;, z: Vec&lt;f32&gt;, // normal vector xn: Vec&lt;f32&gt;, y: Vec&lt;f32&gt;, z: Vec&lt;f32&gt;, // point color r: Vec&lt;u8&gt;, g: Vec&lt;u8&gt;, b: Vec&lt;f32&gt;, } And being able to integrate with utilities which expect array types defined in the `ndarray` (or other foundational crate).
This is interesting, but I am not sure I understood 100% your question. Do you want to know if it's possible to build an equivalent Cloud struct using ndarray::ArrayBase instead of Vec while retaining compatibility with crates that manipulate ndarray::ArrayBase? Would you use one array for each field (as you are doing with Vec) or are you interested in merging multiple fields into a matrix? I assume memory locality is what you are concerned about (having all color values next to each other in memory to use SIMD instructions?). If you could elaborate a little more it would be really useful :)
Fixed the return typo, thanks for spotting it!
Eigenvectors/eigenvalues computation (as well as SVD, QR, LU, etc.) are supported by the nalgebra crate (see [https://www.nalgebra.org/decompositions\_and\_lapack/](https://www.nalgebra.org/decompositions_and_lapack/)) if you need something pure-rust (without any C/FORTRAN dependency). There is also the [nalgebra-lapack](https://docs.rs/nalgebra-lapack/0.9.0/nalgebra_lapack/struct.Eigen.html) that also has eigendecomposition, but backed by C/FORTRAN implementations (based on accelerate, OpenBLAS, netlib, etc.)
For `Copy` types there is a choice. Even for `Clone` types there _could_ be some edge cases where cloning is faster.
Something like [this](https://github.com/JuliaArrays/StructsOfArrays.jl) perhaps is what you are looking for? (from Julia)
I want to rewrite some production code written in php to a faster, smaller footprint.
This is an extremely odd pattern. There might be more efficient patterns. What exactly is your usecase, i.e. original input source and what does your final query pattern look like?
Me too.
I‚Äôd like to vouch for rouille as well. It‚Äôs extremely simple and low-boilerplate. I‚Äôve used it for several projects and have had no problems with it. For example, a hello-world server in Rouille has the lowest boilerplate of any framework I‚Äôve seen: use rouille::Response; fn main() { rouille::start_server("localhost:80", |req| Response::text("Hello, World!")); }
You need to make a HTTP HEAD request first to get the headers.
I started learning Rust because I only had experience with OO Java before, and wanted to learn a systems programming language. The Crated system is absolutely amazing and I love it.
The comment implied something negative about what he was actually saying, though, like it is overboard and biased.
That is awesome, I wish rust had been a thing back when I was a student participating in FRC. Maybe I should go back to mentoring ü§î
Very interested in rust‚Äôs potential in game dev. 
I'd like to expand my embedded experience w/ xargo or the like through Rust's language. Seems like a neat challenge 
Based on the attitude of the developer about licensing issues with this fork I'd stay far away: https://github.com/rust-iendo/yarte/issues/5
[removed]
I'm learning rust because I get to choose languages to use on each project I lead at my job. I've tried to get rust going, but unfortunately my lack of experience with it and the immaturity of it's data science libraries made it a no go for the last project I kicked off.
I guess we can divide into several questions: - Can `ndarray` represent heterogeneous SoA-layout? I *think* it can represent homogeneous cases as arrays with fixed height and dynamic width, but not heterogeneous cases. - Is it possible for `Cloud` to mimic `ndarray` type without copying data around? For example imagine someone wrote a function which fits plane to points represented as `Nx3` array, ideally I would like to use some kind of `From` trait which will pass just 3 pointers, but I guess it will not be possible with how `ArrayBase` is [defined](https://github.com/rust-ndarray/ndarray/blob/master/src/lib.rs#L1048) right now. - Do we have any plans for `ndarray` (or any other foundational crate) and user-defined SoA structs compatibility? The main advantage of SoA-layout is that it's much more suitable for SIMD optimization, with `Vec&lt;Point&gt;` you'll have to shuffle data around, while with `Cloud` you can just load X, Y and Z coordinates directly into SIMD registers. Also SoA is significantly cache friendlier, as you load only data which will be used, so if I want to apply translation I will only load data from `x`, `y` and `z` fields, while `Vec&lt;Point&gt;` you will load data for all fields, due to the fact that CPUs load data into cache by "[blocks](https://stackoverflow.com/questions/3928995/how-do-cache-lines-work)".
I'm learning rust because before 2015, I was holding myself to web design and scripting to automate things around the office I worked for, thinking systems programming and game programming were beyond my ken. In 2015, after a few personal trials, I ended up suicidal and homeless. Last year, I was able to dig myself out of that and back on to my feet. Looking back, I figure if homelessness, alcoholism, and suicide were things I could think through and solve, systems programming can't be all that daunting after all.
I‚Äôm exploring Rust as the potential future for web and cross platform development, as well as a strong foundation for future languages/abstractions to build on top of. I think there‚Äôs a tidal wave of change we‚Äôre going to see happening soon and I think Rust is going to be at the heart of it. I would like to be part of that, or at the very least, learn how to swim üòâ
Ok, I have it clear now. I think what you are looking for is something that is yet to be written, but it's sorely needed - a Rust equivalent to Python's \`Pandas\`, with a strongly typed schema (your \`struct\` definition) while using \`ndarray\`'s \`ArrayBase\` as the underlying data structure to represent the data in each column (column-oriented storage instead of row-oriented storage, or SoA as you called it). This is definitely something we need (for doing handling ML data it's quite foundational) but it's not there yet and it's quite difficult to build. 
Good developer! &amp;#x200B; Big table/Askama time: \[536.39 us 536.60 us 536.88 us\] Big table/Yarte time: \[203.51 us 203.64 us 203.81 us\] Teams/Askama time: \[730.16 ns 731.11 ns 732.20 ns\] Teams/Yarte time: \[248.69 ns 248.77 ns 248.85 ns\] &amp;#x200B; Its a fork! yes it's a fork! you its a fork? who is a fork ?
It's relatively trivial to link Rust code with a C++ program and start using it by using [\`bindgen\`](https://github.com/rust-lang/rust-bindgen) and compiling the Rust program as [\`staticlib\`](https://doc.rust-lang.org/reference/linkage.html). \`bindgen\` produces a C header for your Rust crate and compiling the crate as a \`staticlib\` will produce a \`.a\` file or \`.lib\` file that you can use with your C++ compiler. This should allow you to start using Rust with a relatively native interface in an incremental fashion, without needing to maintain manual bindings. &amp;#x200B; For linear algebra, you can check out [\`nalgebra\`](https://nalgebra.org/) in the [\`rustsim\`](https://rustsim.org/) project. Whether it will bring you any actual advantage over your current workflow is hard to say, but safe Rust does make it \*much\* easier to safely parallelize your code which may be relevant for your domain. Try using [\`rayon\`](https://github.com/rayon-rs/rayon) with \`nalgebra\`. &amp;#x200B; In general, Rust may provide savings for your business by lowering the number of bugs and thus the time you spend debugging. I don't believe any rigorous studies are available to support this, but you can read [this thread](https://www.reddit.com/r/rust/comments/aohq6u/rust_velocity_and_defect_rates/) and [this thread + article](https://www.reddit.com/r/rust/comments/apm5dp/microsoft_70_percent_of_all_security_bugs_are/) for community views on the business value of replacing C/C++ with Rust.
Although they aren't completely visible to the outer world (which is a goal of this post) if you'd like to get involved in the nitty-gritty discussions, check out Raph's synthesizer channel at [https://xi.zulipchat.com](https://xi.zulipchat.com) or the RustVST group on their [Telegram Chat](https://t.me/joinchat/BfEhnw0l4386Uzi5elmGrQ) .
Yes, you got it right.
&gt; Imagine how awesome it would be to have Rust plugins that don't crash their host application, or open up security vulnerabilities! I can imagine that the audio industry would be very interested in seeing this happen. Based on my experience with VST plugin users. They care about whether the plugin gets the job done, and how easy for them is to get the job done using the plugin. They don't know or care about security beyond installing an antivirus and cannot attribute crashes to a particular plugin. And even if they can, they usually stick to it anyway because they've already bought it. Besides, the VST plugin ecosystem is largely commercial, and companies tend to stick to the tried and true tool that they have the experience and libraries for. Making all your products use the same language and libraries reduces maintenance burden considerably. Since VST plugins are not security- or reliability-critical, I do not see companies adopting Rust for VST plugins anytime soon. So while I admire the effort as a programmer, I doubt there is actually a market for it. I would love to be proven wrong, though.
This works as intended ```rust fn main() { let mut data = vec!(0x00, 0x01, 0x02, 0x03,); let done = alter_array(&amp;mut data); println!("done: {}", done); println!("new data: {:x?}", data); } fn alter_array(data: &amp;mut Vec&lt;u8&gt;) -&gt; bool { for i in 0..data.len() { data[i]+=1; } return true; } ``` Now rust "allows" **only one mutable borrow** 
I'm looking for a system programming language that doesn't start with a "C" and helps the programmer write correct software. So far I've played with Ada and like its type system, but I'm also wanted something a bit more modern, so Rust is something I'm exploring for system and embedded programming. 
Crossbeam's 2019 roadmap post has mentioned implementing low-latency SPSC queue as a potential work item: https://stjepang.github.io/2019/01/29/lock-free-rust-crossbeam-in-2019.html#where-to-next
Been using Python a lot for work and school recently, I miss lower level systems programming. So I'm learning Rust in my free time to get back into that world. I've written enough C++ for a lifetime.
Could you provide the rest of the relevant code and post it to [https://play.integer32.com/](https://play.integer32.com/) ? I can't actually check what compiler errors you're getting since there's code missing.
Avoid `if let` in these situations, `match` is much better at allowing moves combined with enums.
I really don't get the hype around these minimal keyboards. It would annoy me to no end to always pushing combinations to access keys that are not present. Ok, you don't always need keys like Pos1 or End, but the F keys? And i do like my numpad.
The whole project is on [https://github.com/awall/rudiger/](https://github.com/awall/rudiger/blob/master/src/backend/shape.rs) &amp;#x200B; It should build with the latest stable "cargo build", except for the one compiler error I'm mentioning. The file is question is [https://github.com/awall/rudiger/blob/master/src/backend/shape.rs](https://github.com/awall/rudiger/blob/master/src/backend/shape.rs)
I'm still a student, but I've recently taken an interest in both C++ and Rust recently due to an amazing professor I have this trimestre that's on the C++ design committee. Rust just makes it easier and more straightforward to achieve what I want to do (usually :p), while forcing me to avoid many pitfalls that I could fall into. I like it so much that my team is using it for our capstone project. 
I think you've made great points, Shnatsel. I completely agree that there is already a lot of inertia with the tools available. Also, VST customers probably won't care about what the heck the thing is written in as long as it *sounds* good. BUT! Thinking in the *long term*, I would not be surprised to see a company like Steinberg or Propellerhead be very interested in having a plug-in SDK that has guaranteed safety. Propellerhead especially, since they are already doing something similar with their sandboxed [Rack Extensions](https://www.propellerheads.com/developers). 
I rewrote the code with match and still have the same error: fn multiply_notok(self, matrix: Matrix2d) -&gt; Self { match self { Shape::Transform(mut t) =&gt; { t.transform = multiply(matrix, t.transform); self }, _ =&gt; { Shape::Transform(Transform { shape: Box::new(self), transform: matrix }) }, } }
I'm learning rust because match &gt;&gt;&gt; switch.
It is not about how good developer you are, it is how decent human being you are, and from that thread it seems that not much. TBH I really hope that the original author will send DMCA on this repo, as we should fight with the hostile and unlawful developers.
Learning rust because I've been silo'ed into web dev and I'd like to work towards the other end of the programming spectrum without completely derailing from the work I do on the day to day (web assembly creates a relationship!)
If you want I can write a small stand-alone [main.rs](https://main.rs) that exhibits the problem.
That is, despite putting at your disposal a much faster code than your current response as programmers to my work that you have not bothered or looked. &amp;#x200B; 20 years developing to say that they have forked your work, I do not even finish the university that's why all this.
&gt; For instance, one solid problem to solve is that we need a really solid lock-free queue that will allow communication with the main audio thread without increasing the probability of causing horribly sounding pops/clicks. Hi there, author of Crossbeam's queues here! I'd love to help here in any way possible, just tell me what you need. :) To be honest, I'm not super familiar with audio processing and need more input on exact requirements, so here are some questions: 1. What kinds of SPSC queues do we want, bounded or unbounded? 2. If bounded, what should happen when we try pushing an element into a full queue? Does the push operation fail or does it succeed by overwriting the last pushed element? 3. Does the queue need a drain operation that takes all elements from the queue in one go? Or are we only interested in popping elements one by one? 4. Can there be multiple producers? Does it ever make sense for multiple threads to produce audio? If so, do we typically want a single MPSC queue or an SPSC queue per producer thread? 5. More broadly speaking, what does the audio thread do exactly with the queue? Is there pseudocode, a blog post, or a tutorial I can read to learn more? I'd just like to understand all this in more detail. 6. What's the element type in the queue? Integer, pointer, something else? Is it a `Copy` type? 7. Crossbeam has [`ArrayQueue`](https://docs.rs/crossbeam/0.7.1/crossbeam/queue/struct.ArrayQueue.html) and [`SegQueue`](https://docs.rs/crossbeam/0.7.1/crossbeam/queue/struct.SegQueue.html), which I believe should be perfectly fine for audio. Anyone tried them? Is there anything they are still missing?
I have programmed a lot in C and wanted to pick up something new. A friend of mine wrote something for rust that rebuilds the AST from the binary to allow for proper exception handling. I have his paper for those interested. And now I am here :D
I don't have all the code so I can't test it properly, but maybe try something like this? ```rust fn multiply_notok(mut self, matrix: Matrix2d) -&gt; Self { match self { Shape::Transform(ref mut t) =&gt; { t.transform = multiply(matrix, t.transform); }, _ =&gt; { self = Shape::Transform(Transform { shape: Box::new(self), transform: matrix }); }, } self } ```
Just wondered how do I produce sound in rust? Is there a lib "play(frez: u128) . and it plays a sound?
Try this self-contained example: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=3056eed46adaf6e481cfa23f3ac78d26](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=3056eed46adaf6e481cfa23f3ac78d26)
Yep, for me `rust-vst` is 95% "this is just cool to mess around with since I'm interested in music production stuff", and 5% "this might actually be pretty useful for 'indie' VST developers to ship plugins with, someday". I'm definitely learning a bunch of stuff I wouldn't normally come across in my day job, either way. 
Just playing with probability. I am learning Rust because I am a systems programmer who moved to large scale distributed systems couple of years ago. I was looking for something which is fast, efficient with high level PL constructs. Found rust via a YouTube recommendation and now I try to learn it in free time. Still newbie but will get there eventually. :) 
Try s =&gt; { Shape::Transform(Transform { shape: Box::new(s), transform: matrix }) },
Hey stjepang! Hopefully u/raphlinus and u/holycity show up to help answer some of those questions, but I can certainly point to the [Boost Lockfree queues](https://www.boost.org/doc/libs/1_69_0/doc/html/lockfree.html) as an excellent example of what audio applications need. The author, Tim Blechmann, did a lot of awesome work on the [SuperCollider](https://supercollider.github.io/) platform, which is a shining example of opensource audio engines. 
This is the most intuitive response I've received about the problem yet. The explanation makes sense, and I have some ideas of how to fix it - aside from using a different library all together. The original design of the library was to use multiple windows in a single run loop, but this could break, or hang, if one window takes over the run loop. As a result, I'm going to break this out into multiple pieces such that the run loop can be run in a thread. This way, access to each part of the app is limited to its window, rather than the run loop. I'd have to pass the Context, G2d object, and widget tree to another routine that is captured _outside_ of the run loop, which will bypass some of the closure restrictions. I just wish the library had been designed a little smarter. Either way, my work-around should solve this, based on your insight. Much appreciated!
You know, the compiler _did_ recommend a clone. However, if I'm storing the widget tree and window instance in Heap, it means for a much slower run loop, since the data has to be copied in heap. It would make more sense if I were drawing on a textured surface, but then I run into issues with the GL library with regards to drawing on a 3D texture. I may approach it from that perspective as well, as drawing on 3D textures and displaying the result on a flat display surface is ultimately the fastest way to render. I'm still thinking about it. :)
Thanks for the giveaway! I'm learning Rust to diversify my skillset (I'm a React dev by day). 
[https://github.com/djc/askama/graphs/contributors](https://github.com/djc/askama/graphs/contributors) 31 commits 1,487 ++ 622 -- [https://github.com/djc/askama/pulls?utf8=%E2%9C%93&amp;q=is%3Apr+is%3Aclosed+author%3Abotika+](https://github.com/djc/askama/pulls?utf8=%E2%9C%93&amp;q=is%3Apr+is%3Aclosed+author%3Abotika+) I'm not programming because of people like you, and I has 54 commits in last few days only in yarte, [https://github.com/rust-iendo/yarte/graphs/commit-activity](https://github.com/rust-iendo/yarte/graphs/commit-activity) &amp;#x200B; Today had to leave the support for super::, parent scope. And thanks to you I'm answering things that have nothing to do with computer engineering.
/r/MechanicalKeyboards 
I'm learning rust to take over the world.
I found rust when I started looking for a solution for fast processing of time series scientific data. I had a brief touch of c++ in high school, but all of my recent work has been in python. I am looking to grow as a data scientist as well properly learning a compiled language. 
Haha, yeah, these videos end up pretty long, but not much I can do about that. It turns out that it takes a while to build real things :p If you find good natural break points in the video while watching though, send them to me and I'll add them to the video description!
\^ tested using the playground link I got from op [(here)](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=3056eed46adaf6e481cfa23f3ac78d26) after seeing that and came up with a similar solution so that probably works... I did the following: fn multiply_notok(mut self, v: i32) -&gt; Self { if let Shape::Transform(ref mut t) = self { t.transform = v * t.transform; self } else { Shape::Transform(Transform { shape: Box::new(self), transform: v }) } } as a kind of "minimal changes" thing.
This [talk from Timur Doumler](https://www.youtube.com/watch?v=boPEO2auJj4) explains the needs of audio applications quite well. Really generally speaking, the audio thread needs to received events from the GUI thread, such as when a user turns a knob, or midi events from a controller. Generally midi events will be buffered and passed to the audio rendering callback along with a buffer of audio (floats), but GUI events will usually be put on a queue to be pulled at the next audio rendering 'frame' (the next time the host calls the audio callback). Raph would really like to have *any* kind of data structure live in that message queue, to allow for really sophisticated audio rendering, but its typically plain old data (POD) like ints and floats. Timur's talk goes into passing more complex data types to the audio thread, and the challenges that C++ presents. 
I am a college student who is just about to graduate and am learning rust because of how promising it is. With good macros, some rust frameworks like Rocket look basically as simply as python. In most of what I work on I really care about getting every ounce of performance out of a system. I feel that most programs waste way too much energy and time. I am learning Rust because I want to be able to write efficient systems with a modern and powerful language that doesn't make me worry about bugs. Compile time is the right time to remove bugs. 
oh I hope that didn't come off as me saying they're too long! I've really enjoyed your series this far! Also, today being the day, if any section break points jump out at me I'll make an effort to forward them along :)
Thank you! At the end of the day, that "ref" did the trick. If I understand correctly, this "ref" means I'm no longer moving the "Transform", I'm just borrowing it mutably, which still allows me to change its transformation matrix. fn multiply\_notok(mut self, matrix: Matrix2d) -&gt; Self { if let Shape::Transform(ref mut t) = self { t.transform = multiply(matrix, t.transform); self } else { Shape::Transform(Transform { shape: Box::new(self), transform: matrix }) } }
`fn unwrap(self) -&gt; T` uses the variable. You need `fn as_mut(&amp;mut self) -&gt; Option&lt;&amp;mut T&gt;` to get to the inner value. Then you still have an option to unwrap.
Yeah, definitely try one before. I didn't try one before but I absolutely love mine and don't use any other keyboard now. Depends on the person.
alright ill try this. &amp;#x200B;
Say what
Im living in germany and have been employed by an startup on my first day at university. Im working on an way to help people to walk again after loosing their nerves in the legs. Ive been searching for an oo language with an easy syntax like python and rust got me with wasm , cargo and even an way to build an programm right from termux.
Depends on the person. I rarely use the keys that aren't on the base layer.
[https://imgur.com/a/esrjKP6](https://imgur.com/a/esrjKP6)
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/u3ptsX5.jpg** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20eh6vif0) 
I don't believe there are any libraries that have that kind of high-level audio programming api's, but I could be wrong. I think that would definitely be a great thing to provide for the rest of the rust community that might need to do some creative coding without having to deal with the low level stuff.
Thanks for your answer. Any thoughts if it is worth to raise an issue for it, and if there is a realistic chance to improve it? [This search](https://github.com/rust-lang/rust/issues?utf8=%E2%9C%93&amp;q=is%3Aissue+label%3AT-rustdoc+anonymous+lifetime) did not find a relevant issue.
I‚Äôm not sure.
Usually you set up a callback which takes in a buffer, and writes samples to that buffer. Something like: ``` fn process_audio(buffer: AudioBuffer&lt;f32&gt;) { for i in 0..buffer.len() { // process some audio, write resulting audio sample to buffer[i] } } ``` The audio backend will call it whenever it needs more samples, all you have to do is fill in the buffer with audio samples. So for example if I want to generate a simple sine wave with a given frequency, I like to make a `SineGenerator` struct that knows what the next sample should be, and within that loop I can just call `sine_gen.process()` to give me the next `f32`.
&gt;&gt; For instance, one solid problem to solve is that we need a really solid lock-free queue that will allow communication with the main audio thread without increasing the probability of causing horribly sounding pops/clicks. &gt; &gt;Hi there, author of Crossbeam's queues here! I'd love to help here in any way possible, just tell me what you need. :) &gt; &gt;To be honest, I'm not super familiar with audio processing and need more input on exact requirements, so here are some questions: &gt; &gt;1. What kinds of SPSC queues do we want, bounded or unbounded? Honestly, both. The common cases are covered by bounded FIFOs (textbook solution to the problem) &gt;2. If bounded, what should happen when we try pushing an element into a full queue? Does the push operation fail, does it block, or does it overwrite the oldest pushed element? I think the vast majority of code out there is using lock free FIFOs where the oldest element is overwritten. The most recent value always needs to be consumed, if the oldest hasn't been consumed then its already invalid. Usually. &gt;3. Does the queue need a drain operation that takes all elements from the queue in one go? Or are we only interested in popping elements one by one? Yes. &gt;4. Can there be multiple producers? Does it ever make sense for multiple threads to produce audio? If so, do we typically want a single MPSC queue or an SPSC queue per producer thread? There are two cases, producing data consumed by an audio thread, and producing data on the audio thread consumed elsewhere. For the former, MPSC is definitely possible, the latter A more specialized use case is that it may be necessary for the software to handle multiple audio callbacks from different devices (which may or may not be on different threads, it depends on the drivers). However you want to present this to the user as a single callback, which would call for MPSC queues. &gt;5. More broadly speaking, what does the audio thread do exactly with the queue? Is there pseudocode, a blog post, or a tutorial I can read to learn more? I'd just like to understand all this in more detail. In general, the audio thread only has access to input/output data and processing state, and any UI/blocking operations occurs on a separate thread. So event and state change data that alters the audio processing is sent through the queue, and if the audio thread produces any information to be displayed you pass it out of the audio callback through a queue. Think meters, visualizations, etc. The JUCE forum has a lot of discussion about this if you search around it, you can also check out the KVR developer forum. &gt;6. What's the element type in the queue? Integer, pointer, something else? Is it a `Copy` type? The type should be generic that is not necessarily copy. It depends on what the audio app is actually doing. Like for example a meter might want to pass off blocks of floats. Parameter changes would be received as something like `(u64, u64, f32)`. Events would be an enum variant. Hope this helps. 
Awesome, just to clarify - since you're not in the USA or Canada, you're willing to pay for shipping? See my post in the comments for rules. Thanks
I'm interested in Rusts ability to be used on Microcontrollers.
Usually you set up a callback which takes in a buffer, and writes samples to that buffer. Something like: fn process_audio(buffer: AudioBuffer&lt;f32&gt;) { for i in 0..buffer.len() { // process some audio, write resulting audio sample to buffer[i] } } The audio backend will call it whenever it needs more samples, all you have to do is fill in the buffer with audio samples. So for example if I want to generate a simple sine wave with a given frequency, I like to make a `SineGenerator` struct that knows what the next sample should be, and within that loop I can just call `sine_gen.process()` to give me the next `f32`. I've played around with the [PortAudio](https://github.com/RustAudio/rust-portaudio) and [Jack](https://github.com/RustAudio/rust-jack) crates, and that's pretty much how it works (a tiny bit simplified, but not by much). This is also how [`rust-vst`](https://github.com/rust-dsp/rust-vst) works as well.
Once a thread gets lost in the weeds of non-terminating code, there's usually no good way to forcibly recover the resources it was using short of terminating the process. (And even that can leak lock files or inconsistent structures in shared memory.) OpenGL has "contexts" and they are in Rust terms Send but not Sync. There's no safe way to fix a context if a frozen thread is holding on to it. Some operating systems, probably most, have some annoying restrictions or others on how GUI events may be handled. (As least X allows multiple connections. Xlib isn't usefully thread-safe, XCB and Wayland may be, I don't think Winapi is, dunno about Cocoa.) Firefox and Chrome use multiple processes for sandboxing and robustness not because it's easier but because they actually have to. 
You might want to look into `Option::get_or_insert_with()` as well.
I keep seeing this stuff, but what is a "template engine?" Is it a way of writing HTML in Rust or something? 
Oh, no, not at all! I was just empathizing with your experience of them being long :) I'm glad to hear you've been enjoying the videos! Awesome, that'd be great.
It's a way to dynamically render HTML on the server side using rust. For example: you could turn a list of strings into an HTML ordered list.
Gotcha, thanks!
I am learning Rust so that my code is more readable to myself when I see it later, better memory management unlike C++, and it has a new concept of data types called vectors which can be declared very easily in the source code. Rust can also be compiled WebAssembly binary format, which is also one of the plus points for why I want to learn it. Another thing that I desperately want to understand is concurrency. Which is why I am learning Rust.
I'm learning rust because I want to use it for low level programming, since I'm not good enough in c++ yet to avoid causing problems.
alright ill check it out. my tree works now and does the traversals i wanted to do, so ill check that out to see if it helps my code out. &amp;#x200B;
there are no official libraries for using rust in conjunction with the RoboRio, but maybe someday! there are some people working on their own versions already
I'm interested in language design and Rust seems like a well-designed language
I checked it out. I cant see where it could be useful, but I cant think of a good logic flow for it. but it is very nice to know about for future endeavors. My 300 level c++ course is going to allow us to do a solo project throughout the semester in whatever language we want as long as we implement data structures and can explain them in terms of c++. So I am going to play with a rust game engine, and this definitely will be for that. 
\*nod\* I'm the opposite. 1. I'm big on fitting my muscle memory to commodity hardware to limit my dependence on a single product line. (A policy I adopted after Logitech [redesigned](https://en.wikipedia.org/wiki/File:LogitechG15V2.jpg) the G15 back in 2007 and, for a while, didn't have anything in the [gen-1 G15](https://en.wikipedia.org/wiki/File:Logitech_G15_(blue).jpg)'s layout.) 2. I rely on things like Win+Arrows or Win+NumPad for custom hotkeys that I use frequently. (Win+Arrows for switching songs in my media player, for example) That said, I did paint myself into a little bit of a corner when Unicomp decided to [make their US-104 layout **non**-standard](https://www.pckeyboard.com/mm5/graphics/ProductNews7-25-13.pdf) in 2013, since they're the only source of buckling spring boards with Windows keys. (I'm too spoiled to like the feel of my old Cherry MX Blue board now.) With the help of eBay, I stockpiled two spare pre-2013 buckling spring boards... and I'm enough of a glutton for punishment that, when I have the budget, I'd like to try a [Model F-based version of the IBM 122-key terminal keyboard](https://www.youtube.com/watch?v=p_JTZo2rKmw), remapped to approximate US-101 with some Windows keys shoved into the closest place they'll fit. (The only way I can think of to get US101-style function key positioning in a Model F board, given that the [project to make new ones](https://www.modelfkeyboards.com/) is focusing on your ultra-compact style of keyboard.)
If you don't care about licensing why is it so difficult to comply with the source you forked? You made a derivative work, you have to give credit. It's not just the right thing to do, you have a legal obligation to do it. Number of commits and performance doesn't matter when your crate isn't legally sound. I can't add it as a dependency if I can't trust that it won't be taken down tomorrow because the author is violating copyright. 
I love the safety it teaches by enforcing it via the compiler. I feel that I'll write safer code in other languages just by learning Rust.
There's something very zeerust about a Rust wrapper around FORTRAN code. Software is weird.
Also, if you haven't already read it, you might want to look at [Learning Rust With Entirely Too Many Linked Lists](https://github.com/rust-unofficial/too-many-lists). (The pre-rendered version is down, so here it is [on the Wayback Machine](https://web.archive.org/web/20190215140704/http://cglab.ca/%7Eabeinges/blah/too-many-lists/book/).) It covers a lot of theory which is relevant to designing and implementing complex data structures of *any* type in Rust.
I'm a university student who wants to write a nice scheduler one day!
Impl Stream == async
Would recommend using a sobol sequence if you want faster convergence over a naive random number generation 
I am not sure that re-introducing the license is sufficient to make a derivative of an illegal derivative legal again...
I do get the frustration, but calling the tool a piece of shit definitely won‚Äôt help.
Wrong question: What you want to be asking is "what should I choose, borrow or own?"
I appreciate the sentiment, but you could just make a PR to yarte that fixes the license?
As the nearly daily email warnings I get for vulnerabilities in different applications I get tell me, memory management is hard. I really like Rust for having amazing speed with a good memory management system. I also really respect Rust's design team for not being afraid to change things if they see the language is going the wrong path. I just started slowly picking up Rust but I'm really enjoying it so far. 
People tried that, the developer of yarte is exceedingly hostile to the idea.
Awesome, thanks so much u/engid and u/Holy_City for very helpful replies! &lt;3 There's a lot to digest here - I'll have to watch the video first and give all this some thought, so pardon me for not being of much use at this moment! :) That said, I encourage you to try out Crossbeam's queues I linked in the previous comment. Both `ArrayQueue` and `SegQueue` are MPMC, which of course means we do some additional synchronization over SPSC queues. But the overhead should be relatively small and I don't expect it to matter for audio processing - after all, you probably care more about reliable latency than high throughput. I'm familiar with Boost's queues and can say the following: * `ArrayQueue` is like `boost::lockfree::spsc_queue`, except it is MPMC. It is not strictly speaking lock-free - there is a chance that an incomplete push operation (if preempted at an unfortunate moment) will block a pop operation. * `SegQueue` is like `boost::lockfree::queue`, except it can dynamically free memory as elements get popped. Boost's queue only frees memory once the whole queue gets destroyed. `SegQueue` is also not strictly speaking lock-free because since there is a small chance an operation will block another if preempted at an unfortunate moment. But don't be scared away because Crossbeam's queues are not *really* lock-free - the chances for blocking are exceedingly small and should not blow the latency up. I did some unscientific benchmarks not long ago to measure tail latencies, compared the results to lock-free queues, and couldn't find anything worrisome. I'd also say the possibility of malloc/free waiting on a lock is a higher concern anyway. Just one more thing I forgot to ask: what guarantees do you need on tail latencies? What's the maximum allowed delay (in milliseconds) between the moment audio is generated and the moment it is emitted on the speaker? And what happens if the audio thread gets preempted by the OS - is that even a concern and if so, are there any remedies? 
that's one way of looking at it i guess.. 
Interesting move, at least! What I would really love is for someone to contribute a handlebars syntax frontend (and maybe some codegen bits as needed) to Askama, which I think would provide a more robust, maintainable base for the future. Askama already has configurable syntax and could take cues from the .hbs extension to enable that automatically, so I think it could fit in well. (It would not be as fast right now, but much faster than handlebars, and we can probably make the same optimizations in Askama that yarte/wearte have.)
Hey from a neighbor in Quebec city, right now I'm so deeply engulfed by snow that my heart is becoming as cold as ice. I think the only that that could warm me up would be a to read a nice Rust book. Cheers.
I‚Äôm currently taking a couple college courses that make use of C. We‚Äôre always given ambiguous warnings of ‚Äúdon‚Äôt do anything unsafe!‚Äù, but are never really told where to start, other than writing lots &amp; lots of test cases. Rust makes that aphorism concrete. I can‚Äôt wait for the day when Rust courses are commonplace at universities like mine!
That would be the ideal solution yes! This was a quick fix mostly just to have fun and resolve the licensing issues :P
Is this the Rust Service Club for the rich and powerful?
I've actually been using them here and there and haven't had any troubles yet! But that said, I have only worked on trivial projects in Rust, and a lot of the headaches pop up when you have multiple things mutating state from different threads, creating a ton of contention. I'd also add that being wait free is just as crucial as being lock free, so there needs to be zero alloc/free on the audio thread. That's a big reason why bounded FIFOs are popular. &gt;What's the maximum allowed delay (in milliseconds) between the moment audio is generated and the moment it is emitted on the speaker? It depends on the driver settings. Worst case scenario is about 1.3ms (and that's somewhat insane). Best case is ~42ms. But keep in mind that any audio code gets just a fraction of that time to work, a big chunk of it is going between user space/kernel space. &gt;And what happens if the audio thread gets preempted by the OS There's a rather messy jumble of callbacks for this kind of thing, and it depends on the drivers and driver abstractions. It's not a big deal on MacOS, where CoreAudio handles a ton of low level stuff opaquely, and it's the only driver API you care about. On Windows it's a bit of a disaster, since you have ASIO (which I don't think even _can_ be preempted by the OS), WASAPI, and DirectSound drivers. On Linux you've got ALSA, JACK, and Pulse. You'd have to check each driver API to see how they handle things. 
How?
Any attacker-controlled data at all, including anything you might do an FTS query on?
Okay... So why?
Nice
Taught myself python to switch careers in software engineering, but I started to see the cost of using a higher level language, and in my search for a lower level lang, Reddit pointed me to rust. Been learning it for about a month now and I‚Äôm loving it!
I don't think 1.3ms is insane, I think it's perfectly reasonable to target it. I think Rust is one of the few languages that can possibly achieve high performance audio. For serious pro applications, it's possible to compile a Linux kernel with preemptive real-time scheduling, but I think even with soft real time threads it should be possible to reliably achieve latencies in this range. So for my own work I've basically set a hard requirement of no allocations or deallocations in the real time thread. This precludes most off-the-shelf solutions, but at the same time I think is a useful organizing principle. A good strategy is for the real time thread to do as little as possible other than computing audio samples. Also as a philosophical principle, for audio really low probabilities of tail latency are the worst you can possibly do, because it creates a motivation to ignore occasional glitches and hike up the overall pipeline latency until the glitch rate becomes "acceptable." Measurement methodology (and ideally all performance work is driven by measurement) should be firmly fixated on the worst case. I have designs for a combination of `Arc&lt;&gt;` and an unbounded lock-free queue. Unfortunately I don't know when I'll get time to implement that (I'm on the cusp of taking on a different hugely ambitious project), but am very happy to discuss.
I am working on multiple projects in Audio in Rust. And I know RustAudio group wanted to contribute but haven't had time to get involved into that. Just please let me know how I can contribute so we can carry on together.
Nice to see a fellow Canadian around here, saying hey from Toronto here. I'm a lurker and a beginner programmer that was drawn in by all the things rust preaches and it's great community. I see a lot of potential in rust and hope to master it one day.
Another great resource is Ross Bencina's writings, of which the most accessible is the blog post entitled [Real-time audio programming 101: time waits for nothing](http://www.rossbencina.com/code/real-time-audio-programming-101-time-waits-for-nothing). He also has a chapter in the SuperCollider book and there are other excellent writings.
I am really looking forward to reading and following this! 
Thanks for the offer, vertexclique! I'm not sure what the next move will be in terms of organization, but in the mean time feel free to jump in the message boards I mentioned \[here\]([https://www.reddit.com/r/rust/comments/aua2tb/rust\_2019\_rust\_audio/eh6pu5f](https://www.reddit.com/r/rust/comments/aua2tb/rust_2019_rust_audio/eh6pu5f)). 
My 2 cents. The industry tends to adopt new technologies slowly, and adopting a new language is an uphill battle. I don't think it's worth it to replace C/C++ in existing technologies like VSTs, other than doing it for personal projects. Plugin products can be maintained for a decade, and stability in the language/ecosystem is as important as speed. At the end of the day, plugin development is just a tiny slice of the professional audio industry, let alone audio as a whole. That said, plugins are an excellent prototyping platform for any audio system, so having a good plugin story in Rust is essential towards moving forward with audio systems using Rust in production. I do think Rust is very well poised to make a splash in audio software, and here are some areas I think should be on the roadmap. ## Interactive and Immersive Audio (AR/VR/XR, 360 video, etc) This is the single biggest gap for pro-audio software today. The software to create immersive/interactive content is either nonexistent or expensive and closed source. There is open demand and investment for these technologies, and I think it would be prudent to consider how Rust can solve some of the unique challenges to these tools. ## Audio over IP (AoIP) [Dante](https://en.wikipedia.org/wiki/Dante_(networking\)) and other AoIP/networking technologies have seen massive adoption across the entire industry. However, these systems are a little closed off. It would be excellent to develop crates to support AoIP and extend Rust's networking ecosystem to support it. ## Multimedia in the Cloud Similar to AoIP, but without the issues of real time streaming. Many professional shops are moving towards project management solutions similar to cloud hosted git registries, but for media assets and projects. There are a number of systems out there that do it, but like immersive content, they tend to be closed and expensive. ## Embedded Solutions C and C++98 are the kings of embedded audio signal processing, and it _sucks_. Being able to translate code written in a plugin to code running on hardware would be a dream. Furthermore, there is a rather high barrier to entry for hobbyists who want to develop digital audio effects on hardware like guitar pedals, and imho, C is a big reason for that. I think we can do things in Rust to make writing audio code friendlier and support their use cases. 
The pattern you seem to be implementing is "use existing value, or insert this if there is none" It means your code could be written something like this if *v &gt; new_val { self.left.get_or_insert_with(Tree::new).insert(new_val) } else if *v &lt; new_val { self.right.get_or_insert_with(Tree::new).insert(new_val) } where Tree::new is fn new() -&gt; Box&lt;Tree&lt;T&gt;&gt; { Tree { val: None, left: None, right: None, } .into() } There way you wrote it is absolutely fine, and it's likely to compile to the same or similar code, but the method "get_or_insert_with" quickly conveys the intent to someone reading it. (Or I completely misunderstood your code :) Good luck with your course!
Reliability is critical though. Not crashing the host application is paramount.
Great read, looking forward for more. A small mistake I found. In the bubble sort example you are saying ‚ÄûWe can use move semantics!‚Äú but it‚Äòs not the move semantics you are using in your example. It‚Äòs a copy because i32 is a copy type. Maybe it‚Äòs useful to point this out.
Is there a way to make a macro which will do something like this: \`let a = \[1,2,3,fill\_in!(true),10\];\` where \`fill\_in!\` will return \`4,5\` if true, and \`5,6,7\` if false, so \`a\` would be equal to \`\[1,2,3,4,5,10\];\` if true, and \`\[1,2,3,5,6,7,10\];\` if false?
Oh now i see where you wanted me to use that. Makes a lot of sense. I am getting the node if its there, otherwise im creating it and then calling its insert function. Both are doing the same thing, yours is just cleaner.
So, even after match ergonomics landed, you still have to use `ref` manually in some esoteric situations? This, combined with how much trouble match ergonomics caused, makes me think it was a really bad idea that should be probably reverted in a future Rust edition.
Thank you, stjepang! I appreciate your willingness to help very much! 
I'm just a beginner looking for a lot of knowledge also started diving into game engine development on c++ and it would be epic to learn Rust and try to use it instead. I only hear good things about it:)
Giveaway?
Yup! See [https://www.reddit.com/r/rust/comments/au8a9z/giveaway\_the\_rust\_programming\_language\_by\_steve/eh69rw4/](https://www.reddit.com/r/rust/comments/au8a9z/giveaway_the_rust_programming_language_by_steve/eh69rw4/) for details.
Thanks! It's actually correct: even though i32 is a Copy type, Vec&lt;i32&gt; does not implement Copy!
&gt; I'd also add that being wait free is just as crucial as being lock free, so there needs to be zero alloc/free on the audio thread. We could implement a bounded wait-free SPSC queue pretty easily, in fact. Push operations that overwrite when the queue is full are a bit tricky to get right, but should be doable too. Regarding unbounded queues, they unfortunately have to allocate - I don't see a way around that. We could minimize interaction with the allocator by allocating big chunks of memory and/or never freeing it, though. By the way, if there are any queue implementations besides Boost's that are useful in audio processing, let me know! &gt; There's a rather messy jumble of callbacks for this kind of thing, and it depends on the drivers and driver abstractions. Oh, that makes a lot of sense now, thanks! Also really interesting, will have to read more about audio drivers...
Add `min_row` and `min_col` to respective values and call it a day. 
Hi! I maintain the ALSA bindings for Rust, i e, the main interface for communicating with audio hardware in Linux.
Oh jeez, that‚Äôs so obvious. I‚Äôll go with that. Thanks for pointing it out!
They do have to allocate, but not on the real time thread. My designs are asymmetrical in this regard. One of the best sources is my talk, linked from synthesize.rs.
In another thread, I floated the idea of having a working group to float ideas about dataframe implementation. Finally got together a repo for discussion, if you‚Äôre interested. https://github.com/rust-dataframe/discussion
Good luck with the borrow checker. I'm not saying it's bad, but you'll probably need some time to get used to it. 
That‚Äôs part of the discussion, I think. Finally got a repo up to start talking, please join in! https://github.com/rust-dataframe/discussion
Finally got a repo up, please come and discuss your ideas! https://github.com/rust-dataframe/discussion
Howdy diwic! Thank you for your work!
How is the 4 made with rust? I think what you describe is similar to what is described in [https://www.cs.purdue.edu/homes/rompf/papers/tahboub-sigmod18.pdf](https://www.cs.purdue.edu/homes/rompf/papers/tahboub-sigmod18.pdf) (than, by te way, I as exploring how emulate) but after some try with callbacks I return to use the more idiomatic rust idioms of iterators and such.
Re the latency, I've seen buffer underruns with a single biquad at that point (64 samples @ 96kHz). But it will take a bit of profiling to figure out the absolute boundaries. 
&gt; I have designs for a combination of `Arc&lt;&gt;` and an unbounded lock-free queue. Unfortunately I don't know when I'll get time to implement that (I'm on the cusp of taking on a different hugely ambitious project), but am very happy to discuss. Do tell, I'd love to hear more! So I suppose we want an unbounded lock-free MPMC that only does malloc/free on the producer side? We should be able to achieve that by taking a Michael-Scott queue and storing unused nodes (to be reused or freed) on a Treiber stack. We basically have all the code for this, just need to put it together. :)
I'd really like to have a look at that paper. Sounds interesting!
Ill fetch it for you. One sec.
Macros by exampel have to be expanded to a complete grammar item, so partial array lists (like in your example) are invalid macro output. You can, however, wrap the complete array declaration into a macro and fill in your desired parts: macro_rules! fill_in { ($($first:expr,)* @(true) $(,$last:expr)*) =&gt; { [$($first,)* 4, 5, $($last,)* ] }; ($($first:expr,)* @(false) $(,$last:expr)*) =&gt; { [$($first,)* 5, 6, 7, $($last,)* ] } } This would expand `fill_in![1, 2, 3, @(true), 10]` to `[1, 2, 3, 4, 5, 6, 7, 10]`. You might want a third pattern that accepts a simple array declaration without an @.
 * Bounded, operations fail if queue is full. * If the queue is about samples, we need a way to pop more than one sample at a time, since one atomic op per sample would be a waste of time. If it's more control instructions, then popping one at a time might be okay. * And having a 100% lock free version is important. Especially if your target is bare metal or an RTOS where you can't blame the OS for not scheduling your thread. 
[https://repository.tudelft.nl/islandora/object/uuid:c4e95618-390d-4210-a76f-ce23640a194d/datastream/OBJ/download](https://repository.tudelft.nl/islandora/object/uuid:c4e95618-390d-4210-a76f-ce23640a194d/datastream/OBJ/download) &amp;#x200B; here you go!
I found an existing bug report.
With your config and no racer in path, I get `No completion found`. But you say it works, so I'll try to debug company.el I guess.
If is KV, then I assume you don't need to depend on order, so you could, in theory, split for each N in a separated thread (ie: perfect partition?). &amp;#x200B; So, I would split the KV in N buckets. The trick is how communicate with fast timings and lock-less. I think maybe a ring is the solution here: &amp;#x200B; [https://www.infoq.com/presentations/LMAX](https://www.infoq.com/presentations/LMAX) [https://martinfowler.com/articles/lmax.html](https://martinfowler.com/articles/lmax.html) &amp;#x200B; With the ring I could communicate without much locking and have N readers and N writers.
In case you‚Äôre not in the other thread on forming a dataframe workgroup, I‚Äôve set up a repo for initial discussion. https://github.com/rust-dataframe/discussion
I love learning Rust because it avoids so many problems, and even though it‚Äôs complex good docs make it all worth it.
Maybe you haven't run across SolveSpace. It's a nice OSS parametric CAD that was originally written by one person. I've poked around the code looking to add features, but part of what stops me is that it's C++. Sometimes I think about writing something like it in Rust, but I'm not up to speed on Rust yet - still learning. Happy to work with anyone interested in this.
The [AbstractFifo](https://github.com/WeAreROLI/JUCE/blob/dc1cf29cae85992f282af5d6519ccdaf73b7f6af/modules/juce_core/containers/juce_AbstractFifo.h) class from JUCE just contains some of the logic for buffered push/pop to a ring buffer. On the topic of unbounded queues, the allocation can happen anywhere but the audio thread. So the trick is to have a producer/consumer where either the producer or consumer is responsible for allocations and frees. But it's tricky. 
I'm a Python and JS Dev but always wanted to learn a lower level language but lost motivation because of the learning curve and the community aspect was never really there. Rust, besides being a fun language to work with, has a fantastic, positive community. Also cargo is awesome. 
If you're wanting to use the ndarray crate there's ndarray-linalg crate which should do what you'd like as well for eigenvectors.
With your config and company-lsp, I get `No completion found`. With eglot I get `Company: backend company-capf error "Symbol‚Äôs function definition is void: nil" with args (candidates )`.
New to rust myself, but a big part of what I love about it is how easy it is to integrate with existing environments. It's surprisingly easy to link to some existing .so but build out the new stuff in rust. Makes it so much better for migrating an old project, since you don't need to move literally everything to rust before you can launch. 
I'm learning Rust because after I want to write a real-time interactive version of a music generator I'm writing in Python, and Rust is nice and fast and clean and stable.
For an MIT-licensed project, it probably is. I am not a lawyer, but I have studied open-source copyright pretty extensively. The Askama code can be used under the terms of the MIT license; the yarte code can be used under the terms of the MIT license; this code follows the terms of the license in both cases as far as I can tell. In any case, unless one of the original authors objects it is *de facto* fine. That said, I personally wouldn't touch yarte or anything derived from it with a ten-foot pole at this point, given the author's attitude toward the law. (Who knows what else has yet to be uncovered in there, or what might be in the future?)
This is great. I'm an image processing and machine learning engineer looking to branch out into Rust, but before now I didn't know the best place for getting started. 
Hi there, really awesome of you to giveaway the book! I'm currently learning rust mainly for a audio related personal project and I like it a lot so far! I live in Montreal too so shipping shouldn't be much of an issue.
Legend, thank you
&gt; Don't create a public dependency `log` is an interesting case, but isn't it already a public dependency by a strict interpretation? None of `log`'s types are public in a library's API, but consumers definitely observe the library's use of `log` via the global logger. If it doesn't unify between versions, then we've got an observable breaking change in the form of lost logs (though it'll still compile, which makes this problem _worse_).
Yes a Vec does not implement Copy, but the the assign value does and this is what matters here I think. You can't simply move a non-copy type out of Vec (without Option for example), because it would leave the original uninitialized. Look [here](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=44a366b40f1855082e8d31700493347d) what happens when you replace i32 by something that does not implement Copy. So it must be a copy in your example.
No
I'm a scientist (molecular biology, genetics, etc) who is interested in developing tools for genomics research that can be distributed peer-to-peer. At the moment, many of our tools require somebody (most often a PhD student or post-doc) to babysit a box to serve applications and data. If we can move some of the visualisation and collaboration tools to wasm running in the browser, it can reduce sysadmin overheads and free up that time for research. My first project will be a genome browser. I've had a poke around rust (github.com/robsyme/rustalind) , but am keen to know more. I'm also in Montreal (Outremont), so I can just pick it up and save you the trouble of posting! I'm keen to chat with anyone in MTL writing rust, so book's fate notwithstanding, would love to get a coffee and hear about your experience with the language.
Since /u/dochtman is here on the thread, one might as well ask him: is he okay with wearte?
May I ask how you use piston and whether there are things that you wish could be easier?
&gt; If it doesn't unify between versions, then we've got an observable breaking change in the form of lost logs (though it'll still compile, which makes this problem worse). Wow, this is insane. It's grounds to implement do the trick to make all log versions use the same global logger, by introducing a dependency on another, forever-1.0 crate (just like rayon guarantees that all versions will use the same thread pool, or like a C library will be linked only once) Also: this trick should be better documented. I've only heard about it on folklore shared on Github issues and Reddit.
I'm a university student looking to expand my skill set by learning new technologies. Learning Rust has also improved the quality of code that I write in other languages by making me think about the flow of data in ny software.
I am not a lawyer, but I don't see how it wouldn't :)
Incremental checks take 15-30s usually. It may not seem like a lot, but when you are relying on it to tell you any problems that might arise each time you chnage something, it can sometimes slow down development.
That's a fair point! What I really mean there is don't introduce a widely scoped public API that makes breaking changes much harder to manage without a lot of intervention from consumers.
Thought I'd lend a hand and grab those links. General stuff about the talk: [https://synthesize.rs/nov-2018-talk/](https://synthesize.rs/nov-2018-talk/) &amp;#x200B; Highlights from the talk: \- [Realtime Threading](https://youtu.be/-F7whGjquHI?t=3496) \- [Architecture for the sythesizer](https://youtu.be/-F7whGjquHI?t=4020) \- [Treiber Stack](https://youtu.be/-F7whGjquHI?t=4226) &amp;#x200B; Here is the current public code for the [Synthesizer's Treiber stack](https://github.com/raphlinus/synthesizer-io/blob/master/synthesizer-io-core/src/queue.rs). 
I'm with you, I'm trying to reduce the compile times of my C++ game project down below 10s. I'm used to Python where startup is basically instant, or JS with Hot Reloading and you save the file and the page updates inplace (state, and all). 25k is big (but not millions) and already slowing down that much is scary.
Different people have different needs, I use one because it fits an my desk better than a full size. I don't really understand why somebody would use anything smaller than a HHKB though.
I can't really talk about the specific details of what the software does. It is specialized CAD software for the electrical contracting industry that vertically integrates a lot of the design and manufacturing process. It *is* a huge scope for a single developer, but my bosses understand that I am only one person, and they seem happy with the incremental versions I provide. We currently only use it internally, but the goal is for it to eventually see external use. Despite the sizable undertaking, I really value the ability to drive the vast majority of the technical design myself, so I get to use Rust.
I've been meaning to order a copy. I've been learning rust as a way of understanding the downsides of languages like C.
Here are some notes here about Raph's [treiber stack](https://www.reddit.com/r/rust/comments/aua2tb/rust_2019_rust_audio/eh7he7q) that I posted below in case that helps. There's a link to source code in there too..
While my original background was in compiled languages, all the way up to C/C++ in college, I landed my first real job as a PHP developer. While I've since moved on to Python (with a dabble of Bash, PowerShell, PHP, and even *shudder* Ruby and Perl), I've had the itch to return to strongly typed compiled languages for years. A few years back I started up a roguelike game in C++, but got frustrated and ported that back to Python before abandoning it. I'd heard of -- and ignored -- Rust for years of course, but it wasn't until a friend suggested I look into it for a chat server project I was thinking of starting up that I finally gave it a serious look. The treatment of memory safety is the biggest draw for me into the language, although strange as it may sound I'm also a HUGE fan of the concept of returning a `Result` enum instead of throwing an exception, even though for the last several years I've been immersed in that Pythonism so much it's now second nature to me. Now I'm looking forward to starting a new roguelike game using Rust, and to the day when I can sit down with my son and program AVR microcontrollers with it!
I do not use a GUI library. All graphics and windowing are implemented using piston. While this is not ideal, as I do have to write a lot of gui code from scratch (menus, forms, user-prompts, etc), I also have 100% complete control over the way the gui works. I know that there a good number of people who don't like piston, but when I considered the alternatives, nothing gave me the amount of freedom that it does with the same higher-level abstractions.
I've heard you can bring that down by splitting your program into separate modules, so chunks of the code don't need to be 'rechecked' when you check.
Datas doesnt need to be really accurate too in that case, even if some are "dropped" or altered, it's fine.
I've thought about that a lot, but the majority of the modules in my main crate are very interdependent, so separating them is a non-trivial task. I would like to split some things up, but I'm just not sure of which separations across which lines would yield compilation improvements substantial enough to be worth the effort of the separation itself.
Thanks!
What keyboard is that?
I was playing around with Rayon, and made two functions that calculate the sum of a vector's contents, one is serial and just uses an iterator, the other uses a par_iter and the sum() method. According to Criterion, the parallel version runs 40 times slower than the serial version. I have a 12 core machine, and Htop shows they are indeed running in serial/parallel accordingly (my computer is SCREAMING when the parallel one runs). When I made the math for each iteration a little more complicated they got closer, but the serial version was always faster. Making the vector outrageously long (1 million elements) didn't close the gap much. Is this an LLVM magic thing, or is there something that makes this unsuited to parallel processing? pub fn sum_par() -&gt; u64 { let mut v : Vec&lt;u64&gt; = Vec::with_capacity(1000); for i in 0..1000 { v.push(i) } v.par_iter().sum() } pub fn sum_serial() -&gt; u64 { let mut v : Vec&lt;u64&gt; = Vec::with_capacity(1000); for i in 0..1000 { v.push(i) } v.iter().sum() }
Usecase that I can't say completely as I'm tied up with a NDA but it's like this: Users post millions of data on the webserver, webserver forward all those queries at this specific "second or time" and need to be then inserted in a DB. Another process is then reading all of them, filter them, do some computation and send it back to another server (delay doesn't matter here anymore), but the filtering need to be done at a precise time.
You guys should check out [audiokit](https://github.com/AudioKit/AudioKit/). Even though it's for apple platforms, the core algorithms are written in c and c++ and are then wrapped in objective c and swift. The core is relatively portable and it could really benefit from simd. 
Here comes the final boss: The Borrow Checker. Na, seriously. I'm glad to see your history has a happy ending. Please accept my online hug. I'm curious about what made you think that systems programming and game development were beyond your ken. I'm pretty sure I'm not a smart guy, but those two topics where the reason I started programming. Good luck! Play Mario kart 50cc n64 version
VSCode + RLS + TabNine
I have a data structure which is effectively: let v = vec![[1_u8, 2_u8], [3_u8, 4_u8]]; I want to "flatten" this into a single array of u8, i.e. [1_u8, 2_u8, 3_u8, 4_u8] such that I can write it to a file. I tried: let data = v.iter().flat_map(|e| e); file.write(&amp;data)); but I'm stuck on how to transform the vector into an array of u8 or whatever will work to be able to write the data to file. Thanks for any help.
When I first started the project, piston was lacking a few niche features that I needed, so I submitted PRs to add them, which I was happy to see were merged in less than a day. Probably the most substantial thing I have made to support the program's functionality (that the community might also find useful) is my [graphics\_buffer](https://github.com/kaikalii/graphics_buffer) crate, which lets you use piston's graphics api to render to a savable image buffer. Currently, my software uses this to do image exports of what the user sees on the screen.
HHKB Type-S
\*\* adds "Listen to New Rustacean episode to tomorrow's Todo List \*\*
Trying to learn Rust because, as someone who's still new to programming, having a language teach me good practices from the get-go would be a great way to start. Hopefully I could eventually program a game, or maybe even a game engine sometime in the future. 
A nice AOIP library would be great! Also options to control VBR/CBR would be very useful in implementing encrypted communications, as VBR leaks information.
very cool :)
It's a lost cause, yarte's author not only doesn't seem to understand anything about how licenses work and what a derivative work is, but is also going [out](https://github.com/rust-iendo/yarte/issues/5#issuecomment-466690302) [of](https://github.com/rust-iendo/yarte/issues/5#issuecomment-466724161) [his](https://github.com/rust-iendo/yarte/issues/5#issuecomment-466792074) [way](https://github.com/rust-iendo/yarte/issues/14#issuecomment-466711674) to be an ass to anyone who tries to explain it to him (and kudos to those people, my patience would have worn thin much faster than theirs). So, it's a shame, but honestly, why bother ?
Yes, that's the bones of it. I think it really only needs to be MPSC, which I think has the potential to simplify things quite a bit. There's a [basic version](https://github.com/raphlinus/synthesizer-io/blob/master/synthesizer-io-core/src/queue.rs) already in synthesize.rs, but it doesn't do any of the reference counting stuff I'm thinking about. That idea is probably too complicated to fit into the margin, but I'll tease it. A major architectural feature of these modular synthesis engines is to do a topological sort of a graph and then run the modules in order (so that all inputs are the outputs of previously computed modules). Right now, the synthesize.rs code does the topo sort on the real time thread after any graph mutation requests have come in on the lock-free channel. This works ok and has simple ownership (the real time thread owns the graph outright), but there are downsides, not least of which is the overhead of doing the topo sort eating into the time budget for synthesis. A more aggressive architecture (discussed with /u/wrl_t and /u/Holy_City) is for the engine (not the real time thread) to do the topological sort, and then atomically swap that out. The real time thread then just does an atomic load of the current schedule and runs that. This architecture requires reference counting (for example, if the RT thread is running a schedule when the engine swaps it out, you want to defer the actual drop of the nodes until the RT thread is done with it. There are also *interesting* ownership patterns, as you want the RT thread to have exclusive mutable access to the state inside the nodes, even as the engine holds references to those nodes as it does the topo sort to create the schedule. But I think I see a way to make it all work. I'll see if I can write something up, and maybe do a little prototyping, at least of the types.
implication was that that's the wrong way if looking at it. Believe it was just a tongue in cheek comment, making a joke of the fact that rust zealotry was explicitly mentioned by OP, so "detecting" it is humorous. Until you explain it, then its not funny at all.
The tie in with the rust audio folks would be that AoIP usually needs algorithms like Voice Activity Detection, Acoustic Echo Cancellation, compressors, EQ, etc. Stuff that should definitely be tested as a plugin. 
This seems to ke a popular reason, but gamedev is the one for me too. C++ needs a hard reset, and I think that is rust.
Thing about mental illness, parts of it cling like glitter. Just never figured I was up to it. Like I couldn't figure it out. But like I also said, if I could figure a way to crawl out the hole, I can figure out a damn machine. Hugs and support not only accepted, but welcome. Thank you.
It introduces a new entity to the language "keyword attribute" or "postfix keyword", which is arguably noticeably worse than introduction of a new sigil. As a consequence it will make code more confusing to understand.
if you have to ask..
Use Python daily and think Rust would be a perfect transition into embedded programming
*Hey just noticed..* It's your **4th Cakeday** tl8roy! ^(hug)
I see you use circle ci. I've considered switching over from Travis, but it seems more complicated to get a basic setup going. How do you like it? 
You could also use `zip(min_row..)` and `zip(min_col..)` instead of `enumerate`. 
if i am using a crate, does it drill down into the crate to offer suggestions on names in the crate?
I‚Äôm learning rust because I am a highschool student and I believe it will become more widely adopted in the future. I want a job as a programmer and I believe this will help me achieve that.
I'm legitimately one of those people that really gain some sanity with quality-of-life improvements with syntax like that, so...yes, I did. :P
`data` currently contains an iterator that will produce your desired data, but not the data itself. Write only accepts &amp;[u8], so you will need to collect your values into something that stores all values contiguously, such as a Vec. In general you do that by `.collect()`-ing an iterator: let data: Vec&lt;u8&gt; = v.iter().flat_map(|e| e).cloned().collect(); &amp;u8 is a Copy type, so that `.cloned()` shouldn't incur any performance overhead.
I am using imgui which provides pretty much all the primitives and widgets that you would expect. It works with all the graphics crates. I am using it with rendy right now.
I'm learning Rust to supplant the de-facto systems language, C, that I learn in school. Hopefully by next year it'll be running my UAV Team's aircraft! 
Been monitoring Rust for a few years. Time to stop dabbling and learn it properly.
I am constantly unsure how to mix two different `Result`s in the same function. Suppose I have a function that reads a file and then parses its contents into a number. fn func(filename:&amp;str) -&gt; std::io::Result&lt;()&gt; { let mut f = File::open(filename)?; // returns io::Result let mut contents = String::new(); f.read_to_string(&amp;mut contents)?; let i:i32 = contents.parse()?; // returns Result&lt;i32, ... &gt; Ok(()) } Suppose I call this function in a loop and do some kind of generic error handling if a given call fails (such as write a log message or something). Defining a custom `Result`-like type and carefully mapping every type of `Result` into my own one sounds difficult.
I am reading a TOML file for global configuration settings for my crate, but I just want to read it into memory right when it starts and then just make references to it available to everything else, including modules. The only way I know of is passing `&amp;config` to every function I call, which seems messy. Is there any way for me to read it once and cleanly let anything else access it without having to keep passing it to every function as an argument?
I want to learn Rust to experiment with my raspberry pi
Learning rust to become a better programmer 
Why doesn't [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=846eda9dfb66756689377b0cd8153383) work? Since the references in `values` are valid forever, you be able to append them to a vector expecting a lesser lifetime, right?
This is already handled in most hosts by sandboxing plugins in separate processes. It is not what you would call efficient or low latency though. 
Also the ownership section of the book covers mutable references: https://doc.rust-lang.org/book/ch04-02-references-and-borrowing.html
I used to write a lot of D, but rust safety features and code quality made me realize it's a superior language for the long run. Long term I'd like to use Rust with AWS Lambda and step functions to automate my work.
FORTRAN is the Keith Richards of programming languages. 
Apparently the PSD file-format documentation is publicly available now? That's a nice change from [the old Xee rant](https://www.jwz.org/blog/2012/11/psd/).
As of a week ago I'll using CircleCI for my open source work from now on (used to use Travis) - \[spurred by this issue\]([https://github.com/chinedufn/percy/issues/78#issuecomment-464394897](https://github.com/chinedufn/percy/issues/78#issuecomment-464394897)) &amp;#x200B; It hasn't felt any more complicated to me, but you're talking to someone that usually stops at "it works" when it comes to CI and hasn't spent much time learning the ins and outs (someday.. whenever I need to!). &amp;#x200B; One thing that felt painful in my config file was some of the repetitiveness - but this is completely due to me not yet spending the time to learn how to split out the re-usable bits into something that I can call throughout the file. &amp;#x200B; All in all though, it hasn't felt more complicated in any way to me and would totally recommend for the speed gains alone! I had a few times today where I clicked into the logs just to be certain that my green build actually ran because it finished so fast. &amp;#x200B; (YMMV though as I am no CI guru)
I have a love/hate relationship with C. When it works, it's beautiful. But it has its warts. I'm learning Rust to see if I can use a "better C" for certain applications. I'm also learning Rust to improve my FP skills. I'm using Rust right now to begin a little side-business project.
This was already submitted some time ago: https://www.reddit.com/r/rust/comments/a9zx7g/thoughts_on_rust_in_2019/ 
I'm checking it out now. Do you have to use it with either GitHub or Bitbucket?
r/lostredditors
In this situation, just return an Error trait object: fn func(filename:&amp;str) -&gt; Result&lt;i32, Box&lt;dyn Error&gt;&gt; { let contents = fs::read_to_string(filename)?; Ok(contents.parse()?) }
I am looking for a developer with Windows expertise (UWP expertise preferred) interested in a short-term contract to add two new Rust targets for arm64 Windows and atom64 Windows and appropriate standard library support; please contact me if that sounds interesting!
[Here's](https://gist.github.com/bschwind/cb11c4c46710732b034ddcd99f3ab0d8) a sample Circle CI config for a Rust webserver, modified from one of my projects. It runs the build on every commit for any branch, and only runs the deploy step on commits to master. You can throw in test jobs or builds for other platforms as separate jobs and define their dependencies. With caching and workspace sharing, my actix-web-based server builds and deploys in around 1 minute. Let me know if you have any questions!
@musicmatze I hope you enjoyed your sabbatical. We are all looking forward to working with you on some new ideas!
Ah gotcha
This is a good use case for [lazy_static](https://github.com/rust-lang-nursery/lazy-static.rs).
&gt;yadm Interesting, I use some primitive technology--cp, gotta try it.
I believe this problem arises from the fact that `&amp;mut T` is invariant over `T`. This means that you can't cast from `&amp;mut T` to `&amp;mut U` even though you can cast from `T` to `U`. This special case may be fine, but allowing it in general leads to some soundness problems. I'm not 100% sure your function is legal, but if it is then you could probably do it with `mem::transmute`. However, you probably just want to do something different. I can't be entirely sure what you'd need without more context, but you can probably just change the `'static` to `'a` and then `values` can be cast to the right lifetime at the call site (which will likely happen automatically). [Here's a playground to help you see what's going on.](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=eba1a8ca4eacffd2855fb1c8753608fc)
Try r/playrust
I'm learning it for fun. I program professionally in dynamic, interpreted languages, and Rust makes me excited about "systems level" programming in a way I haven't felt since learning C years ago. I also just like to play with new (to me) languages and tools, and Rust seems like the sort of tool I won't regret knowing. Thanks for posting this and spreading the good word! ;)
There are situations where person writing code isn't the same that manages the website - any CMS for example.
Thanks, I keep my identity isolated too! Good point - I just felt that some other answers were too off the mark. Thanks again!
Match ergonomics was much more about getting rid of basically-useless `&amp;`s in the patterns of matches than getting rid of `ref` and `ref mut`. The latter are generally unavoidable: The most reasonable default behavior when matching against a wholly-owned object (eg, as above) is to move/destructure it according to the pattern it matches. If you want to change that default (eg getting a reference to the inner bits), then you have to say so, which means using ``ref``.
Learning Rust because I've heard a lot of great things about it and want to know enough to contribute to some OSS projects
This is really cool! I love the fact that there is a WASM demo, no unsafe stuff, and only one crate dependency: `failure`
As /u/JayDepp said, it's related to subtype variance. Your function is sound, but [it needs a bit of a trick](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0df98127e206016d01fcae77bf178da5) to convince the compiler. Rust can upcast `Vec&lt;&amp;'static T&gt;` to `Vec&lt;&amp;'a T&gt;` - it both makes intuitive sense and is allowed by the type system. It cannot upcast `&amp;'b mut Vec&lt;&amp;'static T&gt;` to `&amp;'b mut Vec&lt;&amp;'a T&gt;`. I think the simplest way to explain it is this: We know, thanks to the documentation, that `a.append(b);` empties out `b`. But the function signature allows `append` to take items from `a` and store them in `b`. If it did, then references would escape from lifetype `'a` to `'static`. By changing the code, I have promised that anything that escapes to `values_taken` will be freed at the end of your function. So it's sound no matter how `Vec::append` is modified (unless the signature were changed). The type system sees it this way: it needs the `&amp;mut` operator to produce a value of type `&amp;mut Vec&lt;&amp;'a i32&gt;`. It can't cast the lifetime after the borrow occurs. But the type of `values_taken` has to be inferred, and that gives the compiler some flexibility. [It actually requires that variable to have the type `Vec&lt;&amp;'a i32&gt;`](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=a1cc6e518cd090b6214e50d3a4877ce5) - which makes sense because, as I said, `Vec::append` could leave a reference hanging around in that variable. So the type conversion actually happens just outside the `mem::replace`. I start with a `Vec&lt;&amp;'static i32&gt;` but it gets upcast to `Vec&lt;&amp;'a i32&gt;` because that's what's needed according to type inference. Finally, this change should be inexpensive. `Vec::new` doesn't allocate any additional memory, it just creates a dummy value that points nowhere.
Holy crap, that is perfect! Thank you!
Is there a standard type which will wrap either an owned or borrowed type? For example, I can pass either a &amp;Vec&lt;u8&gt; or a &amp;\[u8\]? Is Cow what I'm looking for?
Good thing you play (presumably) better than you post... (crappily).
You've probably figured this out already, but just to confirm, yes, the `ref mut` means you're now pattern matching and borrowing the matched component mutably rather than moving the matched component out. Matching without `ref` invalidates the self reference for the obvious reason that you moved the internal structure out. Specifically, this is due to all references in (safe) Rust need to be valid at all times. `multiple_ok` is fine because you're reconstructing a new outer structure, so destructiveness of matching doesn't matter.
Yes, `Cow` is what you want here (specifically `Cow&lt;[u8]&gt;` here, but it works with any reference type that implements `ToOwned`.)
You can always try it and see what the error message is. In this case, it's something like "cannot move out of borrowed scope". A function that takes a non-`mut` reference, like `get_x` and `get_y` do, may not modify the parameter, and moving a `String` out of it is a modification.
I think the first 2 options you suggest are a pretty typical answer. The crate petgraph also looks promising. I *think* `Graph&lt;SceneNode, (), Undirected&gt;` (with SceneNode not having a children field) would do what you want. I don't have a lot of experience with it though.
I might not have the best story, but I'm a young french canadian developer who loves learning new technologies and in this case programming language. I would love to have that book to add a new language to my portfolio. Thanks for making this giveaway, I think we all really appreciate it.
Keep in mind that unsafe blocks don't turn off the borrow checker or the type system. I usually find the compiler still helps me a great deal even when I have to write unsafe code. That being said, most of these data structures can be implemented with vectors and indices similarly to how they would with pointers.
I've been learning Python for quite a bit of time, maybe about a year. I've consistently put in about an hour every day into learning Python and after mastering the basics and getting a grasp of some of the more advanced topics, I just feel bored. After that I dipped into web development. HTML was fun and all, but CSS was the equivalent to brainfuck for me. JS was cool, but I just don't see myself ever creating web apps and that was about the extent of that journey. (Also I'm a HS student and I didn't see myself freelancing) About two months ago I started to learn TensorFlow and Machine Learning. I still do put time into learning ML but it still doesn't really create any practical projects for me. I learned about Rust fairly recently and want to explore the machine learning ecosystem for Rust as well as dip into game development in my spare time. Thanks for doing the giveaway regardless of who wins.
I am learning Rust because I am new to programming and I saw it was voted most loved programming language on stack overflow 3 years in a row. I also love the mozilla team and am excited about all of the possibilities I can create with Rust on the Cardano project.
Thanks!
I use Python, but sometimes it's too slow, and c++ is much less elegant than rust 
For those also wondering, [tabnine.com](https://tabnine.com)
I'm a self-taught developer who started with Python and now does web dev. My formal background is that of a translator and linguist, and I found that learning computer languages brings me the same enjoyment as learning human languages. Though I can order appetizers and ask where the bathroom is in Java, C++, Kotlin, and other languages, JavaScript and Python are the only ones I really know well. Last year, I resolved to learn a new language and was drawn to Rust by the overwhelming enthusiasm around it. So far, it's been challenging but truly a great learning experience thanks to the online version of this book and (very many (seriously a lot)) of error messages with clear, explicit and helpful info.
I'm curious about https://docs.rs/lazy_static/1.2.0/lazy_static/#semantics It says it stores the value on the first dereference. However, from trying it out, it looks like it works when I just reference things normally like `&amp;CONFIG`. What am I missing?
Yes it works seamlessly.
The value is initialized on the first dereference, see: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=280915d783848ca8d1232c614cc4a023 The [`Deref`](https://doc.rust-lang.org/stable/std/ops/trait.Deref.html) trait allows custom behavior to implement the dereference operator `*` Note also that the dot operator automatically dereferences bindings as required. E.g: let x = vec![]; let y = &amp;x; let z = y.len(); // x is dereferenced
From the faq: &gt; What language is TabNine written in? &gt; TabNine is 14,000 lines of Rust. &gt; In recognition of the fact that TabNine could not exist without the Rust ecosystem, TabNine's paid features are always enabled when completing Rust code. Thanks!!
You could have used something like the map function for lua. maps function is available in most general purpose languages but lua lacks it. here you can find the fastest implementation - [Lua Map](https://uiv.me/blog/2019/02/25/lua-map/)
Looking at the assembly, it appears the Rayon parallel iter version inhibits vectorization (which makes sense because each integer is queued separately), and probably not pipelining very well either (the CPU is going back and forth between the math and the queue whereas the serial version is a very small, hot loop). That, and the queue overhead itself is likely far outstripping the actual cost of the work you're doing. You said yourself you saw the gap close a bit when you made the unit of work more complex.
I think you have the idea of moving out of scope down pretty well. You might want to read up on the [Drop](https://doc.rust-lang.org/std/ops/trait.Drop.html) trait to figure out what is happening behind the scenes. Basically, when a value exits its scope, drop() is called automatically which moves the value into itself, ending the lifetime of that value in your scope. &amp;#x200B; It's why you cant return &amp;T from a function that takes T and lets it drop, because dropping destroys the value that the borrow points to. &amp;#x200B; I rewrote some of your example to demonstrate some different behaviors with respect to references and drop [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=2670171a059ec27d5e363344dba5cf3d](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=2670171a059ec27d5e363344dba5cf3d)
I doubt rust will ever squeeze out C++, so long as microsoft keeps putting out operating systems, but rust will certainly grow to become the default choice for the utilitarian. 
This is a bitter subreddit fail üòÇ
Weirdly enough, it seems that Rustdoc doesn't render `Sized` bounds anymore. I was wondering if we were looking at the same method because I wasn't seeing it, but sure enough it's there when I go to the source. It actually *shouldn't* need `Sized`; because it takes a mutable reference, it's automatically object-safe. That bound is only necessary for the adapter methods that take `self` by-value because they're otherwise incompatible with trait objects. (You can still use adapters with an `Iterator` trait object because `&amp;mut dyn Iterator` is sized and implements `Iterator` so the adapters take the reference itself by-value.) It looks to be just an oversight, the following issue shows a prototype implementation by the same author as the stdlib version that took `self` by-value: https://github.com/rust-lang/rust/issues/45462 Please feel free to report this on Github, or I can do it for you if you prefer. Good catch!
I hate this game... every time I look for The programming language it always pops up in my search results.
Thanks for your reply! I cloned the Rust repo and tried removing the `Self: Sized` bound from `try_fold` (so not yet anywhere else), but then fn _assert_is_object_safe(_: &amp;dyn Iterator&lt;Item=()&gt;) {} fails with error[E0038]: the trait `iter::traits::iterator::Iterator` cannot be made into an object --&gt; src/libcore/iter/traits/iterator.rs:10:1 | 10 | fn _assert_is_object_safe(_: &amp;dyn Iterator&lt;Item=()&gt;) {} | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `iter::traits::iterator::Iterator` cannot be made into an object | = note: method `try_fold` has generic type parameters That's what made me think it has to do with object safety, despite the fact that `try_fold` takes a `&amp;mut self`.
I started programming by teaching myself C/C++. What a terrible decision that was. Later, I learned JS and found that programming doesn't always have to feel like a chore when I want to build something cool. I soon learned C# and then Java. I want to return to my roots and go back to building cool embedded systems.. but I won't if I have to use C/C++. I believe rust will be the language we write embedded systems with. With all that said I don't think I should have this book. I think it should go to a beginner and to someone with less experience than me. There's a kid I know who is getting into programming and if this book is given to me, I will make sure it gets to him, along with any mentoring I can provide to him. Every good deed deserves another.
I'm learning rust because I want to transition to web development and I foresee rust compiled to wasm being a big deal. 
The downside is that the original vec for `values` is dropped at the end of the function, so that doesn't have *exactly* the same semantics as `.append()`. If `Extend` was specialized for `vec::Drain` then you could make this a one-liner that produces almost the exact same assembly but leaves the capacity on `values`, however this produces a loop that manually copies values and updates indices instead of using `memcpy`: target.extend(values.drain(..)); Funnily enough, though, `Extend` *is* specialized for `slice::Iter&lt;T&gt; where T: Copy` and you can get really efficient assembly while keeping the capacity by doing this, even though it's rather counterintuitive (and requires the values are `Copy` but all immutable references are): target.extend(values.iter()); values.clear(); 
I'm in the process of trying to port a [Pure Data](https://puredata.info/) (a language sort of like [Max](https://en.wikipedia.org/wiki/Max_(software)) synthesis engine (kind of like [dsp-chain](https://github.com/RustAudio/dsp-chain)) to Rust. The project is here: https://github.com/NeoBirth/PureZen My goal is to target `no_std` platforms, namely microcontrollers like the Adafruit NeoTrellis M4: https://github.com/rust-embedded/wg/issues/286
Ah yes, my mistake. I forgot about the generic parameters; if it didn't have those then `Sized` would indeed be superfluous.
r/mk gives you there respect
*OwO, what's this? * It's your **12th Cakeday** dan00! ^(hug)
The first parameter of those methods is `&amp;self` this makes `self` a reference to an struct - `&amp;Point`. Now from struct reference you can't take fields as owned values, only references to them. You can take ownership of struct fields only if you have ownership of the struct itself (each field at most once obviously). `Copy` types allows you to get their owned values from references.
Subscribe to PewDiePie
&gt; That's a nice change from the old Xee rant. The Xee rant was more about the format being garbage than undocumented though. The spec bit was mostly so they could cathartically set the spec on fire.
How is this app related to Rust?
&gt;I think the vast majority of code out there is using lock free FIFOs where the oldest element is overwritten. The most recent value always needs to be consumed, if the oldest hasn't been consumed then its already invalid. Usually. I wouldn't say so. Overwriting is more difficult to implement and has some trade-offs, and ringbuffers are often used for sending events/commands where just dropping things on the floor silently wouldn't be okay. In my experience overwriting is quite rare, actually.
&gt; A function that takes a non-mut reference, like get_x and get_y do, may not modify the parameter, **and moving a String out of it is a modification**. So does the thing in bold also apply to the ```f32``` in the other struct member? Or is this behavior specifically for object-types like String and other structs? 
Since `f32` implements the `Copy` trait, it can be copied out instead of being moved out, so it's fine to use the same syntax that would move the `String`. A type can be `Copy` if you can do a simple copy of its bits over to a new place and then keep using the old one without causing any problems. A `String` is not `Copy` because some of what it stores is a pointer to heap-allocated memory, so if you make an exact copy of it you could have one destructor free the memory while the other one is still trying to use it. A number can be copied any number of times without causing any problems, so `f32` implements `Copy`. If you want to get into the implementation details, a move and a copy are exactly the same thing, except that the compiler doesn't let you move in some situations, and it marks a moved-from value in some way to keep its destructor from running. They use the same syntax, and they both do an exact byte-by-byte copy from the old location to the new location.
Oh shi. Just realized that two unit types in a type param list resemble a ü¶Ä!
Creating a module for bulletproof wide string support on Windows. [link](https://github.com/Lokathor/thorium/pull/1) * This is a work in progress, it will need quite a bit more hammering to get things right. * That said, please review and comment in the PR if something looks wrong. * I'm not even super happy with the API design, it all feels a little off somehow. * I'd like to get more standard lib traits integrated to this as appropriate. I've never quite understood AsRef, Borrow, and BorrowMut but they're probably appropriate to integrate here.
Interesting, do you know anything about this ruckus? I hadn‚Äôt seen this before!
I rewrote my ARMv4T assembler and added a THUMB assembler as well for my emulator. Here is an example of it being used in my tests: [example](https://github.com/ExPixel/Pyrite/blob/master/pyrite-gba/src/cpu/thumb/test.rs#L677-L70). Also added the remaining THUMB instructions to the CPU emulator so this week Ill probably just be implementing the display so I can run ARM Wrestler and other CPU tests that render their output using the GBA. 
Other than that people are extremely happy with his work and research not much :) I believe he did his research for a company that continued bringing it to conventions here in the netherlands (hence the wrongfull crediting as he and his team were credited as a "group of students from TU Delft"). I can ask what company he did this for though if you are curious.
If anybody has used this and qtcreator both- can I get a comparison please? I use qtc and love it. 
Still waiting for TabNine in jetbrains IDEs. Literally considering switching to vscode just to try it out.
What is their ui kit?
Not at all, see the user‚Äòs posting history, this is just normal spam.
Eyy you know about the `gba` crate I hope ;3
&gt;But don't be scared away because Crossbeam's queues are not &gt; &gt;really &gt; &gt; lock-free - the chances for blocking are exceedingly small and should not blow the latency up &gt; &gt;\[...\] &gt; &gt;I'd also say the possibility of malloc/free waiting on a lock is a higher concern anyway. Since you asked about what's different in the audio domain: this is one thing. It's not really about time, so much, it's about giving up your time slice whatsoever. Audio thread(s) ideally follow a real-time philosophy, so blocking \_whatsoever\_ is out. Once you've yielded, all bets are off, the OS could take \_minutes\_ to give you some time again. It won't actually take minutes, of course, but that's how you need to think about it. In practice, things are a bit more lax, for example two hard-realtime threads that \_only\_ synchronize with each other can wait on each other in careful circumstances and it's probably okay, but, for example, malloc/free in the audio thread is completely unacceptable. When things get heavily loaded, this will result in very obviously flaky performance (dropouts). Things that seem fine in isolated benchmarks often fall apart in reality when you start pushing the limits, and users are constantly pushing the limits. Of course, there's plenty of sloppy code out there that does things like this and it sort of works, but I'd say the main goal for Rust audio is to provide all the utilities required to make proper solid audio code that follows these rules strictly. For context, I work in audio and have had many conversations about this in the past few years, and people are excited about all the great work that's been moving in this direction (including your queues), but aren't going to migrate from C/C++ if there's no strictly realtime communication/synchronization plumbing available. The real promised land for audio developers is finally having some ability to be \_more\_ confident in statements like "nothing in the audio thread blocks or allocates/frees memory, \_ever\_". Being appropriate for realtime is a very binary thing: it either is, or it isn't - and "usually" isn't. Anyway, concretely, all sorts of queues can be useful, but a simple bounded SPSC queue where the writer has to deal with failure to push is the bread and butter of audio. Fancier queues are used, but reluctantly, because they're slower and introduce other complexities that are avoided unless they're really necessary.
Hey! I've created a little POC of a WASM client-side library that can identify metadata and codec info about various media (audio specifically) files. It's very very very hack-y and messy at the moment, I'm pretty new to Rust and this is one of my first projects using the language. I used various existing Rust libraries for the file parsing, so my code is basically just a WASM bridge to those libraries, though I did have to modify two of them to support building with no std. IMHO the idea of the library itself is pretty useful - my original intention for this project was to allow web apps to display metadata about audio files being uploaded, without having to send them over the wire (and run ffmpeg locally or whatever). Would love a partner/mentor to kinda help me get better acquainted with the Rust ecosystem :) Take a look: https://github.com/yotamofek/fazer
Deep respect to you and all people that faced the similar issues but was able to overcome the difficulties. As for the systems programming, I strongly believe that it's one of the most, if not the most, interesting thing in computer science. That's where the real challenge and beauty happens. Unfortunately, as with many other disciplines, it really depends on a fellow or a teacher that should help you unleash it. This was especially true before Rust because on its way one could easily be lost in the complexity and tar pit of undefined behaviour. But now we have that brilliant language and amazing community that wrote so many great crates and articles! I r especially recommend "Writing OS in Rust" series. Just remember, it's never too late to learn new things.
I have. I'll probably be giving it a try once I have the emulator working. 
I can't say Rust provides more bloat than in C. There are nice proc-macro crates that help with this, making ?, Ok() and Result&lt;T, E&gt; all you have to add to the functions, plus defining an enum for the possible errors. Even if one implements Into implementations manually, the error mapping and the function using it is separated, making the code more readable.
More generally (don't know if these template engines are specialized for HTML), a template engine is a facility that takes a template (usually text) that contains placeholders and processing instructions and combines them with specific data to generate a final document.
Well, the yarte author [*finally*](https://github.com/rust-iendo/yarte/pull/29) did something. I don't think this actually counts since it doesn't copy the original license, but it at least gives some credit to the askama devs. Honestly, after observing the author's behavior with this issue, I really wouldn't trust them to maintain yarte in a reasonable manner. I don't think I'm the only person who is now going to make sure to stay away from the original yarte project. In fact, they even [explicitly told people](https://github.com/rust-iendo/yarte/issues/5#issuecomment-466792074) who were concerned about the lack of attribution not to use the project. I'm much more willing to touch this fork than I would the one maintained by the yarte developer.
I was referring to the mechanics of passing the value in the bubble_sort function - I will make it more explicit! When swapping values it's Copy all over the place - it's mentioned in a footnote from the scalar product session, but I didn't get into the details because traits are not something I wanted to introduce yet.
This might be a termion question rather than a Rust one but I'm just trying to print a colored box: use termion::color; fn main() { println!("{} \n {}", color::Bg(color::Blue), color::Bg(color::Reset)); } but the background color continues to the end of the line on the second line like: jamie@jdm-pc-mhp:~/test/clr$ cargo run Compiling clr v0.1.0 (/home/jamie/test/clr) Finished dev [unoptimized + debuginfo] target(s) in 0.14s Running `target/debug/clr` ######## ############################################################## (with octothorpes in place of blue spaces). I've asked this before but I'm trying again, any nudges in the right direction? :)
Is it better with the bottom layer turned upside down? Never tried it this way.
You can try using termion::cursor instead of \n
Same on a QtC plugin, I've poked around trying to understand what it would need but I probably need a mentor if I were to make headway in any reasonable timeframe.
Somewhat off topic, but it seems like a decent place to ask. I work professionally with audio files, and have been eyeing a project centered around massive parallel transcoding of audio files in a variety of formats as a place to introduce Rust to the codebase. At the moment this work is handled by calling shell scripts that run FFmpeg. Does anyone have a recommendation for a collection of crates I could explore to get this functionality? I looked a while back at the rust-ffmpeg crate but wasn't impressed with the usability, and the gstreamer bindings crate essentially requires pulling the whole gstreamer C++ toolchain into my build dependencies.
Very cool! I've been using Rust to write a small quantum Monte Carlo library over the past couple of months, so it's great to see more people giving it a go for scientific applications. I've become convinced that Rust would be immensely helpful for scientists in HPC, given enough library support. I'd recommend also doing a post on Cargo at some point, or at least mentioning it. The ease of adding dependencies to projects is one of my favorite things about Rust, and given the amount of scientists that are still hand-writing makefiles it might be to help win them over.
I'm glad that worked for you.
Rust is the newer kid on the block and has a lot of potential for getting better application out there. I've started with rust and am always on the lookout for out for great resources. I am hoping to write a few short blogs myself about writing microservices and such. Good stuff. 
 A colleague of mine suggested Valorem ([https://www.valoremreply.com/](https://www.valoremreply.com/)) which is a consulting firm with lots of experience in Windows 10 (and UWP). Are you looking for individual contractors or are companies ok as well? &amp;#x200B; FYI, I work at Microsoft as the Developer Advocate for Rust so I'm happy to help beyond the teams you're already in contact with. 
I would like to watch a borrowing video that trains to identify "cannot move out.. " etc compiler errors. Often I see myself running the compiler telling me what's wrong and then I fix every error one after another, because when I type I make too many errors, and almost all of them are either due to borrowing, mut borrows or wrong types especially in forms of slices, references etc with all conversion needed. There are hundreds of intro to rust videos already, but none really train to seem, make people deeply understamd what to look for before writing code. "Don't do that it'll lead to this error" instead videos say "Here's an error, compiler will complain". At least that's how I feel. 
I've developed a few audio apps in Java on Android and have started learning Rust out of interest in the performance and memory handling. I think it's a clear choice! I'm converting a DJing program I started in Java to Rust so that I can hopefully get it running fast enough for good responsiveness on a Raspberry Pi. Definitely interested in this community and will be following along.
&gt; It depends on the driver settings. Worst case scenario is about 1.3ms (and that's somewhat insane). Best case is ~42ms. A typical browser that is outputting sound for a low latency scenario, for example Web Audio API or a WebRTC call, (say Firefox, which I happen to work on, an that has decent chunks of rust code for the audio IO) is using 256 or 128 frames buffers a 44100Hz or 48000Hz, on OSX, and soon windows (only on windows 10, we need a specific API). This translate to a budget of 1.33 or 2.66ms, and that being very generous, because the other bits of userspace and the kernel use a non-trivial portion of this. I'm also working on a platform, that runs a Xenomai Linux kernel where the buffer size is 4 frames and the overhead is very thin. This is 86 microseconds, as a point of reference, and is not "insane", it's a common setup you can buy, and is being used by more than a few people for real things (art installation, musical instruments, etc.). Rust has no problem doing this. I'm not doing anything with fancy data structures, and it works well enough with the default channel. I plan to use something with stronger guarantees later, but the priority for now is to have something working (and actually design all the hardware that go with it). I'm being strict about allocations and locking and anything that looks like it would block or take a long time, though, that's not something you can compromise on, but I'm driving a stereo audio output, 8 analog outputs (arbitrary voltage in 0..5V) and 16 GPIO (either 0 or 5V), with zero optimizations (which will come when they are needed), at that buffer size. It just works. 
&gt; I'm writing a pretty big project (~10k loc) Did you mean 100k loc?
I found this to be a common issue for new people, because while &amp; is familiar, `&amp;mut` is downright foreign. That's why Rust introduced automatic help suggesting `&amp;mut` for these cases. Then I found this still is a common issue, because '&amp;mut' is downright foreign and people don't read compiler output.
In my personal experience TabNine _shines_ when it comes to boilerplate. Whenever you start writing code that is slightly repetitive,TabNine kicks in and recognizes surprisingly complex patterns and autocompletes most of them. That said TabNine is completely useless for exploratory programming, when you have a blank sheet in front of you and you want to explore what APIs a type offers. This isn't surprising as this isn't what TabNine is designed to solve. Rust still needs better autocomplete, but for projects with some structure (and associated boilerplate, however little that may be) TabNine offers a very nice experience.
 - [Created an itch.io list of Rust games](https://www.reddit.com/r/rust/comments/arm9dr/a_list_of_itchio_games_written_in_rust). Also, I've sent a request to itch.io folks to add Rust as an instrument, so now a more official list is available: [itch.io/games/made-with-rust](https://itch.io/games/made-with-rust). Looks like my original list will be deprecated with time. - Ported Zemeroth to ggez v0.5.0-rc.0. Filed a bunch of mostly text-related issues in the process ([#556](https://github.com/ggez/ggez/issues/556), [#557](https://github.com/ggez/ggez/issues/557), [#560](https://github.com/ggez/ggez/issues/560), [#568](https://github.com/ggez/ggez/issues/568), [#569](https://github.com/ggez/ggez/issues/569), [#570](https://github.com/ggez/ggez/issues/570), [#583](https://github.com/ggez/ggez/issues/583), [#590](https://github.com/ggez/ggez/issues/590)) and tried to fix most critical for Zemeroth: ["Remove the generic argument from Drawable::draw"](https://github.com/ggez/ggez/pull/559), ["Drawable::dimensions()"](https://github.com/ggez/ggez/pull/567) (big one!) and ["Fix Text::dimensions height"](https://github.com/ggez/ggez/pull/593). Now, [when GGEZ v0.5.0-rc.1 is out](https://www.reddit.com/r/rust_gamedev/comments/auexbj/ggez_050rc1_released/), I can switch to it and try to [merge a WASM version of Zemroth to master](https://github.com/ozkriff/zemeroth/issues/178). - Currently, I'm working on a big refactoring to encapsulate all state mutations in one place - [#195 "Encapsulate all State's mutations"](https://github.com/ozkriff/zemeroth/issues/195) - and trying to create an integration testing machinery to minimize the chance to screw up edge case logic in the process. 
The link to [your book](https://chinedufn.github.io/psd/book) is broken.
Amethyst is currently the most advanced game-engine for rust.
Still contributing to https://github.com/svenstaro/miniserve and still learning a lot from it. We tried handlebars and maud to render the file listing HTML file, and maud it will be. Awesome crate, props to its creator. https://github.com/lfairy/maud
With LSP support enabled, it's pretty alright ‚Äì it's not great, but it's certainly capable of tuning its suggestions based on type information.
&gt; One awesome community I've started to interact with is the RustVST group, which has worked to implement VST2.4 in Rust. I'm working on an audio workstation in Rust. I was planning on dropping to C++ for writing the VST host code. A Rust crate for host- and plugin-side VSTs would be a game changer. Well, for VST 2 at least. I think VST 3 is almost impossible to achieve, since their is no standardized ABI. AFAIK VST3 is just a C++ class library.
Also not a lawyer, but this reasoning seems fine to me. The MIT license only requires attribution; as long as a project attributes rights properly to all of its sources, then it would seem it complies with the license's requirements, even if some of the original works it derives from did not do so.
Pff... not sure you and I have the same idea of fun. :D
Ah, it's on YouTube now, nice! Previous discussion of the talk happened over on https://www.reddit.com/r/rust/comments/ahap4n/is_it_time_to_rewrite_the_operating_system_in/
I integrated Cargo to Windows-based project built using Visual Studio at work. It is pretty straightforward. I used custom build action. If you need to build 32-bit binary (I did), switch on Win32/x64 and pass --target to Cargo. All in all, everything worked fine.
11 minutes in, still nothing about either OS development or Rust. If you know when it begins, please provide the time link.
This guy has next to no concept of staying on topic. No digression left untaken.
These old formats were garbage because they were first implemented by dumping in-memory data structures directly into binary files. It's zero effort and carries no serialisation overhead.
Because I want to be a better programmer! Nice HHKB btw. I use one at work and home. 
Thanks! &amp;#x200B; Yeah the heavy lifter is \`std::io::cursor\` which I wrap in a struct called \`PsdCursor\` in order to abstract things like "red 4 bytes and convert into a u32" "peek at the next 4 bytes and see if they're equal to a certain thing that means a certain thing" &amp;#x200B; [https://github.com/chinedufn/psd/blob/87342041fd1ab1c768c334572b5c1a0ebc65222f/src/sections/mod.rs#L113-L118](https://github.com/chinedufn/psd/blob/87342041fd1ab1c768c334572b5c1a0ebc65222f/src/sections/mod.rs#L113-L118)
Sorry! That link that you pulled from the README was the wrong link. [I've gone ahead and fixed it](https://chinedufn.github.io/psd/)\- but do know the book is nearly empty at the moment. &amp;#x200B; Thanks!
I personally use your 1 in my tree building app ([broot](https://github.com/Canop/broot). The big vec is part of the Builder structure (and thus available in all methods) and nodes use indexes to keep track of parent and children. There would be a 4: unsafe all the things. When you think about the 1, it's really unsafe anyway (meaning the guarantees don't come from rust but from the programmer).
Half an hour in, and it's a reasonable potted history of OS development and languages. Nothing about Rust yet.
It's still incomplete and not up to date with what Adobe use.
As hint related Rust advocacy at Microsoft, having Rust achieving parity with C++/WinRT/CX and C++/CLI is quite relevant for us managed devs to even consider using anything else.
In my Information Theory course we're implementing a Markov chain generator that should work from zeroth til fourth order, and I decided to do it in Rust. It's been fun but I had some problems with the borrow checker when I tried representing everything as a graph, though now that it works I really want to try and compile it to wasm, but I don't think `rand` compiles to wasm at all.
One man army !
Thanks for the feedback. I'll have to give it a shot. 
I am preparing a talk for the [Desert Rustaceans meetup](https://www.meetup.com/Desert-Rustaceans/events/258596537/) in Phoenix, AZ.
RemindMe! 10 hours
I will be messaging you on [**2019-02-25 21:58:02 UTC**](http://www.wolframalpha.com/input/?i=2019-02-25 21:58:02 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/rust/comments/au31cs/implementing_tcp_in_rust_part_1_video/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/rust/comments/au31cs/implementing_tcp_in_rust_part_1_video/]%0A%0ARemindMe! 10 hours) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
I needed to ditch the JVM for Raspberry Pi-hosted projects due to memory and cpu constraints.
Microsoft had the same problem with doc files, it's a tempting "solution", but it's sooo bad.
Yesterday I finally prepared my talk for the Vienna Rust Meetup on Tuesday about Futures and async/await. Got delayed because I got multi-page compiler errors while writing the demo code which took a while to figure out.
Nice work. I like the split between battery/battery-ffi/battery-cli.
Wow! Kudos for the wide platform support, TUI tool, and ffi crate the go along with this. 
Howdy! Jump in on the conversation: https://www.reddit.com/r/rust/comments/aua2tb/comment/eh6pu5f
And here I'm thinking that it is not worth to repost it everywhere. I'm the author, AMA or something
Does this work in place of RLS or alongside it?
Hmm I've been using horror show but this looks a little more mature. Might give it a try
Wait are you serious? At all!? 
Was yarte repo deleted?
Trying to drum up hype for rust in uni clubs... Most stuff I was talking about went way over everyone's head. Any tips? 
It probably _fine_ for a getting a v1 product out of the door. But the first time you write a format migration for v2, you should realise the severity of the problem you need to fix.
Such a great pet peeve! Small enough to polish well, and well done so! I wish all projects were small and polished like this
I'm looking forward to reading more about all this! Regarding updates and deferred dropping, this is what `crossbeam-epoch` was made for. I've also been experimenting with hazard pointers and have some thoughts on that. Also, make sure to check out [`ArcSwap`](https://github.com/vorner/arc-swap), which is fully lock-free (designed to be signal-safe) and might fit the bill. Perhaps exclusive ownership could be guaranteed through simple mutexes (which would never be contended because only the RT thread locks them), if that's not a too high price to pay?
If having to use nightly doesn't bother you, I highly recommend it 
Great answer, thanks for the clarification! This made me understand the problem domain *much* better. I'll make sure to add a simple bounded SPSC queue to crossbeam as soon as possible since it's relatively easy to implement and there's not much bikeshedding to do around the interface.
I'm working on a tool to generate personal code coverage reports by combining code coverage data with git blame data. It's for the company I work for, but in the process of getting it open sourced. It's still a WIP. I'm also launching a side-project this week, with a backend written in rocket :)
Holy energy information Batman! This is awesome! Most people would have stopped after supporting their own OS, but you really went the extra mile or four! I know I'm going to be using that CLI interface from now on!
Alongside it. There is an option in tabnine to additionally use rls for extra completion features
It's also useful when you're running on a device with very limited processing and IO capabilities.
This is so cool! Thanks for making it. The FFI part seems like a great place for other libraries to take inspiration, really shows where Rust shines.
r/playrust
Yeah, FFI was a interesting thing to learn. I have one more blog post about FFI in Rust, going to publish in a couple days
Projects like this one are exactly what will drive the Rust ecosystem into recognized maturity. You're awesome, thanks for contributing this!
Couldn't you just use an in memory database that you dump in a file?
Why are you sorry for fixing a bunch of bugs for me? :D I'm sorry they were there in the first place!
yeah. I have the same approach and just defined a single error type for the application level with some general error kinds. As a result, I just map errors to HTTP status codes on the HTTP API level.
Fwiw, the host seems inaccessible from Russia, probably due to some blocked-in-Russia explicit-content sites among other 1000+ ones on the same IP.
/r/playrust
Fwiw, the host seems inaccessible from Russia at least via some internet providers like MGTS.
What IDE/editor are you using? &amp;#x200B; You should be able to toggle line numbers in the settings, no need to reinstall Rust for that.
Yep, I know, because it is located at DigitalOcean and thanks to RKN it's still blocked.
Do you plan on supporting PSD writing? We could use that for vange-rs to export the levels (which have multiple layers).
Thanks! Worth watching though?
I'm new to audio work in general. Currently cutting my teeth by writing a flac encoder. It's very much a work in progress, and not yet available online, but once I get the basics working, I'm hoping to make it multi-threaded and reuse buffers whenever possible. On the one hand, I think an encoder is an easier way to get started than a decoder, because you can choose what kind of optimizations you support, you can, for example, create a valid flac file that contains nothing but raw PCM data, and is therefore slightly larger than the source wav file, because of the larger headers. Not very useful for compression, but it should play just fine in any flac player. Then I can start incrementally adding new compression strategies. On the other hand, it's also more challenging to do *well* because knowing how the file is structured doesn't tell you when to choose one compression strategy over another. So far, though, it's been a fun project, and I'm looking forward to having something to share with the community.
I can't vouch for the quality of any of these crates, but you could look at: * [https://github.com/lieff/minimp3](https://github.com/lieff/minimp3) * [https://github.com/ruuda/hound](https://github.com/ruuda/hound) * [https://github.com/RustAudio/lewton](https://github.com/RustAudio/lewton) * [https://github.com/ruuda/claxon](https://github.com/ruuda/claxon) &amp;#x200B; I don't think there's a solution for AAC files unfortunately.
This is very interesting. I've been exploring something similar, which is porting the SuperCollider engine. But very interested in the work you've done here.
I'm in my first FTC season and I'm falling in love with this competition. Also in my first year on learning Rust, and guess what? falling in love with the language. If by the time I'll get to participate in FRC it becomes possible to use Rust I'll explode (metaphorically, because someone needs to write the code)
Heh, that's Bryan Cantrill for you.
Looks like it.
This is one of those little things that bugs me when I'm writing C# at work all day after writing Rust at home the night before. It's not a big thing but it becomes clear that `var` and those parentheses are pointless noise when you have to break your flow to go back and fix the red squiggles after unconsciously writing it Rust-style.
The fn signatures thing is huge for me. Basically eliminates the hassle of long repetitive return types. I was writing an AST visitor for a compiler the other day and TabNine quickly learned the function call pattern I used for recursing and combined that with RLS knowledge to suggest things like `.some_never_before_visited_field.visit(visitor)`
Rustaceans are spoiled with serde though. Most of the time, it is not _much_ worse performance to write an efficient format and just se(de)serialize to it. 
This should be included in something like the `psutil` package for Python (I know that similar crate exists for Rust but it only supports Linux).
That's probably not quite right, I think? If you used code from an MIT-licensed project that infringed on outright-unlicensed content, I believe you'd still be liable for copyright infringement: for example if yarte had used source code from Windows. The wearte case works (I think) because the only infringement (as far as we know now) was against the license terms of an MIT-licensed project, so the infringement can be corrected by following the terms of its license. If my analysis is correct (doubtful) this is a weirdly special case.
Imo It's best to start off showing some snippets or demos that shows how powerful/expressive rust is compared to C or C++. The big words can come later if they want to learn more. 
Does Firefox override user settings to use a buffer of 128/256 or is it buffering those individually in a separate thread? For instance on MacOS, the buffer size defaults to 512, and even on beefy machines a buffer size of 128 on Windows can have underruns. 
Awesome, thanks. Yeah, sounds like low-hanging fruit that would be really useful.
I'm working on a library and terminal-based application to simulate Conway's Game of Life. It uses HashLife and SIMD to achieve some incredible speedups for large repetitive patterns. [Here's](https://gfycat.com/celebratedajarhorsemouse) an example showing the evolution of a pattern (Kok's galaxy) made up of OTCA metapixels.
Cool! Finally, I can nerd out about my sport and about Rust at conferences and not even drop change the subject in between!
After having read the Rust Book chapter on error handling, I have written a little bit of code using the *?*-style. ```rust fn main() -&gt; Result&lt;(),Box&lt;dyn Error&gt;&gt; { ... } ``` Now I would like to print some meaningful messages to stdout depending on the error types. Do I need to change the *?*-style back to using `match` in order to be able to use `println!`?
10kloc is getting pretty high up there for a single person
`ref` isn't needed here. You can write this the "new" way using match ergonomics, too. Just replace this: if let Shape::Transform(ref mut t) = self with this: if let Shape::Transform(t) = &amp;mut self [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=f71d93c24e6c7af1f30705b5836fbfdd)
Nice job!
&gt; GNOME's librsvg Rewritten in Rust.
So all of the current functionality is just enough to scratch my own itch, which is being able to read an existing psd file and export certain layers into a final PNG file. --- However, while building I tried to pay special attention to design things in a way to allow for creating `Psd`s that were guaranteed to serialize into valid `.psd` files. For example, we [store the width of the Psd as a PsdWidth instead of a u32](https://github.com/chinedufn/psd/blob/20dfcfe9166c9317c0ee9e60d6bc39b4cf9ca57a/src/sections/file_header_section.rs#L203-L221), and do similar things with other bits of `Psd` data. --- Circling back to your question - my general approach with my open source work is to wait until myself or someone else needs some functionality for some real thing - so I had no _explicit_ plans to support it.. But.. Now that someone needs writing / serialization (yay!) I'd LOVE to help support this. Would you mind opening an issue that describes your use case - I'll probably ask some questions - and then from there we'll have a better sense of the minimum `Psd` changes that we'd need in order to support it? Cheers!
I see, sorry, by ‚Äúruckus‚Äù I thought you meant there was some sort of drama or strong negative reception or something, and given that I hadn‚Äôt heard of it, was curious.
Oh no bad word choice on my part. It has been mainly good reception!
Hey all, this is the first video of a series I'm planning to build an embedded wireless sensor network for my home using Rust. The plan is to start from scratch, and livestream most of the work that goes into the project. The livestreams will have a focus on teaching, rather than building the perfect platform, in order to teach embedded, rust, and IoT concepts for people new to any of those topics. The repository for this work can be found [here](https://github.com/ferrous-systems/internet-of-streams), and a link to the playlist with all videos (only this one so far) can be [found here](https://www.youtube.com/playlist?list=PLX44HkctSkTewrL9frlUz0yeKLKecebT1) Happy to answer any questions!
Anybody having experience of using both `TabNine` and `coc.nvim`? It seems TabNine works based on YCM. After I migrated from YCM to coc, I have to remove the YCM from my vim. Is it worthy to reinstall YCM to use TabNine?
LMDB is the fastest k/v store for ordered data. But if you don't need ordered lookups then certainly a hash can be much faster.
There is the barrel crate: https://github.com/spacekookie/barrel It won't auto-generate migrations, but it will give you a nice rust-dsl for writing them in.
Ahah. I actually tried it a few weeks ago and it is pretty fun!
I see `Pin` gets stabilized. Is this even meaningful without stabilizing generators?
Thank you for your suggestion. It seems I can use it as a feature with `diesel-cli`. I'll try it. Thanks!
I originally looked at SuperCollider, but given my target of embedded devices, this seemed like a better fit (e.g. designed to be embedded inside another program, all allocations in the critical path are on the stack)
I stopped. 
What happened to Rust devs? Before the 2018 edition releases were like only bugfixes and small additions to std, and now every release contains a ton of exciting new features! You guys are amazing!
For real? The releases before the 2018 edition contained awesome stuff like `?`, 128 bit types, impl trait, etc. Hardly what I'd call bugfix.
I mean individual releases, but maybe there're some exceptions
Is the code available to have a peek? 
The graphs made of text in \`battery-cli\` look amazing! How did you achieve this effect? Did you use some external crate? I assume they are displayed using the "braille" characters or something similar.
It's necessary, but you're right in that it's not sufficient. The core team is still working on a solid design for generators; there are several open questions noted by /u/withoutboats in his [blog](https://boats.gitlab.io/blog/post/generators-i/) [series](https://boats.gitlab.io/blog/post/generators-ii/).
I like them too :) All thanks to the [tui](https://crates.io/crates/tui) crate
&gt; Integer patterns such as in a match expression can now be exhaustive. &gt; You can now have multiple patterns in if let and while let expressions. Those feel huge to me, thanks a lot! Looking forward :)
&gt; Do I need to change the ?-style back to using `match` in order to be able to use println!? All you can do with a `Box&lt;dyn Error&gt;` is call the methods of `Error` (i.e. `Error::description`, `Display::fmt`, and `Debug::fmt`). It's probably not a good idea to try to downcast the error. If you just want the error message, you can print the error with `{:?}`. If you want more detailed information about the error, you'd need a trait/enum that encoded that rather than using `Box&lt;dyn Error&gt;` (although you could still write `Into` impls to make using `?` more ergonomic).
Sure thing, but be warned that it's still a work in progress and definitely needs more comments. [smeagol](https://github.com/billyrieger/smeagol) is the library that does all the heavy lifting, [goliard](https://github.com/billyrieger/goliard) is the terminal viewer.
Pinning can be independently useful; boats wrote about using it to implement a GC, for example.
I saw it live and enjoyed it.
I've developed a small REST service called [pudeuko](https://github.com/Deseteral/pudeuko) using Rocket for quickly saving links that I want to check out later. It's actually my first real Rust project. I'm still learning the language. Last week I deployed it on heroku and migrated companion android app and my new tab page to use it. It's in *ugly-but-working* state and this week I will focus on refactoring and adding "delete item" endpoint. 
This is an exception as stated in Rust 2018 documentation. https://rust-lang-nursery.github.io/edition-guide/rust-2018/module-system/path-clarity.html
This release brings \`const fn\`s another step forward, great! I hope that I can use \`assert\*!()\` soon in \`const fn\`s.
I'm just starting with Rust, I've been looking for the answer to this: how does the compiler figure out the exact type of a generic after it was already created? For example: let mut books = HashSet::new(); // Add some books. books.insert("A Dance With Dragons".to_string()); books is already created, yet its type is not known yet. What would happen if different codepaths lead to inserts of different types?
Have you tried fuzzing it yet? That's usually a good way to find bugs in binary format decoders. In Rust it is very easy to get started: https://fuzz.rs/book/
This is very similiar to `cargo redme`, isn't it?
The reason is that `test` is not passed to `rustc` via `--extern crate_name=PATH` by cargo, as it usually happens with other crates, so you have to introduce it in some other way. (`std` and `core` are not passed with `--extern` either, but they are hard-coded into the compiler and available anyway, depending on `#![no_std]` settings.)
You want /r/playrust, or maybe /r/DontFundMe?
Yes we do set our own buffer size, but we don't buffer on another thread, because this adds latency and you lose the benefit of having a real-time priority thread (you can set up things so that you still have higher priority, this is not enabled on release Firefox). The exception is regular media playback, where we don't care about the having long of latency, we care about knowing it perfectly (even with Bluetooth devices, etc.), to be able to shift video frames and have good A/V sync. For the workloads we consider important in Firefox (media playback, webrtc calls with not too much peers or with some infrastructure, reasonable web audio api applications, etc.), this works well, and having lower latency is good. It's no different than, say, ableton, in terms of latency, on a normal system that hasn't been tuned by someone knowledgeable (we can't ask people to install drivers or buy nicer sounds cards). 128 on windows is something we'll try soon. The thread priority things (MMCSS) on windows ought to allow small buffer sizes. 
Not Rust, but Django does it really well.
Thanks! I love it. Sold my other keyboards since I didn't touch them after receiving this one. :D
thank you haha
The `transpose` method for `Result` and `Option` feels like it might conflict a lot with code involving algebra like for gaming and such. What is the rationale here?
I actually haven't ever fuzzed anything and only even heard of it after joining the Rust community last year (just because it comes up so often!) - so thanks a lot for the link I'll check that out!
I should measure the overhead for uncontended mutexes, but am a little worried about the atomic. In running audio processing graphs, many of the nodes do a pretty small granule of work, so added overhead could have a significant effect on overall performance.
It uses all surrounding context within one method to infer the types, no matter if before or after the binding.
That's awesome to hear! (Not that you had to debug a linker bug, but that `gimli` was helpful :) )
Very awesome, thank you for sharing :)
37:52 this is one of the funniest thing I heard regarding Rust
I managed to get FFI bindings to the FDK AAC encoder to work, as far as I know it's considered the best encoder for AAC audio right now. I can share the work in private if you want.
This makes perfect sense, and the Book definitely made note of Strings being stored partially on the stack and partially on the heap. I'm glad I understand this behavior better. Thanks!
Where can one apply?
More packages like these! By the by, you can test ports faster with tonixxx. I hope the MINIX port of Rust gets more traction :)
thanks, didnt even realize it xD
By the way, you should change this: if x.len() != y.len() { println!("..."); process::exit(1); } To simply this: assert_eq!(x.len(), y.len()); It will have the same (or better) effect, and is much more idiomatic Rust. Note that `assert_eq` checks in all builds, not just debug-only builds. (There is also a `debug_assert_eq` macro for that case.) 
This raises an additional question I have with moving. When you call the println macro on the wrapper struct, but then you also call an associated function on the struct to get a value for the format string, does this always result in a move (assuming I don't use &amp;)? Like, for example: //pretend there's some struct named s that has a function named bar impl'd println!("{}", s.bar()); Regardless of what bar returns, will s always be dropped? Even if bar returned a struct with another impl'd function that I call in the same line, ```s``` will be dropped? Also, kind of another noob question, but I'm just experiencing a little whiplash since I've gone from a lang with a garbage collector, to C, to Rust's ownership system. The return value of s.bar() is moved into whatever function calls it, correct? And it is dropped at the end of that same function? I am just ensuring I understand this correctly. Thanks!
Have you seen cargo-geiger? Their output looks really nice. Of course you can't visualise if two dependencies have a common sub-dependency except by adding it to both... But it would at least make it possible to run cargo-deps without having to install some additional tool. Also, have you thought about generating SVG files manually?
This is really cool! I'm a little curious: what's the difference between a battery's percentage and capacity?
Thank you for telling me this. I'm still learning about traits - I'm familiar with the concept of things like Java interfaces, but I still lack info about the standard types and their traits. Thank you!
Is there any such library that implement `transpose` for `Result and `Option`? It's fine if they implement for some other type like `Matrix`, or even some trait that is implemented only for matrices (for example, `Iterator` has a method `map`, and `Result` and `Option` have both a method `map` too)
Working on a couple of [tarpaulin](https://github.com/xd009642/tarpaulin) bits plus a larger investigation while also juggling my new project a computer vision library in rust built on ndarray.
Would this be the first time Rust gets used in [military profiteering](https://www.geekwire.com/2017/microsofts-hololens-joins-marines/)? üò•
Kids like and/or are curious about blockchains (because they're new). Maybe talk to them about how Rust is being used in a lot of cryptography and blockchain libraries because of it's memory safety, speed, and that it plays nice with WASM? - https://dalek.rs/ - https://z.cash/blog/bellman-zksnarks-in-rust/ - https://substrate.readme.io/
Rust already has a [`format!` macro](https://doc.rust-lang.org/std/macro.format.html) if you aren't aware of it. Or is your problem that it's insufficient for some reason and so you want to make a custom version?
`println!` is actually a special case. It's implementation internally borrows whatever you pass it, so it is impossible to move a value into `println`. This is possible because `println!` is a macro and not a function call.
Whom do we have to ping to vite this as the crate of the week for twir?
Dude! I was just exploring the Rust/WASM book last night and wandered into HashLife territory and then discovered your work. Super cool stuff :)
It would be really nice if Rust could provide something like `#[doc(file = ‚Äú../README.md‚Äù)]` instead of using hacks like that. 
Pretty sure the issue is that he wants to take a dynamic format string from the user, and interpolate it safely, which `format!` won't let you do.
I don't fully understand how this works, but I think you need to have the Javascript supply a random seed to the WASM (because WASM is deterministic and doesn't have access to hardware randomness). There's a discussion about that here and apparently the guy got it working, so it's possible (I think): - https://community.zkproof.org/t/zksnarks-in-webassembly-running-demo-and-discussion/30 - also the Rust WASM book kind of touches on this too: https://rustwasm.github.io/book/reference/which-crates-work-with-wasm.html
https://brson.github.io/rust-anthology/1/rusts-built-in-traits.html
Percentage value is how much energy your battery have right now, where zero is a zero and 100 % is a maximum value when it is fully charged. Capacity value basically measures how much your battery degraded. For example, I bought my notebook ~3 years ago and when it was new, its battery capacity was 100 %. Since lithium-ion batteries are degrading with time, now it can't hold the same amount of energy as before, so in my case capacity is equal to 64 % now. Probably I should clarify that in the documentation :)
https://reddit.com/r/programming/comments/ats0bl/_/eh3pky5/?context=1
!remindme 1 week
I will be messaging you on [**2019-03-04 20:17:27 UTC**](http://www.wolframalpha.com/input/?i=2019-03-04 20:17:27 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/rust/comments/auk2qy/introducing_battery_crate/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/rust/comments/auk2qy/introducing_battery_crate/]%0A%0ARemindMe! 1 week) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
&gt; Despite the sizable undertaking, I really value the ability to drive the vast majority of the technical design myself, so I get to use Rust. That's awesome. Living the dream :)
I'm testing it with [cross](https://github.com/rust-embedded/cross), with current build targets it is more that enough (also, cross is amazing). The worse problem is I don't have so much different devices and operating systems, where I can test correctness with real batteries, which leads to issues like [that one](https://github.com/svartalf/rust-battery/issues/8).
Thank you! That was an excellent explanation.
Could you give an example? `transpose` is one of those methods I look at and think "that's interesting but I have no idea why someone might use that".
It was an off the cuff remark, I've since learned that `rand` works fine in WASM and that I am doing far too much IO to bother porting it to WASM anyways, but it was worth a try.
This is awesome! So glad you're working on this :)
To `cargo readme`, yes, as I say it in the disclaimer. But there‚Äôre a few differences.
This is really cool. Kind of reminds me of TensorBoard actually :)
A nice Rust-from-C FFI post would be a great resource. I'm assuming you're already familiar with the FFI Omnibus?
Exactly, thank you for explaining it in a different way. You can think of it like implementing `strftime`.
I support this! :)
I'm working on a [3D cellular automaton simulator](https://github.com/nstoddard/ca-3d) which compiles to WebAssembly. Unfortunately I haven't yet found a rule that's as interesting as Life is in 2D. I'm also working on a [WebGL wrapper library](https://github.com/nstoddard/webgl-wrapper) and [GUI library](https://github.com/nstoddard/webgl-gui), but these aren't complete yet, and I might end up switching to gfx-rs once it supports WebGL.
Yeap. https://github.com/rust-lang/rust/issues/44732
[It actually does have that, though nightly only.](https://doc.rust-lang.org/rustdoc/unstable-features.html#include-external-files-as-api-documentation)
FWIW, I stuck with it.
I'm confused. Wouldn't a compile-time equivalent of this just be `&amp;` and `&amp;mut`?
Contents of `Rc` is immutable unless you use `Cell` or `RefCell`. RefCell is checked at runtime, so that means that two distant parts of the code could crash each other just by accident, with no way to statically guarantee that won't happen. So I'm trying to avoid that risk. (Whether this is a good idea, or practical, or sound is another question, though, which is partly why I'm trying to find out whether there's already a crate for it.)
Just want to put it out there that my creative software company, [Paracosm](http://paracosm.us), is shifting to Rust for systems dev tasks, including audio plugin development in the future. So I don‚Äôt think the effort is misdirected at all, and would in fact be a complete game-changer for the industry. Rust is just way easier to use and get right than C++!
I thought it was also useful for doing DMA related things? Or do you somehow need generators for that as well?
Is there any particular reason to stabilize it now then?
Yes, I'm aware of the difference, so I don't feel like my question has been answered. Do you have an example of code you would want to work in the way you're describing?
I wasn't aware of cargo-geiger, but the output looks similar to that of cargo-modules and that kind of visualization, but for dependencies, is something that I was considering specifically. &gt; Of course you can't easily visualise it if two dependencies have a common sub-dependency except by adding it to both... Yep, but you can hide the sub-dependencies of a dependency the second time it's shown, and it actually is still a pretty good visualization. I think cargo-modules does something like that. &gt; Also, have you thought about generating SVG files manually? What do you mean?
If there‚Äôs no outstanding concerns, there‚Äôs no reason _not_ to stabilize Pin, right?
No mentinon of Rodio?
I don't know man, google is writing fuchsia in go, how is rust better?
&gt; so that means that two distant parts of the code could crash each other just by accident How could the compiler check if two distant pieces of code correctly interact with each other? It cannot check this at compile-time, which is why RefCell works at runtime. 
Cool! For your benchmarks, it might be a bit clearer to plot the inverse of what they currently show: operations per second, rather than (nano)seconds per (100k) operations. This will hopefully show performance scaling linearly with the number of threads more clearly than trying to deduce it from the hyperbolas/ideal curve.
Emacs + either lsp-mode or racer-mode
Wow, the benchmark results are amazing! Great work üëè I'm very surprised your STM-based RBT is competitive with the lock-free skiplist. How did you achieve that level of performance? I honestly never even considered building a concurrent ordered map based on STM. Are there any caveats one should be aware of when reading these benchmarks? The implementation doesn't have too many comments at the moment. I'd love to at least roughly understand what the library does. :) Are there any papers one could read to learn how high-performance STM works? Any future plans for the library? What are other kinds of data structures this STM library would be good for?
Some answers have been provided [on SO](https://stackoverflow.com/questions/32572486/how-can-i-use-a-dynamic-format-string-with-the-format-macro), e.g. the [strfmt](https://github.com/vitiral/strfmt) library.
Well instead of having GraphViz visualise a graph and save it as a PNG, directly output a SVG file with its contents generated by this nice tool. I have no idea how that would work though (the graph part), but as far as I know SVG is just text that's being rendered? So basically like creating a text file in which the positions of "bubbles" and their text is defined and the lines between them. This could even be integrated into readmes when the CI is running on a release build :D
I suppose one could argue that one should wait to deliver the entire "package", if we're discussing the `Pin` API only in the context of generators and, by extension, `async`/`await`. I unfortunately can't speak for the official Rust teams, but there are a couple of reasons I can think of to let the `Pin` API land now: * The official Rust teams want to deliver foundational pieces in increments once there's certainty that the design won't change. This can keep their overall development pipeline lighter. * As the [original `Pin` API RFC states](https://github.com/rust-lang/rfcs/blob/master/text/2349-pin.md#motivation): &gt; This proposal adds an API to std which would allow you to guarantee that a particular value will never move again, enabling safe APIs that rely on self-references to exist. IOW, the `Pin` API might actually be significant for other chunks of the ecosystem, like making a more ergonomic or featureful alternative to [`rental`](https://crates.io/crates/rental).
Thanks! Does any book go into details of this process?
I think it's the other way around, if not stabilizing something does not hurt anyone, then we should not rush things. After all you can not foresee if a better design will be proposed or some changes will be needed to the current one. (yes, probability is quite low, but still non-zero)
It can check by using a different value (MyCellOwner in this case) which isn't behind `Rc` and which is passed around as context. It knows when you're borrowing that value, and the idea is to extend this borrow check to the data behind `Rc` which the compiler doesn't know about. What this means for code structure is that most of the time the context structure remains as `&amp;mut` and unborrowed, but then there are small branches off where we borrow it, do some operation on a value behind `Rc` and release it again. So the code which would have crashed with `RefCell` doesn't crash here because we've been forced to do an operation and then release the borrow before calling into some other code, which then (some way down the call stack) does something similar.
AFAIK apart from generators and async stuf only highly experimental work on GC uses `Pin`. IIRC author of `rental` wrote in one of the discussions that unfortunately `Pin` does not bring anything new to solving self-referential issues targeted by this crate. So I will be glad to be proved wrong, but currently I do not see consumers of the `Pin` feature in the ecosystem without generators and co.
Thank you. The crates mentioned look too limited but I'll dig deeper.
chrono has strftime and parses the string explicitly char by char in a loop. I'm trying to avoid doing that and was looking for the conventional way to support expand `some-%p-pid` to `"some-39393-pid"`.
Definitely not Rust and maybe not even termion. I'd check the documentation or source of the terminal emulator. Which are you using?
[This](https://users.rust-lang.org/t/rental-0-5-released/17247/3?u=jpernst) being the discussion you were referring to? Hmm, yeah. I don't know a lot about this domain, but `rental` was really the only crate I could think of that could immediately take advantage of this. I hope somebody can find a use for it in the meantime! :)
Good point! I agree that ops/second would be more useful. I'll try and spend some time on that. However, I do think set size is extremely important for benchmarking rbtree, as cache misses and transaction failure rate are really dependent on it. &amp;#x200B; [https://crates.io/crates/rbtree](https://crates.io/crates/rbtree) is indeed the single-threaded rbtree in the graphs. I have also done some benchmarks against `BTreeMap`, I'll try and get that in a commit soon as well.
Excited to see how this series pans out. I have a handful of Adafruit Feather devices and have been keen to see if I could get Rust running on the Cortex-M variety. Is Rust use currently limited to a specific set of development boards? The STM32 Discovery is the only board I've seen any content on so far (I'm yet to watch yours).
&gt; This being the discussion you were referring to? Yes, exactly this one. Good job finding it!
Mmhm, I was using the default OSX terminal, I'll test it with a different emulator!
Would an SPSC queue with a lock on the producer side work here? That would simplify things a bit. The "almost-lock-free" queues I know have strictly better progress guarantees than lock-producer SPSC queues (new producers can't delay "old" messages), so I suppose there wouldn't be any problem with them in that case.
My series is on a Nordic nRF52, but lots of chips from lots of vendors are supported at various levels of completeness. The [Awesome Embedded Rust](https://github.com/rust-embedded/awesome-embedded-rust) is the best listing of things that are supported today!
I think there's a thread on users.rust-lang.org for suggestions.
You mentioned smelly code in the post - got any bugs open for those bits? I'd love the chance to do some cleanup work :) 
How / Why does this compile without error? https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=fc5793706042333e5a72e5a8eb1cd47b I don't understand how GradientSettings.do_stuff can call outside_fn which expects a NoiseHelper&lt;int&gt;, when self is not that at the call site. 
Okay, I've put together a longer example [here in the playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=40d573af06d49fb05bb2644e0292d3d8). `test2()` and `test3()` do a similar thing, one with MyCell, the other with RefCell. The RefCell version crashes.
I think the answer is *probably* no. In the current design, there's a return channel from the RT thread to the rest of the app, for monitoring (and also deallocation, but that's possibly a different story), so that can't block.
Yes, and there is typeORM in node.js which is doing very well.
Is parsing char by char so bad? It seems like a very simple operation and if you want special behavior like an escape (\`%%\` -&gt; \`%\`) then most likely any predefined libraries wouldn't work anyway.
Isn't that what [`Ref`](https://doc.rust-lang.org/std/cell/struct.Ref.html) and [`RefMut`](https://doc.rust-lang.org/std/cell/struct.RefMut.html) are for? If you pass these around instead of your 'context structure', what is the problem?
I discovered the same pattern (I called it *token cells*) during some experimentation with GC APIs. I did it the typesystem way; it just needs a runtime check in the constructor for singleton objects that only one instance is ever created. You can enforce that by only having one singleton object implementation, but getting unique "types" out of it by parameterizing it by semantically empty user-provided marker types.
Perhaps try using multiple redis instances in the same machine and access them concurrently.
Thanks for this, I'm going to pull it into my lemon bar status config.
Because perhaps I'm going to have 1000s of `Rc&lt;MyCell&lt;T&gt;&gt;` values. If I kept 1000s of RefMuts open for them then where would I store them? In my code I lookup some random `Rc`, and want to mutate its contents, but without any risk that someone further up the stack is in the middle of doing the same thing. This MyCell approach is quite restrictive in that it means that no-one further up the stack can be modifying *any* of the MyCells owned by the same owner instance, but if that code pattern can be made to work, then (as far as I can see) this approach would give that guarantee.
Got a question about returning a HashSet: pub fn find(sum: u32) -&gt; HashSet&lt;[u32; 3]&gt; { let mut set = HashSet::new(); .... return set; } let s = find(12); Could I interpret that the returned `set` variable moved from being owned by the function `find` to the `s` variable? Thanks
With `map` all methods maintain somewhat the same meaning. I‚Äôm just pointing out that this method might create situations where the intent is not clear in the middle of code working with Matrices. Was this taken in consideration when stabilizing the API?
You can assume `return` always moves unless there's a reference in the return type or the type is `Copy` (for primitives like integers). A function doesn't really retain ownership of anything once it returns anyways; any values not explicitly moved out of the function scope (by `return` or other means like channels) are implicitly dropped (their destructor is run and they're no longer considered reachable). Types like `Rc` complicate this a bit but they still operate within the ownership framework.
&gt; when self is not that at the call site. [Function calls are *coercion sites*.](https://doc.rust-lang.org/nomicon/coercions.html) pub fn outside_fn(x: &amp;dyn NoiseHelper&lt;i32&gt;) { `outside_fn` expects a reference to a trait object of type `NoiseHelper&lt;i32&gt;`. When you call outside_fn(&amp;self) it will attempt to coerce `&amp;self` (which is a `&amp;&amp;GradientSettings`) to `&amp;dyn NoiseHelper&lt;i32&gt;`. This succeeds, since `dyn NoiseHelper&lt;i32&gt;` is implemented for `&amp;GradientSettings` due to the blanket implementation impl&lt;S&gt; NoiseHelper&lt;S&gt; for &amp;GradientSettings { 
Thank you! Crossbeam was a big inspiration for a lot of the low level details. &gt; Are there any caveats one should be aware of when reading these benchmarks? The number of elements in the red black tree matters a _lot_. Smaller tree size causes more transaction conflicts reducing the overall speed. Larger tree sizes, and random accesses, cause more cache misses, which helps to hide the overhead of the STM. &gt; How did you achieve that level of performance? In the STM: Breaking read/write/etc operations up into fast path/slow path is a big part of it. The write log has a bloom filter which allows swym to quickly check if a read should hit shared memory, or the write log (read after write hazards). The write log, and GC both use a "DynVec" which stores elements of varying sizes contiguously in memory - this helps to avoid memory allocations in the fast paths. There's still a lot of work to be done on the slow paths, and to reduce code bloat. Read only transactions (like in `contains_key`) don't need to maintain a read log, a write log, or have a commit algorithm. Essentially, read only transactions act like an elaborate seqlock. In the rbtree: I used the `stats` feature of swym to look for places where writes to the same memory location happened more than once (slow path), and where reads after writes (slow path) happened. Then I tweaked the algorithm to lower those numbers as much as possible. &gt; The implementation doesn't have too many comments at the moment. Sounds like a good thing for me to work on next :). &gt; Are there any papers one could read to learn how high-performance STM works? `swym` uses a variation of the `per-object` `Transactional Locking II` algorithm: [https://www.cs.tau.ac.il/~shanir/nir-pubs-web/Papers/Transactional_Locking.pdf](https://www.cs.tau.ac.il/~shanir/nir-pubs-web/Papers/Transactional_Locking.pdf) The biggest changes are the addition of epoch based reclamation, and changes to the commit algorithm. The bump of the global clock happens after the write set has been published. This allows reads to avoid doing this step: `A load instruction sampling the associated lock is inserted before each original load`, and only do post validation. The load from the global lock, acts like the initial read from the sequence number of a seqlock. The post validation acts like the final read from the sequence number of a seqlock. &gt; Any future plans for the library? What are other kinds of data structures this STM library would be good for? I would like to improve the garbage collector, and try implementing a BTree. It'd be nice to have HTM support, but from some initial experiments, I suspect it'd mostly slow things down. I really don't know what sorts of data structures would be good for this STM. Just have to write them and see :).
Very nice to see someone working on this!
NoiseHelper&lt;T&gt; is a trait and GradientSettings implements it. When calling outside_fn(), the reference to self is turned into a fat pointer, consisting of the pointer/reference to self and a vtable for functions of NoiseHelper&lt;T&gt;. Rust 2018 suggests (although it is not mandatory) to write `pub fn outside_fn(x: &amp;dyn NoiseHelper&lt;i32&gt;)` to make it apparent that dynamic dispatch is occuring.
That's promising, thanks. How did you check that only one instance of the owner type was created? (A global static atomic counter like I have isn't going to work, if many different parameterized variations of the owner type might be created.)
So much changes!
FWIW the industry terms are State of Charge (SOC) and State of Health (SOH). Capacity and Percentage are misleading because they‚Äôre both percentages.
How do people so consistently have bad takes? Every top reply to this ridiculous strawman of "well all technology contributes to the military!!" is the completely normal, rational reply of "we know that, but there's a difference between directly working for them and making a general product that others benefit from". And don't start with the crap that the developers didn't know what they're getting into, or Microsoft doesn't actually deal specifically with the military, or whatever. That's literally what the original complaint was about. 
But he is funny though :)
Does this version include support for cross-language LTO since [PR 58057](https://github.com/rust-lang/rust/pull/58057) landed recently?
Newbie rust guy. Looking forward to keep my rusty excitement going and make useful projects out of it.
The fuchsia team rewrote the network stack in Rust last year: https://www.youtube.com/watch?v=UfMOOxOGCmA&amp;list=PLgC1L0fKd7UlpVTHVfLYVtudVx8CzbSxW&amp;index=15&amp;t=0s, they are keeping the high-level parts in Go because it make total sense, but for the performance sensitive parts, Rust really has an edge (thanks to LLVM optimizations, complete control on memory allocations and the lack of Gc).
Damn, he is SO obnoxious...
Hehe; I would be sad if `if let p | q = expr { .. }` was the only thing we got stabilized this release ;) still... hopefully y'all feel it's a nice small consistency improvement.
I'm implementing Slog in my program. I noticed that when I write to Syslog it does indeed write to syslog. But OSX has "ASL" (Apple System Log) that has a nicer display in Console.App. So I wonder if there is any kind of integration for Rust? Or did anyone work on that?
I would say that Actix‚Äôs websocket support is pretty good, especially with its actor model allowing easy interfaces with synchronous actions. 
Are Rust and Go communicating via C FFI?
I second this! I'm still learning rust and looking for small things to hone on.
"I can write correct C." Greek chorus enters stage right...
I hate to admit it, but this is actually second only to "no suitably complete Qt bindings" as a reason I write less Rust than I'd like to. It's just too demotivating to have to choose between writing my own migrations from scratch when rapidly iterating on my ideas and having to give up SQLite when I'm already dealing with "I've been using Python for 15+ years and can write it in my sleep. I need to keep referring to the API docs when I write Rust." Even when I'm not writing web apps, SQLAlchemy has [Alembic](https://alembic.sqlalchemy.org/en/latest/autogenerate.html) for Django-like "automatically infer a draft to start hand-editing from" migration support. (I've managed to trigger corruption or some other form of data loss in every non-SQLite embedded persistence solution I've tried that was more complex than "load the entire file from disk into memory, modify, save the whole thing to a temp file, then atomically replace the old version". I was especially unimpressed by how readily the BerkeleyDB option in Python's standard library found itself in a "can't open. corrupted." state.)
I think that immovable types are are a useful enough feature that releasing Pin _is_ a net benefit. If I recall correctly, the design Pin is shipping with was settled in September‚ÄîI think a four month gestation period is sufficient.
*Their* blog üôÇ.
That would be awesome! Thank you, stjepang!
That's awesome! Feel free to reach out on [https://xi.zulipchat.com](https://xi.zulipchat.com/) or the RustVST group's [Telegram Chat](https://t.me/joinchat/BfEhnw0l4386Uzi5elmGrQ). Hopefully there will be a 'public forum' thing setup soon, but nothing set in stone yet.
Howdy! Thanks for sharing; feel free to jump on these [channels](https://www.reddit.com/r/rust/comments/aua2tb/rust_2019_rust_audio/eh6pu5f)! 
The current state is NotReady
Gee, good thing Microsoft sells their tech to moral and defensive armies such as the US and China.
Software engineers need to justify making money off "defense" contractors without feeling guilty somehow.
That interface is pure beauty, plus it shouldn't require a different setup to check my desktop's UPS vs my laptop's internal battery. That said, when I tried running it, it flashes the screen and then immediately exits with a status code of 101. Is it possible that it doesn't truly understand my UPS?
I'm not sure I understand your "however". I'm basically just suggesting flipping the current plots by plotting `1/time`, and relabeling the axis, not changing the benchmarks themselves.
The problem would be that you lose all of the nice graph layout algorithms that graphviz has. Going from a plain graph to a graph that has positions laid out in a way that actually looks good is not a trivial problem.
Same happens with `proc_macro`
It looks like someone *just* published something that might be of interest: https://github.com/mtak-/swym
Just remove lifetime from counter variable.
Apologies, Steve! Fixed it. :)
Updated the benchmarks to show ops/sec
Probably not. My understanding is that every 6 weeks, master becomes beta, and beta becomes stable. If it was just merged, it'll probably be in 1.34 in 6 weeks.
Trying to make a blockchain viz in C++. I'll ask some questions over on r/cpp, but am also considering using Rust instead (dumb std::move, etc. blah blah)
i've been playing for 19+ hours and still don't know how to damage other peoples bases.
The `Iterator` trait is set up to require that a consumer can hold on to every element yielded by that iterator at the same time without lifetime issues. Returning a reference to a field of the iterator that you later mutate prevents this from working, so you can't do that with the trait.
You should build the application with `cargo build --release`, then run it from systemd. The once built, the binary can be found in `target/release/{project name}`.
It's in nightly and works, although the API isn't stable yet I think.
Is there a documentation around it?
It's not written in Go. The kernel is C/C++ afaik and the higher level bits are written in a variety of languages including rust, go, dart and others
The best documentation I've found so far is [this video](https://www.youtube.com/watch?v=9_3krAQtD2k), although it uses a slightly outdated version of the API (all the concepts still apply, though).
Experimental, but with a good amount of work being put in at the moment. The core (bikesheds like await syntax notwithstanding) of futures + async fns is relatively stable and probably won't change much between now and the stable release. The remaining work is in the ecosystem, between updating tokio to use futures 0.3 with [romio](https://docs.rs/romio), modular web frameworks like [tide](https://docs.rs/tide/0.0.4/tide/), and a whole bunch of other projects. If you are interested in contributing to the async IO story in rust, come hang out in the [discord!](https://discord.gg/rust-lang) - there's regular meetings every so often, with the next one on [thursday, 28 feb](https://github.com/rust-lang-nursery/wg-net/issues/90). 
Its error is still thread 'main' panicked at 'called Option::unwrap() on a None value', src/libcore/option.rs:355:21 and note: Run with RUST_BACKTRACE=1 for a backtrace.
https://users.rust-lang.org/t/convenience-method-for-flipping-option-result-to-result-option/13695
Does it support websocket and http2?
I think it's more related to the profile of the software engineer. Even if they aren't high-middle class white males idk if they feel special or what, but you go to programmers circles they tend to be heavy supporters of economic liberalism and a lot of them are socially conservative, status quo apologism is heavy, because the status-quo is not bad to them. With its heavy male environments sexism rampant too. That profile tends do have a "fuck those people" behavior...
Are we ORM yet?
What program are you running?
I think this sentiment is true, but Lin also has not been rushed. The concept had its first birthday just over a year ago: https://boats.gitlab.io/blog/post/2018-01-30-async-iii-moving-forward/
http://areweasyncyet.rs
I've been reading both. They work well in combination.
Does Rc::get_mut/make_mut do what you want? It works for your test3 at least
Awesome! The lookups look very good.
Oh thanks for reminding me that's happening this week! I'll be visiting starting that night and might be able to make it.
Just out of curiosity, why Discored (a proprietary, closed communication tool), when there is something like Matrix and etc.?
This is fantastic. I was working on a brute force WebGL GoL implementation a few months ago. Any chance this is WASM compatible?
So to be more precise this is for windows arm uwp compile target
But in such a case you probably do not want (and *should* not want) the *entire* README file.
I built iron as a web server and query cassandra by typing url. [Cassandra](https://github.com/Metaswitch/cassandra-sys-rs) uses the version that calls cpp.
Set the environment variable RUST_BACKTRACE to 1 in order to find where the unwrap is coming from. There might be something missing that the server expects to always be there.
I've been looking into Actix. Seems like that might be the right tool for this.
I think u are in a wrong place :)
I'm very new to Rust, but I really into it with memory safety, ownership, zero-cost abstractions since I started to learn... Really like the way of Rust. But, day after day I've been doing something with Rust, I realized that so many things I've been doing with node.js and python are the fruits of the well grown ecosystem. On the contrary, I felt like it is a great opportunity to contribute to growing the ecosystem of Rust. I think I'm going to enjoy coding with Rust and make some output with it for a while. Thank you for sharing your thought.
This looks really cool, even if I rarely have a use for it. Do you currently use, or in the future plan on using any of the TSX extensions?
Isn't the kernel based on little kernel which is C?
Is there a method on `Option` similar to `map` that doesn‚Äôt consume the `Option`?