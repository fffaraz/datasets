You said run, and to run, the file must be read.
I'm not familiar with ctor internals, but I think this is the key thing you need to account for: if it's possible for users of your crate to use ctors/dtors without using `unsafe` while simultaneously invoking UB, then you need to find a way to force users of your crate to utter `unsafe` at some point. It sounds like this needs more investigation.
I'm not trying to point better or worse, just that comparing the two as almost equal is a mistake.
100% agree here. Appreciate the feedback.
Yeah, I understand. (The legal situation is a bit more complicated ‚Äî Oracle is claiming that Google needed to do some stuff, Google is claiming they weren't actually required to do it. The courts now get to decide, probably eventually meaning the Supreme Court.) It's just that in a climate where Oracle is litigating against the biggest user of Java, it's hard to say "don't worry, it's an industry consortium". I am significantly less likely to (read "won't") do new work in Java in the current climate: I would rather have a reasonably benevolent language steward like Sun than a climate of legal and technical uncertainty. In that sense, I don't think Oracle has been good for Java. Sun saw it coming and managed to fully GPL its Java stuff on the way out the door. I suspect that if they hadn't we'd be in the middle of a mass exodus right now: nobody wants Oracle to have any control over their operations.
Nice article! Now that Rust is using the system allocator on Linux, is there any need to build portable binaries with MUSL? The Rust stuff is all statically linked, so I'm not sure what MUSL is buying vs linking against system `libc` anymore?
The system allocator is the one provided by a libc. Nothing about the allocator default changes the static/dynamic-ness of linking to libc.
As I understood it the main reason folks wanted to ship Rust binaries statically linked with MUSL was to avoid having both dynamic calls to libc code that used the system allocator and internal Rust stuff that used `jemalloc`. Am I completely confused? Is there some other reason I shouldn't be comfortable with trying to run a binary that links to `libc` on a different Linux box? How is shipping a Rust binary to a different machine different than shipping a C binary? Sorry for all the questions: just confused about the status of this stuff. I have in the past built a Rust binary with MUSL to run on an ancient machine with a weird Linux setup, but I don't recall exactly why anymore.
&gt; How do rust perform? How well does it do in memory allocations? While Rust code can perform great (it's more or less comparable with C), you can write slow code in any language, either because of algorithmic reasons, or because of a poor implementation. You should profile your code and look for any hot spots. &gt; Sending HTTP requests via Unix Socket I think you can use https://github.com/softprops/hyperlocal. JSON decoding and encoding should be easy. &gt; I'm a fast learner but I'd love to know how it is like to learn Rust. That depend on you. Read either [the book](https://doc.rust-lang.org/book/) or [Rust by Example](https://doc.rust-lang.org/stable/rust-by-example/), stick with owned data when you're in doubt, and as here or on IRC for help (or on the other [documented forums](https://www.rust-lang.org/community)).
&gt; Am I completely confused? Yes. I mean, maybe some people wanted that, but that's not the main reason. The main reason has to do with libc versioning. libc is forward, but not backward, compatible. Imagine you compile on a box that links to libc version 4.5 (this is not a real libc version, I'm just picking ones, because I'm too lazy to look up the exact details.) If someone tries to use this on a machine that has libc version 4.7, the binary won't work. This means, if you want maximum compatibility, you compile your binaries on an old CentOS (or whatever) box. With MUSL, the binary is fully statically linked, and so has no such requirements. &gt; How is shipping a Rust binary to a different machine different than shipping a C binary? No fundamental difference, really. &amp;#x200B;
But Rust still depends on libc for many other functions like pthreads, and many more. So we still need to link against musl for complete portability. I recently ran into this problem due to different glibc version on my laptop running Fedora and Production server running CentOs. 
Can you elaborate on your use case? How are you using these arrays? Are they sparse? If you have a multidimensional array with only 2 elements in 1000 dimensions, then you have over 1E30 elements. I‚Äôm just a little confused as to what you‚Äôre actually doing. I think this matters, in your case. Rust has potential in scientific computation, but it is lacking in mature libraries. Python‚Äôs numpy and scipy stack are *very* mature and very fast due to most hot routines being written in C. They also have data structures and methods written for sparse arrays. 
It's been a long time since I've ran linux for daily use, but I love the attitude of this. Never have I thought "my status bar is too slow," but hell, _maybe I should have_
Thanks. I hope I didn't come across impertinent. I've learned so much new stuff just by porting a Python project to Rust the past few weeks (my first foray into Rust).
Not at all! &amp;#x200B; Glad to hear it :)
Thank you for your comment. There should be about 30,000 to 50,000 elements each. But I think I should figure out what I'm actually trying to do. Would comeback when I figure out a better way to ask this question. Again, thank you.
Thank you for your comment! I appreciate and would look into those.
One of the very important crates in rust infrastructure. Thank you for your job.
I think musl has its own libc: musl-libc. So when you build with musl target, `malloc` of musl-libc will be linked in the final binary.
Even from a historical standpoint that's kind of an oversimplification, honestly. With regards to the implementation we're talking about here though it's just incorrect. As an example, [this is actual valid Free Pascal code.](https://gist.github.com/Akira13641/0da9f0a87929b68983708c68ff27b07a)
Also worth noting that `Rc` always allocates the ref counter together with the object, so most reasons for using in-object counters go away.
It's bruce lee's book, basically writing down his notes and pointers on how to make your own fighting style, what works for him, and how he came to find what worked for him. 
You can look at rusqlite: https://github.com/jgallagher/rusqlite/blob/master/src/functions.rs#L305
I'm no expert, but I'm pretty sure people have built Erlang native modules in Rust. You might consider having most of your glue code in Elixir while using Rust just for the heavy numeric computation. In particular, I bet dealing with websockets is a lot more fun in Elixir than Rust.
Well, so does `std::shared_ptr` if you use `make_shared`, so I suspect that's not why OP is using their own counters.
I think the more important point here is that it tries to be async wherever possible. Lots of GUI elements in everyday programs get stuck for "no reason" . We really need the "everything is async because we can!" attitude and every little step counts:)
If you re-export the entire crate, that should make the types more distinguishable from internal types, since the crate namespace would be part of the type.
&gt;bail!("HTTP response status was not successful: {}", res.status()); Sorry could you explain this a bit more please? fn fetch_endpoint&lt;T&gt;(&amp;mut self, endpoint: &amp;str) -&gt; Result&lt;T, Error&gt; where T: DeserializeOwned, { let url = format!( "https://euw1.api.riotgames.com/lol/{}?api_key={}", endpoint, &amp;self.key ) .parse() .unwrap(); let fut = self .client .get(url) .and_then(|res| { if res.status().is_success() { Either::A(res.into_body().concat2()) } else { Either::B(err("HTTP response status was not successful")) } }) .from_err::&lt;Error&gt;() .and_then(|body| { let item: T = serde_json::from_slice(&amp;body)?; Ok(item) }) .from_err::&lt;Error&gt;(); let result = self.core.run(fut)?; Ok(result) } This is my function, the compiler is giving me this error: error[E0271]: type mismatch resolving `&lt;futures::future::result_::FutureResult&lt;hyper::body::chunk::Chunk, &amp;str&gt; as futures::future::Future&gt;::Error == hyper::error::Error` --&gt; src\lib.rs:92:14 | 92 | .and_then(|res| { | ^^^^^^^^ expected &amp;str, found struct `hyper::error::Error` | = note: expected type `&amp;str` found type `hyper::error::Error` = note: required because of the requirements on the impl of `futures::future::Future` for `futures::future::either::Either&lt;futures::stream::concat::Concat2&lt;hyper::body::body::Body&gt;, futures::future::result_::FutureResult&lt;hyper::body::chunk::Chunk, &amp;str&gt;&gt;` Thanks
/r/playrust
It is not entirely true that: &gt;C++ allows, while Rust forbids Rust allows you to express more (lifetimes), and when it can't prove your program is safe - you can go into `unsafe` zone and prove it on your own. In C++ you typically never try to prove safety. You just hope that if you will make no mistakes, the libraries you use will work correctly.
Holy moly I didn't even realize. It's done very well for it to hold my attention that long, lol. I do wish it was a bit more succinct but it was a great read regardless. By more succinct I mean cutting down on the friendly hand-holding stuff geared towards people with very little programming experience. Rust does have a use case for that too, but I feel like the primary (not necessarily target) audience is people who have done some programming in a C-like language already (but lots of people are coming from Python apparently too), and for me at least, it got a little annoying because I didn't know when a gold nugget was going to be in with it. Even then though it was able to hold my attention all the way through, and I feel like it prepared me very well to write software in rust without being confused by the borrow checker. While I have you, let me just say you guys are some seriously smart people to have developed such a good language (documentation included). I have been thoroughly impressed by how well it works, and it seems to me like C++ is now starting its arms race to get the best features rust has included within itself, but they'll never be able to catch up. Mozilla (and everyone involved in moving rust forward) is awesome for dealing such a heavy blow to the bureaucratic tech trust trying to kill everything holy about computing (this might sound a little exaggerated but that's how I see it). Major kudos to you for everything you've done, I appreciate it very much
Don't get me wrong, and no offence to OP, but I suspect he might not be accustomed to modern C++ and know all its features.
Try something like: ```rust client // Fetch the url... .get(url) .from_err::&lt;FetchError&gt;() // And then, if we get a response back... .and_then(|res| { // Can check ranges with `is_*` methods on `StatusCode` // Or for a specific status, `res.status() == StatusCode::OK` if !res.status().is_success() { future::Either::A(future::err(FetchError::Status(res.status())) } else { // asynchronously concatenate chunks of the body future::Either::B(res.into_body().concat2().from_err()) } }) // use the body after concatenation .and_then(|body| { // try to parse as json with serde_json let users = serde_json::from_slice(&amp;body)?; Ok(users) }) .from_err() ``` ...no promises on if the error types align. However, since you're blocking on the request (using tokio-core! it's deprecated, consider upgrading!) , I suggest using [reqwest](https://github.com/seanmonstar/reqwest) instead‚Äîno need to worry about futures, contaminators, and the resulting compiler errors.
Thanks! 
 * The learning curve is _unique_ . I.e. its unlikly another language has introduced you to thinking about lifetimes. * The usability &amp; performance you get with [Rayon](https://github.com/rayon-rs/rayon) gets me exited every time. * [Serde](https://github.com/serde-rs/serde) for serialization * I've heard positive things about [reqwest](https://docs.rs/reqwest/0.9.12/reqwest/).
Do you guys have feature requests? Does anyone want to help with an implementation of Clifford algebra based on nalgebra? 
Lifetimes need to be specified correctly, too, to make things work correctly. C++ proves safety by using the type system. And it seems to work well for me, as far as I can say. I found that it's very easy to catch errors, if using types properly. This is comparable with Haskell. It's not exactly the same, but it's methodically similar. It's virtually the same as with Rust. There are certain categories of errors prevented, if you opt in. And you should opt in adequately, not generally go for the extrapolated general case. There are good reasons not to do this. In Rust, there are equivalently good reasons to use `unsafe`.
Awesome! Proper support for complex numbers is very important for being taken seriously in the scientific community, so I'm excited about that. I would also be very interested to follow the CCD developments - how would I best keep up to date on this?
Sorry, I guess what I said was a little ambiguous. What I wanted to say is: The [gdbmi-interface](https://sourceware.org/gdb/onlinedocs/gdb/GDB_002fMI.html) does not have a (direct) way to help out with tab completion, as far as i know.
40,000 elements in each of 1000 dimensions is about 10^4602 elements. There are about 10^80 atoms in the observable universe. That means that you're asking for an array of size (number of atoms in the observable universe)^57.5 Are you sure you want thousands of *dimensions*? If so, it would make a lot more sense to use a hash table indexed by a struct that derives Hash.
I've actually followed the progress of those (from a distance). Ultimately, I decided against using it because I would have had to reimplement all of the functionality that the gdb "shell" provides already. Still great work, though!
Can you compare/contrast this with per-package `init()` in Go? I feel like I've built/used this sort of plugin model in Go and it was always very straight-forward due to the package-level init() functions, where each plugin package can use `init()` to register themselves into a global singleton manager before application start happens. Just curious if this is roughly that, implemented as a Crate, for Rust. Pretty cool testament to the power the user gets with Rust, as well as a useful construct for all the reasons `init()` is useful.
Ah, I see, thanks. Looks like an interesting approach. The current response parser of ugdb is written in nom. Development was indeed quite painful because of not all-that-helpful error messages (maybe that has improved in the meantime?). I really like lalrpop and use it for any new projects that involve parsing, although I'm not sure if I could have implemented the workaround for the breakpoint message problem (that you seem to have encountered as well) with lalrpop -- I have some serious doubts if the language (including the breakpoint message bug) is in LR(1).
&gt; Also, if you switch to assembly while debugging and single step instruction, the window goes back to source code also, which is probably not what's intented. Should be fixed in the repo now.
I'm working with rocket right now and it does this, notice it uses a feature flag that excludes downloading and compiling the library if not needed. https://api.rocket.rs/rocket_contrib/index.html#reexports
I've been wanting to replace some Python scripts at work that rely on RabbitMQ with Rust applications, but none of the existing Rust AMQP clients fit the bill: I need a client that is pretty robust in the face of weird errors (TCP connection drops out or the server Rabbit is running on goes out to lunch, for example). [amqp](https://crates.io/crates/amqp) is fairly incomplete, and as far as I understand it TLS support is mostly incompatible with its internal implementation. I've played with [lapin-futures](https://crates.io/crates/lapin-futures) some, but I don't really want to write my app using futures (although that story might change in the... future). So I've been hacking on my own client, and it's far enough along that it seemed reasonable to release. I'm not going to get a chance to use this for a serious application for a few weeks at least, but if anyone else wants to give it a spin I'd love to hear about any problems. I can't promise there aren't some embarassing edge case bugs I've missed once the client gets under load, but I'm fairly confident in the design (connections are managed on an I/O thread using mio, and crossbeam/mio_extras channels are used to communicate with that thread). Simple examples are working fine, and I've done a bit of stress testing to shake out a few more subtle cases.
&gt; Javascript is out of the question; it fails in many ways. I must know your reasoning for this. Its surely much better at handling "arrays" than beam is. Actually everything is.
I've never used it, but maybe [Rustler](https://github.com/rusterlium/rustler) is what your searching for ? We've got the same questionning at work, where we recently switched to Elixir/Phoenix, but we'd like to keep Rust for some heavy statistic computations.
An aside about the screenshot. What editor are you using? It looks kinda like Atom in the color scheme and status bar, but it's different enough that I think not. Whatever it is, I would love to know how you've got it setup.
Yep, as I said: the breaking changes are a problem whether you re-export or not. All I wanted was an answer to the question: If the external types must be part of the API, should I re-export them? Maybe there is some confusion over what I mean for them to be part of the API. It is possible for them to be part of the API without re-exporting. eg use them as parameters or return types or public fields or in a bound.
Pretty sure that is Visual Studio Code. Can recommend. 
It is Visual Studio Code with the Material theme, which you can install separately. The menu bar, activity bar and explorer are all hidden, which helps me focus while coding. It works great with RLS!
Cool project! I gave it a quick test and had a couple issues: * under KDE the `Position::Bottom` hint isn‚Äôt working, it always shows on the top * on Ubuntu, the file `/sys/class/power_supply/BAT0/current_avg` isn‚Äôt present (I have `current_now` but idk if it‚Äôs the right thing)
Very cool. Every screenshot I've seen of Code looked way too busy. But the performance of Atom has been painful with RLS. I might have to take the plunge.
If anyone has any thoughts (or a different place to ask!) please let me know :)
A couple of comments. 1) Mocking, stubbing and test double are different things. See : https://martinfowler.com/articles/mocksArentStubs.html. 2) Im not a big fan of conditional compilation the way you describe, by swapping imports. It means your code is polluted with test specific stuff. I have a general rule, independent form the language, which is that everything doing IO (that includes clock, Random, http, File...) should be injectable. That way you can stub and test easily. (Injectable can mean different things depending if you have more an OO or FP codebase)
I don‚Äôt understand what you‚Äôre saying is ‚Äújust very incorrect‚Äù, at least from your example source, but I‚Äôd be happy to learn. To see what the compiler does, we need to look at the resulting assembly, not the source code. I was not referring to explicit use of callbacks in source code (like AndThen and Map in your example), nor was I referring to explicit use of pragma inlines (many in your example), I was referring to how the compiler handles function calls in general - does it reuse functions (via literal calls) or does it inline them? If the source code does not explicitly implement pass-by-callback or explicitly require inlining, the compiler has freedom to choose, and in the case of some languages (Go?) it may rarely ever inline anything as a strategy for fast compilation. It‚Äôs been 30 years since I‚Äôve written Pascal, but regarding what I‚Äôll call ‚Äúpragma inlines‚Äù in your source code .... First off, it‚Äôs nice that the language lets you specify that, but there you‚Äôre taking freedom away from the compiler to choose. Second, from my experience with other languages, you can‚Äôt really take freedom from the compiler. Unless you are knowledgeable in how to write the code in a manner (and use the compiler in a manner) which absolutely prevents the compiler from having any choice ... then the compiler is free to ignore the pragma inline and even callbacks. There are examples when using highest C++ optimization that a compiler may inline explicit callbacks and cause bugs; for example, the ‚Äúfirst‚Äù function which the compiler sees passed into the callback parameter will be inlined into that parameter call there after, regardless that many different functions may be passed in (in the source code) there after. In Ada, there are pragma inline and pragma inline-only; the former is pretty freely ignored by the compiler. Regarding Go, which was my main target of conjecture, given it‚Äôs very fast compile times, here‚Äôs a [link](https://medium.com/@felipedutratine/does-golang-inline-functions-b41ee2d743fa) showing it can inline functions (looking at assembly), but here‚Äôs another [link](https://stackoverflow.com/a/45837940) showing it will only do so for very small functions. Also, apparently Go lacks a pragma inline. 
This is a much lower-level construct than Go's init, _but_ you could probably use it to build something like that. I would love to see someone take a project on to provide 1) per-module init and 2) ensure a stable init order across modules (ie: init all children then init self).
FPC does not inline anything at all, ever, unless you either use the explicit global `{$Optimization AutoInline}` directive, or just add local `inline;` modifiers after method declarations as I have there. They're certainly not "pragmas", not that that really matters. Yes, I look at the assembly, as dumping it to file is just a matter of `fpc -a somesource.pas`. FPC also compiles faster than Go in the *general* case (it is Pascal after all), but certainly doesn't "avoid" user-specified optimizations to achieve fast build times. It's a proper compiler with a proper long list of command-line flags (Go has essentially none at all IIRC) that does what you've said it should do.
I might be wrong but isn't that backwards? Libc is backwards not forwards compatible. Ie if I compile something against libc 4.5 it will work with 4.7 but something compiled with 4.7 won't work with 4.5? Which is what your example of compiling on an older distro version would line up with right? This SO answer says the same thing: https://stackoverflow.com/a/11108336
I probably wrote it wrong, yeah. My bad!
They had us in the first half, not gonna lie.
Does anyone know how I can send and receive strings from WASI... Wasmer allows me to access the sandbox memory as seen here: [https://medium.com/wasmer/executing-webassembly-in-your-rust-application-d5cd32e8ce46](https://medium.com/wasmer/executing-webassembly-in-your-rust-application-d5cd32e8ce46) but Wasmer doesn't allow for the standard library. &amp;#x200B; Also - Looking through the code, how safe is WASI? The [wastime.rs](https://wastime.rs) file for WASI doesn't even allow argv to be sent as-is to prevent leaking information. If I sent a string to a function with an assumed name, can that string be sent off somewhere? In other words, will the wasm file be able to make http calls?
Without looking, I thought that was a reasonable proposal.
You should look
Joking aside, this probably would be a good addition to the prelude actually.
&amp;#x200B; [\#rust-beginners](https://chat.mibbit.com/?server=irc.mozilla.org%3A%2B6697&amp;channel=%23rust-beginners) Here it is: [Stack-overflow](https://stackoverflow.com/questions/55447198/can-you-explain-me-why-this-code-is-necessary)
Today is going to be a long day.
I really like the idea of using compile time reflection with const functions instead of procedural macros regardless of whether this was posted on April fool's.
&gt; Moreover, the expect()method will now become useless. Woah there. There are plenty of places where NP problems arising from arbitrary Rust code interacting with enums prevent you from proving everything safe. How much work with stateful views and dependent types would it take to prove an entire Rust 2.0 compiler and standard library safe?
And so April Fools begins
Wrong subreddit mate
I did! üêÆ
It's just as ram heavy, but in my experience it tends to be faster and have a richer feature set.
`2.0`... Knew it. Rust will never have a `2.0` the next major version is `3.0`
Is that really a legit blog? It's uses the style the rust website but it's not hosted on the official website. Looks fishy to me.
Unused RAM is wasted RAM. It's rare that I've got enough going on at once to actually worry about swapping.
It was a minute of happiness: simplifying the rust language and ecosystem... Now it's gone :P Happy fools' day
The idea that one must read every line of code of every crate you consider using is ridiculous. Hope this is April fools.
r/playrust
My laptop has 16GB so I never have to give a fuuuudge about RAM. Specifically did 16GB so I could run full Windows VMs on my Mac, and ended up rarely having to run Windows VMs. So I just enjoy over 9,000 browser tabs with no lag.
April fools day
I am glad it's April Fool's joke :D
Coming to this a little late. There's a lot of t of discussion on how Rust has similar tools for reference counting but (unless I missed it or didn't understand it) you may not actually need to reference count. Rusts ownership and borrow mechanics are very ergonomic. You won't need to reference count unless you need data to have multiple owners and that's quite rare, esspecially in Rust as you can mutably borrow data. 
Regarding C++ interop, you might actually be better calling out to Rust from Cpp land as Rust can create C bindings for you. 
&gt;simplifying the rust language and ecosystem... Now it's gone :P This post totally got me for a bit, because removing complexity seems great on the surface. But, they already do as much as they can to remove complexity. You can't really remove much at all from Rust without leaving it unable to tackle the problems it made to face. That's part if Rust's purpose: abstraction with the minimum cost possible. Funny though.
&gt;Tao of JKD I see, it's „ÄäTao of Jeet Kune Do ÔºàÊà™Êã≥ÈÅì‰πãÈÅìÔºâ„ÄãÔºåbut i really heard about this book for the first time. I just read „ÄäArtist of Life ÔºàÁîüÊ¥ªÁöÑËâ∫ÊúØÂÆ∂Ôºâ„Äã, it is also the work of Bruce Lee. To say a big word, the Tao i understand with Bruce Lee is the same. :D
It's definitely not as complex as Factorio. :P But, using Factorio as a reference, there does end up being a kind of layer of "in order to do A, you have to first do B, which you can't do without C, which you can't do without D" sort of relationship. And many of those stages involved killing certain monsters repeatedly to gather the proper materials. Mostly, my brain gives up trying to remember what I was working on. I can remember what I wanted to be doing in the end, and I can obviously track the current goal I have; but the I can't remember the path to get to the end. So now I have this item I made, but I don't remember what monster I was going to hunt next to get the next items. I started taking notes and building out a tree of needs to get to the top, but doing that along with researching (either in-game or on wiki sites) what I needed was really frustrating to keep track of everything. I figure a program could do this better. And now here we are, and I've had to write custom deserializers for some of the data and everything. XD
Also, as an ex-game designer, the increasing hierarchy of crafting is a SUPER easy way to add a lot of fairly well-hidden gameplay time to anything. It's satisfying because players can easily make progress and measure that they ARE making progress... but it also takes a long time to gather the base materials to make the intermediary materials to make the high-tier materials to make the item you want. (Monster Hunter doesn't actually have too much of that, but it does have gear that's strong against high-end monsters which you have to hunt mid-tier monsters a lot for; and if you want those mid-tier monsters to go down easier, there's other gear that might be useful crafted from other monsters, which might have their own ideal gear loadouts... So same end result of added play time, I guess. :P )
There is realization in Golang [https://github.com/golang/exp/tree/master/shiny/driver](https://github.com/golang/exp/tree/master/shiny/driver) . I wanted to do something like this but on Rust. Unfortunately I am not familiar with this area of developing. Maybe this link could help you.
&gt; Remove Its Inessential Rust RIIR?
&gt; `Cow::Borrowed` would be exported as U+262D HAMMER AND SICKLE, ‚ò≠. This is because ownership is theft. No further explanation is required. nice
COW FACE SAYS YOU TOOK! ‚öí
Sounds like a good time. Might bring my SO. &amp;#x200B; "Oh hey babe look at this line. See that? They exploited the built-in mechanism to save code complexity. The end result is that the next few lines will look very elegant and impress upon the reader that the one who wrote this is very intel- wah babe? Hey babe where'd you go?"
Suit yourself, but most of my ram is used already on my puny laptop so I'm conscious about resource consumption.
&gt; but there's also things that are more along the lines of "wrong" - ie: using bits of the std library that aren't initialized yet Semantically,`unsafe` means that a trait or function depends on invariants that the compiler is incapable of enforcing and the developer has to take special care to do it themselves. Stuff like "`std` is not initialized yet but the compiler won't stop you from using it" sounds exactly like what unsafe was made for. It's as much a signal to other developers as a compiler directive.
Thanks for reading subreddit description before posting.
Wrong sub buddy
by bad lol &amp;#x200B;
I have one general comment about it, it should be possible to allow user manually supply assets instead of loading from file system (i.e. to allow bundling assets in binary)
I don't understand how this i funny? is it supposed to be funny?
Please don't apologize for taking things out of the language. One lesson that should be really clear by now from decades of programming languages continually adding new features with no cleanup is that the model is unsustainable. Recognizing mistakes or consolidating features is a good thing. Breaking APIs is also why we have SemVer in the first place, no one should be suprised. &amp;#x200B; As for packages, I'm not a fan of the npm model of downloading many packages for all the reasons touched upon. Every time I am going to add a dependancy, I have to go through the source code of the dependancy, and looks at its dependancies and so on. One thing Go gets right ([https://research.swtch.com/deps](https://research.swtch.com/deps)), and which go mod really surfaces, is that dependancies are a risk, and the more you use the riskier your situation becomes, and because packages have a human element to them this risk can't be fully mitigated in software.
I have a little program which fetches rss and atom feeds every morning. Today this program fails to compile on my ubuntu machine, probably due to some OpenSSL change. I get really strange errors at link time. Has anyone seen this, and know what is going on? [https://gitlab.com/snippets/1840831](https://gitlab.com/snippets/1840831) It worked great up until this morning.
if the main issue with lapin-futures was its use of futures, you could have built your library on [lapin-async](https://crates.io/crates/lapin-async), which is the version that can be used directly with mio or any other IO systems. lapin-futures uses it for its internal state machine. Anyway, have fun writing an AMQP client, it's an interesting task :)
[Glass](https://github.com/matrizx/glass). This is an experimental frontend development framework I have been working on written entirely in Rust. It has WebAssembly support and is designed to let you write web apps as fast as possible. Here is a greeter in Glass: ``` :html: :center: :p: Hello, :strong:~return prompt("What is your name?")~/ / / / ``` For more information on it, what it can and cannot do, all of its features, and why I made it, check out the readme, also there are some examples in the repo too. See it here: https://github.com/matrizx/glass
I wouldn't mind seeing match ergonomics go... I know it's an April Fools joke, but imho that feature does bring more complexity than it's worth.
Though they can't replace procedural macros as a whole. 
V2 is more of a clean up thing instead of something very new. :')
I needed a way to get a list of the opened connections in the Linux, so instead of parsing `/proc/net` files I'm trying to write a small Tokio implementation for [Netlink](https://en.wikipedia.org/wiki/Netlink) [sock_diag](http://man7.org/linux/man-pages/man7/sock_diag.7.html) protocol. Stuck with a buffering at the moment.
April fools are really elaborate these days.
What would compile time reflection with const functions even look like though? ...maybe like procedural macros?
At first I didn't like match ergonomics, but using something like Intellij/Clion will tell you what that variable you're pulling in *is*, actually making things easier. You know it's a reference without having to type `ref`.
Add HTTPS to your blog, please. It's free using [Let's Encrypt](https://letsencrypt.org/).
Good proposal, but lacks ü¶Ä emoji's
Very small utility to join multipart video files. Shelling out to `ffmpeg` is straightforward, but I‚Äôm trying to gather my courage to learn how to use the API to do it instead.
&gt; Mono is a problem for C# How so? My company is now a .Net Core shop, and Mono isn't an issue that comes up in any way whatsoever.
My idea of a design would involve values that stand in for types, similar to runtime reflection in some other languages. Something like: const fn foo() { let some_struct: TypeMirror = TypeMirror::of::&lt;SomeStruct&gt;(); for field in some_struct.struct_fields().unwrap() { println!("{} {:?}", field.name, field.type_); } } One problem is that you might want (some of) the API to be available only at compile time, since it couldn't be implemented efficiently at runtime, whereas currently `const fn` can be evaluated at both compile time and runtime. A solution could be to create a new type of function which could only be evaluated at compile time, something like `const(only) fn`. Then there's the question of how to go back from the values to the original types. You could have some magic API like type UnderlyingType&lt;const M: TypeMirror&gt;; However, that has a few issues: - In some cases you might want to use `UnderlyingType` within a generic context where you don't know what the type is, but you do know it implements some trait. Since the parameter to `UnderlyingType` could be anything, the compiler obviously can't assume the resulting type implements anything. But if trait generics become a thing, perhaps there could be a variant like struct TypeMirrorImplementing&lt;Tr: Trait&gt;; type UnderlyingTypeImplementing&lt;Tr: Trait, const M: TypeMirrorImplementing&lt;Tr&gt;&gt;; where the compiler would assume that `UnderlyingTypeImplementing&lt;Tr, M&gt;: Tr`. - The `TypeMirror` parameter would have to be truly `const`, as opposed to the "in between" environment of a `const fn` (where you're running at compile time, but the types inside the `fn` are fixed). You could use it with a `TypeMirror` *returned* from a `const fn`, but that would be somewhat awkward to use if you wanted to, say, do something with each type in a list of `TypeMirrors`. An alternative would be to make generic instantiation into an API itself, something like struct Foo&lt;T&gt; { ... } let foo = GenericMirror::of::&lt;Foo&gt;(); let i32_ = TypeMirror::of::&lt;i32&gt;(); let foo_of_i32 = foo.instantiate_with(i32_); ...but that assumes a form of HKT, since you'd need a mirror of `Foo` itself rather than `Foo&lt;T&gt;` for any particular `T`. In any case, this all would add a lot of complexity, but on the other hand it would be drastically more powerful than procedural macros due to the ability to make use of type information.
Awesome featureset! Will Rust 2.0 come out when pigs fly or when Hell freezes over?
&gt; Ah, the "No true Scotsman" fallacy It's not a NTS if there's a standard definition of what a Scotsman is and it doesn't include the person you're referring to. There's an ISO standard defining C. `g_autofree` cannot be implemented in this standard C. GNU extensions to C are required, so it's not simply C. &gt; Doesn't matter that all major compiler vendors support the feature So Microsoft isn't a major compiler vendor? In fact, only GCC and Clang are major compilers? Now *that* sounds like NTS.
Huh, that's pretty cool actually. But it would add a *ton* of complexity. I wonder what sort of applications would actually need it. Even with HKT/GAT, they're not going as far as they could with implementing it because people won't need most of the features it gives, only a small subset, which would cover the vast majority of things people ask for. It would 100% increase compile time, which already is a bit eh, even if it's been getting a lot better. ü§î
finished the initial video and hot reloading for my platform layer, but it's not back to 100% of the features I had before the sdl2 switch over. some more todo stuff: * controller / keyboard input * save / restore state * input playback * no_std? should all be pretty trivial. the last element that will be hard is sound support, because bleh sound.
Sorry, I'm probably not as familiar with modern .Net as I should be. My understanding was that while .Net Core is fine, there isn't any cross-platform GUI except using Mono. Is that no longer correct? I'd greatly appreciate an update on the current C# situation on Linux boxes‚Ä¶
There's Avalon, but it's in a pretty early stage. I don't know if you can run GTK# on Core. We're just doing web stuff, and since the main topic of this post is Rust vs Go, I figured that GUI was not a relevant topic anyway.
My general feeling is this ...... there is really not that much new in languages. Most new stuff is there to protect programmers from themselves. Most languages these days have GCs. Alternatively they have some form of reference counting. Even C++ now has optional reference counting through the standard library. This is not an accident. Some actual functionality for memory management has to be there whether you obfuscate it with a fancy name or not. As previously alluded to, we can also use arrays and indexes and so forth. In an odd way I'm actually doing this, since my heap has an option for 8 byte aligned 32 bit pointers to save memory (either referenced counted or not) which is my most heavily used pointer type. Even more standard vector / index implementations have some management requirements. You may need to grow or shrink a vector, reuse holes, mark things as deleted etc. Of course some implementations may be better than others for a given application, but I haven't found there to be any magic that mostly makes the problem go away. I don't really think having objects with multiple owners is rare in projects of any size. In fact I find that it happens in nearly every project I work on. If it was so rare, I don't think GCs and reference counting would be so prevalent as built in language features. 
Not with that attitude. 
Yeah me neither. It's too true to be funny. Are they suggesting that code *should* be too complex to understand? Or that there isn't a problem with having hundreds of dependencies? Those are legitimate concerns!
It's getting old this kind of shit. 
And signing ‚ÄúThe Rust Core Team‚Äù (even if next to the April 1 date) on page that imitates the style of the official blog is not cool.
Regarding compile time, I'd guess it would depend on the use. Compared to a procedural macro, this would likely be interpreted instead of compiled. There would be less 'constant' overhead from building a whole separate crate, calling out to LLVM to generate native code, etc.; and you wouldn't need libraries like `syn`. But the interpreter itself would run slowly if you tried to do a lot of computation. Regarding complexity... yep. On the other hand, lots of languages have reflection APIs; they're usually runtime rather than compile-time, but that doesn't make *that* much difference in terms of complexity, especially since some of those languages are based on VMs and thus let you do "compile time"-like things at runtime. For example, C#'s reflection API lets you instantiate generics: https://docs.microsoft.com/en-us/dotnet/framework/reflection-and-codedom/how-to-examine-and-instantiate-generic-types-with-reflection C++ is also slated to get a compile-time reflection API in a future standard based on similar principles (constexpr functions). And for the things it's best suited for, I think code using it would be simpler and easier to understand than using the alternatives Rust currently provides. Namely: - Procedural macros: They're fine if you can figure out what you want to do, so to speak, based purely on syntax. But if you can't, you have to have part of your logic in macros and part in the trait system, and it's ugly as well as limiting. - Type/trait-level computation [(like this)](https://docs.rs/type-level-logic/0.1.0/type_level_logic/strong/boolean/trait.BoolAnd.html): Ewww. Will be better with const generics, but not much.
Good to know, thanks! I think GUI is relevant inasmuch as the cross-platform story affects the popularity of general-purpose languages. It's hard for me personally to get excited about mastering a language that apparently has a single implementation that seems pretty tied to Windows, when so many options are available. For a web shop C# probably make a lot of sense, though: there are quite a few C# programmers out there, I think, and the language seems well-suited to this kind of work. Again, thanks for the update!
This may be April fools, but I unironically want much of what's described. Funnily enough, the dependant type example can already be simulated, but it's even better described as `Option&lt;T, true&gt; = T;`.
If you make two unsafe traits, an implementor just needs to define a unit struct and implement: #[ctor] struct MyModuleCtor; unsafe impl Ctor for MyModuleCtor { fn ctor() { // do stuff } } It's not as concise, but the safety obligations are clear.
It's definitely not going to be allocated on the heap. It is going to be allocated on the stack, but LLVM is extremely likely to optimize it away. In fact, I've just checked the playground, and it's definitely getting optimized to just a constant load: `movl $1000000000, %edx`.
Do you happens to know if it CCD will be used by any rust game engine? 
No. Lifetimes must be specified correctly to make things compiler. When you do it wrong - you don't get memory problems, you get compilation errors. C++ doesn't provide safety by using type system. It only catches some errors. Rust prevents whole categories of errors. With C++ it is easy as ever to do stupid errors that no smart type can prevent. Here is one of my favorite error I found **in production** (names of variables and functions are changed) if (auto foo = get_foo()) { auto stuff = foo-&gt;make_stuff(); lot_of_code_here_that(stuff); } else if (auto boo = get_boo()) { auto stuff = foo-&gt;do_stuff(); // here it was meant to be `boo`. Author copied block from above and changed all `foo`s to `boo`s except this one. lot_of_code_here_that(stuff); } `foo` was never null in tests and error was never caught. Those were some kind of smart pointers, but... it was C++. You can't imagine how much failure that happened one time a day costed to the company. Rust can't guarantee memory safety of your program. But it guarantees that memory error can happen only because of bug in `unsafe` blocks. In my experience in Rust (5y) there are 3 reasons to write `unsafe`: * FFI - all calls to foreign language is unsafe unless you prove otherwise. Most programs will only use safe wrappers. * Implementing safe abstraction. Most programmers will never do this. Almost every program doesn't need reinvent the wheel. * Optimize stuff - only when real bottleneck is found and there is no other way. All this you test extensively before releasing and still can find bugs in corner cases sometimes later. But this happens extremely rare compared to errors in C++. Because amount of `unsafe` blocks in complex program written in Rust is tiny compared to number of potentially unsafe operations in similar program written in C++.
Thanks for confirming. 
I appreciate you mentioning the existence of these glib macros / cleanup attribute and their support (icc, gcc, clang) because I really didn't know about this. This is all very interesting and I will dig deeper. I would probably make use of it, too, but only if I was forced to avoid C++ and Rust. But I would shy away from claiming that "C" could handle this because my use of this letter is synonymous with "ISO standard C" and that standard doesn't even cover any attribute syntax as far as I know. But I see that the role of "ISO standard C" is probably less important given how many compilers support all kinds of extensions. It seems, the role of the ISO standard differs among C and C++.
Can you give me a reason to use https for a simple blog?
TL;DR: less crazy =&gt; a bit but likely not as much as it seems, furure proof =&gt; yes but changing to newer breaking future/tokio version is easy (at last for this case) + futures are even needed with thread pool. But then I still would need to return a future to communicate with the thread-pool (because you potentially call the code from async code) so it doesn't really change that much for the user. I mean sure you could return a handle which can be polled sync or async, but I could (and might) do so with the current setup, too. Internally the code also would not change/get simpler that much as most code inside of the mail crate doesn't touch futures, or wouldn't get much simpler even if you remove futures. Also I potentially would need to rewrite a smtp library which would be just a lot of unnecessary work. Sure, tokio (and futures) will at some point have a new breaking release but "upgrading" then isn't that much work, as you don't need to change all future usages to async-await (actually you can't anyways as long as rust doesn't have a existential-\`impl Trait\` in struct field position) . 
This, but unironically
My preferred way of doing mocking is to have a trait with all the required methods on it. &amp;#x200B; Then you can have trait bounds a la \`struct App&lt;DB: Database&gt; { db: DB }\` and just inject it during setup. If the trait bounds become too cumbersome (which can easily happen) just switch to a boxed trait object: \`struct App { db: Arc&lt;Database&gt; }\`.
Social pressure. If we can make not enabling (or defeating/middle manning, in the case of company networks and ISPs) TLS the same level of social faux pas as lighting a cigarette in a preschool and then handing it around with shots of Jack, the entire internet will be better off. Letting people say "it's just a prototype", " it's just a blog" and so on makes it much harder to make privacy by default actually the default, for example by removing the ability to make unsecured connections from browsers entirely.
It does seem a bit like it's just a list of the author's pet peeves/desires, styled to be deceiving, with the "April fools" labelled slapped to rebuff criticisms ("it's not misleading, it's just a joke").
Don't count me in until enumerate() returns (item, index) instead of (index, item).
To clarify on the answer given be u/K900_: `const` is more like a "guarantee" that something will be evaluated at compile-time. However, in a much wider number of cases, there's a very good chance that LLVM will just end up doing it anyway.
Does it automatically create mocks from UML diagrams?
It'll mock you for using uml diagrams
:)
So ISPs or any other actor I'm between you and the site can't inject evil scripts
&gt; ownership is theft Actually, it's *taxation* that is theft.
This is indeed the correct answer. Source code describes a sequence of *observable effects*, and this is the only contract between the developer and the compiler: the compiler shall produce a binary which will produce the prescribed sequence of observable effects. Anything that is NOT observable does not matter, and the optimizer is allowed to do with as it pleases... generally trying to use the most efficient way of achieving the task.
I found it pretty funny in retrospect just how close this is to not being satire. But it definitely does not read like your average April fools' joke.
I think it's not that code should be too complex to understand, but that in reality it's impractical to attempt to understand all the dependencies needed for a large and/or high level project, unless you have mountains of time you want to spend doing that. Even if we had fewer, larger dependencies, you would still have that problem, just with less choice (less choice could arguably be better or worse). That said, I agree this post is a bit too subtle. It could mislead someone who didn't realize it's an April fools joke.
I started doing a decoder for NOAA satellite images half a year ago. You need to buy an FM receiver for 30USD to receive images from satellites. I want to release version 1.0 this week. Had fun learning to make a GUI using gtk-rs too. [GitHub](https://github.com/martinber/noaa-apt) [Website](https://noaa-apt.mbernardi.com.ar/)
Damn, man. I lost it for an 1 hour. Please don't do this to anyone.
Got me too. I really like dependent types and would love it if Rust (or any popular systems-level language) added those to the language, but I know it won't happen.
This is why projects like [crev](https://github.com/dpc/crev) exist: so that one person can read the code, write up a review, and publish it for others to judge whether a dependency is worthy of inclusion in their projects.
Amusingly enough, Spotify just released this, which is also of note: https://github.com/spotify/NFHTTP
I wrote about how I do this: https://blog.yaymukund.com/posts/how-to-mock-rust/ I never thought to use a boxed trait object like you're suggesting, but I want to try that out!
Awful format for an April's Fool. They're supposed to be preposterous Modest Proposals, not serious contrarian proposals.
This is neat! I also prefer using a trait, as others have mentioned, but this is a good quick n' dirty approach.
I firgot the day. I believed they were deprecating `match`. I am not a clever man
Sir, Your headphones cost less than $100.
you fight like a dairy farmer!
Plenty of access points will inject advertisements (or worse!) into your site, even if it's static
Yes... in other languages that's true. Ownership in Rust is a bit different though, and borrows are different to pointers. It's possible you may still need an Rc of course, it's there for those times, however I've only used one once and I subsequently removed it. Most of the time memory is best managed by ownership. It might be worth playing around with borrowing to see. You can make Rust do the sorts of things C++ can do but then you'll end up fighting it and you won't get much benefit from switching languages. Idiomatic Rust is fractionally slower and significantly bulkier once compiled than C++.
I'd like to add that the definition of "observable" here is highly artificial, excluding many observable runtime characteristics such as timing and memory consumption. It's like that for every programming language, of course. (I think this is worth disambiguating considering the significant, multi-decade misunderstanding over what an "observer" is in quantum physics. Domain terminology doesn't always mean what you think it means.)
me: wow, this crev thing looks cool. me: huh, but this is a strange post. me: *reads comments* me: oh damn, it's an april fool's joke. i wish crev existed. me: wow, crev is at least 7 months old... they sure put a lot of work into this
I think you're spot on. Indeed performance (timing, memory) is often not deemed observable, as it would otherwise defeat the whole purpose of optimizing for it... and the very fact it's not deemed observable causes issues with constant-time operations as required by cryptographic primitives to avoid side-channel attacks.
Hot take: I feel like constant time arithmetic primitives ought to be provided by the hardware.
I released [v0.22.0](https://crates.io/crates/uom) of [`uom`](https://github.com/iliekturtles/uom) (Units of measurement -- type-safe zero-cost dimensional analysis) this weekend. The release had a new quantity, `momentum`, and some new `volume` units from dunmatt and Aehmlo respectively. Also some fixes for incompatibilities between the 2015 and 2018 editions. This week I plan to do more work in my experimental proc macro branch.
Actually thought it was an April Fool‚Äôs joke, but this is real.
Recently there have been a number of people on Twitter talking about following this book using Rust: https://shop.jcoglan.com/building-git/ Maybe everybody is happy just to use this a personal learning experience for now, but I think there will be a lot of interest in a shared project soon :)
I was trying to remember the ones from monkey island - love that game!
We are aware of the situation and are contacting GitHub support. See the [#infra](https://discordapp.com/channels/442252698964721669/443148319431065610) channel on Discord.
back up!
Soft question: What is an X11 status bar? Even a short explain-it-like-Im-five would be nice in the docs, maybe with a link to more info. It saves people time by allowing them to quickly tell if they are NOT the target audience.
Update: The issue seems to have been fixed.
No more async/await, eh? Going Pony style instead? Announced on April 1st? 
combine has a language parsing crate you can use just for parsing programming languages or DSLs.
UML: Universal Mocking Language
This
More to this point, Rust runs on an [abstract machine](https://en.wikipedia.org/wiki/Abstract_machine) that is detached from actual hardware. Code in this machine could just as well be executed with pen and paper.
Or you can use MIRI, if you're only slightly patient :)
=P
Well... that and in the wake of all those Spectre/Meltdown side-channel issues, constant time seems to be only of one many desirable properties.
I've lately been working on Rust libraries for file formats used by Age of Empires 1 and 2: https://github.com/siegeengineers/genie-rs One crate I'm especially happy with is genie-scx, which can read and write scenario files from like a dozen game versions, from early 1997 beta versions to the latest HD edition format from 2016 or so. It still needs more facilities for editing scenarios and creating them from scratch, though. This week I'm hoping to build a writer implementation for DRS, the game's custom memory-map-friendly archive format. It'll be interesting to try to work out a way to write those without having to keep the entire thing in memory. DRS files can easily reach 500MB, and to determine the length of the file header you need to know how many files there will be. We'll see...
"When my enemies saw me, they were petrified" "Oh, is that your face? I thought it was your backside."
If someone does want to go the conditional compilation route, I‚Äôve got a small crate that can make the code less noisy: [test_double](https://crates.io/crates/test_double). Reasons people could want to go this route include wishing to avoid proliferation of generics or trait objects. Hope this helps someone!
Rust caused the disk to oxidize 
I agree with this, but I think having `#[ctor(unsafe)]` might be a better approach than marking a function as unsafe (allowing better communication between developers that it requires extra-special care).
I think they meant to say that Duration::seconds(1_000_000_000) is being instantiated every time the after() function is called.
For April Fool's, imagine if r/rust and r/playrust swapped for a day. That would be insane.
The ISO specification is only a baseline for what compiler vendors have to support, just as Rust lacking an ISO specification means very little to us. Compiler vendors also answer to their users, and agree upon implementing a set of extensions on top of that. Eventually, they take this to the committee to request it to be added to the standard, and point to its shared existence and usage in real world projects as an example for why it needs to be in the spec. Regardless of inclusion in the spec, all that really matters is whether your compilers support the feature or not, and thus whether you can use it in your C software or not. It's supported by the three main cross-platform compilers, so the chances are very high that you can use it. This feature in particular has a very strong case for usage in any C project. 
Perhaps tooling could be help here. Instead of reviewing the entire dependency, you really only need to review the parts that end up in your binary. Which might be very little, depending on the library in question (eg. "utility libraries" like `itertools`).
Congratulations on the release! Have you corrected your ongoing issues with refusing to properly license this as a fork of Askana? For everyone arriving at this page: yarte is a fork of [Askama](https://github.com/djc/askama/) for which the author is refusing to properly follow the License terms, calling it a waste of time, which is especially egregious because Askana is MIT licensed and properly forking an MIT project is the easiest thing in the world. More in the reddit comments of previous posts: - https://www.reddit.com/r/rust/comments/au9o3m/the_more_fastest_template_engine_fork_more_than/eh6uecs/?context=3 - https://www.reddit.com/r/rust/comments/asenye/yarte_yet_another_rust_template_engine_is_the/
It's not a GNU extension to C, nor is it a GNOME extension to C. It's a standardized compiler attribute supported by Clang, GCC, and ICC. Microsoft doesn't support it yet, but that doesn't mean they won't. Microsoft is often far behind the three main compiler vendors in supporting the latest C standards, and their compiler only works on Windows. It's not as important as getting that support in Clang/GCC/ICC, which are responsible for the most C code compiling today, even on Windows. It is a "No True Scotsman" to state that people using it aren't writing C. Next you'll be claiming that no one is writing Rust because Rust lacks an ISO standard. The truth is that the ISO spec means very little to C programmers. It's only a baseline for compiler vendors, which often work together to implement extensions to the language on behalf of their users. Once everyone supports the feature and there are real world projects making extensive use of it (GNOME and GTK applications are the largest consumer of the new feature), they can make a case for the committee to make it part of the next standard.
Is a man not entitled to the cows of his fields?
Isn't the surface of a hard drive disk already iron oxide? 
Working on a Rust port of my 2002-2008 Palm OS sketching/animation app [Ninerpaint](https://ninerpaint.com/).
Were you thinking about using the ffmpeg api through some rust bindings? I haven't made the leap to using rust for the video parts of a surveillance project I'm working on. Another choice is gstreamer. It has an api that's more designed for creating bindings in other languages and has a lot of built-in functionality for clipping, cropping, transcoding, etc.
I think I'm going to move a lot of the complexity into procedural macros instead, trait objects feel way too limited to make a nice API for what I want to do.
I think you're looking for /r/playrust. This is the subreddit for the Rust programming language.
Now \_this\_, as a Rust fanboy, is a RIIR I can get behind!
Can you do an easy-to-use git by the way? 
What's wrong with Git? Isn't it already easy-to-use?
Explaining the index to newcomers on day 1 is a drag in my opinion. Likewise the fact that checkout either moves you to a different branch or clears local changes to a file, is more confusing than it needs to be. Or that "all" (one of the most commonly used flags) is -a for commit but -A for add. There's a lot of stuff like that. As programmers who use it every day, we gloss over the complexity. But if you're a non-programmer who uses it once a month, that can be a lot of pain.
The easiest way to tell this was an april fool's joke was the domain. Maybe it's because of the anti-phishing training we did at work, but the domain stuck out to me, and I was alarmed. &amp;#x200B; Then I realized it was April Fool's...
I think his point is this: Rust borrowing has 0 runtime cost. It is 100% handled at compile time. It compiles to raw pointers. So why incur any extra cost if you don't need to.
&gt; "all" (one of the most commonly used flags) Hmm, I rarely use this flag, and I actually think it's harmful. I like to review all code before committing, so I usually do `git diff` followed by `git add -p &lt;file&gt;` to make sure things like debugging prints and whatnot are not staged. But then that mostly goes to your final point about people who use it occasionally and don't get to know it. But those people can just use one of the many guis that make it a _lot_ more easy to use, where you just click the files you want to stage (or click "all") and commit them.
Hi, I'm Pietro from the infrastructure team. We have been in contact with GitHub on this and they fixed the issue quicky, but they didn't give us the reason why the repo went down. Since it affected only a few repos (and there is no mention of the issue on the status page) I really doubt they're going to say something public.
When working on [compact_arena](https://github.com/llogiq/compact_arena) I found a problem with branded indices: The embedded lifetimes appear to not mix well with recursive functions. I may post about it later this week.
Ah, I see. So this is mostly about reducing inconsistencies and confusion so that Git's interface makes more sense.
Wow! You actually escaped the underscores so that you could show them as indicating italics, instead of letting Reddit use them to render actual italics. I'm impressed. :-)
Reddit's formatting does that automatically if you don't explicitly set the input format to markdown. Snark isn't constructive in any way.
&gt; Reddit's formatting does that automatically if you don't explicitly set the input format to markdown. I see. Is that something new that has come with the redesign? &gt; Snark isn't constructive in any way. Huh? I wasn't trying to be snarky. I was honest when I said that I liked it. I wasn't trying to be constructive either. Not even sure what that would mean in this situation.
Yeah in the redesign you have two different input modes with the default being Reddit's "fancy-pants" format but you can change it to markdown on non-mobile (if you can change it on mobile I do not know how).
April fools gone wrong in github? :) "Just push here to defragment the disk :troll:"
Okay, open issue from 3 months ago, so this is no April Fools
Just as a precaution, have you tried `cargo clean &amp;&amp; cargo build`?
Can it rename my entire Music folder according to the rules?
Anecdote time! :-D When Microsoft Office 2007 came out, they decided to redesign the classic menu bar (File, Edit, Tools...) into a collection of buttons that they called "The Ribbon". Naturally they wanted to biggest and most prominent buttons to be the menu actions that people used most frequently, and they had plenty of telemetry data to know what those actions were. So guess what the very most frequent menu action was? The one that became the biggest button in the ribbon at the very top left? [paste](https://imgur.com/a/WLm4UJd) Never in my life have I, or possibly has anyone I know, ever used paste from the menu. Paste is Ctrl-V, _everyone knows that!_ Except that not only does everyone _not_ know that, but so few people know it (and paste is so widely used) that it's the most frequent menu item of all. They told this story to every new engineer in Office, to make it clear that the intuitions we have about using software are pretty widely off the mark for how typical users use software in real life. Frequency of use is one of the differences, also whether you have people around you who can answer questions and give you feedback, and whether you're familiar with any other software that uses similar metaphors.
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/qPpbtVm.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20ejvse6j) 
Clock is the IO that I have to hammer home on newbies so often it's mind numbing. Yes, it really is an external IO! Yes, it is important to test it! After a single 'why does the program fail to work on leap year' debug scenario example, they learn. They learn! &lt;twitch twitch&gt; Sorry. Personal hot button.
We thought we were mocking, but really we were being mocked the whole time. 
Welp, they didn't want long to release the product they're likely using as the backbone for their fork: https://blog.cloudflare.com/1111-warp-better-vpn/
Taxation can only exist because private ownership does.
Yeah, this is great!
[WYSIWYG](https://en.m.wikipedia.org/wiki/WYSIWYG)
&gt; I see. Is that something new that has come with the redesign? I think so, the redesign is pretty buggy crap. It also likes to insert invisible spaces that cause extra new lines to appear. God knows why. More annoying is code blocks only work on the new design, and look horribly broken on the correct design.
We've since asked the author to remove the misleading branding, and they've complied.
&gt; More annoying is code blocks only work on the new design, and look horribly broken on the correct design. I have not noticed this, except in some subreddits, so I have ascribed that to subreddit-specific CSS. Let's try some here: register n = (count + 7) / 8; switch (count % 8) { case 0: do { *to = *from++; case 7: *to = *from++; case 6: *to = *from++; case 5: *to = *from++; case 4: *to = *from++; case 3: *to = *from++; case 2: *to = *from++; case 1: *to = *from++; } while (--n &gt; 0); }
&gt; to make sure things like debugging prints and whatnot are not staged I review all my commits but almost always commit everything because I work on one thing at a time most of the time and commit frequently. I let my debug print statements be included. I use git a lot and mostly only use a few commands. I use these so much that I have since long been using Bash aliases for all of the commands that I use the most. alias st='git status' alias dp='git diff' alias di='git diff --cached' alias aa='git add -A' alias cm='git commit -m' alias pu='git push' alias le='git shortlog -s -e' And a few that I use rarely alias nc="git commit --allow-empty-message -m ''" alias ra='git commit --amend --no-edit --reset-author' alias pc='git log -n1 --pretty=fuller'
I haven't read the code, but how about `games_guard.into_iter().filter(Game::is_active).map(|g| { g.tick(); g }).collect()`
[Here you go](https://sdg.csail.mit.edu/projects/gitless)
I use it all the time while simultaneously caring about my commits (check any of my recently maintained projects such as ripgrep). The secret is that there can be a difference between development commits (how did I get there) and logical commits (what and why did I do). Sometimes I can skip straight to logical commits if I know exactly what path I'm going to take, but sometimes I don't. In those cases, I do a lot of `git commit -a -m "progress"` or whatever. Before that gets merged, I rewrite/squash the commits so that they turn into their logical form.
I believe that you are looking for [warp::reject::custom()](https://docs.rs/warp/0.1.14/warp/reject/fn.custom.html). It may help to take a look at the [errors example](https://github.com/seanmonstar/warp/blob/master/examples/errors.rs) found in the repo. That example should make it clear that you should handle each error variant by rewriting it into a reply and setting the proper HTTP status code inside of a function like `customize_error()`.
I tried it with smart pointers. Compile error at the right place: a.cpp:35:21: error: no member named 'do_stuff' in 'A' auto stuff = foo-&gt;do_stuff(); ~~~ ^ 1 error generated. `class A` does not have `do_stuff` just `make_stuff`. And smart pointers cannot be null when using the proper methods. They can be empty when circumventing pointer management of course, but if you circumvent it, you need to be the manager yourself.
You are looking for r/playrust
No, not those code blocks. markdown codeblocks, like this ```rust fn main () { } ```
use a gui?
Most of these are gittish, not rusty, which just enhances the impression of just how drink you are.
If it's a specific list of traits that you find yourself repeating, there's a hacky workaround until trait aliases land: pub trait Vector : From&lt;f64&gt; +Add&lt;Self,Output=Self&gt; +Mul&lt;f64,Output=Self&gt; +Div&lt;f64,Output=Self&gt; {} impl&lt;T&gt; Vector for T where T : From&lt;f64&gt; +Add&lt;Self,Output=Self&gt; +Mul&lt;f64,Output=Self&gt; +Div&lt;f64,Output=Self&gt; {} 
Thanks for including a lib portion for those of us who would like to gain git integration in our projects, but not necessarily wanting to require everyone to link to libgit for it.
Even as someone who's been using it daily for a while I get tripped up. It mostly drives me bonkers because seemingly similar commands and flags have very different effects. &amp;#x200B; Conceptually git seems simple in my use case, but the swiss knife commands that constantly get in my way
I didn't read it as snark, FWIW. But on the other hand, it's April Fool's Day, AKA the worst day to be on the Internet. I can imagine anyone online right now would be reading the worst into everything out of sheer annoyance.
Your comment and his comment look exactly the same to me.
I am very happy that kill on sight is not allowed so that I might feel more comfortable asking any programming questions on your noob friendly servers. :)
Why do people even use Git in the terminal. It's just objectively harder and less efficient to work with than with a GUI.
You want /r/playrust
Thank you for your reply. I've seen this example, but I don't get how to use it: my endpoint call `create_user` which might failed (username taken for instance). In the error example, it seems that the defined errors are tight to a path as well, so to trigger them, we have to query `http://server/oops` for the `Oops` error.
Yes, I figured I would use `ffmpeg-next`. I know nothing at all about its API, so I would have to learn. Thanks for the tip about gstreamer, though. It looks like it might be a better fit.
I read the first edition of "Mastering Rust" some time ago. It was my first book about Rust and I learned the basics. It didn't use rust for some time after reading it and now I am starting again by reading "The Rust programming language" which in my opinion seems to be better at explaining things. I would say Mastering Rust is one of the better books by Packt but still far from perfect.
Rust statically links all Rust code by default. Most Rust programs depend on libc, which is dynamically linked by default. Additionally, if the programs call out to C libraries, it's up to the author to have chosen dynamic or static linking for them. There is no workflow to force a re-build.
&gt; Are programs such as CLI tools installed via cargo typically using static or dynamic linking? Rust dependencies are linked statically, C ones are either static or dynamic, depending on the build configuration. &gt; If dynamic, what's the workflow to force a re-build when system libs are updated? You don't need a rebuild for dynamic libraries, but for static ones. I don't think there's any workflow. You'll need to rebuild it yourself. &gt; Know a mature example of fully fledged linking options in the wild with lots of static/dynamic and platform switches? I've used `libsqlite3-sys` as an inspiration.
This will be fantastic for forensics! :) I'm sincerely hoping that eventually an open-source friendly ecosystem for forensics will take off, once people realize that Rust has a significant value proposition in that space.
["New" Reddit](https://screenshots.firefox.com/7xugXG5eQCSVbigA/new.reddit.com) vs ["Old" Reddit](https://screenshots.firefox.com/P0ejT9Lx5P4EwYWW/www.reddit.com) Most old farts use "Old" Reddit because it's the way it's been for years, but it lacks some useful features, and features some odd things like avatars.
OP hasn't noted why this is relevant, but if you go down a few paragraphs the article starts with this: &gt; Another interesting thing about Gleam is that its compiler is written in Rust. .... ...and then goes into more detail from there. :)
Why is the markdown parser interpretation different for New and Old reddit? Shouldn't that be completely orthogonal? And, if anything, shouldn't it depend on whether the writer used New/Old reddit and not the viewer? Now you can't know if your post will format correctly unless you view it on both versions of reddit.
Thanks, this worked great!
As a rough guess, it's just because they want to sell the redesign, which enables more advert space. Also, there's a lot of unofficial Reddit clients, like /r/syncforreddit, which also feature some oddities of Markdown. But yes, the most pragmatic solution would be backporting and probably using the CommonMark spec.
currently it does not let you rename files and folders. How do you see the feature can be working ? &amp;#x200B;
Is that a recent-ish book? I can't find a publication date.
I learned mercurial for work last year (after using git for many years) and the UI is generally much better. All the commands use a more consistent vocabulary, so you can more easily learn the whole tool at once. I was used to the git UI, but learning hg made me realize how disorganized git is. Also, mercurial has much better support for rebasing workflows. E.g. when you amend or rebase a commit, the new commit "obsoletes" the old commit, and hg keeps track of this metadata. With the standard evolve extension, hg can automatically rebase everything based on an obsolete commit to the newer commit. Once I learned about this with hg, I tried something similar with git, but git doesn't track that metadata, which makes it very difficult. Also with git, you can orphan commits easily this way and it is difficult to hunt them down again. hg has these really nice visualizations that show your active work and include orphaned commits and why they are orphaned.
A GUI makes me grab the mouse/trackpoint. This is already too much effort to me. And learning the shortcuts for a single git GUI kills the point, because then I'd just as well use the terminal.
I'm also pretty excited about this! I've seen some crates already from this fellow [https://github.com/forensicmatt](https://github.com/forensicmatt), and we're considering porting some performance sensitive ones as well at my workplace. &amp;#x200B; I hope we could share more of these!
AFAIK "fancy pants" as a term is somewhat common and synonymous with WYSIWYG. Though I think WYSIWYG is more common, especially with old hats. Reddit officially calls their WYSIWYG editor the fancy pants editor.
Wow, so new Reddit has a compliant Markdown interpreter!? Propper support for fenced code blocks is _almost_ enough to get me to switch. Now they just need to fix performance and bring back custom CSS.
Keyboard chords for a GUI are way fewer keystrokes than the terminal commands. And I type like 120wpm and even I think it's faster to look at the GUI on my screen to see the diff of a particular file than actually issuing the terminal git diff command and then trying to parse the more confusing text-based output.
Off topic, but the fact that Gmail was launched on April Fools Day should give you at least some optimism.
I already know the relevant git commands, and I can autocomplete them. What I think is what I write. What I'm opposing is your statement saying that GUI is objectively more efficient and less harder. You can see how many 'I's we are using in our sentences. That alone suggests it's a personal taste and practice, which is subjective.
Thanks. That was it. I don't know what broke, but it is fixed now.
This is just an absolute...*mockery*!
&gt; Reddit officially calls their WYSIWYG editor the fancy pants editor. Interesting. That I did not know.
Yeah, I came here to quickly respond a second time saying that I don't want to come across aggressive. Clearly it works for you. It just confounds me personally. But Reddit told me I'm responding too quickly, so now I have to wait a few minutes before letting you know I bring you no harm :D
I've got it at lets remove match statement from the language. :D
You son of a silly person.
Rusty like out of practice :P
Awesome! I'll probably integrate this into my project at some point - I didn't have time to build it myself. I wrote a simple sysmon parser as well, it's not great and I'll probably review your code to steal ideas on how I can do it better.
Agreed. How much of forensics is just parsing data into a readable, indexable format? Like, a *ton* of it. https://github.com/insanitybit/grapl My D&amp;R service is primarily rust, and it's been a great fit for the parsing.
Do we have intuitive repos within repos yet?
Can you imagine that both function existed and it was only one class? &gt; And smart pointers cannot be null when using the proper methods. `std::shared_ptr&lt;T&gt; foo;` How is this improper?
To further expand my explanation, `map()` is used to handle requests that don't fail, while `and_then()` is used to handle ones that can. So you can use warp::reject::custom(ServerError::Variant) in an and\_then() combinator, and rustc should be happy to compile that. as an example: let create_user = path!("user" / String / String) .and_then(|u: String, p: String| { user::create_user(u.as_str(), p.as_str()) .map(warp::reply::json) .map_err(warp::reject::custom) });
Or probably /r/playrustservers
Parsers are the single most important bit for forensics. After that, there's some analysis (i.e., correlating data and events from different sources) that might be interesting to share, but everything beyond that point I'd say is mostly product-specific. Something that might be interesting to standardize is an entity-attribute model that abstracts over disk-based file systems, file-based file systems, and the interesting parts of their internals. Standardizing the "streams" associated with different forensic points of interest and making a framework for browsing them is the most common domain-specific reinvention I've seen. That's because it's hard to get everybody to agree on how things should be structured, but that's exactly what a standard should be for!
You'd think so. I know when the redesign first came out and started gaining steam, it straight up broke a "feature" of markdown I was relying on to store information.
&gt; Parsers are the single most important bit for forensics. After that, there's some analysis (i.e., correlating data and events from different sources) that might be interesting to share, but everything beyond that point I'd say is mostly product-specific. Agreed! &gt; Something that might be interesting to standardize is an entity-attribute model that abstracts over disk-based file systems, file-based file systems, and the interesting parts of their internals. Can you elaborate on what you mean here? Perhaps an example? That bit is confusing, but in terms of 'standard model' - I wonder if adopting MITRE/CIM schemas is relevant?
This is what I finally went with, re-exporting typenum entirely (\`pub use typenum\`) instead of only re-exporting individual types.
Lol, when writing the blog post I thought: I should really put in the Wikipedia link to Mocking, so that I give readers a hint that I know what I'm talking about and nobody lectures me around differences between mocks, stubs etc. :-) Mocking is the umbrella term for replacing dependencies during tests. Mocking is the term used by all mock frameworks in all languages that I know of, even if they support fakes, doubles, spies and whatnot. So I think just using the word Mocking here is fine. In general I agree with your second point, but it has tradeoffs. Using a trait instead of the type std::time:Instant would require to write a lot more code and make the code harder to read. Conditional compilation allows me to keep it simple while still mocking dependencies during tests. With just one additional line in the use statements that is quite an effective tool I like! &amp;#x200B;
What are the main differences between your crate and [slotmap](https://crates.io/crates/slotmap)? Any major design differences or tradeoffs?
You can try [xmlparser](https://github.com/RazrFalcon/xmlparser) instead of `xml-rs` to make it even faster, if XML is a bottleneck.
I'm working to get [my S-expression library](https://github.com/rotty/lexpr-rs) ready for 0.2.0, which will bring initial serde support, more datatypes (such as vectors, byte vectors, and characters), proper string syntax, and more.
Might be cool to support dual numbers for [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation#Automatic_differentiation_using_dual_numbers).
I've made a tool that might help with that! https://github.com/timClicks/bin2src It is a command line tool but if it's useful I am sure that it could be changed to become a library
&gt; gtk-rs This is very interesting.
I imagine the snake case convention could automatically convert from PascalCase, for one example.
Thanks for writing this up!
Should be an alias for `std`.
&gt; Can you elaborate on what you mean here? Perhaps an example? &gt; That bit is confusing, but in terms of 'standard model' - I wonder if adopting MITRE/CIM schemas is relevant? It's abstract, and I'm not surprised that my explanation flopped. :P Perhaps you can help me word it better! So, if you look at something like FTK, [FTK Imager](https://accessdata.com/product-download/ftk-imager-version-4.2.0) ([screenshot](https://www.researchgate.net/publication/321665847/figure/fig3/AS:569131759673346@1512702993521/Screenshot-of-FTK-Imager-showing-its-image-directory-preview-FTK-Imager-allows-the.png)), or [Autopsy](https://www.sleuthkit.org/autopsy/) ([screenshot](https://www.sleuthkit.org/autopsy/images/v3/overview.png)), you'll notice that everything is exposed as an enormous tree. Nodes can have properties set on them, and they can have children representing their parsed internals or some derivative view into the node's contents. This tree model is what I'm talking about. It's pretty straightforward for most applications to browse composite tree structures like this, and I think that defining an API for traversing that tree structure and what the set of node properties can be is what needs to be standardized. This would let developers focus on the interesting part of a product: how to present the data to the user. --- Warning: entering rant mode! If you look at the product screenshots I linked above, notice that each node can have one or more human-friendly representations -- FTK, Imager, and Autopsy do media and hex views out of the box, and FTK/Imager try to present specialized things as HTML tables for the "human-first" view. THIS should be the focus; there's LOTS to do in this space, and I've seen so much time wasted on reinventing components like parsers when more time could have been spent on the user experience. It requires tons of expertise to create correct parsers for proprietary formats, and it requires a ton of expertise to figure out how to turn parsed data into a coherent UX. The thing is...most of the time, the backend (parsing and organizing) is largely the same. I think it's silly to require that a company develop a workforce for both sets of expertise -- they're huge verticals to plumb! If there were an open-source community around writing forensic parsers and plugging them into a nice framework, it'd really speed up everybody depending on the parsing aspect of things.
Yes, there is nothing managed in the shared_ptr. You can dereference it safely, but you should not use it. Also don't forget that default is mutable. I would need to see an example that you cannot mix up two mutable references in Rust under the same circumstances.
I thought it was obvious from the way OP's title trailed off, but it does seem more appropriate to make it explicit.
`and_then` solves the issue! :D As for the error being tied to a request, I was referring to the example https://github.com/seanmonstar/warp/blob/master/examples/errors.rs. I though that ``` let nope = warp::path("nope").and_then(|| Err::&lt;StatusCode, _&gt;(warp::reject::custom(Error::Nope))); ``` defined a query that returns the error. I am wrong?
4 spaces are the og, markdown codeblocks. Three backticks is an extension by GitHub and some other platforms. The Reddit syntax is pretty much original Markdown. In fact Aaron Swarzt, Reddit co-founder, was also involved in the creation of Markdown. 
Last month. I heard about it when it got released, but Goodreads has the publication date listed if you want a source: https://www.goodreads.com/book/show/44128595-building-git
https://youtu.be/ToBqbpm3LDM
http://fitzgeraldnick.com/2018/12/13/rust-raps.html
I'm a fast learner and can usually pick up a language in a week or two, but Rust took me probably 6 months of heavy use before I felt comfortable enough to do something real. So in my experience, it is much more difficult to learn than most languages, and that has everything to do with how to structure programs and work with the borrow checker. The rest of the language is pretty elegant and straightforward. With that said, I have no trouble doing almost anything in Rust these days because I have absorbed the ownership model in my brain, and naturally structure programs with data flows that are compatible with it. It is a very rewarding experience once you get high enough to see over the fog, but it is a steep hill to climb.
\`If Let X\` indeed. &lt;3
Oh, yes, I see. So standardizing and abstracting further above some key forensic areas like file carving, not just at the parsing level, but more at the semantic level where we derive most of our value. That sound right?
Yes - too good! I will be singing this for days! 
Well, TIL. Still, whatever it was originally it's evolved, and we've got CommonMark now, and it's kinda rude for reddit to give the redesign nice stuff like that and not the sane design. should be orthogonal to their design anyway
üíØüíØüíØüíØ`git commit -am wip` basically every time the tests pass
Rust involves very little praying in my experience lol 
I hate April Fools' Day. Some of the stunts can be vaguely amusing. E.g. Stack Overflow has temporarily changed its style to look like an early 90s web page. Some people might like it, but for those who don't, it's obvious that it's an April Fools' stunt and it's easy to disable. So, not so bad. But this kind of post, that's right on the edge of plausibility, that contains a mixture of true content (`crev`is a real thing, faster compile times would be good) and false content? No thanks. Lying to people, tricking people, confusing people, worrying people? No thanks. It's not funny, it wastes people's time and attention, it's disrespectful. Please stop.
I just enjoy getting hung up over technicalities and it's funny when people complain about Reddit not supporting Markdown when there is no major platform with an implementation that come closer to actual markdown then Reddit.
I agree. I see the video was \`Published on Oct 27, 2016\` -&gt; maybe back then it did? 
 lazy_static::lazy_static! { static ref MOCKS: Vec&lt;&amp;'static str&gt; = vec![ ‚Ä¶ ]; } Now you‚Äôre just *asking* to be mocked for using a lazy static and heap allocation. You should use this instead: static MOCKS: &amp;'static [&amp;'static str] = &amp;[ ‚Ä¶ ];
The long con
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/charlottesville] [Rust Meetup in Charlottesville](https://www.reddit.com/r/Charlottesville/comments/b8atvc/rust_meetup_in_charlottesville/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I mean, if we're going for technicalities theres not really such a thing as "actual markdown", is there? What with the lack of an "official" spec, the canonical description being ambiguous, and the original perl implementation others based theirs on buggy?
I'm guessing that this thread isn't the right place to start learning rust.
Amazing, are there more books like this?
Cool thanks! 
Is rust git yet?
&gt;I wonder what sort of applications would actually need it. Would help our cause, I think. We model pretty complex data structures (complex in terms of amount of data types and fields, the types are pretty straightforward structs) and having some sort of "reflection API" would help a lot. A lot of functionality we have (JSON serialization, XML serialization, validation, etc) could be expressed as generic algorithms against that "reflection API". Currently we implement that API via procedural macros, but that generates whole bunch of code. Would be even better to have some sort of const table with metadata in it. I guess one can say that maybe Rust choice is not the best for us, and I wouldn't call them wrong here :D I did some experiments with generating such metadata table using procedural macros, but it uses some pretty sketchy things (which I'm pretty sure have UBs, too). Like constant expression / macro to get vtable reference for a given type at compile time or same thing for getting field offset. Unpacking `Option` at runtime using some metadata is fun, too.
Yeah, I think I misunderstood your initial claim. This filter will always return that specific error, and you would likely never want this in practice.
In my experience the best place is: [https://doc.rust-lang.org/rust-by-example/](https://doc.rust-lang.org/rust-by-example/). 
That, and maybe the schoolhouse-rock-does-rust videos? ;)
That's not a bad idea. I actually did something like that when I coded my original GUI library on the Atari, and I had to store the ICO data in hex. (Of course, I also had to create my own multi-color icon library, but that's another story.) I'll consider it and make an issue for a later release. Thanks!
This might assist with my serde functionality for taking Icon data and dumping it when creating my GUI-based editor... Thanks!
quick-xml is the fastest one in most benchmarks.
It is: [https://vlang.io/play](https://vlang.io/play)
Is this API safe to use? #[repr(C)] union U8sOrU16 { u8s: [u8; 2], au16: u16, } impl U8sOrU16 { fn as_u16(&amp;mut self) -&gt; &amp;mut u16 { unsafe { &amp;mut self.au16 } } } #[cfg(target_endian = "little")] impl U8sOrU16 { fn as_hi(&amp;mut self) -&gt; &amp;mut u8 { unsafe { &amp;mut self.u8s[1] } } fn as_lo(&amp;mut self) -&gt; &amp;mut u8 { unsafe { &amp;mut self.u8s[0] } } } // similar for big endian
It's a made-up word from *Stranger in a Strange Land* that has enjoyed some popularity in nerd circles, for reasons unclear to me. (In fact, usually it just means "to understand," though in the book it is sort of more thorough than that.)
&gt; But if you're a non-programmer who uses it once a month, that can be a lot of pain. Introduce it with some documentation/video providing visuals, and some cheatsheet document for referencing. Alternatively if no one is opposed to it(some seem to be really against the idea), introduce a nice git GUI like GitKraken(not exactly nice when it comes to resources though..) and/or some related tools such as Meld (GTK based diff tool) or P4V Merge(a better visual merge tool than Meld offers), both are free to use and have some nice settings for controlling/ignoring certain things like whitespace handling. Some people will remember/learn the actions better with a visual memory which is especially useful if it's not something they're doing frequently. When it's more practical to switch to CLI they'll be comfortable/familiar with the process they'll frequently be dealing with that the differences that you bring up will be less of an issue.
I believe so, yes, from my reading of [the RFC](https://github.com/petrochenkov/rfcs/blob/8f1a960844b6ae37ec19fd89d39355fa98b1bb2b/text/1444-union.md#type-punning). The tricky parts about unions are Drop types, panic safety, invalid bit patterns, uninitialized reads... I don't think any of those apply here.
&gt; What I'm opposing is your statement saying that GUI is objectively more efficient and less harder. Generally a GUI tool is useful for someone who wouldn't frequently be using a CLI tool to the point that they have no friction to the various incantations that must be remembered(not a problem when you frequently use something). It can also depend on the type of person, but it's not uncommon that someone will visually remember a series of actions(position/location, icons/glyphs/colours, etc) vs series of text commands and flags. I for one often forget about proper usage of a CLI tool beyond the utter basics if I haven't used it for several months(and there's a lot depending what you're doing, on linux various utilities or CLI tools I'd use when troubleshooting something or doing one off commands, sometimes the desired result requires spanning multiple of these, each with their own short flags). At the time of working with them, they're used so often on a frequent basis that it seems silly that I should even document them in case I need to do the same thing again in future (like nmcli for managing network, or journalctl for tracking down a problem). I'll end up having to look those up again (which gets more complicated when multiple options are involved and spanning multiple tools via subsequent commands or piping input/output and the like). Give me a GUI tool though, and there's a better chance I'll remember what to do faster than figuring out what series of incantations I used in the terminal. Good examples might be the file browser, certain quick operations especially within the same location on the system without much navigation involved, CLI can be great, but when it gets more long winded, there's a good chance I'll prefer GUI. I know Vim and Emacs are popular, but as I don't use them my productivity would take a big dive, still I sometimes find myself using nano or less for quick changes/look (or echo and grep). I think they both have their place for being "more efficient and less harder", just depends on context.
While this subreddit is the the programming language, /r/playrust would probably enjoy your content more than us language enthusiasts.
I've been using it for years. But just yesterday I did `git reset --hard HEAD` and then ran `git diff` and there were still differences. I don't understand why.
Very interesting. I've been thinking about a crate that would simplify path handling, because I find the `Path` and `PathBuf` API to be really annoying to use. Your crate would probably be a great basis for it. A thing that is pretty hard to do correctly is reading from a `Read` into a `Vec&lt;u8&gt;`. You need to mess with unsafe and `set_len` since `Read` reads up to the `len()`. It would be cool if `BString` offered a safe interface to read bytes up to its capacity (instead of its len).
I just finished my study of Rust-by-Example. The hard way typing up the examples and debugging my typos since I don't have a coding background. Now I'm diving back into 'The Book' chapters after the guessing game and also started 'Rustlings'.
Happy Cake Day!!!
wat
Thanks for this anectode ! Of course, everyone knows nobody checks the diff before commiting stuff. And code quality in lot of repositories demonstrate that. :-)
Thank you! Saved me from having to do this :) I wonder if a `format!`/`Display` for bstr might be useful. I am surprised by this In other words, bstr is partially a way of pushing back against the micro-crate ecosystem that appears to be evolving. It's not clear to me whether this experiment will be successful or not, but it is definitely a goal of bstr to keep its dependency list lightweight. For example, serde is an optional dependency because there is no feasible alternative, but twoway is not, where we instead prefer to implement our own substring search. In service of this philosophy, currently, the only required dependency of bstr is memchr. I see value in cohesive, high level APIs like this (which is why I was my motivation for wanting to implement this) but I suspect there is benefit to still offering low level algorithms so someone doesn't need all of bstr for an algorithm.
I remember Linus said something similar to this : git is not a tool, it's a bunch of API. Just imagine we type twitter api manually in terminal to tweets.
I am trying to implement needle in a haystack algorithm, basically just see if a string has a match in a text. &amp;#x200B; The algorithm is as follows: - for i in text.len - if text[i] === string[0] - for j in string.len - if text[i + j] != string[j] return false - return false &amp;#x200B; Now I understand that in Rust I need to use iterators. So I currently have two iterators. One is text iterator and the other one is string iterator. So the idea is, first create an outer text iterator. Run the text iterator as the outer loop to get the text iterator starts from the current element of the iterator. Then in the inner iterator, create a new string iterator every time, while cloning the text iterator (since I need the text iterator state to be from what the outer text iterator was), and run the matching. &amp;#x200B; let outer_text_iterator = text.chars(); for _ in outer_text_iterator { let mut string_iterator = string.chars(); let mut text_iterator = outer_text_iterator.clone(); // Failed to compile here // because the value of outer_text_iterator is already consumed by the loop // meanwhile doing &amp;outer_text_iterator in the for loop also does not work since it is not implemented } Any suggestions? # 
At risk of rules 2 and 5, couldn't help myself: "You have very fine outcomes when you `.unwrap()` on both `Result` types"
\&gt; micro-crate ecosystem I would love for there to be "endorsed traits" that are just outside of the standard library. Having solid APIs would enable implementations to experiment and downstream crates would have less to worry about as far as side channel attacks go. &amp;#x200B; (Sorry if this comes across slightly incoherent - I've been meaning to write up my idea properly for a while but don't have the time right now) 
Wait, what? What's the problem with reading into a Vec&lt;u8&gt;?
I can see using this in pulldown-cmark, as we internally use [u8], but have conversions with str at input and output. Those are potentially time-consuming, and also (currently) one of the very few sources of unsafety. In any case, it looks like an interesting project.
Slight side note, but one of my very FAVORITE things about Rust's trait system is that it means you're not tied to a specific interface like you are with Java style interfaces. You can just implement traits for your own types to provide the necessary glue between different libraries with similar functionality.
Please post to r/playrust. This sub is for the rust programming language.
Please post to r/playrust. This sub is for the rust programming language.
Read subreddit description before posting on reddit.
I think you could do it with [block-utils](https://docs.rs/block-utils/0.6.1/block_utils/) `get_all_device_info()`.
You have to deal with set_len because it's inherently unsafe. You can't have uninitialized memory, say it's safe, and call it a day. Either you initialize it (say, 0s), or you accept some unsafe code. Pick your poison.
r/lostRedditors üòÇüòÇ still enjoyed this post
If you feel like diving in the end on filename issues, see https://dwheeler.com/essays/fixing-unix-linux-filenames.html
Why not `thread_local!`? It's on the std lib.
That's a strange name for `Vec&lt;u8&gt;`.
How long does something like this take? I'd like to also try but I have no idea what sort of time commitment i need to make.
I'm curious: why have a `serde1-nostd` feature, as opposed to having that feature selected through the `serde1` feature and the lack of the `std` feature?
This is the type of meetup I like to see in Charlottesville. 
OK, let me look at that. Thanks
I believe there‚Äôs crate for this already.
What exactly do you mean? Are you saying you would name things like this: ``` int int_x double double_y ```
&gt; !RemindMe 3 months 
I will be messaging you on [**2019-07-02 05:41:49 UTC**](http://www.wolframalpha.com/input/?i=2019-07-02 05:41:49 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/rust/comments/b81ekd/gitrs_git_implemented_in_rust/ejxhxx8/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/rust/comments/b81ekd/gitrs_git_implemented_in_rust/ejxhxx8/]%0A%0ARemindMe! 3 months ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
There are many variations, but essentially that's what I'm talking about. I did have an issue when I removed the type identifiers, there was a name collision. A tuple would have been a good solution.
I'm curious why you like to name things this way. Personally, I feel like it is needlessly verbose; it only creates more aspects of your code that need to be maintained, that could easily get out of date when they only contain superfluous information. It just seems like you are adding more to maintain for little to no gain. In Rust, I could see this getting extra confusing because we use type inference so frequently. Speaking of that, do you use this convention with C++'s `auto` keyword? How do you name variables that are generic types in C++? ``` template &lt;typename T&gt; void function(T t_x) {} ```
Naming variables is a whole other topic. Given the scope of a function's parameter, there is little need to add a type identifier. It's for a struct's members where a name that identifies the type becomes useful, normally you are just wanting to get at the member of type X associated with that instance.
Okay sure. With regard to members of a class, they should probably be private and have some sort of method to retrieve them if you are going to retrieve them. In that case, the type would be specified by the return type of the accessor function. My question about generics still stands. Would you write this? ``` template &lt;typename T&gt; class Foo { T t_x }; ```
I don't know much about CPP, if t_x was public how could it ever be accessed wouldn't the type be variable? That's where having a getter would be needed to sort out what type it should be.
/r/playrust
If \`t\_x\` were public, it would still be accessed in the same way. Yes, t\_x would be variable, but all of the information is still known at compile time. \`\`\` Foo&lt;int&gt; f; f.t\_x \`\`\` would be how to access it, if it were public. Aside from this C++ discussion. I'm still unsure why this is useful. I don't see a use for this in Rust (or in C++, frankly). I'm not trying to be negative. I am just trying to understand where you are coming from, and what advantage you feel like adding the type to a member's name provides. 
Once and for all, what is the Rust equivalent of HTML5 canvas that allows for windowing and widgets? For example, if I have a buffer of pixels and they deserve to be drawn to the screen because they're so cute and- ahem. Let's say I need to draw them in a window, what do I use to do that and where do I go to learn it?
You might have to wait a while for the relevant libs to get a bit more mature http://arewegameyet.com/
He's talking about rust the game. 
Not in helium drives. 
Those ambiguities didn't stop anyone from implementing it in their website. I would argue quite the opposite. The ambiguity makes it easier to implement since there aren't that many things you can get wrong. The C programming language got as popular as it is today for similar reasons.
It's just something one would expect to see from a university programming course. I used the convention of the project I was forking. Now I have... ``` struct Device { pub vertex_buffer: Buffer, pub vertex_shader: Shader, } ``` It's a little weird of an example, but I don't think this is the last time I'll write something like this. I just wondered if it was useful in Rust to repeat the type in the name.
This is useful in CPP because we want to be aware of the potential pitfalls of `int_x = double_y;`
Hell of a lot less effort to pass `-Wconversion` to your compiler.
You could reply the outer loop by simply `while let Some(_) = outer_iterator.next()`. Not sure if there is a more "Rustican" way.
You're indexing directly, so I assume you're not interested in any unicode handling. In that case, I suggest using `as_bytes` on your `text/string`, then do the comparison via the `Windows` iterator: for win in text.windows(2) { if win != string { return false; } } The algorithm seems a bit strange to me, but I assume you know what you need or you can adapt :)
Does this have ascii validation ?
Haha, that's funny, I actually just dreamt of meeting u/burntsushi last night :) Not in a weird way, to be clear, we just met on the street and he was like ["Text search is just kinda my thing. :-)"](https://news.ycombinator.com/item?id=13269955), and I was like "I know, big fan! As a linguist, I dabble with Rust for text-processing tasks and your posts have been super helpful! And ripgrep &lt;3..." And then I wake up, go brush my teeth, open up reddit just to have something to stare at in the meantime, and bam! This is literally the first post that turns up. ... just a long-winded way of saying, I appreciate your contributions to the Rust ecosystem in general and to text-processing in particular, keep up the good work!
Also a really good point... 
It's also much less useful in Rust because you can't assign doubles to ints.
You probably want a build script, not a macro: https://doc.rust-lang.org/1.28.0/cargo/reference/build-scripts.html. You have access to the output path via the `OUT_DIR` environment variable (search for it on that page).
`vertex_buffer` and `vertex_shader` are just convenient names, though. They don't have to be of `Buffer` or `Shader` types. For instance, the types could be more specific, like `GLBuffer` and `GLShader` or less specific, like `[u8]` or you could name the variables `vertex_data` and `shader_program`. It's not the nineties anymore, and you don't have to use a WINAPI-like naming convention. What you should do is use a name that reflects the variable's purpose. Also, you might find the books "Clean Code" by Robert Martin and "Code Complete" by Steve McConnell interesting to read - both cover the topic of naming variables amongst other things.
Every week I come here for Rust Lang.. Go back seeing all Rust Game posts. lol
These kinds of 'build a thing from scratch to learn how it works' books are my favourite - does anybody have any other recommendations of similar stuff? My personal favourite at the minute is [Crafting Interpreters](http://craftinginterpreters.com/).
Why would you not want utf8? Genuinely asking not criticizing
I almost immediately realized my mistake
Does this answer it for you? If not, I should improve it. https://docs.rs/bstr/0.1.0/bstr/#when-should-i-use-byte-strings
Why?
Because I don't think it's possible? serde is optional dependency, and you need some way of enabling serde's std feature as well. You can't enable that in bstr's std feature because then it would be impossible to use bstr's std feature without serde. I'm all ears if you can come up with a different way to arrange the features. :)
&gt; I wonder if a format!/Display for bstr might be useful. Yes please! This is one of the most annoying things about having to represent mostly-strings as [u8].
Haha. Glad to provide some reading material! Check out the implementation of grapheme decoding, which is done with a regex. Then check out word/sentence deciding too, and be horrified. :)
Yeah I think some kind of formatting for bstrs would be good to have. Possibly FromStr as well. Just haven't thought about it too much. If you have ideas in this space is love for you to open an issue!
Probably yes. Do you have an up-to date benchmarks?
Types don't lie, variable names do. I've always hated these C++ conventions, and have run a million times into cases where the type of a variable was updated, but the name was not, ... This is completely unnecessary in Rust, if you want to see the type of a variable, just hover the mouse over it.
What is the motivation for that, please?
In recent versions of Rust, you don't need the `'static` either! static MOCKS: &amp;[&amp;str] = &amp;[ ‚Ä¶ ]; Such efficiency!
This is the first time in years that I'm going to argue that this belongs in the std library. This is a fundamental vocabulary type, so fundamental that we even have built-in language syntax for it (`b""`). I wish the `std` APIs would use this type appropriately instead of using `&amp;[u8]` for everything.
I disagree with ‚Äúfix std by providing yet another crate‚Äù on the long-term. It might work on the short-term because impacting `std` on the short-term is hard, but we should seek to fix `std` first.
You could also give a try to [sysinfo](https://crates.io/crates/sysinfo).
https://github.com/BurntSushi/bstr/blob/master/README.md#high-level-motivation https://docs.rs/bstr/0.1.0/bstr/#when-should-i-use-byte-strings Please ask more questions if those don't answer everything, so that I can improve them.
Haskell names it `ByteString`, so it‚Äôs not that strange. However, I have doubts about the motivation. Maybe that crate is useful for a bunch of folks for the short term, though? Haskell has `ByteString` part of the default `GHC` setup (it‚Äôs not in `base` but it comes with the compiler in `bytestring`). I‚Äôm not convinced that `bstr` should exist vs. having more functions on `&amp;[u8] / Vec&lt;u8&gt;` in `std`.
So I was mislead by `bstr` vs. `ByteString` from Haskell. It‚Äôs not strictly a `Vec&lt;u8&gt;` companion as it‚Äôs related to _strings_, right?
Possibly. Although an alternative is to roll many of these APIs back into the `&amp;[u8]` API instead of having a separate type. Either way, I think this is at a minimum the first step. I use the word "experiment" in the docs earnestly. If nothing else, this crate should crystalize use cases, which we will undoubtedly want to explore in detail if we wanted to add this stuff to std. There are also a number of APIs in this crate that go beyond what std has traditionally provided, even for Unicode strings.
I'm more prone to work in the opposite direction, pushing the distinctions into the type system by declaring [newtypes](https://github.com/rust-unofficial/patterns/blob/master/patterns/newtype.md) so that the compiler can catch things like trying to pass a coordinate/dimension on the `x` axis into somethint that operates on the `y` axis or vice-versa. (eg. accidentally typing `x, x` or `y, y` or `y, x` in an argument list or something else in that vein.)
The same example written in Rust looks like this: if let Some(foo) = get_foo() { let stuff = foo.make_stuff(); lot_of_code_here_that(stuff); } else if let Some(boo) = get_boo() { let stuff = foo.do_stuff(); // Compilation error. `foo` does not exist. And it can't, because existence of pointer `foo` would prove it's validity which is not the case. lot_of_code_here_that(stuff); } This is not about mutability. This is about guarantees that used pointers are valid. Unless you create them, or break using unsafe shenanigans: In C++ raw pointers guarantee nothing, references guarantee that they are not null but doesn't guarantee they are valid, **some** smart pointers kinda guarantee that they are either null or valid but incur overhead. In contrast in Rust you have references that are *always valid*, *never null* and *zero overhead*. You will never get Rust level of static analysis in C++ without additional syntax. Even though existing static analysis tools for C++ can find multiple bugs in any software people tend not to use them... 
Why do we need to argue about std right now? Let's try a crate first and see how it goes. If it winds up being a super niche concern, then maybe these APIs don't belong in std after all. If lots of people start using it, then we'll understand the use cases better and hopefully wind up with a more compelling story for why it should be in std.
I specifically said secure, because PoS is not secure.
I'm not sure I understand your question. Byte strings are just wrappers around `Vec&lt;u8&gt;`/`&amp;[u8]` with a string focused API. Can you rephrase?
Yeah so not `ByteString` afterall, since it‚Äôs actually about strings more than binary sequences. Okay, that sounds a bit niche to me and I don‚Äôt see many occasions where I‚Äôd need it. In [luminance](https://crates.io/crates/luminance), I have some places where I handle strings via byte arrays (but those are not `Vec&lt;u8&gt;` but `Vec&lt;i8&gt;`). Since your crate seems to be about `Vec&lt;u8&gt;`, I wouldn‚Äôt be able to use it (I need `Vec&lt;GLchar&gt;`). Also, the tooling I need is very basic (basically, marshal / unmarshal via FFI). I will wait and see how others use the crate because I don‚Äôt see a good fit for it in my codebase :)
Quoting the documentation &gt; Byte strings are effectively the same thing as a `Vec&lt;u8&gt;` or a `&amp;[u8]`, except they provide a string oriented API. Operations such as iterating over graphemes, searching for substrings, replacing substrings, trimming and case conversion are examples of things not provided on the standard `&amp;[u8]` APIs but are provided by this crate.
Think String, but without the requirement that it's valid utf8. That means it has a number of APIs, such as substring search, that work just fine in arbitrary byte sequences.
Substring search in `&amp;[u8]` is achievab
I can't wait to use this in my other crates just for the Debug impl alone. I've probably written dozens of variations on it over the years.
Imo it is still mental overhead even though the types implicitly convert. Like this new crate, i am sure it is useful but non-Rust programmers will ask why Rust needs yet another string type. There is a reason why Kotlin became much more popular than Scala and it is not only because of Android.
It's less not wanting UTF-8 and more accepting that while things are *mostly* UTF-8, sometimes they can be arbitrary bytes: - Directories and files names are not guaranteed to be UTF-8. - Any untrusted input may not be UTF-8, either by accident or design. - There are usecases for searching strings in binary files. - ...
That really sounds like this issue I opened a few weeks ago : https://github.com/rust-lang/cargo/issues/6658
I'm not sure if you realize there are people with different hardware specs. And perhaps some can't afford better one. Or do you think that anyone carse how many giga RAM you have?
\`xmlparser\` didn't have any examples for writing documents. I don't need to do any parsing evtx. I see \`quick-xml\` does have an example for writing, and it seems to be more recently updated. &amp;#x200B; From profiling I can see that most time is indeed spent constructing the XML (which is reasonable) I might give it a shot to squeeze some extra boost :) Although I'm pretty happy with the performance so far.
r/playrust/ ?
Oh, so you don't need to parse an XML? `xmlparser` is just a parser. &gt; and it seems to be more recently updated Not sure if this matters.
Just had a quick look through the code, it looks great. Really slick API. Have you had a chance to look at Maged Michael's implementation? He has these ideas of "domains", which really just are groups of Hazard Pointers and retired memory - [code](https://github.com/facebook/folly/blob/master/folly/synchronization/HazptrDomain.h). I found the code difficult to understand but there's some cool ideas in there. &amp;#x200B; I really like [this](https://github.com/oliver-giersch/hazptr/blob/master/src/retired.rs#L136) idea. I know it's simple but it's very effective. Sometimes I write custom memory orderings and forget what other statements they're meant to synchronise with. &amp;#x200B; Have you tried comparing performance with epoch?
That would work as well. You'd end up with one file handle to urandom per thread, but that's fine. It's random data anyway.
X11 is graphics server for Unix like systems, most notably Linux. Status bar is exactly what it sounds like, a bar to show system status (battery, time, network, sound...). Not to sound harsh, but if you don't know what X11 status bar is, you probably aren't target audience :)
Yup, that looks right.
No that doesn't sound too harsh lol! By target audience I more meant "is this something I should learn more about because I might have use for it?"
Do you comment on every Rust crate you don't need to say "this crate is no use for me"? 
&gt;Never in my life have I, or possibly has anyone I know, ever used paste from the menu. Paste is Ctrl-V, &gt; &gt;everyone knows that! &gt; &gt; Except that not only does everyone &gt; &gt;not &gt; &gt; know that, but so few people know it (and paste is so widely used) that it's the most frequent menu item of all. Try git clean -fdx --dry-run then if you does what you need, remo the --dry-run
It's not because I don't need it that I'm not allowed to give my opinion or even to be interested with why some people want it. And you should really avoid sarcasm. It's not good for clear and appreciable conversation between humans.
evtx records are stored in binary xml format [https://docs.microsoft.com/en-us/openspecs/windows\_protocols/ms-even6/c73573ae-1c90-43a2-a65f-ad7501155956](https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-even6/c73573ae-1c90-43a2-a65f-ad7501155956) A big part of the parsers' work is to decode this format into a token tree that is convertible to textual XML.
Sorry if I was too harsh, that wasn't intended. Point is that several use cases have been given in this thread, the most important one being (to me), the possibility to create a crate to work on non-utf8 paths.
Should I not bother learning the current method for multithreading in rust? I'm still learning the language.
You have some alternatives that you can use from any language, for example cairo (from GTK) or SDL. I didn't check if they are easy to use, but it should be possible
No you should! The await is basically syntactic sugar sonit's easier to write. Behind the scenes is still the same! So you don't waste time at all, the opposite!
&gt; the possibility to create a crate to work on non-utf8 paths easily I'm sure you know this, but just a small point of clarity here for anyone else following along: std's `PathBuf`/`Path` types do work with non-UTF-8 paths. The problem occurs when you want to do something that is more "stringy" on the path itself, like, say, match a [regex against it](https://github.com/BurntSushi/ripgrep/blob/09139721047b1cda6ad88dbf89dc5fa74c66a3a2/globset/src/glob.rs#L117-L119) without needing to pay for the overhead of UTF-8 validation. (Which can actually be quite noticeable on a profile when scanning a large number of file paths.) So you basically wind up writing platform specific code like this: https://github.com/BurntSushi/ripgrep/blob/09139721047b1cda6ad88dbf89dc5fa74c66a3a2/globset/src/pathutil.rs#L81-L104 in order to get at the raw bytes of the path in a zero cost way (on Unix at least). But then you wind up with a `&amp;[u8]` that is not only not guaranteed to be valid UTF-8, but even if you were willing to pay for UTF-8 validation, it would be _wrong_ to do so because not all file paths are valid UTF-8. Relatedly, sometimes you want to perform operations on file paths without the full file path machinery, mostly for performance reasons, so you wind up writing things like this: https://github.com/BurntSushi/ripgrep/blob/09139721047b1cda6ad88dbf89dc5fa74c66a3a2/globset/src/pathutil.rs#L5-L28 I think bstr can help with this stuff. I've loosely been thinking about adding platform independent APIs for converting between OS strings/paths and bstrs. e.g., `from_os_str(s: &amp;OsStr) -&gt; Result&lt;&amp;BStr, Utf8Error&gt;` where the semantics are, "on Unix, this always succeeds and is zero cost. On Windows, this only succeeds if the given OS string is valid UTF-8." (And probably also include a `from_os_str_lossy` variant too.) Unfortunately, while moving back from `&amp;BStr` to `&amp;OsStr` will be zero cost on Unix, you'll need to pay for another UTF-8 check on Windows since you can't build an `&amp;OsStr` from arbitrary bytes on Windows, and a `&amp;BStr` is, by definition, arbitrary bytes. The other trade off at play here is that this won't actually let you handle all possible file paths on Windows, since you can create paths that aren't valid UTF-8. So if we really wanted to make `&amp;BStr` work seamlessly, then either std would need to expose its WTF-8 internals or `&amp;BStr` would have to re-implement it. Rust's Path/OsStr handling is really awesome in the sense that it makes it very difficult for you to write incorrect programs. But the problems that have cropped up in practice are 1) people still like to use strings everywhere, which automatically makes your program buggy on Unix for file paths that aren't valid UTF-8 and 2) the Path/PathBuf handling generally introduces performance overhead when handling a large number of paths.
Yep, hence the "easily" :)
I'm looking for something like try/catch from other languages. I know how to use Results and '?' but sometimes I want to write something like use std::fs::File; use std::io::prelude::*; fn main() { try { let mut file = File::open("foo.txt")?; let mut contents = String::new(); file.read_to_string(&amp;mut contents)?; do_something(contents); catch { println!("Failed to read file, using defaults"); do_something(defaults); } } I want to catch '?'s without writing a new function. I found some RFCs or things like that but I got lost on tracking issues on Github. There is something similar to try/catch available now?
I've used the bytes crate for this in the past, it displays strings "python style" by replacing unprintable bytes with \x00. The definition of unprintable my vary though, for example some people would consider emojis unprintable while others don't.
async isn't the same as multithreading
You are right. I think I shouldn't have put multi-threading in the async paragraph. I didn't mention that they are the same, but from the reading flow you could think that I meant it. I will adjust the wording!
No, it isn't, but for most IO bound applications it's a preferable model. I seldom work on CPU bound applications.
Maybe you should make this clearer in the article? The Rust part starts with: &gt; The Rust Async ecosystem is still in progress and not final yet. Which just sounds like "go away and come back later" to a lot of people. As far as I understand Futures 0.1 works fine and the newer variants are mostly backwards-compatible. Javascript also started with just Promises that are strung together with combinators and callbacks and got the nicer syntax later.
this is what i want to do read a .rs file or project, and select a trait which marked with a custom proc\_macro\_attribute could you please tell me is there any doc or article about this operation on tokenstream?
Thanks for the feedback! That's actually not what I meant. I think the article makes it clear what's in nightly and stable. Will collect feedback and then update the text! 
Interesting. Basically, a `&amp;BStr`'s `Debug` impl will behave just like a `&amp;str`'s `Debug` impl, except when it comes across invalid UTF-8. At that point, it prints out the raw bytes as hex escape sequences. Otherwise, it uses [`char::escape_debug`](https://doc.rust-lang.org/std/primitive.char.html#method.escape_debug) to get a debug representation of each codepoint. Here's the actual implementation: https://github.com/BurntSushi/bstr/blob/26889c3b5bfd922a54567afe28896e527317af93/src/impls.rs#L273-L288
You can emulate this with a closure, but it's not exactly pretty: use std::fs::File; use std::io::prelude::*; use std::io; fn do_something(_: String) {} fn main() { let defaults = String::new(); // return type annotation required if let Err(_) = (|| -&gt; io::Result&lt;()&gt; { let mut file = File::open("foo.txt")?; let mut contents = String::new(); file.read_to_string(&amp;mut contents)?; do_something(contents); Ok(()) })() { println!("Failed to read file, using defaults"); do_something(defaults); } } Extracting the `try` segment to a function is more idiomatic, however, even if it might be a bit more verbose sometimes. 
Yeah overall it's pretty complete. Just that phrasing right at the start of the Rust section might scare off some people.
It looks like the serialize impl just forwards to `serialize_bytes` which will result in something like `[104,101,108,111]` for json, which is not very human readable and also less efficient to parse and store. Maybe it could serialize to a string if it is utf8, or use something like base64 encoding.
I gave a lot of thought to that. In the end, I decided that /u/dtolnay's [`serde_bytes`](https://docs.rs/serde_bytes/0.10.5/serde_bytes/) crate was the right approach. (bstr doesn't use that crate directly of course, but it copies the implementation path.) Basically, bstr shouldn't be baking any kind of assumptions about the serialization format into the crate. Using base64 is somewhat endemic to JSON specifically, since it doesn't have a convenient way to represent packed binary data. (Outside of a simple integer array, as you point out.) But what if you're serializing to CBOR? bstr certainly shouldn't use base64 in that case. Combine the above with the fact that using base64 with serde is _really_ easy anyway. See an example here: https://github.com/BurntSushi/ripgrep/blob/09139721047b1cda6ad88dbf89dc5fa74c66a3a2/grep-printer/src/jsont.rs#L85-L86 Finally, you can see what I did for representing things that are most commonly valid UTF-8, but could be arbitrary bytes: https://docs.rs/grep-printer/0.1.1/grep_printer/struct.JSON.html#text-encoding --- The idea here is that each string is encoded as an object with two mutually exclusive keys. One key is a normal JSON string with UTF-8 contents, while the other is a normal JSON string with base64 contents. I think this winds up working quite well, but it's a very JSON specific structure that probably doesn't belong in bstr proper.
Is there any interest in me submitting a PR to update the version of Thrift used for the parquet crate?
That makes sense, thanks.
I am still a bit confused. All examples of futures I have seen just await any future it created almost immediately. What is the point of that. Why not just use normal blocking io? If futures are poll driven, how are they supposed to do anything asynchronously if I have to explicitly push them along?
&gt; Why not just use normal blocking io? Because with `async` you save up a thread, which sometimes matters in high-concurrency scenarios. &gt; If futures are poll driven, how are they supposed to do anything asynchronously if I have to explicitly push them along? You only need to (a)wait for them, not poll them. For things like sockets you'll be using an OS-level mechanism that notifies the app when an operation can be performed (on Unix) or has completed (on Windows). So once you have a future, possibly consisting of a sequence of `awaits`, you can pass it to the reactor which will take care to `poll` it when it knows that further progress can be made.
The best way I've seen to summarize it is: Async is for waiting on multiple things at once. Threads are for working on multiple things at once.
I will continue noodling on this though, because I don't really like the result either. Perhaps "if it's utf8, serialize as a string" is a better default.
I wish text wasn't so freaking hard. I don't want this to become the haskell nightmare 
To be clear, I'm referring to something like `Display` that instead creates bstrs though `Display` support is nice. The problem I'm thinking of is being able to easily manipulate paths without just saying "forget it, I'll only support UTF-8 paths".
I updated [json\_in\_type](https://github.com/lovasoa/json_in_type#json_in_type), the fastest JSON encoder in rust :) The crate is now 2018-compatible, and uses SSE4.2 SIMD instructions when available for fast string encoding.
Trying to wrap a C library. There is a huge main struct in the header and a lot of the functions return a pointer to that struct. (i.e do\_something(t: c\_int) -&gt; \*mut big\_struct) How would you guys reference the fields of the struct in a safe(ish) way? Most things I've tried leads to core dumps. I've tried is\_null() test the return and it seems not to be NULL. &amp;#x200B;
It's possible to provide a safe interface to read into a vec. let mut buf = Vec::with_capacity(8192); unsafe { let len = buf.len(); buf.set_len(buf.capacity()); let n = reader.read(&amp;mut buf)?; buf.set_len(len + n); }
But what if I have something I want to be doing while the async code is happening? If I await, then I have to wait until it's done to do other things, but if I don't await then nothing gets done.
Er, this overlaps with BSTR, a microsoft COM/Windows api type. 
I'm no expert in Java, why can't you just implement an interface for your class? Where is the catch?
That's not _technically_ safe unless you have control over the implementation of `reader`. Namely, the safety of that code depends on the implementation of `read` knowing never to read any of the bytes in `buf`. This is what the [`initializer` API is for](https://doc.rust-lang.org/std/io/trait.Read.html#method.initializer).
Thanks for the tests and sorry for the late answer. XML support is not perfect but I believe at least on par with xml-rs (plus non utf8, some HTML specific exception etc...). No DTD support though.
A benchmark that takes `0` time usually means the compiler has optimized your benchmark away to nothing. Have you looked at the codegen to confirm this isn't happening? Try using [`criterion::black_box`](https://docs.rs/criterion/0.2.10/criterion/fn.black_box.html) and see what happens. (Or also the unstable [`test::black_box`](https://doc.rust-lang.org/test/fn.black_box.html).)
Sure. I‚Äôll try that.
Yes please, that would probably be both on parquet and sunchao/parquet-format-rs
Isn't there an API in the standard library that uses this pattern and says the `read` impl shouldn't read from the buffer? Also would it be that big of a deal if the `read` impl read some random garbage bytes? It's not like it's a complex type or something that implements drop.
Wow. Code is very readable and easy to follow even without comments. Unsafe isn't used widely but when it is it's done responsibly. The only things I'd suggest is: 1. Reduce code duplication when generating trait implementations for arrays. Instead of copy-pasting `impl_desse_arr` macro invocations over and over again for every numeric type and for every array length I'd group them inside of the `impl_desse`. 2. Try fuzzing your library. In a nutshell, "fuzzing" means generating random inputs and feeding them to a program until it crashes because of memory errors which sometimes happen in Rust libraries with unsafe code. You're already testing deserialization for every single type, but maybe you can try writing a simple code generator which will generate a few random structs with random fields and then testing these deserialization/serialization of these types. Also I'm sure there exist fuzzing libraries for Rust.
If you have two things you want to do, make a future for each, and put both in the runtime.
It's undefined behavior to read uninitialized data of any kind. Full stop. The initializer api i linked in my previous comment is the intended solution to this afaik.
We already had this topic a week ago: [https://www.reddit.com/r/rust/comments/b5bpbb/drew\_devault\_rust\_is\_not\_a\_good\_c\_replacement/](https://www.reddit.com/r/rust/comments/b5bpbb/drew_devault_rust_is_not_a_good_c_replacement/)
This topic has already been discussed a couple of days ago. By crossposting a controversial post from the /r/C_Programming subreddit you will just encourage brigading of that community.
Thanks. Will try to add these things in code.
Great - I'll do that as soon as I can. I'd like to get people off 0.0.4 and onto the 0.12.0. I'd also like to start pushing that crate to be 2018 edition only for 0.13.0.
How are you defining \`big\_struct\`?
My sibling has the only thing you can do now, but something similar to this is coming eventually. Doesn't help you on stable today, though.
This is a huge amount of work! Thanks. I wonder about alternatives to using the replacement character when bad UTF-8 is found. For example, you could use a reversible conversion of an invalid byte to/from an invalid range of codepoint values (e.g. off the top of the valid codepoint range, or half a surrogate pair). You'd only need 128 values. Did that not seem like a good idea when you implemented that part? (For example let's say we need to pass through some known weird control sequences in our data, but otherwise handle things as UTF-8.)
&gt; By crossposting a controversial post I've crossposted the *discussion* which happened less than 12 hours ago. &gt; controversial brigading You seem to be against discussing per se. This is is something which encourages siloeing, and is very unhealthy. 
I wanted to post this here to spark some discussion and see if there were some rebuttals to their points.
Please notice I did not link to the original article, but discussion of said article on /r/C_Programming which is currently less than 12 hours old.
The interfaces that a class implements are defined at class-definition, e.g. `class Foo implements Bar, Baz`. This means that you cannot implement interfaces as an afterthought. If a library provides a class, but that library doesn't know about your code, then the classes from that library won't inplement your interface and instead you have to write wrapper objects. For example, you cannot implement your own interfaces for `String`. Contrast this to Rust's `impl Bar for Baz`, which allows you to implement your own traits for foreign structs (even stdlib ones).
&gt; Also would it be that big of a deal if the read impl read some random garbage bytes? It's not like it's a complex type or something that implements drop. Yes, because the optimizer is completely free to rewrite your code to do whatever since you've invoked UB. 
This is off topic, but is it or will it be possibly to try out your game? It sounds interesting.
I did think about it, but this is really what the replacement codepoint is for. It's generally rendered fairly nicely and has a known meaning: "i found something i don't recognize." Moreover, it provides a very consistent API, particularly when dealing with algorithms defined on codepoints. e.g., how would you implement an iterator over `char`s using your approach? A char has to be a scalar value, and cannot be any codepoint. I think the whole point of using the replacement codepoint here is to make it possible to use byte strings in contexts where valid utf8 is needed. I don't think that can be accomplished with your technique, and I'm not generally sure how your technique would fit into this library. Do you have more ideas? To be clear, when you build a byte string, it does not eagerly replace all invalid utf8 with replacement codepoints. It will let your bytes pass through without incident. The replacement codepoint is only used when you try to read the byte string as if it were valid utf8. But that doesn't happen in every operation, e.g., substring search.
Some points seem noteworthy. But at the end, these same people hate when hackers point out buffer overflows in their codebase. Remember when Linus Trovalds complained about *security guys* slowing down development because they want the bugs fixed? Yeah thats a very annoying issue on the other side too. Too many times when we try to report these memory bugs, we feel it's better to escalate priviledges rather that going back and forth with annoyed developers. Atleast Rust handles some major issues that are hard to fix in a 10K line C codebase. You need 10 geniuses to review C code in that matter. Linters become useless in many cases, throwing out garbage printf's.
The post is mostly self-contradictory and full with ignorance. It argues: * that the rate-of-change of Rust is higher than that of Go, yet it uses Rust release notes for Rust and Wikipedia as a source for Go. This feels like cherry-picking sources to make a point, e.g., using Wikipedia for Rust reveals that.. Rust adds 0 features per year.. The only useful "insight" here is that the rate-of-change of new languages is higher than that of 40 year old languages. * how important portability is, and how portable C is - yet it completely ignores that Windows exists? Windows is an arguably very successful platform that lacks a native C toolchain (MSVC is a C++ compiler). No MSVC version is C11 compliant, and AFAIK no MSVC version is C99 compliant either. * how important a spec is, and how important it is to have different implementations that stress the spec, yet at the same time it mentions how important an ABI is, but the ABI is mostly implementation defined / unspecified in the C spec, and the SysV ABI is popular, yes, but again, Windows exists (multiple ABIs). It also completely ignores that no large scale C program is implemented against the spec. For example, the Linux kernel uses dozens of compiler extensions that are not "specified". In fact, clang 8 was recently, released, and despite 10 years of trying to compile the Linux kernel with the 2nd most popular C compiler, it still does not compile "as is" (without patches) with clang out-of-the-box.
That would be fantastic!
Right, so I'm confused what you meant by asking whether you should wait to learn the multithreading model. AFAIK async await won't change anything about multithreading.
&gt; You seem to be against discussing per se. This is something which encourages siloeing, and is very unhealthy. I strongly disagree. The Rust community already has a bit of a bad reputation ("Rust Evangelism Strike-Force") for responding aggressively when something negative is posted about Rust. It is not necessary to respond in force whenever someone is "wrong" (according to whom?) on the internet. People *like* siloeing, and it is not your responsibility to "cure" them.
Can someone ELI5 this for me?
What other crates that have regular users do you know of, that are still on \`0.0.4\`?
Thank you very much
Thank you very much
Previous discussion for the post on the subreddit happened here: [https://www.reddit.com/r/rust/comments/b5bpbb/drew\_devault\_rust\_is\_not\_a\_good\_c\_replacement/](https://www.reddit.com/r/rust/comments/b5bpbb/drew_devault_rust_is_not_a_good_c_replacement/)
How does someone feel they know enough to write an article about Rust vs C but still think Cargo is mandatory? I'm a Rust noob and have known that you could use Rust without Cargo since I first learned about it. Maybe he should read the Getting Started guide before publishing an article about it?
Not sure what there is to explain. It's an implementation of a paper that gives a sound and complete algorithm for typechecking and type-inference. Basically you can give it an expression like '()' and it will infer that '()' is of type 'UnitType'. (for more non trivial examples check the test cases). If you want to know more about how everything plays together, you should read the paper. If you want to know more about the topic in general, you should read about type-inference, Hindley-Milner, etc. I just worked through the paper and thought the implementation might be helpful for someone at sometime. 
That's a nifty way to limit the active requests. As an alternative, see https://github.com/tower-rs/tower/tree/master/tower-in-flight-limit or https://docs.rs/tokio-sync/0.1.4/tokio_sync/semaphore/index.html.
One has to write type descriptions for them. [LLDB](https://lldb.llvm.org/varformats.html), [MSVC](https://docs.microsoft.com/en-us/visualstudio/debugger/create-custom-visualizers-of-data?view=vs-2017). May be not the exactly right links, but they are close.
That doesn't seem relevant. Nobody will be talking about 'bstr's without any context from which to infer an easy disambiguation.
ZawGyi One 4 Lyfe
Maybe the parent poster is making a distinction between parallelism (performing multiple computations at once, can be deterministic) and concurrency (multiple threads of control, nondeterminism, not necessarily involving parallelism). 
Maybe for simple use cases, but there's a _lot_ that I cannot do nicely with a GUI that is trivial with a CLI. For example: - stash/pop changes - selectively stage/discard chunks (`git add/checkout -p`) - interactive rebase, moving/squashing/rewording commits - writing detailed commit messages (I use my preferred text editor for writing commit messages) - moving and deleting files (`git mv/rm`) - scripting bulk changes (e.g. remove set of huge files from the last X commits) - finding stuff in files (`git grep`) throughout history Maybe there's some magical GUI I'm unaware of, but every single one I've used has been _more_ cumbersome for anything more than super basic usage (`git add; git commit; git push; git pull; git merge`, all w/o any changes in behavior). A GUI may be "easier" for the most common tasks, but it's not faster and it's not scriptable.
I suggest that the first paragraph in the README should explain that you still use BString/BStr for working with UTF-8 strings. I was honestly trying to figure out why a non-UTF-8 string library was needed by reading your documentation. It wasn't until I got halfway through the documentation that I understood what you mean by the "convention" vs "required". Looking back now and reading the first paragraph again I actually understand what you are trying to say. So the documentation is a bit recursive. Only the second time I understood what you meant.
Is it faster then https://github.com/TyOverby/bincode ?
I wonder if we can backwards-compatibly add functions to `std::string::String` that allow the construction of `String`s that don't have valid UTF-8, and effectively merge this crate into the standard library this way.
As per the benchmarks, it is! But, `desse` only supports serialization of types whose size is known at compile time. `bincode`, on the other hand, can serialize dynamically allocated types too.
A thing can be harmful and useful at the same time. I have spent _far_ too much time untangling nasty commits from new users who just use that flag without looking at what they're committing, and we often end up with stuff like debugging printlns or whitespace changes in the repository (e.g. misconfigured editor). These are caught in our code review process, but it happens enough that I think making committing a little more involved would be a net benefit. Yes, it can be useful to quickly stage/commit everything, but it's also _really_ easy to misuse. I've been the team lead for a team with a lot of intern churn, and it's _really_ frustrating to have to deal with this all of the time. I use it myself so infrequently that I'd be completely willing to give up the convenience to encourage new users to be a bit more thoughtful in making commits. I also make use of temporary commits (with later rebasing), but for the same argument as above, I think short commit messages should be more difficult to make (e.g. perhaps prompt for confirmation if your commit message is &lt; 20 characters or something). These types of things can certainly be done with hooks, but there's something to be said for a default configuration pushing users toward "proper" use of a tool.
Yup... Something weird is going on here, the results don't look right.
It is possible to use the trait system to implement this type of function overloading, as shown in the playground link below. Your method certainly does have less boilerplate though. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=3fbadb184909e3d17a7de32f7ccf5e5d I think it would be possible to further genericize this, so you could implement `Addable` on tuples of anything that can be added (impl&lt;T, U&gt; Addable for (T, U) where T: Add&lt;U&gt;), but I got tripped up on using the output associated type of `T: Add&lt;U&gt;` as the output associated type of the `Addable` trait. 
But the serialization scheme very similar for "whose size is known at compile time" between bincode and desse, why it faster?
Yes, it would have to be something like a `bchar` type which has extra values to allow representing invalid-bytes (you'd only need to represent one invalid byte at a time). The only reason would be to make conversion from `bstr` to codepoints and back to `bstr` leave the data unchanged (8-bit clean). However, looking at your `char_indices` call, if I just wanted to copy over invalid bytes unchanged to a new string, whilst modifying other valid UTF-8 as I copy it, then it looks like I could do it with that call. So probably that takes care of it.
I think that's basically equivalent to saying that strings would no longer be guaranteed to be valid utf8? I'd be curious to hear more. It's hard to imagine how that would work.
`hint::black_box` works too
&gt; The other trade off at play here is that this won't actually let you handle all possible file paths on Windows, since you can create paths that aren't valid UTF-8. So if we really wanted to make &amp;BStr work seamlessly, then std would need to expose its WTF-8 internals. atm this is something I consider broken in the stdlib. If I need to manipulate a path, my only choice is to only support UTF-8 paths at which point `PathBuf` using `OsString` feels kind of pointless (can only handle a small subset of cases).
Interesting. That sounds like a good idea. Thanks for the feedback!
I've updated the benchmark results. Thanks for your suggestion.
I don't know if I agree with the top voted comment though. I feel like the reasons Rust currently can't replace C are just because it isn't as old as C. When I hear "Rust is a C replacement" it means the idea / standard of Rust. I know Rust isn't able to target certain architectures, but I assume that will come in due time.
I've generally solved this with code review, where code review is done on commit messages too. But sure, I get where you're coming from.
async/await will change just as much about multithreading as it will I/O. The same async abstraction is used for both.
I work in an industry where most of my users are relatively technically illiterate. We make security software, so "power user" tools just aren't a thing. I am also frequently surprised by some of the changes we have to make (e.g. make this a sentence instead of a word). And that's largely why I consider stuff like the "all" flag to be harmful. It is so easy to misuse it to commit stuff you didn't intend with that flag that many new users will make subsequent commits to remove them. I've trained several new programmers that do stuff like `git commit -a... remove printlns... git commit -a`, and a simple change becomes several commits of adding and removing the same stuff. In fact, it got bad enough that I would often squash everything before committing most PRs because teaching each intern how to rebase before opening the PR got really old (I'd instead teach how to commit more cleanly and I'd handle the rebase). Removing that option would encourage more users to learn how to selectively commit stuff, a task that most GUIs make quite easy. In fact, I'd _much_ rather that a user use a simplified GUI than memorize a handful of CLI commands... But yeah, everyone has a different perspective. My perspective is as a team lead over a team that gets a lot of intern churn. Someone who mostly works with senior devs, authors, or some other group would certainly have a different perspective. However, I think that in general, removing "all" would be a net benefit.
Lol, it certainly feels like I'm the only one...
Yeah, I've been doing that as well. I just feel like a nudge in the right direction from sane defaults in the software would be helpful.
Yup, char_indices is designed with the use case of getting the original raw bytes in mind. :) I would definitely want to avoid creating a new char type. A new string type is hard enough as it is.
Bincode internally depends on \`serde\`. I don't know how \`serde\` works, but, in my opinion, it creates an intermediate representation of your data which can be serialized in \`bytes\` or \`json\`, etc. In all probability, creation of intermediate representation and converting that in bytes takes long time. P.S.: I may be wrong. 
There should be 2 black_box calls in every benchmark. Conceptually `black_box(interesting_fn(black_box(input)))`.
Interesting. I guess for me it's more like, "my code is broken for invalid Unicode paths on Windows only in some cases" since I lossily convert Windows paths to valid utf8. But thia only works to the extent that I put up with using &amp;[u8] as a string type. Hence, bstr.
Here's the thing: you technically CAN use \`rustc\` without \`cargo\`, but...even now \`cargo\` is the talking point in current discussions for integration with other build systems. I'm not sure what situations it would be realistic in to separate Cargo from the toolchain. &amp;#x200B; My argument against Drew's complaints with Cargo is that his expectation should be to use it. Period. He's set on using \`rustc\`, but it's rarely used in practice, and for good reason.
&gt; In all probability, creation of intermediate representation and converting that in bytes takes long time. It is strange view. Yes should be interal representation of `struct` / `enum`, but it is should be constants. Some like `const STRUCT_FOO_FIELDS: [2; Field]`, so "creation of intermediate representation" shoud have zero cost. And "converting that to bytes" may be optimized to just `copy_field1(); `copy_field2();` in simple cases which `desse` handle. May be you need enable some other opitmizations, like lto to get comparable speed?
Sure, but you're also not most users. As a tech lead over interns, it's quite frustrating to see a bunch of garbage in the commits (tons of whitespace changes from automatic formatting to files that are irrelevant to the patch, unprofessional printlns and comments, all changes in one commit instead of split up by "idea", etc). Also, a lot of new engineers make garbage commit messages as well (e.g. "optimize startup time" instead of "Delay loading user records until the app is up\n\nUser records aren't needed until someone logs in and accesses the admin tab, so requests to that endpoint now block on a semaphore if an (unlikely) access is made before they're loaded. This saves ~1s on our test system"). I think making commit messages on the command-line encourages terrible commit messages since they bypass any template that might be available if they opened it up in an editor. I want software my team uses to encourage best practices as much as possible without getting in the way too much. Changes like removing the "all" flag (or at least the short option) and prompting if your commit message is shorter than some arbitrary limit (e.g. 20 characters) would go a _long_ way toward encouraging users to learn their tools a bit better and search out best practices on their own.
Updated the results in README.
Yes. I'll look into it. Thanks.
Top comment on that thread is unreasonably good.
This is just an implementation of *an* algorithm for typechecking and type inference - the algorithm is described in a paper with the title quoted in this post. Its not conceptually any different from "Rust implementation of 'quicksort.'" But any type checking algorithm implements one particular *type system.* This algorithm doesn't implement the same type system that Rust has, so it couldn't replace the type checking system in rustc. Possibly this algorithm is relevant to improvements being made to Rust's type system, I don't know because I haven't read the paper.
Re: portability of C language to Windows. Windows is well served by high quality C implementation, namely GCC.
I see. I bet `xmlparser` is slower because it validates (almost) each char/code-point, while `quick-xml` uses `memchr` to jump around.
Huh, I didn't know that. I thought it was just for Futures.
&gt; Also I'm sure there exist fuzzing libraries for Rust. Several, actually, along with a Book. This GitHub org is a good place to start. https://github.com/rust-fuzz The Book is at https://fuzz.rs/book/ and there's also this blog post: https://medium.com/@seasoned_sw/fuzz-testing-in-rust-with-cargo-fuzz-13b89feecc30
That is some really clear documentation. 
**Quick Reminder**: Let's not flood the r/C_Programming with an avalanche of arguments, or clarifications, please.
Thanks for the encouraging words! I had not yet heard about hazard domains, but I will take a look at the repository. For the most part, \`hazptr\` is a proof-of-concept implementation for the underlying \`reclaim\` crate, which I'm also developing. The idea is to design an abstract interface that works with minimal friction for a wide variety of different reclamation schemes, i.e. equally well for hazard pointers and EBR. I got the idea from [xenium](https://github.com/mpoeter/xenium), which is itself based on a paper proposing such an interface. This repository is also where I got the idea for annotating each memory ordering. Hopefully, in the end this will enable users to implement data structure like this: ```rust pub struct TreiberStack&lt;T, R: Reclaim&gt; { // ... } ``` ...and just choose whichever reclamation scheme works best. I have not yet made or run any benchmarks, but I surely want to, include comparisons with `crossbeam` (and maybe `conc`).
It's interesting to me that concurrency is always the central discussion point around Rust's reference and borrow system. I was 100% sold on lifetimes, immutable by default, and the mutable/immutable borrow system before I ever realized the implications for safe multithreaded code 
Wait. You used `std::option` instead of a pointer type. Do you think this is a fair comparison, when `std::optional` in C++ exists?
It's generally a pretty solid subreddit.
It is, but futures can represent any async operation, which includes multithreaded workloads. 
Have them program in Haskell for a day and to use random. They'll quickly to view I/O in a more general form fast. &gt;.&lt;
What makes the semaphore useful is the `poll_acquire` method, which allows us to be notified when more resources are available, but in this case we don't ever add any requests after starting the loop. That means you can just start 12 tasks that restart themselves until an atomic counter reaches zero.
I‚Äôm still learning Rust, so this might be not 100% true. But when you are writing asynchron code, you split all your tasks in different asynchronous functions (futures, promises, go routines) and combine them to do the job. For example, one function for handling a server request, one for reading a file, one for writing to a stream etc. The main point behind an asynchron function ist that it exists immediately and does not block the current thread. Instead it gives you a promise or a future that will do the work. All this futures are put in to an executor. This executor can be multithreaded or single threaded and will periodically poll all futures somehow. This executor will know when a function ist ready to do the next step and execute it. And if is not ready, instead of blocking the current thread, it will execute other futures and don‚Äôt waste time and resources.
Interesting. Didn't know that!
Not sure about this but 2019 should be binary compatible with 2017. 
The jump between Thread-Based or Event-Based Architecture is kind of big. It reads like: ‚ÄûWe habe option A and option B. B is better‚Äú hmm okay, but why? And in the context of Rust it would be interesting to know, which runtimes are there and how they work? This is what I have expected from the title of this article.
I seem to recall they had problems at one point not with binary compat but finding them on a previous version.
Uninitialized bytes are not the same as garbage bytes. They may have no fixed value at all; they may have values other than 8 bit patterns; they may have values which can't be written to any memory location. This may sound outlandish but it's entirely recognizable in actual execution, rather than merely the optimizer, on some actual CPU architectures (albeit none targeted by rust today). So even if you stubbornly doubt that the optimizer can rewrite code to fail for uninitialized reads - but it can - then you'd still have to admit that reading uninitialized data is incorrect.
I would disagree with 'seek to fix `std` first', mostly because of the 'first'. Fixing things in crates first and then adopting into `std` feels much more comfortable to me, especially given the consequences of having a large `std` which nobody uses all of and which doesn't represent state of the art, as seen in (e.g.) Python or C++. That's not to say that there's anything _per se_ wrong with pulling things into `std`, just that to do it before proving both the utility and the quality in a separate crate feels decidedly premature.
This seems like it would be useful in a binary-text editor (like most of the major text editors are nowadays).
There's a whole GitHub page dedicated to this. I'll link it in a few minutes when I'm off mobile. 
Indeed. But definitely out of scope for `bstr`. Text editors may, these days, choose to only be capable of editing UTF-8. Text editors likely also have the budget to do some kind of encoding detection, possibly followed by transcoding to UTF-8. But I'm no expert on text editors.
It is extremely likely that xi-rope could be adapted to this; it is deliberately generic so it's mostly a question of deciding where boundaries should go (should it be possible to break a utf-8 encoded codepoint in half) and what the "summary info" should be.
That is all definitely true, but as a common base, I think `bstr` serves that purpose very well.
Yeah, I know. However, this article is targeted towards beginner/intermediate/interested developers. There is plenty of in-depth literature out there. I will go into depth in different articles in the series in the future, but this article is focussed on async and how it generally works. Why? I ran a few surveys and with talking to people, and everyone had the same question marks. I wanted to clear the clowds first before I go into depth. 
To your Futures question: There will be an article out there (soonish) where I go in depth into Futures. Runtimes: It doesn't pay off for me to spend hours in figuring this question out. Maybe it will in the future, but not in the next 3-4 months. But thanks a lot for your input, this helps a lot to steer the series and to know which questions people have!
The main thrust of my comment was to acknowledge that "replacement" is a vague word that means different things to different people. So as long as we center our arguments around generic "replacements," we will always be talking past one another. To you, you hear "idea," but to others, they hear "in practice, right now."
\#\[repr(C)\] \#\[derive(Copy, Clone)\] pub struct cdrom\_drive { pub opened: c\_int, pub cdda\_device\_name: \*mut c\_char, ... } extern "C" { pub fn cdda\_find\_a\_cdrom( messagedest: c\_int, message: \*mut \*mut c\_char, ) -&gt; \*mut cdrom\_drive; } Calling is done with let testit = unsafe { cdda\_find\_a\_cdrom(1, 0 as \*mut \*mut c\_char )} } The call seems to be working since it writes ok stuff to stdout. But testit isn't doing so well. &amp;#x200B;
I'm not awake yet but thank you~!
Not bad. One suggestion if make is that you're initializing the strict to be constructed with `std::mem::zeroed`, but are then writing to its fields directly. While I suppose it's not too big of an issue you don't seem to really support pointer types in general, it may be valuable to use `std::ptr::write` to make sure that you don't accidentally run any destructors on uninitialized data. As for serde, it probably wouldn't be hard to adapt this to work with serde. You could always just return an error if you get passed a sequence without a length. Serde provides lengths in an Option so you can take different paths based on its presence.
Sure. Will take a look at it. Thanks.
You call it preposterous, but it took me _twenty years_ to realise that a) Swift was joking, and b) it wasn't an idea that might work even if he wasn't. Satire is an art form, Poe's law is real.
As for bidirectional, consider the snippet `let mut a = None; a = Some(1u32);`. When a is declared, it is an `Option&lt;T&gt;`...but we don't know what T is yet. It's only later on, when the compiler sees `Some(1)`, can it go back and fill in T=u32. Bidirectional typechecking has types propagating forward like normal, but also types propagating *backwards* and narrowing down the types of variables before the actual use site.
With your own benchmark I'm getting around 35 MB/s. Compare that to the [lexer in Ratel](https://github.com/ratel-rust/ratel-core/tree/master/ratel/src/lexer) which is running on my machine atm at 1446 MB/s. Different benchmarks and there is some stuff you do that I skip (like unescaping stuff in strings), but that's a pretty big gap.
It would be great to compare desse with performant serialization formats, e.g. flatbuffets, capnproto, protobufs (you can have some inspiration from https://github.com/erickt/rust-serialization-benchmarks)
Sounds like a good idea. Thanks.
Gotcha! Agreed.
How do you handle endianness? Can the serialized message be passed between platforms that have different native endianness?
Ah that is interesting. Thank you!
This is fair for few reasons: 1. There is no `non-null` smart pointers in C++ std. `std::optional&lt;std::shared_ptr&lt;T&gt;&gt;` can contain: valid pointer, null or nothing which is not the same as `Option&lt;T&amp;&gt;` 2. On the contrary `std::shared_ptr&lt;T&gt;` has two alternatives: valid pointer or null which correspond to `Option&lt;T&amp;&gt;`. 3. Size of `Option&lt;T&amp;&gt;` equals to size of `T&amp;` and in fact Rust guarantee that it has same layout as raw pointer to `T`. I could use `Rc&lt;T&gt;` above, everything would stay true except guaranteed pointer layout.
You'd also have to be careful not to use target-specific types. It looks like `isize` and `usize` are already left out though.
‚ÄúFix `std` first‚Äù is based on the premise that `std` is broken in a way that has one obvious fix. But in think in this case doing some exploration in a crate is valuable: see for example discussion elsethread about having dedicated types v.s. more methods on `[u8]`. And this is more about a missing functionality than a bug.
[IndexMap](https://crates.io/crates/indexmap) supports accessing buckets via indexing. You can use [`IndexMap::get_full`](https://docs.rs/indexmap/1.0.2/indexmap/map/struct.IndexMap.html#method.get_full) to query the map and get back an index, and then [`get_index`](https://docs.rs/indexmap/1.0.2/indexmap/map/struct.IndexMap.html#method.get_index) to get the next bucket.
The macro actually expands to pretty much this. At least when creating a function, it will need to expand to something different if using as a method to a struct. With the generic tuple (T, U) where T: Add&lt;U&gt;, I believe that would require the user to enter the arguments like add((1,(2, (3, (4, 5)))) which means the function would need to be recursive to accept arbitrary inputs, which is interesting. although that is probably still macro territory. &amp;#x200B;
Wait, but Rust includes memory management and option type in this case. Similarly, in C++ you should just use std::option&lt;T&gt; in a local context as above. This supports memory management with RAII and optional value. Then, a reference can be used to handle the rest. Then, you should always instantiate smart pointers with their respective `std::make_` functions and avoid managing empty values. It's also a flaw to misuse NULL as a special return value (special = handled differently in program branches). You need to be idiomatic in both languages when comparing them.
I was expecting a bit more from the blog post, though the diagrams were helpful. Personally, there's one problem I'm currently stuck on (in regards to tokio anyway) I've been taking a crack at writing a protocol around a unix socket using tokio_uds::UnixStream. I ended up getting something at least 'working' by building up a big future: ``` let fut = UnixStream::connect(path).and_then(|stream| { ... tokio::io::write_all(stream, buf) }).and_then(|(stream, _buf)| { ... tokio::io::read_exact(stream, otherbuf) }).and_then( ... etc); ``` But I've no idea how I go from something like this to implementing my own Stream so other people can use my protocol. I could just return this in a -&gt; impl Future but that doesn't seem like a very nice way to do it. Anybody else run into this or know what the 'next steps' are?
That'll keep me going for a while üòÖ Thanks!
Are you 110% sure that it has the same fields with the same types in the same order as the C sources? [I found this](https://www.gnu.org/software/libcdio/doxygen/libcdio-paranoia/structcdrom__drive__s.html) which starts with `p_cdio` as its first field.
IndexMap is an idea that was thrown around the thread on this bug a bit (link in OP). It's not a bad idea. But preserving insertion order would give luster a behavior (insertion order = indexing order) that lua does not have, which means that code that works under luster might not work under PUC-Lua. Which was seen as a thing to be avoided if possible. But it's not a non-starter. The central problem with IndexMap is Lua makes guarantees about iterating using the `next()` function ("The behavior of next is undefined if, during the traversal, you assign any value to a non-existent field in the table. You may however modify existing fields. In particular, you may clear [ie, delete] existing fields."), that IndexMap wouldn't be able to satisfy (as IndexMap very helpfully updates the indices on deletion, as its design requires). It is possible to simply delay actually removing items from the IndexMap until an insertion occurs. But that would require keeping explicit Tombstone values and performing some sort of search after the fact or keeping some sort of list of deleted values. It isn't ideal, but it is a viable workaround. I was just hoping for a somewhat better option, as that's somewhat messy.
await blocks further execution of a function until the async code completes, but the function yields control back to the event loop so it can do other things. The event loop will keep checking the status of async functions until they are ready to continue execution. So if you have a single function, you await inside it, and you only call it once, it might as well be a synchronous program. But if you call that same function 50x, they'll run concurrently.
Sure, s/fix/enhance, then. ;)
Also implementing a trait or not based on generics. The `either` crate's `impl&lt;L: Read, R: Read&gt; Read for Either&lt;L, R&gt;` isn't possible in Java. You would need a separate `class EitherRead&lt;L extends Read, R extends Read&gt; implements Read` and the same for every other trait/interface.
&gt; She enlightened me on the difference between blockchain and holochain. &gt; It is in the same space but acts very differently to blockchain. It is also used for cryptocurrency. Yea, great explanation! I learned a lot!
In the snippet above (with error) `get_foo()` and `get_bar()` could return an `std::optional&lt;T&gt;` with exactly same result. (also note that `std::optional&lt;T&amp;&gt;` is ill-formed).
So I've been posting about this recently to friends. How are you ensuring `#[repr(packed)]` exists and is valid? I've attempted to create other similar things for LMDB, but hit problems with generics and lifetimes when following your approach. 
For example, you cannot print a `Vector&lt;T&gt;` with `println!("{}", vec![0; 10]);`, but you can print it by using `println!("{:?}", vec![0; 10]);`. The reason behind that is `Vec&lt;T&gt;` doesn't implement the Display trait, but it implements the Debug trait instead. In short, every formatting placeholder like `{:x}` or `{:?}` must implement equivalent trait: https://doc.rust-lang.org/nightly/std/fmt/index.html#formatting-traits
I believe that the method you use to locate things changed between 2015 and 2017, but I think 2019 and 2017 work the same way? not sure.
As a side note, Rust recently shipped with the handy dbg!() macro. I would start using that for debugging unless you really want to use Debug formatting.
Thank you! I missed this somehow. https://doc.rust-lang.org/std/macro.dbg.html
Unless serde directly casts bytes to their deserialized type it will be slower man modern serialization schemes, e.g. capnproto. 
FYI I've since went ahead and installed it and uninstalled 2017. Then confirmed I was on MSVC toolchain and it did work. When I didn't get an answer I decided to just risk it.
I guess nobody? I was speaking generally, tbh.
And what new discussion do you expect in /r/rust that wasn't already in the old thread?
I mean, good for the dog, but what does it have to do with the rest of the article?
The further reasoning is that `Display` is for user-facing output, while `Debug` should reflect the data structure directly (as reasonable).
Hah, I imagine a proper explanation might have distracted from the rest of the interview. But looking at their website it does seem interesting.
Yes, you are right. Dereference is an unsafe operation by design. And Rust can circumvent it by using matching combined with scopes, which is not available in C++. This is nice of course. The general problem by the way is mixing up variable names of same type. And you are on thin ice, if you do the same without any pointers but just with i32. You get wrong results. In my first post I haven't seen a reason to use the same type and it was intuitively better to use the type-based check. I try to apply distinct type tactics universally, so most mix-ups wouldn't exist as a problem.
Awesome, glad to hear it!
Just to be clear, I'm not talking about reading memory beyond what's been allocated by malloc or w/e. I'm talking about reading data within the range of data malloc has given us. Should be safe, no?
Oh no. @sgrif's contributions to Rails have been _incredible_. The Attributes API stuff is amazing. He did other great work generally cleaning up and making AR/AM stuff more reasonable and predictable and flexible. This makes me sad, and further encourages the catastrophist "uh oh is Rails dying" worries. :( &gt; It became clear that I have a different vision for the future, and that I would never make it onto the core team. This is further not a good sign. @sgrif did _amazing_ stuff, his vision for the future of Rails is the one I would have wanted. Hearing that a clash on vision for future was part of what put the final nail in... does make me happy. I can only guess what the differences in vision were, but I saw @sgrif making APIs at "under the surface" levels like Attributes, that were polished and sensible, and polished at APIs at all levels so I have the flexibility to do whatever I want in reliable ways is what I value Rails for. And I see Rails focusing on high-level fairly inflexible new features like ActiveStorage and ActionText... and worry that Rails is moving to become a Drupal-esque high-level application solution kind of thing. 
If you're unfamiliar with who Sean is _(like I am)_, I found this helpful from his [Patreon](https://www.patreon.com/seantheprogrammer): &gt; I co-lead the team that manages crates.io, the package repository for the Rust programming language. I'm also the person who gets woken up at 3 AM if the service goes down. I created Diesel, an ORM and query builder for Rust. Each week I co-host The Yak Shave, a podcast about development. I also am one of the all time top contributors to Ruby on Rails. &gt; In 2019, I decided to devote as much time as possible to crates.io and the Rust organization. The language is at a critical point in its development, and I think I'm in a position where I can really help to make sure it succeeds long term. &gt; The problem is that working on MIT/Apache licensed software doesn't exactly help pay the bills. That's why I'm asking for your help. With your donations, I'll be able to continue to devote my time to these projects, and create more open source software for you to use in your own projects.
&gt; Should be safe, no? No. It's unitialized. You can't escape this. There's no way around it. It's UB. See: https://doc.rust-lang.org/nomicon/uninitialized.html
Thanks, I probably should have put more context in the title.
I'm wondering whether there is a complete and actively maintained list of people working on Rust-relative stuff who are accepting donation. I know aturon's sponsorship list: https://aturon.github.io/sponsor/ but it's his personal sponsorship list, and it doesn't seem to be actively maintained (e.g. Patreon pages of first two people in the list are gone). It would be great if there is a list maintained by the community I guess?
I had similar issues when I wanted to store paths as strings in a round-trippable way (say in an MRU.txt file). I went for base64 encoding if necessary, UTF-8 if possible. Tricky bit was getting the data out of the Path. I made a small crate for it (it's my first): https://crates.io/crates/paths-as-strings. Turns out that needing to base64 encode paths is incredibly rare on a typical system (see docs). 
ActiveStorage left a bitter taste in my mouth since Paperclip was deprecated soon after. Like who deprecates a perfectly good library because a newer option exists? Especially since ActiveStorage was definitely a little rough around the edges ([see getting a URL for API mode](https://github.com/rails/rails/issues/32500)). Not to mention they basically screwed any sort of legacy Rails codebase. 
For multiple arguments, it would be nice if you could do something like `impl&lt;T, U, V&gt; Addable for (T, U, V) where T: Add&lt;U&gt;, Output::Add&lt;T, U&gt;: Add&lt;V&gt;` (this is psuedocode, because I don't think real syntax exists for expressing this). Basically, I'd want to express to the compiler that the output of `T + U` can be added to `V`. And then you'd need to be able to tell the compiler that the `Output` associated type would be whatever the `Output` type of adding `(T + U) + V` happens to be. 
Short version: some person is coding in Rust.
Note that C code compiled with GCC can't interface with all system libraries, and in many cases doing so is incorrect (and UB).
Yeah I avoided the complexity by mapping a file path to an object, which has one of two keys set. One key corresponds to the normal utf8 path. The other is always base64 encoded.
Because the maintainer knew that after ActiveStorage was announced people will flock to ActiveStorage. I've heard my work colleagues bad mouthed Paperclip as soon as ActiveStorage eventhough at that time you can do many hooks and processing with Paperclip. Same with their task queue choice, and that js text editor choice, it was bad call IMHO.
Yeah...but even if paperclip was clearly inferior (which I‚Äôm skeptical because it was *mature* which matters a lot), you don‚Äôt just deprecate a library that hundreds of production apps rely upon. I could figuratively hear managers striking Rails off their list with that single deprecation. A stack that can get deprecated at any moment is not a stack you should build a business on. 
I'm getting this error when I use cargo run: \----------------------------------------------------------------------------- `Compiling unicase v1.4.2` `error: couldn't read /home/eyss-dev/.cargo/registry/src/github.com-1ecc6299db9ec823/libc-0.2.51/src/unix/notbsd/linux/other/b64/x86_64.rs: Input/output error (os error 5)` `--&gt; /home/eyss-dev/.cargo/registry/src/github.com-1ecc6299db9ec823/libc-0.2.51/src/unix/notbsd/linux/other/b64/mod.rs:71:13` `|` `71 | mod x86_64;` `| ^^^^^^` &amp;#x200B; `error: aborting due to previous error` &amp;#x200B; `error: Could not compile \`libc\`.` `warning: build failed, waiting for other jobs to finish...` `error: build failed` \---------------------------------------------------------------------- Do you know how to fix it? thanks in advance! &amp;#x200B;
&gt;I had not yet heard about hazard domains, but I will take a look at the repository. As far as I understand them they're just a software engineering concept. Instead of mixing retired memory from multiple data-structures you can separate them out into multiple groups, each with a different collection frequency. I didn't examine your code too closely, so you may have already done this. &gt;I got the idea from [xenium](https://github.com/mpoeter/xenium), which is itself based on a paper proposing such an interface. Oh nice, I've never seen this library before. I know the author though, I've read his stamp-it paper. &gt;I have not yet made or run any benchmarks, but I surely want to, include comparisons with crossbeam (and maybe conc). This will be interesting. I recently open sourced [my stuff](https://github.com/DaKellyFella/concurrent-data-structures), but it's much *rougher* than yours though. Mine is a research implementation of multiple data-structures where you can benchmark and produce various performance statistics quickly. I found that correctly benchmarking concurrent data-structures to be very difficult as there's a huge parameter space and loads of ways to mess it up. My code allows you to swap out both allocators and reclaimers like you said but the interface isn't as clean as xenium's or your desired one, it's also still a huge work in progress. Anyway, thanks for your post, it's great to see people working on concurrency libraries. Best of luck.
Also co-hosted The Bike Shed podcast for years. That's how I first became familiar with Sean.
I think that text about memory-mapped files could be strengthened. Converting them to `&amp;str` is bad not just because of the upfront cost but because (unlike other non-mutable references) they can change at any time. IIUC, `&amp;str` makes a soundness guarantee of valid UTF-8 (thus `from_utf8_unchecked` being marked `unsafe). That's not appropriate when that data can be changed by other mappings (from this process or others) or `write` syscalls. I imagine file contents changing is why `memmap::MmapOptions::map` is unsafe. Any call to that should probably have a comment saying why the mapping won't change (e.g., it's `MAP_PRIVATE`, or no other programs are expected to run as the user with permissions to modify the file) or why the code is sound even if it does. (And an important special case is the file shrinking, causing a `SIGBUS` when accessing the mapping.)
I don't know if this is what bidirectional means. I believe the two directions is more about having two typing judgements: one where we can infer a type and one where we just check it. Here is a good tutorial on the subject: http://davidchristiansen.dk/tutorials/bidirectional.pdf
You can also use the [buffer](https://docs.rs/buffer) crate for this kind of read-initialization.
Yes, but the mmap issues go deeper. Mmaps can violate aliasing guarantees, even aside from the fact that the contents can be mutated to be invalid utf8. That is, even discounting the utf8 issue, mmaps still pose problems. This is why I don't think there is a robust/portable way of building safe APIs on top of file backed memory maps. Any time I use them in a crate, I always make sure the unsafe is propagated out somehow. (See the fst and grep-searcher crates for examples.)
The error messages is saying that it couldn't read the directory where the source file is located due to "os error 5". This seems to correspond to "access denied," so maybe you don't have the correct permissions?
I understand why it's so appealing to work with uninitialized memory, since for very high performance situations it's often required. But as BurntSushi pointed out above, unless you can guarantee the implementation of reader never attempts to read from the byte array, it's going to be UB. Technically, any form of assignment without using `ptr::write`, `ptr::copy`, or `ptr::copy_nonoverlapping` involves a read, since it needs to call `drop` (this will be optimized out for any primitive type, including `u8`, so the value isn't **really** read). Rust is very clear on this being UB even for primitive types, however, from the [docs](https://doc.rust-lang.org/std/mem/fn.uninitialized.html): &amp;#x200B; use std::mem; use std::ptr; // Only declare the array. This safely leaves it // uninitialized in a way that Rust will track for us. // However we can't initialize it element-by-element // safely, and we can't use the `[value; 1000]` // constructor because it only works with `Copy` data. let mut data: [Vec&lt;u32&gt;; 1000]; unsafe { // So we need to do this to initialize it. data = mem::uninitialized(); // DANGER ZONE: if anything panics or otherwise // incorrectly reads the array here, we will have // Undefined Behavior. // It's ok to mutably iterate the data, since this // doesn't involve reading it at all. // (ptr and len are statically known for arrays) for elem in &amp;mut data[..] { // *elem = Vec::new() would try to drop the // uninitialized memory at `elem` -- bad! // // Vec::new doesn't allocate or do really // anything. It's only safe to call here // because we know it won't panic. ptr::write(elem, Vec::new()); } // SAFE ZONE: everything is initialized. } println!("{:?}", &amp;data[0]); &amp;#x200B; Even though the array values are primitive integers, Rust is very clear that attempting to read any uninitialized value, even to assign to it, is **undefined behavior**. So very simply, there is no reasonable way to guarantee that you can safely read into uninitialized memory with the current Rust semantics.
hmmm, I just used: \`\`\` sudo cargo run \`\`\` But it failed again. I'm using nightly BTW
Alright I see. Thanks for the info.
Insofar as a complete lack of private ownership is the most extreme possible form of taxation, I suppose.
I think you are right. Check an expression against a type in [`checks_against`](https://github.com/JDemler/BidirectionalTypechecking/blob/master/src/main.rs#L210) and infere a type from an expression in [`synthesizes_to`](https://github.com/JDemler/BidirectionalTypechecking/blob/master/src/main.rs#L253) Of course the idea of using acquired knowledge to be able to type an expression more explicitly is also true. This is done by applying a context to a type as implemented in [`apply_context`](https://github.com/JDemler/BidirectionalTypechecking/blob/master/src/main.rs#L611)
FWIW ActiveStorage was just a good excuse to deprecate paperclip, not the sole reason. It had been without a primary maintainer for a while and was likely to end up deprecated one way or another either way
Good news for Rust. Sean is a great guy and has already contributed so much to us. Best of luck in securing the funds to do this, Sean. Like many of us, I would love to work on open source Rust stuff full time, but this is a rare privilege. The Patreon model is tempting, but I can't really see it bringing in enough income to support someone (especially if you live in a super expensive place like I do) unless you work on an extremely important or high-profile project. The idea of attempting it to support development of my Matrix project, Ruma, has crossed my mind before, but I'm just not bold enough to attempt it. (Not to mention the project is on hiatus anyway, so it's moot.)
you really do not understand what you are talking about please read some basic economics, and political theory: * Wealth of Nations - Adam Smith * A Discourse of Trade - Nicholas Barbon * A Discourse Concerning Coining the New Money Lighter - Nicholas Barbon * Discourse on Political Economy - Jean-Jacques Rousseau * The Social Contract, or Principles of Political Right - Jean-Jacques Rousseau Then you can start to hopefully have a better understand of the historical evolution of taxation and ownership. 
Thanks for the kind words. I am definitely in a position of extreme privilege to be able to experiment with this, and I know a lot of people don't have that opportunity. The lack of focus on folks who can't even get into open source at all unless they're compensated is something I've tried to be vocal about in the past. It took me a while to come to terms with even trying this since I know so many people cannot. I agree with you that the Patreon model is unlikely to bring in enough income to support someone. My main focus is on larger grants from medium to large sized companies, but what little income I can pull from Patreon will hopefully take a little bit of pressure off of finding those.
Rust is way better than Ruby by every metric, so it makes sense to put more energy into it. Yeah yeah there's a lot of stuff already in rails, by that argument no one would ever move to anything better. 
This kind of mentality isn‚Äôt just wrong, but it‚Äôs also wildly unhelpful to anyone. Ruby is a great language with plenty of compelling use-cases. Rust is a great language with plenty of compelling use-cases. Neither is strictly better than the other in all use-cases, not even necessarily in a majority of use-cases.
I think we're saying the same thing here about aliasing, which is a stronger argument than cost of two passes.
FWIW, this type-in-name convention is [Systems Hungarian notation](https://en.wikipedia.org/wiki/Hungarian_notation). The Rust API Guidelines book has a [Naming](https://rust-lang-nursery.github.io/api-guidelines/naming.html) section, though this mostly deals with method names, not fields or locals.
Name me one use case that fits Ruby but not rust?
It uses little endian by default.
Aaron has specifically called out what you're suggestions as a difficult (if not outright bad) idea. https://youtu.be/0sIgVnRAcn0?t=876
No. Byte strings don't fix the aliasing issue. This is a complex topic and it's one I've thought about a lot. See: https://users.rust-lang.org/t/how-unsafe-is-mmap/19635
I don't rely on `#[repr(packed)]`. I calculate size of a `struct` using `DesseSized` trait.
Zealotry isn't allowed in this subreddit. Please don't post comments like this again.
There should never ever be a need to run cargo or rustup with sudo; you should delete .cargo and/or .rustup and reinstall without using sudo.
Yeah, this is the basis of the idea. Bidirectional type checking is super neat because it allows you to extend your type checking to much more complicated and interesting type systems than Hindley-Milner type systems allow. For example I've been using it to [implement dependent type systems](https://github.com/brendanzab/rust-nbe-for-mltt). One of the interesting parts of the 'complete and easy' algorithm is that it integrates the bidirectional checking with Hindley Milner inference for simpler expressions.
Construct and return an object that stores the stream and provides methods that do things and return Futures. Maybe first try writing a class that handles line-oriented protocols by having `send_line` and `receive_line` methods.
The first is an interactive language shell. Python, Ruby, NodeJS are good for that. And getting applications like a simple webserver up and running quickly, or doing some quick parsing or algorithm work that I don't need to be maximally fast. I could write a web server in C if I had the time, but I usually don't. So then I consider if I have time for Rust or C++. I often don't, so I consider Go, Java, and C#, which take time, so then there's NodeJS, Python, and Ruby. Those are pretty quick to get something running in. And in many circumstances I don't care about squeezing out performance, so they are perfectly sufficient. If I'm pursuing very high performance I'll use Rust or C++, but for many things those take longer to write the code. 
Chapter 15.5 introduces RefCell&lt;T&gt; - there is some code that does self.sent_messages.borrow_mut().push(String::from(message)); I get what this is semantically doing but curious how this is syntactically valid. `borrow_mut()` should return a `RefMut&lt;Vec&lt;String&gt;&gt;`. How is the call to `push` valid, given this is a method of the underlying `Vec&lt;String&gt;`? Is some sort of deref coercion happening here? I can see derefer coercion is supposed to apply as per 15.2 rules: &gt; From `&amp;T` to `&amp;U` when `T: Deref&lt;Target=U&gt;` &gt; [...] if you have a `&amp;T`, and `T` implements `Deref` to some type `U`, you can get a `&amp;U` transparently. Which I guess seems _mostly_ legitimate, except that in this case the `RefMut` is not a reference _itself_ is it? It's a struct that contains a reference? Also when I think this through it seems like a _helluva_ thing for the compiler to infer. As usual, I haven't fully thought it through but dealing with multiple multiple Deref implementations and potentially colliding method names seems like quite the adventure. I see also that the String documentation says: &gt; Strings implement `Deref&lt;Target=str&gt;`, and so inherit all of `str`'s methods. In addition, this means that you can pass a `String` to a function which takes a `&amp;str` by using an ampersand (`&amp;`): Which seems to largely align with what I'm suspecting, - but I'm not sure if I've missed this previously mentioned in the book (I've been reading top to bottom) or it's discussed elsewhere. 
"Rust takes longer" is fallacy. [Here's a really easy to use rust repl.](https://github.com/murarth/rusti) There are web frameworks like rocket and actix that can spin up a webserver in less than a few lines.
C++ error messages: WAIT LOOK THERE'S AN ERROR DO YOU SEE IT OMG RIGHT THERE GET IT Rust errors: Dude you forgot to capitalize this
Awesome, this is so important for mature software. It helps so much when there are a lot of people working on the same code 
All you need to know is that he's the 10x hacker ninja guru. That's what it says on his work permit. https://mobile.twitter.com/sgrif/status/767474860981387270?lang=en
It's cool that there's a REPL, I didn't know that was practically feasible. But that says that it can't be used with any version of rust after `nightly-2016-08-01`. That's a while ago. 
Those web frameworks are *nowhere* near the level of maturity of Rails, and the REPL has been unmaintained for three years. Loving Rust is fine‚Äîit‚Äôs a phenomenal language, and really strikes an amazing sweet spot‚Äîbut let‚Äôs at least be honest about its strengths and weaknesses. 
I'm building a Redis cluster solution in Rust! [https://github.com/doyoubi/undermoon](https://github.com/doyoubi/undermoon) And I posted a little sharing on how Rust help building it: https://www.reddit.com/r/rust/comments/b8kjzz/a_new_redis_cluster_solution_in_rust/
I agree byte strings alone don't fix it. I'm sorry if I was unclear about that. There are a lot of pitfalls to consider, and valid utf-8 is just one of them. Thanks for the link to that thread. But attaching `&amp;str` to RAM that might change is unfixably unsound by itself. As I read your docs, they're taking about poor performance of `&amp;str` when this unsoundness is a much bigger problem. It seems incomplete to mention a performance problem when soundness problems exist.
 I also don't use this "all" flag, because I like to take a look at my work and see if it needs to be separated into different logical commits, sometimes it isn't beneficial to have everything lumped into one, with a single description. Doing it this way also makes it easier to cherrypick some feature/change if required on another branch. 
In the grand scheme of things, if you have the recognition to make it possible, then personally I think many will accept it for the greater good. Perhaps one day open source development will see more funding, but I am definitely hoping you get a shot at full time open source development. You have my üëç.
This reminds me of frank's \`abomonation\` crate, which is also super fast, and uses size of types to do better se/de. However it supports \`Vec\`
Oooh! I kinda toyed with the idea of writing an `init` process in rust. But a whole distro? This sounds like a great idea! &gt; I intend to use existing Rust projects when I can There's a [`coreutils`-in-rust project](https://github.com/uutils/coreutils) worth a look. Also there was a libc-in-rust project at one point, I think. Are you using glibc, musl, or do you already have a rust C lib?
(note to you and others here: sean uses they/them pronouns)
There's also [relibc](https://gitlab.redox-os.org/redox-os/relibc) that the Redox OS team is working on. It's libc implementation in Rust (currently still very new, and I don't think it's feature complete yet).
Check out redox os, I'm sure there will be a lot of reusable parts. Such as there shell ion for example.
There is a libc project in rust called relibc, it was created by the redox team to port software over. As far as I know it supports linux syscalls to.
I would start with the easily accomplished bits first. Coreutils first, then a shell, then init. Easily achievable milestones, then harder ones as the project grows and you find that the replacements are actually useful.
I agree in the context of C programming. But, in general, memory safety doesn't *sound* like much of an improvement over GC, so it wouldn't cause most Java/C#/JS users to switch.
Didn't see a link to the docs [https://docs.rs/aerosol/0.2.0/aerosol/](https://docs.rs/aerosol/0.2.0/aerosol/)
I feel we really need a customizable OS, basically a set of traits to define a scheduler, libc, userspace (filesystem and what not) and many more. Basically make a unikernel composed by a set of traits that can be re-implemented per trait. It would also be a great way to teach about OSs, since you can build only a specific "module".
Can you elaborate a little bit on what specific components you're adding? It sounds like this isn't a full Distro. Can bash interoperate with it?
&gt; C is more complex than assembly on any platform As someone who has previously written a non-trivial amount of assembly, I'm not sure I'd agree with that. In fact, I'd say C is vastly less-complex than assembly.
&gt; I wish I knew why Drew was so irritated by this My guess is he probably gets several requests a day/week from people telling him 'hey, you should rewrite that program you made in Rust'. That's going to get get tiring after a bit.
C _as a language_ is more complex than assembly. There are more things you can do with a single statement in C than with a single statement in assembly, in the same way C++ is more complex than C.
On this note, you should probably never be running tools relating to programming languages (`gem`, `npm`, `go`, `pip`, etc.) as `sudo` as they typically can exist in your user environment just fine unless you explicitly want them to be available for all users. It simplifies the permissions headache later.
This is very interesting. I also created a math expression parser/evaluator as my first Rust project. &amp;#x200B; You may find it helpful! [https://github.com/chmln/asciimath-rs](https://github.com/chmln/asciimath-rs)
Sean has done a lot for Rust already. If he was willing to work on Rust full time, I'd hope that Mozilla would be looking to hire or sponsor him in some capacity.
Chit: (Crate help in terminal): [https://github.com/peterheesterman/chit](https://github.com/peterheesterman/chit) A tool for looking up details about rust crates without going to [crates.io](https://crates.io), try it out. 
Owh.... You stole my idea :-( Anyway, would you consider releasing under GPL3?
Really interesting idea. Would love to see issue 11 (*Tell me if there is unsafe code in the crate i am looking at*) come to life ([https://github.com/peterheesterman/chit/issues/11](https://github.com/peterheesterman/chit/issues/11)) 
Cheers, a project that might interest you on the topic of unsafe rust analysis [https://github.com/anderejd/cargo-geiger](https://github.com/anderejd/cargo-geiger).
How does one `.map()`?
You've largely got it actually. It's deref coercion. You can see [here](https://doc.rust-lang.org/std/cell/struct.RefMut.html#impl-DerefMut) that it does implement `DerefMut`. Some people do get annoyed by automatic dereferencing, but it's largely a good thing. Any slight bit of confusion is better than the sheer *annoyance* in having to figure out exactly how many times you need to be dereferencing. It means that all you need to know is what your type implements, and what traits the structs that dereference from your type implement, and so on. It can get kinda wonky, but that's why it's typically discouraged to just impl deref for everything. It's an [anti-pattern](https://github.com/rust-unofficial/patterns/blob/master/anti_patterns/deref.md), but the `std` library uses the feature well. In the cases you do want to say which particular type you want to call the impl for, see the [Fully Qualified Syntax](https://doc.rust-lang.org/book/ch19-03-advanced-traits.html#fully-qualified-syntax-for-disambiguation-calling-methods-with-the-same-name), though it's not often used. It's generally not necessary, and with most stuff, `deref` coercion is implemented properly and isn't conflicting. I haven't had an issue with it so far. Keep in mind that this feature allows us to use smart pointers, since very few pointers are actually fully built in. Without it, smart pointers would be a big pain to use, almost as big as using them in C.
I'm working on an small symbolic evaluator for MIR i want to produce a tool to be able to decide if two functions are equal (equal meaning to produce the exact same results for every possible input), the code can be seen here [https://github.com/christianpoveda/sire](https://github.com/christianpoveda/sire).
&gt; Is anyone else getting this issue? Same thing here
Rust web frameworks are basically unusable right now, sorry. It sucks but even though I love working with Rust I cannot bear doing anything web-related that's even *remotely* complicated. I was playing around with diesel + actix-web but it was so tedious and verbose versus just spinning up a rails-api or padrino instance. I was able to get a data-entry application with a complex nested-resource form up and running in less than a day. The maturity of rails (and padrino/sinatra) means resources already exist to handle things like session storage, csrf protection, routing, etc, quickly.
Hey, Nice work! I think r/ProgrammingLanguages will be happy to see it too :)
perhaps the `?` should be syntax highlighted, cause you know... safety and whatnot. 
`cargo run` is problematic for things that need root to work (like talking to GPIOs on the Raspberry Pi).
Serde is really well optimized and with LTO on it shouldn't add any overhead to just writing serialization by hand (or none that typically shows in benchmarks). I think the difference is more likely due to things like not having to do an allocation for the output buffer, and not paying the cost of incrementing a write pointer and checking for bounds since everything is known at compile time.
Tweet showing the issue: [https://twitter.com/Garyw\_/status/1113339674033049600](https://twitter.com/Garyw_/status/1113339674033049600) &amp;#x200B; Will be fixed shortly, I am sure.
That's a bit aggressive. Some of those are huge projects, ie systemd, Wayland.
&gt;With your own benchmark I'm getting around 35 MB/s. Compare that to the lexer in Ratel which is running on my machine atm at 1446 MB/s. Different benchmarks and there is some stuff you do that I skip (like unescaping stuff in strings), but that's a pretty big gap. Thank you for pointing out Ratel, your Lexer seems to be very optimised for speed. It's like 40x difference. I accept your challenge üòÅ. Have you also checked the source code? How do you think I could improve the performance even more? I think the best optimisation right now would be to use better hashing function. Phf's hash is quite complex to compute. I think I could achieve the same results with very simple operations. I have 0% branch missprediction for small files thanks to hash map. Before that experiment I was using *switch* statement which had branch missprediction at around 4% but speed was 3x faster. But I have really strong feeling that Hashmap is the right solution but I need a better hashing function
Right, thanks! Coming from a C# background the care with which I need to think about references is doing my head in. Can I just sanity check my line of thinking regarding: &gt; [...] if you have a `&amp;T`, and `T` implements `Deref` to some type `U`, you can get a `&amp;U` transparently. Is this strictly literally correct? It seems like I can get away with a T alone and not a reference to it. As in, let a : RefCell&lt;String&gt; = RefCell::new(String::from("hello")); let mut b : RefMut&lt;String&gt; = a.borrow_mut(); b.push_str("world"); println!("b value is {}", b); let c : &amp;mut RefMut&lt;String&gt; = &amp;mut b; c.push_str(" fizzbuzz"); println!("c value is {}", c); Am I right in thinking that: * `b` is not a reference. It's a struct that _contains_ a mutable reference to `a` * `c` _is_ a reference. It's a reference to a struct that _contains_ a mutable reference to `a` * Calling `c.push_str` is basically doing 2 deref coercions? So derefer coercions can happen on (a) actual reference variables, and (b) non-reference variables that implement the `Deref&lt;T&gt;` or `DerefMut&lt;T&gt;` traits? ** Am I thinking about this fundamentally in the wrong way? are (a) and (b) the same thing? (Hope this doesn't seem too pedantic, but but much like the early-defect-detection, I find investing time into catching defects in my thinking as early as possible is a long-term time saver) 
I have some sort of similar problems before. I want to use `spatialite` library, this library based on several C++ libraries plus `sqlite`. I also want to use `rusqlite` (Rust wrapper around `sqlite`) to work with `sqlite` directly. And obviously I do not want to have two `sqlite` inside my code, one for `spatialite` and one for `rusqlite`. So I use `build.rs` + `cmake crate` to build `spatialite` and all its dependencies including `rusqlite`, and then I use special features and environment variable to force `rusqlite` pick `sqlite` that I build, and reexport `rusqlite` from my crate to other crates in workspace. And in such way I can have only one `sqlite` instance in binary. &gt; We have a C++ library that we're interested in wrapping in Rust and then gradually porting If it all happens inside one crate, you can dig from both sides, Wrap C++ with C and use C API to wrap with Rust code (external), and use cbindgen or rust_swig to replace part by part of C++ code with Rust (internal)
This is an exact copy of someone else‚Äôs comment from another sub. 
I wanted to say at this point just skip the Linux kernel (or abstract it away) and target redox. Would definitely be cool to have a rust userland which could run on Linux and the Redox kernel.
You just invented microkernels.
have you build with \`cargo build --release\`? If you don't know what this means, you probably want to /r/playrust :) 
idk but i need to know if its issues with my pc or game i have latest version of rust i have verified files mutiple times 
But that's the nature of FOSS. If you reeeeeeeeallly need support, get a support contract. Or budget for supporting your upstream dependencies in-house.
You have to install packages. First thing to do is to delete C:/ drive properly. Then install Arch Linux.
I think you might be in the wrong subreddit This one is for the Rust programming language, not the game
- Sees *Nonbinary/Polybinary/Polynomial/ApacheHelicopter/Nuetral/Nootripic genders* - Opens up Jordan Peterson &amp; Shapiro videos Feels better.
Just glancing over it now, doing nested enum for token is going to slow you down. Eg. `StringLiteral(String)` variant makes your entire `Token` to be 4 words (tag, pointer, length, cap), so on 64 bit arch every token is 32 bytes. In Ratel token enum contains no data other than the tag so it's always 1 byte. Those things only really matter when you do really performance sensitive stuff (lexing this tends to be). Using intering for identifiers seems an odd choice to me, you are much better of just borrowing `&amp;str` slices from source insitu (this makes both lexing and then accessing data faster). If you insist on unescaping strings, then using `Cow&lt;str&gt;`, or better yet `CowStr` from [`cowvec`](https://crates.io/crates/cowvec) would allow you to also borrow slices from source in case there is nothing to unescape (which is like 90% of all strings), avoiding all allocations. You can try swapping your hash to [`rustc-hash`](https://crates.io/crates/rustc-hash), which is probably the fastest algo you will find (it processes up to 8 bytes of input at a time, Firefox and rustc are using it), but be weary of collisions (the collision rate is higher than FNV-1a proper that processes 1 byte of input at a time). I'm not convinced you avoiding branch misspredicitions at the cost of having to compute the hash is going to be a win here. Ratel pretty much embraces branching everywhere, with a catch - the first byte of a token goes to a lookup table and then it branches from there - so if you have a token starting with `f` it will continue reading it one byte at a time checking whether or not it produces `function`, `for` etc. In general the best principle I found when it comes to building lexers is making sure that every byte of the source is read and checked once and only once, that usually means building a state machine (either with tables or code branching). [Logos](https://github.com/maciejhirsz/logos) is the culmination of that (it's basically the lexer from Ratel, but generic).
Lol, "dying"? I thought Rails already died somewhere around 2013.
I think we're at an impasse. I can only repeat myself so many times. :-/ Byte strings don't fix the soundness problem because the soundness problem isn't limited to the utf8 invariant.
Damn it, I was about to post, but my freaking computer froze and crashed. I was able to snag a pic, so at least I have a few paragraphs with explanation before I retype. It's worth it! Spreading Rust is worth it! :P Also, please ignore any grammar errors. I had to rewrite most of this and it's also 6am. I'll be happy to clarify further tomorrow, but I *need* to get this out since I started at 4:30 and it takes 45 min to write a single copy. :/ --- &gt;Right, thanks! Coming from a C# background the care with which I need to think about references is doing my head in. It's fine, I come from a Java background. A big part of it is just explicit pass by reference instead of implicit. Lifetime stuff comes with practice. &gt;Is this strictly literally correct? It seems like I can get away with a T alone and not a reference to it. Yes-ish. `String` derefs to `str`, but since `str` is unsized, you have to have a reference to it. (Essentially, the length of str is unknown at compile time, so at runtime there must be another `usize` saying how long it is. It's like how you have `Box&lt;[u8]&gt;`, which is essentially a unique malloc'd buffer with length included.) Types which implement `deref` are all smart pointers, so even if the thing itself is just a struct, it's going to return a reference of some sort. And besides, it takes in a reference, too. `&amp;T` to `&amp;U` and `&amp;mut T` to `&amp;mut U`. --- `b` is a struct called RefMut, one field of which is a mutable reference (`&amp;mut T`). Since the struct `impl`s `DerefMut` and `Deref`, `b` can also be called a reference, even though it isn't strictly `&amp;T` or `&amp;mut T`. Kind of like how there is *the* immutable/mutable reference types (`&amp;T` and `&amp;mut T`), and immutable/mutable references (types which `impl` `Deref` and `DerefMut`). The second ones use the first ones (or just normal `*const T` or `*mut T`), but can have slightly different extra behavior, typically actions taken when dropped (like unlocking a RefCell or Mutex), but also have abilities like `clone` for duplicating an Rc or Arc pointer without cloning its internals. (Here's where I run out.) Look at [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=63f5aa090f365b1de635f3f5207381e1) Rust Playground. (Fuck my computer just crashed again. Thankfully I just installed an extension for this. Thank you Formalizr! I blame disabling Npcap Loopback Adapter.) Look at the second section. What I've done there is converted the call to explicitly use the receiver in a normal function call notation, instead of a method call. Notice how the second `push_str` is just `c`, but the first is `&amp;mut c`. This is because function calls automatically add your necessary reference to the receiver fit it into the function call. Then, it adds the auto derefs. So, both actually only do a `&amp;mut RefMut&lt;String&gt;` to `&amp;mut String`. For the second one, you can also plug in, instead of `c`, `&amp;mut *c`, which returns you to where you started. You can do `&amp;mut **c`, which will be doing that explicit deref. You can try `&amp;mut ***c`, but that's just a `&amp;mut str`, so it won't compile. You can also do a `c.deref_mut()` if you add the necessary `use`, which will automatically return as an `&amp;mut` for you, which is `&amp;mut String`. `Deref` and `DerefMut` only happen on Smart Pointers. Or really should only be implemented on smart pointers, and doing otherwise is an anti-pattern. Thus, you can more or less think of them as references. It's just that they have some special useful behavior you want, but need to actually be deref'd to actually go into functions. I think I've seen some places where the method receiver type isn't just `T`, `&amp;T`, or `&amp;mut T`, but some other pointer type, but I can't quite remember or find it. And it's pretty late right now. They don't really happen on normal references, because those are built in, and are ultimately what the data operates on. Kinda like how there's an `Add` trait, but it looks kinda dumb for normal number types, since that's intrinsic to the compiler and doesn't really make sense. Deref is also weird for Box, which is also built-in due to historical reasons. DerefMut just ends up trying to move types out of stuff, or you use it to assign or change an actual variable when you get down to that level, instead of dereferencing to another reference. --- &gt;(Hope this doesn't seem too pedantic, but but much like the early-defect-detection, I find investing time into catching defects in my thinking as early as possible is a long-term time saver) Naw, it's fine. This pedantry is as important as learning about the Stack and Heap. If you really wanted to be pedantic, learn Haskell, where they build the newest programming language research with entirely too much (or just enough) math. Crazy place. &gt; much like the early-defect-detection, I find investing time into catching defects in my thinking as early as possible is a long-term time saver This is literally the Rust philosophy. Figure out the problems up front with your code so you don't have to deal with them later. Less debugging and no memory problems/threading problems (though deadlocks still possible). It is unbelievable convenient knowing that if your code compiles, there aren't going to be major problems with your code. It's amazing when you begin to understand the compiler; it's like river that makes your programming boat go so much faster. Using it with CLion/Intellij is heaven. I'm really happy some other people have a similar philosophy. :) If you have any other questions, feel free to ask, though I'm no Rust master (though I have been following since 1.0). I've also had to write this post 2 times, so forgive any mistakes or lack of clarity; I'm really exhausted and it's super late. My original had more detail, though this may or may not be more concise. Again, I'm fine with clarifying any further conclusions; it's nice helping people. :)
You have to wrong place bruh... go to /r/playrust
Thanks! I posted it there as well.
Just trying to learn Rust
Yeahh, but isn't the whole idea of microkernels based on IPC? Whereas what @pleurplus is proposing would eventually be built into a monolith kernel. At least that's how I understood it :)
2019 is binary comptabile with 2017 so there is no issue to use it. Personally used RC 2019 before I had to switch back to 2017 for C++ project
same here. And browesr does not offer "exception", due to Http Strict Transport Security (HSTS) being used for that domain.
Mozilla has already sponsored me for the first few months of the year
New ideas are certainly worth exploring. Make sure to remember, "those who don't understand Unix are condemned to repeat it, badly".
If they use let's encrypt, I use a systemd service to automatically sign new certs when needed. Might be useful here 
I think these concerns apply to a list curated by a given person or team. (How should they decide who to include or not?) But maybe this wouldn‚Äôt be as much of an issue if there‚Äôs a list where anyone can add or remove *themselves*? Although there‚Äôs still the question of what order to display the list in.
Yes, I probably misunderstood what he was saying. Is that not how kernel modules work, thoughm
Yes. When you use safe operations, both variables of the same time exist in same scope and you mix them up you can potentially wrong result. The main difference here is safety of the operations. Bad number crunching without unsafe operations involved will not create security problems in your software. It also permits program to output correct results in other cases because it didn't crashed ;) You can't have all possible errors found at compile time, but Rust can find more (few whole categories of errors more). Only in Rust you can safely pass around bare references to stack variables and fields without incurring overhead of smart pointers. And there are little to no downsides. I admit there are few: * Compilation times is bit longer. * Types depending on constants not supported yet. * Variadic templates don't exist (probably just yet). Most C++ programmers think that `Arc&lt;UnsafeCell&lt;T&gt;&gt;` being most close to equivalent of `std::shared_ptr&lt;T&gt;` make them think that Rust requires lots of boilerplate code and borrow checker fighting. But it is not really true. You just need to pay attention to safety and not use `unsafe` unless you really need it.
At that point, it make more sense to go all the way and make a multi-stage Rust ala [MetaOcaml](http://okmij.org/ftp/ML/MetaOCaml.html) or [LMS](https://scala-lms.github.io/). 
*something something halting problem* Apart from that, sounds like an interesting project!
First of all, why can't you do it the normal way? Do you maintain a library that exposes a struct whose fields are all public and now, you'd like to add more fields (of any visibility), thus breaking user code like `let s = S { a: 6, b: 7 };` rendering your crate backwards-incompatible? Either way, a trait can contain these items: Constants, types (called 'associated') and functions. Nothing else. With 'contain' I mean that **any** type T (not just structs) that implements the trait needs to implement those items. Fields are not items and not part of the trait system. Of course, fields can be emulated with functions. Not sure if you want to go in that direction at all, but here we go. Suppose we want to add a new field `c` of type `C`, then we might need `fn c(&amp;self) -&gt; &amp;C` (getter/viewer), `fn set_c(&amp;mut self, c: C)` (setter). We can now view and modify the potential field. Unfortunately, we cannot construct such field, we need to store it somewhere. A trait cannot store anything (and _trait objects_ can only store methods), we need an additional struct. Let's say the struct we'd like to extend is defined like `pub struct S { pub a: i8, pub b: i8 }` and our extension struct/additional store like `pub struct E { pub c: C }`. Equipped with those things, we get a **undoubtedly unsatisfying solution**: trait CExtension { type Store; fn c(&amp;self, store: &amp;Self::Store) -&gt; &amp;C; fn set_c(&amp;self, store: &amp;mut Self::Store, c: C); } impl CExtension for S { type Store = E; fn c(&amp;self, store: &amp;E) -&gt; &amp;C { &amp;store.c } fn set_c(&amp;self, store: &amp;mut E, c: C) { store.c = c; } } // user code fn main() { // line below does *not* break let s = S { a: 6, b: 7 }; // users who'd like to use the field `c` // need to manually create the store let e = E { c: C::new() }; // print s.a and "s.c" println("s.a{}{}", s.a, s.c(&amp;e)); } The `self` parameters are unused in the bodies and could be removed. I added them to get the short method syntax. `S` and `E` are loosely coupled and I do not think you can do it tighter than that without adjusting the definition of `S`. This likely is an [XY Problem](http://xyproblem.info/), please state your actual problem if it's still unsolved!
You pass it a function, that gets applied on each element of the source iterator. If you want to store the return value, you have to `.collect::&lt;Vec&lt;_&gt;&gt;()`, since it also return an iterator. Example: https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=caa38e6141aa1b24d0daeb8714b5772d
Well almost their entire userland already compiles and runs on linux. The only part I'm not sure about is there init system. Also relibc is linux compatible. So the way I see it is this two projects can really benefit from each other.
There is a bug filed for this: https://github.com/cmr/this-week-in-rust/issues/880
We are aware of this issue. I've emailed /u/cmrx64 who manages the server. He is Pacific time zone where it is still quite early morning. I'd expect it to be fixed in next few hours.
Man I wish we had a more common .. singular sounding pronoun. Not that I'm against any of this, it just sounds foreign to describe a singular person as multiple people. Again, not challenging any of it - just commenting on my difficult to adapt :)
Good luck, and hopefully it works out well for you! 
It's not describing a singular person as multiple people: https://public.oed.com/blog/a-brief-history-of-singular-they/ https://en.wikipedia.org/wiki/Singular_they
I wasn't making a factual statement _(sorry if it sounded that way)_, but rather that in my common usage I'm used to "they" representing multiple people. I was not debating the grammar or historical meaning of the word. And again, I meant no offense to anyone, just describing my struggles to adapt. :)
Please no one take this the wrong way, I'm genuinely trying to get a better understanding of things here (and maybe Sean can provide an answer themselves): in their case (and the case of others, I'd assume) is the preference for "they/them" more a way of expressing solidarity with / their general support for the LGBTQ community than it is related to how they personally want to be "viewed"? Just because (to the best of my knowledge) Sean is a biological male, who does not appear to have ever attempted to represent themselves as anything other than specifically a man, which makes other reasons they might prefer "they/them" not immediately clear to me.
Been taking a bit of a break from data analysis stuff and noodling around with actually writing a little bit of a game. In the process I seem to have accidentally brought [`ggez-goodies`](https://github.com/ggez/ggez-goodies/] and the [`ggez game template`](https://github.com/ggez/game-template)... well, not quite up to date still, but a lot more up to date than they were.
I suppose you are using `specs`: In ECS, Entity is just an `int` as an index of `Storage&lt;components&gt;`. The object is a kind of abstraction over that relationship. Therefore, if you need a real struct to represent that. Here are some code example: ``` #[derive(Serialize, Deserialize)] enum SpawnAbleObjs { Player { id: String, base_atk: u32 }, Troll { id: String, base_atk: u32, height: u32 }, } // position is a variable attr of something, which determined when spawned. // You can extend it as spawn_at_pos_with_hp()....etc.... trait SpawnAble { fn name() -&gt; String, fn spawn_at(pos: (u32, u32), lazy: specs::world::LazyBuilder); } impl SpawnAble for SpawnAbleObjs { fn spawn_at(self, pos: (u32, u32), lazy: specs::world::LazyBuilder) { match self { SpawnAbleObjs::Player =&gt; {}, SpawnAbleObjs::Troll =&gt; { lazy .with(AiComponent) .with(CollisionComponent) .with(Position {pos: pos}) .build(); } } } } struct InstanceFactor { map: HashMap&lt;String, SpawnAbleObjs&gt; } // We can load this from a file using serde: // see https://serde.rs/enum-representations.html impl InstanceFactor { fn read_from_file() -&gt; Self; } impl&lt;'a&gt; System&lt;'a&gt; for InstanceFactor { type SystemData = (Entities&lt;'a&gt;, Read&lt;'a, LazyUpdate&gt;); fn run(&amp;mut self, (entities, lazy): Self::SystemData) { let spawn_list = vec![("Player", (1, 1)), ("Troll", (1, 1))]; for (name, pos) in spawn_list { let lazy_builder = lazy.create_entity(&amp;entities); self.map[name].spawn_at(pos, lazy_builder); } } } ```
That clarifies things, thank you. 
Cool project! Do you have any plans on what to do with the data? I think I remember seeing some AoE II clone that *might've* been in Rust, though I'm probably confusing it with something else. I did [something similar](https://github.com/fkaa/ae/blob/master/src/format/slp.rs) a few years back but didn't really get any further than parsing (and rasterizing) SLP files, along with discovering some pretty cool (hidden?) sprites ([a cat riding a shark wearing a chef's hat strapped to a pair of rockets](https://i.imgur.com/2sQPAxC.gifv)). As for writing DRS files; other than temporarily writing things to tmp files you could probably pre-allocate quite a lot of space for tables, since the DRS file header specifies (IIRC) both the number of tables *and* the byte offset to the where the table data starts. I'm not sure how well the game would handle that though..
I'd would be great to see Mozilla hire him as full time, especially now that he has set his goals.
That's the good thing about discussions: you never know in advance what they're going to produce.
You pass it a function, you don't pass it \*as\* a function. Put another way, map takes a function or closure as an argument.
Ohh. Humorous me. 
It might be about "just" expressing solidarity. However, what is more probably, I think, is that it's reflective of a genuine feeling they have that masculine identity doesn't *entirely* describe themselves. That doesn't necessitate that you go out of your way to dress differently, or talk differently, or adopt some other identity. It just means that you don't fit neatly into the specific category denoted by the words 'man', 'he', 'him', 'his', etc. Might also be that they are actually intersex, and simply present as male for convenience. There are lots of different reasons why someone might prefer different pronouns, and not all of those reasons have to do with being full-on trans. 
Maybe some kind of randomization of the order each time the webpage with the list is viewed would be fairest...?
Fuck that. I'm fully supportive of LGBT rights, but demanding that everyone use a specific non-traditional pronoun for you just seems so self-absorbed. It's literally asking everyone to ignore the hundreds of thousands of hours we've spent using speaking standard English (male or female pronouns) and remember to use a non-gendered form *for this one specific person.*
Nope, but I wish there would be more people beautifying the diffs :-/
 &gt; We'd rather not have to maintain a fork of std::collections::Map for just this feature, if possible. You probably can't avoid it. Lua implemented a hashtable and later wrote the [specs](https://www.lua.org/manual/5.3/manual.html#pdf-next) for what happens during 'unsafe' access : &gt; The order in which the indices are enumerated is not specified, even for numeric indices. (To traverse a table in numerical order, use a numerical for.) &gt; The behavior of next is undefined if, during the traversal, you assign any value to a non-existent field in the table. You may however modify existing fields. In particular, you may clear existing fields. --- So your options are : **Exact copy of lua**: Even using a different hash function will give a different behavior. your best bet is to completely re-implement their next method and table. **Follow the specs**: Maintain a fork. You don't have to worry about invalidating memory locations for most implementations because its UB creating new keys during iteration. But you have to watch out how you iterate over removed values . **Ignore the specs**: Modifying a table during iteration is one of the dumbest things you can do in any language. Put it behind a lock and don't allow it. --- I would choose the last and call it a feature. Code getting caught doing this should be modified anyways. 
People use singular they all the time in natural English speech. If it really bothers you, you can always refer to someone by their first name instead of a pronoun. Your unwillingness to make minor adjustments to how you talk about someone is more reflective of your own shitty attitude than anything about California. 
 *their. Sorry. Couldn‚Äôt resist. 
Actually, when referring to me in second-person singular, I'd prefer the pronoun "zhu" instead of "you". And for possessive: "zhur". Please remember this when replying to me in the future.
Well, Kafka is not ideal for ES. But there are almost no solutions that are ideal for it, sadly. Plenty of users out there utilize Kafka for ES, even if it's a suboptimal solution.
I think you would enjoy life more if you spent more time trying to understand the lives of others rather than immediately shutting down when presented with someone's experience that isn't congruent with your understanding of the world. Living with such anger and cynicism when confronted with the mildest inconvenience of someone trying to be happy seems like a miserable way to live.
In with the obligatory "Zero knowledge execution? Sounds like my boss' resume!" post
Couldn't that give you a false sense of security if the crate you are looking at doesn't directly use unsafe, but one of its dependencies does? And you can't just recursively look for unsafe in all of its dependencies, because surely somewhere down the line basically every crate relies on unsafe. 
What distinguishes it from other languages?
Sounds like an executive-level job requirement.
Why are functions prefixed with $?
Can you make sane line endings default? "\r\n"? '\n' is just crazy
Would you consider providing a slightly bigger example? It's a bit hard to get my head around this one.
You're really assuming a lot about my background, emotional state, and motivations from a trivial difference of opinion on a specific subtopic of a gender issue. &gt; mildest inconvenience I notice you didn't reply to me as "zhu". My point is really going over your head, isn't it?
Is it similar to intel TXT but without the HW requirement ?
builtin values ( functions,objects etc)
&gt;What distinguishes it from other languages? So far, it is no different from other languages like Python and Lua, but I would like to make this language more functional and write self-hosted compiler in JazzLight itself
That's one way to understand it, yes.
Yes, in those cases I always use something like `cargo build &amp;&amp; sudo target/debug/twitter-bot-rs`. Same for `strace`.
It wouldn't be a bad idea to remove it as it's often quite annoying to type, like in PHP.
And soon it will be used to fuel crypto pedo coins. :/
Well if nothing else, I appreciate more competition in the bytecode/VM space
Do you have a a typical use-case in mind?
Yup, and it makes it easier to bisect to find the cause for a bug, revert a single change, and resolve conflicts between branches. Sometimes I'll do a code review by stepping through individual commits if the total amount changes is too large to grasp all at once. I like doing `git add -p` followed by `git stash --keep-index` to make sure that each commit compiles and tests pass if I'm going to break a change into multiple commits. However, many people I work with don't, and it's frustrating when a problem arises.
I'd say it's the opposite! ;)
That is super-cool. What's the patent status of this thing?
Why does everything with America have to come down to "my vs your rights"? Why can't we just be goddamn nice to each other without getting into a debate about what words some random people wrote down on paper 200+ years ago. If you don't want to accommodate the request, then fine don't. Nobody is forcing you to. But don't expect courtesy from anyone else when you can't be bothered to give some.
Like... you don't have to honour someone's pronoun requests? Or even be good at it. I misgendered someone at RustFest Paris (ie not the Bay Area), she corrected me, I said "my bad" and we moved on. Alternatively I could have had a big hissy fit about it, or deliberately misgendered her from that point on. Depending on how you approached it you might look like a massive or minor jerk, but you definitely aren't being forced to do anything. People will warn you you're being a jerk or they just won't hang out with you and you in turn get to be however you want.
yes the reason I asked is because `rust` can re-size, and re-order field layout. `#[repr(packed)]` lets you ensure different compilers (even C/C++) will understand your structures (well `#[repr(c)]` will as well, but `#[repr(packed)]` ensures less padding)
You can also set `sudo` as the "runner" in your `.cargo/config`: https://doc.rust-lang.org/cargo/reference/config.html#configuration-keys. Then just a normal `cargo run` will build the binary as your user and then run it with sudo.
Actually, to participate in this forum, you have to honor pronoun requests, it's misgendering to not do so. It's understandable if you didn't _know_ that someone's pronouns had changed, but once told you are expected to use them. People are free to draw the line anywhere, but we as a community are also free to draw the line in excluding them.
Many common errors can be caught with proper types. While many operations in C++ are unsafe by default, it does not mean, you cannot navigate around them. I avoid pointers unless they are really needed, in very rare cases. I like Rust and Haskell if I want to have safety by default. Sometimes you're in a team where you need to choose a common language by majorities. It's mostly possible to navigate around problem with some effort and then you're just proud to have found a solution. On long term, it's crap, but who cares, if you have enough proud moments.
Skimming through the linked paper... going to read that more in details tomorrow. My favourite combination: cryptography and Rust!
Yeah they were decribing kernel modules. Which generally are considered part of a hybrid or monolithic kernel (microkernels tend to run the drivers in userspace instead of as kernel modules.) Of course there's also no hard and fast definition of the terms so everyone can interpret them differently.
That's ... definitely not how I'd write it.
 &gt; (os error 5) On linux this is `EIO`, so I would expect this to be like, out of disk space, disk corrupted, or something like that. 
Does anyone know if videos from the Latam conference are going to be available?
I've been doing [Raytracing in One Weekend](https://github.com/petershirley/raytracinginoneweekend), and I'm starting to see that raytracers are seductive little things, and great for learning. I've recently been brushing up on some linear algebra, and working on my raytracer has been a great review of vector math, and they provide a lot of opportunity to test out different abstractions and are complicated enough that performance matters. I hope to read PBRT one day.
Getting ready to give a conference talk on Grapl, which is largely built in Rust. &amp;#x200B; [https://github.com/insanitybit/grapl](https://github.com/insanitybit/grapl) &amp;#x200B; At least one section of the presentation goes over the Rust code and why I chose it - safe, efficient log parsing. Lots more to do though.
The problem with these is that if we do that as a project, we'd still endorse and that opens a whole can of worms. (Do we really want to endorse _everyone_?) There's already been a couple of cases where this is a relevant question. You'd still have to curate.
I see what you're saying, it might be useless unless you bubble up the most offensive dependancy state of safety, great point. Not sure how to attack this problem yet practically either. I guess I need to look into some more of the core crates that everyone is depending on and figure out if they all do just call out to unsafe code or a c binary down the line. I would hope we are getting to a point where ***some*** of them are completely "safe" by now. Am i just naive? 
The entire project smells like hell. From the author's [comment](https://github.com/uutils/coreutils/issues/1342#issuecomment-467579845): &gt;Supporting Unix (with special code for just macOS, Linux, etc. sometimes), Windows, and Redox can necessitate more complicated code. But then these guys simply crammed in cross-platform logic into each binary. F, buddy, F. Also, [this translation part](https://github.com/uutils/coreutils/blob/master/src/echo/echo.rs#L109) of echo better be split into a function. The one who put that there is clearly a madman, and the maintainer who accepted such atrocious commit is not doing his job at all. &amp;#x200B;
Very good. Please say me how you run alacritty without xlaunch or it alternative?
Why is a month old issue suddenly being posted here? The OP of that issue, even though they say "not trying to be hostile", clearly is.
Didn't I read that those coreutils are not drop-in replacements? If you want people to use it, it needs to be compatible. If you don't care about compatibility then why not spend time doing a complete redesign? I like the idea though.
If I'm understanding you correctly, which I may not on account of the use of OO terminology. I think you're saying create a struct that holds a UnixStream and have some methods that return impl Future or Box&lt;Future&lt;&gt;&gt;. I don't think that gets me all of the way there. It provides encapsulation of the and_then futures into a struct method, but it doesn't allow end-users to use my NewStream as an actual Stream. I have a suspicion what I'm looking for is the Encoder and Decoder traits that http libraries use to wrap TcpListener and provide their own Stream of values. I just can't really figure out how it all fits together.
I think, there are couple of places you can potentially do better than serde, if you can make certain trade-offs. For example, 1. serde has to collect all of the data in local variables first, check that all required data is read, then create a struct and, finally, move data in there. 2. Internally tagged enums. serde doesn't know the final type, so it has to deserialize everything into a temporary tree-ish structure, then replay that back on your final data type once it's known . 3. Serde generates A LOT of code if you have lots of data structures. To be honest, I don't know how much these matter (due to optimizations), but these are potentially the areas where you can do better, if you know your data types. Here are the results I've got comparing our deserialization ("new_deser") with serde ("old_deser"): test new_deser ... bench: 61,992,454 ns/iter (+/- 3,118,640) test old_deser ... bench: 163,444,117 ns/iter (+/- 8,770,767) The test case is reading some amount of JSONs from `&amp;str` into our data structures. Not exactly apples to apples: our "new" structures are a bit different -- we need to "massage" data a bit when reading it -- but both structs should contain about the same data (we don't discard anything from the JSON). I'm a bit skeptical on the results here -- it's hard to believe we are really ~2.5 times faster, but nothing jumps out to me as completely invalid. So, what are we doing differently (based on my understanding of serde -- which is not very deep to be honest)? Several things: 1. All our data types are Default-able, so we can initialize them upfront and fill all the data in-place. 2. All our inputs are always `&amp;str` (we don't do streams), so we do some "scanning" for the tag before we pick target data type (although, in the test case above, I don't think we need to do that scanning at all -- I explicitly specify the target type). 3. Our deserialization is based on dynamic dispatch. There are two parts that vary: deserializers and data types. serde does monomorphization on both sides. We use trait objects to work with our data types (basically, we have our own variant of "reflection" API, like in Java). So, all our deserializer code is independent of our data types: we can even load new types dynamically via dylib (if we need to!) For the JSON part we still use serde_json, but we use it in "streaming" mode: we use "stateful" deserialization as a way to "intercept" events like "object start...field X...value 123...object end" and dispatch them via trait object API on our types. 
What is the best data structure to share some type \`T\` across two threads, where thread A can mutate the value freely without being blocked by a reference held by thread B? If A tries to mutate the value while B is holding a reference, then B's reference should remain pointing to a clone of the old value. &amp;#x200B; In my case thread A is periodically producing an updated value. Thread B is running a server which reads the value. I could store the value in a Mutex, but then I would have to clone out of the mutex on each request to prevent slow clients from blocking updates on the value. What I want is for the clone to happen only in case of contention. &amp;#x200B; It sounds like a \`Cow\`, but which holds an Arc instead of a reference. Does something like this exist? Is it possible?
I would write it something more like this: https://github.com/uutils/coreutils/compare/master...ccbrown:rewrite-echo Much shorter, even with tests.
I would write it something more like this: https://github.com/uutils/coreutils/compare/master...ccbrown:rewrite-echo Much shorter, even with tests.
That code was written before Rust 1.0 was released. Here it is when it was initially added all the way back in **Dec 2013**: https://github.com/uutils/coreutils/blob/4a0c0244860b7cea17815efb82ec9ae22d2dae33/echo/echo.rs --- That's before I started writing Rust. The code structure and approach generally appears mostly unchanged. Take it from someone who lived through the pre-Rust 1.0 to Rust 1.0 transition. It was hard, and code did not evolve well. Things got much better, obviously, after 1.0 was released. But before that, the churn was... difficult, at times, to say the least.
Also think about using [rustfmt](https://github.com/rust-lang/rustfmt): rustup component add rustfmt cargo fmt # run this in your project
Thank you and the others for the responses. The goal of this post was not to call out the project, the author or rust itself. I simply wanted to see more people's opinion on what is considered good or bad. The title is auto-generated from the link, which I simply shared.
That's awesome.
Yeah, basically! :) 
&gt; The one who put that there is clearly a madman, and the maintainer who accepted such atrocious commit is not doing his job at all. There's an argument for quantity over quality to be made, I suppose. The very concept of Technical Debt, after all, is to first get it to work, and then clean things up. The clean-up was forgotten here, as it too often is, but in the mean-time it did enable coreutils to be able to claim that it had a working `echo` program. 
&gt; has bad Java stdlib interop [scala.conversions.javaconverters](https://www.scala-lang.org/api/2.9.0/scala/collection/JavaConverters$.html), [scala.compat.java8.FutureConverters](https://github.com/scala/scala-java8-compat) are pretty decent for converting standard Java data structures to Scala. &gt; implicits make it almost impossible to debug Implicits are a feature that's too powerful. But if you use them in a couple of restricted situations, like for type classes, they're not too bad.
Does A need to be able to read the value? Would cloning preemptively be an unacceptable cost (because you expect contention to be extremely rare in the implementation you suggested)? If the answer to *either* question "no" then you may be overcomplicating things. Just have A occasionally "send" a new boxed T to B and whenever B is about to use the one it already has, it checks if there's a new one to replace it. "Sending" can be accomplished in many ways; `Mutex&lt;Option&lt;Box&lt;T&gt;&gt;&gt;` or crossbeam's AtomicCell. But the point is B *removes* the value from this "channel" and stores it in its own owners variable before working with it. If there are multiple B threads, then `Mutex&lt;Arc&lt;T&gt;&gt;`, and the Arc is cloned instead of taken. You could probably remove the lock for this case with crossbeam's epoch based collection but I've never actually looked at the API; I'm just familiar with the concept. But cloning the Arc is cheap here so it's probably not necessary.
This is great. I'm in the machine learning field and productionization of models is the toughest part in an applied setting (research is a different beast). I have a feeling that rust is going to be a great tool for shipping machine learning models. PyTorch+TorchScript is arguably one of the future standards, I have a feeling ONNX is going to go out of fashion (I say this as a large contributor to both ONNX and PyTorch) and TensorFlow is going to stick to its own serving solution. Rust even has a future in training deep learning models due to the limitations of GIL in python, and the biggest slowdown coming from data processing/movement usually. But for the edge, rust is the future of serving models (I hate having to deal with C++ on edge devices). Even for my personal projects I'm using Rust to serve models on Raspberry pi.
&gt;There's an argument for quantity over quality to be made, I suppose. Agreed. But It's painful to see this level of dirtiness and inconsistency in such a low-complexity project. &amp;#x200B;
And `shared_ptr` can actually disable atomic operations if it doesn't detect pthread use. So really it's an automatic `Rc`/`Arc` hybrid &amp;#x200B; [https://snf.github.io/2019/02/13/shared-ptr-optimization/](https://snf.github.io/2019/02/13/shared-ptr-optimization/)
I'm not using specs, I'm building it from scratch, both for fun and as a learning exercise. I'm grateful for the help but what I need to know is how to determine which structs to select based on the value a string. The components are hardcoded(for now?) but which components an entity template will be formed from are only known at run time, not compile time. An example entity template for mobs (only one I can load atm) is this: ```yaml --- orc: feature_packs: - physical - basic_identifiers_mob components: - component: char initial_value: T goblin: feature_packs: - physical - basic_identifiers_mob components: - component: char initial_value: t ``` As you can see there are templates for two mob types, "orc" and "goblin", they both possess two "feature packs" (a group of components labelled under one name) and they both possess a "char" component which sets what character the mob will be rendered as in the game. This all loads in fine: ```json Manager: { template_types:{ "example":Templates { templates:{ "example":Template { feature_packs:[ "example", "example" ], components:[ Component { component:"char", initial_value:Some(Char('T')) }, Component { component:"string", initial_value:Some(String("asdasdasd")) }, Component { component:"int", initial_value:Some(Int(2)) }, Component { component:"float", initial_value:Some(Float(3.2)) }, Component { component:"bool", initial_value:Some(Bool(true)) }, Component { component:"range", initial_value:Some(Range(0..9)) }, Component { component:"range", initial_value:Some(Range(0..9)) } ] } } }, "mobs":Templates { templates:{ "orc":Template { feature_packs:[ "physical", "basic_identifiers_mob" ], components:[ Component { component:"char", initial_value:Some(Char('T')) } ] }, "goblin":Template { feature_packs:[ "physical", "basic_identifiers_mob" ], components:[ Component { component:"char", initial_value:Some(Char('t')) } ] } } } }, feature_packs:FeaturePacks { packs:{ "basic_identifiers_mob":[ Component { component:"name", initial_value:Some(String("list")) }, Component { component:"kind", initial_value:Some(String("mob")) } ], "physical":[ Component { component:"location", initial_value:None }, Component { component:"position", initial_value:None } ] } }, lists:{ "race":{ "elves":[ ], "humans":[ ], "orcs":[ ], "genric":[ ] }, "mob":{ "generic":[ ], "goblins":[ "sfasf", "asfasf", "asfsaf" ] } } } ``` I just don't know how to say, build an orc entity from the orc template. How do I select the `Char` component struct based on the textual value `"char"`? 
C++ will not replace us! (sorry)
Type classes implemented via implicits was the biggest reason for us to abandon Scala forever. Also, the "if you use them carefully" argument doesn't really work, because even if you decide to avoid them, other libs that you depend upon will force you to use them, like in example with type classes.
Who needs line endings anyways. Structured data ftw, lets just revive `\x1e` 
That's because they're not finished; they are intending to be drop-in, as far as I know. You might also be thinking of tools like ripgrep, exa, etc. Those ones are not intended to be drop-in.
Is it possible to create a type that is public (so it can be named in fn arguments), but that can only be instantiated through a macro?
I was about to ask about making it so that there is a way of serializing/deserializing with serde then I read your theory on why bincode is slower &gt;Bincode internally depends on serde. I don't know how serde works, but, in my opinion, it creates an intermediate representation of your data which can be serialized in bytes or json, etc. In all probability, creation of intermediate representation and converting that in bytes takes long time. ‚Äãso instead I ask that you add in a [feature](https://doc.rust-lang.org/cargo/reference/manifest.html#the-features-section) that can be used that allows one to use structs that can be serialized and de serialized with serde to more easily be serialized and deserialized with desse
I recommend having a copy of [Unix Hater's Handbook](http://web.mit.edu/~simsong/www/ugh.pdf) available at all times.
There isn't (I'm not for instance and I know a few others who aren't either).
Ah, I missed that you wanted the result to be a Stream. Just make NewStream implement Stream, what's the problem?
I have something for you then! &amp;#x200B; \`\`\`rust iter.enumerate().map(|(x, y)| (y, x)) \`\`\` &amp;#x200B; You're welcome! ;)
Hehehehe, yeah of course is an undecidable problem. But is fun to try to get as general as you can 
All things being equal c is simpler because it's not type safe nor is it robust. Rust at times requires explicitness, sometimes required by the language, sometimes required by the current limitations of the type and borrow checker.
For scx, the primary motivation is to be able to convert between game versions; in particular, converting scenarios built in HD to the [WololoKingdoms](https://github.com/AoE2CommunityGitHub/WololoKingdoms/) mod. WK has all the same units from HD Edition, but with different IDs for engine limitation reasons. Eventually I'd like to use it in an exe mod to convert files on the fly, so you can just open an aoe2scenario file in WololoKingdoms and have it work transparently :) There is a AoE1 clone that's Rust: https://github.com/chariotengine (I actually reexport their palette implementation) Preallocating doesn't sound like a bad idea‚Ä¶! it's only 12 or so bytes per file, so reserving a low amount of megabytes should be enough for everyone (heh). IIRC, HD Edition does expect that files themselves are contiguous, but it may not apply to table metadata.
Thanks for posting this! It's not always obvious which panics are normal "indicates a bug" panics and which are "typechecker reporting an error" -- are the latter always the ones which have messages?
A key thing about this project is that it's not meant to be compatible with Unix-like systems. I'm aware of the massive penalties to usability that will result from that, but it's an experimental project.
Can we reimplement echo with structopt? Is there a reason they don't depend on something like structopt?
LENS isn't really a Linux distro. Technically, a full version would distribute Linux, and thus be a Linux distribution, but the implications of that are inaccurate. LENS is *not* compatible with Unix-like systems or current Linux distributions. It's meant to reimplement and redesign everything above the kernel level, because there's a lot of poor/outdated design decisions in userspace.
It is. I intend to shoot for simplisticness first. Instead of something like `systemd`, a simple system like `runit` might be a good target. And I mean to stay command-line only until and unless somebody actually wants a GUI.
It's currently available under MPLv2, which is compatible with the GPLv3 via an explicit dual-licensing permission clause. MPLv2 has an advantage over the GPL by being file-level, thus making reuse in projects under other licenses easier.
`\r\n` is unnecessary and weird, even if it once better represented the actions performed by a line printer. Text in LENS is BOM-less UTF-8 with `\n` line endings.
Cryptography is the canonical one. Storing the keys and performing operations with the secret data
I have a sort-of shell now, and my next target is a simple service manager that doesn't depend on being PID 0. I'm currently testing inside my existing Linux system, so testing a PID 0 would be a pain.
I think /u/pleurplus is basically shooting for a highly-modular kernel. Monolithic kernels like Linux have a lot of stuff that can't be swapped out. You could theoretically modularize a lot of what's built into Linux into hot-swappable modules that use a standard interface. For instance, instead of it being a core kernel component, the block layer (the framework block devices need in order to function at all) would be a loadable module that's inserted at boot.
Ok. I would have preferred pure GPL but even MPLv2 is fine. Just avoid the cuck licences like MIT ;-)
Thank you for the link. Good to have a list of gripes to address.
Certainly. Unlike Redox, LENS isn't Unix-like, so they have different goals. But I think theirs is more likely to succeed; I hope they take a couple of ideas from me. :)
That was a fascinating story. Thanks for sharing. 
I commented elsewhere that the coreutils code has evolved since before Rust 1.0. Back in those days, if memory serves, `getopts` was the only game in town for parsing an argv, and that's what coreutils uses today: https://github.com/uutils/coreutils/blob/8cadaa4664153e2371eab7a37b8a4abecb18fe6c/src/uucore/Cargo.toml#L7 --- Or at least, its successor, which I think was ripped out of the Rust distribution and put into a crate a while back: https://github.com/rust-lang-nursery/getopts/commit/32aa8d3d4f53bee81689cd6cb0da9bf190745e0b So coreutils just evolved with getopts. Not everyone has the time to refactor the world when something new comes out. For example, `xsv` still uses `docopt`, but if I were to write `xsv` today, I would choose clap.
Sorry about the recent certificate expiration issue. We plan to migrate the site to GitHub Pages this weekend so this shouldn't happen again in future.
I worked through the first couple of chapters of Building an Interpreter in Go, but obviously in Rust. Anyone up for some code review? I'm new to Rust and I'm fairly certain my code is riddled with bad practices. It works, though. I just have the lexer ready. I tried to document everything thoroughly. [Gist](https://gist.github.com/rust-play/4c8c464336a6a17aba1139d0f91394e9) \- [Rust Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=4c8c464336a6a17aba1139d0f91394e9). Mostly you use the Lexer::new method to get an iterator of tokens, like this. extern crate lexer; use crate::lexer::{Lexer, Token}; fn main() { let program = " let ten = 10; let add = fn(x, y) { x + y; }; let result = add(five, ten); "; let l = Lexer::new(program); println!( "HELLO, THIS IS YOUR PROGRAM: \n {:?}", l.into_iter().collect::&lt;Vec&lt;Token&gt;&gt;() ); } &amp;#x200B;
It appears it was only published this year, and in theory [you can patent something up to a year after publication](http://www.mateoaboy.com/f6/blog_files/874912ee2802a38923c533ba23ecf6c5-32.html). Google Scholar doesn't seem to know about any patents by the first author, Sean Bowe, at this point, FWIW. If this work was done for ZCash, there's good reason to hope that it won't be patented.
Thank you. I am actually trying to implement a small RegEx engine. If I want to use unicode handling basically there is no way to do it using this as_bytes function right?
Thanks, this works. I am actually trying to create a RegEx engine. Is there a way to make this a double ended iterator if I want to implement a backtracking?
Maybe just use the _serde_ crate? Not sure about yaml though. In time you'll probably prefer a binary format with a custom editor.
It's hard to avoid type classes, since that's one of the uses of implicits that the community has largely agreed is reasonable. It's pretty rare to see libraries using implicits for things the community doesn't agree are reasonable, though. Out of curiosity, what issue did you have with implicits used for type classes? If it's instance non-canonicity, I don't think I've seen libraries in the wild that actually use multiple instances for a single type.
Thank you for the detailed answer! &amp;#x200B; Thread A does not need to be able to read the value. I don't know if I should worry about preemptive cloning. \`T\` is going to be a \`String\` no longer than the text in your post. I am using the warp web framework, if that matters. &amp;#x200B; \`[crossbeam](https://docs.rs/crossbeam/*/crossbeam/index.html)::[atomic](https://docs.rs/crossbeam/*/crossbeam/atomic/index.html)::[AtomicCell](https://docs.rs/crossbeam/*/crossbeam/atomic/struct.AtomicCell.html)\` looks like it would do the trick. &amp;#x200B; I have a couple of questions related to using \`Mutex&lt;Option&lt;Box&lt;T&gt;&gt;&gt;\` as a sending mechanism: * I thought \`Mutex\` couldn't be shared between threads. How do they both access it * Why is \`Box&lt;T&gt;\` necessary?
Panics have error messages when at the time of implementing I knew what it meant at that point to panic. Panics in context functions (`split_at`, `drop` and `insert_in_place`) should not happen on any user input and are probably bugs. Panics at other places denote 1) invariants that do not hold. I.e. a type that should be well-formed but is not, or a non-existent annotation for variables. Or 2) a situation where we could not find a matching rule. For case 1) I am actually not sure if panicking is correct here. My guess is that other rules should be checked before a panic. In `checks_against` for example, I could imagine, that there are situations where the rule `forallI` panics but the rule `sub` would actually return a result. But I have not yet played enough with the system yet. The next step is adding more kinds of literals, let-bindings and product/sum-types. The system as is does not allow any kind of elaborate playing around. 
They also lead to APIs that are incomprehensible to an ever-greater quantity of users. I would strongly encourage not pursuing this. I find writing rust even as it exists today \_very\_ challenging because of the level of complexity encoded into types; many libraries I can't figure out how to interface with at all, requires simulating too much trait resolution machinery in my head and I can't do it. And I helped build the damn language!
When other game engines load external data to describe how entities should be, how do the transform the textual representation into in-game objects? Using Ruby as an example, how do I do the following in rust: ``` data_manager = function_that_loads_data('folder_path') Entity_Manager.build(:mob, :orc, data_manager) class Entity_Manager class &lt;&lt; self attr_accessor :entities, :components end def self.build(entity_type, template_name, data_manager) template = data_manager[entity_type][template_name] entity_id = generate_unique_id entities &lt;&lt; Entity.new(entity_id, components: template.components.keys) template.components.each do |component| components[component.name][entity_id] = Components.get(component.name).new(component.initial_value) # &lt;= This part, how do I do the equivalent in rust, a function that will return or allow me to get or create a struct based on the value of a string variable end end end ``` 
From the quick look you could return `impl Iterator&lt;Item = usize&gt;` from `item_indices` instead of allocating temporary vector.
Nice to read success stories :) I was sort of expecting that there would be Rust jobs on the jobs page given that the article links to the jobs page but couldn't find any from by searching for Rust at https://jobs.zalando.com/tech/jobs/ Also, the link to the jobs page from the bottom of the article does not load the jobs page correctly in Firefox. The URL of the jobs link at the bottom of the article has a query parameter that is probably intended to give some metrics on the number of clicks, but which looks like it probably should have been `?gh_src=4n3gxh1`, but instead the query parameter is `?gh_src=4n3gxh1https%3A%2F%2F`. And when I open that link in Firefox, the address bar starts filling with more `%2F` and my browser becomes very unresponsive. Is anyone else seeing this happening? Perhaps debugging where some JavaScript on the jobs page goes bonkers with such input is part of the application process :P
/u/tonguejob is definitely a bot. Googling various comments from their profile turns up earlier, original comments from different users all over the place.
&gt; we approached Zalando‚Äôs Technologists Guild What a weird company. 
Got it. In that case I wouldn't feel bad about adding a PR to modernize some stuff in there! I just wasn't sure if they were trying to use structopt only or something.
LOL
That might be welcomed, but you should definitely file an issue before submitting a change like that. They might be perfectly happy with getopts. :-)
1. I believe this is a problem that [RFC 2089: Implied Bounds](https://github.com/rust-lang/rust/issues/44491) addresses partially, though I believe that your example won't actually be resolved by it. The linked RFC goes into great detail about Rust's trait and well-formedness checking, so it might at least answer *why* it doesn't currently work. 2. Every `Fn` implements `FnMut`, but not the other way around. Since `for_each_mut` returns a `Foreach&lt;F&gt; where F: FnMut(T)`, Rust cannot guarantee to `foo` that the parameter implements `ParallelReducer&lt;T&gt;` since it requires that the earlier `F: Fn(T)`.
Doesn't seem to be possible. I thought perhaps you could give it a private member, then external use wouldn't be able to instantiate it, but they could pass it around. However, that doesn't work. Wherever you use the macro, it will tell you that the field is private.
Go, Java, Scala and Swift all compile. Go and Swift even compile to native code.
This is nice and all but also super weird. Their boss just straight denied the possibility of using any other language, especially when they kinda needed Rust for this high performance application. There wasn't a "is Rust stable enough yet", where Stable means a lack of bugs. It would be fine to have the program change a lot, actually, because they had originally finished it so fast. Anyway, they never actually did anything to try and get it into production, not really. They just set it aside, and said, "oh well". The article just says they didn't need it anymore. What the fuck? What happened to that app that wasn't performing well? And why did they need to go announce and prove their usage of it to make it an official language? Clearly, through the rewrite, you know it decently. Write a report to your boss, showing research of how *it's not gonna crash*. You wrote it in a short time, so clearly you're able to maintain it with Rust, as it changes. And this is 2016! Rust hit Stable already, so the program isn't going to drop dead like with pre-1.0. You have the need, and it seems reliable. Maybe you can spend more time accessing it for harder projects, but it was clearly a success for this single project. And you drop it‚ÄΩ How do you not need it anymore‚ÄΩ This story is just really weird. I would stay away from this company. Look at u/ergzay's post. Jeez.
Keep in mind clap and structopt are kinda the same thing. structopt was originally written on top of clap separately, but is currently being merged into clap as structopt_derive, only to be accessed through clap. Not yet though, currently you'd just use structopt, which would import clap automatically.
Note: the coreutils project uses `getopts`, not clap.
Already working on it. ;)
Needed a way to represent an interconnected tree for a game I‚Äôm making with a friend. Decided to view it as a binary relation so I‚Äôm working on getting an efficient binary relation going. There‚Äôs probably a crate out there for that but nice to spin that for myself! 
Yes. But, it‚Äôs highly unstable and shouldn‚Äôt be used unless it‚Äôs necessary.
Java doesn't compile and neither does Scala.
In case other people want to join projects listed here. My advice is to start by writing tests and build up knowledge from there.
I edited my post.
I thought embedded rust used rustc directly, but could be very wrong. 
thanks heaps for that detailed answer! I'm not going to pretend I understand it all but I think I get the gist and when I have time I will come back and digest it fully!
That‚Äôs pretty bad taste dude. 
It looks like a lot of red tape and non-technical decisions. I think I got a little but lucky. May be working in 100K+ software engineers company has its own pros - people are more willing to take the risk of being early adopter if it fills the niche and adresses a pain point. Here are is some of my experience (I don't have a blog): - 2013 I decided to write a streaming data analytics system, I was given a choice, but it has to run on JVM - still not bad. I chose Scala. It was not obvious decision at the time - there was not Spark, Flink or the rest of the Scala data analytics ecosystem around. It turned out good choice - I delivered ahead of time (e.g. went to production in 3-4 months), adding features at fast pace, replaced most of my company internal use of Hadoop, etc. I am still proud of the software but it's not open source and my company decided that it's too complex to build a service around it. - fast forward to beginnign of 2018, I switch teams/service, already following Rust (actually since 2014-1015). They care a lot about CPU/memory efficiency, have a lot of C code. I fix bugs, add new features, deliver new systems. I wrote a prototype to replace an existing C subsystem in Rust, new design solving a lot of issues. Got approval to go ahead, got more developers to work with me. Went recently in production. - we looked around us: major dependency already is written in Rust, a few big teams have big chunks in Rust running across few architectures. Now we have Rust code base in the service. - some time ago my service decided to standardize on Go. So, based on my team delivery, the observations and goals, we have now project ongoing to rewrite a central piece (small scope though) from Go to Rust in order to evaluate how hard it is to be switching to Rust as primary language where it matters. I got great feedback from peers, they actually turned to like more Rust than Go and are very enthusiastic. So, I am optimistic about Rust adoption at my team/service. Here are what big companies care and how they make decision (from my POV): - safer is always better than faster development. If we cannot ship bugs it's better than shipping sooner but buggy. But this also means we have to spent more time in advance that our foundations are solid rock and good example for whoever comes after us. - letting people collaborate on single code base without fear is always better than relying on discipline and code reviews. Also helpful is good example. - having people refactor code bases without fear is always better than allowing interns (people that don't know the context and the language) make incremental changes. Companies care about big changes and features, small changes can be made independent of the language with mostly the same effort. I agree that my experience is a little bit later than yours. Just wanted to give some feedback and share my experience in the same vane as yours.
Have you tried running git fsck? 
I would love help on tallystick. https://github.com/phayes/tallystick
Why not `#[repr(c, packed)]`?
See Baidu's similar project: https://mssun.me/blog/mesalock-linux-a-memory-safe-linux-distribution.html.
How do you suggest make the code cross-platform then? Functions relevant to multiple utilities are generally extracted into uucore.
&gt; A compiler is a computer program that transforms computer code written in one programming language (the source language) into another programming language (the target language). https://en.wikipedia.org/wiki/Compiler In other words, a compiler is roughly a function `LanguageA -&gt; LanguageB`. That the target language is machine code is incidental. You could also compile to WASM byte-code (which rustc will allow you to do). Your terminology is nonstandard.
I‚Äôd be very happy to accept PRs modernizing/refactoring the code :)
The compiler has lots and lots of unfinished things ;) Here's a start: [https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AE-easy](https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AE-easy) and [https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AE-help-wanted](https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AE-help-wanted)
FWIW, from what I can tell you actually can't implement echo using structopt. For `echo Hello -n World` it has to output "Hello -n World". Structopt will treat the `-n` as a flag regardles of its position. It will also throw errors on anything else starting with `-`, treating it as an unrecognized flag. Maybe there is a way to change this behavior, but I couldn't find it in the documentation.
You're welcome! &gt;I'm not going to pretend I understand it all but I think I get the gist and when I have time I will come back and digest it fully! At first I was worried, but definitely try figuring it out later. Sometimes it can be hard to figure stuff out from articles without trying it out for yourself. Just comment reply or pm me if you want any more help from me. Otherwise, this weekly thread is always a great place to ask for help. But it's not a substitute for experimenting yourself! Also, thinking back to my comment, I think my original version had some links to the standard library and what to make things clearer. Definitely go visit the pages for Deref and DerefMut; it's very useful to see the actual implementations of stuff instead of only talking about the trait itself. Also, sometimes it's helpful to just take what you're confused about for granted, try coding normal projects, and following the compiler's instructions to get them to work. You might find that, for a lot of stuff, you just kinda absorb it and realize how it works. But again, if it still doesn't make sense, always feel free to ask. But since you mostly get it, I think what you mostly need is just experience using it. üòä
What kind of votes do you think people will tally with this? Looks cool.
That does hit the spot for very valuable contributions! Thanks :)
I'm going to preemptively thank everyone for their future contributions as a result of this ;)
It‚Äôs meant that be general purpose. So all types. It‚Äôs part of a long-term project of mine to build an online cryptographically secure online voting system. 
The projects I've been getting involved in truly just need more hands on the merge buttons pinging PR's to keep them moving along. Ensuring that there's multiple repository org members is important. Guiding PR's across the finish line and operating an engaging project has more beneficial effect for most projects than trying to write code directly.
For clap at least, possibly some combination of `TrailingVarArg` and `AllowLeadingHyphen` will do the trick. Whether structopt exposes that or not, I don't know, I haven't used it. But it looks like you can since it exposes the clap `App`, which can be configured: https://docs.rs/structopt/0.2.15/structopt/trait.StructOpt.html
That depends entirely on the platform in question. I do embedded work on ARM devices, and we use \`cargo --target blah build --release ...\` for release builds.
You could try [`DoubleEndedIterator`](https://doc.rust-lang.org/stable/std/iter/trait.DoubleEndedIterator.html). However, you _might_ want something that lets you move the iterator back, in which case you'd need your own trait.
Gesundheit
That's a very neat idea.
Any projects you would like help on?
&gt; once better represented I see somebody has never programmed raw terminals. You may want to set smaller target before replacing 'systemd' ;)
Better yet, we could use a nice [rust library](https://crates.io/crates/acme-client) to implement on-demand certificate signing, similar to [caddy](https://caddyserver.com/docs/automatic-https)
Awesome to hear! üòä
Just to make the time inside the mutex minimal, or better yet to enable AtomicCell to be lock free as long as it's a single pointer or the isa supports pair CAS (and if AtomicCell leverages this, which I'm not sure about). If T is within your max atomic width it's irrelevant. Interestingly, with atomic pairs it would also be possible to implement a mostly-lock-free Arc-like version, using distributed ref counting. But that's probably overkill.
Are there any actively developed Xlib bindings? Or does the standard library render that moot now?
I'm not going to hook a teletype up to my laptop, and I don't expect anyone else to either. `\n` is easier conceptually and easier to program with. If absolutely necessary, a translation layer can be put in place to handle things that need `\r\n`.
The point is what is right technically. Lots of things are easier conceptually and easier to program with. I'll tell you what- write your LENS in java or C# ;). Easier to program and same memory safety!
What line ending character you use means virtually nothing except in a few rare edge cases. Depending on what you work with, you may encounter those edge cases more often than most. That doesn't make them not edge cases. It therefore makes sense to use the option best suited to ease of programming. When necessary, conversions can be made at the boundary between normal code and the component needing the more complicated option. Therefore, `\n` is the better choice. I am not going to keep arguing with you about line ending choice unless you give me an actual reason to use `\r\n` besides "some rare devices expect it."
To your second question: I ran into a very similar issue recently, and it turned out to be a compiler bug. Usually all possible `Fn` traits are derived, but when a closure that could be `Fn` is passed directly to a function that expects `FnMut`, only `FnOnce` and `FnMut` are derived. ([GitHub issue](https://github.com/rust-lang/rust/issues/26085)) &amp;#x200B; My side-project is stuck until this bug is fixed and I've thought about trying to fix it myself, but I'd have to familiarize myself with that part of the Rust compiler first, so that's definitely not going to happen anytime soon.
I might be bitching too much, but platform-specific code should never be permitted inside main files. It's about separating logic and behaviours, and behaviours of different abstraction levels. This is one of the most basic principles that people never learn to apply in actual jobs. Also, managing platform-specific code on ad-hoc basis will end up building separate management structure for each submodule. This will burden maintainers in a long run. It's better to maintain a dedicated module for platform-specific code, with few exceptions ofc. These are old lessons from C-based multi-platform projects, including Linux kernel and glibc.
Hoo boy, this was a FUN bit of type tetris you sent me on. :) I managed to get the function to compile by itself here, and I knew that getting it to do so would be more helpful in illustrating the points I want to make...probably tomorrow, since it's late here: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8a2077ed26e851e893305192ecc2bc22
&gt;Well if nothing else, I appreciate more competition in the bytecode/VM space Bytecode is really to decode and encode, strings encoded with a null terminator at the end so string size is unlimited. Some instructions encoded with 2 bytes, for example, all load instructions encoded with `3` byte and next byte is operation e.g `3 0` equals to LdFalse This code: ``` var fac = function(x) -&gt; { if x == 0 { return 1 } else { return fac(x - 1) * x } } $print(fac(5)) var s = "Hello,world!" var obj = $new(null) obj.string = s $print(obj) ``` Compiled into this: ``` 00000000 02 00 00 00 01 00 00 00 23 00 00 00 01 01 00 00 |........#.......| 00000010 00 01 00 01 01 00 00 00 01 00 58 ef bf bd ef bf |..........X.....| 00000020 bd ef bf bd ef bf bd ef bf bd 4b 70 06 00 73 74 |..........Kp..st| 00000030 72 69 6e 67 0a 00 11 00 00 00 00 00 00 00 00 00 |ring............| 00000040 00 00 00 03 05 00 00 00 00 13 0b 0a 02 07 00 00 |................| 00000050 00 00 01 00 00 00 00 00 00 00 0b 14 03 05 00 00 |................| 00000060 00 00 00 01 00 00 00 00 00 00 00 03 05 00 00 00 |................| 00000070 00 13 01 03 06 00 00 00 00 07 01 00 13 02 0b 0b |................| 00000080 03 06 01 00 00 00 04 00 00 00 00 00 00 05 00 00 |................| 00000090 00 00 00 00 00 03 05 00 00 00 00 07 01 00 03 08 |................| 000000a0 02 00 00 00 07 01 00 02 0c 00 48 65 6c 6c 6f 2c |..........Hello,| 000000b0 77 6f 72 6c 64 21 04 00 01 00 00 00 03 02 17 04 |world!..........| 000000c0 00 02 00 00 00 03 05 02 00 00 00 03 05 01 00 00 |................| 000000d0 00 04 03 58 ef bf bd ef bf bd ef bf bd ef bf bd |...X............| 000000e0 ef bf bd 4b 70 03 05 02 00 00 00 03 08 02 00 00 |...Kp...........| 000000f0 00 07 01 00 |....| 000000f4 ``` 
VM supports multithreading and executes fast but I think without using `Arc` from std VM speed will be much faster. Also I'm working on simple x86-64 JIT compiler for VM bytecode.
Crikey. That's monstrous. Thank you so much, you probably saved me hours of searching and frustration. Having such a complex example is a huge help, and I'll be referencing your comment heavily come tomorrow. Thanks man.
Brother I was being an asshole sorry, bad day. Keep going and good luck 
the edit is still wrong... those languages [don‚Äôt perform horribly](https://www.techempower.com/benchmarks/#section=data-r17&amp;hw=ph&amp;test=plaintext)
This is awesome. I would like to see more images you've got.
isn't xlib bindings could just be generate by bindgen with C header file ? If you think about a safe binding... I think we would have to make a rotation between dev to avoid them become crazy by reading the doc again and again without understand anything of course that suppose they find the doc first ;)
This is so cool!! What an awesome idea. Keep doing fun creative things in Rust please!
Is it possible to write something like the following zig code using rust's stdlib? const std = @import("std"); pub fn main() !void { const stdout = try std.io.getStdOut(); var it = std.os.args(); _ = it.skip(); // skip program name var newline: bool = true; var first_item_visited: bool = false; if (it.nextPosix()) |arg| { if (std.mem.eql(u8, arg, "-n")) { newline = false; } else { first_item_visited = true; try stdout.write(arg); } } while (it.nextPosix()) |arg| { if (first_item_visited) { try stdout.write(" "); } else { first_item_visited = true; } try stdout.write(arg); } if (newline) { try stdout.write("\n"); } } 
I only know PBR from the real-time context of game engines. This isn't real-time is it? How long do these images render for?
The meme that Java and Scala don't perform well it's extremely tiresome, high performance Java systems underpin more than you might expect. Admittedly, you get much more consistent latencies from C/C++/Rust services (all else equal). Not to mention Go...Go can perform exceedingly well. I'm fairly confused by your claim.
&gt; it makes platform dependent function calls more noticeable since you actively have to bring the trait into scope Yes, that's the reason : to stop users of an API from relying on platform-specific parts of it without realising they're doing do.
I'm curious about dealing with position/motion sensors, is there anything about this in there?
GPL is cucked, damned commie.
It seems like declarative macros 2.0 _should_ be intended to access `pub(crate)` items but I haven't found any RFC where this has been discussed.
I'd like to define a trait CloneFrom that allows you to create T from &amp;F (the converting properties of From with the non-destructiveness of Clone). I want to avoid cloning the F object, as I am expecting them to be significantly larger than the T objects. An obvious example is `[u32;4]` from `&amp;[u32;32]`. Implementing this for every conceivable use-case is fine but seems like a lot of unnecessary boilerplate. I tried this, but the compiler doesn't allow it, as upstream crates can implement AsRef. impl&lt;F,T&gt; CloneFrom&lt;F&gt; for T where F: AsRef&lt;T&gt;, T: Clone { fn clone_from(f: &amp;F) -&gt; Self { let t: &amp;T = f.as_ref(); t.clone() } }
This is written from the perspective of a single dev. There are always (at least) two sides to any story, and it seems you're kind of assuming the worst from the lead dev. Introducing a new programming language for a core component is a major decision, as is replacing a core component with a rewrite. There probably *should* be pushback on such a change, especially when it was made just because of performance issues. It's probably more important to ensure that the code is still the same level of quality (testing, documentation etc), that the same number of dev team members is able to work on it, that the technology used is mature enough etc. And it's hard to even determine that when all the parts are new to the organization. The dev who wrote this blog underestimated those costs and requirements, so the company ended up solving the initial problem in a way that had less complex consequences. TLDR: If you want to switch the programming language of a core component, get signoff from your boss before fully committing to it. For smaller or new components it's probably less of an issue.
In fact, of all the problem stories I read about Java and Scala on the web, none of them are about speed. They are always about memory consumption.
This is very fair. I mostly just wish the author had described the way it is there more. They way they wrote it plus how little detail there was in this section plus what details they did give us about how the company acted here just made the entire thing feel very strange. That's why I wrote that comment. While all that you say might be true about how they did stuff, it's not necessarily the case. We don't know. And from what little we see, I think they could have went further in figuring out whether to use Rust for this particular project instead of dropping it entirely and waiting for something else. In most other articles, they have these details, and I'd feel and recognize stuff in exactly the same way you do. But this one just strikes me as very odd. ¬Ø\\\_(„ÉÑ)\_/¬Ø
Would it be simpler to do with parcel? Or parcel has no way to generate nodejs output? I believe it could.
You can simplify that a lot by demanding that w and h are of the same type which also probably makes more sense in normal use
Related question: How is the work on the ~~Cretonne~~ Cranelift backend for rustc going ?
True, but you'd have to think about if you really need unicode handling. E.g., for equality comparison, you can easily drop to the byte level, and `as_bytes` doesn't allocate, so it's very cheap. Really depends on what exactly you're trying to do :)
&gt; especially when they kinda needed Rust for this high performance application. Well, they didn't really _need_ it; they "solved" it by throwing more hardware at the problem. That appears to have worked fine. Introducing Rust would have resulted in cost savings, but not implementing it would not result in the service not working. It makes sense that the team lead is hesitant. Teams change, applications get moved to different teams, all those things happen in large companies. In short: a different language made the organisation less flexible in terms of which/how many current and future employees can be assigned to the code base. That isn't necessarily a blocker, but it's a trade-off the company should make, which is why they had to justify it. Ideally, of course, teams would be relatively stable, and their environments isolated enough that they have relative freedom in terms of choosing their tech stack. But I don't think this is the case for most "enterprisey" companies, and is something that should originate elsewhere in the organisation, probably.
To clarify, the compiler doesn't forbid this `impl` block by itself; you must have this alongside `impl`s for other types you don't control or another blanket `impl`. You have to kinda just choose one or the other, unfortunately. With [specialization](https://github.com/rust-lang/rfcs/blob/master/text/1210-impl-specialization.md) you'll be able to mark the blanket impl as `default impl` and then overlapping implementations are allowed as long as they're strictly more specific. You can try it now on nightly with `#[feature(specialization)]` but [it kinda has a habit of causing compiler crashes](https://github.com/rust-lang/rust/issues?utf8=%E2%9C%93&amp;q=is%3Aissue+is%3Aopen+specialization+label%3AI-ICE+).
Not yet. But adding those features depends on the drone. But if it is one with a well documented api it would be a lot easier to implement than trying to reverse engineer the firmware. 
&gt;It makes sense that the team lead is hesitant. Teams change, applications get moved to different teams, all those things happen in large companies. In short: a different language made the organisation less flexible in terms of which/how many current and future employees can be assigned to the code base. &gt;Ideally, of course, teams would be relatively stable, and their environments isolated enough that they have relative freedom in terms of choosing their tech stack. But I don't think this is the case for most "enterprisey" companies, and is something that should originate elsewhere in the organisation, probably. Yeah, this is a good argument. I mostly wish the author talked more about it, but then again, it wasn't particularly about it. :/ I may be a bit idealistic sometimes.
This was painful to read - so much politics and bureaucracy... Stories like that always remind me why I'm self employed.
wouldn't it be better to replace multiplication by 2.0 with just addition? that way it will work with integers too.
You can probably use type aliases to make it "more" readable.
Steady progress: https://github.com/bjorn3/rustc_codegen_cranelift
&gt; Data is rarely copied. &gt; [...] &gt; Ad hoc, built-in heuristics. Call me a Knuth-skeptic, but while this may be good for maximum performance, I think architecting a compiler in this way (mutable, stateful, and ad-hoc) is error-prone as it makes reasoning about the language spec vs. the implementation and soundness of the implementation a whole lot more difficult than mostly pure passes and generally formulated logic. `rustc` has these problems too, and e.g. `DefId`s and diagnostics logic (interspersed with main logic) contribute to ICEs and make things harder to understand. We should avoid making matters worse.
Try trait Foo { type A : Debug; } This way, you require for every associated type to implement the debug trait.
I think the derive on Moo desugar to something like [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=3036fc610ee3357381fd9af435d83ab5) but what you want is just [that](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b0d7ac3e1996f5b9c797cd400d1e4d24).
so cool
`A` should not have to implement `Debug`, because that is provided by the `DebugWrapper`.
Right, so one workaround could be to provide a manual implementation of `Debug` for `Moo` - but in the real code, `Moo` contains six fields rather than one, so it would be nice to have a derived implementation... The other workaround I can think of would be to make a `DebugWrapperFooA&lt;F: Foo&gt;(F::A)` struct, which is also annoying because of the number of debug wrapper structs I then have to make in the real code.
Can you show the real struct? Also you could make a proc macro to mimic Derive but without the bound and you could use derive with it just like you would have with Debug.
Definitely needs Phong shading ;-) But that would maybe break your edge detection. Nice Demo!
The team argument is the one that keeps Rust adoption back. It is damn hard to find whole team of experienced Rust programmers. The bigger company is - the bigger this issue gets. We have a lot programmers (maybe more than a thousand) and many of them creates backends for web services. They all use C++ as main programming language. It is literally impossible to teach all of them Rust. It is impractical to allow one team to use Rust, because they won't be able to use common libraries and others won't be able to use theirs. If we would have C as our common language this won't be a problem, but linking Rust with C++ is such a PITA right now. C++ itself is PITA too, but most of us just get used to it already. But I'm getting so sick of C++ at work that I can't use it for hobby projects anymore.
On a mostly unrelated note. &gt; Arena memory management. Compilers allocate many tiny pieces of data, largely for AST/IR nodes and symbol tables. To nearly eliminate the non-trivial runtime cost of malloc(), free() It would be interesting to see if malloc and free could be 'in-lined' in some way and code like [this](https://rust.godbolt.org/#g:!\(\(g:!\(\(g:!\(\(h:codeEditor,i:\(j:1,lang:rust,source:'%0Apub+fn+test\(a:u32,b:u32\)+-%3E+u32%7B%0A%0A++++let+l1+%3D+Box::new\(%5Ba%3B16%5D\)%3B%0A++++let+mut+v+%3D+l1%5B4%5D+%2B+l1%5B6%5D%3B%0A++++let+l2+%3D+Box::new\(%5Bb%3B16%5D\)%3B%0A++++v+%2B%3D+l2%5B0%5D+%2B+l2%5B2%5D%3B%0A%0A++++v%0A%0A%7D%0A'\),l:'5',n:'0',o:'Rust+source+%231',t:'0'\)\),k:27.834082055873743,l:'4',n:'0',o:'',s:0,t:'0'\),\(g:!\(\(h:compiler,i:\(compiler:r1320,filters:\(b:'0',binary:'1',commentOnly:'0',demangle:'0',directives:'0',execute:'1',intel:'0',libraryCode:'1',trim:'1'\),lang:rust,libs:!\(\),options:'-C+opt-level%3D3',source:1\),l:'5',n:'0',o:'rustc+1.32.0+\(Editor+%231,+Compiler+%231\)+Rust',t:'0'\)\),k:46.00511472149259,l:'4',n:'0',o:'',s:0,t:'0'\),\(g:!\(\(h:cfg,i:\(editorid:1,j:1,options:\(navigation:'1',physics:'1'\),pos:\(___x:0,___y:34.999999999999986\),scale:0.8220132358063392,selectedFn:'example::test:'\),l:'5',n:'0',o:'rustc+1.32.0+Graph+Viewer+\(Editor+%231,+Compiler+%231\)',t:'0'\)\),k:26.16080322263366,l:'4',n:'0',o:'',s:0,t:'0'\)\),l:'2',n:'0',o:'',t:'0'\)\),version:4) would be able to optimize out the second alloc call. Perhaps as a miri phase ? 
Per pixel lighting would totally look cool with the gradient of characters.. I'll look into it üòä
Perhaps. I'm still learning but a longer-term goal of mine was to try writing an X-based window manager in Rust. But it looks like that's impossible for now. :\
The `malloc` and `free` symbols are already special to compilers, and they can optimise out some allocations by promoting the memory to a stack variable, e.g. https://gcc.godbolt.org/z/7Ir8mU in C, and https://rust.godbolt.org/z/vGZ1kT in Rust. I don't know if any will coalesce/reuse allocations. It's likely to be hard for a C or C++ etc. compiler to do this: any pointer might actually be used as an array and there's no static way to see, plus aliasing makes everything with pointers hard (maybe Rust would have a chance, but it seems likely to be nontrivial and of potentially limited use in cases like this). 
Yes, it is possible, and likely not even a major change (I suspect it could be done exactly line-by-line). Is there something you suspect might be difficult? Have you tried and struggled?
well, I think you could but first try to do it without safe binding, calling yourself unsafe FFI function. Then you could have a better understand of the mess of Xlib. and you could maybe be the one who will dev the binding, actually there is already one here, [https://github.com/Kintaro/wtftw](https://github.com/Kintaro/wtftw) 
To be fair, those are usually quite closely related for GC'd languages: for code that allocates (i.e. creates garbage), the program often needs to be permitted to use many times more memory than its "true" maximum size of live objects, or else the garbage collector is triggered more and more often, slowing the whole program down.
Both compile to bytecode (most people consider `javac` and `scalac` compilers, FWIW... I'm not sure what else one could call them?), and `scalac` even has an optimiser.
Rust beginner here: I have rustc 1.33 here, and am getting this error: `error[E0505]: cannot move out of \`a\` because it is borrowed` `--&gt; bidirect.rs:619:17` `|` `615 | Type::Existential(ref alpha) =&gt; {` `| --------- borrow of \`a.0\` occurs here` `...` `619 | a` `| ^ move out of \`a\` occurs here` &amp;#x200B; `error: aborting due to previous error` While I start to understand what the error means, I am a bit puzzled why the pattern match in the function should not be able to return the matched value.
From glancing at it, the key question I suspect is, "does it need to work on non-Unix systems?" Or, perhaps conversely, "what is the behavior of the Zig program on non-Unix systems?" In particular, the program appears to be iterating over the argv and printing out some of those arguments directly. In Rust, `it` would be an iterator of `OsString`, and there is no simple cross platform way to non-lossily dump an `OsString` to stdout. On Unix, it's of course simple to do with [`OsStrExt::as_bytes`](https://doc.rust-lang.org/std/os/unix/ffi/trait.OsStrExt.html#tymethod.as_bytes), but on Windows (for example), you'd have to resort to lossily converting the `OsString` to UTF-8 and then writing that. So that if the program is given a positional argument that is not valid UTF-16, then its output won't match the input. My knowledge of Windows isn't great, and I'm not even sure if it's possible to do this losslessly on Windows at all. You can access the underlying (potentially malformed) UTF-16, but once you have that I'm not sure what you do with it. [`WriteConsole`](https://docs.microsoft.com/en-us/windows/console/writeconsole) supports writing UTF-16, but probably not invalid UTF-16? Rust's standard library [requires valid UTF-8](https://github.com/rust-lang/rust/blob/e43f99ce576152d4b2f7315d491c4210211228d6/src/libstd/sys/windows/stdio.rs#L53) when writing to a console on Windows, for example. It's plausible that someone might not know about `OsStrExt`. It's a sneaky little API and isn't portable. So if all you care about is writing programs that work on Unix systems, its "obscurity" might not be received well, since it's "simple" to accomplish this in other languages like C (because they aren't portable to Windows). The giveaway is the use of the word `Posix` in the Zig program. Other than that... Yes, I agree that the Zig program could be translated almost verbatim line for line.
&gt; I might be bitching too much Yes, I think you are. You talk about old lessons, but perhaps an even older one is to take some time to do some thoughtful perspective taking. Firstly, not everyone is aware of how important it is to push down platform specific logic. Secondly, not everyone needs to share your priority. It can be more important to get something out of the door than it is to figure out the right abstractions. When I first released ripgrep, there were *tons* of platform specific bits littered in the `main` program. You can see for yourself by checking out the `0.2.0` tag and searching for `cfg\(` in `src`. There's tons of `cfg(unix)`, `cfg(not(windows))` and `cfg(windows)`. Compare that with today, there's only one instance of `cfg(unix)`/`cfg(not(unix))` left, and that will soon be removed by using my new `bstr` crate. The initial release contained a lot of platform specific code in the main program not because I didn't know any better---I knew what I was doing was bad---but because I hadn't figured everything out yet, and the _right_ abstraction boundaries weren't clear to me. They didn't become clear until I got more experience with the code and, most importantly, user feedback that introduced new requirements. It took a _serious_ amount of work to do the necessary API design to push the cross platform pieces down. I don't mean that in the "I did it wrong first and it was hard to unwind it" sense, but rather, "it took me a while to figure out where the right abstraction boundaries were." It took me years, actually. It's not like it was my singular focus, but figuring out how to push all that stuff down into libraries with simple APIs is no easy task. Lots of crates came into existence in part because of this: `termcolor`, `wincolor`, `winapi-util`, `ignore`, `globset`, `bstr` and probably more that I can't think of at the moment. My suggestion is to stop punishing people in reddit comments for their code, and especially stop with the condescending "it's okay for me to bitch because, golly, don't you know that this is so _basic_." The obvious implication being, "wow you sure are dumb for not knowing this super basic stuff." Talking and walking are two different things. Principles don't always get put into perfect action right away. Sometimes it takes time. And it definitely takes someone with the will to actually do it.
Not only this, but Rust does not define arithmetic operators where the operands have different types, to avoid potential confusion with overflow. As a result, the fully generic version isn't even particularly useful.
I absolutely love [mdbook] and use it to write guides for all of my repositories as well as the internal engineering documentation at my job. One problem that I ran into is: 1. You want to import a small piece of a file into your `mdbook` so that you can discuss it or use it as an example. 2. You import it by line numbers 3. Someone changes that file, your import is now importing a completely irrelevant part of the file Back in Feb I opened [#879] in `mdbook` with some thoughts on how to fix this. So that was marinating in the back of my mind for a bit. Fast forward to last week... --- At my job we have one week out of every 6 weeks where we work on internal tooling / investments / paying off debt / etc types of things - so this time around I worked on open sourcing [mdbook-superimport], a plugin that allows you to tag a small section of a file so that it can be imported into the book. So far it's been super useful because it opens up the ability to pull in real code examples when we're explaining the codebase or products from a birds eye view or documenting different data flows that span multiple files. So I wanted to share it with other `mdbook` fans in case its helpful!! [mdbook]: https://github.com/rust-lang-nursery/mdBook [mdbook-superimport]: https://github.com/tailwind/mdbook-bookimport [#879]: https://github.com/rust-lang-nursery/mdBook/issues/879
Thanks for the JavaScript explanation. My Firefox started thrashing the disk like crazy when I tried to load the jobs page. After 10 minutes of unresponsiveness, I had to reboot my computer :(
Internally, the `regex` crate operates on `&amp;[u8]`, but still provides Unicode support. :-) How it does it is complex, but the short answer is that Unicode is built into the finite automaton.
In your example LLVM fails to eliminate the loads from the boxed arrays (I didn't investigate why it does though). And it only removes malloc/free pairs if the only operations performed on the allocation are comparisons to null, stores and free calls. &amp;#x200B; In the example given by u/dbaupp the code is simpler and LLVM can still see that \`\*p\` is just \`num\`, so the load is removed, and then then malloc/free pair is removed as well.
Wait, you mean that `w` and `h` can't even be different types because both `+` and `*` require the Left and Right to be of the same type? So is there literally no reason to allow this to be "fully" generic in the way OP was writing?
&gt; Introducing Rust would have resulted in cost savings, but not implementing it would not result in the service not working And I'd wager that the cost of training developers in a new language and fragmenting the company's internal ecosystem _could_ be far greater, in the grand scheme of things, than the cost of just using twice as many servers for the application in question. 
How do you get this error? Can you post your changes to the code? If you clone and `cargo run` or `cargo test` no errors should occur with 1.33.
&gt; Quite the mental exercise, some people do Sudoku, others solve borrow puzzles! So true. A while back I realized I trawl the various Rust beginner chat channels mainly looking for small and interesting puzzles to solve. Unfortunately I think I've gotten good enough by now that it's no longer as interesting. 
you cannot downcast `Any` to trait object, you should directly pass a type of a subscription also this type isn't correct ```rust let subscription: &amp;Box&lt;Subscription&lt;Context = C, Message = M, Error = E&gt;&gt; = subscription.downcast_ref().expect("error downcasting"); ``` because you call `downcast_ref` on the value in the box, not on the box that contains a subscription.
I can't find it now, but I recall reading an article (quite a few years ago) by someone working on speeding up the D compiler. They measured the overhead of memory allocation and garbage collection involved, measured the amount of memory actually used... and got fairly nice performance gains by replacing the GC's `free` function with a no-op. The compiler would allocate a bunch of memory, never free it, and then the program would end. Apparently it just didn't allocate enough for that to be a big problem. You want a time-vs-memory tradeoff? There you go. ;-)
I downloaded [https://raw.githubusercontent.com/JDemler/BidirectionalTypechecking/master/src/main.rs](https://raw.githubusercontent.com/JDemler/BidirectionalTypechecking/master/src/main.rs) and invoked rustc on that. No changes on my side. &amp;#x200B; rustc --version gives: rustc 1.33.0 (2aa4c46cf 2019-02-28) &amp;#x200B;
"Make it correct, make it robust, make it fast, in that order." I do like that he prioritizes interning of strings, though, basically making data that he knows will have to be reused anyway immutable. And prioritizing speed of compilation in the first place is nice. As Go demonstrates, you can get impressive results when you predicate your design on that sort of thing. Wonder what other trade-offs are being made besides implementation complexity though.
The traits `Add` and `Mul` don't require the types to be different; that's why they're so complicated. A specific example is that they are overloaded to work with both references and non-references, like adding together `usize` and `&amp;usize`. This is just for convenience to reduce the number of references and dereferences required, though. And there are many situations where it would be sensible to define for truly distinct types, like say multiplying a matrix by a scalar. But for the numeric types in the standard library, you can't multiply different ones together. You must explicitly convert one or the other.
nice
Hey I cannot tab out of my game without my game responding and sometimes it just dosent respond. I have a ssd I5 1060. Anybody have any suggestions to help me.
It looks like someone else solved it, and it's offensive to programming. I have no idea what the behavior will be much less what the compiler will do in the mixed type cases.
I'm very new, trying to learn programming (again.) Rust seems interesting to me because it seems to have literally no weaknesses (again, very new.) My question is, what are some situations where rust simply isn't a very good language to use? And I mean from a technical perspective, not a politics perspective.
&gt; "Make it correct, make it robust, make it fast, in that order." :+1: Readable / maintainable should be in there as well ;) &gt; I do like that he prioritizes interning of strings, though, basically making data that he knows will have to be reused anyway immutable. Making things more immutable is always nice for robustness. Interning can result in more stateful APIs due to singletons, but I think you have to cut corners somewhere for performance. &gt; And prioritizing speed of compilation in the first place is nice. As Go demonstrates, you can get impressive results when you predicate your design on that sort of thing. Go gets away with this because it does much less interesting things for you (generics, monomorphization, fewer optimizations, a richer type system, ...). Trading robustness and the ability to write abstractions in user code is not a trade-off I would consider making. A more interesting challenge is to have a rich type system and a language that does a lot for you while still improving compile times.
Don't worry...I intend to show with my solution WHY OP shouldn't do this, in case the compiler isn't already telling them. :)
&gt;where rust simply isn't a very good language to use? I would say... when you want learn programming... &gt;And I mean from a technical perspective, not a politics perspective. too broad, I would say... mathematics
+1
On one hand having IR is essential for a compiler \[1\], and on the other hand having too much types of IR hurts performance, which as mentioned is one problem Cranelift is tackling with. &amp;#x200B; Do you think that it's possible to use less types of IR in rustc as well? Or is the current architecture most beneficial? &amp;#x200B; \[1\] [https://news.ycombinator.com/item?id=19536179](https://news.ycombinator.com/item?id=19536179)
btw, I'm one of its maintainers, so you can ask me anything
Following works on my machine: `git clone https://github.com/JDemler/BidirectionalTypechecking` `cd BidirectionalTypechecking` `cargo test`
Relative to other languages, rust is still pretty young. While I don't think that is a bad thing, it means the ecosystem of community supported libraries isn't as mature in some areas. I use Go and Rust a lot and would choose Go over Rust for things like web servers. Diving into neural networks and machine learning? Probably Python is the better path. If you are new to programming and are starting on a project, a lack of library support for your specific use case can be a major blocker.
Oh yeah. I didn't catch that. Since there is a blanket impl Debug for DebugWrapper, I don't see, why this does not work...
cargo run does it, thanks a lot. The difference is, cargo run invokes 'rustc --edition 2018'. &amp;#x200B;
I have code for verifying jwt tokens with a JWK set in ooproxy. See: https://github.com/HAL24K/ooproxy/blob/master/src/openid.rs
Im absolutely newbie in Rust, I don't have experience. It's my first Rust code.
Sure, I don't have lots of good images, [these are the best ones](https://imgur.com/a/qWryVxN). There are people that have the reception automated with a Raspberry Pi so they have like two images per day. You can see more images on r/RTLSDR, keep in mind that most images are colorized using another software, WXtoIMG (propietary and no longer mantained, that's why I made noaa-apt). But there were a few posts that used noaa-apt.
*YOOOOOOOOOO!!!!* It's your **2nd Cakeday** InnPatron! ^(hug)
Fewer kinds of IR is not inherently faster, it really depends.
This is very cool! Yes, we're working on it.
You can simplify this a lot if you're willing to make some assumptions: [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=16cb0c13f4052a41d58838f135db7314). You should also look into the Num crate.
That's a great idea!
I haven't looked at it recently, but I believe this in one of [pijul](https://pijul.org/)'s aims. It's largely focused on correctness, but I being nicer to use than hit is a secondary directive.
That's what I came up with: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=d0b9bfffabcb399afc203304788a7c9c](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=d0b9bfffabcb399afc203304788a7c9c) As I understand, R can just be derived from input types, so it's not so dead.
&gt;My suggestion is to stop punishing people in reddit comments for their code Yeah, I think I should stop, and I should've picked my words. I was simply too frustrated with the code quality, mainly because I've worked only on paid or old projects during my recent years. Also, my last paid project was managing and maintaining a real-time analytics system installed in a highly restricted area. I had to be cocky w/ every *possible* issues, since applying fixes would take months thanks to paperworks. I've been trying to detox myself from the remnants of it, and think I should keep working on it.
Where is that figure coming from? I can't find it...