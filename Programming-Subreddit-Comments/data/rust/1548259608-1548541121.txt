I'm not sure that's a valid translation, since the second block isn't in an `else` clause. I think this is actually a current limitation with the borrow checker regarding early returns as described [here](https://github.com/rust-lang/rust/issues/54663).
&gt; Your structs need to derive(Serialize) though, which might generate a fair bit of code. Then I haven't won anything, because I wanted to save the "Debug" derives for each struct I want to dbg!(..). I tried to implement Serialize for $t in a generic way, but wasn't successful. 
Ya, my bad, for some reason I thought that the subtraction was to account for the values being exclusive of $x, so just adjusting the indices, but you're right. The implementation of binary\_search\_by uses the pivot as being size/2
Thanks for the response. Why would you need to call \`move\` on a lambda though?
do you actually mean struct of array rather than array of struct?
Does [`toml-rs`](https://github.com/alexcrichton/toml-rs) not count for being `serde`-compatible with TOML?
TOML is a bad format for snapshots because it can‚Äôt represent arbitrary strictures and null. 
A possible extension is to re-shuffle array elements after construction to enable http://bannalia.blogspot.com/2015/06/cache-friendly-binary-search.html
I sat down with the algebra. [An exhaustive test of i8 shows that wrapping_mul](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=ee31ba3747d9404b6fc1ce60949d9d50) does what you want. A signed number can be replaced by a sum: `x = s + u`, where `u` is unsigned of the same size, and `s` is either 0 or -2^n matching the sign bit. This means that the signed product decomposes like this `a * b = (s_a + u_a) * (s_b + u_b)` s_a * s_b + s_a * u_b + s_b * u_a + u_a * u_b The last term is just the unsigned product. The other terms have a factor of `2^n` and are discarded by wrapping modulo 2^n. Therefore the signed and unsigned wrapping products will have the same bits. 
Yes. Column rather than row orientation, basically. It works better with SIMD operations and in the context of many kinds of operations is better for branch prediction.
I really *don't* know why it mostly died out. There was never really a "killer app" for STRIPS, and it's in a hard part of the computational complexity space (PSPACE-complete). In practice this means that large instances are pretty tough. The problem of computing cost-optimized, robust, and/or anytime/reactive plans is even harder, and less progress was ever made on it that I am aware of. A\* does a lot of the simple things that a STRIPS planner might be asked to do, efficiently and with an easy implementation, so that could be part of it. I would have thought that SATPLAN augmented with an SMT solver or somesuch would be routinely used for design problems in areas like IC design, but that doesn't seem to be the case. The rise of ML as the dominant paradigm in AI also didn't help the planning field: ML has been "sexy" for the last 15 years. Not that ML really addresses the same class of problems, but with everybody carrying around this big hammer I guess maybe everything looks like that kind of nail at least a little bit. Those are my guesses, but I really don't have an "inside story".
Honestly YAML is fine. People make too big of a deal about it in practice. 
There is a binary heap though? https://doc.rust-lang.org/std/collections/struct.BinaryHeap.html Why would I use the sorted vec over the standard library. 
Very interesting! Thank you for sharing. +1 on the IC design would be great if the computer can ‚Äòfill in the blanks‚Äô. 
It's not just the effort that could've been saved but rust actually outperforms C(++) in my (limited) experience. For bare number crunching (numeric integration using simpsons rule and discrete fourier transform as FFT). A buddy of mine wrote the C++ version (being a professional C++ guy) and I the surely quite shitty rust version and one in C and on my machine the the C and C++ versions clocked in at 0.004 to 0.012 seconds and rust at 0.0038 to 0.0043s (for the particular testcase). What I found especially interesting was that rust ran so stable with respect to runtime whereas the C and C++ versions had these large jumps in runtime. (I also did a python version, it ran about an order of magnitude slower than the other languages :D )
No I guess I should clarify. When you put the sync code in an actor it still blocks the thread. But actix has a nice example showing how you can make a small pool of these actors and asynchronously send them work from a separate thread (like the main one). It‚Äôs a shim, but I found it handy. 
I don't quite get it. If you use structs with arrays as fields, won't that boil down to being a bit worse than pure arrays? I may be not deep enough into the topic to follow you here, I for example have no idea what SIMD operations are.
This is really interesting. I will be looking at this in a lot more detail over the next few days. Thank you for sharing. &amp;#x200B;
Yeah I'm not satisfied with the background on the redesign, I just grabbed a random orangey-thing to attempt to give the sub some distinguishing feature and make it look less bland. If anyone has anything better I'm receptive to suggestions.
&gt; There is a compiler pragma, `overflow-checks`. It applies to the entire artifact - the crate and possibly all functions inlined from other crates (since it's a codegen option). I would expect it to apply to *all* crates, yours and dependencies, since it's a codegen option and dependencies are compiled with the same codegen options; I may be wrong. Still, this means that the user *can* override the default behavior and pick either of panic or wrapping for all built-in arithmetic operators for their whole application. The compiler only has "sensible" defaults.
You aren't using stack_count anywhere except to decrement it. You can either use it (ie in an expression) or rename it to start with an underscore.
There is even https://crates.io/crates/binary-heap-plus which one could use. But congrats on the crate anyway!
SIMD operations means single instruction, multiple data. They are instruction sets found in *most* modern processors. They let you load 2, 4, 8 or more data elements (ints or floats of various widths) into "SIMD registers" and then perform the same operation in a single clock cycle (well, usually anyway) on all of the elements rather than one at a time. By using struct of array, you simplify the loading of the elements into the SIMD vectors into a single load instruction rather than having to pack elements from multiple addresses. Array of Struct is the opposite and is more oriented around infrequent access. For data stores where you really don't access the actual data much and when you do, you only need a few of the records, that's fine, but a lot of hot paths in code work with *all* of the data in a given collection. Even for some on-disk data it can make more sense to have it oriented by column rather than row. I might be getting some of the fine details a bit off and glossing over some things since I tend to work with higher level tools that exploit these instructions, but that's the gist of it. Honestly, the choice comes down to knowing exactly how your data is going to be accessed and used, but I think struct of array is a better choice in a *lot* of situations. That said, few languages explicitly lean into that kind of decision, and as a result kind of force array of struct when creating generic data structures, but anything that uses the concept of a DataFrame is almost assuredly struct of array.
Huh, thanks for the extensive answer. I only worked with RISC architectures on the very low level where loading multiple into multiple registers at once isn't a thing. Guess I'll have to take a shot at x86 to get to know the inner workings
Yep. We haven't found any bugs in Ulf's core algorithm, and we have ongoing round-trip testing (every PR and CI build tests some random doubles, and will fail if they don't round-trip; I didn't write test code to detect too-long rounding, but all of our manual tests have passed.)
You want r/playrust.
Compiling Rust to NVPTX is still a work-in-progress. I'm a bit out of the loop on this - I know that some members of the [unofficial Rust-CUDA team](https://github.com/rust-cuda/wg/) have been working on this but I don't think anything too major has changed lately. They can correct me if I'm wrong. It is possible to compile really basic Rust kernels, but that's about it. My recommendation is still to use CUDA C to write the kernels and use [RustaCUDA](https://github.com/bheisler/RustaCUDA) to load and launch them, though as the author of RustaCUDA I might be biased.
You probably meant to go to r/playrust. This subreddit is about Rust the programming language.
&gt; because I wanted to save the "Debug" derives for each struct I want to dbg!(..) If that's what you want to do, deriving `Debug` is the cheapest technique by every standard I can think of. Code complexity / impact on the source? Yes. Runtime size? It *should* be possible to optimize out\* and if it doesn't then other techniques won't either. Cache performance? `Debug` doesn't change the data representation, it just adds instructions to interpret the data and serialize it as utf8 text. \* specifically it implements `Debug::fmt` for you. This is a trait method which takes a `&amp;`-reference to your struct, a parsed version of the `{:stuff}` template, and a vtable+data pointer of type `&amp;'a mut (dyn Write+'a)`. The last two are packed into `fmt::Formatter`. `Write` in this case is `fmt::Write` with the required method `write_str`. Thus the responsibility of `Debug::fmt` is to generate fragments of utf-encoded text in order (or referencing global static data) and call `write_str` - indirectly though the vtable - to copy those fragments to wherever they're going. [You can see for yourself by implementing and importing `fmt::Write` like so](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=fa3f17547d8532b2e9a392094d21adc6). (I find it interesting how many times `write_str` is called with an empty string. Each of those is a machine-level indirect call instruction! Serde hopefully does better.) If you really do need to visit every field in an automated way, especially to generate something other than utf8 text, Serde is probably the best framework. But it's overkill for `dbg!`. 
&gt; RISC architecture Have you heard of ARM's NEON instructions? They are SIMD. The x86 architectures have gone wider faster (512 bit SIMD registers), but even 128 bit can get you some nice speedups if you can fit your data into smaller floats and ints.
Can't wait to give a listen! 
Nope, haven't heard of it. I only did 8-bit AVRs up until now. Really makes things easy if 8 bits are all you have and there are not datatypes (except for when you need to access a bigger adress... but lets just not talk about these times) :D
So, programming languages/functions that rely on working efficiently with huge vectors: would they actually go that far down to utilize SIMD directly? Stuff like matlab or numpy I mean.
Thank you! That worked 
I would prefer to stick to Rust libraries or things that improve the experience of using Rust in some way, but I could be willing to make exceptions if the idea would make for a good Rust learning experience for somebody. What do you have in mind?
very cool! that will be simpler code than casting and shifting things around. 
great to hear I'm not just being excessively fussy. I would suggest just making it a flat colour (as boring as it sounds), and rely on the banner and icons to distinguish it. just having the classic Rust 'R' chainring logo visible somewhere is enough IMO.
&gt; Still, this means that the user can override the default behavior and pick either of panic or wrapping for all built-in arithmetic operators for their whole application. It also means that anything upstream of that decision can't decide differently which is my biggest pain-point with the whole thing. I'm not sure we're disagreeing, I'm just salty that when I come across an algorithm that needs wrapping math I either need to depart from `std` or live with an *enormous* amount of `Wrapping( ... )` and `x.0` everywhere. I should probably redirect that salt into writing a simple, lightweight, and highly usable crate for bit-twiddling. But that's *haaaard*.
This is called [Eytzinger](https://docs.rs/eytzinger/1.0.1/eytzinger/) layout.
It's a very good article. Thank you for sharing.
I second the idea of trying Postgres. Most people pigeon-hole Postgres into "only a relational database" because that's what it does best. But even if you need a document or object store, the `json/jsonb` and `array` data types are quite powerful and performant in Postgres. Postgres 10 also introduces a rather easy way to shard data sets by a certain key (you could always do it, but now it's easier than before), making a distributed document/object system entirely feasible to build in Postgres. Plus, even websites or apps that primarily need document-based storage usually need at least *some* relational storage as well, e.g. maintain a user list relationally, but then give each user their document storage space. Postgres can easily integrate relational and object storage in a single system, removing the need for two databases.
I second the idea of trying Postgres. Most people pigeon-hole Postgres into "only a relational database" because that's what it does best. But even if you need a document or object store, the json/jsonb and array data types are quite powerful and performant in Postgres. Postgres 10 also introduces a rather easy way to shard data sets by a certain key (you could always do it, but now it's easier than before), making a distributed document/object system entirely feasible to build in Postgres. Plus, even websites or apps that primarily need document-based storage usually need at least some relational storage as well, e.g. maintain a user list relationally, but then give each user their document storage space. Postgres can easily integrate relational and object storage in a single system, removing the need for two databases.
Serde is truly best in class. It's probably the library I miss most going to other languages.
* You can't get a sorted slice of a BinaryHeap. * You can't iterate over a BinaryHeap in sorted order without consuming it. (`BinaryHeap::iter` yields the elements in arbitrary order.) * A sorted vec gives O(1) access to both the max and min items. (BinaryHeap only gives you one of these.)
This is awesome -- I've considered trying to hack together my own solution for this, but didn't think of using wasm-bindgen to help produce the typescript definitions. When I have a chance, I'll try and implement this, see how it works out.
This looks once again like a super-interesting crate! Is there an explanation some where how deserialization (or rather [`inventory`](http://github.com/dtolnay/inventory) works?
One of the issue of using a compressed representation like `Vec` is that insertion is O(N): - O(log N) comparisons to find where to insert. - O(N) to shuffle all elements after the insertion point to make place for the element to insert. I remember having a lively discussion with Alexandrescu about how to improve his `AssociativeVector` (Loki library) to manage a true O(log N) insert and remove while maintaining O(log N) search, and one possibility we considered was to maintain a "staging" area of log(N) elements at the end of the `Vec`... never proved the complexity of insertion or removal, but we ended up thinking it'd probably be more around sqrt(N) than log(N), which is not too bad I suppose. Look-up: - O(log N) comparisons in staging area (linear scan)^1 , then O(log N) comparisons in main area (binary search). Deletion, no compaction: - O(log N) look-up. - O(1) Tombstone. Deletion, with compaction: - O(log N) look-up. - O(1) Tombstone; counter reaches O(log N). - O(N) compaction. Insertion, on tombstone: - O(log N) look-up. - O(1) insertion; decrement counter. Insertion, incomplete staging area: - O(log N) look-up. - O(log N) insert in staging area (amortized). Insertion, completing staging area: - O(log N) look-up. - O(log N) insert in staging area (amortized). - O(N) in-place merge of main area and staging area (both are sorted). The complexity of Deletion and Insertion are slightly complicated by the fact that O(N) happens only ever O(log N)... still, in any case, the algorithmic complexity is properly worth it. And of course, one could object that the principle use of such a vector is to write once, read many times. ^1 *Yes, I am proposing linear scanning a sorted staging area. Modern processors LOVE linear scans, so for few items it's worth it.*
More or less. If they don't explicitly invoke the SIMD intrinsics, they're probably written carefully to [autovectorize](https://en.wikipedia.org/wiki/Automatic_vectorization).
Nice man! It's great to have some extra time after graduation :)
Very marginal speed loss for a significant memory gaiin. Seems like a reasonable change for Rust, from both a pragmatic and a philosophical perspective.
That's quite interesting, thanks for sharing! 
Proc macros are pretty complicated, but probably not something the average user needs to write (though they may certainly benefit from crates providing them). &gt; I thought Rust macros were inspired by scheme macros, and scheme's system is simple and lets you run arbitrary code, so why is rust so complicated? I think fundamentally it's more complicated in Rust because Rust is not a homoiconic language written in s-expressions. The syntax of scheme (and other lisps) is really, really simple, making things like this much easier. Rust has a more typical and complicated syntax, which makes this harder. So writing procedural macros involves manipulating a complicated parse tree, and Rust has to decide how to provide a public API for that, without restricting future changes to the language. Also, scheme is a dynamic language, while Rust has to evaluate the macros at compile time. Which adds a bit more complexity to proc macros.
Thanks; I'll merge it! I just grabbed the links from Amethyst's own README, so you might want to open a PR there as well!
Yeah, I would definitely never recommend this as a general practice. üòÜ It's kind of *terrible* actually. But it's a perfect fit for what I'm doing with the show ‚Äì modulo a few things I have to do that are extra work to make it do the right thing for e.g. having discoverable links to the RSS feed, iTunes, etc. I mostly picked it because I knew I'd have *tons* of code samples anyway, and that the show would essentially need a dedicated crate of those to make sure they all worked, and‚Ä¶ I knew I *could* make it work.
I wrote it thinking it would be pretty uncontroversial. I think it just needs some people to get it over the finish line it's almost done!
`null` is normally represented as simply not being present in TOML. Why would you need explicit null? And what do you mean by "arbitrary structures"? This is a domain I'm curious about, so I'm hoping you'll enlighten me. :) 
why don't you have `WebEvent: Serializable+Deserializable`?
On zero-cost abstraction, or zero-overhead abstraction, unfortunately iterators are not QUITE zero-overhead abstractions. I've actually been hunting a missed LLVM optimization over `RangeInclusive` iteration that is *really* annoying, and mostly boils down to using external iteration vs internal iteration: https://www.reddit.com/r/Compilers/comments/afmhgq/how_to_debug_missed_optimization_in_llvm/eek5ou2 . The problem is that when you have an internal iteration which does a first thing *then* a second thing, in the external iteration you need to remember whether you were in (1) or (2), and this induces a switch on this case every time `next` is called. Sometimes LLVM manages to realize that the transition from (1) to (2) can only happen once, and transforms: case = 1 loop { if case == 1 { // block A // in some conditions, case = 2 } else { // block B // in some conditions, break } } into: loop { // block A // in some conditions, break } loop { // block B // in some conditions, break } ... but sometimes it doesn't, and performance suffers :(
This problem, referred to as _ordered file maintenance_, requires `O(log^2 n)` or `O(log^3 n)` depending on how much extra space you're willing to allow the array. [Source](https://epubs.siam.org/doi/pdf/10.1137/130907653)
or remove it
&gt; I should probably redirect that salt into writing a simple, lightweight, and highly usable crate for bit-twiddling. But that's *haaaard*. Ah, I understand better then. Indeed, when writing a library you have to consider that the result of `a * b` is *unspecified* in case of overflow: it could either panic or wrap, you can't rely on either. And yes, for bit twiddling... 
&gt; null is normally represented as simply not being present in TOML. Why would you need explicit null? Because it makes a massive difference for a snapshot test if data was accidentally removed or set to null. Additionally see next comment &gt; And what do you mean by "arbitrary structures"? You cannot serialize many structures. For instance Sentry's protocol structures which we snapshot test have a structure like this in JSON: {"seq": [1, null, 2], "_meta": {"seq.1": "meta info here"}} This cannot be formatted to TOML because of the null value in the array. Other things that cannot be represented in TOML: {"":23} [{"x": 42}] [1, 2, 3] There are many more things. TOML might be nice for configuration but it cannot represent arbitrary structures which makes it useless for this purpose here.
No because lifetimes allow for most of the compilers static analysis which would prob be impossible otherwise. But I'm not suggesting another language would be able to figure that out how to achieve rusts safety without lifetimes. I said that the potential competitor would just have to be viable for systems + slightly easier to use. Its very possible it would be less safe and system programmers would still choose it over rust. I'm picturing a c clone with all of the modern syntactical niceties and maybe a cargo tier package manager to go with it. That would be very compelling to people already writing systems and would not require a drastic change of their mental model like lifetimes do. Rust would still have it's niche but the competitor would just be way too compelling.
You'll get used to the derives fast enough. I'd say being idiomatic is more important.
Would love to see a blog post explaining how this works!
Indeed. Although I would assume that the performance of the "system allocator" probably depends quite a bit on which system you are running! Of course the best bit is that it's (trivially) configurable. So you can easily choose whichever one best suits your application.
Indeed. I've been learning C# recently, and while there's definitely some C# I would like to see in Rust, but I haven't found anything for (de)serialization that's nearly as good as serde. I'm considering making a port!
Later on he makes the jump to floating bar. At that point he still had fixed sizes for both the numerator and denominator. When he also extends it to 64 bits he claims to achieve a whole rendered image with exact results.
Not trying to be 100% negative tho. Rust is doing pretty good. The google fuchsia stuff keeps me hopeful. Scala had the opposite with google actively supporting 2 different competing languages ( kotlin/go ). 
I implemented a fairly slow but neat sqrt using [continued fractions](https://en.wikipedia.org/wiki/Methods_of_computing_square_roots#Continued_fraction_expansion). You compute the continued fraction of the product of the numerator and the denominator using that algorithm, and then return the largest approximant divided by the denominator that fits in the number of bits available. So in a sense it is the closest representable fraction to the true square root.
What in C# would you like to see in rust?
I didn't know about `inventory` before. It might be a nice way of making criterion / bencher easier to use. Rather than having a central list of all benches that can get stale (forget to add some), you can have registration next to each bench, or a proc-macro.
jemalloc shines with limiting fragmentation in face of long-term churn and in avoiding contention in face of heavy multithreaded workloads. I woudn't expect to see much difference in small benchmarks like this.
[The docs describe AsMut as "A cheap, mutable reference-to-mutable reference conversion."](https://doc.rust-lang.org/std/convert/trait.AsMut.html), which sounds somewhat vague to me. Is it typically implemented for containers that want to easily yield mutable references to their content? E.g., you have a mutable reference to an Option 'a', and `a.as_mut().unwrap()` would yield a mutable reference to its contained value. Hence the term "mutable reference-to-mutable reference"?
I read the results differently. Of the 10 results 6 of them have an improvement of about 1mb. Maybe I'm just too used to using Java, but these days a 1mb improvement is pretty trivial. Yet with binary-trees you have a 15mb loss. To me that's a bigger issue.
Because Serialize and Deserialize aren't object-safe. There needs to be some code to say what is actually in the `Box` when doing `Box::&lt;dyn WebEvent&gt;::deserialize(...);`. Rust won't write that code for you (to determine what goes in the box, of all different types implementing WebEvent)
This in amazing! I can't really say anything more. I thought this would always be 100% impossible.
How do you know? Can't find it mentioned in the text ‚Äì is it in the video?(havn't watched it yet)
Yes! An attribute macro that you write directly on the bench function to register into a benchmark group would be great.
A big one is some form variable length functions / optional function arguments. Keyword arguments and/or type inference for struct instantiation would make a big difference too. I can't tell you how much ergonomic APIs are when you can call `foo.bar()` and `foo.bar(qux)` and `foo.bar(opt1: qux, opt2: qak)` without: 1. Having to change the method name (whose name you have to guess) 2. Having to import another struct (whose name you have to guess)
I was thinking about some solution that could use this bound internally, but expose something object safe. What if the user wanted to write a manual impl of serde traits? (his solution doesn't have an `#[derive(Serialize, Deserialize)]` that I could substitute, in principle, for a manual impl)
Can one replace `NonNull&lt;T&gt;` with `ManuallyDrop&lt;Box&lt;T&gt;&gt;`, and have multiple copies of the latter (eventually dropping exactly one of them)? Or is that somehow UB (perhaps due to box magic)?
Which License?
The structs `PageLoad` and `Click` in the example code both derive Serialize and Deserialize and could be substituted for manual impls. Deserialize as a supertrait is not a thing that makes sense because in order to call supertrait methods on a trait object you need a value of that type already. When deserializing you don't start with an existing value of the right type.
Ah, ok. Thanks for clarifying.
oh. got it
I honestly thought you were going to say deffered execution or extension methods. I guess I haven't used rust enough in anger to see that shortfall.
The crate is truly impressive but for me, it is a bit too much of magic. I can imagine that I would extremely enjoy using it today but I can also imagine that headache while investigating how it works months or years later.
Isn't that an argument in favor of iterators, rather than against it? If the iterator implements `try_fold` then you won't have this problem afaik (as long as you don't iterate over it with a `for` loop).
That's what it is intended to be used for. But inside that function the compiler only knows the methods of the trait and doesn't do anything special. Perhaps you are expecting it to behave more like `Deref` which the compiler treats specially, making it a bit magic. For example it will automatically coerce when a function expects a &amp;-reference as an argument. `AsMut` gets no such magic handling by the compiler.
Extension methods are pretty easy, you create a trait and implement it for whichever `T` and presto, 'extension methods' :p (well, you have to import the trait, but iirc you have to do that in C# too)
Is there a link somewhere that shows some details of how Actix is involved? &amp;#x200B;
I believe that you *don't* have to do that in C# (you have to import the package containing the extension methods into your project, but you don't have to import anything extra in the file you use the extension methods). Not sure which of these I prefer.
&gt; (as long as you don't iterate over it with a `for` loop) Well... it means that the obvious interface to iteration (the `for` loop) is NOT zero-overhead abstraction. And let's be honest, coming from C, C++, Java, ... people are more likely to write: for i in 0..=n { count += i; } Than they are to write: (0..=n).for_each(|i| count += i; ); So any performance difference between the two is jarring, and certainly a contradiction of the zero-overhead principle. *Note: and yes, otherwise, adding `try_fold` to `RangeInclusive` nicely improved performance.* *Note: I may a bit grouchy related to this topic; in my defense I've now spent 3 week-ends pouring over LLVM IR in an attempt to understand why it refused to optimize the naive `for` loop correctly...* 
I am one of the team. It is written in rust and actix. This blog post just a marketing material.
Hey, a podcast about rust. Cool. I am a beginner at rust, should I start with the first episodes or just roll with the new ones?
Hey, a podcast about rust. Cool. I am a beginner at rust, should I start with the first episodes or just roll with the new ones?
This was a really good explanation, thanks.
I am surprised at the binary-trees case as well. It seems likely that this reflects a slab-size issue: when allocating memory for a node, the allocator does not allocate *exactly* the number of bytes requested, but rounds up to the closest slab size. I suspect that the size of the node is such that jemalloc was getting lucky and the system allocator is not... perhaps because jemalloc is more fine-grained?
It's not clear to me if the `#[typetag::serde]` attribute on an `impl` will create: - one entry in `inventory` per concrete type. - OR one entry in `inventory` per `impl`. I would expect the latter, seeing as when de-serializing `WebEvent` you would need to know which concrete types are valid for a `WebEvent`... but I may be mistaken.
I just pushed another [RFC](https://github.com/rust-lang/rfcs/pull/2628), this time a very small change to make macro expansion work for `proc_macro_attribute`s. Also I'm working on rewriting [mutagen](https://github.com/llogiq/mutagen) using the new API.
Out of curiosity I decided to check out the source for `Rc`. The contained value is dropped, as promised, when strong reference count drops to zero. The `Rc` itself is freed when all references, including weak ones, are gone. So the natural question is: is it possible to make a reference cycle of weak references and produce a tiny memory leak of an `Rc` without contents? This has to be pretty convoluted, though. On a related note, the implementation determines whether or not the underlying pointer is still valid by comparing it with `usize::MAX`. I assume there's a good reason for doing this as opposed to using an `Option`, but what is it?
Optional function arguments with default values would really shine when programming GUIs. GUI elements often end up highly configurable, but you commonly need just a few parameters. HTML,CSS and JS take this to an extreme where basically everything is optional (causing confusion and unreliability IMO). In Java on the other hand, you have to call a setter for everything, which becomes very verbose. I would love it if Rust wouldn't become as verbose as Java in GUI programming. But I doubt we will have optional arguments any time soon. (I guess problems with the trait system would arise.) Macros could probably provide a good workaround, with a similar system how Kotlin's optional arguments interact with Java. 
Why did Microsoft chose actix? Performance or rust first project ?
In C#, to use a set of extensions methods in namespace `Foo.Bar`, you have to add `using Foo.Bar;` at the top of your file.
IIRC, we don't set codegen_units in the benchmarksgame. I remember seeing some workloads improve when compiled with `codegen_units=1`.
Simpler approach to the relationship between files / modules / namespaces / packages but that ship has likely sailed.
Thanks, I'll give it a try!
Both (it will error if you try to put it on a generic impl)
[https://github.com/TeXitoi/deriv-rs](https://github.com/TeXitoi/deriv-rs) Using typed-arena, I go from 2.3s to 0.9s with 10 as parameter. I don't have twitter, thus if someone want to respond with this link, feel free.
I think quite a lot of "higher level" apis (where there is a lot of optional configuration to specify) have this same issue. See for example `rusoto`. It's full of structs/traits like [this one](https://rusoto.github.io/rusoto/rusoto_s3/trait.S3.html) which an options struct per method, each of which must be imported by the consumer of the method.
I did end up adding a more explicit note about that.
Yes, it's possible. 
The programs are compiled with `-C codegen_units=1`. You can see the build command on the page for each program, e.g. https://benchmarksgame-team.pages.debian.net/benchmarksgame/program/revcomp-rust-2.html
Yep, I haven't gotten deserialization of generic impls working yet but I have ideas. Currently the error is: error: deserialization of generic impls is not supported yet; use #[typetag::serialize] to generate serialization only --&gt; examples/web_event.rs:34:5 | 34 | impl&lt;T&gt; WebEvent for Vec&lt;T&gt; { | ^^^ There is a serialization-only mode though, if that's all you need, and it does work for generic types. #[typetag::serialize(tag = "type")] trait WebEvent { fn inspect(&amp;self); } #[typetag::serialize] impl&lt;T: Serialize&gt; WebEvent for Vec&lt;T&gt; { fn inspect(&amp;self) {} }
They built it
Then why did they built it ?
Yes.
Actix was personal project. And was built just for fun.
Fun and TechEmpower Benchmark prowess!!!
Oh, very sorry about that. That will need to be fixed indeed. Still, I appreciate the quick response!
Oh, very sorry about that. That will need to be fixed indeed. Still, I appreciate the quick response!
I think you had f.lux or something equivalent running, messing up the colors.
I'm just looking for something that looks roughly like the original type - like, if I feed it `Vec&lt;String&gt;` that's what I roughly expect to see. Both `{:?}` and `{:#?}` produce a debug printing of nested struct that is pretty far off.
Thata quite cool. We need more such apps so we can kick those Electron guys asses. Also...every lazy shell guy sets aliases...tons of aliases.
I made some quick graphs, if anyone is interested &gt; https://docs.google.com/spreadsheets/d/1i4CfMvZAeI_GgDfqCuHnxpwn7nOHOikV3KVkTm34d24/edit#gid=0
I made some quick graphs, if anyone is interested &gt; https://docs.google.com/spreadsheets/d/1i4CfMvZAeI_GgDfqCuHnxpwn7nOHOikV3KVkTm34d24/edit#gid=0 
Excellent talk. I really wish someone would have explained async as "basically a userspace scheduler" back when I was first learning it.
Got it. Thanks for the detailed response, TIL!
Thanks and agreed! Also, funny you should say that about aliases. This whole little project got started when I was looking at the following lines from my `.zshrc` and thinking "there's got to be a better way": ```bash alias notes="bat --style plain --theme TwoDark ~/.notes_file.md" alias link="bat --style plain --theme TwoDark ~/.links.md" alias ideas="bat --style plain --theme TwoDark ~/.ideas.md" alias todo="bat --style plain --theme TwoDark ~/.todo.md" ```
The things that /u/dtolnay manages to achive with proc_macros never ceases to amaze me. Great work as always! Both `typetag` and `inventory` look like they open up quite a few new interesting possibilities for writing more maintainable code and creating better ecosystems of crates that depend on plugins.
Maybe. In doing so, you need to copy the data so that each of those sorting threads has its own space to work without overwriting the original list, particularly for sort-in-place algorithms which can't share their buffer (noting that sort implementations take `&amp;mut self`). There is also overhead in then moving this data over to the other thread, or worse, spawning a new one. I suspect that for most cases, the overhead incurred this way would overpower any gain from finding the "best" algorithm at runtime.
Newbie here, struggling with the concepts of borrowing etc. Can someone explain to me why the following [function](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=56ea7eb03746266b8dcdb99ae3424334) fails? ```rust pub fn largest&lt;T: PartialOrd + Clone&gt;(list: &amp;[T]) -&gt; T { let mut largest = list[0]; for item in list.iter() { if item &gt; largest { largest = item; } } largest.clone() } ``` 1. Why is &amp;T expected in the first error? My function accepts a reference to a vector, not a vector of references right? ```bash | 6 | if item &gt; largest { | ^^^^^^^ | | | expected &amp;T, found type parameter | help: consider borrowing here: `&amp;largest` | = note: expected type `&amp;T` found type `T` ``` 2. Howcome largest and item are not of the same type? ```bash error[E0308]: mismatched types --&gt; src/lib.rs:7:23 | 7 | largest = item; | ^^^^ expected type parameter, found &amp;T | = note: expected type `T` found type `&amp;T` ``` 3. How would I fix my function to use the Clone trait to find the largest item in a vector? Is it possible to make a function which finds the largest item in any iterable, to make it more generic?
I have not! This is great, thank you.
Thanks! Piet looks very interesting.
Oh dear. I hope this won't bring more deserialization bugs to Rust... This gives a lot more leverage for constructing serialized representations that conform to the types as declared, but violate some implicit assumption in the code. 
I don't know what the margin of error is for each of these results, but I'd assume that the difference is within or close to it.
For benchmarking, a bump allocator that never frees is probably ideal. Not much can be derived from benchmarks regarding allocators, in my opinion, since benchmarks are short lived and something like jemalloc is designed for Firefox, a very long lived program.
What happened?
The first thing you need to fix is let mut largest = list[0]; That's trying to move the first `T` instance out of the slice. However, you haven't said that `T` is `Copy`, so that move would leave a logically uninitialized hole at the front of the slice, which would lead to UB since the slice has no way to represent "missing" elements. The easiest way to fix that is to take a reference instead of trying to move the element: let mut largest = &amp;list[0]; Making this change will also get rid of both of the compiler errors you included, because now everything will be `&amp;T` rather than a mix of that and `T`. (I think the reason that the compiler didn't actually bother you about the illegal move above is that these type errors came up before it noticed.)
https://github.com/krl/appendix/blob/master/Cargo.toml#L9
My suspicion is that doing something like this without triggering UB would at least have to involve `UnsafeCell`, as in maybe `ManuallyDrop&lt;Box&lt;UnsafeCell&lt;T&gt;&gt;&gt;`, along with some runtime guarantee that you never obtain two `&amp;mut T`'s at the same time. But I'm not certain that that would be good enough.
I don't see how you can produce a reference cycle with *just* weak references; once the strong count falls to zero on one of them, each one of the cycle will be freed in-turn. You'd have to hold or leak one strong reference to at least one of the nodes to leak them all (and then it's at least just the allocations that are leaked and not the contents).
Oops, I think I missed the ‚Äúonly weak‚Äù part of the parent üòÖ
I think the compiler *does* assume that `Box` is unique so changes done through one of the pointers might not be reflected on others if the optimizer elides some loads due to this assumption. ("They just loaded this pointer here and it's *supposed* to be unique, so why load it again? Just reuse the value.")
Bugs are always a valid suspicion! The core code of Serde is reasonably battle tested but this feature is built on some brand new code outside of Serde -- so I am under no delusion that it is bug free. It's worth considering both sides though: over time we will iron out the bugs here like we have in Serde, and there are going to be use cases that are bug-prone or impossible before today that are made *less* bug-prone when written using Serde trait objects. Regarding violating implicit assumptions of types, the feature is certainly possible to use inappropriately but I don't see it as being any different from existing plain Rust enums: #[derive(Serialize, Deserialize)] enum WebEvent { PageLoad(PageLoad), Click(Click), } All you're getting here is that we register each trait impl automatically as an enum variant. You could have written the enum yourself but it would have been nasty to maintain and you would be writing boilerplate bug-prone code (!) to implement methods on the enum by dispatching to methods on the individual variants.
Thanks for the link. I do think is the same issue.
Thanks for the executable example!
&gt; jemalloc is designed for Firefox jemalloc was designed as a [replacement for phkmalloc in FreeBSD](https://people.freebsd.org/~jasone/jemalloc/bsdcan2006/jemalloc.pdf).
Okay so maybe I should explain a bit more (and also be a bit more careful about phrasing, I edited my original post a bit). What I'm specifically concerned about is that this will make it easier to write "enterprisey" code where you have many layers of objects, all with their own responsibilities, being serialized into the same document. Due to the separation of concerns in such code you no longer have a single place where security-relevant constraints on the object graph should be / can be handled. An example. * The top level code performs deserialization on some user input to get a fairly innocuous `FrobRecipe` struct, but has no awareness of how the things it's deserializing work internally. * The `FrobRecipe` is internally using some general utility trait object that uses dynamic dispatch. Let's call it a `BuilderGraphNode`. In practice this is always a `FrobBuilderGraphNode` or a `FancyFrobBuilderGraphNode`. * But there are lots of other places in the program that define their own varieties of `BuilderGraphNode`. Some of them do some truly remarkable and dangerous things. Maybe a `ShellCommandBuilderGraphNode`? * Now, the code that thought it was only deserializing an innocent `FrobRecipe` can actually be tricked into deserializing a `FrobRecipe` that contains a `ShellCommandBuilderGraphNode`. This may cause shell commands to be executed when the top level code thought it was only invoking some innocent Frob code. This is all very theoretical of course, but I hope it kind of illustrates how such a high level of abstraction and separation of concerns this kind of flexibility in a serialization format enables can cause unexpected situations. I hope I never see Rust code that is quite as "Enterprisey" as this, but it's a big problem in Java land. Admittedly things go bad much faster in Java land because the code will happily load libraries to find more types and it has means to construct and load bytecode at runtime.
&gt; **something like** jemalloc is designed for Firefox
Nah, I was legitimately just misremembering, and thought that jemalloc was built by Mozilla for Firefox. It's probably something I unintentionally "learned" years back when I didn't have a strong technical background, and saw that Firefox used jemalloc, and I just never unlearned it until today.
FWIW, the derive\_more crate comes with support for Deref And DerefMut derives. [https://crates.io/crates/derive\_more](https://crates.io/crates/derive_more)
Isn't that Go?
As an aside, since Java 8 you _can_ write count + IntStream.rangeClosed(0, n).sum(); but I agree that it's much more likely they use a for-loop - also, in Java it most probably not zero-overhead (but it might be - keeping fingers-crossed for escape analysis isn't confidence-building). In the general case they're even more likely to use a for-loop given the limitation of capturing in the lambda. You can't do this... int count = 0; IntStream.rangeClosed(0, n).forEach(i -&gt; count += i);
Oh, that's... awkward, hahaha. However yeah my point is not to point out **something else** was actually something else, but that adding the phrase into context gives another meaning to it (claiming "jemalloc is made for Firefox" to claiming "jemalloc's purpose is to support long-lived programs"). That said, Rust definitely wins English in terms of conciseness!
/r/playrust
I see what you mean. I appreciate the thorough writeup! There are two major differences between Serde and (what I understand of) Java serialization that may sufficiently mitigate the ShellCommandBuilderGraphNode class of concern: - We require you to write `#[derive(Deserialize)]` on the ShellCommandBuilderGraphNode rather than working silently on the class via runtime reflection. The author and the code reviewer should pause and think whether they really want shell commands getting deserialized. - We require you to write `#[typetag::serde]` on the trait impl. The author and code reviewer should *really* pause and think whether they want shell commands getting deserialized in code that doesn't know it is dealing with shell commands. This is unlike Java where accidentally having a ShellCommandBuilderGraphNode on your classpath can make you vulnerable. Ultimately if the author and code reviewer decide they want shell commands getting deserialized in code that doesn't know it is dealing with shell commands, they will find a way to introduce that vulnerability regardless of what language or libraries they are using.
&gt;doesn't compile for anything other than my native target. Many, many people cross-compile *ring* successfully. Tip: Use [cross](https://github.com/rust-embedded/cross) if you can. \`cross build --target &lt;target&gt;\` will build your thing and will handle getting the C compiler and linker and all the settings right, automatically. Even \`cross test --target &lt;target&gt;\` works! It's pretty amazing. Anyway, I think the Rustls feature for ws-rs would be very cool.
Async/await with Future&lt;T&gt; is what comes to mind as a long term C# dev.
woops
Can someone ELI5 for a Rust noob?
Hey, I'm in London! And I'm also interested in a London Rust meetup. The second group you listed seems to have been having monthly meetups up until about 2 months (relatively shortly before Christmas), so possibly that will start up again? (coincidentally, I'm currently working on an alternative interface to Meetup).
I've seen color distortion with broken video cables that are dropping one of the color channels. That would be my guess. What were they supposed to be?
Assuming the numbers from the OP come from running on Linux, we're talking about the glibc allocator vs. jemalloc. The glibc allocator has a larger overhead compared to jemalloc for small allocations.
This looks great! I move between machines a lot. I'm wondering if there is there a way to have the mnemonics available from anywhere (ie. automatically sync'd as a \`.md\` file in GitHub repo or something like that?)
I tried with ref mut .. its worked too.. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=97aeba0bc909b992baaa5b5b461d57d6 
This seems like the kind of thing that Enums (when specific combinations are allowed) or builder patterns (when any combination is allowed) solve fairly well.
Thank you! Looking forward to your comments!
Thanks, glad you like it! There's not currently a way to do that **automatically**, but that seems like a great idea. Would you mind opening an issue on GitHub to request it as a feature and I'll put it on the roadmap for pre-1.0.0? In the meantime, you could certainly sync the mnemonics manually‚Äîthey're saved as `.md` files in the local data directory for your OS (so, for me it's `~/.local/share/mn`; check [the directories-rs docs](https://docs.rs/directories/1.0.2/directories/struct.ProjectDirs.html#method.data_local_dir) to see the data_local_dir for your OS). But that's not nearly automatic enough, so I definitely think this is worth a feature request!
You could do it, but not easily. All macros are evaluated _before type resolution_, so you'll need to manually read the file the macro is being invoked in and find the right structure. This is 100% possible with a `proc_macro` crate, but I would recommend against doing this. There are three main reasons we use `#[derive()]` macros instead of standalone `impl_debug!()`: 1. With `#[macros]`, you have a very clear view of what code is being meta-programmed on. "attribute-style" and derive macros all operate exactly on the code their attribute is applied to. This avoids "action at a distance", as it's called. 2. Local action not only lets users read what a macro acts on, it makes it very nice for the compiler to find all the input it needs to feed the macro. As I mentioned above, type resolution isn't done until macros are completely executed, so that macros can influence the type system in any way. This is good for what macros can produce, but bad in the sense that you can't get type information from the compiler from within your macro. This makes it much harder to implement "action at a distance" without the user also providing a list of fields, or a copy of the struct definition. 3. A line of `#[derive(A, B, C)]` above a struct or enum gives the reader a very clear view of what they can rely on being automatically derived. Combined with putting `impl`s near the struct, this increases readability quite a lot. There's one standard place to have automatically derived structures, and this is more than trivially useful when looking over someone else's codebase (or one you wrote a year ago). With those points in mind, I would recommend you stick to using `#[derive(Debug)]` rather than making your own macro. You totally can, but it'll be a pain, and I believe the end result will also decrease readability and comprehension of your code.
Thank you!! This is immensely useful.
How does this compare with erased_serde? https://github.com/dtolnay/erased-serde
Oh, of course, I wasn't planning on using these for `&amp;mut`. Just an `Rc` variant.
Worth noting that there's also https://actix.rs/, another actor framework but built on top of tokio. It also runs on stable rust, while riker seems to require nightly? Disclaimer: I've only ever used tokio and actix, have not user riker
Or you can always go macros.
Erased-serde is a low level building block for interacting with generic Serde APIs in an object-safe way. That is not enough to deserializing a boxed trait object, which involves knowing the set of concrete types that the data might be -- a totally different problem than calling Serde APIs. Consider that just using Serde, whether erased or not, you aren't going to be able to implement a function that takes the string name of a type and gives you a value of that type. This typetag library handles distributed registration of trait impls and then uses that impl registry together with erased-serde to perform trait object deserializations. The end result of conveniently deserializing trait objects isn't possible without both pieces.
That's neat, but I'm never going to remember the name of the damn thing‚Ä¶ Seriously, though, fun app.
thanks , I will try it.
thanks, I will try it.
Missing a zero in the 1.32 reverse complement memory value.
Is futures 0.3 even an option with Tokio yet? I thought Tokio only supports 0.1 while romio supports 0.3.
I did k-nucleotide #9. ~Month ago my solution was the fastest, after week I found that I am 3rd, first was #4, today I see that #4 is not the best too. I am a bit confused with the performance instability. BTW, often I was not able to find reason: no rust or libs releases and about impossible to understand what was changed. 
Ah okay. Been using serde_dyn's TypeUuid for type identifiers with manually registered types, but this `inventory` crate looks amazing! Looks to be the missing piece of the puzzle for automatic deserialization indeed.
&gt; Very marginal speed loss for a significant memory gain. That's what I thought at first, but then I realized some of that might have to do with the units and range of numbers involved. So I plugged the numbers into excel and on average speed differed by approximately 0.14%. Exactly half showed 1.31 as faster and half showed 1.32 as faster. I think it's safe to conclude that there is no difference in speed between these two. As for memory, they differed on average by 6.25% and all but binary trees were faster in 1.32. So I don't think there's any real trade-off here. The new version is a no-brainer.
Does the ctor crate bring the C++ static init fiasco to Rust or does it somehow avoid those problems?
+ it would be interesting to find top-time which happened.
It avoids those problems! The C++ static init fiasco is that construction of a static global can refer to other static globals, combined with initialization order being unspecified. So things inevitably end up referring to uninitialized other things and it can be nasty to track down where this happens because there is no signal of it in the source code. Also ultimately it's undefined behavior so who knows how the problem even manifests. The `ctor` crate doesn't give you any equivalent of a "static global". All you get is a set of functions `fn() -&gt; ()` that will run in some order before main. If you wanted, you could make one of those functions call another of the functions, but there's no hard there. Maybe the worst you could do is have an ordinary Rust `static mut` that is written by one of the functions and read by another function, but there is no violation of type safety there. With `inventory`, conceivably you could have one plugin's constructor iterate previously registered plugins of the same type. That's probably not useful but it is safe. It will just iterate the already registered plugins without observing the ones not yet registered.
I am no lawyer, but I would just let GitHub add the standard License file for GPL-3 then. Can be done entirely on the website üòÄ
So, I'm scraping a website using reqwest--which honestly is something I do a lot of, and I've always been very satisfied. This time, though, I've got something weird going on. Or maybe this has always been happening, but I just never noticed before? Say I get the content a la... ``` let content = client.get(foo).send()?.text()?; ``` ...I'm finding that all the ampersands and so forth have been replaced with HTML entities *even inside the links.* Is this something weird that reqwest is doing, or is it a quirk of the server, or...?
Would it be possible to in the future have `for` loops call `try_iter` instead, using something like [the `LoopState` enum](https://github.com/rust-lang/rust/blob/master/src/libcore/iter/mod.rs#L351-L356)?
Using serde on trait objects is often a pain in the ass due to the fact that you don't know what the underlying type often is. This allows the types to be tagged so when a traitor object is serialized it's able to find the correct serialization function dynamically as opposed to statically. 
Is there a way to tag with something more compact than the full human-readable type name in non-human-readable formats? What happens if I try to implement the same serializable trait for two different types that have the same name, defined in different modules?
futures 0.3 has `futures::compat` for interop with any 0.1 API, including tokio
I am confused, why is this a macro? Could it have relied on the Ord PartialOrd, and possibly an Order generic argument? &amp;#x200B; Also, does it help to avoid stop checking the first bytes when binary searching string, in the later iterations?
+1 for 'traitor object'. But seriously, this is a marvelously flexible serialization system.
I don't know what else to use. Maybe a 64 bit hash of the name? I would be willing to consider a PR for this. I briefly considered using the type's index in the list of types sorted by name, but the problem is if you add a struct `Aaaaa` and recompile your program then all the previously serialized data is hosed. Currently all other types will continue to deserialize successfully but when/if the ambiguous tag appears it will fail to deserialize.
Sorry.
Why specifically rewrite the DB interface in Rust? That seems to me something that C# is already very well-suited for. &gt; C# and Rust can potentially use different allocators depending on OS They are practically guaranteed to, given that C# uses a GC. So unless you're talking about the `Marshal.Alloc*` methods, that's a given. Your `string_rs_to_cs` function does nothing. I'm not sure what you expect it to do. Your `string_deallocate` function *might* do the right thing, if you originally allocated the data via a `Vec`. But in either case, the principle is wrong. You have to transcode between UTF-8 in Rust and UTF-16 in C# anyway. You should therefore hand a non-owned pointer to the target language, and have that language allocate its own native memory for any owned things. This way you don't have the problem of freeing the allocations.
`yield return` from C#. Maybe I'm a bit slow but I just figured out after 2 years of spare-time Rust that `fn foo(x: ...) -&gt; impl Iterator&lt;...&gt; { Some(x).into_iter()...` is almost as ergonomic as yield return.
You say it doesn't have those problems, but then as far as I can tell describe it having exactly those problems. If the registrations run in an unspecified order, and they can contain arbitrary code, including code that can behave differently depending on the order that they actually end up running in (because of a static mut, or inspecting the registry), that's the fiasco.
TIL about [inventory](https://github.com/dtolnay/inventory). This is going to be extremely handy.
&gt; On one end, languages like C/C++ are efficient, but require manual memory management; This is not true for C++. In fact, since the beginning of C++ it offered destructors which allows programmers to delegate resource management to objects. So, in C++ there is *also* an "ownership concept". But "ownership" alone doesn't prevent dangling references. The big difference between C++ and Rust is that the Rust compiler understands "borrowing" and is able to make sure that references never dangle. So, I would say, Rust extended C++'s ownership concept by adding borrow checking on top of it.
So a small utility to convert a csv into json. Pretty much take a csv with headers, make a json object for each row in an array with the headers as key, and the csv values as keys. CSV input foo,bar 1,2 3,4 JSON output [ { "foo": "1" "bar": "2" }, { "foo": "3" "bar": "4" } ] Something like this would be useful because you'd be able to query the JSON with a tool like `jq` or similar. Something I don't believe you'd be able to do easily otherwise. The CLI utility would use csv and serde_json crates respectively. The actual code wouldn't be too difficult, but making it into a polished CLI utility with configurable switches would be some work, but again, not too bad. I think it could be a good learning experience, and it might be useful. Or at least I've had a need for something like this before. 
Hey Kiddo, this is the wrong channel, you will probably need /r/playrust this is a subreddit for the rust programming language, if you want those valuable views, you need to post this in the correct subreddit. 
&gt; Maybe a 64 bit hash of the name? That seems like it might work okay, though you'd likely want to account for more than just the type name. &gt; Currently all other types will continue to deserialize successfully but when/if the ambiguous tag appears it will fail to deserialize. It's a bit weird for two distinct types to be considered ambiguous. Perhaps the tag should include the full path of the type, rather than just its name? Maybe even the assignments of any generic parameters.
There is at least one https://lokathor.github.io/learn-gfx-hal/
Also, GCs for C++ have existed since the beginning of time.
I am not taking a jab at the RLS team here, as they have a gargantuan task on their hands. I just think it‚Äôs important to take note of industry moves like these and let it inform the short to medium term roadmap.
I'm almost sure it's because you're declaring a function inside a function. The compiler is asking you to use a closure instead. Can't check because I'm on a phone now.
The difference is soundness. This initialization is type safe in Rust and unsound in C++. In both C++ and Rust, statics have a type. In Rust, regardless of what tricks you are doing with initialization, statics will hold a value of their correct type immediately before and immediately after any user-defined initialization routine. In C++, statics may initially hold unconstructed data i.e. not a legal value of the type i.e. breaking the type system, and this is observable by user-defined constructors of other statics.
&gt; So, I would say, Rust extended C++'s ownership concept by adding borrow checking on top of it. Technically Rust extends C++'s ownership rules by putting them under [affine types](https://en.wikipedia.org/wiki/Substructural_type_system#Affine_type_systems) and adding borrow checking.
Same here. I cannot imagine the hard work it has been to write such a crate.
Neat idea but I would say this is outside of the scope of my list. Thanks anyway! Maybe you could catch one of the many people who ask for intro project ideas in the rust IRC every day? Fun fact: I worked on jq for a while before I got into Rust. :)
Oh okay thanks man :)
Yes. I could see in their history the they had very regular events. It seems odd that they suddenly stopped. 
it seems they didn't only remove rust :-o [https://about.sourcegraph.com/blog/java-php-experimental\_language\_servers-temporarily-unavailable](https://about.sourcegraph.com/blog/java-php-experimental_language_servers-temporarily-unavailable)
I edited the question so new people reading this won't waste their time. Basically this is not possible to achieve with current APIs. That's why my repository for r2d2-tiberius is gone. To share a bit more detail about why this is not possible: r2d2 acts as a pool where it gives out (mvoes) a connection and later takes it back. Due to tiberius' use a future streaming API, this can't be done, because the connection is owned by a future object. The only way this could work is if the aspect of a connection pool was internal to tiberius, ie. it would manage more connections internally so then you can still continue to use its future streaming API and not care about the pool implementation.
If I am reading.for the exact opposite reason though, right? They are disabling them temporarily to switch onto their LSP implementations.
see https://docdro.id/duNtEXA for a pdf version
That crate only allows it on single field structs AFAICT, where as derefable allows you to have multi field structs.
I wonder what metrics are used to decide what the most loved language is. But for I selected 'used this year' and 'wants to use next year' for sure. 
The only thing sourcegraph can do well is to take someone else's technology LSP(Microsoft) and squat on a web-page without giving them more than a cursory credit. 
The main problem here is that compilers can only auto-vectorize raw C loops, and that's what auto-vectorizers are designed for. External iterators like Rust `Iterators`, C++ ranges `View` adaptors, etc. are not raw C loops, and LLVM does not have any passes that look for the patterns that these produce and transforms them into the canonical loop patterns that the optimizer works on.
What is the difference between annotating the type of a variable using suffix annotations or prefix annotations? To be clear : Let a : f32 = 3; // throws error Let a = 3f32; // works fine It seems to me those are just two different ways of forcing a literal to have a specific type. Why is there a difference? What is the difference? Which syntax should be used for which purpose / case? Thank you in advance. 
I have the following code with an odd error in it: [playground](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=ef56c88636eaee50859b1d5d938de3f1) trait IFoo { fn foo(&amp;self, arg: &amp;()); } struct Foo&lt;F&gt;(F); // Adding the FnMut constraint to the Foo struct makes the error go away: // struct Foo&lt;F: FnMut(&amp;mut ())&gt;(F); impl&lt;F: FnMut(&amp;())&gt; IFoo for Foo&lt;F&gt; { fn foo(&amp;self, arg: &amp;()) { (self.0)(arg) } } fn f(foo: &amp;IFoo, arg: &amp;()) { foo.foo(arg) } fn main() { f(&amp;Foo(|arg| {}), &amp;()); // ^^^^^^^^^^^^^^ one type is more general than the other } Here I define a wrapper Foo holding a closure callback, taking an argument by reference. I implement IFoo only when F is a closure (while Foo struct is strictly more general, if F is not a closure it's pretty useless). Yet this code complains about concrete vs bound lifetime parameter in the closure argument. When I also add the bound to the struct, the error goes away! Am I overlooking something or is this just a Rust compiler error?
Last years, it was basically "most wanted", as far as I understand.
When a literal does not have type suffix Rust will try to infer which type you want your literal to be. However it appears that only literals with a "." in it will either consider `f32` or `f64` and literals without a "." will only consider integral types (`i32`, etc) not floating point types: let a: f32 = 3.0; // No suffix, presence of "." is used to infer either floating point or integral type let b = 3f32; // Suffix is used, "." for floats is optional As for the choice, try to let inference do its thing. But do use "X.0" if you want a floating point type. If there is ambiguity whether to constrain the ambiguity (by adding a type parameter somewhere) or changing to an explicitly suffixed literal depends I guess, I don't have a preference either way.
&gt; Macros could probably provide a good workaround I would love to see postfix macros in Rust. You could implement optional and named arguments: window.settings!(height: 100, border: 2); But, with `Default` and `..` you can do something fairly close already: window.settings(Settings { width: 200, .. Settings::default() });
The answer here is: No. There are some subtleties involved here, for example even if your type is repr(C) it may have padding. I'm sure there's subtleties involving manipulating the padding bytes in any way. The struct you are transmuting to probably also has alignment requirements. Straight up doing `let mystruct = &amp;*(byte_buffer.as_ptr() as *const MyStruct);` is UB if the alignment requirements do not match. If you want to be safe, copy the bytes out of the buffer into your struct instead. If you really feel this is not performant (or if you want to transmute to a slice of your structure) then unsafe shenanigans seem like the right way to do it. Just keep all the gotchas in mind.
OK thank you, I dislike annotating types in suffix so I guess I will annotate with the regular syntax and make sure to use "." for floats, just like in any other language. 
So you are basically asking this subreddit to brigade the SO survey? Isn't that defeating the entire point of the survey, by introducing (even more) sampling bias? Rust isn't a sports team, and it doesn't need to 'win' to be good.
This article is posted in the one sub whose readers know everything it contains. This doesn't sound optimal.
The what? Who? How? let event: Box&lt;dyn WebEvent&gt; = serde_json::from_str(json)?; Oh! I get it. Before I could only deserialize to a type but now I can deserialize to a trait object.
found the person replying on a phone 
I have been trying to extract the parameters from a HTTP POST request made. I have used Gotham for the localhost. I did not find a method to handle a POST request. Is there any alternative? Also, is using async crate like Gotham better for HTTP requests, or should I look for other crates? Thank you in advance.
Are they really asking to disable adblock because the third party software they use is shitty?
Most loved:) https://www.reddit.com/r/rust/comments/842adc/rust_voted_most_loved_language_for_the_3rd_year/
I assume you have a question? What is it, exactly? :)
I partially agree on this point but this subreddit is for Rust and Rust was the most loved language for 3 years in a row in this survey and pretty sure about the 4th year :) https://www.reddit.com/r/rust/comments/842adc/rust_voted_most_loved_language_for_the_3rd_year/
Thanks; that suddenly made it a lot clearer. I feel like half the time borrowing is obvious, yet the other 50% I a still stumped.
You could! But that would restrict both the types of values you could store (they'd have to be at least PartialOrd) and the keys. The current design allows for keys that are derived from, but not equal to the value itself.
The blog post: https://stackoverflow.blog/2019/01/23/our-2019-developer-survey-is-open-to-coders-everywhere/
&gt; Why specifically rewrite the DB interface in Rust? That seems to me something that C# is already very well-suited for. Because why not? This is more meant as a learning exercise than something practical. Originally, there was a naive hope that it could be practical, but as I've delved into it, it's become more apparent that it's not exactly practical. Trying to avoid the `Marshall` stuff since its an additional copy/clone and Rust/C# only need to read the UTF8, not modify. Thanks for the info on the deallocate fn. It's inline with what IRC told me. So, returning an input `String` doesnt give up ownership of the memory to C#?
I am using uBlock Origin but this is not asking to disable it 
o\ Thanks, this is probably the one kind of syntax I didn't try.
does Tokio will support futures 0.3 later? when ?
Yeah, I struggled a bit with the name‚Äîapparently, naming things is hard. Who knew? I wanted something short, somewhat memorable, and that didn't clash with a widely used utility. `mn` as an abbreviation for mnemonic was the best I could come up with, but feel free to alias away 
It's literally written in the link you posted &gt;If you use security or ad-blocking plugins, you may see error messages &gt;Our third-party software provider, Qualtrics, does not work well with certain ad blockers and security software. To avoid error messages that prevent you from taking the survey, please try specifically unblocking Qualtrics in your plugin or pausing the plugin while you take the survey.
&gt; which is built on the [`ctor`](https://github.com/mmastrac/rust-ctor) crate to hook up initialization functions that insert into the registry Huh, that sounds like life-before-main, did someone really make a crate about that? So I take a look at `ctor`'s README: &gt; Idea inspired by this code in the Neon project. Probably my worst Rust contribution ever, how can I make this right?! I don't have a time machine to go back and stop myself from telling /u/dherman that the global init can be done on the Rust side :(
Yeah, I looked at it hoping for more new materia/actual results. Maybe the later articles in the series will have some more interesting details 
Totally agree.
You are right and not right at the same time. It depends on the people who answer. If they don't lie, then this is not defeating the point of the survey. On the other hand, it sounds like the call for false votes. But I believe it was not the intention.
Is there a reason `glib_object_subclass!();` isn‚Äôt an attribute macro that sits on top of the `impl` block? (I‚Äôm not sure of the attribute macro name) That seems cleaner imo.
Do you think Swift would work here since it‚Äôs ARC?
Yes, but OP is asking people to vote for rust, so they are asking to brigade. We may choose not to, but they are still asking.
Yeah the convenience of copying integers around can make it harder to remember what is and isn't allowed when it comes to more general types. Another thing you can try to do in these cases, is to put in explicit types on your variables. Then if something's not the type you expected, you're almost guaranteed to hear about it immediately from the compiler.
Not too familiar with different HTTP libraries but it seems that Gotham only handles paths and query parameters out-of-the-box. You need to parse the body yourself. Look into [Gotham's examples](https://github.com/gotham-rs/gotham/tree/master/examples/handlers) and [Serde](https://serde.rs/).
I'd *definitely* start with the first episodes: the teaching content is designed to build on itself and I'll often reference (and assume people have listened to!) earlier episodes ‚Äì you can probably get away with skipping the interview episodes (but they're really fun!).
This seem to be a very stupid question but when I try to run a stream with tokio-core, use tokio_core::reactor::{Core, Interval}; fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; { let mut core = Core::new().unwrap(); core.run(Interval::new( std::time::Duration::from_secs(10), &amp;core.handle() )?); Ok(()) } it says the trait future is not implemented: the trait `futures::Future` is not implemented for `tokio_core::reactor::Interval` In all examples I've seen it seemed to work. I'm using tokio-core 0.1.17
I can not recommend anyone use lambda_http right now in a production environment. It is not ready for production, [even by their own admission](https://github.com/awslabs/aws-lambda-rust-runtime/issues/67) and when I tried using it last week, the crate wouldn't even compile. aws_lambda_events is still a better wrapper to use.
It seems that default cpu target supported by Rust doesn't have any efficient vector instructions for widening operation. If you add eg. a `-C target-cpu=native` flag you can see that it produces very different assembly. I don't have time to look at it now, but I presume with this flag the compiler is able to vectorize also the first function.
As far as I know, reqwest doesn't know anything about HTML. Are you using any other libraries for example for parsing? Also compare the response with something like browse and `curl`. Are you sending `Accept` header with the request?
As I see from the docs, `Interval` is not a `Future`, but a `Stream` that produces unit values. So what do you expect your example to do? Maybe instead you wanted to do this? core.run( Interval::new(..).for_each(|_| { some_action(); }) );` This would run `some_action` repeatedly.
Emphasis on the MAY. It worked just fine for me with uBlock Origin.
You're trying to do static dispatch on a dynamic type. That won't work. Your `calculate` function needs to take a `dyn A`, and then dispatch at runtime.
This is not possible in Rust. The type of the item in a `Box&lt;dyn X&gt;` is erased. The box only holds a vtable and no type information. For something like this, you would have to use `Any` [see docs here](https://doc.rust-lang.org/std/any/trait.Any.html). You can downcast a `Box&lt;dyn Any&gt;` with `my_box.downcast_ref::&lt;SomeType&gt;()` or check the type with `my_box.is::&lt;MyType&gt;()`.
There are many errors in that code, at least when I looked at the playground. Maybe try something easier first?
I think the important thing here is that the OP should be pinning the git revision of the awslabs dependencies 
It's still pathetic... It's 2019, sites having trouble even with the shittiest ad blocker is really sad... Specially stack-overflow, and not a shitty generic bloc.
Oh thanks! I didn't know that `for_each` was doing this 
\`product\_cast\_result\` will overflow u32 quicker than \`product\_cast\_elem\` will overflow u64. If in release builds, neither will panic, but they may produce different results.
Well. Thats a bummer. Could you give hints which parts you're refering to? The `calculate` method?
I'd love to see the `.. Default::default()` become optional actually. When left out the compiler defaults to the Default trait to fill in the rest of the struct: window.settings(Settings { width: 200, .. }); That's starting to look pretty nice for named and optional arguments. Further syntactic sugar could be debated, make naming the struct optional if the method only has one argument and switch to using curly braces: window.settings { width: 200, .. }; Of course if method macros ever become a thing then all of this becomes moot as macros can fulfill this feature and much, much more.
So, let's say I'm interested in helping out with Rust analyzers/RLS implementations. Which one should I contribute? `rust-rls` or `rust-analyzer`?
I did not. The slides looked normal on the projector
Slides are here: [https://asquera.github.io/goto-async-rust-2018/rust-async.html](https://asquera.github.io/goto-async-rust-2018/rust-async.html#/)
This kinda helps misusing `Deref`/`DerefMut`, as those traits are supposed to be implemented only by pointer-like types such as `Box&lt;T&gt;`, `Rc&lt;T&gt;`, etc. The `MutableMap` example at the very least looks like code smell to me.
It begins here: fn main() { // Traits trait TraitA { fn something(val: u8) -&gt; u8 where Self: Sized; } Why do you put the trait definition into the main function?
For an example how that might look, take this [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e94ff5adc04fa49b96019f3963c89df5).
In C++ statics of primitive type initialized to a constant expression (e.g. 0) are also guaranteed to have a value. Also people use the static local variable pattern to make variables be lazily initialized. So yeah, that CAN happen, but when people complain about the fiasco I think they are still referring to code that changes behavior because the linker happened to put things in a different order which it sounds like is still going to happen. You're just guaranteed variables have a valid empty value if not really initialized yet.
I'm sorry! I should have been more clear. The `lambda-http` crate _is_ ready for production, but we wanted to gate its release on our redone error-handling. We expect that we'll release everything onto crates.io today or tomorrow. (I'm davidbarsky@ in the GitHub thread.)
Oh. That is because of lazyness. I wanted an minimal example up in the playground and did not structure the code. In the original code the traits are in their appropiate modules.
I was hoping it would elaborate on results. How it enabled the CSS engine to be safely parallelized in a way that would have been impractical before, a graph of reported memory safety related bugs before/after, etc.
Fascinating. Thanks for the reference!
programming language here...
I take it reading comprehension is not a requirement? ;-)
What's your raid boss‚ÄîBorrow Checker?
Semi off-topic, but the triple-backtick formatting does not work on reddit. Prefix each line with 4-spaces to have it marked as a code block. Reddit Enhancement Suite can help with its handy buttons.
/r/playrust
Mostly because that requires another crate for the procedural macro and I didn't get to that yet. I have some other things on my list for GLib that would also be nicer with procedural macros.
I like it!
Thankfully rusoto's function body structs mostly implement default, so it could be even worse.
Yes, but the Survey does not ask for love, but "I use it now" an "I do want to use it next year". As far as I understand, "most loved" is mostly coming out of "want to use it next year".
Don't get me wrong, this is cool and it's good that it exists, but the response to this thread so far makes it seem to me like we are collectively perfectly fine with the general concept of subclassing (or *inheritance* if you will) as long as we're only *approximating* it. We'll even jump through all kinds of hoops to get as close to it as we possibly can, and anything that results from this is great and apparently clearly better than what would be possible if it actually existed in the language. It all just seems a bit self-contradicting to me.
Should it really be on the website devs to take the time to make sure their page doesn't break with any ad-blocker? Isn't that responsibility on the ad-blockers themselves considering they are the ones controlling how they modify the page? (Obviously, this excludes cases where the website devs volunteer break their websites for ad-blockers).
Keep in mind that this is a binding for GObject, which does the exact same thing in C. The fact that it‚Äôs pre-existing means that it‚Äôs not really the Rust community responding positively to subclassing, but rather us responding positively to people RIIRing.
My understanding is that ‚Äúmost loved‚Äù means you‚Äôve picked *both* ‚ÄúI‚Äôm using it now‚Äù and ‚ÄúI want to keep using it‚Äù
I'm using this as an alias/shortcut for declaring a Result with my Error type: pub type Result&lt;T&gt; = result::Result&lt;T, Error&gt;; However, I can no longer use the normal Result type (with 2 arguments?). Anyway I can have both?
Unless you block all trackers, Qualtrics *should* work with your adblocker. I have to temporarily unblock the Qualtrics tracker in Ghostery when visiting a survey hosted by them, but I usually leave ABP on.
Unfortunately rust does not have this capability. You are returning an `dyn Trait`, and this is _decided at runtime_ which of the things it fulfills. "Static" methods with no `self` are always resolved at _compile time_, so there isn't a way to call them on these traits. You have it in your definition - `where Self: Sized` - this is needed _because_ this static method cannot be used on `dyn Trait`. You also cannot solve this by having `impl Trait` instead. `impl Trait` in return position is always _exactly one type_. You are using a match at runtime, and this can return one of two types. A method cannot return a different types depending on its runtime behavior, because to compile it the compiler needs to know the exact size of what it's returning. To solve this, I would recommend changing your methods to take `&amp;self`, and passing around the empty structs to supply to `self`. Then your `Box&lt;dyn Trait&gt;` can actually be used too, since the `self` argument can be used to distinguish which one is behind the box at runtime. I've modified your playground example to do this, and it should work: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=06188d6f6b064baa60a12dbb3e950005 The disadvantage, of course, is that you now need to pass around a bunch of `a, b` structs instead of just having type parameters. This isn't _horrible_ though - it will have 0 overhead when the types are 0-sized (like `StructA`), and will have _just enough_ overhead when they aren't (it will store a vtable pointer for `Box&lt;dyn Trait&gt;` and nothing else since what you're putting in it is 0-sized). 
What is the most idiomatic way to define this? Given a function `calculate&lt;T: Trait1, U: Trait2, V: Trait3&gt;(value: u32)` and different structs implementing these traits; how can I write a CLI tool with the syntax `rust-app --t1 A --t2 B --t3 C --value=42` ??
Who will decide that?:) Personally I vote for rust analyzer just because it's better conceptually and I like neat ideas:)
It is! But we want to achieve that _fairly_, if we are to achieve it at all. Brigading from this subreddit won't make the actual results different, it will just introduce a sampling bias from /r/rust. It also looks bad to other communities, since this post could be seen as "we need to introduce bias in order to win this", if that makes sense?
I've not gone into the depths of the type system, but from my understanding, the answer is indeed "the current type system cannot do this". It _might_, and that's a very large might, improve with [chalk](https://github.com/rust-lang-nursery/chalk) integration. But I don't know of any actual plans to make this kind of situation nicer. This doesn't mean much, but I haven't seen any RFCs to do anything about it nor anyone trying to make sealed traits a thing that can be relied upon. It's a pretty core design decision to have "add `impl Trait for Thing`" be a non-breaking change in as many places as possible. Sealed traits are a necessity for allowing different non-breaking changes to the trait, but I haven't seen them used in this way, and I'm ~75% sure the compiler doesn't even understand know what a sealed trait is from a type system perspective. It's just a trait with no visible access from the outside.
You can still use normal `Result` if you use its full type (`std::result::Result`,) or a shorter alias (if you've done `use std::result;`, you can just use `result::Result`.)
Wow. Thank you for your great help. Most of the structs I am using in this application are actually 0-sized (like `StructA`). It seems like I need to restructure my code a bit. ALthough I understand now why it is not working how I want it to; I am not sure what the most idiomatic way is in Rust to solve this. Is the syntax of `calculate&lt;A,B&gt;()` unhappily choosen? There must be a better way to do this... :( 
You can have an alias with two type parameters, with the error one defaulting to your error type: pub type Result&lt;T, E = Error&gt; = std::result::Result&lt;T, E&gt;; 
`fn`s can't capture variables (like you're trying to do with `cass_it`,) so you need a closure. So you'd write: ``` let handler = |req: &amp;mut Request| { // convert the response struct to JSON let out = serde_json::to_string(&amp;cass_it).unwrap(); let content_type = "application/json".parse::&lt;Mime&gt;().unwrap(); Ok(Response::with((content_type, status::Ok, out))) }; ```
 impl&lt;T: TraitA + ?Sized&gt; TraitA for &amp;'_ T { fn something(&amp;self, val: u8) -&gt; u8 { (**self).something(val) } } Why do we need to dereference self twice?
The reason for all this is to be able to a) Interact with existing GObject C libraries that simply use subclassing and mapping the API to something usable in Rust, b) Write libraries in Rust and be able to export a GObject C API to be consumed by other languages (this is the case of librsvg: it's a Rust rewrite of a C library and it must stay API/ABI compatible with the old C version) Personally I only ever make use of this in Rust at the API boundary between those two worlds and keep all other Rust code "clean" of this. That said, I think it's still impressive how much can be implemented with Rust that is part of the language in other languages.
This is a drop-in replacement for an existing GObject library, which uses subclassing, so there's literally no way that librsvg could avoid it. Greenfield projects can be judged by different standards. Worse, I don't think adding subclassing to Rust would help with the GObject bindings that much anyway. Using GObject with languages like C++ that have subclassing still requires bindings to be generated, because they don't use ABI-compatible representations for objects; it would be the same for Rust.
Because in this context, `self` is of type `&amp;&amp;T` as the implementation is for the type `&amp;T`, and the something function takes it by reference.
You're right! 2 functions is vectorized.
Are you sure traits are actually a solution here? Why not just have some freestanding functions, if you're just choosing one based on a command line argument? 
I believe that if we get specialization over associated types, this should be doable (make `Not`, `Xor`, etc. supertraits of `Bool`, and provide an impl generic over `Bool` that is never used). Anyway, if you find a way to make it work, please let me know, as it would make typenum far more ergonomic.
You can have each trait (eg. NotImpl) implemented for `True` and `False` separately, and then make all of those traits a super-trait of the `Bool` trait. Now you only need to specify the `Bool` trait, but can call methods on those other traits.
I like it too. Do you know if there's an RFC for this?
I was just joking, actually. A dumb little "mnemonic" joke. `mn` is fine.
True but I do appreciate the content as something I can pass on to my team which is still learning Rust.
Check out RFC [903](https://github.com/rust-lang/rfcs/pull/903). You check for read() returning zero bytes to detect when it's at EOF.
It's to call the method of `T` rather than `&amp;T` and avoid infinite recursion. These impls are providing an impl for `&amp;T` given an impl for `T`, so `Self` is `&amp;T` and `self` provided by `&amp;self` is `&amp;&amp;T`. To call the method of `T` rather than `&amp;T`, we use `**` to get rid of both `&amp;`.
How about RethinkDB?
Still waiting for the `Handler
The cleanest way would probably be at the top of your file, have: \`use std::result::Result as StdResult\` And then have something like: \`type Result&lt;T&gt; = StdResult&lt;T, MyError&gt;;\`
Dupe of https://www.reddit.com/r/rust/comments/aizz91/goto_2018_rust_async_programming_in_2018/
I have a rust workspace project, let's simplify it down to the following: &amp;#x200B; \- Executable \- Lib &amp;#x200B; Executable has a [main.rs](https://main.rs) file that tries to import a macro from Lib which is a library project. I've configured cargo.toml in both crates to use rust 2018, yet rust insists that I use the old extern crate/macro\_use mechanism to import the macro. Am I doing something wrong? Does the new mechanism not work between crates inside the same workspace?
There was a pre-RFC here: https://internals.rust-lang.org/t/pre-rfc-sealed-traits/3108 but it never made it to RFC status unfortunately
Huh, that's actually pretty neat! In fact while reading that, an idea occurred to me: if floating-point is limited in how well it can represent square roots, couldn't a similarly close approximation be used with floating-bar and computed in fewer iterations? This would give small numbers that are still usable *and* give a very close result to that of floating-point. Thank you for sharing, it might have given me a practical way to do square roots! :D
Well, that cinches it :) I think I remember that glibc only uses power-of-2, while jemalloc has both power-of-2 and the midpoints: 12, 24, 48, 96, 192. So, if a node is 24 bytes, it consumes exactly 24 bytes in jemalloc, but 32 bytes in glibc. That's a +33% overhead for glibc.
I'm new to Rust but I'd love to contribute. &amp;#x200B; I'll follow along w/ the Discord and Repo and try to contribute as I learn.
I don't know, but it seems to me a transformation to `for_each + LoopState` would be beneficial to avoid relying on the optimizer being smart... because it's often not :(
When she asked how many have programmed in rust before and estimated about 5% of the audience, i was like: wow i would have been a real rust expert at this conference.
Something is wonky in their compiler version reporting. From the page: rustc 1.32.0 (9fda7c223 2019-01-16) LLVM version 7.0.0 From my system: $ rustc -vV rustc 1.32.0 (9fda7c223 2019-01-16) binary: rustc commit-hash: 9fda7c2237db910e41d6a712e9a2139b352e558b commit-date: 2019-01-16 host: x86_64-unknown-linux-gnu release: 1.32.0 LLVM version: 8.0 It's the same exact commit but somehow the LLVM version is only 7?
Short/Mid/Long-term? The RLS is used right here and now, so any improvement is of immediate benefit. rust-analyser is not packaged with rustc, yet (if ever), so improvements may not benefit immediately, however there is a strong change that its architecture allows for a better experience down the road. Choices, choices.
Not sure what you mean by unhappily chosen? It was definitely a syntax choice but it doesn't seem like the worst one to me. It unambiguously brings new type variables into scope, and that's what it is meant to do. I think the most idiomatic way to solve this in rust depends on what your end goal is. Using tons of generics like this can work well, and can create super efficient code, but can also be overkill if your problem doesn't depend on compile-time data at least 90% of the time. Generics are fundamentally a compile-time concept, and so they're most useful when dealing with things you know at compile time. If you find yourself with branches like this in much of your codebase, it might be a good idea to use `enum`s instead and just have everything decided at runtime? --- I can't give any really good recommendation though until I know what you're trying to do with this. If 90% of your decisions for what zero-sized type to use are known at compile time then this could be great.
No. I am not. But the traits give me a nice separation of concerns. I might be able to do this with the calculate function taking other functions as arguments and returning the results. This would have the same advantage of separation and I would just need to rewrite calculate. But the traits in the full code example are implementing several functions incl. an inverse method. What would be your suggestion?
I guess that depends on if you consider annoying logical errors in a sound program to be worse than potential security issues from an unsound program. Sure the unsound program might crash and give you an obvious segfault to signal that you have Problems, but it also might not. Either way I'm not sure if ordering problems could truly be fixed on the language level since all this relies on the whims of the linker.
I would not call *that* a GC. It's a useful hack, but the functionality provided is far enough from what GCs in other languages provide, that it just fosters false hopes: 1. The Hans Boehm "gc" does not prevent use-after-free for stack allocated objects. It's a common error in C and C++, and Undefined Behavior. 2. The Hans Boehm "gc" does not prevent leaks of graphs when two objects with finalizers are part of the same cycle. 3. The Hans Boehm "gc" is conservative; anything that looks like a pointer is interpreted as a pointer; unless specific type information is provided. This may induce the "gc" to mistakenly retain memory (and not execute finalizers) long after it should have. Those are rather serious limitations, most specifically the first one. Furthermore, I am unclear on the thread-safety aspect of the collection. Typical GCs use either read or write barriers to achieve it, which a typical C++ program doesn't. There may be a trick there, using virtual memory.
Wat. C++ having destructors does not prevent programmers from having to perform ‚Äúmanual memory management‚Äù. A programmer writing destructors for all their classes to decide which bytes get released when and where is the very definition of manual memory management. It has gotten somewhat better with unique_ptr and move semantics. I can‚Äôt fathom how anyone could deny that C++ requires manual memory management? I am bewildered.
It's almost useless to post these numbers without any info on how noisy these numbers are. A sample without a distribution to give it context is useless, from an analysis point of view.
I listend to the first three episodes today. Now my brain is full and nothing will go in anymore. Thanks a lot, I already learned quite a lot. It will be a while until I have caught up, but I will try hard.
"I asked for two different things and I got two different things." Do you have a question? Are you surprised that two very different inputs to the compiler produce two very different results? 
This is very cool! I appreciate that you've shared the OS development blog you used as a reference, as I'm looking to do something similar myself.
Sorry, I never followed the named/optional arguments RFCs. They were too much effort to follow the huge amount of comments those threads get and named/optional arguments aren't that important to me. So really take my comment with a grain of salt, it's just some guy commenting 'why couldn't you just' from the side line. I'm sure these suggestions have come up and I don't know what the current state of discussion is. That said, defaulting to Default trait for optional `..` is something I occasionally wish I had. At some point I just thought this would neatly tie into the named/optional arguments debate but I never explored it any further.
I was not planning to. What do you see as the advantages of including typetag as a feature flag in Serde?
For a very long time, LUA has been the script language used in games because it was easily embeddable. I wonder if WASM could change this statu-quo.
That would be awesome! I think the main advantage of lua is that it's easy to write, but wasm can compile from a ton of different languages... &amp;#x200B; I'd be super interested in seeing a game that used wasm instead of lua/python!
True. That's what they provide. Maybe somewhere they have the distribution
&gt; Because why not? This is more meant as a learning exercise than something practical. That's fine. The context made me think you actually want to make this part of the larger project. &gt; So, returning an input String doesnt give up ownership of the memory to C#? The problem is that you can't represent the Rust `String` type in C#.
The problem is that the algorithm is slow, and has a lot of steps each iteration. Keeping in mind that this probably will only ever live as a software implementation, the simplest solution would be to compute the f64 sqrt of the rational, and then find the continued fraction representation of that float, stopping when the convergents are too big for the number of bits you have. You still have the problem that you essentially have to find the convergent each iteration, but at least you have finer grained control. The algorithm I linked to turns out to not provide the canonical continued fraction representation, and so it can skip more accurate convergents that still fit in the bits available.
Any baseline benchmarks compared to similar projects? Just curious to see some sort of perf 
Yeah, I realize now I didn't really think it through. Sure `Weak`s will keep an `Rc` with no strong references alive (but not its content) - but it doesn't point to anything anymore, so it can't participate in a cycle.
It's all right, I had to think pretty hard about it too. No question asked in earnest is a stupid one.
Has anyone done similar to this with AppSync?
Right, but if *all* `for` loops could reliably be transformed to `for_each` \+ `LoopState` by the compiler, then we would no longer depend on the optimizer being smart (as opposed to when that transformation could only be done sporadically).
&gt;but it seems to me a transformation to `for_each + LoopState` would be beneficial By the compiler, you mean? That would be ideal, if it could do that transformation for all possible `for` loops.
When it's ready, I imagine.
What does active development mean to you? Do the crates lack features that you require?
Yeah this is totally going to happen and it‚Äôll be glorious. Unity (and others) will probably support it at some point
Cool stuff. Webassembly will change the software industry as we know it. Reuse software between languages and platforms like never before .
The most popular crate (from what I can tell), influent, only appears to support up to influxdb 0.9.2 (current version is 1.7), and the repo hasn't been touched in months. I'm hoping to find something that is keeping up (or at least trying to) with versions of influx. 
Looks really similar to my [enum\_dispatch](https://crates.io/crates/enum_dispatch) library, which I made for performance reasons but is essentially the same mechanism and serializes as a side effect. Did you see that before, by chance? I do like your trick of putting the attribute on the \`impl Trait\` block, which removes some of the extra code. Curious though, are you still able to create \`typetag\`ged structs with normal constructors? The only way I could figure out how to do that was by creating \`From\` implementations to convert each struct that was marked with an attribute into the internal enum representation.
We have a PR going in now that will improve this. OpenGL doesn't have the ability to detect this so we are attempting to infer it from the renderer string. &amp;#x200B; [https://github.com/gfx-rs/gfx/pull/2595](https://github.com/gfx-rs/gfx/pull/2595) &amp;#x200B; if anyone is aware of gaps in our logic/assumptions there please let us know. &amp;#x200B;
Honest question. If one has a sealed trait, why wouldn't one just use `enum` in the first place?
Yay, I've been waiting for something like this!
one less import
awesome! if u need help learning, id message Zester on our discord, hes our rust wizard &amp;#x200B;
based
Has anyone found Sourcegraph indispensable? I've found the RLS to be so. I'll take a slow initialization time for a highly valuable, free tool.
I think you've just given me a way to move the runtime-loadable plugin system from the Python side of my rust-cpython project to the Rust side. :)
Why are we still using this cancer platform medium? It was never good for publishers and never good for readers.
I will. And probably on game development in general. I went through a Unity tutorial and the basic architecture clicked but man.. Talk about the potential for a spider's nest of logic. Thanks for the nod :)
Yes by the compiler :) There may be subtleties due to borrowing, however it seems that the loop-body could just become the body of a lambda and then `continue`/`break`/`return` are appropriately transformed. Labelled breaks may be an obstacle, though.
Basically what /u/matthieum said, but I'll add that I believe we'll slowly converge in terms of team effort, design and the actual tooling, so hopefully it does not matter as much in the long run! &amp;#x200B; Apart from QoL fixes, at this point the RLS would mostly benefit from the "end-to-end queries" work in the compiler itself, which is what rust-analyzer focuses on (albeit with a twist - IIRC they ship their own parser, own query infrastructure based on Salsa etc.).
This looks like exactly what I've been looking for for a couple of projects, if as I understand it I can specify at run time when loading the WASM what imports are available to it and thus how it can interact with the world. My next question is can I achieve the same thing with Rust compiled to wasm? Ie can I safely load isolated modules interacting over a specified API into wasm from wasm. My guess is no - at least not for now but I'm interested whether it is plausible that this could be achieved.
I have used influent 0.4 version with InfluxDB 1.7 for a hobby project. Has worked great. However, the current influent 0.5 made everything really difficult so I'm not going there.
By doing this within the type system, you can basically make compile-time choices. With an enum, the best you can do is maybe hope that the optimizer recognizes something is pre-determined. &amp;#x200B; Example use case: \`\`\`rust // If the \`UTF\` type parameter is True, we ignore utf-8 checking. struct StringWrapper&lt;UTF: Bool&gt; { inner: String, p: PhantomData&lt;UTF&gt;, } &amp;#x200B; impl StringWrapper&lt;True&gt; { pub fn new(data: Vec&lt;u8&gt;) -&gt; Self { StringWrapper { inner: String::from\_utf8\_unchecked(data), p: PhantomData, } } } &amp;#x200B; impl StringWrapper&lt;False&gt; { pub fn new(data: Vec&lt;u8&gt;) -&gt; Self { StringWrapper { inner: String::from\_utf8(data), p: PhantomData, } } } \`\`\` In this case, it might only be saving a bool field and a few if statements; but it can be used for much more complex changes to API without any overhead. Note that we didn't have to store any fields other than the \`inner\` field, so this should be optimized into the same amount of memory space as a normal String.
This seems like a pretty cool way to enable plugins in a rust application in a technically language agnostic way. 
I'm not entirely sure what you mean here, but you can just have publicly visible C symbols (via no_mangle and extern "C") for the exports and you can have extern "C" blocks for defining imports. Pretty similar to how you would interact with a C environment.
My expectations are constantly being shattered by the good work being done in collaboration between the GTK+ and Rust communities. My thanks goes out to all who are involved.
You aren't forced to use bundled LLVM...
&gt; My next question is can I achieve the same thing with Rust compiled to wasm? Ie can I safely load isolated modules interacting over a specified API into wasm from wasm Last time I checked WASM does not support JIT, which limits your ability to do such wasmception, at least with Wasmer. But I guess you could use WASM interpreter, [wasmi](https://github.com/paritytech/wasmi) looks like it might work?
I actually use wasm for loading custom user scripts into my project. And so far it seems to be a good choice. In fact I experimented with embedding a JavaScript runtime into the wasm files to support JavaScript files as well and that seems to work perfectly fine. So in theory wasm allows users to write their scripts in tons of different languages by just compiling their runtimes into the wasm as well.
Though the original link makes it sound like Rust in particular might've been causing them problems: &gt; We've since removed Rust support and don't have immediate plans to bring it back.
If you're doing this based off of command line functions, trait are not what you want. The best way to do this that everyone supports will be an `enum` with three branches for A, B, C. Deciding types must happen at compile time, and so generics aren't really ideal for this kind of runtime differentiation. You _can_ do it this way, but know that it'll make everything quite a bit harder compared to using an enum with inherent methods.
Slowly, slowly working my way through the rust book as I can find time (Please note I'm reading this top to bottom for the perspective of a C# user, so possibly this is addressed later, I'm missing lower level fundamentals, or I've missed, forgotten or misunderstood something previously.) Q1. In [4.2](https://doc.rust-lang.org/book/ch04-02-references-and-borrowing.html) under `Mutable References` it shows how you can't call `push_str` on a mutable reference. This makes sense but how does the rust system know whether a method call is mutable (not sure if I'm using the right term here) or not? For example if I toy with the code I can call `some_string.len()` with a immutable reference - obviously _I_ know _semantically_ that `len()` won't change the data but how does rust know? Does the compiler figure this out somehow (I guess the compiler could scan the implementation to see if it changes any state variables, but haven't fully thought through if this is reliable) or are methods marked or annotated in some way (this seems error prone and dangerous) or some method of both? Q2. In [4.3](https://doc.rust-lang.org/book/ch04-03-slices.html) there's a `first_word` function defined that takes in a string reference and returns a string slice. Later on, it shows that `let word = first_word(&amp;s);` is performing an immutable borrow of s. This is doing my head in a little bit. Again, semantically this makes sense, but how does rust (or the compiler) _know_ that the returned string slice, which is put into the `word` variable is tied to `s`? Couldn't it conceivably return a slice of something completely unrelated - in which case `s.clear()` would be valid. Is this just a restriction of the ownership construct or something mitigated for in lifelines? Q2b I also notice if you replace `let word = first_word(&amp;s)` with just `first_word(&amp;s)` then the code compiles. So this suggests to me that in that case, a mutable borrow is occurring and then immediatelly being de-scoped - is there a better term?). Is my thinking here correct? Q2c Following on from that, is there a way I can explicitly kill or clear the `word` variable so that `s.clear()` is valid? I tried something like this but without luck: fn main() { println!("Hello, world!"); let mut s = String::from("hello world"); let word = first_word(&amp;s); let word = 1; // was hoping this shadowing would cause the borrow to be removed, but does not appear to be the case s.clear(); } Q2d Lacking that, what is the appropriate practice here? or is that revealed later?
I have a suggestion: What if you exposed the combination of all the impls as the normal type name? So for example: ```rust use bl::*; mod bl { // Note: `priv` is a reserved keyword. pub trait BoolCore: private::Sealed {} pub trait NotImpl: BoolCore { type Result: Bool; } pub type Not&lt;B&gt; = &lt;B as NotImpl&gt;::Result; // This is my suggestion: pub trait Bool: BoolCore + NotImpl {} pub enum False {} pub enum True {} impl BoolCore for False {} impl BoolCore for True {} impl NotImpl for False { type Result = True; } impl NotImpl for True { type Result = False; } impl&lt;B: BoolCore + NotImpl&gt; Bool for B {} mod private { pub trait Sealed {} impl Sealed for super::False {} impl Sealed for super::True {} } } ``` 
Hmm, yes. But then you have a restricted/selected amount of functions on `Bool` that "work properly" (meaning: without needing to specify them explicitly). Consider the general case where my hypothetical crate does not only export a `Bool` kind but many more (`Nat`, `BinaryNatTree`, `Mode`, `Config`, ‚Ä¶). Said crate would provide utility-functions which could be grouped together as you describe, however this does not extend to library users who want to _use_ those exported kinds to define their own (more complex) functions. Think of a function like: type Foozle&lt;SourceTree, SecondaryTree, MaxDepth&gt; = &lt;SourceTree as FoozleImpl&lt;SecondaryTree, MaxDepth&gt;&gt;::Result; trait FoozleImpl&lt;SndT: BinaryNatTree, Depth: Nat&gt;: BinaryNatTree { type Result: BinaryNatTree; }
&gt; This makes sense but how does the rust system know whether a method call is mutable (not sure if I'm using the right term here) or not? It's explained in [5.3](https://doc.rust-lang.org/book/ch05-03-method-syntax.html), but basically methods declare whether or not they mutate their `self` parameter (e.g `fn add_1(&amp;mut self)` is a method that requires a mutable reference). There is no such things as a mutable or immutable call - the (required) mutability is a property of a method. So in a way it's a combination of both your guesses - you annotate the self parameter, but it's not error prone nor dangerous because the core feature of Rust - the ownership system - guarantees you can't modify memory you shouldn't be able to. 
Q2c: That should Just Work (tm) without shadowing or anything if you're using [Rust 2018](https://rust-lang-nursery.github.io/edition-guide/editions/transitioning-an-existing-project-to-a-new-edition.html). Rust 2018 uses a feature known as non-lexical lifetimes. In short it means that references only last as long as they need to be, so `word` will be dropped after it's last use (which is never, so `s.clear()` can be called immediately.
Good questions! I'm on mobile but will try to answer some of them real quick. &gt; Q1 A method like `len` is defined like this: `fn len(&amp;self) -&gt; usize`. That `&amp;self` means that the data is borrowed. If it was `&amp;mut self` it would be borrowed mutably. &gt; Q2 Not sure how it's actually defined but let me try to describe this in a more abstract way. Let's say you have a funktion/method that takes in one borrowed/reference parameter, and you want to return a reference, too. What are the possible valid options? I can think of two: The reference you return lives at most as long as the input reference, or you return a reference to something "static" (data that is part of your binary, like a literal string for example). &gt; Q2b Yes. There terminology is "drop". &gt; Q2c `word` is a read-only reference to a part of `s`. As long as you can access `word`, it's data is guaranteed to stay they same. Changing (clearing) `s` would violate that. &gt; Q2d What do you want to do? Do you want to "drop" `word`, because you no longer need it? The most explicit way of expressing that is to wrap the part of the code that uses `word` in a block (curly braces). This creates a new scope. At its end, `word` (and possibly other temporary bindings) are dropped, and after it you are allowed to mutate `s` again.
&gt;Again, semantically this makes sense, but how does rust (or the compiler) know that the returned string slice, which is put into the word variable is tied to s? It will be explained in [10.3](https://doc.rust-lang.org/book/ch10-03-lifetime-syntax.html). Basically in addition to function and type parameters (just like in C#) Rust also has _lifetime parameters_. Lifetime parameters are used to tell the compiler that some bits of data have the same _lifetime_, effectively meaning they are related. The `first_word` function is missing the lifetime parameters, because the compiler can oftentimes infer them. The function definition actually looks like this: ``` fn first_word&lt;'a&gt;(s: &amp;'a str) -&gt; &amp;'a str { let bytes = s.as_bytes(); for (i, &amp;item) in bytes.iter().enumerate() { if item == b' ' { return &amp;s[0..i]; } } &amp;s[..] } ``` ... which tells that the return value has at least the same lifetime as the argument `s`, meaning the slice returned by `first_word` is valid as long as `s` is valid. You can usually ignore the parameter return something else as long as it has a compatible lifetime - for example string literals, which have the always valid lifetime `'static` - but the compiler goes by the function signature and doesn't try to be too smart. 
 export PATH=$PATH:/usr/lib/llvm-7/bin Which LLVM will rust use?
I wasn't even talking about /that/ overhead. glibc stores the size right before the allocated chunk, which means a 32 bytes allocation is actually 40. In comparison, the overhead for a 32 bytes allocation on jemalloc is close to 1 bit.
Hi everyone, sorry in advance for the spam! üòù &amp;#x200B; I'm Syrus, CEO of Wasmer. Here at Wasmer, we are building a universal WebAssembly runtime aiming to enable the next generation of cloud computing. If you are as excited as we are about Rust and WebAssembly please reach me at [syrus@wasmer.io](mailto:syrus@wasmer.io) ...we are hiring!
It would be very strange if the compiler shootout was creating a strange combination of rust+LLVM version that's unlike the one shipped and used by most.
Encoding additional information in the type system enables checking at compile-time whether certain guarantees/invariants hold. The `Bool` kind I defined above is a lifted version of the well-known `bool` type for example. With lifted I mean lifted to the type-level; the logic moves from runtime-checks to compile-time checks. We are going to know more about our programming statically without even running the program itself. This already prevents a load of possible bugs. A plain `enum` provides variants which cannot live at the type-level, so it won't be of any use for our quest to eliminate bugs at comptime. `enum` variants can of course live at compile-time if used inside `const` contexts (e.g. `const fn`), however apart from a return value which can be used at runtime, a compile-time function/calculation is separate from runtime code. A (sealed) trait does live at the type-level though. Types share many similarities with mathematical sets. Types contain a defined amount of values (`Bool := { False, True }`). Let's move to the type-level. Let there be "kinds" which are the types of types or sets of types (set notation didn't change: `Bool := { False, True }`). Rust does not support custom kinds as of now (unlike Haskell), still I'd like to group the type-level values/terms (= types) `False` and `True` and call it `Bool`. Traits allow me to encode this grouping of types: Type `T` is a member/an element of kind `K` if it implements the trait `K`. The only issue: My "set" can be expanded later-on by third parties, so I'd like to seal it. The module-hack is all fine and dandy except it's not recognized by the type-checker. Unfortunately, that is exactly what matters: Being recognized by the type-checker and receiving all its benefits. Hence, my post. Take a look at [this StackOverflow answer](https://stackoverflow.com/questions/24481113/what-are-some-examples-of-type-level-programming#24481742) about type-level programming.
The elapsed times (secs) for those Rust programs vary a lot ‚Äî knucleotide.9.rust_dat 8.795 7.210 6.661 6.284 6.234 6.853 knucleotide.4.rust_dat 9.956 7.281 7.163 8.348 6.760 7.761 knucleotide.7.rust_dat 9.156 5.583 5.476 6.490 7.644 5.447 
If you're interested in working on stuff like this and are as excited about Rust and WebAssembly as we are at Wasmer, shoot me an email at [lachlan@wasmer.io](mailto:lachlan@wasmer.io)! We're located in San Francisco, but are open to remote work as well.
[README.md](https://salsa.debian.org/benchmarksgame-team/benchmarksgame) Where can I get the program measurements? ;-)
Thanks for your input! Here's [my reply](https://www.reddit.com/r/rust/comments/ajdmhu/can_i_prove_to_the_type_checker_that_a_trait_is/eevkr0y) to a similar suggestion.
&amp;#x200B;
I wrote one of these awhile go from the same tutorial as one of my first rust projects. https://github.com/alastairgould/little-computer-3-rs Although different design. Mine separates the decoding of the instruction, and the execution of the instruction a bit more. Didn't implement all the trap codes though.
Thats looks nice. Simple, natural extension to the syntax. `..` already means "i don't care about the rest", so it makes sense to use `Default`, and makes default-filled structs significantly more ergonomic. &gt; Further syntactic sugar could be debated, make naming the struct optional if the method only has one argument and switch to using curly braces: That, I don't like. Changing the way to call methods and inferring based on the function signature seems a bit much. &gt; Of course if method macros ever become a thing then all of this becomes moot as macros can fulfill this feature and much, much more. Macros are great and all but using macros to reinvent optional arguments in every crate(in macro_rules syntax?) doesn't sound fun at all.
Destructors enable RAII, which really does simplify memory (resource) management. For a manual experience, try to do the same thing in C. (And no cheating with extensions like `__attribute__(cleanup)`.)
I'm currently trying to figure how Tokio Error Handling works. I have something like the snippet below, my question is: If something enters the map\_err does the whole stream processing stop? something .for_each(|b| // ... ) .map_err(|e| println!("{}",e))
Is there no possible type or macro hackery to enforce ctor code can't invoke other ctor code without using unsafe?
It has nothing to do with PATH. It only matters what version of LLVM rust was configured to use during compile time.
Why do you think most of the people use the combination you use? 
Yeah I really like the idea of .. without value to mean `Default::default()`. Nothing I expect to be too controversial. About the syntactic sugar: Yep, very debatable. What I'm trying to achieve here is to avoid having to write out the type of the struct which represents the parameters, this is to avoid having to explicit import the argument struct of a method separately. The idea of making macros more powerful is to allow more experimentation so pro/cons arguments are less about what ifs and in a vacuum. By making them more accessible allows more and faster iteration on ideas without Rust itself having to commit. Of course just like the `?` operator I'd expect Rust eventually to commit to some scheme. Also it would require a macro per method you want to have keyword args for :P Unfortunately some of the Rust team members have rejected this approach of experimenting with language features in macros before committing (i'm not quite sure about the actual arguments) eg. in case of async await. I'm not sure how to interpret this.
I am still very new to rust, and have been looking through the source code. There is a lot I still need to learn, and I would really like to. I can't say that I'll be able to contribute much though, due to my lack of knowledge.
I'm a very recent newcomer to Rust, but I write so-called data science code for a living in R, C++, and Python. I understand analytics isn't the focus of the Rust community, but I was a bit surprised to find that there isn't a proper data frame structure that has been adopted. A standardized data frame built from the language's native data structures sets the foundation for an ecosystem of compatible data carpentry, statistics, and plotting libraries. I'm using the void as an opportunity to learn Rust by building something I'll actually use on a daily basis, but it's also probably worth the attention of folks who are already comfortable using the language. &amp;#x200B;
would love to have you aboard, if u need any help with the language message our core dev \*zester\* on our discord :)
You do realize that sourcegraph is an open source project?
Well, as long as `String` is a raw pointer to a valid UTF8 "byte array", I can reconstruct it into a C# type by returning the pointer and length. Right? If its a fat pointer or some such, I'd need a way of converting it to a plain old pointer+length,
If it's the optimizer that's making zeroing it unreliable, the simplest solution would probably be the same tactic used by benchmarking to ensure the benchmark doesn't get optimized away. Once a mechanism for inline assembly is stabilized, the old `test::black_box` solution would be the most reliable: /// A function that is opaque to the optimizer, to allow benchmarks to /// pretend to use outputs to assist in avoiding dead-code /// elimination. /// /// This function is a no-op, and does not even read from `dummy`. pub fn black_box&lt;T&gt;(dummy: T) -&gt; T { // we need to "use" the argument in some way LLVM can't // introspect. unsafe {asm!("" : : "r"(&amp;dummy))} dummy }
Considering this code: struct NPC { hp: Option&lt;i32&gt;, } fn main() { let mut npc = NPC { hp: Some(5), }; change_hp(&amp;mut npc); if let Some(hp) = npc.hp { println!("Finally hp is {}.", hp) } else { println!("NPC doesn't have HP!"); } } fn change_hp(npc: &amp;mut NPC) { if npc.hp.is_none() { return } else { let hp = npc.hp.as_mut().unwrap(); println!("Found {} hp,", hp); *hp = 65; println!("changed to {}.", hp); } } Is there a cleaner, better way of writing `change_hp()`'? I'd prefer not to have to match and use `Some(ref mut hp)` (which I heard that match ergonomics got rid of, but that only seems to be true if the Option is passed in as a reference directly; it doesn't seem to work in this case, where it's inside of a struct that was passed in as a reference).
I still don't understand how rust can compile so slow, even in check mode :(
Thanks, in that case: ~$ rustc -vV rustc 1.32.0 (9fda7c223 2019-01-16) binary: rustc commit-hash: 9fda7c2237db910e41d6a712e9a2139b352e558b commit-date: 2019-01-16 host: x86_64-unknown-linux-gnu release: 1.32.0 LLVM version: 8.0
Lua is also easy to read and easy to script. WASM is ought to be a very low level language. No doubt its usage will increase and we might see more WASM embedded in binaries, but at the code level, I doubt it. At best, Mmybe some Lua transcompiled to WASM?
You need to make the compiler unable to do that optimization. [This crate](https://crates.io/crates/clear_on_drop) has three methods: inline assembly that does nothing but forces the optimizer to be conservative around it, inline assembly in a C file to do the same thing but not require a nightly Rust compiler, and messing around with atomic instructions which might not actually work. The method that [OpenSSL uses](https://stackoverflow.com/questions/26433772/why-does-openssl-cleanse-look-so-complex-and-thread-unsafe) is to use C's `volatile` keyword to force the compiler to not optimize away the call to `memset`. Calling Rust's [`std::ptr::write_volatile`](https://doc.rust-lang.org/std/ptr/fn.write_volatile.html) function in a loop should do something similar by forcing it to not optimize away the memory writes. You also need to watch out for the possibility that the RAM holding the data you're trying to erase was copied to the hard drive because of swapping. Operating systems provide a way to [specifically forbid swapping](https://security.stackexchange.com/a/29354) for a particular piece of memory.
Because it uses typed\_arena, allocations should be large. I'm not super familiar with the typed\_arena source code, but I think it should be allocating 1 kilobyte chunks.
Good catch, I lost some zero because of the comma. Corrected now!
Correction: jemalloc used to be the default on Windows I know because I had a performance regression when they changed it, and it was super a point where custom allocators were not a thing
Do we have usage statistics of RLS vs. intellij-rust vs. nothing?
I doubt you could do that on the functions directly. Though it sounds like the only way to share state with these functions is via `static mut` (or `static UnsafeCell&lt;T&gt;` or similar) and `static mut`s are already unsafe to access by default so it's not like the potential problems that could arise are invisible.
I see that you can call an external function belonging to the host code. This function is okay for return value strings. Is there a way to send strings to the wasm module?
Yeah, if I set the blue components of the background and text colors to 0, it's a very close match. Not that you probably really cared, but there it is. :D Thanks for posting the slides.
You can, but it's not particularly simple. &amp;#x200B; From within the wasm module: 1. Allocate space for the string. 2. Tell the host where that memory is. From the host: 1. Write your string into the memory that the wasm module allocated for your string.
thank you! reassuring to know it is covered later and I'm not misunderstanding
On the Haskell side of things, try using `{-# LANGUAGE LambdaCase #-}`; it's a really enjoyable extension that allows you to reduce repetition by writing: ```haskell rigged :: Semiring s =&gt; Reg -&gt; Regw Char s rigged = \case -- No need to introduce a temporary and we don't have to repeat `rigged` so many times... Eps -&gt; Epsw Sym c -&gt; sym c Alt p q -&gt; Altw (rigged p) (rigged q) Seq p q -&gt; Seqw (rigged p) (rigged q) Rep r -&gt; Repw (rigged r) ```
If performance isn't an issue, the easiest way would probably be to add in your zeroing function the line `assert!(v.iter().all(|x| is_zero(x));` for a given definition of `is_zero`.
*zesterer ;)
For those looking for some more information: We're developing Veloren using modern techniques such as ECS, a lockless architecture, data-driven design principles and worker/manager multithreading. It's multiplayer, with a client/server architecture designed to handle high-capacity workloads with ease. The game takes influence from Cube World, Dwarf Fortress, BotW, and others.
&gt; Unfortunately some of the Rust team members have rejected this approach of experimenting with language features in macros before committing (i'm not quite sure about the actual arguments) eg. in case of async await. I'm not sure how to interpret this. Interpret it as the stable channel not being for experimenting and wanting to reduce the technical debt of the known-to-be-poor solution of `await!(future)` in the language specification.
I'm working on something close to this. :)
That depends on how smart the optimizer is. If after it churns through all of the abstraction layers it sees something like this: x = 0; assert!(x == 0); then it will be happy to optimize that into `assert!(true);`.
Webassembly is not meant to be directly written by humans. It is meant to be a compile target for higher level languages like C or Javascript.
Thanks for your answers! &gt; `word` is a read-only reference to a part of s. As long as you can access word, it's data is guaranteed to stay they same. Changing (clearing) s would violate that. Yep, I understand that. I was hoping that the variable shadowing of word (me putting `let word = 1` would effectively cause the previous variable to be 'dropped', as I could not longer use `word` to as a read-only reference to `s` after shadowing (I don't think?). I guess I was trying to achieve the lexical scope that is available in Rust 2018 (based on what /u/simspelaaja said in another reply), so all good!
Thank you, makes sense!
You can do this slightly silly thing: ``` for hp in npc.hp.as_mut() { println!("Found {} hp,", hp); *hp = 65; println!("changed to {}.", hp); } ``` Why don't you like the `ref mut hp` way?
It seems like this has some problems compiling on Windows. Cranelift has problems with mingw's python and then wasmer itself references a module that doesn't exist.
Cool! That blog is very concise and clear. OS development is a very enjoyable and fruitful learning process. Good luck!
Thanks. Trying to read about Rust 2018 but is there any reason not to use it other than breaking-changes-legacy thing? Would I be right in thinking it's a stable release not some wacky or experimental/alpha branch?
I fixed the module problem on my local version of \`wasmer-runtime-core\`, but the memory module that was missing previously throws a bunch of errors and cannot compile.
Yeah I just ran into that too. Have you fixed any of them or should I attempt to do it myself?
That works, but I'd be sad if there was no better way... :c not to mention because the `ref` way seems like the cleanest! &gt;Why don't you like the `ref mut hp` way? Incurred trauma. And not just mine; it seems there's been a consensus that `ref` should be avoided, hence match ergonomics and the Rust 2018 compiler [no longer suggesting using it](https://github.com/rust-lang/rust/issues/52423). From [here](https://github.com/rust-lang/rfcs/blob/master/text/2005-match-ergonomics.md): &gt;The ref keyword is a pain for Rust beginners, and a bit of a wart for everyone else. It violates the rule of patterns matching declarations, it is not found anywhere outside of patterns, and it is often confused with &amp;. (See for example, https://github.com/rust-lang/rust-by-example/issues/390).
Looks like I should've just tried the easy way first: ``` if let Some(hp) = npc.hp.as_mut() { *hp = 65; } ``` works just fine.
The \`&amp;str\` to \`String\` errors were simple enough. There's a reference to the crate \`errno\` which is a unix compilation dependency. I'm not sure if the single \`libc\` references is intended to be there, or if it should be using something in \`winapi\`. 6 items in the \`use winapi::um::memoryapi::{ .. }\` statement don't exist in that module. I'd say go for it for trying to fix it, but I myself am not confident enough in what this module is doing to take a stab at it myself :)
&gt; WASM does not support JIT, Neither did JavaScript, until everyone started doing it. JIT is all a matter of the interpreter/compiler/etc‚Ä¶
Ha! Yay! The brevity of `ref mut` *is* hard to beat, but `as_mut()` is more... idiomatic? Less unicorny? I don't know. Thanks. :)
Perfect! I was just looking for how exactly would I go about using WebAssembly for plugins in my experimental (Vim/Kakoune-like) text editor: https://github.com/dpc/breeze
Good point.
advice friend: "I might hack on it continously in the future, or I might loose the motivation" - literally nobody is going to use this, ever, given this endorsement from the author. i can see it can display and edit text already - that's cool - and i see a statement of philosophy. but why this over vim/emacs/nano/ed/xi/etc/etc/etc/etc - there's no reason. cool that you're learning - but not worth our time just yet. worth our support, for sure - editing/WASM is an endgame for Rust i believe - but you're a ways off. if you're passionate and you really have the time to bring it about, i suggest rolling in to an OS project - namely Xi, Google's exact copy of your project (tho i think it predates) - modal editing in idiomatic Rust. you'd be welcomed.
For what it's worth, all of the latest revisions are out: https://github.com/awslabs/aws-lambda-rust-runtime/releases/tag/v0.2.0. What sort of compilation errors were you running into? Could you open an issue for us to track?
The libc on your platform may provide functions for this purpose that you could call via C FFI like [explicit_bzero](https://man.openbsd.org/bzero.3) or [SecureZeroMemory](https://msdn.microsoft.com/en-us/library/windows/desktop/aa366877(v=vs.85).aspx).
Maybe. It‚Äôs worth noting that many people saw the JVM in the same way: Java, JRuby, Scala, Kotlin, Clojure, etc. Right now WASM looks like it‚Äôs in a better position because it‚Äôs more open, but I think it‚Äôs worth pondering why the JVM isn‚Äôt already this.
Yes but to embed usefully you would probably use a scripting language. So you would have to compile the entire runtime. At that point why use wasm? It's awesome for sandboxing but it's basically a bettwr jvm.
First of all, this crate is awesome. Thanks to you I am decoding JWT after a couple of weeks trying to sort this stuff out. One question though -- right now my JWKS contains only a single key and I'm hardcoding the `kid` to extract the `JWK` and then validate it. What is the reason to make the `keys` field private in the `JWKS` struct? I could just access the key by index since I know it's always the only one. Alternatively, how do you get the `kid` from the token? The token is encoded, you need the kid to decode it, but you can only get the kid from the decoded token. Catch-22?
I spent a few hours diagnosing this yesterday. First, I'll answer your questions... 1. No, I'm not using other libraries for parsing HTML. 2. Chrome does not get spurious HTML entities. Curl does. 3. I am indeed sending an Accept header. I tinkered with hitting a lot of other websites using the same basic strategy I was using for this one and exactly zero of them send me HTML entities inside href properties. I finally concluded that their server is *actually fucked.* :|
Suppose I have a struct with a lifetime, `Bar&lt;'a&gt;`, and a `Foo&lt;'a&gt;` which can contain some of these, like this: struct Bar&lt;'a&gt;(&amp;'a str); struct Foo&lt;'a&gt;(Vec&lt;Bar&lt;'a&gt;&gt;); impl&lt;'a&gt; Foo&lt;'a&gt; { fn add(&amp;mut self, b: Bar&lt;'a&gt;) { self.0.push(b) } } I can now use `Foo::add` both with a `Bar&lt;'a&gt;` and a `Bar&lt;'static&gt;`. Now, I want it to be possible to add a `Bar&lt;'static&gt;` to a `Foo&lt;'a&gt;` without having a reference to `Foo`. My idea to solution is to have a `Foo::install` method that installs a pointer to `Foo&lt;'a&gt;` into thread-local storage, so that my instance of `Foo&lt;'a&gt;` becomes the thread default (and then use `RefCell` and/or `Rc`/`Weak` to manage memory). But I can't install a `Foo&lt;'a&gt;` into a thread-local variable - because it has a lifetime - so I have to install something else, but I can't figure out what. My current attempt involves a `transmute` from `Foo&lt;'a&gt;` to `Foo&lt;'static&gt;`, so my question is: 1) can this be written without unsafe code? and if not, 2) is this in fact unsound in some way I haven't considered? (Only allowing installing a `Foo` if it is `Foo&lt;'static&gt;` is not an option because then I can't mix, i e, I lose the possibility to add both `Bar&lt;'a&gt;` and `Bar&lt;'static&gt;` to the same `Foo`.)
How about: fn change_hp(npc: &amp;mut NPC) { npc.hp.as_mut().map(|hp| { println!("Found {} hp,", hp); *hp = 65; println!("changed to {}.", hp); }); }
It was made the default version a month or 2 ago. If your Rust toolchain is up-to-date, our should default to Rust 2018 for new projects.
You also need to make sure that your vector isn't moved in your code which is (iirc) expressed as a memcpy/move in rust. I think there has been talks about making memory immovable, but I don't know how far things have progressed.
I think the openess is key here. Wasm is also backed by many bug companies. There was a totally different climate when the jvm entered the world. 
For anyone interested, a fork has been created here: [https://github.com/Darksonn/criterion-plot](https://github.com/Darksonn/criterion-plot)
&gt; For a very long time, LUA has been the script language used in games because it was easily embeddable. The Lua runtime is around 30k lines of code. What‚Äôs the smallest WASM runtime out there including a language frontend?
I don't really care about the LoC of a runtime as much as the binary size and overhead. 
Hey! Thanks for your reply! Would you then suggest throwing two kind of errors in the MRTReader impl: Unexpected EOF and Expected EOF? Because there seems to be no other way then to actually try to read something from the stream (which you also have to put back somehow again)?
If you feel the need to define destructors for all your C++ classes you're doing it wrong! In Rust you don't manually implement the Drop trait for almost all your types either. Same thing. Avoiding resource leaks is as easy in C++ as it is in Rust for the same reason: Destructors / Drop. What Rust adds on top of that is consumable objects (affine types, which avoids the C++ error class use-after-move without forcing types to have an otherwise unnecessary"zero" state) and the borrow rules/checking which eliminates dangling references and data races. Avoiding leaks in C++ is not the problem and memory management can be as automatic as in Rust.
I don't have an answer, but [this talk](https://media.ccc.de/v/35c3-9788-memsad) might be interesting for you ;-)
I would add that (at least in games) the advantage of using Lua is that you get a command console for almost free. 
Well there is a very big difference, nobody planned to compile C to the JVM
Since "Verloren" means "Lost" in Dutch, could it be that you or some of you are located in the Netherlands? I might be taking a look to see what I can do as well!
we probably do, as we have lots of German members, uk, polish, mostly eu XD
more than 2 secs diff sometimes (not first run). Why is it so big? #7: 5 and 6 run.
&gt; Well, as long as `String` is a raw pointer to a valid UTF8 "byte array" It isn't though. It's a structure with unspecified layout that contains such a pointer somewhere inside. If you want to take it apart, there's an example in the documentation of the "putting it together" method `from_raw_parts`: https://doc.rust-lang.org/std/string/struct.String.html#method.from_raw_parts
It's the same word in German.
Your OS zeroes pages before giving it to another process so this is about securing something within your process.
Not until they put a GC in it.
This! All types in Rust are movable without running code, which is a _great_ simplification over C++ that helps make good performance easier to attain in a bunch of places. But as a result, you can't do something like securely zero in the move constructor. You might be able to use something that only works on [`Pin`ed](https://doc.rust-lang.org/nightly/std/pin/struct.Pin.html) data, but I don't know how much that's been explored yet.
Would it be possible to put wat support behind a feature gate?
Why do you think the rust versions provided by rust-lang.org are not the most used? Maybe some use distro packages instead, but here we're trying to benchmark the latest version of rust. Using an old LLVM makes no sense.
The JVM isn't really all that flexible of a runtime. The JIT is tuned for Java, the GC is tuned for Java, the instruction set was designed for implementing Java. All the other languages/recompilers had to be built around these limitations, and additionally had to be designed for Java interop to have any chance at success. Arguably only Scala, Kotlin and Clojure have had any real success, in my opinion mainly because they sought to improve on Java rather than try to crowbar an existing language into the JVM. WASM, as far as I can tell, was designed as a virtual machine and flexible compilation target first and foremost, and it's building on old experiments like NaCl and asm.js, both of which had to compile to Javascript and so are rather similar to the situation with the JVM. It also has an LLVM backend which means almost any language with an LLVM frontend can already compile to WASM. The alternative languages to Java all had to write their own compilers from scratch (though I'm sure they reused some stuff from OpenJDK).
Same for me. I read 1mb less and I'm like "so ...?", but it's a whole different world. One comment which popped up again and again was how big hello world is with around 1.5mb. And about 800kb (or so, I don't remember the exact numbers) were jemalloc. For me that's a trivial thing to nitpick about, but .. different languages, different standards.
Yes, and you might have additional information that is stored about the type you're pointing to. Single field `Deref` types are useful if you want to only add additional methods that don't require any additional state.
Can anyone else confirm this?
This is awesome! One step closer to my dream of XXI-century Emacs in Rust, with WASM runtime, sane scripting language and real GUI :-) Thanks!
Because you want to benchmark rust and not llvm? It's like saying that testing it on older hardware makes no sense too. Most Linux distros and OSes package. Not everyone is using rustup.
Because it is still popular. You can use [makemediaumreadable](https://makemediumreadable.com/), which helps immensely.
Thinking some more, using HTML entities inside attributes is [completely valid syntax](https://www.w3.org/TR/html5/syntax.html#elements-attributes) and widespread practice. You should use a parser to handle them properly.
I am not an expert but would be surprised if it didn't do it.
Hey! Thanks for the feedback :) There is a `token_kid`function explicitly for the purpose of retrieving the `kid` before any other fields (see usage example [in the docs](https://docs.rs/alcoholic_jwt/0.1.0/alcoholic_jwt/)). Can you file an issue on GitHub? If it turns out no functionality is missing, it's still a documentation issue. Going to write a more detailed response later, but am currently on a phone keyboard üôÇ
You shouldn‚Äòt use something because it‚Äòs popular, but rather because it is exactly what you need. It‚Äòs so sad nowadays we write browser plugins to make websites useable. The web wasn‚Äòt mean for this...
Fair enough. If you put it like that, there isn't much difference whether the language defines it to mimic a macro or makes it explicitly part of the syntax in terms of stability.
Check the man page of brk sbrk and mmap.
[zeroize](https://www.crates.io/crates/zeroize) is a newer crate that uses `ptr::write_volatile` and has a [detailed explanation](https://docs.rs/zeroize/0.5.2/zeroize/) of how it zeroes memory along with some obstacles. I believe the author is currently looking into using the `Pin` trait to avoid moves.
If your OS doesn't do this, then it doesn't isolate processes properly. If your OS doesn't isolate processes properly, you have bigger problems (any process might be able to read all your memory, before you actually zero the vector).
AFAICT, - `Pin&lt;Vec&lt;T&gt;&gt;` and `Vec&lt;Pin&lt;T&gt;&gt;` aren't what you want, because Pin's type argument must implement Deref and is treated like a reference to the actual type you want to pin - `Pin&lt;&amp;mut Vec&lt;T&gt;&gt;` pins the Vec itself (e.g. the memory that stores its length and pointer to its storage), but will let the actual storage be reallocated - `Vec&lt;Pin&lt;&amp;T&gt;&gt;` will properly pin it, but doesn't have ownership and thus ~~the actual owner of the values may be able to move it~~ since you have a reference to the values, I don't think they can be moved at all, but they can't be moved *at all* and the borrow checker will probably have you jump through a lot of hoops to prove they won't be moved - `Vec&lt;Pin&lt;Box&lt;T&gt;&gt;&gt;` pins the Boxes, not their storage, but since Box never moves its stored value (?) that might work I'm not aware of a type like Vec that pins its storage. Since the contained values can't be moved, I suspect the PinVec will have a maximum capacity, which sounds like [arrayvec](https://crates.io/crates/arrayvec). It looks like you might be able to dance around ArrayVec like this // let mut a: ArrayVec&lt;[T; N]&gt; = ... let len = a.len(); a.clear(); for i in 0..len { a.push(/* zero value */); } std::mem::drop(a); But that's still a bit clumsy.
[Stream::for\_each](https://docs.rs/tokio/0.1.14/tokio/prelude/trait.Stream.html#method.for_each): &gt;The returned value is a `Future` where the `Item` type is `()` and errors are otherwise threaded through. Any error on the stream or in the closure will cause iteration to be halted immediately and the future will resolve to that error. &gt; &gt;To process each item in the stream and produce another stream instead of a single future, use `and_then` instead. So yes, `for_each` will stop the stream processing as soon as there is an error. My understanding is that you can use `something.and_then(|b| ...).map_err(|e| ...)` to process the whole stream and handle the `Ok` in the first closure and the `Err` in the second one. Or you could also use `something.then(|r| ...)` to handle the `Result` directly and handle both outcomes in the same closure (by using a `match`, for example).
&gt; Because you want to benchmark rust and not llvm? It's like saying that testing it on older hardware makes no sense too. Wanting to benchmark "rust" and the latest one at that and then compiling it in a non-standard way is strange. They're probably just using 1.32 from debian experimental though.
## How to correctly handle EOF? Let's say as an example I have the following code: ``` fn my_complex_parser_function(readable: &amp;mut Read) -&gt; Result&lt;MyStruct, Err&gt; { // Multiple read calls here for each field // of the struct that I want to parse. // Returns an EOF when it cannot read more bytes. } fn main() { // Construct something that implements the Read trait..., for example a File. let readable: File = ... // How to distinguish between an unexpected EOF and a termination of the loop because there is no more data to read? while ??? { let result = my_complex_parser_function(readable); // Do something with result here. } } ``` I hope you can help me find the most idiomatic way of reading a Read till the end of the stream without having to read everything to a buffer (as some Read streams might be very large).
&gt; Semi off-topic, but the triple-backtick formatting does not work on reddit. It does work with the new reddit, but if you use it those still using "old" reddit won't see the code properly formatted.
I wonder if you could compile Lua to wasm, then just use wasm for everything.
Perhaps something like this? [ttps://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=44ca41ea965920e110975d9628438c3e](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=44ca41ea965920e110975d9628438c3e) The check for 0 bytes read is necessary, see [https://doc.rust-lang.org/std/io/trait.Read.html#tymethod.read](https://doc.rust-lang.org/std/io/trait.Read.html#tymethod.read) for details.
Thanks for your answer! The only downside is that you already read in the loop, while I'd rather only read in the complex_parser_function. If possible I'd rather pass a Read object into some kind of parser (which might be a separate crate) and let the parser handle the rest. It's because I do not know upfront how much bytes will be read by the complex_parser function, that I cannot read small parts in memory first either.
Jamey Sharp ported that paper to Rust [here](https://github.com/jameysharp/weighted-regexp-rs).
Hmm, so the end-of-file can either be unexpected and be considered a failure, or it can mean there's nothing more to do... I'd suggest changing the function signature to return an `Result&lt;Option&lt;MyStruct&gt;&gt;`. That way you can let the caller know that there's nothing more to read, without signalling that an error occurred. Here's an example without error handling or any reading, just to show what I mean with the function signature: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=b43905024f03d602408bff4151d08457](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=b43905024f03d602408bff4151d08457) Beyond that, an error enum would help distinguish between error types so the caller can explicitly match on the error to see if `UnexpectedEnum` is the source. The `while let` trick does discard the error, so may want to turn it into a `loop` that matches on the result and breaks on errors and empty if you wish to handle it. 
There‚Äôs remacs. Elisp is quite a sane language imho
Great! This was what I was looking for! Thanks!
Glad to hear it helped :)
Very simple question: What has happened to the Rust docs? I am unable to connect to [https://doc.rust-lang.org/](https://doc.rust-lang.org/)
Library crates can have generic implementations of those traits, ie. `impl&lt;T: Bool&gt; BoolExt for T { ... }` Those implementations will have to build off your base implementations though (ie. they won't be able to tell whether T is true or false, but they can use your existing boolean traits as building blocks, which should be enough to express pretty much anything)
Congrats!
This isn't the error I was receiving before, but this is what it is right now... Compiling lambda_runtime_core v0.1.0 (https://github.com/awslabs/aws-lambda-rust-runtime#66c0ba00) Compiling lambda_runtime_errors_derive v0.1.0 (https://github.com/awslabs/aws-lambda-rust-runtime#66c0ba00) Checking lambda_runtime_errors v0.1.0 (https://github.com/awslabs/aws-lambda-rust-runtime#66c0ba00) error[E0599]: no method named `name` found for type `&amp;(dyn failure::Fail + 'static)` in the current scope --&gt; /home/****/.cargo/git/checkouts/aws-lambda-rust-runtime-7c865cce90132439/66c0ba0/lambda-runtime-errors/src/lib.rs:40:32 | 40 | self.find_root_cause().name().unwrap_or_else(|| "FailureError") | ^^^^ error: aborting due to previous error And here is the git status for the crate... **** ~/.c/g/c/a/66c0ba0&gt; cd ~/.cargo/git/checkouts/aws-lambda-rust-runtime-7c865cce90132439/66c0ba0/ **** ~/.c/g/c/a/66c0ba0&gt; git status HEAD detached at v0.2.0
Neovim already has the |-cursor and I think vim and emacs can be configured to. I would consider that a pretty standard feature at this point.
&gt; I don't really care about the LoC of a runtime as much as the binary size and overhead. Sizes with GCC 8.2.1 / x86_64: #### sizes for -O3 | lib | unstripped | stripped | src/liblua.so.5.3.5 | 293688 | 265704 | src/liblua.a | 502028 | 258580 #### sizes for -Os | lib | unstripped | stripped | src/liblua.so.5.3.5 | 219752 | 187896 | src/liblua.a | 375820 | 177116 The values are for a regular build with the compat symbols for older Lua versions. For size-efficiency you probably want to compare the shared version at ``-Os``. It links against nothing except the C library (1960064 B vs. 1709504 B stripped for glibc 2.27 on Fedora). With LTO, a bare ``liblua.a`` is 2223188 B at ``-O3`` and 2096532 B at ``-Os``, a minimal statically linked self-contained executable results in a 256496 B and 182408 B binary, respectively. LTO appears to be the most size-efficient method. At ``-Os`` it even beats lhf‚Äôs amalgamated version (http://lua-users.org/lists/lua-l/2015-01/msg00334.html) which produces a 183760 B binary. Though this may be still be an option depending on your platform‚Äôs compiler. For a meaningful comparison with WASM we‚Äôll need the size of a size-optimized shared object for the dynamic linking case, and that of a linked binary for the static linking case. Feature wise, the result should include a frontend for a scripting language and its standard library so it can run programs an average user of the language would write. As far as overhead is concerned, that will depend too much on the workload you envision to address it here.
Works fine for me.
&gt;The JVM isn't really all that flexible of a runtime. There is also CIL/CLR. I guess it started as the JVM for C#, but pretty soon they wanted to support other languages with it. The mono implementation can be embedded on the common platforms.
If you read `0` bytes, then that's generally regarded as EOF. If you hit EOF and you still need additional bytes for a valid result (e.g., only reading 3 bytes but the caller asked to decode a 4-byte little endian integer), then yes, you can treat that as an unexpected EOF. [`Read::read_exact`](https://doc.rust-lang.org/std/io/trait.Read.html#method.read_exact) is useful for this. Otherwise, if you hit EOF and it's expected or otherwise valid to be done, then you wouldn't return an error. Your operation completed successfully.
Can you give more context? `Result&lt;()&gt;` isn't valid, if you mean `std::result::Result`. The error type can be anything, but generally should probably be an enum.
My guess is that you are talking about std::io::Result and std::Result. When you look here https://doc.rust-lang.org/std/io/type.Result.html you will see that the first one is simply type Result&lt;T&gt; = Result&lt;T, Error&gt;; So it depends what kind of error you want to return. If it's std::io::Error, then you can use the first one.
I've got the following function. fn my\_func() { let file = std::fs::File::open(file\_path)?; } &amp;#x200B; I'm seeing both options in various locations online like [https://doc.rust-lang.org/std/result/index.html](https://doc.rust-lang.org/std/result/index.html) &amp;#x200B;
 Would this be suitable? fn my\_func() -&gt; std::result::Result&lt;(), std::io::Error&gt; { let file = std::fs::File::open(file\_path)?; }
Also on that note what does the () in "Result&lt;()," mean?
You could just use `std::io::Result&lt;()&gt;`, it's the same thing. Though in the long run you'll want to introduce your own error type (and possibly a result alias for convenience), or just `Result&lt;(), Box&lt;::std::error::Error&gt;&gt;` for simple scripts.
`std::fs::File::open` doesn't return an `std::result::Result`, it returns an `std::io::Result&lt;File&gt;`, which is defined as `pub type Result&lt;T&gt; = result::Result&lt;T, Error&gt;;`, so `std::io::Result&lt;File&gt;` is just a shorthand for `std::result::Result&lt;File, std::io::Error&gt;`. If all your function does is open a file, you probably want it to just return an `std::io::Result` without handling the errors at all.
`()` means Unit, which is basically nothing. You return a `Result&lt;()&gt;` if you just want to indicate that calling the function resulted in an `Ok` but don't have any payload you need to return.
`()` is the value/type that means "nothing". So, `Result&lt;(), std::io::Error&gt;` is a Result that contains either an error, or nothing. It's kind of like `void` in Java/C. If you were porting JavaScript code, `console.log` would probably return `()`
Thanks (everyone) that clears it up.
Ah, crap‚Äîwe should have set the lower bound of failure to 0.1.5. I knew I forgot something! Can you try doing that in your Cargo.toml?
&gt;How it enabled the CSS engine to be safely parallelized in a way that would have been impractical before FWIW, this has been written about before: https://blog.rust-lang.org/2017/11/14/Fearless-Concurrency-In-Firefox-Quantum.html
What's Result&lt;(), Box&lt;::std::error::Error&gt;&gt; ? Does this just catch all errors? Is the error handling different?
Strictly speaking, *no* optimized high level language in common use has a mechanism for telling the compiler that a value is confidential enough that you need to destroy it when finished. The optimizer is allowed to cache anything anywhere. In practice you could fork `Vec` (it's fairly straightforward Rust with an MIT-style license) and use `write_volatile` or an external call to `memset_s` / `SecureZeroMemory` to clear heap after a drop or reallocation. Rust's type system makes it much more difficult to write Heartbleed-type vulnerabilities to external threats. Zeroing memory won't protect against os-level threats (pages may be retained in a swapfile or you could be core-dumped or any number of things).
I would be happy to join; I have 20 hours of weekly free time, of which I could devote 10 hours to veloren
Guidelines for "serious" APIs: [https://rust-lang-nursery.github.io/api-guidelines/interoperability.html#c-good-err](https://rust-lang-nursery.github.io/api-guidelines/interoperability.html#c-good-err)
Pardon me for my naivety, but if you are not selling it, why not make it open source to invite more contributors?
Any error type your going to encounter is going to implement the `std::error::Error` trait, so returning `Box&lt;dyn Error&gt;` allows you to easily return any type of error regardless of its type. Note that we need the `Box` since `Error` is a trait. If you're making library methods, you shouldn't use `Box&lt;dyn Error&gt;` in your return types, since it makes it very difficult for your users to see what went wrong and handle the errors. The main usage is in your own scripts where you just want a quick and simple way to return an error, that you aren't going to handle in any way except for unwrapping it. If you want the user to be able to handle the error, create your own error type, which should probably be an enum that implements `Error`.
It's the "unit" type, so called, because there is only one possible value. The name comes from algebraic data types, where you can apply mathematical constructs to types, and the unit type behaves like the number 1.
Box&lt;&gt; is a pointer to a dynamically allocated object. Since it is dynamically allocated it can indeed refer to any object implementing std:error::Error. The `dyn` keyword is not mandatory since it is the default, but it is preferred now to indicate that the type Error is determined at runtime, while the `impl` keyword indicate it is determined at compile time.
`Result&lt;T, Box&lt;::std::error::Error&gt;&gt;` is literally a synonym of `Result&lt;T, Box&lt;dyn Error&gt;&gt;`. `::std::error::Error` is just the fully qualified form of `Error`, and `dyn Trait` is a newer spelling for trait objects, which used to just be written as `Trait`. The new form exists so you don't confuse them with a concrete type of the same name. It's meant to be analogous to `impl Trait`. A *dyn*amically chosen trait object, vs a statically chosen *impl*ementation of the trait.
Cool, thanks. I'll look into it... after I've finished my own take. I'm trying to learn, not copy other people.
 if let Some(hp) = &amp;mut npc.hp { println!("Found {} hp,", hp); *hp = 65; println!("changed to {}.", hp); }
I'd also vote for the rust-analyzer. However, you may wish to wait for the 2019 roadmap post (which should come sometime in early feb I think), which might contain some details on the plan for these tools going forwards.
`#[macro_export]` can be used, and then reference it with a path. // lib.rs #[macro_export] macro_rules! m { () =&gt; () } // main.rs use mycrate::m; fn main() { m!(); } 
False sharing? Spanning a NUMA node? It would be interesting to see if this variance is reproducible across systems and what the root cause(s) are.
Not to be that gouy, but it is called the Benchmarks Game.
The way you want to do it is unsound - once you `install` some non-static `Foo`, you don't know what lifetime can `Bar` have to be safe to add to it. So you can only safely add `Bar&lt;'static&gt;` - otherwise I could install `Foo` with a longer lifetime than the `Bar`, you want to add, and then try to use it once the `Bar`'s lifetime expires. And when you can only add `Bar&lt;'static&gt;`, then the installed `Foo` can be `'static` too without extra restrictions. And this is what the compiler tries to guide you to when it says that you can store `'static` values to globally.
Unrelated hint: If you don't want / need to support rustc &lt; 1.26.0, you can shorten that code by using [std::fs::read_to_string()](https://doc.rust-lang.org/std/fs/fn.read_to_string.html).
Imagine it as a tuple with no items, ie it doesn't convey any information. It's very useful when you want to return nothing from something. 
Not sure what you mean. Wouldn't a Benchmark Game want the best versions of everything? It's likely this is using whatever is the latest package on Debian which is a practical way to do it but I think ideally you'd want the latest release from each language as packaged by their authors.
Thanks for sharing.
It's completely on par or faster than C++ for me, don't know what you're complaining about.
&gt; I wonder if you could compile Lua to wasm The biggest obstacle to compile things to wasm is that it doesn't have a GC yet so you have to provide one. For webpages it prohibitive because by the time you have downloaded the GC the plain JS would have finished running. For a game, that might not be a concern but the lack of a GC means that people are less interested to use wasm as a compile target. It's been actively worked on though and eventually it will be a target that's as attractive to Lua and Rust.
I'm under the impression that you might think about this the wrong way, possibly influenced by fully dynamic languages like Python. If you know what \`find\_match\` can only ever return either \`StructA\`, \`StructB\` and so on, an \`enum Match { A, B }\` is the way to go. The \`enum\` can implement any trait you want and - while doing so - has to deal with the being an \`A\`, a \`B\` and so on. Most of the time, you need a \`Box(dyn trait)\` only if you can't say anything about what type it will be. This is rare. &amp;#x200B; As a side note: \`find\_match\` is a candidate for \`[FromStr](https://doc.rust-lang.org/nightly/std/str/trait.FromStr.html)\` where the \`Error\` is \`'static str'. You can then do something like \`function\_using\_trait("a".parse()?)\`.
The source is in the post. It's on Gitlab: https://gitlab.com/veloren/game The post could have been edited after your comment
I think it'll help a lot that Webassembly started with a simpler runtime model (flat memory) and went from there. Also that it's an open standard, and is much better integrated with the Web.
I cannot reproduce this and it would not make much sense in that context either because fewer lines of code are typically compiled for C++ usage than Rust. Maybe if you compare unified C++ builds with Rust that would make sense but even then C++ is not the benchmark here. Jai, Go, C, D, C# are all compiled languages with compilers that are significantly faster than Rust. I understand that they are all doing less during compilation but the end result is a much smoother development experience when it comes to iteration times.
I wonder if that would beat the standard lua interpreter performance-wise. It might if your wasm code was jitted. You wouldn't beat luajit, of course, but nothing beats luajit so that's not worth remarking on.
the bottom type is cooler. Though it would be admittedly not very useful if the Result could have it as a parameter (it would mean that the function simply quit the program unconditionally... i guess).
Sometimes you want to ensure the same type is passed in via trait bounds like so: fn add&lt;T: MyTrait&gt;(lhs: T, rhs: T) { .. } But there's no way to make that guarantee with an enum
I was just commenting that the name changed to "Benchmarks Game". Isaac Gouy is the maintainer of The Benchmarks and used to try and correct people on the name. 
[https://github.com/schollz/croc](https://github.com/schollz/croc) can I get a hint of libraries so I can rewrite it in rust? &amp;#x200B; I want to make it as part of my first cli project
Not sure about the rest, but keep in mind that Go made compromises in language complexity partially for compile time developer ux. And they also argued against generics because of the difficulty it would pose in keeping the compiler fast. Granted, they are adding generics now - so they clearly figured out a way. I think the point is still valid in that language complexity is something Go is specifically tailored against and boasts compiler speed partially due to this decision.
&gt; I'm not aware of a type like Vec that pins its storage. This proposal would provide such a "view" on `Vec`: https://internals.rust-lang.org/t/pre-rfc-fixed-capacity-view-of-vec/8413/51
When I want to benchmark x264, I'm not changing clang it compiled with in order to benchmark actual project. &gt; compiling it in a non-standard way is strange. Compiling project with system-provided dependencies is the standard way. Using bundled dependencies - is not. I've tried to avoid bundled LLVM for a long time when I was "maintaining" `lang/rust-nightly` I don't understand what are you arguing about? 
Not the same. You get `|` but under the hood it works like a block.
I would avoid futures-await if possible and use the await feature provided by tokio. Running on nightly you can use the built in async function syntax and it is much easier to use than futures-await. I recently migrated our codebase over and it has helped a lot. The main issue is futures-await will hide syntax errors and other issues behind very opaque error messages in the compiler. It makes getting work done difficult.
You can define `enum Void {}`. If function returns `Result&lt;Void, E&gt;` you know it always fails. On the other hand `Result&lt;T, Void&gt;` is always `Ok`. This is useful, for example, when you implement a trait and need to specify error type, but your implementation never fails.
This feels very clean and pretty 'rusty' to me, with no matching on references and such: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9b058ce522b46f21f8a7cfdcc8998fbb A lot of times in the standard library when there are updates to some owned value, you return ownership of the thing you are changing so that someone consuming the API can either let it drop or use the value that was previously there. This follows that model. 
Rust has the bottom type. `fn() -&gt; !` doesn't return, `Result&lt;!, E&gt;` is never `Ok` etc. etc.
It's stable now, at least everywhere I've used it while working through AoC.
&gt; Compiling project with system-provided dependencies is the standard way. For distro packages sure. For development and deployment it's increasingly the case that people will use rustup and similar stuff to get standardized toolchains instead of whatever the one that was shipped in the version of the OS they are running. &gt; I don't understand what are you arguing about? Initially I wasn't arguing about anything, just found it strange that LLVM 7 was being used when I knew that 8 was already shipped with 1.32. Meanwhile this discussion evolved into what version should be used for benchmarking. And for this shootout I can see that "whatever is the latest version shipped by Debian" is a great baseline to use as it puts everyone in equal footing. But for the point of this actual post, someone on /r/rust curious about what 1.32 brings using the rustup toolchain would be ideal. It's what I do here for example: http://chimper.org/rawloader-rustc-benchmarks/
We've gotten Lua working with our emscripten layer running on the old Wasmer runtime. 
I find this confusing too, because I often find myself importing a type called Result from some library, which shadows the std lib one. In this case I usually rename it to SomethingResult when importing. 
Hello all! I totally forgot to pin the version for the lambda\_\* crates. I am currently on vacation but whenever I get to a laptop I will make sure everything works with the post. Until then please feel free to make a PR!
Hello all! I totally forgot to pin the version for the lambda\_\* crates and other things. I am currently on vacation but whenever I get to a laptop I will make sure everything works with the post. Until then please feel free to make a PR! [https://github.com/itsHabib/api-gateway-rust](https://github.com/itsHabib/api-gateway-rust)
You might want to contact booya (https://twitter.com/booyaa) either there or through the community mailinglist. The meetup is definitely alive, but they are always in search for help. &lt;3 for inquiring.
I created a crate that makes generators easier to play with so code like this runs nicely #[generator] fn test_macro(n: u64) -&gt; impl Iterator&lt;Item = u64&gt; { let mut num = 0; while num &lt; n { yield num; num += 1; } } ... let sum: u64 = test_macro(10).sum(); for var in test_macro(5) { println!("{}", var); } should I publish it or there is already a crate for that?
What did you use for GC? 
What would you recommend I use? I'm definitely open to suggestions.
Fit.
You could have a look to the [sdset library](https://docs.rs/sdset/), a library to work with sorted and deduplicated slices of data that I made.
I think it's idiomatic to never import those Result-types directly. Instead, import `std::io` so it becomes `io::Result&lt;T&gt;`(this is what basically every example in the stdlib does).
I‚Äòm actually looking for an algorithm like this, but where the slice that I‚Äòm searching for has holes (i.e. certain elements that can be anything). Is the algorithm easily extensible to that? I‚Äòm not necessarily proposing adding it to your crate, but maybe I can use the algorithm here and extend on it for my use case.
The simple answer is to use a regex. But that can be overkill. I don't know of any existing crate that does fuzzy search in the manner you're asking, but if you can make Shift-Or work for you, then its [fuzzy search variant](https://en.wikipedia.org/wiki/Bitap_algorithm#Fuzzy_searching) isn't too bad to implement. Note that this is a bit parallel approach. Bit parallel approaches are really nice because they're fast in practice and simple to implement, but their key disadvantage is that they only support needles up to a certain size. (You can go arbitrarily large, but performance takes a big hit once your needle's length exceeds the number of bits in a computer word.) [Flexible Pattern Matching in Strings](https://www.amazon.com/Flexible-Pattern-Matching-Strings-Line-ebook/dp/B01N6J6M8E) has a more comprehensive treatment. (Although, damn, is it expensive. If I knew you IRL, I'd lend you my copy. :-))
Well its pretty easy to look at the [go.mod file](https://github.com/schollz/croc/blob/master/go.mod) and try to find replacements. I've been around a while so I'll point you towards the libraries that I'd use. - toml =&gt; https://crates.io/crates/toml - seelog =&gt; https://crates.io/crates/slog seelog looks like a "structured logging" library, and slog is the popular Rust library for doing that. A simpler logger like env_logger would also work. - go-humanize =&gt; maybe https://crates.io/crates/humansize depending on the features used. Search for 'humanize' on crates.io for others. - color =&gt; https://crates.io/crates/colored or https://crates.io/crates/termcolor - w32 =&gt; https://crates.io/crates/winapi - wui =&gt; https://github.com/gabdube/native-windows-gui is the closest I know - go-colorable is not necessary, colored and termcolor work on windows - go-isatty =&gt; https://crates.io/crates/atty - go-homedir =&gt; std::env::home_dir has the same behavior, but I'd recommend https://crates.io/crates/dirs which has better behavior on windows and supports XDG directories - errors =&gt; https://crates.io/crates/failure or https://crates.io/crates/error-chain may be similarly useful - mnemnonicode =&gt; https://crates.io/crates/mnemonic - pake =&gt; https://crates.io/crates/spake2 looks decent, though I haven't heard about it before. Another option is to use the https://crates.io/crates/ring hkdf module, though I don't know what other work that would entail. - peerdiscovery =&gt; https://crates.io/crates/mdns could do similar things using mDNS, or you could roll your own like https://github.com/WiSaGaN/muc/blob/master/src/main.rs - progressbar =&gt; https://crates.io/crates/indicatif - spinner indicatif can do this - open-golang =&gt; https://crates.io/crates/open - testify =&gt; maybe https://crates.io/crates/simulacrum - cli =&gt; https://crates.io/crates/quicli - crypto =&gt; https://crates.io/crates/ring et. al. For networking I'd recommend using the standard library for TCP and https://crates.io/crates/websocket for websockets. 
I certainly don't; I don't think intellij-rust uses rust-analyzer either, though, Jetbrains have their own framework for language analysis.
a common pattern in rust code is to define an error type for your entire application (normally using error-chain or failure crates), and then defining type Result&lt;T&gt; = std::result::Result&lt;T, MyErrorType&gt;; The crates I mentioned will take care of converting other error types to the error type of your application. That way, you will _always_ write down `Result&lt;()&gt;`. https://blog.sentry.io/2018/10/22/getting-started-with-rust-error-tracking If you use failure (which is the best practices as of 2019) you would do `type Result&lt;T&gt; = std::result::Result&lt;T, failure::Error&gt;` and be happy.
Actually I think that's wrong. std::io creates its own error type which you probably shouldn't be using directly. It aliases Result to always use that error type. I believe the more idiomatic solution is to create your own error type that possibly wraps inner errors up, and make your own type alias for Result that defaults to that error. This way you can provide more information about what went wrong.
Aha! even that one is more high level and more anecdotal, but fair enough. more informational either way 
Labelled breaks are quite trivially transformed to a normal break + a bool, so I wouldn't expect that to cause major issues either.
&gt; "whatever is the latest version shipped by Debian" is a great baseline Yes. However, in the case of rust, that doesn't seem to be what we've got from [the official Rust standalone installer](https://forge.rust-lang.org/other-installation-methods.html#standalone). 
wow. i remember encountering code for the first time in my career as that impossible to grasp. nice to be back again.
I think you might have confused things. GP is just saying, don't do, `use std::io::Result;`. Instead, do `use std::io;` and qualify use of result with `io::Result`. They aren't saying you should use `io::Result` everywhere for everything. There are some folks that disagree with creating the `Result` type alias in the first place, basically because of exactly this confusion. I personally weakly disagree and like the pattern, but I see where they're coming from.
Awesome hint, thanks. I was wondering if I'd missed something in the stdlib.
You don't recall correctly, so please correct this.
You're totally right. I misread the comment. This is what I get for responding right after waking up :P
Thank you so much!!!!
No worries. I do the same thing. Repeatedly.
&gt; But as a result, you can't do something like securely zero in the move constructor. Note that the fact that `Vec` is trivially relocatable hinges on the fact that only a pointer is moved, so when `Vec` is moved the memory buffer is not. --- For traces left in memory I'd watch out for: - growth: anytime `realloc` is used, the former buffer is not cleared... and you technically don't even have access to it any longer to actually clear it. - stack: it's possible that the compiler could copy part of the buffer on the stack or in registers when operating over it.
While I have you here, thank you for your wonderful ripgrep tool. I use it constantly. Keep up the great work!
Specifically, any new memory page you get from the OS is full of zeroes. It's an actual guarantee you can rely on to optimize out zeroing.
E can be whaever, but for sanity, you should really do an Enum. in this Enum, you can add your own error whtit the parameter you want and also forward errors from others library, and from the standard library. Then the really cool thing is how easy is to wrap error by implementing a From trait for every error. Here is an example of error type of mine: https://github.com/mardiros/cabot/blob/master/src/errors.rs Once it is done, you always use your own result and error type, and map error so easilly such as: https://github.com/mardiros/cabot/blob/master/src/dns.rs L19 `?` if theDNS server is not responding, the Error is autowrapped L23, declare the error explicitly and the `?` on li e 24 will return it in case there is no ip address for the domain. There is some non standard library such as Failure to handle it, but I don't see the point for using them. 
I will, thanks for the reference!
To safe disk space, you could get rid of `next_checksum` by having a special `next` value !=0 for "there is no next entry". u64 types seems also large.
Lua has its own GC, so it just used that, but running inside the wasm linear memory.
Why would the official rust packages use debian compiles?
I think the best approach would be for a crate to give a `SecureBuffer` that handles things like zeroing memory on reallocation and preventing the OS from swapping it out. As that crate describes in the docs, some of how a `Vec` behaves is incompatible with the idea of scrubbing all traces of the data it holds from RAM.
I was not aware of this syntax with Default. Thanks for mentioning it!
Can you further explain the difference? (Also, I'm sure it could be implemented as some plugin. Although by that logic, kakoune could've been implemented as a plugin for emacs)
Firewalls typically block incoming connections that don't have an existing corresponding outgoing connection, which makes it difficult to connect peer-to-peer. This can be fixed with port-forwarding but that's not usually an option in corporate environments or public hotspots. Using a relay server lets both peers get through the firewall since they're both connecting out to some server rather than trying to get traffic in directly. https://crates.io/crates/p2p could help with this, it looks like it does encryption as well. I've never had to do this before though, good luck :)
&gt; it would not make much sense in that context either because fewer lines of code are typically compiled for C++ usage than Rust Rust has had incremental compilation for a while now, so this isn't at all a given.
That doesn‚Äôt help here. For what they need here they need to compile the entire crate. 
Not my quarrel ‚Äî suffice to say, I simply hadn't considered what the installer was doing.
Hmm, maybe I need to rephrase my question. This example is a bit contrived, but I want somebody to be able to use Foo like: let x: String = format!("{}", 7); let foo = Foo::new(); foo.install(); // Bar&lt;'a&gt;, because x will go out of scope foo.add(Bar(&amp;x)); // Bar&lt;'static&gt;, can be added through the thread default default_foo::add(Bar("Hi!")); foo.print_all(); // Prints "7" and "Hi!" Now that I think of it, it would be possible to have two different arrays, one `Bar&lt;'static&gt;` and one `Bar&lt;'a&gt;`. And then Rc/RefCell the `Bar&lt;'static&gt;` one. But it feels like a detour just to satisfy the borrow checker.
I'm not sure why else you'd think C++ has less code to compile.
Because the unit of compilation is the file you‚Äôre looking at. You just need to resolve the headers which is less than what RLS needs to consider. 
good sir it is open source :) and i posted the open source link at when i first made the topic &amp;#x200B;
As a first attempt, I'd try to build a simple connection pool. Create a bunch of connections to the database, add them to a vec, and wrap it in a mutex and an arc (and maybe a refcell). Pop from that vec if you need a db connection and make sure to push it back when you're done with it. There might already be crates available that do something like that, but I have to admit I've never used a database from rust... 
Well it appears after doing some digging that the mongodb driver provides a connection pool internally, and the returned client object is an Arc&lt;ClientInner&gt; which is intended to be cloned and used wherever it is needed.
Thanks again!! I really appreciate it.
Looping forever is also valid in both cases, so a function that either loops forever or errors out would return `Result&lt;!, E&gt;`. This is equivalent to just returning `E`, but maybe you have some API constraint that forces a `Result`.
Mods are asleep, post rust?
Depends on what you're used to; but this makes sense from the POV of Haskell, `\` is the first token of a lambda, and `case` is the first token of a case expression; put them together and you have lambda-case. Moreover, my reddit nick is *etareduce*, so I'm obligated to do that ;)
If I were evaluating a text editor, I'd care far more about latency than throughput. The traditional, and low-latency, way to do this was bitmap glyphs that can be blitted or tile-mapped to screen - originally by hardware. That doesn't mean that hardware-accelerated vector text *can't* be as responsive today, but often new graphics technology seems to ignore latency and not do so well. 
My C++ code compiles faster than Rust on Windows, because I am able to take advantage of incremental compilation, incremental linking, pre-compiled headers and binaries libraries. It only gets slower if I start throwing in libraries with heavy use of templates.
Because C++ community endorses binary libraries, so you don't have to compile the all world from scratch.
If Sourcegraph is running on the entire codebase, it has to process everything, and with the way headers work it's probably processing them many times over. Meanwhile, RLS can still take full advantage of rustc's incremental compilation cache.
I think [gen_iter](https://docs.rs/gen-iter/0.1.2/gen_iter/) is usually used for this, but the attribute cleans it up a bit.
There is no "character **under** the cursor".
I have a rust internals question about the following (invalid) code. &amp;#x200B; `let a : String = format!("abcde");` `let a_reverse = a.chars().rev().collect::&lt;String&gt;();` `println!("a is: {:?}\n", a);` `println!("a_reverse is: {:?}\n", a_reverse);` `let v : Vec&lt;u8&gt; = vec![1, 2, 3, 4, 5];` `let v_reverse = v.iter().rev().collect::&lt;Vec&lt;u8&gt;&gt;();` `// a collection of type \`std::vec::Vec&lt;u8&gt;\` cannot be` `//built from an iterator over elements of type \`&amp;u8\`` &amp;#x200B; String.chars().rev() yields a Rev&lt;Chars&lt;'\_&gt;&gt; whose internal item is slice::Iter&lt;'a, u8&gt;, and Vec&lt;u8&gt;.iter().rev() yields a Rev whose internals are also a slice::Iter&lt;'\_, u8&gt;. I'm curious why .collect() is allowed for the string without the reversed string taking ownership or complaining about references, but the vector one produces an error.
To add to this, I'd recommend checking out the `error_chain` crate. 
&gt; Like I discussed in a previous post, for loops in Rust can work with either and iterator or a ranges. More precisely, ranges in Rust *are* iterators. If I were teaching someone programming I think I'd probably take the time to look at how `Iterator` is implemented for ranges and slices - and maybe even `Vec` for a taste of `unsafe`. It's no more difficult than a C-style `for` expression and it helps the student get a feel for when they could implement `Iterator` for themself.
I should've clarified that it's usually not a good idea to use "foreign" error types.
Except I can't think of any *new* language being developed primarily for the CLI/CLR that isn't published by Microsoft. According to Wikipedia, there's been a number of attempts, but most of them look to have stagnated or been abandoned.
No
Please respond with reasons. Otherwise we aren‚Äôt having a discussion and I believe the rust community is smart to have engaged, open, inventive discussions around challenging topics such as this. Otherwise we are saying we care more about our opinion than the longevity and evolution rust may have. 
I think this is a really interesting project, and something I really wish existed back when I was working on my fuzzing projects. Unfortunately, the performance tanks once the data it stores no longer fits in memory (and it has a rather large overhead for small keys, with all of its checksums). This is fine for one of my usecases, which is a Rocket server that deduplicates work while fuzzing (basically checks whether an md5 hash was seen before). My previous implementation was just a global hashset, whose contents I wrote into a file on a 10 minute interval. This project is much more elegant than that. I hoped I would be able to use this for an upcoming project of mine, but unfortunately the scaling issues prevent that. I need to handle just under a billion small KV pairs in total, but this isn't performant enough, even at 100 million keys. I was hoping to avoid learning some complex KV database, but I may not be able to do that to achieve acceptable performance. P.S. One thing I noticed is that the [crates.io](https://crates.io) (and docs.rs) entry for this crate does not link to the github repo, you should add it to Cargo.toml so both of those link there properly.
[removed]
The selling point of wasm-bindgen is that it uses a kind of shared memory approach to passing data between wasm and js, which avoids serialization costs, and is forward-compatible with the host-bindings proposal, which would allow interaction with the dom without the overhead of js at all. However, for a toy example you probably don't need this. I hope that the stdweb and wasm-bindgin libs get unified at some point.
Let's assume we somehow managed to find the absolute best name possible. We'd gain perhaps 5% additional momentum and lose 70-80% because what everybody used to call Rust is now called `foo` and all of those articles and blog posts and SO questions and Reddit comments people have been reading for last 5 years are now all wrong and everybody who isn't already a Rust programmer is confused. Now we have to start from 0 just to get back to where we are now. If changing the name was going to happen, it needed to happen before 1.0. That ship has long since sailed and further discussion is literally just bikeshedding.
I think it's kind of late to rename Rust, it has garnered a fair share of love from its users, and the name is spreading - I'm hearing more and more developers that at least know of the language now. I think the name Rust is very fitting, taking a lot of old but good features from other languages and keeping a familiar syntax. It is a short name, and memorable. It is unfortunate it shares it's name with the video game, but I have found it very easy to distinguish between the two in most searches.
I understand your valuable insights. The most important you present is the possibility to lose previous gains due to potentially confusing those searching for Rust articles. Thankfully rust doesn‚Äôt have the most widely accessible documentation for newbies who learn mostly on udemy and YouTube. That means we are essentially at version .30 of documentation. Just as golang has been shortened for the masses as go we can simply drop the t from rust, call it Rus, and forward a wonderful crab mascot made out of gears. It could change EVERYTHING for the language by giving it a new image. We have to get it to stick out in peoples mind. Remember beta-max V.S. VHS? Beta sounded weaker. Alpha vs beta. VHS is easy to remember. We don‚Äôt call it foo. We call it Rus. It would be magical and could make rust the leading language it deserves to be. 
The word rust is catching on to identify the language however the word in mainstream culture means non-durable rusting of metal. People will associate it with a security risk just as rust poses a risk for cars and other metal objects. We can‚Äôt live in the qualities of the language itself. Look at python. I hate python. However it‚Äôs easy for newbies and has a great name. Why can‚Äôt rust do the same? 
Believes in co-location asking help from community that thrives being distributed. Interesting world.
&gt; Thankfully rust doesn‚Äôt have the most widely accessible documentation for newbies who learn mostly on udemy and YouTube. We already have YouTube documentation and a number of video learning solutions have content as well. &gt; That means we are essentially at version .30 of documentation. That's not how versioning works. Documentation is in production right now. &gt; Just as golang has been shortened for the masses as go Go was always referred to as Go. People only use golang when googling. &gt; beta-max V.S. VHS VHS won for other ... rather different reasons. Feel free to google that. ------- Frankly, a name change is going to start at -10000 points. I can tell you with almost complete certainty that the community will not go for a name change.
Hah touch√©! To be fair, though, we're building a hardware product, and that changes the game somewhat. There are a few companies that have distributed hardware teams but I hear it's pretty tough to manage.
I understand that documentation exists. This indicates that it is accessible if someone goes searching for it. If. Conditions. How about we make it more useful? In the world of adoption of new technology for the mainstream it needs certain qualities that appeal to us humans and our more emotional and social story telling side. This gives something +4000 points in creating positive neural associations based on previous context. Think of it like training a neural net. We have tons of training for positive images and tons of training for negativity images. Rust is not a negative image. So we can change or tweak the name to utilize the positive associations while also catching headlines about the name change. This will drive new users to be interested, want to try it out, and adopt the language. Think of golang - their website says ‚Äútry go‚Äù. That sounds great. ‚ÄúTry rust‚Äù sounds awful. The language name can be like a Pok√©mon. It can evolve. It can adapt over time. I believe it‚Äôs crucial we talk about this within the community at length. What do we have to lose in a wide, open, and participatory conversation? 
Makes sense, happy you all are doing what you do. Sounds exciting.
Bikeshedding level over 9000
Google rust and tell me what you see. Oxidizing metallics. Why is this appealing? This sort of refusal to care about the common person isn‚Äôt what makes a community. Community is welcoming. Go is welcoming. That‚Äôs what I‚Äôm saying - we could be more welcoming by acknowledging our faults and not trying to defend a very simple problem. Very easy fix to employ by real problem solvers. Are you one of them? Please say yes. 
`String::chars()` gives you an iterator of type `Iterator&lt;Item=char&gt;` since it has to construct the `char` values from whole-cloth by parsing and interpretting the UTF-8 bytes of the String, and `String` has an [implementation of `FromIterator&lt;char&gt;`](https://doc.rust-lang.org/std/iter/trait.FromIterator.html#impl-FromIterator%3Cchar%3E). In the second case, `v.iter()` gives you an iterator of type `Iterator&lt;Item=&amp;u8&gt;`, and then you're trying to build a `Vec&lt;u8&gt;` from it. There's no implementation of `FromIterator&lt;&amp;T&gt;` for `Vec&lt;T&gt;` since it's not always possible to convert a `&amp;T` into a `T`. If you want that (and the type you're iterating over implements `Clone`), you can use the [cloned](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.cloned) method: let v_reverse = v.iter().rev().cloned().collect::&lt;Vec&lt;u8&gt;&gt;() since that will convert the `&amp;u8` into `u8`.
What kind of salary are you offering?
This sounds very exciting! Is there any chance you guys would have a new-grad position open in the near future?
The `chars` iterator specifically returns a `char`. This `char` value is constructed based on UTF-8 data in the `String` rather than simply being a view into the UTF-8 bytes themselves. Meanwhile calling `iter` gives you an iterator over `&amp;u8`, which is a reference to one of the `u8` values that the `Vec` is made of. To collect into a new `Vec&lt;u8&gt;` you need a series of `u8` rather than `&amp;u8`. Easiest way to do that is just add `cloned()` to your iterator chain.
I've been at the meetup a couple of times and it was pretty great, I guess the organiser is just busy atm?
Her name is Ferris and she is not a robot! &gt;:( Rust is actually named after a [particularly resilient fungus](https://en.wikipedia.org/wiki/Rust_\(fungus\)).
`Vec` implements `Deref`. `&lt;Vec&lt;T&gt; as Deref&gt;::Output = [T]` I'm not sure what pin would do when the underlying reference points to a DST like a slice.
Please be sure to include a location in job posting titles.
I'm glad we're a progressive enough community that you can so freely identify as a programming language. 
That's understandable, but it would be nice to know what kind of salary you're offering as well, especially if you expect your new employee to live in/commute to SF.
r/rustjerk
I remember when the language wasn't the top search term for Java. Then again with Python. Then again with go. This isn't a new thing and the examples you gave went through the same difficulty.
Damnit.
... in LA.
Groovy
Would be so cool, but I've never actually shipped any embedded products. GL!
Apologies for the snarky response, but this is the kind of change that doesn't add any value and has massive costs associated with it. Which is the definition of bikeshedding. &gt;Google rust and tell me what you see. Oxidizing metallics. [This is what I see.](https://i.imgur.com/Prd2ZR0.png) After opening a private tab in a browser I don't use with all cookies/history cleared (to remove any search bias) I count 7 out of 10 of the first Google results page directing to Rust forums or pages. And that said, this isn't something unique to Rust. Python, Ruby, Go, Java, Swift... plenty of languages share a name with words in the English language. What you're talking about isn't small, and it isn't simple. It's a massive breaking change that would ripple through thousands of users and projects, and it would effectively split the ecosystem. So if this is something you want to push: 1. Collect some hard evidence that the name is harming the usage of the language. 2. Construct an argument as to why changing the name would have greater benefit than the costs of transitioning. 3. Discuss it in a pre-RFC on Discord or internals.rust-lang.org to get more constructive feedback from people who are actively engaged in the development of the language 4. Don't feel personally attacked in further discussion. The community is certainly open to new ideas, but changes aren't implemented with wild abandon. There's a process for going about changes to the language itself, and bikeshedding is going to be killed in the womb almost 100% of the time. Lots of energy over trivial things, when that energy could be spent better in other areas. 
Names are less important than you think. Most examples of 'strong' names for things are just survivor bias. We retroactively justify a strong name when it had very little to do with the success of a thing. Python is popular because it is easy to learn. JavaScript is popular because of web browsers. Go is popular because it is supported by a multi-billion dollar company and it's creators are some of the biggest names in computer history. Swift is popular because Apple. Ruby is popular because of Rails. Java is popular because of Sun. Little to nothing had to do with the naming. 
Just tell people it's "close to the metal" and they'll get the joke.
Forgot about that one, though the only high-profile use I can think of is Gradle.
But Pythons are snakes and lots of people hate snakes! Python needs to change their name too
&gt; Unsafe can do what it wants, but it shouldn't break that rule. `mem::uninitialized` does in the sense that it can't name every field...
Appreciate your thorough response. I‚Äôll return if I gather more convincing hard evidence to justify the ROI :) 
Thank you for educating me! This is why I want rust to win. So much goodness. I‚Äôm just concerned about the name... perhaps it‚Äôll grow with time... 
If you feel this passionately about it, then you need to write an RFC. Reddit is not where Rust language decisions happen. However, a vital component of a successful RFC is showing prior art. What successful languages have changed their names after 1.0?
I think Rust has and is continuing to catch on as fast it needs to. The name is less important than the quality of the libraries and surrounding tooling.
You‚Äôre right to question what data exists to promote the change. Sadly I wasn‚Äôt aware of the language prior to 1.0 getting released. My background comes from design where I‚Äôve had to interface with clients to gain buy in based on them seeing the works adoptability by a demographic. To be transparent my interest in seeing the name changes stems from a hunch that JavaScript could be given rest in favor of rust + web assembly as the primary language of the spatial web / mixed reality. Seeing as Ready At Dawn has already chosen it over C++ which is the language of Unreal and by extension mixed reality made in unreal, we could see rust handle everything that JS can plus more. I also have a thing against python just cuz so rust getting used for ML and XR sounds beautiful. That said, it‚Äôs hard to imagine millions of devs building on top of ‚Äúrust‚Äù. Just doesn‚Äôt sit right with me. As more people lose jobs to automation we will gain many more devs. I would like to see rust as one of the foundations of that transformation because it‚Äôs a language that seems to represent many values of the decentralized web. 
Maybe re-read the r/rust rules. Especially 3, 4 and 5.
I agree 99%. I‚Äôm just concerned again language, even Go, will try to build libraries or functions into their language to approximate some of Rust‚Äôs great functionality while using its easier to swallow name to win over the masses. Google isn‚Äôt exactly my favorite monolithic big brother corporation in the world, you know? 
Groovy is also used for everything in Jenkins.
Is it published in crates.io?
They‚Äôre talking about it too... https://www.reddit.com/r/golang/comments/ajorhy/go_on_your_cv_go_golang_or_go_golang/?st=JRCQ6ALC&amp;sh=ceefc118
Nah, but I'll do it soon enough. Just want a few eyeballs on it to see if it's even sane as is. 
Is there a crate for regex on arbitrary slices and not just on strings?
Amen!
Note that empty loops, especially when combined with empty enums, have outstanding soundness bugs, like [this one](https://github.com/rust-lang/rust/issues/28728).
`regex` provides a mirrored API that works on `&amp;[u8]`: https://docs.rs/regex/1.1.0/regex/bytes/index.html If you mean `&amp;[T]` where `T: PartialEq` or something like that, then, I no, I don't know of any non-toy crates for that.
Yeah I'll have to redo this with more backstory.
To speak more precisely, the correctness of unsafe code is not necessarily composable: one function can do something which is only defined behavior in certain circumstances. And those circumstances are somebody else's responsibility. Safe code *should* be very composable - it is impossible, or at least very hard, to put together safe code in a way that breaks type safety. `mem::uninitialized` exists because uninitialized-poison is a useful primitive when you allocate something and initialize it with FFI. Rust has a rule that you must initialize; by using that function you give the optimizer a strong hint that initialization isn't necessary; you just need allocation and a pointer to pass to an external function. After that call, the compiler understands that the value is initialized. Anything that observes the variable has to see whatever was there when the call ended. At that point we're back within the rules of the type system. The span of code in which the variable is in the dangerous, uninitialized-poison state is quite small. So hopefully nobody will forget about it and accidentally read from the variable. As a rule, you shouldn't exit unsafe code unless the type system rules have been re-established. So it's fine for `uninitialized` to exist. But you really shouldn't return it, or risk passing it to a function unless you're *sure* that function knows what to do with it. (For example, an unsafe version of the `Read` trait might have a method which knows how to read to an uninitialized buffer. You could call that method from safe code, no problem, so it's a safe method.) So you almost certainly shouldn't create uninitialized fields, but if you really have to (probably for performance reasons) you *can* do it with unions or `uninitialized`. The important thing is that safe code should *never* be able to notice that you're cheating the type system rules. 
In my X environment, this is what I'd do: [andrew@Cheetah ~]$ xprop -root _NET_ACTIVE_WINDOW _NET_ACTIVE_WINDOW(WINDOW): window id # 0x2600003 [andrew@Cheetah ~]$ xprop -id 0x2600003 _NET_WM_NAME _NET_WM_NAME(UTF8_STRING) = "3:1:zsh - \"~ - xprop -id 0x2600003 _NET_WM_NAME\" " Whether this works for your use case or not, I don't know.
I'm not particularly worried. Google could certainly try to get Go to match Rust's community and package management story, but Rust's static guarantees and performance capabilities are intrinsic to what it is. Go without a garbage collector would be an unrecognizably different beast and you're unlikely to ever write compiled extensions for other languages in a language which is so tied to its green threading runtime. Likewise, the C++ standards people are trying to incorporate lessons from Rust into future versions of C++, but they're inherently limited by the need to retain compatibility with existing C++ code, which doesn't give the compiler the necessary information to satisfy stricter checks, and there's no easy way to get everyone to unify around a single package management solution. etc. etc. etc.
&gt; it keeps printing the name of the binary Without seeing your code, it's difficult for anyone to tell you why your program is doing any particular thing. If you could put together a minimal example that's doing X when you think it should do Y, you'd be almost guaranteed to find someone who can help you understand why.
I kinda think `await {}` is a good compromise, but at this point I have no idea what we're going to land on.
Great insight. 
That said it is only a matter before IoT and the web makes a single language necessary. Could it be Rust? 
My personal thought at the moment is that only landing a postfix `await` will be a huge readability disaster for Rust.
[removed]
My Question is more of the theoretically how would you go about getting the name of the terminal. In Bash you can do `ps -aux | grep \`ps -p $$ -o ppid=\`` and get this ouput user 4239 0.0 0.7 292708 15744 pts/8 Sl 11:39 0:02 xfce4-terminal user 4800 0.0 0.0 6176 820 pts/0 S+ 12:23 0:00 grep --color=auto 4239 or with xdotool installed you can do `perl -lpe 's/\0/ /g' /proc/$(xdotool getwindowpid $(xdotool getactivewindow))/cmdline` and get konsole or `basename "$(cat "/proc/$PPID/comm")"` and get this konsole &amp;#x200B; However when I do the equivalent, trying to get the parent pid of the current pid from with in the program it will only tell me the name of my program
What do you mean by "the name of the terminal"? Do you mean the controlling TTY, like `/dev/pts/10`? Do you mean the title-bar text of the window, like `me@mypc:/home/me - Terminal`? Or do you mean the name of the terminal program, like `xterm` or `gnome-terminal`?
The name of the terminal program.
I can't believe I didn't think of just re-assigning the entire Option. :p (I had tunnel vision since the thing motivating this example has to do with a more complicated struct that I wouldn't like to re-assign like this.)
Nice! `&amp;mut npc.hp` is arguably better than an `npc.hp.as_mut()` if the type doesn't implement `AsMut`. : o
Also, don't you guys feel somewhat unfair that Rust team members will thumb up their peers' comments while a lot of well articulated discussions doesn't receive any from these members? How can this encourage people to give their feedbacks?
I like postfix `expr await;`. To me it is not less readable than `?`. I think it will greatly facilitate chaining futures wich seems idiomatic.
[removed]
I mean, they‚Äôre still just humans with their own preferences. What should they do instead? Vote for the opposite of what they want? No snark. Just a practical question. 
Same here. I'm definitely coming to the conclusion that we ought to go for prefix syntax initially, and then weigh up our options for postfix syntax later.
Congrats on your crate! I made a similar crate using typenum (https://github.com/ambaxter/bitarray-set). Feel free to copy features you find useful!
When Nintendo did their first presentation about the Wii at E3 they said "We'd like to thank the two persons who told us they like the name." And yet, it was a massive success that people remember fondly.
My old company set up a webcam for remote engineers to watch the blinkenlights on hardware units when doing driver development!
That's difficult, because there's not necessarily any link between your process and the terminal process. For example, imagine the terminal launches a shell, the shell launches another program, the other program launches your program, and then the other program quits. Now the kernel reparents your program to PID 1, so no amount of `ps` grepping or parent-pid manipulation will get you back to the terminal. Or maybe your program gets launched via `ssh`, so following the chain of parent PIDs will just take you back to `sshd`, and no terminals are involved at all. Just taking a stab in the dark, but if the reason you want to know what kind of terminal you're using is so you can figure out what kind of escape-sequences it will accept, maybe you just want the `$TERM` environment variable?
Listen. If I don't get postfix await, whether through you, or a crate, or a proc macro or however you want to get it, I will shut Rust down. I'm proud to say that and I'll tell you why. The people of this community don't want prefix awaits coming in and bringing their parentheses with them. I will shut Rust down. I'm not going to blame you.
I think a space-separated postfix keyword is too much of a special case on a syntax level to justify.
\&gt; Rust meanwhile sounds weak and dangerous That's your opinion. In 5 years I've been lurking this community this is the first time I'm hearing of someone not liking the name. The name is great. 
This works for me on my Mac and should be portable to Linux or any Posix environment https://gist.github.com/dgovil/4aaedb6fc97d6a312fbb4753cc021e34 It'll print all the parent processes out. The first one should be your current rust application, the second should be the terminal but I can't guarantee that since it depends on the way everything was launched.
Try writing complex software in Go. Rust has nothing to work about. No matter how much a language tries to implement similar APIs, it's effectively impossible for them to do it without having the same level of language concepts to express such APIs.
I don't think we'll ever see a single language for everything. The requirements vary too much. You'd either wind up with some situations where it's more onerous than necessary, prompting someone to develop something more suited, or you'll make nobody happy by trying to optimize for a middle ground. At the very least, I foresee two languages. One for systems-level work (Rust could do this) and one for scripting and disposable code, like one-off scripts and rapid-iteration prototyping where you're trying to identify the appropriate algorithm to tease an acceptable result out of a test corpus.
&gt; What should they do instead? Vote for the opposite of what they want? That they currently vote for what they want is not what is being insinuated by the parent comment (and imo is somewhat disingenuous to insinuate in turn), rather that they only participate at all in a clique composed of Rust team members, and that the presence of said clique is what is 'unfair'. I have no idea if it's true or not, just assisting with reading comprehension
Ohhhh, I see your problem. When you run `cat "/proc/$PPID/comm"` from an interactive `bash` process, you get the first 15 characters of the filename of `bash`'s parent process. In an interactive terminal, that's probably the terminal process. When your Rust code launches `bash` as a subprocess to do the same thing, you get the first 15 character of the filename of `bash`'s parent process, which is your Rust process. Instead of launching `bash` as a subprocess, you probably want to do something like [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=48d7aff5bd872b17622bd6842c6ab3f6)... but even though it shows parent of the Rust process, that's not always going to be the terminal process.
The only reason postfix was considered in the first place is because prefix `await` keyword has the precedence issue with `?`. I wonder if a go-like `&lt;-` wouldn't actually work. E.g. the following has obvious _and_ useful precedence. &lt;-client.get("https://my_api").send()? Some might take issue with the terseness. I'd advise those people to read [this](https://thefeedbackloop.xyz/stroustrups-rule-and-layering-over-time/). Not going to make this comment on that thread though because it's already noisy enough, and I'm sure there's a reason I'm overlooking that this wouldn't work.
What are the issues with using 'await!()' for now and punting the issue? IIUC await is a reserved keyword, so it is unpractical to stabilize 'await!()' for now and use the same keyword in a different context later, but perhaps one could stabilize a lower level syntax and place 'await!()' in a semiofficial library fow now.
First, your example code snippet is failing because it doesn't walk up the ancestry tree. ssokolow@monolith tmp % ps -aux | grep `ps -p $$ -o ppid=` ssokolow 5565 0.0 0.3 92020 60676 ? Ss 2018 13:56 SCREEN -RR ssokolow@monolith tmp % bash -c 'ps -aux | grep `ps -p $$ -o ppid=`' ssokolow 28821 0.2 0.0 52176 6912 pts/16 Ss 21:43 0:00 /bin/zsh Second, as has been said, there's no reliable way to do what you want unless you're more specific about what overall goal you're trying to accomplish. * If you walk up the process tree until you find an ancestor that matches the name of a known terminal, you'd have to maintain a list of all possible terminal emulators. * Windowing systems have no concept of mapping a particular process to a terminal window it's running in. * Querying the active window is flaky, since someone might touch off a process and then change focus before it does the querying... and Wayland disallows that as a security risk. * Process tree-based solutions will be foiled by both remote shells and popular tools which support allowing terminal sessions to outlive their terminals, such as [GNU screen](https://en.wikipedia.org/wiki/GNU_Screen), [tmux](https://en.wikipedia.org/wiki/Tmux), SSH, and Mosh, because a fresh terminal, re-attaching to an existing session or a process on another machine won't be ancestors of the persistent `sshd` process or `screen` process or what have you. * Solutions based on the `TERM` environment variable won't be reliable because tools like GNU screen paper over differences between the terminal you started on and whatever one you might finish on by being terminal emulators unto themselves. (Screen and tmux work by presenting themselves to your applications as terminal emulators, interpreting the control codes received, then re-rendering the interpreted content using whichever control codes are appropriate for the terminal emulator you're running them inside... this even extends to being able to have multiple *different* terminal emulators "following along" as you type into a GNU screen session for a terminal analogue to the collaborative editing in Google Docs.)
Rust 2015 crates are compatible with Rust 2018 crates, you just can't mix editions within a single crate. So even if a crate you need only has a 2015 version available (might be a lot because Rust 2018 is somewhat new), you can still use Rust 2018 :)
... wow, what happened in there? I looked last week, and there were just a couple comments, now there's over 200? üò±
I think there's a clear difference (although it might not matter much in practice): In your first example you annotate the type of the variable/binding `a` and then try to store an integral number, which is illegal for obvious reasons*. In the second case, you're using a literal of type f32 and type inferences chooses the same type for the binding. \* It's probably less obvious that number literals without a '.' are never floating point numbers.
&gt; Go was always referred to as Go. People only use golang when googling. The original plan was to follow up with a debugger named Ogle so that when put together it would make Google.
I personally prefer postfix @, but that doesn't seem to be a common preference. Out of genuine curiosity, would someone who doesn't like postfix @ mind explaining why, and how they think about it in comparison to the postfix ? operator.
People keep repeating arguments and write "I like X" comments without giving elaborate arguments on why... this adds up quickly. ;)
Almost every other language uses prefix...
I updated my original post. Hope it's clearer.
Hi i'm wondering if there is a built in way to check the licenses of the packages installed by cargo?
 client.get("https://my_api").send()?.json()?; ^ await As a bonus, a developer could easily extend the underscores to express how long the wait should be: client.get("https://my_api").send()?.json()?; ^^^^^^ await 
From a parsing perspective it really is no harder than `?`, assuming `await` would be a reserved keyword.
IMO Rust needs less, not more, symbols. It really hampers readability.
Yes, that makes sense. In my case, I just want to make sure I'm not doing something "obviously slow" in the rust ecosystem--i.e. I don't want to naively pick a crate that does what I need, but find out a few months later that there's another crate that does exactly the same job but faster and better. Of course, as it stands, it looks like there are not a lot of mature options in the space yet, so I don't think I'll have buyer's remorse at any point in the future :)
It's not about machine parsing. It's about cognition and learning complexity. While it's true that it's probably no more special than `?` to the parser, I've poked at quite a few mainstream or aspiring-to-be-mainstream languages and I have yet to see a construct like that. By comparison, a trailing `?`, not separated by a space, has already shown up in various other languages. (I first encountered it in CoffeeScript.)
I don't want to sound mean, but comments like this are why I don't participate in such Rust discussions. If I don't manage to read and internalize all the prior discussion I'll get told off by a core team member.
My personal Rust onboarding story is that last year we had a developer from Rust team (I forgot the name sorry) coming to our university to give a talk on Rust. I was fascinated by its distinct features like ownership, concurrency, memory safety, etc because I'm a PhD student in systems and these features are much needed for systems language. Equally important has been its resemblance to C/C++. If it cannot do functional programming well, I will forgive it and still love it because of aforementioned features. But it's a little sad that with `await` syntax, some team members are apparently putting functional ahead of systems.
AFAIK, the Coroutine TS may be going into C++20, fingers crossed. The final opportunity for it to be voted in is in Kona, next month. The Coroutine TS has semi-working MVP implementation in Clang and MSVC, although they both have compilation issues, including crashes and stupidly long compilation times. It's also very bare-bones and is primarily meant for library developers - getting some async code written takes a significant amount of boilerplate. Having used both the Coroutine TS and nightly Rust, IMO Rust is currently in much better shape. C++ generally acknowledges that it needs coroutines/resumable functions very soon but there's still a lot of question marks around 'when' and 'how'.
Me too, just wait until you type await for the umpteenth time people, you‚Äôre going to want @ postfix!
Post should be removed.
Oh wow, that one is similar. Well, this is just the kind of feedback I'm looking for. So AFAICT BitArraySet does Hash,PartialEq,Eq,Clone but doesn't implement Copy? Is that because it doesn't make sense for this type for some reason? The underlying `BitArray` seems good, too. It doesn't implement Copy either. I suppose the idiom should be that Copy is only for primitives and small structs? Can you help me understand the feature gap? What does `BitArraySet` do that `StaticBitSet` doesn't? I see several `from_*` methods, those look convenient. And different ways to iterate. But what kind of representation does `BitArray` use? Does `BitArraySet::&lt;u32, U8&gt;::new` use heap allocations or do those only happen w/things like `Box`/`Rc`? With the `Clone` implementation does it end up doing something like a memcpy spanning the elements? Or a loop over elementwise copies? Or something else? I don't see a need for `staticbitset` if `bitarray` and/or `bitarray-set` already do what I want. I guess I just want to understand whether that's the case. `StaticBitSet` depends on nightly (boo!) but it's `no_std` so that's nice. If I can't get `BitArray` to do what I need then I will probably give `typenum` a try too.
Out of a-bit-more-than-curiosity, why do you want this?
Yeah but Rust gets the chance to do it differently, so they want to make sure that the decision made is the best possible for the time and people involved (also forward compatibility, ofc)
Yeah, it's definitely hard to read 1000 comments in order to participate. I think conversations like \`await\` are frustrating in particular because they're things that are really easy to have an opinion on, and very few people's opinions are significantly more informed than others. There are some examples that can help make the decision easier, and some general language principles to consider, but in the end it's a matter of preference. &amp;#x200B; By contrast, there are a lot of RFCs and tracking issues that have received \*zero\* comments for months, and that are really just waiting for someone with a strong voice and a willingness to do some consensus-building to help move things forward. These are often ones that are a bit tougher to have an opinion on, as they require understanding more detailed design decisions than "should \`await\` go before or after the identifier". &amp;#x200B; In the end though, I really appreciate all the valuable feedback we get from the community. Rust wouldn't be half as good of a language without the wide range of technically-diverse input we have.
Also, with some contributors clearly have preference for one solution, how can individual commenters debate with them? We only have one person, but many contributors can argue with me.
Can you say what gave you the impression we were de-prioritizing systems programming in our design of \`await\`? I'm one of the people who is most involved (if not the most involved) in the day-to-day of \`futures\` and Rust's async/await, and my day job is using all that good stuff to build an operating system at Google. I'm curious about the impression that \`await\` isn't built for systems programmers.
\`await!\`-as-a-macro actually relies on \*turning off\* \`await\`-as-a-keyword today. There are some hacky ways around this if we wanted to do it, but I think we're all eager to settle on the best syntax for \`await\` now (or soon, at least) so that we don't have to live to fight this fight another day ;) In any case, we'll have had at least two if not three different syntaxes for \`await\` available on nightly before anything stabilizes, so we'll have plenty of chance to try things out and see what works for people.
Hey! lang team folk here-- yeah, github votes are kinda dumb-- I'm personally one of the folks who wishes we could just remove them altogether. Still, I think they're a nice way to encourage folks who brought new and interesting points to the thread (which takes a lot of work on a conversation as bike-shed-y as this one). &amp;#x200B; As for your other points (1) and (2), I definitely try my best to listen to folks and respond to their ideas. Feel free to message me on Discord, Zulip, or here on Reddit if you think there's something I missed or if there was something I didn't respond appropriately to. I've personally been kind of checked out of that whole thread in particular for the last few days since it's been so busy, and a lot of people are reiterating the same thoughts, but I'll definitely make sure to give it a more comprehensive read-through before making any kind of decision here, and I leave my thoughts on the thread just like everybody else.
yeah, they do-- it's definitely unfortunate that "the obvious thing" from every other language doesn't work well for us because those other languages basically all use exceptions for error handling rather than explicit error propagation with \`?\`. This kind of messes everything up because \`await future?\` is really unclear-- you want it to behave like \`(await future)?\` most commonly, but the precedence there looks all backwards and doesn't mesh well with other operations.
Good luck with the candidate search!
\`@\` is already used in rust to bind a name to a pattern, like in \`match ... { x @ Some(\_) =&gt; { ... }, ... }\`. These two uses obviously have nothing to do with one another, so that's both a blessing and a curse ;) &amp;#x200B; As for the rest of the keyboard worth of symbols, I personally prefer a keyword since it's easier to Google search for and learn about. It also does less to spend our overall "weirdness budget" for people coming from other languages. There's only a certain amount of funky symbols and stuff that people will tolerate before their eyes glaze over :). \`await\` also has solid precedents in a number of other languages, which make it easier to understand and pick up for folks who've seen \`async\`/\`await\` code before.
It's not the same thing other languages do, that's for sure. Do you happen to have any examples of code that you think look much less clear with a postfix-oriented \` await\`/\`.await\`/\`.await!()\` syntax? I'm personally a big fan of postfix-over-prefix as I've written a bunch of futures code that looked kinda ugly or had weird line-wrapping due to the current \`await!(...)\` syntax.
&gt; &gt; &gt; The underlying BitArray seems good, too. It doesn't implement Copy either. I suppose the idiom should be that Copy is only for primitives and small structs? I think it's better that anything that can be `Copy` to implement it, provided you guarantee that future versions of the crate will implement it (adding `Copy` isn't a breaking change but removing it is)
I personally doubt we'll get much more information that would help inform the decision post-stabilization than we do now. There're already a number of pretty large codebases (Fuchsia, my job, included) that use \`await!\` all over the place and have lots of examples showing the relative benefits and discomforts of each syntax.
\&gt; **cannot reach consensus** &amp;#x200B; Oh hush now, we'll get it sorted out ;) &amp;#x200B; It'll take some time to hear everyone's thoughts, and it's a tough thing to talk through given how subjective the topic is, but eventually we'll all grudgingly accept something and move on. ;)
This. Just keep await!(future) macro, and then, if needed, add future@ syntax, same as try! and ?
This is what happens when you haven't polling and emoticons don't count. You have to fllood with similiar comments just to support opinion of someone else.
Heh, it's probably release jitters ... I just fixed a couple of critical bugs, so let's mark this off as a 0.1.1 release, which was just made. It fixes a couple of critical bugs, which deals with config items not being set. Found 'em in the test app and squashed them quickly!
@ is already in Rust it's been around since before 1.0. You're not adding anything new.
Well, rust has an async story, so that's already better than c++...
The code seems nice; just some small things: - For the TODO/FIXME about `staticarray!(256)` having length 9 instead of 8, you might be able to round up the result without rounding up an exact division like `256 / 32` using something like `($bits + BLOCK_SIZE_BITS - 1) / BLOCK_SIZE_BITS`: https://stackoverflow.com/a/17974/1256624 - For `count_ones`, there's [a builtin `count_ones` method](https://doc.rust-lang.org/std/primitive.u32.html#method.count_ones) on integers, so it could potentially look something like `self.bit_blocks.as_slice().iter().map(|x| x.count_ones()).sum()` - For `is_disjoint`, it could also potentially be written with iterator adaptors, starting with [`zip`](https://doc.rust-lang.org/core/iter/trait.Iterator.html#method.zip) to work with the two sets of bits together: `self_slice.iter().zip(other_slice).all(|(x, y)| *x &amp; *y == 0)`, where `self_slice = self.bit_blocks.as_slice()` and similarly for `other_slice` (a function `fn blocks_slice(&amp;self) -&gt; &amp;[BlockElt]` might be a helpful convenience to make these a bit shorter)
Yeah but it's *one* symbol, and not even a new one, it's currently used to bind names in patterns.
Two things I look for immediately in a crate: Docs (preferably on docs.rs) and examples. It looks to me like your project has neither. From your description this sounds like something I would love to use but I have _no idea how to use it_.
You're adding new meaning to an existing symbol in a different context. It's even more confusing.
I didn't say it wasn't confusing. I was just responding to the person. It sounded like they did not know @ was a predefined symbol.
I can be highly opinionated and I'm not a PL guy. I guess I'm misunderstood and I definitely think async/await feature itself is great for systems programming. But w.r.t `await` syntax, I'm not a fan of postfix and would rather Rust stick to how C/C++ are doing with keyword, i.e. prefix form. I actually commented the below idea in the Github issue. To repeat, how Rust advertises itself is it's a systems language. So, I guess it should prioritize on how it could do things as well as C/C++/Java/etc. which all have first-class imperative style support. That's why I think it's not good to use functional / chaining to argue for a postfix syntax as some team members did in the Github issue. In other words, do imperative really well and then let's work on functional to solve some pain caused. In other words, functional programming can wait and is secondary. Doing it the other way, it would feel very unnatural and dissuasive for programmers/developers/researchers who are familiar with classical languages. Anyway, I still love Rust and we even use it in a graduate course to implement a simple memory allocator. Imagine learning Rust in two weeks' time and implement it. :) And I really understand how difficult this kind of decision can be. Guido van Rossum resigned because of assignment expr :=. I really hope consensus can be reached here.
Hey all, I wanted to share a mad science project of mine. This is a proof of concept to address a few frictions of mine: * when I program web assembly front end, I seriously don't want to see ANY javascript * as cool as wasm-bindgen and web-sys are, it's kind of heavy weight and confusing, and I wanted to see if there was some non-Rust specific way to expose web IDL much more easily than current offerings * I wanted to learn more about where web IDL and host bindings are going to evolve to and I hope I can do that with this project and create something useful for my own projects Right now I only autogenerate bindings for console, but I'd love to figure out the minimal web IDL connections to be able to do canvas drawing. If anyone out there knows ANYTHING about web assembly host bindings, i'd love to find more details out on anything that's "official"
The problem with `try!()` was that it didn't do all that `?` can do. Not that typing six characters exhausted programmers.
Yeah open source across the board is very clearly not a meritocracy because things often play out how you are describing. You straight up aren't going to be able to fix that in people. Maybe once we have some sort of ai smarter than us and proved to be non-biased making the decisions. IMO just let larger projects do their thing. Work on smaller projects with your acquaintances where you can make a larger impact. 
After seeing each argument being reiterated at least 3 times, I feel like I know quite a lot about all possible points of view. :D
Okay but how do you do a hard reset from the wrong end of a webcam...
I want the "obvious" prefix syntax with optional `{}`s, and a postfix macro `.await!()`. Having a postfix keyword does not "feel" rusty.
Shut up ! Do you learn Rust because of it's popularity ? If yes, go and f...k yourself.You should care about your skills not other's skills.
You have some serious problems, why do you need another name for Rust ?!? And why you are concerned about the name ?!?!? It is a popular and it is used in production in the moment od speaking so go and make your research ! 
&gt; What successful languages have changed their names after 1.0? Racket (used to be Scheme). I think that's it. The only language I know of that changed its name on account that users hated the name changed before 1.0 (Nimrod which became Nim). So not a common thing.
Done.
Not to support either side, but this isn't really a good argument. It's how feature creep is introduced. If every time someone wants a new feature, they say *it's just one symbol/name/etc* or *we are just giving it one more meaning,* eventually it becomes very muddled.
Using `future@await` for await, and `expr@try` for `?` would feel nice and consistent. But probably not an option given where we are with `?` already.
Like turning the power on and off? IoT power switch products surely exist that cater to just that :P I worked for an IoT company once and they had a few products using different protocols for lights, switches(power on/off, monitoring), locks, etc.. usual sort of things. When combined with something like openhab or node-red, they're pretty easy to setup and automate however you want.
Got it, thanks for explaining again! For me, the prefix/postfix thing isn't really very philosophical wrt being imperative vs. functional-- it's an imperative operator with side-effects whether `await` is before or after the expression. For me, the difference is just about that I've seen more code that reads more clearly to me when `await` comes after the expression.
https://doc.rust-lang.org/std/fmt/struct.Formatter.html See functions: fill, width, alignment, signplus, alternate, 
ROASTED
We type await all the time in JavaScript.
Super minor nitpick here (sorry). I don't think semirings originated in set theory. I'm pretty sure they came about from algebra (more specifically, they are a central concept of what people call "modern algebra" or "abstract algebra"). I'm not the most well versed in the history of mathematics, but I'm pretty sure set theory originated as a way to put mathematics on a rigorous foundation and really has to do with giving a semantics to familiar mathematical objects and the steps taken in proofs. Whereas, algebra is more interested in the consequences of structures that naturally occur. If I'm mistaken, then please provide a source as I would love to know for sure how these concepts originated.
Do you have some links to to code examples in large code bases that would look great with postfix `await`. That could be interesting to read.
AFK right now, but I'll post some examples in the GitHub thread later for sure!
It appears the project prefers Go. Which is a valid choice for them to make. Let's not descend into language bashing, please.
Thank you that could be interesting to read. BTW: This [https://github.com/rust-lang/rust/issues/57640#issuecomment-457811283](comment) links to two code examples
Sorry, to me it sounded like you were sying "it's Ok to add it, because it's not a new symbol". Though, the way the discussion on the forum is going I'm finding myself leaning more and more towards `@` as postfix :D
Nice!
I guess I was right for opposing that stupid question mark operator all this time ;-)
Haha :) yeah, I can't pretend to justify that in a logically consistent way. I definitely like it better than try, but perhaps a postfix `.try` or something could have worked, who knows. However, one thing `?` has going for it is that it's (a) something you hit really early on, like day one Rust and (2) there are similar (though not quite the same) uses of `?` in some other languages. I think both of those make it easier to pick up than @/#/~/whatevs for `await`.
But await should be special. I think postfix @await will always appear special and will guide users into doing research If they don't understand It. https://github.com/rust-lang/rust/issues/57640#issuecomment-457457727
It's easy to bring up the argument that every language uses prefix but the other side is to question If It is correct to use prefix. Prefix await would require alot of parenthesis If you want to apply chaining. https://github.com/rust-lang/rust/issues/57640#issuecomment-457457727 
? Why are you upset and projecting onto my post? You didn‚Äôt ask what my values are, or why I care about rust, or what I believe about the value of mass adoption in terms of servicing the human species. Please refrain from asserting defensive statements onto someone who has taken the time to thoroughly maintain a difficult conversation and repeatedly admitted to the challenges thereof. No one wins when you express anger without articulating the source of that anger or respect another humans perspective. Computer programming is a tool of our social species. It‚Äôs not anyone personal thing. We only have life because of each other. 
Again asserting negatively without reading throughout the thread. I‚Äôve described my background and my reasoning. 
I have a question to [https://github.com/rust-lang/rust/issues/57640#issuecomment-457434201](https://github.com/rust-lang/rust/issues/57640#issuecomment-457434201). @[cenwangumass](https://github.com/cenwangumass) proposed explicit implicit await. Does anyone has any comment? Especially from the core team?
Just like `return` or `break` or `continue` or any other control flow looks special because it uses a symbol?
The moment someone works out how to work out who has the most merit or even what merit actually is we can work out a meritocracy. It's kind of hard otherwise. As far as I can tell the definition of a meritocracy is a system wherein the speaker gets what they think they deserve. 
First off, thank you for the detailed answer. This part of the application is handling data casting. These casting operations are not necessarily across datatypes (e.g. `f32` to `u32`) but also within datatypes (e.g. `u32` to `u32`). An example for the latter is [Caesars cipher](https://en.wikipedia.org/wiki/Caesar_cipher). Because of this, naming it "casting" might not be appropiate but it is close enough. The `Trait` operations in these example provide different types of casting operations like the ones I described just now. `TraitA` might define casting operations between between data types and `TraitB` defines casting operations within data types. The user defines an input file with its original dataformat and chooses which casting operations should be applied. For now I defined four traits dealing with different scenarios. Therefore the use can choose between four methods. Here was my problem. I had to choose at runtime which of the casting operations I have to apply to the data. I am unsure if this problem is considered to be depended on compile-time data. I know in which dataformat the file of the user will be and I am "just" applying casting operations on it. But the filesize of the input from the user might be of several GiBs and applied on collections of several TiB. The bottleneck for sure will be IO, but it should still run as fast as possible...
If we invent new syntax like postfix macros or magic fields for this use case, shouldn't it be proposed in a separate RFC first?
Dunno about C++, but Rust‚Äôs async story is not very good right now. The libraries are setting a good platform for things to grow, but so far it seems to me that there‚Äôs not much anything else than the platform. I attempted to write a GRPC service recently, and every grpc library afaik is wrapped around tokio. I found no way to do such simple things like attach database connections to my request handlers. Once async/await stuff gets stabilized, perhaps things will get better. I‚Äôll be doing my async/net things on Go, where I can get things done, but will be watching how Rust progresses with this ‚Äî I‚Äôd much rather use it. 
In the future, when postfix/method-style macros are added to the language anyway, people will be able to trivially implement the postfix await themselves. But the prefix syntax _is_ a compromise - it doesn't compose nicely, or chain with error handling, so "experienced" rustaceans will switch to the postfix macro. Then we have a keyword in the language that is only used by newbies. Waiting for postfix macros, and implementing await based on that gets us to the same position, but without a potentially redundant/confusing keyword. If we find that we still want the keyword at that point, it could be added later. Anyway, that's why I'm in the "postfix party"!
Alright - that makes sense. Since you're dealing with a lot of data and it seems like speed could be more important than code size and a bit of code complexity, I think going full generics could make sense. When rust compiles a generic function, it will "monomorphize" the function and create one copy per type used in it. This makes the code fast, but can drastically increase your binary's size. If you want all the code to be monomorphized / specialized to run with the different types, you want all of it in generic functions. Using `Box&lt;dyn Trait&gt;` or an enum will both introduce some overhead, because it avoids monomorphization. If you want to take full advantage of this code specialization / genericness, you want to "split" the call graph as soon as possible. Then, once you've split into cases with the different traits, _you can't rejoin and enter the same non-generic code path again_. Doing so would require either `dyn Trait` or some other way for all the data types to be put into the same variable. For example, take your earlier code: fn choose_first(val: &amp;str) -&gt; Box&lt;TraitA&gt; { match val { "a" =&gt; return Box::new(StructA), "b" =&gt; return Box::new(StructC), _ =&gt; panic!("Wrong input") } } // point 0 let first = choose_first("a"); // point 1 let result = calculate::&lt;first, StructB&gt;(21u8); At "point 0", there's on code path with no monomorphization. In choose_first, you split on different types. Then at "point 1", you've stored all these different types in a variable and thus you're forcing yourself to be non-generic. The solution is to never return generic data from a generic context into a non-generic context. fn use_first_choice&lt;T: TraitA&gt;() { let first = choose_first("a"); let result = calculate::&lt;first, StructB&gt;(21u8); println!("{}", result); } fn choose_first(val: &amp;str) -&gt; Box&lt;TraitA&gt; { match val { "a" =&gt; use_first_choice::&lt;StructA&gt;(), "b" =&gt; use_first_choice::&lt;StructC&gt;(), _ =&gt; panic!("Wrong input") } } Now, instead of trying to "rejoin" the different generic paths into one function and thus require all the different types to be stored in the same variable, this calls deeper into generic functions. With this new code, the resulting binary has (at least) two copies of `use_first_choice`. One for `StructA`, one for `StructC`. After calling into `use_first_choice`, you'll need to just continue calling functions generic over `TraitA`. This way, you never have to store "what type is used". Storing that in a variable will force the compiler to have some kind of dynamic dispatch. But if it's only ever passed as a generic argument, the compiler can resolve it all at compile time, and optimize knowing exactly what functions on what types are called in which branches. If you use this strategy, your binary size will explode, but you'll get a fully optimized code path for every type combination. It's like making a bunch of different functions, one for each `T,U` combo, and then choosing which one to call based on user input. You can "know" what the types are at compile time, and just choose which one is right when called. I wouldn't recommend it in smaller applications because of the code bloat and the awkwardness of not being able to store the type in a variable, but if you want the fastest speed this is what will give you that. I feel super ineffective at communicating this, so apologize if that's a bit of a ramble. I have a kind of intuitive understanding of this, but I've not formally explained it well before. If I can expand on any part here, please ask?
&gt; I think we're all eager to settle on the best syntax for `await` now (or soon, at least) so that we don't have to live to fight this fight another day ;) &gt; IMO `future.await!()` **is** the best syntax. 
As the tie breaking vote, I choose prefix
Just seeing this for the first time, it doesn't feel very Rusty to have this kind of magic auto code insertion, even if it's locally opt-in. Also, the exact placement of await is semantically important - futures are valid objects to pass around sometimes, without wanting to wait for them to complete. I don't think it could work to have it applied automatically because of nuances in _exactly_ what you want to happen when multiple futures are around.
Symbols are ungooglable
&gt; I don't think there is a chance that consensus will be ever made. There doesn't need to be consensus. Just a decision. 
I just have written the enum version of the above algorithm ([Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=86ec39e8b1097096176a514a59ca0898)). It looks more coherent, but I dunno if it is better performing. This might be a good benchmarking opportunity since I (will) have both implementations. // enum version enum Match { A, B, } impl TraitA for Match { fn something(&amp;self, val: u8) -&gt; u8 { match self { Match::A =&gt; val, Match::B =&gt; val + 2 } } } fn choose_enum(val: &amp;str) -&gt; Match { match val { "a" =&gt; return Match::A, "b" =&gt; return Match::B, _ =&gt; panic!("Wrong input") } }
Only if postfix macro is a standard thing that can be declared with macro_rules! and procedural way.
Yes, absolutely.
ECMAScript!
...And those companies usually fail. Especially distributed teams spread over several continents/timezones. Been there, done that, won't go back.
"Experienced" async code writers don't care about chaining that much. As someone who wrote async code in Scala for 2+ years, the block style `await { }` is already plenty sufficient, and the use case for chaining is extremely overhyped and in practice is not that useful.
I read through 200 comments on there. It's not that absurd. It took me about 20 minutes. And what I noticed was a disproportionate minority racking up tens of comments. If you did a histogram, you'd probably find that the number of participants in 200+ comments is less than 100.
See, I consider myself near-expert level at Rust, with well over a hundred thousand lines of code written over the years, and I find prefix `await` so much more natural, clean and readable, to the point I'll probably just stick to raw futures if something else is settled on. Calling one syntax "for newbies" feels like an unnecessary attack. However, yes, I do think prefix keyword along with a postfix macro would be the ideal compromise.
Yeah, I do not feel that magic fields, magic methods, or postfix macros is the way to go. A sigil like ‚Äòfoo@‚Äò is also not likely since adding a new sigil is a huge deal. That leaves us with two options: prefix await operator `await foo` or postfix await operator ‚Äòfoo await‚Äò Prefix await, in my opion, is the best solution. It is in line with the other async languages, it is line with other operator (break, yield, continue) and clearly shows all await points in code because they line up. The disadvantages is the unfortunate interaction with ‚Äò?‚Äò where ‚Äòawait thing()?‚Äò does not do what you expect. This could be solved by an additional ‚Äòawait? thing()‚Äò syntax which could be interpreted as one operation (the await-and-propagate operator). Perhapse in the future, either a postfix sigil operator or postfix macro could be added to accomodate those who enjoy chaining.
Why can't we have both? We already have prefix `for` and postfix `foreach`.
Maybe orbital (orbtk) from the redox os project. Not sure if it runs without sdl2 etc.
I'd like to challenge you to show me the last bit of async code you wrote that would be better with chaining. That's my biggest issue with all these people suggesting that chaining would somehow magically be improved with a postfix syntax: it really doesn't improve things that much, if at all, and potentially has more downsides considering you're changing the entire meaning of the control flow in the middle of chaining things.
I think part of why this solution seems unappealing is the experience with pre-1.0 sigils. There's pretty complete consensus that sigils were a bad idea, and I would be very hesitant to start adding new ones again. `?` is somewhat of a special case because it's meaning as punctuation maps relatively well to it's actual meaning in the language. It was also added *after* people used a more explicit syntax. I think it would be a serious mistake to add `@`, but not `await!` for that reason.
Rust only supports that kind of array initialization with Copy types. Technically, all you would need to do would be to add an additional Copy bounds on dyn Object. However, since you want to allow structs which may not implement copy, I would recommend reading (here)[https://www.joshmcguigan.com/blog/array-initialization-rust/] and (here)[https://stackoverflow.com/questions/28656387/initialize-a-large-fixed-size-array-with-non-copy-types]. Here is a link to the (RFC)[https://github.com/rust-lang/rfcs/pull/2203] describing the (unimplemented) solution.
http://areweguiyet.com/
The error occurs because the array initialization syntax requires the element to be Copy (as it will be copied over and over again) while Box never implements Copy even if the underlying type does, because creating it is never a trivial copy and always involves a heap allocation. 
I didn't get to ask in the other thread, but you mentioned pushrod to be an alternative to conrod, without expanding on what you mean by that. I have no idea about GUI libraries and approaches, so I'd be curious that you meant.
Thanks for you answer and for links! I want to implement Copy trait, but i don't know how! Because i already implemented it to all of my structs, but compilator still asking me to implement Copy trait to `std::boxed::Box&lt;(dyn Object + 'static)&gt;` So, what i should do to implement Copy trait to that thing? Again thanks for you answer.
Check out https://crates.io/crates/cargo-lichking.
Yup, I was mistaken. Box can't be made Copy. AFAIK, you're probably going to have to initialize the array with some of the workarounds and use the link in the edit to access to Clone on the trait objects.
Thanks for you answer.
Got it! Again thank you for you answer!
You could also try using a vector instead of an array for your stuff, as arrays have some ergonomics issues and vecs give you additional flexibility should you need it. The vec! macro to create them also works well with Clone types.
I'm want try to create simple rougelike game and when i thinking about what to choose - i prefer to use arrays because i can easily check what, for example, standing on right of my player just by checking the array\[position.x+1\]\[position.y\]. And also - thank you for you answer! =)
Oh, and this might be useful to you: [serializing trait objects with Serde](https://github.com/dtolnay/typetag).
Rust has already built its own positive associations with the name for very many devs (e.g. #1 most loved language). That it may also be an oxide or a fungus is neither here nor there. As a more extreme example, "git" is an insult in British English, something along the lines of "bastard", and that hasn't harmed its adoption: "the 'bastard' version control system" doesn't have such a ring to it somehow. But our brains are quite good at separating meanings by domain.
Thanks!
As someone building something similar (Rust on home routers) You may be interested in [compressed log](https://github.com/althea-mesh/compressed_log) which we use for logging aggregation. I also have to say that co-location reduces the challenges for the managers, but the cost effectiveness and talent reach of a distributed team can simply not be matched. 
I understand the sentiment, however I'd turn it around: *Anything that you write will have to be read by anyone wishing to participate, so do make sure it adds value!* As far as I am concerned, the bigger the audience, the higher the threshold for speaking up, both in form and content.
Actually, the fact that it's already used for something else is **even worse** from a discoverability point of view. Not only is search for `@` on Google a nightmare, but if by chance you manage it and land on the page describing binding names in patterns... then you'll be utterly confused as to its usage outside of patterns. Reusing keywords/symbols for different purposes is a mistake; see C++ `static` / `&amp;` for examples.
See sibling. 
I'd rather not have more sigils, or more use of existing sigils, in the language. Sigils are hard for discoverability. @ is already used today, go ahead and Google `Rust @`: the `@` is ignored, and you land on generic Rust (programming language or game) pages. Rust already has a number of difficult concepts to learn, adding undiscoverable sigils to the mix increases the complexity of the language, so it should really have a high bar. Reusing sigils is even worse, in a sense. If you somehow manage to hunt down a page talking about `@` in Rust, chances are you'll find one discussing pattern bindings. Wait, how is `future@await` a pattern binding? Where is the pattern? That's very confusing, really. *Of course, one could argue that you could search `@await`, `await`, etc... but this won't help those who picked the wrong alternative.*
I‚Äôm among for linux and MacOS platforms 
thanks you, this is what i need
I thing /u/razrfalcon has provided a good link that keeps track of the current gui-state in rust. Afaik, orb is the only lib that is (mostly) written in pure rust. All other framworks are bindings / wrappers to libs written in C(++) like GTK, SDL2, QT of different abstraction levels. If any of these, then it'll be orbtk that will, in the future, be fully written in rust. It's a long way to go I believe. It can be compiled for Windows, Linux and Mac.
As someone who has worked with Yocto, I'm going to recommend keeping your hands off the distro itself as much as possible. It's a massive time suck. Seemingly trivial things can take days or weeks to accomplish. My suggestion is to get your base disro to a bare minimum state where it can run containers and then build your app as a container. There's a few projects out there looking to bring containers to embedded Linux. Resin is one and Azure IOT Edge looks very promising too. Azure is also working on a system on a module to go with it. I think it's still in beta though. 
Not sure why you were downvoted. There‚Äôs never going to be a consensus about bikeshed things like this, it‚Äôs simply too strong a requirement for decisionmaking.
This is what bikeshedding looks like.
I'm making a [fetch](https://github.com/FriedPandaFries/fetch) program that's like neofetch but written in rust rather than bash. I'm going to use it in another program I'm making called [oracle](https://github.com/FriedPandaFries/oracle). Oracle's function is to make it much easier to be a distro hopper. From the command line it can find all of your iso/img files and all of your USB's and install them for you. It also can download them from the internet. Oracle also display information about the distro you are about to install before you do it and for some extra eye candy it launches neofetch as soon as you run oracle. I have a short video in it's github if you're curious. But I don't like the idea of requiring someone to install neofetch to use oracle 100% and I also don't like using external processes in rust (it feels like a cop out) so I'm doing my best to implement both programs with as little of these as possible.
Not going to lie. Names matter to me and Rust has a great name and logo. It reminds me of the fact that everything's going to rust and decay and we need to engineer and maintain things with that in mind. It doesn't evoke images of foolish grandiosity that will eventually lead to a fall.
Poetry. That really spoke to me. Maybe you alone could make the change I want to see by sharing this message with others who, to be honest, think more like computers than humans. Names of tools do matter. They carry emotions and stories and visions within them. Perhaps rust is about not letting it rust, or not letting the fungus decompose, it‚Äôs a reminder that rust is inevitable for unused, unmaintained structures and with Rust‚Äôs amazing compiler built for safety, we can use it to create and maintain safe utilities on the global web depended upon by all. That said, I‚Äôm curious to see what happens when the coder playing field is 50/50 between men and women. It‚Äôs a very masculine logo and name. Partially why Go has more women I believe is their ‚Äúlook‚Äù. The women of rust could perhaps be a new Rosey the riveter.... 
What about this syntax: (await thing())?
Rust is a resilient parasitic disease spread by wind and water? Huh. Explains the growth rates and FFI success stories.
A string literal in `write!` will always be taken literally. You can call `fmt` directly on a string to achieve what you want: Example::One =&gt; "1".fmt(f)
Awesome thank you! It worked for me on arch linux. I'm going to try running through a few distros in a vm and see if the results are consistent and see what happens when it's run through ssh and tmux if not I'll probably try looking at all running processes and look for running emulators. Thank you for your help!
Indeed, I stated multiple times in the issues that "await chaining" is a code smell, and simply does not improve anything. Programs don't get faster the fewer lines you have, only harder to debug. We shouldn't be encouraging that at all. I would hate to debug some of the errors that will come from those single-line await chains. Like, if we thought futures now were difficult... Also, if prefix keyword `await` took the next expression as its value, `await {}` could probably work without any special changes, as `{ expr }` is also an expression.
Maybe azul? azul.rs 
seems difficult because GUI's are tied to platforms and their choice of language &amp;#x200B; windows - win32 C api -&gt; C++ MFC-&gt; C# .. apple - objective-C -&gt; Swift ... Android platform - JVM 'cross platform C++' - Qt &amp;#x200B; you ask 'native/rust' which means you probably want something rendering it's own gui , not just interfacing to platforms via a rust wrapper ? &amp;#x200B; rusts natural constructs are just different. &amp;#x200B; I'm not sure Rust is a particularly nice language for gui applications anyway (things like C#,swift are designed with tradeoffs for application code) .. but it would be interesting to see what other people say.
organize yourself and find the correct subreddit for your concern.
You get a original name Rust is a name for a game not for this shitty i dont even know wtf is this
Then again, the `Try` trait *still* hasn't been stabilized... so `?` barely does anything new.
The rust programming language has been around longer than the rust video game.
Or the order of precendece could be changed. What are the arguments against that? 
nope, this is still not r/playrust do you guys just... blindly make posts and hope for the best? I'm curious as to how this keeps happening
Technically, original name Rust is a name for that layer thing you get on old metal.
good bot ;-)
You have to mention your platform! Statistically speaking- you're probably asking for windows. In which case there is an amazingly well-working win32 crate 
SDL2 is required on other platforms, for now, until it can be replaced with a newer client renderer.
That is also fine. However, consider that nearly every instance of await involves some error condition. The original Future trait even had an Err type built in since it is so common for asynchrouns code to return an error. `await`and `?`are thus very likely to be used together. It would be nice if there was a way to reduce the number of parentheses for the common case.
Writing a UI directly against Win32 is a fate undeserved even by your worst enemy.
It's totally possible to rewrite the Rust game using Rust programming language. However it's impossible the other way round. What delicious irony that would be if it really did happen! üòÇ
Perhaps the name changed so long ago that I don't recall but I can't remember a time that it wasn't called Javascript. 
Perhaps I should have used a more precise term than just successful. Do you have examples of languages more successful than Rust changing their name?
I agree. If the name is the tipping point for a project or product then I imagine the thing was iffy already. People can joke and talk about a name but in the end it needs *a name* and someone made that decision. It's everything that comes after the name that makes or breaks it.
Hey man, that's really nice of you. I am pretty sure you meant to go to this subreddit, though: https://www.reddit.com/r/playrust/
I think you're looking for /r/playrust
oh sry my bad :D
IIRC, `BitArray` doesn't implement `Copy` because I couldn't figure out how to get the type system to accept `Copy`. I'm sure it's possible, but I gave up after a few days. `BitArray` depends on [typenum](https://github.com/paholg/typenum) and [generic-array](https://github.com/fizyk20/generic-array). Together they create support for a generic, compile time sized array by gloriously abusing the type system. At the time I wrote this library language const functions and integer generics were a long way away.^^^but ^^^sooooooonish I believe `Clone` is implemented by [iterating the generic-array](https://github.com/fizyk20/generic-array/blob/master/src/lib.rs#L546). They work great, but come with a pretty hefty cost when it comes to development time. For example, to calculate the necessary storage size for a particular number of bits I needed to do a compile time [calculation](https://github.com/ambaxter/bit-array/blob/master/src/lib.rs#L193). storage: GenericArray&lt;B, // based on the calculation `(nbits + U32_BITS - 1) / 32::BITS` in bit-vec Quot&lt; Sub1&lt;Sum&lt;NBits, BitsInOut&lt;B&gt;&gt;&gt; ,BitsInOut&lt;B&gt; &gt; &gt;, That's not too bad, but it means that every declaration and its dog needs the following where clause: where NBits: Add&lt;&lt;B as BitsIn&gt;::Output&gt;, &lt;NBits as Add&lt;&lt;B as BitsIn&gt;::Output&gt;&gt;::Output: Sub&lt;typenum::B1&gt;, &lt;&lt;NBits as Add&lt;&lt;B as BitsIn&gt;::Output&gt;&gt;::Output as Sub&lt;typenum::B1&gt;&gt;::Output: Div&lt;&lt;B as BitsIn&gt;::Output&gt;, &lt;&lt;&lt;NBits as Add&lt;&lt;B as BitsIn&gt;::Output&gt;&gt;::Output as Sub&lt;typenum::B1&gt;&gt;::Output as Div&lt;&lt;B as BitsIn&gt;::Output&gt;&gt;::Output: generic_array::ArrayLength&lt;B&gt; That also means that anything else that would also like to generically declare the bit size needs that where clause. The type requirements eventually became enough of a burden that I gave up doing further work on the library in my spare time. Any changes in the type required updating a bunch of locations across the library. I made a mess more than once :D Keep at it! There's nothing wrong with depending on nightly for features that aren't done yet. There's also nothing wrong with having competing libraries. Personally, `BitArray` and `BitArraySet` are a bit of a dead end for now. I doubt I'll be touching them again until integer generics are done. Please feel free to copy code you find useful. Heck, most of my code was copied from [bit-set](https://github.com/contain-rs/bit-set). Let me know if you have any questions and I'll be more than happy to help!
I AM DEFINITELY NOT OKAY WITH THE SPACED SYNTAX. Make it Scala or Kotlin style, not C# or python and the rest style.
Its only bikeshedding when people don't understand the semantics. 
There are plenty of old languages that target it though. I believe there are more targeting it compared to wasm.
In fact I remember only one language that was named to be easy to google, Clojure. Rich checked that it returned no result on Google before taking the name.
We just need one more question mark operator to sort this out... `¬øawait future?` vs `await ¬øfuture?` ;)
The official name is Ecmascript. This is the third name of the language (the first was Livescript). But it became so popular under Javascript that people keep calling it that. So super popular language that did go throug a name change well after 1.0. the name change itself was a failure. I love this satirical take on the name changes: &gt; 1995 - Brendan Eich reads up on every mistake ever made in designing a programming language, invents a few more, and creates LiveScript. Later, in an effort to cash in on the popularity of Java the language is renamed JavaScript. Later still, in an effort to cash in on the popularity of skin diseases the language is renamed ECMAScript. If you want to have some fun, check his take on the rest of the languages : http://james-iry.blogspot.com/2009/05/brief-incomplete-and-mostly-wrong.html
Yeah that's understandable. Though people reading the comments didn't read my follow up ü§∑‚Äç‚ôÇÔ∏è
[removed]
Why not have the CPU be in control here, and give it read/write access to the GPU, while the GPU just has a flag to indicate an interrupt that gets checked every emulated CPU cycle?
I think azul is pure rust until it gets down to the actual OS graphics apis, but I'm not 100% sure. 
Haha which is more popular fah
Probably yes. He might be asking for something like flutter which renders its own widgets. Having one wrapper for native platform GUIs would be very hard to achieve if not impossible IMO.
People chaining async code are not writing async code.
Postfix macro is the cleanest, least intrusive syntax proposed thus far.
There are niche IP KVM tools that do it, but you're right that remote work on physical hardware will require _someone_ to be present.
I'm convinced, open the RFC! ;)
Are you fully employed? What you do for a living comes with all kinds of constraints where as what you do as a hobby doesn't. Whatever community you're a part of here has no position on "distributed work". 
How does rust team make sure that their decision is truly good for the entire community not just for themselves? rust community is becoming larger and there can be times when the needs of the rust team members dont reflect what the community wants.
Awesome, thanks. For some reason I had convinced myself that zip wouldn't work here, so thanks for the tips.
Well this shed some light into the matter. Seems like I was on the right track anyway. In my case the binary size is irrelevant. The throughput \[bytes/sec\] of the application is top priority. I did not know that enums are actually preventing monomorphisation and that they generate overhead. But your suggestion would be to not use the function `fn calculate&lt;T: Trait A, U: Trait B, V: Trait C&gt;(val: u8) -&gt; u32` but to split it up into different "subfunctions" like `fn calculate_tmp&lt;A: TraitA&gt;(val: u8) -&gt; u8` and then `fn calculate_result&lt;B: TraitB&gt;(val: u8) -&gt; u32` assuming that `val` of `calculate_result` is the result of `calculate_tmp`. This would actually also prevent the `Box&lt;TraitA&gt;` in the above example ([Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9e0f45c4843bfd1cd6f5f27c959daefa)) Or am I wrong? &amp;#x200B;
My mental model for a rust gui is - a crate for efficient 2D graphics (batching, caching etc for maximal perf, Direct2D is good for inspiration) - a layout engine (e.g. like flutter) - assistive tech - a model for user interaction (callbacks, or something else) - a cross-platform window and input handling lib (‚ô° u winit) - a gui lib to bring everything together - all of this to be cross-platform (winit and gfx-hal) It's a long way off yet. I've tried making a d2d-like lib on top of vulkan/hal but it's hard!
I think the tech to do what you want almost certainly already exists, it's just not discoverable. Once the Lang features land in stable, there will be a huge push to sort out the ecosystem and its docs
What do you want to do? [Conrod](https://github.com/PistonDevelopers/conrod/) is game-focussed, [orbtk](https://github.com/redox-os/orbtk) for desktop-use.
As it stands, the library exists just as an extension of the Piston framework, with the ability to draw some UI elements on the screen as base elements. My best suggestion would be to look at the starting point "test_window.rs" ... it will at least give you an overview of how to set up a window, add a UI element, and start the event loop. I'll start adding documentation to it. Would it make sense to keep it all on docs.rs, or would it make sense to keep things in Github as well? I'm curious to hear what you think.
It's an alternative in that it's lighter weight, less code, easier to understand, and possibly easier to maintain (crossing fingers here.) I have years of experience with Atari ST GEM/AES/VDI, and I have had experience with Qt/KDE. I am taking the knowledge I gained from the use of both environments and trying to make a GUI framework that is easier to use. My point with a GUI is - I want to code, I don't want to have to worry about the GUI interaction. Set up the layout, write the app. This may help in the creation of an IDE for Rust, written in Rust!
Very cool! Just wanted to say, I'm with your CEO on this one. Currently working remotely and it's a pain in the ass reaching people sometimes. Good luck coordinating a quick response to a production issue with more than 2 people that are across time zones/continents. It sucks. I'm all for colocation.
That's why we need extrafix syntax: `aw { x } ait`
I'm trying to solve /r/dailyprogrammer [challenge #372](https://www.reddit.com/r/dailyprogrammer/comments/afxxca/20190114_challenge_372_easy_perfectly_balanced/) with Rust and as I'm finalizing it I wanted to print the example values using closures so I don't have to repeat myself. let print_f = |name: &amp;str, func: &amp;Fn(&amp;str) -&gt; bool| { |s: &amp;str| { println!("{}({}) =&gt; {}", name, s, func(s)); } }; // balanced and balanced_bonus both are fn(s: &amp;str) -&gt; bool let print_balanced = print_f("balanced", &amp;balanced::balanced); let print_balanced_bonus = print_f("balanced_bonus", &amp;balanced::balanced_bonus); print_balanced("xxxyyy"); // =&gt; true print_balanced_bonus("xxxyyyzzz"); // =&gt; true Unfortunately, it does not compile: error: borrowed data cannot be stored outside of its closure --&gt; src/main.rs:6:9 | 5 | let print_f = |name: &amp;str, func: &amp;Fn(&amp;str) -&gt; bool| { | ------------------------------------- ...because it cannot outlive this closure 6 | / |s: &amp;str| { 7 | | println!("{}({}) =&gt; {}", name, s, func(s)); 8 | | } | |_________^ cannot be stored outside of its closure ... 11 | let print_balanced_bonus = print_f("balanced_bonus", &amp;balanced::balanced_bonus); | -------------------- borrowed data cannot be stored into here... I googled a bit and found [this thread](https://stackoverflow.com/questions/26511472/returning-a-closure-with-mutable-environment) suggesting to put explicit `move` ahead of the inner closure arguments. However, it still does not work: error: borrowed data cannot be stored outside of its closure --&gt; src/main.rs:6:9 | 5 | let print_f = |name: &amp;str, func: &amp;Fn(&amp;str) -&gt; bool| { | ------------------------------------- ...because it cannot outlive this closure 6 | / move |s: &amp;str| { 7 | | println!("{}({}) =&gt; {}", name, s, func(s)); 8 | | } | |_________^ cannot be stored outside of its closure ... 11 | let print_balanced_bonus = print_f("balanced_bonus", &amp;balanced::balanced_bonus); | -------------------- borrowed data cannot be stored into here... I can't find enough docs on how to return closures from functions, or maybe I just don't understand what's written in the Rust book. Is there a way how to write the `print_f` function to use it to generate functions for printing ultimate results? I'm using stable rustc 1.32.0.
gtk-rs is "native" in a lot of Linux desktops. It works fine, but it gets pretty ugly. For that reason people are using relm as a more "idiomatic" GUI library
GUIs are hard. It's not helped that many OSes insist and almost mandate a language to be used (example Mac OS X).
I don't want to return to the era where people need to run gtk on Mac or Windows to make an application work, not to mention that gtk integrates with nothing on the OS and none of the standard keyboard shortcuts work either.
It's because programming language is so complex that not a random programming guy can understand. If it's like a project written in rust, if you dont seek consensus, we can easily fork it.
Oh this is a good one...
Seems like you are looking for /r/playrust
Also he teleported them back when they had timers because we outplayed them
You're in the wrong subreddit buddy. 
What sub should.it be in
It should be in the r/playrust. This is rust the language. 
Oops
Please respect rules 1, 3 and 4. Additionally, as other people have said, I believe you're looking for /r/playrust.
&gt; GUI's are tied to platforms and their choice of language Not really. Qt basically renders all its own widgets, as does Flutter and they both do a good job of feeling "native". Nobody writes apps using X11's "native" UI system, and few Windows apps still use the Win32 controls. 
It's less that I think we don't have the information to decide on a postfix syntax now, and more that I think that `await` isn't the only thing that would benefit from a postfix option (`break`, and `continue` in particular, but really all sorts of more domain-specific functions). But that I think async/await is more urgent than the time it would take for us to settle on and implement such a syntax. So I think we should go for an `await` syntax that is prefix (like all the other keywords in Rust), so as to leave the syntax space open for a general "use prefix operator in a postfix position" solution later when we do have the time to work through the design and implementation of such a feature.
\&gt; Qt basically renders all its own widgets, I would describe Qt as a C++ GUI - it' design is tied to C++, and it's been problematic making rust wrappers. not impossible, it's just ugly, because it's designed for C++'s specific tools. it's still different to native OSX apps &amp;#x200B; \&gt; Nobody writes apps using X11's "native" UI system X11 is a lower level; so we have Gtk and Qt written on top of it .. C and C++, with their own look and feel. &amp;#x200B; regarding windows, I haven't kept up with their specifics, but I know they first wrapped C++ MFC around C, and these days I am guessing they give UI libraries based on C# /CLR &amp;#x200B; So.. you could certainly write a Rust GUI library at the level of Qt over X11, but on windows/mac people like things to look like windows/mac apps. &amp;#x200B;
There are serious suggestions for an `await? future` syntax sugar...
Just await the consensus decision. #intended
You can either use a vector or a crate I've made some time ago, [`array-macro`](https://crates.io/crates/array-macro).
[Here](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0339accc3afb0accf8730cad781c4bff) is a solution.
I think `await {}` is clearly the most readable and explicit. It is more verbose and encourages proliferating temporary variables, but I believe this is a worthwhile tradeoff for clarity. It's also the most aesthetically pleasing as it doesn't add visual clutter to the syntax since expressions are already very common. However, if prefix await is untenable, I think it *has* to be a sigil of some sort, which pains me. `expr.await` is magic property access, which is confusing. `exp.await()` indicates action nicely but is confusing because awaiting is a method in any way. `expr await` is the worst of both worlds to me, incredibly ugly. Postfix macro would require a new generalized rfc... If I had to choose a sigil, I would choose `!`, as `expr!?` looks best as it's combining punctuation characters. `@` and `#` are exceeding ugly imo. I might be able to get used to `expr~?`.
Your `src/window_test.rs` is an example, you should call it that (that is, it goes in `examples/` not `src/`). I see you're calling it a test and trying to treat it as such but I wouldn't since it can't be run automatically. When I say I want docs, I mean that handwritten docstrings are really nice, but your crate doesn't even have a `Documentation` link to docs.rs on its `crates.io` page. Why?
I expressed similar concerns, for me, await is a way to break the chains that combinators introduce...
/r/playrust
To add onto that, C++ has `std::async` which is... honestly nobody knows, but I can certainly say it's not for async programming. I don't think there is a `futures` library for C++, like there is for Rust (even having to use higher-order functions like you have to do with Rust's `futures` would be something). That said, this may change with Coroutine TS, that may be (but doesn't necessarily have to) added in C++20.
Christ
Okay, I'll make appropriate changes and link the documentation to my Github page so it makes more sense. Lots of people downvoting - I'm guessing it's because there's no docs. I'll fix!
Um wrong sub
It looks like I'm in a sticky situation üò¨ reuploading soon 
Thanks! The compiler was suggesting to add static lifetimes when I experimented a bit with the code but it didn't make much sense to me. Now it kind of does.
The first example is actually invalid; you'll get a "cannot move out of borrowed context" or a type error I think, you need to return &amp;mut Self. Once you change that, they're both idiomatic. The second one might be slightly slower if the compiler doesn't optimize out the struct copies, especially if your builder struct is very large. That won't really be a problem though unless you're building a lot of things very fast.
It's not that there's a performance penalty; it's that, to be chainable/fluent, the return value of the builder methods needs to be the same as the type of `self` taken in the consuming method. That is, if `build` takes `self`, then all the methods should probably take self; whereas if `build` only takes a `&amp;mut self`, then the other methods should only take `&amp;mut self`. That said, my understanding is that the reason to default to `&amp;mut self` is that a method that takes `&amp;mut self` is more general than one that takes `self`, and we should make methods more general to support more use cases.
By "native", do you mean that it should wrap whatever the platform's native toolkit is so that it behaves like an app written specifically for that platform? Or do you mean something else, like a "pure Rust" toolkit (which is more or less the opposite goal)?
What is the state of the art for CI coverage reporting? I couldn't get taurpaulin to actually install, even with nightly and the flags specified. &amp;#x200B; When I use the \`kcov\` command as specified in the cargo kcov documentation, it sent invalid flags to kcov and errored out. &amp;#x200B; What's the best way to get code coverage working on travis currently?
You don't *have* to. It seems to me that a flood of similar comments will be treated the same way as emoticons or a poll, anyway. The point of RFCs is to gather information about the *design space*, not popular opinion- there's only so much weight that the popular-opinion signal can carry, regardless of how it's conveyed.
Man there should be a central areweblankyet. There‚Äôs a site for everything!
I don't _think_ that you'd need to return `&amp;mut Self`. [This code](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=72899fdf185fe19553ca351630d414cb)‚Äîwhich is a slightly expanded version of the same idea and returns `Self`‚Äîcompiles and runs. &gt; The second one also requires you to thread the struct through returns if you have functions that modify builders I'm not sure I understand what you meant by that. Could you elaborate a bit?
I asked a similar question about "function vs. imperative" in Rust a couple of years ago, and one of the answers was from Raph Levien: https://www.reddit.com/r/rust/comments/4mbpc6/is_there_an_idiomatic_style_guide_for_writing/d3uhflz/ Rust is not a functional programming language, and if you try to use it as one, you'll be working against the language (and against many libraries). I found that it was better to let functional programming to actual functional languages and use Rust the way it's meant to be used.
`&amp;mut` in Rust is not as non-functional as mutation in other languages, as the language's control over aliasing guarantees the mutation is local and isn't changing some far away state. A function `fn(&amp;mut T)` can essentially be thought of as an optimised version of `fn(T) -&gt; T`. The old style guide touches on when to use each style: https://doc.rust-lang.org/1.0.0/style/ownership/builders.html . The `&amp;mut` form is preferred when possible because that is most flexible for users of the builder.
For the *first* example you need &amp;mut self: [playground link](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b7a73f008e38203304967b6f9d1bb78b) and, imagine you have: fn configure_bananas(x: &amp;mut TreeBuilder) { ... } if the builder was in the functional style, you'd instead need: fn configure_bananas(x: TreeBuilder) -&gt; TreeBuilder { ... } which is fine, but it can get annoying: fn configure_farm(x: TreeBuilder, y: SoilBuilder, z: BreadBuilder) -&gt; (TreeBuilder, SoilBuilder, BreadBuilder) { ... } because otherwise there'd be no way to communicate the config changes out of the function.
Sometimes the thing you want to build from is situated somewhere where it can't be moved. You might be perfectly fine with building "in-place" by mutating the thing, but the functional style disallows it. ([playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=d89b55a99fcffed9cb24ce996dd55da0))
I assume you're compiling the rust code in release mode, correct? Have you tried turning on LTO? Since rand is in another crate that could maybe help.
Implementation issues aside, the Coroutines TS unfortunately has a very nasty API. It has *fifteen* separate things you need to override to implement something awaitable, and even with that many knobs and dials to turn it *still* requires a hidden allocation by default. This is a big part of why the proposal is still so controversial. Google has an alternative, "Core Coroutines", which is simultaneously simpler and more flexible. It has only three customization points (one that works like call/cc, one vaguely analogous to Rust's `Try` trait, and one analogous to Rust's tasks) and no hidden heap allocation. However, people are already so invested in the Coroutines TS that even these clear wins are insufficient to sway them, so I don't see any way for both sides to be happy with whatever result C++ gets at this point. (For context, Rust's async/await has... two customization points, depending on how you count? The `Future` trait with its `poll` method can be implemented manually when necessary, and each executor provides its own `Waker` implementation. This is nowhere near the flexibility of either the Coroutines TS or Core Coroutines, though, so it's not a great comparison.)
https://wiki.mozilla.org/Areweyet
I have a `u64`, and I need to convert it to a `usize`. I'd like the following behavior: * If this is compiled for &gt;= 64bit, it should be a simple `as` conversion * If it is compiled for &lt; 64bit, it should have a runtime check, so that if the number is small enough, it succeeds, otherwise returns an error (or at least panics). Is there a way to do that? I've read the `From` stuff and know about `as`, but I can't fully wrap my head around it. Or do I need to write my own function or method that compiles differently based on `usize`'s size (I assume that's available as a `cfg` somehow). Thanks for any pointers ;)
Messing around with bash, I came up with this solution, which seems to work (but is not necessarily guaranteed to work under all circumstances). It should be easy enough to turn into Rust code: ```bash pid=$PPID while true do for i in /proc/$pid/fd/* do if [ "$(readlink $i)" == "/dev/ptmx" ] then readlink /proc/$pid/exe exit fi done # parent pid=$(cut -d ' ' -f 4 /proc/30046/stat) done ```
glibc's `rand()` with default settings is literally just int32_t val = ((state[0] * 1103515245U) + 12345U) &amp; 0x7fffffff; state[0] = val; *result = val; That is, it's horribly dumb. You can probably reimplement that in Rust and get similar performance.
\`token::op::PLUS\` is used in a new submodule \`parse\`. Try moving the \`use crate::token\` into \`mod parse\`.
you seem to have an inline module parse in your parser.rs. You need to bring token into scope there, not in the parser.rs module around it.
Did you look through https://crates.rs/search?q=rng? At least Xorshift and Weakrand look like they might float your boat.
Screenshots help too. Some people won't bother cloning the repo and running the test if they don't have an idea of what it looks like.
You* (need to get used to my new keyboard haha)
&gt; and even with that many knobs and dials to turn it still requires a hidden allocation per coroutine. nit: the TS *allows* for an allocation of stack space for each coroutine, the janky pre-merge implementations of the TS take this liberty for ease of implementation
Yup, basically this. If you feel like your position has already been represented in the thread and is being heard, please don't spam "I also think this" comments. The Rust teams don't make decisions based on popular opinion. We make decisions based on which argument is stronger. I know this is can be frustrating, but we try hard to listen and respond to every argument on its merits, regardless of whether one person made the argument or whether 100 people did, so re-posting what others have said only makes life harder for everyone trying to participate in the discussion.
I did look for other options, but I didn't spot Weakrand. I will try that I think.
As I commented elsewhere, the number of people making an argument is ideally much less important than the merits of the argument. Now, that's a bit harder to judge on issues like this which basically boil down to subjective preferences, but don't be discouraged if lots of people disagree with you-- it's not like unpopular opinions have never won out before ;) (That said, don't just keep restating one point in order to make sure it's heard-- we read every comment, so posting the same opinion a dozen times just adds noise.)
Yep, this is a sticking point for me personally-- there are some good arguments against method-position macros (e.g. discoverability, conflicting with methods, etc.) and I don't want to choose this syntax if it isn't something that we make available to the language more generally.
Or maybe just use https://docs.rs/libc/0.2.48/libc/fn.rand.html. Seem like that will be faster than any "real" RNG by what /u/K900_ said...
I wasn't using release mode; I didn't know that existed. I still don't really know what it does (it just finishes very quickly without actually apparently doing anything), could you explain it or point me to some documentation? (I really cannot find any).
That is in deed the issue. I could reproduce the authors ~8s for `100_000_000` (with `SmallRng`) in debug mode. With release mode, I'm generating `1_000_000_000` in ~1s.
Whenever I need a non-crypto RNG I usually reach for [PCG RNG](http://www.pcg-random.org/) with some fixed seed. It looks like there's a good implementation on crates: https://crates.io/crates/rand_pcg
Here is some code from my project a game server for some ea games: get_cached_cfg(idx) .and_then(move |cfg| -&gt; ConfigFuture { match cfg { Some(cfg) =&gt; Box::new(ok(cfg)), None =&gt; Box::new(get_cfg(idx)), } }) .map(|cfg| ConfigPacket::new(cfg))
Using release mode compiles your code with optimisations (what `-O` does for C code, I believe). The book has some information: https://doc.rust-lang.org/book/ch01-03-hello-cargo.html#building-for-release
Since there is no side effect the compiler removes the code. You have to actually use the random data. You can use a fn black_box to avoid the optimization, there are some implementations around.
Thank you. Apparently I skipped over that bit, and it wasn't showing up in my searches.
Those two have different usecases, and for general purpose, you should just use `Vec` until a point where you find allocation from `Vec` takes significant part of time based on profiling. Actually at that point, you should probably still consider `Vec::with_capacity` first.
Regarding your first point: isn't that just another place where you'd need an extra copy, which comes back to a (minor) performance penalty? ([playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=17078cbbcb90e2c8b534c3d41924b6e2)) On the second point, I can see that concern. I will say that there are times when the builder pattern can be _really_ handy‚Äîfor example, it makes clap's API much easier to learn/use (https://github.com/clap-rs/clap/blob/master/examples/07_option_args.rs) 
Also codegen-units=1, I think. Getting this stuff inlined in release mode is really important. You may also want to try PCG: it should be faster than the generators you've listed, I think. (Unless it's "standard" now: I forget.) ' That said, none of the generators in the `rand` crate are particularly fast. I plan to oxidize my [`toyrand`](http://github.com/BartMassey/toyrand) C library sometime soon. It seems pretty suited to your use case, and should have pretty similar performance to your C code.
Here's [my version](http://github.com/BartMassey/phoenix-raytracer/blob/master/lib/frandom.rs) if you want to try it. Gross but fastish.
I don't think your comment really clarifies anything. The specification does not allow for zero-allocation coroutines, given that all coroutine instances with the same interface have the same type. This requires some sort of type erasure to be happening behind the scenes, which requires an allocation in general. In contrast, Rust generator instances are each their own type, which lets them be different sizes (which is necessary to preserve their arbitrarily-sized stack).
In the first example, did you perhaps intend to write pub fn name(mut self, name: String) -&gt; Self { self.name = name; self } ? Note that it takes a `mut self`, not a `&amp;mut self`. Regardless, I agree that the second one looks nicer!
Does LTO even make any difference in release mode?
Comparing await to return, break or continue is wrong IMO because they are totally different in various points: 1. Prefix await will not work nicely with the ?-Operator so Postifx Await is still on the table and can be easily overlooked If It looks like a simple function call(.await). Using a space is also easily overlooked. @await at the end is something I would not overlook and every user who is unfamiliar with It would notice It's special. 2. Await will actually return something. It's by far more similar to the ?-Operator. 3. Await is not just another control flow operator It's by far more complex than the existing one.
Using Vec from stdlib is best, unless you are using many many small arrays and allocations are limiting performance. Like you said, the difference between smallvec and arrayvec is that smallvec spills to the heap while arrayvec panics.
https://wiki.mozilla.org/Areweyet
But do we `await { consensus }` or `consensus.await()`? 
Yes, yes I did. Thanks for the correction! 
You can also just xor the variates together and print the result. Easier than using `black_box` and should give about the same performance.
What? Scheme still exists, it wasn't renamed. Racket is *a* Scheme but there are many others.
PLT Scheme if you prefer. You're being pedantic.
You want lto=fat for best performance. I think the default is lto=thin.
I suspect someone will give you a better answer, but you could always use C's rand function via the `libc` crate: https://docs.rs/libc/0.2.48/libc/fn.rand.html
Looks like `SmallRng` in `rand` is currently `PCG`.
I reproduce this roughly (1.7s). That is kind of terrifyingly fast...
I tried adding them and printing and it seems to make it do more work but still optimises away most of it.
Stuff returned from `par_iter` doesn't implement `Iterator`, but `ParallelIterator`. There are certain things can't be done with the latter, `enumerate` is one of them. Actually `slice`'s `par_iter` returns a `IndexedParallelIterator` which supports `enumerate` but `flat_map` melts the indexability.
&gt; I found that it was better to let functional programming to actual functional languages and use Rust the way it's meant to be used. That's probably true for any language, other than garbage languages like JavaScript.
Enumerate requires that the given iterator is an `IndexedParallelIterator‚Äò, but ‚Äòflat_map‚Äò returns a regular `ParallelIterator‚Äò. In more human terms, the number of items returned by flat_map cannot be know in advanced and enumerate requires this.
Hmm, that looks like a data race to me. You probably want to use an atomic there.
It should optimize away most of it. Ideally, your inner loop is going to be less than 10 instructions including one L1-cached read and write. If adding and printing gives the "right answer" then the compiler has done what it is asked to do: it's hard for me to imagine the compiler being smart enough to "look ahead". That said, xor is probably a better choice than plus, because it reduces the chance the compiler is going to do linear math lookahead even if it is magic.
is lto=true equivalent to fat or thin?
The compiler error is actually a bad one. It believes you tried to use the enumerate method from `std::iter::Iterator`, while you want to use the enumerate from `rayon::iter::IndexedParallelIterator`. Which immediately shows you the problem: FlatMap not an indexed parallel iterator. [Documentation](https://docs.rs/rayon/1.0.3/rayon/iter/trait.IndexedParallelIterator.html#method.enumerate) I assume when Rayon tries to enumerate an iterator, it splits the data into multiple tasks and completes them in parallel, trying to guess for each part where to start. However, if you try to enumerate the indices in the second task, you need to know how many elements have already passed before. Otherwise you first have to wait for the first task to finish before you can start the next one, essentially serializing the entire process. Which is why the enumerate method is only implemented on parallel iterators that can actually tell you how many elements came before a certain element.