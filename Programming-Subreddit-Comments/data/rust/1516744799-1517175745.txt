I think a good practice can be using the [unsafe mem::transmute](https://doc.rust-lang.org/std/mem/fn.transmute.html) function to do this kind of cast/coercion.
Here's my short-list: * safe, GC-less systems-level programming. This is the killer feature and is unique among all mainstream programming languages. * trait system * high-quality, modern strong/static type system w/ enums (aka "tagged unions" or "sum types") * great dependency management &amp; build tooling 
In my RFC I propose to make `as` [be a simple syntax sugar](https://github.com/Kerollmops/rust-rfcs/blob/1285b70/text/0000-as-keyword-consider-into-trait.md#reference-level-explanation) for a call to `Into::&lt;Foo&gt;::into(bar)`. There is no actual problem with `moves` mecanics... This works like any other operator. For example the [`std::ops::Add`](https://doc.rust-lang.org/std/ops/trait.Add.html) Trait needs to move self, you just impl `Copy` on your types if needed.
Damn :D
See the paragaph entitled "Secure Open Source" for the news. Mozilla is awarding this grant as part of its Mozilla Open Source Support program.
Is this the rogue fork of `ffmpeg`?
I generally use `include_bytes!()` to load them into my executable, and then have my executable on startup check the filesystem them and if not found, install them (the `appdirs` crate provides a nice way to get paths to your app's config/data folders when in active use).
shared_reference is a borrowing empty's reference to self. Until shared_reference goes out of scope, empty's reference to self cannot be used. See this: https://play.rust-lang.org/?gist=3a5bbdcd013bb6ab839fbc5fce4fcb78&amp;version=stable
Thanks :) I did not think of the yielding-nothing combination.
hey all, if you're wondering about the rust-av project, here's the [github organization](https://github.com/rust-av). It 's a gathering of codecs and formats in separate crates, with [rust-av](https://github.com/rust-av/rust-av) providing common traits and plumbing to write multimedia applications. We already have a few formats implemented, like FLV and MKV (work in progress), and bindings to various codec libraries. We plan on making it a great toolkit to write codecs and multimedia applications :) If you're coming to FOSDEM, [Luca](https://www.reddit.com/user/lu_zero) will give a [talk about our project](https://fosdem.org/2018/schedule/event/rust_av/).
Yup! It uses the same resolution stuff as any other regular path. (There's already been some confusion: it treats paths as if you were using them outside a `use` statement. So if the thing your path starts with isn't in scope somehow, you need to prefix with `::` to make it an absolute path.)
The compiler always has to support all epochs. Unless people will be creating forks of libsyntax for each epoch which I doubt, this won't help much with API stability.
For those curious, today I gave a really quick presentation of the project during the Torino Coding Society [rustnight](http://torinocodingsociety.it/events/torino-coding-society-23gen18/) For those even more curious the [presentation](https://github.com/rust-av/presentations/tree/master/tcs-20180123) is also on the org github.
I think you have some formatting issues in your comment.
The last time I checked libav was criticised for poor handling of security issues and the ffmpeg leader resigned in hope to merge back the two projects. That didn't happen, it seems.
Seems handy with a return value I suppose. Do you know if the yield keyword is planned to work for Iterators too?
hey now, please don't drag that issue in here. Opening the old wounds when talking about un unrelated project is not nice. rust-av builds on the experience of those projects, but is written from scratch, in nice Rust code :)
Cool cool, this is still a huge improvement!
How is this unrelated? The first question I wondered was "why not start with ffmpeg?"
unrelated to the fork. Related in how we designed the architecture of rust-av. Why not reuse those? The article tells it well, multimedia library have a huge attack surface, and are becoming more interesting targets now that browsers are getting safer. We're betting on Rust to avoid a lot of the common security issues we saw in formats and codec C code. As a side note, this also builds on my work on the [nom parser combinators library](https://github.com/geal/nom) :)
geeal basically wrote the nom parsing framework and I think worked on integrating it in VLC for codecs. I'm on my phone now, but there was a paper about that. So while I disagree with the remark about ffmpeg being an unrelated project, he has a lot of experience with Rust and is probably one of the best picks for for this project. He also seemed like a nice guy in our short interactions on IRC. I don't know anything about Luca, but I would assume the same. I'm not sure what their stance on the libav fork is, but this is not the place to ask.
The borrow checker has no way to know that the shared reference returned from `excl_to_shared` refers to the same instance as the mutable reference passed in. Combined with interior mutability, allowing access to `empty` would be unsound. [playground](https://play.rust-lang.org/?gist=5d46da7f966432bc2c14574d5520dd10&amp;version=undefined) There may eventually be a way to mark that a mutable reference in a function effectively becomes a shared reference once the function returns.
Well, we cover the basics. Typically, the chapters on tetris and gtk are pretty easy even for beginners. The last chapters really get into advanced topics.
Presumably it's because the borrow checker doesn't "know" what is actually going on inside of the shared_reference function. All it sees is that the function takes a mutable reference and returns that reference, albeit coerced to a shared reference. Perhaps your specific example is sound when called twice, but that doesn't necessarily mean that the same holds true for all functions from `&amp;'a mut T` -&gt; `&amp;'a T`.
There's the post I was thinking of. I knew I saw "On the other hand, Microsoft is not giving such advice and apparently is not planning to introduce retpoline support in MSVC." somewhere.
You may be right. I haven't had time to really dig into the details of how broadly they mean when they talk about predicting an indirect branch to an "attacker-controlled" destination. ... but this is a language whose most high-profile user is a web browser, the textbook definition of a place where you'd want to go in the direction of replacing C++ with a language with stronger guarantees in the same memory space as untrusted JITed code. 
I have a build and test issue I want to find a clean solution for. I have a project of projects in a workspace. Lets say the structure is like this: project_workspace | main_crate | library_a_crate \ library_b_crate `main` is the binary with the `main()` function. `main` imports `library_a`, and `library_b`. I build everything, run their tests, and everything is good. Then I make a change to `library_a`. I do a `cargo run` in `main`, and it sees the change. It rebuilds `library_a`, but it does *not* run it's tests. What I want to do is to have `library_a` run it's tests automatically. My two solutions so far seem to be: * Manually run `cargo test --manifest-path="./library_a"`. Having to do this by hand for each library sucks. * Run `cargo test --all`. This runs *every* test. Whilst the tests are fast, the start and stop of cargo as it goes project to project is slow. I'd rather skip tests on things that built. Am I missing something??? tl;dr; I want to automatically run tests on my local dependencies, but *only* on the ones that changed. Is there a neat solution to this problem?
Isn't that just `syn`?
Your question has already been answered, but as an aside, I'd just like to point out that having `New*` struct's with Diesel isn't really recommended these days (unless that struct is *also* doing other stuff like `#[derive(Deserialize)]`. There isn't any advantage to doing insert_into(tags) .values(&amp;NewTag { label: "foo" }) over insert_into(tags) .values(( label.eq("foo"), )) 
I agree with the web-based recommendation but I chose a true GUI framework because I am more comfortable with Web technologies rather than native GUI programming. As for why I chose Conrod, a Quora answer and some other results on Google seemed to mention it as very promising so I went with it. I really so enjoy the aesthetic value in the framework but the docs and example code have been a let down thus far.
I didn't realize this was going through implementation. I'm excited to have this in stable. Having the ability to link to other code is extraordinarily useful for allowing easily traverse-able documentation. I hope IDE integrations pick this up 
I've just hit a similar issue that might not be that obvious: If you want to put a link in the first line of a doc comment, it's not going to work in all cases unless the link is absolute. The first line will be put into the containing module which is a level above the item itself, so the link will not resolve there. Looking forward to this!
I still don't see the point. You could achieve the same thing using futures by cloning items of Stream and forwarding them to Sinks.
&gt; Maybe there should be a few people reviewing those RFCs and prioritizing them for a spotlight discussion. This is something that "shepherds" do, and it is very useful work.
Assuming we make only non breaking changes to the syntax (not a good assumption, though!) there should be *some* way to represent it which would also not be subject to breaking changes; enums all have to be nonexhaustive and structs all have to have secret fields. And this representation may grow to be suboptimal if generalizations &amp; abstractions that can't be applied to it are found. But we do make some genuinely breaking changes when resolving grammatical edge cases.
Honestly, it might even make sense for the RFC process to start including prototypes/first drafts of the RFCs implementations. Why? Because it is easy to say "Rust should have FooBar feature!" but implementing FooBar is ultimately a huge burden. Further, I think doing some basic prototypes of the desired feature would definitely help with the refinement of the RFCs. Love it or hate it, this is basically what is starting to happen with Java. And I think it is a good thing. They have a ton of interesting new language additions and features on the horizon while not having finalized JEPs with target dates (because they are still playing around with the interactions of the features/additions)
My favorite is the help note of this error: 57 | #[widget] | ^^^^^^^^^ | | | expected &amp;str, found struct `std::string::String` | help: consider borrowing here: `&amp;#[widget]`
That was my impression as well.
Couple of questions having about serde stuff (specifically for `serde_json`): --- Given a set of JSON data that you want to present in a slightly different struct (e.g., JSON has a `"value": "12"` that you want as `value: usize`), what's considered better/cleaner: having a separate `StructSerde` for `Struct` and performing the conversion manually in a `Struct::from_json()`, or manually implementing `serde::de::Deserialize for Struct`? --- Iterating over a possible array: Currently I have (something like) this code: let json = json!( /* ... */ ); if let Some(Some(list)) = json.get("list").map(|r| r.as_array()) { for item in list { // do stuff, but taking ownership requires `item.clone()` } } This is super boilerplate at the point I am with my implementation and I could hide it behind a macro, but I feel it could be done better, and without having to clone to take ownership. My issues here are: - indexing into a JSON set that might not have that field; - `as_array()` returning a `&amp;Vec&lt;Value&gt;` rather than an owned one; - being unable to iterate over `Value`s with `list.into_iter()`, because `list` isn't owned to begin with; - being unable to cleanly (code-display-wise) take ownership of `list` earlier in the process because `Option&lt;&amp;Vec&lt;Value&gt;&gt;` can't be dereferenced (obviously), and chaining `map(move |a| *a)` onto the `as_array()` and changing the other map to `move` doesn't let me take ownership.
That's... delightfully disgusting.
Correct. Unless someone decides to allow major version updates without checking anything, which would be...odd.
As long as there's a way to give rust-av first crack at a file/stream, but then fall back to ffmpeg, I'm certainly for getting it into as many of my applications as possible as quickly as possible. (I still remember the bad old days when my MPlayer had to load 32-bit DLLs for some of the formats from my collection of old CDs, such as Intel Indeo 5, and I had to keep MPlayer, Xine, and one other player (VLC?) around because each one had at least one file it wouldn't like.)
Interesting. When I heard it affects ARM I just assumed that meant the Pi too.
Once again, the 6502 remains safe from advanced attacks!
The first is currently what I have to a point. I'll look at implementing `Deserialize` like that for the main struct too. For the second, I thought briefly about a separate struct. The main issue personally is that, though I didn't say it, I'm doing this for about five different types. I'll probably macro it away anyway, but that solution is way cleaner than what I have. I'll have a look at using these when I get some time. Thanks.
You just can't. The goal of casting a pointer is to change how you interpret the thing being pointed to without changing the identity of the thing being pointed to. It's a "free" operation in terms of memory and processing. But a "pointer to a concrete type" and "pointer to a trait object" are *different sizes*. You can't paper over that. The only way that can work is if you reallocate the thing being pointed to, at which point it's no longer a cast, it's a conversion, and *very definitely* not free.
+1 from someone who likes using Rust for digital art (visuals and audio). 
The changes needed in pulldown are not that big -- I opened an issue a while back about it and Manish made a PR that IIUC gives us exactly the API we want yesterday :)
Thank you so much /u/Manishearth and /u/QuietMisdreavus for implementing this! 
Unfortunate that it's LGPL, but there are worse choices.
When to use bidule instead of futures?
It feels like a real problem with cargo. The forced separation between build and test. There are a lot of other decisions I find questionable. Currently I’m thinking of similar, but with a bash script or make command on top. So I don’t need lots of terminals, don’t need to worry about adding crates to my watch list when I make them, and to kill the processes when I kill the script. I did something similar to that recently for a non Rust project. 
Presumably because it means you can't use it without either a) open sourcing your own code or b) dynamically linking it while not using any generics or inline functions that someone might want to modify. I don't think that's necessarily a problem but that tends to be the objection.
This is really cool. Rust is *almost* perfect for writing safe media decoders/encoders. And we need those badly because fuzzing as good as it is doesn't catch everything.
As a student you should know that you can learn any knowledge online for free. If you really want to learn you wouldn't let anything stop you.
Like I said there are worse choices, but the Rust community seems to have centered around dual-licensed MIT/Apache which are both a bit more friendly for use in commercial contexts than LGPL.
If you're intending to shut down so far that you need to reinitialise everything, why not just jump straight to the reset vector?
It's not in stable, it's in nightly and currently set to be nightly-only.
Would it be enough to pin a hypothetical syntax crate to the Rust release version? (Rust compiler 1.30 needs the rust-syntax 1.30) Or is it infeasible for a syntax crate to be part of the rust release train?
I know that; I've already learned Rust from the official book and just using it. I've also dabbled in multiple of these topic fields. It's really the examples I want my hands on.
It's always lovely when I get to see `&lt;unnamed&gt;` in an error message path. Happened to me recently when trying out amethyst: error[E0599]: no method named `par_join` found for type `(&amp;amethyst::&lt;unnamed&gt;::Storage&lt;'_, pong::Paddle, amethyst::&lt;unnamed&gt;::Fetch&lt;'_, amethyst::&lt;unnamed&gt;::MaskedStorage&lt;pong::Paddle&gt;&gt;&gt;, &amp;mut amethyst::&lt;unnamed&gt;::Storage&lt;'_, amethyst::&lt;unnamed&gt;::LocalTransform, amethyst::&lt;unnamed&gt;::FetchMut&lt;'_, amethyst::&lt;unnamed&gt;::MaskedStorage&lt;amethyst::&lt;unnamed&gt;::LocalTransform&gt;&gt;&gt;)` in the current scope --&gt; src\paddle.rs:21:14 | 21 | .par_join() | ^^^^^^^^ | = note: the method `par_join` exists but the following trait bounds were not satisfied: `(&amp;amethyst::&lt;unnamed&gt;::Storage&lt;'_, pong::Paddle, amethyst::&lt;unnamed&gt;::Fetch&lt;'_, amethyst::&lt;unnamed&gt;::MaskedStorage&lt;pong::Paddle&gt;&gt;&gt;, &amp;mut amethyst::&lt;unnamed&gt;::Storage&lt;'_, amethyst::&lt;unnamed&gt;::LocalTransform, amethyst::&lt;unnamed&gt;::FetchMut&lt;'_, amethyst::&lt;unnamed&gt;::MaskedStorage&lt;amethyst::&lt;unnamed&gt;::LocalTransform&gt;&gt;&gt;) : amethyst::&lt;unnamed&gt;::ParJoin` 
nice :)
Ah yea, I meant that I'm excited to eventually see it in stable - I only use nightly for RLS (when it's there~)
I was with Fenrir, but thinking more about it, yes the compiler borrows mutably, but the mutable borrow can be considered "done" after excl_to_shared() finishes (though the shared reference remains). The compiler should be able to infer that without looking into the body of excl_to_shared(). Which brings me to my point, if I select the Nightly compiler and add #![feature(nll)] to the top of the file, it works for me! 
I've got a fairly large program I'm working on that doesn't do everything it's supposed to yet. It compiles without warnings, so I'm confident it'll work. I've never had that feeling with any other language, (apart from Haskell,) so it's just plain *fun* to be so worry-free. 
Thanks for this. I'm currently working on crates for RTMP (https://github.com/KallDrexx/rust-media-libs) with the intention of making it dead simple to create live streaming applications, and fully intend to make an open source wowza/evostream competitor in native rust. These bindings will definitely help.
Right now? DCA of AES. I'm rewriting some libraries I have in python. In general get decent at rust.
I'll keep that in mind. Thanks!
Nice!
There's been once or twice wear it got into an infinite recursion trying to resolve a type and eventually stack overflowed, printing out a longer and longer generic type with each recursion. I don't remember how I did it though and it hasn't happened in a long time.
Well the only idea I’ve got is a jobs site built with the backing of the Rust core team, or the Rust community. I am well aware of how secretive the job search market is, having interned at job search company a couple of years ago. Besides that, I don’t have much of an idea how, or even if this a problem that can be solved. There’s a lot of weird things that contribute to the dynamics of job advertising and hiring. 
With typenum, we have experienced exponential behavior from the type system multiple times, so the thing would typecheck for we don't know how long. Not an error message, but certainly the nastiest I've ever encountered.
Well the only idea I’ve got is a jobs site built with the backing of the Rust core team, or the Rust community. I am well aware of how secretive the job search market is, having interned at job search company a couple of years ago. Besides that, I don’t have much of an idea how, or even if this a problem that can be solved. There’s a lot of weird things that contribute to the dynamics of job advertising and hiring. 
*shameless plug* https://deterministic.space/elegant-apis-in-rust.html
Summoning /u/eijebong and his `&amp;(` trees!
If you are reading this and despite a weird fascination for huge error messages still want to make them go away/make them readable: I've written about [some ideas for custom error transforms](https://deterministic.space/hook-into-rustc-errors.html) but haven't had te time to get started working on this. Ping me if you want to get this started!
FYI, your code works on nightly with non-lexical lifetimes: `#![feature(nll)]`. Can't wait for it to land on stable.
Hah, well isn't that neat!
The biggest one I've ever encountered, merely due to a single missing `&amp;` in from of `&amp;new_post`. ``` error[E0275]: overflow evaluating the requirement `_: std::marker::Sized` --&gt; src/lib.rs:33:30 | 33 | diesel::insert(new_post).into(posts::table) | ^^^^ | = help: consider adding a `#![recursion_limit="128"]` attribute to your crate = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;std::vec::Vec&lt;_&gt;` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;[std::vec::Vec&lt;_&gt;]` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;[std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;]` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;[std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;]` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;[std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;]` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;&gt;` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;[std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;&gt;]` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;&gt;&gt;` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;[std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;&gt;&gt;]` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;&gt;&gt;&gt;` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;[std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;&gt;&gt;&gt;]` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;[std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;]` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;[std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;]` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;[std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;]` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;[std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;]` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;[std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;]` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::UndecoratedInsertRecord&lt;schema::__diesel_infer_schema::infer_posts::posts::table&gt;` for `&amp;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;` ``` And counting up to : ``` = note: required because of the requirements on the impl of `diesel::query_builder::insert_statement::IntoInsertStatement&lt;schema::__diesel_infer_schema::infer_posts::posts::table, diesel::query_builder::insert_statement::Insert&gt;` for `&amp;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;std::vec::Vec&lt;_&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;` ```
"Viral" is a spin-doctored term from the old FUD campaigns. The GPL doesn't randomly infect unrelated codebases. It's a "hereditary" license, not a "viral" one.
Why so much hate against viruses ? ;) I know Steve Balmer said this word to harm Linux, but he failed. And anyway I don't think “viral” is such a negative term nowadays, we hear it all the time in non-negative contexts, like “viral marketing”.
Would be super cool if the RLS could pick up on these!
Ah, thanks for explaining! I understand now.
Yeah I tried using NNLs to see if those could handle it but there seems to a bug in it where it disallows something that is allowed now that I need.
But your example _is_ allowed and safe; You can just uncomment that line and it works. Now if you put the commented line below the other line then it is refused by the compiler but if you change it to: { let shared_reference = empty.excl_to_shared(); } empty.just_shared(); Then the compiler accepts it again with the { ... } which surely produces the same logic.
Had already read it :) It was very helpful
Awesome! Glad you liked it :)
So you mean I'll be able to decode AAC using rust?
TIL. Thanks guys !
This would be a good moment to lobby them to rewrite their parser in Rust and use it in both their app and the website, through wasm.
&gt; but pretty bad if you're Mozilla and Google/Apple/Microsoft just pick your work and include it in their proprietary browser If think this point is debatable. It's not necessarily a bad thing, and even often a good thing. This just means that they can use your work without open-sourcing their own, but this gives them a reason to contribute to the open-source libraries they're depending on. I don't see this as a bad thing for the open-source ecosystem in general.
&gt; I don't see this as a bad thing for the open-source ecosystem in general. From a software point a view, it's not necessarily a bad thing (especially nowadays, because companies mindset are evolving and they are more an more willing to accept to contribute, but it wasn't the case even ten years ago). But if you do care about *user freedom*, then it's bad to have a privative software using your tools. It's already hard to be competitive while being a free software, because monetization is way harder, but if you give your technology to your competitors, you're pretty screwed. 
again, not going to discuss the fork (but maybe, do not continue judging the whole project from one old blogpost with questionable metrics). I have been watching the multimedia space for quite some time now, and I stand by what I said, there's a huge attack surface: hundreds of formats, each with dozens of variants, hundreds of codecs doing low level calculations, all of this in C and assembly. It is extremely easy to make a mistake. We can (and we do) use fuzzers to detect flaws, but we could also take a step back and rewrite some specific parts in a safer language (what I've been doing with nom). Doing the complete toolkit in Rust is also a way to start over with a good architecture that leverages Rust's features. We don't rewrite everything, we also have bindings to existing libraries. It is a bit like \*ring\*, we can reuse fast and well maintained low level elements (a lot of codecs will still have handwritten assembly) but provide a safe and moreidiomatic API. About the idea that multimedia is a more interesting target now that browsers are improving their security? It's something we've watched happen for some time at VideoLAN. We're working on it, with various initiatives, like a [bug bounty](https://hackerone.com/vlc) funded by the EU's [free software security audit programme (FOSSA)](https://joinup.ec.europa.eu/collection/eu-fossa], improving the usage of fuzzers (and putting more resources on this), and investigating sandboxing usage. Kostya's work is related, we talk regularly, but he has a different approach (rewriting without using external crates, etc).
the LGPL does not require to open source the whole application, the GPL does. With the LGPL, you can use the code in a proprietary application without issue, but you are required to provide the source to the LGPL library if you changed it.
Well, if the most important motivation for Rust existing is to make software safer, then I guess MIT license is better at achieving the goal.
This is a [cross post](https://www.reddit.com/r/javascript/comments/7sk0gm/you_can_now_import_rust_functions_directly_into/) from /r/javascript. I think how easy it makes it look is too cool. Copied my comment from /r/javascript: Pretty awesome how simple it is to use wasm like that, I'm super impressed! Rust #[no_mangle] pub fn add(a: i32, b: i32) -&gt; i32 { return a + b } JS import { add } from "./add.rs" console.log(add(1,2)) Done.
Hi, [est31](https://www.reddit.com/user/est31) already opened an [issue](https://github.com/rust-av/rust-av/issues/37#issuecomment-359969254) about it. As stated in the [contributing](https://github.com/rust-av/rust-av/blob/master/CONTRIBUTING.md#license) document the license can be changed and from what I'm reading _should_ be changed. LGPL is sort of _the_ license used in opensource multimedia (think about projects like vlc, gst and the one that seems people still have some quite strong feelings about, libav) so it got picked as baseline. You might notice that most of the other crates used later use the MIT license (beware though that licensing is fun so the libx264 bindings are MIT, but libx264 itself is still GPL-or-other-deal). 
Let us know if the muxing/demuxing API as we designed it works well enough for your purpose :)
I’d be happy to help with deciding aac (I am kinda doing this though Mozilla’s mp4parse for .m4a containers) but I am hopefully lost with the licence issue. Do I need to ask Apple a license just to build a decoder?
To me one important issue with the already insanely good error messages is the hard line wrapping. A very long error message in itself is ok but if it is wrapped hard at the line limit it becomes one big wall of incomprehensible madness...
This is great. Yesterday I was thinking "it would be cool to rewrite ffmpeg/libav in Rust". Today I find someone is already doing it.
+1 for Tera! The same developer who developed it also wrote the static site generator that I use for my website, so naturally it uses Tera for templating, and I've found it really nice to work with.
That's really awesome!
I'm not sure it allow static linking? Since Rust often require static linking, this could be a problem.
And in the eight months since... nothing. Super frustrating when something like this happens. 
You can store `&amp;'a mut self` in `&amp;'a T`, which is bounded by that `'a`, and use `&amp;'a T` to mutate `self`, because it contains `&amp;'a mut self`. I guess lazy_static or Box::leak will help finding an example.
Yes, because it's meant to evoke the idea of something being so memetic that you encounter it in passing and can't forget it. (Hence, "randomly infecting the minds of unsuspecting potential customers.")
TIL that fork is still alive. I thought it died when debian switched back to ffmpeg o_0
Moving doesn't zero the original binding, that's pointless. The compiler internally tracks moves so it knows where ownership has gone and doesn't allow you to access previous bindings that have been moved from. In fact, implementing `Copy` can be slower depending on the size of the type, since a move often won't end up changing the final memory location; it just affects which code is allowed to access said location. However, copying is usually obligatory except when the optimizer can figure out that it's unnecessary. This isn't really something to worry about unless your type is very large, though. A type having move semantics vs copy semantics mostly boils down to correctness, usually to do with internally owned resources. `String` can't be `Copy` even though its fields are because a copy would point to the same heap allocation and when one is dropped it'll free that allocation while the other still has a pointer to it. However, `&amp;str` can be `Copy` because the lifetime information tied to it ensures that the pointer remains valid. 
This is because suggestion works based on `CodeMap::span_to_string()`
Moving doesn't zero the original binding, that's pointless. It's just a copy that doesn't allow usage of the original binding, as you've figured out. The optimizer can work with it either way. A type having move semantics vs copy semantics mostly boils down to correctness, usually to do with internally owned resources. `String` can't be `Copy` even though its fields are because a copy would point to the same heap allocation and when one is dropped it'll free that allocation while the other still has a pointer to it. However, `&amp;str` can be `Copy` because the lifetime information tied to it ensures that the pointer remains valid. In general, if your type doesn't require move semantics to be correct, then it's preferable to implement `Copy` for ergonomics. 
You can use `proc_macro2::Span::located_at` to change it, but I don't know if proc macro can register arbitary filemap.
I see that in the repository it's now been changed to MIT. That's great news!
See: https://github.com/parcel-bundler/parcel/commit/a429c52bb4e53effe586d677d53704a78c8d302b#diff-baa25227eb962b83d55f105a57f60d29R41
Rust does not *require* static linking, it defaults to it for other Rust libraries.
Thanks for confirming my understanding of move and copy semantics. I'm with you that Copy should be preferred, but that leaves the question open if the compiler gives additional optimization hints to the llvm backend when the move semantics is used.
No shit, i tried it because i could not believe this could possibly work "just like that" But seriously just npm install -g parcel-bundler &amp;&amp; npm init -y create an index.html &lt;html&gt; &lt;body&gt; &lt;script src="./index.js"&gt;&lt;/script&gt; &lt;/body&gt; &lt;/html&gt; an index.js import {add} from './add.rs'; console.log("hello world: " + add(2, 3)); and an add.rs #[no_mangle] pub fn add(a: i32, b: i32) -&gt; i32 { return a + b } and hit parcel index.html That's crazy, seriously!
Hoping this will help getting SIMD (and possibly asm) support landed in stable, as that's are very much needed for efficient media processing.
From the optimizer's point of view, move and copy are the same. The optimizer sees a copy, and in some cases, may see an opportunity to reuse the same stack slot for the same thing or something else (i.e. all the time for moves and whenever you do a copy and don't reuse the original) implementing Copy does not prevent optimizations
Switching from an older version of `syn` to the new one is not an easy task. Hopefully, someone might work on this soon.
It was always fun to have the compiler summon Cthulhu on you when you really messed up. That’s gone the way of the Elder Gods.
If I have a `Vec&lt;u8&gt;` that represent an `i64` (via BE twos compliment). If I constructed the `u64` combination of the `u8`s and then cast it to an `i64` is rust performing the twos compliment conversion for me?
Will do. I have a long time before all the pieces are in place where I need to do demuxing I think (live ingestion and distribution is my more immediate focus). In my prototype I made in Elixir the only things I had to delve into h264 were for checking if a frame is a keyframe (first byte is 0x17) or if the frame is a video/audio sequence header (0x1700 and 0xaf00). Outside of that it was mostly just take a packet and pass it along to viewers. Unfortunately, in Rust it's going to be paramount to keep core paths efficient since it's going to be hard to make it multithreaded.
&gt; Thanks for the reply. Midi sequencers need lots of IO and as much memory as possible. 10-30 buttons with matching LED's, depending on the design. You can either use a chip with tons of GPIOs for that or you I2C based IO expanders like the MCP23017 for that which will vastly reduce the hardware complexity but also the software implementation because you don't have to care about a complex interrupt setup for each individual button.
I am also a newbie, but I am a big fan of being very conservative. I much rather prefer there being one way to do things instead of 5 different ones. I know people want flexibility, but often flexibility is bloat. This doesn't mean we need to be super-hardcore about it, but should definitely be kept in mind when working on/advancing Rust.
You can have SIMD on stable if you use C like ring does.
I don't think that Rust can win the race of features with C++. And this is a good thing. C++ is still way ahead and doesn't plan to stop. I think the real problem is in contradictory features like exceptions or polymorphism. Some libraries use exceptions, some not. And I don't want to even start talking about build systems. Such features breaks ecosystem in a bad way, imho, and Rust doesn't really have one yet(?).
I did some experiments with using WebRender (for UI / overlays). I honestly didn't expect it to be that easy. Just push a rect, then a box shadow, boom you have a rectangle with a shadow. Works pretty well for my use-case, so thanks for all the hard work with batching / clipping.
&gt; How would you do power management with RTFM? Where you want to shut down a number of peripherals for a while, and then wake them back up later? It's the same process as for any other OS or when doing it yourself in another language, it's basically a two step process: * Get rid of all polling and continuous processing (i.e. make sure the whole software is interrupt driven and your idle task is empty / there's no main loop doing anything else besides waiting for interrupts) * Set up a mechanism that will wakeup the MCU (preferably external interrupt based rather than periodically) (optionally explicitly shutting down peripherals) and enter sleep in your idle process / main loop; of course if you shut anything down before going to sleep you should enable the peripheral in the interrupt handler when coming out of sleep Usually just making sure only required components are enabled, you're running at the lowest possible frequency and exclusively operating interrupt based and hanging out in regular run mode while waiting for an interrupt goes a **long** way already. Then measure power consumption between the regulator and the MCU inputs and only if that doesn't meet your expectations I'd fiddle around with sleep or standby mode. In at least 99% of all cases it won't be the MCU using the most power anyway...
It's a valid consideration. The "solution" for a language that grows overly complex can be the emergence of a newer language that addresses the same niche of needs in a novel and simpler manner. Rust is somewhat doing this to C++ today. A smaller language may do the same to a bloated Rust of the future.
@kvarkus Since your username is all over both webrender and gfx, any plans on using gfx as webrender backend? :)
&gt; Outside of that it was mostly just take a packet and pass it along to viewers. Unfortunately, in Rust it's going to be paramount to keep core paths efficient since it's going to be hard to make it multithreaded. Try to use [iovec](https://crates.io/crates/iovec) to spare some copies.
Is it obvious? After the left-pad incident, I'm not sure it is.
I agree. I do C++ mostly, and it really feels like there's a million ways to do anything, and very few ways feel right. Even if you have to write a little bit more code in the short term, it's worth it to have one way of doing things.
Thanks for the reply. My question is more about using as to cast a number for `u64` to `i64`. My example was a bit contrived. As a learning exercise, I am trying to understand how to read a SQLite database file. In the documentation it defines a data structure `varint` as a static Huffman encoded 64 bit big endian signed integer, encoded as 1-9 bytes in length with the high order bit indicating the last byte in the structure. This needs to be constructed by taking the lower 7 bits of each byte and, if there are 9 bytes, the full 8 bits of the last byte. So, first I am breaking the file buffer down into `Vec&lt;u8&gt;` with a length between 1 and 9. I am then looping through this `Vec&lt;u8&gt;` backwards, removing the high order bit on any bytes after the first, I am then shifting the byte left the required number of bits (((i - 1) * 7) + 8 if i &lt; 1) and finally `BinaryOrAssign`ing each byte into a total. So I guess I have 2 questions: 1. If I cast this total value to an `i64` does rust perform a two's compliment conversion? 2. If I `BinaryOrAssign` instead into an `i64`, is this effectively performing the same operation?
That is not so much a matter of feature bloat, but of missing best practices: lisp in it's most basic form has a million ways to do anything even though it is far from bloated.
Absolutely! See the [previous comment](https://www.reddit.com/r/rust/comments/7n3lp1/2017_year_in_gfxrs/dryw4ei/) on the topic. The HAL port is in progress ;)
Sweet. :9 That makes me think that webrender will be an excellent choice to build game GUIs with quite soon, using gfx HAL as rendering backend for both game world and GUI.
&gt; But that's not technically required for memory safety. The only kinds of shared mutation that lead to unsafety are the kinds that change the "shape" of an object- reallocating a Vec, changing an enum to a different variant, etc. Other kinds are totally safe- writing a scalar value in a struct field or array element, writing a non-owning reference, etc. That. And yet I'm getting the funny looks because I want to have my mutable shared array in Rust and eat it, too!
There is an idea to [make enum variants types in their own right](https://github.com/rust-lang/rfcs/pull/1450), but it's complicated, and hasn't gone anywhere.
Right now I'd like to have the aligned allocator API to hit stable. There is a crate to use `asm!{}` from stable already but you cannot do a lot if your buffers aren't aligned. Same to be said about using hardware acceleration. 
Indeed i used the wrong word, but static linking is clearly the preferred way to use libraries in Rust.
Isn't it that new features _must_ be added though an RFC process, with a comment period. I'm sure that people will start complaining about _bloat_ features, causing them not to be added. Although this isn't really a solution nor a strategy to prevent this. I'm sure it helps quite a bit keeping things clean. 
So you have no qualms about friend classes then? 
With a proper reactor, that should be doable, yeah.
I'm one of those ppl who hate c++ since they started to adding features. I sticked to c++ for 10+ years and I was very excited about c++0x. But when I tried it I totally abandoned this language and in my personal opinion, the current c++ is a garbage because of tons of the features that sum up to infinite complexity. I think the main issue in c++ is backward-compatibility. New features (like new variable initialization) should unify and replace old ways of doing the same. Generalization on the feature level is good as long as deprecated features are removed.
C++ has a lot of original problems too.
And header files. And the lack of a standard build system.
&gt; So the optimized version should in theory (if applicable) do nothing and just use the stack pointer offset of the original variable. The compiler disallows further usage of the original value, so this should be fine. That sometimes happens. The equivalent code for fn create() -&gt; Object {...} let object = create(); in C is void create(Object * object); Object object; create(&amp;object); For `Copy` types this *can* happen, but it usually doesn't. Many `Copy` types are extremely small, and therefore the pointer to a variable might be larger than the variable itself, so functions that return a `usize` or a newtype around `usize` usually simply store the entire blob in `eax`. Larger copy types might be addressed by pointer in the future in release mode, although the current iterations of rustc [don't do that](https://play.rust-lang.org/?gist=beef3e5e00daae4d6bc1fdcad7dd544d&amp;version=stable).
The NLL-related work is also (eventually) supposed to fix some soundness issues, such as [this one](https://github.com/rust-lang/rust/issues/38899). It's possible your code is unsound, or (yes) that NLL added an extra restriction, the latter of which would hopefully be a bug. I don't suppose you have an example?
This new wave of zero-config web development tools is really exciting to see. Webpack is fantastic, but I don't want to spend ages setting up a build config if I'm trying to start up a weekend project.
Some people will start complaining, others will be excited. As you already spotted, RFC is not the ultimate solution
The MPL license has roughly the provisions you're describing and is much friendlier in corporate environments because your company's legal team only needs to review the license once instead of all of the individual "you can static link" clauses that people tack on their LGPL code.
Thanks for the detailed answer! (and to [MSleepyPanda](https://www.reddit.com/u/MSleepyPanda) also ). This certainly clear things up. The code indeed is a part of user-space file-system, where the hashmap is a block-map of a file. The custom FS will be then exported via NFS. P.S: This is something I really like about rust community. Lots of patience and going out of the way to explain in detail.
I will be working on a dedicated interval type for postgres. I am hoping to have enough by the end of this week for someone else than myself to review the code. That being said if anyone has suggestions early on you can find the repo [here] (https://github.com/piperRyan/rust-postgres-interval)
You are also required to enable users to replace your application's copy of the library with a modified one- thus dynamic linking and refraining from using generics or inline functions that they wouldn't be able to replace.
depends on the cpu and the hardware acceleration SDK are quite strict about it.
NLL gonna be so nice...
&gt;&gt; "One of the arguable cons of C++ is that it is a language that never says no to adding features. " The right features simplify use; for years C++ resisted things like 'auto' (fwd type inference), range-based for, lambdas ('just make an object!') which clean code up alot C++'s problem is that the features are half broken, not that it has too many. Adding the right features (e.g. UFCS, tagged-unions) could clean it up further
&gt;&gt; ", and very few ways feel right. " thats the real problem: features that are incomplete/half broken, so you need to stretch them in awkward ways. I'd argue it takes *more* features to fix. 
macros &amp; raw pointers were the right features for C which enabled it to do more than rivals; C++ then comes along and builds on what was already established, and continues to be the standard FFI (e.g. Rust felt the need for C FFI, but C++ practically includes C) C++'s inexcusable problems are the ones it introduces: My pet hate is how classes and headers interact. In plain C you can write function defs in a source, struct defs in a header, then you could generate the header for the functions from the source. In C++, you end up needing to split the definition between 2 places (e.g. default params go in the header, and there's an awkward syntax change in the prototypes, and you can't parse it till it's defined.. arrrgh)
Maybe one day Rust will be as fat as C++. But that will hopefully be far in the future, as in in 30 years or so. Until then another language will have emerged that I can switch to :). But yeah I get what you mean: in C++ it is very hard to collaborate on a project from various backgrounds because everyone uses their favourite set of features. If you read other's code you need to know those features and this is really a burden.
&gt; It's only for when you want to make a standalone app with a web frontend. That's not what I want to do so I'll go look for a GUI toolkit instead.
I haven't had the need to use Diesel yet, but I wonder if these errors couldn't be greatly improved by extending and stabilizing `rustc_on_unimplemented` for external crates.
I'm 99% certain /u/rabidferret commented on the tracking issue for that ;)
Actually i'd prefer your solution over mine, though i had to look up the `Entry` API. Much cleaner and more concise!
This seems quite impressive. I was just doing a prototype design of a new TLS service. My bucket of willpower was too empty to consider SGX - then along comes Baidu SGX. I think this is going to be fun! 
I agree. The main issues with C++ is not per se the number of features, but their interactions. For example, the new introduction of Uniform Initialization syntax (`T t{1, 2}`) was poised to solve two issues: - the Vexing Parse and Most Vexing Parse, where a constructor call is seen as a function declaration by the compiler (the joys of having an ambiguous grammar), - unintentional narrowing, when passing a `std::size_t` to a `std::uint8_t` accidentally. In the same version of the standard (C++11), someone created initializer lists, which simplify the initialization of containers like `vector`. Awesome! Except they used the *same* syntax. As a result, today you can use Uniform Initialization syntax *except* on types with a constructor taking an initializer list. Uniformity flew out the window on day 1 :/
Er, half a dozen LET variants in Common Lisp is inimical to productivity.
That's insane. What a world we live in. Seriously, config files, and gulp/webpack are some of the worst warts of "modern web dev".
What do you mean by a two's complement conversion? My understanding of `u64 as i64` is that it's a no-op that just reinterprets the bytes as they are.
Preach
Yeah, and in fact there are pieces of chrome in firefox and pieces of firefox in chrome. I don't have a list of them but for many years chrome was using nss which is Firefox's security/crypto tool box. The thing is, it's hard to compete (as in outperform) when using someone else's tech because said tech is developed and optimized for the original author's needs and architecture. 
Switching from `*mut T` to `Option&lt;NonNull&lt;T&gt;&gt;` seems like a win for null safety but a major loss for ergonomics? Without a `Deref` for automatic `NonNull` to `*mut T` transition, it would be just plain worse to use like that.
&gt; In general, if your type doesn't require move semantics to be correct, then it's preferable to implement Copy for ergonomics. On the other hand, it's a maintainability complication, because removing `Copy` is an API breakage (while adding it is not).
&gt; And no, I couldn’t “just use postgres” for this It actually sounds like a pretty ideal case for a key-value store like [Bolt](https://github.com/boltdb/bolt) (in the Go world) or something similar.
Sure, a GC might be bad inside the core of a database. There are lots of places it makes a lot of sense. If I'm building a carousel for a webpage, then I don't care about how long the worst percentile of a GC is. Context is what's important here.
That is a good point. My primary use case is shutting everything completely down when the keyboard (in bluetooth mode) isn't in use for a few days so the battery won't drain. There's a good chance that it'll lose RAM contents anyways and boot normally. I guess I should just try.
There is a mentality of *"if I have a hammer, everything is a nail"* with languages and frameworks. It's often seen as a bad thing. A big pro however is that you just get on with it. Like, as simple as that. No thinking (or very little). You just do it.
I believe moving sometimes requires runtime tracking in order to figure out when to drop the variable (a bit/byte on the stack). Of course, non-trivial Drop types shouldn't be Copy anyway.
That error is a thing of the past. (At least for Diesel)
That makes sense. Thanks to RTFM everything is completely interrupt based already, and I think some of the keys are wired to a wakeup pin. My main question is about how to shut everything down nicely, as that requires write access to a good number of registers, which you usually don't have anymore after init returns, or if you use the nice new typing to split them up into pieces.
Sorry, I meant something like this let shared_reference = empty.excl_to_shared(); empty.just_shared(); shared_reference.just_shared(); 
I sure hope Rust is easier to learn and more worth learning (i.e., more useful outside of just your group's work) than some proprietary scripting language from the 90s
Is that switch mentioned anywhere? I did a little raw pointer rust as well while wrapping a C library, as I needed to add a few extra things. I only had to do a few functions, so it was not a big deal in my case, but if I had more raw pointer code to write, I would have seriously considered writing those functions in C and compiling them into a library in *build.rs*.
In practice, only commercial users of your decoder will need to care about patent licensing. I don't know how is this related to Apple, license for AAC patents can be bought from [Via Licensing](http://www.via-corp.com/us/en/licensing/aac/overview.html). Apple is not in [the list of licensors](http://www.via-corp.com/us/en/licensing/aac/licensors.html) but are in the [list of licensees](http://www.via-corp.com/us/en/licensing/aac/licensees.html). So Apple has simply bought a license to use AAC. 
Is any of the following true about the type? - needs or may need to implement `Drop` - needs or may need to implement `Clone` as anything other than a simple bytewise copy - points to memory (other than `&amp;` references) - represents a handle to any other kind of resource which needs to be "closed" or "freed" when you're done with it? - for some other reason you can't allow mindless duplication of values? If so, the type is `!Copy`. Otherwise if it's just plain data (no matter how large) and most likely `Copy`. --- The rustc front-end converts all local variables to static single assignment form, then LLVM does register and stack allocation from scratch. There's no difference with `Copy` variables because LLVM doesn't know anything about copying and moving - at most it knows about the drop flags. (Extra variables that track whether each variable is initialized or not.) The difference isn't `Copy`, it's `Drop`. If a variable has a Drop type, then `drop` will be automatically invoked at the end of the block (roughly `if x__drop_flag { x.drop() }`), which means that LLVM must either: - keep the variable around until then - rearrange things so that the drop happens earlier LLVM can only rearrange things if you wouldn't notice. It can't rearrange external calls, to `close` or into jemalloc, so it cannot reclaim heap space or file descriptors early unless you `drop(x)`. 
Sorry if I was not clear. I mean that if you're currently using `*mut T` (for whatever reason you like) and someone tries to tell you to switch to `Option&lt;NonNull&lt;T&gt;&gt;` to improve safety or clarity or whatever reason... That's a very hard sell. Other than null safety, the `Option&lt;NonNull&lt;T&gt;&gt;` form is just worse to use because you have to do the `as_ptr()` call yourself. ``` if Pointer.is_null() { return; } (*Pointer).Field = (*Pointer).Field2 + Value; ``` Becomes this ``` let NN = OpNN?; (*NN.as_ptr()).Field = (*NN.as_ptr()).Field2 + Value; ``` It's like some goofy joke about Java verbosity made real. Obviously having `NonNull&lt;T&gt;` deref directly to `T` is unsafe, but having it deref to `*mut T` would be safe and far better.
If you want to get a better idea about navigating the captured state, check out the description I wrote to [WR #2340](https://github.com/servo/webrender/pull/2340) where I trace through all the data associated with a particular item. 
That's a remarkably sensible thing to do...
Is there a problem with `friend class` other than `friend` being a last resort in general?
That's typically only necessary when branches are involved where one branch causes the value to be dropped while the other does not. It only happens for types that implement `Drop` (for composite types that don't implement `Drop` but contain `Drop` fields, this is tracked per `Drop` field).
tl;dr: zig catches alignment issues and rust does not. EDIT: With rust nightly it emits (valid?) alignment information https://godbolt.org/g/q7HM8f.
Not sure what the your question is. It takes ownership so you can chain/combine it . It doesn't return a stream on error because the stream had an error and you can't use it anymore.
One thing Rust has over C++ in this regard is that Rust and rustc are handled by the same group. This means that features can be tested in a real implementation before being stabilized. Problems and weird interactions that weren't obvious during the design phase can be more easily found.
That's a delightful bug! Here's the deviousness explained slightly differently: The function `std::mem::transmute` is terrifyingly unsafe, but is subject to a compile-time check that might inspire a false sense of security: the _from-type_ must be the same size as the `to-type`. For instance, this fails: std::mem::transmute::&lt;u8, Foo&gt;(0); ...with a comforting error: error[E0512]: transmute called with types of different sizes --&gt; src/main.rs:8:9 | 8 | std::mem::transmute::&lt;u8, Foo&gt;(0); | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ | = note: source type: u8 (8 bits) = note: target type: Foo (64 bits) But this author isn't transmuting a `u8` to a `Foo`, they're transmuting a _pointer_ to a `u8` to a _pointer_ to a `Foo`, and these _pointers_ have the same size. Thus, let foo = std::mem::transmute::&lt;&amp;mut u8, &amp;mut Foo&gt;(&amp;mut array[0]); compiles just fine. Want to dump some uninitialized memory without a tell-tale call to `std::mem::uninitialized`? This trick works _perfectly_ for that: #[derive(Debug)] struct Foo([usize; 32]); fn main() { unsafe { println!("{:?}", std::mem::transmute::&lt;&amp;u8, &amp;Foo&gt;(&amp;0)); } } 
It's not correct: %array = alloca [1024 x i8], align 1 %5 = load i32, i32* %4, align 4, !dbg !12 
This approach would break a lot of existing code thought which is what they wanted to avoid.
I just tried it out. Seems like no. This [StackOverflow post](https://stackoverflow.com/questions/47529643/how-to-return-a-string-or-similar-from-rust-in-webassembly) explains how to work around it. 
From what I've seen of optimized assembly, moves often don't even cause a value to leave its memory location. LLVM will just keep it in the same position on the stack. Of course, if it's small enough to fit in registers then it may never even touch the stack; x86-64 has an astonishing number of registers and they get wider with every new SIMD instruction set. Copies are much of the same. If the original binding isn't mutated or doesn't have unsafe pointers taken to it then LLVM will often elide the copy entirely. But again, if it's small enough to fit into registers (and you'd be surprised what can) then even that's not really a problem.
Hmm, surprising to see rust as low as it is, especially being in the red with younger demographics is a surprise to me.
For the record, rustc could warn about this (erroring would be problematic in general because `*mut u8` ends up being cast to `*mut T` *a lot*, and also you can't know the alignment of generics), it's just a matter of adding the special case into the compiler. Changing the alignment of the `alloca` or of the `load`s at codegen time is *also* doable, but it would only catch very local cases. FWIW, we do track the alignment of a MIR "place expression" during codegen, so if this didn't have to go through a reference and a raw pointer, it'd result in lowered alignment for `load`s. However, this tracking is specifically intended for safe access to packed fields though, which can only be direct.
So just to make this absolutely clear, since I too was confused by this at first: The reason for UB is not that the alignments isn't outputted to LLVM, it is that the alignment of `%array` is only 1 byte, and we're storing a `i32`, 4 bytes, into it. The correct line here would be ``` %array = alloca [1024 x i8], align 4 ```
It's a recurring complaint of mine that once FOSS projects _get the money they cry for so often_, they turn out incapable of any reasonable oversight and delivery.
That argument applies to literally every trait.
How much of the negativity to rust might be the backlash to the idea of Rewrite it in Rust being a meme, no matter how much you ACTUALLY see it said?
Awesome, I’ve been wanting to learn how the graphics stack works. Looking forward to it!
I help maintain an out-of-tree port of the rust standard library for Nintendo 3DS homebrew. Nightly rust moves fast though and things had gotten pretty out of date, so I went and [redid the port](https://github.com/rust3ds/ctru-rs/pull/48) from scratch. Fortunately it was easier this time around because I was able to borrow a bunch of stubbed-out modules from the `wasm` target. And now that things are up to date and compiling again, I've been able to start chipping away on new functionality that I've been wanting to add for a while.
See also https://github.com/alexcrichton/futures-rs/issues/602
Well all statistics bear about as much truth as you fake them. This is a Hackerrank community survey of _their community_, roughly 40000 developers. Hackerrank is a site for jobs, Rusts weakest point. It's no surprise that Rust isn't of much importance to them. Getting a job with Java, .NET or Javascript is by far a more profitable option. Let's see it positively that 20% want to learn Rust as the next language. On a side note, it's funny that the diagrams break completely if you change the URL, then use the back button. The web is broken.
*Or:* %5 = load i32, i32* %4, align 1, !dbg !12 This is what we should already be generating if `struct Foo` were `#[repr(packed)]` (although feel free to double-check).
Yeah you're right, I constructed a simple example to show the undefined behaviour if this was allowed: use std::cell::Cell; fn get_ref_to_inner&lt;T&gt; ( cell : &amp;mut Cell&lt;T&gt; ) -&gt; &amp; T { cell.get_mut() } fn main() { let mut cell = Cell::new("a value with drop".to_owned()); let str_ref : &amp;str = get_ref_to_inner(&amp;mut cell).as_str(); cell.set("another string".to_owned()); // str_ref now points to dropped data }
Yes, both alloca and load/store are aligned with one.
That's pretty good, but then if you `iter_mut()` that slice you get a pile of `&amp;mut T`. Each of those is treated by LLVM as if it doesn't alias any other pointer in the program while it's alive, which _might not be true_, so we'd need a type like or something `&amp;ali T` to allow mutation through the pointer while telling LLvM the right rules to follow. Also this would allow data races if not externally synchronized by something else of course, so we can't really do that exactly. It's not an easy problem, I'm not saying it is, but it also makes for some very un-ergonomic code in the current state and it's something to work on. The best solution ive seen so far is an rfc to allow trait implementations to add const or unsafe to their implementation of a trait, so that usage of the trait for that type can be const or can require an unsafe block. That would fix a huge pile of pain all at once.
Welcome to Reddit. Before posting to a subreddit/forum/community, you should check to see what that subreddit is for. This includes reading the sidebar and the rules. You should also pay attention to warnings that you're posting to the wrong subreddit. Check /r/playrust. 
Now, curious question: how would you deploy something like stdweb using that?
Seeing this, I should really try to make time to get back to work on my efforts to make a [game launcher of my own](https://i.imgur.com/2yQMBZI.png). It's been mothballed for the last few months but, while the frontend may be PyQt, most of the work is going into a heuristic "Here's my games folder. You figure out the rest." module that I've been porting to Rust to become a reusable crate I can offer to things like eidolon, GNOME Games, and Lutris.
Yes. You have to refer to `'./crate/src/lib.rs'` in your import, and then it finds the Cargo.toml one directory up, and does the right thing.
I only used the slice produced to replace instances of `*ptr.offset(i)`, that is I only used the slice where I would have used the pointer. And in my case, where I had `*mut` pointers they had no aliases. So yes, `slice::from_raw_parts_mut` is unsafe, and unsafe is hard.
The issue is that you have one reactor, but two futures on the same thread. I.e, you're trying to run two tasks but only one can be run at once on the same thread, and getting a deadlock. This line here: let sync_result = sync_api.sync_call().unwrap(); Will never complete, because you haven't started the tokio core until after this line: core.run(async_task).unwrap(); Both are using the handle to the same core. Now, to resolve this, I'm not sure the best solution, but I would probably use a [future cpu pool](http://alexcrichton.com/futures-rs/futures_cpupool/struct.CpuPool.html) and block on that. 
Thanks, and how is it different from this? https://crates.io/crates/carboxyl
I believe that error is due to how you're using the split up references in the next line: `people.entry(v[3]).or_insert(vec![v[1]]);` If you change it to something like: `people.entry(String::from(v[3])).or_insert(vec![String::from(v[1])]);` so that you create a copy of the String contents rather then using the references in the HashMap, you should be fine. The borrow from `input` will end at the end of the current scope, so adding those references into the HashMap would create a dangling reference.
I was able to get the example work, and it feels amazing, but I can't find any information about the types accepted and returned between JS and Rust. The example uses i32, but when I tried to return `String`, it returned `undefined` instead. What about an array of strings? boolean? etc. Is there any list of supported types? Is there any issue with the list of planned types to be added? My end goal would be to be able to return JSON, but I'm afraid we're pretty far away from that...
How is that code "_Unsafe_ Zig"? I don't know Zip, but it doesn't look like there is anything there to go into I-know-what-I'm-doing mode...
So this applies to packed structs? &gt; on some architectures it will only cause mysterious slowness, while on others it can cause an illegal instruction exception on the CPU
It appears to handle `Cargo.toml` no problem
Having many necessary features is not a problem, but having unnecessary ones. The best measure of necessity is orthogonality, i.e. "should we add this feature to the lang, or can it already be expressed as a combination of already existing features?". This is why I don't like that `impl Trait` is added for function argument types, it's not orthogonal. We only really **need** `impl Trait` for return types, [not for argument types](https://www.reddit.com/r/rust/comments/7qd3gp/rust2018_a_neon_wish_list/dsr6dnm/). For argument types, it introduces another way of doing `&lt;T: Trait&gt;` so it's not orthogonal, now there are two competing ways to express that, and the new way is **less** powerful because it doesn't allow lifetime bounds etc.
To make the demonstration a _little_ more scary, we can even move everything but the dereference outside of the `unsafe` block: struct Foo { a: i32, b: i32, } pub fn main() { let mut array: [u8; 1024] = [1; 1024]; let foo = &amp;mut array[0] as *mut u8 as *mut Foo; unsafe { (*foo).a += 1; } } 
So the question becomes, does Rust interpret the raw bytes of an `i64` using twos compliment?
I wonder if /r/playrust ever gets any /r/rust related posts !?
Isn't `&amp;ali T` actually `&amp;UnsafeCell&lt;T&gt;`?
Unfortunately, it's not possible to use languages that compile to JS (like PureScript) with sciter: &gt; Sciter uses its own script which is incompatible with JS. An idea to support JS via external engine was considered from time to time since people keep asking it, but it's just an idea still. [source](https://github.com/sciter-sdk/rust-sciter/issues/22#issuecomment-360016987)
&gt; Usually you try to keep the base vectors (lang features) orthogonal so there is only one way to express any point (program) in terms of your base vectors (lang features). It's definitely a good thing to keep in mind, yes! You don't want to confuse or overload people by giving them a million ways to do the same thing. However, at the same time I think there are a lots of cases where there are obvious ergonomic/learnability wins to be had from syntax sugar. Closures, for example, are just structs that implement a function. `for`, `while`, and `loop` are all redundant with one another. Even methods and operators are just fancy functions. However, these features all make the language easier to use and make developers more productive. Like many (most) things, there's a trade-off involved and the "right" decision isn't always obvious.
From what I can recall that is correct. However, as far as I can tell the UnsafeCell type has no way for you to make one from a raw pointer. Further, it seems that you're expected to manipulate the data via getting the raw pointer out and then using that. I don't recall any abstraction in rust for the case where you want to alias something but keep null safety and "bit pattern" safety (that is, block the user from writing invalid state to that location, such as a bool that isn't 0 or 1, or some other invalid enum-ish situation). That would be a useful tool. Until then it's *mut for me I guess.
The results look fairly volatile, I suspect that their sample size for Rust is fairly low.
Younger demographics strongly prefer languages that are popular in the job market.
All zig is unsafe zig.
What's the lattice rule?
So enums can be used with diesel/postgres now, without having to manually impl `FromSqlRow` and `AsExpression`? Where can I find an example of that?
Actually, there is another issue with the Rust code as well: Because `struct Foo` has no `repr`, Rust is free to reorder its fields. As a result, we don't know what byte in `array` will end up being incremented.
Very slowly but along with going back through the Rust book (2nd edition) started playing with doing the work from Crafting Interpreters in Rust. We'll see how that goes, as I want to get my head around building a toy language for some ideas, and I really want to do it in Rust.
My main point was simply that moving doesn't always boil down to a _just_ a copy.
Yea but `for`, `while` and `loop` are semantically different (their intention) so you rarely have to change a `for` loop to a `while` loop or `loop` loop etc. But with `impl Trait` for argument types, there is no semantic difference to `&lt;T: Trait&gt;` and you have to change your code using `impl Trait` into using `&lt;T: Trait&gt;` a lot, e.g. when you add lifetime bounds etc. `for`, `while`, and `loop` have semantically different use cases which makes it very easy to choose which one you should use, but `impl Trait`'s functionality for arg types is a strict subset of `&lt;T: Trait&gt;` with no added functionality, so it makes it harder to choose one (and you often end up having to change it later).
It's funny that Rust is so disliked in general here while its one of Stack Overflow's most loved 
So access to packet structs in arrays won't be slower?
So learning rust now, at the chapter on enums in the rust language book v2, I want to extract the string value into a string again, but how can I achieve this: enum IpAddr { V4(String), V6(String) } impl IpAddr { fn to_str(&amp;self) -&gt; &amp;str { // wtf goes here } } fn main() { let home = IpAddr::V4(String::from("127.0.0.1")); let loopback = IpAddr::V6(String::from("::1")); println!("home = {}, loopback = {}", home.to_str(), loopback.to_str()); } 
Dag, I was a little distracted when i wrote this and thinking about the value being nonzero instead of the pointer being nonnull. So i retract this particular complaint
Depending on which sleep mode you use, you're either guaranteed to lose the RAM (standby mode) which will automatically cause a reset on wakeup, or guaranteed to retain it (all other sleep modes). You probably don't need to do anything special at all. If you need to maintain a tiny bit of volatile state across Standby mode, there are a few backup registers available which stay intact, which you can check on startup.
Known issue, https://webpack.js.org/guides/development/#adjusting-your-text-editor, essentially safe write works by writing to a separate, differently named file, then switching it with the actual file once the writing is complete. Anything watching the original file will get thrown off because the original file isn't being updated.
Ah, thank you! Damn, seems like seamless json between rust and js is gonna take time :)
As the README says (though maybe it was added after this post went up), sadly this is not being further developed. It was announced very recently that the company behind Eve is shutting down and the founder is looking for new work.
I couldn't help myself: https://github.com/parcel-bundler/website/pull/102
Do we have a clippy issue for this? On mobile right now, otherwise I'd check.
yep https://github.com/rust-lang-nursery/rust-clippy/issues/1384
So essentially we need Unsafe Rust to be more ergonomic. The community focuses so much on making sure Safe Rust is safe, with no focus on making sure Unsafe Rust can be written safely. I wonder what can be done.
Great episode, very informative.
I put together a library for this very use case, to make it easy and ergonomic to write functions taking/passing strings. Check out [rust-wasm](https://github.com/jsonnull/rust-wasm).
Well this is as is designed, correct? Pointer dereferences are unsafe.
The site freaks out entirely under mobile Firefox
To be clear about what's happening here: pointer types in zig are parameterized by their alignment. A `&amp;align(4) u8` is a pointer to a `u8` that is aligned to a 4-byte boundary. This is part of the type system. If you - const foo = @ptrCast(&amp;Foo, &amp;array[0]); + const foo = @ptrCast(&amp;Foo, &amp;array[3]); the type of the second argument is `&amp;align(3) array` so it will again fail to compile. But if you change the `3` to a `4`, it will work again. If the index can't be computed at compile time, the alignment is falls back to 1. So, like how Rust references are parameterized over lifetimes, you can't really do this with just a simple lint without changing the code (because the checks need to span function boundaries and you need to assert the alignment requirements for the function inputs).
That's a shame. I was learning Clojure while Light Table was on the rise, so I have mixed feelings about Chris' track record at this point. Both LT and Eve were really really interesting projects and it's a shame they didn't pan out the way I hoped they would. I hope he's proud of his projects and continues making things he likes.
That doesn't compile. Also doesn't String::from(value) create a string? I can't return a slice to a new string in this scope can I?
Still sleeping somewhere deep in the compiler?
We should do it on 1/4
This should work. impl IpAddr { fn to_str(&amp;self) -&gt; &amp;str { match *self { IpAddr::V4(ref s) =&gt; s, IpAddr::V6(ref s) =&gt; s, } } } 
&gt; A Compromise Between Substring and Prefix Matching I played with this in the past. One thing you didn't touch is how to handle multiple words in the search query. The best I came up with was word prefix matching and requiring them to be in the same order as in the query (e.g. match "**foo**x bar **baz**" against "foo baz", but not against "baz foo"). The other is how to efficiently do this query. A trie would probably work, maybe even a regex with a weird hack (concatenating the strings).
I'm 25 years old. Rust is a small but non-zero part of my professional development and a large part of my extraprofessional interests. My company paid for me to attend RustConf in 2017. Based on this survey, though I am at the lower bound, my age group is barely in the greeen. I see this as a positive thing. At this stage in Rust adoption it is the senior developers that need to champion the cause and work on basic infrastructure to empower Rust development in their organizations.
For now you don't. `stdweb` requires tighter integration with JavaScript than what `rustc` and `cargo` support, so it requires building through `cargo-web`. But it's been on my agenda for quite some time now I plan on supporting this very soon.
Unsafe means that the compiler can trust that the programmer knows what she's doing, but in this case there is no way for the programmer to do the right thing because they can't guarantee the alignment of the array. If they could do that then the code would still be unsafe, but it would work. Something like: #[align(* Foo)] let mut array: ... Of course, if the alignment isn't part of the type then this trick won't work for arrays passed into a function, but asolution doesn't have to work for everything to be useful.
We need *Unsafe* Unsafe Rust!
We can have safe rust, safe unsafe rust, and unsafe unsafe rust. We need to go deeper.
AFAICT that’s kind of orthogonal to the OP, since that describes compile-time capabilities vs what the runtime capabilities you desire. 
No, unsafe has a very precise meaning. Pointer arithmetic with transmutes is perfectly fine. The part that is not fine is dereferencing the pointer that you obtain from it.
I want to be kind in how I ask this, but does this _actually_ work or does it "work" like how the VS Code plugin "works" where half the time the plugin is crashed and you get no assist. I used Eclipse with Java for years and I'd be happy to install it for Rust usage if it's a reliable plugin.
&gt; One thing you didn't touch is how to handle multiple words in the search query. I didn't think it needed to be said. Both substring matching and prefix matching treat spaces no differently from any other character. "pirates of" will match "pirates officially rule" but not "pirates and officers" or "of mice and pirates". Of course, one detail I *did* neglect to mention is that I generally normalize all input data with `trim()` and an HTML-style `\s+`-to-` ` substitution before working with it. &gt; The other is how to efficiently do this query. A trie would probably work, maybe even a regex with a weird hack (concatenating the strings). Because my solution was a substring patch pinned to begin on a word boundary, all I had to do was regex-escape what's been typed, prepend `(^|\b|\s)`, and then run the search case-insensitively, as I described in the blog post.
RFC: transmutes must require use of the ̟̺̜̙͉Z̤̲̙̙͎̥̝A͎̣͔̙͘L̥̻̗̳̻̳̳͢G͉̖̯͓̞̩̦O̹̹̺!̙͈͎̞̬ * keyword.
need unsafe safe rust to complete the quadrants
This should work as well as VS Code because they share the backend, Rust Language Server.
&gt; I didn't think it needed to be said. Both substring matching and prefix matching treat spaces no differently from any other character. &gt; &gt; "pirates of" will match "pirates officially rule" but not "pirates and officers" or "of mice and pirates". Guess it's not that obvious, then :D. I would actually prefer "pirates and officers" to match e.g. "pirate officer".
&gt; Because my solution was a substring match pinned to begin on a word boundary, all I had to do was regex-escape what's been typed, prepend I meant matching a query against a set of strings at once.
This would deconstruct `self`, in which case `String::from` is unnecessary. But `to_str()` takes `&amp;self`, which makes it impossible.
Yeah, Sciter uses it's own language. It also uses it's own version of HTML, but they work really well for modeling UIs.
I wonder what unsafe safe rust would be like.
Ok, that's exactly what I thought it was lol, what about Vue and Rust not working at the same time ? Running yarn dev makes Vue.js working, but logging the import from test.rs displays the hash, like /dist/fgh89hslq652 for example. Launching parcel directly (which is what Yarn does, so that's odd) makes the logging change to some Wasm module, and then using Rust works as expected... But the vue module doesnt compile ! Do I open an issue or did I get anything wrong ?
I see four things. Younger developers love the idea of being hardcore bare-metal hackers, and have never experienced the dismal horror of working on large old code bases, and so are attracted to C and C++. This is especially true of the Hackerrank community. Young developers want to make money, and at present there is no adequate GUI library for Rust for desktop or mobile[1]. Lastly, sadly, there is an angry contingent on places like Slashdot that calls Rust “political” simply because it put a notice outside its virtual clubhouse saying people had to be nice to each other. This may turn people off, even though most languages nowadays have codes of conduct. Rust is not taught in university like Java/C++/C/Haskell (Python?), and doesn’t have a compelling use-case to make kids look at it. Personally, as an older developer, I can see the ways in which Rust stops bugs I’ve seen in production, which is why I like it. But that comes with experience of working in software _teams_. The easiest way to rectify this is to finish off the impl period work, and get to a point where Rocket.rs is competitive with Go on things like Techempower benchmarks using stable async Rust. --- 1. Relm is not an adequate GUI toolkit, GTK+ looks and feels alien and cheap on Windows and Mac. Libui would have been a better baseline choice for that toolkit. 
``` fn main() { #[derive(Copy, Clone)] enum Void {} union A { a: (), v: Void } let a = A { a: () }; match a.v { } } ``` This is [it](https://github.com/rust-lang/rust/issues/47412).
moving the assignments was my first attempt but I needed that order for the loop. let mut department :HashMap&lt;String,Vec&lt;String&gt;&gt;= HashMap::new(); loop { println!("type in department {{department name}}to list all people by department, or people to retrive all people"); println!("type add {{personname}} to {{department}} to add a person to a department"); let mut input = String::new(); io::stdin().read_line(&amp;mut input) .expect("failed to read line"); let input = input.trim(); println!("you typed {}", input); if input == "people"{ println!(""); for (key,value) in department.iter(){ let peoplelist = value; println!("department = {}",key); for n in peoplelist.iter() { println!("{}",n); } } println!(""); continue; } let v:Vec&lt;&amp;str&gt; = input.split(' ').collect(); if v[0] == "department" { println!(""); for (key,value) in department.iter(){ if key == v[1] { let peoplelist = value; println!("department = {}",key); for n in peoplelist.iter() { println!("{}",n); } } } println!(""); continue; } let people = department.entry(v[3]).or_insert(vec![]).push(v[1]); if people[0] != v[1] { people.push(String::from(v[1])); people.sort(); } } i am not entirely sure of the difference between the two hashes the &amp; is borrowing rather then taking ownership right? 
I know a bit about this from talking in person at meetups: It’s based on Frank Mcsherry’s work (see timely and differential dataflow) and it is exceedingly fast. Apparently orders of magnitude faster than existing RDF databases, and fully incremental. I highly recommend diving into this code. There’s almost definitely some worthwhile things to extract. If anyone has questions I can try to answer based on knowledge from past conversations.
Awesome! This is a really well-designed crate. I'm glad to see the improved errors in this version :)
Can you give an example? I looked around and couldn't find how that works.
Those are not really a recent addition, but yes, i could do without them and for that matter inheritance is pretty useless too.
It uses the same backend (RLS), which is known to be experimental right now. Look at it this way: When the vscode plugin gets better, this will also improve :)
**Stemming** In linguistic morphology and information retrieval, stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root form—generally a written word form. The stem need not be identical to the morphological root of the word; it is usually sufficient that related words map to the same stem, even if this stem is not in itself a valid root. Algorithms for stemming have been studied in computer science since the 1960s. Many search engines treat words with the same stem as synonyms as a kind of query expansion, a process called conflation. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
I also agree. C++ is actually missing key features that would unlock all those newly added half-finished features added since C++11. If we had those features, we could finally deprecate some older features. The problem with C++ now, imo, is mainly the syntax! We are out of new syntax that doesn't look ridiculous. For example, the lambda syntax is so verbose (which is also due to bad defaults regarding forwarding and `noexcept`) that people are already working on a new lambda syntax. Lambdas are only about 6 years old, which isn't a long time in C++. C++17 also introduced `std::variant`, which emulates a sum type with some verbose syntax, due to C++ lacking pattern matching, so people are working on proposals to introduce language support for proper sum types and pattern matching. So I think the real problem is C++ has this tendency of introducing wanted features with "bad" implementations, that people deem unusuable or just verbose or boilerplate-heavy.
I like the project, but the name is confusing because of [Redox OS](https://www.redox-os.org/)
heh , looks rather similar to rust, but with little tweaks; I did something similar a while back but figured it's too much work to flesh out an ecosystem single handedly. I wonder how many of my extra personal preferences the author may consider absorbing..
You're not wrong but Copy is one of the few traits I've seen where people will suggest "you should implement it every time you can". It also does not have any methods (you just derive it) so it looks very innocuous, despite having far-ranging effects for userland code.
I rewrite my web server in Rust, I'm currently happy with it!
People not using it as a last resource?
"This is a warning and your code is bad, activate #[deny(broken_pointer_alignment)] to make this an error" is always an option. 
But casting through `*mut u8` or `*mut ()` happens *a lot* in the real world, so if you have generics the bounds are likely *inexpressible* without dependent typing. And the warning would likely be silenced in most libraries anyway, so the value is pretty limited.
Even pure assembly written by a bunch of monkeys with typewriters is still safer than unsafe rust, so it doesn't surprise me. What does surprise (and shock) me is the omnipresence of unsafety in Zig. I'm not really sure what improvements it offers compared to C or C++.
I'm not sure what you mean - where is that quote from? We generate `align 1` on direct accesses of packed fields, which may be slower or not, but it *always supported* even if the hardware can't - that is, a LLVM target for an architecture with no unaligned memory operations would likely have to come up with something that *does work* (even if it's much slower).
Then there is no virtue in it being safer than unsafe Rust...
It looks like the vue loading still isn't fully released yet, and the vue example pulls from the vue beta branch; which hasn't backported the rust support yet.
It looks like the vue loading still isn't fully released yet, and the vue example pulls from the vue beta branch; which hasn't backported the rust support yet. So until the vue branch gets merged ([soon!](https://github.com/parcel-bundler/parcel/issues/5)) it's one or the other :(
Thank you very much ! :)
Hm.... that doesn't seem to be as easy as I wish: the trait `std::marker::Send` is not implemented for `futures::Future&lt;Item=std::string::String, Error=()&gt;`
The vim popularity numbers are a dead giveaway that the sample is far from representative of all developers.
Right, once you put it in a loop you won't be able to keep a `HashMap&lt;&amp;str, &amp;str&gt;` since the source of the `&amp;str` borrows is the input string that lives only for one iteration.
I remember this post recently discussed on r/programming: [std::visit is everything wrong with modern C++](https://bitbashing.io/std-visit.html), which seems also relevant.
Yea but I want to use PureScript :)
Why not use a higher-level garbage collected language?
I use a free Amazon EC2 instance with 1GB of RAM, it may not be enough for a garbage collected language.
TL;DW?
Simplicity and the ability to use higher-level concepts like purely functional data structures.
Go does just fine. Our company's application runs on the same and does just fine. I think we use 100MB or so for our application and the database uses the rest. However, I'd still like to RIIR, but I don't want the pain of retraining our software developers.
But it won't lead to UB, right? Because the code I pass it to will always know it (in the safe subset)?
Purely functional data structures are inherently acyclic, so they lend themselves well to memory management via reference counting. There are certain things you can't easily do in Rust, but purely functional data structures are absolutely not one of them.
You're implying the GC'd languages require more memory than Rust which is a belief I've heard elsewhere so I [tested it](https://flyingfrogblog.blogspot.co.uk/2017/12/does-reference-counting-really-use-less_26.html?m=1) and failed to find any justification for it. I have actually never seen any empirical evidence to substantiate that belief.
I am personally in favour of clear and informative library names over clever puns.
Purely functional data structures are inherently acyclic, so they lend themselves well to memory management via reference counting. There are certain things you can't easily do in Rust, but purely functional data structures are absolutely not one of them.
If I were writing an nginx-style webserver, I would probably do it in Rust. Not for performance or memory footprint - though these things very much matter - but because the web is an adversarial place, and you need all the resource safety you can get. Garbage-collected languages may be memory-safe, but most of them don't give me too much help with managing e.g. filesystem handles.
I don't know was it because being garbage collected or not, but it actually use more memory than Rust in my case. My old NodeJS server uses 1GB of RAM (on a 1.7GB server), meanwhile Rust server uses about 10MB, which is quite impressive.
&gt; GC'd languages require more memory than Rust which is a belief I've heard elsewhere so I tested it I fail how to see how this link is related to Rust. &gt; I have actually never seen any empirical evidence to substantiate that belief. https://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=rust&amp;lang2=java Are you implying that boxed data on the heap is the same size as unboxed data, which is quite common in Rust? Again your Rust test results would help.
Wow, that's a huge difference.
If there's no such thing as safe Zig, then unsafe Zig had better be safer than unsafe Rust. If there's no safe code and the unsafe code is less safe than ours, congratulations, you've invented C in new syntax. Rust unsafe can be a hellscape of nasal demons and Eldritch horrors, because it's explicitly opt in; when a language is unsafe by default, it should really apply some global sanity checks or else it's just C in new paint.
thanks, and thanks for the great discussions on your [quicli](https://github.com/killercup/quicli/issues/20) issue tracker! Let's make creating CLI applications in rust ergonomic!
Hear, hear!
TIL there is a thing called highlight.js, and I stuck it on my website so I don't have to look at plain white code snippets anymore. Thanks!
Personally I don't think garbage collection is a big part of it, but working with higher level languages, especially dynamically typed ones tend to be easier to work with, and allow one to build features out faster. If I were using Java or C# over Rust I would still get the stronger typing to help avoid mistakes, but more ease of use due to libraries, the language being less challenging, etc.
Were they doing the same thing? Like it is just running webserver to respond to requests? I also wonder which of your two setups would handle more requests concurrently. The RAM consumption is interesting, but I feel like I need more info :D
&gt; Are you implying that boxed data on the heap is the same size as unboxed data on the stack No. Why do you raise the issue of stack vs heap? &gt; Again your Rust test results would help. I tried [to port that test I referenced to Rust](https://stackoverflow.com/questions/48246510/is-it-impossible-to-have-a-nested-match-on-a-recursive-datatype-that-uses-a-smar) by using `Rc` for memory management but never managed to get it to work. 
I can envisage Rust's approach being preferable when handles need to be borrowed from one scope to the next but I cannot recall ever having needed that myself. Do you do that a lot? 
What about non-modern CPUs?
&gt; Purely functional data structures are inherently acyclic, They aren't *inherently* acyclic because you can easily construct counter examples like: let rec xs = 0::ys and ys = 1::xs but they are often acyclic and some languages (e.g. Erlang and Mathematica) even impose unidirectional heaps. &gt; so they lend themselves well to memory management via reference counting. Only if the RC implementation handles tail calls which Rust doesn't. When you use purely functional data structures you need to use recursion to implement loops because you cannot mutate them so you need that tail call elimination which Rust currently doesn't do. Consequently, Rust will leak memory during recursion. 
yes, /u/jdh30 was talking about what a GC gains you.
In my extremely limited experience and opinion, isn't that what the `-std` switch is for? If you don't compile under the new standard, compile under the old; object files are object files.
I think he was referring to the benefits of e.g. Go over Rust, and I was saying that this isn't one.
&gt;They aren't *inherently* acyclic because you can easily construct counter examples right, I was assuming a language which disallows recursive values (so almost everything out there). &gt;Only if the RC implementation handles tail calls which Rust's doesn't. Fair point. &gt;Rust struggles to pattern match over reference counted data structures because you cannot pattern match "through" an `Rc`. Damn, this blows.
The LLIR output doesn't include any system linkage, so you would need to need to finish compiling to object code and then make sure clang knows to link in the allocator, libc, libunwind, and anything I'm forgetting. You're probably much better off using the staticlib or cdylib output type to emit binary artifacts that other projects can link; the only good reason (of which I can think) to do this is when you need to target an architecture or tool system that can consume LLIR but that rustc cannot currently target, which is … pretty far in the weeds. I know I've done this before; I'll try to replicate the process and take notes this time.
Could you please explain me why dependent typing is needed? Is the future const generics sysetem going to be enough to allow expressing generic pointer alignments? fn foo&lt;'a, const N: usize&gt;(&amp;&lt;align(N)&gt; 'a [u8]) {
My servers are very simple, just craw some web pages, store them and display the data. A performance test will not be fair because the rust server is more well written, but I have seen rust outperformed nodejs in many test :D 
Speaking as a guy who writes C# at his day job, the "stronger" typing thing isn't as handy as one would imagine. Earlier this week I and another fellow spent an hour looking for a nameless 500 error that turned out to boil down to calling `String.Replace` on a null string. If it had been Rust, it would at least have involved some kind of entertaining `.expect("Damn your eyes, Charlie...")` message.
I haven't read the book so I might be completely off here. I think what the author is trying to say is that if you have a concurrency problem, it might be tempting to solve it with a `Mutex`. Just lock the shared data and call it a day, but that is neither efficient nor good practice. If you have a concurrency problem, ask yourself questions like: Where do you need to mutate? Which parts can stay immutable? etc
The stronger typing makes maintenance and refactoring easier too.
Seems like a mix of Differential Dataflow and the Datomic-style (a la Rich Hickey) datalog. Did he explain why he implemented his own dataflow instead of building on McSherry's crates for timely and dataflow?
He didn’t, but if I had to guess I’d say performance. Eve has its own dynamically typed data model that I imagine he could get working better by specializing the engine to it.
I had an error in my Rust server where I forgot to put the response through my method that added CORs headers. Spent 3 days tracking that one down -_- String typing did not help here. Thinking it solves all problems is naive. It's very nice but it's not bulletproof
Er... I just said it solves a common class of problems that drives me insane in my daily work. Whatever, man. :|
If you can pass strings you're only one macro away from seamless.
Can you build a react web app with rust?
Qt seems like a great gui library to be written in rust. I wish there was a bigger push to make rust a first class citizen with Qt.
`fn foo&lt;'a, const N: usize&gt;(_: &amp;'a Aligned&lt;[u8], N&gt;)`, maybe? You could even have `Aligned&lt;[u8], align_of::&lt;T&gt;()&gt;` in the future, but it's not clear to me how well that would work with most code (especially if trait objects may be involved).
Ah sorry still a bit of a noob myself. Must've misread the initial post. In my mind the entire function was like so: fn to_str(self) -&gt; String { match self { IpAddr:V4(value) =&gt; value, IpAddr:V6(value) =&gt; value, } } Which compiles and works but not exactly what the OP was looking for in response.
I'm not sure I'm buying this argument, since the C++ compilers usually have implementations before the standard is finalized.
"It depends. Proposed criteria for decision: [...] Quick review of [successful] case studies: [...]"
Let me try and add a bit more flavor to /u/trishume's answer, as I understand Eve. Eve uses something akin to Datalog as its internal execution model: relations defined recursively using a relational model (i.e. joins mostly). This can be simplified a bit if you know you will only ever work with triples, in particular triples of ints (post-interned strings, for example), but it gets more complicated because the joins are often cyclic (non-tree shaped). Standard DB join processing can blow up on cyclic joins, performing way more work than it requires. Differential dataflow is among the few systems capable of performing incremental updates to iterative data-parallel computations (the other that I know is Logicblox). However, its default `join` operator is not the type that is robust to cyclic joins (whereas Logicblox's is); you can write [a robust implementation using differential dataflow operators](https://github.com/frankmcsherry/differential-dataflow/blob/master/examples/ngo.rs), but it makes lots of sense to do it natively if you know that is what you want.
&gt; Again, left pad was because someone took their package off of npm. Well, this problem is non-existent on crates.io, because you can't take off packages. What I meant is that it is not obvious who should get the package. (I'm not a fan of how npm gave the kik package to some company, so I think it is fair to say it was a controversial, non-obvious decision.) &gt; If a lot of people rely on request, it probably won't be given to the reqwest folks, eh? Maybe, but this would not have helped at all with left-pad. An author had a package used by almost no one taken away from him, which triggered him to take off all his packages, including left-pad, which was used by lots of people. 
&gt; For the record, rustc could warn about this (erroring would be problematic in general because *mut u8 ends up being cast to *mut T a lot, and also you can't know the alignment of generics), it's just a matter of adding the special case into the compiler. Would a warning of the kind "Casting pointer of &lt;known alignment&gt; to &lt;unknown alignment&gt;, please add an appropriate debug assertion: &lt;spell out assertion&gt;" be possible? Also, when we're not casting u8 to T, but to, say, u32, would it be possible to error?
Thanks for the link!
Thanks Frank! I'm facing a similar implementation decision (in fact, this Eve rust implementation may be another potential starting point) and also working with time-stamped triples. I've got some experiments going with a domain model that compiles to your differential dataflow as well as a direct interpreter in dataflow. It's a great fit so far. I think I've read about 2/3 of your blog and several of your papers in the last couple of months. It almost feels like I should be paying rent for living in your thought space :)
I filed a new bug: https://github.com/alexcrichton/futures-rs/issues/716
Thank you. Other folks (MSR) paid brain rent for a while, and I'm now trying to redistribute the loot where I can. If you've got any questions or asks, drop in on the issues page or the timely gitter (I can't imagine understanding DD without help; I barely do).
I don't think that the memory overhead for garbage collection comes primarily from the boxed/unboxed distinction. Heap object descriptors do take up some space, but descriptors are often amortized over multiple heap objects. In fact the sources I've seen usually place this overhead at around 1 or 2 percent of memory in use. A much bigger source of memory useage for GC systems is the set of objects which have been dereferenced but not yet collected and the free space that the garbage collector must set up to allocate into.
No, as `transmute` says that it checks the sizes and nothing else, and you're responsible for it all. We could add a new version of transmute that also does this kind of check, but like, you need these kinds of sharp tools sometimes. `transmute_copy` doesn't even check the size!
&gt; inexpressible without dependent typing I'm not much of a type theorist or systems programmer, so I might be off the mark on this, but isn't alignment a property associated with the type?
How about this? let NN = OpNN?.as_mut(); NN.Field = NN.Field2 + Value; https://doc.rust-lang.org/nightly/std/ptr/struct.NonNull.html#method.as_mut
Sure, we can definitely try it out, if anyone wants to play around with it, in `rustc_typeck::check::cast` you can just do `(self.tcx, self.param_env).layout_of(ty).map(|l| l.align.abi_bytes())` where `ty` is the type you want to get it for, and you get a `Result&lt;u64, LayoutError&gt;` (you can ignore the error / change the message based on it - since it encodes "unknown type" pretty directly).
**YES**
&gt; So I think the real problem is C++ has this tendency of introducing wanted features with "bad" implementations, that people deem unusuable or just verbose or boilerplate-heavy. I wonder if this is a result of the design-by-committee process. In order to satisfy people, early proposals intentionally have a minimal impact (such as `std::variant`, a library, vs sum types, a language feature). This allows approval and feedback, however it leaves a trail of half-features behind since nothing is ever deprecated.
Ok interesting I see what you're saying. So I needed to output the LLVM so I can see what Rust is changing the function/type names to. After that I went ahead and ran `rustc --crate-type=staticlib test.rs` which output `libtest.a` and had multiple notes that said: note: link against the following native artifacts when linking against this static library note: the order and any duplication can be significant on some platforms, and so may need to be preserved note: library: System note: library: resolv note: library: c note: library: m I then tried to compile with `clang -L. sample.ll -lSystem -lresolv -lc -lm -ltest` and get linker errors that the functions defined in `test.rs` (being called from `sample.ll`) are undefined symbols.
We got a EPUB renderer. Cool!
There are only two programming languages in the entire world with reliable destructors. One of them corrupts your data without a warning if you make a mistake.
Fair enough, but ideally the unsafe code should actually be safe, just not something the compiler can prove is safe. In this case, however, the person writing the code can't ensure that the pointer has appropriate alignment, so they can't make that guarantee to themselves. It would be nice if they could.
Isn’t this dependent types?
I think you just said that (simultaneously) stronger types aren't all they're cracked up to be *and* that the stronger types of Rust would have prevented the error?!? I'm confusinged.
A number of functions could be supported already. For example, on arrays: // To be invoked with T: [X; N] and U: [[X; A]; B] where N = A*B. fn chunkify&lt;T, U&gt;(t: &amp;T) -&gt; &amp;U { assert!(mem::size_of::&lt;T&gt;() &gt;= mem::size_of::&lt;U&gt;()); assert!(mem::align_of::&lt;T&gt;() &gt;= mem::align_of::&lt;U&gt;()); unsafe { mem::transmute(t) } } // To be invoked with T: [[X; A]; B] and U: [X; N] where N = A*B. fn flatten&lt;T, U&gt;(t: &amp;T) -&gt; &amp;U { assert!(mem::size_of::&lt;T&gt;() &gt;= mem::size_of::&lt;U&gt;()); assert!(mem::align_of::&lt;T&gt;() &gt;= mem::align_of::&lt;U&gt;()); unsafe { mem::transmute(t) } } This code should be safe, even if actually `X` is not `X`. You can add the is `X` really `X` check by opting in to an unstable feature (`unsize`), unlocking the `std::marker::Unsize` trait: // To be invoked with T: [X; N] and U: [[X; A]; B] where N = A*B. fn chunkify&lt;T, U, X, Y&gt;(t: &amp;T) -&gt; &amp;U where T: Unsize&lt;[X]&gt;, U: Unsize&lt;[Y]&gt;, Y: Unsize&lt;[X]&gt; { assert!(mem::size_of::&lt;T&gt;() &gt;= mem::size_of::&lt;U&gt;()); assert!(mem::align_of::&lt;T&gt;() &gt;= mem::align_of::&lt;U&gt;()); unsafe { mem::transmute(t) } } // To be invoked with T: [[X; A]; B] and U: [X; N] where N = A*B. fn flatten&lt;T, U, X, Y&gt;(t: &amp;T) -&gt; &amp;U where T: Unsize&lt;[Y]&gt;, Y: Unsize&lt;[X]&gt;, U: Unsize&lt;[X]&gt; { assert!(mem::size_of::&lt;T&gt;() &gt;= mem::size_of::&lt;U&gt;()); assert!(mem::align_of::&lt;T&gt;() &gt;= mem::align_of::&lt;U&gt;()); unsafe { mem::transmute(t) } } *I am not sure if there's a way to elide `X` and `Y` from the signature, I'd like to be able to create name in `where` clauses.* Note that even though `assert!` is normally a run-time check, in practice it will get elided every time the condition is known to be true at compile-time. So, while it's not as good as a compile-time check, in practice it's pretty good since it should blow-up the first time you try to test the function if it's wrong, and if it doesn't blow up it's elided entirely :D
Moving resources between "threads" (or whatever) is pretty rare in typical webserver scenarios, so you'd probably be able to get by pretty trivially using `withBinaryFile`-style functions. (Everything is scoped to the request.)
&gt; On the Rust side, you just need to make sure that function names aren’t mangled and are public. Huh, no `extern "C"`?
Here's the link for the 1.20.0 std Documentation: https://doc.rust-lang.org/1.20.0/std/ However Rust usually also comes with an offline version of this, so you might already have it.
I'm 24, and in a similar position tonyou. My day job is full stack web dev, mainly using dynamic languages (javascript/python/php), but I did spend 3 months of last year writing a Rust microservice that made it into production, and much of my non-work programming is rust focused. However, most of my peers/colleagues seem to be more interested in learning Go. Partly due to thete being more job opportunities (it is seen as mainstream in a way that Rust isn't), partly due to it being seen as simpler/easier to learn.
&gt; I think another thing is that lots of people in the committee are company-sponsored, so they will want to push for the features their company's code base needs to most. That, as well as being reluctant to removing things their companies do use (for example, IBM was very reluctant to removing support for trigraphs because they have mainframes using the EBCDIC character set which requires them). &gt; This problem isn't unique to design-by-committee, though, and I think some people have already raised concerns about this happening in Rust. It's not indeed; however I think it's possibly amplified. I also think that there's a lack of foresight in C++ that maybe Rust does not suffer so much from yet. I don't *mind* incremental solutions. One step at a time. However, *incremental* suggests that it's a first step. The problem exhibited by `std::variant` vs sum types is that `std::variant` is NOT a first step, it's another path altogether. From what I've seen, there really is a conscious effort in Rust RFCs to make them *foundations* rather than *terminals*, so they can be built upon. There's also a conscious effort about considering what paths get closed by the RFC. Nobody wants to paint the language into a corner; although of course it may happen by accident.
The implementation should be pretty simple, however right now there is no way to even specify the signature. My main reason for this post is not to seek a solution but to open the eyes of people for the possibilities hidden in the upcoming year. Having const generics in stable safe rust is a tool many people are waiting for and will change the API of multiple crates. This is just a sneak peek at what such an API might look like - in this case a few functions I met a need for multiple times while writing stuff.
I think OP's capability type is not the runtime user capability you are describing, although the two are related and the latter may very well be built on (or even automatically generated from) the former. 
Ever since I learned what mdbook was, I've been using it for all my note-taking. Good stuff!
I did. Once. But I can't find it. If anyone can show me the guy that tested jemalloc on a crapton of Rc's, realised that they all used 48 bytes, and transmuted those Rc's to &amp;'static in order to save memory, I'd be grateful.
Oh we're on the same page. Of all the upcoming features, const generics are my most desired one. I don't care much about async, generators, futures, or `impl Trait`... but `const` generics and the ability to manipulate arrays, vectors and matrices. Yes please.
Meh, what you describe is just minor issue. Combine overloading, default parameters and integer coercion and you get much bigger hell. Personal experience: spent ~2 days searching for a bug that turned out to be call to `foo(int, int, bool)` with arguments `int`, `true`, because the interface of the function changed from `foo(int, bool)` to `foo(int, int, bool x = false)`. Bonus: any seasoned Rustcean would use special `enum` for each of those `int`s. It really tells something about competence of the developers too.
I submitted a `clippy` lint for the case in the OP: https://github.com/rust-lang-nursery/rust-clippy/pull/2400 If you have any other ideas for `transmute` lints, you should submit an issue to suggest them to `clippy`. I'm pretty sure the `clippy` people would be happy to have more ideas for lints which make unsafe rust safer.
How familiar are you with C#'s type system? :p Yes, I did simultaneously say that "stronger types" (as the term is applied to C#) aren't as valuable as people seem to think, and that "stronger types" (as the term applies to Rust) would prevent the error. This is because any reference type `Foo` in C# is, secretly, implicitly, a `Maybe&lt;Foo&gt;`. If you cross your fingers, say your prayers, and respect your parents, it may usually have a value. ...The rest of the time, you're fucked.
Same old. Rewrite it if it gives good benefits with not too much effort. Leave it alone if the thousand bugs are actually features and the system breaks if you try to fix them.
 I reread this after firing it off and using that word choice was strong and harsh. I apologize. That wasn't a nice way to say that at all and frankly I'm mad with myself for having said that.
You just but I always felt it'd be nice if Rust also marked functions as `partial` above unsafe; as in those functions that can panic or not terminate. "safe" rust is then only total functions—functions that are guaranteed to never panic on their input and always terminate. Having to use `partial { ... }` blocks might be super unergonomic though at times.
https://youtu.be/6jqy-Dizd0I?t=753
That's what's not clear to me. In theory, anything that could be UB should be `unsafe`, and [PR44884](https://github.com/rust-lang/rust/pull/44884) sounds like it did that. Pessimistic loads directly from packed fields ought to be safe though, no UB at all.
You just got burned by *Primitive Obsession*. Primitive types are great to build on top on, but too few developers do build on them. A primitive type: - carry no semantic: sorry, but an Id is not a Quantity, and a Percentage is not a Price, - carry no unit: what this seconds? milliseconds? something else? Some libraries introduce half-way primitives; C++ has `std::chrono::duration` for example. Great, now you have a unit, but the compiler still has no idea what it represents: a timeout? an elapsed time? for *what*? I've even seen developers introducing an `Id` or `Quantity` type. Awesome. Except when you pass an Apple `Id` as a Car `Id`, where it's nonsensical. I've seen multiple justifications: - performance, in language where abstractions cost (Java...), - boilerplate, in languages where introducing new types is costly (C...). But in C++ or Rust, where you have generics and zero-cost abstractions, it's just often laziness or ignorance.
Thanks a lot for the feedback. Best ideas usually come from the community :) * git - Would love if you opened a github issue and explain there a bit more on the git issue you faced because didn't understand that one. * slow - it is possible that the search for newer version on startup could be the issue you are facing. I try to notify when new versions are available and that you are running on outdated versions to ensure users are running with all fixes. I do that by searching the registry which is a performance hit. * verbose - I tried to keep it to minimum important info. I know I can't hit the spot for everyone, but you can tune it down with loglevel error. But I agree that putting it in command line each time might be annoying. I'll take this comment and create an issue to support some global config with loglevel defined there. * default flows - ya that is actually what i wanted. to give a tool that works out of the box without people having to create their own tasks for every project they write again and again. I recently added a config in the Makefile.toml (skip_core_tasks = true) that actually removes all the default tasks for you if you wish to start without them and write everything yourself. maybe give it a try. * workspace - by default I run each task on every member. so ya its command line arg to tell it don't do that. I'll be happy if you open an issue if you have an idea on how you think it could be made easier while keeping in mind that same task you might want to run on member, or on workspace level without duplicating the task code. * running from src - nice idea. I'll open an issue to add that.
&gt; Younger developers love the idea of being hardcore bare-metal hackers, Really? I'd guess young people are more prone to impatience, so they don't want to learn difficult language, but have something "working quick" without looking at long-term. &gt; Personally, as an older developer, I can see the ways in which Rust stops bugs I’ve seen in production, which is why I like it. But that comes with experience of working in software teams. I like Rust for exactly the same reason, but interestingly, I liked it before experiencing work in teams and I think most people would still consider me young (&lt;26).
 fn rewrite_in_rust() -&gt; bool { true } 
&gt; If there's no such thing as safe Zig, then unsafe Zig had better be safer than unsafe Rust. Yes, agreed. Everything should be as safe as possible really. The post is showing that it is theoretically possible for unsafe code to be safer than unsafe Rust. &gt; Rust unsafe can be a hellscape of nasal demons and Eldritch horrors, because it's explicitly opt in That doesn't follow either. It isn't the "opt in" that makes it very unsafe, it's that the language doesn't really help you when you're in unsafe land (e.g. no alignment in the type system like Zig). The *reason* for that is presumably that the Rust developers had more important things to worry about, and they could justify the decision to not put a lot of effort into make unsafe Rust safe with "you won't need to write unsafe Rust very often - just be super careful", which is a reasonable justification. Zig is "opt in" too (by using it) and it is apparently slightly safer.
In general you should use the `byteorder` crate for such conversions.
Just started using this last week as a code documentation system... not quite what it's designed for. Search and indexing would be cool, but maybe a bit beyond the scope of the project. Really glad to see epub support now!
Very easy question (paging /u/imperioland): how do I get my light-background nightly docs back? There appears to be a "brush" button with a menu to switch the theme, but it doesn't do anything.
&gt; So essentially we need Unsafe Rust to be more ergonomic. I almost got the impression it's deliberately un-ergonomic to stop you wanting to write unsafe code in the first place.. 
A more general version of your chunking: https://play.rust-lang.org/?gist=60d84c52ac5a6d6dd06e786ba3bf50ac&amp;version=nightly (uses unstable specialization, to support all array sizes (instead of a short harcoded list) it'll need integer generics)
&gt; Damn, this blows. Yeah, it's a real shame. I think if Rust supported TCO and pattern matching through `Rc`s then it would be a different story but, for now, GC'd languages have real advantages here. 
Way to not engage! :) You da man.
Either use he, she, or they BUT STOP MIXING THEM.
&gt; A much bigger source of memory useage for GC systems is the set of objects which have been dereferenced but not yet collected and the free space that the garbage collector must set up to allocate into. On what basis do you say it is "much bigger"? Doesn't Rust defer `Rc` decrements to the end of scope? If so, it is potentially introducing more floating garbage than a production GC. Without measuring it, I'm very skeptical of any claims that one or other is "much bigger". 
&gt; If anyone can show me the guy that tested jemalloc on a crapton of Rc's, realised that they all used 48 bytes, and transmuted those Rc's to &amp;'static in order to save memory, I'd be grateful. That's an interesting article, thanks. You definitely want to avoid `Rc` whenever possible because it is so slower and memory hungry. &gt; also, I'm not surprised that Rc's are slower than GC. What we're talking about, however, is a system that relies on the ownership model, and uses Rc as a last resort. Absolutely. I share the dream that it might be competitively good, if not now then in the future. However, the reality appears to be that nobody has ever actually tested this. 
Require the response to be of type WithCorsHeaders
&gt; What major benefit does garbage collection gain you in this context? The servers I've written recently maintained in-memory state as a purely functional dictionary, making it easy to backtrack. The purely functional collections are traversed using recursion because they are immutable. I've tried doing similar things in Rust and it is a disaster. There is no GC so you resort to Rc. There is no unidirectional heap so you must manually check for cycles because they leak. Even if you have something as simple as a tree of `Rc`d branches it turns out Rust's pattern matching doesn't support indirection through an `Rc` so you must resort to compiling your pattern matches by hand, which is like going back to C-style switch. I actually gave up on the project in the end because it was so cumbersome. Much easier to use a GC in that case... 
Followup (ping /u/freshcannoli since I don't like sibling replies): `rust-ffi.rs` #[no_mangle] pub extern "C" fn call_me(argc: isize, _argv: *const *const i8) { println!("Received {} pointers to char", argc); } `rust-ffi.c` extern void call_me(long long argc, char** argv); int main(int argc, char* argv[]) { call_me(argc, argv); } Now let's do some compiling. $ rustc --crate-type=staticlib rust-ffi.rs #=&gt; librust_ffi.a $ clang rust-ffi.c -L. -lrust_ffi #=&gt; a.out $ ./a.out hello world Received 3 pointers to char Making a staticlib archive and linking against it works great. $ rustc --crate-type=staticlib rust-ffi.rs --emit=llvm-ir #=&gt; rust-ffi.ll $ clang rust-ffi.ll rust-ffi.c #=&gt; errors about not linking the Rust stdlib Making an LLIR output file and using clang to finish compiling that is less great. As long as you have function and type declarations in your caller language (I'm using C, but anything Clang accepts will work here) that map to the `pub extern "C"` functions and types in Rust, your caller language can freely enter the Rust archive. Complex Rust types are not FFI-safe, because Rust does not have a fixed memory model or ABI yet. A data-carrying enum is a frightening thing to have crossing the FFI boundary, because the other side has to have something that exactly matches it, and we don't know what it looks like! As a general rule, only primitives and `#[repr(C)]`'d simple types should cross FFI. You can freely give out *pointers* to opaque types that you allocate and free in Rust, and that the FFI caller just has and doesn't ever try to use directly, since pointers are just words that can cross FFI. ---- Unless you have a really good reason for emitting and consuming the LLVM IR textual representation of a file, which is pretty niche, you're much better off having `rustc` build an object-code archive that the other compiler can just eat. These archives can even be consumed by GCC or MSVC, whereas LLIR can only be consumed by LLVM (`clang` doesn't process `.ll` files at all; it just ships them to LLVM proper alongside the LLIR it generates from source, and then LLVM finishes compiling and links). Since `rustc` is just a front-end to LLVM like `clang` is, and `rustc` knows how to pull in system libraries for linkage, there's not really any particular reason to defer final compilation of Rust code to object files unless the Rust toolchain is incapable of emitting the object code you want and Clang *can*, which is ... rare. I would guess, but I'm no expert, that in this case you'd have to compile `libstd` to LLIR and tell Clang to pull THOSE in as well, and let LLVM deal with stripping everything you don't use. TLDR get comfortable making object-code archives for FFI first, and work your way up to passing LLIR instead of object code once you've got that figured out.
He might be pointing out that RC is a form of GC. 
This is almost a *direct hit* on the roadmap RFC draft I have so far...
I suspect the answer is "you can't", but I don't know for sure. If anything I'm a bit puzzled at why you'd even want to do that. `from_str()` borrows its input rather than taking ownership of it, so it's not like there's any need to return the original string to the user when the parsing fails.
One obvious use case is specifying some subsection of the `&amp;str` that was unparseable. Further, it's much more ergonomic to handle, display or pass off the resulting error type rather than the error type and the `&amp;str` separately.
I agree with most of things, but I really would like async/await sugar ASAP. Sure you can do without it, but it makes code so much more readable...
I think it's like that to an extent, but there's some parts where they can have the compiler assist you/write in such a way that you don't need to think so hard to make sure it's right. Not 100% sure though, because I don't know unsafe rust well at all. That said, an example of improving unsafe rust is finishing inline assembly, which I'm let to believe has several problems and is unfinished. ¯\\\_(ツ)\_/¯
Right. You can add as many variants to the enum as necessary to specify which stage of parsing failed, but I don't think that you can pass along and reference the input `&amp;str` itself in the error message in the way you're hoping to. [This](https://doc.rust-lang.org/src/core/num/mod.rs.html#3361-3394) is how the standard library handles the display of `int` parsing errors, for example. The errors tell you the shape of what went wrong but they don't give you a full-blown "here's your input and here's the exact spot where parsing failed" message. As far as I can tell, that's beyond the capabilities of `FromStr`.
It also allow you to make much more mistakes. Static typing is for stuff that HAVE to work.
`from_fn` on slices doesn't work well if the function panics. It would either need to catch the panic and destroy only the ones that have already been initialized or leak the entire thing.
While this ties back to a lack of documentation, I'll just clarify one point while i"m here. &gt; 4.3 The lack of multithreaded tokio cores concerns me Tokio itself is (mostly) just futures + mio. It doesn't provide a multithreaded core because it doesn't need to. It lets the user of Tokio build its own concurrency setup on top. You can run multiple cores yourself, or you can do all work on a thread pool (or some blend thereof). All of Tokio's types are Send.
with `const` generics this will become so much faster! For now, recommend ``` #[inline] fn rewrite_in_rust() -&gt; bool { true } ```
Eventually, we'll have a version drop-down on doc.rust-lang.org Just haven't done it yet
&gt; GC let me have full type inference, What do you mean by this? I'm not too familiar with programming language design, but I would not think a GC has any implications on type inference. 
&gt; Does that mean we can have official EPUB versions of the book soon? For a much closer definition of "soon" than in the past, yeah. [We still have to update to actually use this](https://github.com/rust-lang/rust/pull/47753), and then add the proper build...
As someone doing something close to embedded development (working on a hobby OS in rust) definitely inline asm really needs to be improved. I wanted to get sine and cosine working and looked into writing inline asm FPU code, and had a lot of trouble with this one error (SIGSEGV: invalid memory reference) that I couldn't find any information on related to inline asm. One thing that would be a godsend is a crate or built in API that would let me easily create functions and pass parameters to a multiple line chunk of asm code in a safe ish way. I was considering using some fast software sine assembly but the current state of inline assembly at the moment made it just easier to write the same thing in plain rust. I feel like it should be possible to create something like what I described above, but I really don't know too much of the specifics of how it would need to be implemented to make a guess. But something that lets you "safetly" integrate assembly into code is one of the last big things that needs an overhaul for embedded (along with xargo integration, but thats in the works already). I know inline assembly will never be close to safe rust code, but it would be nice to have some kind of framework inplace that helps a little.
oh, you can definitely do this, if `FromStr` was defined with a lifetime. Here's a playground with an alternate version of `FromStr&lt;'a&gt;` that allows this: https://play.rust-lang.org/?gist=9e5a3324e612f3b127d62c56e327256f&amp;version=stable
The comparison that comes to mind for me would be to a soldier who wears body armor but complains that bullets still get through it. He can, of course, envy some other guy whose armor is somewhat more effective, even if the other guy still isn't invulnerable. :)
You can specify a category of error with variants but not the specific input that triggered the error. If it is impossible, it's in my mind a significant flaw in the design of `FromStr`, since you should be able to point to where the input is wrong without heap allocating or abusing enums. Here's a version of `FromStr` that would allow this: https://play.rust-lang.org/?gist=9e5a3324e612f3b127d62c56e327256f&amp;version=stable
What does that actually give you over the existing version though? You already know what the input is because you just provided it to the parse function.
I'm writing a parser, so the error will be occurring from a small section of a much larger String. I'd like the error to specify the isolated portion of the input it failed on. Without this, my options are 1) allocating a new string because the type system can't do this, 2) constructing a really awkward system to return the start and stop indexes of the part of the string that failed, 3) Logging a much larger string and then spending time later trying to find the part that caused the failure, 4) not using `FromStr` (which would be easy but this issue comes up from time to time and I'd like a solution going forward). 
I've read papers that benchmarks GC'ed languages and the conclusion is often "can be about as fast as manual memory management, but have higher peak memory usage". Can't find the one I was thinking of right now, but https://dl.acm.org/citation.cfm?id=1094836 is similar. That said, it's certainly *possible* to make GC'ed programs small. I interpret your tests mostly as saying "OCaml is slim and lightweight, Swift is big and gnarly, .NET in general is somewhere between." GC is part of that but hardly the whole story; there's lots of wiggle room for memory semantics besides "tracing GC, refcounted or manual".
Maybe `#[inline(always)]`
&gt; Curious - what language did you implement this low-latency server in? OCaml. &gt; What do you mean by this? I'm not too familiar with programming language design, but I would not think a GC has any implications on type inference. Rust uses the type system to convey ownership (linear types) which cannot be inferred so you must declare and annotate types by hand. OCaml uses the GC to handle ownership so it doesn't need linear types and can use a type inference algorithm that always infers the most polymorphic type and can infer the type of any expression. 
You sunk my Battleship! But in seriousness, if this is roughly what to expect from Rust in 2018, I'm hype.
I'm the opposite for my are group 18-24. I actually quite love rust and came into the community last year after my high school robotics couch told me about it. I was going to go the route of learning c, but after we talked about rust that's the path I decided. Though I'm only a hobby developer so I don't have to worry about what's popular at the moment, which is kinda nice to be truthful.
I'm the opposite for my are group 18-24. I actually quite love rust and came into the community last year after my high school robotics couch told me about it. I was going to go the route of learning c, but after we talked about rust that's the path I decided. Though I'm only a hobby developer so I don't have to worry about what's popular at the moment, which is kinda nice to be truthful.
The whole thing around Traits serving the purpose of duck typing, but statically checked, is something that I've thought for a while, but really never had the concrete ability to talk about. The key part is that Trait impls can be added later on, after the structure already exists, as opposed to how Interfaces are handled in Java. In this, Rust is more conservative than Swift is, with its coherence rules. But that doesn't come up too often, so it's not that big of a problem, and when it is, a Deref-able newtype wrapper can fix that.
FWIW, parsing with nom will help with the question you're actually asking (return an error with context into the source text). The Error type carries a context value, which is a failure code and a reference into the source buffer indicating the start of the specific parse operation that errored. If you build a tree out of its macros, nom typically returns the error from the root node's perspective, which can be overly large. It has options to build a list of errors, which requires an allocation as the tree unwinds, or you can write your own code that is much more shallow and ensure error handling with the correct context. But yeah, I agree with you that `FromStr` should *absolutely* be bound by the lifetime of the input `str`, since *all`str`s have lifetimes*.
I'm excited to see where this goes. How Rust handles generators interests me. The use of C# Generators in Unity to create co-routines that can run across multiple frames but are written in a procedural manner interests me, and I've got an itch to scratch designing an engine built around that kind of structure of collaborative asynchrony.
The examples in the [dev blog](http://incidentalcomplexity.com/) also look really inspiring. I wonder whether there is a community willing to continue their work.
Why not? If that’s an invariant that they want to maintain they can write their own wrapper pointer type that maintains it. But if they want to type erase the invariant to, for example, interface with C, they can use raw pointers. Complaining that these raw pointers type erase the alignment is a bit moot, because doing what C does is their whole point. In particular because in the time it takes to complain one can write the wrapper that solves the problem. Yet nobody seems to care enough about this to actually do that. Maybe because even if you preserve the alignment you still need to make sure that dereferencing the pointer is safe and if you manage to do that then the alignment is correct.
It is going to compile (probably transpile to C at first) a language similar to Jonathan Blow's Jai language, as that's what inspired the project. I'm still working on parsing at the moment. I keep on scrapping everything and restarting, which is stupid, and I'm resolved not to do that anymore. However, now tgat I recently found a full-time job I have less time. If I ever get something eirth sharing working, I'll probably share it on this subreddit (assuming it's still written in Rust).
&gt; I've read papers that benchmarks GC'ed languages and the conclusion is often "can be about as fast as manual memory management, but have higher peak memory usage". Can't find the one I was thinking of right now, but https://dl.acm.org/citation.cfm?id=1094836 is similar. That's the paper I see most commonly cited but it only addresses toy implementations of a variety of GC algorithms, most of which haven't been used in production for decades. Despite the pre-existence of a real production GC in the JVM they actually neglect to test it. Furthermore, [other tests](https://www.excelsior-usa.com/blog/java/5plus-garbage-collectors/) found that HotSpot doesn't exhibit that behaviour. &gt; That said, it's certainly possible to make GC'ed programs small. I interpret your tests mostly as saying "OCaml is slim and lightweight, Swift is big and gnarly, .NET in general is somewhere between." GC is part of that but hardly the whole story; there's lots of wiggle room for memory semantics besides "tracing GC, refcounted or manual". That is entirely possible but it doesn't change the fact that this commonly-held belief seems to be entirely unjustified. I would love to see it tested properly. 
And here is your example with my function(that I needed to add a lifetime to): https://play.rust-lang.org/?gist=0cb5009fa1fbf1e638dd181fe035e896&amp;version=stable It doesn't compile, because the `String` there doesn't live long enough. In your usage example the string is `&amp;'static`, but real programs tend to want to read strings from user/network/database/files/etc.
Only in that it won't assemble ( 100 - 1^-10 )% of the time (assuming a minimum number of instructions to actually do stuff, I'm sure the change of an instruction assembling is actually not nearly that bad, but try assembling a couple hundred of them (random number) and having them all be right. Also, the exaggeration is intentional as in reality if a bunch of monkeys with typewriters managed to assemble say and entire idk... Chip 8 emu, I'd probably have gotten struck by lightning several times, and won the lottery just as many or more times)
Very digestible, good post!
Great work, /u/withoutboats ! Looking forward for more on this.
as i expected thank you
I would. Love for this to be the road map for this year.
This article is very well written! +1
&gt; What I would really like to see is a walkthrough of creating a medium-sized program in Rust This would be fantastic. There's loads of great libraries around, but I haven't yet seen much code that shows how a non-trivial app is structured. And a big +1 on all the rest too - especially SIMD and Embedded! :)
Would love to be able to search 
An example of a medium sized app is actually the one area I hope to be able to contribute to myself. Unfortunately I can't open source the only production Rust app I've created so far, but I figure my second attempt is likely to be better anyway :)
Rust doesn't guarantee that your destructors are run. E.g. they are not run when the process is killed (e.g. `cargo watch -x run` and you modify a source file) or when you have cyclic references.
&gt; I don't recall any abstraction in rust for the case where you want to alias something but keep null safety and "bit pattern" safety Isn't that just Cell?
I'm working on a no-frills BLAS-flavored generically typed linear algebra library. Focus is on correctness and avoiding `T::clone()` calls whenever possible. No attention to numerical stability or blazing speed, since this would be working on exact types like `num::BigRational` and other rings like modular fields that aren't unstable like standard floating point. Other actual BLAS wrappers exist for that sort of thing. 
What would the const generic version look like?
I've been banging my head against problem 502 for literal years.
Oo, I *really* hope we get self-referential struct support in Rust at some point. This feels to me to be like const generics in that Rust doesn't quite feel complete without it. If we could get it within 12 months, that would be amazing.
Maybe the WASM target automatically forces public functions to a standard calling convention?
This one's easy. :) https://play.rust-lang.org/?gist=1920ede58f948e2d0cfca94dc811f634&amp;version=stable But really, there are [other people with the same problem](https://www.google.com/search?q=rust+lifetime+in+associated+types) with lifetime parameters in associated types. The answer I came up with is you have to either use unsafe code or wait for the rust compiler to learn some new tricks.
This makes me wish for a "semi-safe Rust" mode that is stricter about these sorts of things, but still suitable for FFI.
True, the function `read_from_stdin` isn't possible (without leaking memory), even if `FromStr` had a lifetime parameter, but that's a problem with that specific function. I would just refactor the code to create `line: String` on the stack, and call `line.parse()`, and the result would be valid for the lifetime of `line`.
That's not just this specific function - that's a problem with any usecase of loads a string from somewhere and parses it. If `FromStr` had a lifetime parameter, all these usecase would have to provide some proof that the `String` is alive while the result of the parsing is being passed around.
Thank for your explanation.
`collect()` has an impl to turn a `Iterator&lt;Result&lt;T,E&gt;&gt;` into a `Result&lt;Vec&lt;T&gt;,E&gt;` . It's *awesome*. You might be able to make it do things other than a Vec if you try, I'm on my phone and can't experiment.
You can collect an `iter&lt;item=Result&lt;T, U&gt;&gt;` into a `Result&lt;Vec&lt;T&gt;, U&gt;` with the exact behavior you're looking for. I.E. Remove the `expect` and the `collect` will do what you want.
Perfect, thanks /u/icefoxen and /u/Eh2406
What do I do when I really do need to make multiple mutable/immutable borrows? In my below code, I need to insert a value into a tree (`self.crk_col.crk_idx`), get a different value from it, and later update multiple values in the tree. How can I do this? let v_low = low + !inc_l as i64; self.crk_col.crk_idx.insert(v_low, p_low); // Mutable borrow let j_low = self.crk_col.crk_idx.get(1 + v_low); // Immutable borrow if !j_low.is_none() { for idx in (p_low+1)..(j_low.unwrap()+1) { let mut indices_to_add = self.crk_col.base_idx[idx].clone(); self.crk_col.base_idx[p_low].append(&amp;mut indices_to_add); self.crk_col.crk.remove(idx); self.crk_col.base_idx.remove(idx); } self.crk_col.crk_idx.subtract_where_gt(v_low, j_low.unwrap() - p_low - 1); // Mutable borrow } Thank you so much for any help!
In the meantime you could use this: https://github.com/danslapman/rust-mdo-future
You are a hero!
Either approach results in limits to where it can be used, I'll give you that. &gt; real programs what's with the lip? I'm asking about this for a production codebase.
heh
While I agree transmute being a sharp tool and the user being responsible of using it, I think that it would be immensely beneficial to warn in cases where the compiler can be statically sure that the use case is certainly wrong – it would seem even unkind and un-rustic not to do that! Fortunately a lint just landed to help: https://github.com/rust-lang-nursery/rust-clippy/pull/2400 ...which brings to mind: I really wish that getting clippy to stable and part of the default package is going to happen this year :)
 const fn rewrite_in_rust() -&gt; bool { true }
&gt; real programs &gt; &gt; what's with the lip? I'm asking about this for a production codebase. In a real program you wouldn't have something like `Point::from_str("x: 1.0, y: 2.0").unwrap()` - that's good for demonstrating the function but pointless in actual code because you could just write `Point { x: 1.0, y: 2.0 }`. In real programs you would have `Point::from_str(string_you_got_from_somewhere)` or `Point::from_str(somewhere.get_string())`, and then the string won't be `'&amp;static`.
&gt; It lets the user of Tokio build its own concurrency setup on top. You can run multiple cores yourself. Forgive me for the stupid question: Suppose I have a 4 core machine, and the only thing I wish to run on this machine is a fairly standard web API server with some CRUD apis which do parameter validation, run a database query, and then return a response to the client. Notably there is nothing especially CPU intensive going on. Now presumably in this scenario if I want to make best possible use of resources, I want to run 4 tokio cores, one per cpu core. What I don't understand is how I would load balance between the 4? I guess one reason why i have an intuition that this should be possible is rayon and it's work stealing which will automatically balance work between all cores. I feel ideally tokio (or some layer on top of tokio) ought to support something similar. But I'm admitedly not very knowledgable about the details of either implementation...
I asked [a similar question](https://www.reddit.com/r/rust/comments/62hi8e/best_way_to_deal_with_iteratormap_when_map/) almost a year ago and got a couple of good answers. The suggestion to look into [itertools](https://crates.io/crates/itertools), in particular, seems like it might be what you're looking for.
Yes, but you'd be hard-pressed to find an example where llvm wouldn't optimize that one already
First, I think the mutable borrow it's complaining about is the `subtract_where_gt` row rather than the one you marked. Second, it looks like your tree values are integers, so we can copy them without hurting performance. To go from an `Option&lt;&amp;i64&gt;` to an `Option&lt;i64&gt;` you would do `.map(|x| *x)`, so you'll end up with something like: let j_low = self.crk_col.crk_idx.get(1 + v_low).map(|x| *x); This should resolve the borrow check error. For extra bonus points, use the `if let` construct after that, like this: if let Some(j_low2) = j_low { for idx in (p_low+1)..(j_low2+1) { /* ... */ } } ...this way you don't have to unwrap `j_low`.
Yep. The person writing the `FromStr` trait decided what the trait definition should be, i e, that `FromStr::Err` it should not be able to depend on the input string. This was a design decision which you cannot change without changing the trait. Maybe in hindsight the above version of `FromStr` would have been better, or it would have caused problems for some other use case of `FromStr`.
Don't get too excited, I don't want to disappoint you. I said async/await/generators within 12 months, I did not say self-referential structs. I do not have a fully general solution to an open research question up my sleeves. ;-)
There's actually a [PR for that][pr] in the works! ([proof-of-concept copy of *The Book*][poc]) [pr]: https://github.com/rust-lang-nursery/mdBook/pull/472 [poc]: https://phaiax.github.io/mdBook/rustbook/ch01-00-introduction.html
So what would be the point in using const like this then? What is the hype about const generics for? Does it remove the current limitation of inference for Array sizes being 32 max? Anything else that is neat it would enable? I think there is some site that keeps track of these features and provides examples, or at least I remember a podcast show about them.
I've seen hype for const generics a bit, I don't get what they are or what sort of benefits they bring just yet, but a better idea with seeing these examples here. Is it allowing arrays as parameters without having to specify a static length/size? Any more examples? I'm looking forward to NLL and `impl Trait`(streaming iterators I think was the reason, or maybe it was GAT I was waiting on..), async is pretty important for web related stuff afaik(especially for websockets sharing port 80/443 iirc from current projects having trouble supporting it well).
I believe the standard library "cheats" here. When you have a UTF-8 error, it'll return the index where the error was encountered so you can figure out which bits of the input are good.
Thanks a TON, this cleared up a lot of questions I had and pointed me in the right directions. I'm going to work with this and see where I get, thank you!
No. If you're writing something new though, you should write it in Rust. :-P
There's a small trick: if you open the "Debug" window of Visual Studio and attach to your process, you will see thrown exceptions in there. You can also make the debugger break on unhandled exceptions.
&gt;This is also how Futures have been designed to work in Rust, and &gt;one of the reasons they lead to *better performance *and *lower &gt;memory overhead* than systems like green threads. Just curious, What will prove it to you?
Slightly OT but does anyone know of a similar tool in the Rust ecosystem with Asciidoc support?
This is also how Futures have been designed to work in Rust, and one of the reasons they lead to better performance and lower memory overhead than systems like green threads. &amp;nbsp; Just curious, It's said the performance of tokio is not good now, how did you prove what you said?
In case of a parse error Option one doesn't sound too bad. The performance overhead for allocating a new string and copying something into it won't really be a problem. It would only suck if you wanted your parser to never allocate memory, but in that case you could create a static buffer in advance...
It uses an embedded Python environment: https://www.mercurial-scm.org/repo/hg/file/@/rust/hgcli/src/main.rs :/
I'm genuinely interested as well -- I have only been following Tokio ever now and then for the last year (but don't have a project that uses it): Who said the performance of Tokio isn't good? Compared to which other system? IIUC you need to be careful to use multiple cores and possibly threadpools to really use it to the max, but that's ergonomics issue, and not something that inherently limits how much throughput you can get.
https://blog.guillaume-gomez.fr/articles/2017-02-22+Rust+asynchronous+HTTP+server+with+tokio+and+hyper
https://mmstick.github.io/gtkrs-tutorials/chapter_04/markdown_to_html.html
AFAIK there is no Asciidoc parser in Rust
https://github.com/tokio-rs/tokio-minihttp/issues/9
This was posted on 2017-02-22. I've seen some performance problems discussed and fixed since then. No idea how it holds up today though.
If you are willing to use nightly Rust, there is https://github.com/alexcrichton/futures-await , though I think it is considered experimental for now (well generators in general). One of the limitations is that it only works with owned values as of now, but I've found my code to get significantly more legigible this way. 
One thing I like about Rust, that helps avoid become full of half-useful, conflicting features like C++, is that when new features are implemented, they are hidden behind a `#![feature]` flag. This way, we can be free to implement cool new features in an experimental fashion, and it gives us lots of time to try out new features and notice fundamental problems with their design before they are stabilized (which is usually an irreversible decision).
I thought this too 
For many applications, I agree tokio is fine today. A single-threaded event loop is sufficient. Either the applications just aren't CPU-bound or the CPU-heavy stuff is easily farmed out to a `CpuPool`. The Rust application I'm working on now is in this category. But let's consider the type of application I write at work (Google). Google has a lot of really nice common infrastructure for this kind of stuff, including a fancy multithreaded event loop that's well-integrated with its RPC system (Stubby, basically the predecessor of gRPC). At a high level, my typical application is basically a proxy server. It receives Stubby requests, fans those out into subqueries to other Stubby servers, waits for the replies, does some application-specific stuff (usually not very CPU-intensive), then replies to the inbound requests. Most of the work is handling the I/O, so doing stuff in thread pools isn't going to help much. What about multiple event loops (which I've heard called the "siloed" approach)? Well, there are complications: * How do you ensure balanced load between the cores getting inbound requests? One of my servers is old enough that it started life single-threaded. Going from 1 thread to ~8 threads, with 1/8th as many processes, significantly improved tail latency. There can be short-term load imbalances between processes, and they're less dramatic if you have fatter, unsiloed processes. * Do you have to have separate outbound connections for each silo? Yuck, this overhead is significant in terms of memory usage and health-checking costs (bandwidth and CPU). It's an N^2 thing (connections = clients * servers) unless you aggressively subset and/or add a mixer layer, which have their own complications, so I'd rather not be forced into them prematurely. * Or so that you can share outbound connections, rather than one event loop per CPU, do you basically do a separate event loop for outbound connection types to each server type? That gets ugly fast. It limits scalability of course, and rather than just being able to monitor overall CPU usage, you have to watch if any of those threads are close to the limit. Also, you need a lot of thread handoffs then. It'd be better if when the outbound replies you're waiting for come in, you can reply to the inbound request right there rather than handing off to another thread. IIUC, tokio is designed to always write to a connection on the tokio core that owns it, even though most of the time a write would succeed immediately from any thread.
There is an unsafe solution for self-referencing problem that has landed few days ago. #![feature(generators)] fn main() { unsafe { static || { let x: u64 = 1; let ref_x: &amp;u64 = &amp;x; yield 0; yield *ref_x; }; } } It's unsafe because it's UB to move generator after you called resume. An async/await lib built on top of it: https://github.com/rozaliev/mirage 
It is also probably quite feasible to make Rust work with MSVC 2008.
Same here. The way I see it, we have two possible solutions: 1. Position independence: store an offset relative to the position of the value instead of a pointer/ref ('thaw'). All access to the pointers must take value position into account. 2. 'Freeze' the position in memory – e.g. by keeping the value `'static` or `box`ing it. The value may not be moved. A solution that offers the programmer a maximum in control would allow both options somewhat transparently and use the type system to distinguish thawed and frozen values.
Aaaa how is that not an error?
[Iron Pear](https://bitbucket.org/TechPriest/iron_pear) - my playpen for learning Rust and Bittorrent-related stuff. At this moment it can't do much but parse torrent files and I'm not sure I won't get bored with it someday soon, but maybe it can be useful for somebody in any way.
"What’s the biggest challenge when hiring talent?" &gt; Not enough diverse candidates - 30% &gt; Russian Federation 5/7
Seems like lot of magic to me, but who knows...
How would I go about waiting on two (different) asynchronous receiving channels? I'm trying to utilise `gstreamer` and I need the player thread to respond immediately to signals from its parent, but I also need it to handle EOF/errors on the actual audio file (which is provided by waiting on another channel). I'm currently handling one with a blocking wait. A nested `if let Some(msg) = ...` results in the waiting on one channel to be blocking for the other, so that doesn't work. Does `if let Some(...) {} else if let Some(...) {}` work in Rust for channels?
Of course it can work. An offset-stored reference is simply a different type from a regular reference, and the conversion between offset vs. absolute reference happens transparently in the compiler. C++ has had a pointer-to-member type since forever, it's just that essentially no-one uses it because of its horrible safety and ergonomics. In Rust's case, this could be solved for instance by having `&amp;'self Bar` be a relative pointer, and introduce monomorphization over lifetimes. So when `Iter&lt;'self, Bar&gt;` is monomorphized, its internal `&amp;'a [Bar]` reference monomorphizes as an anonymous relative pointer type. If you borrow this as a regular `&amp;'a [Bar]`, the compiler already today freezes the struct in memory for the duration of the borrow, and so it's entirely possible to safely convert this relative pointer into an absolute one, completely transparently to you. I'm not saying it's going to be easy, nor that this is necessarily the best solution. But it's definitely *possible*. 
Maybe you're already aware of it, but I think you're a good candidate to have a worthwhile participation in the inline assembly Pre-RFC discussion here: https://internals.rust-lang.org/t/pre-rfc-inline-assembly/6443/19
I believe this is a LanguageClient issue, see e.g. https://github.com/autozimu/LanguageClient-neovim/pull/193, https://github.com/autozimu/LanguageClient-neovim/pull/286, https://github.com/autozimu/LanguageClient-neovim/issues/294. I don't use snippets myself, so I'm not sure if any of those are really related to your problem, but you should have a look around existing issues and maybe open one yourself, if none fits. Autozimu is really active.
Show me when it's done even if it's in any other language :-)
Man, this is seriously awesome! `mdbook` makes great books, but would be so powerful as a general documentation tool with searchability. We were thinking that marriage between `rustdoc` and `mdbook` would be made in heaven :)
I agree that it is not optimal, although in many cases the overhead of the lock is much less than the 'payload' of the operation. Is it not better to say that _overlocking_ is a sign of bad design?
I guess the compiler hackers are not the semi-gods we thought they were, what a disappointment ;) 
I have yet to see a reason why offsets don't work, especially in the case of generators, where references can be loaded into the stack at each resume and placed back in the generator when yielding. I mean, I guess it could be more complicated than it looks at first glance, but it would be nice if you could explain why they aren't viable, or point us to some blog post or comment explaining why.
Worked first time, thanks very much! If-let is a nice syntax too, thanks for showing me
`std::io::Error` is probably the biggest example of this. It even has an additional layer that allows also to propagate OS error numbers. https://doc.rust-lang.org/std/io/struct.Error.html https://doc.rust-lang.org/src/std/io/error.rs.html#67-75 
&gt; (last updated January 10, 2017) Did they mean 2018?
&gt; an in-memory database implemented using purely functional dictionaries. It does seem that this kind of thing would essentially require a pluggable GC at least (that is, "GC" within a structure-specific arena), as soon as the in-memory database starts featuring cycles. That is, unless there is enough of a structure to the "dictionaries" that all memory-deallocation operations are predictable, but the "purely functional" qualification makes that unlikely (since it implies that it's expected that some references to "old", even deleted data will hang around indefinitely).
You should probably make the `Async::poll` method in your library unsafe.
there is the [`select!`](https://doc.rust-lang.org/std/macro.select.html) macro in the standard library, but it is unstable and will probably never be stable, at least in its current form. the crate [crossbeam-channel](https://docs.rs/crossbeam-channel/0.1.2/crossbeam_channel/) offers mpmc channels with select
Yeah, definitely, I should probably reread everything and check once again. It used to be easier with immovable types, but with unsafe gens have to check for accidental moves. Thanks for a reminder!
You are right, but `ExprVector` arguments are used in `ArrayMap` only in argument for `Vec` (`elements: Vec&lt;(ExprVector, ExprVector)&gt;` after substitution), so why we can't derive `Default` in this case? Probably it is a trait derivation algorithm limitation in case of circular references, which results in almost-unrelated error message.
"Wowzers" 'Ready for the mosh pit shaka brah.'
How should I make a single executable web server (some toy project function like http file server) listen to multiple address? As far as I know, most production web server use nginx or other router and let the actual server listen to one address. However it seems that nginx on windows is closed source. Should I make a router server in hyper in front fir each address?
I understand what you're saying now...I don't believe it has to do with the circular types but the generics. Check out this reduced test case with no circular types: https://play.rust-lang.org/?gist=33adfa26b2b3cbec8189bde3eae0b17a&amp;version=stable My guess is that derive isn't smart enough to understand that it doesn't need the generic parameters to be default.
I write a letter t of unsafe code and find it very ergonomic :/
Is there still any support for full coroutines or will that be never supported in the language?
Maybe not from stdin, but you will read it from a file, or a network request/response, or a database... Having somewhere to put that string is easy - but if the result of `::point_str` is going to borrow that somewhere, you need to provide the compiler with a proof that that somewhere is still available - at least until you are done with that result.
Can you write an user defined integer type in C++ that has the same interface as int but with explicit instead of implicit conversions?
Why is that bad? That might only be bad if your objective is to make money. If your objective is to make the web better then other browsers adopting better technologies is the best that could happen.
Yeah, exactly. The lifetimes of the sub-trees in the dictionaries is determined by the result of processing the input data, which is non-trivial. There are no cycles so RC is an obvious alternative to a tracing GC but RC is slow and requires of a lot of memory overhead per node (the nodes are small) so it isn't a strong contender. The only obvious solution is to Greenspun you're own tracing GC which seems silly... 
I skimmed the discussions about immovable types a while back - I didn't know they were a real thing yet! I see you're using unsafe { static move || {...}}. Is this now how we're doing immovable closures? Is there any docs/RFC that describes how an accidental move could happen? I'm curious - how you would check for an accidental move? Thanks! 
There's a pretty significant impedance mismatch between Qt, with its OOP design, and Rust, with it's trait-orientated programming design; so I never think it'll feel truly native. Nevertheless there are several reasonably stable QML Rust bindings out there.
Yeah, it makes sense.
Well, it uses sync db driver
It's also pretty good for the JSON test. All of which indicates the issue is at the database layer rather than Tokio itself. This could either be due to the libraries not being optimised, or -- more likely -- not being used in an async fashion. 
&gt; I skimmed the discussions about immovable types a while back - I &gt; didn't know they were a real thing yet! They are not, at least not yet. There was PR https://github.com/rust-lang/rust/pull/44917, but for now all that is on pause, until ?Trait story is clear (https://github.com/rust-lang/rfcs/issues/2255). &gt; I see you're using unsafe { static move || {...}}. Is this now how we're doing immovable closures? That's actually a immovable generator https://github.com/rust-lang/rust/pull/45337 unsafe { static move || { yield }} &gt; Is there any docs/RFC that describes how an accidental move could happen? Well, there are no docs as far as I know. UB example https://play.rust-lang.org/?gist=7ea538c78e7f505b4858f5ef8505d84e&amp;version=nightly It's unsafe because you should not move static generators once their internals are observed (.resume() called), but you can. So far all the work on generators is very experemental, the goal is to experiment and get some insights. 
Mh, maybe I don't have a full understanding of what a coroutine is. Not sure I understand what you mean.
&gt; A well-known classification of coroutines concerns the control-transfer operations that are provided and distinguishes the concepts of symmetric and asymmetric coroutines. Symmetric coroutine facilities provide a single control-transfer operation that allows coroutines to explicitly pass control between themselves. Asymmetric coroutine mechanisms (more commonly denoted as semi-symmetric or semi coroutines) provide two control-transfer operations: one for invoking a coroutine and one for suspending it, the latter returning control to the coroutine invoker. While symmetric coroutines operate at the same hierarchical level, an asymmetric coroutine can be regarded as subordinate to its caller, the relationship between them being somewhat similar to that between a called and a calling routine. Coroutine mechanisms to support concurrent programming usually provide symmetric coroutines to represent independent units of execution, like in Modula-2. On the other hand, coroutine mechanisms intended for implementing constructs that produce sequences of values typically provide asymmetric coroutines. Examples of this type of construct are iterators and generators. Ana Lúcia de Moura and Roberto Ierusalimschy in their paper "Revisiting Coroutines": A good image to describe the difference is the following https://imgur.com/YOLuLxv
Ah I wasn't aware of that, thanks for letting me know about it. I will definitely look into it and see if there is anything that I can help with.
In general I saw a lot of support for SIMD, calls for stability of existing nightly features, decreasing issues count and maybe embedded. Then everyone had his own favorite thing (games, gui, wasm, etc). But the above where the ones I saw repeating a lot.
See also [das Buch](https://doc.rust-lang.org/book/first-edition/ffi.html); the first edition has an FFI chapter while the second does not. I have not yet needed to get weirder than what the book has to say, except in very specific circumstances that had their own manuals.
&gt;&gt; What do you mean by bloat? I mean the bloat required to do the same things in rust versus C or C++. it's not 'just' writing unsafe; the same operations are more verbose.
The biggest pattern I saw was the idea that 2018 should be a "tock" year and focus more on driving projects already started towards stable than starting new things. That, and both SIMD and the Async story seem to be the popular "major features" to focus on. This is super vague...
https://rustbyexample.com/error/iter_result.html
&gt; We were thinking that marriage between rustdoc and mdbook would be made in heaven :) I do too ;)
What's the use case of self referential structs?
If you are wondering that, you should really read this post! :)
If my goal was to allocate as little on the heap as possible, I would probably go with option 2. Keeping track of indexes seems to be the common advice when dealing with buffers since there's no self-referential struct support yet (not that they would help you here).
And if it's running on Windows, the exceptions also show up IIRC in Event Viewer, under Applications :-D.
Hey, hey, hey, we thought about sending their posts and _we do the work of summary_. You're taking all the work from us! Thanks, you're awesome! 😂
Riiiiight. Event viewer. Handy if it were on an environment with one of *those...*
[removed]
It's ok, if this post gets the reception I'm hoping it will, we'll still have the work of summarizing _that_ :p
&gt; e.g. you can’t index into C arrays with user defined integer types Well... indexing into a C array requires implicit conversion, so no you cannot have both implicit and explicit conversions. On the other hand, you can wrap your C array into a typed array which supports indexing by your custom type.
Haha. Sorry, I'm used to computers being on the ground, not in the sky.
I'm probably reiterating stuff that you all on the various teams have discussed, but my inclination is to just allocate generators that need to borrow across yield points on the heap, which effectively pins the data to a specific memory location. When I had to solve problems like this in early design of Rust, I usually ended up thinking "what does C/C++ code do?" And indeed, apps like nginx or the Linux kernel will heap allocate (whether through malloc or slab allocation or whatever) the per-connection data structures. You wouldn't want to move them anyway; that would just be a lot of copying for no reason. And if malloc ever becomes a bottleneck, your app could always just switch to a slab allocator. This is only a strawman proposal, because there are a lot of language-level details to hammer out. But from a bird's eye level it's the way I'd be inclined to go.
&gt; the things you wanted unsafe for (casting, pointer manipulation, etc) &gt; ... &gt; are significantly more verbose But those things are neither unsafe nor IMO more verbose than in C++: - casting: Rust (safe): x as Type, C++ xxxx_cast&lt;Type&gt;(x) - pointer manipulation: Rust(safe): x as usize +- offset, or x.offset(value). C++: x +- offset (implicit conversion) 
This [pretty simple copying collector][http://www.cs.princeton.edu/research/techreps/TR-220-89] illustrates why half the heap has to be kept in reserve as overhead, and also shows a couple of tricks that people use to keep the descriptor overhead down. It should be easy to see that for such a collector descriptor overhead could only compete with other factors if every heap object was &lt;= the size of a descriptor (a word). I can't think of any system where that is true. The linked paper is actually more focused on the GC data structures than the algorithm itself. Now you might point out that that is a pretty silly example to give you because no one uses garbage collectors like that for real (just like no one uses pure mark-sweep for real), and you would be 100% right. For a slightly more reasonable example, you can take a look at [immix](http://www.cs.utexas.edu/users/speedway/DaCapo/papers/immix-pldi-2008.pdf), or [GHC's gc](https://simonmar.github.io/bib/papers/parallel-gc.pdf). Those are more representative of modern, production grade GCs. Both of them use a really slick trick where they use one descriptor for multiple heap objects at once, bringing the descriptor overhead even further down. I tried to find precise numbers on descriptor overhead for you, but unfortunatly I didn't have the time for a close enough re-reading. I'm sorry I don't have a more quantitative basis to supply, but those papers are the ones from which my intuition comes.
I maintain ldoc, a Lua documentation generator, and it came out of a need to unify three aspects of good documentation- API docs, narrative explanation, and code examples. Still think it's a worthwhile goal - after all, developing a lib inevitably involves making examples, and it's a pity that they get hidden away in some github repo 
Rc isn't *that* slow if you can get away with not syncing the Rc updates atomically (and Rust makes this possible by providing both `Rc` and `Arc`). There is a memory overhead *per allocation*, but that's quite small unless you're doing very silly things like, idk, representing a graph of `u8`'s with `Rc` references or whatever. The memory overhead of tracing GC is both large and unpredictable, so `Rc` is not really a bad technical solution.
&gt; Does it remove the current limitation of inference for Array sizes being 32 max? YES
Intermediate documentation, which for me means figuring out what design patterns work well in Rust. Type level integers (is that their name?). There seemed to be a general agreement that unstables features should be stabilized or rejected.
The main problem is that Rust has been getting boring to me, but on the other hand, nothing has the same performance and safety guarantees.
&gt; Rc isn't that slow if you can get away with not syncing the Rc updates atomically (and Rust makes this possible by providing both Rc and Arc). When [I tested RC vs tracing GC](http://flyingfrogblog.blogspot.co.uk/2011/01/boosts-sharedptr-up-to-10-slower-than.html) I found RC was 10x slower with atomic updates and 6x slower when it is thread unsafe. &gt; There is a memory overhead per allocation, but that's quite small unless you're doing very silly things like, idk, representing a graph of u8's with Rc references or whatever. That is [how purely functional dictionaries are represented](https://www.cs.cmu.edu/~rwh/theses/okasaki.pdf): as a DAG from a memory management point of view, representing many different versions of an evolving immutable tree data structure. &gt; The memory overhead of tracing GC is both large and unpredictable, so Rc is not really a bad technical solution. I tested that too and found only [a counterexample](http://flyingfrogblog.blogspot.co.uk/2017/12/does-reference-counting-really-use-less_26.html) where RC-based implementations require substantially more memory than those using tracing GCs so I am very skeptical of that folklore wisdom, particularly because I've never seen any compelling empirical evidence to substantiate it. 
Monthly Hacker News threads?
The one I found myself nodding along with the most was the [back to the roots Reddit thread](https://www.reddit.com/r/rust/comments/7p6n90/rust2018_back_to_the_roots/). This is all about the things that are mostly in progress already, that would help Rust target its most important use case; being a viable alternative to C and C++ for systems and embedded programming. I really like that Rust is also suitable for a wide number of other types of use cases, like WASM, command line tools, async servers, web dev, and so on, but I think that focusing back on fixing all of the little papercuts, nightly only features, and in-progress features that makes Rust not quite competitive with C and C++ for many domains is one of the most important things to work on. Besides that, something that I didn't see covered as much, though it isn't as relevant to the core Rust project (compiler, stdlibs, tools), is GUI application development. This is one area in which Rust is fairly far behind C++; `gtk-rs` is great, but GTK isn't the best fit for cross-platform applications, and there's very little in the way of a good, Rusty cross platform desktop or mobile GUI framework, nor much in the way of rich bindings to other platform specific GUI libraries. The final point that I really want is better support for integration with packaging and build systems. I want to be able to easily create a Debian package from a Rust project. I want to be able to have people install Rust and get up and running using their standard package manager, not have to fiddle around with `rustup` and `cargo install` and so on to get their dev env up. I want offline crates.io subsets to be easier so I can have repeatable builds without depending on a network connection, and make it easier to ensure that `cargo` never needs network connections.
isn't the deadline 31 Jan? 
Creating one hyper server per address, and having the right behavior behind each one seems like the best idea to me. I mean, that's what nginx is going to be doing anyways if you link to it. In hyper 0.11, if you create your own `tokio_core::reactor::Core`, you should be able to run all of the different hyper servers on one thread. I think all you need to do this is just to use `Http::serve_addr_handle` rather than `Http::bind`?
Refocusing Rust around it's roots as a new generation system's language. Particularly the "back to the roots" post, the embedded posts, HPC/Graphics posts. Feature wise const generics, SIMD, Inline ASM and No-std stuff are the stand out foundations. Support more target platforms, move to LLVM 5.0+ and get AVR support, turn focus back to projects like Cretonne. Of course async/await is also important and I'm mostly interested on that building into an MPI solution rather than any traditional web stuff. But I think the core motivation for the above is to bring people into the fold of Rust, whose domain and skill would be uniquely suited to refining Rust's foundation. The quicker Rust bolsters itself in that sphere, the quicker it get's all sorts of Boost-like numerical method libraries, the quicker it will be in a position to expand in all directions. I love the passion to make Rust one if not the best language for the web. But I also feel it's sort of on track already, and I don't find it really all the time sensitive the mark Rust as "the" wasm language. Rust is in many ways already much more powerful than the web languages of old. Where as I feel Rust has a lot more work ahead of itself to earn the crown from the C/C++ world. I want to live in a world where the only reason not to use Rust, is because your working on an existing code base.
My prediction is that it will work as follows: First, let's define a "self-ref lifetime" as a lifetime that both: 1. Is confined to the body of the generator/future. 2. Crosses a yield point. These are the lifetimes that would need to appear in the lowered data structure and cannot currently be expressed in rust. The first step would be to borrow check the body of the generator/future as if it were a normal function (with possible extra consideration for the special semantics of yield, but even that might not be necessary). Once the body has been verified to be internally consistent, it can be lowered to a state machine enum. If any self-ref lifetimes exist, then the state machine will be marked as an immovable type (pending RFC 1858), and all self-ref lifetimes within it will be type-erased and replaced with an unbounded lifetime such as `'unsafe` (pending RFC 1918). This should be sound for similar reasons that rental is sound, which is that the data structure is opaque and the fields are inaccessible, except via specific methods exposed on the type, which will have already been validated by the borrow checker. As long as a type bounded by a self-ref lifetime cannot leak out of the generator/future body, then there is no danger. That's my theory at least. It's possible I'm complete off base and the solution is totally different. Either way, exciting stuff.
I hope so! Hoping to find some time to write a last-minute post!
`Iter&lt;'a, T&gt;` doesn't have an internal `&amp;'a [T]`. It has two internal `*const T`s, with no lifetimes to be polymorphic over. In this particular case you could probably do the conversion when it converts back to a `&amp;'a T` in `next`, but that isn't universally applicable either. Feels like too much subtlety to hinge on a lifetime, and thus too much subtlety to just push onto unsuspecting, generic, unsafe code.
I suspect that's the main use case everyone has in mind when talking about immovable types and self-reference, with those just being the mechanism to enforce that a generator is heap-allocated without tying the language to any specific allocator interface (let alone implementation).
I want to agree with you, but the pun lover in me just can't
First you make us write the posts, and now you want us to summarize them, too? Sure you're not the crowdsourcing team? :P I like how a lot of posts recognize that there is a lot of cool stuff in the Rust-y pipelines, and also that the plain *number* of these pipelines – and thus the folks working on different stuff simultaneously – is quite large.
You're goals look like my goals, let's team up! Check out https://github.com/rust-crates/ergo
Great! Thanks for the resource, I'd also like to add this [tutorial](http://zsiciarz.github.io/24daysofrust/book/vol1/day23.html) which helped me in combination with what you have written! Just in case someone comes across this thread with a similar issue.
Great post! I'm really looking forward to what non-code practices the rust community comes up with this year! Also: Thanks for quoting me (incl a typo I just noticed)! I want to add that assert_cli also has a great maintainer who is more active that I am :)
That will probably never be supported in the language. There used to be a green threading runtime (which includes all the pieces needed for coroutines, it just handles scheduling differently) but it was removed because it made things more complicated for essentially no benefit (because of the tradeoffs it had to make to coexist with native threads). There are already coroutine libraries like [libfringe](https://github.com/edef1c/libfringe) or [context-rs](https://github.com/zonyitoo/context-rs), so I'm not sure there even *needs* to be any support at the language level.
[cassowary](https://docs.rs/cassowary/0.3.0/cassowary/)? It's technically specific to UIs, but maybe it's worth a look.
While I agree with most of your post, I disagree with the fundamental statement. Why sticking to compete with c/cpp (actually I think only with c, because nearly all developers I know think that cpp defeated itself without any help from other languages), if we can compete with languages like c# or java? I hink that with some better tools we could even compete with scripting languages. Rust is 'low-level', but has great and expressive abstractions and solves so many problems, I would love to see it as a language of choice for most of the usecases.
Well, yeah, but it still has to be typed right and given the right args
&gt; This pretty simple copying collector illustrates why half the heap has to be kept in reserve as overhead, I don't follow. What in that paper makes you say that half of the heap has to be kept in reserve as overhead? &gt; and also shows a couple of tricks that people use to keep the descriptor overhead down. Yeah but it misses one really obvious trick for statically-typed languages: reify generics so you don't need any run-time space overhead because all types are statically known. &gt; It should be easy to see that for such a collector descriptor overhead could only compete with other factors if every heap object was &lt;= the size of a descriptor (a word). I can't think of any system where that is true. The linked paper is actually more focused on the GC data structures than the algorithm itself. &gt; Now you might point out that that is a pretty silly example to give you because no one uses garbage collectors like that for real (just like no one uses pure mark-sweep for real), and you would be 100% right. For a slightly more reasonable example, you can take a look at immix, or GHC's gc. Those are more representative of modern, production grade GCs. Both of them use a really slick trick where they use one descriptor for multiple heap objects at once, bringing the descriptor overhead even further down. Hmm, OCaml doesn't use BIBOP but it is still very compact. &gt; I tried to find precise numbers on descriptor overhead for you, but unfortunatly I didn't have the time for a close enough re-reading. I'm sorry I don't have a more quantitative basis to supply, but those papers are the ones from which my intuition comes. I see. I think the main thing is that you don't actually need any descriptors at all. That whole concept stems from Lisp's uniform data representation which is a consequence of dynamic typing. The descriptor is essentially your run-time type information. But all of this says nothing about the amount of floating garbage which is, I think, the elephant in the room in this context. 
Full coroutines are not part of the proposal. The reason is that they need a full stack to be allocated for them. The current proposal (semicoroutines a.k.a generators) don't require that because they can resume only at the bottom level of the stack (which means that their size is known at compile time). This means that the whole semicoroutine/generator can be regarded as just another value, and it doesn't need any special handling, so anyone can roll their own library and no runtime magic (a la Go) is needed.
I didn't know about bit fields before reading this post, and now I want them! The Erlang example looks so neat. /u/whitequark wouldn't that simplify a lot the [wire module of smoltcp](https://github.com/m-labs/smoltcp/tree/master/src/wire)?
The problem with this is that every async function call becomes a heap allocation, encouraging users to avoid splitting up large functions and possibly encouraging them to write manual futures and avoid async functions entirely.
Stabilizing features that make it easier to write Rust. RLS, NLL, impl Trait, documentation. I didn't see anything about getting even better error messages (not sure how you'd even improve them), but that'd fit the pattern (easier to write without impacting stability). 
Not for the use cases I described. They can't take arguments on yield, whereas generators in many other languages can.
That is also my understanding, extensions are hugely important to mercurial, and python is a great language for that.
&gt; it's like an echo chamber of sorts How so?
This is how any network service written on top of futures would work, but my point is it does require solving the problem of borrowing across yield points without just heap allocating every generator that does so.
Looks cool. Does it support syntax highlighting for multiple languages? Can it invoke clang for showing syntax errors, and does it support auto-completion?
Yea, `std::io::Error` implements the same concept thought it doesn't do so on top of failure's API, it has its own implementation (because its in std, so it doesnt have access to failure). I don't know any libraries that have implemented the pattern on top of failure, but hopefully `std::io::Error` can get you an idea of the interface I was trying to describe.
I was doing this just yesterday, though with MySQL and a simple repr(i8) enum. The Diesel tests have an example here: [custom_types.rs](https://github.com/diesel-rs/diesel/blob/v1.1.1/diesel_tests/tests/custom_types.rs). You can derive `FromSqlRow` and `AsExpression`, but to really use the enum you still have to manually derive `ToSql` and `FromSql` (unless I am doing it wrong). Although for my case it was pretty easy to just convert my enum to i8 and defer to these traits as already defined for `i8`.
&gt; GUI application development. This is one area in which Rust is fairly far behind C++; I'm no C++er - what alternatives in that language are better? Thanks :)
never mind, it's for_each() :)
Was immovability ever completely decided upon? That'd make self-referential stuff reasonable, right?
Well, some of the first posts (from the Rust team, I think) were about making fewer changes this year, cleaning up the open RFCs and issues, implementing `await!` and stabilizing the existing features. And it seemed that the later posts were directly inspired by the first ones. So these ideas were thrown around a lot and they might have drown out the other, more "original" ones. Which isn't really bad, since these must be things that people want, but reduces the visibility of others.
&gt; Most of the work is handling the I/O, so doing stuff in thread pools isn't going to help much. This is a common misunderstanding regarding how Tokio is designed (and docs should be fixed). For Tokio, "event loop" means something different than other libraries. There are two separate concerns with building async I/O code: a) Receiving readiness notifications, e.g. be notified that additional data arrived on a second. b) Execute user code to advance the application state, i.e. respond to the notification. The concurrency model of receiving readiness notifications (a) is dictated by the OS (epoll on linux). The concurrency model of user code execution (b) is flexible. Other evented systems tightly couple these two concerns, which means that those libraries are forced to implement concurrency logic. This also means that these libraries are forced to pick a concurrency model. Tokio, does not conflate these two concerns. They remain decoupled, which means that Tokio the library does not force any concurrency model on you. One source of this confusion is that the Tokio reactor actually does provide both (a) and (b), but this was done as a convenience. &gt; How do you ensure balanced load between the cores getting inbound requests? You do this however you want :) I know it is vague, but there are a multitude of strategies by which this can be accomplished and it is up to the dev. Tokio doesn't force you into any strategy. The simplest is to spawn all your tasks that operate on a TCP socket onto a CpuPool. Again, docs should be improved to include a cookbook illustrating how to implement all the various concurrency strategies... &gt; Do you have to have separate outbound connections for each silo? This question is not applicable to Tokio as it is up to the end user. &gt; IIUC, tokio is designed to always write to a connection on the tokio core that owns it This is not true. The tokio core's primary job is (a) from above. It receives notifications on epoll and flags the associated tasks as "ready". The associated tasks can execute on any futures-rs executor using any concurrency strategy you want. 
&gt; Amp will happily close modified buffers without warning when quitting. Sharp tools, folks. Not sure this is a good idea...
I don’t disagree with you.
You use an executor that lets you load balance. Tokio's TCP types can be moved to any executor (CpuPool, work stealing pool, rayon, etc...) and used from there. Tokio's executor (`Handle::spawn`) is provided as a convenience, not a requirement. In fact, it is being removed from Tokio in the next iteration and moved to futures-rs so that can be used w/o pulling in the tokio dependency.
Const params and Simd would mean sensible numerical libraries could be created to match the C++ gems like Eigen which would be fantastic for furthering almost all uses of Rust. That and embedded. Coding C or worse C++ on embedded (cortex-m, avr, avr32, etc) hardware has always been a huge pain. I wish I could use rust *now* there.
There is out-of-the-box highlighting, but not the other features you mentioned.
This calls for adding `UnsafeDeref` and `UnsafeDerefMut` traits to the languages, which is something that I and others have been thinking of for a while, but no one has written an RFC yet
Not very complete, then.
I sure hope it’s not intentional :o
&gt; Why sticking to compete with c/cpp (...), if we can compete with languages like c# or java? I don't think that Rust should "stick to" competing with C and C++. As I said, I think it's good that there's so much work going into features that make it competitive as a higher level application language. However, I think that in 2018 it would be good to finish a lot of the work that prevents it from effectively competing with C and C++. For competing with managed languages, even with all of the ergonomics works, it's hard to make the borrow checker quite as ergonomic to work with as garbage collection is. For people writing basic applications without substantial performance requirements, a garbage collected language is likely to be easier to use for quite some time. I mean, look, even Ruby had substantial success on the server side with GC, terrible performance, and no async support. I would absolutely like to see it as the language of choice for a broad range of purposes, but I think that it's a lot closer to being a full-fledged C/C++ competitor so that people can actually stop writing code in those languages, and focusing on getting over the last few hurdles there (which is mostly already work-in-progress that's just not finished, though some of it is closer than others) would really help sell it for that use case. &gt; (actually I think only with c, because nearly all developers I know think that cpp defeated itself without any help from other languages) There is a lot of software written in C++. Windows is written in C++; msvc didn't even support C99 until relatively recently because Microsoft believes C is obsolete (not all of it uses C++ features, most of win32 is C-style APIs, but it's all compiled with a C++ compiler). Web browsers are all written in C++, with the exception of Servo and now a few bits of Firefox. Most major cross-platform desktop applications are written in C++. Anyhow, I absolutely agree that Rust should continue to push towards being a viable replacement for C#, Java, and even scripting languages. But in 2018, I'd like to see a bit of a push to clear the hurdles that are preventing C and C++ developers from moving to it for new projects, since that's one of the places where it can have the biggest impact.
this is absolutely going to be a focus of new rustdoc; i actually wrote this functionality before getting the api docs done. (still not public yet. soon!)
I would say that it calls for _literally the opposite_, that we simply accept and implement this RFC https://github.com/rust-lang/rfcs/pull/2237 As well as the (implied later in the discussion) variant RFC where we do the same thing with `unsafe`.
is https://crates.io/crates/bitflags good enough for your use-case? 
bitflags doesn't cover the case where a group of n bits are used to encode a n-bit value; it's useful only for modeling a sets of exclusively boolean values. Picture a 32 bit struct with the following hypothetical fields: ``` struct Register { a: u4, b: u4, c: u8, d: u16, } ``` bitflags doesn't help here.
How close are the default keybindings to vim? If they're close I'd be excited to try it out!
&gt; First, those things are not unsafe. obviously I mean use of those pointers aswell. &gt; casting: Rust (safe): x as Type, C++ xxxx_cast&lt;Type&gt;(x) no, you have to faff around more than that when casting raw pointers to interpret memory differently (e.g. doubly casting because you can only change one part at a time) they removed the default of mutability status so that you have to say both 'mut' or 'const' because we're too stupid to figure out the default might be different ? &gt; x as usize +- offset illustrates the casting issues again.. (no assumption that non-destructive conversions can happen). I might also be reacting to the loss of c-like for loops with the increment operators. ultimately it might be an unfair comparison since C is designed *for unsafe code first and foremost* (with some safeR techniques retrofitted in c++) , whilst rust is the opposite, but I still feel they went out of their way to make people *not* want to use unsafe techniques. As such if I want to knock up a custom data structure with some bit-packing for an option in a grid cell or navigate BLOBs .. it's still more pleasant to do all this in C++
&gt; sharp tools, folks &gt; written in rust hmmm
what no screencap on the homepage???
Quite similar, although it gets rid of most keybindings by offering alternative features like the "jump mode". https://amp.rs/docs/usage/
I like the idea of a legacy-free, sanely configured Vim written in Rust so I hope the goal of simplicity doesn't mean forgoing the features that make Vim so productive (for me at least). Can't imagine going back to an editor without text objects (ciw, dap, ci", daW, cs'", ds{, etc.) and macros.
This is super opinionated. But it’s kinda impressive to see Rust enable such thing. 
I write mostly unsafe Rust nowadays and never consider any of the things you mention issues. At the same time I’ve written way too much C++ in the past decade, evolved, and continue to evolve the C++ language, and the direction me and many others are actually pushing for is making C++ more like Rust. I think that the issues you mention might be real for you, but are not shared by others (or at least other volunteers evolving C++ and/or Rust). Maybe you should consider volunteering if you care about any of this. Otherwise it might turn out that you can’t use Rust because x issues and also can’t use C++ because we introduce the Rust issues you mention there. Sadly, I can’t help you because I see the problems you mention as advantages of Rust over C++ or at least I am not getting the points you are trying to make (your answers seem more focused on winning an argument than in trying to convince me of anything).
Yeah I was just being sarcastic, sorry about that :)
I guess I /r/woosh ed then
&gt;This is not possible. unsafe code is allowed to cast any reference it receives as a pointer. We could still use the type system to detect thawed instances and convert their offsets to pointers upon cast. &gt;Consider this version: &gt; &gt; struct Foo { &gt; array: [Bar; 16], &gt; iter: Iter&lt;'array, Bar&gt;, &gt; } &gt; &gt;The internal implementation of that iterator likely does pointer arithmetic on the reference its holding, which doesn't work if that reference needs to be stored as an offset. Why? The single difference is that the base pointer must be added once. &gt; (Well it might work in the case of `Iter` because it just advances through the array, but it easily could not work.) So it *does* work on instances that are stored in continuous memory. Granted, it's not a general solution, but it should work on an interesting range of types (from a perf standpoint).
Unless I missed it, there is no documentation on how to write to the buffer (s in normal mode)
it is responsive, so it shows on desktop, but not on mobile
https://github.com/pnkfelix/tango
Don't we have enough editors?
The request I saw the most was stabilising high value features like impl Trait that feed into the async story. Having only properly working with Futures yesterday I feel there is still quite a way to go before async in Rust is as easy to use as node or Go.
Xi is fundamentally a back-end for a text editor, while the focus here appears to be on the front-end. This could be built on top of Xi for all I'm aware of.
Is there a way to skip to the end of a document? I didn't see that in the docs.
Well, we have two. Vim, and evil mode.
The backend is `xi-core` and operates entirely through json rpc over stdin / stdout as you've noted but there is an official latency-focused frontend by Raph in Swift that makes a complete editor (basic, notepad + syntax highlighting). I'm interested in building a Vim-like editor** with Xi since there seems to be a decent amount of momentum behind the project but I want the operation + range editing model to be built into the core instead of emulated like it is in evil or the plugins for vscode, atom, intellij, sublime, etc. After briefly talking to Raph in person at a presentation he gave this week I've been slowly working my way through the various xi codebases and putting together an RFC for it. We'll see how it goes. ** I suspect the Kakoune model is better but I've been doing Vim a lot longer.
"You should have done this thing you made for yourself the way *I* wanted you to do it" Software doesn't need more naysayers, and it's not up to you how someone spends their time. If you want a text editor based on nano you can certainly spend your time doing it.
I opened a 314KB file in it and it struggled. It opened it just fine, but as I scrolled down the file it got increasingly slow to the extent that it would be impossible to actually use. Navigating and editing on line 1? Just fine. Navigating and editing on line 6000? Very much a struggle. It's a nice idea and certainly impressive, definitely needs a bit more polish before it's ready for prime time. And Q to close without prompts is definitely a disaster waiting to happen. :)
thanks! I used `include_bytes` to include my CA certs, worked great!
It might be syntect, it has some C dependencies.
That's not responsive if you're removing key information...
that's what "responsive design" means. I do agree that a screenshot would be nice, i was confused at first too.
Tried it out. Pretty nice! I've been using Spacemacs (with evil mode, of course) for so long though it's hard to replace the hardcoded keyboard mapping in my head... I do like the emphasis on no configuration needed for a good experience. That is the reason I use Spacemacs and not Eamcs ;). Hope the project progresses more, maybe I'll switch to it if it has some nice features I can get around (that jump mode seems _really_ cool)
Only when no type conversion or precondition checking is involved, though. And it would make the interface inconsistent if some fields *do* need those...
It’s not very good responsive design but I suppose it’s technically responsive 
No, responsive design is about layout, and removing unimportant details. I wouldn't exactly call a screenshot unimportant.
I'm trying to compile a list of what everyone asks for, but people keep posting blog post so every attempt is instantly outdated. However, I have been able to distill a few common requests: * crate stability (18) The common "Oh no, this crate is in alpha!" * documentation (14) Half of them ask for "Better documentation", half ask for "Intermediate documentation with use-case examples" so they would understand better how to use a crate, instead of just seeing the individual pieces. * stability (10) The common "Oh no, this feature is only on nightly!" * simple to learn (10) The common "Oh no, I have no idea how to start with this complex language" * xargo integration (9) Cross compilation is apparently very popular. *web (8) A decent web story can be useful. Rocket on stable, for example. Or a default framework everyone can use. At this moment it's kind of a mess. * nll (8) * less rfc’s (8) The common "Oh no, too many RFC's are in flight, we need to sort out this bunch first" * const generics (8) * compile times (8) are still too long * ide (7) RLS improvements, mostly. * embedded (7) Most crates for embedded systems are both nightly and alpha, making embedded system development especially painful. * wasm (6) * simd (6) * rust at work (6) Encouraging Rust in production. * marketing (6) Encouraging Rust in general. Caveat: this includes asking and listening to why they don't use Rust. Don't play the RESF here (one of the blogs stated exactly that) * impl trait (6) * Debugging (6) A *much* better debugging story (do we even *have* a debugger?). Includes tooling. * tooling (5) in general. * syntax improvement (5) Because sometimes, Rust is still extremely verbose. * procedural macros (5) aka Macros 2.0 * fast rfc’s (5) Don't let RFC's linger for months or even years * error handling (5) Things like ?, failure, etc. * clear pr (5) The common "Oh no, I want to help the community but I have no idea how!" * Tooling, profiling (4) Because Callgrind is cumbersome and benching is too coarse. This includes the proposed metrics-rs crate. * Specialisation (4) * Async/Await (4) * Support for no_std (4) * Inline assembly (4) -------------------------------------------- Those were the most frequent complaints. Aside from them, some people made interesting and specific suggestions: * Make unsafe code safe (unsafety guidelines); * Private crate registries for companies, so they can publish proprietary crates to their own server, not crates.io; * TryFrom and RangeArguments stabilization; * Plugging I-unsound issues; * Build integration, because CI software exists other than Travis; * C integration that is better than bindgen; * A more generic, improved libstd with a separate core minimizing platform dependent code; * GUI dev; * Iterator ergonomics, because implementing one now is quite cumbersome (generators do help); * French, German, Chinese and other documentation; * GPU and Spir-V support; * A garbage collector alongside Rc&lt;&gt;; * math, sparse matrix, numeric, email, vobject, cursive, multimedia, pass-bindings, qt, markdown and ipfs crates; * Cloud computing support; * Meetups outside of the EU or US; * Being able to look at how LLVM is generated; * Lifetime visualisation; * More tier-1 platforms, and more cross platform code; * Information about patterns, behaviours and complex structures in Rust; * Derive(Debug) never failing; * More functional programming concepts in Rust; * More women in Rust (Thank you Kelsey); * And permission to roll up the RESF. Alongside one single request: "Please don't be boring this year, next year, or ever." Phew, you guys sure ask a lot. Keep it up! 
You can manually do it like this: `cargo update -p regex --precise 0.2.0` But it's possible that something else in your dependency graph will require a newer version, and then I think you're stuck.
This is correct. Source: literally best web developer of all time OF ALLLL TIME
https://en.m.wikipedia.org/wiki/IBM_Common_User_Access It's basically what you might think of as the "normal windows key bindings" that GUI editors and browsers tend to use. Ctrl+XCV are cut/copy/paste, Ctrl+Z is undo, Ctrl+Y is redo, and all that.
Non-Mobile link: https://en.wikipedia.org/wiki/IBM_Common_User_Access *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^142155
**IBM Common User Access** Common User Access (CUA) is a standard for user interfaces to operating systems and computer programs. It was developed by IBM and first published in 1987 as part of their Systems Application Architecture. Used originally in the MVS/ESA, VM/CMS, OS/400, OS/2 and Microsoft Windows operating systems, parts of the CUA standard are now implemented in programs for other operating systems, including variants of Unix. It is also used by Java AWT and Swing. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
`crossbeam-channel` was looking good up until the part where I needed to actually use the select statement, and it turns out it's not lax enough to take two different types of streams :( I guess I'll manually implement what the macro would do.
https://github.com/tock/tock-teensy
https://crates.io/crates/packed_struct should do it.
In this case, the screenshot doesn't really tell you anything. It's not even really a screenshot, it's just a styled div.
Is there a link to this Xi talk you could point me to?
I mean, we have the internals forums, and requests pop up at a regular cadence on both Discourse forums and Reddit. This was more of a structured ask.
Here's an example in which the UB of moving the generator can actually be observed: https://play.rust-lang.org/?gist=9569e0d440886836a46b102df779bfec&amp;version=nightly
Note that tock is more than just running rust code on a microcontroller: as self-described, &gt; Tock is an embedded operating system designed for running multiple concurrent, mutually distrustful applications on Cortex-M based embedded platforms.
Just tried it, First impresstion not bad. The Jump mode abit weird though.
&gt; Is there a link to this Xi talk you could point me to? It was recorded but I don't see it online. [Here's the event](https://www.recurse.com/events/localhost-raph-levien) and [this looks like the youtube channel](https://www.youtube.com/channel/UCR1uNZFzyXOuty6FK8hXGxQ) which has the previous month's talk up. The talk mostly covered the swift frontend.
Something something teco, needle butterfly?
I don't have any links on me atm but there is a well known community member that blogs and writes crates for embedded. I remember mention of Teensy support in one of the blog posts iirc. 
&gt; on the topic of rls, it seems to be mostly in maintenance mode. [That's](https://github.com/rust-lang-nursery/rls/graphs/contributors?from=2017-12-29&amp;to=2018-01-27&amp;type=c) not how maintenance mode looks imho.
Spacemacs is waaaaay better than just evil mode
Thanks for explaining all that, I mostly get it :) So this will be really good for some existing crates like nalgebra? I think I heard crypto benefits quite a bit too. I remember writing some code for generating permutations and it was really efficient with an array vs vec but quite inflexible to become a crate that could configure the array length well, maybe I'll be able to go back to that and release it as a crate once const generics is available? :)
In that example, how does const generics apply here? Is it specific to the addition of typying/struct? It looks from a glance like it'd otherwise be fine and work? Or is it specific to the method name `from`? I sort of get what the logic is doing but not sure what const generics is enabling here?
This isn't relevant. Crates.io can handle naming conflicts. The end.
Looks like it could work as expected. You could potentially use `TypeId` (or, e g, TypeId % prime) instead of manually generating checksums. I'm guessing that you want "checksum" to be the first field of the struct? If so, remember that `Foo` needs to be `#[repr(C)]` or Rust is free to reorder Foo's fields. 
How do I make this Nom parser `named_args!(p_str(n: u32)&lt;&amp;str&gt;, take_str!(n));` fail if `n &gt; 512`?
Why a custom CSS parser, out of curiosity?
You know, tetanus isn’t a bad name for some sort of pen test framework for rust. 
Can’t SO_REUSEPORT mitigate any load balancing issues between multiple processes? Network programming is something I get confused about sometimes, so maybe I’m totally off base on that.
hmm... ya I think I can: - mv Cargo.lock Cargo.lock.bk - `cargo update -p ...` for _every_ depdenency to its _lowest_ version - cargo test - mv Cargo.lock.bk Cargo.lock 
&gt; You could potentially use TypeId (or, e g, TypeId % prime) instead of manually generating checksums. Ah that looks like a great option. Thanks! &gt; I'm guessing that you want "checksum" to be the first field of the struct? If so, remember that Foo needs to be #[repr(C)] or Rust is free to reorder Foo's fields. In this case I'm doing Rust -&gt; other lang -&gt; Rust, so wherever Rust wants to put the field should be fine. The structs are opaque to any FFI code anyway. Thanks for the help. Still kind of curious whether this is a common phenomenon, and if not, why not. So far I've only found [this](https://github.com/csullivan/any_ptr) which feels like the same kind of idea.
In theory, sure, but combinatorial explosion might not ever let you finish...
Here's my [summarization of the full set](https://paper.dropbox.com/doc/aturons-Rust2018-summaries-Xq57JQv6EkDr0nF5kLsWe)!
!redditgarlic
[**Here's your Reddit Garlic, sophrosun3!**](https://i.imgur.com/etMqixE.jpg "Reddit Garlic") /u/sophrosun3 has received garlic 1 time. (given by /u/pythonETH) ^I'm ^^a ^^^bot ^^^^for ^^^^questions ^^^^^contact ^^^^^/u/flying_wotsit
&gt; I really wish RLS was done yet, but that's not how maintenance mode looks imho. I mean, it looks like mostly dependency updates and build fixes. Which is exactly what I would call maintenance :P. &gt; I don't go too much on reddit apart from this thread, but when I do I often get insulted just because I express a disagreement. In comparison, I really like how polite people behave in here, even when they strongly disagree. Fair enough, and (regardless of my opinions on the subject) that's probably how it should be. It's not like I don't know -- I've been called an idiot for asking stuff in `##C++` on Freenode. But I was talking about threads where people said "hey guys, we're worried about your trust in person X because they have a history of doing Y in the past", where posts that weren't even criticizing anyone were deleted (and then the whole thread was deleted). This was rationalized as "it's not allowed to state facts because they might prompt criticism" -- which I strongly disagree with. It has a really authoritarian vibe, and criticism is actually helpful at times because it can give people a wake-up call. Disallow that and you end up with another echo chamber of sorts. And it's not only that, but a sibling thread does discuss "bad stuff that people did", without any intervention from the moderators (not that it's needed in my opinion, as everybody was quite polite). So this "don't state facts" rule is selectively enforced, which is to be expected, as it was kind of made up for the former thread.
&gt; This was more of a structured ask. Sorry, it wasn't clear. That's true, of course, but my suggestion (unrelated to #Rust2018) was to set that up in addition to the other feedback mechanisms. I suppose there's no way to tell from two years' worth of Discourse threads what people asked for the most. Look at [this comment](https://www.reddit.com/r/rust/comments/7t5gyo/what_stood_out_for_you_from_the_rust2018_posts/dtaq5nt/). Doing that must have been a lot of work, and I don't think anyone is going to do that for more than a month.
I might be not understanding something: Is the problem that you can’t coordinate between the processes about when to block on accept in the multiple process model? Because I feel like that’s only a fairly small additional wrinkle. You can use any number of IPC methods to coordinate a process’s load information, right? And if you *do* use an IPC method to share that load info, that makes it comparatively easy to scale out to multiple hosts, right? Sorry if this is just totally off base though.
Why are these things not built on top of xi-core?
First look seems nice, thank you! I will give it a try.
I've had 0 time to read any of the posts. I can say, with certainty, that I care almost entirely about improving rust's concurrency story. Frankly, if that were the only thing Rust focused on for the next year, I'd consider that a very smart move.
Concurrency is a broad subject; do you have something specific in mind? A better thread pool, more crates, new language features?
Syntect can build without python afaik
I guess I should have said 'concurrency story'. Right now when I talk to people about languages that they are excited about, I hear 'go' a *lot*. There are two reasons given - it was easy to learn enough to play around, concurrency is super easy. I want to hear that about Rust and Go's concurrency model has its share of issues; there's certainly room to still be exciting here. Concretely, I'd like to see async/ await stabilized, and I'd like to see a *ton* of documentation and tutorials for it - like if someone wants to learn about async/ await in general, rust should be a great candidate for that. If we get that, that would make me very happy and I think would get a lot of people interested.
That might be a good target for a custom object allocator. I've been interested for some time in the concept of an allocator that wraps another allocator and adds extra functionality. You could imagine making a higher-level abstraction around your idea that works something like this: If you have a type, `T` (the type you actually care about), and a wrapper type, `W` (the type that adds extra fields to allow you to do your runtime checks), then you can provide an [object allocator](https://crates.io/crates/object-alloc) for `W&lt;T&gt;`. `W&lt;T&gt;` could implement `Deref&lt;T&gt;` by first doing whatever dynamic runtime checks you propose, and then handing out a reference to the inner `T`. Thus, you'd end up with code something like this: ```rust fn get_t() -&gt; *mut W&lt;T&gt; { my_alloc.alloc().unwrap() } fn do_thing(t: *mut W&lt;T&gt;) { let rf = t.deref(); // runtime check; can panic rf.method(); } ``` In fact, you could go even further. Let's say that you want your object to be opaque to the external code and only modifiable via the functions you provide. You could store some kind of hash of the state of the object internally and validate it to make sure the memory wasn't corrupted. This is roughly the approach I use in [this allocator tester](https://crates.io/crates/object-alloc-test), and it's worked pretty well for me.
Default key shortcuts seem very powerfull, Look at this default.yml file at https://github.com/jmacdonald/amp/blob/master/src/input/key_map/default.yml
It seems like there are no job postings listed under MaidSafe on rustjobs.rs at the moment - maybe your previous post expired? http://rustjobs.rs/company/37/maidsafe
Thanks for your response. I don't recall the specific posts that prompted me to say that, but they were probably the ones wrote by [Nick](https://www.ncameron.org/blog/rust-2018/) and [Manish](https://manishearth.github.io/blog/2018/01/10/rust-in-2018/). But regardless which person or group of people came up with the idea of tying up loose ends, it's still a good thing to do. Sorry if it seemed as if I was trying to put the #Rust2018 initiative in a bad light. I meant it as an aside remark instead of criticism. As you've noticed, my list broadly matches those written down by others, so I wasn't that worried about specific wishes being drowned out by the more popular ones.
I think I've read that the rust to c compiler (crust?) works on the 32-bit teensys. What about the 8-bit ones?
&gt; Sorry if it seemed as if I was trying to put the #Rust2018 initiative in a bad light. I meant it as an aside remark instead of criticism. As you've noticed, my list broadly matches those written down by others, so I wasn't that worried about specific wishes being drowned out by the more popular ones. I didn't read it like that. It hadn't occured to me that our posts could be read like that and it can totally be the case that people see things like that. It's a problem of any project that tries to be transparent that we are rarely transparent about how things work even for us. So, I considered you post as a pass ;).
I wouldn't say you _can't_ coordinate between the processes; only doing so is surprisingly complicated and imperfect, enough so that you're better off to just have a multithreaded reactor. There are tons of small decisions with no clear universal correct answer. For example: You mentioned "comparatively easy to scale out to multiple hosts". It's a different problem to handle N processes sharing a socket address and N hosts (with different addresses). In the former case, the servers decide which of them handle a connection from the client. In the latter case, the clients decide which to connect to. You probably wouldn't use the same mechanism to communicate load then. You could instead use N different addresses on the same host to make the mechanism like the N hosts case. But...that means that a single machine failure will take out all N, so maybe the client shouldn't treat them like separate hosts, depending on your reliability requirements. (Sometimes high-reliability/low-latency requests use a hedging strategy: send a request to server A; if it hasn't succeeded after some time, send it to server B in parallel, use the reply from whichever succeeds first. This is most effective if they're not "shared fate". If server A and B are on the same host, you're not getting as much value from the hedging.) So now maybe you want to put this additional complexity into the client library to know about shared fate when picking a server for the hedge request. Okay, you can do that, but it's a surprising consequence of whether you have a multithreaded reactor or not.
Close can sometimes be worse (uncanny valley effect)... suffering that a bit with kakoune. 
I don't know, I've never wanted it.
i want the regular CUA controls, combined with chords for tiled windowing (emacs wind move, and i gather vim has that). i got that burned into my fingers from '[Brief](https://en.wikipedia.org/wiki/Brief_(text_editor))', which was copied by '(CodeWright)[https://en.wikipedia.org/wiki/CodeWright]'
If you're going to that much trouble you could just hand out opaque handles, like sequential ids or random numbers, and keep something like a HashMap from handles to Boxes. Then it's impossible to forge something that looks like a legitimate handle but isn't. 
I was joking, but what you say about key conflict is interesting. The main terminal chords are (to use emacs notation) C-c and C-d, right? That's a little conflict with CUA, but I think not too much. I'm not even sure that C-d has a CUA meaning? Mostly I'm thinking of zxcvyf, possibly r and h as well, but that seems a little less consistent from program to program. If you really need copy you could put it on some other key maybe, or the user can cut and immediately paste and then the buffer will be correct and you'll also have the desired text in the clipboard.
Which is fine, we only want to do this kind of thing once a year. With discourse threads you also have the problem of long-running asks; there's a lot more hysteresis with these. For example HKT is something you'll see crop up often but it's nearly absent from the 2018 posts for various reasons. The teams _also_ keep an eye on the forums, but this is an opportunity to take the community's overall opinion on what _this year_ should be.
I like that this post is looking at Ada and D for searching safety features.
And then there are the [real programmers.](https://www.xkcd.com/378/)
Someone could do some NLP on all #Rust2018 blog posts and show the most frequently mentioned concepts.
You're correct the heavy OO and message passing design pattern (signals/slots) would pose a problem. I'd be happy to use QML bindings, but the real power of Qt (For me) is when it's used on mobile. For that you'd need to use the C++ libraries or write wrappers. The win you'd get is rust's macro system could replace the moc in Qt, which would remove most of the need for QObject, perhaps all if implemented correctly. Its all wishful thinking unless the KDE project or the Qt company got behind rust, I don't see either of those things happening anytime soon.
Did you consider using an imperative approach instead? It sounds like you were trying to squeeze in functional programming techniques that are known to be cumbersome in Rust? This question is not meant to provoke fans of pure functional programming.
Which is why I'd probably make my editor's bindings exactly equal to Vim's. Any extensions (that change the fundamental way a key works) have to be enabled manually, otherwise they're bound to the leader key. Vim's bindings are fine, I'd just like to see more advanced features (like injected language highlighting so some HTML in a JS file or something gets highlighted as HTML, not as a string literal.
You're thinking of /u/japaric
Would be nice if they could get closer to C's syntax though. I think C is the cleanest syntax of all of them, and only falls down if you need nested bitfields to refer to the same bit multiple times (which can be useful). 
We (well, mostly oli-obk and Manishearth) have done a lot of work to prepare building clippy with rust so rustup can just components add clippy and installiert / update it once it's ridden the trains.
From my experience with FFI in Servo, there was never a case where we passed an entirely unrelated pointer to some FFI function.
Spacemacs is okay, I guess, but evil-mode is spacemacs editor, and a well configured emacs with evil-mode is better than spacemacs.
[Micro](https://github.com/zyedidia/micro) is an editor written in Go which has CUA keybindings.
I still don't really understand what the problem with self borrowing is. Reflexivity trivially ensures that the lifetimes `'a &lt;: 'a` work out. Is it just an issue of atomically allocating and freeing the self pointer? Like, I think struct Foo&lt;'a&gt; { i: i64, selfRef: Option&lt;&amp;'a mut i64&gt; } fn useFoo() { let foo = Foo { i : 42, selfRef : None }; foo.selfRef = Some(&amp;mut foo.i); //... } should work today?
&gt; Did you consider using an imperative approach instead? If were to solve the same problem using imperative programming I'd probably start by basically emulating purely functional data structures. Specifically, I'd replace the immutable dictionaries with dictionaries + undo buffers. Whereas purely functional data structures are naturally incremental and, therefore, low latency the same cannot be said of their mutable counterparts. For example, all common hash table implementations have amortised complexity where some insertions will incur O(n) time complexity, stalling the program and spoiling its latency characteristics. Even mutable sorted dictionaries using trees commonly use arenas and copy everything out in bulk when they're full so, again, an O(n) pause. &gt; It sounds like you were trying to squeeze in functional programming techniques that are known to be cumbersome in Rust? I don't see an easier way to do this in Rust, at least until pattern matching through `Rc` is supported. 
I think the only part all definitions share is `trampoline + stuff`. The difference between the ones you quoted are whether you cps or build a stack. There are also frequent differences about what types of in/output are allowed, whether you are allowed to name other coroutines or need to parametrize over them, what shapes of control flow graphs are allowed, what combinations of push/pull flow are allowed, whether the coroutines have to be synchronous, if the flow rates have to match...
&gt; &gt; I'm guessing that you want "checksum" to be the first field of the struct? If so, remember that Foo needs to be #[repr(C)] or Rust is free to reorder Foo's fields. &gt; &gt; In this case I'm doing Rust -&gt; other lang -&gt; Rust, so wherever Rust wants to put the field should be fine. The structs are opaque to any FFI code anyway. You misunderstood the issue. Your function called with `*mut Foo` receives what is essentially an opaque blob of memory: - what is the size of the memory allocation, - where in this memory allocation is the checksum placed? If the size of the memory allocation and the offset of the checksum vary per type, then you cannot "guess" the type of an opaque blob. Using `repr(C)` lets you manipulate the order of the fields, and therefore allow you to ensure that the checksum is always the 8 first bytes, no matter the type. 
And as someone who has worked with Ada, ranged types are so enormously wonderful yet such a simple concept. I think they are not popular because of the runtime overhead, but this is a fallacy. The compiler is often smart enough to not constantly check the ranges. This leaves most checks to untrusted input -- which should be checked no matter what. During development the overhead is not a problem in the rest of the code and after extensive testing they can be confidently turned of with a pragma. Ranged types are a charm to develop with and they don't have to introduce a runtime cost.
Sort of C/C++ without NULL. It's a bit niche perhaps, but –depending on performance– could be useful. I quickly browsed the documentation, and there are some nice features, such as compile time code, which have a quite readable syntax.
&gt; Ranged Types I'd really prefer to explore the possibilities of const-generics here. Ranged numerics are just a special case of invariant; I'm not sure they warrant a built-in (and thus inflexible) language feature. &gt; Bit Fields This *could* be specified via libraries, to an extent (I did it in C++), but it would limited. I think a lang-item, for which I humbly suggest the name `Nibble`, would be very useful: - to get bit-level alignment (disallowing pointers to it, that's fine), - and bit-level size. I imagine something like: #[repr(C)] struct CR2Register { frequency: Nibble&lt;5&gt;, _reserved_6_7: Nibble&lt;2&gt;, iterren: Nibble&lt;1&gt;, itevten: Nibble&lt;1&gt;, itbufen: Nibble&lt;1&gt;, dmaen: Nibble&lt;1&gt;, last: Nibble&lt;1&gt;, _reserved_13_31: Nibble&lt;20&gt;, } For bonus points, combine with an attribute allowing to specify the exact alignment of a field (at bit-precision): #[repr(u32)] struct CR2Register { #[bit_align(0)] frequency: Nibble&lt;5&gt;, #[bit_align(8)] iterren: Nibble&lt;1&gt;, #[bit_align(9)] itevten: Nibble&lt;1&gt;, #[bit_align(10)] itbufen: Nibble&lt;1&gt;, #[bit_align(11)] dmaen: Nibble&lt;1&gt;, #[bit_align(12)] last: Nibble&lt;1&gt;, } and get rid of those "reserved" fields. &gt; Volatile I agree it's currently verbose. Still, there's this nagging thought that sometimes it's good to clearly shows what happens. Volatile memory means that reads/writes can have side-effects, accidentally reading twice for example could return a different result the second time (because internally it advances through a queue of signals). Writes are generally pretty obvious in your proposed syntax, however there's no distinction between regular reads and volatile reads. Imagine instead: volatile { UART1.CR1 |= UART_CR_ENABLE; UART1.CR2 = UART_CR_ENABLE | UART_CR2_STOP_BITS_1; } where `UART_CR_ENABLE` is a volatile read. Is the double-read intentional or an error? Should the read be cached in a local variable instead? We've lost *intent* here. Imagine, instead, using a macro: volatile! { UART1.CR1 |= UART_CR1_ENABLE &amp; volatile UART_CR1_READY; UART1.CR2 = UART_CR2_PARITY_EVEN | UART_CR2_STOP_BITS_1; } which under the hood converts this to: write_volatile(&amp;mut UART1.CR1, read_volatile(&amp;UART1.CR1) | (UART_CR1_ENABLE &amp; read_volatile(&amp;UART.CR1_READY))); write_volatile(&amp;mut UART1.CR2, UART_CR2_PARITY_EVEN | UART_CR2_STOP_1); Would that be good for you?
Text editor assertions are subject to Poe's law.
Well... it's unclear exactly what const generics will end-up like in Rust, so allow me to use C++ to demonstrate. I'm sorry, it'll be a bit gross... template &lt;typename R, typename I, I min, I max&gt; class Ranged { using common = typename std::common_type&lt;R, I&gt;::type; static_assert(std::is_unsigned&lt;R&gt;::value); static_assert(static_cast&lt;common&gt;(max - min) &lt;= static_cast&lt;common&gt;(std::numeric_limits&lt;R&gt;::max())); public: explicit Ranged(I i) { this-&gt;set(i); } I get() const { return static_cast&lt;I&gt;(mData) + min; } void set(I i) { if (i &lt; min || i &gt; max) { throw std::out_of_range(); } mData = static_cast&lt;R&gt;(static_cast&lt;common&gt;(i - min)); } private: R mData = 0; }; This is, possibly, the most generic ranged type possible. Most interestingly, its data-representation is independent of the type of the range represented, which is quite interesting for packing options: you can represent the range of all valid birth dates for your customers (1890 - 2145) in a single `uint8_t` instead of a `int16_t` for example. 
I think it's probably more fun to build everything yourself.
I depends on where you come from. I love concurrency and async in Rust and hate Node and Go. Why? Because I always manage to set myself ownership traps - which Rust doesn't have. We're terrible at communicating that, which makes verbose API take over. 
&gt; I love the passion to make Rust one if not the best language for the web. But I also feel it's sort of on track already, and I don't find it really all the time sensitive the mark Rust as "the" wasm language. Rust is in many ways already much more powerful than the web languages of old. Where as I feel Rust has a lot more work ahead of itself to earn the crown from the C/C++ world. I want to live in a world where the only reason not to use Rust, is because your working on an existing code base. Hm, I'd really like mention here that we have high interest from production companies in our WASM implementation. The reason being that something that was missing for a long time is now coming close: the ability to share algorithms between all platforms, including the web.
Both the bitfield and the packed_struct crates look like pretty comprehensive solutions for bitpacking. Before looking at them, I tried to come up with a simple solution for hardware registers (ie. single machine words of packed data). Here it is in a playground: https://play.rust-lang.org/?gist=59e3bb433436bce92bc01938dfffde03&amp;version=stable For this use case I quite like the simplicity, and I think a read-modify-write should compile down to very optimized assembly. (Possibly very slightly faster than solutions that unpack to a struct and then pack that again?)
Features like injected highlighting work (pandoc does it), but it slows vim down a lot. It would be nice if highlighting could be done in the background, and any new text that is typed just inhirits the highlighting of the character before it, or default if it's the first character on the line. That could just be the specific plugin doing it badly though, maybe asynchronous highlighting is possible in vim. 
Yay - I thought something like this was happening, although I'd lost track of the details. Thank you. The fact that it's happening doesn't change its importance. :-) I wish the other issues were as easily fixed.
While it's not trivial to implement `from_fn`, that's exactly the reason it should be implemented in std and not left for every person to implement by himself (with bugs).
Did you install webkit2gtk? It's not included in gtk3 itself.
Is it possible to select text and move cursor using [shift] + [ctrl] + arrows/home/end?
I would be ecstatic to use [rust-crates](https://github.com/rust-crates) github organization for this. We just started the **ergo** crates ecosystem project (not yet ready for announcement) and we would probably be willing to take maintenance of any crates that are/will-be part of that ecosystem, and maybe others as well.
This is a pretty cool crate, but it also illustrates some of the issues that I hope a built-in bitfield abstraction could help with. First, I haven’t studied this crate in detail, but it looks like it's fundamentally a serialization crate, which means that there’s a separate packing and unpacking step which deserializes all fields and places them on the stack. So, a hardware register with 32 single-bit fields would be deserialized to a 32 byte boolean struct, even if only one of the bits is accessed. What I want for embedded is something that operates in-place, extracting only the field that is requested. I’d also like to have struct-like access to individual fields, which simply not possible now because the language does not support field getter / setter traits. There’s the separate issue that right now we have multiple crates tackling the same fundamental problem, but each is significantly different: some use special syntax, some use attributes with different names and semantics, some are minimalist and some are maximalist. As a library author that wants to use bit fields, selecting a crate is a research problem, and it’s yet another API to learn and dependency to support; I have an incentive to not use a bit field abstraction at all by using ad-hoc bit manipulation, or write my own bit field abstraction that suits my own purposes.
Also, you may have installed an older version, so please check this.
&gt; I still don't really understand what the problem with self borrowing is. most succinct example I can give https://play.rust-lang.org/?gist=75a68b5c46b23d37f1e17e6c2adece64&amp;version=stable
no design was accepted yet, no.
https://github.com/getsentry/sentry-rust Logging to stderr on production is a joke. Even if it then goes to the system journal. Nobody reads logs regularly. Every serious project needs to forward errors to a service that can aggregate them.
This is an awesome idea. The contract with the maintainer with what's allowed and what isn't could even vary from crate to crate.
&gt; I'd really prefer to explore the possibilities of const-generics here. Ranged numerics are just a special case of invariant; I'm not sure they warrant a built-in (and thus inflexible) language feature. My thinking is that simple ranged types are pretty fundamental; for the bit-sized ones, I don’t think there will be many disagreements about how they should work, and there are a few wrinkles with the non-bit-sized ones but I think the Rust community could come to a consensus on how they should behave. Having these available as a primitive and in the standard library would vastly increase their use. Another benefit of having ranged types in the language is that they make compiler optimization potentially a lot easier. For instance, ``` fn my_func() -&gt; u4 { … } let arr = [0u8; 16]; for x in 0..100 { arr[my_func()] = x; } ``` The compiler can eliminate bounds checks from the array access simply based on the function signature. &gt; Writes are generally pretty obvious in your proposed syntax, however there's no distinction between regular reads and volatile reads. In this specific example, UART_CR_ENABLE is meant to be a constant, so there’s no issue with multiple reads. More generally, in my proposed syntax, ALL reads and writes would be volatile, plus I would expect that the compiler to respect the exact order of reads and write. You would be responsible for reading into a temporary variable if needed. So you might do: ``` let data: u8 = volatile { UART.RDR }; data = (data &lt;&lt; 4) | (data &gt;&gt; 4); volatile { UART.TDR = data; } ```
Awesome idea Matthias! This is especially important for the large/most used/important for the ecosystem crates!
Sometimes it goes further than those two, but it never finishes..
This is a tangent to your point, but even in a "detached environment" you probably don't ever want to close file descriptors 0 (stdin), 1 (stdout), or 2 (stderr). If you really don't stdout/stderr to go anywhere, do something like `fd = open("/dev/null", O_WRONLY); dup2(fd, 2); dup2(fd, 3); close(fd);`. I say that because lots stuff will try to write to them, like `assert` calls in C code. If you close them, then the next descriptor you open will claim that number, and then bad things can happen. See ([https://www.sqlite.org/howtocorrupt.html](How To Corrupt An SQLite Database File).
I will refrain from trying to pretend that I can come up with a simple solution and instead say that it sounds like an interesting challenge :) Thanks for sharing.
Logging to stderr doesn't mean your logs aren't being forwarded to an aggregation service. 
`winapi` is big. *Really* big. You just won't believe how vastly, hugely, mind-bogglingly big it is. I mean, you may think it's a long way down the road to the chemist, but that's just peanuts to `winapi`. Use `--no-deps` and never, *ever* let it try to document `winapi`.
Finally!!! Thank you for that! Why isn't --no-deps a default?!
When `cargo doc` was designed, they did not forsee `winapi`. They did not believe the legends. *The warnings*. But now, like the Cygnus, caught in the pull of a black hole, all we can do is fall. Fall into darkness.
I've tried this recipe and it has been running for almost 30m, it seems to be stuck here: https://imgur.com/a/JlDke :'(
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/O1SWOL4.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20dtbn7sl) 
Read again. You're trying to be pedantic but you're failing. Forwarding logs to a logging aggregation service does not make stderr not suck for productional use. It only fills the hole with something else (Sentry, Rollbar...). Stderr remains just as unstructured, primitive, queriable in O(n), deleted after several rounds of rotation, rather than sampled. Forwarding it to logstash does not cut it. A joke from the 70's or early 80's. That's why context-aware log aggregation is a must.
&gt; My thinking is that simple ranged types are pretty fundamental [...] I think the "notion" of ranged types is possibly fundamental, but I am not sure that there's necessarily a broad agreement on how to (1) represent and (2) operate on such types. We can take inspiration from other languages, but we should also consider their shortcomings. A few points to consider: - It seems a mistake to tie the memory representation to the range: just because there are at most 61 seconds in a minute does not mean I want a 5 bits seconds fields. It's compact, but reading/writing requires bit-masking/shifting which may negatively affect performance. - It is not clear whether such types should support operations. Does multiplying two u2 make sense? Adding them? Should there be an overflow check? Maybe such range types should be *storage-only*, with an overflow check only when setting the value? This is why I'd like to distinguish between: - memory representation (and proposed `Nibble` for bits-sized types), - and type invariants. And this is why I propose that we first investigate the design space via libraries once const generics make it feasible. &gt; The compiler can eliminate bounds checks from the array access simply based on the function signature. Range constraints seems a desirable feature independently of ranged types. I think it would make sense to use an *attribute* which would apply to types, arguments and return values of functions. The compiler would then automatically insert checks as necessary to guarantee the constraints are respected (with an unsafe hatch as usual). &gt; In general I don't think there's any harm that a too-broad volatile block could do; it's just a section of code where certain optimizations are disabled. Well, as I mentioned, accidentally reading twice from a register would be a bug, and it might not be *obvious*. At the very least, that you and I have a different opinion on the right way to read volatile values (more or less expressive) indicates that experiments would be valuable to gather feedback. And I propose that experiments be conducted in the library space using functions/macros. Depending on their success/pain points, we can then make an informed decision on the best path forward: - maybe it'll be doing nothing (just use the crates), - maybe it'll be introducing a new API in core to simplify the implementation, - maybe it'll be introducing a new feature in the language to simplify the implementation, - maybe it'll be taking in the functions/macros in the core library (and possibly have them use unstable features/APIs), - maybe it'll be introducing a new keywords or two. I don't know, but I'd rather not pick the solution before investigating the problem.
Oh, I think I got hung up over the self-referential bit and missed the actually important `move internally borrowed data` part. Probably not the first to think of this but couldn't the data be stored in a tree instead of a flat enum? That is, something like struct AAndB { data_life_across_yield: ..., other: AOrB } enum AOrB { A(i64), B(&amp;'static str) } That means the generator as a whole is still unmovable but you could step it without moving the enum contents?
Haha, I have a personal note app written in rust, I call it tetanotes :)
Yep, essentially it's a serialization crate. An extension that emits a getter/setter functions that directly manipulate just certain bits could be implemented. My primary motivation are drivers that manipulate registers using an external bus, be it I2C or SPI. For instance, stuff like [this](https://github.com/hashmismatch/periphery.rs/blob/master/periphery_devices/bmp280/registers.rs) or a bit more visual representation of the docs support - [USB PD](https://users.rust-lang.org/t/bit-level-packing-library-request-for-feedback/14383/8). At this point, I'm probably a bit in over my head to actually stabilize all these complex crates in my own free time, but we'll see. I'd need a PR department to bring some help in :)
That doesn't look stuck. It's working. It's just brew hiding make's output from you. Look at the task manager / `top` / `htop`. Building a whole browser engine takes time. It's about 30m on my Ryzen 7 workstation. If your CPU is slower, expect it to take longer.
I understand the sentiment, but that approach doesn't scale. Say, you maintain a crate that depends on 5 crates. 3 maintainers of those crates drop out. You now maintain 4 crates. Finding people to take over crates is valuable work, which I guess would be great if it had a dedicated team.
Are there any of those were there aren't any panic-less versions? I think only the allocation ones, which is still in the planning stage. But for all others there are alternatives I think.
There were plans to do something like this within the Rust community team, but - quite frankly, we didn't have enough hands and also not much experience with that. I think having a team experienced in identifying and facilitating handover of important crates would be awesome. There's whole foundations built around the idea of longevity (Apache), it's an incredibly important work. If you want to help out with something like that. I guess there's absolutely no harm to get in touch and talk. community@rust-lang.org? :)
as an application, you can get this for everything by setting `panic=abort` in your `Cargo.toml`.
I would want the methods on a trait to resolve to links that terminate at hyperlinked examples of that trait being defined and/or used.
Thanks for informing that. README.md is uploaded now. I forgot to git push before. :D
This idea reminds of the the [jazzband](https://jazzband.co/) organization for Python projects.
As a fun exercise, you can close these descriptors in shell using `&lt;&amp;-`, `&gt;&amp;-`, and `2&gt;&amp;-`, and then see how many standard programs start misbehaving. I've seen editors bark error messages into open text files, even outright crashes when a program tries to log stuff to a rogue socket or a read-only descriptor. There is no guarantee that 0, 1 and 2 are open and useful when your program launches, yet most programs just assume that this is the case. 
Oh, wow, thanks for pointing them out!
Yeah, I agree that in practice `?` should be reserved for when the expression contains the same error type. I'm not sure how one would avoid this without manually handling the error.
&gt; I think the "notion" of ranged types is possibly fundamental, but I am not sure that there's necessarily a broad agreement on how to (1) represent and (2) operate on such types. We can take inspiration from other languages, but we should also consider their shortcomings. For the uX bit-width types, the intent would be that the semantics and supported operations are the same as u8, u16, etc. The amount of physical space they take up would depend on structure packing rules (if in a struct) or the space required by their container if variables on the stack. Ranges might indeed be an orthogonal issue and could be tackled with a different approach. I could see a case where you want to have a 1..31 range contained within a u32 for performance reasons. &gt; Well, as I mentioned, accidentally reading twice from a register would be a bug, and it might not be obvious. At the very least, that you and I have a different opinion on the right way to read volatile values (more or less expressive) indicates that experiments would be valuable to gather feedback. I’m not sure if we are communicating well here. Accidentally accessing a register more or less than intended is certainly a bug, but it’s one that Rust already lets you make. Right now you can write UART.TDR = (UART.RDR &lt;&lt; 4) | (UART.RDR &gt;&gt; 4); without any warnings from the compiler. A volatile block wouldn’t change that except to ensure that the compiler *always* does two reads. I definitely understand the argument that volatile read and write operations be intentionally noisy, but that seems to be an opinion that can’t be answered by more experimentation in the crate ecosystem. There’s no way that I know of today for Rust code to say “don’t apply certain optimizations to this block of code”, which is why I suggested this option.
I don't think this is a huge problem. There are many things that can cause performance issues. Rather than trying to guess what is fast and what isn't, much better to code as comes naturally, then benchmark, profile and fix. In this particular instance, I'm not sure what exactly the problem was. The [failure docs](https://docs.rs/failure/0.1.1/failure/struct.Backtrace.html) state that If this crate is run without the RUST_BACKTRACE environmental variable enabled, the backtrace will not be generated at runtime. Therefore there shouldn't be much of a performance impact? It's possible that `Box`ing the errors may have caused problems.
It's a good idea. Sublime Text do this for years now.
The only thing you can't work around by way of `map`, `get` and such are actually performing allocations and recursion. 
I built webkit2gtk with macports again and It took about 32 minutes (to test build times, my cpu is i7-7920HQ) and I got an error when running webkit2gtk-rs examples, also **while building webkit2gtk my cpu usage was almost 90% all the time**, however when building it with this command brew install astroidmail/astroid/webkitgtk@2.4.11 my **cpu usage is below 5%** and never ends (I'm going to let it run for an hour or so.. but I don't think it will ever end) BTW this is the error I got when I use the version compiled with macports. Compiling gio v0.3.0 (https://github.com/gtk-rs/gio#2f52f9a6) Compiling pkg-config v0.3.9 Compiling c_vec v1.3.0 Compiling gdk-pixbuf v0.3.0 (https://github.com/gtk-rs/gdk-pixbuf#9d4e424b) Compiling libc v0.2.36 Compiling bitflags v1.0.1 Compiling lazy_static v1.0.0 Compiling gdk v0.7.0 (https://github.com/gtk-rs/gdk#9d9658e6) Compiling gtk v0.3.0 (https://github.com/gtk-rs/gtk#22f82907) Compiling cairo-rs v0.3.0 (https://github.com/gtk-rs/cairo#b01edff7) Compiling cairo-sys-rs v0.5.0 (https://github.com/gtk-rs/cairo#b01edff7) Compiling webkit2gtk-sys v0.5.0 (https://github.com/gtk-rs/webkit2gtk-rs#6bb613f3) Compiling gobject-sys v0.5.0 (https://github.com/gtk-rs/sys#1eb3c44b) Compiling glib-sys v0.5.0 (https://github.com/gtk-rs/sys#1eb3c44b) Compiling soup-sys v0.5.0 (https://github.com/gtk-rs/soup-sys-rs#0b249ac5) Compiling gdk-sys v0.5.0 (https://github.com/gtk-rs/sys#1eb3c44b) Compiling pango-sys v0.5.0 (https://github.com/gtk-rs/sys#1eb3c44b) Compiling gtk-sys v0.5.0 (https://github.com/gtk-rs/sys#1eb3c44b) Compiling gio-sys v0.5.0 (https://github.com/gtk-rs/sys#1eb3c44b) Compiling atk-sys v0.5.0 (https://github.com/gtk-rs/sys#1eb3c44b) Compiling gdk-pixbuf-sys v0.5.0 (https://github.com/gtk-rs/sys#1eb3c44b) Compiling javascriptcore-rs-sys v0.1.1 (https://github.com/gtk-rs/javascriptcore-rs#dbef830c) Compiling glib v0.4.0 (https://github.com/gtk-rs/glib#ccee59f8) Compiling pango v0.3.0 (https://github.com/gtk-rs/pango#82423a55) Compiling javascriptcore-rs v0.3.1 (https://github.com/gtk-rs/javascriptcore-rs#dbef830c) Compiling webkit2gtk v0.3.0 (file:///Users/matias/workspaces/rust/webkit2gtk-rs) Finished dev [unoptimized + debuginfo] target(s) in 67.50 secs Running `target/debug/examples/main` thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: BoolError("Failed to initialize GTK")', src/libcore/result.rs:906:4 stack backtrace: 0: 0x101b02313 - std::sys::imp::backtrace::tracing::imp::unwind_backtrace::h3421d74c3554d1d6 at src/libstd/sys/unix/backtrace/tracing/gcc_s.rs:49 1: 0x101afedfc - std::sys_common::backtrace::_print::h81d2920454574615 at src/libstd/sys_common/backtrace.rs:68 2: 0x101b036a1 - std::panicking::default_hook::{{closure}}::h046b82ccd70886b8 at src/libstd/sys_common/backtrace.rs:57 at src/libstd/panicking.rs:381 3: 0x101b033a6 - std::panicking::default_hook::h00ff9adc172e30f9 at src/libstd/panicking.rs:397 4: 0x101b03b85 - std::panicking::begin_panic::hf76e4af07ba1dfa4 at src/libstd/panicking.rs:577 5: 0x101b03a1e - std::panicking::begin_panic::hf76e4af07ba1dfa4 at src/libstd/panicking.rs:538 6: 0x101b038f2 - std::panicking::try::do_call::h3cbb81c41447d36b at src/libstd/panicking.rs:522 7: 0x101b03852 - std::panicking::try::do_call::h3cbb81c41447d36b at src/libstd/panicking.rs:498 8: 0x101b3a163 - &lt;core::ops::range::Range&lt;Idx&gt; as core::fmt::Debug&gt;::fmt::h7e1bfae6b8dbdbf2 at src/libcore/panicking.rs:71 9: 0x101adc546 - core::result::unwrap_failed::h56531e79fa31ebae at /Users/travis/build/rust-lang/rust/src/libcore/macros.rs:23 10: 0x101adc199 - &lt;core::result::Result&lt;T, E&gt;&gt;::unwrap::h49534f69fdb0ee20 at /Users/travis/build/rust-lang/rust/src/libcore/result.rs:772 11: 0x101ade392 - main::main::hb68c20266f5facaa at examples/main.rs:34 12: 0x101b0e75e - panic_unwind::dwarf::eh::read_encoded_pointer::h3e27ca5c61a4336a at src/libpanic_unwind/lib.rs:101 13: 0x101b03e48 - rust_panic at src/libstd/panicking.rs:459 at src/libstd/panic.rs:365 at src/libstd/rt.rs:58 14: 0x101adebe4 - main::main::{{closure}}::h4f07463f5eb86194 Process finished with exit code 101 I really appreciate your help me through all this, any ideas what else it could be? Thanks! 
where can I find a list for every #[allow(_)] attribute?
Well, it wasn't exactly the nicest production environment we had. I was contemplating to fix that issue, but the deadline had other plans. For completeness: the server was run by starting a terminal, running `cargo run --release &amp;` and then closing the terminal. Getting it to work in that environment was a hell for more than one reason.
Not sure if this because of the ? operator or if this is specific to the Failure crate, but this is mentioned on the dedicated Failure website : &gt; The Error type allocates. There are cases where this would be too expensive. In those cases you should use a custom failure. (https://boats.gitlab.io/failure/use-error.html#caveats-on-this-pattern)
In this scenario, ultimately the Error type should not have been used, but yes I agree there are clarity issues with what exactly `?` does.
You can recurse without panicking. Especially if there's tail call optimization.
The box can also make things faster. As you say, best to measure.
That's `unsafe` which is arguably worse than panicking.
Ah, fair.
“Any circumstance” is hard. What if the power is pulled right before the call, for example? Or, do_a could abort, or produce a segfault with unsafe, etc.
May I ask, is there any specific reason to visualize all 3 million data points in a image? 
You may wish to check out / contribute to Gutenberg, which is a static site generator written in Rust. However, for actual sites I would currently recommend Hugo, which is written in Go. It's a lot more mature / fully featured than Gutenberg at the moment, it's super-fast, and they provide binary releases (also available from package managers), so you don't need a Go environment.
The most basic odd-thing I see here is [prints possibly panicking instead of returning io::Result&lt;()&gt;](https://github.com/rust-lang/rust/blob/1.23.0/src/libstd/io/stdio.rs#L661).
Sorry, don't have enough time to fully dive into the type system question, but just wanted to ask: Have you thought about using multiple schemas (in Postgres) and put each tenant with the tenant-specific tables into their own schema? (Probably depends on whether you have 4 tenants or 4000 :))
One option around your particular problem is to subsample the data you're plotting. If your data files are structured well enough, you could even save a lot of disk reads this way.
&gt; I think having a team experienced in identifying and facilitating handover of important crates would be awesome. I would heavily favor a team helping with the *transition* rather than a team *taking ownership*: 1. I doubt taking ownership would scale, 2. It's unclear whether anyone on the team would be qualified in the crate's domain (anyone feeling up to... `ring`?), 3. Maintenance is nice, but continued development is better. As such, I say "nay" to the maintenance team, and "yeah!" to the handover team. *Side-note: should a policy be put in place for crates.io staff to be able to handover publisher's rights for a crate if the only publishers become inactive/unresponsive?*
Yes, I have, and I know this is a common solution. However, I'm looking to see if this can be done in the type system, so that it could be applied to systems with &gt; 1000 tenants, or (if rust supported it) a database like mssql which doesn't have the same schema support as postgres.
I'll be happy to review whatever patches, but as for integrating it with diesel or rust-postgres it might be cleaner to to impl To/FromSql in the crate itself and pull this crate as dependency be it a feature or otherwise. I'll be trying get most of the features done over next couple of weeks so I am hoping to publish fairly soon. 
There's also `get` which doesn't panic either and it's not `unsafe`.
This is true, it depends on whether you want to have `#[no_panic]` disallow stack overflows by recursion too. (I can't remember if they count as panics or just aborts) If we had `become`, that'd be safe to use even in a no-panic context.
`abort` I believe is for the entire process whereas a stack overflow is per thread. I'm not sure. Elaborate please on `become`?
I didn't think I wanted/needed this until now. Is there an RFC?
I think it got stalled. https://github.com/rust-lang/rfcs/issues/271
I think this would be very useful, although this as always has to be weighted against increasing the language. Two examples: 1) Imagine that you really want to catch all panics, so you use `catch_unwind` to do so. But is there code *after* catch_unwind that might panic, causing a breach in the panic catching net? A `nounwind` attribute could assist you with making sure there are no such breaches. 2) The `take_mut` crate could have a simpler/faster implementation if it took a `Nounwind + FnOnce(T) -&gt; T`. I'm sure this is not the only place where a "nounwind" function could have a faster implementation. As a first step, I wonder if it's possible to implement a check in a procedural macro? MIR should be able to reason about which functions can panic and which ones can not, right? 
Yeah, I noticed that it didn't play nice with large files, as well, along with some other polish items. It will be neat to see amp's progress in the future!
Also https://www.palletsprojects.com/
Running gnuplot is slightly slow even for small datasets. It would be great to have a pure rust plotting library. So far [dataplotlib](https://github.com/coder543/dataplotlib) seems to be the most promising pure rust library. (Or alternatively a rust backend could be written for [rustplotlib](https://github.com/ubnt-intrepid/rustplotlib))
In general, very good points. However, the traditional smart-pointers aren't the only things which heap-allocate; RawVec apparently uses the new Allocator API, and since I'd imagine that most smart-pointers use that API, it would probably be best to modify that API and propagate the changes upwards to the smart-pointers, than to only modify the smart-pointers.
Author of Gutenberg here, thanks for the plug! What features from Hugo are you missing it apart from i18n? I've moved some of my sites from Hugo to Gutenberg and it's usually much much nicer because of the better template engine and removing the nodejs dependency for sass.
You're actually quite right, we can 'anchor' types today in trivial examples like this. The problem is that you cannot implement this kind of anchoring as a method on `Foo`. To modify your example to try this: https://play.rust-lang.org/?gist=34cf11eedd38db3ff156046b45765407&amp;version=nightly (I turned NLL on because it gives a much better error message, even though it doesn't enable this.) Since you can't actually much about in the guts of a generator, we need to expose this "anchoring" operation as a method somehow.
Ah thanks. I must have been thinking of D instead of C++. The D compiler will statically check functions declared "nothrow" to ensure they throw no exception (and presumably do not call functions that may do so).
I use PCP on a project. If you use integer domain for your constraint, it's really interesting. It use constraint propagation which has better performance than backtracking. It can even manage cumulative constraint. I think it's easier to use than the other projects for constraint solving (if you don't already know them). I use it inside an automate for task planning and it works well with good solving time. You can contact the author to validate that it's adapted to you constraint problem.
You're being belligerent for no particularly clear reason. /u/radix's reading comprehension isn't lacking, nor is s/he being pedantic. Most of the flaws you see with stderr are problems with stderr as a log storage format (though I'm not clear on how you think people are using a stream as a storage format), but radix is suggesting it as an initial step of transport to a more robust service. You say that using it for transport "does not cut it," with no explanation, just more vitriol. 
&gt; I suspect the Kakoune model is better but I've been doing Vim a lot longer. I used Vim for twenty years, but after using Kakoune for a few weeks it's overwritten my Vim habits.
Failure actually `Box`es things anyway: https://github.com/withoutboats/failure/blob/master/src/error.rs#L21-L28 I'm one of the authors of the slow library OP was using. The problem was that we'd hit a pessimal case of failure, because we'd been confused by the line in the [failure docs](https://docs.rs/failure/0.1.1/failure/struct.Backtrace.html) that states: &gt; Even if a backtrace is generated, the most expensive part of generating a backtrace is symbol resolution. This backtrace does not perform symbol resolution until it is actually read (e.g. by printing it). If the Backtrace is never used for anything, symbols never get resolved. We assumed this meant that it was fine to create `failure::Error`s with impunity, as long as we didn't print them. We used them widely in our codebase, with `RUST_BACKTRACE` enabled to help in cases of actual error. Unfortunately, it turned out that creating the backtrace, even without resolution, still had around 5μs of overhead, which was too much for hot code. Disabling RUST_BACKTRACE lowered the overhead to around 50ns, but we switched off of `failure` anyway, because even that much overhead was unacceptable for our use case. Using an old-school error enum brought overhead down to around 1ns, a reasonable amount. There were some other interesting aspects of the project that I have a half-written blog post about, I'll definitely post it here once I finish the write-up.
I think that's only because the anonymous `&amp;mut self` lifetime isn't unified with `'a`? With a manual annotation it compiles: https://play.rust-lang.org/?gist=21ca51ce1dfaa65aee9c0cf7eeca5660&amp;version=nightly
Thank you that was mostly what I was looking for
I wonder if in addition to this they could be helo with defining the role of a maintainer and training people to take on maintainer roles? I've not seen this done before, but it sounds like a fantastic idea..
https://github.com/rust-lang/cargo/pull/4977 will help tremendously, though won't do anything about winapi taking forever to document.
I want to migrate from Hugo to Gutenberg, but It took me some time to get used to hugo. Is there any migration guide from Hugo? I think that would be really useful for people like me wondering how hard and how many things will seamlessly work or not work.
If rust can't satisfy the "writing hacked up software" requirement it will never be viable for production.
&gt; I'll definitely post it here once I finish the write-up. that'd be great! Especially as more people use `failure`, making sure it's up-to-snuff is super important!
Forwarding to logstash definitely cuts it just fine.
&gt; Side-note: should a policy be put in place for crates.io staff to be able to handover publisher's rights for a crate if the only publishers become inactive/unresponsive? This has been debated, but that's a can of worms that's really problematic. I think the problem of making it feasible to actively give away ownership is important first.
Where do people store stderr output? People use rotated files, non-rotated files (bad), system journal. It's pretty poor if it's not streamed somewhere where you can query logs from the entire infrastructure. Down the rabbit hole: why stderr does not cut it; 1. Processing unstructured logs (like AWS Logs, Kibana) and why it's not all that great No matter what you do with unstructured log lines, you still have unstructured log lines. It gets worse when messages get broken up into multiple lines (tracebacks). All that you can do with text is match it with some kind of expression. 2. Usefulness of auxiliary data When you have a log handler for warnings and errors, and an uncaught exception/panic handler, they can get insight into what's going on the very moment shit hits the fan and they have access to whatever instrumentation you added to it, like previous logs, HTTP request context (Sentry calls it breadcrumbs). 3. Why stderr is bad for rich structured logs That's too much information for a primitive approach. If you implement an error aggregation system with stderr, then you lose the only use of stderr on production - relatively terse logs that you can grep when primitive approach is what you actually need. That's why rich data should go through a side channel.
The problem is that this training usually happens in-project (I've seen this, and the Rust project does this). The reason why I think there's no open maintainership trainings is that people don't plan to take over maintainership with fresh projects/libraries. Suddenly, it's there. And those that kind of find their way out of that phase don't need it anymore. Still doesn't mean that you shouldn't try.
I think the `?
it's also offtopic for that, they want /r/playrustservers
&gt; Side-note: should a policy be put in place for crates.io staff to be able to handover publisher's rights for a crate if the only publishers become inactive/unresponsive? I guess that's rather complicated because of licensing. My idea was that the author _actively_ says "I don't want to maintain this anymore" rather than the team simply "taking over". From what I read in this thread, my definition of "maintaining" is slightly different from you people in here: I think of updating dependencies, updating documentation, keeping the project up to date with compiler changes and dependency changes ... not necessarily adding functionality, changing functionality or such things. Not even closing bugs - rather document them and make them visible to the crates users (for example in the documentation). The ultimative goal should **always** be to move the crate out of the teams responsibility if someone steps up and wants to _actively_ develop it. 
What's an idiomatic way of doing this? I'm fighting a borrow checker pretty hard. pub fn expand_changesets(sets: &amp;mut BTreeMap&lt;OrdVar&lt;f64&gt;, ChangeSet&gt;) { for (modifier, set) in sets { for (earlier_modifier, earlier_set) in sets { /* calculations */ if condition { to_append.insert(OrdVar::new(new_modifier),new_changeset); } } sets.append(&amp;mut to_append); } } I realize why this is forbidden-- normally, there's no guarantee the new key wouldn't be earlier in the BTree-- but in my situation, I do have that mathematical guarantee. I need to loop through all earlier entries and possibly insert with a guaranteed greater key.
oh sorry
I've made a number of passes at using Kakoune but the two reasons I don't stick with it are the lack of plugins and the awkwardness of the alt-key chords as part of the normal editing sequence. This week as part of my research I've made another go at it and set up space to act as alt when chorded and I find that a lot easier.
I don't have an opinion about whether println! should panic. I do have strong feelings about error aggregation though. Positive feelings about proper error aggregation, mixed feelings about various crutches (Kibana usage doesn't really compare to Sentry usage).
I think the guideline should instead be that `Try::from_error` should be cheap. Checking an environment variable and taking a backtrace is not cheap enough to go there.
Alt is a *little* bit annoying for me to press, but I'm adapting. Using space as a modifier sounds amazing, though—how did you set that up?
I’m not the person you were asking, but I recently set up my blog and thought about Gutenberg and Hugo. I went with Hugo for a few reasons. I'm only able to work on Rust related things on nights and weekends, so the more time I can devote to that the better. The site generator is something I’m rarely going to touch, so I don’t want to spend a ton of time messing with it. That includes picking the theme, among other things. In this regard the major thing in Hugo's favor is the wealth of themes available. I only saw two themes listed on the Gutenberg site, and neither one was really what I was looking for (no one's fault, I’m picky). I’m sure I could port a theme if I really wanted to, but I didn’t want to, so that was that. On top of that Hugo has been around a while, so I knew if I had an issue someone else would have written/asked about it somewhere. All that being said, I look forward to using Gutenberg in the future once there’s a larger community around it.
&gt;Kibana usage doesn't really compare to Sentry usage yes... because they're not doing the same thing... so what's your deal with replying to OP like this if you *know* that logging to stderr and using sentry is not really mutually exclusive at all?
So basically, it's the ability to both `await` some information and `yield` some information. That does make some sense. (But wouldn't this still be semicoroutines though? As I (barely) understand it, full coroutines are allowed to arbitrarily send execution to any other coroutine, whereas semicoroutines can resume down or yield up, but can't jump sideways.) So if we had argument resuming generators, you could do something like the following (ignoring some complexity): (forgive mobile formatting) let file_stream = open_file(); while let next_byte = await file_stream.next() { push_parsing(); if has_next_token { yield next_token; } } Whereas that's not really possible with today's design?
50ns vs 1ns is a *huge* difference for something that's supposed to be free (that is, `failure` with `RUST_BACKTRACE` off). :/
(I am not familiar with the `failure` crate, so I'm going on what I've read in this post. I hope this doesn't mean I'm adding more heat than light...) That creating a `failure::Error` is much more expensive than programmers generally expect given their experience with errors elsewhere in Rust, combined with the ubiquity of error type conversion, is a footgun. This is the sort of thing Rust claims to avoid. Even without looking up symbols, generating a backtrace on Linux or macOS entails parsing DWARF (well, a minor variant thereof) unwind information for each machine code location that appears in the backtrace. Unwinding libraries designed for profiling, like Firefox's [LUL][lul] or Valgrind's unwinder, can make this pretty fast (about [220 instructions/frame][speed]), using all sorts of optimizations, but it's still pretty heavy. Conditioning capture on `RUST_BACKTRACE` doesn't really help, because that used to be a flag that developers could simply leave on by default during development without performance impact. Conditioning capture on an environment variable specific to this case, say, `RUST_FAILURE_BACKTRACE`, would be better. [lul]: https://searchfox.org/mozilla-central/source/tools/profiler/lul/LulMain.h [speed]: https://blog.mozilla.org/jseward/2013/08/29/how-fast-can-cfiexidx-based-stack-unwinding-be/
&gt; 2018-01-31 A post from the future :O Time travel is real!
Muhahahah.. Did not notice. I planned to finish the post until end of the month and publish then, but was too eager to get it out,... These things happen. No harm done, I guess.
It is RLS related, tried the other Rust plugin (kalitaalexey.vscode-rust), same issue. But I'm on stable, weird.
I think I might have found a bug, but I'm not sure if there's already an issue on it or not, I'd expect the following code to compile with nll, but I get a ``cannot borrow `f.bar` as mutable more than once at a time`` // struct Foo { bar: Bar, } // struct Bar(); // do_foo(&amp;mut self, v: u8) // impl Foo // fn do_bar(&amp;mut self) -&gt; u8 // impl Bar f.do_foo(f.bar.do_bar()); If I instead do: let v = f.bar.do_bar(); f.do_foo(v); It compiles, hence the possibility of it being a bug. Any idea where to report this if it isn't reported / if it is even a bug in the first place?
The way I see failure, hot code should be returning `Result&lt;_, impl Fail&gt;`, and _application_ code `Result&lt;_, failure::Error&gt;`. It's better to give information out as well, so your `impl Fail` type for the error case would be a exhaustively `match`able enum of possible errors, as opposed to `failure::Error`'s dynamic resolution. `failure::Error` is for cases when the consumer is unlikely to be able to handle the error. `impl Fail` is for cases when the consumer might want to ignore the error. A regular struct/enum is for when the error case is an expected code path and should always be handled.
Wait, is that returning a failure::Error in nonexceptional conditions? Because I'm pretty sure you're not supposed to do that.
I'm on OS X and use [Karabiner](https://pqrs.org/osx/karabiner/) to do keyboard modifications. [Here's the config](https://gist.github.com/grayrest/c2e5f4ef498feb87d9ca91684ba2004a) which goes in `~/.config/karabiner/assets/complex_modifications/space_opt.json`.
It's unfortunate that the backtrace functionality is provided as a library feature that any crate in your dependency graph can enable. Ideally it would be part of the language instead, like `panic!`, so the primary crate could control it.
I fully agree and think this is a huge issue in itself. Since the announcement of the Failure create I got really worried exactly because of this broken promise, but also because now that the dust was settling on error handling a "Rust 2.0 feature" appears and everything changes again. I'm uneasy with Failure becoming a new standard and more yet if it becomes part of std. I may be missing or misunderstand something, but for now I will continue avoiding Failure. I'll surely do some testing and comparison though. Sorry about this message. 
Also, if using Windows, you'll want to turn off Windows Defender (or add an exception for your project directory). Trying to scan every file as it gets written is really where the slowdown comes from. See also this issue: https://github.com/rust-lang/rust/issues/41470
Yeah, you soon realize that actually what you want is a *total* function, not a nothrow one. Basically, you restrict yourself to a non-Turing complete subset of the language where all loops have statically enforced upper bounds, no `unsafe`, obviously no diverging functions, and so on. Guaranteed totality is certainly desirable in certain applications but definitely not so simple as just forbidding panicking.
I know about those things. I'm not saying writing panic-free code is impossible, I'm saying it is much harder than most people expect.
My wife and I have been looking into foster parenting where we’ve been exposed to the term “respite” care. It’s basically vacation for foster parents. You can get a break for a few days or weeks while someone else covers for you. This blog makes me think of it as “respite care for open source projects”. I’m a big fan of this.
I threw together a benchmark and it's closer to 35ns, but still. Also, that's only at the creation of the not-backtrace; passing around a `Result&lt;Thing, failure::Error&gt;` is equivalent to passing around a `Result&lt;Thing, usize&gt;`, that is, fairly inexpensive. A lot of the cost at creation seems to be coming from the cost of copying around an empty [`InternalBacktrace`](https://github.com/withoutboats/failure/blob/master/src/backtrace/internal.rs#L13) struct; maybe a couple of inlining annotations would help.
Well, there are a bunch of slightly differing definitions of coroutines. The core is always some sort of trampoline (pausing computation) and generally they both yield and await. For instance there are a couple papers that call haskells streaming libraries anonymous continuations. For instance the conduit library: yield message .| encodeUtf8C .| encodeBase64C .| stdoutC each part seperated by the .|'s is a coroutine that awaits from the left and yields to the right. There are also more complex variants that allow arbitrary control flow graphs but that's as annoying to write as fully explicit coroutines. 
What's the most ergonomic way of handling multiple optional arguments (without using a builder*) that is still readable? Currently I have a bunch of `Option&lt;T&gt;` arguments which isn't particularly good. I'm in the process of moving these to a trait `IntoSome` that means I can give that argument a `None`, `u8`, `String`, etc. and it won't complain. Building on that, I've thought about an `IntoSomeStr`, `IntoSomeNum`, etc. for strictness on exactly the type of that argument, but it's starting to look a little wordy. Is this still okay? \* This issue is with a couple dozen functions that would all need their own builder to make that work, so that's not happening.
I've found taking just `Into&lt;Option&lt;T&gt;&gt;` to be reasonable. I mean, if your own trait offers more advantages over that, that's also good. If `IntoSomeStr` and `IntoSomeNum` could be refactored to just be a generic `IntoSome&lt;&amp;str&gt;` and `IntoSome&lt;u8&gt;` though, I wouldn't make them separate types. I mean for me, `Into&lt;Option&lt;u8&gt;&gt;` works well - but I don't know if you have a more specific use case. fn build_it&lt;T, U&gt;(name: T, amount: U) where T: Into&lt;Option&lt;String&gt;&gt;, U: Into&lt;Option&lt;u32&gt;&gt;, { if let Some(name) = name.into() { println!("Hello, {}.", name); } if let Some(amount) = amount.into() { println!("amount: {}", amount); } } fn main() { build_it("name".to_owned(), 4); build_it(None, 22); build_it(None, None); } 
I'll be checking it out tomorrow. I've always wanted something like this in my very short time in rust as well.
Have you looked at the Nom `verify` macro?
But then you can't call it more than once, because every call is to the same lifetime. This doesn't work for resume. What we need is a way to say "`self` cannot be moved for lifetime `'a`", which is not exactly what either `&amp;self` or `&amp;mut self` say.
`Error` allocates and we've never claimed it is free. You and I have had this discussion before.
Verify will parse and then it will check result of the parser. I need it other way around. I will see if I can write such macro myself.
That might actually work, thank you.
FYI: a better way to run that command would be `nohup cargo run --release &amp;&gt; /dev/null &amp;`: `nohup` will eat the SIGHUP when you close the console (which *should* otherwise be passed through by Cargo and cause your program to exit) and `&amp;&gt; /dev/null` will redirects stdout and stderr, rather than just closing them.
Also, every program runs on a real computer, which may suffer from hardware bugs, power failures, cosmic rays, baseball bats, etc.
I've created [Don't panic crate](https://crates.io/crates/dont_panic). I believe you will be interested in that. :)
As a matter of fact, we did keep failure around for slow-path errors :) It was also quite nice to have backtraces during development, although I'm not sure if "use Error then switch to an enum for release" is actually reasonable advice.
&gt; although I'm not sure if "use Error then switch to an enum for release" is actually reasonable advice. It definitely seems like a workflow that's worth supporting. I think that if you create the enum, derive Fail for it, and then just use `Error` in your APIs, you can replace the `Error` with your enum before you release and nothing should break (assuming every time you threw an error it was your enum type).
&gt; I think it's one of those intractable computational problems that has no theoretical answer at the moment. An arbitrary Turing-complete function cannot be proven to exit¹. This is not merely intractable; it is proven impossible. This is known as the [halting problem](https://en.wikipedia.org/wiki/Halting_problem). ¹ To be precise: no program in a Turing-complete system can determine, for every possible program in a Turing-complete system, whether that program halts or runs forever on any given input. If it could, it could be fed a construct around itself which would contradictorily halt if it said it wouldn't and not halt if it said it would. Note that such a system may determine for *some* inputs whether they halt, e.g. it is easy to inspect `loop { }` and determine that it does not halt.
**Halting problem** In computability theory, the halting problem is the problem of determining, from a description of an arbitrary computer program and an input, whether the program will finish running or continue to run forever. Alan Turing proved in 1936 that a general algorithm to solve the halting problem for all possible program-input pairs cannot exist. A key part of the proof was a mathematical definition of a computer and program, which became known as a Turing machine; the halting problem is undecidable over Turing machines. It is one of the first examples of a decision problem. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
failure checks an env var one time and thereafter its a single atomic load if backtraces have not been turned on.
`RUST_BACKTRACE=1 RUST_FAILURE_BACKTRACE=0`.
Thanks. I didn't look at the source but I did try to find it in in the rustdocs (the main page) and in the GitHub readme. It may be useful to put this there.
Yeah, we definitely should have used an error enum (with `#[derive(Fail)]` instead; and that is in fact what we ended up doing.
I think this feature was added without documenting it at all. :-\
It would be nice if there was some kind of global config to disable either specific crates or all dependencies.
https://play.rust-lang.org/?gist=6eac9ece61060dfd98403455b5219145&amp;version=stable I am trying to remove items off vector while borrowing from it. I think it is not possible to do this. But what are other ways of doing this ( except consume_for). Consume and consume_for does the same thing here, consume does not compile because of the remove
So kind of like modern advice on exceptions. They're practically free to have present, but expensive to throw.
&gt; The Error type allocates. eeeeeeeewww
In this post, I'm discussing the (arguably) lesser-known [`stream::unfold` function](https://docs.rs/futures/0.1.17/futures/stream/fn.unfold.html) from the _futures_ crate. It shows how you can use `unfold` to create a `Stream` of items from some third-party API that uses the common pagination pattern -- i.e. returns a response containing an offset/token that you need to pass again to get the next batch of results. In a sense, this is a limited form of the `stream_yield` macro from _futures-await_, but with the added benefit of working on the current stable Rust. What you cannot do with `unfold` is to "yield" items more than once per function call, which thankfully isn't really a problem for this application. Shout out to maintainer(s) of [the _hubcaps_ crate](https://docs.rs/hubcaps) whose code I studied to get a better grip on how `unfold` works in the first place :)
I haven't had time to trawl through the source here, but I'm assuming that on Windows you're setting some console modes. All of the API looks like free-standing functions and structs, so my guess is that the current design does no cleanup of any of the console modesetting?
You usually want deps to be documented so that cross linking works. --no-deps docs aren't so great.
Yes, precisely. To grossly exaggerate, I feel like this blog post is saying: “The ecosystem would greatly improve if this big pile of work got down *somehow*.” (So far this is fact.) “If we just declare that there is now a team who’s responsible for that work, surely people will magically show up to be part of that team and do the work.” (Which is just not gonna happen.)
Well, thinking about this a bit more this won't quite work for subcommands. So ignore me.
Regarding Termion, a windows port is in the work: https://github.com/ErichDonGubler/termion [pancurses](https://github.com/ihalila/pancurses/) may also be interesting for a full ncurses experience.
[removed]
How are backtraces generated for panics, then? Shouldn't this just rely on precisely the same mechanism?
Even `cargo clean` hangs my system when it gets to `winapi`
&gt; Gutenberg I didn't discover that before. Gutenberg looks great.
This is awesome, i've wanted a crate like this for a long time. 
libbacktrace is a part of rustc &amp; the rust runtime, which isn't available to libraries.
But is your memory safe?
Right, which is why I suggested it be part of the language.
Idk is 16 GB good enough?
Did you go to rustup.rs and download the latest stable too?
And now you want to rewrite Rust in Rust. Yeah!
Please don't take this as me being unfriendly, but we try to keep this kind of posting in /r/rustjerk (our /r/circlejerk analogue) to keep this subreddit as productive as possible. That's part of what the "Submissions must be on-topic." rule means.
I'm interested to explore this idea more. So the problem we're trying to solve is that the author of a crate may eventually lose the bandwidth the continue developing or maintaining it. If that happens then what happens to the crate and the authors of crates that depend on it? Maybe there are benefits to an ownership team with a GitHub org of small, stable crates to maintain, by making it feasible to share resources amongst many crates that wouldn't be reasonable for a single small crate. Like regular triages, common set of issue labels, buildbot integration etc. Would an organisation like that with a few active members be able to maintain more crates than if those crates were under a few individual maintainers? On a related note I'm excited about the trend of setting up GitHub orgs and teams around larger projects like `crossbeam`, `lalrpop` and `rayon`. Would that work for smaller crates too?
Thanks!! and so did I. If you have sugestions for features please let me no.
for Windows I use winapi and for Unix I use ANSI escape codes. I AM abstracting away that portion so that the client can call the action it want to perform and unther water it wil do the operations bases on the current platform. 
Thanks for the suggestions did not noticed that there was a Windows branche on termion but I did see that the development on that crate is not much. And I don't see termion work for Windows because it's design is tangled into ANSI codes. Much work to be done to make it Windows supportable. And pancurses does not have the options to set cursor positions clearing the screen etc. that termion does have. So that was the problem what a lot of people are facing including me. So you have to add an crate dependentie to termion an pancurses and some other library's to just get your simple console application to work on both Unix and windows. 
There is no trait for `as`. You should `impl From&lt;myType&gt; for anotherType` and use `from()`/`into()`.
They are also in Pascal and Modula-2. I really enjoyed using them back then. And in C++ they are easily implemented, given the language flexibility. So I expect something similar can also be done in Rust, even as library type only.
Nice post! This makes some very good points about safety and I agree that Rust should emphasize embedded use cases.... Not just in 2018 but also beyond. As for the "emitting C" proposal, I'm not sure whether making rustc usable as a gcc frontend is a better idea. We definitely shouldn't stay dependent on LLVM in this regard. &gt; And for a mixed example, the C standard informs me that dereferencting nullptr is Undefined Behavior and must not occur I don't want to be nitpicky but it probably didn't use the term `nullptr` as that is a C++ concept. In fact using `nullptr` [gives a compiler error](https://godbolt.org/g/FZRfbD) for C code. In C, you use `NULL` instead.
&gt; Friday, restate my assumptions &gt; &gt; The writer writes for himself, not for you &gt; &gt; Saturday, restate my assumptions &gt; &gt; A song is not a song until it's listened to &gt; &gt; —The Divine Comedy in Note to Self An ode to writing code docs? The song also has this bit: &gt; Into the heart of darkness &gt; &gt; Beyond the point of no return &gt; &gt; What the fuck is happening? &gt; &gt; Where has everybody gone? &gt; &gt; What the hell is going on? &gt; &gt; There is nothing as frightening as being alone :-)
&gt; I think only with c, because nearly all developers I know think that cpp defeated itself without any help from other languages Given that all major C compilers are written in C++, and it is also the language driving many compiler backends, including Rust, C is the one defeated here. C is only relevant on embedded space, where many devs are still dreaming of being able to use C99 compliant compilers and UNIX related low level development, due to the symbioses UNIX/C. While C++ has gone down the stack in what concerns GUI frameworks and game engines development, it is still there and there are no relevant game engines or GUI frameworks in 2018, other than Gtk+, still being done in C. So the issue is how does Rust improve itself, to be able to take C++'s role in such architecture models.
That's amazing, had no idea it was in the works! Been waiting for something like that for so long
Well, I'm a believer in the idea of lightning rods, so having an approachable team to think about the problem and that can be easily joined might be worth the effort. _But_, it's a terrible lot of very specialised work and an eternal struggle to find people to do the work.
Don't you use IDEs? With VS that would be a simple F12 press at the call site.
For the `Error` type this is an apt analogy! Like exceptions, its intended for situations where errors are uncommon and not locally resolvable. But custom errors can be very cheap. Its all about finding the design that fits your usage patterns.
This would have to be an RFC that I don't have the time to write (but would be happy to provide feedback &amp; support on.)
&gt; I'm not sure whether making rustc usable as a gcc frontend is a better idea. That's something that should be done anyways, but it won't help you if you need to use icc, xlc, cray, ... or some architecture's modified fork of gcc 4.2... 
Thanks!
Yeah themes is definitely the issue for many people I think. There are actually a few more (https://github.com/Keats/gutenberg-themes) but I need to work on creating a themes page on the side based on the repo so it's always in sync. What's the theme you ended up choosing? I'm porting some various themes from other SSG to get the thing started but I'm the kind of person that would always write their own theme for each site so I don't really know what people are looking for there.
How was I supposed to know to look there in the first place? If I knew, it'd take me at most one minute even without the IDE. Funnily enough, I normally code in vim, but this one was Arduino IDE. The result of that bug was receiving of garbage data. One reason it took me so long was because at first, I suspected bug in processing of the data. I found the interface change by accident when looking at the header file if there's some way to invert HIGH/LOW in the signal (I suspected inversion could be the issue).
I would say that such criteria are the norm. Dynamic allocations are at least heavily discouraged against in e.g. MISRA C (which is also used at JPL).
I tried it out a bit, so far it looks good to me. Just a few remarks: * I think, with `safe_position` you meant `save_position`? * Calling the functions all `get` is in my opinion a bit inconvenient as you always have to include the module name if you want to use e.g. cursor and terminal.
**MISRA C** MISRA C is a set of software development guidelines for the C programming language developed by MISRA (Motor Industry Software Reliability Association). Its aims are to facilitate code safety, security, portability and reliability in the context of embedded systems, specifically those systems programmed in ISO C / C90 / C99. There is also a set of guidelines for MISRA C++ not covered by this article. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
&gt; Be sure to include the binary stripping step and use some of the less invasive options to shrink binary size in [this guide](https://lifthrasiir.github.io/rustlog/why-is-a-rust-executable-large.html). Some other steps you didn't come out for or against: 1. Consider using `opt-level = "z"` with a nightly compiler to optimize for binary size. 2. After stripping, use [sstrip](https://reposcope.com/man/en/1/sstrip) from [ELFKickers](http://www.muppetlabs.com/~breadbox/software/elfkickers.html) to trim down remaining ELF structures not needed for execution. 3. Pack it with [UPX](https://upx.github.io/). (It supports ELF binaries for mips, mipsel, arm, and armeb architectures among others and the overview on the website advertises very fast decompression and in-place decompression for "no memory overhead".)
Exactly, that's like using exceptions for control flow in languages with exceptions. One should not do that. 
even on stable channel? I know that some nightly were shipped without RLS component, but I'm on stable
Can I combine somehow two results? let name = env::var("NAME").unwrap(); let dir = env::var("DIR").unwrap(); println!("NAME: {}", name); println!("DIR: {}", dir); Is this the Rust way of doing things? If this were javascript without async/awayt I would have done this in the following way let namePromise = getPromiseForVar("NAME"); let dirPromise = getPromiseForVar("DIR"); Promise.all([namePromise, dirPromise]).then(function(values) { const name = values[0]; const dir = values[1]; console.log(name + " - " + dir); }, function(error){ console.log(error); }); Is there something similar in rust? Just unwrapping seems dirty.
Or use screen. Or tmux. Both work well.
Might design by contract work? There are a few design by contract frameworks in Rust. [This](https://github.com/nrc/libhoare) seems to be the most popular on crates.io, but there are a couple of others as well.
The only problem with emitting C code, of course, is to manage to circumnavigate around all aspects of undefined behavior. The fact that Rust embraces the C11 memory model should definitely help, however the different rules about `volatile` may be trickier to encode.
I actually found z or s to be very close to a tie. But maybe that's just my code. Thanks for the other recommendations, I'll have to check them out. 
I think it's a great idea. The more constraints you can put on your program, the less chance for error there is. Ada, which has a similar focus to Rust, has inbuilt support for range subtypes. You can define a variable to be an integer, natural (0,1,2...), or strictly positive (1,2,3...). Going even further, you can restrict a variable to be within limits. For example: subtype Speed is Integer range 0 .. 1000; The compiler will automatically add in the necessary checks to ensure that the value never goes outside range, and will raise an error if it does. Some of these checks are at compile time, and some are runtime. Obviously this comes with a performance penalty, and the idea is that after you test your program extensively, you can disable the runtime checks and maintain the same performance.
[`core::nonzero::NonZero`](https://doc.rust-lang.org/nightly/core/nonzero/struct.NonZero.html)? This will give you the benefit of things like the null-pointer optimization as well. I believe that there are efforts towards allowing specification of reduced-range numbers.
This definitely goes in the right direction. Many thanks for the links. 👍
Are these simple heuristics that can catch such misuses in the most common cases? We could make a Clippy lint. I don't immediately see such heuristics but you know better than I :)
If you want terminal and cursor you would have to do use cross_terminal::terminal; use cross_terminal::terminal::ClearType; use cross_terminal::cursor; fn main() { let term = terminal::get(); let cur = cursor::get(); terminal.clear(ClearType::All); } and you cant just use `cross_terminal::terminal::*` for having `ClearType`, but I don't know whether using the `*` is good practice in the first place as I'm also relatively new to Rust.
Is there a major difference in time taken between stable and nightly? We recently landed a rustdoc feature that has the potential to slow stuff down (but didn't in my measurements). I do plan to land some things making the happy path faster but I haven't gotten to that yet.
Great post. This push toward webassmebly has always struck me as odd because it's moving Rust to something it was specifically not aimed to do. Rust right now cannot even exist in the backend networking world. All we have is gcc, and it's ancient version of gcc on CentOS. Good luck convincing someone to put a new compiler on such a system.
I must have missed something in my computer engineering education as this lambda language used in this proof is entirely foreign to me.
&gt; d you cant just use cross_terminal::terminal::* for having ClearType, but I don't know whether using the Oke, I'll get the point. As far as I know `*` should not be preferred but I think it is important too leave that option open for the user of the library. I will take a look at it to find an better way for accomplishing the current situation with other naming conventions. Really thanks for yout time and feedback! 
`catch_expr` is on the path to stabilization though there's a couple of open design questions on it, I think namely whether it should be `catch` or `do catch`, and whether the value in the return position of the block (the last expression) should automatically be wrapped in `Ok()` or if it should require that to be written out (the optimistic solution is to see if it can support both). * Tracking issue: https://github.com/rust-lang/rust/issues/31436 * Auto-wrapping discussion: https://github.com/rust-lang/rust/issues/41414
I don't think you answered the question; to clarify for /u/ErichDonGubler, Termion has a RawTerminal struct that you hold to keep the terminal in raw mode, and will reactivate cooking when the process ends. Do you have anything like this?
Thank you for the extra info :)
&gt; GCC frontend You know what's probably even less actionable than a C transpiler? A frontend to GCC 4, which is where I live;) Plus, ICC is still kicking around. I wouldn't minda GCC front-end; it just won't solve my specific issue afaik &gt; nit DAMMIT you right I am using `NULL` in my code, since it, y'know, compiles; being around C++ means that I mix vocabulary in English though ugh. I'll edit, thanks.
Modified fork of 4.2 is me, yes
*Typestate flashbacks*
The crate I'm making is very simple, I think that having a bunch of crates listed on the side would just make it look more confusing than it is. But yes, for bigger crates that might require the programmer to dive into its inner workings to make some custom types or something, having the dependencies documented might be best. Which makes me wonder how they deal with this slowdown. Maybe only document with ```--no-deps``` until it's time to publish?
Not really. Typestate was about adding predicates to existing types depending on control-flow; here the type *always* satisfies the predicate.
During development it's also really convenient to just "cargo doc —open" and take a gander at your dependencies's specifics when you're solving issues.
This is an excellent Tutorial session for newer rust programmers and some of the whys are wherefores of rust idioms and syntax. It has a couple of exercises as well that are well thought out with questions by the attendees answered live.
&gt; completely forgo any type of dynamic memory allocation IDEALLY, yes; in practice, … I haven't seen it yet, but I am still very young. The two projects on which I've worked are large enough that they run operating systems (VxWorks) which provide a dynamic allocator to userspace and use one within the kernel as well, and work with peripherals that may generate unsized data or generate fixed-size messages at variable rates. We do as much as we can to constrain the system to a finite state machine, but sometimes that just isn't feasible. FWIW, unsized messages can still work on a static memory system, as long as they're guaranteed to be smaller than some ceiling and processed in a deterministic time, which is how my ring buffer implementation works. You can see a sanitized port of my BioSentinel structures [here](https://github.com/myrrlyn/wyzyrdry-c), as well as the very clear Rust influences on them. I'm interested to see the development of TockOS and if it will ever become a feasible contestant in our niche. ---- Something that took me by surprise is that even the small, constrained, CubeSats on which I work are flying full, real, *computers*, not just microprocessors. The peripherals are run on microcontrollers which are absolutely candidates for finite-state-machine programming, static-only memory, and everything you enumerate, but the primary nodes of the network aren't. BioSentinel uses a distributed network model for its avionics bus, with the primary node being a Cobham-Gaisler LEON3 UT700 CPU which is fairly modern in terms of features and onboard controllers; it has a built-in MMU, four SpaceWire networking devices, SPI controllers, and even Ethernet. Our secondary node is an FPGA running finite-state-machine programs which serves as a network mux, system clock, and independent memory supervisor. It lives on a physically separate board, connected to the CPU's board by a SpaceWire network bridge. Beyond these, we have the power supply, attitude controller, sun/star sensors, the biological payload, and other instruments I'm eliding all connected to the FPGA. Those leaf instruments are the components that MISRA targets for strict FSM behavior and that are going to be driven by very, very constrained microcontrollers (radiation hardening takes up a huge chunk of complexity budget). If their vendors ever look at Rust for these devices, it will be assuredly in `#![no_std]` and possibly in `#![no_core]` mode, and for me right now this is well outside my realm of consideration. So TLDR the primary computers on the satellites we build are large enough and complex enough that we do use a dynamic memory scheme. VxWorks offers an allocator and a dynamic scheduler for task-based parallelism, which TockOS demonstrates CAN be done statically but it's easier not to, and we also fly RTLinux if the customer asks for it. As I understand it, the allocators and schedulers we use are much coarser than what is generally found on the ground, and we definitely use anti-fragmentation strategies proactively and are much more willing to handle OOM with as much possible grace than I've seen in ground software.
I found the part about safety even better than the part about Rust. 😊 and that's not to say I disliked that one either. I agree that we should not rest on our laurels and improve safety of Rust code through better rules, practices, docs, tests, fuzzers, lints and sanitizers. By the way, [clippy](https://github.com/rust-lang-nursery/rust-clippy) has a good number of lints that relate directly to MISRA C rules, and we strive to add more (and better) checks as we go. What's your take on clippy, quickcheck, cargo-fuzz, afl-rust and the additional lints in rustc?
My general sense of #Rust2018 posts is that the language has reached a critical mass toward true competition with C and C++. People want the 2017 advancements completed, but also want to see rust push into C's space in a strong way: const generics, SIMD, assembly, better numerics story, etc. These are all important to low-level code. Things like WASM and the emphasis on the web seem to have gotten down-played. While critically important as well, the incremental development on many more fronts is desirable. Better community organization for tackling specific challenges has also been presented. Mechanisms that aid in community development are probably going to become that much more important moving forward.
[I'm doing a thing.](https://i.imgur.com/a2ZCGZC.png)
&gt; e.g. it is easy to inspect `loop { }` and determine that it does not halt. Well except for the LLVM bug in which `loop { }` is considered undefined. https://github.com/rust-lang/rust/issues/18785
I am so sorry for you.
After every action that has been called on the terminal the terminal will be reseted and all it styles and attributes will be cleared. So that if You call the paint method to color the font the font will be colored but after that it will be set back to default color. ``` // Print some colored font print!("{}", paint("Collored text").with(Color::Red).on(Color::Blue)); // This font has the default color print!("Normal default color"); ``` You can store the syles into an variable so you can reuse the style. ``` let mut styledobject = paint("Stored styled font").with(Color::Red).on(Color::Blue); print!("Font with colors {}", styledobject); print!("Font with default colors"); print!("Font with colors {}", styledobject); ``` My library does not put the terminal into an raw state as termion does, and can not be restored at the end when the process ends to its original state YET, however it resets to default settings after an action like coloring or styling the font as shown above. Is this what you mean? 
Rust's plethora of built-in and extension lints, checks, etc., is wildly thrilling. I didn't enumerate them because I've never used the fuzzers and tbh I kind of forgot clippy existed, since adding it to project root is unconscious muscle memory at this point. My clippy config just promotes everything by an error level: deny warnings, warn on allowances and I don't consider a build clean until it's been quieted with a fix or an explicit `#[allow(lint)]` and an explanation. I haven't used quickcheck *yet*; my current project is approaching the point where I'll need to do so and I'll have more useful thoughts on it than "seems neat I guess" then.
At our university, it was an optional course, named "Fundamentals of Programming Languages", dealing with stuff like Simply Typed Lambda Calculus, Kinding, Universal and Existential Types, AST transformations, etc. Not many CS engineers take the course since it's "too mathematical", but it's really interesting and useful if you decide to design your own language or compiler.
[Let's get weird](https://twitter.com/myrrlyn/status/922615769703227392)
Today (01/28) is the only correct date to publish 2018 posts imo, which is one reason I held off All the other reasons are "filthy procrastination"
Did anyone say [rust performance pitfalls](https://llogiq.github.io/2017/06/01/perf-pitfalls.html)?
Crates on the side is standard rustdoc, so it won't be confusing. no-deps till you publish makes sense.
Well, the library works great. I already started using it in one of my hobby projects. Is there a way to get the current size of the terminal? I saw there was a way to set coordinates of the cursor.
To be honest, I hoped there would be some progress since I last checked what was out there in the Rustland. I myself is rather inexperienced in embedded development. While I can make Teensy do stuff in Teensyduino I feel a distinct lack of knowledge when it comes to lower levels of development (registers, memory layouts, that sort of things). So I hoped maybe there's a thing that can replace Teensyduino but written in Rust. `teensy3-rs` feels a bit neglected. Last commit was almost 9 months ago. It depends on bindgen 0.23 (about 10 versions behind). I tried building it locally and am getting the following error: error: failed to run custom build command for `teensy3-sys v0.2.0 ([...]/teensy3-rs/teensy3-sys)` process didn't exit successfully: ``[...]/teensy3-rs/target/debug/build/teensy3-sys-ba23f4b48330abc5/build-script-build` (exit code: 101) --- stdout cargo:rustc-link-search=native=[...]/teensy3-rs/target/debug/build/teensy3-sys-ceb2415f276019c8/out cargo:rustc-link-lib=static=teensyduino --- stderr thread 'main' panicked at '#include &lt;...&gt; search starts here:', libcore/option.rs:917:5 Compiling `teensy3-rs-demo` was no more fulfilling. error: linking with `arm-none-eabi-gcc` failed: exit code: 1 | = note: "arm-none-eabi-gcc" "-L" "[~].xargo/lib/rustlib/thumbv7em-none-eabi/lib" "[...]/teensy3-rs-demo/target/thumbv7em-none-eabi/release/deps/teensy3_rs_demo-596a541cb7aee7f3.teensy3_rs_demo0-b1445b3372f28abe90e7247339408ee3.rs.rcgu.o" "[...]/teensy3-rs-demo/target/thumbv7em-none-eabi/release/deps/teensy3_rs_demo-596a541cb7aee7f3.teensy3_rs_demo1-b1445b3372f28abe90e7247339408ee3.rs.rcgu.o" "[...]/teensy3-rs-demo/target/thumbv7em-none-eabi/release/deps/teensy3_rs_demo-596a541cb7aee7f3.teensy3_rs_demo2-b1445b3372f28abe90e7247339408ee3.rs.rcgu.o" "[...]/teensy3-rs-demo/target/thumbv7em-none-eabi/release/deps/teensy3_rs_demo-596a541cb7aee7f3.teensy3_rs_demo3-b1445b3372f28abe90e7247339408ee3.rs.rcgu.o" "-o" "[...]/teensy3-rs-demo/target/thumbv7em-none-eabi/release/deps/teensy3_rs_demo-596a541cb7aee7f3" "-Wl,--gc-sections" "-nodefaultlibs" "-L" "[...]/teensy3-rs-demo/target/thumbv7em-none-eabi/release/deps" "-L" "[...]/teensy3-rs-demo/target/release/deps" "-L" "[...]/teensy3-rs-demo/target/thumbv7em-none-eabi/release/build/teensy3-sys-57be77ad947fb422/out" "-L" "[~].cargo/registry/src/github.com-1ecc6299db9ec823/teensy3-sys-0.1.0/teensy3-core" "-L" "[~].xargo/lib/rustlib/thumbv7em-none-eabi/lib" "-Wl,-Bstatic" "[...]/teensy3-rs-demo/target/thumbv7em-none-eabi/release/deps/libteensy3-06c940060ec3b4a8.rlib" "[...]/teensy3-rs-demo/target/thumbv7em-none-eabi/release/deps/libteensy3_sys-94a88f6480e1b243.rlib" "[~].xargo/lib/rustlib/thumbv7em-none-eabi/lib/libcore-f552cc688e49637b.rlib" "-mcpu=cortex-m4" "-mthumb" "-Tmk20dx256.ld" "-Os" "-Wl,--gc-sections,--defsym=__rtc_localtime=0" "--specs=nano.specs" "-lm" "-Wl,--start-group" "-lnosys" "-lc" "-lgcc" "-Wl,--end-group" "-Wl,-Bdynamic" = note: [~].xargo/lib/rustlib/thumbv7em-none-eabi/lib/libcore-f552cc688e49637b.rlib(core-f552cc688e49637b.core15-3a311d37549c31b5180a28dca3e3896f.rs.rcgu.o): In function `core::panicking::panic_fmt': core15-3a311d37549c31b5180a28dca3e3896f.rs:(.text.cold._ZN4core9panicking9panic_fmt17h863d85a67433966bE+0x24): undefined reference to `rust_begin_unwind' collect2: error: ld returned 1 exit status A this point my lacking knowledge of Rust is becoming a roadblock. I have a somewhat similar issue with `cortex-m-quickstart`. In step 5 it suggests me to add a support crate for my chip but there's no such thing for K20. I guess, I'm expected to create one myself but unfortunately it's beyond my ability at the moment.
Funny, I posted a blog touching on this and had a lively discussion about this yesterday: https://www.reddit.com/r/rust/comments/7t6th5/rust_2018_improving_safety_and_ergonomics_for/ One thought I've had after digesting some of the comments is that Enums are pretty close to being able to handle this, and it’s possible to use macros in some cases - see my crate [bobbin-bits](https://github.com/bobbin-rs/bobbin-bits). The biggest issue with using enums is that it’s impractical to enumerate all of the individual items for large ranges (for instance if you wanted to cover [0..2^12]), even with macros. Allowing RangeExpressions as the body of an Enum would allow you to write enum Hours { 0..24 } enum Minutes { 0..60 } enum Seconds { 0..60 } Then, with some minor grammar tweaks you could write let h: Hours = Hours::12; let m: Minutes = Minutes::30; let s: Seconds = Seconds::0; It would be nice if all the math operators could be auto-derived with sane semantics (i.e. Hours::23 + 1 panics on debug but wraps on release, Hours::23.wrapping_add(1) returns Hours::0). I’m not the only person to think of this: it’s previously been [proposed](https://github.com/rust-lang/rfcs/issues/1493) in a slightly different form without much discussion. Maybe it’s time to start working through the details.
I work on satellite software and the previous team I worked with did not permit dynamic memory allocation. They recently amended their coding standards to permit memory allocation in rare circumstances, but never delete.
I'm writing a text parser that will eventually become a code generator and binary-packet processor, so both of those will become necessary when I get there. I don't know how I'd fuzz a contextual language; right now I'm just using a known base of good and bad text that must succeed and fail according to manual expectation :/
[~~Un~~resolved questions](https://twitter.com/QEDunham/status/946509336737648640)
I ended up choosing a theme called Kiera. You can see what it looks like in use at my blog, [Tinkering](https://tinkering.xyz). When I think of a static site the first thing I think of is a blog, though I know people use them for all kinds of things. To that end I was looking for a relatively minimal theme with a focus on legibility and use of screen real estate. I see a lot of themes with huge (mostly empty) sidebars or gigantic margins and type that is too small, which hurts legibility. Kiera was closer to what I was shooting for. I do want to learn how to make a theme from scratch, but then again there’s a lot of things I want to learn :)
Does [#1930-#1933](https://github.com/rust-lang/rfcs/issues/1930) address what you're discussing here?
Thanks! Updated!
In fairness, I didn't find that because I'm a Rustorian; I found it because I'm in that thread and just had to scroll down my Twitter profile a bit
\&gt; [discovered](https://twitter.com/myrrlyn/status/946560348106174465)
&gt; No unsized types Unsized types don't require memory allocation, for example imagine a `fn transmit(&amp;[u8]) { ... }`, sometimes I might pass it a (statically allocated) `&amp;[u8; 256]` and sometimes I might pass it a `&amp;[u8; 512]. Monomorphizing it might lead to unnecessary code bloat.
Thanks, the method to get the current size is called terminal_size in the crossterm_terminal module. https://docs.rs/crossterm/0.2.0/crossterm/crossterm_terminal/struct.Terminal.html#method.terminal_size If I may ask wits platform are you using?
I'm using Solus (Linux) and windows. It a simple cache cleaning utility, that I wanted easy cross-platform color support in the terminal. For fun, I'm going to try and implement the fallout terminal and I'll be giving it a go to use your library because it has great cross-platform support. 
/u/DroidLogician covered the main cases, but there's also a less-pretty-but-usable-on-stable solution using combinators: match env::var("NAME").and_then(|name| env::var("DIR").map(|dir| (name, dir))) { Ok((name, dir)) =&gt; { println!("NAME: {}", name); println!("DIR: {}", dir); } Err(e) =&gt; eprintln!("error: {}", e), } I don't think we have something as nice as `Promise.all(x, y)`, but `x.and_then(|x| y.map(|y| (x, y)))` will technically achieve the same result.
Thank you myrrlyn for voting on WikiTextBot. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
I struggle to conceive of a use case for PLCs in flight anywhere but as a controller of a specific instrument on the edge of the control net.
Some fuzzers check what parts of code are being stressed and jump things up to try and hit the most code as possible. I saw a blog about afl where after running it for ages and ages on image processing it started to figure out how to generate valid JPEGs. Or you can build up a text corpus of common words/terms and use the fuzz input to choose whether a common word/character is chosen or a random one. Using a constrained random like that can be useful and isn't too dissimilar to how tools like Polyspace or UVM work to test code is good
Use [`Weak`](https://doc.rust-lang.org/std/rc/struct.Weak.html) to be able to look at a value you don't own and mustn't drop.
[Relevant](https://www.reddit.com/r/rustjerk/comments/7cpvhn/summoning_the_rust/)
Please, dear mods, give this exemplary person a "Rustorian" flair!
Out of curiosity what language is it? 
[removed]
&gt; Younger developers love the idea of being hardcore bare-metal hackers, and have never experienced the dismal horror of working on large old code bases, and so are attracted to C and C++. This is especially true of the Hackerrank community. I am currently in college (graduating soon with a degree in computer engineering) and while this might be part of it, I don't think this is the main reason. I think the main reason is because younger developers care core about the languages that get them jobs. In addition, many of the people who go through college programs, while able to program, don't really care about programming and so don't do much with it outside of class and work. This means a lot of younger programmers don't find rust because it hasn't been handed to them and they haven't been told to use it. Couple this with the fact that (as far as I see) most younger programmers have a fear of low level programming (e.g. anything where you have to use C, in their eyes at least) and are perfectly content to make apps in C#, Java, and Python, the younger developers just don't care about Rust as a whole. The only reason I care about Rust is because I am one of those crazy people who program in their free time, love low level programming, and have had to work on the types of ancient C code bases that make you want to gut yourself rather than wade through the undocumented mass of code laid before you.
Just to say - I recently used Gutenberg to help set up my new website and I loved it. I was already using markdown for post and project texts, so I just had to get the frontmatter set up for each and I was good to go. I had no intention of using a predefined template, and I like how Gutenberg kept out of the way and just gave me everything I needed to make my site work however I like. I haven't tried any other static site generators, so I can't provide any actual comparisons, but Gutenberg was a pleasure to use :)
Yup, it was a really good watch and mentioned points which are usually not mentioned anywhere else. A lot of material oriented towards rust beginners does not talk about the patterns and idioms encouraged by the community.
It's pretty "Pythonic" to do so in general which is one of the reasons I dislike "Pythonic" as a philosophy. But Rust absolutely lets you use Result for control flow situations and unlike exceptions there's no major problem with this. I mean the very existence of `Result::is_ok` hints at control flow.
AFAIK stable does not have RLS at all, but beta and nightly do have RLS.
Can I amend this RFC for you people to learn some Latin before slapping Latin on a bunch of stuff? There are many issues here. "Tutum" is nominative neuter singular, but "celer" is nominative masculine singular. Interestingly, the Latin word for "rust" is "robigo", which is feminine. "Simul" is an adverb, so it doesn't belong anywhere near this discussion. "Concurrentium" is... I don't even know. But what you really want is the participle form of "concurre" which is "concurrens".
Blasphemy! (Also thanks! While I had latin in school, am far too lazy to actually look anything up and I forgot basically everything.)
While all this is blowing over let me declare that THERE IS NO HASKELL CABAL. Package names implying the contrary are false flags.
What an odd coincidence that I just saw [this](http://www.sketchplanations.com/post/170228270351/the-streisand-effect-a-term-coined-by-mike)
The Lambda Calculus is regarded as the simplest Turing complete language available. Used a lot in CS for examples in PL theory stuff.
Do you really want people to view our ancient forebears to be ignorant because of some improper Latin? (I studied far too much classical languages in school. Might as well use it for something... even if it is just correcting the heraldry created by programmers.)
&gt; improper Latin BLASPHEMY! :P
Latin for rust is "puccinia", derived from the name of the guy who described the critters first, Tommaso Puccini.
Huh. I always thought it was named after iron oxide, not the order of fungus. Either way, it's feminine.
I came here to say this. Non Scholæ sed Vītæ Discimus!
&gt; `teensy3-rs` feels a bit neglected It totally is. James Munns and I mostly worked on it when we met at RustFest Berlin. But my own Teensy project was already "in production" and it’s running without issue, I haven’t felt the need to touch that code since. I suspect that for James as well it was a side project, and he’s been working on other things since. I understand it’s not what you hoped, but as far as I know this half-broken prototype is the “state of the art” today. The Teensy community is small, the embedded Rust community is small, and their intersection is a few people who played with things for a couple weekends. Welcome the the world of very early adopters :) ---- To take more advantage of existing code, I’d recommend buying some other hardware that’s better supported by japaric’s crates, and read http://blog.japaric.io/ . The "blue pill" has a size similar to Teensy: http://wiki.stm32duino.com/index.php?title=Blue_Pill
If that’s the case then that’s great, Rustup needs this so badly. 
I have opened an issue with brson: https://github.com/brson/temple-of-rust/issues/4 I have suggested it be updated to: "Certa. Celeris. Concurrens." Anyone want to double check my Latin?
This is awesome. I'm going to amend the RFC.
[This](http://cosmosrb.com/docs/telemetry/)
By no mean I was criticising your or James’ choice of time investment. I was merely pointing out that at the moment I’m encountering issues with the code and unfortunately is incompetent to overcome them yet. As for chip choice, unfortunately the choice is not mine. The project I have in mind is a firmware for a keyboard. It’s a readymade design. The keyboard is based on K20 chip which happens to be the same as one in Teensy 3.2. As far as I can tell the chip (and Teensy) is quite popular in the mechanical keyboard community.