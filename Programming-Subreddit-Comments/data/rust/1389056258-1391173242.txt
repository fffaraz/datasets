@bjzaba I am hoping you might be able to provide me with some insight to as why CodeRunner would return with "Untitled: No such file or directory". https://gist.github.com/bjz/8253053#comment-981545 Thanks in advance.
I could've been clearer, sorry. I was working on a friendly JSON API for finding potentially deeply nested values. I looked to TreeMap for method naming inspiration and settled on 'find()' and 'find_path()'. Since each find_path() call could result in a number of possible errors or an actual value, I returned a Result.
Yes, if you compile from source on-demand then you can enforce safety guarantees at load time. Obviously this has many drawbacks: * librustc and llvm have to be loaded by the application. Alternatively you have to shell out to rustc. Either way, this requires the compiler to be present at runtime. * The compiler is a bit sluggish. This would make dynamic crate loading potentially unacceptable in desktop applications where responsiveness matters. * The source must be available, but this may not be feasible for business or licensing reasons.
I came across this while preparing the [first issue of LLVM Weekly](http://llvmweekly.org/issue/1 ) and thought it might provoke some interesting discussion. Additionally, the author is actually looking for contributions or reviews from projects targetting LLVM IR such as Rust.
That's where I saw it, nice to have more weekly updates :D. And I did mention on `#rust-internals` that it should be useful for [my endeavors in trans land](https://github.com/mozilla/rust/pull/11252) (for example, I didn't realize function arguments could be named).
I don't know what the exact plan is for the standard library (iirc some kind of versioning), but 1.0 is only intended to freeze the language.
I wouldn't so much say freeze the language as make it so there can't be any breaking changes to the language. Which that helps with documenting the language itself. I remember reading (mailing list probably) that even libraries won't really have breaking changes. They'll create new ones to replace the old ones and then deprecate the old ones for a few versions before being removed. That also helps with documentation in my opinion.
agreed, I had no idea it was only programming until now
We're probably referring to the same thing. :) And yeah, that's what I meant to say, just not what I said.
Hello, friend. I believe you're looking for /r/playrust
Commented!
&gt; brson: We've talked about combining SharedChan and Chan. Wary of having a wide range of channel types. That would be super cool.
Failure should be rare and explicit. The `foo_opt()` -&gt; `foo()` change doesn't make the failures any more common than they already were, and makes them more explicit, so it's a good idea. If the result is that "this is awful, we have `unwrap()` everywhere", that means that what we currently have is *even more awful*, because all of the same failures are being swept under the carpet. People frequently mention Haskell's `do` notation as something that might help, but while nice, I don't find myself using it with `Maybe` very often. Much more common are `fmap` (which we have as `.map`) and the various `Applicative` utitilies like `liftA2` (which is like a multi-fmap that takes a two-argument function and two `Maybe`s) and `&lt;*&gt;` (which applies a function in a `Maybe` to a value in a `Maybe`, likely to be much less practical in Rust due to our lack of currying and partial application).
&gt; static trait method syntax A shame they didn't get to that in the meeting - hopefully the next one. It's important to settle that for 1.0. Edit: I spite of that, I was impressed with how much they got through this meeting.
Agreed about sweeping things under the carpet. Would be awesome if `lift` and `&lt;*&gt;` could somehow be generically implemented for N number of args
What's this about?
We ran out of time.
Guard pages are a **MUST**. You will corrupt memory on stack overflow otherwise, which is unacceptable. more_stack prologues are useless, you'll get a page fault anyway (assuming you use guard pages, which again, you MUST). At any rate I fail to see why Rust can't, in the native case, just use pthread_create, CreateThread and do code generation just like C, which handles this stuff automatically. 
I think this probably needs some kind of variadic generics (like C++) for it to work nicely. Macros could likely do it too if they had some kind of recursively-defined machinery to desugar to, but I'm not sure they do, or can. I haven't thought about it very hard though, so I hope someone proves me wrong. W.r.t the aforementioned variadics, I'm a bit wary about adding type system features which the languages with the more principled type systems (i.e. the various members of the Haskell and ML tribes) don't have. On the one hand, it's not clear how it's going to interact with all of the things they and us both do have. On the other hand, there might be a reason why they have avoided adding it. That might be just the fact that their functions are unary, and not our N-ary (which we can't do much about)... or it might not. On the third hand, it means we don't have a good place to copy from (I don't feel like C++ is a good place).
Next week? I'd be happy to get something done this week (self.reminder: need to summon nmatsakis).
you won't get a page fault, morestack doesn't touch the stack. I plan on migrating us to a windows-like stack safety scheme.
You meant to post to /r/playrust
&gt; pcwalton: We're never going to be that fast at task spawning. I feel as though I keep seeing more and more indications that spawning a task is going to be a costly prospect. That's disappointing to me as I loved the notion that I could freely spawn tasks all over the place to handle the most trivial workloads. When I learned that 1:1 was going to become the default, strcat was kind enough to assuage my fears that each task was going to take a full 8MiB. I'm still a little worried about the cost of spinning off a thread for each new task. Can someone knowledgeable paint a picture of how I'll be able to use tasks in the post-1.0 world? Am I going to have to carefully manage taskpools to mitigate the cost of spinning up?
You get a page fault when you access the guard page via the stack pointer due to local variable access. If the stack frame is larger than a page, this is not guaranteed (the guard page may be "skipped over"), and that's why all decent compilers insert prologue code that manually touches all pages in order to trigger a page fault if there's not enough stack. A manual stack pointer comparison is never required (unless one is using segmented stacks). This is how C programs work without corrupting memory. Of course, recovering from this (which, however, C generally doesn't do) requires generating unwind info with enough granularity to support unwinding on any memory access instruction and within the prologue for large functions. 
Our `__morestack` knows how much space the current stack frame requires, and how much stack is remaining, and aborts if the former is larger than the latter. No accessing of anything on the stack, and so no page faults. (NB. I'm just pointing out what the current implementation does, I'm definitely not saying we should keep morestack.)
 trait Foo { fn construct() -&gt; Self; } impl Foo for MyType { fn construct() -&gt; MyType { ... } } fn main() { // currently must by called as let x: MyType = Foo::construct(); // people want let x = MyType::construct(); }
its a great server 
This subreddit is for the Rust programming language. You're looking for /r/playrust
Oh my bad! thanks man! 
Related issue: https://github.com/mozilla/rust/issues/11351 So the current idea is to have a single `Chan`, which would be (internally) transmuted to `SharedChan` upon the first `clone` call. It will involve the conversion between different kinds of concurrent queues as far as I know.
It's not clear. Certainly right now tasks are not cheap - they contain a very large number of allocations. If we can get those allocations down to 1 or a few and start caching things cleverly then tasks could be cheap (er than a native thread). There are some tricky perf hazards around guard pages and madvising unused stack pages that may require tough tradeoffs. Right now it's not a priority to improve spawning performance, but there are probably a lot of low hanging fruit if somebody wants to tackle it. Native tasks will be as expensive or more expensive than native threads.
The current notion is that the shared state between the sender and receiver (called the 'packet' in our impl) contains room for one message, so the common single-send use case is very fast. On the second send it gets upgraded to a single-producer/single-consumer queue. On a Chan clone it gets upgraded to a multi-producer/single-consumer queue. This seems doable, though the implementation no doubt will be pretty sprawling.
Doesn't Windows XP support EoL this April? If Microsoft doesn't support it, why should you?
&gt; I guess LLVM has something similar. Nope, it doesn't have something similar. It only supports that kind of stack safety on Windows via a `chkstk` function.
Rust uses foreign functions calls extensively, so `__morestack` can't provide safety unless you're opting out of the standard library and building your own library from the bottom up without C.
Because it still has lots of users.
Ah, thank you. What *I* want is `let x = construct()`. :)
I don't know anyone who runs XP. Where are these users? Any serious developer would be on Vista or later (and probably Windows 7 or later at this point). Businesses will not be using XP. It's a 13-year-old OS at this point. Supporting XP will just bloat your code base and increase maintenance. I highly recommend *against* supporting it.
Note the *huge* list of problems with the current implementation. (I'm working on thinning that down as we speak. *e:* performance improved 70%!)
I agree with you that Rust should not lose any sleep over not supporting XP. However, the line "Businesses will not be using XP" can be trivially refuted: guess where I am right now, and guess what OS I am typing this on. Furthermore, guess whose company policy is that hardware is refreshed in five-year cycles, and guess for whom that refresh is still three years away. I'll be using XP well into 2016, at which point I'll have Windows 7 to look forward to. I work for a lumbering corporate enterprise! And you would surely be horrified to realize just how many of us there are out there.
While I sympathize with your plight, your argument can be trivially refuted, too. The sort of company that still uses XP despite the fact that it's going to end of life in 3 months is not the sort of company that's ever going to use Rust in production, so it's a moot point.
So what happened to the GC work Graydon was doing back when?
It's still around; https://github.com/graydon/rust/tree/gc I'm not sure of niko or felix were planning on reviving it (they've been putting a lot of the thought into a "proper" GC afaik). The motivation behind this, I think, is to just get *any* GC working at all and dropping @T.
(There are multiple branches starting with `gc` in Graydon's repo, e.g. [gc-prefix](https://github.com/graydon/rust/tree/gc-prefix) has more recent commits.) That is my motivation: IIRC the major problem with trying to land Graydon's GC was memory usage during the compiler bootstrap: it would balloon so large that was impossible to compile on 32-bit platforms. With `@` and `gc::Gc` being separate this is no longer a concern. My goal was to experiment with a true GC in the standard library (and, it would be an added bonus to land something as a baseline that we can improve on). (This GC would definitely perform far far worse than graydon's if it were to be used to bootstrap.)
XP is still huge in Asia. It's global marketshare is around 19-29% depending on the source, but in Asia it's more like 40%, and China is 51% (!). To address your point below, the point isn't companies wanting to develop in Rust, it's using Rust as an implementation language of whatever programs they might use. It's unclear if XP is still going to be relevant. I think we should drop it, but it really seems like the only major thing that's different for us is cvars and maybe MSVC's stack safety scheme. If it's really that minor, I don't see the bloat/maintenance concern as valid. It's also not like we can't ever go back on this decision. If in 6 months XP still isn't dying at a good clip, we can add support for it, even if it's just a slow emulation layer.
See the subreddit description. You want www.reddit.com/r/playrust
The OP is looking for /r/playrust. It's an unfortunate coincidence.
I downloaded 0.9 for Windows yesterday. http://static.rust-lang.org/dist/rust-0.9-install.exe
The git still doesn't have a 0.9 tag either. Just 0.8, 0.7 and earlier: # zsh auto complete for `git checkout ` completing commit tag 0.7 release-0.1 release-0.3 release-0.4 release-0.6 0.8 release-0.2 release-0.3.1 release-0.5 release-0.7 
Does this work? fn eval(self) -&gt; Up { let f = self.f; let v = self.v; f(v) }
Also, is there a changelog anywhere? I just love seeing this language evolve! 
It shouldn't, but: `let Think {f, v} = self; f(v)` should. (Possibly `f: f, v: v` if that sugar hasn't been implemented for struct patterns yet)
Struct patterns are extremely sugary. We have `{f, v}` and `{ref v, mut v}` etc etc.
I totally forgot about `struct` pattern matching when I replied, that's what I wanted to use (matching) initially.
Not. The same problem.
thanks! Btw, it's nice seeing Rust generating Apple-like levels of fanboyism with people like me queuing up days before the actual release :)
Thanks! This does work!
Also: https://github.com/mozilla/rust/wiki/Doc-detailed-release-notes
Yup, planning on it! And of course it's me :D
Excellent. Is James coming too? I've been meaning to ping you two now that I'm in the bay area, haven't had the chance yet.
Haven't mentioned it to him, tbh, I should though. I told Eric he should check it out with me, but he hasn't responded yet. So we may be rollin' 3+ deep!
Hi, I am said engineer. Contributions are very much welcome. As soon as possible I want to get a prototype deployment up and available, starting with the Rust code base and then Servo. At that stage, feedback would be really helpful and I'll post again. If you'd like to help out or are just interested, ping me (nrc) in #static or #rust. If you'd like to follow along on progress, work is tracked at https://bugzilla.mozilla.org/show_bug.cgi?id=956768.
Except it's fully open source, so you don't need to wait :)
Yay!
A selection of some of my favorite aspects of this release: 1. The (yet-ongoing) removal of managed pointers, leaving us with one fewer pointer type. Final tally of built-in pointer types: unique pointers, mutable references, and immutable references. 2. The dead code detection pass (https://github.com/mozilla/rust/pull/10477), contributed by a student of the University of Virginia's Rust-based systems programming class (http://rust-class.org/pages/using-rust-for-an-undergraduate-os-course.html). 3. The `Any` trait, giving us on-demand dynamic typing (https://github.com/mozilla/rust/pull/9967). 4. The clean abstraction of green threads and native threads out into their own libraries (https://mail.mozilla.org/pipermail/rust-dev/2013-December/007565.html) such that any library that makes use of the stdlib will work regardless of which strategy the user selects. We're not quite in the home stretch yet, but there are very few hard blockers left on 1.0. Here's the list that I can think of: 1. Dynamically-sized types (http://smallcultfollowing.com/babysteps/blog/2014/01/05/dst-take-5/) 2. The extension of rvalue lifetimes (http://smallcultfollowing.com/babysteps/blog/2014/01/09/rvalue-lifetimes-in-rust/) 3. Struct single (note that's *single*) inheritance (http://smallcultfollowing.com/babysteps/blog/2013/10/24/single-inheritance/) (EDIT: pcwalton informs me that this may not be on the docket for 1.0) 4. Niceties and sugar to support custom smart pointer types to complete the excision of managed pointers As far as I know, the devs are still aiming for a 1.0 release in 2014. The 1.0 release will *not* necessarily mean that the language is done evolving or ready for production use, but it *will* mean that the developers will begin honoring language-level and library-level backwards compatibility. I predict *at least* two more unstable point releases (i.e. 0.10 and 0.11) before a 1.0 release occurs. (and yeah I copypasta'd this comment from HN and /r/programming. like I have time to write an original comment on all three forums!)
I believe this is one of the goals, yes. I'll ask nmatsakis to confirm.
You are looking for /r/playrust
Im sorry
:D
Why was Either removed? I searched around and couldn't figure out why. I don't follow Rust development much (although I plan on diving into it soon), but Either is a really useful type in Haskell.
We also have the isomorphic `Result` type, which has more meaningful variant names.
Makes sense. Left and Right are pretty bad names (unlike Just and Nothing)
Indeed, cycles are the bane of unique pointers. In the past I'd have told you to use unique pointers for the links in one direction and unsafe pointers for the backlinks. As of today, though, we'll have strong and weak refcounted pointers in the stdlib that you can use for this purpose instead: https://github.com/mozilla/rust/pull/10926 Of course, you could also just give up and use the stdlib's `Gc` smartpointer. :)
The managed pointers are being moved into libraries, with `Gc&lt;T&gt;` being a garbage collected pointer and `Rc&lt;T&gt;` reference counted. I believe `Gc&lt;T&gt;` is not yet implemented. There's also work in progress on a trait for pointer-like types, which would make library smart pointers nicer to use.
Rust is designed to be a cross-compiler, but as cross compiling is crazy complicated, it tends to only work in scenerios that people have actively worked to support. Right now the scenarios that I know work are `x86_64-unknown-linux-gnu` -&gt; `i686-unknown-linux-gnu` and vice versa, `x86_64-apple-darwin` -&gt; `i686-apple-darwin` and vice versa, and `*-unknown-linux-gnu` -&gt; `arm-linux-androideabi`, though I know people like Luqman have done more exotic stuff and that some people have occasionally gotten Wine cross-compiles into various stages of completion. The general way to create a cross compiler is to build Rust with `--target=${triples}` where `${triples}` is a comma-seperated list of target triples. Right now Rust isn't going to support cross-compiles between any of OS X, Linux, or Windows out of the box, but Linux -&gt; Windows via Wine should be relatively easy to get working with a little work and some amount of changes to the build process.
I've had x84_64-unknown-linux-gnu -&gt; i486-pc-mingw and x86_64-w64-mingw32 work before.
I've seen ways that people partially compile rust code, then use other tools to cross-compile. Do you have any idea on how to do this?
I don't remember how, but I did it right after static linking landed.
We still have raw pointers.
Thought you could only use them in unsafe regions?
Well yeah. But they're unsafe. When else would you use them, in a language whose sole motivator is safety? :)
&gt; * Comments may be nested. [](/soawesome) This is one of my favorite features of Haskell! Kudos to whoever implemented this.
Thank you kibwen!
With a combination of -c (generate .o files) or --emit-llvm (generate .bc files) plus --target to specify the target triple you can do just about anything. For *completely* unsupported triples you may need to teach rustc what the triple's data layout is.
But first I need to compile rust for different platforms right? Or does it work just compiled for my system? I've already got it working without cross-compiling, I just need to get the right libraries for the target.
x86_64-apple-drawin -&gt; arm-linux-androideabi also works I believe.
I was slightly confused when pressing the right arrow displayed only 3 slides and then "Thank you!". ;)
Sad to see do syntax change, I get why it was changed but can we not get another thing that acts the same as do used to? It was so pretty/useful. Something like "do x || {}" for procs and "perform x || {}" for non procs, maybe?
You can pass them around and stuff in safe code. The unsafe operations like dereferencing would probably be in a function that has an unsafe block doing the proper null checks. Rust is motivated by safety but still needs to be practical so banning unsafe operations would be silly: you just need to be aware of when you do them and what the consequences are. In the end this is the same level of care you need to devote to writing c++ but explicit in where.
Hey ! That's me ! My only contribution to rust ! I'm so proud to be kudosed !
Sometimes the small things make a big difference. One of my first contributions to rustc was the `^~~~~~` display in the error output.
&gt; `^~~~~~` display in the error output. I have a weird question. Do you perchance know how does Rust compiler knows how much context he needs to create a meaningful error message? I'm making a parser and this question keeps bugging me constantly :(
The parser attaches "spans" to each part of the AST that is built. A span is just a starting and ending position (where a position is a line and column number that can be traced to a particular file), so the error reporting code requires a span along with any message that will be produced.
pdf please?
This subreddit is for the Rust programming language, not the Rust game ;)
Print it to a file? Otherwise `pandoc` can convert it into a PDF document.
oops, sorry
Wow that is a ton of contributors!
To be fair, the use of `Rc` is somewhat unsafe; if you make a cycle...
I am not sure how useful the segfault code examples are. The rust example appears to be written to look similar the the c version, but it is not trying to do the same thing. The resulting compilation error is less of an indication that it was preventing a runtime error, and more of a suggestion that the line is just not valid rust.
Note: a span covering multiple lines is annoying to display, as is one containing multi-bytes characters.
This subreddit is for the Rust programming language. You're looking for /r/playrust.
You can do the same thing with channels, as they're reference counted too. Until yesterday, it wasn't possible to make a cycle with `Rc` in safe code though so it's not possible in 0.9.
I would if I could by I can only see 3 slides. I guess my browser is not up to that level of JavaScript magic.
The presentation is divided up into top-level categories. You need to use the down arrow to descend into these categories and see the real meat of the content.
Here's an example of what it looks like when printed: https://www.dropbox.com/s/45gapmh82pgjcc5/2014-01-09%2011.40.16.jpg ...courtesy of Jack Moffitt's twitter feed: https://twitter.com/metajack/status/421354852124352512
You're looking for /r/playrust
That is awesome.
That's a very serif-y R. Very cool!
It's not silently exiting for me. But I don't know enough about rust or rust on Windows to be much help. Good luck. Linux 3.12.6-1-ARCH #1 SMP PREEMPT Fri Dec 20 19:39:00 CET 2013 x86_64 GNU/Linux: &gt;1 &gt; &gt;[1] 9799 segmentation fault (core dumped) ./test 
It occurs to me that we completely overlooked your other questions. &gt; It would be also very interesting to see the list of possible runtime fails for core Rust language The manual might have this, but I'm not really sure if an exhaustive list is documented anywhere. There's at least the following: 1. Index out of bounds 2. Stack overflow 3. Division or modulo by zero Standard stuff. I'm not sure that there are many more instances of dynamic failure in the "core language". &gt; is it possible in Rust to emulate common pattern in Java/C++ that class has both mutable and immutable fields? Normally in Rust we have a pattern where we flip a data structure between mutable and immutable on the fly, as needed. let foo = SomeStruct { x: 1, y: 2}; // totally immutable // foo.x = 2; // ...so this would fail to compile let mut foo = foo; // now foo and all its fields are mutable ("thawing") foo.x = 2; // so this is fine let foo = foo; // immutable once again ("freezing") If you really want a certain field to be mutable, I *think* that's what the wrapper types `Cell` and `RefCell` are for. But I'm not sure.
Thanks! Very interesting. &gt; I'm not sure that there are many more instances of dynamic failure I remember reading about dynamic checks for borrowed @mut pointers: http://pcwalton.github.io/blog/2013/01/21/the-new-borrow-check-in-a-nutshell , is it still relevant?
&gt; that's what the wrapper types Cell and RefCell are for. But I'm not sure. Yes. --- The converse question (if you really want a certain field to be immutable always) has a similar answer: not directly, but you can implement simulate something a little like it: pub struct Immutable&lt;T&gt; { priv data: T } impl&lt;T&gt; Immutable&lt;T&gt; { pub fn new(x: T) -&gt; Immutable&lt;T&gt; { Immutable { data: x } } pub fn borrow&lt;'a&gt;(&amp;'a self) -&gt; &amp;'a T { &amp;self.data } } and then you can write (rather verbosely) struct Foo { x: int, y: Immutable&lt;int&gt; } let mut foo = Foo { x: 1, y: Immutable::new(10) }; foo.x += 1; println!("{} {}", foo.x, *foo.y.borrow()); // can't write anything directly like // foo.y += 10; // unfortunately still legal foo.y = Immutable::new(*foo.y.borrow() + 10); (As the last example shows, this would require language support to work completely correctly.)
@mut is now removed, so no. (The replacement `RefCell` has similar dynamic checks and failure, but is entirely implemented in libstd so it doesn't represent a failure built into the language itself.)
I ran across the problem like this: Some(~"foo").unwrap_or(~"bar").trim() I'm not at all fond of how ad-hoc the proposals seem, especially since this is one of the conclusions: &gt; people do not like the idea of an ill-defined lifetime inference algorithm dictating when their destructor will execute. You could always rigorously define the algorithm.
very helpful, Thanks.
*Excellent* talk, cleared up a lot of things for me! The title isn't indicative of this, but I think this is a nice introduction to Rust as well.
I liked this talk quite a bit. Two points I thought about: 1. One major difference between Rust ownership types and C++ smart pointers is that the former is compile time checked. Perhaps I misunderstood the question, but the answer almost seemed to say that C++ libraries could achieve similar things (but needed discipline to make sure you didn't use naked pointers etc. - the tradeoff is much stronger). 1. The comparison to Go will probably come up again and again, so I think you should have some stronger arguments (the answer seemed to be almost "Go is great, and we only have some slight advantages"). You're competing for mindshare, and while you don't want to come off as arrogant it does seem like you should point out the various significant problems that Go has that Rust doesn't (possibly as a result of increased simplicity). Null pointers, no generics, runtime casts, perf. issues due to the extra indirection (due to interfaces everywhere) and on and on.
The fact that so many people think they're competing (mostly because people oversell go as a systems language), means they're competing in practice. 
Yup, I can't say enough good things about this talk. Wow. I'm wondering if maybe this would be a decent basis for the mythical introduction I've been wanting to write...
My point in including it was simply to say "hey, here's the kinds of things that can go wrong in C. They can't go wrong in the same way in Rust."
Yeah, video would help here: I started the talk by saying "Here's what I'm going to talk about: x, y, and z" and then go back and dive into each one. I've heard (mostly) extremely positive feedback after switching to this style.
Hello everyone! These are the slides for my talk at Codemash a few days ago. Sorry that they're not that useful without video, that's just my presentation style. I had a packed room even though I was up against some big names in my slot. Lots of people are interested in Rust!
Sure thing. You can export to PDF, I linked the instructions below.
&gt; mostly because people oversell go as a systems language I am currently into D and Rust, after my disappointment with many of Go design decisions. However, given that Go is quite similar to Oberon, I believe it could actually be used as a real systems language if one tried to do so. As the latter was used to create quite a few workstation based OSs in the early 90's. Some info here in case you don't know it, http://www.inf.ethz.ch/personal/wirth/ProjectOberon/
Its just that most calculations won't benefit from a higher precision. You would optimize for a special case. There is no point in introducing a feature that almost nobody will use or turn off with a compiler switch. On the other hand Rust will be expressive enough (given that operator overloading is implemented) that user-implemented numeric types can be used without pain (unlike Java for example). What is (to my opinion) debatable is, whether “int/int” should return an integer by default or not (I like the python solution of introducing an “//” operator for integer division).
I've written about this on my own blog (but I never proposed it for Rust): http://iopq.wordpress.com/2012/09/09/binary-floating-point-numbers-vs-scaled-decimals/ I believe in a high level language the width of a register should be abstracted away. Not sure if Rust is that language, though. Of course you could write 0.2f to use floating point numbers and 0.2 would mean a decimal float. That would be enough to satisfy those who want the performance while allowing the default to be more sane for human use. Then 2 becomes a 31 bit integer with the last bit signifying whether it's a bigint (basically a pointer because pointers end in a 0) or an actual integer (last bit is 1 that is ignored in math). And you can have 2i or something to have bare 32 bit numbers without extension to bigints.
Real arithmetic as usually defined in mathematics is not computable. You would have to settle for a kind of constructive/computable real instead, which also behaves differently to what many people would expect, e.g. partial equality testing. And that's without even worrying about the performance...
Simple way to download without manager: http://packages.nuget.org/api/v1/package/Rust Open the file with 7zip.
I guess *unsafe* is a bit subjective; I use it for anything that can get my process to crash. Generally speaking you need to control the amount of resources of your process, and you can use pools and such to avoid overflowing the required amount of resources... but memory leaks can be incredibly insidious :/ Since I work on backends with days/weeks/months of up-time (only stopped to change the software version), anything that can lead to a crash (such as a memory leak) is a very serious issue. Which is one of the reasons I am so interested in Rust in the first place, with C++ being so crash-friendly :)
&gt; real becomes, not a 32-bit float (as I understand it currently is), but what it sounds like: a real number, covering all numbers in the real number range, using an arbitrary precision type I wonder, how he is going to represent sqrt(2).
join this ip 88.150.159.135:29215
&gt; Its just that most calculations won't benefit from a higher precision I don't think it is as much a question of precision than correctness. Stuff like having `assert_eq!(0.1+0.2, 0.3);` succeed. I personally encountered a somewhat related issue recently: I wanted to sort a vector of floats. But floats do not implement `Cmp` because `NaN.cmp(NaN)` is not defined. Again, this was not a question of precision, but a wrinkle due the fact that floats behave differently from real numbers. So for decimal numbers I'd be completely ready to abandon floats as default, at least assuming that `let f: f64 = 0.1` would work as excepted. For integers I'm not that certain, partially because they are far more pervasive in the language overall, and generally I tend to encounter less issues with them. And *if* decimal type would behave intuitively, then I suspect you could use it as a replacement for bigint in many cases (but of course not all).
&gt; I wonder, how he is going to represent sqrt(2). [Lazily](http://hackage.haskell.org/package/numbers-3000.2.0.0/docs/Data-Number-CReal.html). Of course, equality testing can diverge, and printing a result can take infinite time. It's still useful because you can specify what precision you need at the usage point, without having to worry about intermediate results. I hardly do any numeric stuff, but I imagine it's very, very useful as a baseline to compare more efficient implementations of your algorithm against.
I haven't seen this thread when I created mine. It is the same video on youtube http://youtu.be/gfCtbGiHcg0
Now landed! This is fixed in HEAD, and a regression test added.
Great talk! Edit: Double post, other discussion is here: http://www.reddit.com/r/rust/comments/1uxaig/memory_ownership_and_lifetimes_niko_matsakis/
&gt; Well people have written OSes in Haskell too. Except those OS are not a fully working GUI workstation with network capabilities, used across the IT department during almost 10 years for several tasks. You even had video players available, in what concerns performance. &gt; The term "systems language" has all sorts of de facto connotations that Go just doesn't meet. Like? For example, on Oberon's case. The GC is only used for heap allocations, you can allocate statically on the global memory or stack, just like C and C++. The meta package SYSTEM provides all the operations for doing the usual unsafe tricks you do in C and C++. This is not much different from the unsafe meta package in Go. What I do concede Go might be lacking is that the unsafe meta package does not provide all the operations that the Oberon SYSTEM package does. Plus, Oberon does not use strides, which in Go's case do require GC support. So, if one would pick up Go, create a syscall package similar to Zero.rs. You could create an OS in Go. Please note that I more into D and Rust, just noting from a compiler design geek point of view that one could write an OS in Go if so desired, by looking at the history of computing.
&gt; For example, on Oberon's case. The GC is only used for heap allocations, you can allocate statically on the global memory or stack, just like C and C++. In Go you don't know for certain whether something is allocated on the stack or the heap, by design. The language spec doesn't say, the FAQ says "you don't need to know", so the only way you will know is by reverse engineering the escape analysis code in the compiler. This may be different in Oberon, but this rules out Go for kernel contexts in general. For example, you can't safely write an interrupt handler in Go, because interrupt handlers may not allocate, as interrupt handlers cannot lock without risking deadlocks and malloc may need to lock. (As always, I'm not criticizing Go's design decisions here, by the way; I'm just saying that it's not suitable for kernel contexts.)
&gt; IMO Rust is for people who would like to use a high productivity language but are forced to use C or C++ for practical reasons like the need for low level code, tight resource bounds and performance. Like game developers, etc. Yes, I agree. I'd also add that Rust is for domains in which C++ level performance is paramount, but in which you also need ironclad security. Those domains didn't exist at the time C was invented, as machines basically trusted one another, but they do now. Rust is not trying to be the language for all use cases. But I think that "secure software that needs to run really fast" is actually a really big field that's only going to grow as our industry matures.
My favorite quote (stolen from HN): Rust is a high-level systems programming language, Go is a low-level managed language runtime. I think that nicely captures the differences.
&gt; The term "systems language" has all sorts of de facto connotations that Go just doesn't meet. &gt; &gt; Like? Predictable (and high performance), for one. The fact that it's possible to write an OS doesn't make it a suitable systems language (as I said, Haskell has a few). People do all sorts of unnatural things in all kinds of languages. You wouldn't want to write router firmware in Go, for example.
Sure, but is not a particularly good exemplar of that principle. The c version tries to overwrite the first character of a constant string, which can segfault depending on the platform and compiler. The rust code, while looking similar, appears to try to assign to the entire string (if that was a thing that you could actually do). A more helpful example would have code that semantically does the same thing, but which rust disallows in the unsafe case. A dangling pointer is always a good one.
I agree. That's great.
Yeah, and even if security/safety isn't a critical feature (e.g. games, non-critical client apps, etc) it's still hugely important for any consumer-facing product to behave nicely (or they face backlash). It doesn't really matter in the grand scheme of things if a game crashes, and yet: http://en.wikipedia.org/wiki/Battlefield_4#Bugs.2C_glitches_and_legal_troubles ... If you want to be successful in the long run you need to produce quality software that doesn't crash and behave erratically, and a language which eliminates many of those issues by design is huge.
Yes, in Oberon only what is allocated via NEW lives on the heap under GC control. You can do manual allocation via the meta-package SYSTEM, for the cases when it is really required. Any package that imports SYSTEM is considered unsafe. You know my stance on Go from my HN posts as well. I was just trying to clear out what might be the issues with it.
Well, you could have a real time Go runtime, in the same way there are Java real time runtimes controlling missile control radar systems, but I do get your point.
Quite fair. If I give it again I'll change that, thanks!
The `Rc` in 0.9 requires that the inner type either have a `Send` bound (`Rc` is not `Send`) or a `Freeze` bound (`Rc` is immutable so if the inner type has inherited mutability, you cannot alter it to refer to itself). Shared, mutable concurrent data structures are `Send` so preventing cycles in those requires adding a `Freeze` bound. Although this works, the current view is that it's too restrictive. It's definitely not `unsafe` to leak, so that's also the wrong way to prevent it.
Did you add 'runtime' part to Go by accident, or intentionally? It seems like language to me.
The word "language" was in the original HN quote. However, Go does have a complicated runtime that handles all the garbage collection, goroutine scheduling, channels, network I/O etc.
&gt; Of course you could write 0.2f to use floating point numbers and 0.2 would mean a decimal float. A decimal float with how much precision? Arbitrary precision decimals need a way for the user to pass the desired precision, so a simple literal isn't enough.
&gt; What is (to my opinion) debatable is, whether “int/int” should return an integer by default or not Floating point numbers have a much steeper learning curve than understanding the rounding methods used by integer division. I don't think Python does anyone any favours with this kind of implicit conversion to binary floating point.
You can hit escape...
Interesting article. I like the idea - I think it's important to be correct if the lower-level types are still available to programmers. 
Ah cool.
Wrong subreddit?
This is not the rust one?
&gt; Given you had an infinite amount of memory to represent floats, that test would succeed. Given any arbitrarily big (but finite, because computers are in the real world) amount of memory to represent floats, that test (or others to the sort) will never succeed. It's not a matter of precision; some numbers can't be represented.
&gt; Or say "I need numbers in the range (-12,100320), figure out how to model that in hardware. As a side note, VHDL lets you express that, and the synthesizers do figure out how to model it in hardware :)
Not entirely fair, modern Go ships with a static analysis tool to heuristically detect some data races. I can't say how well it works, but at least it's there.
Well the literal itself has precision of one decimal place and one sig fig. When you add, you preserve the decimal places of the arguments. When you divide you get a rational number as a result. 0.1 + 0.2 = 0.3 (*the simplest example where floats fail you*) 0.1 + 0.02 = 0.12 (*two decimal places*) 1 / 3 = 1/3 (*represented by a ratio in memory*) 0.12 + 1/3 = 34/75 this is how it works in Smalltalk, except with the addition of decimal numbers you can do the following: 3.4 / 10 = 0.34 (*same amount of sig figs*) 0.34 / 3 = 0.11 (*I guess this would be surprising*) 0.340 / 3 = 0.113 (*more sig figs*) so if you really want accurate division you need to just go with rational numbers for division? toRatio(0.34) / 3 = 17/15 34/100 / 3 = 17/15 in my notation ratios don't have spaces between them, but division does, not sure if that's clear
What about multiplication? let x = 0.25; let y = 0.25; let z = x * y; // 0.0625 or 0.063? In my opinion, writing out a bunch of zeroes to ask for a lot of precision would be *really* annoying. I guess you'd have alternative ways of constructing a decimal.
You might want to post the actual link to the library.
`0.063` unless you write something like let z = prec(16, x) * prec(16, y); it's the method call notation in Rust that makes this verbose you could have this implemented in Smalltalk like z := x prec 16 * y prec 16. or you could have literals like 0.25p16 but this is a language feature while prec is a standard library function that just sets the precision of a number (it turns 0.25 to 0.2500000000000000) but you'd have to do the rounding at the very last step possible and evaluate it with extra precision in intermediate steps (you have to do this with floats as well or you'll have many rounding errors) to do it exactly you could do also: let x = 1/4; let y = asRatio(0.25); let z = x * y; // 1/16 or 0.0625 so I guess decimal numbers and rational numbers are kind of two separate issues
Who said anything about a link? Can't you just be happy for James?? EDIT: I think this might be it: https://github.com/lilac/quick-check
OH, you are right!
&gt;&gt; Its just that most calculations won't benefit from a higher precision &gt; I don't think it is as much a question of precision than correctness. Stuff like having assert_eq!(0.1+0.2, 0.3); succeed. You will run with it in other places however like for example `assert_eq!(1/3 + 1/3 + 1/3, 1)` or `assert_eq!(sin(x)*sin(x) + cos(x)*cos(x), 1)` for any x. If you have a floating points decimals then you fail `assert!(x + 1 &gt; x)` - on the other hand if you don't then you need to either a) limit precision which means that `assert_eq!(x/2 + x/2, x)` fails b) limit range which means that `x + 1` might overflow. You can have arbitrary precision but then how would you represent irrational numbers? In the end in financial application you can simply use fixed point arithmetic where 1 represents say 1 cent/1p/1 eurocent/whatever instead of 1$/1 pound/1 eur/whatever (ok - from what I know the calculations are done in 0.0001$ not 0.01$ but the general idea is the same) - but check the local regulations for details. On the other hand in numeric applications they want to have the floating point instead of fixed as it's apparently easier to manage errors (I don't know all the details). On top of that add 30 years of IEEE 754 being de-facto standard and any divergence from it would be a surprise for many programmers (including NaN == Nan) - and we (programmers) learned how to deal with its quirks - changing the system would most likely require learning brand new ones. Even in Haskell which have sort of built-in syntax for the rations etc. in the end everyone is using Float/Double (I believe - I haven't done any survey) - rust being more low level language would be even more prone. In the end the problem with intuition is that humans are wonderful and can detail with changing environment and partial data... at the cost of allowing to have in-consistent believes. So while some behaviours might feel 'natural' it tends to just specify the general expectations and it might give a contradictory requirements in edge cases.
Ada has built-in support for user defined decimals and floats that might be a starting point. http://en.m.wikibooks.org/wiki/Ada_Programming/Types/delta
The race detector is runtime instrumentation, not static analysis. It works amazingly well. You can build binaries and have one of your servers running the race detector all the time (small slowdown), our just have it run through your test suite.
if you record 50 hz video projector with 60 hz camera or vice versa, you get this sort of flickering issue. Sometimes the camera has a switch to avoid it (the problem comes up when you have any sort of AC lighting running at a slightly different framerate to your camera) (AFAIK)
Could a rust version of QuickCheck become as feature-rich as the Haskell version? Or is there some inherent language limitation of Rust vs Haskell?
Exactly. This is why arbitrary precision numbers won't help either. Some numbers can't be represented by them either. No point in blaming floats. They are a sufficient compromise for most cases. And more importantly they are implemented in most modern hardware.
Well, clang and gcc ship with a set of [thread safety annotations][1] by DeLesley Hutchins and of course you also have [Helgrind][2]... yet I would not call C or C++ "thread-safe". - the thread safety annotations can be forgotten (hum...) - and of course Helgrind only detect races if they occur during the execution (runtime tests cannot prove correctness) Rust guarantees at compile time, with no annotation burden, that the program is thread-safe. This is much safer. [1]: http://llvm.org/devmtg/2011-11/Hutchins_ThreadSafety.pdf [2]: http://valgrind.org/docs/manual/hg-manual.html
[**@makoto_kato**](https://twitter.com/makoto_kato): &gt;[2014-01-06 05:32:42 UTC](https://twitter.com/makoto_kato/status/420065365779943425) &gt;[#rustlang](https://twitter.com/search?q=%23rustlang) book [*pic.twitter.com*](http://pbs.twimg.com/media/BdRfOV0CEAAVqrX.jpg) [^[Imgur]](http://i.imgur.com/8oLb5Vf.jpg) ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/1v10dt%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
&gt; Rust guarantees at compile time, with no annotation burden, that the program is thread-safe. This is much safer. There is a trade off: a flexibility burden. Rust will reject some programs that are valid and safe, because the compiler can't prove that, but C/C++ compilers don't have to do many proofs, so they let more valid and safe programs compile (while also letting through many many more invalid and unsafe ones).
It was also posted on /r/programming: http://www.reddit.com/r/programming/comments/1uygbh/the_rust_language_memory_ownership_and_lifetimes/
This is awesome! ... ... Till 1.0 comes out and breaks everything &gt;.&lt;
Ah, thanks. I had no idea that it was a dynamic rather than static analysis.
I can't think of any reason why not. Traits for Arbitrary and Shrink should be enough, yes? 
looking at this: router.add("/posts/:id", posts); and this: fn posts(request: &amp;ServerRequest, response: &amp;mut ResponseWriter) { let id = request.params["id"].unwrap(); made me wish for type-safe URL routing. Strawman proposal: maybe something like route!(router, "/posts/:id", posts); with a typed ```posts``` callback that has an ```id``` parameter fn posts(request: &amp;ServerRequest, response: &amp;mut ResponseWriter, id: u32) { which would ideally statically check that the route string "/posts/:id" specifies one parameter, and that the ```posts``` callback has one extra parameter. Like how the format! machinery statically checks format strings. Would [https://github.com/mozilla/rust/pull/11151](https://github.com/mozilla/rust/pull/11151) let you do something like that in a library? edit: or rather, if PR11151 is about procedural macros, maybe "statically" is the wrong word. Checking before runtime is what I meant.
This week I have decided to start learning Rust because I think it's a fascinating language and the community is awesome. That said, coming from Python and Go, and Rust being a project spear headed by Mozilla, I am surprised that Rust does not have an HTTP server in the standard library. The only thing this website is missing is a Rust based HTTP server. This is the best developed http server that I have found for Rust: https://github.com/chris-morgan/rust-http
I love the enthusiasm, hopefully it focuses on core concepts that are unlikely to change :/
An HTTP library does not belong in the standard library
How do I get a copy?
Eventually we will have an officially supported http crate, and it will be the same one Servo uses, so it will hopefully be comprehensive and fast. It won't be part of std, but it will be trivial to install. In general we do want rust to include all the batteries via an extensive ecosystem of curated crates.
It rather seems to be a magazine: http://translate.google.de/translate?hl=de&amp;sl=ja&amp;tl=en&amp;u=http%3A%2F%2Fsaneyukis.hatenablog.com%2Fentry%2F2013%2F12%2F23%2F165610
I actually have some plans for registering a handler that converts params into a typed struct. If the handler succeeds, then you're typesafe from there on out. fwiw: I changed the Index API (`params["foo"]`) to automatically unwrap (and thus fail the task if the param is not present) and plan to add `params.optional("foo")` that would return an `Option&lt;~str&gt;` for optional params.
Also, yes, loadable syntax extensions (and loadable `deriving`) would do the trick. I was thinking about something like: #[deriving(FromParams)] struct PostParams { id: uint, page: Option&lt;uint&gt; } fn main() { route.add::&lt;PostParams&gt;("/posts/:id", |request, response| { request.params // a PostParams }); }
Ah. This makes sense. Thanks!
I don't know any of the four authors. That's pretty cool.
I sent the Rust Samurai an email asking about acquiring a few copies.
I... don't think writting a Rust book gives much money... It's though to profit from technical books! It's more about a language showing passion/enthusiasm coming from its users. And as /u/rustcvswvi discovered, its a Japanese magazine, not a book. And it's really nice to see Rust Love spreading worldwide! 
Really glad to see the initial pass at [placement box](https://github.com/mozilla/rust/pull/11055) (can't think of a better name) finally getting merged. I'm really looking forward to the changes this will bring to the language along with the removal of @-ptrs.
Is there a reason this requires node?
Wrong subreddit.
This is an urgent need which is not yet satisfied—and there are a large number of things that can't be done until it is satisfied, a handful of the ones I care about being: IRC clients and servers, HTTP/2.0 servers, efficiently pipelined HTTP/1.1, WebSocket implementations, &amp;c. The primary solution Alex has been discussing is making select work on TcpStream as well. That is indeed one solution that will work; another, with benefits and problems of its own, would be to split the TcpStream into a reader and a writer and letting different tasks take care of each. In the end: yes, this is known to be a severe deficiency which needs solving, but the solution to be used is not certain yet, nor is code yet being written.
What's the end goal of Rust I/O, anyway? The early inclusion of libuv left me hopeful that 1.0 would have default-nonblocking I/O, or a higher-level loop like asyncio, but the language is starting to stabilize and async I/O still looks to be various flavors of "throw sockets and threads at it". It's a little worrying to hear that IRC and HTTP are still _impossible_ in a new systems language. :)
You switched up your ()s and []s in the link.
Ah, thanks. I had the right order of placement for the brackets and parentheses, but messed up the order of parameters. Was typing it out quick in mobile.
I ran into this issue while I was writing an IRC bot in rust, it's really ridiculous that such a major part of the language is missing, and instantly demotivated me from writing anything further network-related in rust. Why are there things I have to dispatch to C to do because rust can't? And more importantly, why don't we have a solution in place (like separate readers and writers) rather than sitting around bikeshedding over which solution we should use, at this rate there will be no solution by 1.0, and it will become a major downside to anyone looking to use the language ("oh, well, it can't do that" "why?" "..."). Last time I asked about this, there was in fact an overall negative view of exposing any form of async IO at all (even despite the runtime already being dependant on it!), and it was just so confusing why anyone would take on the view that limiting flexibility is a good thing to have in a system's language - we didn't compromise with the complexity of pointer lifetimes, why are we compromising with the complexity of async IO?
Ah well. I guess that's an itch I may just have to scratch myself one day. Thanks for the response, anyway! :)
&gt; The goal with libuv wasn't to expose nonblocking I/O, it was to enable multiple tasks doing I/O on the same OS thread without blocking other tasks on the same thread. It was an enabler of M:N scheduling. Why not just use a thread now that the resource consumption is the same? What justifies the complexity?
Hence wondering what the end goal is—`select` is still pretty low-level. Maybe 1.0 won't change the world, but is there a far-future I/O dream the language is trying to aim for?
Stable server with no lag, active admins and perfect mods!
I'm not exactly sure how to Google this, what is this io select? I would like you read up on this, to understand.
http://en.wikipedia.org/wiki/Select_%28Unix%29 It's one of the very basic primitives in Unix for handling more than one source of (potentially blocking) input at a time; basically you feed it a list of open files/sockets/whatever and it tells you which ones are ready to read from or write to.
The code is in the [rust-http repo](https://github.com/chris-morgan/rust-http/tree/master/comparisons).
No, there isn't. It's just to simplify the prototyping for Markdown and the code snippets. I'm going to transition to static pages anyways.
It's a straightforward `node apache_fake.js`. It's not a particularly scientific benchmark, but it gets the basic idea across. Running multiple processes would be a separate benchmark, in my opinion—both are valuable for comparison.
So the "concurrency" is the concurrency of `ab`?
&gt; It's a straightforward node apache_fake.js Huh? That's how you can start the server, sure, but that doesn't answer how they benched it. Are they hitting that one server with many requests, or spinning up a few in parallel? &gt; it gets the basic idea across Well....no. If you're going to bench something you have to use it how it's meant to be used. Node is very resource efficient and performs very well on a single thread, but if you want to run it in parallel or scale it you have to spin up multiple processes. Rust and Go I assume actually run on multiple threads, so of course they're going to perform better if you treat them the same way. They'd probably still perform better even if each language was utilized properly, but the margins might be a bit smaller.
We will need to expose select over I/O streams before 1.0. We also want a solution to split TCP streams into a separate reader and writer. So far the focus has not been on async I/O, except multiplexed over M:N threads, because exposing the event loop directly results in callback hell and that isn't a very nice programming style. But that said, we do want to expose libuv directly if you want to program directly to it. I suspect only really high-performance use cases that are OK with callback hell will want that, though, and as a result I don't think it blocks 1.0; the only thing that this buys you over the Rust preferred solution is a little memory footprint and saving the overhead of register swaps.
&gt; rather than sitting around bikeshedding over which solution we should use, at this rate there will be no solution by 1.0, and it will become a major downside to anyone looking to use the language ("oh, well, it can't do that" "why?" "..."). Rust 1.0 will not be released without TCP splitting or select. &gt; Last time I asked about this, there was in fact an overall negative view of exposing any form of async IO at all (even despite the runtime already being dependant on it!), I don't have a negative view of exposing async I/O. If you want to write something that will compete cycle-for-cycle with nginx you'll need it, and Rust should be a good language for writing nginx alternatives in. I don't think we should encourage async I/O for most apps though, as it encourages a pretty miserable programming style (callback hell).
Yes. (I know ab is not highly thought of; it was just the simplest tool to start with and I haven't got onto anything else yet.)
I was referring to the parallelisation technique used: that it is just a single process. My experience in commercial deployments is limited, but what experience I have suggests that merely *saying* "thou shalt run multiple processes" is fairly meaningless: most small deployments will not do so unless it is made trivially easy. It's thus still an important *real life* benchmark.
&gt; Comparing a context switch between tasks on different cores and tasks on the same core isn't a useful benchmark. You need to set the affinity of native threads to match where the green tasks are running. The Linux scheduler was found to be doing this implicitly when everything was serialized. &gt; The glibc POSIX mutex supports a dozen kinds of locking and needs to dynamically select the correct code. It also has to track the owner of the lock. Other implementations are significantly faster. IIRC in Alex's measurements almost all the time of the POSIX mutex was found to be spent in the futex syscall. Remember that we were benchmarking the contended case. This shouldn't be a surprising result, really; userspace context switching is faster than kernel context switching.
This is the subreddit for The Rust Programming Language. I guess you're looking for [r/playrust](http://www.reddit.com/r/playrust) :)
Go and Rust have both Light threads and Kernel threads. Go runs arbitrary amount of co routines but will run upto [`runtime.GOMAXPROCS()`](http://golang.org/pkg/runtime/#GOMAXPROCS) system threads.
&gt; The Linux scheduler was found to be doing this implicitly when everything was serialized. I can't reproduce this. &gt; IIRC in Alex's measurements almost all the time of the POSIX mutex was found to be spent in the futex syscall. Remember that we were benchmarking the contended case. It doesn't sound like anything representative of a real workload if it's sleeping all of the time and I doubt it was really doing the same thing in green/native cases. What's an example of a workload green tasks can complete faster than the code written using native threads? &gt; This shouldn't be a surprising result, really; userspace context switching is faster than kernel context switching. The cost of a kernel context switch isn't very expensive. Switching stacks and cores is expensive. Fair scheduling is more expensive than leaving it as a problem for the user. Linux has `SCHED_BATCH` if you don't care about latency. Windows user-mode scheduling is a complete improvement over Rust tasks without drawbacks. It can context switch on a blocking system call or page fault, so there's no need to reinvent any wheels and it's 1:1. M:N scheduling never makes sense there.
Speaking of Rust CI, I kinda have a tiny project in it that needs to be removed (duplicated), but I can't seem to be able to remove them... Is there any chance we can log into Rust CI via Github and delete our repositories?
Green threads use blocking I/O built on the async libuv API. On Linux, libuv ends up using sync I/O in thread pools for everything other than sockets anyway. It offers the ability to opt-out of fair pre-emptive scheduling which will save you some cycles, but not lower resource consumption or more scalable I/O.
It doesn't _have_ to be callback hell; Python 3.4 is making pretty good use of `yield from`, which seems like it would work even better in a statically-typed language (where you can't accidentally leave it off).
I think the idea is to extend this select so that it works for both ports and OS objects (file descriptors in Unix, handles in Windows): http://static.rust-lang.org/doc/master/std/comm/struct.Select.html Same idea as unix select though.
&gt; Maybe 1.0 won't change the world, but is there a far-future I/O dream the language is trying to aim for I don't think there are any existing plans for high-level async I/O like C# async/await or even Boost ASIO. Rust was designed to follow Go's lead in only offering synchronous interfaces but lightweight tasks via segmented stacks were at odds with other goals and are gone.
See also https://github.com/mozilla/rust/wiki/Community-libraries#gui
The `select`/`poll`/`epoll` functions don't work on files. In fact, Linux doesn't use asynchronous I/O for files at all. It uses non-blocking sockets and synchronous I/O elsewhere.
&gt; IIRC in Alex's measurements almost all the time of the POSIX mutex was found to be spent in the futex syscall. Remember that we were benchmarking the contended case. I asked about this here: https://github.com/mozilla/rust/pull/11509#issuecomment-32153646 If it's really not letting the scheduler sleep, then `pthread_mutex_t` or `tbb::queuing_mutex` aren't the types to compare with.
I think the main question about 0.9 is if anybody will actually use it. So far most people seem to track master and if libraries do that then rest of users follow. And if that happens then these intermediate releases seem bit insignificant.
Rust's select only works on channels and not directly on OS objects. I don't think the plan is to extend it but rather to expose another kind of select.
You're probably right that that's not the plan. Actually, the plan seems non-existent to me. I just saw this idea mentioned in several different places as suggestions by others: - https://github.com/mozilla/rust/pull/11294#issuecomment-31613198 (in the context of timers) - https://github.com/mozilla/rust/issues/11165#issuecomment-31301030 - https://github.com/mozilla/rust/issues/11165#issuecomment-32102210 
Mail sent.
There is an (in progress?) Rust port in the [rust branch](https://github.com/alexcrichton/jba/tree/rust), with the most recent commit 3 days old.
I have been on an unfortunate Rust hiatus for a while. So I'm gonna suggest an alternative for your build_from_grid() function, with the disclaimer that it might not compile because I'm not up-to-date on all syntax changes. I suggest to avoid nested pattern matches, using tuples instead. pub fn build_from_grid(prevg: &amp;grid::Grid) -&gt; grid::Grid { let mut result = prevg.clone(); for row in range(0, prevg.height()) { for column in range(0, prevg.width()) { let ncount = count_neighbors(grid::Row(row), grid::Column(column), prevg); result.inner[row][column] = grid::Cell { value: match (prevg.inner[row][column].value, ncount) { (grid::dead, 3) =&gt; grid::alive, (grid::alive, 2..3) =&gt; grid::alive, _ =&gt; grid::dead } }; } } return result; } // fn build_from_grid
Ah, cheers.
I received this mail from Hans Jorgen saying that these tweaks are coming soon :D 
FRP, if it can be efficiently implemented in rust, is a very powerful solution to callback hell.
Of course no one is going to use it.What would the point be? Releases are time-based right now, they're not supposed to be significant.
Having correct number types be the default is not really going to be able to be optimized very much, except in very specific cases; you'd need a dependant type system to get any meaningful amount of dropping to primitive number types.
Last year there were over 60000 release downloads between Jan and May: http://static.rust-lang.org/logs/analog.html#type
See also https://github.com/mozilla/rust/wiki/Community-libraries#regular-expressions
&gt; It doesn't sound like anything representative of a real workload if it's sleeping all of the time and I doubt it was really doing the same thing in green/native cases. What's an example of a workload green tasks can complete faster than the code written using native threads? It's a decent benchmark of raw context switching performance, which is one of the main practical differences between 1:1 and M:N (the others being I/O and thread creation). We don't have enough real-world data to know a lot of performance considerations in Rust. Mostly what we have to go on is small benchmarks at this point. The data from small benchmarks is mixed versus 1:1/M:N at this point. So far 1:1 seems to be better in most cases, but the question is not yet resolved. &gt; The cost of a kernel context switch isn't very expensive. Switching stacks and cores is expensive. That doesn't match with what I've seen. Changing stacks is simply faster in userspace, because the operation is the same but the kernel doesn't have to be involved. See the numbers for scheduler activations here: http://people.freebsd.org/~deischen/docs/Scheduler.pdf &gt; Windows user-mode scheduling is a complete improvement over Rust tasks without drawbacks. It can context switch on a blocking system call or page fault, so there's no need to reinvent any wheels and it's 1:1. M:N scheduling never makes sense there. Taking advantage of UMS will probably entail a third kind of scheduler, which validates our choice to leave scheduling undefined in `libstd` instead of just going `libnative` everywhere.
You could do that in Rust too if we exposed libuv directly. Just use libuv where it makes sense to and don't use it where it doesn't make sense to.
This: let args = os::args(); assert_eq!(2, args.len()); let arg_vec = args.iter() .skip(1) // Skip program's name. .take(1) .to_owned_vec(); // I don't know if this is the best way in rust. let filename = arg_vec.head(); // It won't let me chain head() (idk why YET!) println!("Opening file {:s}", filename.as_slice()); let path = &amp;Path::new(filename.as_slice()); Could be written as: let args = os::args(); let path = match args { [_, filename, ..] =&gt; { println!("Opening file {}", filename); Path::new(filename) } _ =&gt; fail!("No file name given."), }; This: let mut timer = match Timer::new() { Some(t) =&gt; t, None() =&gt; fail!("Error creating timer.") }; Could be: let mut timer = Timer::new().expect("Error creating timer.");
I recall a while back that there was some work being done on the date/time libraries, with a lot of people hoping to get something close to joda-time. Does anybody know of the status of this work? I'm hoping it makes it into the next cycle. 
Great!
Wow - I would never have thought about matching the args with a vector that way! Nice example.
&gt; Rc now supports weak pointers, and it no longer requires the wrapped type to be Freeze or Send. That is, it no longer statically avoids cycles using the type system. It was found to be too restrictive. The only constructor is now Rc::new. Does this mean that we might expect memory leaks in Rust ?
I haven't been paying attention, so help me out here - wouldn't the simple/obvious solution be to expose normal unix socket api (like python 'socket' module), and build high level abstractions on top of that later on?
Clueless newbie lurker here. Hello! I love the flow in your writing, and as with the recent Niko Matsakis talk, the focus on ownership is a good way to cover both memory allocation and concurrency. My only nitpick (sorry) -- is mentioning the Cyclone language in the intro a good idea? I suspect most people outside of PL design won't have heard of it, so it feels a little out of place. (This isn't to say it's not important, of course -- after all it did influence Rust itself. But it will mean little to most C++ or similar folk.)
I was wondering the other day if we couldn't have some kind of bindings to Qt QML stuff. I'm totally noob in this question, but from my understanding it is a high level DSL for declarative gui interface and the backend logic of the applciatino then has to be written in either c++ or javascript, so I was wishing I could prototype somthing quickly with it and just throw a rust backend at that gui.... Specially usefull for trying to write a rust application for my Jolla phone :P
I get it. I just keep forgetting. Especially when it's only split into 2 parts, rather than 3.
Great talk! Very informative about the state of documentation in Rust, and where to go from here. I liked the perspective from a Ruby programmer, having written a lot of Ruby code in the past. 
Well, you're right. No one would muck around with that until it becomes a problem... but if you only care about small numbers of requests then it really doesn't matter what server you're using; they will all handle small loads just fine. It becomes a problem under huge loads, and then that's when the bench becomes important. Which solution scales best? This benchmark won't answer that. But anyway..I'm beating a dead horse.. it's not an issue for me right now so I'm not overly concerned :-P When/if I am, I'll write my own benchmarks.
Agreed. Don't want to send somebody off to wikipedia before we've even got them hooked.
While this is great, this just doesn't seem to have the kick that the talk had, though I can't pin down why. Maybe it's the lack of those nice illustrations of the state of the stack/heap, or the medium, or something else, I really don't know what it is.
Yeah, illustrations would be really great.
Yeah, I always wonder about that too... thanks!
Thanks! I'm assuming you've seen my www.rustforrubyists.com ?
&gt; Taking advantage of UMS will probably entail a third kind of scheduler, which validates our choice to leave scheduling undefined in `libstd` instead of just going `libnative` everywhere. UMS is still 1:1 threading. It makes sense to use it for pools with varying types of scheduling inside of an application using 1:1 threading but there's no need for a different I/O stack, TLS, etc.
The first time I have to type ReferenceCounted&lt;T&gt; or, god forbid, ReadableWritableAtomicallyReferenceCounted&lt;T&gt;, in code, I'm going to flip a table.
Supposing that I still want to use Rust to build a cool website. I’m using Nginx to serve all my HTTP stuff. How must I configure it?
If you're sure about two digits of the operands, probably not. 0.25 means 0.245-0.254 0.25 * 0.25 means a range of 0.060025 - 0.064516 potentially of course that's the interpretation that the user only gave two sig figs when they typed 0.25
Indeed I have; it's a good introduction 
You're moving a *~Node* out of its Option and into *node* in that match arm. What you're looking for is probably *Some(ref node)*, which will take a *&amp;* (reference) to your *~Node*.
(I think he actually needs `Some(ref mut node)` (in order to get a `&amp;mut Node` instead of a `&amp;Node`), but you've got the right idea.)
If you're creating cycles of Rc, yes. We could probably add a lint that checks for cycles of types with a `#[cycle_check]` attribute. (It'd work on actual instanciations of polymorphic types)
But then you'd be forced to use an IDE to deal with boilerplate...
/r/playrust
If that means no name conflicts, I'm down for that. 
I'm curious about this sample, fn main() { let numbers = [1,2,3]; let (port, chan) = Chan::new(); chan.send(numbers); do spawn { let numbers = port.recv(); println!("{:d}", numbers[0]); } } How come we have to use a channel to pass in the numbers if they're immutable? Do variables not automatically pass into an inner-scope? Can't the compiler know they're immutable and safe to use without copying?
Right you are :)
In that case, passing the variable in by capturing it in the `proc()` closure that `spawn` takes is fine: fn main() { let numbers = [1, 2, 3]; do spawn { println!("{:d}", numbers[0]) } } A more realistic example would be going the other way (from the inner task to outer): fn main() { let (p, c) = Chan::new(); do spawn { c.send([1, 2, 3]); } let numbers = p.recv(); println!("number from another task: {:d}", numbers[0]); }
Much better. Does `p.recv()` block then? Are channels akin to C#'s Tasks?
Fair enough. Thanks for the answers :)
I think you mean `ReferenceCounteredPointer&lt;TypeParameter&gt;`. ;)
/r/playrust
1. I'm by no means an archaeologist, but the use of `self` comes from a series of pull requests starting from [#295](https://github.com/mozilla/rust/pull/295) (!) by Lindsey Kuper. There is no indication why `self` was chosen though, and I cannot find it in the mailing list either, but it was so early decision that it persisted over the course of evolutionary changes including the removal of classes (`obj` keyword at that time). 2. I think `impl List { ... }` is really a shorthand for `trait List__extensions__ { ... } impl List__extensions__ for List { ... }` (with corresponding method definitions in the trait) thus the syntax makes sense. I also think that you occasionally have to convert an `impl` block into a `trait`-`impl`ementing block (which C# does not have) for the purpose of refactoring and the syntax is handy for that.
FYI, [rust-kr.org](http://rust-kr.org/) is powered by [rust-http](https://github.com/chris-morgan/rust-http) (and I believe this is currently the only website to do so). As /u/chris-morgan pointed out, this is not yet ready for production uses though.
Depends on the library you use. For the case of rust-kr.org, the Rust server understands normal HTTP requests (via rust-http) and the forefront web server acts as a HTTP reverse proxy to that server. In Nginx it would take a single `upstream` entry, I think.
Thank you so much! I was hoping for feedback like this, your vector matching is badass. I'm curious about expect(), I had never seen it before. Searching through the repo isn't immediately enlightening, I'm not sure the best way to find the definition of the function. Is the expect() pattern preferred to pattern matching like this?
I'm going to try this right away, thanks! I need more practice with pattern matching :)
Ah. Ok. This makes much more sense when you're implementing methods from an abstract class or interface. Thanks! The logical grouping bit shouldn't be an issue though. I assume any sane person would throw these methods in the same file.
I think `self` has been used longer than `this`. At the very least, it has a long history of use dating back at least as far as SmallTalk. Either way, I personally prefer `self` to `this` for rust, mainly because I find the change to be refreshing.
In PHP `self` refers to the class so you can access static members, whereas `this` refers to the instance. Does Rust have a way to refer to... I guess you wouldn't really have static methods would you? Just throw them out in the wild...good ol' functions....
See also http://rigaux.org/language-study/syntax-across-languages.html#bjcrntRflCrrnnstn
Simula used "THIS", which is the oldest variant. That something is older is not necessarily a good thing though.
*Edit: Was pointed out that a double linked list can not refer both to previous and next. Leaving post for context. Rust supports generics, but has no null pointers. Use the 'Option' type instead: pub struct ListNode&lt;T&gt; { next: Option&lt;~ListNode&lt;T&gt;&gt;, previous: Option&lt;~ListNode&lt;T&gt;&gt;, value: T } The 'Option' is an enum with field 'None' and 'Some(&lt;val&gt;)'. It is kind of like a union struct in C. As for performance: Using vec and slices require fewer allocations, fractions the heap less and is better cached in the CPU. I am not an expert in this area, but reducing the number of heap allocations and storing data sequential in memory usually means speedup. In addition a vec allows you to allocate on the stack if you only need it temporarily. 
Best of all would be CSS animations showing moves, as in [this amazing explanation of Raft distributed consensus](http://thesecretlivesofdata.com/raft/)!
&gt; I particularly hate that Python used up keywords like str, list and dict. They're not keywords, they're just variables in the builtin namespace.
Intrusive data structures provide the ability to have the same object in more than one container, and they separate allocation from container logic. For example, you could have some objects stored in a vector with multiple linked lists and tree-based sets threaded through them.
As a non-native English speaker, `self` always felt more natural, even though I can't exactly explain why, it just feels more intuitive.
This is how I implemented it. Probably won't compile today: https://github.com/DanielWaterworth/rust-datastructures/blob/master/intrusive_list.rs
A vector can be monetized to emulate tree search and set operations on indexes, or it can encode a heap of binary tree, depending of the need. In addition iterators on vectors sometimes gets optimized by the compiler. There is no container structure I know of that can't be implemented in vectors, but one drawback is harder to find the algorithms or eventually write them yourself.
Does anyone know where are the slides?
Although we typically try to encourage pattern matching, the particular case of "grab the value out of this `Option` and just `fail!` on `None`" is so common that we have a method to make it a bit more convenient.
it can not be done this way: each node will be referenced by both previous node and next node. this break the rule: one object can only be owned once.
iOS support is the last thing keeping me from going full force on rust for my game engine.
Would `AtomicRc` be so bad? I don't mind abbreviations, `Rc` and `Gc` are just fine, but when a name is *outright [misleading][1]* that crosses a line for me. (`Pod` is the other example I'm glaring at right now.) [1]: http://en.wikipedia.org/wiki/Arc_%28geometry%29
Your C++-example at the beginning is actually just C code. Am I assuming correctly that C++ would have the same problem if you would use references (which are considered to be more sane if const) instead of pointers?
Be sure to note that all the types with grey backgrounds are currently impossible, but would be enabled by the DST proposal (http://smallcultfollowing.com/babysteps/blog/2014/01/05/dst-take-5/).
Whoever made this should be given some sort of award for actually having meaningful rows and groups in a "periodic table" graphic.
Nice chart! Closure types could fill their own chart unfortunately. For starters there's three meaningful traits, not two: `Fn` (`&amp;self`), `FnMut` (`&amp;mut self`), and `FnOnce` ([`&amp;move self`][1] *) - so three rows. Then multiply that by those reference types plus any number of smart pointer types. Some combinations don't make sense: in particular, `&amp;FnMut`, `&amp;FnOnce`, and `&amp;mut FnOnce` can't be called. (The latter two are present in the chart, and should be fixed. If `Fn` is implied to mean `FnMut`, then that as well.) Unboxed closures would also make better sense in the "bare" column (more consistent with the rest of the chart) than top-level `fn`s do. Plain `fn` is equivalent to `&amp;'static Fn` in terms of semantics. \* can be approximated as `~self` for only heap but not stack once closures [1]: https://github.com/mozilla/rust/issues/10672#issuecomment-29939937 
Nice 
`Yurume` on IRC, but I don't know their reddit username.
My point is the ability to have *multiple* sets, maps and lists threaded through the same values regardless of where they are stored and without those additional containers requiring any heap allocations.
Needs to updated for 0.9… It’s complex at first glance, however it’s a pretty cool cheat-sheet. \^\^
This is true! Thanks for noticing.
How is this different from a vector of indexes (which monetized can represent a set)? It does not contain the data but point the location of data. Only one heap allocation is necessary per set, while intrusive data structures requires one heap allocation for every connection. Maybe I misunderstood you?
This is very clever and useful. I added a link to the wiki https://github.com/mozilla/rust/wiki/Docs
So many things missed... the woes of finite time. :(
My experience has always been that talking about programming because extremely confusing when `this` is a keyword, because no one can tell if you're talking about `this` the keyword or "this" the English word. So before I even joined Mozilla, I'd resolved to prefer `self` to `this` in programming language design. If memory serves me that was also the consensus within the group, but I could be coloring it with my own preferences.
Intrusive data structures don't require heap allocations. The whole point is separating containers from allocations and allowing the user to store the values *anywhere*. You can dynamically insert and remove elements from an intrusive container without involving dynamic allocation. A vector of indexes isn't at all comparable because you're still forcing all of the values to be allocated as a dynamic array to index them. Maintaining a sorted set with a vector also isn't going to have both `O(log n)` insertion and `O(log n)` removal.
An intrusive data structure in a systems language would be expected to decouple allocation from the container logic. If it's not possible to use it without allocation, then many of the advantages are lost.
A better term to be used would be "unimplemented". The chart also represents impossible data types, ones that don't make sense or are unimplementable.
Yes. C++ references, iterators, and pointers can be invalidated, whether they are const or not. std::vector&lt;int&gt; v; // (add some data here) const int&amp; r = v.back(); v.shrink_to_fit(); The last line may invalidate reference r.
Eek, I'm sorry! I should've asked first - another person posted it in IRC, so I assumed this had made the rounds already outside of Reddit.
For the closure types, I've consulted [#10124](https://github.com/mozilla/rust/issues/10124) and then got advised by eddyb on the current situation. (I think your suggestion, e.g. `FnMut`, does not appear in the issue tracker while it does make sense.) I've made sure that the proposed `Fn` traits are not settled yet and can be changed.
Don't mind! I should have used the URL like `/2014/01/super-secret-do-not-link-yet-please-contract-Yurume-on-moznet-about-that-and-yes-I-am-lengthening-the-url-at-the-purpose/blabla`...
Right. Which makes it even worse because you can override them to mean something else.
Oh! Well, that's cool. I actually like that. `Self` with a capital S makes sense to refer to the type.
How do you play Rust?
(You spelled "dereference" incorrectly, btw.)
This is down to some hard work by Chris Morgan; including convincing some other (smaller) languages to move away from the .rs extension.
So many neat things here, like that Rust is made up of 240k lines of code, and it's 93% Rust. Number of contributors is up 142% year-on-year.
What do you mean by updating for 0.9? It was newly created within the last few days.
I think you mixed up the terms "rows" and "columns" in your guide. E.g. "Columns indicate the different kind of types" seems like it should read "Rows indicate the different kind of types".
Well spotted, fixed!
I am impressed how succinctly you were able to implement this. Good job!
I shouldn't have told nmatsakis about my [env-param-removal branch](https://github.com/eddyb/rust/tree/env-et-self-no-more), now [default type params](https://github.com/mozilla/rust/pull/11217) are delayed for \*another\* week :/.
"Over the past twelve months, 296 developers contributed new code to Rust (programming language). This is one of the largest open-source teams in the world, and is in the top 2% of all project teams on Ohloh."
I don't understand. This doesn't require any allocation to add/remove (existing) items to/from a list.
Shouldn't the Raw line be 2 columns instead(raw and immutable raw)? It would make a lot of black box but it seems more natural to me : pointer types on columns, type of data referenced on lines.
I heard that @mut and others syntaxic sugar have been deleted.
Do you see any mention of `@`?
It requires the nodes to be in `@mut` allocations.
Well, you still can't call an `&amp;FnOnce` or `&amp;mut FnOnce`. Just think it through: you have an `&amp;` pointer or `&amp;mut` pointer to the environment, and calling it needs to take `~self` (or `&amp;move self`). There's no way to go from the former to the latter. Similarly, the single `Fn` trait you have listed takes either `&amp;self` or `&amp;mut Self`. If it's the former, then `&amp;mut Fn` can't actually mutate the environment, because the `&amp;mut` is frozen to `&amp;` when calling it. If it's the latter, then `&amp;Fn` can't be called because you can't get `&amp;mut` from `&amp;`. (The existing `|Args| -&gt; Ret` closure type corresponds to `&amp;mut FnMut`, and can't called through an `&amp;` or copied.) I should make a closure chart to illustrate all this. Without committing to doing it, may I borrow your HTML/CSS for it if I do? It looks very nice. :)
I've yet to be convinced that this isn't necessary.
A large part of the motivation for using intrusive data structures is avoiding memory allocation. Intrusive lists, trees, etc. in the Linux kernel and Boost don't require any dynamic allocation to use. They can be threaded through existing objects anywhere. http://www.boost.org/doc/libs/1_55_0/doc/html/intrusive.html
I still think the best approach to new features is to add them and put them behind a feature gate. That way they won't block 1.0 (there's no commitment to them), we get valuable experience about how useful they are and how well they work, and contributors don't get demotivated (important!) by being told that if they want to work on something, they shouldn't, or their already-written PRs being rejected because of some "feature slush".
&gt; like that Rust is made up of 240k lines of code Only or already?
You can simply use `self` instead of `~self` to allow `&amp;FnOnce` or `&amp;mut FnOnce`, so that the `call` method to them essentially consumes the closure regardless of its environment. I agree that `&amp;FnMut` wouldn't make much sense though, so there are six or seven possible combinations: &amp;Fn (&amp;mut Fn) ~Fn impossible &amp;mut FnMut ~FnMut &amp;FnOnce &amp;mut FnOnce ~FnOnce I'm still not sure about the distinction between `Fn` and `FnMut` though. Is there an use case that the distinction is important? Right now I can't think examples that do not involve function-like objects (which are not built-in functions but implement `Fn` etc. anyway). On the licensing: It's a horrible mess of HTML and CSS, so do whatever you want, I've added a proper licensing statement (CC-by) now :)
The problem is that in order to do it that way in rust, you'd have to be sure to remove items from their lists before deallocation and removing items means modifying adjacent items in each list. Anyway, you're trying to convince me that this is necessary in order to be useful, but don't you think that, as I wrote this code prior to seeing this thread and that I presumably wrote it for a purpose, that you might find that a difficult point to argue?
&gt; Anyway, you're trying to convince me that this is necessary in order to be useful, but don't you think that, as I wrote this code prior to seeing this thread and that I presumably wrote it for a purpose, that you might find that a difficult point to argue? I'm not trying to convince you it's required in order to be useful. I'm just mentioning that as far as I know, Rust is unable to handle half of the intrusive data structures picture without pervasive `unsafe` code. You can certainly use `Gc&lt;T&gt;` to thread linked containers through objects. The original post was looking for an equivalent to the lightweight intrusive data structures in Boost.
It already has that many lines of code. (Tests take a third of them, but the Rust compiler and runtime has definitely 100K+ LoC.)
&gt; Intrusive data structures requiring allocation aren't what the original poster was looking for. Maybe not, but I don't think that's clear from the opening post. To me, the essential nature of an intrusive data structure is its intrusiveness; that you can traverse along one list, arrive at an item, switch to another list/tree/whatever and traverse in another plane.
&gt; You can simply use self instead of ~self to allow &amp;FnOnce or &amp;mut FnOnce, so that the call method to them essentially consumes the closure regardless of its environment. You still can't move out of `&amp;` or `&amp;mut`. &gt; I'm still not sure about the distinction between Fn and FnMut though. Is there an use case that the distinction is important? It's essentially the same distinction as between `&amp;` and `&amp;mut`. One is freely aliasable and read-only, the other can't be aliased and is allowed to mutate. I'm not sure where the drawbacks of mutable closures bite really hard, but immutable closures *would* be more appropriate in many cases, for example `fn sort&lt;T&gt;(vec: &amp;mut ~[T], cmp: |&amp;T, &amp;T| -&gt; Ordering)`: it makes no sense for the comparison function to mutate its environment every time it's invoked. (It makes no sense for it to do IO either, but that's another matter.) Edit: Oh, obviously: `Gc&lt;FnMut&gt;` and `Rc&lt;FnMut&gt;` can't be called either, because their contents are shared and immutable. (`Gc&lt;RefCell&lt;FnMut&gt;&gt;` and `Rc&lt;RefCell&lt;FnMut&gt;&gt;` presumably could.) `Gc&lt;Fn&gt;` and `Rc&lt;Fn&gt;` are fine. &gt; On the licensing: It's a horrible mess of HTML and CSS, but do whatever you want, I've added a proper licensing statement (CC-by) now :) Thanks!
I dabbled with this when I created widmann (http://github.com/skade/widmann, currently not in development, because dependency management in Rust is still a pain because everything is changing all the time). So, first of all: yes, you can accept HTTP, route it and respond to it properly. It won't be a pleasant experience though, for multiple reasons: * Immaturity of the stack: expect breakages to be common in all parts you use. For example, my widmann test server threw errors every ~100 requests when it still compiled ;). Certainly things you can iron out, but irritating nevertheless. * No templating: There are currently no templating libraries that I am aware of. * No tooling whatsoever, so stuff like CSS and Javascript will be in your hands :). That really shows if you are used to it. * Lack of standard implementations, like session handling, etc. Which doesn't mean that you shouldn't attempt it. You learn a lot of stuff that you have previously "just used".
rustcvswvi is asking if brson is either surprised that Rust *only* has 240k lines of code (i.e. brson was expecting more lines), or surprised that Rust has *already* got to 240k lines (i.e. brson was expecting fewer). (Another subtlety of English. :) )
Yes! However, I don't think we should be too keen on merging things just because they sound good and are behind a feature gate... all the code goes into the same compiler, and there's already quite a bit of technical debt in some parts of the compiler.
Yes indeed. I agree that implementation complexity should be the major consideration in these cases (assuming the idea makes sense on the merits of course).
Yes. Go for example is 4 times as large: https://www.ohloh.net/p/go Is it 4 times as powerful? Their standard library is richer for sure.
Notably they've much more non-Go code, both as a percentage and in absolute LOC. Although, I imagine their rewrite of the compiler into Go will remove most of the C.
Brilliant.
It is just a reduction of syntax, it can be replaced by a library.
`AtomicRc` wouldn't be so bad.
Exciting!
There's `Rc&lt;T&gt;` (reference counted shared pointer, closer to @-pointers) and `Gc&lt;T&gt;` (garbage collected shared pointer), both in the standard library (I think they're still WIP for 0.9), similar to how C++'s `std::shared_ptr` isn't part of C++'s core language, but is in the standard library. The new syntax is slightly heavier, but it also makes it a bit easier to read code using a variety of pointer types.
I think you have the wrong subreddit - did you mean to go to /r/playrust? This is the subreddit for Mozilla's programming language called [rust](http://rust-lang.org).
Black magic indeed. It's clever, but horrendous and we should all shun its existence. :P
This worked out!
Well it is a "Request For Comment"... But yes, it's long since skyrocketed past the productivity threshold. Mailing lists can only admit so many replies before the majority of observers just can't be bothered to keep up. Here's hoping someone steps in to close it.
lol yea, i did. thanks =P
It's a cool but horrible hack like the nested for-loop in a single for statement I came up with a few years back, using the comma operator in C++: for (unsigned int i = 0, j = 0; j &lt; 4; (i == 4) ? i = 0, ++ j : ++ i) std::cout &lt;&lt; "j: " &lt;&lt; j &lt;&lt; ", i: " &lt;&lt; i &lt;&lt; std::endl; So disgustingly beautiful. Please, never use this.
Not to mention that making GC a little harder to use is a good thing: people have historically over-used heap allocated memory because it was so easy.
Can it do `break`? Even if so, `continue` will certainly not work as expected because it does not reevaluate the condition.
This is so ugly it's beautiful. &lt;3 Wouldn't you need paranthesis around the i%5 though?
Is there plans to have ~ moved to the libraries as well? (Like C++11's unique_ptr&lt;T&gt;)
Here it’s the subreddit of Rust the programming language, not Rust the game. See [here](http://www.reddit.com/r/playrust).
Is there a way for the mods to add something to the Submit page for /r/rust that points unsuspecting players of the game to /r/playrust?
It's already there.
Imagine what would happen if it wasn't... O___O
What replaces `@mut T` then?
&gt; Immaturity of the stack: expect breakages to be common in all parts you use. For example, my widmann test server threw errors every ~100 requests when it still compiled ;). Certainly things you can iron out, but irritating nevertheless. Yes, I saw the awful 0.8 → 0.9 breakage. Not a problem for me, I know Rust is not production ready. &gt; No tooling whatsoever, so stuff like CSS and Javascript will be in your hands :). That really shows if you are used to it. ? If I use PHP or Python, I still need to do the CSS and Javascript, isn’t it? &gt; No templating: There are currently no templating libraries that I am aware of. That’s underestimate awesome Rust community. See [rust-mustache](https://github.com/erickt/rust-mustache). &gt; Lack of standard implementations, like session handling, etc. Good point. I knew I forgot something. It’s a bit annoying. But as I see [here](http://webpython.codepoint.net/cgi_session_class), it’s not impossible. I don’t know how to manage session expiration though — maybe a cron to delete old sessions, but that doesn’t seems to be the right way to do things.
That’s sorcery. I didn’t understand until someone explain how it works in a comment on the gist. This code is a great demonstration of the flexibility of Rust. I like it. Even hacks looks clean in Rust, how is it possible? :p
`Gc&lt;RefCell&lt;T&gt;&gt;`
That's so beautiful, but if I ever saw that in production code... I'd slap the author with the back of my hand.
Good point, and no, `break` and `continue` don't work.
Yup; as a Rust reviewer, I wouldn't approve any patch with this in it. (Although... I might accidentally overlook it if it's just in a small test.)
Or `Gc&lt;Cell&lt;T&gt;&gt;` if you don't need borrowing from the interior.
It also has do-while-do loops: while { let x = foo(); bar(x); x != 0 } /*do*/ { baz(x); } 
Wow, I had checked before I wrote that comment and still didn't see it. No wonder, it's at the bottom of the page! If it was at the top, in place of the yellow/orange banner, that would be more noticeable.
Yeah, it's rather hidden at the bottom... I tried to put it at the top, but I couldn't work out how to do it.
They could be implemented as a library, but they're used often enough that giving them syntax makes sense. There is discussion about changing the `~` to `box` though.
I wouldn't think so as they relate specifically to the borrow checker. 
(And if your type is `Pod`)
Why does the List `struct` have a member of type `Node`, instead of `~Node`, or `Option&lt;~Node&gt;`?
Just use a macro :P
Value should be T and not ~T (if the user wants the value to be an owned box, they can put the ~T themselves). onValue should be on_value. You probably need to have a way to remove observers, figure out whether/how to support concurrency, and probably use weak references to or inside the observers, which are the hard parts. 
Idea was that some of that bikeshedding could spill over here. Let redditors take the burden of bike-shedding.
`TcpStream.read()` takes `&amp;mut self` because the underlying calls into C can (and IIRC do) mutate the socket object. Using `&amp;self` lets the optimizer make certain changes with the understanding that `self` is immutable. Since `self` isn't immutable, those optimizations usually end up causing segfaults. Source: I implemented this IO code over the summer and spent a very frustrating day trying to make `read()` take `&amp;self` instead of `&amp;mut self`.
I agree to an extent, but it may be nice to have uniformity in having all pointer types in the libraries.
Dare I ask what a 3-depth version would look like?...
It's proof: Rust is better than C++!
Ah, but that will be self-documenting and easy to understand. The two *worst* properties a good piece of code can have. ;P
Well, you won't get borrowed pointers as a library, so it won't ever be 100%...
Redditors are great at that ;)
Strength in numbers I always say.
Terrific! Thanks for continuing to share your results! Would it be possible, I wonder, to include one or two other languages' implementations in the charts? While we're not yet quite up to C++'s speed, it'd be fun to see how we compare to some higher level languages with respect to Cap'n Proto.
It occurs to me that it'd be interesting if someone implemented the Protobuf version of the benchmark in Rust.
Ahh, that's helpful.
I think I'm misreading the two sets of charts -- it appears that the Python takes between .030 and .035 seconds to run the 'object' version of catrank 'bytes', but C++ and Rust take between 0.8 and 1.0 seconds? Could you help me identify where I'm going wrong? Or are there other differences between the benchmarks?
That'd do it! Thanks.
&gt; My thought on using '~' was to make sure the observer was the only owner of the value There is no difference between ~T and T in terms of "ownership". There is in fact no semantic difference at all in safe code, except that you must use ~T if the T is a trait or an array, or if defining a recursive type, since the size in bytes of T is unbounded and dependent on the actual value in those cases. 
I don't know how far you're willing to go with this project, or even if Rust has support for datagram sockets. In essence, you open up a long-running server on your machine and it receives and sends data from the socket (it's a unix system construct). This is the way php-fpm works, if you're familiar with it. As to the relevance - when you have the persistent server, you can just invalidate old sessions on a timer, or even set up a new timer with each new session that will destroy it after a period of inactivity. 
Rust syntax is not easier. What do you mean by flexibility and use? What are you trying to build? Games? Windows apps? Web apps? Distributed systems? Without more information to go on, my suggestion is Python / Go. Possibility Java depending on use case.
C# is an easier language to use, so... Rust is probably not what you want.
I think you don't even need a closure, as you can define functions within functions if I'm not mistaken!
I think both are fine. Rust does not necessarily try to reduce indentations, and you can find some examples of severer indentations in librustc. Moving `cell_value` into a closure does have an effect of refactoring and is not bad to do so, though. You can iterate over each items in the vector: `for &amp;i in some_vector.iter() { ... }`. An explicit `iter()` is required since there are several modes of iterations, including `mut_iter()` and `move_iter()` in this case.
Closures can have environments while functions can't. `prevg` from the outer environment is used so it should be a closure.
Hmm, I wonder if Rust should try and reduce indentations.. severe indentations I would hope should be avoided! Thx for the feedback!! My goal for iterating, would be to remove the explicit for loop all-together, replacing it with a function that performs a fn 'foreach' element the vector iterator returns.
I don't think that the change was an improvement. Something that I think *would* be an improvement, on the other hand, would be making the style conform more closely to standard Rust formatting: `{` not on its own line and using four space indents, for example.
The { on it's own line I can get behind, I was just trying it out.. I'll go take a look at the compiler, make sure I'm emulating { placement, as well as return value placement. Thanks
It is documented [here](http://static.rust-lang.org/doc/0.9/std/gc/index.html) and [there](http://static.rust-lang.org/doc/0.9/std/cell/index.html). The tutorial also mentions `Gc` and `Cell`, though it is a bit vague about various use cases.
It's not as bad as I thought it would be.
Don't look at the compiler as a source of style guidelines! It's *horrible*. On the other hand, libstd is usually pretty good.
Thanks, for your explanation. I'd misunderstood "Copying an owned box is a "deep" operation" from http://static.rust-lang.org/doc/master/rust.html#pointer-types Do you know why the last statement is problematic? It causes a seg. fault. on my machine. Or is it because of the issue caused by previous statements?
&gt;Everything that is syntactically legal that the compiler will accept will eventually wind up in your codebase. --John Carmack
You are very right, I didn't see that. Thanks!
If you only want to be able to what C# does and you want a simple syntax then Go is probably what you're looking for. If you were looking for an alternative to something more powerful than C# eg C++ then rust would be a good option.
As far as I understood there should be a compiler error at line let ax : ~int = a.x; Since a is already borrowed, it cannot be mutated (as a move in the next line does).
Minor thing, but it looks like the old grid data is being copied before it's being written over which is not necessary. Also it's being mutated in place when it could be created in one expression without (visible) mutation, using nested vec::from_fn() calls. E.g.: let new_grid = vec::from_fn(num_rows, |row| vec::from_fn(num_cols, |col| ...value created from old grid)) As for spaces, I always thought 4 was excessive myself. I'm toying with the idea of settling on 3!
`loop` is still valid because apparently a lot of people really enjoy an explicit construct for infinite loops, rather than just using `while true`.
The point of an owned pointer is that only one piece of code owns it at any time. Two names cannot bind to the same unique/owned pointer at the same time. let pa = &amp;a; This moves/borrows the stack pointer to `a`. So at this point you can do `*pa.x` and `*pa.y` without issues. The problem is actually not on the "should be an error line", but this line: let ax : ~int = a.x; Since `a` has already been borrowed, we should not be able to borrow it's fields. Otherwise, we can dereference both `ax` and `pa.x`, which is supposed to be impossible with owned pointers. Take a look at the failing test that was added, it fails at that step, not the last statement: https://github.com/mozilla/rust/pull/11465/files#diff-6ccc1656cc9cca8315c202ccdb627a38R25
One part of the solution will be the `Deref` trait. Another part might be typedefs and helper functions.
It also helps the compiler reason about the loops, for example let x; loop { x = 1; break; } println!("{}", x) is perfectly valid, while let x; while true { x = 1; break; } println!("{}", x); fails to compile with "use of possibly uninitialised variable" pointing to the `x` in the `println`. In the second case, the compiler is not detecting that the body of the loop will always run at least once. (Of course, we could special case the construct `while true` to act like `loop` does now. I believe this is what Java does.)
That's pretty cool :). Really need to find sometime to dive into rust.
Please do it. Lots of newbies use ~T unnecessarily because it's so "simple". Of course this must only be done after the deref traits are introduced, and the compiler accepts the same code that would work with ~T. 
2 is the natural evolution! :P I kid.. Thanks for the nested vec::from_fn()! I was trying to remove all mutation, this is great!!
This also makes collection types (ref-counted and mark-sweep) *orthogonal* to the other pointer types. That means you can have owned+gc and borrowed+gc types; that wasn't possible with '@' if I recall correctly.
Maybe I'm just weird, but after it clicked it seemed perfectly okay to me.
and the logical follow-up, applying the same ideas! Goodbye mutable state! I'm actually having a lot of fun with this lol https://github.com/ShortStomp/ConwayGameOfLife-RUST/commit/440c00cae814671434032a81d345c4643284782c
This is not the subreddit you’re looking for. /r/playrust
This is getting annoying, but it's kind of hilarious.
I'd be interested to see the compiler flags used with each implementation. And was the C++ version compiled with GCC or Clang?
Looks good! PS: You might also be on a first name basis with your friend std::vec, by putting "use std::vec;" at the top and then just calling it "vec". :) 
Thank you for your explanations, I forgot that `FnOnce` does require movability. Though I think, for your `sort` example, there is actually a good use case of `FnMut` for [generating an advesarial input](http://www.cs.dartmouth.edu/~doug/mdmspe.pdf) ;) The table has updated to reflect some of your points (not all since it does not have `&amp;mut Fn` etc, it would involve the relabeling of rows) so please check it out.
&gt;Since `a` has already been borrowed, we should not be able to borrow it's fields. not able to borrow its fields or move/modify its fields? * if former, then as soon as I use the borrowing `&amp;` operator on any object, I lose my ability to modify it by directly accessing its ident, right? (I thought `&amp;` gives you a pointer to access a memory owned by others with the promise/restriction of not being able to change it, so we can access the content of object without paying for copying overhead.) I am confused, I need to re-read the docs :) Thanks for your comment. 
I think this has sequence point issues. Perhaps this: `j += !(i = ((i + 1) % 5))`?
Can this be chained forever?
You can see the flags in the Makefiles, for [Rust](https://github.com/dwrensha/capnproto-rust/blob/master/Makefile) and [C++](https://github.com/dwrensha/capnproto/blob/benchmark/c%2B%2B/src/capnp/benchmark/Makefile). The C++ version was compiled with Clang.
indeed, we can also use this alternatively : ++i, i%=5, j += !i or even those ( not sure if it's ok) : ++i %= 5, j += !i j += !(++i %= 5)
Purely for my own curiosity, does changing `-O` to `--opt-level=3` have any effect on the Rust code? I'm perpetually curious at how much of an effect these levels actually have for us.
All your alternatives modify `i` twice, so they have sequence point issues as well.
We need a rustfmt
I see no significant effect. The differences are within measurement noise.
`rustc --pretty`
I can't tell if the explicit 'std::vec' in-front of the from_fn() call is a good idea or not. Maybe I'm just to used to C++
Something to keep in mind is that `Gc&lt;T&gt;` is currently based on reference counting and those cyclical links will cause the whole structure to leak. The only way to write a cyclical data structure without leaks at the moment is `Rc&lt;T&gt;` and `Weak&lt;T&gt;`.
What's the reason for wanting to write `foo.each(|| { body })` instead of `for x in foo { body }`? The closure will result in more restrictive type checking since it's capturing and borrowing an environment rather than existing as part of the existing scope. For loops are intended to be *the way* to iterate.
What does "easier syntax than C#" mean? If you can't learn the C# syntax, you aren't likely to be able to be proficient in programming in any language. If instead would prefer a language that is smaller and more elegant than C#, then Rust fits those requirements, although it's a different kind of language. Alternatively, Scala is the most elegant language in the same space as C#. 
This is seriously one of the coolest PRs I've seen. Time to get crackin' on LINQ syntax for rust. ;)
Woohoo!!
Yeah, I was a bit joking about that. I think your point with `Gc` and `Rc` is compelling enough to separate `Fn` from `FnMut`.
Values aren't immutable exactly. Whether or not something is mutable depends on what's holding it. A struct held by a variable is immutable, a struct held by a mut variable is mutable. A struct held by an owned pointer in a mut variable is mutable. etc. So you can create something using mutation and then move it to an immutable variable, and that works fine, for example.
This won't work for a cycle. Constructing a cycle always needs some form of inner mutability, e.g. `struct Foo { x: Gc&lt;RefCell&lt;Foo&gt;&gt; }`, or otherwise there is no way to actually put a reference to a value into itself.
What if I use only private properties and only expose an immutable interface?
Oh, cool :)
Lazy evaluation is implemented on top of *mutable* thunks. The mutability is abstracted away, and you can do the same in Rust.
Delimiters have to be matched inside macro invocations, otherwise they're way, way harder to parse.
Yes, that's a good point. I think it's important to understand that the values may be mutable or immutable, except that there are no public fields to mutate in that case; and everything with access to the private fields happens to never take a mutable pointer to the object (or does take a mutable pointer to it, but doesn't do anything with it.)
Gulp, I didn't think before I spoke. It's too easy to answer lazily. Thanks for the correction.
Yeah, I guess you only need to be able to take an `&amp;mut` to the whole structure, and after that the borrow checker can see which parts of it are disjoint. So it's not a question of expressiveness so much as convenience. Could this sort of thing be *inferred*, or is it unavoidable that, using a library `My&lt;T&gt;` instead of built-in `~T`, my example would have to be rewritten to make the `&amp;mut` borrow explicit? (We can assume the existence of `Deref` and whatever other smart pointer related language features that are planned.)
I would say it's a proof that Rust is not as clean as it intend to be.
There was an [issue][1] for this which got closed as wontfix. I'm still hopeful that a solution might be figured out someday. (To be clear, that issue was for doing it with plain, strict, immutable garbage collected values - if you allow yourself `(Ref)Cell` and `Option` you can do it today.) [1]: https://github.com/mozilla/rust/issues/7082
For the most part it is, but when you delve deeper into things like select many statements and let statements where you need to start building up an environment of in-scope variables in order to generate the appropriate method calls it gets much trickier.
brson and I attended a similar talk at OSCon last year, and we both liked it a lot. Some of the lower layer of Mirage is written in C, and they are considering whether Rust would be a safer replacement.
I think you have the wrong subreddit - did you mean to go to /r/playrust? This is the subreddit for Mozilla's programming language called [rust](http://rust-lang.org).
Rosettacode perhaps? More algorithms than cookbook. Not sure if it's up to date.
That's a bit of a silly criticism. It's a benign combination of two language features, and it would be much less "clean" and much more of a cognitive burden to arbitrarily restrict what could appear in the expression position of a `while` loop. Not only that, but people would *still* find ways to subvert your rules. Here, behold as I implement one of /u/next4's `do`-`while`-`do` loops in Python! x = [1,2,3,4,5,6] while [eval(i) for i in [\ "x.pop()", "exec('y = sum(x)')", "print(y)", "len(x) &gt; 0"]][-1]: #do: x = [i*2 for i in x] #output: #15 #20 #24 #24 #16 #0 ...and if you're going to say that this is proof that Python is not as clean as it's intended to be, I wonder what languages *do* meet your criteria for cleanliness. :)
It could be improved quite a bit, but the basics are there.
There would be if I had more time :(
Some really awesome PRs landing this week. Keep up the great work!
I'd love to have documentation like this and would be happy to take it in the main repo in order to keep the code up to date. This type of thing is *perfect* to do collaboratively since every bit is self-contained. Somebody should lead an effort on the mailing list. Likewise, our ['cheatsheet'](http://static.rust-lang.org/doc/master/complement-cheatsheet.html) can also be beefed up piecemeal as a collaborative effort.
Anil is a really engaging guy that we've talked to a few times. The types of exokernels he's building seem very appropriate for Rust and I'd love to see some Rust experiments along these lines.
If you want C# but easier go buy a Visual Basic.Net book
That would be great! ML all the way down. :)
Yeah i would love this also, my development on gcc rust has gone quite slowly last 2 months because i am spending so much time doing trial and error on learning the language and the only real reference is reading libstd. I think its been a real eye opener into language design though because holy crap under the hood rust is amazing.
I would loooooove a Rust exokernel. Back in college my friends were writing one in D...
This is deceptively exciting, especially for people like me who love writing succinct code snippets. AFAIK (I'm still compiling) it should mean that the following finally works: for num in [1,2,3].iter() { /* party */ } Previously we required you to stuff the array into a temporary variable, because the compiler had no idea how long a literal like `[1,2,3]` should live for. Hooray Niko!
There is ongoing work on getting Rust samples of the remaining Rosetta code tasks, feel free to peek here: https://github.com/Hoverbear/rust-rosetta
FYI there are docs for libstd: http://static.rust-lang.org/doc/master/std/index.html
Making things harder to use in order to force discipline on newbies is a philosophy that leads down the path of Java-style BDSM programming. I'd honestly prefer Rust to be a language that primarily aims to make life easier for those programmers who generally know what they are doing.
I remember reading about that, makes sense that something like this hasn't happened yet. I'm just very excited about Rust and was hoping to jump on something like this to study.
Specifically embedded in Rust? Well, we now have an `Any` type for dynamic typing.... ;) There's been lots of work of embedding Rust in Ruby, but little in embedding Ruby in Rust. I think Lua would be a fine choice.
That's really interesting. I see there was a [brief mention](http://blog.xen.org/index.php/2013/07/31/the-xen-project-at-oscon/) of this on the Xen community blog.
Ruby and Python are out because they have too much global state in the interpreter.
We just need someone to adopt that feature, fix the problems it has and update it in line with current styling, then it should promoted to a first-class feature.
I went to a talk by Walter Bright, where he was talking about the expressivity of D's equivalent of typeclasses / concepts and how it lets you write pretty expressive code. He mentioned as a side note that a big gaming company was moving from C++ and Lua to D - they were happy with writing performant D to replace the C++ and expressive D to replace the Lua. That seemed like a substantial win. I'd love it if Rust was / gets to the point where it is expressive enough such that it was it's own best scripting language. I'm not sure if how the explicitness of ownership and lifetime would effect that, and I think higher kinded types would help tremendously. 
I'm wary of any article at this point that predates 0.9, but the information still appears to be largely correct. Spotted a syntax error though: struct Pod {x: int, y: uint, z: [3... int]} should be: struct Pod {x: int, y: uint, z: [int, ..3]}
Indeed, the purpose of embedding a scripting language in your application is to make it easier for users who are not professional programmers to add custom behavior. In this sense, a scripting language should be conceptually small, easy to use, and easy to learn. Unfortunately, our modern "systems" are all sufficiently complex enough that they place a lower bound on how small and easy a language can be while still calling itself a "systems programming language". For a casual modder or an artist/level designer, proficiency in Lua is doable. Learning D or Rust in its place would be a relatively enormous undertaking.
I think it's great that so many people in the community are hammering on this issue. It frees me up to write about other things :) Seriously though, it's good stuff. And after grokking Ownership and Lifetimes, the eager Rust Novice's the next step is to face the trial of arguing in #rust with strcat about copy semantics.
Rust can't be a scripting language by definition. But yes, `@` is going to be removed. It's replacement will be more powerful (`Gc&lt;T&gt;`).
Lua is the only choice unless you want to do a tons of work yourself to write bindings. What is your actual usecase, though? In some of the other comments there seems to be significant confusion as to what a scripting language actually is. And it *is* a really conflated term, with no real definition. So what do you want? Lua is an embeddable, extensible language, Javascript isn't, and Julia is a compiled language.
Initially Rust has the @ syntax for managed memory, that is convenient. I knew the motivation of removing it, but I just miss the convenience of @. I hope it can be a sugar for optional GC in stdlib. Currently, I think the syntax is verbose. For instance, to create a mutable Gc managed memory, I need something like Gc&lt;RefCell&lt;T&gt;&gt; or Gc&lt;Cell&lt;T&gt;&gt;.
chibi-scheme!
A typed racket or typed clojure style lisp would be pretty amazing IMO.
I hope we never regain `@mut`. Too much implicit (and expensive) magic to obey the borrowing rules. RefCell at least makes it easy to see the cost. The type will probably never get shorter, but usage will with pointer sugar.
Wait a few hours and I can put a clone of the project on Github, I have enough time at the moment to do quite a few of them as well as manage contributions. I'm still pretty new at programming with rust but exercise is the best form of practice! --EDIT-- So I've created a repository on github: https://github.com/cjschneider2/rust-by-example Contributions and feedback is welcome! I'll be adding more thought the weekend but I wanted to get it set up so other people could contribute if they were interested.
Nice one. I added it to the wiki: https://github.com/mozilla/rust/wiki/Docs
I'd like to see experiments in new dynamic languages designed to be complementary to Rust's memory model. I don't know what that would look like, but surely it would be different from existing dynamic languages (as Rust is different from existing statically-typed languages).
Well, MRI and CPython do. I don't know what the situation is with embedding other implementations of these languages such as PyPy.
[Squirrel](http://squirrel-lang.org/) is one scripting language specifically designed for embedding, heavily inspired by Lua. I haven't actually used it yet, but it is on my list of thing to try out.
which mailing list would that be?
My main ideas for projects in Rust involve using it partly as a scripting language. Developing and compiling a well thought out library with high level abstractions, and then using the library in small scripts with a Rust interpreter shebang at the top. Example programs where I imagine this type of approach could work are [PIN](http://en.wikipedia.org/wiki/Pin_%28computer_program%29) and [pydbg](http://pedram.openrce.org/PaiMei/docs/#pydbg). The main consumer would be someone who is expected to know how to program. I know rusti is broken at the moment, but doesn't this approach make sense to anyone else? Are there features in the language (pointers/lifetimes) that makes this sort of approach unsavory in a post-1.0-world? Rusti will likely be back in the future when the language has stabilized right?
*Here's a bit from linked Wikipedia article about* [***Pin (computer program)***](http://en.wikipedia.org/wiki/Pin%20%28computer%20program%29) : --- &gt;**Pin** is a platform for creating analysis tools. A pin tool comprises instrumentation, analysis and callback routines. Instrumentation routines are called when code that has not yet been recompiled is about to be run, and enable the insertion of analysis routines. Analysis routines are called when the code they are associated with is run. Callback routines are called when specific conditions are met, or when a certain event has occurred. Pin provides an extensive application programming interface (API) for instrumentation at many abstraction levels, from one instruction to an entire binary module. It also supports callbacks for many events such as library loads, system calls, signals/exceptions and thread creation events. --- [^(about)](http://www.reddit.com/r/autowikibot/wiki/index) ^| *^(/u/tr0mb can reply with 'delete'. Will also delete if comment's score is -1 or less.)* ^| ^(**Summon**: wikibot, what is something?) ^| [^(flag for glitch)](http://www.reddit.com/message/compose?to=/r/autowikibot&amp;subject=bot%20glitch&amp;message=%0Acontext:http://www.reddit.com/r/rust/comments/1vhcwm/what_scripting_language_with_rust/cesmd91)
Thanks!
There's [a link](https://mail.mozilla.org/listinfo/rust-dev) under discuss on the sidebar.
There's docs for all the core crates and the tutorial/manual/guides listed here: http://static.rust-lang.org/doc/master/index.html
Very cool! (The `std::...` function names below are all links to the docs, in case the stylesheet is disguising them for anyone else.) FWIW, the `src/raw.rs` module is entirely unnecessary: the bindings are already written in `std::libc`, e.g. [`std::libc::mprotect`](http://static.rust-lang.org/doc/master/std/libc/funcs/posix88/mman/ffi.mprotect.html) (note that this function is defined in a deeply nested submodule but, like everything in `std::libc`, is re-exported at the top level), and the constants are also available. *And* there's actually better interfaces to mmap (in the form of [`std::os::MemoryMap`](http://static.rust-lang.org/doc/master/std/os/struct.MemoryMap.html), although I don't think it includes explicit support for `mprotect`), and `memcpy` should be done via either [`std::ptr::copy_memory`](http://static.rust-lang.org/doc/master/std/ptr/fn.copy_memory.html) or [`str::ptr::copy_nonoverlapping_memory`](http://static.rust-lang.org/doc/master/std/ptr/fn.copy_nonoverlapping_memory.html), or even [`std::vec::bytes::copy_memory`](http://static.rust-lang.org/doc/master/std/vec/bytes/fn.copy_memory.html) (this last one would work especially well if `MemoryRegion` provided a method like `unsafe fn as_mut_slice&lt;'a&gt;(&amp;'a self) -&gt; &amp;'a mut [u8]` that let the region of memory be viewed as a slice of bytes). &gt; Tip: A * defines a raw pointer. Thus, it's equivalent to C pointers. It's slightly more subtle than this: `*T` is equivalent to `const T*` in C, and `*mut T` is equivalent to `T*`. This distinction allows bindings to assist programmers in doing the right thing, because `&amp;T` will auto-coerce to `*T` but not to `*mut T`. Hence, external functions that modify their arguments should take `*mut T`, or you can accidentally end up with an immutable local variable like `let x = 1;` being modified by an FFI call, e.g. extern { fn increment_argument(x: *int); } let x = 1; unsafe { increment_argument(&amp;x) } // the immutable `x` is now 2! The correct form would be extern { fn increment_argument(x: *mut int); } let mut x = 1; unsafe { increment_argument(&amp;mut x) } // notice all the extra `mut`s, it's clear (to both compiler and programmer) that modifications happen One could argue that FFI is unsafe anyway and so this is unnecessary, but one might as well use all the tools the compiler provides to avoid mistakes. (The stdlib is particularly bad with incorrect mutability in FFI bindings, but rust-bindgen acts correctly: `const` pointer parameters become `*T` and non-`const` ones become `*mut T`.) &gt; We also return an owned pointer of MappedRegion if the function succeeded. We could've returned the instance by value, but we'll need to pass this around to multiple functions, so we want to reduce copying. `MappedRegion` is 2 or 3 words, so one is not going to notice a performance difference from the extra "copies" of passing it around by-value, but there are the fundamental performance problems of an allocation and the loss of data-locality of a heap pointer, so the direct form is probably slower. If you think you need `~` for performance, you almost certainly don't, and when the structure is tiny you definitely don't. (Basically, benchmark.)
&gt; Structures larger than one machine register (basically &gt; uint for all supported architectures) are always passed by reference. Yes, but they're copied into new alloca's before being passed, [as demonstrated by this gist](https://gist.github.com/huonw/b7571a7b5998bfc7b9ac) (compiled with `rustc -O --emit-llvm -S`, [line of interest](https://gist.github.com/huonw/b7571a7b5998bfc7b9ac#file-gistfile2-ll-L16)). (In any case, to allay fears of the word "copy" and a call to memcpy: LLVM lowers that into two `mov` instructions, i.e. very cheap.) &gt; The reason you'd use ~T (when you don't have to) is not performance, but reducing memory usage. Yes, maybe, but that's not at all relevant to this discussion when it was stated that `~` was for performance, to reduce copying.
The "interpreter" was just LLVM's JIT-compiler compiling a rust crate and executing it. It was just like AOT except it was slower. rusti was a repl, not an interpreter. it still had to compile things. I really don't think this makes sense. Rust is made to be at the bottom of the stack, not the top.
&gt; Currently, as far as I'm aware, the Rust compiler must compile itself 3 times, including, but not limited to: LLVM, libuv. This is incorrect. The compiler + stdlib are bootstrapped, but not LLVM and libuv. They are built once.
This was really well written, it is obvious you put a lot of effort into it!!
This is probably what he meant, just it's not clear from what he wrote. I.e., The rust compiler must compile LLVM, libuv once, and itself 3 times. It's actually quite hard to write it so that it's explicitly clear, how many times everything is compiled.. 
Awesome, thanks for the pointers. Yes, the raw interfaces are pointless. &gt; and memcpy should be done via either std::ptr::copy_memory or str::ptr::copy_nonoverlapping_memory Ahh yes. This is where I had some weird bugs. For some reason the contents weren't the same in the mapped memory as the vector. This gave me constant bus errors and segfaults. I'll probably try it again considering I have a much more cleaned up codebase than before. &gt; std::os::MemoryMap Awesome, I didn't know about this. &gt; It's slightly more subtle than this: *T is equivalent to const T* in C, and *mut T is equivalent to T*. This distinction allows bindings to assist programmers in doing the right thing, because &amp;T will auto-coerce to *T but not to *mut T. Hence, external functions that modify their arguments should take *mut T, or you can accidentally end up with an immutable local variable like let x = 1; being modified by an FFI call, e.g. Makes sense. I had a feeling I was missing a `mut` somewhere. &gt; MappedRegion is 2 or 3 words, so one is not going to notice a performance difference from the extra "copies" of passing it around by-value, but there are the fundamental performance problems of an allocation and the loss of data-locality of a heap pointer, so the direct form is probably slower. Yeah, that would be better. Considering the copy would be extremely minimal, and I could've just borrowed the structure to the other functions with `&amp;` instead. I'll update the article with the improvements.
Yes, that's correct. I went under the assumption that if the first byte is correct, everything else should be. Now, this was true in practice, but it might not be. The safest way would be to check every byte correctly. I'll probably add a notice to the article about this.
PyPy cannot be embedded right now at all.
BTW, a consequence of the `*T`/`*mut T` distinction is `memcpy`'s first argument should be `*mut` and `mmap` should return `*mut u8`.
It was updated for 0.9, and so is not ancient.
"We can create an owned pointer by taking the address of something with the address-of operator &amp;." This should read "borrowed", not "owned". Additionally, "C/C++ references" is an incorrect term; only C++ has references.
I also look forward to such languages. Do you think something like ClojureScript but targets at Rust is possible, or worth to try?
Rust's compilation model really isn't compatible with "recompile part of it". I suggest not using Rust this way, there is only pain and unkept expectations down that path. Rust has lots of goodies, but its focus is on *safe no-overhead performance*. I think any other safe, more functional language would be more appropriate. You bring up Scheme, which I think is a fine choice :)
Oh hi! Just a little thing: I think `jit_func` should be marked `unsafe`. That's because you can make the program segfault by passing it garbage input. I'd suggest also doing a bounds check in `safe::memcpy` for the same reason. There's also a potential dangling pointer bug in there: it's possible to deallocate the memory map while still holding a reference to it via the function pointer. A complete fix would involve lifetimes though, which might be out of scope (excuse the pun) of the tutorial.
Hey, &gt; Just a little thing: I think jit_func should be marked unsafe. That's because you can make the program segfault by passing it garbage input. I'd suggest also doing a bounds check in safe::memcpy for the same reason. Ideally, the high-level API that would wrap around a JIT compiler would be safe, whereas the inner workings are not safe. That was kinda my goal for not making the entire jit_func function unsafe. However, this is a rather simple JIT compiler. Having an API like LibJit would make it much better. There definitely should be checks in multiple of those functions (especially memcpy) to make sure the memory address is valid and of the correct size. &gt; There's also a potential dangling pointer bug in there: it's possible to deallocate the memory map while still holding a reference to it via the function pointer. A complete fix would involve lifetimes though, which might be out of scope (excuse the pun) of the tutorial. Yeah, I've ran into that one. I decided to keep the article fairly short, but those details are definitely important. I wouldn't tag that program as correct in any sense, although getting to that point is the goal. 
Wrong subreddit.
Just got the wipe on, if you had an avatar that had shit... it's still there. You just need to build up a new base 
/r/playrust
Yes! Rust is not JS or Python c'mon. I think `~` should stay as a primitive, easy-to-use symbol.
It was not saying that Rust is a bad language just because of this, It was a joke answer to the dbaupp joke. I do like Rust. I know this behavior is a consequence of the fact that everything is an expression, which is a great feature indeed. I was just pointing that you can do unclean things even with languages targeting to avoid it.
Quick question about the example of the for loop over a list literal: why can't the compiler automatically use value.iter() if the loop value doesn't possess the Iterator trait but it does possess an .iter() method that returns an Iterator? Is such magic considered undesirable for some reason? 
`for` expansion happens during parsing, long before typechecking. Sounds like you want the future `Iterable` trait (which does exactly that). If we can make one that works, we will probably use it for `for` loops.
There's [an issue for it](https://github.com/mozilla/rust/issues/10090) but alas, [no consensus to implement it](https://github.com/mozilla/rust/wiki/Meeting-weekly-2013-12-10#enum-mod).
(Note that strongly typed is unrelated to scope)
I guess the "real" reason is because they pull double duty as enumerations and algebraic data types. There isn't really a good choice here, as either way has pros and cons. The ideal is to allow both, as has been proposed. 
Thanks, exactly the kind of links I was looking for. This is the only thing that bugged me with the language for now, I can live with that. :)
I suspect you're confusing rust the programming language with something else.
That's right. The scope is mandatory only for the strongly-typed enum, though.
Interop between two languages with different syntax and semantics is a pain, though. There may be only pain down the path of using Rust for more dynamic things, but if someone writes the right tooling, there might not be. Look at ghci for Haskell, for instance...
&gt; they pull double duty as enumerations and algebraic data types. That's not really an issue if you could do this: pub enum Option&lt;T&gt; { Some(T), None, } pub use Option::*;
As the other comments have mentioned, this was part of the original designs for external iterators, which is still blocked on the fact that `for` loops are currently implemented as a bit of a hack. Once that's resolved, I imagine that the devs will need to evaluate whether they still think whether such automagic is desirable.
This forum is about a programming language, not a videogame of the same name.
/r/playrust
It would probably have to look something like this to pass on the type parameters to the type constructors: pub use Some&lt;T&gt; = Option&lt;T&gt;::Some; pub use None&lt;T&gt; = Option&lt;T&gt;::None; pub enum Option&lt;T&gt; { Some(T), None, } There have been legitimate concerns though about implementing types embedded in paths, specifically in regards to a `T::f()` syntax for accessing associated functions from a `Trait` impled on type `T`.
Is it because Java's import are not specific enough?
More because Java's imports are freakishly huge. There is a Pimp my Car joke somewhere. I heard you like imports so we made your imports longer than the longest German words.
just tried this in windows and it does not print anything in the end (it looks like it exists without blocking and waiting for the result on the recv()). rustc.exe 0.10-pre (0e6455e 2014-01-1 9 18:21:39 -0800). EDIT: no, it actually works for lower values of N (e.g. N=500) but crashes silently for N=1000 or more
That code break when built with LTO. Filed as https://github.com/mozilla/rust/issues/11683
Without `-Z lto` that doesn't cause a SIGILL for me. Just a ton of task failures because of "receiving on a closed channel".
Weird. I submitted from my phone. Might be a bug in the app I was using.
Isn't it actually normal since as far as I know optimization isn't priority at this stage of Rust's development?
Usually Rust is within C++ performance, if it's performing this much worse than Go, I don't think it's performing as good as C++. It could be either that code was written naively, or that Rust has a performance problem with channel due to some bug.
The Go implementation is using a single thread without any synchronization. The channel has no capacity, and is doing a context-switch on a send, and then a context switch back on the next receive. The Rust implementation is spread over multiple threads, and is using unbounded queues built on linked data structures (inefficient) with atomics for synchronization between the threads. &gt; first class channels They're no more first-class than they are in C++ as they're entirely a library feature. &gt; Since Rust tasks are lightweight, I wanted to test whether Rust would behave similarly. They're not lighter on resources than OS threads.
Sorry, it wasn't letting me edit this comment so I posted it again. &gt; But what would the canonical code for this kind of program be? It doesn't demonstate a pattern you would use in Rust. Rust tasks aren't a substitute for generators/iterators and they're not around as a control flow feature. &gt; Is improvement of performance of such task expected? I'm not sure what it's attempting to measure. To compare the performance between languages, you provide an input and have the program compute the expected output. The implementation will likely vary between languages based on their idioms.
&gt; Isn't it actually normal since as far as I know optimization isn't priority at this stage of Rust's development? It's a demonstration of performance issues in the design and implementation of the standard library. The language is already performing fine and optimization has been and continues to be a focus.
&gt; Usually Rust is within C++ performance, if it's performing this much worse than Go, I don't think it's performing as good as C++. C++ would be much slower than Go here too, if it was doing the same thing as the Rust code and not the Go code. &gt; It could be either that code was written naively, or that Rust has a performance problem with channel due to some bug. It's comparing a single-threaded Go program using unsynchronized channels with no capacity to a multi-threaded Rust program using channels implemented as a linked data structure with atomics. Unlike Go, Rust's channels are a library feature and not an intrinsic property of the language. They are not meant to fill every need.
&gt; It's comparing a single-threaded Go program using unsynchronized channels with no capacity to a multi-threaded Rust program using channels implemented as a linked data structure with atomics. Well then it is written naively ;) Still if new programmers pick this language, write a code in it naively and don't get decent performance, they might leave. Has the "UX" of language and the eco system been considered?
It seems like you saying that Rust should only offer functionality that *can't* be misused to give poor performance, which is impossible.
&gt; It seems like you saying that Rust should only offer functionality that can't be misused to give poor performance, which is impossible. Not at all. I'm saying we should figure what the closest tool for the job shouldn't be the one that will turn them off. It may be impossible to achieve that, but that is another story. 
Well, the example in the blogpost is basically catered perfectly to Go &amp; its goroutines, so if someone does need that sort of performance for that sort of task then Go is actually the language they *should* be using. Rust has different goals.
I don't think the fact that we use atomics even in single-threaded mode is a design problem. I don't see any value in Go's optimizations for real-world use; optimizing for single-threaded performance in 2014 is pretty silly IMO.
&gt; the standard library would provide bounded array-based queues It will, according to the latest proposal.
The linked list allocations are cached so they won't allocate in most cases. This is why Rust channels are typically just as fast as Go channels.
I wouldn't more it to the lib either. It is too fundamental. Removing @ makes sense on the other hand, because you might want to specify the management model (like Gc&lt;T&gt; and Rc&lt;T&gt;) which would require another pointer type otherwise... :) I'm unsure about box...maybe to verbose. ~ is easier to read.
Memory locality is the problem. It uses significantly more space for each element and they're spread out.
I profiled this and found that the vast majority of the time was spent allocating stack segments. So the basic problem is that this benchmark is simply tuned for segmented stacks. An implementation that does not use segmented stacks will do worse on this benchmark. We've rejected segmented stacks because they don't perform well in the real world (and hurt many other benchmarks), but they do make this benchmark fast. The debate on M:N versus 1:1 threading seems irrelevant to this benchmark. In 1:1 mode we will also spawn a lot of stacks. Channel performance is mostly irrelevant to this benchmark. It's hard to say what the more "idiomatic" Rust version of this program would be, because this program doesn't *do* anything. The fastest version of this program would be `println((N + 1).to_str())`. :) An implementation based on libdispatch/TBB-style blocks might be faster, but it would look quite a bit different from this benchmark.
Now that there's a 1:1 and an M:N mode, I wonder if it makes sense to resurrect segmented stacks for use with M:N. Is it completely crazy to have segmented vs. not-segmented be a (compile- or run-time) setting?
I don't consider the lack of implementation optimization for single-threaded applications a problem. The problem is only offering threads and synchronous interfaces and spending all of the development time and complexity budget building an alternate implementation of the same thing to fill the same niche. Rust doesn't have a high-level way of writing generators/coroutines, so tasks are how people are going to approach it when they don't want to write a state machine by hand. The performance will be very poor in comparison to languages with real support for this (Lua, C#, etc.) and somewhat worse than a language like Go with a lighter concurrency unit. There isn't any implementation of data parallelism or a task graph more suited to fine-grained parallelism. So, tasks are going to be used for this too and the comparisons with other languages with mature parallelism support will also be poor. Tasks don't replace the use cases of non-blocking/asynchronous I/O because there's no way to avoid a stack per client. We have libuv in-tree, but it's only being used to expose an alternate implementation of synchronous I/O. AFAIK, there isn't a safe callback-based API exposed and users will expect a lot more after being exposed to stuff like C#'s async/await. We still don't even have a high-level mutex type with support for any number of condition variables, let alone a modern take on shared memory like software transactional memory or RCU. As far as I can tell, green tasks pretty much rule out using lock elision and hardware transactional memory, which is only going to get more sad down the road than it already is with Haswell. Everything that touches parallelism or I/O is going to be held back by the need to add support to the M:N threading stack with the API as the lowest common denominator mapping down to both. It doesn't make any sense to me that Rust would take the position that something like memory-mapped I/O or a concurrent hash table isn't idiomatic, or that running a long loop or calling an sqlite3 should be a stressful prospect because it may block a scheduler and cause unrelated networking requests to time out. It's true that with a lot of work on libuv itself, it could gain proper multi-threading support, but why is it worth spending all of this time to get a slower implementation of I/O and concurrency without any concern for latency or fairness?
&gt; Now that there's a 1:1 and an M:N mode, I wonder if it makes sense to resurrect segmented stacks for use with M:N. Is it completely crazy to have segmented vs. not-segmented be a (compile- or run-time) setting? The generated code will always need the preludes if it's supported at runtime. Anyway, if Rust isn't going to put in the effort to make system calls without using the standard C library and libuv, then it will pay a huge price for stack switches as it did before. Go is likely switching away from segmenting stacks anyway by leveraging their precise GC to make relocable stacks. Rust can never do this.
&gt; The obvious thing for us to do is cache stacks (and a dozen other parts of the task structure), but doing so in a way that is really useful requires some careful thought. There are also lots of other allocations in the task that can be eliminated with more or less effort. I don't think stack caching helps in this benchmark. We actually do have stack caching in 1:1 mode on Linux via glibc and it's just making it worse if anything. &gt; I wonder how performance of this example would improve if the code explicitly asked for less stack. When we're calling `mmap` + `mprotect` to add a guard page, I don't think it matters. cmr did some benchmarks and it was the same ballpark for different stack sizes.
Ruby's `p` also returns the value besides just printing it. Can the same be done with macros somehow? That should allow for wrapping statements with `p!(...)` to debug without altering the control flow of the program.
Isn't a generic function good enough here? `fn p&lt;T&gt;(v: T) -&gt; T { println!("{:?}", v); return v; } `?
You're probably just running out of memory and hitting the `abort` in the Rust codebase. It doesn't currently print an error message and `abort` causes an invalid instruction to generate a core dump for you.
I'd just use `debug!`.
I think the author was using it as a demonstration of the new macro technique that just landed in master.
This could be a problem, but so far I haven't seen this be a problem in benchmarks. In any case, we are going to offer both array and linked list implementations in the standard library, just like java.util.concurrent.
&gt; Rust doesn't have a high-level way of writing generators/coroutines, so tasks are how people are going to approach it when they don't want to write a state machine by hand. The performance will be very poor in comparison to languages with real support for this (Lua, C#, etc.) and somewhat worse than a language like Go with a lighter concurrency unit. Throwing away M:N won't fix this. &gt; There isn't any implementation of data parallelism or a task graph more suited to fine-grained parallelism. So, tasks are going to be used for this too and the comparisons with other languages with mature parallelism support will also be poor. Throwing away M:N won't fix this either. &gt; It doesn't make any sense to me that Rust would take the position that something like memory-mapped I/O or a concurrent hash table isn't idiomatic, or that running a long loop or calling an sqlite3 should be a stressful prospect because it may block a scheduler and cause unrelated networking requests to time out. M:N scheduling is designed to spin up more schedulers to deal with this as needed. &gt; We still don't even have a high-level mutex type with support for any number of condition variables, let alone a modern take on shared memory like software transactional memory or RCU. As far as I can tell, green tasks pretty much rule out using lock elision and hardware transactional memory, which is only going to get more sad down the road than it already is with Haswell. You were claiming that a mutex was impossible to implement for M:N and 1:1 right up until Alex did it and showed that it had the same performance as pthread mutexes. We should not declare defeat until the battle has been fought. &gt; It's true that with a lot of work on libuv itself, it could gain proper multi-threading support, but why is it worth spending all of this time to get a slower implementation of I/O and concurrency without any concern for latency or fairness? It remains to be seen whether I/O will be slower when fully optimized: we still hit epoll far too much and libuv doesn't have multithreading yet. And in any case, concurrency has not been shown to be slower in M:N mode. We need to make measurements, especially in Servo, to decide what to do here—it is very important that DOM-to-layout queries be extremely fast and direct control over scheduling can be a powerful tool that I'm not ready to throw away yet. I understand that you feel that M:N is just a dead end, but we simply haven't given it the fair shake it deserves. We need to optimize it, get Servo taking full advantage of it, and measure on all OS's before we decide whether to keep it.
I think the concern might be that a function could consume its argument by-move, thereby changing the semantics of the program.
This is a holdover from Latin where almost All group designations take on the masculine conjugation... People getting offended over accepted grammar rules is arbitrary and infinitely regressive unless language has evolved in a way to support an alternative. English has not evolved to support a gender neutral set of pronouns therefor you either have to standardize across male or female, picking female just because it's not male enforces a worse standard than sticking with male because it's the global standard amongst Latin derivative languages This entire thread illustrates what happens when people have too much time on their hands (myself included). Lets just enjoy rust.
I think this should do it: macro_rules! p( ($ident:ident) =&gt; ( { println!("{:?}", $ident); $ident } ); ) Now it should expand into a block that first prints the argument, then evaluates to it.
So what exactly is up with rustpkg as it stands?
But if you give rust enough hints, it can figure it out: static y = 40; fn foo(val: int) { } fn main() { let x = 40; // not sure what x is at this point foo(x); // oh, x must be an int. foo(y); // it seems like rust should be able to figure out that 'y' is an int } 
I've kept my [non-promise][1] and made one of these for only closure types, which are a big enough space on their own. It might be worth reading the explanation (below it) before the table itself. [1]: http://www.reddit.com/r/rust/comments/1v7hqb/the_periodic_table_of_rust_types/ceq1amp
`s/return v;/v/`
Rust doesn't have (nor wants to have) global type inference ("type inference at the API level"). Therefore items such as `fn`s and `static`s must have their types explicitly declared. It could make sense (I think it would) to try to infer the type from the RHS only, but not from the rest of the program. This is issue [#9346][1]. [1]: https://github.com/mozilla/rust/issues/9346
/r/playrust
It is not a demonstration of exportable macros; everything required for it has been in master for a long time.
&gt; It might be worth reading the explanation (below it) before the table itself. Then you should put the explanation above it. :)
Yes. OP, why not put another note in your readme: "Why this and not rustpkg"?
I'm not exactly sure what you're trying to say, but Rust completely forbids implicit coercions between numeric types. You must explicitly use the `as` operator if you want to, for example, cast an int to a uint.
This is not a bug; traits must be in scope to call methods on them.
Or more generally: macro_rules! p( ($e:expr) =&gt; ( { let v = $e; debug!("{} = {:?}", stringify!($e), v); v } ) ) This will allow something like the following: fn main() { println!("answer is {}", p!(p!(40) + 2)); } ...which only prints the traces when `RUST_LOG` is set: $ rustc foo.rs $ ./foo answer is 42 $ RUST_LOG=4 ./foo 40 = 40 p!(40) + 2 = 42 answer is 42
Now I realize this is something I will remember Rust by! I should have removed "Default" from the subject. If I don't have a use statement for the trait, I can implement its method but I can't call the method I just implemented! I think I would have liked it better if I was just forbidden from even implementing the trait. #[crate_type = "dylib"]; mod base { pub trait HotOrNot { fn IsItHot(&amp;self) -&gt; bool; } } pub struct Temperature { val: int } impl base::HotOrNot for Temperature { fn IsItHot(&amp;self) -&gt; bool { self.val &gt; 76 } } impl Temperature { pub fn Hot(&amp;self) -&gt; bool { self.IsItHot() } } 
The ergonomics of a language are important. If you've ever had a cryptic type error from Haskell, that's because of global type inference (normally). By limiting type inference to function scopes, it limits the scope of type errors. This makes the language a little nicer to use. From a technical standpoint, limiting inference to function scopes makes dealing with linking much easier, as much less type information needs to be stored in the library itself. It's a nice guarantee that a function will either work with any valid input or be a compile time error. 
Alex tells me that it's only 2x slower than Go with 16KB stacks.
&gt; They're not lighter on resources than OS threads. Why no thing like Plan 9 libthread?
In addition to what Aatch wrote, I believe global inference would also significantly complicate the type checker, though I'm not very familiar with the details. (And if you think about it, Rust's `static`s can't be polymorphic, so this is effectively the monomorphism restriction, well-loved by Haskellers everywhere, which reinforces his point about cryptic type errors.)
It is really sweet, especially the [project listing](http://www.rust-ci.org/projects/) is really great. It even has direct links to generated documentations if available. (E.g. [shameless plug](http://www.rust-ci.org/lifthrasiir/rust-encoding/doc/encoding/).)
Not related to the recent changes, but seeing all those green build badges make me very happy.
Indeed, I'm amazed by the number of listed packages already!
It would be inconsistent in a very bad way to disallow it—everything like that uses paths and that's how the language is fundamentally structured. You'll quickly get used to it and realise more fully why it would be a bad idea to disallow it.
But this would fail to work on `let a = ~40; p!(a);` because you'd be moving out of the variable before attempting to stringify it.
&gt; It would also have a form of tasks without stacks for small units of CPU-bound work like the Thread Building Blocks task graphs. How would this work exactly? Without a stack, I'm guessing you can't have local variables or call functions... ?
&gt; Not related to the recent changes, but seeing all those green build badges make me very happy. Yeah, Travis is great at that `^_^` 
You can have local variables and call functions. The code is running on a stack, but each task doesn't need an *exclusive* stack because there is no context-switching. Rust tasks need a stack because they can manually yield control to another task, as is done for the synchronous wrapper around asynchronous I/O.
(I added a row for unboxed closures, for great completeness.)
And all those hardworking Rusticians, that make sure that their libraries build with Master.
&gt; cmr did some benchmarks and it was the same ballpark for different stack sizes. Actually the performance *dramatically* improved with 16KB stack sizes.
`pub use` with globs is incoherent and unimplementable (as in, "very smart people have tried to implement it over and over and failed"). Globs are feature gated and have a good chance of being removed entirely for this reason.
just to make sure: are you running the commands in an MSYS shell (as per the instructions in the "Quick Steps for Windows environment setup" section of the wiki page you've linked)? It looks like you might be trying to run the commands in a windows command prompt or powershell.
Thanks for answering, yeah I tried it first but it didn't work... So then I tried it in cmd, which did work up to ./configure. After reading what you wrote I tried it again in the MSYS shell and now it works! Oh well, thank you again! Everything seems to work now!
no problem, glad it works now. If you're just trying Rust it might be easier to get the pre-compiled binaries via nuget (https://www.nuget.org/packages/Rust/) than compiling from source. 
Now that Tim isn't working at Mozilla, it's sort of atrophied. There's a lot of parties who want to make the situation better, it'll improve with some time.
I read this as 'included with.'
&gt;And all those hardworking Rusticians, that make sure that their libraries build with Master. Thanks :D Though it's easier when your library does nothing (jab at myself). I'm just saying those Travis badges are highly motivating for me to not be a slacker and keep up to date. I must appease the pretty sticky `^_^`
I'm very much in favour of better documentation on primitives... but not so much in favour of the scheme as implemented: having a lang-item for each and every impl of builtins seems *impossible* to extend to generics like vectors and tuples. Also, I don't see how DST will resolve this/make it any easier when revisiting: we'll always want `impl&lt;'a, T: Trait&gt; &amp;'a [T]` for multiple different `Trait`s (e.g. `Eq`, `Clone`, etc), and DST isn't abstracting that.
Given the fluid nature of the language at the moment, would it be a good idea to require the rust versions each example was coded in, so that we can easily review/replace obsolete code?
I have written an article for [how to install an unofficial nightly for Windows](https://github.com/mozilla/rust/wiki/Doc-how-to-install-an-unofficial-nightly-for-Windows). The Rust team is willing to provide the official nightlies, so think that as a stopgap.
So many questions....
I like this overall, but: &gt; 1 use std::io::stdio::println; You shouldn't need to import println as it's in the prelude. Or is that just `println!`? &gt; 'Integer myInteger = new Integer(5)' I'm afraid this would give the impression we autobox primitives, which is very much not true.
`println` was removed from the prelude in favour of using the `println!` macro directly.
/r/playrust
What does "Traits as predicates on types" mean?
 let squared = map(list, |value: &amp;uint| { *value * *value }); That looks kind of ugly actually. Particularly because `value` is an int. What does it mean to "borrow" something anyway. Does it create a new pointer to the existing object? So in the case of integers, you wouldn't actually save on performance because it's allocating/copying just as much memory, but now you have this extra layer of indirection?
`map` is generic, so you may have `List&lt;HugeStructure&gt;` where you don't want to copy because it's big memcpy, or `List&lt;~str&gt;`, where a copy would be a new allocation. It has to provide a uniform interface, and the correct one is to pass borrowed pointers (which are a C-like `*` pointer (so borrowing is just an address-of operation), with some semantics that the Rust compiler checks at compile-time: nothing at runtime). &gt; allocating `int`s are not an allocation, neither are borrowed pointers.
&gt; You shouldn't need to import println as it's in the prelude. Or is that just `println!`? I think the slide intends not to introduce the macro system, so that the audience won't question why `println` has a trailing `!` while others don't.
&gt; How one would work safely with an external library without encapsulation? Why don't you consider the visibility system to be providing encapsulation? I don't really understand what you need beyond private fields, types and functions.
The declaration fn generic&lt;T: Eq&gt;(x: T, y: T) { ... } is saying that `generic` can take any `T` that implements `Eq`, or, flipping it around, that, to be able to call `generic` with some value of type `T`, that type `T` must be comparable for equality (i.e. implement `Eq`), basically, it's a boolean assertion/predicate about the type.
Maybe it's because I speak primarily to ruby people but until it was pointed out that ! meant macro to me I never even considered it.
You're right. I missed that there is actually a priv word that can be used at the module level.
IMO all this stuff should be handled by libsyntax. Just like in clang: http://clang.llvm.org/doxygen/group__CINDEX__CODE__COMPLET.html
Vector destructuring is also pretty cool :D
I kind of find the special cases when it comes to visibility weird. Would be nice if it was either one or the other.
My concern is only if we have deriving directly encoded with the trait (so that `use std; #[deriving(std::fmt::Default)]`, `use something = std::fmt; #[deriving(something::Default)]` etc. work). If we have a hard-coded map of path -&gt; deriving implementation it will be ok (i.e. to derive `std::fmt::Default` you always write `fmt::Default`, imports are ignored). But, it will act slightly strangely, since importing `use some_crate::fmt;` won't change the behaviour.
Does the trickiness surrounding paths with deriving also relate to the difficulties in having something like this for macros? use mystd::io; mod mystd { pub mod io { pub macro_rules! println(...) } } io::println!(...) Or is that a separate issue?
Thanks for writing this. I didn't know chocolatey. I just donwloaded nuget's command line (https://nuget.codeplex.com/releases/view/58939) and run nuget install Rust from Powershell
Thanks, I added an example for that one, too! Though I got some compiler errors on some patterns :-/
The head destructuring of vector seems bit unintuitive. To me `[head]` reads like destructuring a single-element vector. I'd prefer possibly `[head..]` or something similar to distinguish it from single element case.
Instead of `fail!("This will never happen")`, I would recommend writing `unreachable!()` (it expands to `fail!("internal error: entered unreachable code")`). It's shorter, indicates the intent of the code more quickly and (if used more widely) is more consistent.
I am posting my findings as I learn Rust with examples here http://pzol.github.io/getting_rusty/
`[head]` is destructuring a single element vector. A "true" head would be `[head, ..]` (or `[head, .. tail]` if you want the tail too... or `[..init, last]` for the reverse).
One would normally just write `let squared = map(list, |&amp;value| value * value);` -- leaving off the type and braces, and using destructuring to automatically dereference the pointer.
Yeah, I personally find it quite nice - maybe it's just poor documentation.
1) Yes, no boxing. 2) Rust does structs just like C does. (Helps with FFI.) You should care about alignment and layout to save space. 3) I don't know.
Thanks!
I should also probably add: 4) Is there or will there be an official ABI? This kills the C++
I don't know if there is an existing units library for rust, but it is trivial to make one - Unit-like structs and impls make it easy to do. For example: struct Meter&lt;T&gt;(T); impl&lt;T:Num&gt; Meter&lt;T&gt; { ... } There are traits for all of the numerical operators in rust - addition, multiplication, etc. Since Meter&lt;T&gt; is an entirely new type, it does not inherit the implementations from the parent class, so Meter&lt;int&gt; is not compatible with int unless you define an impl for those two types.
And it would be possible to implement the traits such that e.g. multiplying two distances gave you an area?
How would you do something like Distance/Time = Velocity Velocity/Time = Acceleration
In that case it is quite nice. I hope /u/pzol would update the example to reflect this.
In addition to &amp;Pair{x, y} it would be nice to be able to say &amp;Pair{x = xval, y = yval} or something similar. With larger structures it's not very nice to need to consider every field and remember their ordering. 
Ah, gotcha!
Rust doesn't have one, but you can use the C or a few other ones. 
You can give new names to fields of destructured structs via: let Foo { x: new_x, y: new_y } = foo; This form is position-independent, so you can indeed just do: let Foo { y: new_y, x: new_x } = foo; ...without regard for the order of the original fields. And if you don't want to bind all of the fields anyway, then you can just throw the rest away: let Foo { y: new_y, ..} = foo;
&gt; impl Div&lt;Time, Velocity&gt; for Distance Heh, even if you were writing a library specifically for this, it sounds like you'd want to do some sort of code generation to save your sanity. With just a few base SI units (those you use in intro mechanics) would be a pretty big grid of boilerplate to implement.
Is there a way to change it to that?
No, gotta repost over there. You can delete this post I guess but it's not a big deal either way.
Bravo sinma! &gt; `std::rt::io` est une réécriture de `std::io` et vient le remplacer dans cette version I think that this sentence is a bit ambiguous as it could be interpreted as "you should use `std::rt::io` from now on". &gt; Le consensus semble être qu’utiliser reStructuredText et Sphinx soit la voie à suivre. There's been a proposal on that but I don't think that one person == consensus. (from the comments) &gt; Ce sont tous des pointeurs «intelligents». I think that `&amp;` is not a smart pointer (it uses compile-time checks and is like a C pointer otherwise).
The Meetup link: http://www.meetup.com/Functional-Brighton/events/141262992/
ahh, fantastic. I didn't see an example of it in there. What about &amp; for matching twice on the same thing? e.g. let Foo { y: new_y &amp; (new_yx, new_yy) } = foo? I find this particularly useful for complex evaluating of ASTs.
There exists a `.take(n)` method on iterators to restrict the iterator to the first `n` elements. And since iterators are lazy, there's no overhead of constructing an intermediate list.
Rust has nothing like that, to my knowledge. I'm not even sure what it's intended to do. :P Can you explain it? Is it an idiom from another language?
Ah! I see now. To my knowledge, we don't have `&amp;` (we do have `|`, but not in assignment statements, in which we only allow irrefutable patterns). So your example above would just have to be: let Foo { y: new_y } = foo; let (new_yx, new_yy) = new_y; EDIT: You could also do this, which I never realized was possible before now: let Foo { a: (x, y) } = foo; Pattern matching is cool. :P
Ahh, but what about when you're mid-pattern match?
That makes perfect sense. Strict evaluation with lazy iterators seems like a win-win for a language.
You'll have to elaborate.
This exists, with the Haskell @ syntax. let Foo { x: tuple @ (a, b), .. } = bar();
If you have a small fixed number of things to take, you can match on `(it.next(), it.next(), it.next())` (or however many elements you need).
neat, I didn't know about this haskell feature.
LLVM will usually optimize out the pointer indirection if it can figure out that they are unnecessary.
Except it's not possible in C++. If you #define RETURN(x) return(x); } i.e., make a macro that returns something and ends the function with a brace....it'll compile, but your IDE will freak out.
&gt; ints are not an allocation, neither are borrowed pointers. Perhaps I'm using the wrong terminology. What do you call the 4 or 8 bytes that are [allotted] to store the int or pointer?
Is that a "yes, it parses it"? I'm not reading through some auto-genned docs to get an answer.
Conventionally, saying "allocation" refers to a malloc and free (or something similar); qualified as "stack allocation" it's clear that it's not malloc and free. In any case, I'd personally just call the bytes the memory used by the pointer or int.
/r/playrust
Well, if I don't want every user of the `It` struct to know that its `my_tyname` method came from a certain trait, shall I do this? impl It { #[inline] fn my_tyname(&amp;self) -&gt; &amp;'static str { (self as &amp;worksornot::traitdefaults).my_tyname() } } Does it incur an overhead? Is this related to the single inheritance effort? 
Spoiler, on this graphic http://sogrady-media.redmonk.com/sogrady/files/2014/01/lang-rank-114-wm.png Rust is near coordinate (35, 27).
Awesome, I was missing this, added it to the examples as well!
This is mostly irrelevant to your specific criticisms, but I think the module system is pretty cool. Coming from a C++ background, I was used to #include directives, and had the impression that 'mod' and 'use' were somewhat redundant, because they seem to be two statements that accomplish one thing. I came to realize that C++ isn't any better in this regard, since, when calling a C++ compiler, you need to pass it all of the .cpp files you want to compile as arguments, and it requires you to make up your own system for managing that list (say, .vcproj files). In Rust, `mod` pulls that information into the language, so there's no need for some other way of managing what files are part of the create. `mod` is a nicely consistent construct that gives you just about everything C++ namespaces, separate .cpp files with public parts in a header, and .vcproj can give you, but in a unified way, without all the weirdness. `mod` always does the same thing: declare a module and where to find its body. // declare a module (and provide the body) mod tests { #[test] fn TestNothing() { } } // declare some modules (but the bodies live in separate files) mod fiddle; mod swizzle; mod twiddle; `lib.rs`-type files can look a lot like a project file, and I think that's just fine: https://github.com/bjz/cgmath-rs/blob/master/src/cgmath/lib.rs Anyway, I'm OK with `use` always coming before `mod` (and before everything else except external crates). Certainly, module declarations with a body feel correct when they come below the imports. For modules that live elsewhere, we can either have the consistent option, with `mod` after `use`, or the other option. Since the consistent option is what we have now, and is perfectly usable, I don't think there's a reason to change this. On point #2: for relative module paths, there's `super::` (although I don't know if that's staying in the language?). I suspect making relative module paths the default for `use` could prove to be equally annoying as the scenarios you describe, but in other circumstances. One advantage to absolute module paths is that a simple global search/replace should always work correctly when the path of a module has changed (I think?) and a simple global search can find every place where imports from a module are used. This fits nicely with the 'greppability' of the rest of the language.
`use` has the advantage of being a full English word. Well, so is imp, but it means something quite different from import--think Poe's 'imp of the perverse' :)
Will do when I geht home.. EDIT: Changed my OP
This would mean I can't run a search for "use net::http" and see every place that pulls it in.
You already can't because of "use net::{http, whatever};"
I like the way the module system is now, except I would like to have a "rust.rh" file that declares all 'mod' and 'use' for the files in same folder. The compiler could strip out circular dependency to the file it is processing. Maybe forbid circular dependencies, as internal dependencies is not the big deal, it is bringing traits into scope that gives me headache. This would also maintain backward compability with typical use of lib.rs. This would make it easier to maintain larger codebases where each trait is uniquely brought into scope per folder.
I've been looking at how Boost does it. They use a whole slew of MPL magic to automatically determine expected types. 
I thought the problem that putting templates into header files caused for C++ was compilation times. Are we winning there?
I'm actually pretty happy with the current module system, aside from a few of the rules for `use` (mostly it feels awkward that `use` has to come before any `mod` statements, and there can be a fair bit of noise when it comes to re-exporting symbols from nested modules). I also agree with the devs in the thread -- when I think of a simple, powerful, and/or elegant module system, Haskell is certainly not what comes to mind. I think something more like SML's module system + SML/NJs compilation manager is a better ideal, although I like not having to write separate signature/interface files for Rust, and nesting modules in separate files is not really easily done in SML.
I was thinking more about, say, the number of different things that will multiply to give you force. Force could be `(mass) * (acceleration)`, or `(mass / distance) * (velocity^2)`, or `(Energy) / (distance)`, etc. A person can [figure out](http://en.wikipedia.org/wiki/Dimensional_analysis) what these combinations are just from a small set of definitions, but it seems like the way you're talking about would require them each to be defined manually. What you (ideally) want is a system where you * give a set of fundamental units (e.g. time, distance, and mass) * define a set of derived units unit in terms of those fundamental units * let the system figure out all the possible relationships and define multiplication and division appropriately for those units (There are really an infinite number of possible relationships, since you could have a calculation for distance with a term like `(velocity^10) * (time^10 / distance^9)`, but you could just put an upper limit on such terms, I guess. Would be nice if somehow the compiler could figure out such combinations as they occur, of course!) *e:* I guess pretty much you want an algebra of types based on a rank in each of the fundamental units.
I think it's more that this comment doesn't add anything while being overly negative. I don't want a culture of "X sucks *drop the mic*". "X sucks, and let me expound upon at length and in detail why my opinion is correct": awesome.
I am 80% sure of these answers, criticisms welcome. &gt; Since the struct I'm returning will reference the byte vector I use as my buffer, this exact buffer has to be a unique pointer (~) right? Yes. If it wasn't heap allocated, it would get destroyed when the function is over, and you'd be returning invalid memory. &gt; When I try this, I don't know how use this as an argument for read_bytes, since I cant figure out how to write this (&amp;~ anyone?) In general, you should start off by writing functions that accept pointers as borrowed pointers. `fn foo(ptr: &amp;[u8])`. You would pass them in as a reference as well: `foo(&amp;buff)` &gt; When I try to use a borrowed pointer (&amp;) for the buffer, the call to read_bytes works fine, but I cant return the struct since it would outlive the buffer (I think?) Yes. &gt; On lifetimes in general I am kinda lost. I just annotated the target struct and its vector fields with &lt;'a&gt; as I read in a blog post but I am not really sure why. (But otherwise I got something like "unlimited lifetime" from rustc). You might enjoy the lifetimes guide: http://static.rust-lang.org/doc/master/guide-lifetimes.html &gt; Is '&amp;[u8]' even the 'correct' type for a vector hold by a struct? Seems fine.
Yeah totally agree with you there. I did some stuff in C for University recently and it really gets quite complex rather fast. After that I find rust's approach even more appealing but that doesn't make it easier :D
Thanks for all the answers! I read the guide but unfortunately it uses managed boxes which I think get removed soon? Anyway any resource helps and I will read it again ;)
I agree: - constructive criticism is awesome - detailed criticism still gets you closer to a solution by virtue of being detailed - snappy criticism tells you more about the mood of the OP than what is being criticized...
Modules were already available in Modula-2, Cedar and the many Pascal dialects, before C++ got namespaces. I never understood why the compiler vendors never came up with a proper way to support modules. Now C++ might get modules, for those willing to wait until around 2020, or something. I hope Rust will already be a mainstream language by then.
I get the feeling it is similar to *with* and *use* in Ada, right?
The presentation looks really nice! I will play around with the generics/algebraic examples because those are new to me.
Ok, so it's about a week old, so not exactly *new* new, but brson was lamenting in IRC that he wanted more feedback on this design before forging ahead.
Seems to me you were downvoted because your comment was vague and unconstructive, and then later because you tried to cast your downvoters as Mozilla fanboys. Please see rule #2 in the sidebar.
Jeffery Olson (olsonjeffery on IRC) is a longtime Rust contributor, and was the first person to ever dive in to integrating libuv into the compiler. That first attempt at integration was later abandoned, but the lessons learned were used to determine the design of the second Rust runtime, which introduced the ability to swap out the event loop for non-libuv implementations.
I think this is a brilliant compromise. The original proposal was to warn whenever *any* return value from a function was ignored, and I worried that this would lead to tons of spurious warnings. But by only warning on types that have the `#[must_use]` attribute, we can fend off an explosion of warnings while also "blessing" the `Result` type, which will hopefully spur users to make it the preferred way of indicating failure. Very excited by this.
The lowest bidder?
personally, I liked Boeing's x35 better than LM's
+1 for adding a SyncChan as described. I think this will become my personal default when creating channels. I'm against merging Chan and SharedChan at the expense of overhead. I'd rather be explicit about my intended use case and keep the performance optimized. If it's practical, I liked Eric Reed's suggestion to make a unified "Chan" trait. I'm also in favor of having separate one-shot types to keep that use case speedy. If the unbounded channels are going to `fail!` at a given depth, that depth should be configurable. I'm not sure I understood the proposal properly -- if I use Chan::unbounded() to instantiate it, does it not have a fail depth?
sorry 
You're looking for /r/playrust. This subreddit is dedicated to the Rust programming language.
Wrong subreddit.
I think changing Port and Channel to have names that reflect which is the publisher's end and which is the subscriber's would be a huge help. When I first started out I consulted examples 5 or 6 times before I had it memorized.
Oh, I see what you mean now. I just did some playing around with it, but I came to the unfortunate conclusion that HKTs seem to be required to do much :(
Seems several people don't like the idea of merging these two types, but nobody has objected to optimizing the single-send (oneshot) case. I'm not sure if we can do that optimization either without any overhead, so we could end up with three different async channels. Yes, `unbounded` would not have a fail depth.
The programming language will hardly be the issue. Every line has to be reviewed and carefully checked anyway. But the JSF is simply a mess on all levels. They try to make one aircraft do the job of what would usually be 3 or 5 different aircraft. The required software is unprecedented in scale for such a project. And with the mess that's already going on in the JSF project it would have been quite surprising if the software would be any better.
Hl2 and hl2: lost coast?
From what I understand, by default it will be a compile-time warning (not an error) to ignore any type with the `#[must_use]` attribute. And if you want to ignore Results without being pestered by the warning, you can just turn it off like any other lint pass with `#[allow(unused_result)]` (or the equivalent compiler flag). Both these together should be lenient enough to stave off any hasty comparisons to checked exceptions. That said, why are you using Rust if you don't care about safety? Check your return values!
Well the methods on each are called `send` and `recv`... so how about `Sender` and `Receiver`? :P
I like 'Sender' and 'Receiver'.
Oh, I see that you've already submitted this to that subreddit, but still decided to submit it here. Please don't do it again.
As mentioned in the thread on /r/programming, there's a PR to move towards removing conditions from the API. I also felt that a digression into conditions was a bridge-too-far for an introductory, 800 word blog post. I am thusly chastened.
For those interested in what name to paint the bikeshed: https://github.com/mozilla/rust/issues/11765
&gt; As the Rust community grows, more people will want to stick with official releases, and these are much more valuable when most of the Rust projects have easy-to-find versions that work with these releases. Agreed.
Exceptions have performance issues in a systems language. Also, in Rust there is just one type of exception you can declare to return at a time (since Result just has one error type parameter). In any case it is *much* less wordy. Anyway, I don't see much of a problem with exceptions philosophically. They aren't right for Rust, but I think they aren't a bad feature per se.
A short while ago clojure got the core. async library witch does simular things. What is intresting is that in clojure there is no unbounded channels. The standard channal (chan) is a direct sync. You can great larger channels with (chan 10). They dilibratly do not want any unbounded channels, its a recipe for disaster. This kind of library forces you do make a choice, even if you would rather pretend the problem does not exists. There are some default buffer (chan (sliding-buffer 10)) and so on, but you have to make choice. If you really refuse to do the smart thing, you can of course still do something like (chan Integer/MAX). I think rust should adoped the same semantics.
This proposal also does not have unbounded channels unless explicitly requested. The default instantiation of an asynchronous channel has a 'large' bound to prevent unbounded growth, but does not block once that bound is encountered (it fails). I do think synchronous, unbounded channels are a reasonable (if slow) default choice, but am still very skeptical of asking people to pick bounds for channels that require buffers but do not grow without bound - it seems like the kind of judgement that most people are likely to get wrong most of the time. 
`yield` was [renamed to `deschedule`](http://static.rust-lang.org/doc/master/std/task/fn.deschedule.html).
&gt; I do think synchronous, unbounded channels are a reasonable (if slow) default choice. Go's default, unbuffered sync channels (aka `chan 0`), happened to be a really judicious choice just because it drastically helps finding-out a bunch of logic errors and deadlocks as soon as possible. Any other values must come from deeper and careful thoughts, because dictated by application's core logic or performance tuning (or both of them), so are basically incompatible with the very idea of a default choice.
&gt; If I try to build glfw-rs as crate_type lib, it fails Fails in what way?
I can only agree. This is very intuitive
TL;DR: One can volunteer to receive a bug digest every week. You can receive as many or as few bugs as you choose. Some might only do 5, some (*coughcmrx64cough*) might do ludicrous quantities of 100 or more. You go through the bugs, adding tags, updating old information, and running the test cases to see if the bug can be closed. It's a big help!
I wouldn't be bothered by having three async channels -- I rather like making the choice explicit. I think it'd make it easier to eyeball performance issues. "I notice you're using a UniqueChannel here, but you only send to it once. Switch it to a OnceChannel and you'll see a big speedup in this loop." Someone that's not thinking about performance yet could used a SharedChan for everything.
As I understand this, part of the value is to try to reproduce old bugs with the latest master code, to see if anything has changed (maybe issue is fixed, maybe it's a different error message, etc). If we did this on an ad-hoc basis (for example, sort in github by last modified), would this also be a valuable thing to do? Would it step on the toes of people signed up with Brian's script?
Whether it steps on toes or not, triaging bugs is always valuable! :)
&gt; Bravo sinma! Thanks! &gt; I think that this sentence is a bit ambiguous as it could be interpreted as "you should use std::rt::io from now on". You’re right, this sentence is really tricky. It’ll be fixed soon. &gt; I think that &amp; is not a smart pointer (it uses compile-time checks and is like a C pointer otherwise). I didn’t say that, and I believe the guy that I answered didn’t think `&amp;` is a smart pointer. I don’t think any of the comment is ambiguous on this subject.
Ha! To be fair though, there is a [Java Real Time Standard](http://docs.oracle.com/javase/realtime/rts_productdoc_2.2u1.html). According to [this source](http://stackoverflow.com/a/3122861), it has made its way to the T-50 trainer.
```Out``` and ```In``` 
As /u/GingerScottishDwarf said, this is the wrong subreddit to post this in. But as long as you're here, be sure that your video drivers are up to date. Sometimes the impact of out-of-date video drivers is limited to just a few games that happen to be sensitive to that issue.
Not really, knowing that `0` is the default I can just get into the habit of using `42` and leave a note `FIXME: might want to re-examine that size some day`.
sorry, and thanks 
I pointed it out on the mailing list, but since there seems to be some duplication of the discussion... ... it feels wrong to me that the `Chan` type does not seem to allow multiple consumers (apologies in advance if it does...) but will allow multiple producers. The asymmetry is jarring. Given the drive toward a simpler "idiot-proof" API, I would advise to use a MPMC implementation as the default since it is the most flexible. In general, I value making things easier for beginners and possible for experts (1). More intricate use cases requiring either extreme performance or a narrowed down interface are not a daily occurrence, so it is acceptable that they cause a small bump, and experts are much more likely than beginners to know about the possible alternatives. (1) C++ disagrees with me on the `operator[]`/`at` duality which is expert-friendly but causes a lot of hair-pulling in beginners.
Does rust actually promise that freeing `~`-boxes happens by calling libc `free()`?
There's also http://www.codetriage.com/ , which works for any GitHub repositories.
Yes, it is super valuable. This is actually how I got commit to Rails: I started off by doing all this triage stuff, and then eventually learned enough to make patches...
Awesome! I would participate.
Yes you can, but a language is not responsible for that, it is responsible for its defaults, thought.
Don't hesitate to reply directly to the post. About topic for conferences etc...
Last year we didn't expect to do GSoC but we had a great application so Josh Matthews mentored Michael Woerister to implement debugging support. I think again this year we are not going to actively pursue a GSoC student (we already have a large summer internship commitment) but would consider excellent applications from self-motivated individuals. FYI, Servo is also a very fertile project for aspiring interns, and thus far it tends to have fewer applicants.
I would attend as well, and I'd be happy to host the event in the Moz space.
You're looking for /r/playrust. This subreddit is for Mozilla's Rust programming language.
With the error error: linking with `cc` failed: exit code: 1 note: /usr/bin/ld: /usr/local/lib/libglfw3.a(context.c.o): relocation R_X86_64_32S against `.rodata' can not be used when making a shared object; recompile with -fPIC That from building it with cmake following the instructions in the repo. *edit: I just discovered it works if I build it with rustc --lib lib.rs in the src folder, so that build error must have had something to do with how cmake was configured. I'm still however getting the "undefined reference to `glfwSomething'" errors when I try to compile my program, and I know it's not a problem with my glfw install as the version of glfw-rs I was previously using worked fine. 
Glfw-rs is built with cmake, so I didn't think that would work. But, it does, and it seems possible to build it as a .so this way whereas just changing the crate-type in lib.rs results in a build error. Thank you for that! With glfw-rs as a .so, I still however get the series of "undefined reference to `glfwSomething'" errors, but I think that must be a problem with the version of glfw-rs I'm trying to build rather than with mixing crate types.
/r/playrust
well, thanks i've register there :D
I'd like to see idiomatic bindings for Qt, but it will be a rather large task. There are things like how it provides its own fundamental data types which are incompatible with Rust's: `QString`, for example, is based upon UTF-16, while our `str` types are based upon UTF-8 (and our `Str` trait can only be implemented for such things as it must return a `&amp;str` from `as_slice`). PySide and the PyQt4 API v2 automatically convert any `QString` that is accessed to `unicode` (for Python 2), but this sort of performance compromise is probably not going to be acceptable to Rust. `QUrl` and `extra::url::Url`; `QList&lt;T&gt;` and `~[T]`; `QDir` and `std::path::Path` + some things in `std::os`—the list just keeps on going of ways where Qt has built their own solutions for things which are in our standard library. How do we handle all of these? I don't know. I really don't know. We might also run into trouble with Qt's execution model and executing things on multiple threads leading to an inability to have any form of sound references because another thread could change your world underneath you. That *would* be a sad situation. I don't know whether it's real or not.
Nice. :) A game jam in rust would be to nice. x)
Seems like the manual needs fixed then :/
Wrong sub. This is for the programming language.
/r/playrust
When someone could take me from saxony and back, i would participate too.
This is pretty awesome! Is cmake building a makefile?
&gt; The **default implementation** of the service-provider interface consists of the C runtime functions malloc and free. It doesn't *require* that it's C's malloc &amp; free.
This subreddit is for Rust the programming language.
Now what I want is an easy, guaranteed-safe way of calling runtime functions (like `spawn`) from `extern "C" fn`s. That would be *awesome*.
/r/playrust
FWIW, the best way to mark bugs as "fixed" is to submit a pull request with a test (normally in src/test/run-pass or src/test/compile-fail, [full description](https://github.com/mozilla/rust/wiki/Note-testsuite)) with some text in the commit message like "Fixes #&lt;bug number&gt;". When such a PR is merged, github will automatically close the associated issue. (If you do do this feel free to group several tests into one pull request, even if they're wildly different.)
Well the options for binding as I see it are: * Make use of [SMOKE](http://techbase.kde.org/Development/Languages/Smoke) * Make use of the generator from PySide * Make use of the generator from PyQt * Forget binding all of Qt and do a Rust equivalent of [go-qml](https://github.com/niemeyer/qml) * Do something totally Rust specific
I'm from Lille but I'd definitely try to attend something like this.
Oops, joke went over my head! `import` is certainly less ambiguous. I don't know what I like anymore!
I very much doubt that it would be faster to write our own GUI library to the standard of Qt. Qt is a very extensive and mature library with very broad support for the different techniques of different operating systems and windowing systems.
It was actually the reverse last year; I decided that I wanted to mentor a project to improve debugging support, and Michael stepped up to the plate.
Also adding "pyotherside" approach as a lightweight way to integrate with QML (like go-qml).
See https://mail.mozilla.org/pipermail/rust-dev/2014-January/008154.html
Multiplay :: Operation Jesus - 66.223.16.7:29015
Newbie question: what is the effect of &amp; here (towards the end of the article): for &amp;Pair {x, y} in pairs.iter() { assert_eq!(x + y, 30); }
It's been done before for Haskell: http://hackage.haskell.org/package/hsqml, though I haven't tried using it. 
good to know, thanks!
I say: convert everything, every time, so that using Qt from rust will feel as natural as possible. A GUI framework which is a pleasure to work with will be a huge win for rust. I don't think that there's really going to be a performance hit: it's a GUI we're talking about. What amount of strings are you going to pass to and from Qt that will make the UTF-8/UTF-16 conversion noticeable?
Why not use Queue semantics for channels?
How useful would the `rust-bindgen` be for generating bindings from Qt's header files? How well supported is C++ FFI in Rust (calling class member functions), for that matter?
/r/playrust
I might attend, not sure what happens at "language meetups" though
For eons now we've wanted to rewrite the build system in Rust, to escape the hell of our makefiles. Perhaps rustpkg will rise to the challenge one day. The relevant bug: https://github.com/mozilla/rust/issues/2237
No C++ FFI at all, but there is [an issue about it](https://github.com/mozilla/rust/issues/5853).
So the plan is still to package them with the compiler (batteries included approach)?
For now, package them with the compiler; when we have a super-awesome package manager, maybe they'll not be part of the minimal distribution (but will be very easy to install, and will almost certainly have some sort of official support).
I've been meaning to suggest something like this; thanks for taking the initiative!
 fn pipe() -&gt; (RecvPipe, SendPipe)
If you're asking that question, it's probably best to wait.
Probably mostly depends on how much time you want to lose on updating the code as changes flow in. I would say: explore, but don't build anything more than a prototype yet.
It only works this way in for if you have a borrowed pointer to Point
Using trait objects means every call to encode something is a virtual call, which can be expensive and inhibit optimisations (due to being indirect). Of course, in practice, the cost of these calls may be small enough to be irrelevant; someone would have to measure.
Note that there are some fundamental things missing from the standard library that you need for good network IO, especially for a fast-action online game: https://github.com/mozilla/rust/issues/11165 Edit: Looks like Alex Crichton has made some progress here! https://github.com/mozilla/rust/commit/431eac19bd2a1caba3d6b23c4d2f7be4103e81e7
In the source for glfw-rs, add `#[crate_type="dylib"];` underneath the existing `#[crate_type="rlib"];`. Same for gl-rs, unless you use the generator in which case you need to go into the generator code and find the part where it prints the header, and do the appropriate changes there.
Thanks everybody for their answers. I have decided that I will wait and when it comes the time that I can no longer put it aside maybe Rust will be a viable option
/r/playrust
 Right now, it's not possible to specify a parameter / enum variant as "something that can be encoded" - only "something that can be encoded by this particular encoder here". What exactly do you mean by this? I know we had some of this conversation already in the context of feral, but I guess I'd like to understand more about what exactly you're looking for (and I guess I feel like we're talking past each other to a certain extent, as well). Can you post a code example that succinctly represents this? Because, I don't think that using `Encodable` forces you into using one `Encoder` or another, at all, especially when you restrict declaration of `Encodable` and `Decodable` to within a `deriving` annotation. When you hit situations where you're ready to encode, you should have already settled on an Encoder to use for that path, as well. And that is the point where you can apply a `&lt;'a, E: json::Encoder&lt;'a&gt;, T: Encodable&lt;E&lt;'a&gt;&gt;&gt;` or whatever. I guess the point is that this API is set up so that you get the perf benefits of static dispatch around serialization workloads, at the cost of (possible) code duplication since you have to explicitly code out each path for each Encoder/Decoder scheme your program can hit at the point where you dynamically select a scheme before sending it over the wire (or writing to a file). I'm dubious about the tradeoff here (although I'd want to see perf numbers, as well) being worth it, since outside of a web application (where you'll have what: xml and json?) you're probably going to be limited to one serialization scheme (a network application is going to settle on a single scheme like msgpack or cap'n'proto) anyways.
Wrong subreddit, the one you're looking for is /r/playrust :)
Good looking out. Thank you sir.
Trying to do that for glfw-rs gives me the error: relocation R_X86_64_32S against `.rodata' can not be used when making a shared object; recompile with -fPIC How would I go about adding the fPIC flag to the cmake build instructions?
So this just broke for me (I have no idea if it was this patch or last one with lifetimes): let read = BufReader::new(bytes!("string into bytes")); I know of a workaround by splitting `bytes!` into a separate variable, but this seems highly inelegant. 
How about making a board that lists Most Wanted requests? This seems nice, but what happens when those things get fixed or another change renders them obsolete?
See [this comment](https://github.com/bjz/glfw-rs/issues/77#issuecomment-32733813)
FWIW, I don't see any reason why it shouldn't be possible to monomorphise functions taking trait objects when the underlying type is known. fn foo(arg: &amp;Trait); is semantically equivalent to fn foo&lt;erased T: Trait&gt;(arg: &amp;T); 
I think it was the last one with lifetimes. It broke other stuff too. I think niko knows about it.
&gt; Using trait objects is often an explicit choice to reduce code bloat from monomorphisation. Indeed. I had once performed a de-monomorphization for very large parsing function (about 2,000 lines of code after the macro expansion) and that shaved about 10% of the binary. The function only sparingly needed virtual calls (besides from reading from `&amp;mut Reader`) so there were no big performance impact.
It was [the big rvalue lifetime patch](https://github.com/mozilla/rust/pull/11585). The bug with `bytes!` is filed as [#11640](https://github.com/mozilla/rust/issues/11640) &amp; [#11641](https://github.com/mozilla/rust/issues/11641).
Thanks.
I agree that when you can do it either way, it's better to avoid a vtable lookup. But I was having trouble actually expressing in code "this function takes an Encodable" without having this.
I wouldn't even bother responding to this hacking twonk. He's spamming this video everywhere to prove himself because a bunch of people are pissed he's been profiting off hackers in a video game. 
The reason it might be nice to have them behave the same is because then it would be a convenient shorthand, exactly like with lifetimes: you only have to introduce a lifetime parameter explicitly if you want to tie the lifetimes of two things together. Here, the same with types. Of course you do also need control over monomorphization. Potentially that could be influenced by a `#[specialize]` / `#[no_specialize]` attribute depending on what the default is (though trait object form ceases to be a shorthand if you also have to accompany it with an attribute). (Not making any proposals here, just thinking out loud.)
&gt; Is cmake building a makefile? CMake can be used to test your current setup (ie. like the configure script of the autotools suite) but will delegate the build itself to another component, such as Make or your IDE (Makefiles are the default on my Linux system). For information, here's what's supported on my setup: * Unix Makefiles = Generates standard UNIX makefiles. * Ninja = Generates build.ninja files (experimental). * CodeBlocks - Ninja = Generates CodeBlocks project files. * CodeBlocks - Unix Makefiles = Generates CodeBlocks project files. * Eclipse CDT4 - Ninja = Generates Eclipse CDT 4.0 project files. * Eclipse CDT4 - Unix Makefiles = Generates Eclipse CDT 4.0 project files. * KDevelop3 = Generates KDevelop 3 project files. * KDevelop3 - Unix Makefiles = Generates KDevelop 3 project files. * Sublime Text 2 - Ninja = Generates Sublime Text 2 project files. * Sublime Text 2 - Unix Makefiles = Generates Sublime Text 2 project files. 
I'm also new to the language but would love to attend this meetup. Good idea!
Here's an example of where this would be useful. I have a servlet, and a task returns a ~Encodable. Then, the container looks at the Accepts: header, and builds the object as desired. Basically, it seems like any time we could reasonably want to decide at runtime, trait objects are a better choice than monomorphization (sp?).
I don't really know. I didn't have the problem myself, I just remembered that comment and thought it might help. You'll probably need to read up a bit on cmake.
Having a shorthand would be quite nice, but I'm personally not keen on having overlapping syntax, especially since `let x: &amp;Trait = whatever` would then (possibly) be weird.
&gt; Or is it incorrect, my assumption, that if something has [deriving(Encodable)] that it can be encoded by any encoder? This is correct. The problem here is a `&amp;mut Encoder` trait object doesn't implement `Encoder`. If you were to submit a pull request that added `impl Encoder for &amp;mut Encoder { ... }` to `extra::serialize` it would probably merged.
There are [compiler intrinsics](https://github.com/mozilla/rust/blob/master/src/libstd/unstable/intrinsics.rs#L182-L183) for volatile memory accesses.
Hmm, interesting. But I still can't pass in an `&amp;Encodable`, right? Because that's not a fully specified type (has to be `&amp;Encodable&lt;X: Encoder&gt;`?
Thanks for the pointer. The intrinsics require me to remember to use the intrinsic on every access. If I forget just one, I'll have a Heisenbug that disappears in debug builds. To be feasible, volatile must be defined for the address *once*, not at all the many points of access. 
I agree with you. I think one possible design would be creating a wrapper type `Volatile&lt;T&gt;` for pointers where the only way to access it uses those intrinsics, but the fundamental/underlying support is there. Or, (if it's a `static mut` global) have the data as a private `static mut` with accessors that use those intrinsics. (I guess those are both mildly less ergonomic than just `volatile int x = 0;`. Either way, the language *does* support volatiles, but maybe not as smoothly as, say, C does.)
Could `Volatile&lt;T&gt;` work on non-pointer objects, as in `Volatile&lt;struct regs&gt; my_regs;` A common technique is to cause the compiler to use a linker relocation rather than pointers to save a register and a few cycles.
No idea; it was a completely hypothetical wrapper... so it depends on how the person programmed it. But I imagine something like that could work, yes.
Hmm? What do you mean by overlapping syntax? The only difference compared to now would be that, in the cases where automatic-coercion-to-trait-object would happen today, instead the function gets specialized to that type. Otherwise, it is called normally. And then there wouldn't be a performance difference between `fn foo&lt;T: Trait&gt;(x: &amp;T)` and `fn foo(x: &amp;Trait)`, and the latter could be freely used as a shorthand for the former. (You can do it today, but most of the time it'll make your code slower). The drawback is that monomorphization would then have to be controlled some other way, such as attributes. I don't think it would have an effect on `let`s.
At some point we need a definite syntax for trait objects, e.g. if you're not passing the trait object into another function: let x = if something() { &amp;type_X as &amp;Trait } else { &amp;type_Y as &amp;Trait }; And, `&lt;T: Trait&gt; &amp;T` and `&amp;Trait` are not precisely same (as `transmute` or `size_of` will tell you). Although DST probably makes this concern invalid since then even the generic `&amp;T` won't be consistently one word. Also, there's a significant semantic difference between trait objects and generics: generics allow you to call functions requiring the (non-erased) `Self` type*, and call generic methods. I imagine this could be worked around with a `#[specialize]` attribute, but we'd need to be able to specific exactly which arguments are specialised and which are not... I feel like having it as an explicit syntactic difference at the type level would be simpler. (I'm only against having identical syntax for the shorthand vs. not. Having a shorthand would make some things much smoother.) *This could be encountered by `&lt;T: Trait&gt; &amp;[&amp;T]` vs. `&amp;[&amp;Trait]`.
I'd like to hear what are the problems with `rustpkg` other than it doesn't work on Windows (most Rust tools don't work cleanly with Windows either :/). Also Tim Chevalier (I hope I spelled that one correctly) said it might be best to discuss why three previous attempts at packaging system failed.
&gt; deprecate it immediately And using what instead?
&gt; This could be encountered by `&lt;T: Trait&gt; &amp;[&amp;T]` vs. `&amp;[&amp;Trait]`. This is a good point (and a difference compared to lifetimes). I'll keep thinking about it.
Yeah, you'd need to pass in `&amp;Encodable&lt;T&gt;` where `T` is the type of the encoder that you're going to encode to (e.g. `json::Encoder` or `&amp;mut Encoder` with the appropriate impl added to `libextra`).
I don't get it. Why? It works great! It would be so sad if Rust 1.0 shipped without packaging. Downright embarrassing.
I think you might have posted this in the wrong subreddit. This is /r/rust for Rust(the programming langauge) I think you might want /r/playrust is for Rust(the game)
You must've been lucky to avoid the various major bugs. ([The full list](https://github.com/mozilla/rust/issues?labels=A-pkg&amp;page=1&amp;state=open).)
Or https://github.com/cmr/cargo-lite
Those would be reasons to fix it, not to throw it away. Is rustpkg's model broken? In what way? That is what I don't see on the ML thread. Of course, I could think of some ways in which it's not great (for example, it should really have some notion of an index for crates).
Never quite understood why a more general approach to dependency management/build system isn't feasible. (i.e. not language specific) I mean, I understand that every language is different, and handles modules differently, etc. However, ultimately, you have either: * a dynamic language, where nothing is compiled, so a list of required files should be enough * a compiled language, where for a given package you have some inputs and some outputs. some other packages may depend on the outputs of another package. It seems to me a more general approach is particularly warranted, considering the fact that cross-language dependencies exist, and indeed are quite common. (packages that wrap C libraries for example) I get the feeling that the problem could be split into * dependency declaration (what inputs are needed to compile this, what outputs does it produce) * dependency management (how to get and build the dependencies of this package) The "dependency declaration" part could be language-specific, while the "dependency management" part could be a more general system. The latter could trigger specific build instructions for each package, which could be not only language-specific, but *package*-specific. (e.g. not all C libraries use the same build system!) Thus languages would only be responsible for providing a means to list the required inputs and where they can be found, and the outputs of a build. The dependency manager would take care of the rest, downloading and building the dependencies wherever they are found and triggering their build systems. 
Note that TJ Holowaychuk is working on [exactly this](https://github.com/mozilla/rust/issues/10041#issuecomment-33130674). There's also things like Gradle which attempt to be this.
&gt; Never quite understood why a more general approach to dependency management/build system isn't feasible. (i.e. not language specific) It is feasible. It's already what nearly every Linux distribution does.
That's a good point, it should also integrate as much as possible with the system package manager. e.g., you should be able to choose whether it uses a system version of a package, or installs its own version (perhaps an updated version). Of course it goes without saying that it should handle multiple versions of packages side-by-side.
The problem is that the linux tools are for the whole system and not individual projects which is why people generally don't look there.
That's a bit of heavy handed solution and does not work if my development environment is OS X. That's why people like tools like virtualenv.
It can't be solved by yet another language-specific package manager. A cross-platform package management tool with local workspaces is not a Rust-specific need, and will never be a full solution if it can only deal with Rust.
So, we couldn't do json::Encoder here since it's a runtime decision which one to use. If we were to add an impl for `&amp;mut Encoder`, wouldn't it have to use dynamic dispatch anyway (in which case it might be easier to just make `encode` use a trait object? Or would that let us monomorphise the 'known at compile time' case, but still use vtable lookups for the 'known at runtime' case?
Awesome! Do you have any recommendations for organizing this event?
Do you know where he's developing it? "Versions.io" is not among his GitHub repositories and it does not show up in Google either.
Why does it need to be a "full solution"? Trying to solve every problem for every language community sounds very ambitious.
I've encountered some of these bugs, but I agree with lucian - I think that their presence does not indicate wrongness of the whole rustpkg model. When I was reading documentation for rustpkg, I thought: "That's one of the greatest package managers I've ever seen. It supports both system-wise and project-wise packages; it has convenient directory and locations semantics; it is able to automatically identify and download dependencies of the given crate; it has integration with version control systems". Yes, there is a number of issues, and some lack of functionality (for example, I would like to have an ability to override version number detection so it won't use version control tags), but there is no reason to dismiss the tool for them completely, I think.
We used to have such a thing in early Rust (probably earlier than most people here remember) :) and it was removed due to being awkward to use.
Why not?
I proposed they use 0install (http://0install.net/) a while ago, which is cross-platform (Linux, Windows, OS X, BSDs), language-neutral and can (optionally) integrate with distribution package managers too. At the time, they said it had: "Too many concepts and moving parts. We kept degrees-of-freedom to a bare minimum with cargo, and there are still probably too many. We might well shave more." Maybe they now feel they need some of those features? There's a page summarising the situation here: http://0install.net/why-not.html
&gt; Easier to use than gnu-text for localisation/adding content. I agree on this point. &gt; Multi-languages (not programming language). ;) Multiple language on wiki often means different levels of quality. I strongly prefer a good doc in english than a partial or not updated doc in my natural language that can mislead me. &gt; Wiki. Not really compatible with documentation in code comments. &gt; Not designed for web doc -&gt; Firefox building system. I don't understand this point &gt; MDN will have a new section for newcomer and new developers. -&gt; https://wiki.mozilla.org/MDN/Learning_Area It can be donne without moving all documentation to MDN, isn't it? I agree documentation should handle a way for the users to provide feedback allowing to suggest improvements. But MDN don't seem the good way to do that for me.
Oh I forgot about 0install, but I was quite a fan of the idea when I first read about it. I always thought a distro should be built on it, just to see what that would be like.
`Makefile`s
I suspect I or nicalsilva would be fine choices to host the event in the Moz space. I've never hosted one; I think he knows more about the process than I do, so maybe I'll try to twist his arm into hosting and let me apprentice under him in the process. :)
Rust libraries often use native C libraries, and those libraries use more C libraries. You need a package manager to at least retrieve security updates and avoid a lot of pain. Why not start with [Zero Install](https://en.wikipedia.org/wiki/Zero_Install) and adapt it to Rust if necessary?
Such attempts are reinvented every now and then. Sometimes platform/language specific (e.g. ant, maven, distutils). Some wants to be a general build system (make, cmake, scons, autotools, and myriads of others). They all suck in their own ways.
Hm, I think I'm talking more along the lines of a package manager than a build system. A package manager that resolves dependencies and triggers the build system for packages as necessary. Since outputs depend on package configuration, packages or languages would need to provide a method for the manager to determine what outputs are generated. For example, a tool like rustpkg, instead of actually building the binary "myprog.so", could just output information such as myprog.rs -&gt; myprog.so; uses somecrate and someClib and the manager would fetch these packages and run "configure; make" or whatever for `someClib`, and `rustc` for `somecrate`, and install them before doing so for `myprog`.
I would appreciate it if the HTTP examples changed from using LF (`\n`) to using CRLF (`\r\n`). As observed in [RFC 1945, appendix B, Tolerant Applications](https://tools.ietf.org/html/rfc1945#appendix-B), &gt; The line terminator for HTTP-header fields is the sequence CRLF. &gt; However, we recommend that applications, when parsing such headers, &gt; recognize a single LF as a line terminator and ignore the leading CR. It is merely a *recommendation* that servers support LF-only; there are doubtless servers out there that don't function correctly with LF-only.
And what about windows?
Yes, `&amp;mut Encoder` implementing `Encoder` would use dynamic dispatch, but it would be *optional* unlike always using a trait object in `encode`; people who know which `Encoder` they are using can still get static dispatch (which isn't possible when `encode` takes a trait object).
This was my first commercial contract for Rust: an API client library for [Diffbot](http://diffbot.com/) in Rust. Diffbot provides a service which is a "visual learning robot that identifies and extracts the important parts of any web page". I'm really pleased with how the GitHub + Travis CI + Rust CI combination works; combine it with Rust's built-in testing support with `#[test]` and it's a pleasure to test! Travis CI even allows the encryption of a valid Diffbot API token, which is a secret, so that it will only work when tested from the one repository. There's not much fancy HTTP juice here; it's mostly straightforward GETs but it does let you POST a text/html entity body, which is slightly interesting. rust-http is not complete but it is entirely up to this task. This library also conveniently shows how rust-http and JSON can be combined. I wanted to extend it much further and load the JSON into appropriate structures, which would make the result *enormously* easier to use, but Diffbot say that they're going to be expanding the number of public APIs quite a bit and don't want something that needs that much maintenance at present, so it's JSON-only for 1.0. (A pity—I was looking forward to playing around with procedural macros, which one of my ideas on the topic would have used.) Later we might have a 2.0 release doing it in a more idiomatic fashion. (P.S. I'm available for further commercial contracts if you've got any other development you'd like done.)
If somebody wrote a successful multi-language package manager in Rust, it might count as a 'killer app' and heap increase the popularity of Rust further.
&gt; _is cross-platform within reason_ better?
Well, our current `{:?}` doesn't use the implicit ability of going through trait objects, so we can totally keep it without having monomorphic (over the `TyVisitor`) `visit_glue`.
Regarding DST, if this isn't going to be used by growable vectors, couldn't this be solved with constant parameterisation? fn foo&lt;T, static N: uint&gt;(xs: [T, ..N]) { ... }
 extern "rust-intrinsic" { fn abort() -&gt; !; } #[no_mangle] pub extern "C" fn rust_stack_exhausted() { unsafe { abort() } } should fix that. (Edited to be better.)
Perhaps rustc can just inject that snippet when a lang item isn't defined.
That would imply there is something wrong with the design. All arguments I've seen so far point out bugs.
So the consensus on the whole select() vs clone() vs split() for streams was to go with clone() (or dup() since it fails)? That feels ugly to me, I'd personally prefer the de-structuring of TcpStream to (TcpReader, TcpWriter). But we will see what happens. (I'm just intrigued by this since my current project is blocked on some form of async TCP I/O. Looks like a whole lot of threads rather than the (e)poll() I would have gone with in C/C++, so that could be fun).
Sadly, it only works in cygwin. I don't think there's a fundamental reason why it wouldn't work, though. Nix does indeed solve this problem quite nicely.
Well, Qt switched to their own JavaScript engine exactly because converting QLists/QStrings/... to their respective JavaScript (v8) types was to heavy.
I would definitely like to see something like 0install used. The Rust devs already have a long todo list without re-re-re-implementing package management too.
As would I, this is disappointing news; a default system is a huge part of what made Go so easy to adopt. I'm not looking forward to the replacement war, where libs are scattered between competing and incompatible systems. A default packaging system doesn't need to do it all either; there will always be those with extraordinary needs, and for those people there are a variety of established tools (make, scons, gradle, etc.). edit: [This post in the thread notes some issues with rustpkg](https://mail.mozilla.org/pipermail/rust-dev/2014-January/008238.html) The points mentioned seem to be reasonable issues, though I'm not quite understanding why they can't simply be posted as issues. Is it simply that no one wishes to maintain rustpkg? 
At least, that’s the impression I have. Maybe it’s because it’s easier to do some things than in class-based inheritance, like taking a class and replace/add some element to it, that I’ve this impression.
I know Rust since 0.4 if I remember correctly, and I really wrote some pieces of code since 0.6. I guess Rust 0.1 and Rust 1.0 are two completely different languages. \^\^
Are there any plan to add this kind of inheritance (before 1.0)? I’ve already read that and that seems really interesting.
In bocca al lupo! :)
I have fixed SIMD bit shifts. SIMD division will take some more thinking. Since divide by zero is an undefined behavior in LLVM but not in Rust, zero checks need to be inserted and I need to figure out how best to zero check SIMD vectors.
I agree, it's not clear to me why nobody is talking about fixing it.
http://metajack.im/2013/12/12/building-rust-code--using-make/
I like this approach as well. +1
I don't think so, since it's backcompat.
I can only wonder *why* make it 2 characters when 1 suffices.
Not necessary, agreed, but it makes this argument in favor of rust stronger
I would rather std be improved to support rust-core's use cases.
It already does now, there are safe types like Arc and RWArc that synchronize access to shared memory. If you want unsynchronized access you need unsafe code atm.
I can see people confusing the game with the language. It's unfortunate. The subreddit of Rust (the game) is here: http://www.reddit.com/r/playrust
Darn, I'm an undergrad. :(
Adding a [Share kind](https://github.com/mozilla/rust/issues/11781) is planned and will allow for sharing immutable data between parallel workers without reference counting, and lending out mutable data without locks. A vector can already be partitioned into disjoint mutable slices, and it will be possible to give these to parallel workers without copies or locking.
[rust-core](https://github.com/thestinger/rust-core) includes instructions on how to work around the various problems with the compiler in the README.
The morestack code isn't going to work in many freestanding use cases, so I don't think this error should be hidden.
&gt; The actual package manager Nix is cross-platform and I too think that the concepts of Nix are worth a closer look. Zero Install works on Windows today and has existing cross-platform repositories.
To add to what others have said, Servo today uses shared memory concurrency extensively to great effect.
(The safe types are in [extra::arc](http://static.rust-lang.org/doc/master/extra/arc/index.html).)
I think some writeup on this would be interesting to read and would attract the right kind of publicity for Servo.
Need a few PRs to land first: https://github.com/mozilla/servo/pulls/pcwalton There's exciting performance stuff in the works for Servo…
The other thing stopping Rust from taking over the world ist documentation. Currently i am most efficiently learning about the functionalitiy in libstd by reading the source code.
May i ask what are the implications for current code? What's the replacement for do?
No (sugary) replacement: do spawn { foo() } // becomes spawn(proc() { ... }) // or (if the contents is a single expression) spawn(proc() ...) There's [talk](https://github.com/mozilla/rust/issues/11892) of adding a macro that allows for spawn! { ... } but this would just be a normal macro, no compiler magic required.
I'm hoping this may open the door for monadic do at some point, after HKT exist.
I agree! Would love to see how to do some data-parallelism in Rust.
Will this allow for mutation on vectors similar to this, not working, example: http://lpaste.net/99248
Me too!
Maybe something like v.mut_chunks(n / p).parallel_map(|chunk| { for x in chunk.mut_iter() { x *= x } }) You'll have to have separate slices into the vector: all threads directly indexing into &amp; modifying the same vector is impossible for the compiler to statically verify as safe (in general).
I tried with: use std::vec; use std::iter; fn main(){ let n : uint = 16; let p : uint = 4; let mut v = vec::from_fn(n, |x| (x as f64) ); for chunk in v.mut_chunks(n/p){ do spawn { for x in chunk.mut_iter(){ *x *= *x; } } } println!("{:?}", v); } But it doesn't typecheck. Can this be fixed or would that create unsafe code?
`unsafe` code will work, but we will be able to do it in safe code with the `Share` kind, as /u/strncat said.
The op asked about "shared memory parallelism". Would you consider this the same as concurrency?
I'm new to Rust, and I thought do made some nice syntactic sugar. Can someone explain why it's being removed? Edit: I found [this issue](https://github.com/mozilla/rust/issues/10815), but I still don't see how option (a) is better than option (b). Other than ease of implementation, I suppose.
I'm really sad to see do go. I think the ({}) stuff is really hard to read. :(
spawn! { ... } is really easy to read though.
Servo uses both: concurrency to enable "everything off the main thread", and parallelism to make layout/rendering/etc faster.
Why wouldn't it? It transforms into `foo(bar, |baz| { ... })`, which is a relatively trivial transformation. If you're unconvinced, I might write one up :)
I just don't like the whole ) after } thing, and you wouldn't be able to make a macro that invokes like: foo!(bar) |baz| { block }; , because it'd turn into something like: foo!((bar) |baz| { block }); Edit: now foo!{(bar) |baz| { block }}; would maybe look decent. It's the mixing ) and } that puts me off, but two } after one another doesn't look half bad.
Do you have an example of how I would change the code to do this with unsafe? I've played around with the obvious stuff and couldn't get it to work. It seems that the main problem is that the chunks are of type &amp;mut [f64] which doesn't fullfill the Send trait.
Yeah, it's a shame...
In the past, at least, undergrads (especially those with pre-existing research experience) have been considered. It can't hurt to apply!
&gt; Is it simply that no one wishes to maintain rustpkg? It's certainly true that when I announced I was leaving Mozilla and wished to transfer ownership of rustpkg, no one was interested in taking it on. But that raises the question of who would do the rewrite, and -- probably more importantly -- who is going to be willing to *maintain* the rewrite long-term. I think it's unlikely that that person is going to be a paid Mozilla developer, so we would be looking at volunteers; from a volunteer perspective, it's relatively easy (and exciting) to get started on a new project from scratch, but understandably hard to commit to maintaining one and fixing the long tail of bugs.
I think it's also worth linking this post: http://smallcultfollowing.com/babysteps/blog/2013/06/11/data-parallelism-in-rust/ It's a bit old already but still quite valid.
The macro could be `foo!{bar, |baz| ... }`.
I think I'll wait till next year, I'm not sure I could contribute at the level I would expect from myself in such worthwhile positions. Besides, I'm still learning Rust (and love it!) :)
Me too. I really liked the "do" syntactic sugar (for both, procs and stack closures)
At runtime? That won't be type safe. Just to make that clear: Classes are prototypes for the compiler. 
I saw this on /r/compsci. [Link to the original submission](http://www.reddit.com/r/compsci/comments/1wk37s/an_empirical_investigation_into_programming/).
Things that might be desirable for Rust 1.0: * What's the equivalent of OpenMP in Rust? Fork/join parallelism (i.e. tasks bound to a lifetime, instead of being dynamic) * How to implement nginx in Rust? Async I/O API? Better green tasks? (and whether this requires compiler changes) * How to interoperate with C++, COM, Java and .NET code (things like ability to have explicitly vtables, etc.) * C-compatible bitfields (for full support of C APIs) * &amp;my/&amp;move pointers * Potentially removing ~ in favor of implementing as a library * Full support for writing OS kernels and similar * Documentation with rules on how to write unsafe code that doesn't break Rust semantics * Review of all unsafe code, replacing with safe code whenever possible with no downsides * Database access API * Decide whether #[deriving(Clone)] and similar should be implicit Other ideas, either for Rust 1.0 or &gt;1.0 * Enum datatype refinements * Variadic generics * Integer generic parameters * High-order generics * Arbitrarily long integer types (e.g. u24, u1000) * Bitfields * Continuation-passing transform support * Syntax sugar for monads * Effect system * Optional cross-thread GC * Running Rust on GPUs * Language-level security manager * Support for HTML code with embedded Rust and viceversa for web apps * Software transactional memory * Hardware transactional memory * Functional persistent data structures 
&gt; How to implement nginx in Rust? Async I/O API? Better green tasks? (and whether this requires compiler changes) I'm wondering about this too. Green threads are a wonderful way of doing async I/O &amp;ndash; but with segmented stacks removed, I have no idea how this'll work out. &gt; Support for HTML code with embedded Rust and viceversa for web apps We already support quasi-quotes. You could probably write a HTML macro now, if you felt like it :p &gt; * Continuation-passing transform support &gt; * Syntax sugar for monads &gt; * Language-level security manager Too high level for a systems language, I think. I also don't know how a CPS transform would interact with ~~regions~~ destructors &amp;ndash; TCO was dropped for this reason, after all.
&gt; Software transactional memory &gt; Hardware transactional memory I think these would be the same feature, using hardware transactional memory where available.
I don't think you're quite understanding the purpose of 1.0, which is "language-stable public release". &gt; Documentation with rules on how to write unsafe code that doesn't break Rust semantics http://static.rust-lang.org/doc/master/rust.html#unsafety &gt; C-compatible bitfields (for full support of C APIs) It's pretty hard to have C-compatible bitfields when they don't even have a defined ABI. Furthermore I don't think they're important, I would categorize them under "language bloat".
&gt; What's the equivalent of OpenMP in Rust? Fork/join parallelism (i.e. tasks bound to a lifetime, instead of being dynamic) Nothing yet, but there are plans to [provide compiler support for certain "kinds"](http://smallcultfollowing.com/babysteps/blog/2013/06/11/data-parallelism-in-rust/) to allow libraries to implement this safely themselves (at least, to expose an entirely safe API (not necessarily safe internals), without having to make the API too restricted). 
Is nginx written in C? I believe there is no fundamental reason why we couldn't use exactly the same techniques it uses, in an equivalent Rust program/library (sure, the async I/O might not be in the stdlib, but then it's not in C's "stdlib" either). (Especially with the slow movement of the stdlib to be more and more freestanding.)
Interesting! However, I'm not sure how much applies to Rust, since it doesn't attempt to be a beginners language at all (without any evidence, I'd think that a new programmer would struggle to get started if they had to fight mutability and explicit lifetimes).
I think we'll probably end up creating an event-loop-based async i/o api, on top of libuv, but not for 1.0
You're looking for playrust, not the programming language. 
An RAII model doesn't prohibit more detailed error checking. Something like this is totally possible: struct File { .. } impl Drop for File { fn drop(&amp;mut self) { ... } } impl File { fn close(self) -&gt; Result&lt;(), (FileError, File)&gt; { ... } ... } A user can either simply let the file fall out of scope or manually close it and handle the result. 
&gt; Syntax sugar for monads Why is this too high level?
&gt; TCO was dropped for this reason, after all. [That is not at all correct](https://mail.mozilla.org/pipermail/rust-dev/2013-April/003557.html); in many ways lifetimes/regions work more naturally with recursion than with loops. When handling `&amp;mut`, loops occasionally require some (safe) tricks to convince the compiler that everything is OK, while recursion basically works first time, every time; especially with recursive data structures like singly-linked lists and trees.
Whoops, I meant to say *destructors*. Thanks for pointing that out.
I had been waiting for post this; I only recently found the link posted at the [codemesh site](http://www.codemesh.io/#felix-klock-ii) It seems like the "slides" link at the codemesh site might be incorrect. For now, you can find the [slides posted here](http://pnkfelix.github.io/present-rust-codemesh2013/fklock-rust-codemesh2013.pdf) also (previously seen on reddit).
Why not have those integrated into Rust windows install package instead?
As a newbie, reading x &lt;- safeDiv(a, b); y &lt;- safeDiv(x, c); z &lt;- safeDiv(y, d); Some(z) would you expect it to allocate three closures? `do`-notation takes these runtime costs and sweeps them under the rug. That's okay in a magical compiler that would have optimized them out anyway (like GHC), but I don't think we should expect this from Rust and LLVM. (Re-reading this comment, `Option` was probably a poor example. A better one would be a parser or a continuation monad.)
&gt; Syntax sugar for monads I'd settle for proper monads first. That is, higher kinds. In general, the type system should see some overhaul, streamlining and proper theory now that it's not as much of a moving target.
A fresh example: a nice [write-up of CVE-2014-0038](http://www.openwall.com/lists/oss-security/2014/01/31/2) that got assigned today for Linux kernel &gt;= 3.4. Local privilege excalation mostly due to raw cast. [Sparse annotations] are there, but you need another external static checker to catch it (this was also behind an kernel-config #ifdef). By using **proper** different types for user/kernel pointers and forbidding raw casts, the rust compiler can mostly keep you away from this kind of flaws (no runtime involved here).
Come to think of it the closest existing system I can think of is [Homebrew](http://brew.sh/).
I would prefer a library-based approach like e.g. nVidia's thrust (which has openmp, tbb, and cuda backends).
I think variadic generics should be in 1.0.
That would be handy, yeah. If bors could handle this directly, I think that would be best. But I'm not sure if it's set up to do this. I also don't think bors has enough build resources at its disposal. If people think this is really useful, however, I can attempt to deploy a "bors-lite" build service.
I'm not sure what you mean -- have what integrated into the rust Windows install package?