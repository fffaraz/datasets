https://github.com/rust-lang/cargo/issues/2654
I'm sure I had all dependencies downloaded while building other crates.
I'm looking forward to your comparison with FCL as well! I did not know this library and its seems we use similar algorithms (their implementation is less extensible though). I expect them to be faster though because there are many places where ncollide still uses generic algorithms where more specific ones could (and will) be implemented (e.g. for box-box collision detection). Btw, I would be very grateful if your benchmarking code ends up open-source. That would help tracking the performance comparison over time! About robotics, keep in mind nphysics does not have stable kinematic chains yet (nor supports reverse-kinematics explicitly). But, as everything this is just a matter of time.
I use it everyday at work, without such simple feature every editor will be editor and please don't call it IDE as it's offensive to IDEs :)
And you might also want to use [`npm dedupe`](https://docs.npmjs.com/cli/dedupe).
Yes, this is planed in my mind. We will be able to read options from Cargo.toml so you won't need to type in every time. The only issue is I haven't seen any tool that creates a custom section in Cargo.toml. Is there any best practice or convention for that?
It's probably using the gcc crate, which is configurable using environment variables. Mingw doesn't have a cc.exe, so try creating a CC environment variable just set to "gcc" On msvc, it will use cl.exe instead of cc so should just work.
While you're thinking about it, github enterprise users have different domains. E.g.: pushing to entreprise github's gh-pages branch for a repo at https://YOUR-DOMAIN/YOUR-USER/YOUR-REPO will result in a pages link that looks like: https://YOUR-DOMAIN/pages/YOUR-USER/YOUR-REPO May also be worth supporting :)
&gt; Well, if you want to do a linguistic task without linguistic information Huh? Levenshtein distance uses _no_ linguistic information at all: it simply counts insertions, deletions and transpositions in a sequence of tokens from some finite alphabet: letters in word, words in a sentence, alleles in a DNA sequence, or pixels in an image. Phonetic semantic hashes like soundex on the other hand make _exclusive use of linguistic information_, determining if the two spellings result in two sequences of phonemes and thereby two pronounciations which to a native speaker would sound alike. This is why phonetic hashes can _only_ be applied to words, and often only words in certain languages. Now of course, as I mentioned in my spellchecker example, you rarely use phonetic hashes alone: you often add other sources of information like edit distance, though ideally one incorporating linguistic information regarding the likelihood of certain transpositions (Jaro-Winkler is one such algorithm). You can also use language modelling algorithms like Knesser-Ney to create a distribution over what the misspelled word should be, given the preceding sentence. Interestingly, like Levenshtein, this is not a linguistic method. It operates simply on sequences of tokens from some alphabet, which is why the Sequence Memoizer language model can also be used to compress binary data. In recent times there have been some improvements: rather than have developers manually create mapping from spellings to phonemes in a hand-crafted hash like Eudex and Soundex, people instead use Hidden Markov models to learn how observed letter sequences ("graphemes") map to hidden phonemes. But for the lay-person, phonetic hashing is still useful, it was used in [this spellchecker in 2003](http://eprints.whiterose.ac.uk/689/1/hodgevj2.pdf), as well as aspell for unix, and IBM uses them for [blocking records in data-linkage](http://www.ibm.com/support/knowledgecenter/SSZJPZ_8.5.0/com.ibm.swg.im.iis.qs.ug.doc/topics/c_Applying_blocking_variables.html). Honestly, I'm struggling to understand how you can (a) say that phonetic hashing uses no linguistic information and (b) believe that it will give garbage results. They've been used extensively in the field of information-retrieval for the last 40 years.
You know, benchmarks can be different. Could you specify your setup, code that you've used and benchmarking tool (with parameters ofc)?
Basically a package manager in Rust that helps to install packages no matter which linux distribution you are on?
Thanks for the answer. About the physic engine we use it is PhysX but unfortunately, we didn't found the time upgrade our version (which is 2.7). Last question, I saw in your codebase that you provide a convex hull decomposition algorithm (HACD). Is it based on Khaled Mamou algorithm or a somewhat older version ?
Exactly! It acts as a wrapper around your distributions package manager to convert other distro package names to your own and then installs them.
Awesome! Just a little suggestion: Packer is widely used as AUR helper, suppor it too! :)
The project may be usefull to some people but it adds yet another abstraction layer that increases the complexity. Linux needs some kind of universal package format like Android's apk.
Ah forgot about that one! If you file an issue on the Repo I'll make sure to add it
Great, I just filed an issue!
Awesome to hear. Love the work on regex so far :)
The normal trick is to add a link or something that looks like one onto the end of the paragraph text. It gets people to mouse over and notice it's clickable. In technically inclined groups I've seen in the past about half the people will click the outer target and half the link.
"An integrated development environment (IDE) is a software application that provides comprehensive facilities to computer programmers for software development. An IDE normally consists of a source code editor, build automation tools and a debugger. Most modern IDEs have intelligent code completion." Atom meets this definition and is therefore an IDE. To claim otherwise would merely be denial. In addition, I never stated that Atom doesn't provide support for breakpoints, as it very much does, I just do not have a use for it.
I think you could use it that way. https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.size_hint Relevant snippets: &gt; Returns the bounds on the remaining length of the iterator. &gt; Specifically, size_hint() returns a tuple where the first element is the lower bound, and the second element is the upper bound. &gt;size_hint() is primarily intended to be used for optimizations such as reserving space for the elements of the iterator, but must not be trusted to e.g. omit bounds checks in unsafe code. An incorrect implementation of size_hint() should not lead to memory safety violations. 
I'm curious: does the Haskell community tend to follow semver closely? And does cabal take this into account?
I've used default settings for minimal example to test all 3 solutions and run siege. I don't have source code, make hello world in 3 of them and check yourself... These are not apache and nginx in which configuration matter a lot more. Setup was xeon 8 core processor (bare metal) and os was debian jessie. It was compiled for release version etc.
[They did](http://refspecs.linuxfoundation.org/LSB_5.0.0/LSB-Core-generic/LSB-Core-generic/swinstall.html), and it is called RPM. Unsurprisingly, pretty much nobody gives a shit.
Fist, I like it. Adding a max version too could lead to a dead-lock like situation in the future so I hope the implementors will think of this.
This was [already proposed and knocked back](https://github.com/rust-lang/rfcs/pull/457).
I think it makes sense. One of the projects I contribute to has their CI test rust 1.3, stable. And nightly. So we know it works back to then, but this isn't documented anywhere and not communicated well to the user. If this was stated explicitly and caught by the compiler (or Cargo, where I would think this logic actually belongs) by using a min-rustc in Cargo.toml I think it'd improve the ecosystem. Why don't you file a bug on Cargo and see what happens?
The [self.reserve()](https://doc.rust-lang.org/src/collections/up/src/libcollections/vec.rs.html#1388) call in that code pre-allocates based on the iterator's size hint.
It be great if this supported gitlab as well, which uses gl-pages for their page hosting branch. Though a name change to git-pages-import might be in order then.
Been working on Dyon the part few days, and managed to tidy up the language a bit. Enjoy!
Ah, you are correct.
&gt; Today, Cargo will automatically share dependencies between crates if they depend on the same major version (**or minor version before 1.0**), since Rust uses semantic versioning. This is both a blessing and a curse. On the one hand I think this is one of the reasons that Cargo and crates.io work so well, but on the other hand, most of the crates.io ecosystem does not use semantic versioning at all. Instead, the versioning pattern is `0.major.minor-or-patch`. Currently the top 10 most downloaded crates on crates.io are all unstable. These are crates with lots of users and lots of crates depending on them. They are battle-tested. Nine of them have been around since before Rust 1.0. Yet they don’t deserve a 1.x version number? I understand that sometimes there are good reasons to not call a crate stable, but I think in many cases authors are overly conservative. Even the `num_cpus` crate — a ~100-line crate that exposes a single function — is still unstable. (I don’t mean to pick on that crate, it is simply an example of a crate that in my opinion is overly conservative in its versioning.) Rust has been stable for over a year. Version 1.0 of a crate doesn’t have to be perfect, that is what 2.0 and later versions are for. I think crates.io is at risk of 0.x versions becoming de facto stable. It has happened before with [Hackage](https://hackage.haskell.org/), Haskell’s package ecosystem. Cornerstone libraries such as [`bytestring`](https://hackage.haskell.org/package/bytestring), [`attoparsec`](https://hackage.haskell.org/package/attoparsec) and [`tagsoup`](https://hackage.haskell.org/package/tagsoup), and popular frameworks like [`snap`](https://hackage.haskell.org/package/snap) are still in the 0.x versions, despite having been available for almost ten years (five for Snap). Hackage does not encourage semantic versioning the way Cargo and crates.io do though, and a four-component version is common on Hackage. I have one idea that might help push stable versions a bit more without breaking compatibility: colour 0.x version numbers red when Cargo prints what it is downloading and compiling. And maybe even make stable versions green, at the risk of having the output look like a 70s disco party. It is not a behavioural change, but it appeals to the “red is bad, green is good” intuition.
[Ran into this with `regex`](https://github.com/rust-lang-nursery/regex/issues/206) a few days ago. It's on the libs team agenda to discuss (at least as a matter of policy for `rust-lang(-nursery)?` crates), but we haven't yet.
The linked post describes how webkit overhauled its locking infrastructure, and how it implements its own `Mutex` and `Condition` to be as lightweight as possible (memory wise).
&gt; I get paid to make lights change patterns on a screen and I can't imagine doing anything else. Best description of a developer I've seen in a long time!
Right. Still seems worth addressing. It feels weird to break others' code so blatantly. :-/
[Image](http://imgs.xkcd.com/comics/standards.png) [Mobile](https://m.xkcd.com/927/) **Title:** Standards **Title-text:** Fortunately, the charging one has been solved now that we've all standardized on mini\-USB\. Or is it micro\-USB? Shit\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/927#Explanation) **Stats:** This comic has been referenced 2863 times, representing 2.6096% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_d2vci2b)
Hahaha I'm glad you got a kick out of it.
Great work! :) I'll just highlight that Flattr-button you hid ( http://ncollide.org/about/ ), because you do deserve some of that! Even more since it seems I was your first flattrer :)
I agree. This would have helped avoid the fallout from [this openssl PR](https://github.com/sfackler/rust-openssl/pull/385).
Looks like `pre-` (press MIR on http://is.gd/hZizzC), didn't think about this... This would make it quite tricky to generate C from it... Maybe C++ with templates? The latter are duck typed so it should be possible.
If I'm not mistaken, this will evaluate to false on `baz(Ty1(123), Ty1(456))`, while the OP wants to only compare the tag, not the contained values.
My comments in that thread are still relevant. I’ve been [playing with PDF generation](https://github.com/mbrubeck/robinson/pull/8) a bit, but that code is nowhere near complete. (Axis-aligned RGB rectangles! … that’s it, for now :))
Thanks I'll check this out! https://github.com/redo-studios/exoskeleton/issues/1
Ah, yes. Nice catch. /u/rs12ji , you'll have to implement `PartialEq` yourself for this: http://is.gd/xsWopz
Depends. See the problem is that the cost of rewriting increases much faster per extra LOC than converting. As your system becomes bigger and bigger it becomes an issue with regressions and such which end up surpassing the cost of modifying the code. Generally what you want to do is a hybrid solution. You alter the existing code to modularize it into smaller and smaller sections. Because these are non-functional changes (the kind of stuff that can be done entirely through refactoring) it shouldn't be too hard of an improvement. Once the parts are small enough you can focus on starting from scratch each individual part. This makes it small enough that the extra cost of handling regressions and compat issues. Moreover some parts might be easier to split, parts that are easy are given to junior devs, parts that are hard and have a high ROI are given to teams and have design docs made, the rest waits until it makes sense to handle it.
This is the first post in the series of more technical blog posts about the Dropbox project that contains Rust! This one is a high-level overview, and doesn't talk about rust specifically, but I still thought it might be relevant.
What if the GitHub repository were mirrored to S3 and used as a fallback? Degraded performance is certainly preferable to total downtime.
Rewriting tarpc on top of mio. Progress is [here](https://github.com/tikue/tarpc/tree/async?files=1).
I'm holding my upvote until they actually get around to talking about Rust. :P
Agreed. May be this post encourages more folks to write other queues :) 
I think this is a great idea. If it helps any, in the Haskell world two versions of this effectively exist, and I have had a good experience with both of them. The first and older one is that [GHC's base libraries](https://hackage.haskell.org/package/base) are a semantically versioned package (i.e., "crate") that your projects have to explicitly depend on. This library is released with the compiler, so by depending on a specific range of versions of `base` you implicitly lock down a range of compiler versions. The second, newer mechanism is that the [Stack build tool](http://docs.haskellstack.org/en/stable/README/) ties package snapshots to specific compiler versions. For example, the [LTS-5.15 snapshot](https://www.stackage.org/lts-5.15) is tied to GHC 7.10.3. One of Stack's neater features is that it automatically downloads and installs the compiler version specified by the snapshot that you're building the project against—this isn't just convenience, but also part of the goal of making builds perfectly reproducible. For example if you were to clone [this project of mine](https://github.com/sacundim/tau-sigma) and run a `stack build`, the [included `stack.yaml` file](https://github.com/sacundim/tau-sigma/blob/master/stack.yaml) (the rough equivalent of `Cargo.lock`) would guide Stack to build with [LTS-3.20](https://www.stackage.org/lts-3.20), which is tied to GHC 7.10.2 (the version just before the current one). But if I want to try building against a later or newer snapshot I can just override it in the command line and see what happens: $ stack --resolver lts-5.15 build Downloaded lts-5.15 build plan. Caching build plan Fetched package index. Populated index cache. While constructing the BuildPlan the following exceptions were encountered: -- While attempting to add dependency, Could not find package Chart-diagrams in known packages -- Failure when adding dependencies: Chart-diagrams: needed (-any), stack configuration has no specified version (latest applicable is 1.7.1) needed for package tau-sigma-0.6.0 Recommended action: try adding the following to your extra-deps in /Users/luis.casillas/GitHub/tau-sigma/stack.yaml - Chart-diagrams-1.7.1 You may also want to try the 'stack solver' command It won't work! Well, trying the suggestion in the last line of the output, we can do this: $ stack solver --resolver lts-5.15 Using configuration file: stack.yaml Using cabal packages: - tau-sigma.cabal Using resolver: lts-5.15 Using compiler: ghc-7.10.3 Asking cabal to calculate a build plan... Trying with packages from lts-5.15 and 2 external packages as hard constraints... Successfully determined a build plan with 7 external dependencies. The following changes will be made to stack.yaml: * Resolver is lts-5.15 * Dependencies to be added extra-deps: - Chart-diagrams-1.5.4 - OneTuple-0.2.1 - SVGFonts-1.5.0.0 - mersenne-random-pure64-0.2.0.5 - text-1.2.2.1 - tuple-0.3.0.2 * Dependencies to be deleted extra-deps: - pipes-csv-1.4.3 To automatically update stack.yaml, rerun with '--update-config' So now I can rerun the `stack solver` command with `--update-config` as suggested, and then run `stack test`, and if the latter succeeds (which it didn't -_-), then voilà, I've upgraded the project to a new snapshot (newer compiler and library versions).
You also need to go to a top school. 
*and go to a top school, that too. 
Your `print_iterative` is almost there, but you've misplaced your `ref` keyword. The `&amp;Some(x)` pattern needs to be `&amp;Some(ref x)`, or else it will try to _move_ the node into the local variable `x`, rather than just taking a reference to it. That means you're taking apart the list, when you just meant to iterate over it. It fails to compile for two reasons: 1. You're trying to stash a reference to `&amp;x.next` right before the node owned by `x` gets dropped at the end of the loop. This is the lifetime error I see when I compile your code. 2. `current_link` is a shared reference, and you can't move a value out of a shared reference. You'll see this error if you hack around the first one. The only other problem is that `current_link` needs to be `mut`, because you're assigning to it. This version works: pub fn print_iterative(&amp;self) { let mut current_link = &amp;self.head; while let &amp;Some(ref x) = current_link { println!("{:#?}",x); current_link = &amp;x.next; } } *Tons* of related examples in [*Learning Rust With Entirely Too Many Linked Lists*](http://cglab.ca/~abeinges/blah/too-many-lists/book/README.html). Edit: Actually now that I look closer, I'm guessing you adapted the linked list from there :)
AFAIR there is an intrinsic to get the discriminant of an enum, but it's unstable.
I fear that if left to the developers of individual crates, we'll end up with most people declaring the version they themselves used the minimum since it may be difficult to know what specific version is the lowest possible without testing every version and ain't nobody got time for that, you know. Speaking from experience with attempting to declare lowest possible version of whatever dependencies or systems I've been relying/building on in other languages.
For those who, like me, were unclear on what CountTree is, here's the relevant bits from the documentation: &gt; Counting tree implementation. &gt; &gt; When should you use CountTree? &gt; &gt;* You want to maintain a possibly large unsorted list. &gt; *You want to access, modify, insert, and delete elements at arbitrary position with O(log(n)) time complexity. &gt; * You can tolerate O(n log(n)) time-complexity for (not implemented yet): &gt; * splitting at arbitrary position &gt; * truncating the length (complexity unclear) &gt; * appending another list (complexity unclear) &gt; * You have less than 4.29 billion (u32::MAX) elements!
Will these type (core?) of libraries be promoted to stdlib in the future?
I think a successful build/test of a project should get logged in the Cargo.lock and part of that logging would be the platform/version of the compiler. Edit, and since there are crater runs every so often, it could build everything on crates.io with multiple versions of the compiler. This could get logged in available metadata.
~~I don't see a bug here. The `impl Public&lt;Private&gt;`implementation is only available when you actually have access to the Private type. It doesn't allow you to access this impl anywhere else.~~ ~~I guess using pub fn's in impls that aren't pub could be turned into a warning or an error, though.~~
Oh, nvm, wow, this actually compiles (with some bugs fixed in your code). This definitely shouldn't compile. You should really file a bug then.
If you talking about pthread locks (and cond vars) in libraries like glibc, then yes it's possible to create lighter weight version. Take a look at the articles here: http://locklessinc.com/articles/mutex_cv_futex/ . A lot of the speed up comes from not needing to conform to POSIX requirements and then some other trade offs.
Hadn't actually occurred to me about the obvious solution to just implement PartialEq to discard inner values. Although, I already derive it for certain situations, but at worst case, a separate comparison function would suffice. Thanks for the suggestion.
I'm confused as to why this is allowed - `the_module::new_external_public_private` returns an identical type but produces a compiler error. ~~Alternatively, I'm confused as to why `the_module::new_external_public_private` is disallowed - I can think of reasons to allow a public type signature to contain a private component (though it would make it difficult for calling code to store/pass around such a value).~~ Neither interface exposes direct access to `Private` - I can only access that type through the implementation of `ExternalTrait` on `Public`. Am I missing something fundamental?
Actually it's quite easy to know the lowest supported Rust version if you use travis and [configure it to use these versions](https://docs.travis-ci.com/user/languages/rust/#Choosing-the-Rust-version). Or at least you can ensure that it still works with the version you specify.
We'll now we're arguing about what "poorly-specified" means. My argument is that it's up to the author to determine how they want to define the lowest rustc to work with (maybe per-platform). I do think the solution is to have a warning when compiling a crate on a platform/rustc that is below their stated minimum requirements. If the user is comfortable with that, fine. Otherwise they can work with upstream to get the requirement lowered. I don't see a need to make this any more complicated than just a compile-time warning.
What stood out most to me was that they eschewed distributed protocols when designing MP. There is a thread of pragmatism throughout. I especially liked that they choose MySQL instead of a key/value store like memcached, redis, etc. I believe that deeply understanding the technology one uses is superior to adopting (new) technology where the trade-offs are not well known. 
Yeah, we really just needed a fast/reliable place to stow metadata. Dropbox has a really good DBA team, automation, etc, around managing MySQL (we have many thousands of MySQL servers), so that option had the least # of unknowns.
You might be interested in looking at my implementation of a similar data structure for C++. It's implemented using a counted B+tree and offers very good performance for random access insert/erase: also O(log n), but excellent constant factors as well. https://github.com/det/segmented_tree
Because Public&lt;Private&gt; implementation shouldn't be public, as well as all its methods (even the pub ones).
Ah, I understand. The functions defined in `impl Public&lt;Private&gt;` should inherit the visibility of `Private`, but don't.
I will do just that. Just looking for similar bugs right now. [This looks like it could be related](https://github.com/rust-lang/rust/issues/30476)? Edit: [Opened an issue](https://github.com/rust-lang/rust/issues/33479).
Really, really excited to see Helix going live! Congrats! :D
Nitpick: You write: for (int i = 0; i &lt; n; i++) will repeat n times, as n can be assumed to not be negative. I think this example is off: Firstly, if n is of type int, it cannot (in general) be assumed to be non-negative, but if it is, the loop will repeat n times, with or without undefined behaviour on overflow, because no overflow can possibly occur. You probably meant something like: for (int i = 1; i &lt;= n; i++) Here overflow will occur if n==INT_MAX. A naive implementation will either never terminate (if it wraps around) or trap on the overflow. However, since the behaviour is undefined, an optimizing compiler can still produce code which will loop exactly n times without overflow. 
For a start you have two mutable references to one object. You'll need to use Arc and Mutex. A more irony way to do this might be to use middleware: https://github.com/iron/persistent 
I'm lost now, I think there was a misunderstanding somewhere on my part because you seem to agree with what I said? With my first comment, the only thing I wanted to state is that cargo should not fail automatically if the rustc version requirement is not met (like it is proposed by OP). The user should have the possibility to at least try to build the crate. If it fails, the user will not be surprised because he was shown a warning before compilation. I suggested the "yes/no prompt" to make sure the user saw the warning in case there are multiple compile errors pushing the warning of screen and the user would not think to scroll to the beginning. Alternatively the warning could be issued after compilation, but that seems "out of order".
sodiumoxide is a binding to a C library, so probably not - there's currently no good pure-Rust crypto library, and likely won't be for a good long while.
&gt; I’ve tended to be of the opinion that crates.io should play a more active role in maintenance. Things like API-level semver verification as a part of publishing a release, simply by compiling it and comparing and objecting if there are breaking changes. Isn't this what the Elm compiler enforces? It could be a source of inspiration.
And then there's Nix, which just entirely ignores how we assume package managers should work.
The layout of `enum` tagged unions is very much not well defined and should not be relied on at all. An RFC for untagged unions was accepted recently, so hopefully someone implements it soon. https://github.com/rust-lang/rust/issues/32836
Two things: --- You have a temporary pointer (`&amp;T`) inside what you most likely want to be a long-lasting structure. This is guaranteed to cause headaches but it's a little too abstract for the compiler to give good error messages about the root cause. Much like C, you have to think about what owns the keys in the hash map (i.e. what has responsibility for freeing them). The difference is that Rust is more picky at compile time. Solutions often involve `Cow` or `Rc`. --- The signature of `doSomethingElse` implies that it invalidates the iterator when called in `doSomething`. The compiler doesn't look at more than one function at a time when checking memory, so it can only go by what the signature says. And the signature says that `doSomethingElse` is allowed to completely replace the value of `self` if it so desires. One solution is to factor most of `doSomethingElse` into a function whose signature doesn't need all of `self`. This should be free after inlining. Another is to do runtime borrow checking with `RefCell`. This is less restrictive but requires runtime record-keeping, so it's best if you have a slightly more complex case with not too much call volume. Neither will be possible if you are in fact invalidating the iterator by mutating `x` in `doSomethingElse`.
[removed]
/r/playrust 
rusty_nail is going to be the name of my next crate!
&gt; A mutable binding is just a variable that you can assign to with = And, importantly, take mutable references of.
This also seems very relevant in case there should ever be a "Rust 2.0" Release. Would prevent a situation similar to the one with python2 and python3.
That is _so_ beautiful and well-documented, wow! I'm amazed, thanks a lot for putting in so much effort!
&gt; stream.close() Couldn't you use RAII in the Rust binding?
Looks very interesting, especially [these graphs](https://det.github.io/segmented_tree/boost_segmentedtree/performance.html). But I could only find [this script](https://github.com/det/segmented_tree/blob/master/scripts/bench.py) from the repo which looks related in generating them. I'm interested to where (index) the elements were inserted into and deleted from -- completely random?
I did. That's just there in case you want to be able to catch errors confronted in closing out the connection instead of panicking. It'll close itself up if you drop it on the floor. I've added a note to the documentation to that effect. Thanks for letting me know!
What gtk theme do you use?
That's cool!
I just went through all the steps to generate raw numbers in this paste: https://gist.github.com/det/2396b51509146ba4483be2e27a45b720 If you get any errors reproducing these steps then you are missing some dependency. You will need boost, including development headers. If you do not have ninja then you can remove the -GNinja from the command line when running cmake. This is on a i7-6700k and all timings are in milliseconds. I also made sure to put my cpu into a performance instead of powersaving profile before running the tests. You may also be interested in avl_array which is a C++ library that is more similar to yours in that it uses a binary tree. At only 7936 64bit elements, it is not able to beat std::vector for random access insert as its constant factors are too high. It's important to note however, that avl_array provides stable iterators. Summary timings for random insertion of 7936 64bit elements: segmented_tree::seq: 0.239114ms std::vector: 1.26456ms avl_array: 1.28235ms Edit: The cmake --build line was missing a ".", I replaced the gist url with a working one.
Hm, does Glade not let you set up the treeview-related objects as well? The Glade manifest seems to require GTK 3.20. Is that intentional? The [clone!](https://github.com/gtk-rs/gtk/issues/290) macro might be handy to somewhat reduce signal connection boilerplate. Might want to look at the `log` crate and various logger implementations.
Didn't he borrow it from [xkcd](http://xkcd.com/722/)?
[Image](http://imgs.xkcd.com/comics/computer_problems.png) [Mobile](https://m.xkcd.com/722/) **Title:** Computer Problems **Title-text:** This is how I explain computer problems to my cat\. My cat usually seems happier than me\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/722#Explanation) **Stats:** This comic has been referenced 152 times, representing 0.1384% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_d2wvpzc)
I didn't know this existed, but it's very interesting! I was able to read through the readme and fully understand why this is useful, how it works, and where to use it. Thank you for the thorough work!
It's a very good soundex replacement. Soundex is useful for sound-like kinda comparison. In data science I have found that soundex was also useful for classifying names. That said, I do think that the readme's algorithm explanation adds a bit of confusion. The rs file explains things much better 
This is quite interesting but it seems to fail with digraphs: Word | Word | Distance ---|---|---- Few | View | 72057594037927936 Few | Phew | 504403158265496576 Chew | Jew | 360287970189640704 Chew | True | 576460752303465729 Through | Cough | 576460772184424448 To | You | 16861477004875137024 Car | Cat | 188 Though to capture that complexity you'd need a language model which is what Soundex may be using (never looked at their stuff though).
I tried to come up with an easy answer, and realized that the standard library is missing a very useful kind of hash table. The ones it does have are implemented well, but I really want to [intern](https://en.wikipedia.org/wiki/String_interning) the node data. Cargo has a decent, but limited, directed graph implementation. (at `src/cargo/util/graph.rs` IIRC) It would be a good read both to see how it can be done and why you might not want to do it that way. Also see how it's used in the dependency resolution code. It needs reference counting to avoid duplicating the node data. This reference counting isn't part of the `Graph` implementation, it just puts `Rc`'d nodes in the graph. So I'm sorry that I don't have an easy answer. Rust is pretty low-level and the libraries aren't as mature as an older language would have.
I may be wrong, but I believe Rust would have a huge advantage there by being a compiled language. If Rust gets a stable ABI before the 2.0 release, it should be easy enough to allow Rust2 to call into Rust1 code similar to how it calls into C. 
Wondering if'm reading this correctly on how simple this should before filing an issue... 
**Update:** I've lowered the required GTK version to 3.14. I have no experience with GTK programming before this, so maybe I was doing it wrong, but I wasn't able to get the list store that I created in Glade to work with my code so I just wrote it manually, which was simple enough. I'm using Arch Linux which has a nicer Glade than previous versions, although I'm not sure of the specifics on why it would automatically require GTK 3.20. I've done no manual editing of the produced Glade UI.
Whoa! I was designing a library like Helix but it is still in its early stage. And suddenly I found someone have just announced it!
[removed]
[removed]
[removed]
The distance is a XOR metric, so that table is quite misleading. Also, Soundex isn't aware of digraphs. In fact, it is much simpler than Eudex.
I always forget the semicolon after `let foo = Struct { ... };`, so I decided to require semicolons everywhere ... (Not sure if it's really better lol)
Use a BTreeSet, maybe? EDIT: you should be able to derive Hash for such a simple struct.
BTreeSet doesn't seem to be unique EDIT: nevermind, the issue seems to be elsewhere
Depending on the usecase, you need to process the distance in one way or another. Hamming weight is the most obvious: Word | Word | Distance (Hamming weight) ---|---|---- Few | View | 1 Few | Phew | 4 Chew | Jew | 3 Chew | True | 6 Through | Cough | 5 To | You | 5 Car | Cat | 5 For comparasion of words that doesn't sound alike: Word | Word | Distance (Hamming weight) ---|---|---- Write | Amdomino | 50 Facebook | Youtube | 47 Rust | Go | 54 Strange | Office | 46 Surströmming | Merda | 45 Redox | Linux | 60 Note that since the distance is u64, the max Hamming weight is 64. See the `readme` where a modified Hamming weight method is described.
Fixed.
I guess you'd be surprised when I tell you that a simple spinlock with exponential backoff is nearly perfectly fair if there is only one possible critical section for the lock in your code. Rust's Mutex (or most mutex implementations in general) are extremely unfair on the other hand. Furhtermore my own benchmarks suggest that their lock is less than twice as fast as a mutex on Windows and Linux (because that would be optimal performance which they can't achieve), but it could be much more on OS X because pthreads is utter shit there... I think the main advantage of their new lock struct is simply the very compact size.
BTreeSets/Maps need `Ord`, which f64 also doesn't provide.
For reference, there's a reason that you shouldn't use floats as keys: comparing for exact equality between floating point values is almost always a bad idea. Floating point computation is not exact, so rounding errors, order of operations, and numerical instability can mean that two points you would like to consider equal do not actually have the same coordinates. What exactly are you trying to do? You may be better off using an approximate comparison (ie. deduplicate points which are closer than some epsilon distance).
Can you elaborate?
You can derive PartialOrd and PartialEq. Then sort your vec with `.sort_by(|a,b| a.partial_cmp(b).expect("No NaNs")`. This doesn't work if any of your points are NaN (NaN is the reason floats don't impl Ord in the first place. If you want to handle NaNs, you can decide how to do so, and do that instead of unwrapping) You can then use `vec.dedup()` which only requires PartialEq. http://is.gd/G3dVA1
Check out VSCode as well. OSS, and much faster than Atom (despite JS)
In that case, you'd be better off making your octree insertion function resilient to this case rather than handling it as a preprocessing step. Presumably you've implemented it recursively: when you reach a leaf node and decide to split it, first check if the existing point at that leaf node is equal to the one you are inserting. Also, there are a number of related cases that may cause you problems: if you insert two points that are very close together, you will end up with a *lot* of nodes to get to the depth required to separate them. To solve this, you might consider: - Storing multiple points per leaf - Having a maximum tree depth - Only splitting a node when the number of points it contains is more than N Performing a linear search is also more efficient than recursing into a tree for small numbers of items (I'd estimate around ~20 before its worth splitting into a tree, but you'd have to experiment)
I think that having Hyper do verification itself is what Brian is referring to with "I expect it will get easier to do quickly."
funny mistake :)
There is a tracking issues for this https://github.com/hyperium/hyper/issues/472
all good points. I wanted to make the vec unique within the constructor of the tree (not a node). This way there's no required preprocessing by the user and I only need to perform the action once. Maximum depth or minimal count/distance are good ideas
Yup. Definitely what inspired me to put it there considering how perfect that comic was
&gt; comparing for exact equality between floating point values is almost always a bad idea. I can think of a few applications where you need the exact comparison. Most prominently comparing to zero, because division by zero is undefined, but division by a very small number is.
1. I stole ideas from Haskell, Rust, Agda, Scala, Idris, etc. 2. There's no such paper as far as I know. 3. I came up with the idea of `const` and `class`es first and mix them and unexpectedly found that they are Java classes. 4. Surely that Scala has first-class named `impl`. 5. I read a lot of rfcs and think a lot, but I can't think of any particularly important resources.
Do you know of prior work similar to your [modes](https://github.com/AndyShiue/Ende-readme/blob/master/README.md#modes-a-summary)? (that is, different ways to pass parameter to a function) It could be useful to collect relevant bibliography ([Lambda the Ultimate](http://lambda-the-ultimate.org/) may be a good place to search; it's giving an error right now though)
Agda has 3 modes, which are `()`, `{}`, `{{}}`. They are similar to Ende's `()`, `[]`, `[()]`, but I don't remember I've seen anyone actually calling them "modes".
Cool!
There's a lot of value to a language that is planned, rather than grown. 
Interesting, I had almost the same idea for my first rust project. It goes by the slightly awkward name show-rename and you can find it at https://github.com/HessiJames/show-rename. Maybe it can be of value to you. My approach is quite different though, show-rename is cli-only and supports multiple websites it scrapes the data off, imdb being the default. The tvdb back-end has gotten the least love from me and I'm not using their API. I was thinking about writing a GUI as well because I would like to experiment with [qmlrs](https://github.com/cyndis/qmlrs).
[removed]
I'm actually somewhat proud how I'm not too far away from the cargo implementation, but I can see many improvements I can do to my code now. Thanks! 
Awesome. Thanks. It appears it has been redirected now.
&gt; Floating point computation is not exact I think a better way of putting this is that floating point computation is not the same as real number computation. We've mostly gotten rid of x87's fuckyness (altering results based on register allocation, WTF?), but there are still a fair number of situations where floating point and real arithmetic differ. If you take the same inputs and do the same operations, you'll get the same result. The issue is that many mathematical identities like (a + b) + c == a + (b + c) don't hold with floating point numbers.
There's a lot of cool stuff going on in the Ruby + Rust space: mrusty, ruru, and now Helix. I also have started a ruby-sys crate for the low-level bindings.
I'm working on a Tic Tac Toe server using Iron, At first I used /u/cmsd2 's way to pass my "users" and "games" to the middlewares (if you need code reference feel free) but then I decided to just use redis...
What a magnificent beard in that thumbnail.
&gt; first check if the existing point at that leaf node is equal to the one you are inserting. As you said, don't check for equality. Check that the distance between the points is less than `::std::f64::EPSILON`
Good point. People usually don't compile with that flag, though. It tends to cause problems if you have different rounding behavior on different builds of the same software.
Completely agree. I also like the regularity of it. Similarly I tend to put a comma after every match arm, even if it contains a block, because it's easy to be mindless about it.
But dividing through a number very close to zero is often also a bad idea and sometimes even worth an error.
This is the subreddit for a programming language. You're looking for /r/playrust .
/r/playrust would be more likely able to solve your problem.
Well you would just need to adjust it to include the exponents also, not too hard a change to make. I was really just trying to provide a real world example.
Isn't -ffast-math the default in Rust? I can't recall, I just have a vague memory of feeling disappointed at some point when that discussion happened (e.g. C# does this "Let's subtly break programs by default over minor efficiency concerns!" by using the equivalent of the fast math flag). Can't find any information about default floating point behavior in Rust after brief searching though.
There's an [open issue](https://github.com/rust-lang/rust/issues/21690) for providing a way to use an equivalent to `-ffast-math`, so I don't think it's the default or even an option at the moment.
I'm not really surprised. Rust's devs are definitely focusing on eliminating footguns over speed, like with default bounds checks on array accesses and explicit numeric casting.
It's actually forbidden to scrape the website of TVDB, and probably most other TV databases, hence I chose to use a pre-existing TVDB crate for gaining access to the TVDB API. I decided to focus on TVDB as my only source because it has the most comprehensive collection of data for TV series. The main reason why I haven't been pursuing using QML with Rust is because Qt technologies are heavily dependent upon C++, which doesn't mix well with non-C++ languages. GTK is written in C and has really good support for Rust, on the other hand, thanks to the work of the GTK-rs team.
GTK's biggest weakness is precisely that it doesn't have good tutorials. I'm still figuring out things as I go myself. The GTK-rs team has been making GTK programming a lot more approachable though. I'll investigate adding support for optionally defining a template in a future release.
I think the lifetime error may be a compiler bug. Just binding the result of the `match` statement in your original code fixes the error. This might be related to [issue #31439](https://github.com/rust-lang/rust/issues/31439). fn len(&amp;self, prev_lock: &amp;MutexGuard&lt;RefCell&lt;Link&gt;&gt;) -&gt; usize { let next = self.next.clone(); let next_lock = next.lock().unwrap(); let len = match *next_lock.borrow() { None =&gt; 0, Some(ref rest) =&gt; { mem::drop(prev_lock); rest.len(&amp;next_lock) + 1 } }; len } Some unrelated notes: First, dropping an `&amp;T` has no effect, so the `prev_lock` argument serves no purpose. The Arc::clone call is also unnecessary: fn len(&amp;self) -&gt; usize { let next_lock = self.next.lock().unwrap(); let len = match *next_lock.borrow() { None =&gt; 0, Some(ref rest) =&gt; rest.len() + 1, }; len } I think your intent was to unlock the first mutex while processing the next node(s). But Rust won't let you continue to access the data inside the mutex while it's not locked. Second, it's a little unusual to have a RefCell inside a Mutex, since they serve a similar function. If your data is already protected by a Mutex, the RefCell is probably unnecessary. Likewise, having a Box inside of an Arc is an extra level of indirection that is not usually necessary. I think the code could be simplified to this with no loss of functionality: pub struct List { head: Arc&lt;Mutex&lt;Link&gt;&gt; } type Link = Option&lt;Node&gt;; struct Node { elem: i32, next: Arc&lt;Mutex&lt;Link&gt;&gt;, } impl Node { fn len(&amp;self) -&gt; usize { match *self.next.lock().unwrap() { None =&gt; 0, Some(ref rest) =&gt; rest.len() + 1, } } } [(Playground link)](http://is.gd/G4zhsf)
Thank you for the useful tips! I think I realised I was very confused about what I was trying to do. Now I've rewritten the code to look like this: pub struct List { head: RefCell&lt;FineLink&gt;, } type Link = Option&lt;Box&lt;Node&gt;&gt;; type FineLink = Arc&lt;Mutex&lt;Link&gt;&gt;; struct Node { elem: i32, next: RefCell&lt;FineLink&gt;, } impl Node { fn len(&amp;self, prev_lock: MutexGuard&lt;Link&gt;) -&gt; usize { let next = self.next.into_inner(); let my_lock = next.lock().unwrap(); match *my_lock { None =&gt; 0, // this is wonky and weird Some(ref rest) =&gt; { rest.len(my_lock) + 1 } } } } I'm using the `RefCell`s because I want this list to be shared among threads without using a single `Mutex` around the list (hence the fine-grained locks), and I thought the right way to do this was to make all the `List` functions take `&amp;self` rather than `&amp;mut self` and use `RefCell` for interior mutability (correct me if I'm wrong on this point). Also, I realised that my use of `&amp;MutexGuard` was a mistake (as you pointed out, dropping that does nothing). What I really want here is to pass along the current node's `MutexGuard` (giving up ownership) and have the `len` function (or the `insert` function) `mem::drop()` that `MutexGuard` when it no longer needs it (like how in C you would call `mutex_unlock()` on the previous node's mutex when you wanted to release that lock). But this doesn't work, because `len` takes in `&amp;self`, not `self`, so I can't use `into_inner()` to get the `MutexGuard`. Is there another way I should be trying to do this? (At this point, I am considering trying to subvert how Rust mutexes are supposed to be used by adding a `Mutex&lt;u8&gt;` field to my `Node` struct that I use like a `pthread_mutex_t`...) (actually, upon further thought, that probably won't work either, since it'll involve handing over ownership of a mutex contained within an `&amp;self`)
You can start from the "More general `class`" part. There are a lot of intersting ideas after it.
You could do something like this ([playground](http://is.gd/lp2PTf)): type Link = Option&lt;Mutex&lt;Arc&lt;Node&gt;&gt;&gt;; pub struct List { head: Link } struct Node { elem: i32, next: Link, } impl Node { fn len(&amp;self) -&gt; usize { match self.next { None =&gt; 0, Some(ref next) =&gt; { let rest = next.lock().unwrap().clone(); // lock is dropped here. rest.len() + 1 } } } } This works because it locks the Mutex just long enough to clone the Arc inside of it, and then it accesses that cloned Arc instead of one the one protected by the Mutex. You could make this more explicit by binding the MutexGuard to a variable and then dropping it: let rest_lock = next.lock().unwrap(); let rest = rest_lock.clone(); drop(rest_lock); If you want more RefCell-like semantics, replace the Mutex with an RwLock. The code is almost identical ([playground](http://is.gd/EXOcPA)), but now allows multiple concurrent readers. Just putting a Mutex inside a RefCell (or vice-versa) won't work, because the Mutex still prevents concurrent access to the data. Mutex and RwLock also provide interior mutability, so you don't need a RefCell for that. In general, Cell and RefCell are for single-threaded sharing, while Mutex and RwLock and `std::sync::atomic` are the multi-threaded versions.)
This looks pretty cool! I'll take a look at it once I get to my PC.
I'll be short on time this week, so I don't expect to get much done apart from running clippy on a few projects, writing a bit for TWIR and preparing yet another talk for Friday's Rhein-Main Rust Meetup.
Porting the beginnings of [Philipp Oppermann's OS blog](http://os.phil-opp.com) to a Raspberry Pi 3. So far, I have console I/O but not printf! - but getting there. Kind of have myself sidetracked on memory mapped I/O. If I could just force myself to ignore that for now, I'd be a lot further.
Certainly. I'm not averse to pull requests.
It truncates because the code chooses to: https://github.com/PistonDevelopers/table/blob/854514f440a434a2df51f11469c69551d5cfb673/src/lib.rs#L128
The colors break the output on play.rust-lang.org: &lt;anon&gt;:25:9: 25:12 (B[0m[1merror: `foo` does not live long enough &lt;anon&gt;(B[0m:25 (B[0m foo.hey1() // `foo` does not live long enough(B[0m (B[0m (B[0m^~~ &lt;anon&gt;:26:7: 33:2 [1mnote: reference must be valid for the block suffix following statement 0 at 26:6... &lt;anon&gt;(B[0m:26 (B[0m };(B[0m (B[0m (B[0m^ Maybe this can be worked around?
See also [this internals.r-l.o thread](https://internals.rust-lang.org/t/new-error-format/3438)!
wow, I didn't know the `env` trick, since switching to fish a few days ago, I've wondered how to pass one-off env variables …
How does this look on Windows and non colored terminals?
Knocking out more issues for [Alchemist](https://github.com/mgattozzi/Alchemist). Specifically how I can get the package all set so that running: ``` cargo install alchemist ``` Sets everything up including the database but only when doing an install. That and adding some more docs, possibly fleshing the rest of the AUR helpers out as well.
Do you really need to use `env` there? $ VAR=1 ./prog Edit: right — that's not the case in Fish. I guess I find that surprising, and think it kinda sucks. Bash and Zsh support this syntax.
Fish has a relatively strong break from a lot of bash-esque idioms. As a result, lots of things you think you should be able to do in other shells can't be done in the same way in fish (although arguably there is usually a more powerful and less magical way to do them nonetheless). $ NAME='kevin' ./setup.py Unsupported use of '='. To run './setup.py' with a modified environment, please use 'env NAME=kevin ./setup.py…' 
Author here. Panopticon grew out of my frustration about the lack of usable implementations of cutting-edge program analysis research and the fact that the industry standard for RE is a proprietary software that looks like Windows 95. I toyed with the idea of rewriting it in Rust since 1.0 became stable. The whole port took around 3 months. I got the size down from 10.000 to 8.000 loc. Looking back it was the right decision. Programming in Rust is not only more fun, it's definitely easier too. Panopticon used alot sum types that were implemented using `boost::variant`. Like everything with Boost it kind of worked but was incredible ugly and complex. Replacing them with `enum`s was probably the biggest reason I switched to Rust. Also I found iterator invalidation bugs simply by translating C++ to Rust, thanks Borrow Checker!
FYI, `export RUST_NEW_ERROR_FORMAT=true` is a valid fish command. EDIT: I'm not actually sure why it works for me. `export` seems to be not fish related
What happens to Leaf? I think there are enough interested developers in the Rust community to continue the development. Personally I am interested in Deep Learning for research in game development. Would rather use Leaf than starting something new under PistonDevelopers.
I don't think 4K+ stars is losing. I don't think being a spotlighted project using Rust is losing. I get that making money is important. Good luck you guys!
This is the first time for us, that we pass on a software project. We personally hope that Leaf will be picked up by the Rust community and we are happy to assist with it. The project is well documented and I think it could flourish without an institutional engine. Let's see if the need is high enough for the Rust community. 
Yes: https://github.com/rust-lang/rust/issues/33366
https://www.reddit.com/r/rust/comments/4iipj7/the_new_error_format_is_now_in_nightly/d2ylrwb
So I'm not sure if this was what confused you, but the whole idea of RefCell is that you don't need a mutable reference to RefCell&lt;T&gt; in order to get a mutable reference to T. That's why, as the [other comment](https://www.reddit.com/r/rust/comments/4ij34q/how_to_use_rcrefcellt_properly/d2ygu45) already explained, it's enough to dereference the Rc&lt;\_&gt; (which is done implicitly when you call the RefCell&lt;\_&gt; methods on it).
This came as a surprise! I've been aspiring to receive a fraction of the attention you guys get with my library. You've achieved a huge amount and I share other's hope that leaf will continue to be maintained by the community. That said - I think it is awesome that you guys are recognizing this and acting on it so boldly. I can't wait to see what you try next!
Having contributed to Collenchyma and Leaf for last two month, I think that's right decision but for another reason. Leaf uses imperative approach to construct NNs. Some optimizations that come mostly for free in graph-based design would be difficult to implement, for example doing parallel transfers to/from GPU, concurrently updating weights during backpropagation in another CUDA thread with lower priority, concurrency in general, etc. This made me thinking I should start a new NN project with dependency-based computations and graph optimizer, reusing collenchyma or maybe lower-level libraries. Or just use Tensorflow. From perspective of getting things done Tensorflow looks much better, while a new project is a fun way to get deep understanding and learn a lot of related stuff. Re winning / losing, I don't think that not being leader in marketshare is losing. It's fine to just hold a niche. After all, Rust is niche language right now and will be for several more years at least. It's difficult to expect wide popularity when newcomers would have to learn rust in addition to a NN framework. That said, Leaf could considerably extend it's niche by providing first-class OpenCL support. AFAIK, Tensorflow doesn't do it, Caffe doesn't have it in the mainline, so it would be a good way to diffirentiate itself. It's also be possible to provide C bindings with wrappers for several popular languages to make Leaf accessible to hackers who don't want to learn Rust. That's, of course, a lot of work...
Doing a little 2048 clone using piston. Well trodden ground, I know, but a fun little project for an amateur. 
Its a built-in function found in /usr/share/fish/functions/export.fish: function export --description 'Set global variable. Alias for set -g, made for bash compatibility' if test -z "$argv" set return 0 end for arg in $argv set -l v (echo $arg|tr '=' \n) set -l c (count $v) switch $c case 1 set -gx $v $$v case 2 set -gx $v[1] $v[2] end end end 
How do you debug rust in VS without VisualRust?
I haven't tried out YCMD yet as I've had no issues with racer. I could give this a go at some point if I remember.
Just open the .exe as a project, and then hit start debugging.
 fn main() { let a = 1u8 as u32 &lt; 2; } Errors with `error: expected type, found 2`. Same with `&lt;&lt;` instead of `&lt;`. Added braces where appropriate solves the issue. This sounds very similar to C++'s most vexing parse. I thought Rust solved this by requiring the turbofish to where needed to disambiguate? Any more info on this subject?
Well, I don't have any hard numbers either. Current Leaf benchmarks don't help, since they are for just backward and forward passes, without running solver, as I understand it. Test networks are strictly sequential, dependency graph in this case is a straight chain of computations with no chance for parallelization. Some parallelization could be introduced by mixing weight updates with backpropagation, but in current architecture weight updates seems to be managed by the solver that runs after backpropagation is done. I don't know if parallel weight updates would account for much, but if it's only 10% it'd be substantial. Of course they are possible to implement in imperative style, but that'd require mixing solver and backpropagation step, making code not that clean. It'd be nice to see benchmarks with solver included, but the solver should be optimized first -- there are some easy 5-10% improvements, and I guess several more hard ones. Issue #37 is mostly about memory transfers betweed memory locations of SharedTensor and it doesn't touch async and parallelization.
Here's some discussion on [the issue](https://github.com/rust-lang/rust/issues/22644).
Thanks for your work, I am really amazed at the pace.
I wonder, are black people living and working in Africa under-represented? What should they answer in your survey? This question in survey looks somewhat US-centric. Even the term "person of color" is a US-term and can be hard for people in other countries to understand. I don't completely understand it, e.g. does it include Asians or not.
Just a regular breaking-change.
I know many Asians identifying as PoC. We consulted people from multiple places around the world. The suggestions mostly came from non-US people here, but I have to admit non of them were from the from Africa. If you feel black people living and working in Africa are under-represented, I would definitely check.
Is there memory unsafety associated with failing to close? If the thread is already panicking while this `drop` is running and `drop` panics, the whole program will abort! If there's no safety issues if close fails, it may be preferable to just ignore the error.
IIRC, that question let you pick multiples, right? I feel the same; my OS will not be on stable for a long time, but everything else will be.
I was personally looking for the "Whichever stable release supports Serde / compiler plugins" option :P
&gt; They are underrepresented in tech In U.S.. I don't think black people are underrepresented in Africa in tech or Asians are underrepresented in Asian tech companies. That's what I was referring to.
This is another issue I am not too upset about. If `?` is never generic, I won't be disappointed. I understand the benefits of operator overloading, but sometimes I like the fact that, when I see `?` (or `try!`, as it's been so far), I know I'm dealing with a `Result&lt;T, E&gt;` type. I might be in the minority here, and if so then so be it. But I am quite happy with `?` being the way it is.
In the world.
White is a color, did I check the wrong box if that's how I feel? :-p More seriously, perhaps black people are underrepresented within the Rust community, but people in Africa will probably be underrepresented in general. If we look only at people in the Rust community living in Africa, are black people still underrepresented? Are black people underrepresented in tech in Africa? Are black people underrepresented in the Rust community compared to tech in general? I think all of these questions might have interesting answers, and the survey could have been more helpful by directly asking 'What is your race?', so we won't need to interpret vague phrases like 'person of color'.
[removed]
I'm somewhat incredulous that "Rust" isn't a choice for "What programming languages are you most comfortable with?"
I think /u/carols10cents means the proportion of people of colour in the worldwide developer population is less than the proportion of people of colour in the world. Of course, as you've pointed out, there are large regions where this isn't true, but I imagine (I don't know for sure, and could easily be wrong) the effects of being underrepresented globally are still easy to notice/feel in this age of the internet: the euro/US-centric nature of this question in this survey being an example! I think this last point comes down to the crux of the matter: the question is trying to touch on how people feel, it is not looking for a scientific assessment of whether a person has attributes that occur less than they "should" in a random sample of their region's population.
I read that question as _other_ PLs, but apparently it wasn't that, ha!
Do you really expect people to have heard of a new, niche language like Rust, let alone be comfortable with it? :P
Phil-Opp! You're my hero. Thanks so much for the blog. No, I haven't really gotten that far with it. I guess I could, given how much you've put into making sure others could benefit from your work. Maybe I'll do some cleanup and github it and just document what I've done as I go along, just like you do. Your approach to the blog has been an awesome way for me to learn.
I might be willing/able to do that. PM me and we'll talk about it.
It wasn't my comment, but yes: `#[derive(Hash)]` just calls `hash` on each field in turn, and hence never loses any information unless `Hash` implementations of the individual fields lose information themselves.
caffe-ffi (assuming you're referring to something like https://github.com/ajtulloch/caffe/compare/caffe-ffi) is a trivial patch that would apply cleanly to any Caffe branch (like the Windows one). The patch is just https://github.com/ajtulloch/caffe/commit/e58efb0a7d8f1ced8d87bf8f989ee16a81914f93. If you want to just run forward passes and get things done, the Caffe FFI approach is a very reasonable one. 
Done :) The question about which platform I compile for I found slightly misleading, or perhaps there's a better way to get at the data. I compile for Linux, Windows, and OSX...but I felt like only putting Linux since that's the *main* platform I work on. Putting all three feels like I'm giving data that isn't quite correct. Just my opinion though.
It was a great talk, nice one! :)
&gt; Another disclaimer: pipeline diagrams are still wrong and this one is hilariously wrongerer than the previous one. Hahaha
After a period of inactivity, I've picked up on my [turtle graphics](https://github.com/Kingdread/Rurtle) again in the past weeks. I've finally written some tests, and the resulting images are uploaded to [a webapp I wrote in Python](https://kingdread.de/eltrur/) where I can review them, though I still need to tune the image comparison algorithm, as the current version is a bit slow...
Panopticon will never die, but I will. When I remember correctly I promised you to hold talk before February this year. I'll try work something out. Also I'm looking into the OS X build problems.
And here's the start of the companion blog: https://konohitowa.github.io I went with dark colors ~~sense~~ since I tend to code a lot ~~at~~ when I wake up at 2AM and can't get back to sleep.
I don't know much about this, but it may be beneficial to look at / ask in /r/rust_gamedev - it isn't as active there but I'm betting someone who knows more about GPU programming in rust would see this there.
After a short break I hope to resume my work on [BrainDamage](https://github.com/dos1/braindamage) this week - right now it's a Brainfuck interpreter in Rust, but the goal is to expose basic game engine functionality to Brainfuck, allowing to write simple games in it - if you're brave enough. I just need to write some docstrings, have the code reviewed for its *rustiness* (it's my first Rust project) and I can start integrating Piston :)
Did someone write a time machine in Rust? (look at the title) EDIT: apparently I don't know the difference between right and write... and it bothered me so much 1 day later, when re-reading this comment, that I couldn't stop myself from fixing it.
In China, both Beijing and Chengdu will have a meetup to celebrate Rust's first birthday
It's European format. They're two years ahead of us. I think it might relate to the Julian calendar.
The first sentence... 'Whether or not you use Rust today, we want to hear from you!' ...makes it seem as though folks who have yet to begin using Rust might be welcome survey respondents, but the design of the first question only includes current and former users. This may be a survey design mistake.
Oh awesome! If you have any links that I should be sharing on Twitter or otherwise, please let me know!
Damn! I was so sure not to have left a trace. You got me, I'm from the future.
I'm using caffe-ffi in Linux, but I haven't figured out how to compile the Windows branch actually...
&gt; the first question Do you mean "Do you use Rust?"? If so, I don't quite understand what you mean: there's an "or" in the No answer, meaning (unless I'm missing something obvious...) it covers people who don't use Rust as well as people who stopped using it.
After talking with Niko for a bit, it sounds like the [SEME regions RFC](https://github.com/rust-lang/rfcs/pull/396) would yield an equivalent system of lifetimes when applied to an SSA intermediate representation (which is one of the alternatives mentioned at the end of this blog post). I am curious if it possible to eliminate the flow-sensitivity of the 'outlives' check. SSA is often used as a tool to add a degree of flow-sensitivity to flow-insensitive analyses, but in this post Niko suspects that it may not be enough.
How was the experience of making a GUI app in Rust?
Rust is the language I've programmed in most out of anything and the one I'm most comfortable with! Dunno what that says about me... :O
&gt; I think /u/carols10cents means as the proportion of people of colour in the worldwide developer population is less than the proportion of people of colour in the world. Which seems like a strange thing to look at to me, because many people worldwide live in relatively poor countries and might not be able to afford a computer, internet, or a computerscience related education, or they may simply not have the free time available to spend on open source contributions, or choose to spend their time differently. The economic differences between countries might be influenced by racism but to compare the world population and the developer population wrt demographics (and the unspoken oppression/racism conclusion) seems pointless without looking at all the other factors involved. 
SSLstrip is not a problem here, we don't use HTTP in the process. Your link for MITM only talks about how an MITMer can be malicious, but for that you need an MITM in the first place. curl | sh, implemented correctly, is not problematic at all. It's usually _not_, which is why it's "considered harmful". Up to date packages doesn't really help the situation where you want to add cross compile toolchains or have multiple versions of the compiler locally. rustup itself could be in repos, but that takes a while to happen.
Well played, Strangelove!
I'm Australian, but I don't play Rust... I program in Rust (a programming language) on occasion, which is why I'm part of this subreddit. Perhaps you'll find some help at /r/playrust :) Hope you find some people to play with!
Beijing will also do at that day.
Yeah, but why was it removed? May be there is a better way to do it?
&gt; One downside of this approach is that it requires augmenting the subtyping relationship with a location. I don’t see this causing a problem, but it’s not something I’ve seen before. Is this related to the "flow typing" of the Whiley language (http://whiley.org/ ), but at the level of just lifetimes?
You are not alone! Rust is by far the language I'm most comfortable with, too.
From what I remember, support for non-preflighted requests is basically just "Check the `Origin`header in the request and echo it back in the appropriate response header to authorize... or just send a wildcard authorization." Here's the MDN page on it for more information: https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS
This question felt really out of place for a global survey, felt like a US-only question.
Done. I guess I missed questions with regards to what's good or bad about the language and what could be approved. I was asked what the hurdles for adoption are, but that is not necessarily the same.
Thanks so much for the kind words! &gt; Maybe I'll do some cleanup and github it and just document what I've done as I go along That would be awesome! [Several](https://github.com/phil-opp/blog_os/issues/142) [people](https://news.ycombinator.com/item?id=11480861) have indicated interest in an ARM port, and I am very interested, too :). I've just read your [Getting Started](https://konohitowa.github.io/2016/05/09/getting-started.html) post and I really like it! Looking forward to some more posts ;).
&gt; Hope you don't mind the name Um, I think it's a bit… weird…
X-Post from HN. [Other discussion](https://news.ycombinator.com/item?id=11664933)
&gt; we don't use HTTP in the process. Once rustup.rs is downloaded, no, but a false paste attack on a stripped version of the web page could download and install anything at all - a botnet, or even a simple `rm -rf / --no-preserve-root` if someone just wanted to be mean. 
&gt; installing rustup.rs via your package manager! That's a solution I would love to have. &gt; I need more than my platform's package manager for rust. I totally get that. The appropriate solution is a repo package with an installer in it, so the user installs the installer traceably, and then the installer (which is signature verified) installs whatever the user likes. This is similar to what DropBox does. 
Some notes on string handling 1. Nothing wrong with `strng.as_str()` [here](https://github.com/rootking/Rusty_ML/blob/f9d91ed1bc536edea5364830b93cfe40c4980cd1/src/main.rs#L32), but it is idiomatic to write `&amp;strng` instead. 2. [Here](https://github.com/rootking/Rusty_ML/blob/f9d91ed1bc536edea5364830b93cfe40c4980cd1/src/main.rs#L71) you mix `to_string` and `to_owned`, but for the `&amp;str` type they are both the same thing. I prefer `to_string`. Also, instead of `fs::create_dir(n_st.to_owned())` you can write `fs::create_dir(n_st)`.
When would you use it, instead of let's say Vulkan? OpenGL stateful nature is best fixed by having a truly stateless API.
Providing DEBs, RPMs, and a signed tarball _of rustup_ should solve the problem for close to 90% of users, and would also put us on the track to have repo support _for rustup_ on Debian, Ubuntu (and derivatives), and all RPM distros.
For that the website needs to be MITMable, though. It isn't. It's purely on HTTPS. Having a brew install/apt-get install command on the site is vulnerable to the same thing, anyway, if people copy it. And you can type it out, of course, but curl/bash sh.rustup.rs
Do you want to write the whole thing in rust, including the kernels, or just the API calls?
Programs on Windows always depend on other DLLs. Even using just the NT api directly, you're still stuck using at least `ntdll.dll` due to the syscall ABI not being stable. Most DLLs that you end up depending on though are system DLLs that are always available anyway. The vc++ redistributable is an optional component however which isn't always installed, so if you really want you can statically link the CRT instead of dynamically linking it (assuming Rust actually exposed a way to do this which it doesn't, so you'd have to manually invoke the linker). Your error code of `c000007b` is `STATUS_INVALID_IMAGE_FORMAT`, are you _sure_ you're trying to run it on 64-bit Windows? If the vc++ redistributable were missing you'd actually get `STATUS_DLL_NOT_FOUND`, which means there might actually be some other issue here. Also, your program definitely wouldn't depend on .NET or DirectX since you aren't using any libraries that would depend on them.
&gt;are you sure you're trying to run it on 64-bit Windows? Yes [computer I'm executing under](https://i.imgur.com/jKk3EPz.png) [computer I'm compiling under](https://i.imgur.com/pW9LMh3.png) Both report Windows 7 x64 professional. &gt;Also, your program definitely wouldn't depend on .NET or DirectX since you aren't using any libraries that would depend on them. I'm aware. Just wanted to be clear I've done *some* due diligence when troubleshooting this problem :\ P.S.: Also before you ask, yes the SHA1 sum's of both executables are the same (I checked this first thing to ensure it wasn't file corruption). This is why it's listed in OP. Edit 1: Wrong link
You're right. For some reason my eyes missed the "or" when I read it last night.
Layout changes [look fun](https://github.com/servo/servo/pull/10691)...
That's gorgeous
I've ran it: * In C:/Windows * In My documents * In a USB stick on its own same error every time. No change when placing `vcruntime140.dll` in the same directory level. Running the windows update (within the zip file) errors saying the update isn't applicable to my computer. The instructions say to pick the installer for my system architecture except there is one installer.
Haven't really played much with Vulkan. Ultimately Vulkan is a more modern API, but also a more low level one than OpenGL. I imagine you could build something glium-like on top of vulkan (https://github.com/tomaka/vulkano is lower level than glium) and get the best of both of worlds.
Glium's own developers are not going to pursue anything past OpenGL 3 support because they view their work on Vulkan to be the future. There is a Vulkan API being actively worked on right now: vulkano
&gt; For that the website needs to be MITMable, though. It isn't. It's purely on HTTPS. SSLStrip works against websites that are purely HTTPS unless they employ cert pinning, and even then there are circumvent ions possible. Moxie explains this really well on his website, and it has been demonstrated multiple times at various conferences.
Yeah, hopefully something higher level for Vulkan will emerge, which will preserve it's stateless nature.
&gt; Your criticism might have been taken more constructively if you hadn't cross posted to /r/hacking with the title "Rust community dismisses inherent flaw in the recommended installer. Have fun running MitM against Rust devs!" That was petty, and I'm sorry. &gt; rustup.rs is not (yet) the recommended way to install rust My mistake; I was conflating recommendations from the tutorials I originally learned from with official Rust documentation. I'll submit PRs or bug reports to them. &gt; if you have a more practical solution than "provide packages for all distributions", feel free to suggest them, or even submit a PR. I think I must be misunderstanding something rather badly. Why isn't it desirable to distribute a stable stub installer that allows traceable bootstrapping of the installation? A user could install a package, using the existing signing and verification tools of their package manager, and that package could install and update Rust (or another installer like rustup) until Rust (or rustup) is stable enough that distros can keep up with it. If the reason is that nobody wants to work on it, that's totally legit, and I'd be more than happy to write it and maintain the packages as soon as my semester ends.
The "under represented minority" question should be taken out. Unfortunately, as much as I like Rust, it seems that it is getting a reputation of being associated with SWJs.
This is a dupe of https://www.reddit.com/r/rust/comments/4ilwf3/doom_on_glium_or_how_i_learned_to_stop_worrying/?ref=share&amp;ref_source=link
We don't consider inclusivity to be a negative.
Yes, for sure.
Sort of a high level question regarding the use of sockets. With C, if you have a struct, lets call it "Message" you can pass that struct to a socket by just giving it a pointer to the start of the struct and providing the size. Done, no need to copy memory around etc. In C# to get a struct into a socket you have to manually copy the data from the struct into a byte array that you can then send to a socket via a stream. I'm wondering what is possible with Rust. Can you get a struct into a socket without unnecessary overhead? I am aware of portability and versioning issues with this approach. 
Ad hominem. I agree with troll. curl | sh is a bad idea. I think you agree too. I put off installing rust for weeks, because there's no way to get signed binaries or binaries with signed checksums. I started to build from source, and that takes forever. And I presumably get some one off snapshot that nobody else is using. Then last night I finally decided to shoot my laptop in the head and install unsigned binaries for the sake of getting started. I'm not happy that I did that. I consider the whole machine compromised now, but I want to learn rust. I do wonder how many others like me decided to give up on rust because of the lack of easy, verifiable install options. 
Going to comment on a few places which could be written slightly neater: [Here](https://github.com/rootking/Rusty_ML/blob/4c53960a06091c973a67421aa7ef843bc7da1ffa/src/main.rs#L105-L109) you could just write `s.lines().count() == 0`. Then there are a few places where you should consider using methods on [Option](http://static.rust-lang.org/doc/master/std/option/enum.Option.html) and [Result](http://static.rust-lang.org/doc/master/std/result/enum.Result.html). These are not exactly easy to know when you are starting out but given how ubiquitous these types are in Rust code they are really useful to know :). [Here](https://github.com/rootking/Rusty_ML/blob/4c53960a06091c973a67421aa7ef843bc7da1ffa/src/main.rs#L94-L98) you can use `.unwrap_or_else(|why| panic!("couldn't open {}: {}", display, Error::description(&amp;why)))`. You might wan't to consider returning `Result` from this (and other) functions as well and use `try!` for error handling (though for a small program like this, panicking is certainly a fine approach). [Here](https://github.com/rootking/Rusty_ML/blob/4c53960a06091c973a67421aa7ef843bc7da1ffa/src/main.rs#L217-L223) you could write `has_meta_data = count_files("./meta").is_some();`
As you know the layout of structs is unspecified and cannot be relied upon. From [the Book](https://doc.rust-lang.org/book/ffi.html): You can add `#[repr(C)]` to make your struct laid out by the rules of C, or even `#[repr(C, packed)]` to squash padding (but has some non-trivial caveats). 
I clicked thinking "oh god, we have cargo, why would anyone want to get autoconf involved?" and now that I read it, I think this is terrific. Maybe another road in the future would be tools in cargo to generate rpms with service files for deployment.
Considering how big this is (from a user perspective, I assume from compiler/runtime too) I'm not surprised it took a while to settle. That said this is wonderful.
I feel flattered and I really appreciate the attribution, but it's kinda weird to see my username as a project name :D. So I would prefer a different name... 
&gt; How interested are you in Redox? [1 2 3 4 5] It is customary to mention what number represents what meaning. I assume 5 means "very interested", but it could also be a grade (several countries use numbers for school grades).
Oh, my bad, I misread the caption :/
Yep. In the world of the Internet, and the large ecosystem of HTTP JSON APIs, a large number of programs will need to do serialization.
Ah, so when I see you pop into a PR to say `@bors retry`, it's usually not due to a spurious failure, but because the PR was updated. It's impossible to tell since all of that history goes away upon rebase. I wish GitHub would keep that information around somehow.
Hi there! I guess I could attend your meetup, though I'm not sure I can make it until 19:00. How long will the meetup be? Do I miss something if I come until 20:00? Would be a pleasure to meet some of you! Feel free to contact me here or via PM!
Retry restarts with the same commit. A second r+ means that a new commit was added.
You assume people know what Redox is?
I view that as a problem to be fixed, not a permanent state of affairs. Signed binaries and deterministic builds are an important part of the solution. For a language that prides itself on safety, these changes seem like a natural progression. I'm not insulted by the term paranoid, but rank and file developers are the target of well funded nation states today. That is no longer considered paranoid fantasy. Post-Snowden, that is well documented fact. XCodeGhosts are out there. NPMgate proved anyone can play, no nation state backing required. Ignoring security threats doesn't make them go away. We should all be demanding improvement here.
`@bors: retry` is typically a synonym for "I think this was a spurious failure", although often that suspicion is wrong :). There was only [one of those](https://github.com/rust-lang/rust/pull/32900#issuecomment-210127897) on this PR, and [the other](https://github.com/rust-lang/rust/pull/32900#issuecomment-212111048) is actually a synonym for "someone restarted buildbot and bors is stuck", and this happens much rarely! I also wish that github preserved more history between force pushes...
As someone who has grappled with SEH in Windows I can completely understand some of the frustrations in there. Nice job in the end!
As /u/sanxiyn illustrated [here](https://www.reddit.com/r/rust/comments/4ikawg/launching_the_2016_state_of_rust_survey/d2zpndo), people from other cultures may not even understand the intent behind the questions, and answer them incorrectly. In this specific case, I imagine it will exaggerate the degree to which 'under represented minorities' will appear under represented. If the questions are formulated in such a way that those who should answer them fail to understand them, the survey will give very inaccurate results.
OK, I'll do that as soon as my semester ends. 
I made one of these in Python, and it is fairly straightforward if you've got a reasonable parser generator. It can get complicated if you want to match groups though. It also was quite slow. Of course, if you *have* a parser generator, it might just be easier to write your queries as grammars and parse your input that way.
&gt; The binary worked fine on my computer Wait, you just ran a random binary off the internet on your computer?
If I'm understanding this correctly, the worry is if I use bing.com (unlike google.com that works over https) to get to rust-lang.org I might get landed on a similar sounding page that would instruct me to download malware. But that isn't a problem because no matter how you secure your software the attack can still happen. Suppose then that I've already connected to the true rust-lang.org over https, can I get redirected to http afterwards, either in browser or in curl? Because last I checked curl/wget check certs if you feed them https urls. Lastly, just to put it out, it'd be best if rust relied on gpg and/or signify as a first line of defense and then on https as a failback for users that don't have keys already stored somewhere. Https seems more fragile, it relies on a bunch of CAs doing their job right every time which they've already demonstrated that they can't while gpg doesn't have to rely on third parties to make it work. 
And some jerk web designer out there depends on those ripple effects that were introduced by mistake/coincidence in IE4 to make his floaty button fade in correctly, right :)
MIR, being designed around flow-control graphs, could be used to ensure that only safe gotos were accepted. The MIR goto concept which it reduces all the other looping and branching constructs to is not what I’m speaking of—that construct would be more like `unsafe goto` (not that we’d allow such a thing when it would only allow the addition of demonstrably wrong code) in this hypothetical world where we actually had goto in Rust itself.
Error handling is certainly the most obvious thing, and it *is* something that can mostly be handled by `Drop` implementations; it’s definitely not going to be as useful an idiom as it is in C. Really, I don’t have a *compelling* use case for goto. I just kinda want it just because we can. To prove a point. But there are definitely cases (not particularly uncommon, either) where goto would be easier than the alternatives, and more probably more comprehensible as well.
… but you’ve got to admit that it’s uglier than a simple `goto` would be.
We already [do for apks](https://www.reddit.com/r/rust/comments/4fmxgb/announcing_cargoapk/). My top comment there is proposing that we add a first-class "package" argument to cargo that supports exactly this use case. Would love to be able to package RPMs as easily as `cargo package rpm`.
Yeah that'd be great too. I like it!
It would be relatively stupid simple to slap together a GTK3 frontend using [gtk-rs](http://gtk-rs.org/docs/gtk/) with conditional compilation if Linux is detected so that you could have support for Linux.
I first disassembled it to check for anything malicious, and then ran it sandboxed.
It's even been added under "Links"!
In this case, Autoconf is not for detecting dependencies it is all about packaging the generated binaries/libraries by Cargo to platform specific location. 
Sadly, yes, that's the conclusion I came to as well. It's really too bad, since most distros' repos move very slowly.
All of the listings for Rust I see so far are complete nonsense. The borrow checker won't be a problem once MIR has landed. i32 and impl communicate what they are perfectly if you have a rudimentary understanding of the English language and the programming basics to understand what a 32-bit integer is. Semicolons and double colon syntax wasn't inherited from C++, and it makes a lot of sense as to when to use :: and when to use a period. You can index a string slice, and you can slice a vector.
Autoconf shouldn't be touched as much as possible. RPM generation is nice, but something else (plain make all the way or something working directly with cargo) should be used or written instead of Autoconf.
The borrow checker *is* annoying. It makes things hard. You can’t just write stuff and have it work because reasons. Of course, once non-lexical borrows lands, almost all of what people complain of as borrow checker problems will mostly be consequences of the *ownership model*, not the borrow checker. For the rest, it comes down to what you’re comparing it with. `::` *is* subjectively ugly with generics especially (`foo::&lt;Bar&gt;()`). `impl` is just a keyword, it’s moderately meaningless as keywords go. (Implied? Implicit? Implement? Implode? Implant? Implacable? `impl&lt;Foo&gt; Bar for Baz` is kind of “implement (given generics Foo) trait Bar for type Baz”, and inherent implementations `impl&lt;Foo&gt; Bar` are kind of “implement (given generics Foo)… uh, just implement these methods on Bar” (`impl` might expand to “implement methods on” in that case). &gt; You can index a string slice [Nuh uh.](https://is.gd/fvS4xa) You can [slice it](https://is.gd/3bYDaD), but you can’t index it. Personally, I believe that allowing slicing was a mistake. It should have been `.slice_bytewise(slice)` or something like that, making the slice index units clear. &gt; and you can slice a vector Yeah, *this* allegation in the article is wrong. Though admittedly slicing yields a `[T]` rather than a `Vec&lt;T&gt;`. &gt; All-around complicated rules about what you can and can't do with arrays and strings. Once we bring *arrays* into the mix, yeah, it does get a bit complicated. Overall, it’s a mixture.
It's much much easier (and more elegant) to generate code for finite automata using goto.
"Because we can" is not a particularly compelling pitch. :P
Panics if non-ASCII characters. fn main() { println!("{:?}", &amp;"лес"[1..]); // лес = forest } With **&amp;"foo"[0..]** displays **"foo"**. With **&amp;"лес"[0..]** displays **"\u{43b}\u{435}\u{441}"**.
A good thing is, it is quite hard to come up with ways in which Rust sucks.
That is also likely to be nicer in many situations, yeah.
Is it? I guess it depends *how* computed the goto is, but something like the `DISPATCH()` example in the linked article seems fine, as it is essentially a faster piece of code equivalent to: let old_pc = pc; pc += 1; match code[old_pc] { 0 =&gt; goto 'do_halt, // ... 6 =&gt; goto 'do_neg, _ =&gt; panic!("code is out of bounds") } The compiler could theoretically treat the computed version as if it were that version for the purposes of analysis. (It seems to me that the main purpose of a computed `goto` rather than, say, a macro around a match like the above, would be to guarantee the jump table behaviour, although it seems to me that the `match` is a natural way to express that.)
[embed_lang](https://github.com/Marwes/embed_lang) is starting to work quite well so I am going to tackle the hardest task of all, naming it, after which I will push it to crates.io to indicate that it can be used (though obviously not for anything serious). Any time not spent on this arduous task will be spent improving the [tutorial](https://github.com/Marwes/embed_lang/blob/master/TUTORIAL.md) with a "Calling from/to Rust" section and squashing parser bugs.
To be fair, Rust has the advantage of hindsight compared to a lot of popular languages. And hindsight is 20/20, especially when it spans 15+ years (Java 1.1 was released in 1997, ANSI C was published in 1989, C++98 was published in, well, 1998). It will be much easier to bash on Rust in, say, 10 years' time, when people will have experience building complex projects and know what sticks and what doesn't.
Yeah, that's the problem with these lists, it's all so subjective. The first 3 points alone, 75% of the list, are completely subjective. Coming from C++ :: and generics are very natural to me, I don't see the 'ugly' because C++ was the first language I dove into. So for me it's natural. i32? Again, natural, and ideal for me. I never fight the borrow checker anymore, so it's not a problem - coming from C++ I love it, especially since I was starting C++ when move semantics were becoming a big thing in the language. But for others these aren't going to be the awesome 'features' that I see and instead problems with the language. So what's the point of the list? As for 4, it's not about &amp;str or vec - the rules are not about either. It's about the traits they implement. You can slice a &amp;str because it implements Index&lt;Range&lt;usize&gt;&gt;. You can index a vec because it implements impl&lt;T&gt; Index&lt;usize&gt;. And you can slice a vec? https://is.gd/jQls8t Not very arbitrary at all, really.
&gt; I only offer it as a better alternative [Better than this?](https://is.gd/qZGxIt) edit: I guess that's what you're saying.
Easy. Just factor your basic blocks into separate `extern "C"` functions with `unsafe asm!` continuation passing. (Please do not do this.) More seriously there are about two or three decent uses of `goto`: error handling or cold paths, emulating do..until in languages that don't have it, and maybe possibly simple state machines. On the other hand: - you'll probably `#[inline(never)]` fn anyway so what's another wrapper function to make `try!` work? - complex state machines mean you need a flowchart in the source tree, use good labels, `loop`-`match` isn't any better or worse than `goto` - do..until - Actually, do..until would still be nice to have. `loop { ... if done {break} }` is okay though and I'll not complain. 
As discussed below, bors is actually being reliable here: it is reliably flagging failing tests, it took a few revisions to clean out all the bugs (all the ones the test suite found anyway).
I'm going to attempt to install the toolchain on the other computer and diff the binaries (or just see if installing visual studio fixes the issue)
Can you go into detail? I'm just learning about seh and want to compile to memory with libtcc while catching any crashes.
I'd prefer tail call optimization (with `become` instead of `return`) and each state being represented by a function.
On that note. I think slices are promoted too much. And it's not made clear that, in some cases, array references should be used instead. An array ref can be coerced into a slice ref, but not the other way around. I came across a crate* that uses a slice ref instead of an array ref as return type of a getter function. The slice ref points to a `u8` array that has a constant length (hash value). This forced me to add a second array and then clone the slice content into it using `clone_from_slice()`. I did this to avoid having a slice, an `Unsized` type, in my struct. So yes, getting vectors/arrays/slices right is not trivial. \* It's still WIP, so I'm not going to name/shame it.
I hope you don't buy it just on the title because now we'll see some show up on amazon that are like 10 pages long.
In GNU C, you can jump to an arbitrary pointer, so...
Unfortunate but true.
\#1 in my opinion would be that the compile-times are dreadfully slow... For a small program (~2K lines) it takes ~2s to cargo check, ~5s for debug build and ~12s for relelease build, I don't mind the release build but the first two are too much. I read somewhere that people refrain from using some language features (generics I think) just to keep compile times low enough. And that seems sad. 
Since they're wrong, I was hoping that by this post somebody would register and fix them, and additionally add more things about Rust that suck.
I don't see the difference from dbaupp suggestion. It is still has an useless loop that need to be broken at the end. I was suggesting using labels on normal blocs so you can do cleaner. Something like : 'bar:{ if (condition) { break 'bar;} ... } ...
You might be interested in taking a look at section 7.7 "Structural Analysis" in Advanced Compiler Design and Implementation by Steven S. Muchnick (ISBN 1-55860-320-4). It's an extended generalisation of the T1-T2 technique that can create a wider range of high-level control flow constructs, and also apparently handles irreducible regions better.
Hm, what's the use of a pile-on list? Many of these things are fundamental to the language or will at some time be fixed. It brings no value over the occasional rant some blogger uses for cheap fame, which will most likely be more up-to-date.
I don't know where to put it, but at least it isn't in `target/`. See `cargo clean`
💖💖💖 Edit: Also did you consider shelling out to `rustc --print sysroot` instead of requiring the `SYSROOT` variable? I think that should work with and without multirust.
&gt; Today, I am happy to announce that you can just copy the title of this blog post to your command line and provided you have a nightly rust, $ rustup run nightly cargo clippy thread '&lt;main&gt;' panicked at 'need to specify SYSROOT env var during clippy compilation or use multirust' nooooooooo
I have to say I personally dislike the notion of thinking in a programming language. It's limiting. Think in thoughts.
The underlying functionality can be replicated somewhat with `take_while` and `zip`. It might be possible to write a macro that does this? I'm not sure unfortuantely, I haven't touched macros much.
Have you considered bundling it within the executable? I do it for font files, compressed with LZMA and include_bytes! and then I decompress them at startup and use them. 
"Before you read this, please understand that I never wanted to write this document, being grossly under-qualified, but I always wanted to read it, and this was the only way." - Paul ``Rusty'' Russel, "Unreliable Guide To Hacking The Linux Kernel"
I didn't know about include_bytes, it looks definitely very interesting ! I will pass the step about compressing for now, maybe I will look it out when I will be more experimented in the subject. However, I would still like to know about other files that could be dynamically loaded (and not stored directly in the binary), because, well, maybe in the future it might come handy to have this piece of information for one my projects :) !
Thank you! I'm especially interested in writing idiomatic rust so that if this project ever has other people involved they don't hate me :D!
Is this a good way to test for palindrome? fn is_palindrome&lt;T: PartialEq&gt;(arg: &amp;[T]) -&gt; bool { //all slices shorter than 2 are palindromes (ignoring NAN==NAN for now) let ln = arg.len(); if ln &lt; 2 {return true}; let (a, b) = arg.split_at(ln / 2); !a.iter().zip(b.iter().rev()).any(|x| x.0 != x.1) }
Ah, thank you! Do you have any recommendations for simple rust libraries that I could read to improve my code writing ability? 
Why do you skip? Wouldn't this fail to detect things like "watsup"?
Then again, a language that doesn't change how you think isn't worth learning. Or so they say...
No worries, glad to see this. Regardless, any idea of what the fix is? Should I file a bug of some kind?
I may be doing decision trees soon too - I don't know them well and wanted to learn :). Maybe we can help each other out on that one. I'd say linear regression would be a good starting point. You have a closed form solution and so don't have to worry about implementing gradient descent etc. K-Means is also good for the same reasons. If there are other algorithms you are more familiar with I'd just go with those though. The biggest issue I had when starting out is linear algebra. I ended up writing my own native stuff. I'd recommend you take a look at [ndarray](https://github.com/bluss/rust-ndarray) - it should give you most of what you need. I'm also planning on pulling out my linear algebra into it's own crate (probably pretty soon). In which case you could use that too (or use it as-is within rusty-machine).
I think `skip(1)` was just me testing something. It shouldn't be there (removed it now). What did you mean by "watsup"?
Why `Sized` on `T`?
For that, you should be able to use just use make.
I actually agree with you but I can't entirely rule out a legitimate use of autoconf. 
Ah, a built in assembly solution isn't going to work for my workplace, they will reject that as unmaintainable. What I need is some kind of algorithmic trade off of some kind, or maybe direct support for exactly that in rust through AtomicUsize, where I could just do some kind of series of operations, achieve the same final end result, yet protect against races on side A.
Besides using `AsRef&lt;[T]&gt;` instead if `&amp;[T]`, I think our functions are equivalent.
You could protect the pair of variables with a spinlock or even a mutex if it's not performance sensitive.
Awesome, thanks :)
I *think* that the working directory for executables run with `cargo run` is the root of the crate, so if you have assets there, you should be able to just `cargo run ./image.png`
This is a half-answer, but: even if C/C++ didn't exist, if you do "systems programming" you will still care about custom memory management (to do things the borrow check disallows) and custom memory layout, both of which needs unsafe Rust. To learn about *The Dark Arts of Advanced and Unsafe Rust Programming*, check the [Rustonomicon](https://doc.rust-lang.org/nomicon/). An example of custom memory layout is [nan-boxing](https://wingolog.org/archives/2011/05/18/value-representation-in-javascript-implementations) used by some Javascript engines. That is, storing pointers in otherwise unused space of NaN doubles. One way to do this in Rust is cast a float into an array of bytes and manipulate the byte values directly, [like this](https://stackoverflow.com/questions/29445026/converting-number-primitives-i32-f64-etc-to-byte-representations/29482767#29482767) (note that [`mem::transmute`](https://doc.rust-lang.org/std/mem/fn.transmute.html) is unsafe).
I'm building a mini CRDT engine in xi editor, which I will use for async plugins and undo. It's a bit rocket-sciency, but that's the kind of programming I like.
I would agree with this generally, but like, you still want to put them in the repository somewhere.
You're looking for /r/playrust
If I have it right, your function would return true despite it not being a palindrome.
So far, I'm using a RwLock&lt;(usize, usize)&gt;
But then it doesn't matter (personally I would use just `res/` as it would be reachable when running `cargo run` in root folder).
You rock. Btw. do you plan some sort of visual line break? Given that your algorithm is so fast, it should be suitable for that, too.
Thanks, fixed.
No one could credibly say that Rust's string handling isn't sensible and exhaustively thought through, but it is a lot more complicated than many languages which have less restrictive requirements than Rust does (not only in terms of guaranteeing unicode correctness, but also in terms of memory management).
This page is a bummer. I think contributing to it is a mistake.
My function can't accept strings at all.
A trait cookbook would be handy. The Into/From relationship blew my mind and lead to the solution of some of my design problems. It feels like there's a big bag of trait-tricks out there that should be written down.
Yeah. Plus, when you go through the list, its clearly misnamed. Its more like a "list of tradeoffs that someone doesn't like".
Can you spare some bits? If so you could use a few bits on top to act as a "tag". I e, say you use the top 4 or 8 bits to represent a tag and the real value is in the rest of the bits. Every time you write, you increase the tag and write the same tag in both AtoB and X. A reader will verify that the tag is the same in both AtoB and X and if so strip the tag away and just return the values. If the tag is different, you could read again (i e loop until both tags are the same), use the last correctly read value, or what makes most sense for your application.
Yeah that's a good idea, I was thinking about setting a boolean, but it would have had to be atomic too, and also represented the same issue.
There are tricks to implement compare-and-swap for arbitrary big chunks of data, e.g. [here](http://www.cl.cam.ac.uk/research/srg/netos/papers/2002-casn.pdf) (search for 'casn compare and swap' on google for more papers), but I doubt your company would accept this if they would reject an assembly solution for being unmaintainable. Which surprised me in itself, because doing lock-free communication and multithreading *correctly* is much much harder. You claim the code is very performance sensitive, have you profiled with a `RwLock&lt;AtoB, X&gt;`? Do I understand correctly that there are only two threads? Because if that is the case then I think there is a very easy solution. Edit: [here](https://gist.github.com/anonymous/dbc504294a03a65b3e5003008be166f7) is an outline of what a solution might look like, assuming there is but a single writing thread ([playground](https://play.rust-lang.org/?gist=dbc504294a03a65b3e5003008be166f7&amp;version=nightly&amp;backtrace=0)).
Published.
Well, C++17 will have [std::optional](http://en.cppreference.com/w/cpp/utility/optional), and there's a C++11/14 implementation on GitHub: https://github.com/akrzemi1/Optional
I am still seeing 0.0.66 as the latest version, maybe it needs some time to sink in...
You missed the tokamak plugin for Atom, which is pretty much vital for Rust. Enabling clippy in Atom should also be vital for a Rust development environment. In addition, rustup.sh was replaced by rustup.rs: `curl https://sh.rustup.rs -sSf | sh` As for actual programming, don't forget about `usize` and `isize` as they are recommended over defining the size of your integers manually. The compiler should automatically choose the best integer size.
I found this post pretty helpful for exactly that! https://llogiq.github.io/2015/07/30/traits.html
I just completely rewrote the entry. Better?
I think they're changing (removing) that empty struct syntax for consistency, though.
Currently there's a key binding to break lines, but it does so once (at least in my tests, which admittedly were cursory and marred by crashes), instead of while I type. By the way, I think there should be an option to keep/copy certain prefixes during line breaking, e.g. `/// ` so one can line break doc comments.
Can you cite a source? I don't think that either of the ways of writing an empty struct are being removed. It would be a big breaking change, for one. The idea behind having both is discussed in the following RFC: https://github.com/rust-lang/rfcs/blob/master/text/0218-empty-struct-with-braces.md
It keeps wrapping as you type, but you probably saw bugs. The feature is still very rough and definitely needs more polishing (for example, to make the line width variable). Edit: making line breaking dependent on context (such as being in a doc comment) sounds like a pretty advanced feature. But I'll give some thought to whether it might be practical, especially whether a plugin might be able to control line break behavior on a per-span granularity.
This is awesome!
What is this `*` syntax? I did not find it in the reference.
It's like an awesome alternative syntax for a 'do while' loop
Sorry, this is the other Rust. You're looking for /r/playrust.
That's a bug, though. If this thread were counting bugs, I'd have a *lot* more examples to give. :P
 fn main() { return return return return return return return return return return return return }
Could you try to be subjective? &gt; [...] C++ developers who ban exceptions, which is all the serious ones Ok? &gt; In summary, Rust's "safety" is there when you need it the least, and not there when the real bugs come up. lolwat
It's not just you; /u/wycats has said that Rust has improved his JS for similar reasons.
Hmm, I might remember this changelog entry wrong: &gt; Empty structs can be defined with braces, as in struct Foo { }, in addition to the non-braced form, struct Foo;. RFC 218.
There are many more issues with it now, which leads me to believe that it's written by someone that's not very familiar with Rust programming. Silly entries like needing to type `&amp;*variable` is funny and sad at the same time. I've seen some amateurs making the mistake of assuming that they need to always pass values by reference even when the value is already a reference, and so they type `&amp;*variable` instead of `variable` which is what they should be doing.
LMAO
That's not how you index a string slice. You can indeed index a string slice, and any slice for that matter. [This is how it is done](https://is.gd/HiSInp).
What do these lints do? 
From what I understand LLVM will actually generate a jump table if there are enough `if` or `match` arms to justify it. (At the moment I'm pretty impressed that it does let (c, cf) = a.overflowing_add(b); // ADD let c = if cf {c+1} else {c}; // ADC one's complement addition in two instructions.) edit: I'm not sure if it generates multiple jump instructions, but it wouldn't surprise me.
What is so surprising about that?
The function signature of `fn plus_2(*) -&gt; i32`?
This seems to be true across the board. Sticking to JS as the subject, writing JS that was heavy in anonymous functions made figuring out functional programming easier, which in turn helped my callback patterns in JS. Although FP also made me write some really weird, unfriendly-looking Python for a while, but that's back to normal now.
&gt; Granted, that's more "thinking in patterns" than "thinking in languages," but certain patterns are far more pertinent to certain languages than to others. You could say those are the same things, because generally you'll have one language with that pattern that you use a lot more than the others. That is, I know a lot of OOP languages, but only use one or two with any regularity. Thinking in that language is the same as thinking in that pattern, because that one language and the pattern it uses that I'm concerned with becomes my main reference regardless. At some point it probably doesn't matter what language you think in, because the similarities will be what your brain sticks with as they're the most useful parts in this scenario.
[This is maybe even better](https://github.com/rust-lang/rust/blob/c66d2380a810c9a2b3dbb4f93a830b101ee49cc2/src/test/run-pass/weird-exprs.rs#L34)
Ok! I will leave it in your capables!
Firstly, I was talking about `cargo install`, secondly, why the hell library would need external resources?
You did talk about cargo install, but you claimed that you shouldn't include resources in a cargo-managed crate (in bold and all caps), which includes libraries. A plausible example of a library which uses an external resource is one which generates some sort of status page or automatic documentation which is made available in a styled document format (such as HTML), possibly with images. I know many libraries that have this behavior in other languages.
Agreed. This page gets a lot wrong IMO, and it's not just limited to Rust.
Looks like calling `.ip().octets()` will get you a `[u8; 4]`.
How does this compile? What does it do?
I was working on some code the other day, and I added an unconditional break statement to the end of my infinite loop just for a quick test... like so: fn main() { let mut y: f64; loop { //do lots of exciting work here y = 32.4; //and more here println!("{}", y); //add temporary always-break for dev purposes break; } } which led to a surprising message: &lt;anon&gt;:8:9: 8:14 warning: variable does not need to be mutable, #[warn(unused_mut)] on by default &lt;anon&gt;:8 let mut y: f64; So, I did as Rust informed me. fn main() { let y: f64; loop { //do lots of exciting work here y = 32.4; //and more here println!("{}", y); //add temporary always-break for dev purposes break; } } and it actually worked! I didn't expect Rust to calculate that the loop never repeats, therefore this immutable variable does, in fact, only ever get assigned one value. I was rather impressed. [Rust Playground link](https://is.gd/qNai3R) My use case was that I had originally been taking user input in the loop, recalculating some stuff, and then outputting related results, but doing so generated a Kiss3D window and waited on the user to close it. Unfortunately, when the user closes a Kiss3D scene, it appears to be impossible to create a new Kiss3D window without causing a panic. So, I added a temporary `break` statement at the end while I looked for a workaround.
that makes sense! although it seems like the compiler would at least warn about writing such illogical code.
 fn main() { .. .. .. .. .. .. .. ..; }
I would consider doing something like this: trait IOHandler { fn handle_io(&amp;mut self, Exit) -&gt; bool; } fn run_sim&lt;H: IOHandler&gt;(handler: &amp;mut H) { loop { let exit = run(); if exit == Exit::Hlt || !handler.handle_io() { break; } } } (Then to make `run_sim` generic over hypervisor types pass in a `Hypervisor` argument, or make `run_sim` a default implementation on a `Hypervisor` trait, or something)
Helps in C# where there's the IDisposable interface with syntactic sugar through using. Feels insufficient. C# has a convention that a class should 'own' their members, but it's not upheld by the type system. But today I was writing a system where there's a context object that holds a SqlConnection &amp; I wish I could put a lifetime parameter saying "This context contains a SqlConnection which outlives it" Thinking in Rust is thinking of conventions as types. Also non nullable types because convention of non nullability should be typed
Same as anything -- you take your pure vision of what you want to create and as you bring it closer and close to physical reality, it becomes more and more shaped by the tools and materials available to you. Same for composing music, creating pottery, painting a picture, programming, etc, etc. So at some point in the process you need to embrace the materials and tools and work *with* them rather than against them.
I created an Option type for C# for one of my assignments, because I've gotten used to it in Rust. (Yes I am aware of nullable, but that only works for primitives. The Option type I made works for objects, and I use nullable for primitives.)
Rustup.sh is not yet depreciated. It won't be until rustup.rs is ready. The shell version is still the official way to install Rust.
Not only is that unsafe, it's undefined: you can't be sure the representation is correct.
 fn main &lt;&gt; () -&gt; () where for &lt;&gt; T &lt;&gt; : for &lt;&gt; U &lt;&gt; {} impl &lt;&gt; U &lt;&gt; for T &lt;&gt; {} enum T &lt;&gt; {} trait U &lt;&gt; {}
ok, now someone make a macro that allows you to write "return" as "buffalo"
We definitely care about fixing this, last I checked it's simply blocked on the maturation of LLVM support for stack probes. There seems to be a patch in the queue at http://reviews.llvm.org/D12483 .
I believe Rust uses hygienic macros, making this (thankfully?) impossible.
Here is list (scroll down) https://github.com/Manishearth/rust-clippy
I have a [working prototype](https://plus.google.com/114251447858061222694/posts/35wbSWqoKWf) right now. I'll be hammering on it for the next day or so before uploading it to my repository.
One shouldn't be passing values as `&amp;String` though. You should ensure that your values are being passsed as either `String` or `&amp;str`.
Go is good with servers sure, its fast, its made by google... It doesn't have generics like you said. It might seem like a shiny new toy but you end up writing tons of boilerplate for algorithms and data structure, while Rust shines as it can be used generally as many other languages.
float_arithmetic allow Any floating-point arithmetic statement integer_arithmetic allow Any integer arithmetic statement Apologies for being dense, but would you use these to forbid float or integer arithmetic (ie force programmers to use decimal types or other more appropriate types)?
&gt; The real WTF to me is why we allow a where clause on a function that doesn't have any type parameters. :P That makes the code generation *much* easier. Compare this: macro_rules! impl_whatever { () =&gt; (); (&lt;$($i:ident),+&gt; $t:ty; $($x:tt)*) =&gt; (impl&lt;$($i),+&gt; Whatever for $t {} impl_whatever!($($x)*)); ($t:ty; $($x:tt)*) =&gt; (impl Whatever for $t {} impl_whatever!($($x)*)); (&lt;$($i:ident),+&gt; $t:ty) =&gt; (impl_whatever!(&lt;$($i),+&gt; $t;)); ($t:ty) =&gt; (impl_whatever!($t;)); } with this [1]: macro_rules! impl_whatever { ($(&lt;$($i:ident),*&gt; $t:ty; $($x:tt)*);* $(;)*) =&gt; ($(impl&lt;$($i),*&gt; Whatever for $t {})*) } [1] It is clear that the latter requires `&lt;&gt;` for the empty type arguments (fine for internal usages, though!). But wrapping `&lt;...&gt;` with `$()*` causes a local ambiguity.
There's a big difference between a `&amp;String` and a `&amp;mut String`. I've used many times without ever needing to perform `&amp;*` which is complete nonsense.
The compiler is supposed to automatically be able to choose the best integer size for performance. You also shouldn't be using `isize` unless you really need support for negative numbers.
Keep it in your root directory and cooy it to `target` with a build script.
A string slice *can’t* be indexed; that’s what I was demonstrating. Your choices are bytewise—`str.as_bytes()[i]`; codepoint-wise—`str.chars().nth(i)`; or grapheme-cluster-wise—[there’s a crate for that]. I’ve steadily headed to the point where I reckon that doing *anything* with a string beyond loading, storing, displaying and running deliberately designed things like a full text search, is a code smell. Anything like slicing or extracting is right out.
Apart from being able to demangle Rust function names, what other benefits does `cargo profiler` provide over `kcachegrind`?
That seems like an optimization (which LLVM does), as opposed to the borrow-checker understanding the control-flow graph.
It *would* be a great talking point. A feature that we never intend to make stable but couldn’t resist implementing just because the conventional wisdom said it was impossible—not even Chuck Norris tried to make a safe `goto` (or some other absurdity). Rust, on the other hand, is all cool about it. You want a memory-safe `goto`? Here!
For context, see the original file when it was added in [Rust's primordial past](https://github.com/rust-lang/rust/blob/664b0ad3fcead4fe4d22c05065a82a338770c429/src/test/run-pass/wierd-exprs.rs). That code was morphed into the current state over aeons of mutation as Rust evolved into its current form.
I was talking about front-end smartness, but if we're comparing backends we can do even better than that example: Rust compiles `(0..x).fold(0, |sum, i| sum + i)` (involving an iterator, a generic function, and a closure!) down into `((x - 1) * (x - 2) / 2) + x - 1`. Not quite as adept as Gauss, but quite good. :)
Cool stuff, but as `valgrind` is a Linux-only tool, I have no use for it yet. I'm most of the time working on a Windows platform.
Ok, maybe. I do not know Windows. You mean root certificates need to be distributed with each software that uses OpenSSL?
It's far from unprecedented to have a memory-safe language with `goto`. Go beat us to it by ages. :P
[removed]
There should be a lint against that, I think.
Even Python [has](http://entrian.com/goto/) [goto](https://github.com/snoack/python-goto)… Doing it in a GC-free language is more impressive.
&gt; Windows is for the boring corporatists Please avoid baseless assertions like this.
Again, `&amp;*var` is necessary at the head of a match statement (though stylistically most users pref `&amp;var[..]`).
 fn main() { let foo = || { return return return return return return!!!!!!!!!!!!!!!!!!!!!!11111; }; }
I'm just sticking my head in here to say I'd love to come but I'm In Hannover. I wish there was a meetup here, I left Hamburg just before the rust meetup started there. :(
Greetings! I myself barely ever used performance tools on Windows outside of Visual Studio, but those are the things you are looking for: - [Application Verifier](https://msdn.microsoft.com/en-us/library/windows/desktop/dd371695%28v=vs.85%29.aspx) - [Windows Performance Toolkit](https://msdn.microsoft.com/de-de/library/hh162945.aspx) including [XPerf](http://blogs.microsoft.co.il/sasha/2008/03/15/xperf-windows-performance-toolkit/) There are also plenty of non-Microsoft tools out there, but I don't know about their quality.
ALGOL-68 was the original champion of that kind of programming in imperative languages. You could write INT min = IF x &lt; y THEN x ELSE y FI; Does that look familiar? Well, you could also write: WHILE declarations; statements; some boolean expression DO statements OD It's a great alternative for loop { ...; if ... {break} ... }. I must say that the rust version with { } { } looks less intelligible.
Tautology implementations are, interestingly enough, accepted: trait Foo { type Bar; } impl&lt;T: Foo&gt; Foo for T { type Bar = T::Bar; } Not entirely surprising, when you think about it, but still...
I haven't really tried hard, but Windows has [Very Sleepy](http://www.codersnotes.com/sleepy/) that is probably fine for many casual profiling jobs. It had a support for DWARF for a long time so it would work for Rust programs as well.
Types, variables, ~~and functions~~ all have their own namespace, allowing madness such as the following: fn main() { type t = i32; fn t&lt;t&gt;(t: t) -&gt; t { t } let t: t = t::&lt;t&gt;(1); t; }
Here's another one I like: fn main() { (||||||||||||||||||())()()()()()()()()() } Edit: (move||move||move||move||move||move||move||move||move||())()()()()()()()()() // I like to move it move it
[Intel VTune](https://software.intel.com/en-us/intel-vtune-amplifier-xe) would be a good one, but it only knows about C, C++, Java and .NET. Not sure how it would handle Rust code.
&gt; variables, and functions These are in the same namespace. Your example works for the same reason that the following works: shadowing. let x: i32 = 1; let x: bool = x == 1; The compilers emits an error if you try to call the `t` function after the `let`. (Not that that makes the example any less weird.)
Thanks! The threads on this topic are unexpectedly helpful to learn more about Rust.
&gt; do you really miss the do-while loop from C/Java I'd like something like a do-while to be added to Rust.
yeah, sorry about that. would be cool to have other OS profilers included here -- just started with Linux stuff since that's what I use :P
Not at the moment, the subcommand only has support for callgrind and cachegrind. I mostly wanted to POC and gauge interest before proceeding with other profilers.
&gt; Maybe a connection with a transaction that was never committed automatically gets rolled back when the connection is dropped? Correct. You can establish a new connection for each test, and call the [`begin_test_transaction` method](http://docs.diesel.rs/diesel/connection/trait.Connection.html#method.begin_test_transaction) &gt; For tests that require more than one HTTP request (e.g. registering a user and then having that user do something,) how do I ensure that all requests to the server have a view of the same transaction? You can write your code so that the connection can be injected into either the request or the application itself. crates.io does this with a middleware, where per request the connection is established if it's not already present. Then in the tests they can just mock out the middleware.
Thanks, and you're welcome! At the very least, I think it will save us some eye strain. 
Thanks for all the feedback guys. Its so crazy how much this is growing :D. Quxxy thanks for your words of wisdom, I went ahead and did some more reading and from what I can tell if you use a 64bit sized variable on a 32bit system I believe that it will spread it across 2 addresses is that correct?.
That, and the fact that it's a more lightweight tool within Rust ecosystem, are basically the only immediate benefits right now. We can do more with the performance data -- I detail some ideas in the post. It would be cool to automate benchmarking with something like this.
Does `do { /* stuff */ } while (condition)` truly add so much value compared to `loop { /* stuff */ ; if (!condition) { break; } }` or `while { /* stuff */ ; condition } {}` that it's worth the extra syntax? How often does one need do-while anyway?
Delighted to hear it!
I haven't seen the source code of `CountTree`, so those are just wild guesses that might be just wrong: - Moving a first `insert` out of the loop makes the CPU prefetch your data's memory regions. Thus, your loop won't be waiting for initial work. This is, however, only relevant for array-like internal data structures. Besides... whether you prefetch directly before or right inside the loop should not matter. - The first insert into your `CountTree` might trigger some initial construction of internal data structures. Again, this would mean that your loop isn't initially waiting. Especially for the second case, it might be interesting to check whether you get the same performance results if you construct your `CountTree` with an initial capacity like `Vec::with_capacity(N)` instead of inserting an element before entering the loop. This initial creation of internal data structures is what I think might be the most likely cause from what I know. Dynamic data structures like `Vec` always have some checks for `can I haz moah memoriez plz?` somewhere. Any by moving the one and only triggered `if` doing just that out of the loop, the loop will always skip this branch and function call, making the branch predictor very happy. In fact, modern branch predictors do not just check a branch by itself, but also use information about previously taken branches to gain "deeper" contextual information about what to do next. Anyways, like I said, those are just wild guesses. I don't know `CountTree`'s source code and I don't know your generated assembly. Thus, it might as well be black magic. Edit: I seem to have managed to overlook the provided LLVM-IR. This is so much unreadable. ._.
 $ cargo-clippy.exe --help C:/Users/Faizaan/.cargo/bin/cargo-clippy.exe: error while loading shared libraries: rustc-cb705824.dll: cannot open shared object file: No such file or directory Any reason why this happens? Win10 32-bit, with rustup.
I like that. I think that might be actually useful.
As noted above with the other posts: *so sorry* I took so long to reply, but Reddit just fell off my radar with other things going on. Thanks for this feedback!
I'm very interested in this, but cannot reproduce it myself. Your examples generate almost identical assembly and perform very similarly on my machine. I'm really bad at reading LLVM IR, so would you mind posting the assembly version as well (preferably with Intel syntax?). The `rustc` flags are: --emit=asm -Cllvm-args=--x86-asm-syntax=intel
So all I need to do is `&amp;mut Self` ? 
Well, there are 2 apparent changes for me, but why LLVM choose them, I have no idea: 1. Completely different inlining choices: the first version inlines half of `CountTree` into main, but then leaves some other functions uninlined (`detach_left`, `detach_right`) 2. Probably the more interesting one: It looks like that in the second version LLVM gets rid of most of the calls (and references) to `std::Option`. It seems to me like LLVM proved (?) that the root of the tree should never be `None` inside the main loop, and used that knowledge to avoid ever checking for it (there's an extra call to `unwrap` in the second version, which seems to support this theory I think). I think why I didn't see the difference before was because I tried to profile them side-by-side: LLVM generated the regular versions of the functions and used them for both benchmarks. As soon as I tested them one-by-one I got the same result as you did. I'm sorry if I'm completely off-base here and if I am, someone with more Rust-oriented assembly knowledge will surely correct me (and please do!).
In the Rust forum there was part of a thread about this topic. Think about translating this D code into Rust: void main() { bool cond1, cond2, cond3, cond4; do { if (cond1) continue; if (cond2) continue; if (cond3) continue; } while (cond4); }
In my experience it worked well with Rust code on Windows. At the time it didn't seem to be able to un-mangle function names as well as it could with C++, but if that hasn't been solved yet (in terms of improving Rust's debug output) I expect it will be. 
I'm not sure I understand your question, is the following what you mean? loop { if cond1 { continue; } if cond2 { continue; } if cond3 { continue; } if cond4 { continue; } break; } It seems like a strange way of stating `if cond1 &amp;&amp; cond2 &amp;&amp; cond3 &amp;&amp; cond4 { loop {} }`.
Nice! I like the modularity of the design. For those wanting support for other tools, you can just check out [src/parse/cachegrind.rs](https://github.com/pegasos1/cargo-profiler/blob/master/src/parse/cachegrind.rs) for an example. It looks like a pretty minimal number of functions that would need to be written. It seems like the use here is less about printing things to the console, though, than about having an in-memory representation of the data. So, the tools built off of *this* tool are the real key. A way to visualize and manipulate profiler data drawn from multiple tools would have use far beyond Rust users alone.
I wish Rust had another backend besides LLVM ([QBE](http://c9x.me/compile/) may be?). Even if not as performant as LLVM, we could compare performance between Rust source code structuring with just the well-known optimizations. Having MIR, this should be much easier now.
Are you sure your code is semantically equivalent to mine?
Oops, you are correct. How about this one: loop { loop { if cond1 { break; } if cond2 { break; } if cond3 { break; } break; } if cond4 { continue; } break; }
I've tried to make a trait object that implements two traits: trait A { fn a(&amp;self) { println!("A!") } } trait B { fn b(&amp;self) { println!("B!") } } struct S; impl A for S {} impl B for S {} fn main() { let x = S; x.a(); x.b(); let y = &amp;x as &amp;(A + B); } I get this: **error: only the builtin traits can be used as closure or object bounds [E0225]**. So, is this going to be possible someday, or is there a reason it is not possible? And what is the solution? Should I write a new trait AB that inherits A and B, implement AB for S, then cast x to AB?
That page reminds me, I don't understand why Rust uses leaving off a semicolon to mean "return", and discourages you from using the "return" keyword. It seems like it goes against the explicitness used everywhere else. You define a function with "fn", shouldn't you return with "return" or at least "rn"?
It looks great!
yeah, i didn't realize there were development versions of valgrind available for osx.
Indeed. I'd like to see backend that generates portable C. That way you could use rust to incrementally replace C in C projects without hurting portability. If you were to generate the C as part of `make dist` you wouldn't even add build-time dependencies for your downstreams. This is what vala does.
No, and again, [it's not needed](https://is.gd/ewe3kg) in a match statement either.
Yes; you can auto-implement the combined trait for all candidate types: trait AB: A + B {} impl&lt;T: A + B&gt; AB for T {}
Looks good, although I'd remove the double negative and write `a.iter().zip(...).all(...)`.
I 100% agree with everything you said here. This comment is just to write down a thought I had, which is that for me (and probably some others), my first instinct upon seeing the name of a piece of software I want is to type `yaourt -S softwarename` (or the equivalent for whatever package manager).
Almost. Difference can be seen in case like this: enum Foo { Bar(i8, i8), Baz(i8, i8), } let foo: Foo; match foo { // Bar(_) is invalid Bar(_, _) =&gt; {}, Baz(..) =&gt; {}, } So in simple words `..` means match any elements and `_` means match that particular element. PS this works also with structured enums: enum Foo { Bar { a: i8, b: i8 } } match foo { Bar { b: _, .. } =&gt; {} }
Actually `..` can match zero or more, but it is linted out by default: &lt;anon&gt;:8:9: 8:21 error: `Foo::Bar` does not name a tuple variant or a tuple struct, #[deny(match_of_unit_variant_via_paren_dotdot)] on by default &lt;anon&gt;:8 Foo::Bar(..) =&gt; { } ^~~~~~~~~~~~
&gt; Windows support is at best an afterthought for each of the aforementioned projects. It took a long time before you could even run Rust on Windows, as LLVM didn't have support at all until recently. This is... plainly false. Rust has worked on Windows for years, and making it work well is absolutely a priority that we've invested a lot in.
Can you explain how those are apparent to you? I can usually squint my way to figuring out IR/assembly but I'm not well versed in reading either so those conclusions would take me a very long time to reach.
That's true for using trait methods, but not for what I'm asking about here. Anyway, importing the trait does nothing.
But it was `0` at some point. While it is in the same state, one of those sequences contains more information.
Did you compile clippy with the same nightly?
Nice to see that they are already fixing it.
I think I took it too far. This results in a segfault ;) https://play.rust-lang.org/?gist=bf2b9682535145e60e3fc91b6488f81e&amp;version=nightly&amp;backtrace=0
This is really hard, because C has a good portion of UB (undefined behavior) that Rust does not have. Writing code to perform the same operations in portable C would require a lot of extra checks and probably be much slower.
Cool, didn't know that.
Well, I feel weird explaining it since I don't even know if my conclusion in the second case is correct. But given the assumption it is, here's the steps I followed: 1. Load up the 2 different assembly files in a diff tool, which makes it much easier to reach any kind of meaningful conclusion 2. The inlining thing (if you're not interested in all the details) is fairly easy to spot: * in the case of things being inlined to `main`, you can just look for the matching `.cfi_{start,end}proc` pairs. In the first case `main` is around a 1000 lines, in the other it's ~120 * the general case is much easier if your diff tool is good: you can just look for `call` instructions that are not present on one side, but are on the other 3. This is where I jump to conclusions: * The most obvious different (and what made me think about it) is the lack of `std::Option` prefixes around the `drop` calls in version one * There seems to be much more calls to `Option::drop` than `Node::drop`, from places that don't look like unrolled loops. I assumed these come from the bunch of `unwrap()` calls in the original code (this is where my knowledge of Rust codegen is not really up to par: I know `panicing` `unwrap` will call `Drop::drop`, but I could be easily wrong here) * there's no actual code generated for `Option::drop` in the second version Again: if I'm completely off-base, someone please correct me, I'd be glad to learn more about assembly generated from Rust code Edit: fixed typos 
I am able to duplicate similar behavior (I just get a silent failure), and I've opened an issue at [Clippy exits immediately](https://github.com/Manishearth/rust-clippy/issues/923)
All of the packages depending on diesel appear to depend on version `0.6.1`. Now, diesel itself is compiling based on the latest master on github because of some other issue I ran into that wasn't fixed on the latest cargo version (there was an issue open against this and that was the suggestion). But the version numbers match. Could that still be the issue? diesel = {git = "https://github.com/diesel-rs/diesel"} diesel_codegen = {git = "https://github.com/diesel-rs/diesel", default-features = false, features = ["nightly", "postgres"]} dotenv = "*" dotenv_macros = "*" r2d2 = "*" r2d2-diesel = "*" Edit: on that note, I *did* try using the latest r2d2-diesel from github, too; doing that did not solve the issue.
What's the difference between the "deny" and "forbid" lint levels?
Playing around with that actually gave interesting results. Start with [this](https://play.rust-lang.org/?gist=5fdc2decdef9d20966c23bb40808ddeb&amp;version=nightly&amp;backtrace=0), and then slowly chop off (or comment out) one `... ..` after each other. The results are: Segmentation fault (core dumped) playpen: application terminated with error code 139 --- thread 'rustc' has overflowed its stack fatal runtime error: stack overflow Illegal instruction (core dumped) playpen: application terminated with error code 132 --- Segmentation fault (core dumped) playpen: application terminated with error code 139 --- Segmentation fault (core dumped) playpen: application terminated with error code 139 --- error: overflow evaluating the requirement `std::ops::RangeTo&lt;std::ops::RangeToInclusive&lt;[...]&gt;: std::fmt::Debug` [--explain E0275] --&gt; &lt;anon&gt;:6:9 6 |&gt; .. ... .. ... .. ... .. ... .. ... .. ... .. ... .. ... .. ... .. ... |&gt; ^ &lt;anon&gt;:6:9: 30:39: note: in this expansion of format_args! &lt;anon&gt;:6:9: 30:39: note: in this expansion of print! (defined in &lt;std macros&gt;) &lt;anon&gt;:6:9: 30:39: note: in this expansion of println! (defined in &lt;std macros&gt;) note: consider adding a `#![recursion_limit="128"]` attribute to your crate note: required because of the requirements on the impl of `std::fmt::Debug` for `std::ops::RangeToInclusive&lt;std::ops::RangeTo&lt;[...]&gt;` [...] I ommited some parts of the output for obvious reasons
Does that thread have an actual real-world example of a do-while loop that's challenging to translate to Rust? Artificial examples are not particularly compelling. :P
Hey, at least it's just segfaulting the compiler, rather than segfaulting at runtime. :P I wonder if this is LLVM choking on something that we're handing it.
I've been writing a macro that removes the casting boilerplate you need when defining quickchecks (without using the syntax extension). quickcheck will maybe include it down the line. For now I'm testing it out. [Link to macro](https://github.com/bluss/rust-itertools/blob/56bbfa146c7bb3898f43e9759f9f47a060a55435/tests/quick.rs#L155-L193)
Oh nice. Luckily, the boilerplate is not that big at the moment, so I am fine with having it completely macro-less, but I can see the benefit of that macro.
I'm working on my netmap/syncookie project. Today 1 reached 10Mpps with 10 cpus (Xeon E5 2680).
I assumed there would be some more code in between the `if` statements in a real-world scenario. Otherwise I obviously agree with you.
The best you can do is generate dynamic C libraries using Rust. This works better with huge applications, that may already have a plugin infrastructure though. Then have your C call Rust-C functions, or have Rust call the C functions.
Almost exactly like C. Only real difference is to use Rust's `&amp;[_]` pointer-length pair. https://is.gd/HPZ9N8 The same gotchas with padding, endianness, and trap representations apply. Rust (currently) disables borrow-checking for the result of functions like `slice::from_raw_parts` - that's what the docs mean by "The lifetime for the returned slice is inferred from its usage." Best practice is to pass it through a method or function call as demonstrated. I believe it's possible to do a clever and probably ill-advised implementation of `AsRef&lt;[u8]&gt;` so you can just say `out.write_all(&amp;msg)`, but `Borrow` is probably the more correct trait stylistically.
Usually I really enjoy Julia's blog. It's one of the few programming blogs that I read semi-regularly. However, her conclusions in this post don't seem very fair. She seems to equate the presence of a batteries-included standard library with the language being easy to learn, which of course is silly. Also, she mentions that she doesn't know C, but doesn't say how much time she's invested (if any) into learning C. Without that bit of knowledge, it's hard to say whether her anecdotal experience learning Rust is truly an indication that it's easier to learn than C. Personally, I think C is easier to learn, but perhaps more primitive and less well-defined, and thus more difficult to use effectively.
None of the Rust toolchains I use compile this. I even downloaded nightly-2016-05-12 and that failed too. Edit: Ok, 1.8 seems to work fine (I've been programming in rust for over a year and have never used a stable version lol...) How do I tell what version(s) of Rust a Rust project will work with? 
Eh. The untyped lambda calculus is the easiest functional language to learn, but building anything in it is really hard. I also completely disagree with a batteries included standard lib being a silly thing to care about. C *has* a standard lib and it is responsible for a huge number of software errors. It is also probably what prevented an untold number of other errors.
I never said a batteries-included standard library was a silly thing to care about. I think it's a huge advantage. Also, I completely agree that libc is basically garbage. It's full of broken and useless functions like `atoi`, `strtok`, `strncpy`, etc. My point is that these facts don't imply that Rust is easier to *learn* than C.
Easier to get work done with?
Easier to learn how to get stuff done with it?
This thread is going off on a tangent completely unrelated to my original comment. The blog post claims that Rust is easier to learn than C without any convincing evidence. That's all I was trying to point out. Is it easier to learn how to get stuff done with Rust? I have no idea. I don't wish to argue about this any further.
Yay Windows!
The first big thing I would say is match statements [like this one](https://github.com/shterrett/efficient_route_planning/pull/1/files#diff-b32354c253cf6b140db803e937de39d4R49) where the `None` case does nothing. In this instance, you would want: something.get("value").and_then(|node| { // do stuff }); Check out [`Option` function composition](https://doc.rust-lang.org/std/option/enum.Option.html) for more fun.
Or hodor.
Wouldn't it be okay to go from a safe language to an unsafe one, as long as you didn't modify the results by hand? Sort of treating it as a less useful version of MIR?
Why would you use signed integers if you don't use negative numbers? If you use an integer for counting things (buffer/string lengths, tree depths, event counts, …), which is the majority of my integer variables, then a sign bit is just an opportunity for invalid state, and ultimately wasted space.
Option HoF are generally transformative, so from an `and_then` semantically you would return a value, not perform side-effects. For side-effects, especially with only one branch, `if let` seems better indicated to me: if let Some(node) = something.get("value") { // do the thing }
Doesn't the `insert(0, 0)` effectively remove the None case and provides a hint to LLVM? Analogous to say, doing an `assert(value)` to do type hinting for a JIT (PyPy). My conjecture is that calling remove doesn't remove the fact derived from the previous insert.
She knows her fundamentals pretty well, from what I've seen on her blog/twitter. She just likes talking about tooling, and talking about stuff she has just recently learned about.
I would still write my scripts in python, I feel that rust is better for doing stuff that needs to be right, and bigger programs. For the things that she's writing about in the post at least I think doing them in python would be better. Now for writing something complex I'd rather do it in rust.
Third speaker will come over the day.
How does `fn notsure()` work? I thought Rust didn't have assignment expressions‽
Making `Graph` generic would be good style and practice. For example, you can make it work on both `String` and `&amp;'static str` and save a lot of the `.to_string()` calls in the tests.
I don't think so.
Thanks for the comments, everyone!
One of my favorite testing libraries for Haskell is available in Rust? Hell yes.
I believe this info should be in the Cargo.lock file
`deny` can be overridden by an inner `allow`, but `forbid` cannot. This program compiles: #![deny(unused)] #[allow(unused)] fn dead() {} fn main() {} but if you replace `deny` with `forbid`, then you get errors.
I've seen it in the Servo codebase. It's being phased out for other forms, though. Edit: By "it" I meant `&amp;*`.
The thing is, I'm not 'violating' the spirit of the coherence rules as I'm only implementing `MyTrait` for my own types. I feel the coherence checker is being more strict than necessary. I'll probably go with macros then. Thanks.
This is a cargo subcommand. Here are all the currently known cargo subcommands! https://github.com/rust-lang/cargo/wiki/Third-party-cargo-subcommands
Glad to see folks using quickcheck. :-) It is definitely standard to put `quickcheck` in your `dev-dependencies`. Using a feature is overkill. To conditionally include it, you can do, e.g., #[cfg(test)] extern crate quickcheck; It would be great if you could update your blog post---we don't want people adopting an unnecessary dependency. :-)
Surely it's the same thing. If you can't "get stuff done" in C, can you truly claim you have learned the language? If knowing the syntax and semantics of the C language by heart means you have learned C, then wouldn't knowing the Peano axioms imply you have learned number theory?
&gt; Having an opinion is against rule 4? I don't think so. Maybe you aren't sure, but Rule 4 is the "No zealotry" rule on the right hand of this subreddit. The full text of the rule is: &gt; When discussing other programming languages, maintain civility and respectfulness.
That's quite an impressive overview of the engineering of a modern compiler, and it has ideas for other tasks as well.
My other response was from before you edited your post. Calling another language "shit" is inflammatory, unwelcoming, and without purpose. The comment we're talking about would have be fine if it had been reworded only slightly. You, however, are _abusing_ the notion of tone policing and that upsets me. Tone policing is the discriminated employment of civility requirements toward subaltern groups, either intentionally or as the result of an implicit inability to recognize real violence against groups which are not privileged. It is a tactic used to silence people and perpetuate systems which destroy peoples' lives. It has nothing to do with the Rust community maintaining a standard of discourse. EDIT: My apologies everyone, when this user listed "no hate speech" as one of their requirements I thought they were well-meaning but misguided. Sorry for furthering this unproductive conversation!
Your code is basically doing double free: On the end of the `unsafe_scanl`, the destructor of `v` is run, and on the end of `test`, the destructor of `u` is run, trying do deallocate the same chunk of memory. You can `std::mem::forget` the `v` before the last line of `unsafe_scanl`, but the better way to do it would be to use [`Vec::set_len`](http://static.rust-lang.org/doc/master/collections/vec/struct.Vec.html#method.set_len), get rid of `from_raw_parts` and just return `v`.
if you have pure rust code without FFI dependencies does the musl technique pretty much work to get a static binary?
I like that this attempts to fight the right-ward drift so common with rustfmt, although I'm not quite sold on the exact style. Definitely nice to see an alternative style actually implemented, though!
I don't intend to address the issue of downloading the toolchains themselves in platform-dependent ways. rustup is fundamentally a tool for installing the official rust binaries. So I imagine Homebrew, PPA's and less strict package ecosystems would be fine packaging a rustup that delegated *self-updates* to the packaging system while still using static.rust-lang.org for the toolchains themselves. That said, I do recognize that it would be *really nice* if one could use rustup's toolchain-juggling even with distro-installed packages. Technically it's conceivable, since the rustup model of toolchains + targets is quite simple, and could be mapped to other system's commands. Practically though it would be very complex since every package manager operates differently, subdivides packages differently, provides varying quality and completeness levels.
Even with FFI dependencies, you may be able to link statically?
Is it not possible to merge these features into rustfmt and provide them as an alternative?
Even with FFI deps it's possible, but every case will probably require its own tweaks. The rust-musl-builder docker image I mentioned in the post should help since I think it's done the builds for libs you're most likely to run into. I haven't actually tested rust-musl-builder myself though.
The Burroughs MCP mainframe OS was created in 1961 using ESPOL, which is known nowadays as Unisys Clearpath/MCP. https://en.wikipedia.org/wiki/Burroughs_MCP Lisps were of course using dynamic memory allocation in the early 60's. Several OSes were written in Algol 68 including systems with GC support, yes. As starting point, https://en.wikipedia.org/wiki/ALGOL_68 Then there were all those PL/* variants. &gt; BCPL and Pascal did not had typed manual dynamic memory management BCPL of course not, it was barely a more human friendly Assembler, after its author rebelled against CPL's complexity. Pascal as designed by Wirth not, but most Pascal dialects allowed for arrays with dynamic bounds, if that is what you mean by "typed manual dynamic memory management". Also malloc() and free() with void* are anything but typed. 
This is terrific! Though I'm still bummed that XDC paths aren't used.
thank you! It all works very well now.
I say that the comment in question violates rule 4 (and a bunch of comments below violate tons of the rules). It is okay for other community members to point out the rules.
I'm still learning Rust (and the style) so maybe others will have more input. But this looks mostly good to me! I only have one thing: [`let mut layers = Vec::new()`](https://github.com/hatsunearu/neuraltoy.rs/blob/master/src/neural.rs#L35) As you know the final length of the `Vec` it would be better to instantiate this using `with_capacity()`. In case it can help you later down the line you could check out the [rusty-machine neural network](https://github.com/AtheMathmo/rusty-machine/blob/master/rusty-machine/src/learning/nnet.rs) implementation. It is also a simple feed-forward nnet but with a few more moving parts. 
It's a rule against "zealotry," which includes calling programming languages shitty or sexy. The OP obviously did that. We don't allow that, because it's just asking for flame wars and never accomplishes anything. Voicing displeasure is not always zealotry, though. For example: &gt; I found another way to make quickersort walk across memory with an invalid Ord implementation. I hate my life... That is clearly caustic, but doesn't seem to be zealous.
&gt; That is clearly caustic, but doesn't seem to be zealous. I don't think that's caustic though. *shrug*
I did a similar thing when I started out so I totally get it. Good luck!
Thanks! I'm gonna finish the backprop tonight. Designing the data structure was the hardest because I was trying out various ways until I found the one that was least painful in terms of the borrow checker.
How do I make this compile with safe code ? https://is.gd/xu7j0x trait Decodable { fn decode(&amp;mut self, buf: &amp;[u8]); } impl&lt;'s&gt; Decodable for &amp;'s str { fn decode(&amp;mut self, buf: &amp;[u8]) { // *self = std::str::from_utf8(buf).unwrap(); *self = unsafe { std::mem::transmute(std::str::from_utf8(buf).unwrap()) }; } } fn main() { let mut s = "foo"; let v = vec![b'h', b'i']; s.decode(&amp;v); // oops } I'd like to constraint buf's lifetime to &amp;str. Is it possible? Thank you.
This might have some relevant useful information, since the rust team is also working on [IDE support](https://github.com/rust-lang/rfcs/blob/master/text/1317-ide.md) and [incremental compilation](https://github.com/rust-lang/rfcs/blob/master/text/1298-incremental-compilation.md).
&gt; She seems to equate the presence of a batteries-included standard library with the language being easy to learn, which of course is silly. How is it silly? A programming language without a standard library isn’t worth much—the standard library is the common vocabulary with which real programs are written. It stands to reason that a comprehensive and user-friendly standard library should make it easier to learn to use a language *for real-world tasks*. From a user’s perspective, there’s no material difference between features built into the language and those provided by the standard library, because the latter (under normal circumstances) is always present.
I think Rust makes it easier to accomplish certain real-world tasks without understanding the language, so it may *appear* easier to learn. Consider this contrived example: you want to write a program that computes the Levenshtein distance between two strings, and you try it in both D and Rust. In D, `levenshteinDistance` is a library function in `std.algorithm`, so you're already done. In Rust, you need to learn about the syntax for loops and conditional statements, you need to learn about the different string types, maybe `Vec` or some other collection (depending on your implementation), etc. Does that mean D is easier to learn than Rust? I don't think so.
One reason I saw was "because cargo does it too" which is an even bigger bummer.
If I have a `multirust` ATM, should I be moving to `rustup`, or not yet?
Checkout the latest release (0.5) it goes much further to avoid rightward drift in large blocks and method chains.
This isn't the way that the `link` attribute is supposed to be used. Instead, you use the `links` key in Cargo.toml along with a build script. See here for more: http://doc.crates.io/build-script.html#case-study-linking-to-system-libraries
 Okay, is there a way to have my `build.rs` reliably find the `libprofiler.so.0` without manually searching through the `LD_PATH`?
.profile is the correct place for it to be, and bash *will* execute it, but you do need to re-login or start a new login shell after making the changes. This is a limitation of how environment variables work on linux. For your first problem: You can't just install the windows toolchain on linux, that won't work. (The error you're getting is because in the windows toolchain, rustc is named "rustc.exe"). If you look at the latter examples in the blog post, you'll see that they use the standard toolchain for the host (in this case linux) but install an additional target for that toolchain (in this case windows). You'll also need a PE linker, which you should be able to get by installing mingw, and then you'll have to tell rustc to use that linker instead of the default system linker. (I don't have exact instructions for you, but it should be very similar to the android example, just with mingw instead of the android ndk)
Will do!
Well, maybe it's a bit early for this—this project is brand new, I know, and I'm sure there are bigger fish to fry right now—but I'm left thinking about: 1. Tool proliferation. Why do I have to interact with two different tools (Cargo and rustup)? 2. Granularity of state. If I'm working on two source trees simultaneously that call for two different toolchains, will I have to `rustup` back and forth all the time? It sounds like it would be better to have each source tree "know" its current toolchain. 3. Why even be limited to one toolchain at a time? If I'm building a project for which I want to release binaries in two or more platforms, why can't my source tree "know" this, say through a Cargo profile that allows multiple platforms to be built with one command? 4. I feel this also ties with the [recent suggestion that crates should be able to declare a minimum compiler version](https://www.reddit.com/r/rust/comments/4i5l5j/crates_should_declare_a_minimum_required_rustc/). With automated toolchain provisioning such metadata quickly becomes more valuable. Haskell's [Stack](http://docs.haskellstack.org/en/stable/README/) build tool already has a version of this—it will select and provision a GHC version appropriate to your source tree's metadata (but doesn't support cross-compilation, only compiler version agility).
For those unfamiliar with Tokei, its GitHub home page describes it as: &gt; A blazingly fast CLOC(Count Lines Of Code) program, written in Rust.
Do you have a `~/.bash_profile` or a `~/.bash_login` ?
One way is the `pkg-config` crate. Depends on what you want to do.
I'm trying to create a REST api with rust, postgres, diesel (orm), iron, and serde for json serialization. I'm using rust nightly because diesel and serde are easier to use with it. I've been slightly frustrated (for several months) trying to figure out how to compile successfully with the latest nightly version where all dependencies also compile. It's sort of like a balancing act to get everything working, however once it's working, it's pretty stable. I'd like to keep the nightly version of rust fairly current instead of depending on a version from march and old versions of libraries. Here's my workflow for attempting to update all my dependencies to the latest version and update rust nightly version: - Use multirust to update nightly - Open Cargo.toml and look at each dependency, and for each: - Search on crates.io to see what the latest version is - Update Cargo.toml to that version - EDIT: run `cargo update` - Attempt to compile. - This latest attempt, diesel didn't compile. It's [getting started site](http://diesel.rs/guides/getting-started/) mentions that it works on 2016-04-09, so I used multirust to switch to that nightly version. - Diesel built successfully, but [aster](https://github.com/serde-rs/aster/issues) didn't. This could be because the rust nightly for 4-9 is too old... or new? What does one do in this situation? Am I doing something wonky? I hope so because this is too difficult to keep updated. I could create issues every time I get a nightly build issue (which I've tried) but waiting on those pull requests to get in and the crates.io version to be updated can be a long process. I could fork all the repos, and attempt fixes on my own, but that gets tedious. I could keep going back with dependency versions and rust nightly versions until I happen to hit one where everything jives, but that is not a great way to do it. If this is what I should expect, then that's too bad. Ideally I'm doing something wrong and this issue can be remedied! Thanks!
I assume you mean the [XDG basedir specification](https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html)? As mentioned below, rustup is following cargo's lead. [Here's a stale PR for cargo, with some discussion](https://github.com/rust-lang/cargo/pull/2127) and [here's an actual issue, with little discussion](https://github.com/rust-lang/cargo/issues/1734).
So rustup apparently follows the rbenv/pyenv model, which is all well and good, but I'm more comfortable with the Python virtualenv model, where by default the only tool you have is the "give me a toolchain" tool, and when you ask for a toolchain it's installed into an environment that you can mess with without affecting any other environments you might have installed. This means: - I can't start a project without deciding which toolchain I want it to use. - If I'm working on one project, then switch to something else, when I come back I won't have nasty surprises caused by changes made to other projects (like changing the 'default' toolchain'). Is there some alternative or competitor to rustup that works like that?
What is the upgrade path from multirust.sh to rustup.rs?
So I did `rustup update`. Then reinstalled clippy with `cargo install`. $ rustup run nightly cargo clippy src/lib.rs error: C:/Users/Faizaan/.cargo/bin/rustup.exe: error while loading shared libraries: ?: cannot open shared object file: No such file or directory $ cargo-clippy.exe src/lib.rs C:/Users/Faizaan/.cargo/bin/cargo-clippy.exe: error while loading shared libraries: rustc_driver-cb705824.dll: cannot open shared object file: No such file or directory No idea what's wrong :/ 
Could bors automatically re-test new revisions that were previously asked to be tested before? Or would this waste too much computational resources? Btw this testing bot is amazing!
https://github.com/Manishearth/rust-clippy/issues/923#issuecomment-219155212
Yes, it is just a personal tool for my personal code style preference. rustfmt is great for configurable. On the other hand, I think it is really hard to satisfy everyone's code style preference. Although the philosophy of gofmt is on the opposite side to rustfmt, it offers another opinion about source code formatter.
I think your main issue is that you attempt to use the latest of all. It is much easier to stick to a working set and update when it is absolutely necessary. You did not explain what your motivation is to update everything regularly. If it is not because of a feature that you need asap then I think you are just making yourself a problem for no real gain. I assume that you are developing an application with real functionality and not just attempting to beta test these libraries.
If you use rustup override, changes made to other projects won't cause any problem of changing the default toolchain.
You need to uninstall multirust first. If you try to install rustup it will detect multirust and it will tell you how to uninstall it
While not called XDG, specifications exist for other OSes as well, none of which are followed by cargo/rustup.
Anders really stressed the importance of the immutable AST which is something that isn't quite Rust's strong point. Sure you can use `Rc` or `Arc` and I think it should actually work well in for this use case as cloning and creating new nodes should be relatively rare. On the other hand using a single owner for each node (using `Box` basically) may also work quite well as you would be assured when updating the tree that noone else is holding onto references to data that is about to be stale. That being said, I can't quite say if there are other problems with a single owner approach.
Honestly I don't even understand why your code works at all: `Decodable::decode` takes self as `&amp;mut str`. Because `str` is a fat pointer, you get a pointer + length as input by value. You cannot modify either so w/e you do must retain the original length. (your example somehow still works, how?!) Slices have a method to do something like this: [`clone_from_slice`](https://doc.rust-lang.org/std/primitive.slice.html#method.clone_from_slice) but no such method exists for `str`. Notice how the it requires the argument have the same length? If your use case is to simply extract a `&amp;str` from a byte vec, then `from_utf8` should work just fine, no? You can even have a `String` buffer, to which you can assign `&amp;str`: fn main() { let mut s = "foo".to_string(); let v = vec![b'h', b'i']; s.clear(); s.push_str(std::str::from_utf8(&amp;v).unwrap()); println!("s:{} v:{:?}", s, v); } Why do you want to constrain this lifetime? You are copying from the input `&amp;[u8]`, not retaining references to it so lifetimes don't come into play.
`.profile` is loaded on login, not on each shell startup. Try logging in with eg. `ssh localhost`, it should be printed then.
Thanks for your reply. `Decode::decode` is implemented for `&amp;str`, making `self` of type `&amp;mut &amp;str`. What I try to achieve is to update a `&amp;str` to points to a slice of bytes (assuming valid utf8), without copying anything. Using `String` as you proposed looks like a good alternative if the zero-copy is not achievable. Maybe a more concrete example of what I'd like to do: loop { let buf: Vec&lt;u8&gt; = recv(); let len: u8 = buf[0]; let mut name: &amp;str = Default::default(); name.decode(&amp;buf[1..len+1]); do_something(name); } The real-life example is more complicated than this snippet and I must be able to use `decode` through a trait function (because the actual types to decode are generic).
Slightly off-topic, but if you're going to use `pyenv`, I'd always recommend [`pyenv-virtualenv`](https://github.com/yyuu/pyenv-virtualenv), which basically provides a wrapper around creating virtualenvs and the like. For example, when I create a project, I do `pyenv virtualenv &lt;python version&gt; &lt;env name&gt;`, then `pyenv local &lt;env name&gt;`, and I get all the pyenv goodness and magic, whilst still getting a unique virtualenv for that specific environment. That said, as other people have pointed out, it's still somewhat different - Python generally has a global package installation system, whereas (apart from `cargo install`) Rust uses per-project package installation. If you've got a package installed for a single project, `cargo` will only ever include it when it's building that project.
&gt; In Rust, you need to learn about the syntax for loops and conditional statements, you need to learn about the different string types, maybe Vec or some other collection (depending on your implementation), etc. Or just search `levenshtein` on crates.io and heuristically choose the one with the most downloads. Done! :-)
Modifying your PATH is an install option when you install rustup: if you don't want it to modify your dot files, simply choose "no", and rustup will instead explain how to make the change yourself. `.profile` is the only place which will affect all programs run by your user. If you use `.bashrc` or similar, then you will not be able to use rust from outside the bash shell.
Sounds nice, though for me it crashes because of an regex error. Going to file an issue now.
FWIW, I've been using rustup for quite a while now and havent seen a single bug. So it might depend on how complicated your workflow is too, but for the average case rustup has been flawless for me.
Great video, lots of ideas there, and the code for both TypeScript and C# (OmniSharp) is fully open source and available to study. One question raised, looking at the [RLS RFC](https://github.com/rust-lang/rfcs/blob/master/text/1317-ide.md). Conversions between UTF-8 byte offsets, UTF-16 code unit offsets, and line/column are all easy and efficient using a rope data structure that stores all three counts in the "node info". The `Tree` in [xi-rope](https://github.com/google/xi-editor/blob/master/rust/rope/src/tree.rs) is generic with respect to node info, but the current [rope](https://github.com/google/xi-editor/blob/master/rust/rope/src/rope.rs) instantiation only counts utf-8 and newlines. I'm strongly considering changing it within xi since most front-ends do care about utf-16 (right now, the conversion is done in the front-end on a per-line basis).
I just installed racerd as it lands in my distro packages soon and I'm just wondering: If I type ``` foo.bar(). ``` I get the completion on `foo.` for `bar` (without parentheses actually... is that intended?) but not on the result of `bar()`. I'm using neovim with YCM as completion engine, racerd as backend. Not sure whether I should post this here or over in /r/neovim or...maybe even somewhere else?
Hello everyone, I played with http://rustbyexample.com/ a bit, and now I'm trying to code a little game as a first project with rust. Here is my code: extern crate sfml; fn main() { let mode = sfml::window::VideoMode::new_init(1280, 800, 32); let title = "Game window"; let style = sfml::window::window_style::FULLSCREEN; let settings = sfml::window::ContextSettings::default(); let mut game_window = sfml::graphics::RenderWindow::new(mode, title, style, &amp;settings); 'game: loop { for events in game_window.events() { match events { sfml::window::event::Closed =&gt; break 'game, sfml::window::event::KeyPressed {code, ..} =&gt; { match code { sfml::window::keyboard::Key::Escape =&gt; break 'game, _ =&gt; {println!("Key pressed")} } }, _ =&gt; {} } } } } And here is the error I got when compiling: src/main.rs:17:35: 17:41 error: no method named `events` found for type `core::option::Option&lt;sfml::graphics::render_window::RenderWindow&gt;` in the current scope src/main.rs:17 for events in game_window.events() { ^~~~~~ I don't understand what I did wrong, since *game_window* is a *sfml::graphics::RenderWindow*, and according to the [doc](http://www.rust-sfml.org/doc/rsfml/graphics/struct.RenderWindow.html#), it has a method called *events()*. Could someone point me in the right direction? Thanks a lot!
From a thread in /r/programming, `-1 as u8` generates a compiler error about unary `-` not being allowed on an unsigned integer. I did not expect this; the type of the literal `1` appears to be under-constrained, so I would have said its type was `i32`. I poked around in typeck and found [this](https://github.com/rust-lang/rust/blob/6ba8a1a657cf37e648166ee4b41f51768ea46c1e/src/librustc_typeck/check/mod.rs#L3632) and chasing it down a little suggests typeck will try to use the RHS type as the type of the LHS in a cast. Okay, so far so good, because the operand of unary negation is also taken to be the same as the type of the whole unary negation expression here. But if I have `(255 + 1) as u8`, this generates no compiler error and it results in 0. OTOH, `(255u8 + 1) as u8` obviously generates compiler warnings and run-time-panics in debug mode. But [I thought](https://github.com/rust-lang/rust/blob/6ba8a1a657cf37e648166ee4b41f51768ea46c1e/src/librustc_typeck/check/op.rs#L134-L135) that these literals would be `u8`s because the RHS type would be given to the under-constrained LHS and then given to the literals. I guess I should figure out how to compile rustc and see if the `debug!` messages help me, but meanwhile I thought I'd see if someone would explain this.
Found it, `I` was only constrained by `Impl` so `#[derive(Clone)]` fucks up because `I` is a member of `Foo`. Instead of giving a warning that `Foo` is unclonable, it instead clones the reference (not the underlying struct). To solve this: pub trait Impl: Clone {}
Are there any good speech recognition crates?
Read the error carefully! It says "no method named `events` found for type `core::option::Option&lt;sfml::graphics::render_window::RenderWindow&gt;`". So what you are dealing with is not a `RenderWindow`, but an `Option&lt;RenderWindow&gt;`. `RenderWindow::new` can fail, so you have to check for `None` and decide how to handle that error before you can use the object.
In what way is it different than the first example I gave as far as being unconstrained?
Let's starting posting rustlang stuff in /r/playrust and see how they like it
I believe you want to be in /r/playrust
Thank you! Seams like I should read the theory a bit more :) But a the same time, working on a project makes it easier to learn.
That parens are not offered for `bar` might be an issue with the completion engine using racer, or maybe racer is picking up a private field of the same name. That `foo.bar().` is not completed is probably hitting a limitation in racer. There are quite a few types (mostly when generics are involved) that it can't handle (yet).
I don't think this will work without giving Decodable a `&lt;'s&gt;` generic lifetime: https://is.gd/FkgRx2
FWIW tokei was first released 11 days after 1.0, everyone else is just copycatting :). /s
In an emulator, the effect of this is typically *not* significant due to all the other code involved in executing instructions that is *also* compiled in debug mode.
Ah, thanks. Been awhile since I set it up, so haven't gone back to see about updates to rust-mode since then. 
So, I couldn't remember the exact time, and I had rustup'd between then and now, so I reinstalled to double check the time, so this was 2.0 :)
I didn't know about the wrapping_add/sub methods, thanks. Those seem to do the trick.
Yeah, you've got rather Scala-like traits. If you haven't seen it already, I'd recommend watching /u/edwardkmett's [Type Classes vs. The World](http://www.youtube.com/watch?v=hIZxTQP1ifo) for some nice analysis of why Haskell type classes are the way they are. Implicit impls are nice, but can have some nasty consequences with algorithm reliability at scale, which seems to be something you're going for.
&gt; or maybe racer is picking up a private field of the same name. I just tried with a type of mine that has no private members of the same name. Parentheses are not offered. &gt; That foo.bar(). is not completed is probably hitting a limitation in racer. There are quite a few types (mostly when generics are involved) that it can't handle (yet). I understand. Though, the point is: There is no special stuff involved in the example I tried. No generics, no lifetimes, just types.
Thanks! Got a similar setup running right now testing it out. What does YCM add to racer?
It _uses_ racer, it's not an addition to racer. It offers go to definition (`:YcmCompleter GoToDefinition` IIRC), automatic on-the-fly completion as you type (no need to type C-x C-o)... See [this blog post](http://blog.jwilm.io/youcompleteme-rust/) for more info.
Here are some good reads on the topic of how to implement graphs in Rust: * http://featherweightmusings.blogspot.com/2015/04/graphs-in-rust.html * https://github.com/nrc/r4cppp/blob/master/graphs/README.md * http://smallcultfollowing.com/babysteps/blog/2015/04/06/modeling-graphs-in-rust-using-vector-indices/ And the corresponding /r/rust discussions: * https://www.reddit.com/r/rust/comments/319dfg/tutorial_on_graphs_in_rust/ * https://www.reddit.com/r/rust/comments/31o4wh/modeling_graphs_in_rust_using_vector_indices/
YCM uses racerd(built on racer) which is faster. It also has JumpTo
I'm very new to Rust- a beginner. I'm super used to Java. Damn... I'm aware that I will struggle to start off with, but it sounds like it will be naturally hard. 
The language isn't *that* hard, it's just that thinking about ownership takes some getting used to after coming from a garbage collected language, and the borrow checker is quite strict (don't despair, you'll thank it later). And since data structures such as doubly-linked lists don't have a clear ownership relation between cells they're really frustrating to implement for beginners.
Since that issue is open, I'm going to say there's still no good way :(
[Playpen link](https://play.rust-lang.org/?gist=fd1008c269fe4096b4b47e9a726defd9&amp;version=stable&amp;backtrace=0). The assembly for `add_raw` includes addl %esi, %edi seto %al testb $1, %al jne .LBB0_2 which is pretty much free as long as the branch prediction works out well (i.e., if it's run multiple times and usually doesn't overflow). `add_wrapping` includes callq _ZN3num8wrapping23Wrapping$LT$i32$GT$.Add3add20h3b35548733e4f344DMbE AKA `num::wrapping::Wrapping&lt;i32&gt;::Add`. It's not inlined in debug mode.
Hmm ok fair enough, though I don't see why it doesn't get inlined. `#[inline(always)]` is supposed to work in debug mode. Maybe not for trait methods?
I did some investigation elsewhere and `#[inline(always)]` definitely *can* take effect in debug mode, but it doesn't always work and I'm not sure why. (See my other reply.) EDIT: It just wasn't getting optimized in dead code. In general `#[inline(always)]` seems to work in debug mode.
Very nice talk. I don't use ruby but It is nice to see Rust playing nice with the rest of the world.
Re: your edit: It's much more important to understand how datastructures work than to be able to implement them in Rust. For interviews usually being able to implement them in any one language it's fine. I suspect that Rust interviews will not ask for this stuff, but there is a small sample set of those right now so I don't know.
This is yet another good argument for adding a wrapping / bit-twiddling primitive type. It should also have methods for signed operations. Anyone interested in working up an RFC?
Fair enough! And as we can see below, it really *is* fast :)
An option is to use [wrapping macros](https://github.com/lfairy/wrapping_macros).
&gt; I suspect that Rust interviews will not ask for this stuff, but there is a small sample set of those right now so I don't know. It would be plainly _unreasonable_ to ask an interview candidate to implement a graph in Rust in the timespan of an interview.
Definitely not, just less than ideal streaming conditions for a bit :)
I'd like to see a technical comparison to other competing technologies. Roslyn is indeed very impressive but I don't think it represents the state of the art. LLVM and clang for one are designed with IDE in mind and there's a vi plugin that uses libclang for semantic auto complete. Of course for Java tooling was a goal since the beginning and intellij has far superior capabilities compared to visual studio. 
If you need to clean a lib build, you could manually delete the .rlib (or .so/.DLL, depending on lib type and system) from target/{debug/release}. Also possibly test binaries. But I'll agree that's not a *good* way.
BEST. INTERVIEW. EVER. A more reasonable linkedlisty interview question would be to create an efficient (well, as efficient as a SLL can be) singly linked list in only safe code, and do things to it (traverse, split, reverse) in pure safe code using stdlib types (not including LinkedList :P). This is pretty straightforward. I don't like linkedlisty interview questions, though, so I'd probably not ask this if I ever had the opportunity. 
I've got YCM and everything setup on neovim... Nice! Thanks for the pointers, this is what I've been looking for in rust!
Wow, I thought for sure this was a procedural macro, but its [all pattern macros](https://github.com/rustbridge/helix/blob/master/src/macros.rs).
I'm looking forward to see your emulator grow. It's very amazing to see the progress and play around with the code. I've downloaded Rustendo64, Turtle's ROMs, opened the source in IntelliJ IDEA with intellij-rust plugin and created a run configuration that runs `cargo run ...`. Works amazing. Also `rustup`makes it very easy to keep the toolchain up-to-date.
That looks a bit *too* good - 0.00 user and ~0.00 system? I don't expect full CPU use due to the I/O heavy nature of the job, but no CPU?
:D
Hey awesome! Love that you're playing with it!
Ah, I see. I'm not convinced this has any practical benefit over adding `Clone` bound to `Impl`. This is about making a deliberate choice of adding an autoderived `#[derive(Clone)]` to a type that doesn't support it by itself. Is there any situation where you actually want to do this and _not_ add `Clone` to `Impl`?
Seems like at least one of my issues is already posted in https://github.com/phildawes/racer/issues/481 
What about something like [`into_boxed_slice`](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.into_boxed_slice) on `Vec`? (I think that, if doesn't need to shrink, it doesn't reallocate - see [here](https://doc.rust-lang.org/src/collections/up/src/libcollections/vec.rs.html#474))
So, when will it be the first Obfuscated Rust Code Contest?
We already had two inofficial Underhanded Rust Contests on this subreddit, so feel free to submit a text post and declare the First Obfuscated Rust Contest.
Well in tests/mod.rs I test for OverwriteKey errors and other invalid input, or do you mean some other types of errors? I'll read about the testing, thanks! Edit: I moved all the tests into lib.rs, I'll need to look into the non-hardcoding idea as well. Is it good practice to put the tests into `src/tests.rs` or `src/tests/mod.rs`?
Super! Appreciate that.
&gt; from_exact_size_iterator looks ideal
With that signature for `add_inline_container`, you are asserting that the lifetime parameter of `LayoutBox` (`'a` in `LayoutBox&lt;'a&gt;`) and its mutable borrow (`'a` in `&amp;'a mut`) live as long as each other. This means the mutable borrow inside the for loop cannot end till `'a` ends (which spans the entire `build_layout_tree` and more), but `root` is moved out before the borrow ends by `return root` (of course)!! Try changing the signature of `add_inline_container` to this: fn add_inline_container&lt;'a&gt;(layout_box: &amp;mut layout_structs::LayoutBox&lt;'a&gt;) -&gt; &amp;mut layout_structs::LayoutBox&lt;'a&gt; This will confine the span of mutable borrow to the `Inline` arm of match block.
Please click the report button for any rule-breaking comments so we can deal with them :)
`Rc&lt;str&gt;` would also be quite handy, even `rustc`'s own string interner would benefit from it. Unfortunately, `Rc&lt;str&gt;` can't be created even with coercion, because there are no fixed-size strings! `Rc` really needs some methods for creating unsized values, but no one bothered to write RFC for this, AFAIK.
My thought is that you should just type `let x = !0u8;` instead of trying to use the unary minus there.
This is an evil trick from C that should not be allowed in any form in Rust. What's wrong with using ```u8::MAX_VALUE```? Also, the ```as``` keyword in Rust is rather a blant tool and does several kinds of conversios and coersions ("casts") and there is work in the community to improve this, e.g. implement integer conversions in std with the ````From / Into```traits.
Is this more tuned to the academic side or industry meetup side? Either way, congratulations! 
I can't agree with this. Utilizing the way casts works is not evil. Plus, you're only really going to be doing this when you're fiddling with bits, in which case knowledge about wrapping is requisite. There's nothing wrong with `u8::MAX_VALUE` for the trivial example, but the question isn't so much about "how can I express this" (`!0u8` seems ideal for that) but more "why is Rust inconsistent here?" 
`let x = -1 as i8 as u8;` I'm doing such things all day.
Yup, builder pattern or two methods with different names is the way to go. I would write `update` and `update_with_connection`, personally.
Thanks to both of you! I think in this case the builder pattern would be a bit of an overkill. Two function names seems kind of awkward as well but it is probably the best option for me.
Does `-1 as u8` parse to `(-1) as u8` or `-(1 as u8)`? If it's the second then this error message seems correct to me, if it's the first it doesn't. Of course, `(-1) as u8` has the same error message, which I do consider inconsistent with the rest of the language.
I think the "Create a new connection on the fly, taking the connection string from global variables" approach is dubious. I'd make the parameter mandatory.
This is my second serious blog post ever published. Any feedback on writing, style, subject matter, code/theory ratio etc. is much appreciated.
The former: unary operators bind more tightly than any binary operator.
I've gotten pretty close (I think), but have a vexing type error here: https://github.com/shterrett/efficient_route_planning/blob/generic-graph/src/connected_component.rs#L19 src/connected_component.rs:19:54: 19:60 error: mismatched types: expected `&amp;weighted_graph::Graph&lt;&amp;T&gt;`, found `&amp;weighted_graph::Graph&lt;T&gt;` (expected &amp;-ptr, found type parameter) [E0308] src/connected_component.rs:19 let connected_nodes = explore_from(root, &amp;graph); ^~~~~~ src/connected_component.rs:19:54: 19:60 help: run `rustc --explain E0308` to see a detailed explanation I'm not sure why the`&lt;&amp;T&gt;` is showing up, because all of the declarations are `Graph&lt;T&gt;` or `&amp;Graph&lt;T&gt;`.
Yes, but Rc stores the counts inside the allocations so it would still need to reallocate. 
I am always a little confused when people talk about the builder pattern because it seems to be used for multiple constructs: let foo = Foo::new() .with(bar) .and(baz) or let foo = Foo::new(FooParam{ bar: bar, ..Default::default() }) The first one is nice, I use it regularly. Of course it has its limitations. The second one I really dislike, I find it clumsy and not elegant. Of course it's a matter of taste... I personally think keyword + default parameters would nicely complement the builder pattern. For example when you have only one optional parameter. Or you have an optional parameter that is rarely used. Or multiple optional parameters that share no link whatsoever other than being parameters to the same function. Or... Consider the following example: some_function(arg, verbose=true) some_function(arg) vs some_function(arg, Verbose{ verbose: true }) some_function(arg, Verbose::default()) *It may be a bad example, there might be a nicer way to do this that I don't know of. If there is, please do show, because obviously I am not aware of it ;)*
Haha I think you're looking for r/playrust This sub is for the programming language
I'm not saying that it's better. It depends on what you want to communicate. Using `-1` might communicate something about how you handle "high numbers" or just the 8th bit in a way `!0` or `u8::MAX_VALUE` don't.
Yes but the fact that Rust doesn't do this very thing auto-magically is what separates it from Haskell. And yes it likely isn't the type of behavior you'd want to take place automatically. 
&gt; This is an evil trick from C that should not be allowed in any form in Rust. No. It's an evil trick from finite math that very much should be allowed since finite math is the only kind that computers can do in finite time without corner-cases. Finite math is used *extensively* in crypto, error correction, probabilistic algorithms, hashing, etc. Not every developer needs to understand it but it's strikingly unprofessional for a low-level language to be missing finite-math primitives that all modern CPUs support. 
Good to know another option. Currently I don't use any formatter. 
Hey cool, really glad to hear it! I'd love to see what you're working on :)
I agree, very nice proposal on the RFC too!
I think your first example has more to do with Rust's lack of automatic garbage collection than its type system.
Nothing too interesting or complex, just this attempt at a crate library to handle some files for an old game: https://github.com/hexjelly/elma-rust Not having done any real programming before, it's been a good challenge, without ending up getting completely stuck. And now I absolutely love Rust, even though I'm only using the very simple basic features of the language. Glad I came across your video and learned about it!
But insisting that this sort of rarely used math is done via `Wrapping&lt;T&gt;` types instead of the default integer types everyone uses is generally sensible and already a settled question. The only question to me raised by this post is one of consistency. Int types default to `i32`, why is casting it to a `u8` immediately but not later changing that default?
Trait Objects already exist. I think you got them mixed up with first-class type constructors?
Here's an intuitive explanation of the pumping lemma for context-free grammars (by using abstract syntax trees): * Suppose that we have a string `s` that belongs to the CFG and that we've constructed its AST. The AST's leaves correspond to terminals, while its internal nodes correspond to nonterminals. * If we could pick any path from the AST's root to a leaf that contains the same non-terminal symbol at least twice, then we could replicate part of the AST [as many times as we want, get a new AST and a new string that belongs to the CFG](https://en.wikipedia.org/wiki/Pumping_lemma_for_context-free_languages#/media/File:Pumping_lemma_for_context-free_languages.svg). * Can we always find a sufficiently long path, though? Well, considering that this is an explanation of the pumping lemma, the answer is definitely yes. Suppose that your language has `n` non-terminals and the longest rule in the language has a length `k`. This means that the branching factor of your AST will be at most `k`. * If you pick a string whose length is at least `k^(n+1)`, then the AST's height should be at least `n+1`. This means that you can pick a path from the root to a terminal that will contain at least `n+2` nodes (Reminder: a tree with height of 2 has a path that contains 3 nodes, a tree with a height of 10 has a path that contains 11 nodes, etc). * Out of these `n+2` nodes, you'll have one leaf node (which is a terminal), thus leaving you with `n+1` nodes. But because of the pigeonhole principle, since you have `n` terminal symbols and `n+1` nodes, two nodes will correspond to the same non-terminal, which is exactly what we want.
Are you on a quadcore? PS you randomly switch to tabs sometimes
Obviously the best kind of cake is the kind that looks like a rabbit. http://i.imgur.com/WfJFFbS.jpg
I solved this exact problem [like this](https://bitbucket.org/minno/advent-of-code/src/206eee23bbd9588dfebd6877881d476055123166/src/main.rs?at=master&amp;fileviewer=file-view-default). You could also make a `BTreeMap&lt;u32, fn() -&gt; ()&gt;` that stores the solution functions, or a macro that expands into the sort of thing that I wrote. AFAIK there's no way to call a function by name in Rust, since function names don't really stick around after compilation.
That is exactly what I was trying to avoid. I guess it's time to learn how to make macros.
It's specifically that Haskell boxes things by default and Rust doesn't. You will hit the same issue in Haskell if you specifically mark the field as non-boxed.
Party time! https://www.youtube.com/watch?v=T1zxRWDb4V4
𝕃𝕖𝕥'𝕤 𝕡𝕒𝕣𝕥𝕪
He's getting down voted because he's being toxic and passive aggressive. If he has a valid point to make he can do so in a reasonable and civilized manner. Posts like this lower the level of discourse and thus detract from the conversation rather than add to it (not to mention the hostility distracts from what may be a perfectly valid point).
&gt; That is a separate set of semantics and need to be a separate type I agree. `Wrapping&lt;T&gt;` is an okay prototype, but it still *feels* like a prototype and not an integral part of the language. let mut ck_sum: Wrapping&lt;u16&gt; = Wrapping(0); .... ck_sum *= Wrapping(577); That's unpleasantly verbose compared to this: use std::num::modular::*; ... let mut ck_sum: m16 = 0; .... ck_sum *= 577; (edit: and a type alias doesn't help; [I tried](https://is.gd/SPljG3)). C-like "unsigned" ints can mean two different things: natural numbers or modular. Depending on a programmer's background, either expectation could be reasonable. Common sense or experience with a business-oriented language like Java says "natural." Experience with C and similar says "modular." Since different programmers have different expectations it's not possible to satisfy Least Surprise for everyone. But we can get close by giving the business-logic folks natural numbers `u` and if anyone is looking for modular, `m`.
I'm just wondering if the presentations are meant to be like meetup presentations or journal paper presentations? I like that its community focused, but getting money for attending has to be justified in academia. :) 
I decided to port a toy language interpreter I'm working on to Rust and it's been great so far
Yes, a clearer way to express it is that Rust has unboxed types by default, whereas Haskell types are boxed by default. Rust doesn't allow a recursive type definition that only consists of unboxed types, but if you break the recursive cycle with some kind of box (Box/Vec/Arc/etc) then it's fine. This is OK: struct A(B); struct B(C); struct C(Box&lt;A&gt;); This is not: struct A(B); struct B(C); struct C(A); 
There are some subtlties around creating `Rc&lt;...&gt;`s out of other allocated types, because the reference counts have to be stored somewhere, which (most) other types won't leave space for by default. Specifically, `Rc&lt;T&gt;` is a pointer to a struct like: struct RcInternals&lt;T&gt; { strong: usize, weak: usize, data: T, } While `Box&lt;T&gt;` is a pointer to a `T` directly, and `Vec&lt;T&gt;` is a pointer to a sequence of `T`. In either case, converting to an `Rc&lt;T&gt;` (or `Rc&lt;[T]&gt;`) would require reallocating, or, at least, copying data, to make space for those two `usize` reference counts.
To me this points to the need for new data structures. Dbl linked lists are easy but have poor cache coherency. I can think of a few list alternatives that should be easier to impl in rust and have better memory layout. Oh implementing a dbl linked list is nigh impossible in Haskell as well. 
I think you want /r/playrust
CAKE MEMES WILL BE TOLERATED
The cake is a lie...
Big, big topic. I'm going to get at least one thing wrong here, so please don't hesitate to point it out. (For the record, I'm pretty new to Rust, but I have substantial knowledge of Haskell.) **Type inference** Haskell is designed to allow inferring types anywhere as the general rule, but with exceptions where types cannot be inferred. Rust requires types to be declared for all arguments and results of functions, and some declarations. Rust's requirements resemble Haskell practice—Haskell programmers routinely do declare types for their top-level definitions even if the compiler could infer them, because they help document the program. **Product and sum types** Or, as Rust people would call them, structs and enums. These work basically the same in both systems. **Lifted vs. unlifted types** A.k.a. strict vs. non-strict, eager vs. lazy, `data` vs. `newtype` (in the Haskell sense of the term). In Rust all types are "unlifted"—meaning that if `&lt;expr&gt;` is a computation that diverges (never returns), then neither does `Some(&lt;expr&gt;)` nor anything of the sort. Haskell famously has *lazy evaluation*, which means that if you have `Just &lt;expr&gt;` you can tell that it's headed by `Just` even if `&lt;expr&gt;` diverges. But it has means of turning this off—the `newtype` data type declaration is the major one. **Function types** Haskell's got function types of the form `a -&gt; b`. As I understand it, Rust doesn't really have first-class function types, but rather, `Fn`-family traits that "callable" objects implement. As I understand it: * If you want to return a function or closure from a function you have to return a trait object; * If you want to accept a function or closure as argument, the function that takes the argument gets implicitly specialized to a one-off anonymous type for the functions that are passed in. (If there's any place where I got anything wrong here this might be it!) **Recursive types** As other comments have pointed out, type recursion works differently between the two languages. Haskell generally allows types to have members of the same type, Rust forbids it. But Rust allows *indirect* type recursion through some specific type constructors (e.g., `Box`), while Haskell has some subcases where recursion is forbidden (`UNPACK` pragmas). So this is more of a practical than a theoretical difference—but it's a huge practical difference. **Affine types** This is the rule that a variable can be used at most one time. Rust's got this as the killer feature of its type system. Haskell doesn't have this at all. Example: I was just recently reading [this paper about splittable random number generators](http://publications.lib.chalmers.se/records/fulltext/183348/local_183348.pdf), which documents the design of the [`tf-random` library in Haskell](https://hackage.haskell.org/package/tf-random-0.5/docs/System-Random-TF-Gen.html). They spec out, using Haskell notation, an abstract API like this: split :: Rand -&gt; (Rand, Rand) rand :: Rand -&gt; Word32 ...with the additional stipulation that: &gt; Similar to the original API, an additional requirement is placed on the program that it is not allowed to call both `split` and `rand `on a given generator state, since the parent generator state is not guaranteed to be independent from generator states derived from it. In Rust you can use affine types/move semantics to enforce this at compilation time: pub trait SplittableRng { // These require `self` to be moved in, so can't reuse same state! fn split(self) -&gt; (Self, Self); fn rand(self) -&gt; u32; } **Reference types and lifetimes** If `T` is a Rust type, then so are `&amp;T`, `&amp;mut T`, `&amp;'a T`, `&amp;'a mut T` and so on. This is a big centerpiece of Rust's type system, but I suspect it's more of a huge practical difference than an actual theoretical one; `&amp;` strikes me as a plain old generic type with special syntax (like `[]` is in Haskell). I haven't really figured out Rust lifetimes yet, but they're treated as type variables, so I wonder if they're similar to [Haskell's `ST` monad's `s` type parameter](http://stackoverflow.com/questions/12468622/how-does-the-st-monad-work), that's used to guarantee that mutable state doesn't escape from the scope it's allowed to affect. **Type classes vs traits** Fundamentally similar. No surprise, since Haskell was the inspiration for Rust here. **Higher kinded types** You can't write Haskell's `Functor` class as a trait in Rust: class Functor f where fmap :: (a -&gt; b) -&gt; f a -&gt; f b The key thing here is the `f` type variable, which gets instantiated with types like `[]` ("list"), `Vector` ("array"), `Map k` ("maps with keys of type `k`"), `ParsecT e s m` ("parsers that fail with errors of type `e`, consume inputs of type `s`, and perform side effects of type `m`") and so on. The `Functor` class implements a trait (in Rust-speak) that can be implemented by most types that provide a `map` operation. Rust doesn't currently have the ability to abstract this into a single trait. Beyond this GHC has a system of kind polymorphism that I don't really understand. And the concept of promoting data types to kinds, which I do kind of understand but can't explain. **Constraint kinds** This is a GHC extension that allows type classes ("traits") to be treated as types. Since Haskell has higher-kinded types, this means that you get the ability to use type classes as type parameters. (In Rust terms: traits as type parameters, e.g., `MyType&lt;Iterator, String&gt;`, where `Iterator` is a trait.) **Multi-parameter traits, functional dependencies and associated types** Rust doesn't have GHC's multi-parameter type classes and functional dependencies, but it did take a version of the newer associated types feature. Whether the former is a lack I won't tell, but associated types *might* be an improvement over multiparam classes and functional dependencies. **Existential types** Rust doesn't have general purpose existential types, whereas GHC does. Rust has trait objects, which can be seen as a specialized form of existential types. What are existential types? Well, one rule in Rust is that if you have a type declaration like this: struct Whatever&lt;A&gt; { foo: A, bar: B, to_string: Box&lt;Fn(B) -&gt; String&gt; } ...then, unless `B` is a type in scope of the definition, this is an error—what the heck is `B`? In Haskell this is an error as well: data Whatever a = Whatever { foo :: a, bar:: b, consumer: (b -&gt; String) } ...but this one isn't: {-# LANGUAGE ExistentialTypes #-} data Whatever a = forall b. Whatever { foo :: a, bar:: b, consumer: (b -&gt; String) } In this case, values of type `Whatever a` (`Whatever&lt;A&gt;` in Rust) have members with types that mention `b`, but `b` is not a type parameter of `Whatever`—meaning that: 1. External consumers can never know what type `b` is; 2. In fact, different values of type `Whatever a` may have different internal choices for `b`; 3. But external consumers *can* tell that, within any one `Whatever a` value, the `b` in `bar` and the one in `b -&gt;String` are the same, so you can call the latter with the former. **Generalized Algebraic Data Types ("GADTs")** In Haskell you can have types like this (think of it as a recursive enum for a simple language): {-# LANGUAGE GADTs #-} data Expr a where BoolLit :: Bool -&gt; Expr Bool Not :: Expr Bool -&gt; Expr Bool And :: Expr Bool -&gt; Expr Bool -&gt; Expr Bool IfThenElse :: Expr Bool -&gt; Expr a -&gt; Expr a -&gt;Expr a IntLit :: Int -&gt; Expr Int Plus :: Expr Int -&gt; Expr Int -&gt; Expr Int Times :: Expr Int -&gt; Expr Int -&gt; Expr Int `Expr` is a generic type with parameter `a`, but `BoolLit` is a data constructor (Rust: enum variant) that can only take a `Bool` argument, **which forces the `a` parameter to `Bool` as well**. You can't do this in Rust: enum Expr&lt;A&gt; { BoolLit(bool), Not(Expr&lt;A&gt;), And(Expr&lt;A&gt;, Expr&lt;A&gt;), IfThenElse(Expr&lt;bool&gt;, Expr&lt;A&gt;, Expr&lt;A&gt;), IntLit(isize), Times(Expr&lt;isize&gt;, Expr&lt;isize&gt;) } This might not even compile, but even if it did, the problem is: the type of `BoolLit(false)` isn't `Expr&lt;bool&gt;`, it's `Expr&lt;A&gt;` for some unspecified `A`. GADTs imply existential types; the `Whatever` type from above can be written this way too: data Whatever a where -- The type variable `b` is not a type parameter of -- the `Whatever` type; this makes it an existential -- type. Whatever :: a -&gt; b -&gt; (b -&gt; String) -&gt; Whatever a **Higher-rank polymorphism** This has a similar name to higher-**kinded** polymorphism, but it's not the same thing. I refer you to [this popular Stack Overflow answer](http://stackoverflow.com/questions/12031878/what-is-the-purpose-of-rank2types). GHC's got it, Rust doesn't. This is a feature that's hard to grasp at first what it's for, because it's not really "for" any one specific thing. But once you've grown used to it you resent all those languages that don't have it. (Same for GADTs and higher-kinded polymorphism. Or generics; newcomers often think that generics are "for" collections, but there's just no end of good things that generics are good for.) **Dependent types** Neither language really has these. There's a lot of work in GHC toward getting a version of this features. Funnily, Rust does have *one* tiny spot where, strictly speaking, it's dependently typed: array types are parametrized by their size: `[u32; 16]` vs. `[u32; 32]`. Also, there's some compile-time computation of the dependent indexes; source programs can have type expressions like `[u32; 32 - 1 - 1 -1]` that will be solved at compile time to the same type as `[u32; 29]` (I've seen this in `rand` crate macros).
Integers in rust do not function as modular arithmetic, since it is valid for an implementation to always panic (per RFCs/reference, which as close to a spec as there is), and it is explicitly an error to overflow them. Further, they aren't even used as modular arithmetic in practice since they panic in debug builds with the normal compiler and settings. What you might argue is that we should call them finite integers. Which you will notice we *do* by specifying the size in the type name!
https://cdn.meme.am/instances/57619358.jpg
&gt; I wasn't able to get the compiler to allow me to omit the lifetime for the mutable reference as you specified. I thought the omitted lifetimes would get elided. Guess not, since there is another equality assertion between argument and output lifetimes which should be explicit.
He's being downvoted because he's violating the second rule in the sidebar: &gt; Criticism is encouraged, but ensure that your criticism is constructive and actionable. Throwaway comments are just noise. The comment in question is pretty much exactly what that rule is talking about. I have responded in a level-headed manner to hotheaded comments many times. Most of the time, it just results in the hothead getting increasingly more angry and frustrated, and eventually I have to stop because it's clear that it can't go anywhere constructive. There are a few people who can respond well to even-handed responses, but the vast majority are just a waste of time.
There is an RFC-issue for adding optional arguments and keyword arguments. I personally like the idea, but other posters don't https://github.com/rust-lang/rfcs/issues/323 BTW: Would it be possible to have a compilerplugin for creating macros that behave as functions with keyword arguments? I don't know much about compiler plugins, but the following would be cool. #[derive_keyword_argument_macro("foo",y=42)] fn _foo(x:u32, y:u32) -&gt; u32 { x+y } assert_eq!(foo!(5, 7), 12) assert_eq!(foo!(5), 49) assert_eq!(foo!(5, y=7), 12) 
Is there a public repository?
Is the compiled book available somewhere? (perhaps Github pages?)
https://intermezzos.github.io/book/
&gt; Rust doesn't have GHC's multi-parameter type classes I'd say that it does have them. trait Whatever&lt;X, Y&gt; { type P type Q } This trait has `Self`, `X` and `Y` as input type parameters and `P`, `Q` as output type parameters. This is roughly equivalent to class Whatever s x y where type P type Q from Haskell.
I love the idea and execution of your IntermezzOS book, Steve. I'm planning on following along on my Raspberry Pi!
&gt; Funnily, Rust does have one tiny spot where, strictly speaking, it's dependently typed: array types are parametrized by their size: I think that's just a limited form of type-level integers. With dependent types, one would be able to write a function that receives an integer, and build an array whose size is this integer (that is, the type of this array depends on the value the function receives). This could be a problem in Rust because arrays goes to the stack so Rust needs to know its size at compile time.
**Function types &amp; Recursive Types** This boils down to "Haskell always boxes everything" and Rust doesn't. You can accept/return a raw function pointer with the `fn` type, but this will exclude closures. This is an instance of Rust actually being more expressive than Haskell (at the cost of ergonomics). **Higher Kinded Types** You can encode fmap, but it's going through more hoops than you want. Rust doesn't let you talk about generics types with unapplied parameters, so you need to make a type to stand as proxy for that, and use traits to express the higher-kinded relationship. I describe how to do this [in this post](http://cglab.ca/~abeinges/blah/rust-reuse-and-recycle/#higher-kinded-types). [Here's fmap](https://play.rust-lang.org/?gist=9825ba4aa0110ea4a2dfa26205de2544&amp;version=stable&amp;backtrace=0) **Existential Types** Your example can be encoded with closures or trait objects, but you are correct that Rust doesn't let you decouple existentials at *quite* that granularity. It's not clear to me that it's actually useful to do so. **Higher-rank polymorphism** [Rust does have higher-rank trait bounds](https://doc.rust-lang.org/nomicon/hrtb.html), but they're currently only allowed for lifetimes. **Dependent Types** God help us all
Actually, Rust *could* conceivably have at most one array per stack whose size isn't fixed at construction as long as said array never leaves the stack frame. I have wondered whether this could be used to speed up some operations, but alas the compiler won't have any of it.
This is supported in newly pushed 0.5.0 You can use --doc-branch option to customize the branch for doc.
I reckon you could actually do that as a macro, but yeah it's definitely possible as a plugin.
What kinda bass ackwards notation is that? We have notation&lt;sup&gt;for that&lt;/sup&gt;
[If you're in Boston](http://www.meetup.com/BostonRust/events/230419544/) on May 25th /u/steveklabnik1 will be giving a talk about intermezzOS. I know I'm excited for it.
Wow, I never knew that cargo could run examples. I'll have to remember that in case I ever publish a crate. As for my problem. I was spending [way too much time](https://xkcd.com/1319/) on it, so I just went with [big ugly match](https://github.com/giodamelio/projectEuler/blob/master/rust/src/main.rs#L40).
/r/playrust
Ya, I looked into macros! They seem really powerful (I have never worked with them before), but I don't think my problem could be solved with them. I guess I could write a compiler extension, but that [seems like overkill](https://xkcd.com/1205/).
Yes, Intel i7 (hyperthreading) to be precise. You mean in code? I always use tabs if I'm not mistaken.
What sup?
Pretty soon you guys will need to use an u32.
Thanks! Aren't those ARM, though?
Ah! I forgot to link this in the github repo!
I'm continuing to work on my simple crate [progressive](https://github.com/palango/progressive), which shows progress information for loops/iterators without hazzle, (inspired by [tqdm](https://github.com/tqdm/tqdm)).
You can also have multiple binaries, no need to abuse the examples for this ;) I have heard that all the files in `src/bin` are treated as executables. I have always added a couple of lines to my `Cargo.toml` to make it work: [[bin]] name = "10" path = "src/bin/10.rs" [[bin]] name = "11" path = "src/bin/11.rs"
Not much man, you?
like^so^(`like^so`)
Thanks for the cargo-profiler shoutout! 
Woah, someone other than me uses flame! I might have to go back and write a proper visualizer now! Let me know if you want any features for use in flamer.
Artificial examples are fine, they better show the essence of a problem. And this particular example is just a reduction of a real-world example I've hit in my code. So far I have not seen reasons to not have a do-while in Rust.
Is there a way to globally tell Cargo to include certain Library Search Paths when compiling? This is especially bad on Windows with MSYS2, where it often forgets to tell gcc where to look for libraries. This is pretty annoying and I often have to copy my libraries from /usr/lib to the target folder, just because the gcc call doesn't have -L "/usr/lib" for whatever reason. Setting LD_LIBRARY_PATH also doesn't do anything.
&gt; Is there any situation where you actually want to do this and not add Clone to Impl? No, I don't think so. I just wanted to show that "a type that cannot be cloned" is not quite correct, so a lint wouldn't be useful.
I don't have the time to look into it closely right now, but remember that one function's generic `T` is potentially different from another function's generic `T`. It is possible that how you're using `connected_nodes` lets the type inference assume that `explore_from`s return value is a `HashSet&lt;&amp;T&gt;` (with reducer's `T`), so its input must be a `Graph&lt;&amp;T&gt;`. I think it will help a lot to use temporary type annotations on the `let` to restrict the inferencer, for example let connected_nodes: HashSet&lt;T&gt; = ... and then see where the root of the type mismatch is.
Slow Develoupment
It is! Diesel is maintained by Sean Griffin, who is also the maintainer of Rails' ActiveRecord ORM. You're right that that connection might be a little oblique though...
Functions that return structures. In C, this does a needless copy. struct foo { /*...*/ }; struct foo f() { struct foo temp = { /*...*/ }; return temp; } Maybe some compilers optimize out the copy, I don't know (and wouldn't count on it). So does this Rust code copy the struct? struct Foo { /*...*/ } fn f() -&gt; Foo { Foo { /*...*/ } } What about this? fn g() -&gt; Foo { Foo::new() // assume typical definition } I had been assuming that the last one is less efficient, but maybe I'm jumping to a conclusion. Similarly, what happens when a struct is passed into a function by value? Is a copy made? I am starting to think that a big part of my confusion about Rust is that in C, `&amp;` means pass a pointer, not a copy, but in Rust it doesn't. Edit: formatting
Well, congratulations. May it have a long and fruitful life.
I think it's the same thing [/u/llogiq commented on almost two weeks ago](https://www.reddit.com/r/rust/comments/4i0str/cargo_predictable_dependency_management/d2u5lc8?context=3). I've run into the "can't run cargo without internet" issue myself once, though I don't do much offline programming so it barely affects me. If it's not an actual bug I think the recurrence of this theme might indicate there is surprising default behavior and/or there is a need for a clear "here's how you run cargo offline" document.
Well, it could actually be better in the sense that it exchanges a number of known security weaknesses against an unknown number of possible security weaknesses.
Where in that code is the work done? It's impossible to translate that into Rust because in Rust this is all semantically dead code. Is each `cond` a function call?
Congrats :D
Congratulations to us all – it's been a great year. Also @aturon thanks for the TWiR shoutout. And the year isn't even half through, yet there are so many awesome changes prepared around Rust that I have very high hopes for Rust's second year since 1.0. Also cake.
Dyon looks great! Are the docs hosted anywhere?
I get that. But that was never explained in anything I read. The first time I heard about `cargo fetch` wasn't from `docs.crates.io`, it was in that previous thread. In my quick search I couldn't find the command listed in the guide or the FAQ, not even in `cargo help` or `man cargo`. It's only in `cargo --list` and doesn't have a description there. You'd have to do that and then `cargo help fetch` after inferring the command might be the one you're after. The fact that I've seen it come up multiple times and that llogiq, who is far more active with Rust than I, also was unaware indicates to me that discoverability/documentation might be improved. Mentioning `fetch` _somewhere_ would be useful. For example, I can imagine listing each of the steps that `build` does in the guide and including the separate cargo commands that can accomplish each portion. Or perhaps something like, "`cargo build` can be thought of as `cargo fetch` followed by `cargo rustc`. The `fetch` must be online the first time it's called but `rustc` can be offline, so you can use `fetch` to prepare for a future offline build."
Well, `fetch` isn't special: a `cargo build` should do it as part of its process, that's why I mentioned "equivalent". I could have been more clear about that, though. And totally, that could be put in the docs. Maybe open up a bug on Cargo about this?
Not yet. Been very busy working on the language.
Rust has done a truly phenomenal job at being a new language. I can remember when it was first announced, the demo of rust looked like linefeed noise (anyone remember the @'s?) It has become incredibly ergonomic. I think rust took the right amount of time to stabilize, the long beta/alpha period was well worth it. I also love just about every decision make about the language and ecosystem. Small standard library. Sanctioned build system/dependency management. Unstable features for evolution. Continuous language feature deployment. Using cargo to check for breaking language changes. Really, just fantastic. I can't think of any other way to start a language. Here is to hoping that someday I can get rust at work.
The one true name for this is `Spliterator`. On a serious note, I love how much experimentation/development is happening for parallel libraries like this.
It actually is possible to write your GADT example in Rust: https://is.gd/ucNkoX However, without HKTs or polymorphic recursion, GADTs aren't that useful.
This is an amazing post! Most of the nits have been picked in sibling comments, but I'd also add that Rust does have function types (written `fn(T) -&gt; U`), but they are rarely used because lambdas each have a unique anonymous type. All functions declared with `fn` have a type like this though. Other interesting features of Rust's type system that you didn't mention: * Lifetimes are of a separate kind from types. This doesn't have implications really but its interesting that the language has two base kinds. * Rust makes a stronger coherence guarantee than Haskell, being AFAIK the only language with type classes that attempts to guarantee that any dependency graph made up of valid nodes will not have coherence errors.
Feel free to borrow some ideas from Dyon!
Hm...I am seriously considering a rename now. How did I not think of that? `IntoSplitter`, `Spliterator`, `Split`... would people prefer that? &gt; I love how much experimentation/development is happening for parallel libraries like this When you're using work-stealing parallelism, it's usually optimal to submit jobs which recursively split themselves until they are small enough to process. The problem is that those kinds of jobs take a lot of boilerplate to write, so users won't want to use the thread pool that way. `SplitIterator` and rayon's `ParallelIterator` are designed to let the user feel like they're writing code which operates over data linearly, but is actually recursively splitting the data under the hood. It's fair to say that parallel iteration is the natural conclusion of using thread pools in Rust. So the principle of the two parallel iterators is the same, but the implementations themselves are quite different -- I intentionally did not look at rayon's source while implementing `SplitIterator`, so I could come up with it all on my own. In practice, I have found that they both perform about equally fast as each other and as writing out the job splitting by hand. It's fantastic that LLVM's optimizer is powerful enough to let abstractions like this have practically no overhead. Edit: I'll leave this here...https://github.com/rphmeier/jobsteal/pull/19 
I can't think of any downsides to Spliterator. It conveys the same meaning and is 2 characters less to type.
appreciate it lol. I was in game so had to post in a hurry 
In honor of Rust's birthday I am starting a blog series on creating webservices in Rust. I know webservices are not the main focus of Rust, but I think this is a great way to get web developers introduced to thee language. Introducing web developers to the language using concepts they are already familiar with allows them to get value out of Rust faster. After a web developer is comfortable with Rust, then they can dive deeper into systems stuff. The cognitive load will be a lot less. Enjoy!
Looks great!
This is awesome! I've been wanting to try out a simple gtk GUI like this in Rust. I'm going to dig into the code and see just how you did this :D
Oh, thank you for letting me know. I will update in a bit.
I think `match &amp;input` should work. Otherwise try `match &amp;*input`.
The following should work: [playground link](https://is.gd/WtV0ST). Your main problem is trying to match a `String` to a `str` which are two different types of things in Rust. The `input.as_str()` makes a string slice of your String to match against the static string `"test"`. You could also use `&amp;*input` due to Rust's dereferencing rules but I think `input.as_str()` is clearer to the reader.
Check out the chapter in The Rust Book on Strings if you want to know *why* there are two different types for strings: https://doc.rust-lang.org/book/strings.html
https://play.rust-lang.org/?gist=82ebfa1c923f04872014aaf8926390d1&amp;version=nightly&amp;backtrace=0
Thanks for adding that, I should have linked that in my original comment.
Why not Rustoberfest? :D I'm totally going to try to come though. I'm glad there is a relatively active Rust community in Germany. Though sadly nowhere near where I live.
That's true, although jobsteal is still at the pre-1.0 phase. Technically, I'm pretty sure pre-1.0 in semver means "anything goes", but I try to keep things stable on minor versions. So I will probably just bump the minor version (to 0.5.0) to alleviate any backwards-compatibility issues. I think that's how semver works, at least. Also I don't know if #[deprecated] has been stabilized for user code yet. I know /u/llogiq's RFC was approved but I haven't kept close track.
I've been thinking about switching it to MIT, but to be honest the license doesn't matter too much to me. I'm probably going to be the only developer. As for the release, I'm sorry that I haven't been making releases, but if you need them I'll make a new release soon.
I'm trying to package it for Nix which actually has a `fetchFromGithub` function. But it's hard to know which commits are meant to be stable releases. When I release something, I usually make a "release commit" that just bumps version numbers.
Will these talks be recorded?
Hang on then. I'll publish a new release shortly.
&gt; Technically, I'm pretty sure pre-1.0 in semver means "anything goes", As you say, this is technically true, but Rust decided it was suboptimal: why bother with two digits in `0.x.y` if `x` and `y` mean the same thing ("possibly breaking change")? Thus, cargo treats pre-1.0 versions as if they were `0.major.minor` (i.e. having same meaning as `major.minor.patch` post-1.0), as it allows library authors to update their code without users running the guantlet of "does `0.1.2` &amp;rarr; `0.1.3` have breaking changes?".
You need to use "as_ref()" match input.as_ref(){ "test" =&gt; println!("That was test"), _ =&gt;{} }
&gt; Why not Rustoberfest? :D Berlin is in Prussia, we certainly don't bend to the Bavarians :) &gt; I'm totally going to try to come though. I'm glad there is a relatively active Rust community in Germany. Though sadly nowhere near where I live. "relatively" is downplaying it and the European community is great in general :). Looking forward to meet you.
Lol. Next in press: Oracle vs Jobsteal ;)
There is no reason to choose "0.8.*" as a version number, because it is effectively the same as "0.8.0", which is the same as "\^0.8.0". I suggest reading up on crate version numbers on http://doc.crates.io/crates-io.html#using-cratesio-based-crates It usually is best to just use the version suggested by crates.io, as it always allows for non-breaking updates, and specifies the correct minimum version you also used to develop your project. Apart from that, seems to be a nice article! :)
Out of curiosity because I am looking into this sort of things too, how does this crate compare to rayon in terms of the approach? At first glance both crates seem to be based on a Chase-Lev work stealing queue with a divide-an-conquer approach to spread jobs efficiently across workers. Has anyone experimented with other approaches to do multi-threaded job scheduling in rust?
&gt; How? How to party you ask? This is how you party https://youtu.be/tkZMs0Qbljw?t=10s
&gt; but I think input.as_str() is clearer to the reader. I think it's idiomatic to write it as `&amp;input`, even if it's more complex due to the interaction between different rules.
Any plans to add macros? I think it'll combo very well with horrorshow-rs: https://github.com/Stebalien/horrorshow-rs 
when close systemd-manager on my box ,i got errors: thread '&lt;main&gt;' panicked at 'called `Option::unwrap()` on a `None` value', ../src/libcore/option.rs:330 note: Run with `RUST_BACKTRACE=1` for a backtrace
That's right, `&amp;input` works [only when calling a function](https://is.gd/buWK8v). Now that's annoying.
This website has no link to where the actual documentation is hosted. How do i actually **view** the documentation? wtf.
I'm finishing up my [apply_attr](https://crates.io/crates/apply_attr) crate that provides higher-order attributes via syntax extension. The crate allows for this to compile: #![feature(plugin)] #![plugin(apply_attr)] #![apply_attr_enums(derive(PartialEq))] #![apply_attr_structs(derive(PartialEq))] struct Foo; struct Bar; enum Baz { Blee } fn main() { Foo == Foo; Bar == Bar; Baz::Blee == Baz::Blee; } I initially began working on this the day before yesterday for the sake of being able to effordlessly marking all functions within a `mod`/`impl`/`trait` as `#[inline(never)]` when profiling crates with /u/pegasos1's [cargo-profiler](https://github.com/pegasos1/cargo-profiler) and ended up realizing that a general solution would be of much wider use.
That is actually very interesting :D ! I still don't know where the project is headed, so I can't be sure whether there will be any macro support or not. For the time being, its still all with methods but I can see the ease with macros.
Just do what I've been doing at work: use Rust for one-off scripts and utilities. Instead of reaching for python or another scripting language, I've been using Rust. To date I've written a dataset-generating simulator, a parser/converter, load generator and a simple ETL tool. A few I've even shared with colleagues. My plan is to keep spreading the little tools around and infect from within :)
I hope by that time we'll have figured out more powerful compile time guarantees than even Rust provides.
thanks, IMO that link should be on the page linked in this post, people familiar with rust might know about it, but noobs (like me) haven't got a clue.
You can open a PR on GitHub ([link to repository](https://github.com/guillaumegomez/this-week-in-rust-docs)) if you want. However, I think the goal of this blog is to *tell about progress* in the docs, instead of *presenting* the docs in a beginner friendly way. Therefore I am not sure if such a PR would be accepted, but you can of course try. By the way, if you are learning Rust, you will probably find the [Documentation](https://www.rust-lang.org/documentation.html) section of the website useful.
Well, why not...
The box syntax is coming (it's available in nightly since a looooong time)! ``` box T; ```
I believe that it's the latter.
Hence the adjective "legacy" :-)
[Here](https://is.gd/S3p1nD) is one possible fix: impl&lt;S&gt; B for Multi&lt;usize, S&gt; where Multi&lt;usize, S&gt;: A { fn bar(&amp;self) -&gt; usize { self.r } } 
If you read the README, it produces a `.deb` automatically and installs it.
Good write-up. I'm keen to tackle some new projects at work using rust. A small isolated webservice would be a good starting point here. Unfortunately my company uses a *single-giant-legacy-oracledb-as-the-heart-of-everything* approach. So the communication with the oracle database is the biggest blocker for me at the moment. I've already tried [this](https://github.com/obivan/rustoci) but didn't succeed due to some strange authentification errors, also looks like it's abandoned. Are there any oracle related crates or other efforts I'm not aware of? 
Certainly. I think java gets somewhat of an unfair bad wrap. The language isn't perfect, but the ecosystem is second to none.
Adding `Copy` to the constraint in line 1 makes it compile. I guess your question is "why?" Pretty sure this is because `T: Trait` is not necessarily copy-safe. Thus `NewT&lt;T&gt;` might not be copy-safe. 
I'm starting my summer-long project to add an OpenCL support pathway for Rust. 
Note the definition: `struct NewT&lt;T: Trait&gt;(pub T::Type)`. I don't instantiate a type that implements `Trait` only the associated type `Trait::Type` which does have a `Copy` bound.
It seems that `gtk::main_quit()` in `window.connect_delete_event()` is causing the panic when the close button is pressed, but `gtk::main_quit()` in `window.connect_key_press_event()` when the Escape key is pressed does not cause a panic. I'm not sure as to why that would be.
You could take a look at how [`aster`](https://github.com/serde-rs/aster), or even my own unfinished [`js_builder`](https://github.com/Ogeon/js_builder), works if you want to take the builder pattern to an unholy extreme. It's perhaps not really necessary in your case, since CSS is less complex than Rust or JavaScript, but it may serve as an inspiration for a structure (for better or for worse ;) ).
Very nice, Andre! It's the week of Rust profiling and syntax extensions, apparently. cargo-profiler, flamer, apply_attr (WIP), … I like where this is going. 
Probably a smaller project, but I find nature-inspired algorithms quite interesting, especially evolutionary and swarm algorithms. See [1] for a good overview and introduction. [1] http://cleveralgorithms.com/nature-inspired/index.html
Interesting. The front-end generates its own unrolled vectorized store; it doesn't use `llvm.memset`. Given a local variable it generates alloca and a memcpy (using `llvm.memcpy` this time). It also feels free to align the alloca to 16, optimizing its custom memset... but preventing copy elision. Oops. (edit: it looks like LLVM might not have a memset for fill patterns larger than one byte, so that explains why it's not being used.) 
You misunderstood: that's what i said about JS, ant that's why it's “ASI” is bad. And about your rust example: why not only add semicolons to make things evaluate to unit? And ignore evaluation types of e.g. branches of an if statement (as opposed to an if expression)
Sorry, I just wanted a nice project to learn how to write procedural macros and since I had an open issue + PR at your repo for some time, I figured it would be OK to act myself. :-) Btw. I very much like flame's idea. If I can help out, just give me a shout-out.
Deref coercion sadly doesn't work with match statements.
Yes, I suspected as much, but I was on my phone so I couldn't check, and the question had gone unanswered for like 2 hours, so I figured I'd apply the "perfect is the enemy of good" principle and just post what I thought might help :-)
REALLY new to Rust (started poking it last night). I've generally got the concept of `Result&lt;R,E&gt;` &amp; Pattern Matching for returning results w/ error handling. However I'm struggling with a scenario like this: fn my_func(/* args */) -&gt; Result&lt;i32, &amp;'static str&gt; { if /* some failure condition */ { return Err("This is a string literal, stored in the data section of the binary and thus is referenced with the 'static lifetime") } // ... } This makes sense if my error messages are all static string literals and owned by the global scope. But if I need to return some literals, and some formatted error messages like this: fn my_func(/* args */) -&gt; Result&lt;i32, ??&gt; { if /* condition 1 */ { return Err("Some Literal Error Message"); } if /* condition 2 */ { return Err(format!("The value {} is too large.", value)); } // ... } I run into problems. The 2nd condition's error message is no longer owned at the `'static` scope, so I cannot use `&amp;'static str` I'd like to have a str passed back and ownership transferred to the calling scope. Or am I missing something here? I'd like to not have to pass `String` back as I'd be allocating a lot of useless `String` objects when dealing with static strings. Sorry again as I'm **very** new to rust and have spent a long time away from lower level languages like c/c++.
You're looking for `Error&lt;T, std::borrow::Cow&lt;'static, str&gt;&gt;`. `Cow` is a smart pointer that can hold both an owned instance and a borrowed value of the given lifetime (here `'static`). If you like, you can read more [here](https://llogiq.github.io/2015/07/09/cow.html).
The test I see at least seem much more like integration tests than unit tests - they all test the ETD result of using the library on different inputs. Could you clarify why you would want these ta be in lib.rs rather than tests/?
True, that could work.
If the function is typed as returning unit, why would you need to explicitly insert the `()` return. Wouldn't it be reasonable for the compiler to just ignore the result of `read` in your example?
It's not really that Rust is not smart, its just that you don't really seem to understand generic programming. In generic programming the goal is to be has generic has you can until you need to be more specific later. *Even now iv been too specific,* i could of just done `NewT&lt;T&gt;(pub T)` and it would of worked. So in other words your assumption is not wrong, `impl&lt;T: Copy&gt; Copy for NewT&lt;T&gt; { }` is exactly what the compiler does. It's just that its not going to use that implementation unless your `T` is actually `Copy`. It's going to use it later if you actually end up using this implementation. ----------- Let's say you had a card game, your need to order your cards by rank, you could make your self a type has generic has this: enum Rank&lt;T&gt; { Ace, Number(T), Jack, Queen, King, } You do not need to be any more specific, because it doesn't have any functionality yet, its an enum and it does nothing. Then you can go ahead and implement/derive what ever you need, being a tiny more specific in areas that need to, like implementing ord/eq: use std::cmp::Ordering; #[derive(PartialEq, Eq, Ord)] enum Rank&lt;T&gt; { /* ... */ } impl&lt;T: Ord&gt; PartialOrd for Rank&lt;T&gt; { fn partial_cmp(&amp;self, other: &amp;Self) -&gt; Option&lt;Ordering&gt; { use self::Rank::*; use std::cmp::Ordering::*; match (self, other) { (&amp;Ace, &amp;Ace) =&gt; Some(Equal), (&amp;Ace, &amp;Number(_)) =&gt; Some(Less), (&amp;Number(_), &amp;Ace) =&gt; Some(Greater), (&amp;Number(ref a), &amp;Number(ref b)) =&gt; a.partial_cmp(&amp;b), // ....... _ =&gt; unimplemented!(), } } } Then once you finished that, you can still create other types without telling everyone that `T` is going to be implementing `Ord` (unless you want to actually use `Ord`) and specify other things about `T` that your ord implementation did not need to know about, like display (to print stuff): use std::fmt::{self, Display}; impl&lt;T: Display&gt; Display for Rank&lt;T&gt; { fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result { use self::Rank::*; match *self { Ace =&gt; write!(f, "Ace"), Number(ref n) =&gt; write!(f, "{}", n), Jack =&gt; write!(f, "Jack"), Queen =&gt; write!(f, "Queen"), King =&gt; write!(f, "King"), } } } Has you can see we have no idea what `T` actually ever is, we just take little assumptions about it each time we implement something else. *This means if our `T` does not actually implement `Ord`, which it does not need to based on our `enum`'s generic declaration, it's just not going to have the `PartialOrd` implementation unless we implement it for a more generic type.* Then when it comes the time and we need to know a lot about it, we could just be very specific like: impl Rank&lt;u8&gt; { fn number(n: u8) -&gt; Self { if let n @ 2...10 = n { Rank::Number(n) } else { panic!("not a supported card number") } } } Then you can just use it: fn main() { let card0 = Rank::number(4); let card1 = Rank::Ace; if card0 &gt; card1 { println!("{} is greater then {}", card0, card1); } else if card0 &lt; card1 { println!("{} is smaller then {}", card0, card1); } } playpen: https://is.gd/l1xEqd
&gt; which IMHO is a much better approach than sampling profilers, because though it likely introduces more overhead, it does not suffer from sampling bias This is a little misleading: naming a bias is no substitute for understanding the actual shape the bias comes in. - the sampling profilers Rust can use are different to many JVM ones, e.g. something like `perf` uses features in the hardware to sample at regular intervals at the instruction level, rather than just at compiler-inserted "safe points". - the overhead of an instrumented binary isn't just a fixed percentage slow-down: it introduces its own biases (some of which probably fall under the umbrella of the broad "sampling bias" category too). For this case, instrumenting at the function level means profiles will be biased towards things that call a lot of functions. For an example of the bias instrumentation can introduce, consider: fn accumulate(x: &amp;mut f32, y: f32) { *x += y } fn sum1(xs: &amp;[f32]) -&gt; f32 { let mut sum = 0.0; for &amp;x in xs { accumulate(&amp;mut sum, x) } sum } fn sum2(xs: &amp;[f32]) -&gt; f32 { let mut sum = 0.0; for &amp;x in xs { sum += x; } sum } With optimisations, both `sum1` and `sum2` produce the same machine code, but instrumenting all of the function calls in profiling mode will mean `sum1` takes a lot longer than `sum2` due to the overhead of `accumulate`'s instrumentation. And, that's not even accounting for optimisations that may be inhibited, e.g. if I use `i32` instead of `f32` both versions vectorise, but I imagine `sum1` would not if `accumulate` had instrumentation. This will mean the programmer's attention may be drawn away from the function(s) that take the most time in a true release binary, to instead focus on those that call the most instrumented functions. That is not to say that native sampling profiling is perfect---there are even [mathematical theorems](https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem) that say it can't be ([more discussion](http://danluu.com/perf-tracing/))---but dismissing one approach out of hand is unfortunate: both tracing and sampling profilers are tools that are sometimes appropriate and sometimes not. There are other features/tools that may change the equation for the best way to analyse performance too, e.g.: - ["causal" profiling](https://github.com/plasma-umass/coz) for concurrent/parallel code - [nascent processor tracing](https://software.intel.com/en-us/blogs/2013/09/18/processor-tracing) makes tracing at the instruction level actually feasible - [flame-graphs of time spend off the CPU](http://www.brendangregg.com/FlameGraphs/offcpuflamegraphs.html)
&gt; like implementing ord/eq By the by a single match statement is gonna be fuuuugly. I'm not the best at such things, but boy does this beg for a functional style: fn partial_cmp(&amp;self, other: &amp;Self) -&gt; Option&lt;Ordering&gt; { fn ord_n(x: &amp;Self) -&gt; isize { return match x { &amp;Ace =&gt; 0, &amp;Number(_) =&gt; 1, &amp;Jack =&gt; 2, &amp;Queen =&gt; 3, &amp;King =&gt; 4, }} return match (ord_n(self)) .cmp (ord_n(other)) { Greater =&gt; Some(Greater), Less =&gt; Some(Less), Equal =&gt; match (self, other) { (&amp;Number(ref a), &amp;Number(ref b)) =&gt; (a) .partial_cmp (b), _ =&gt; Some(Equal), }}} (See, it's possible to write Lisp in any language.) Not being able to compare the discriminants of this enum directly is kinda lame though.
My method: Search what I want on duckduckgo with `!crates`, i.e. `readline !crates`, this leads me [here](https://crates.io/search?q=readline). Scan names, and descriptions to find crates that seem to match, pay mild attention to download counts on the right. Open up the first few that look like a good chance. Check their github repos and check if they are actively maintained, if there is a docs link check if the api seems to match what I'm looking for. I'd be interested in what other people do though. As a side note, by convention `-sys` crates are raw ffi bindings and not what you are looking for unless you want to make a rust wrapper yourself. Specifically for readline I've used rustyline, which is the 3rd result in the above search. I was mostly satisfied, but never went very far in a project using it.
If you want everything to coerce to unit, yeah.
If you want something super ambitious, how about a Rustic reimplementation of the BEAM virtual machine (that Erlang runs on)? Or if you want to do something that'll not be that ambitious, look at the help requests in This Week in Rust?
Maybe you should take more showers! ...wait, that came out wrong.
Thanks, it's changed now. I missed that, probably came from the symmetry with get_uri() that works with Option&lt;String&gt; :) This is now more ergonomic to use
Having a library to work with microsoft office could be great to help rust integration in enterprise: - reading/writing from excel file - sending an email via outlook 
Checking the list of dependent crates is also useful.
It just makes using the crate easier, as it provides all the types you need for working with the crate directly, instead of you manually having to use the crate it is relying on too. So it's definitely something you are supposed to be doing. I'm not aware of any downsides to doing this.
One downside is that it may cause problems if users of your API intend to use a different (e.g. newer) version than the one you reexported.
Last week I looked at some of the first code I ever wrote. ( not code I copied from a book and modified it. But one of the first things I did by my self) It's a little game written in JavaScript. The code was horrible. Global variables for everything. Duplicate code everywhere. The naming was horible. The formating as inconsistent as possible. I made every mistake that I could make. But the thing worked. And that was really cool. So little 11 years old me kept programming. And later on I learned about all the things that you have to pay attention to. Of course today I prefer a language like rust. With a wonderful type system and with a compiler that tells me if I did something wrong. ( and a great community) But I guess 11 year old me would not have liked rust. It would have been to complicated for me. I didn't know closures. I didn't understand what an object is. I probably did not really understand functions. I didn't even know that "else" is an english word. I just knew what it does. No way I would have understood traits or ownership. Once you understand some basic programming concepts you can try to understand rust. ( well or if you have a degree in mathematics or something) Maybe I just wasn't a very smart 11 year old. But I wouldn't be a programmer today if I tried to learn programming in rust. ( if it would have existed back then) (Maybe if you have somebody that teaches you programming it would work. But I was on my own) 
I only ran into the opposite problem so far. I get a deep-dependency type from some library, but can't guarantee that my program creates a compatible type itself. I would have to manually force specific version due to https://github.com/rust-lang/cargo/issues/2064 Until that's solved, I'd much rather have the reexported module available.
A nice GUI
Yep. Recent breaking changes in the [url](https://crates.io/crates/url) crate, which hyper/iron and others have `pub use`d, have caused me issues in a crate that tries to use all of those... [here's my story](https://gist.github.com/carols10cents/b5fc3702a23a0c5d48e7643218e6ff7d) and a [pull request to iron](https://github.com/iron/iron/pull/452) that should help. I'm not sure if this is just something that's going to happen as a result of breaking changes, or if we shouldn't be `pub use`ing to prevent this, or if there's another solution. I think /u/dwrensha has thoughts on this too...
I'm pretty up to date on rust + editor tooling and I've never seen something like this. It also might not work, depending on how magic you want things. In your example `io::stdin` could refer to `::std::io::stdin` or `self::io::stdin`
Hello. I'm not sure how I can match + update a borrowed enum value. While writing a parser, I end up with this kind of code (https://is.gd/EdPyot): // T is not necessarily Copy nor Clone. enum State&lt;T&gt; { First(T), Second(T), } struct Parser&lt;T&gt; { state: State&lt;T&gt;, } impl&lt;T&gt; Parser&lt;T&gt; { pub fn advance(&amp;mut self) { match self.state { State::First(i) =&gt; self.state = State::Second(i), State::Second(i) =&gt; self.state = State::First(i), } } } fn main() { let mut s = Parser { state: State::First(0) }; s.advance(); } Of course, the match statement borrows the state and I cannot move the state value to another enum value (e.g. First to Second). Was anyone stuck on this kind of pattern ? Is this solvable ? Thank you
Speaking of the `uri` property... g_value_take_string (value, sink_get_uri (sink-&gt;instance)); This means libgobject is responsible for freeing it. CString::new(uri.clone().into_bytes()).unwrap().into_raw() Letting the other side free the pointer returned by `CString::into_raw` is risky. I'd do something like this instead: assert!(uri.chars().all(|c| c != '\0')); g_strndup(uri.as_ptr() as *mut c_char, uri.len() as size_t)
I know someone is working on the organisation part, not sure about adding and removing. I'll ask him to look at this post, he's here at the meetup.
if you stick to the antirez/linenoise derived projects you'll be able to stay relatively cross platform. i've tested the octplane/linenoise-rust crate on windows, and the pure rust ones i would hope are cross platform right out of the gate. if you known you need readline features then you might be in a tricky spot.
Well now I feel stupid. I was sure I had tested both readline and linenoise and found that they don't work on windows. Turns out linenoise works perfectly well! Thanks!
Note that spray "became" akka-http, you might find it interesting to have a look at that too. :) Would be interesting to see the performance differences with akka.
Cross-posting this here on /r/Rust because I found very interesting that the major problem that Uber is facing is to achieve Safeness - which is one of the core tenets of Rust! "Key takeaways: * Expanding a company and team at this rate is genuinely hard. Lots of mistakes have been made along the way. Microservices allow companies to grow rapidly but have a cost in terms of aggregate velocity. * Uber is gradually moving its marketplace development from Node.js to Go and Java. Java is used for the map services. Aggressive failure testing is used extensively in Uber. * Some early design choices - like using JSON over HTTP - make **formal verification basically impossible.** "
I'll look into it, but first I'll catch some sleep.
Actually I suggested that we should attempt to formalize the notion of a suggested code change so that rustc can give IDEs / interactive code wrangling tools enough information to do their job.
I am trying to write a generic factorial function that will work on anything that implements [`Integer`](https://autumnai.github.io/leaf/num/integer/trait.Integer.html) (from the [num crate](https://autumnai.github.io/leaf/num/index.html)). It is my first time using generics and my understanding of the borrow checker is not so great. So far I have /// Get the factorial of a number /// /// # Example /// ``` /// assert_eq!(math::factorial(10), 3628800u64); /// assert_eq!(math::factorial(16), 20922789888000i64); /// ``` pub fn factorial&lt;T&gt;(n: &amp;T) -&gt; T where T: Integer { if *n == T::zero() || *n == T::one() { T::one() } else { *n * factorial(&amp;(*n - T::one())) } } I am getting the error `cannot move out of borrowed content`, but I though I was getting around borrowing the input by taking it as a reference. Any help would be much appreciated. Rust's lifetimes and borrowing haven't quick "clicked" for me yet.
&gt;Some early design choices - like using JSON over HTTP - make formal verification basically impossible. " Formal verification of a HTTP/TCP/IP stack sounds like you may end up formally verifying the Linux Kernel which... I mean there is a reason so few x64 system are formally verified. 
You meant to post this in /r/playrust.
I don't see how rustc could have a role in this other than its existing role of identifying errors. I don't see how the compiler would be any better at mutating source files on disk than any other tool with access to its error output.
I think it's likely that the word _formal_ was used sloppily here. But then, I haven't listened through the whole thing.
Damn, really awesome! thanks!
That's not completely true. I haven't seen Iron use a macro for routes (but I haven't seen everything) and the only reason it's used in Rustful is to make tree structures easier to write, so it's #[macro_use] extern crate rustful; use rustful::TreeRouter; let router = insert_routes! { TreeRouter::new() =&gt; { Get: show_welcome, "about" =&gt; Get: about_us, "users" =&gt; { Get: list_users, ":id" =&gt; Get: show_user }, "products" =&gt; { Get: list_products, ":id" =&gt; Get: show_product }, "*" =&gt; Get: show_error } }; instead of extern crate rustful; use rustful::Method::Get; use rustful::{Router, TreeRouter}; let mut router = TreeRouter::new(); router.insert(Get, "/", show_welcome); router.insert(Get, "/about", about_us); router.insert(Get, "/users", list_users); router.insert(Get, "/users/:id", show_user); router.insert(Get, "/products", list_products); router.insert(Get, "/products/:id", show_product); router.insert(Get, "/*", show_error); The result is the same, but the macro has less repetition (which is what macros are good for, in my opinion). I do admit, however, that the second alternative should be advertised more. It wasn't _really_ as nice before, but recent changes got rid of some awkward stuff. What /u/banister wrote made me think that it may be possible to achieve the same goal with a builder pattern. I haven't thought about that before, but I had my head deep down into that rabbit hole recently. I should write that down somewhere...
Neat. Looks like an improved [hprof](https://github.com/cmr/hprof).
[removed]
&gt; FLAME lets you choose what you want to see in the graph by adding performance instrumentation to your own code. That's what I'm referring to. So Flame seems to insert some code (or you insert Flame code) into the function - what does it actually do? Is it just a timer? Does it collect it into a structure as the function runs?
How far are we from tools fancier than racer?
Last time I paid attention to Rust there were some RFC's and discussion about how Rust was going to implement static v. dynamic dispatch with regards to inheritance, virtuals, etc. Is there a summary of how all of that works as of today?
Ah, gotcha. I asked while on the train, I assumed it would be longer. Thanks.
That isn't what illogiq suggested. The suggestion is to make rustc output some sort of diff for suggested code changes that tools could apply.
How are multiple threads handled?
I don't really know... When I said that I'm up to date, I mean that I try every tool that comes out, not that I follow their development. 
Each thread captures timespans separately, so you'll need to dump from each thread that you are interested in. However, it is on my todo list to allow threads to automatically add their counters back to a global queue when a thread dies, allowing for all-thread capture at the end of a long-running program.
FLAME by itself requires that you insert calls into your program for starting and stopping spans. `flame::start("foo");` and `flame::end("foo");` will create a timespan named "foo". /u/llogiq's flamer will insert these calls for you on a function-by-function basis. Yes, it collects this information into a per-thread structure which can be retrieved via `flame::frames()`.
IIRC they're ad-hoc.
What's your current setup?
Neovim with * Neomake set up to do a full cargo build on every save. This gives me 100% of the cargo errors in vim. * Racer * The standard rust vim plugin
Looks like they are so you can instantiate them yourself, e.g. so other crates can't do `flame::Frame{ roots: vec!() }`.
Java has improved in leaps and bounds since the early 2000s. I think a lot of opinions of Java are circa 2003 rather than Java today which is really quite impressive. They're even stealing away the best features in Scala.
Btw. I'm planning to extend flamer to be able to insert flame calls for all loops within functions, or even all blocks. This would include some sort of name wrangling, which would be advisable anyway as we could have multiple impls with the same function names.
Ooh, that would be really neat! I wonder if we could come up with some scheme for de-mangling in the viewer so that things are pretty in the flame graph?
What would be the correct way to free it though? I just saw in the docs now that CString::into_raw() should not be freed by free(). Should I call CString::from_raw() from C code instead? Is there some CString::into_raw_malloced() or similar that could be used instead? In this case the memcpy() has no real performance impact, in other places it could though.
That's so far a general problem with the code, yes. But this specific part alone should never panic, right? It seems that std::panic::recover() is the latest way (but marked as unstable) to catch panics, while std::thread::catch_panic() is marked as deprecated. I assume one of those two should always be called at the boundaries?
That's also true, yes (although IIRC there were discussions about deprecating the API to set your own malloc/free/realloc functions). I guess for now doing the memcpy() and calling back into Rust for freeing the string is the best choice then. Maybe at a later point some kind of GLibCString type might make sense, I would assume that the gtk-rs people already have a thing to keep the number of copies low. Changed that now, thanks again!
`CString::new(x).unwrap()` and `assert!` can panic but that is avoidable of course. Then, `Sink::get_uri` could panic as well. In that case it's possible that the sink instance is corrupted (see the `RecoverSafe` discussion in the docs). You may have to kill the process.
Wrong subreddit :0
There are already some projects that are working on this topic. Here is a small list: https://github.com/flosse/rust-os-comparison#embedded-systems
Can I remove `#![feature(box_syntax)]` from my lib any time soon?
Yeah, forgot to catch you... :)
Hanno Braun keeps a log of his Arduino work at http://embedded.hannobraun.de He recently presented his current results at the Rhein-Main Rust Meetup to much applause.
Could you open an issue please?
I'm contemplating writing a code generator that would parse the ui definitions and take care of `get_object` boilerplate. You'd only need to clone a single struct e.g. if you've created `button_1` and `text_view_1` in Glade, let objects = resources::ui::build(); // ... let objs = objects.clone(); objects.button_1.connect_clicked(move |_| { objs.text_view_1.do_something() }); Maybe some macro could reduce this further.
Expanding on what zzyzzyxx said: you should probably be taking (n: T), not a reference. If caller calls with T: Copy, then he doesn't have to do anything (it will work with primitives out of the box). If for some reason he wants to call it with a type which isn't Copy it will work too, but the original number will move and can't be reused. If the caller needs to keep a copy of the value, he's responsible of cloning it.
I'm trying to understand the ownership semantics as a second nature, so I have to think less about my type signatures when building my APIs. As part of it, I'm doing a study ([Playground](https://play.rust-lang.org/?gist=e4c00e1b60aed25582458774410a266f&amp;version=stable&amp;backtrace=0), [Gist](https://gist.github.com/anonymous/e4c00e1b60aed25582458774410a266f)) on the different ways to take bytes as parameters to transform them (I found the use case particularly interesting since it's quite common and has simple requirements). I'd like some feedback on my progress so far. In particular: - Did I miss any combination of parameters/return type? - Are any of my assumptions wrong? - Are my conclusions sound? Any help/comments will be appreciated.
Intel claims to do formal verification of its circuits internally. But judging by the skylake 14,942,209 exponent bug I think they're either lying, or their system has holes in it. Likely the later. I trust they tried but reality/management/budget requirements set in and the goal posts move.
The string searching literature certainly appears to think it is worthwhile to discriminate classes of algorithms based on whether they are NFAs or DFAs. The fact that they are computationally equivalent is irrelevant to the real world practical implementation choices that either one implies. If your *implementation* keeps multiple states active simultaneously, then that is said to be an NFA implementation. If your *implementation* maintains a single state at any point in time, then that is said to be a DFA implementation. The reason why the discrimination is important is because it typically corresponds to trade off between space and time (and typically also implementation complexity). So yes, if the implementation uses an NFA but is called a DFA, then I would absolutely call that wrong/misleading. But if Friedl's book is your guide to naming your automata implementations, then it's not clear that *anything* is actually ever wrong. For example, PCRE claims its primary matching algorithm is an "NFA," despite the fact that it can resolve backreferences, which is not something an NFA can do.
I think we need to return "easy" to the title, or maybe replace it with "quick". There's some questions here that deserve their own thread, either for the discussion they generate or because they're harder to answer and will just get buried here. The OP also doesn't really give useful criteria for figuring out whether to post here or as a new thread. Addendum: I don't think it'd be remiss to have a link to the previous thread in the OP, either.
/cc /u/hannobraun
A Rust port of the Java Topology Suite (GEOS), or GDAL/OGR.
You're right, I didn't know if posting to the subreddit or here was the right choice. Having some criteria would help.
None of those proposals have moved forward, because focus was put on specialization first instead, as it's a pre-requisite for a lot of them. It has since landed on nightly, but the proposals haven't been picked up again just yet.
That's a bit like saying that since VisualBasic and Rust are both Turing complete then it's not wrong to say that coding in VisualBasic is just like coding in Rust...
An automatic conversion between `&amp;String` and `&amp;str` (called a coercion) exists because of [`Deref` coercions](https://doc.rust-lang.org/book/deref-coercions.html), but it can only happen at coercion sites. I can't find it in the book, but [on the coercions RFC](https://github.com/rust-lang/rfcs/blob/master/text/0401-coercions.md#coercions): &gt; A coercion is implicit and has no syntax. A coercion can only occur at certain coercion sites in a program, these are typically places where the desired type is explicit or can be derived by propagation from explicit types (without type inference). The base cases are: &gt; (...) &gt; * In argument position for function calls. The value being coerced is the actual parameter and it is coerced to the type of the formal parameter. For example, where `foo` is defined as `fn foo(x: U) { ... }` and is called with `foo(e);`, `e` is coerced to have type `U` [This](https://is.gd/urh3nr) doesn't work because the `...` in `match ... {` is not a coercion site. If one wants a coercion without writing another function, one way to do so is to use a let binding with explicit type, because it's another coercion site: &gt; * In `let` statements where an explicit type is given: in `let _: U = e;`, `e` is coerced to have type `U` [Like this](https://is.gd/4b6RuA). Another option is to use a cast, [like this](https://is.gd/8DHQ5k).
(1) and (3) are the same signature. The `mut` annotation is on the parameter *binding*, not the parameter *type*, which does not influence the function's contract - the caller gives up a Vec, and gets back a Vec. If it's the same Vec or a newly allocated Vec is of no concern to them. This also answers the unresolved question at the end. 
The fn test_no_matches can't be changed but I didn't notice that. I did solve this by changing the public function signature to: pub fn anagrams_for&lt;'a&gt;(word: &amp;str, inp: &amp;[&amp;'a str]) -&gt; Vec&lt;&amp;'a str&gt; And not the test appropriately fails (because I actually have to write the anagram part). But it is this change with the inp variable in the signature that makes it work. Thanks for the answers!
&gt;Plushie Rustacean Pattern I tried to follow, but it got caught by the borrow checker and wouldn't assemble. 
&gt; I'm unsure of the logistics of starting a group Find a place, find foods/drinks, find a topic, and advertise so that people come. Make sure you keep track of the costs and ask if everyone is willing to chip something in, its OK to make a small profit for unforeseen calamities (the disaster pot if you will). You may also want to register with your government, I don't know how to do that since I'm dutch, but you can do that once you got it of the ground (ie had several meeting and some people are committed).
There's a [tracing framework](http://google.github.io/tracing-framework) by Google with features very similar to this one. It has a very nice browser-based trace viewer with zooming, filtering and multithreading support. I think it'd be awesome if FLAME could output traces in a compatible format, and we could just load them in that viewer.
No no, cloning an entire image is far too expensive! The problem is clearly that they're trying to match the pattern by-value. They should just add `ref` to the pattern to capture it by-reference! Rust will then make tab invalidation a compiler error. You will probably need to stitch the plushie with scoped threads to prove to the compiler that you aren't doing that, though.
Ah, that makes sense. I removed the reference bit and got it working with primitives, but I really want it to work with BigInt's. When I run it with a BigInt, I get the error `the trait bound `num::BigInt: std::marker::Copy` is not satisfied` pub fn factorial&lt;T&gt;(n: T) -&gt; T where T: Integer + Copy { if n == T::zero() || n == T::one() { T::one() } else { n * factorial(n - T::one()) } }
Crabs don't walk on threads -- so they can't be Sync!
Hm, how about having a more or less official mascot of the Rust programming language, similar to Android's approach?
Certainly, I can do that.
That would help quite a bit if you could implement that.
Definitely not the wrong place to ask. I run the LA Rust meetup and the travel is hard even if you are closer to the city. If you want assistance or have any questions, please do not hesitate to reach out and ask.
Soo awesome 😻
That would be really neat! I wonder what their file format looks like?
As a side note: [you want to make your `T: Integer + Unsigned`](http://rust-num.github.io/num/num/trait.Unsigned.html), or else your factorial will run infinitely (until stack overflows) if you get a negative integer. In fact, [factorial is only defined for non-negative integers](https://en.wikipedia.org/wiki/Factorial). Rust's type system is so cool it allows you to express this kind of constraints and check them at compile time :)
Is [Option::or_else](https://doc.rust-lang.org/core/option/enum.Option.html#method.or_else) what you're looking for?
Not necessarily a bad idea, it's just that many Rustaceans prefer a functional style instead of mutability everywhere, so I doubt this will make it into the stdlib. Not a big burden to roll this out on your own: [quick example](https://is.gd/l8fnjQ) (could easily be rewritten to use a `Fn`).
Good point. Memory corruption/code execution bugs are far less likely with Rust code. What exactly do you mean by "number of known security weaknesses"? Unsafe blocks or are there known problems with piston-image? Or something else?
This post and these comments are really why I love the Rust community! I should try to sew one of these fellas some day! 
It doesn't look like the function actually allocates anything, as a single pointer wouldn't be enough to set the pointer you are passing to the function. So it expects you to allocate the 31 bytes and pass a pointer to it. You can just use a Vec to allocate the memory, construct a CString out of it, call into_raw on it, pass it to the function and then construct back the CString and possibly later a String out of it. The code would roughly look like this: https://is.gd/yD6wVL (switch to Nightly on PlayPen due to the libc feature) You could probably also just go straight from the Vec to the ptr with its into_raw, not sure if that's safe (as into_raw wants you to use the from_raw of the same type). Also on a side note: According to the documentation it seems to be returning void and not int. Another thing you could do is not actually initialize the Vec with zeroes, as the ffgerr function is initializing it anyway.
I think that makes sense. It would have exactly opposite use case as `take` and `take` is standard. Still, I think I prefer explicit control flow to show mutation: if the_option.is_none() { the_option = ... } 
As a general rule of thumb, you can search the feature name in the Github issue tracker to find the tracking issue for a given feature, if it's not reported by the compiler when you omit the flag. For the `box_syntax` feature, you're looking at the [placement-new tracking issue](https://github.com/rust-lang/rust/issues/27779) which deals with all the work on boxing syntax and related features. It's unclear how much movement there's been on it and what the prerequisites are to complete it, but with many upcoming features, I think MIR plays a big part as they don't want to implement any new syntactic sugar in the current compiler stack just to have to port it to the MIR architecture.
You'll have better luck in /r/playrust
And it seems titles don't have markdown. :-/
Why does `shortest_match` only return the end index? 
You're doing something that wants to step outside the guard-rails. - You have a function `advance` that mutates a structure `&amp;mut self` which lives in far (i.e. not-local) memory. ('far' isn't the standard term for this, but I'm not aware of a standard term) - If you read from a far-memory location that would leave a value behind and creates a local value. This is only safe if the value is copy-safe (`Copy` trait). - Also you can't have an uninitialized far location. - the only safe operations with a far location are: - Replace and drop old value: `*far = new;` - Replace and take old value: `let old = mem::replace(far, new);` - Swap values between two far locations: `mem::swap(far_a, far_b);` - Access a sub-location which has a Copy-safe value. (This is what most methods do.) If there's a panic between the read and replace, you could end up double freeing the inner object or exposing uninitialized memory. Not in this simple example, but in more complex ones. Safe Rust is the guard-rails, undefined behavior is the cliff. In this simple case, you [could choose to step outside the guardrails](https://is.gd/U3m22S). I wouldn't accept that `unsafe` block in my own code, but it's an option and worth learning how to do. (Going outside the safeguards the only way to define new types of memory-owning containers.) A better way to do it is to explicitly mark the invalid transitional state so if a bug occurs you'll catch it. This is done with `Option` and its `take` method. [This is a lot better but still not ideal.](https://is.gd/Xlesne) There's a bit of overhead involved: 32 bits for `Option`, 32 bits for the `State&lt;T&gt;` discriminant. The generated code is pretty enough, because LLVM really does do a good job, but it proactively writes a 12-byte `None` value before checking for the `unwrap()` panic. This costs about a cycle, maybe a little less. [We can do better](https://is.gd/s2rZtD) by folding the invalid state into the State&lt;T&gt; type. This gets the size down to 8 bytes and is something I'd be happy with. The machine code isn't as pretty this time but it looks equally fast. All that said, I would most like to move the `T` value out of the state enum and avoid this wizardry.
If you know the size statically, you might as well just use a `[u8; 31]` instead of a `Vec&lt;u8&gt;`.
I would like to pay somebody to make one of these for me. I'm afraid that attempting to make one myself will most likely result in a strange tangle of orange fabric that looks almost, but not quite, entirely unlike a Rustacean. Anyone else interested in jumping in on either the supply or demand side of this?
Well, :-(
Transpiling from one language to another is fairly common so it's not like the problem is intractable. NFAs and DFAs have different usage characteristics however, just like VisualBasic and Rust do.
great to hear!
The official unofficial mascot, even, though note that I say this in an unofficial official capacity.
Specifically, here's the link to the page that concerns Rust support: http://developers.algorithmia.com/algorithm-development/guides/rust-guide/
Your site looks pretty neat, sort of like a library ecosystem without the libraries, but if I could make one suggestion it's that you could be more clear and up-front on the benefit that this delivers to developers. A programmer is going to want to find your site and immediately know the answer to the two questions 1) what problems of mine does this solve, and 2) how do I use it, and it took me a frustratingly long time of navigating your site to determine that the answers are 1) the ability to forego needing to install local dependencies in order to experiment with a specific algorithm, and the ability to totally ignore the language that an algorithm is written in while enjoying its use from any of the supported languages, and 2) by installing the "algorithmia" library that you provide for supported languages and making simple API calls over a network. Also, I see on pages like https://algorithmia.com/algorithms/SummarAI/Summarizer that Rust isn't listed under the heading "3. Use this algorithm", does that imply that this announcement means only that Rust can now be used to define algorithms (rather than consuming them), or is that simply an oversight in the UI?
I'm just barely discovering Rust, and I don't actually live in Tampa right now, but I'll throw my hat in the ring.
Why are they not available in svg?
So, is someone interested in writing bindings for this library? Should I? Is that hard? This is something I've been looking for in Rust for a very long time.
I'll try to make one over the weekend and see how much work it is to make a few for people if they want them.
I tried with the guard from gtk-rs, but when testing it fails with a SIGILL and "fatal runtime error: Could not unwind stack, error = 5" before the call stack is even unrolled up to the Rust code that created the guard. Will debug this more closely later.
Anything of any size can't use native widgets, that even applies when you're using the native widget library directly (as you'll need to extend it). Most UIs however are, apart from eye candy, not actually complex. Especially the ones doing the same job as plain command-line interfaces and/or configuration files. (Regarding that application area: It'd be nice to have command line, config file handling, and basic GUI generated from a single declarative spec).
Anyone use [IUP](http://webserver2.tecgraf.puc-rio.br/iup/) or [FLTK](http://www.fltk.org/index.php)? I remember playing around with them a long time ago, both are also cross platform GUI ~~using C~~ (and in IUP's case, Lua as well). edit: looks like IUP already has a rust binding: https://github.com/dcampbell24/iup-rust Edit: fltk uses C++, IUP uses C
The Qt Company announced that they're going to adopt PySide as an official, first-tier set of bindings, similar to what QtJambi used to be. As part of that, the devs are investigating ways to make their bindings generator compatible with the newer versions of C++ that Qt 5 is starting to use. https://groups.google.com/forum/#!topic/pyside-dev/pqwzngAGLWE One of the avenues being investigated is letting llvm-clang do the heavy lifting, as far as parsing goes, and I'm hoping they do take that avenue because it seems logical that the easiest way to write a "C++ to Rust" bindings generator would be to take a production-quality "C++ to Python" bindings generator that's already been interfaced with another LLVM-based project.
What would have been awesome is just having the types automatically filled in by the compiler in implementations (since they are defined by the trait signature + associated types). Like this: trait Test&lt;T&gt; {fn test(x: Very&lt;Long, Type&gt;, y: Option&lt;T&gt;) -&gt; Result&lt;T, Long&gt;;} impl Test&lt;u32&gt; for SomeStruct {fn test(x, y) {/*…*/}}
Wow that's awesome. I made the mistake to consider PySide "dead" since there were no Qt5 bindings, when now I'm reading that it's indeed being worked on. :') I hope we'll see a good c++ to Rust bindings creator some time soon. You are right that it makes sense to develop the core of such a binding generator only once and not a new one for every binding. 
What's new in this version?
You can now disabled tests by replacing `it` with `ignore`. You can now also test the message of failing tests (i.e. `failing("the message")`). Benchmarks also work again. Oh, and I hope the documentation should be better now as well.
How can I get a buffered TcpStream (or anything that implement both Read and Write) ? I tried using BufReader and BufWriter but I can't use both at the same time: they require me to either move the TcpStream, or use two mutable reference to the stream.
I would suggest using [Neomake](https://github.com/neomake/neomake), once installed it should Just Work^(TM).
Haha, well it's the thought that counts. And as far as being new to the language... I've followed it for a couple years, but as far as building things, I'm relatively new myself.
In my case, the C lib specifically needs a va_list argument.
Awesome work, burntsushi! Could you, please, give an advice on which book, papers, ... you found valuable while implementing the engine? I would be very curious to learn from the insights you gained. Perhaps you could write an article on it, even though I realize you must be very busy person? Again, I'm huge fan of your regex engine, thanks for the hard work!
When you say "much harder to cause undefined behavior with", does that mean that the scoped API has undefined behavior even in safe code? Or just that it makes unsafe code easier to write?
Russ Cox's articles are canonical: https://swtch.com/~rsc/regexp/ --- Rust's regex crate is heavily inspired by the content of those articles. Many of the comments in Russ's RE2 implementation were also quite helpful. For the most part, these articles will carve out a path that anyone can follow. If you're interested in something more specialized, you can read up on my latest changes to add [SIMD accelerated multiple pattern matching](https://github.com/rust-lang-nursery/regex/blob/master/src/simd_accel/teddy128.rs). There are paper citations in the comments. That would actually be an interesting thing to pursue further independent of the `regex` crate IMO.
To build when a .rs file isn't the current buffer open your vimrc and add something along the lines of command -nargs=* Cargo cex system("cargo &lt;args&gt;") Then run **:Cargo build --verbose** or whatever command you like. If you only want it for running **build** you can have "cargo build &lt;args&gt;" instead. 
I'd echo what other people said about a Rusty interface. Ive found it very hard to work with APIs that aren't reworked to match the language to be very difficult. For example I've worked with C or C++ libraries in Python and they have surprising APIs because they weren't adapted to be Pythonic. I'd also like to say you should talk to the GTK guys. They're building an automated tool to generate a Rusty API to the GTK C API. It's not all there but much of it is. I'd suggest hitting them up to see if it might help you out. Their interface is really great to use even though I'm still learning what Rusty means.
If you add a SPIR-V backend to rustc, it would be great to have some high-level heterogeneous computing library like [SYCL](https://www.khronos.org/sycl) - to enable writing single-source programs that run on either GPU or CPU, via OpenCL. You may want to look on its API (I never used it). What I would like is to have attributes (like `#[parallel]` or `#[opencl]`) to mark Rust functions that would run as an OpenCL kernel, making the process as transparent as possible.
Absolutely. One of the complaints about using cross-platform GUI toolkits, such as GTK or Qt, is they don't match the look/feel of the native GUI toolkit. Judging by the example screenshots, they did a pretty decent job abstracting away the differences between various GUI toolkits and matching the native look.
This should be possible, and I do think that it is a good idea. This is great for a compiler plugin that refers to the basic OpenCL API, but I am starting to think that it will be best to start with a simple binding and build packages on top of that to make it more rusty and add ease of use.
I've seen a few libraries for autogenerating C bindings. I am going to have to start testing some of them soon to see which ones can actually provide a nice binding to openCL.
It seems that on Linux it simply serves an abstraction for GTK3, on Mac is merely an abstraction for Cocoa, and on Windows it is merely an abstraction for .NET.
Agreed.
I've been working on a safe IUP wrapper: [Clear Coat](https://github.com/jminer/clear-coat) The biggest problem I have with IUP is that it doesn't have a native OS X backend. However, it has been on the shrinking todo list for years, so I have hope it will be started before long now.
I've actually been waiting for tutorial like this, I tried doing something simple like this using hyper but I couldn't figure out how to get the server to read in the request, capitalise the request and then send it back out as the response.
I'm gonna keep plodding through exercism while contributing where I can and studying Rust API design--if I get enough headway I'll try and emulate some simpler machine learning algorithms soon. Speaking of, is anyone considering picking up development on Leaf? 
Yes that was my point. Java AWT/Swing/SWT attempt to mimic the native look/feel, but still stick out like a sore thumb. Another problem is over-abstracting the GUI toolkits to a lowest common denominator, where you lose access to important style and layout controls, making your GUIs look "crufty".
Not .net; raw Windows API. (I did experiment with WPF at one point. It was interesting, but some essential things are missing and a few things are noticeably non-native such as button hover animations (or lack thereof)).
I've done my best to make the API of my OpenCL Library, [Ocl](https://github.com/cogciprocate/ocl), as rusty as possible but of course the kernels are still in C (or whichever language the user wants). I'd be interested to hear your opinions about it as it seems to be in the neighborhood of what you're working on. As for the kernel side of things, I'd be interested in contributing to whatever effort you're planning for Rust -&gt; SPIR-V compilation. Designing this would basically entail using a subset of the Rust language with a slightly special syntax. A few things would probably be a bit different from vanilla Rust. For example, lifetimes might not end up being very useful in a kernel. Instead of references, raw pointers might end up being be the convention. Lots of interesting stuff to consider.
Nice! Where is `drop()` coming from though? 
https://doc.rust-lang.org/std/mem/fn.drop.html
Nah, the types are the same; it's rust doing the formatting and layout on both ends. Just the place where main() is is in C code, not rust. That's all - it's a C program calling over to Rust code that does the formatting and exchange logic. I have the specialized mutex down. I know how to program concurrently, it's just the Condvar that is giving me a heartache.
I already have a lot of Rust code that manages multi-multi consumer producer relationships that I don't want to have to throw away. Extending or upgrading existing libraries is more expensive to use what I already have, because from what I've seen, IPC mechanisms don't handle this current relationship right now.
You can use `std::ptr::write` to specify the address for a new value. It's just `write(where_to, Thing::new(...));`. With a `Copy` type it's preferable to use a regular `*where_to = Thing::new(...);` . It's not advisable to use a (standard) Mutex though. Shared memory (between processes) can't contain pointers and resource handles that would only be valid in one process. A `!Copy` type almost certainly contains those, and they'll point to non-shared memory. As best as I can tell the standard library isn't intended to sleep-wake threads across different processes. This depends on OS-specific mechanisms and it might not work in the future. Atomics will work because it's the same machine language and same physical address. If you're doing something as performance critical as this sound, I imagine you want to optimize blocking too.
`Neomake` loads into the location list (`:lopen`) and uses the makers files, but `Neomake!` loads into the quickfix list (`:copen`) and uses your `makepgr`.
Thanks, it's all cool. Let me just try it out and give a shout with the results when I'm done.
&gt; I'm not sharing pointers. It's just the data itself. There's a pointer inside the `Mutex` So sayeth the source: pub struct Mutex&lt;T: ?Sized&gt; { // Note that this static mutex is in a *box*, not inlined into the struct // itself. Once a native mutex has been used once, its address can never // change (it can't be moved). This mutex type can be safely moved at any // time, so to ensure that the native mutex is used correctly we box the // inner lock to give it a constant address. inner: Box&lt;StaticMutex&gt;, // &lt;&lt;-- Pointer here. data: UnsafeCell&lt;T&gt;, } &gt; I'm pretty sure that the semantics of locks extend from the assembler as well. There is a `LOCK` instruction prefix on x86, but it only makes certain operations atomic. True locks need to answer the question "what to do while waiting?" If the answer is "sleep and let some other thread run" that requires a system call. 
Ah sheit. Didn't know that part. Alright, well that part helps me see that I was going to get the next part that I was going to try in the next 5 minutes wrong. Thanks. Thanks for the "that requires a system call"; I didn't know how the service was forwarded up by the machine underneath. I've even put processes to sleep before from kernel land drivers, so I know how interaction with the scheduler works. It's just that I wasn't ruling out the possibility of some assembler semantics based on memory change to fire a signal somewhere.
Maybe I'm too tired, but: why is the `drop` in the tututorial's code needed? AFAICT it's *not* needed and thus should be removed ... ?
x86 is smart but it's not quite that smart. I believe you can put pthreads primitives in shared memory.
There is now a repo for the site: https://github.com/aldeka/rustacean.net - you could open an issue and request svg versions.
Considering that the performance of such an application depends on putting packets onto and receiving packets off of the wire, the minor speed differences you might see between Rust and C++ should be small enough to be hidden in the noise of normal variance in network latency. Are you planning on rolling your own library on top of UDP sockets or using an existing library? I see there is a [raw wrapper for ENet](https://github.com/ruabmbua/enet-sys) that might make a good starting point.
You cannot move pairs out of `&amp;self`. Remove the `&amp;` to consume `self`. https://play.rust-lang.org/?gist=f38d29899c23ec93385b26886dc516fc&amp;version=stable&amp;backtrace=0
I actually had to avoid consuming `self` because the exercise reused my structure instance a few times during a couple of the tests. [Here is the exercism exercise in question, with test cases in the Test Suite tab.](http://exercism.io/exercises/rust/nucleotide-codons) I don't think I can share my solution unless you've solved it too, unfortunately.
Rust is very competitive with C++ in terms of performance for this kind of application. Rust's design and compilation through LLVM leads it to have performance competitive with C++ so your game event loop would be just as efficient. Rust's borrow checker makes it much easier to abstract operations on buffers while maintaining safety and zero-copy, zero allocation performance. Rust's FFI ensures you'll be able to access any native C API you'd need to get the best networking performance. On Windows there is the miow wrapper around IOCP, but you could also make a wrapper around the Registered I/O interface to get ultra low latency, zero-copy async I/O. Mio provides a no overhead interface on top of epoll and kqueue for Linux, BSD as well. 
Would it be possible to have rust stdlib as multiple separate crates? And then std would just reexport them. I think it would simplify things for contributors. For example, when profiling I found that channels from std::sync::mpsc (particularly, sync_channel) spent too much time locking/unlocking. I had to clone the rust repo, take std::sync::mpsc out and search-and-replace stuff to build it, which wasn't a very pleasant experience. (I [replaced](https://github.com/polachok/mpsc) std locks with [parking_lot](https://crates.io/crates/parking_lot) locks, which are about 10% better on my workload now).
&gt; quite common Is it? I've been dealing with Rust code for a while and indexing is not too common (iterators are preferred). On top of that, indexing a constant-size array (not a slice!) with a constant is even rarer.
I'd panic if the str to CString conversion fails as this is nothing that is supposed to happen and can reasonably be dealt with. If it fails, it's an indication of a bug and should stop the program.
I really enjoy the length of these videos.
&gt;This is not some bizarre usecase but quite common I strongly disagree with this. This is specifically a case where you're indexing a fixed-sized array with a constant value. Unless you can provide an example that isn't terribly contrived, I'm going to side with /u/Manishearth and the others. 
I come across this error quite often myself, probably because I'm terrible at coding in rust. Surely *any* errors that can be identified at compile time should be? The quicker errors are recognised the better. I'm a bit of an amateur though, so I don't know really.
Quite a bit. You can see some benchmarks on the PR: https://github.com/rust-lang-nursery/regex/pull/231
Wow! That's incredible!
OP's code is not exposing a C API for a Rust library, so it's OK to panic.
I disagree. Returning a `Result` seems correct here. The string could be provided by an end user, for example. In particular, perfectly valid UTF-8 can cause `CString::new` to return an error, which would in turn cause the program to panic given your suggestion (e.g., if the text contains a `NUL` byte). At the very least, it seems sensible for a library function to pass-the-buck on the error returned by `CString::new` in this case.
Yeah, looks like "\0" can result in an Err here, so I guess you are right. Seems weird how an "implementation detail" leaks out towards the signature though, as this would not be the case with a pure Rust implementation.
Yeah, there's some other things potentially amiss here too. Looking at the [C implementation wrapped in this library](https://github.com/JanLikar/levenshtein.c/blob/658921da844024a9df0bcee23706dee6248380f0/levenshtein.c), it looks like it "just uses a C string." So there's really no defined encoding in the interface other than "every byte is treated as a character in terms of edit distance." Technically, a pure Rust implementation of the same algorithm would actually have the same type signature given the same input parameters (which notably don't include the string length). Of course, that's a little wonky since if you were doing this in Rust, you might do it [like this](https://github.com/dguo/strsim-rs/blob/master/src/lib.rs#L187), which reports edit distance in terms of Unicode codepoints. Still not quite correct, but probably more correct than every-byte-is-a-character and a decent enough compromise in general IMO.
&gt; Rust is often marketed with "all errors are caught at compile-time." Shouldn't be because that is logically impossible. 
The idiomatic spelling is: for &amp;pair in &amp;self.pairs { println!("{:?}", pair); } If you have a reference to a structure, `r`, `&amp;r.field` shifts that reference to just point at the field. `&amp;c` on the left side of a pattern assignment (i.e. `let &amp;c = ` `for &amp;c in` and `match { &amp;c =&gt;}`) causes `c` to be initialized with a copy from a borrowed value. 
&gt; description is owned by the err object Shit, right. So I'd have to return the entire object? Thank you for your help. Returning &amp;str wasn't the best idea anyway, I guess.
Incremental compilation (file-by-file instead of crate-by-crate) is coming soon. Might make this kind of work painless enough. `parking_lot` is pretty cool, I gotta say. It'd be interesting to compare the pros-cons of using that approach in the standard library. One concern I'd want to figure out is this: Rust doesn't have the concept of "unmovable values" - i.e. this value will always be at a specific location. Thus keying thread queues to virtual addresses might not be sound. I suspect that it is in fact sound, but it deserves a look from people smarter than I am. 
I think the problem is that only a small number of rarely occurring index errors can be caught at complied time: those which are in a fixed size array with a constant index. I would think it would be even more confusing if the examples had errors which were caught at complied time, but none of the actual programs you would write would be able to catch this. If you expect an out of bounds error to be compile time, you won't account for the many, many time in which the compiler can't tell.