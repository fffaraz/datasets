Watch [this video](https://www.youtube.com/watch?v=hmX2s3pe_qk)!
I would check out Debasish Ghosh's [book](https://www.manning.com/books/functional-and-reactive-domain-modeling) and [blog](http://debasishg.blogspot.com/).
In FP, there's denotational design. The following slides by Conal Elliot is based in Haskell but it should translate to Scalaz: http://conal.net/talks/denotational-design-lambdajam-2015.pdf If you're in the OO camp, the above may not have a lot of value. 
It helps a little bit, but not much: nothing stops one from not using an alias, and the IDE would normally show a popup suggesting that the expected type is `Car =&gt; Boolean`. I think it is also important that almost all the injected services are only implemented in one class; tests inject mocks (I hate mocks, too, but for that instance they are useful). So code navigation usually gets you exactly to the actual class — in a single click!—making it clear what code runs and why. Navigation to `apply()` is, well, not exactly as easy. I feel it creates more problems than it solves: instead of one type, you now have two. YMMV, of course.
&gt; because idiot code is the simplest code possible that gets the job done. Idiot code will generate far higher creation/maintaining costs just as overcomplicated code. But Clever != Overcomplicated and Simple != Idiotic. But Simple == Clever. Think twice before being a [KISS radicalist](https://en.wikipedia.org/wiki/KISS_principle). &gt; To have the exact same symbol represent 15 different things in 15 different contexts is complicated. The underline symbol mostly represents the same: the 'wildcard'. Anyway, it isn't a problem.
No, this is a compiler plugin, so you can use it with whatever build system you use. You just need to add an -Xplugin:clippy.jar option. There is an SBT plugin provided for convenience as well, which does that automatically.
&gt; The problem with business people is that they lack analytical skills and the problem with developers is that they don't have the inclination to understand the business. Get some skilled developers willing to talk with non-technical people, get some skilled business guys capable of understanding the technical side, put them in a room, problem solved. We have this thing called "analysts". They form a layer of separation between users and developers. I have yet to decide whether they are an aid to communications or a hindrance. I expect it will end up depending on the analyst/situation.
In my opinion an extra layer is much worse. A big part of the process is negotiating what can be implemented and how. Analysts lack context about how the implemented system works internally, about what's possible to implement and they lack deep knowledge about the business as well. They often can't foresee conflicts in new requirements and already implemented features, they often can't simplify those requirements and they often do a bad job of explaining the technical side to the business people and the business side to the technical people. You get the worst of both worlds imho. Business analysis should be in my opinion in the job description of every software developer, because you can't offer good solutions without deep understanding of the problem you're trying to solve and without offering suggestions directly to those proposing the features.
I'm all for naming things explicitly and self documentation. But when that name is just going to refer to the singular of a name you can already see, it's not adding any documentation to the process. But ultimately, it's a stylistic concern. Just do it your way if you like. 
From this well-written post: &gt; If and only if I could, hypothetically, write a matchless fold, or use an existing one, and rewrite this in its terms, this pattern match is safe. I don't fully understand. Could someone please give another example of when it is safe versus is not?
Vague question is vague, so here is a very general answer: Type Driven Development. AKA: TDD, Type Directed Development, Type First Development, and "the thing programmers just do without having a name for if they have a sufficiently strong type system". Not to be confused with: TDD (Test Driven Development) 
What errors are you getting? I didn't use Android Studio proper, but I did setup an IntelliJ + Android Support + Scaloid project a few months ago. I didn't write down instructions but I might be able to help resolve any lingering issues you have.
All of your complaints are much more valid in a language that doesn't have type checking. The principle of least astonishment is a requirement in a language where you don't get immediate feedback if you do something wrong, as the cost is much higher (bug is found in automated testing, or worse, QA/Production). When you have a compiler, it's much less important to decrease your lack of surprise, and instead maximize the kind of expression you need to type check. What you wrote here is a perfectly reasonable 'criticism' for someone new to Scala. You *could* write your apply method similar to your last one: def apply(a: TextType, f: TextType =&gt; Writeable[TextType]): Result But that's not what the original does. It's not bound on any particular text type. It's a type class not, as milyardo points out, a context bound. Look, most people get pissed at the Scala language at first for the same reasons you're pissed. (A few get pissed for different reasons if they come from OCaml or Haskell). But at a certain point you're going to have to decide if we're all either lunatics, or trust us that we've been there and if you embrace the scala way, it starts making a lot more sense *eventually*. 
It seems vanilla Intellj is preferred. https://github.com/pfn/android-sdk-plugin The primary IDE recommendation is IntelliJ, not Android Studio nor Eclipse. 
The underscore is not just a stylistic concern. It's also a type inference concern. Let's say you have a line of code that takes in a function like " _ == 'text' ". The compiler cannot infer whether "_" is a String or an Int, but you pass that function in place of a parameter that expects a function that takes in an int, so the compiler infers indirectly that underscore must be type int. All good. But what happens when you need to re-use that function somewhere else and so you pull that function out of the parameter position and assign it to a variable? Well that variable isn't going to have the right type signature anymore and so when you try to pass it back into the original param, the code won't compile and will throw a weird type error. In essence, this: doSomething( _ == "text" ) Is not equivalent to this: val func = ( _ == "text" ) doSomething( func ) I don't know about you, but I find this behavior surprising. Note that this: doSomething( (myJSON: String) =&gt; myJSON == "text" ) is the same thing as this: val func = ( (myJSON: String) =&gt; myJSON == "text" ) doSomething( func ) Much better 
&gt;Wrong. The principle of least astonishment is valid everywhere Everything is a tradeoff. Python makes this tradeoff constantly, but also discourages almost any useful abstraction. There's a reason people don't really build big systems in python. &gt;The thing is, I'm not really that new. I mean I programmed in Scala for six months in college plus a few months after college. And even after eight months, when I'm reading Scala code, I'll see something like this So how many years are you out of college? It sounds like you are pretty new to the industry, so I'm a little surprised to see how defensive and unwilling to listen to so many others in this thread. &gt;But the thing is, it takes a lot of training to get to the point where you can glance at something like that and go No, its a type class. I don't understand what is hard about it. &gt;Compound that with the Haskell developers who bring with them two and three letter variable names and you're on a crash course for legibility pain. There's nothing wrong with single letter variable names if the method is generic. What could you possible name the variables otherwise? I work on a very large scala team. We are able to quickly review each others code, jump in, make modifications, easily understand what is happening, and be *very* productive. The expressivity of the type system is what gives us this advantage. 
I posted this a while ago, hopefully it can help clear things up https://docs.google.com/presentation/d/1CNGLH5ZfQlMC8di_eXM0Lkq0KTtNloLGj_-SKQ0MJnM/edit?usp=sharing
I think there are two good uses for implicits in scala: * Encoding typeclass constraints and deriving instances. * Bedazzling existing types with new operations. I have an example of these uses [here](http://tpolecat.github.io/2013/10/12/typeclass.html). At the end where I'm deriving typeclass instances inductively I think you will see a benefit. It's not just saving typing, it's using the compiler to figure out what you need to type. I don't like implicits for: * Magically converting between types. * Passing configuration arguments (sessions, "contexts", etc). In the first case conversions can happen by mistake, allowing code to compile when it really shouldn't. If I wish to treat a `String` as a `Woozle` I prefer to use an implicit conversion to add a `.toWoozle` method to `String`, rather than providing a direct conversion. In the second case (passing configuration implicitly) you are missing an opportunity for abstraction. Instead of `def foo(a: Int)(implicit c: Context): X` I prefer `def foo(a: Int): Context =&gt; X` which gives me a type that composes in useful ways. This pattern is called the Reader monad if you want to google around for it. In any case, implicits are often misused and this can quickly lead to confusion and suffering. I suggest joining the `#scala` IRC channel and/or the `scala/scala` gitter channel where there are a lot of friendly people who can help you work through specific problems.
I wish people defining implicit conversions would at least read [this](http://repository.cmu.edu/cgi/viewcontent.cgi?article=2276&amp;context=compsci).
PPrint is very nice, but I could find no examples that deal with case classes. Given that our style guide encourages using case classes (foo.bar.baz is easier to comprehend at a glance than foo._2._1), sadly, we can't really make use of PPrint. Any advice?
According to the page I linked, it _does_ work with case classes (as of v0.3.7). There is an example in the REPL session at the very beginning.
Thanks, missed that. Very nice library!
Be super careful with scredis. The driver is multi-plexed and has some existing issues that cause it to return incorrect data under certain circumstances. See: http://techblog.appnexus.com/blog/2015/09/29/the-scredis-driver-malfunctions-in-pathological-environments/ and https://github.com/Livestream/scredis/pull/51. Running into this bug and trying to figure out what _exactly_ was happening was not fun (see tech-blog post)
Also, it seems they don't have any unit-tests around their multiplexed IO that I can tell, so more bugs like this may exist. Suffice to say, we no longer use this driver in production. We are currently using Jedis (synchronous java library). We haven't done much performance tuning with it so out overall throughput is now lower, but our application response times are unchanged.
Re-posting since now there are SBT installation instructions, so that you can quickly play around with the library.
http://scalarelational.org/scalarelational/latest.html#appendix-benchmarks for benchmarks
 The project is very interesting. As I've seen it the query generation is done at compile time(that's why /u/argv_minus_one is [upset ;)](https://www.reddit.com/r/scala/comments/43ne51/scalarelational_a_typesafe_sql_lib_performance/czjjdpn)) which is good. But the inserting and the modelling seem to be boilerplate-ish just like in slick. Is there a plan to improve it?
Hello. I try to create few class for make some background task. I want to make something like that: val task = new MyTask() where MyTask extend Future class. I am try to write FutureAdapter with some dummy implementations for abstract method. class FutureAdapter extends Future[Unit] { def isCompleted: Boolean = false def value: Option[scala.util.Try[Unit]] = null def result(atMost: Duration)(implicit permit: CanAwait): Unit = () def onComplete[U](f: scala.util.Try[Unit] =&gt; U)(implicit executor: ExecutionContext): Unit = () def ready(atMost: Duration)(implicit permit: CanAwait): FutureAdapter = FutureAdapter.this } When I try to compile project, I get error: overriding method ready in trait Awaitable of type (atMost: scala.concurrent.duration.Duration (implicit permit: scala.concurrent.CanAwait)FutureAdapter.this.type; method ready has incompatible type def ready(atMost: Duration)(implicit permit: CanAwait): FutureAdapter = FutureAdapter.this What I am doing wrong? What I should use? I want to write something like that: class MyTask extends FutureAdapter { //some code } I should not make this with Future? What I should return from ready method?
I'm trying to use AppDynamics with a Scala Play application but the response times for my endpoints always show as 1 millisecond, as opposed to the more accurate 20-60ms. I think that AppDynamics isn't capturing the results of the Futures? Furthermore the exceptions caught don't tie back to end-points. Has anyone seen this and know how to resolve it please?
Great question! What it seems like Slick is not describing very well is what behaving like the collections library buys you. One thing is, of course, familiarity, which is certainly a nice-to-have. The key thing, though, is that, like collections, queries are monads, the benefit of which is that you can compose them using for-comprehensions. This gives you a kind of mix-and-match capability, even though, under the hood, you ultimately still end up with a `PreparedStatement` with all of its security, caching, etc. benefits. Finally, this has been integrated with Akka Streams, so some of the blocking behavior of the interaction has been obviated. JDBC itself is blocking, so there remains no free lunch, although non-blocking alternatives are being developed. We'll see how that goes.
For referencing ordered collections, should I be using the Seq interface, generally, or should I use List or something else? 
What are you trying to accomplish? If you are not trying to override any behaviours of Future. Just use an implicit class. Put any Functions to wish to extend Future in that class. 
Hacking the Scala compiler is hard and the Typelevel folks probably have their hands full at the moment, given the last year's explosion of activity in other Typelevel projects. But btw, such questions should probably be asked on Typelevel's official communication channels ([see them here](http://typelevel.org/about)), since that gives a better probability to take the real pulse and receive a knowledgeable answer, plus ways you can help if interested, versus Reddit.
There is likely to be more focused effort this year. We are having a summit in a month and this will certainly be a big topic of conversation.
I wonder if this is related, currently cannot grab slick-extensions 3.x.x via sbt anymore. Its missing off bintray, yet I see no follow up release. So, can't build our code on fresh machines now. Anyone know when they may release updated packages that include the drivers?
Thank you. I did not think about it. It looks and works great.
The most general form is `Foldable`, the typeclass of things you can fold. ``` def sum[F[_]: Foldable](fa: F[Int]) = fa.foldLeft(0)(_ + _) ``` However, it makes much less sense to put a foldable-only F in return position. The broader problem is that the rules of universality for arguments of a function are opposite to those for return values. So there cannot be any one-size-fits-all, because List -&gt; Seq adds generality on one side and removes generality on the other. Same for Seq -&gt; List. I recommend that you learn about the use of type parameters for the *Like traits in the collections library, how to work with `CanBuildFrom`, and how to use type classes that characterize different aspects of collections, if you wish to maximize your generality. These are tools for being precise at the type level about what attributes your functions need to implement their behavior correctly; that's exactly what is needed for the most general abstractions. I strongly recommend against any "just use Seq" rule of thumb.
Generally, `Seq` works well enough. Lots of people will complain about how they can be lazy, or infinite. These are real problems, but despite that I find it works well enough in practice: I don't remember the last time I ran into bugs that involved lazy or infinite `Seq`s. My general rule is: - `Seq` is a default - `IndexedSeq` or `Vector` if you want something that has `O(1)` index/random-access lookup - `Set` if you want de-duplication or fast-contains - `List` if you want really-fast, immutable construction (`a :: list` is faster than `a +: vector`, but still immutable) - `Iterator` if you want to avoid creating intermediate data structures - `scala.Stream` just about never. It's slower than a `List`, takes more memory than a `List`, creates just as many intermediate data structures as a `Vector`, isn't really lazy (e.g. `.filter` can cause an arbitrary number of things to evaluate). - EDIT: `Iterable` is also basically never what you want... at least I've never wanted it. The scalaz/typelevel people will tell you to use a `: Foldable` typeclass, but I've never used it so I can't comment other than to say I've written a lot of very useful Scala and never found myself wanting it. I've almost never needed to fiddle with `CanBuildFrom` or care about the `*Like` traits. You can probably ignore them and just use `Seq` everywhere.
Looks OK for me: http://dl.bintray.com/typesafe/commercial-maven-releases/com/typesafe/slick/
No? It seems to be just a layer on top of Finagle. I'm not sure what framework you're talking about.
AFAIK, yes. It uses annotations and, I guess, reflection.
Probably a mix of things. FreeSlick's been a bit of a PR thorn for TypeSafe, and maybe they're not making a whole lot off the paid driver model to justify keeping the source closed. Beyond that, Zeiger's been AWOL of late wrt to maintaining Slick due to TypeSafe needing him to help out on the Scala 2.12 compiler (which is 6 months behind schedule). Allowing community commiters opens up Slick itself, which means longstanding bugs/deficiencies may get addressed rather than languishing for months/years ;-) We shall see, Slick codebase is, to put it mildly, complex. Not sure how many Slick users will be able to step up to the plate and deliver high quality PRs for non-trivial issues. Regardless, OSS'ing Slick across the board is a good move on TypeSafe's part for the long haul.
You can do: Action(parse.json[Foo]) { implicit request =&gt; val foo: Foo = request.body // ... } It'll return BadRequest if the reader fails
oh very cool! I didn't know this was a thing. And if you have some implicit converts you can appear to return something that is not a Response object. I like this.
Don't take this as an official statement, just a personal comment on the situation: As a small company with big growth ambitions, you have to pick your battles carefully. And while most apps need to connect to a relational database for some of their data (even if it's mostly NoSQL / big data stuff otherwise), it's just not an area where you expect a big growth by investing a lot into the technology. A larger emphasis on the community, including the open sourcing of Slick Extensions, is simply a consequence of a lower investment on our side (which means, as many may have already noticed, that I'm not working full time on the project anymore).
No compiler plugins as of yet, but that's a good suggestion, thanks! Currently, I've implemented everything as a Scala DSL. The use-case is incremental computation (think spreadsheets) together with cryptographically strong authentication. I understand that not everybody is super interested in those properties (yet!). Probably if I recast SPREAD as being 'purely functional reactive' people would be more interested :) But the real revolutionary thing is the SplitHash data structure. Just take a look at the repo to see what it is about.
The Typelevel projects, like many other projects in the ecosystem, are being built by down to earth individuals, mostly in their spare time and not by companies. There are no marketing departments to speak of. I don't understand the "real street" argument, but it does touch a nerve, so let me be honest ... I'm not speaking in anybody's name, but it's a pretty known fact that Reddit is a cesspool full of trolls. As a consequence, many people in the Scala community don't participate in the discussions here. How that happened, I don't know, but you can get a hint from the upvotes you got for a comment that is basically insulting. Cheers mate,
As an side, per your example: case class User(name: String, email: String, userName: Option[String]) In what cases would it make sense for `userName` to be `null` rather than present or absent? Understood that JSON spec allows `null`, but I'm curious when you'd use `null` rather than leaving it out completely, i.e. `None`. Lastly, I would consider modeling such a response as: sealed trait User case class UserType1(name: String, email: String, userName: String) case class UserType2(name: String, email: String) I'd be interested to hear your response/thoughts.
&gt; I was just making the point that Python is MUCH more readable It is on a per line basis, but not in aggregate. I'll explain what I mean shortly. &gt;and has a minimal learning curve and that adds a lot to the languages appeal and that maybe Scala should try to be more readable and try to reduce its learning curve wherever possible. I think you're touching a nerve here because you are conflating a few different things. *YES* Scala needs to simplify, some things are design flaws/warts that need to go away. **HOWEVER**, some of the things you assume are flaws, end up being powerful. Yes they have a steep learning curve but they will make you more productive in the long run. Your example on context view bounds is perfectly valid, maybe Scala doesn't need two ways of doing that. Your other example on different ways of calling a method is another complaint that others showed Scala is already in the process of simplifying. &gt;But there is something wrong with one, two, three letter variable names literally everywhere else. Not when you're writing abstract code :) This is the area a lot of folks coming from everywhere but Haskell (like me, for instance, since I came from Java land) struggle with but come to love. What else could you name the variables in this function: def foldMap[F[_], A, B](fa: F[A], f: A =&gt; B)(implicit F: Monoid[B]): B It doesn't make sense to call them anything else. This goes back to why I said python is 'simpler' on a per line basis, but not in aggregate. Once you get familiar with the type class pattern and higher kinded types, you can start writing code (or using Scalaz or something else) and i will save you *thousands* of lines of code. You might use the above trait in 5 different places in your code base, but you only need to understand it once. Where in python, you'd have to write the same(ish) function over and over and over, each time a little bit different, test each time, etc. Small, powerful, abstract functions *do* take much longer to read/write, but in the long run they're a net win. &gt; Also, I had to put intelliJ in a RAM disk just to get an acceptable level of responsiveness. And I also had to give up my favourite IDE to switch to intelliJ because the pop-up documentation and auto-complete in the IDE is so indispensable for learning all the functions and classes on the job. These are fair complaints. A newbie to Scala is going to be less productive than a newbie into another language. There are definitely times where it's better to use another language. But there is *power* there in the type system that is very useful (and fun!). 
Or you could use Option[Option[String]], if you don't mind Some(None) being the json null...
Or, and I'm just putting this out there... you could use a faster drive, like an SSD, and save yourself all the hassle. 
Also, Linux's `tmpfs` implementation details make copying anything manually to it almost always pointless. It uses the page cache to store it's data, exactly as any read from a filesystem in permanent storage would do for caching. In many cases all you get is double-caching by removing the association between the data in the cache and in the disk. source: [kernel documentation](https://www.kernel.org/doc/Documentation/filesystems/tmpfs.txt) Reading all the files in the IntelliJ directory so the cache is warm when you next want to use them should achieve the same or similar performance gain without most of the inconvenience. Incidentally, opening IntelliJ is a good way to do just that. edit: It's possible to observe the page cache at work with the [vmtouch](https://github.com/hoytech/vmtouch) utility. Before running IntelliJ: $ vmtouch intellij-idea-15 Files: 3630 Directories: 1313 Resident Pages: 0/192948 0/753M 0% Elapsed: 0.05082 seconds Started IntelliJ, marked 16.5 seconds until my last opened project was visible and syntax highlight turned on. Afterwards: $ vmtouch intellij-idea-15 Files: 3630 Directories: 1313 Resident Pages: 95274/192948 372M/753M 49.4% Elapsed: 0.050738 seconds So only half of all IntelliJ data was used at first load. Curiously I saw no change at all in the loading speed: it seems I wasn't I/O bound (which is a nice confirmation that SSD is being worth it's weight - a Samsung 850 PRO 256GB). But there were no changes to the cached pages, so it's likely that all the reads hit the cache. It's possible to force the whole directory to be cached, which seems easier than all the copying: $ vmtouch -t intellij-idea-15 Files: 3630 Directories: 1313 Touched Pages: 192948 (753M) Elapsed: 1.0628 seconds 
You could do EitherT[Option, JsonNull, String]. Then you can get for comprehension right down to the 'string' value. 
&gt;1. But why is (LoginRequest.apply) map to data? LoginRequest seems to be an interface without any actual data The term `(LoginRequest.apply)`isn't applied as a second parameter to `Form`'s constructor, rather it seems the function `mapping` has multiple parameter list. The [companion object](https://github.com/playframework/playframework/blob/master/framework/src/play/src/main/scala/play/api/data/Form.scala#L346) of `Form` has an apply method with 1 `mapping` parameter which is the factory method used in this example.
[removed]
&gt; Does apply method in companion object always have precedance such that it can hijack the constructor call? Kinda. An instance `thing` with a method `apply(x: Int)` can always be called like `thing(1)` instead of `thing.apply(1)`. Likewise, `object Foo { def apply(x:Int) = … }`can always be called like `Foo(1)`. This is because an object **is** an instance: A singleton-instance. &gt; However I am still confused &gt; `case class LoginRequest(username:String, password:String)` &gt; doesn't have a apply function or an unapply function? Scala autogenerates an .apply and .unapply method (among other things) for case classes. This makes them suitable for use in pattern matching as extractors.
In addition to @sjrd's answer... what would a reliable Java-to-JS compile be? Just curious...
Have you tried using vmtouch to lock a sbt project into ram? Does it speed up compilation much or does ~test keep enough in ram to not really be an issue.
All good points, thanks!
I think I get the general concept, but it would be good to have more use-cases. It seems related to Bitcoin and Merkel trees, where you can guarantee that the result of your code (with its final hash) contains specific computations because you can verify that their hash contributed to the final hash. Right? As predef said, it would be better if it was automagically added to ones code, or called via annotations or something. The %/!/~ would get messy quickly. Just my two cents.
&gt; Hey look, I can understand this. It's a container with a transformer and we're folding the container by applying the transformer. Horrible idea. You just made the code way more unreadable. Container is not a type, it's a type constructor, and you didn't distinguish that at *all*. 
I'm getting performance of ~60% of Spray, which is a significant improvement over what I got for the previous version (~10% of Spray).
It's an interesting concept. Maybe this could be used in banking. I'd stick to Scala if I were you as you'll get much more of an audience. Maybe you could use something like AOP http://stackoverflow.com/questions/5025700/can-i-do-aspect-oriented-programming-in-scala or just use Scala implicits. I'd imagine this functionality would most likely be called at a function level, and not within the same line in the same expression. Something like this: class Interest { @addHash def calculateInterest() = ??? } class Fees { @addHash def calculateFees() = ??? } @finalRootHash def calculateTotal() = currentAccountMoney + interest.calculateInterest() - fees.calculateFees() Your lib would then be able to certify that fees.calculateFees() contributed to the final value of calculateTotal() 
If that's correct then from now on I'm using that exact syntax from now on. That's EXACTLY what I mean. Explicit is better than implicit.
This is true for pattern matching, but I'm not sure how you would define `map`, `flatMap`, `forEach`, etc. without specializing toward the right-most type (`String` in your example) which would get you pretty close in semantics to what I have.
Oh, I just googled `EitherT` and saw it was something that exists in scalaz. So what I just said above probably doesn't make any sense because I'm not familiar with the class. I thought you were just making up a type. My mistake! So, I guess this is something I'll have to look more into. Link for anyone else not familiar [here](http://docs.typelevel.org/api/scalaz/nightly/index.html#scalaz.EitherT)
&gt; My mistake! So, I guess this is something I'll have to look more into. No problem. You can always ask questions on #scalaz or tweet to me or the other Scalaz folks. EitherT is kind of the gateway drug to Scalaz. You don't really need to know how anything else in Scalaz works to use it. I don't really think it's *better* than your approach, just a different one you could take (with different pros/cons). /u/noel has some great tutorials http://underscore.io/blog/posts/2013/12/20/scalaz-monad-transformers.html
We've been packaging using Docker, and deploying to Kubernetes. I've got a [minimal sample project](https://github.com/vyshane/klusterd) that uses the sbt native packager Docker plugin and also contains sample Kubernetes manifests. It also sets up Akka Cluster peer discovery.
I work at a bank which was a big source of inspiration! I like your annotation idea, because it is not so intrusive as all the other options (compiler plugins, macros, etc). Thanks for the suggestion. 
Personally, I'd look into building your app with [sbt-native-packager](http://www.scala-sbt.org/sbt-native-packager/) and using [Terraform](https://www.terraform.io/) to manage your deployment.
I used that for a while in one of my projects, but I ripped it out and put in macwire for DI instead. I found it simpler to reason about dependencies and easier to test using Moq (though some would argue Moq is code smell).
It's an architecture smell in the sense that what you're saying is: this trait _must_ be mixed in with a DatabaseService, solely for the purpose of having a DatabaseService in scope. In other words, you're modeling an IS-A relationship when all you want is a HAS-A relationship. I personally wouldn't bother with any sort of DI approach here; I'd just have the trait have an abstract `DatabaseService` member. If you want to go on from there, I suggest going ahead with a `Reader`/`Kleisli` to get the `DatabaseService` in whatever context you need it in.
This is fantastic. I love Scala even with most of its warts but it's been sad seeing soundness issues and bugs in the language itself discovered over the past few years mostly go ignored. It doesn't exactly fill you with faith or confidence. This blog post implies that the reason for the neglect hasn't been *"fuck it, mostly works, good enough"*, it's actually been *"this is hard and there's no point fighting each small fire; let's fix this from the ground up"*. I respect that. 
This usage of the self type is a example of unnecessary coupling. Like /u/paultypes mentions there's no reason dbService can't be a normal abstract def. However, if PeopleRepository were more general, ie it was of the type `Repository[People]` then a self type annotation in some other trait composing Repository would be useful. trait Repository { type Entity def db: DatabaseService def fetch: Seq[Entity] = ... def get: Entity = ... def put(e: Entity): Unit = ... } trait HasFriends { repo: Resitory { type Entity &lt;: Person } =&gt; //constrain Entity to some Kind of Person def friends(p: repo.Entity): Seq[repo.Entity] = ... }
What are you trying to do after a test? Each test should be independent.
I agree, I wasn't so much asking him as giving him a chance to either say something more substantial as I like Haskell for what it is and possibly make it clear to any newbies that his comment wasn't something to give any weight too. 
If you mean `(xs = ys) =&gt; (xs.foldMap(List(_)) = ys.foldMap(List(_)))`, then no.
This is only the first blog post of a series, I assume at some point union types will be derived from the calculus illustrated here.
Scala exploded a lot in the span of 5-7 years, with heaps of features being added into the language (and only some we are removing now), the result is what we have now. I think the general opinion is that, right now, Scala is as good of a spot as you can be, and any non trivial incremental effort to fix issues would most likely require ridiculous amounts of time
I was wondering about the purpose of Section 6 of the linked paper: &gt; In this section we show by means of an example that path-dependent types are themselves a useful programming concept. Indeed they are useful. However, the more important question is are they necessary or more useful than existing mechanisms? The example does not really illustrate this well. Aside from requiring slightly less syntactic noise it does not really seem too different from an implementation with generics, i.e.: trait Key[Value] trait HMap { self =&gt; def get[Value](key: Key[Value]): Option[Value] def add[Value](key: Key[Value])(value: Value) = new HMap { def get[V](k: Key[V]) = if (k == key) Some(value.asInstanceOf[V]) else self.get(k) } } object HMap { def empty = new HMap { def get[Value](k: Key[Value]) = None } } The comparison with Haskell mainly highlights terseness (Haskell's one "expresses a dependent method type with an additional polymorphic parameter"). Was that the main point? The second point about extensibility seems somewhat contrived (though true) since it stems from a comparison with a non-OOP language, and the third one about monadic key creation as well. A comparison with an implementation in Java would not have revealed this advantage. interface Key&lt;Value&gt; {} interface Hmap { static Hmap empty() { return new Hmap() { public &lt;Value&gt; Optional&lt;Value&gt; get(Key&lt;Value&gt; key) { return Optional.empty(); } };} &lt;Value&gt; Optional&lt;Value&gt; get(Key&lt;Value&gt; key); default &lt;Value&gt; Hmap add(Key&lt;Value&gt; key, Value value) { return new Hmap() { public &lt;V&gt; Optional&lt;V&gt; get(Key&lt;V&gt; k) { return k.equals(key) ? Optional.of((V) value) : Hmap.this.get(k); } }; } } I know that what I describe above is not the main point of DOT (as type parameters are turned into PDTs anyway), yet I think Section 6 could be further clarified. In my (very limited) experience PDTs are more useful (i.e. special) when it comes to inner classes, not type aliases. But maybe I am missing the point...
I find the pattern matching variant most readable. Unfortunately the Scala community doesn't always prefer readability ...
[Here](http://lampwww.epfl.ch/~amin/dot/scaladays-slides.pdf) is some slides introducing DOT from 2014 (don't know if everything is still valid). [On Dotty](https://d-d.me/scalaworld2015/#/), the actual compiler based on DOT (mostly talks about the implementation, less about the language). Do you know if there is a simple break-down (slides) of Idris available that one can grok fast?
Thanks. The [Idris website](http://www.idris-lang.org/example/) is quite clean with some examples. There is a link to a [short course](http://www.idris-lang.org/dependently-typed-functional-programming-with-idris-course-videos-and-slides/) on the site. 
Pattern matching make the intention more clear than `map` followed by `getOrElse`. I think it doesn't make sense to start a battle here. A usability tests would be better to answer questions about readability, but they are hard to realize.
In this case I'd go with fold. It gives better type safety then get or else. Pattern matching isn't particularly efficient and is overkill when you only have two possible outcomes. 
Very cool use of a type bound I'm not familiar with: `=:=`. In bluntly-applied OO sub-classes sometimes have methods that throw an exception to say "That's not allowed". A horrible solution. Publishing this in interface, so no contract is being broken and it's clear how to use it is awesome! _Edit: Removed suggestions to fix formatting as it's now all fixed — thanks author!_
Thanks, on a further link I found [this tutorial](http://docs.idris-lang.org/en/latest/tutorial/introduction.html) useful to refresh my memory of the implications of dependent types. __Edit:__ So, ..., but I can't tell whether DOT is in any way related to Idris when it comes to dependent types, so waiting for other people to comment on this ;)
It's worth mentioning that some published Scala coding conventions recommend pattern matching for `Option` in some cases. [PayPal recommends pattern matching unless the `fold` is trivial](https://github.com/paypal/scala-style-guide#option)(as yours is). [Databricks recommends keeping monad chains short](https://github.com/databricks/scala-style-guide#monadic-chaining), though I really dislike their example. 
Your match is too simplistic, I wouldn't use it unless you have more conditions. However as far as when to use `map/getOrElse` or `fold` it depends on who will be reading that code in 6 months. For someone who is new to functional programming I'd go with `map/getOrElse`. The intentional of that code is clearer to those you are unfamiliar with monads. After watching [Marconi Lanna's talk](https://youtu.be/ol2AB5UN1IA), that msimav posted. I have to revise my opinion. In light of that talk, before I use pattern matching I would ask myself if what I am doing is better expressed with one of the higher-order functions. 
I was trying to save all the results into a map where actions can be performed on it later. I managed to solve the problem by using withFixture. Currently I'm having the same problem with junit tests in scalatest. It seems like when I extend testwatcher and override the succeeded and failed methods, those methods aren't getting run when tests failed or passed. Is there an way to do what withfixture does for scalatests with junit tests in scala?
I now tend to use `fold` as it's more succinct than `map` followed by `getOrElse` and better represents the intention of an if-then-else. Unfortunately it collides with the type inference, so in most cases you need to write `.fold[A](...)(x =&gt; ...)` and give an `A` because the second parameter list does not participate in the type inference. The advantage of pattern matching is that the Scala compiler will correctly infer the super type of both branches together. Example sealed trait State case object Pausing extends State case class Running(task: String) extends State def test1(in: Option[String]): State = in.fold(Pausing)(Running(_)) // FAIL: found Running required Pausing.type def test2(in: Option[String]): State = in.fold[State](Pausing)(Running(_)) // give up on inference I don't know how to properly fix this. Attempt: implicit class FoldNew[A](opt: Option[A]) { def foldNew[B, C, D](z: C)(fun: A =&gt; D)(implicit evc: C &lt;:&lt; B, evd: D &lt;:&lt; B): B = opt.fold[B](z)(x =&gt; fun(x)) } def test3(in: Option[String]): State = in.foldNew(Pausing)(Running(_)) // yes! ------ __Edit:__ A case where you would need to employ pattern matching is when you write a tail recursive function. __Edit 2:__ Another case for pattern matching is if you want to unapply the value inside the `Some` as well, like `case Some((a, b)) =&gt;`
I think the advice is to create "smart constructors" for Pausing and Running that return State. There may be a macro that does this for you.
Nice talk, thanks!
Honestly I don't know. I haven't done anything that fancy with scalatest
I am surprised that the pattern match gets so little love here. Not only is it by far the fastest (probably at least 10 times as fast as the alternatives), it is also the clearest. What's not to like?
IntelliJ suggests refactoring from map/getOrElse to fold. I personally use fold if the case is trivial, if not I use pattern matching. 
&gt; I guess I just wished the type inference algorithm could look at the expected type more persistently before giving up. I mean if I write If type inference did attempt to LUB like pattern matching does then you'd get instance where `Any` is inferred when you make a mistake, which would be worst than sometimes having to add a type annotation.
This is why I always use scalaz's `cata` instead of `fold`: It has named arguments of `none` and `some` which makes it nice. val cow = foo.bar.baz.cata(none = ..., some = a =&gt; ...) (This was a reply to /u/lihaoyi but I think it is also my response to OP)
Oh wow that is pretty nice!
Fair enough.
Personally I like the obj.map(func).getOrElse(defaultVal) the most. I don't really find it less clear then pattern matching and it's just a one liner compared to 4 lines with pattern matching. 
I always pattern match if there are multiple lines happening in either case, otherwise fold!
I was just watching your talks and noticed one of the things I complained about. https://www.youtube.com/watch?v=kkTFx3-duc8&amp;feature=youtu.be&amp;t=26m15s . Scala programmers tend to use the variable "x" a lot and instead of just calling the variable "key", or some other dictionary word, they say "x" and then I weep.
Also, in that same talk... items +(10) xs map(f) car accelerate(10) xs flatMap(fun) filterNot(isZero) groupBy(keyFn) ^ I would just combine the two approaches (space and parenthesis) into one approach and make that approach mandatory.
In ML-family languages one way to indent sanely would be using local `let` bindings, so in Scala we could do the equivalent: val cow = { val ifNone = { ... } def ifSome(x: A) = { ... x ... } foo.bar.baz.fold(ifNone)(ifSome) } Depending on the names you pick for the sub-expressions, you can express the meaning of an unknown method pretty decently.
It's actually a really strong argument. Readability is super important.
Not sure about Scalatest, but [utest](https://github.com/lihaoyi/utest) could be nice for this. You can launch the tests yourself and it gives you a nice data structure with all the results.
I see how that can be misunderstood. If your application fits a monad patten, i.e. you can use a for-expression over options, by all means do that (except if performance is super important, then the pattern match still wins). But if your use case can be expressed with a simple pattern match, why encode it using fold or map/getOrElse? Note that neither fold nor getOrElse are mentioned in scaladoc's "idiomatic use" clause.
Ah, yes, I hadn't considered that before. I suppose in Scala's case that's literally true for the types that have an `unapply`. Cool!
Will do
"Numeric ::= [0-9]+" ^ Hole crap. This "::=" is ugly.
&gt; "Numeric ::= [0-9]+" ^ Hole crap. This "::=" is ugly. Not my invention: [Backus-Naur Form](https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_Form).
Have you watched Marconi Lanna talk on Options? He points out that the compiler has no problem with: val foo:Any = maybeNum.map(f -&gt; f * 2).getOrElse("No Number") That is type checking is not preserved in `map/getOrElse`. Whereas it is when you use `fold`. Marconi Lanna talk is linked, in the thread if you missed it. 
I have a different question, What about `flatMap/getOrElse`? I often have transformation that might fail on values that might not have been set. For example, in this function it uses today's date if dateStr was None, or if dateStr can't be parsed. def getCatPics(dateStr:Option[String]):JsValue = { def maybeParseDate(str:String):Option[DateTime] = Try(DateTime.parse(str)).toOption val date:DateTime = dateStr.flatMap(maybeParseDate).getOrElse(DateTime.now()) someFunc(date) } I suppose I could throw an exception if the Try fails. And just use a `fold`.
Thank you for that answer. 
Or you could use: def inMonitoredConfigs(configOpt: Option[String]): Boolean = { s = configOpt getOrElse "compile" s.split(',') exists monitoredConfigsStr.contains } Which is probably more efficient since it uses `exists` instead of `.toSet intersect`
Just no. In the play framework I have seen so much code like that break because of changes in the imports or versions. 
What are you talking about?
Thanks for the tutorial. I also found the docs to be overwhelming and always had a hard time understanding all the details mentioned in talks and webcasts about reactive streams in Akka/Scala.
I've watched the talk by now and it is a valid point to use fold. I still find map/getOrElse to be more clear, but thinking about it's probably not worth giving up type safety.
I mean there would be a file with implicits in it and it would work on Play version 2.4.0-M2 and then you bump the version number up to 2.4.1 and it breaks and says implicit is missing. 
Afaict, Scala has dependent types to the extent that it has _path-dependent_ types, i.e. types which are selected from different paths, like `x.T` and `y.T`. cc /u/predef
Well, there is [this proposal](http://docs.scala-lang.org/sips/pending/42.type.html), and as far as I understand, Dotty will have singleton types for string literals (?)
But you are saying that during an update I'm not allowed to set the value to an empty value since you're asserting that 1) `Option` is the correct type and 2) `Option` during update means the value was not supplied (in the case of partial update). If the entity/model allows for `None` values, then you need a way to differentiate between 3 possible states on a partial update: value given, value not provided, value given as `null`.
Nope, asshole
Nice, could you use implicit classes to maintain OO syntax?
On all of my SSDs it takes tops 20 seconds to open and afterwards it basically flies.. I don't see the point in hassling with unstable ramdisks..
To me the important thing is that I get an easy-to-interpret error message when I make a mistake. Not needing type bounds or implicits is just a bonus.
What do you mean by "contribute to Scala?" If you mean the distribution of the language, maybe start by improving some of the documentation. If you mean the Typesafe ecosystem, consider contributing some Activator templates. If you mean the compiler or standard libraries, I don't like to be discouraging, but yes, those really do require quite a bit of expertise. Apart from that, though, publish some open source, write blog posts, and enjoy!
Disk space is not that expensive. I find SBT easier to use and wayyyy better than gradle. It has a lot of other features gradle doesn't, of course. See the documentation. 
Yeah you would think that, wouldn't you? But unfortunately they not only have different types, but they live in different typing universes. I wrote a [tiresome novel](http://tpolecat.github.io/2014/06/09/methods-functions.html) about this. So in some circumstances Scala will perform η-expansion and turn a method into a function (like if you say `xs.map(f)` and `f` is a method) but here the `implicit` will interfere and the `Context` will be demanded at the point where η-expansion happens rather than at the point where the "final" composed function is invoked, which isn't what we want. It would also take an awful lot of type ascriptions to make it work even if you did get rid of `implicit`. So in practice the types are similar but not close enough to be interchangeable in a useful way.
There is a new book, [sbt in Action](https://www.manning.com/books/sbt-in-action), which might help. &gt; costs valuable disk space This is 2016, not 1970 ;)
SSD
Generally, I think it is OK. If it works for you, you can use it. SBT may be the tool of choice because of its incremental capabilities. For example, incremental compilation. It means that whenever you modify some source file, SBT can re-compile your project. Or, it can incrementally run your tests. Or, it can run tests that failed in the previous invocation. Or, it can even launch a web server or your GUI program, so that you will have a very quick edit&gt;observe&gt;edit&gt;observe cycle. And what's important, all of it in a warmed-up JVM. So you don't wait some seconds for it (or gradle) to launch.
Nice article! Why do you use Json.stringify on each response?
&gt; My biggest complaint about SBT is forcing distributed file config... I don't know what this means: you _can_ put everything in a single .sbt file, even for a multiproject. &gt; the % operator, I don't know what it does or why its there. It's documented well [here](http://www.scala-sbt.org/0.13/docs/Library-Management.html). It's just a simple DSL for building [`ModuleID`](http://www.scala-sbt.org/0.13/api/index.html#sbt.ModuleID)s. You certainly can go ahead and use `ModuleID` itself if you prefer. &gt; Also installing yet another build tool for a language that can be build with Gradle seems strange (and costs valuable disk space). A good reason to get rid of Gradle!
I was kidding, but I find sbt quite a bit more sane than Gradle. When I took over [spring-scala](http://hub.darcs.net/psnively/spring-scala) I switched it from being a Gradle project to an sbt project, partially for my own sanity, and partially because in the (unlikely) event of anyone else contributing, they're overwhelmingly more likely to know sbt than Gradle. But again: mostly, I was kidding with that last part. **Update:** [This](http://stackoverflow.com/questions/11061938/comparing-sbt-and-gradle) comparison may be helpful, but it's several years out of date, so the situation with both tools has no doubt improved.
I'd expect singleton types for objects in general. But DOT papers never mention singleton types, so I don't get if they're easy to add, they can be encoded, or its something they left out.
I'm about to write a DSL compiler using Scala Parser Combinators. The DSL gets translated into Java source code (or Scala source code). The DSL has "closure" blocks which map 1:1 into methods, i.e. the closure block should become a method block "as is". Are there parser combinators "out there" which I can use to parse a Java block or Scala block? Ideally, the parser combinator would produce an AST snippet of what it accepts.
It shouldn't be. Play JSON is its own library. The code in the post is pulling in all of Play WS, which is heavier than needed. (N.B., Play WS isn't nearly all of Play though.)
Here http://nordicapis.com/building-a-rest-api-in-java-scala-using-play-framework-2-part-1/ :D 
Why would you possibly use mysql...
[FastParse](https://github.com/lihaoyi/fastparse)? NB: it includes scalaparse as a subproject. It's used by Ammonite REPL. Seems like what you want.
It looks like they got it wrong in the article, Dotty doesn't seem to be something that will supersede or otherwise replace Scala: http://www.scala-lang.org/blog/2015/10/23/dotty-compiler-bootstraps.html
luckily I never encountered a scalac bug and I'm using it in production. I'm also quite pumped for the new dotty features
*You* may be afraid, but I'm jumping to Dotty when it becomes suitable for production. Scala is dead; long live Scala!
Sounds like /u/zyg_fryd (suspended), trying to [replicate a misguided comment](https://www.reddit.com/r/programming/comments/445jih/jvm_languages_news_kotlin_10_release_candidate_is/czou3jh).
well, this post was intended to a full webapp, where you are already using Play. Of course, using Play for a simple command line may be 'a little heavy handed', but Play has been making a nice job into splitting the framework in several modules as @excitedrustle pointed out
Oh, why has he been suspended?
is the dotty compiler is passing a negative sentiment of un-certainity of Scala in the future. I hear people complaining that typesafe is not concerned about fixing issues in the compiler rather they are working on improving dotty. On the other hand I doubt whether dotty will be replaced by Scala in the coming years.
that's a DB war, and not really the point of this post. I work with postgresql daily, so I decided to try MySQL :)
No idea. I'm just guessing it's the same person. __Edit__: Don't know what this guy is doing, he/she seems to run into [the same procedure](https://www.reddit.com/user/moon_spider) ;)
In short, scala community does have a troll who constantly spreads disinformation.:( More precisely, read the full comments on the original post of course.
I'm actually pretty curious what these people are doing to encounter _compiler_ bugs all the time. I don't think I've ever seen one in the wild.
may be... but looks like they are going to maintain 2 branches like python 2.x, 3.x... where scala will get new features from dotty and it would be a plus if they are backward compatible. dotty will be new experimental playground but still stable enough for production.
What I would like to see is an ecosystem of innovations developing around scala.js. ClojureScript has core.async, Om &amp; Om Next, cursors, Reagent, [Reframe](https://github.com/Day8/re-frame), [Datascript](https://github.com/tonsky/datascript), [transit &amp; edn](https://github.com/cognitect/transit-format). I am excited to see what ideas and projects Scala.js makes possible. Are there any yet? What new ideas will [modeling React.js state in a state monad](https://japgolly.github.io/scalajs-react/#examples/state-monad) make possible?
This is rather specious argument. DOT represents a language/compiler that's based on logic and mathematics. How could precise semantics in a programming language ever be bad?
I guess new ideas are mostly type-based: * [Scalatags](https://github.com/lihaoyi/scalatags) provides type-safe HTML fragment construction * uPickle, BooPickle, Prickle and others provide 100% reflection-free serialization (scala-pickling needs reflection, at times) * [Autowire](https://github.com/lihaoyi/autowire) provides type-safe RPC calls from client to server! * [Widok](https://widok.github.io/) I don't know much about, but they've probably some cool innovations too :p * [Diode](https://github.com/ochrons/diode) is apparently a Flux/Elm/Om/Redux-like thing written in Scala.js [Most libraries](https://www.scala-js.org/libraries/libs.html) written for Scala.js are actually pretty innovative. It's the first time a type system as powerful as Scala's is available on the front-end, so that was bound to happen.
this post was intended to cover simple models. I never though about covering such cases. If you can give us a more concrete example I may try to find a nice usage example. Or if you find the answer in the meanwhile, please share. I'm not a Scala expert, I was just digging into the issue one day and decided to share my findings 
What is a mechanized/machine-checked proof?
Yeah, I don't use scala that much curious. Usually case classes are based on abstract class heirarchies. How do you deserialize a cow that inherits from animal, vs a cat that inherits from animal, directly to an animal type. This is a really common class of problems, at least in .net/Java land. C# and Java both add a type discriminator, like a json field of "_type" that is a string which represents what is the subclass type to deserialize to when the target type is part of an inheritance structure 
Don't forget the `%%` operator. And the dev zen of using `~testOnly myText` for TDD.
I just opened Eclipse for the first time. It opened on 5. Like on the count of 1... 2... 3... 4... 5. My IDE opens in 5 seconds the first time and the auto-complete is in real time - same amount of lag as if I were typing in Notepad. It took me maybe 2 minutes to set it up on my Linux machine. So worth it.
never heard about haskell ? :-) 
sorry didn't want to get across as a "leecher", I have some ideas for this myself, but I've got the feeling to do it "right" I will have to dive into the compiler-plugin (which will hopefully happen one day) do you think a opinionated full-stack framework with scala.js is something which is desirable? 
Spray is being merged into Akka, so if you need something lightweight, cool and with future try out Akka HTTP Play framework might be easier to adopt for you and if you do not need all the bells and whistles you can use the netty core an embedded app since 2.4 https://www.playframework.com/documentation/2.4.x/ScalaEmbeddingPlay You can check out a small example I have done here https://github.com/jonasanso/play-embedded 
Scala can be fun! Try out www.scalakata.com
Sometimes I feel like it's easier to use Java libs because I don't have to worry about whether the lib was compiled with Scala 2.10 or 2.11.
I've had good experience with Scalatra. The others listed here are good as well.
Out of curiosity, have you read SBT in Action? If so, what did you think? I'm asking because I just finished it and feel a bit frustrated. The reviews are really good, and I'm sure it's well deserved, but it appears not to have been proof-read - so many small mistakes, like variable names changing from one example to another, or example code that doesn't match what the textual description says...
Liftweb json is fantastic for this. Very beginner friendly as well.
Do not reinvent the wheel, use [Jsoup](http://jsoup.org/): val html = "&lt;p&gt;An &lt;a href='http://example.com/'&gt;&lt;b&gt;example&lt;/b&gt;&lt;/a&gt; link.&lt;/p&gt;" val doc = Jsoup.parse(html) val text = doc.body.text // "An example link." http://jsoup.org/cookbook/extracting-data/attributes-text-html
Just add `libraryDependencies += "org.jsoup" % "jsoup" % "1.8.3"` to your `build.sbt` file.
Damn, I already used jsoup to parse it, yeah this just solved it, I overlooked jsoups' capabilities. Thanks
As for counting word frequency, it can be done in a single line of Scala, albeit a little long one: scala&gt; val text = "99 bottles of beer on the wall, 99 bottles of beer. Take one down and pass it around, 98 bottles of beer on the wall." scala&gt; text.split("\\W+").groupBy(_.toLowerCase).mapValues(_.size).toSeq.sortWith(_._2 &gt; _._2) res0: Seq[(String, Int)] = Vector((bottles,3), (beer,3), (of,3), (99,2), (on,2), (wall,2), (the,2), (98,1), (down,1), (it,1), (around,1), (take,1), (pass,1), (and,1), (one,1))
I would have given you gold if i had any. Thanks!
You can write a Play app in 38 lines of code, including comments and imports: https://beachape.com/blog/2015/07/25/slim-play-app/
Just separate tests groups by time they take to execute. There's plenty of articles about it.
never heard about it. I suppose you are talking about this right ? https://github.com/lift/lift/tree/master/framework/lift-base/lift-json couldn't find examples on how to create case class models from a json, can you provide any source?
I highly recommend [http4s](http://http4s.org), but be aware that it entails drinking the FP/scalaz kool-aid. (I recommend that, too; I just feel it's intellectually honest to be explicit about it.) http4s is essentially impossible to beat for minimalism in Scala, and the pure-FP approach means a "middleware" is literally just [a function taking a `Service` to another `Service`](https://github.com/http4s/http4s/blob/v0.12.1/server/src/main/scala/org/http4s/server/package.scala). http4s comes with [several helpful `HttpMiddleware`s out of the box](https://github.com/http4s/http4s/tree/v0.12.1/server/src/main/scala/org/http4s/server/middleware). Hope this helps!
What do you mean? Its literally in the github docs. Its in the extracting values section.
&gt;/u/soc_puppet That's hilarious, assuming that actually is one his accounts.
I'm curious what motivates someone to go to such lengths. As much as I like Scala, it's a programming language. I can't imagine how a programming language might upset a person so much, they must be in a poor situation. I must admit I feel fairly sorry for him.
Do we really need such posts? 
Akka-http is essentially Spray 2.0. The API is almost exactly the same, especially the routing DSL. When I migrated, I had to change *very* little of my code. The internals are completely redesigned though, it's using akka-streams now and I love it even more. If you want more of an FP approach, go for http4s since it's based on scalaz `Task`. Akka uses stdlib `Future`. Akka-http is not imperative by any means, but people have made various cases against stdlib Futures. It has a solid community and it's backed by Typesafe so I guess it's a safe long-term bet. Really though, you can't go wrong with either one.
Same here, I think it's pretty clear someone has organized this effort to spread disinformation, but to attach a name to this effort requires a bit more explanation.
Before they were suspended, after /u/cbeustwatch brought it to our attention it was painfully obvious that some of these accounts were Beust from looking at their posting history. When they weren't trolling /r/scala, they were posting links to articles on his blog. The same old FUD about Scala, while at the same time praising Kotlin. One of the accounts in the above list, /u/tuoba1 was one I guessed myself must be Beust from the posting history.
[Apparently correct](https://github.com/http4s/http4s/pull/309). I'm kind of hoping [/u/tpolecat](https://www.reddit.com/user/tpolecat)'s [atto](https://github.com/tpolecat/atto) makes it in.
It's a stretch to say that posting links pointing to a site is a correlation to the poster. On that note, beust.com has about as much praise for scala as it does criticism. This is a hard pill to swallow, and appears to be libel without any hard evidence to back it up.
That's not very convincing. Who are you anyways, and why would you have been tracking these accounts, or Cedric Buest to begin with?
This is a tricky one, you can get a short-circuiting fold by rolling your own [lazy fold right](http://voidmainargs.blogspot.co.uk/2011/08/folding-stream-with-scala.html), but it won't be tail recursive.
If not evaluating everything is what's important you could use scalaz-stream Process rather than Seq. Honestly if you want absolute maximum performance you should probably be using explicit vars and while loops rather than @tailrec. I would strongly recommend just doing the foldLeft unless and until it shows up as a hotspot under profiling. 
Spray is wonderful. You can lift your middleware right into the type system so it's just resolved implicitly where it's needed, and then you have a static guarantee that e.g. confidential information is never accessed without authentication. Your route definitions are a DSL that looks like config but is actually code so you can refactor them, pull out useful pieces into methods and so on. It's very nice to use and really shows off the power of Scala. 
I use Xitrum for everything now. Super light weight, fairly non-judgmental, and super easy to extend when needed. I build a slew of custom traits extending action, extend those in my controllers and easily have a robust RESTful backend. 
Isn't it obvious? This is another Cedric account just looking to muddy the waters!
Like [this](http://applicative-errors-scala.googlecode.com/svn/artifacts/0.6/pdf/index.pdf). This is a great example of where I would use scalaz's [ValidationNel](http://eed3si9n.com/learning-scalaz/Validation.html) and [`|@|` (Applicative Builder](http://eed3si9n.com/learning-scalaz/Applicative+Builder.html)\). NB: the paper is a bit out of date. For example, in scalaz 7.1.x, there is no `&lt;&lt;*&gt;&gt;`. The link to Learning Scalaz above shows the use of `|@|` to combine `Validation`s, which is possible because `Validation`s are `Applicative`s. You've added another wrinkle, though: "Merge above responses and respond to original request." So you want to use [`+++`](http://docs.typelevel.org/api/scalaz/stable/7.1.0-M3/doc/#scalaz.Validation) to reduce your collection of `ValidationNel`s to a single one. This requires that not only the _left_ of your `ValidationNel`s be a `Semigroup` (binary associative operator), which a `NonEmptyList` is, but the _right_ be, too. If you have a merge operation for your responses already, then just implement the `Semigroup` typeclass for it. Otherwise, consider using a `List` or `Set`. If you did the `import scalaz._, Scalaz._` dance, `List` and `Set` will have `Semigroup` instances. Finally, my guess is you're looking stuff up in some store by ID. In other words, you're doing I/O, and it can fail, and maybe you'd even like to do it asynchronously. I had to do that recently—download a bunch of files from an FTP server, actually. I added exactly the "return a `List` of `File`s or `List` of `Throwable`s" stuff I've described in [this](https://m.reddit.com/r/scala/comments/3xavvi/scalaz_and_scalazstream_simplify_things/cyc7hy9) post. I wrapped ftp4j in `Task`, which is a `Monad` (hence `Monoid` and `Applicative`) that handles I/O, concurrency, and exceptions. `Task` has a function, `attempt`, whose return type is `Throwable \/ A`. `\/` has `validation` and `Validation` has `toValidationNel`, so I'm golden. One more thing: consider using [`traverse`](http://eed3si9n.com/learning-scalaz-day12) to traverse your collection of IDs, apply the `Applicative`s that do stuff, and reduce to your ultimate result. NB: the "reduce" part only works if the `Applicative` is `Monoid`al, but `Validation` is. :-) Oh, and use `Task` to do the dirty work. So an unbelievably powerful scalaz idiom is: myListOfFunctions.traverse(Task(_)) As Rúnar Bjarnason says, "use `traverse` and an `Applicative` whenever you think of using `foreach` for side-effects." The result of that is a `Task` that, when run, runs all the functions in the `List` ~~in parallel,~~ and completes when they're all complete. The resulting `Task` will also reflect success or failure (the first failure, if any). This is the base idiom, but you can use the `.map(List(_)).attempt.map(_.validation.toValidationNel)` trick on the `Task`s, just like I did. Finally, this is a lot to take in, but if you look at my FTP example, you'll see it's actually not much code, and it's specifically about accumulating results and errors from `Task`, which sounds like _exactly_ what you want. And don't hesitate to ask more questions! **Update:** Also consider using `Nondeterminism[Task].reduceUnordered` on your collection of `Task`s. This requires an implicit `Reducer` to be in scope. scalaz offers several `Reducer`s out of the box, but again, consider writing a `Monoid` instance for your response type and using `UnitReducer`, which works with any `Monoid`, with it. In fact, the more I think about it, the more I think that's where I'd start: you say you need to merge responses. At the very least, that implies creating a `Semigroup` instance for it. But consider whether you have some kind of "empty" response (I'll bet you do). Then you can/should create a `Monoid` instance for it. At that point, you have a `Monoid`, `Applicative`, `Semigroup`, and `Functor` instance for your response, and many, _many_ things become trivial, including "merging a collection of these into one." **Further update:** [/u/ItsNotMineISwear](https://www.reddit.com/user/itsnotmineiswear) rightly [points out](https://www.reddit.com/r/scala/comments/4594pk/reactive_either_stream_or_something_else/czwa6nt) that I misremembered the behavior of `traverse` with `Task`s `Applicative` instance, which is not parallel. So this suggests `Nondeterminism[Task].reduceUnordered` even more strongly to me, which makes implementing a `Monoid` instance for your response type an even more compelling idea. **Yet another update:** I keep learning nice things about scalaz myself. TIL that `Nondeterminism` has [`aggregate`](https://github.com/scalaz/scalaz/blob/v7.1.4/core/src/main/scala/scalaz/Nondeterminism.scala#L148). It takes a `Seq` of `Monad`s of `A`s and, you guessed it, returns a `Monad`of `A`, where the `A` is created using `A`'s `Monoid`. Then I found that `Validation`'s [`Monoid` instance](https://github.com/scalaz/scalaz/blob/v7.1.4/core/src/main/scala/scalaz/Validation.scala#L399) uses `+++` for its `append`, just as I did explicitly in my FTP code, _if the right side of the `Validation` is itself a `Monoid`_. So if you implement the `Monoid` instance for your response type, you're _really_ on easy street: just write a function of type `ID =&gt; Task[ValidationNel[Response]]` (remember, you can turn a `Task[Response]` into that with `.attempt.map(_.validation.toValidationNel)`), `.map` it over your collection of `ID`s, and call `Nondeterminism[Task].aggregate` on that. Boom, done, and I'd be shocked if the whole thing didn't fit in a page. **Final update:** Less talk, more code! import scalaz._, Scalaz._ import scalaz.concurrent.Task object Failure { type ID = String // More interesting type here, or not type Response = List[String] // More interesting type here /** Cheating by relying on std List instances. In reality * you'd do this: implicit def ResponseMonoid: Monoid[Response] = new Monoid[Response] { def append(r1: Response, r2: Response): Response = ??? def zero = ??? } } */ def handleID(id: ID): Task[Response] = ??? // Talk to internet, DB, throw exceptions... def handleIDs(ids: Seq[ID]): Task[ValidationNel[Throwable, Response]] = { Nondeterminism[Task].aggregate(ids.map(handleID(_).attempt.map(_.validation.toValidationNel))) } } 
I'd recommend finatra 2.0
&gt; The result of that is a Task that, when run, runs all the functions in the List in parallel, and completes when they're all complete. The `Applicative` instance of `Task` is not parallel: scala&gt; List(Task { Thread.sleep(10000); println("after 10") }, Task { println("right now") }).sequence.run /* Waits for 10 seconds */ after 10 right now `Nondeterminism`'s `gather`/`gatherUnordered` is what's necessary for parallel execution: scala&gt; Nondeterminism[Task].gather(List(Task { Thread.sleep(10000); println("after 10") }, Task { println("right now") })).run right now /* Waits for 10 seconds*/ after 10 Alternatively (and new to 7.2.x), there is [a parallel `Applicative` instance for `Task[?] @@ Parallel`](https://github.com/scalaz/scalaz/commit/d7241aead51f828bf781db6bedfcb951525e2d55)
This is still relevant. I'm still hiring. 
&gt; In the code you provided how to get 1) list of failed ids with reasons they failed, 2) list of succeeded ids with a result for each id? `.zip` the `Seq` of `ID`s with itself, then `.map` over the pairs and handle one of the elements, then `aggregate` the `Response`s with `List` instead of having a `ResponseMonoid`, then `partition` the resulting `List` by `Task` succeeded vs. `Task` failed. &gt; Also what would be the best way to do it using plain Scala (no scalaz)? Not to. **Update:** I'm trying not to be snarky, but it's tough. Part of the point of what I wrote was to show how _absolutely trivial_ scalaz makes this sort of thing, including concurrency and error handling. Even providing your own `Monoid` instance for accumulating the successes is a few trivial lines (if your type does, in fact, form a `Monoid`). The result is well under a page of code that works. Is it really not obvious that reproducing this with just the standard libraries would be, at a minimum, many dozens of lines, and you'd never be sure that it did I/O when it was supposed to, or didn't fail catastrophically on some exception, or that it ran in parallel, without deadlock, livelock, or race conditions? It's a serious question. I get the impression that either people think code like this has failure modes that it doesn't, or that the equivalent standard library code would be about the same size with about the same capability and safety. I'd really like to understand where these ideas come from.
Hi there! We were chatting earlier on the tabulate Gitter. I notice that you have a `kantan.xpath.DecodeResult` and a `tabulate.DecodeResult`. Are these the same type?
I can try explaining this from my point of view. First of all the imperative implementation of this requirement is very straightforward and anyone coming from Java would be able to write it without even thinking what libraries and language constructs to use. Also please note that this code doesn't need to run in parallel and runtime errors (e.g. coming from a database, etc) are most likely will be handled in a generic manner in a higher layer. On the other hand I can probably understand only half of your post and you (obviously much more knowledgeable in Scala than me) made 3 updates showing alternatives way to do it. I would absolutely not call this trivial. Basically I beleive it comes down to the fact that while the end result might look elegant and shorter it takes too much effort (including learning, choosing the right variant, reading out of date papers, etc) to come up with it. And even then a less experienced developer wouldn't understand what's going on.
&gt; .zip the Seq of IDs with itself, then .map over the pairs and handle one of the elements, then aggregate the Responses with List instead of having a ResponseMonoid, then partition the resulting List by Task succeeded vs. Task failed. `handleIDs` returns `Task[ValidationNel[Throwable, Response]]`. There are multiple responses (because Response is List[String]) but only one Throwable. What ID does this Throwable correspond to?
&gt; `handleIDs` returns `Task[ValidationNel[Throwable, Response]]`. There are multiple responses (because Response is List[String]) but only one Throwable. What ID does this Throwable correspond to? There's actually one `Response`, which in my example is a `List[String]`, but the point is that it can be any type that forms a `Monoid`, which `List` certainly does. The left of a `ValidationNel[X, _]`, though, is a `NonEmptyList[X]`. In this case, a `NonEmptyList[Throwable]`. In other words, when run, the `Task` yields either the `Response` or the list of `Throwable`s explaining why you don't have a `Response`. But I also like the question earlier: how would I associate successes and failures with their `ID`s? Assuming: val ids = List("foo", "bar", "baz", "bletch") def handleID(id: ID): Task[Response] = ??? it'd be something like: Nondeterminism[Task].gather(ids.map(handleID(_).attempt).map(ids.zip(_).partition(_._2.isLeft)) I mean, break it up and use names instead of anonymous lambdas. Fine. The point is, the question was about how to do this with FP, and all the answers with scalaz are trivial, and can trivially include I/O, concurrency, and exception handling with no additional effort.
&gt; I was just trying to explain an alternative point of view. If I already know how to implement a requirement using straightforward and easy to understand code (see below) I do not want to spend an hour (or maybe even much more) trying to learn a new library. I really do understand that. What I'm trying to explain is that the idea that this satisfies any production-grade notion of "requirement" is false, and it's only "understandable" because it completely ignores everything but `MapFailedException` and of course the for-loop get interrupted at any other exception. Can you show me a version that actually captures all non-fatal (not OOM etc.) failures without terminating the iteration prematurely, including at least some try/catch block that either logs the exceptions or returns them in a list or something? In short: you know this code isn't competitive with even the synchronous scalaz code, right? &gt; I also understand that there are different opinions and I agree that if I had better knowledge of Scala and Scalaz it would be easier for me to understand the code you provided. OK. Ultimately, all I'm saying is: anyone who puts the time into learning scalaz they'd put into learning any other framework can also knock out very featureful, correct code that just works, an order of magnitude more reliably than with any Java framework. But just a final reminder: the question was "how can I do this in FP in Scala?" Well, scalaz is the most mature FP library for Scala, so why wouldn't it be the right thing to use?
I run in to this a lot, and as far as I know, the pattern match is the only way out. A sufficiently smart compiler might in theory try to inline flatMap, which could make the recursive call end up in tail position in some cases, but that's not the compiler we have right now.
This might be what I'm looking for. I'll have to prototype this in Java (gross), but it might be a good argument for me to introduce a little more Scala into the codebase.
I think this is probably too much to take in coming from 90 % java (I'm pretty comfortable with scalaz and my eyes still glossed a bit.) I also think applicativebuilder is no good here b/c OP wants to keep both failures and successes. Applicative on ValidationNEL accumulates failures but is still either all success or all failure.
&gt; I am not sure if we are competing here... You challenged me on my code. If you didn't intend to, fair enough. &gt; ...but the code I provided can certainly be part of a reliable application. Not as long as it can throw out of the iteration it can't. It wouldn't pass code review in any Java shop I worked in within the last decade or so. It also doesn't have enough detail to actually compile and try. My last code example does, and in fact I would encourage people to do so: implement `handleID`, change `Response` to a more interesting type (and implement `ResponseMonoid` for it)... &gt; Surely you do not want to collect exceptions if you made a mistake in SQL syntax. Why not? What do you propose instead? &gt; In case if a database connection failed you should probably fail or retry the whole request (if this is a web app). That's exactly the sort of decision a client of this code can make. A very nice example of a simple REST API using scalaz at both the HTTP layer and database layer is [here](https://bitbucket.org/da_terry/scalasyd-doobie-http4s), FWIW.
something like this should work: type ID = String type MyObject = String type OtherObject = String type Success = String // it was named "something else" in the text type MyError = String // assume MyError is a class renderable by your REST service def isBad(id: ID): Either[MyError, ID] = ??? def getObject(id: ID): Either[MyError, MyObject] = ??? def getOtherObject(mo: MyObject): Either[MyError, OtherObject] = ??? def getSomethingElse(mo: OtherObject): Either[MyError, Success] = ??? val idList: List[ID] = ??? /////////////////////////////// val response = idList.map { id =&gt; isBad(id).right.flatMap { id ⇒ getObject(id) }.right.flatMap { myObject ⇒ getOtherObject(myObject) }.right.flatMap { getSomethingElse } // or a shorter version: // isBad(id).right.flatMap(getObject).right.flatMap(getOtherObject).right.flatMap(getSomethingElse) } val lefts = response.flatMap(_.left.toOption) val rights = response.flatMap(_.right.toOption) Note that I did not use the one-liner solution as default (it's commented out). The reason for that is that in real world, you usually do not have the functions defined earlier, but instead place your code in the transformation chain. This is nicer to do inside the long version I wrote. Also, the "filtering bad IDs" is not a clear step. You usually cannot just "filter", you should have a justification for that. So my function is returning Either[MyError, ID], not Boolean. The dublicating ID can be a bit confusing.. Dunno the best way to deal with that. Well, anyway, suggestions welcome.
I think this use of `.map` and `.flatMap` in a chain is good justification for using [scalaz's Disjunction](http://bytes.codes/2015/04/10/a-skeptics-guide-to-scalaz-part-1-disjunctions/), even if you do nothing else with scalaz.
I don't think you implied the need for scala and scalaz understanding for it to make sense, I think that's just the reality of the situation. Speaking for myself and what I've observed with extremely intelligent colleagues, this stuff is hard and takes time to get comfortable with. If someone has been mostly writing java, casually throwing out the term Monoid trivializes the amount of knowledge you are assuming on behalf of the reader. Personally, my eyes gloss quickly based on length of content, so contents are even secondary. That said, I didn't actually count but a vague skim of your original comment I see at least 10 concepts introduced (just looking at inline code blocks). I may be familiar with half or more but I don't even have the attention span to find out, let alone dig up the ones that I don't immediately recognize. Edit: clarity
 Vector is only better at mutable contexts because of the lesser needs of reallocations(like in java/c++ etc.). At the immutable contexts List provides better performance. If you don't believe me, make benchmarks or implement a linked list and a dynamic array immutably and you'll see the difference.
The problem with the mapping + summing is that it creates an unnecessary collection and performs a second unnecessary iteration making the O(n) operation to be O(2n). 
Right. If you can't cope with change we don't want you, and that's fine. 
Uh, doesn't it depend on the usage pattern? I mean, if I'm working in an "immutable context" but need to access elements of a collection at arbitrary positions, Vector is faster: effectively-constant time vs O(n).
True. To traverse only once, use an iterator: pairs.iterator.map(_._2).sum
We're talking about "general purpose use" in FP, I've [recommended](https://www.reddit.com/r/scala/comments/45dxo6/using_an_arraybuffer_in_scala_newbie/czx501o) Vector for random access.
+1
if you have the time, try both for a day each. 
When a Java developer (or any X developer, not trying to pick on Java here) casually reads this definition, they would stop when they read "associative". Maybe they would have a look at the example, but then stop. Because in the Java world, you do not care whether anything is associative or not. You do not generalize things, you rarely think of operations and their properties. All the thing you have mentioned do not make sense to an ordinary programmer. I know that you are saying that if they put some effort they are going to understand it, but such explanations need to be more intuitive. Even talking about operations and associativity scares people off. I think a nice way to achieve that is to make them invent them on their own. Then you'll say "hey, you know what, we knew about this all along, here's a Monoid", and the guy will understand that you aren't trying to be cool when you talk about associativity, it's an important property, and he really needed that. 
&gt; When a Java developer (or any X developer, not trying to pick on Java here) casually reads this definition, they would stop when they read "associative". Maybe they would have a look at the example, but then stop. I think that's OK, though. That's what the examples are for. Unless this hypothetical developer is sitting in an interview with me, it's really OK if they don't immediately start using a `Monoid` (scalaz's, Cats', homegrown, whatever) whenever they could. Sure, they could make their lives easier by doing so, and more to the point, by taking advantage of these libraries' _other_ features built around `Monoid`s. But horse, water, all that. I just thought, here's a piece of low-hanging FP fruit someone was kind enough to point out to me, and if one or two people feel like they understand better, that's good enough for me.
I have used play a couple times before for small projects. That's how I know what a headache it can be! I think its just too robust for what I need. 
scalatra it is. it's not worth thinking about the decision for a day, just try it! :) 
The wikipedia entry for Monoid mentions that abelian monoids are a type of monoid! Wow, how cool is that? I love when abstract math and abstract programming intersect.
Yep! Functional Programming constructs _really are_ "effective models" of their mathematical counterparts, in the [effectively computable](http://dictionary.reference.com/browse/effective-computable) sense. The culmination of this is [Propositions as Types](http://homepages.inf.ed.ac.uk/wadler/papers/propositions-as-types/propositions-as-types.pdf), which relates types and mathematical logic, and from the type theory side is more commonly known as the [Curry-Howard Isomorphism](https://en.wikibooks.org/wiki/Haskell/The_Curry%E2%80%93Howard_isomorphism).
Abstract algebra studies a number of variations on the theme of "set equipped with a binary operation with some properties". There's something of a tower of these constructs where you either add or remove (depending on the direction) properties. Monoids are lower on the tower than abelian groups. In particular, if you take your definition and remove commutativity, you get the definition of a group. If you then remove inverses, you get the definition of a monoid. Mathematicians don't often talk about monoids: there are many fewer interesting proofs that hold when you remove inverses. Computer scientists don't often talk about groups: many interesting data types don't have inverses (for example: list concatenation forms a monoid, but not a group since theres no inverse elements), and has enough computationally interesting properties to be a useful abstraction.
But I think it goes without saying at any software job. When a job posting emphasizes it though, it scares people into thinking they mean 'to the extreme'. So, the job might be awesome and perfectly reasonable, but I don't know if it needs to be said in the job post (the flexibility requirement) :) 
I've never worked with Scalatra, but apparently there are some thread safety issues with it: * https://beachape.com/blog/2015/07/25/slim-play-app/
[\*_cough_\*](http://www.fisica.net/mecanicaclassica/struture_and_interpretation_of_classical_mechanics_by_gerald_jay_sussman.pdf) [\*_cough_\*](http://groups.csail.mit.edu/mac/users/gjs/6946/calculus-indexed.pdf) ;-) It's probably also worth pointing out [Geometric Algebra and Geometric Calculus](http://geocalc.clas.asu.edu/), which is entirely computable. [GAViewer](http://www.science.uva.nl/research/ias/ga/viewer/) is a very nice program with a scripting language for doing visualizations and animations, and there are quite good libraries like [versor](http://versor.mat.ucsb.edu/) for when you need top performance.
Exactly. This subreddit frequently get visits from critics, and when you look, either it's a totally new account, or links to something like the single post on Medium, or, even more amusingly, all the poster's other posts are positive in, e.g. the Go subreddit. I dislike encouraging people to assume bad faith in debates, but in this subreddit, for whatever reason, bad faith is the rational default assumption, i.e. critics need to prove their bona-fides.
the plot thickens...
Is it seriously possible to get a CS degree these days while being scared by the word "associative"? I don't believe it.
You do hear about associativity, especially if you take an abstract algebra course. But there is a high chance that (1) you do not need to take such a course (2) even if you hear about it in such a course, or maybe in introduction to calculus, you learn about it, solve the exercises, write the final, and you're done with that topic. When someone says "associative" to you a few years later you end up saying "oh, I had heard about that a lot in college, and realized that I didn't need much mathematics when I write Android apps, so I don't really care listening what you say about associativity since I'm sure that it won't be useful since my experience tells me so". 
Depends on the school I guess. Our class was simply named "Algebra", as part of which we learned both the abstract algebra concepts (up to polynomial rings) and linear algebra (up to SVDs and eigenvalues).
Sure! What prompted the post was a question about having some collection of IDs, doing various lookups/transformations on those IDs (some of which can fail), _merging the results into a single result_, and returning that result. The question didn't specify this result type, but one thought that occurred to me is that it could be a chunked HTTP response, which fairly obviously forms a monoid, i.e. there's an empty chunk and an associative append operation. In other words, if I do N things, each of which returns a chunked HTTP response, it's easy to turn that into one chunked HTTP response. OK. So scalaz has a very powerful tool for "doing stuff," including I/O, exception catching, and concurrency, called [`Task`](http://timperrett.com/2014/07/20/scalaz-task-the-missing-documentation/). Really describing `Task` would take us too far afield (read Tim's great post!), but a `Task[A]` is a `Task` that, when run, returns an `A`. Remember when I said `Task` also catches exceptions? That means the `Task` can end up in either a success or failure state. It's a lot like the standard `Future` in that sense. But there's also a function on `Task`, `.attempt`, that transforms a `Task[A]` to a `Task[Throwable \/ A]`. `\/` is like `Either`, but works in for-comprehensions. So if I have a function: def doStuff(id: Int): Task[Chunk] = ??? and a bunch of IDs: val ids = List(42, 96, 2, 17, 5, 9, 23...) then obviously I can do: val tasks: List[Task[Chunk]] = ids.map(doStuff) Now, what I'd really like is either all the `Chunk`s combined, or a list of the errors that occurred in the `Task`s building the `Chunk`s. The first question is: is there a convenient way to run all the `Task`s, maybe even in parallel, and accumulate the results? Actually, there are several, but the one I'm interested in is [`Nondeterminism[Task].aggregate`](https://github.com/scalaz/scalaz/blob/v7.1.4/core/src/main/scala/scalaz/Nondeterminism.scala#L148). As you can see, it takes a `Seq[F[A]]` and returns a `F[A]`, but it can only do that if `A` is a `Monoid`. `Chunk` may be a `Monoid` (we're assuming it is), but what about accumulating errors? It turns out scalaz has another handy type, [`ValidationNel`](https://github.com/scalaz/scalaz/blob/v7.1.4/core/src/main/scala/scalaz/Validation.scala), which is like `\/` but accumulates errors on the left. In fact, the `Nel` refers to a `NonEmptyList`, i.e. a `ValidationNel` is either a "right" with a value or a "left" with a list of errors that can't be empty (because what would a "left, but empty list of errors" mean)? Now, if I have a `\/`, I can turn it into a `ValidationNel` easily: `.validation.toValidationNel`. Great. But is this a `Monoid`? It turns out that [it is](https://github.com/scalaz/scalaz/blob/v7.1.4/core/src/main/scala/scalaz/Validation.scala#L399), if and only if its _right_ is a `Monoid`. So instead of val tasks: List[Task[Chunk]] = ids.map(doStuff) I say: val tasks: List[Task[ValidationNel[Throwable, Chunk]]] = ids.map(doStuff(_).attempt.map(_.validation.toValidationNel)) In other words, I have a list of monads of monoids, which means I can say: val task: Task[ValidationNel[Throwable, Chunk]] = Nondeterminism[Task].aggregate(tasks) Now I have one `Task` that will return the `Chunk` built by merging all the `Chunk`s from all the `Task`s, or a `NonEmptyList` of all the `Throwable`s that caused (any of) the`Task`s to fail. I hope this helps. It's a bit long because I wanted to describe a real-world use case.
Yes, I know, `cats` or `scalaz` _could_ be used. There's a whole post (yours, actually) that describes this approach along with Monoid-s, Task-s and 8 other links. Then again, I wanted to write a simple solution that would not go outside of Scala standard library.
&gt; I wanted to write a simple solution that would not go outside of Scala standard library. Sure, but val response = idList.map { id =&gt; isBad(id).right.flatMap { id ⇒ getObject(id) }.right.flatMap { myObject ⇒ getOtherObject(myObject) }.right.flatMap { getSomethingElse } isn't simple, and in _this case_, I explicitly said: &gt; this use of `.map` and `.flatMap` in a chain is good justification for using [scalaz's Disjunction](http://bytes.codes/2015/04/10/a-skeptics-guide-to-scalaz-part-1-disjunctions/), _even if you do nothing else with scalaz_. In other words, my other post is irrelevant to this, and there's something _very weird_ about twisting your code into pretzels just to avoid `\/`.
I see no reasons as to "why not". If you feel scalatra fills your needs, go for it. I'm personally a fan of `liftweb`, but I haven't used `scalatra`, so I can't suggest.
(╯ಠ_ಠ）╯︵ ┻━┻
I have in same state currently. Used Play in multiple startups and production. Play is heavy weight and just hard to do simple things (json, logging, etc..). Also the changes between versions are no longer fun to keep track off. I started playing with scalatra last week on a simple REST server. So far the experience seems nice. Still evaluating it currently.
why not finatra?..it's similar to scalatra but with better performance and more type safety and testeable, I really can't understand why finatra is not more popular in the scala community, because it's great and really nice for build api's http://twitter.github.io/finatra/user-guide/json/ ...maybe would be because it's not a typesafe product
 Append is only effective on vector when the appendable's size is known. And the term of 'update' is O(n) for both but the the list will be able to reuse some of its parts. Scala != Java, the previous knowledge of the mutable spaghetti world won't help you here. "You shouldn't be telling people new to the language to use List instead of ArrayBuffer." - ArrayBuffer is mutable which isn't recommended neither in Scala nor in any other FP language for general use. Today, creating concurrent and concurrent-capable modules are more valuable than creating early-optimized one-threaded garbage. If the usage of data structures are unclear for you I recommend you to read about them more and go practicing.
What did the penne say to the macaroni? Hey! Watch your elbow.
Totally sensible response, I appreciate it.
Yes. A Monoid is a Group that doesn't necessarily have inverses (therefore all Groups are Monoids, but not all Monoids are Groups). E.g. for a fixed type `A` (e.g. `Int`), the set of functions `A =&gt; A` (e.g. `Int =&gt; Int`) (endomorphisms) form a monoid with •=`andThen` (you can check that this obeys associativity, and identity is... `identity[Int] _`). But this isn't a Group because some elements don't have inverses, e.g. `val f = {x: Int =&gt; 4}` is an `Int =&gt; Int` without an inverse: there is no `g` such that `f andThen g == g andThen f == identity[Int]` (leaving aside for a moment the difficulty of defining `==` for functions). Abelian just means commutative.
Yes, it really is incredibly simple and banal. There's an inverse relationship between complexity and generality: the more complex a definition is, the fewer things will meet it. What makes the concept of a Monoid valuable is that you can write a function using just the Monoid properties (e.g. `foldMap`) and then that function can be called for almost any datatype (String, Int, List, Endomorphism, ...) If you're coming at this from an OO background then I find it useful to think of typeclasses as a way of associating a "default strategy" to a type. If you have a method that follows the strategy pattern (like `reduce` where you pass a reducer), then you often end up having a particular "natural" strategy for each type. Rather than passing it in each time, if you make the strategy implicit then you can define an implicit instance in the companion for the type, and then each type you call it with will "magically" (but in a way that you can see in the IDE) use the correct strategy for that type. (Of course, you can still manually override the strategy if you want to do something different). Ta-dah! That's a typeclass. If you do this a lot then you tend to see the same strategy types coming up often - and also that you can often define some complex strategy in terms of a simpler strategy. E.g. the `Monad` instance for `Writer[A, ?]` is defined in terms of the `Monoid` for `A` - so you can use any `A` for which a `Monoid` instance exists. That is to say, if you're calling something like `traverse` that needs a `Monad` typeclass instance (i.e. a "effect merging strategy"), then when you pass `Writer[MyLog, Int]` there's a "default strategy" that's defined in terms of merging the `MyLog`s using the "default strategy" for doing that (i.e. the `Monoid` typeclass instance for `MyLog`).
Split it into the left hand side of the `=` and the right-hand side. def delta[A, B, C]: (C =&gt; A) =&gt; (C =&gt; B) =&gt; (C =&gt; (A,B)) = f =&gt; g =&gt; x =&gt; (f(x), g(x)) So `delta` has type `(C =&gt; A) =&gt; (C =&gt; B) =&gt; (C =&gt; (A,B))` which means it returns * a function that takes a `C =&gt; A` and returns ... * a function that takes a `C =&gt; B` and returns ... * a function that takes a `C` and returns an `(A, B)`. The implementation is `f =&gt; g =&gt; x =&gt; (f(x), g(x))` ... `=&gt;` associates to the right so this is really `f =&gt; { g =&gt; { x =&gt; (f(x), g(x)) } }`. The types of `f` and `g` and `x` are inferred but you can supply them if you want: def delta[A, B, C]: (C =&gt; A) =&gt; (C =&gt; B) =&gt; (C =&gt; (A,B)) = { (f: (C =&gt; A)) =&gt; { (g: (C =&gt; B)) =&gt; { (x: C) =&gt; (f(x), g(x)) } } } 
I have been using Play Framework for some time. It's decent to say the least. Try it out. On the other hand I think Scalatra is anti-Scala. The API isn't type safe and relies heavily on mutation. Folks might dismiss this argument, but consider that in terms of type-safety the Java APIs, like Jax-RS are doing a better job and Scala isn't Ruby. If you want dynamic typing you're losing by not picking a dynamic language. Scalatra also doesn't provide good facilities for asynchronous processing and worst of all, it really doesn't provide much over the Servlets API. This might seem like a virtue in certain contexts, but isn't, as the Servlets API takes care of everything hard about building a web framework and you can build your own API on top of Servlets that's better than Scalatra in a single sprint. I know I did. And if you're conservative in your choices, might as well go with a Java selection. DropWizard would be a better choice. Picking Scalatra is a common mistake that people do when switching to Scala. And from what I've seen, it's a choice that people end up regretting. Json4s is another one.
The only problem for me was play's logging is not something that you can swap out easily, but that'll change in 2.5.
Thanks you. The only thing I can't understand yet is what feature allows us to drop the actual parameters from function definition. I guess, I should read more about carrying and Scala's syntax on it. 
 You're either a troll or biased or angry with List(what?) but I don't know why. How could somebody call shit one of the most used data structure in FP and recommending a mutable data structure for a beginner? Those two random pdfs add nothing here. Consider this instead: List is better at tail-recursion(head/tail, often used in FP), filtering, removal, appending another list and stack/queue operations while Vector is better at random indexing, reversal iteration and if implemented well then insertion. It's good at appending a collection too if the appendable's size is known(O(1)) which isn't a general case. Where List is better, Vector either use too much allocations or just bad in concept. The usefulness of both depends on the usage contexts, non of them are 'shitty'.
It's the example the author uses to convince us to not (ab)use pattern matching, but it's really not comparable. Pattern matching is not slower. And to must people more readable. Note that in the case of a fold, the first parameter is not a default value, it's an initial value. getOrElse is the least powerful method and clearly expresses that a default value is specified, so I tend to use either that or pattern matching.
Didn't cause me any issues here. It got out of the way as I scrolled down
Yes, this is what I had in mind, that I can't implement it. Can't say all this stuff is clear to me. In a case you wonder what's going on, I come across (functional programming with arrows)[http://scala.org.ua/presentations/scala-functional-programming-with-arrows/index.html#/]
Just wanted to say this. You can't really compare an Akka actor to a goroutine...
Actually none of the tests use that many threads, because they are all implemented with actors, goroutines or other pooled resources. I did notice that the Go variant was never able to use more than 50% of the CPU, while the Scala Future version went easily to 100% of CPU core usage. Also Go started running out of memory as soon as iteration count went over 10M, while the Scala version was happily crunching away 100M or even more iterations.
Seriously?
Play's logging is standard Slf4J with Logback. What do you want to swap out?
Thank you for your inputs. I guess I should have been more clear. The service works on it's own, but when executed with "spark submit" on the server, issues arise. It works with no issues using a pre-built spark on the same server however (java -jar Spark-Scala-assembly-1.0.jar will start the service up no problem too). Would the same exception not be seen in all environments if slf4j or logback class were not included in the fat jar like you say? This is why I took the stack trace less too account. Though I may be incorrect in doing so. Apologies, I'm still new to the scala/spark world. Unfortunately due to company restrictions, a lot of unknowns are introduced. I figured maybe someone has experienced the same things before. I'll definitely take into account your comment on avoiding Spray. Though our intention is to not have a "very basic REST service". We're just building everything a little at a time and getting it to work before adding any complexity. If you have other framework suggestions, I am completely open to them as well. 
No I mean extend type function with input candy output candy. I made a mistake sorry it should be: class CandyController(pizza:String)extends (Candy=&gt;Candy) { apply(c:Candy):Candy = c } &gt; also functions can't be compared So that means you can't properly put functions *in* case classes like what I wanted to do. println(Pizza("blah", Foods.eat) == Pizza("blah", Foods.eat)) weird, so it wraps the function calls inside an anonymous class and uses that object ID as method of comparison, always I guess. If so I would expect this to be true: val func = Foods.eat _ // wrapping only happens here println(Pizza("blah", func) == Pizza("blah", func)) 
Monotonic distributed algorithms and massively parallel systems aren't complex tech. They're good engineering. But to give you a little bit of insight into what we're doing: we're doing both data engineering, and solving the low level distributed computing problems so that application engineers don't have to. Most of the time, we build on existing technology, but we're working at a level where fundamental understanding is required, so our abstractions don't leak, and the engineers who use our tools can concentrate on reasoning about their features, and how their code interacts with ours, instead of reasoning about the whole stack at a low level of abstraction.
Please do apply, and mention your reddit username. We'll talk, I'm interested. Edit: I think you got downvoted by somebody who was angered by terms they don't understand. 
&gt; Using the objectID of that anonymous class to compare functions simply won't work It works for the cases where they're equal. Then you know its the same function. But you're right. I didn't wanted a full logical comparison, just a name one. ie: Foods.eat == Foods.eat That's better than a identity check while still not a logical comparison.
Daxten has on the money. You just need to use traits. Your `CandyController` should be a trait and the `eat` and `trash` would be implementations of that trait. Then you just need to pattern match to see if you were getting the eat class or the trash class.
Ahh yes, that will work. This would make the scheme I have in mind even better. Thank you!
I had a suspicion there was some kind of dependency conflict, but hadn't yet investigated that thread and you've only confirmed it's probably the issue. The dependencies we're restricted to develop with that at the company I work for handicaps developers so much (pretty sure they won't have Akka 2.4.2-RC3). It's quite frustrating. Anyways, that's another subject. You've been a tremendous help. I'll take into account all your suggestions and will definitely look into http4s. This will most likely have to be the route I take (if they have it available of course). Thanks a lot! 
I know a few people that moved from Play to Scalatra, because of the breaking changes the play usually introduces with every version and they claim that Scalatra works well for them. However, when I looked at it I didn't like the api too much. For example, you can return any value to a controller action and it tries to make a response out of it, so, you loose type safety here.
I think the memory gets dusty, plus making the connection to a particular context might not come in a flash of insight. For example, by the time MapReduce (not Hadoop yet, just fawning over Google's big new secret sauce) hit the streets, I'd been programming in Lisp for a couple of decades, and was very familiar with `map` and `reduce`. Heck, I even preferred [Richard Waters' Series package](https://github.com/tokenrove/series) to the venerable LOOP macro. It would probably be fair to say I had an intuitive understanding of the roles of commutativity and associativity in using `map` and `reduce`, but it never did—and likely never would have—occurred to me to think about their significance in a concurrent or distributed setting. Come to think of it, I think that helps explain why I'm such a typed FP zealot today: because I studied both CS and physics formally, and in retrospect it feels like I was taught a bunch of random, disjoint mathematical/logical/computational factoids, and only within the past 5-7 years has any kind of through-line appeared to tie it all together. And when it _does_ all hang together, it is _heartbreakingly beautiful_, I mean John Nash seeing visions in windowpanes heartbreakingly beautiful, and unfortunately, failure to share that beauty can (and in my case, frequently does) become perverted into frustration and even anger or contempt. I'm trying to reacquire (if it isn't too presumptuous to claim I ever had any) some spiritual discipline about this, and remember to _share_ rather than _ramrod_. Because if this stuff really is _beautiful_ and _fun_, it will reveal itself to others without any _Sturm und Drang_ from me.
Java guy here. A couple of things I don't get: 1- Can Scala type system enforce Monoid properties? The monoid trait I see here does not enforce op to be associative, and does not even mentions a mempty "zero like" element. I suspect it is something like Set interface in java, that can not enforce elements being unique, so you just have to trust the implementation. 2- Can Scala type system express anything like "one element with specific properties" or at least "one specific element"? I mean, If I'm writing a library that uses monoids, I'm probably going to need access to the zero element. In java the closest thing I can think would be an instance method getZeroElement, and there is no way to enforce zero element to be unique, or even get the zero element without another one. Maybe a MonoidFactory would do the trick.... but that's too java. Is there anything better in Scala? 3- Let's say you have a function that operates in monoids only, f(Monoid[T]) -&gt; Monoid[T] , and you want to use it with Integers and addition. In java I'd need a small wrapper over Integer, and also convert everything before and after. Something like Integer integerResult = fromMonoid(f(toMonoid(integerVariable))); I assume scala implicit conversions will get rid of the convert-to/from-monoid step, but do you still need a small wrapper over Integer? Or is there any other Scala feature I'm not aware of that may help? 
Great questions! &gt; Can Scala type system enforce Monoid properties? Technically, yes (Scala's type system is Turing complete). As a practical matter, I haven't seen it done. Mostly, this is an area in which we tend to use [property-based testing](http://timepit.eu/~frank/blog/2013/03/scalaz-monoid-example/) to show, probabilistically, that the laws hold. It's worth mentioning that [Cats](https://github.com/typelevel/cats/tree/v0.4.1) does this much more consistently, taking advantage of [Discipline](https://github.com/typelevel/discipline), although we shouldn't overlook [scalaz-scalacheck-binding](https://github.com/scalaz/scalaz/tree/v7.1.4/scalacheck-binding/src/main/scala/scalaz/scalacheck), either. This does include coverage of the [monoid laws](https://github.com/scalaz/scalaz/blob/v7.1.4/scalacheck-binding/src/main/scala/scalaz/scalacheck/ScalazProperties.scala#L90), which depends on those laws being expressed [in the `Monoid` typeclass](https://github.com/scalaz/scalaz/blob/v7.1.4/core/src/main/scala/scalaz/Monoid.scala#L77). So if you write your own `Monoid` instance with scalaz, you may want to use scalaz-scalacheck-bindings to test your instance with the laws. &gt; Can Scala type system express anything like "one element with specific properties" or at least "one specific element"? I mean, If I'm writing a library that uses monoids, I'm probably going to need access to the zero element. Yep. [`aggregate` from `Nondeterminism`](https://github.com/scalaz/scalaz/blob/v7.1.4/core/src/main/scala/scalaz/Nondeterminism.scala#L148) is a great example. It constrains the type variable `A` to be a `Monoid`, and uses `implicitly[Monoid[A]].zero` to get whatever the `zero` is for the `A` in question. &gt; Let's say you have a function that operates in monoids only, f(Monoid[T]) -&gt; Monoid[T] , and you want to use it with Integers and addition... I assume scala implicit conversions will get rid of the convert-to/from-monoid step, but do you still need a small wrapper over Integer? Or is there any other Scala feature I'm not aware of that may help? A couple of them, because, as I'm sure you're alluding to, `Int` forms at least two `Monoid`s: one with `0` and `+`, the other with `1` and `*`. So there is an implicit [`intInstance`](https://github.com/scalaz/scalaz/blob/abbd0238972d71bd07724218d4f85341ab720389/core/src/main/scala/scalaz/std/AnyVal.scala#L234) and also an implicit [`intMultiplicationNewType`](https://github.com/scalaz/scalaz/blob/abbd0238972d71bd07724218d4f85341ab720389/core/src/main/scala/scalaz/std/AnyVal.scala#L253), which relies on a [type tag](https://github.com/scalaz/scalaz/blob/abbd0238972d71bd07724218d4f85341ab720389/core/src/main/scala/scalaz/Tags.scala#L49) to indicate which `Monoid` instance to use. Hope this helps! (And come to the dark side! We have cookies!)
Hi Travis. Thank you for a great release. I've moved all of our projects over to using Circe from Argonaut. Can you give us a bit of background on the generic derivation overhaul (pull #164)? I make heavy use of the automatic derivation, but sometimes it is too automated. It would be nice to have convenience syntax, similar to Argonaut's casecodecN series of functions, to provide alternative constructors/deconstructors and my own field naming. But perhaps I am missing something that is already covered in the API. Thanks again. I am very happy to benefit from excellent progress.
The first defines a function that accepts an `Int` and returns an `Int`. The second defines a function that accepts nothing and returns a function that accepts an `Int` and returns an `Int`. A couple of clues are that `x` is mentioned in the first signature (because Scala supports named arguments) but not in the second (because the second function takes no arguments), and that there's a `=&gt;` (signifying a function type) to the right of the `:` (i.e. as part of the return type) in the second signature.
Thanks! There is [an issue open](https://github.com/travisbrown/circe/issues/26) for porting the casecodecN functions. It's a pretty old issue, but I've been avoiding contributing an implementation myself, since I'd rather have this kind of thing be handled as part of a coherent, configurable generic derivation framework. That's proven a little harder than I expected, though, and #164 gets us only part of the way there, so I'd be more than happy to review and merge a fix for #26 in the meantime. I can also add it to my to-do list, but I probably wouldn't be able to get to it for at least a couple of weeks. Thanks again, and let me know if there's anything else we can do that'd make the project more useful for you.
 First, I've called you a troll because you call something shit what you don't understand. Second, I don't care about neither clojure nor about that guy. People who use dynamically typed languages would be the last ones I'd ask about performance. List IS a good general purpose data structure in FP. You can't just link junk and convince me with it. &gt; If someone new to the language says hey what immutable data structure do I use instead of arraybuffer, the answer is vector, not list. ArrayBuffer != Vector, the concepts are different. I'm really tired of explaining all of it to you so, I just leave it on you. Just don't misguide the new ones.
I won't argue with that but your assertion that this is "an unrealistic scenario" is contentious. 
[This great article](https://tpolecat.github.io/2014/06/09/methods-functions.html) by /u/tpolecat explains this in much more detail.
&gt; There is also a point, where if your needs dictate you having so many threads, you are just going to run it on a server or cluster. Exactly. And what better way to determine where that point is than to measure. 
They do, but it's not clear why you should bring it back from your memory if you're a mobile developer. It surely is relevant in Java, your example is a good one. But when you deal with those, no ordinary Java developer says "+ is left associative, - is not, so I should beware". They instead say "Oh, I wrote this expression involving two division operators and it turned out that the compiler didn't understand it in the right way. I will parenthesize it so that the compiler doesn't fail". Note that they haven't used the word "associative" and didn't realize that it was the same concept they learned in their middle school classes (or even Calculus courses at college). What I'm really saying is not that "associativity is irrelevant", it is "given this state of the world, it is very hard for a regular programmer to notice the relevance".
Awesome! Really like the direction circe is heading! Thanks
&gt; Thanks for answering so fast (man, is Sunday! take a break!). Gotta do _something_ while the filets are on the grill... :-) &gt; Oh, I'd love to try Scala at work, but it has become such a big beast it's really scary. I should have tried 5 years ago. Today I'm becoming old and conservative. I'm between 5 and 6 in this list Heh. I know what you mean, seriously. I've written a lot of OCaml recreationally, and none of it "pure." I played with Haskell, but it never took. When Scala hit the street, I thought "Yay! OCaml for the JVM!" I still didn't care about purity. What's funny is that it's been on the job, at Verizon OnCue, that I've drunk the scalaz, monads, etc. kool-aid, especially since learning how trivial implementing them with free monads is. Now the question is how to get the word out and cut through the fog... which can be ironically difficult, because the point of FP is composition, so to understand anything you have to understand everything it's built on... Anyway, we'll make a fresh batch of cookies anytime you want to look more closely. :-)
The implementation - aka logback. Ofc its a good logger, but its always nice to have a choice.
As someone who's just learning Scala I found this to be a pretty useful guide. Thanks, /u/lihaoyi
But `O(n) = O(2n)`. I know what you're saying though.
Just curious, did you do something special to improve error reporting when the derivation fails?
 &gt; Ahahahahaha you're trying to talk about the importance of FP What? You've problems with english :D Can you read at all? Go back and do your homework instead. &gt; and you just called Guy Steele "that guy" That guy has no importance here. Don't try to push his 'reputation'. &gt; Do yourself a favor, suck up your ego, and actually read the links I posted. Somebody is really pesky, you should watch what you write! And you've posted 2 lisp related pdfs, it's really suspicious... lispers are the ultimate trolls of the prognet. You can write/link anything and you won't change anybody's mind. 
See also these questions on Stackoverflow: - https://stackoverflow.com/questions/22354396/practical-difference-between-def-fx-int-x1-and-val-f-x-int-x1-in - https://stackoverflow.com/questions/9892976/defining-scala-function-differently - https://stackoverflow.com/questions/2529184/difference-between-method-and-function-in-scala
I've experienced this kind of thing with a lot of things on Spark. The problem is generally when Spark comes with one version of a library on its classpath and you want to use another. I'd stick with Spray, it's wonderful. But with Spark you'll have to get used to this kind of problem. I usually run `mvn dependency:tree` on my project and compare the output (or eclipse has a GUI version) to the jars in the spark lib dir before deploying anything to the cluster.
That's quite an ego-boosting title for a FP devotee like me, but I'd like it better if it was accompanied by cogent arguments. Why would intelligent programmers enjoy "difficulty, the need for strict discipline while coding, and its mathematical basis"? I think it's the opposite: with a strict compiler, programmers don't need as much self-discipline while programming, because the compiler will catch more errors for them. And if that increased strictness happens to make the language more difficult, well, that's a price we gladly pay because we can see the benefits, not a feature in and of itself. And please don't claim that FP projects are "inevitably successful", it's an hyperbolic claim which shows that your passion for FP has eclipsed your reason, and makes the rest of the article less trustworthy. I think the "magnet and filter" you're describing was better described by Paul Graham in his essay "[The Python Paradox](http://paulgraham.com/pypar.html)": passionate programmers take the time to explore new languages in a search for better ones, and so if you choose one of those good languages for your project, the people who will apply to work for your project will be those passionate people.
Yup, I'm doing a similar thing now. This should be fun :) 
I like FP as much as the next guy but this is a load of rubbish lol.
No, this is unchanged. It'll get slightly better in 0.4.0 after the fix for [#513](https://github.com/milessabin/shapeless/issues/513) in Shapeless 2.3.0, though.
Functional programs are better programs. Functional programmers aren't necessarily better programmers.
&gt; I'm talking on the level of wrapping every expression in a Task, not even for increased parallelism but so that they can be flatMapped together to avoid "impure" imperative code. Or creating custom Lenses for every data type and using those to access nested fields even when those fields never needed to be updated and normal dot notation would have sufficed. This just sounds like he or she was doing purely functional programming in Scala. `Task` isn't just for concurrency, and lenses aren't just about functional update. So if this is representative of your complaint with your colleague, can I get their résumé? :-)
It'd be interesting to compare with an implementation using [STArray](http://docs.typelevel.org/api/scalaz/nightly/index.html#scalaz.effect.STArray).
OK, I just read "A founder will have more applicatives..." Send help.
&gt; I'd stick with Spray, it's wonderful. But with Spark you'll have to get used to this kind of problem. I don't think there's a solution to the last version of Spray being based on Akka 2.2.x and Spark 1.5.0 being based on Akka 2.3.x, though. I strongly suspect the shortest path is migrating to Unfiltered. Spark unfortunately does a lot of its own classpath magic, and it's a mess. They should have used OSGi (yes, really). But here we are.
You could've created a proper pull request to your own repo. :) From "dumb mistakes" I can see far too many calls to ".get" on option. It's a source of errors and since you return also an option, method ".flatMap" seems to fit better. And now, let's open Battle.net launcher and do something different with their APIs.
Ah, [good catch](http://spray.io/project-info/current-versions/)! I was looking at the [dependencies](http://spray.io/documentation/1.2.3/spray-caching/#dependencies) section, which apparently purports to cover both 1.2.3 and 1.3.3, but doesn't. But [/u/MisterDoubleT](https://www.reddit.com/user/MisterDoubleT) is using Spray 1.3.3 and having difficulty with spark-submit so... yeah. The "get this stack working at all costs" model seems unwarranted to me when there are several good REST API serving alternatives.
Any time you need to do multiple actions stemming from an option, it's helpful to use for comprehensions. It's sugar for the repeated map and flatMap calls
Thanks, I just was reading up on them, I'm gonna add this to my list to re-implement all the ugly get chains into for comprehensions.
How do you create your Eclipse project? The recommended way is to use [sbteclipse](https://github.com/typesafehub/sbteclipse). I use the Scala IDE with sbteclipse-generated projects every day on Scala.js projects, and I don't have the problems you describe.
I'm glad this is fixable! I baselined off the project here. There must be something wrong. https://github.com/vmunier/play-with-scalajs-example
There is a license in the Readme? Do I need it in it's own file or something?
Try adding `EclipseKeys.useProjectId := true` at the end of the build.sbt file. Regenerate with `eclipse` then reimport the projects from Eclipse.
oh no I didn't see it, my bad
How can I get copy() or copy()-like behavior in this situation? Let's say you have code like this: sealed trait Food { val name: String } case class Fruit(name: String, sweet: Boolean) { ... } case class Vegetable(name: String, bitterness: Double) { ... } val sustenance: Array[Food] = Array(new Fruit("apple", true), new Vegetable("bitter melon", Infinity)) Then we'd like to create a new array by changing the bitterness field for bitter melon to 9001. This doesn't work: sustenance(1) = sustenance(1).copy(bitterness=9001) The reason is there's no copy() for the Food trait -- only for case classes themselves. Is there any way to do this so that I wouldn't have to explicitly write my own copy for each case class? Is there a better way to architect this approach? I'd like a more functional style if possible, but my googling has failed me.
He was let go months ago so if you can find him, you're more than welcome to him. The point is that if you're going to do something, then the benefits need to out-weight the costs. In neither of these cases were any benefit derived other than adhere to a shallow form of functional purity. I think it's safe to say that a big draw of functional programming for many people is that it can make programs simpler to reason about, so any unnecessary complexity by itself is a violation of that appeal and an added cost. That's not to say it's the only cost. Taking the Tasks around every expression, for example, there were so many instances being created that the service was spending a vast majority of its time in garbage collecting the very short lived instances. When we finally ripped out 90% of those Tasks our throughput increased by an order of magnitude.
Where on earth did you find a cluster consisting of 40,000 separate computers to push to? I mean Facebook has 80,000 servers and ~1 billion distinct users.
If you want to create new array, you should not use update metod (sugared as `sustance(1) = ...`), use `updated` instead. Easiest way to do it is: sustenance.updated(1, sustenance(1) match { case v: Vegetable =&gt; v.copy(bitterness = 9001) case other =&gt; throw new MatchError(s"$other should be vegetable") }) Note that 3rd line (`case other =&gt; ...`) is not required, but compiler will emit a warning that pattern matching is not exhaustive. Also, you can create "extension method" for array so you don't need to repeat index. First, you create implicit class: implicit class RichArray[A](val array: Array[A]) extends AnyVal { def updatedAt[B &gt;: A](index: Int)(updater: PartialFunction[A, B]) = { array.updated(index, updater(array(index))) } } And then you can import it where needed and use like that: val updatedArray = sustenance.updatedAt(1) { case v: Vegetable =&gt; v.copy(bitterness = 9001) } Looks good to me: clean and no compiler warnings (since partial functions do not require exhaustiveness). If second element in array is not an instance of Vegetable, runtime exception will be thrown: - if runtime exception is ok for you, then we are done :) - if you want instead of having runtime exception just silently do nothing, you can rewrite `updatedAt` function body like that: array.updated(index, updater.applyOrElse(array(index), identity[A])) - if you want *compile* time error, instead of arrays you should use heterogenous lists (it's a big topic, take a look at [shapeless](https://github.com/milessabin/shapeless/wiki/Feature-overview:-shapeless-2.0.0#singleton-typed-literals))
&gt; The point is that if you're going to do something, then the benefits need to out-weight the costs. In neither of these cases were any benefit derived other than adhere to a shallow form of functional purity. Forgive me, but I very much doubt this. I don't even trust the word "purity" precisely because people think it has more than one definition. The term "referential transparency" is to be preferred because it's unambiguous and constructive, and being unambiguous and constructive, is machine-checkable. &gt; I think it's safe to say that a big draw of functional programming for many people is that it can make programs simpler to reason about... Not _can_. _Does_. &gt; ...so any unnecessary complexity by itself is a violation of that appeal and an added cost. Of course this sounds good, but taken with: &gt; I'm talking on the level of wrapping every expression in a Task, not even for increased parallelism but so that they can be flatMapped together to avoid "impure" imperative code. Or creating custom Lenses for every data type and using those to access nested fields even when those fields never needed to be updated and normal dot notation would have sufficed. is a _huge_ red flag. I'd bet substantial quantities of money that if you pulled out substantial uses of `Task` and these lenses, your code is no longer referentially transparent (because `Task` was being used to provide referential transparency, not just referentially transparent concurrency), and/or your code is more _actually_ complex, e.g. has multiple access methods to the same case classes, rather than having more _perceived_ complexity, e.g. "why are we using `Task` for non-concurrent code? Why are we using Lenses for stuff we aren't updating?" &gt; Taking the Tasks around every expression, for example, there were so many instances being created that the service was spending a vast majority of its time in garbage collecting the very short lived instances. When we finally ripped out 90% of those Tasks our throughput increased by an order of magnitude. I believe that. The thing is, I'll take someone who understands referential transparency and teach them scalaz/JVM pragmatics in a month. Give me a JVM tuning expert with a decade's experience and I may not get safe, reliable code from them for six months, or ever. So how often is this an issue? My team has scalaz code in production at Verizon wireless scale, and we have exactly _one_ service that's showing GC pauses that we're concluding are too much, so we're looking at building something very lightweight and off-heap, probably with [scala-offheap](https://github.com/densh/scala-offheap). But however we do it, I can assure you it will still be referentially transparent.
I assume both the case classes have a "extends Food" on them. As already pointed out, you're working with a base trait (Object with Food). This will not work until the compiler got a concrete implementation it can call, so you'll need a match/case in there. Alternately, review your design. You're applying operations to a generic (trait Food) that aren't applicable to all members of that generic. Another implementation might be to supply a type parameter on the trait and then supply setters to return new values: trait Food[A] { def name:String def setBitterness(newVal:Double):A } case class Fruit(name:String, sweet:Boolean) extends Food[Fruit] { def setBitterness(newVal:Double) = this } case class Vegetable(name:String, bitterness:Double) extends Food[Vegetable] { def setBitterness(newVal:Double) = this.copy(bitterness = newVal) } If you view this from a very high level, you're implementing something that looks a lot like *copy*. In fact, you could use named parameters make it look a lot more like copy (but you couldn't require an implementation in the base trait since you've got multiple method signatures). Rinse and repeat for all your "generic" operations. I don't think the Generic Array implementation is capable of doing the job with this implementation -- I get an odd error trying to update the element. Vector works just fine, though. edit: I somehow screwed up the formatting.
Have you seen sbt-datatype? http://www.scala-sbt.org/0.13/docs/Datatype.html
The benchmark results [reported in the README](https://github.com/travisbrown/circe) haven't been updated for 0.3.0, but in a quick local test 0.3.0 looks pretty much the same as 0.2.1.
imo play framework, it's the most mature one and has a very active community
thanks, of course I know play, but I could not yet find a comprehensive open-source ecommerce solution -based on play, scalatra or whatever else.
I imagine you're going to have a hard time finding what you're looking for. It's the kind of thing people get paid good money to spend time developing for businesses. Also you're more likely to find an open source version of what you want in a more widespread language like java.
Also, you referred to the javax DocumentBuilderFactory which indeed allows the developer to setup the coalescing attribute. However, scala xml uses and expects a SAXParser, even if i were to override the method it would still expect a SAXParser which does not have a coalescing attribute. Am i missing something here? 
External Documents. I read them from a file descriptor to a String and then run XML.loadString(xml) which invokes the default SAXParser. I believe all i have to do is set Coalescing to false to the SAXParser but still trying to figure out how :/ Oh the life of a rookie
Still: http://www.computerworld.com/article/3010395/solid-state-drives/consumer-ssds-and-hard-drive-prices-are-nearing-parity.html
So you were being literal? That's interesting, and thanks for the clarification. It'd be interesting, then, to gain some of the next-step insight. I mean, if it's known that an expression is referentially transparent, and not being composed with another `Task`, what was this developer's rationale for using `Task`? If the answer you get is "referential transparency," isn't pointing out the expression is already referentially transparent sufficient? There certainly are times when we have `Task.now(...)` too, in other words, because the expression shows up in the middle of a for-comprehension with other `Task.async()` and `Task.delay()` clauses. Similarly, // Only usage of the lenses in the entire program, seems key. I'd understood the presence of case classes and Lenses to be more pervasive. But I gather you weren't able to convince your colleague of the points, and fair enough given that.
Nice! I like your design also.
Well it was a research language where success was not part of its initial consideration. It was invented to explore and because of its constraints its still a great language to explore and sharpen your skills. I question its usefulness in the real world myself but it hardly sucks, for what it was built for it does a great job and some of my most complete and robust small applications I wrote in Haskell.
Just admit you don't like Functional Programming languages, then you can take your misinformed trolling somewhere else.
&gt;Haskell sucks because even the most trivial things are painful. Because you're not using it the way it is supposed to. &gt;Also, as solid as the code is, the IDE's are not. Why need an IDE? The compiler will tell you where you were wrong in any case. &gt;Almost anything that I wanted to do in Haskell, I could do in Scala. You could also do that in Java, C and Assembly.
You can use record updates to handle the first bullet. No need to use lenses. Lenses become useful once you need to handle nested data, but for a simple record the built-in syntax is fine: Prelude&gt; data Person = Person {age :: Int } deriving Show Prelude&gt; let p1 = Person {age = 2} Prelude&gt; p1 Person {age = 2} Prelude&gt; let p2 = p1 {age = 3} Prelude&gt; p2 Person {age = 3} 
Are you trying to achieve anything constructive with your posts? Because if not, I suggest you don't keep posting here.
Inflammatory title: ✓ Random broken markup: ✓ Post with a 5th grade writing level: ✓ Contradict every criticism with empty praise in the same run on sentence: ✓ Make references to dank memes: ❌ 4/5 not bad.
Just remember that when you're doing this: x = x + 1 Just remember that you're actually doing this: x(i) = x(j) + 1 Or in other words, x from moment _i_ is equal to x from moment _j_ plus one. It goes without saying why that's very problematic, especially in a multi-threading context. In the real world there is no such thing as a "mutating int" and by modifying a value in-place you're losing information. Accountants for example never update data in place. Also, a person is a value, in the sense that information about that person are facts and facts are immutable. If you store the user's birthday, you don't need to increment any age field ;-)
Records have a number of big issues in Haskell, enough so that its not recommended to use them. One glaring issue is that records pollute the namespace when you import them
Do lenses fix this issue? Wouldn't you have to prefix all your lens names with the type or something like you'd have to with records? Or is the key difference that you can qualified-import lenses but record accessors are always imported unqualified or something?
 This might be a silly question but where does the A come from below? implicit def functionMonoid[A,B](implicit bm: Monoid[B]): Monoid[A =&gt; B] = new Monoid[A =&gt; B] { def id = A =&gt; bm.id def op(x: A =&gt; B, y: A =&gt; B): A =&gt; B = { a =&gt; bm.op(x(a), y(a)) } }
Walmart Canada has built their own e-commerce platform using Play, but it's not open source: http://www.nurun.com/en/news/nurun-launches-redesigned-transactional-platform-with-walmart-canada/ Start off with boilerplay: https://github.com/KyleU/boilerplay and then add a catalog and a shopping cart system -- that will take you most of the way.
&gt; def id = A =&gt; bm.id so I don't know why I used `A` instead of `a` here, but I normally would use `a`. Anyway, this is an anonymous function. Since this is a monoid for Functions, we have to return a function for the monoid `id`. In this case we create an anonymous function which ignores its argument and returns the `id` element from the `bm` monoid. so perhaps you would understand this better if I write it like this: def id: (A =&gt; B) = { (a: A) =&gt; bm.id }
I haven't done anything like a deep-dive, but this series is completely perplexing to me. Can someone help me with some context and maybe a general outline of what's going on here?
Duchey condescention: ✓ A tendency to focus on trivial details: ✓ A vocabulary that is better than yours: ✓ Inability to distinguish between praise and defeat: ✓ Make references to dank memes: ❌ 4/5 not bad. 
And it's not just learn a little bit of Scala. No. I have to learn SBT and Akka and Monads and trampolines and scallaz and all this crap. All because I can't type without auto-complete and because I hate mutable state and because I need a few features. I could be going to grad school. I could be applying for jobs. But no. I need to learn fucking Scala.
This is not the first time he posted this kind of trash, nor is it likely to be the last. I think a ban would be both overkill and useless - he seems driven enough to just create fake accounts to post his flamebait. On the other hand, nuking these posts would at least prevent the damage they do - if they are the first glimpse newcomers have of this sub, it's probably quite a turnoff.
I think he is trying to change scalas type system into a full logic. This is useful because the study of logic is much older than programming languages so you can build onto past experiences. Soundness is a logical property. which means the system you are using produces correct results. (correct me if I'm wrong). So what he does with DOT is starting small. So that reasoning about the system becomes easier and that early bugs can be squashed. Then once he is confident in that system he tries to scale it up into full Scala.
Sounds like a real predicament, though I don't exactly understand your problem. Sublime Text has an awesome autocomplete, but it is based on the source you're currently in. You can copy-paste from Javadocs/Scaladocs. If Scala makes you mad, you can use Play and Akka in Java, with Sublime and copy-paste from Javadoc. True, Scala is hard to learn, but there's a lot of other awesome tools out there. Maybe you'll even find Play with all its shining and sparkling reactive stuff too heavy for your particular project; I personaly prefer Scalatra.
Typesafe recently decided to release those drivers as open source as well: http://slick.typesafe.com/news/2016/02/01/slick-extensions-licensing-change.html In the next release they will be bundled with slick itself, for now I guess that you can safely use the driver package released for development.
did you check these: https://github.com/lauris/awesome-scala#database
Through not strictly an ORM and originally a Java framework our team made good experiences using JOOQ (http://www.jooq.org/) with scala. It is a simple SQL-framework: You have to do the queries and most of the mapping yourself, but then JOOQ abstracts different different SQL-dialects from you and ensures type safety.
Sorry, I forgot that scala-xml uses SAXParser. Regardless, the compiler setting does not affect any part of the scala-xml module itself, only a few places in the main scala module itself: https://github.com/scala/scala/blob/2.12.x/src/compiler/scala/tools/nsc/ast/parser/MarkupParsers.scala#L237 So you may not be able to do what you're trying to do with classes from scala-xml alone.
http://getquill.io
From this piece of code: // XML parsing options object XxmlSettings extends MultiChoiceEnumeration { val coalescing = Choice("coalescing", "Convert PCData to Text and coalesce sibling nodes") def isCoalescing = (Xxml contains coalescing) || (!isScala212 &amp;&amp; !Xxml.isSetByUser) } val Xxml = MultiChoiceSetting( name = "-Xxml", helpArg = "property", descr = "Configure XML parsing", domain = XxmlSettings ) Should i not be able to setup the -Xxml coalescing property to false? Sadly, when i prompt scalac for -Xxml:help it only accepts -Xxml:coalescing which would set it as true. But i believe the default is already true. Kinda confused
Fair point, Simon Marlow is not your average programmer. However, there are other examples: * http://www.yesodweb.com/blog/2014/02/new-warp * http://haskell-distributed.github.io/ * https://github.com/diagrams/diagrams * https://wiki.haskell.org/Haskell_in_industry 
+1 for slick. Using it in production and I love it! The code generator for generating table models from your schema is great. 
Slick gets my vote too. Someone in your shoes might find the [awesome scala](https://github.com/lauris/awesome-scala) list useful as well before you get started.
Having multiple attributes doesn't necessarily mean a type representing a Person in code has to be nested. All the things you listed could be flat attributes of a single record. Also, updating nested data in mutable languages isn't much prettier than it is in Haskell/Scala. And at least in Haskell and Scala you can abstract over data type nesting in a first-class manner with lenses.
&gt; Church-Turing Thesis The operative word is "thesis" as in a conjecture about computable functions. The turing machine is not a good mechanism to think about your code in any practical sense. However, applying category theory or topology to understand the invariants of one's computational problem will make you better programmer and lead to better and well-defined APIs. &gt; If a procedural program couldn't be reasoned about formally you wouldn't be able to create a practical application Simply not true. How many imperative programs do you know that has been proven to be correct? Take something simpler than a program, take some imperative API, how many of those have been proven to be correct? Monads provide a way to model imperative computations. It's a mathematical object that can be reasoned about as any such object. &gt; Anything that can be reasoned about is modeled in mathematics Not true, but we can gloss over that. But FP is open to the application of large tracts of mathematics to help in reasoning and proving a computation. &gt; Understanding the system of trade-offs You'll be much more successful in understanding these trade-offs in FP where the separation between code and mathematics is minimal. The link below may provide a good example of the statement above: [An example of fast numerical computation using Haskell](http://www.mit.edu/~mtikekar/posts/stream-fusion.html) It's impossible to do even mildly-nontrivial physics or serious engineering without a background in mathematics. Their success is due their application of mathematics. I see no reason why CS should be any different. And it won't be. It's mostly being worked out by the FP camp.
This is a pointless discussion. 
That seems like a very nice idea. Thank you.
Best of luck to you!
I'll take that to mean you've realized how much hogwash you've made public on the internet. I understand though. Choosing precise language and making well-founded assertions is tough. Its not for everyone.
Fair enough. Scala with scalaz will give you FP. You can still play around with FP techniques, if that's your goal.
The link is to an assignment I already completed, so I'm not doing this for homework help or anything like that. I wrote it in a OOP-style with arrays to represent the grid, getters/setters to open cells, etc. I tried to make it as functional as possible but cannot see how the entire problem can be modeled without imperative techniques. If we want to conform to functional design, must we rebuild the grid every time a square is modified? (This sounds *horrible*)
This is exactly what I was looking for, thank you! However, it seems horribly inefficient and I think I'm gonna stick with imperative solutions for these problems. Do functional languages truly have no practical solution for graph processing?
Hello, and have a good weekends, everyone. I have quite a newbie question. Let's imagine there is a code that requires some checks due the course of execution. Live example is below. It works, yeah, but I feel like it could be rewritten using Either in a more comprehensive and clean way. Someone mentioned that there is a `kleisli categories` that should be used in a such o a cases. Any advice, please? Option(db.findById(orderId)).map { order =&gt; if (order.owner.userId == callerId) { if (order.state == State.FULLFILLED) { db.delete(orderId) Right(order) } else { Left(InvalidOrder) } } else { Left(InsufficientPermission) } }.getOrElse(Left(OrderNotFound))
Yours is a very interesting question. The first thing you could try to do is to separate side-effects from your computation. Extract the side-effect from your computation like this: // Side-effects-free computation val deletableOrError: Either[OrderError, Order] = Option(db.findById(orderId)).map { order =&gt; if (order.owner.userId == callerId) { if (order.state == FULLFILLED) { Right(order) } else { Left(InvalidOrder) } } else { Left(InsufficientPermission) } }.getOrElse(Left(OrderNotFound)) // Side-effects isolated here for (order &lt;- deletableOrError.right) { db.delete(orderId) } Now, when I see all this if-nesting I ask myself if it would not be possible to write something more elegant / Scala-like... Allow a semi-newbie like me to try to deliver such a more elegant solution. Note that I have no knowledge of the more functional libraries like shapeless, scalaz, etc. I hope that somebody better qualified can provide you a better answer using one of these pre-existing libraries. At the end, I would like to have something like this: val deletableOrError: Either[OrderError, Order] = Option(db.findById(orderId)) .toLeftIfNone(OrderNotFound) .toLeftIfFalse(_.owner.userId == callerId)(InsufficientPermission) .toLeftIfFalse(_.state == FULLFILLED)(InvalidOrder) for (order &lt;- deletableOrError.right) { db.delete(order.id) } I start by wrapping the "findById" (which we assume to return null) to an Option. If you defined that method and it's in Scala land, strongly consider to make it return an Option in the first place. Only wrap potential null-values if interfacing with Java APIs. Then if that Option is not defined, it is transformed to a "Left" value, wrapping whatever I give it as a parameter. In this case "OrderNotFound". If it IS defined, it is mapped to a "Right" value (Some -&gt; Right). In the two following lines, we evaluate something against the "Either" that resulted in the first mapping operation. If that "Either" value is already a "Left", it is passed untouched. Only if it's a "Right" the condition is evaluated against it. If the condition evaluates to false, then the second parameter given is wrapped to a "Left" value. Note that this short-circuits: as soon as we have a "Left", all other mappings are skipped. At the end, we have an "Either", which is either an "OrderError" (fictive superclass of your errors; it could be a Throwable or a sealed-trait) or a proper "Order" which you know you can delete. Finally, you can proceed with your side-effect part and delete the order. In order to have these two new functions `toLeftIfNone` and `toLeftIfFalse`, I used the pimp-my-library "trick" by "extending" `Option` and `Either` like this: implicit class RichOption[T](opt: Option[T]) { /** * If this Option is defined, returns its defined * value as a Right, otherwise it returns * Left(leftValue). **/ def toLeftIfNone[A](leftValue: A): Either[A, T] = { opt.map { value =&gt; Right(value) } getOrElse Left(leftValue) } } implicit class RichEither[L, R](e: Either[L, R]) { /** * If this augmented Either is a Right value, it evaluates * the condition against it. If it evaluates to "true", * then the Right value is passed. * In any other case, the function returns Left(leftValue). **/ def toLeftIfFalse(condition: R =&gt; Boolean)(leftValue: L): Either[L, R] = { val definedIfRight = e.right.toOption val definedIfRightAndTrue = definedIfRight.filter(condition) definedIfRightAndTrue.map(Right(_)).getOrElse(Left(leftValue)) } } Note that for simplicity I left out variance indicators (e.g. it should be `RichOption[+T]`, with a "plus"). Advanced readers are more than welcome to point out improvements to type-system related issues. Again, if something like this exists already please let me/us know. Otherwise I hope this helps.
See [Quiver](https://github.com/oncue/quiver), our port of [fgl](https://hackage.haskell.org/package/fgl) to Scala. I also second the recommendation to read Okasaki. Finally, be aware that, with attention to sharing, functional data structures can be _faster_ than imperative ones due to caching on modern processor/memory architectures.
Clojure does this with update-in cljs.user=&gt; (def o [[41 42] [43 44]]) cljs.user=&gt; (update-in o [1 0] (fn [x] (+ x 100))) ;; [[41 42] [143 44]] cljs.user=&gt; (update-in o [1 0] + 100) ;; syntax sugar I am posting clojure because I am entirely dissatisfied with the answers so far in this thread. Updating immutable structures should be easy and surely there is an easy way to do it in scala.
BTW, I thought you meant graphs as in graphs. :-) If you just mean arrays, see [STArray](http://docs.typelevel.org/api/scalaz/stable/7.1.0-M3/doc/#scalaz.effect.STArray), i.e. referentially transparent mutable arrays.
You want lenses. Note that you'll need a HList instead of an array so that you can preserve the type information. Check out Monocle and Shapeless. I'm happy to help in more detail if you need it. 
Do you know of any Github repos that have answered Okasaki's exercises in either ML or Haskell, Paul? I had gotten up to ch4 (heaps, I believe), but ran into trouble/stumbled on my lack of familiarity with ML. If there was a comparison guide of answers (ML or Haskell), I think that would help (at least me) to continue making progress in that text.
Here's a [heap](http://hackage.haskell.org/package/heaps), unsurprisingly from Ed Kmett. [Here's](https://github.com/tianyicui/pfds-ocaml) a collection in OCaml. You might also find the [proven functionally correct](http://www.chargueraud.org/softs/cfml/) versions interesting.
&gt; I code scientific apps in Scala for a living Such as? I used to do this too.
As someone who has spent a decent amount of time optimizing code, I have yet to see a single case where a functional data structure is even close to as performant as a mutable one. Functional data structures make it easier to reason about your code, but they are absolute performance killers. Even most mutable data structures pale in comparison to the fastest data structure of them all, the array of numbers. For instance I managed to make some NLP code I wrote in grad school 100x faster by switching from a HashMap&lt;String, Double&gt; to an array of doubles by "interning" all the strings and assigning an index to each. In that class, we were supposed to learn how to use a supercomputer in order to process the documents in time. By making the code 100x faster with smart data structures and parallelizing it across cores, I was able to do the processing fine on a simple desktop.
&gt; As someone who has spent a decent amount of time optimizing code, I have yet to see a single case where a functional data structure is even close to as performant as a mutable one. It's certainly not _common_, but it [does happen](https://www.cs.tufts.edu/~nr/pubs/zipcfg.pdf). I suspect the context has to be a lot like this one, i.e. a relatively large structure with relatively sparse pointer manipulation killing cache locality, vs. a lot of small, short-lived allocations with a copying collector, so when GC does happen, it _improves_ cache locality. In general, though, of course, you're right. But measure anyway. &gt; Even most mutable data structures pale in comparison to the fastest data structure of them all, the array of numbers. Yep. It's one reason I like to point people to [STArray](http://docs.typelevel.org/api/scalaz/stable/7.1.0-M3/doc/#scalaz.effect.STArray). You do not have to give up mutable arrays for the sake of referential transparency. &gt; For instance I managed to make some NLP code I wrote in grad school 100x faster by switching from a HashMap&lt;String, Double&gt; to an array of doubles by "interning" all the strings and assigning an index to each. Not at all surprising. High-performance code will often do things like use specialization to take advantage of libraries like [fastutil](http://www.scala-blogs.org/2008/10/manifests-reified-types.html). Certainly, when performance counts, care like this should be taken. &gt; In that class, we were supposed to learn how to use a supercomputer in order to process the documents in time. By making the code 100x faster with smart data structures and parallelizing it across cores, I was able to do the processing fine on a simple desktop. Which is great, but did you learn the supercomputer approach, too? :-) Class exercises often don't "need" what they're asking for, being _exercises_.
Seems somewhat biased. since its from the quill project.
I don't think you need Kleisli categories since you're only actually working with one effect. Using Scalaz (need 7.2 for `unlessMU`) and `\/` aka `Disjunction` (the ScalaZ version of `Either`) I'd write something like: import scalaz._, Scalaz._ //good practice to be more specific but I can't remember the details for { order &lt;- Option(db.findById(orderId)).toRightDisjunction(OrderNotFound) _ &lt;- (order.owner.userId == callerId).unlessMU(InsufficientPermission.left) _ &lt;- (order.state == State.FULFILLED).unlessMU(InvalidOrder.left) } yield { db.delete(orderId) order }
Thank you a lot, have to accommodate myself to this ideas.
It's good to see that something like what I suggested already exists. However, if I understand correctly the error value gets lost, right? (if something goes wrong the whole thing would evaluate to None?)
Does the solution to 3# prohibit the idiom/trick for 'constructing' context bounds from multi-parameter types? For example: def stringify[T: Stringifyable](in: T) = ... is current syntactic sugar for def stringify[T](in: T)(implicit ev: Stringifyable[T]): String = ... But, this doesn't work (directly) when multiple type parameters are involved. For example, def chain[A,B](acc: A, next: B)(implicit ev: CanBeFed[A,B]) = ... However, the following use of type functions/projections gets it to work: object CanBeFed { type By[B] = {type CB[A] = CanBeFed[A,B]} ...} def chain[A: CanBeFed.By[B]#CB, B](acc: A, next: B) = ... I suppose I am not sure if that structural type {type CB[A] = CanBeFed[A,B]} is considered concrete enough (it will never be instantiated although everything is defined). This has been my primary use of cleverer typing when writing DSLs and it would be a shame to see it go. Although, a generalization of the context bound syntactic sugar to allow it to work better would probably be even better (namely, being able to get rid of the explicit type projection).
If at least 2 allocations for inserting/appending a primitive isn't horrific for you ... well ... have fun with your vectors. They're a good tool, but pretending they're efficient is strange. 
None of those lines are actually using any monoids, we use a monoid on the subsequent line that calls fold. The call to fold looks for monoids to be in implicit scope at the call site. We brought them into scope by importing everything from the Monoid object: &gt; import Monoid._ 
allocations the jvm are dirt cheap. There are definitely use cases where that even small, ephemeral garbage that is generated by immutable structures can hurt you, but for many use cases, you really don't need to care.
I think it’ll be tough because folks who write Scala programs that are very different from Java programs don’t like to write Java programs :-/
It's a trivial application meant to track things (an SWTOR Cartel Market tracker, to replace the spreadsheet I'm currently using). Mainly it's an excuse to learn Scala while I expand the capabilities of what-used-to-be-a-spreadsheet. I'd like to avoid going the browser route for now, since that involves an entire stack that I'd rather not deal with for this. I can see going that route--later. Thanks for the suggestion.
The JVM GUI story is a disaster, sorry. Your best bet is probably the Java Swing APIs ... the Scala wrapper is incomplete and undocumented, and you end up having to drop into the Java API pretty quickly anyway. It's deeply awful but that's the reality of things.
Really? I think it's pretty good actually swing and JavaFx always did everything I needed. 
I could share a skeleton project and give you some hints if you need.
Will this help? https://github.com/atemerev/skynet Ignore the benchmark part. The same program has been written in different languages. 
Correct me if I am wrong, but I don't think that IntelliJ uses swing anymore. They used to, but I think they now use a much lower level library.
They built their own look-and-feel, and probably most of the code editors go down to Java2D, but [I see a lot of Swing bases](https://github.com/JetBrains/intellij-community/search?p=2&amp;q=JComponent&amp;utf8=%E2%9C%93).
What's the raison-d'être for 'suit'? At first glance it looks like a design very similar to Scala-Swing.
Use the latest Java8. That is the big one. Then have newest SBT use newest Scala. Then you should be in good shape :)
apt-get gives you the latest version: $ sudo apt-cache policy scala scala: Installed: 2.11.7 Candidate: 2.11.7
This is fascinating, thanks for posting
Show them examples of: case classes, pattern matching, and for comprehensions. The three easiest and sugariest parts of scala. Avoid talking about functional programming at all cost. Don't even bring up concepts like Option, folds, lazy programming. Most java devs didn't learn the new java 8 APIs, and the ones that did, won't need any convincing to switch to scala.
Well, I disagree. Swing "works really well … across all platforms". JavaFX although it uses CSS in no way builds on web technologies, other than adding a dedicated Web view. Just like Swing it sits on top of Java2D, if I'm not mistaken. You can skin Swing to look like native toolkits, but you can use look and feels that, just like the default JavaFX look and feel (which certainly doesn't win a beauty contest), look the same on all platforms. There are some high quality LaFs for Swing. In that respect Swing is no different than for example Qt. JavaFX simply adds more "effects" like transitions and the stuff, an XML description layer (which sucks if you want to programmatically create UIs), and some improved components (table view I think). As a price, it doesn't run on older Java platforms such as Java 6 and Java 7. I'm not even sure that you have particular good support under OpenJDK 8.
&gt; What's the raison-d'être for 'suit'? "An utility for Scala to use Java's swing library and others a lot easier and to create gui-based applications faster with rich client components. It introduces some other components from libraries and connects those here. " It's planned to be a richer(more layouts &amp; components) and simpler swing. Scala-swing isn't supported anymore and I didn't like its syntax. Consider a little button-app with Scala-swing and suit: import scala.swing._ import scala.swing.event._ object ScalaSwingButtonApp extends SimpleSwingApplication { def top = new MainFrame { title = "My Frame" contents = new GridPanel(2, 2) { hGap = 3 vGap = 3 contents += new Button { text = "Press Me!" reactions += { case ButtonClicked(_) =&gt; text = "Hello Scala" } } } size = new Dimension(300, 80) } } and import org.suit._ import layouts._ object SuitButtonApp extends DesktopApp("My Frame") { val layout = GridLayout(2, 2) layout.vGap = 3 layout.hGap = 3 frame.layout = layout val btn = Button("Press Me!") frame += (btn @&gt; (btn.text = "Hello Scala")) frame.size = Size(300, 800) } 
&gt; Scala-swing isn't supported anymore Well, it's as much supported as your custom library. It is an open source library with some community members taking a bit of care for it. If people submit improvements and bug fixes, they will be reviewed and merged. Certainly you will be able to use Scala-Swing for years to come. If your library would abstract from Swing altogether, making it possible to plug into different user interface kits, I would see the point of writing a new library.
&gt; If your library would abstract from Swing altogether, making it possible to plug into different user interface kits, I would see the point of writing a new library. suit has been suspended in december. For now, I wouldn't use any of them instead of a web platform in a real world app. + suit was never released/advertised and it was planned to be a UI toolkit on desktop/android/web. &gt; It is an open source library with some community members taking a bit of care for it. If people submit improvements and bug fixes, they will be reviewed and merged. scala-swing is "mostly-unsupported" from last may and there are no bug fixes from then. Of course, if you like it and use it effectively then it's good enough. 
Well, yeah, the benchmark is totally off, Akka is not really scala, it's just a high overhead library.
Try doing sbt clean
Scala.js + Web UI?
I would argue that readability is a part of cleanness. As a matter of the fact there were hardly any cases where I saw clean functional code and it was not more readable than its imperative counterpart. Could you give us some examples on code that you find readable and its less readable clean counterpart? I want to be sure I understood you correctly. EDIT: I figured out that you probably meant using vals in functions against using just chains of calls so that vals won't be needed. Personally I try my function at first to be one chain of operations. If I cannot obtain that, because, e.g. I need some value more than once and it needs to be calculated and it begs for storing that in a val, I do this. I would try to achieve it without vals, but sometimes your function will be smelly if you leave it as a bigass chain. Sometimes refactoring helps and sometimes all you need to solve the problem is just extracting one or two vals. Always aim for readabilty. Tomorrow's you will be grateful.
I let IntelliJ handle the installation of Scala on Ubuntu 14.04. Use the package manager to get Oracle JDK 8 from the webupd8 ppa.
Quill's codebase is [very well tested](https://codecov.io/github/getquill/quill) when compared to the other available alternatives and, given the fact that query generation happens at compile time, the amount of code used at runtime is minimal. It's almost equivalent to using the database driver directly at runtime, so eventual bugs are easily detected during compilation before even running tests. In comparison to Slick, I'd consider Quill more stable. Its query engine is based on a principled set of normalization rules [published](http://homepages.inf.ed.ac.uk/slindley/papers/practical-theory-of-linq.pdf) by Philip Wadler et al., while Slick's is a fragile [(example)](https://github.com/slick/slick/issues/1424) ad-hoc compilation mechanism. The high test coverage together with the lean normalization engine make it easier to fix bugs in Quill, you can observe the fast-paced evolution of the project comparing [its pulse](https://github.com/getquill/quill/pulse/monthly) to [Slick's](https://github.com/slick/slick/pulse/monthly). Currently, there are [very few](https://github.com/getquill/quill/issues?q=is%3Aissue+is%3Aopen+label%3Abug) known bugs and new bug reports are fixed within days. Quill's API isn't considered stable yet because there are some [important changes](https://github.com/getquill/quill/issues?q=is%3Aissue+is%3Aopen+label%3A1.0) in development. As of today, there's only one more main feature missing, that is better handling of auto-generated columns. On the contrary to Slick's major releases, that require complete rewrite of the applications using it, Quill's future releases aren't expected to require major rewrites. For instance, while Slick introduced `DBIO` changing most of its API, Quill will provide a similar monad probably without changes to the current APIs. In terms of performance, Quill tends to be more scalable. The runtime overhead is minimal and it has proper implementation of non-blocking database access, not only a an async wrapper on top of blocking IO. I haven't had time to validate it yet, but there's a benchmark comparing Quill and Slick created by Jilen: http://jilen.github.io/sdb.
Did you mean var? They are the mutable variables that you should avoid when writing purely functional code
I'm writing a small service which needs to poll from a SQL db, transform the records and publish them to Kafka. Its basically done with normal Akka but I'm unhappy with the result as its really hard to see the flow of the application, there is a batching actor, business metrics stats reported, db access and a kafka producer. It runs every configured set of seconds. Would Akka Streams be a better at this job? Is there a way to make the data flow more explicit?
functional programming is about immutability and composition, vals are immutable, values can be substituted for the expression they are equivalent to and compose equivalently to said expression, use them, one-liner monstrosities are the anti-pattern here
A problem you may run into is the wealth of nearly incomprehensible examples out there (I am looking at you shapeless!). Here is a fibonacci example using Shapeless. Someone seeing this as an example of "good" Scala for the first time would probably run screaming. class Fibonacci[I &lt;: Nat, N &lt;: Nat] object Fibonacci { def apply(i: Nat, j: Nat) = new Fibonacci[i.N, j.N] implicit val fib0 = Fibonacci(0, 0) implicit val fib1 = Fibonacci(1, 1) implicit def fibN[I &lt;: Nat, L &lt;: Nat, M &lt;: Nat] (implicit l : Fibonacci[I, L], m : Fibonacci[Succ[I], M], sum : Sum[L, M]) = new Fibonacci[Succ[Succ[I]], sum.Out] } def fibonacci[N &lt;: Nat](i : Nat)(implicit fib : Fibonacci[i.N, N], wn: Witness.Aux[N]): N = wn.value
I would argue that Option is one of the very first things a newcomer to Scala should learn, followed closely by pattern matching, and then lazy vals. These concepts allow a newcomer to begin programming in a functional-ish way almost immediately without even realizing that they are doing so.
I've got no Haskell or ML version, but here are [Scala solutions to most exercises up to chapter 9](https://github.com/KamchatkaLtd/okasaki). Hope it helps, and beware of the spoilers!
Let's say a typical (incremental) compile on desktop takes 5s, on an amazon micro 50s, where would I find e.g. the i5 surface pro 4 or the dell xps 13? 
What is the best up-to-date learning resource for Akka? Can anyone recommend one of: * [Akka in Action](https://www.manning.com/books/akka-in-action) * [Reactive Messaging Patterns with the Actor Model](http://www.amazon.ca/Reactive-Messaging-Patterns-Actor-Model-ebook/dp/B011S8YC5G) Or something else? Bonus points for a book with exercises, I find that really helps me learn (like Functional Programming in Scala style)
If I do that `sbt reload update` ends up erroring. I tried bumping my scala version down to 2.8.1 but that didn't help. Edit: Oh damn, this wasn't the issue but still needed to get it to run, thanks.
There are two Scala features, which just does not click somehow (beginner coder here): * implicits * options Can anyone ELI5?
If you're new to SBT, I'd suggest having a read of https://github.com/shekhargulati/52-technologies-in-2016/blob/master/02-sbt/README.md It sounds like it might not know where your source folder is and just picking up the compiled classes from your 'target' folder. What happens if you 'clean' before you 'run'? The whole "lazy val root = (project in file("."))." isn't needed if you're just using a default project layout/don't have lots of modules that you want to compose. You should just be able to 'libraryDependencies += [blah]' to pull stuff in. 
&gt; $ sudo apt-cache policy scala :( me@machine:~$ sudo apt-cache policy scala [sudo] password for me: scala: Installed: (none) Candidate: 2.9.2+dfsg-2 Version table: 2.9.2+dfsg-2 0 500 http://us.archive.ubuntu.com/ubuntu/ trusty/universe amd64 Packages me@machine:~$ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 14.04.4 LTS Release: 14.04 Codename: trusty 
[You should get the latest JRE from the webupd8 PPA (the official Oracle one).](https://launchpad.net/~webupd8team/+archive/ubuntu/java) For Scala itself, I've never had luck with the package manager for Scala or any other JVM-dependent thing, and I've been writing Scala on Ubuntu LTSes for 5-6 years. I install Scala from a tarball from scala-lang.org basically just for the REPL. I let my build tool (Maven or SBT) handle downloading a particular Scala compiler and standard library versions.
Thanks for the link. I'm new with sbt but I was doing it right all along, I just for some reason had a copy of my main class in src/main that I was editing instead of the real one in src/main/scala. I have no idea where the other file even originated from but total oversight on my part.
Pretty sure it's scala build tool edit: checked, while wikipedia claims its scala build tool it's often mentioned as "the simple build tool"
implicits means two things: implicit conversion and implicit parameters. implicit conversions are defined like this implicit def dog2cat(d: Dog): Cat = /* etc */ If this implicit def is imported, then if you try to use a Dog where a Cat is required, the compiler will use this implicit conversion to convert the Dog to a Cat without you having to do anything. This sort of usage is discouraged, however. The most common use-case for implicit conversions is adding methods/operators to types. For instance, say we want to add a .quoted method to strings that quotes the given string. We would do it like this: class QuotedString(s : String) { def quoted: String = "\"" + s + "\"" } implicit def toQuotedString(s: String): QuotedString = new QuotedString(s) Then you can import it and do "test".quoted .quoted isn't a method on String, so the compiler tries to find an implicit conversion in scope to get this to compile. It'll find toQuotedString. implicit parameters are different. They are parameters to methods that are keyed by their type. So if I have an Int implicit parameter and I do not provide it explicitly, the compiler will look in scope to try to find an implicit Int declaration and then use that one. If it finds two, it will fail due to ambiguity. Implicit parameters are most commonly paired with generics to constrain types via the typeclass pattern.
It *should* definitely be "Scala Build Tool". Curiously, the new SBT book still calls it on the cover "Simple Build Tool". Unless it's sarcasm, I don't get why the editor or authors went with that.
I don't disagree on the difficulties of sbt, but instead of trying for days and wasting your time, you should just have asked the community, for example in the [Scala.js gitter channel](https://gitter.im/scala-js/scala-js). I think I even have an [example](https://github.com/ebruchez/darius-xpath.js/blob/master/build.sbt) here of how to do it.
Historically it was the simple-build-tool. I guess the authors realized themselves that this wasn't always true, so it was changed to sbt, and now we have a bacronym like 'Scala Build Tool' :)
Is scala's yield a safe way to express a C style long jump?
The blank line issue [has been fixed in sbt 0.13.7](http://stackoverflow.com/questions/21780787/why-does-sbt-version-%E2%89%A4-0-13-6-require-blank-lines-between-settings-in-sbt-fil) so you are beating a (recently) dead horse.
Thanks for the comments and help guys. I do wish scala had some idea of like an implicit english import for different packages. It's just been maddeningly frustrating, and I felt like the syntax was just a disaster. Although being in intellij I think has helped a bit. I wish I had clickable sources with documentation. I'm sure that's around though I just need to find it. Thanks again for hearing me out.
the name is terrible.
Don't want to be "that guy" but... I don't like it. I thought Typesafe was a clever name that sounds professional and is somewhat related to the field - keeping your type safe. Lightbend just sounds like some generic "hip and with it" marketing company who want to sell you wordpress "web design" packages. In the end it doesn't matter much really but I think it's a shame to waste a good name.
I also really quite liked the name.
I've never understood folding before. after being explained the folding domino's once I forever now understand. I still don't know the English equivalents.
It's clearly satire. It's just not even good satire.
It's simple to me. I just avoid it :) But the zinc incremental compiler is decent.
yes, please go back to Typesafe.
What a sad day for Scala. Hopefully they will learn from the Borland/Inprise/Borland fiasco and revert the decision.
Satire of what? 79 character line length limits?
Operators: there is exactly *one* operator you need to remember in sbt: the := And honestly, I would find a build much *less* readable if it read: set(name, "My Project") rather than name := "My Project" += and ++= logically derive from := and are completely in sync with the collection libraries. All other operators of sbt are superfluous and should not be used anymore. They were made useless by sbt 0.13, which was released more than 2 years ago. As was said in another commit, the blank line bullshit was fixed, too. "Make the darn thing faster"? Yeah, maybe. Its startup time is a pain, but then I *launch* sbt perhaps twice a day, so it's really no big deal. The sbt hate has to stop. **We keep getting arguments that date back to sbt 0.12**, like *all the time*.
I really do understand the argument of "having a name that caters to your target buyers"...but when it comes to things like this I believe it is a balance of having a name that is not horrid to start with, and then, the most important part is the "life" (branding and marketing) that is imbued into that name... "Oracle" as a name can also be seen to sound meaningless to top level managers...only that it does not, because of the investment that has gone into that name...same can be said of "Windows" of "Apple" or "Facebook" or "Toyota"... Typesafe was not an horrid name to have start with. Not sure about lightbend though. 
SBT is a weird beast. It starts off pretty simple, then you get to the point where you want to do things a bit more sophisticated than just `compile whatever is in src/main/scala` and you spend hours pulling your hair out, then you actually sit down and learn the tool and... back to simple. I went through the process and there was a period in which I absolutely loathed SBT. After biting the bullet and reading SBT in Action (good book, very poor proof-reading) and adding new features to an existing SBT plugin, I'm back to thinking it's a pretty well thought out piece of engineering. Not intuitive, mind you, and the syntax does take some getting used to, but once it clicks it's fairly straightforward. The way you're going at it, though - starting with something complicated and trying to summon the right invocation to get it to work - is sure to end in tears of frustration. Depending on your goal, I'd advise asking for help (if you're not interested in learning SBT, which is fair) or taking the time to actually learn how the tool works (if you're more interested in a long term investment).
I stopped using SBT mid 2015. It was a slightly complex project setup with submodules and IntelliJ struggled every day. It was a breeze to use Maven + IntelliJ afterwards.
Sometime ago, when I was giving my first steps into Scala + SBT I googled some doubt I had at that time, and in a StackOverflow post I saw a discussion about why not using Maven with some plugin for scala. Even though some will argue that maven sucks because of XML, it's kinda performant, and I very stable. Anyway, now it's to late to go back and focus on maven and discard SBT :)
From the [example project](https://github.com/smarter/dotty-example-project/blob/master/build.sbt): // Dotty version scalaVersion := "0.1-SNAPSHOT" // Note: Dotty can use Scala 2.11 libraries so we set `scalaBinaryVersion` // to `2.11` for convenience. However, if you publish an artefact compiled // with Dotty, you should set it to `0.1`, this will force you to change // your library dependencies to be of the form `"org.foo" % "bar_2.11" % "1.0"` // instead of `"org.foo" %% "bar" % "1.0"` scalaBinaryVersion := "2.11" // By default, sbt will depend on the scala-library version `scalaVersion`, // so we need to override it. autoScalaLibrary := false // 2.11.5 is the version used by Dotty itself currently, we do the same to // avoid trouble. libraryDependencies += "org.scala-lang" % "scala-library" % "2.11.5" // Maintained at https://github.com/smarter/dotty-bridge scalaCompilerBridgeSource := ("ch.epfl.lamp" % "dotty-bridge" % "0.1-SNAPSHOT" % "component").sources() First you have to clone and `publish-local` [dotty](https://github.com/lampepfl/dotty/) and the [dotty-bridge](https://github.com/smarter/dotty-bridge) yourself, though.
That seems crazy but I guess it makes sense...
Don't worry you'll get used to it even if you have the IQ of a squirrel.
Personally the issue with SBT for me is that its design doesn't really fit well for how people generally approach build tools. It seems like SBT's design was sought of spawn offed how maven did things, but then SBT introduced a whole level of abstractions over abstractions and it kinda turned into a monster. The problem that I see all the time with SBT is, that while its really easy to use when your project is trivial in definition (just plonking stuff in `libraryDependencies`), once you start wanting to do something that is non trivial, you kinda hit a brick wall, and I think this is what is indicative of a not well thought out design (hypothetically speaking, if SBT had a good design, this step would be intuitive). In other words, SBT seems to be great for trivial setups, and maybe the really complex setups that are provided for you (i.e. the Play webframework), but the middle ground (which is where a lot of people end up) has a gaping whole that is left to be undesired. This often creates the situation where you have the "SBT guy", which is the guy that manages SBT because no one else seems to understand the tool. Then you have these weird inconsistencies (the last thing you want in build tools is inconsistencies). This includes - 2 seperate ways to define build files (`.sbt` vs `.scala`), each with slightly different semantics. Did you know, for example, that custom `config` that you merge with `inConfig` don't have their settings visible in the SBT repel if you use the `.sbt` version. If you make the equivalent `.scala` version, it is visible. Why? Who knows (I am sure there is a reason why, but its still inconsistent). - Another example, the repl doesn't exactly match the syntax that the sbt code does. I mean, it does match it around 80% of the time, but then you have weird things like, to run a task in REPL you have to use a lower case version of it (i.e. the `config` name), but in code you always use the actual name of the assigned type (yet in the REPL, for other things, it uses the name of variable) Also as /u/lihaoyi said in gitter, SBT tries to reimplement all of the Scala concepts in its own weird ways - We have tasks and settings which are conceptually vals/defs/lazy val - We have configs/scope as some sought of weird replacement for scoping? - We have applicative functors and custom functions like `inConfig` as some sought of weird replacement for inheritance/scoping? Lastly you have the fact that SBT tries to use a lot of the Java ecosystem, which seems to be now causing it more harm than good. A big reason for SBT's really bad resolution times is the use of `ivy`. There is coursier, which does a great job in lowering resolution times, but its nothing like https://buckbuild.com/. If you want good resolution times, you need really aggressive caching coupled with idempotent builds. Also a custom artifacts repository solution (using things like headers or even UDP) along with a performant data structure to represent the dependency tree. Also a lot of the SBT weirdness (for example, trying to define a library that is only available at compile time and doesn't appear in POM) often needs manually adjustment of the POM.xml, so we kinda have this weird state where we use a new build tool but it has this awkward inter-opt with maven, so to do more complex intricate stuff, we know need to know SBT **and** maven. The fact that SBT is so complex means its also hard for IDE's to integrate. Eclipse doesn't integrate with SBT at all last I checked (they just use a tool to get the dependencies from SBT so they can build their own format). Ensime is in the same boat. IntelliJ SBT support is a bit more advanced, but there are a lot of corner cases/bugs, and it still only really uses SBT for getting dependencies (albeit in a more direct way). You still can't run SBT tasks through Intellij, and IntelliJ still uses its own system for building Scala code. Honestly, I think that if a build tool was made from scratch, with a very strong emphasis on good design (in regards to performance and usability), it would be miles better than SBT. However build tools are notoriously complex, and I don't think that Scala would be in the position that it is now if it wasn't for SBT. Even though maven gets a lot of hate, I find its underlying design principles quite good. I think mavens biggest problems are - It uses XML, which is really verbose format. Something more human readable (like yaml, or HOCONF) would have made it a lot more pleasant to work with - Because of the above, there wasn't really any "defaults" for maven builds, people just copied over XML files. Again if instead of XML we had code (like a Scala ADT), you could just `.copy` over default trees and replace the settings that you want changed
Serious question in response to a serious question: why wasn't it sufficient to read the docs about [Defining a Task](http://www.scala-sbt.org/0.13/docs/Tasks.html)? "Tasks with inputs" describes how to look up the values of `Setting`s and other `Task`s in your `Task`. &gt; inspect fastOptJS reveals: [info] Task: sbt.Attributed[java.io.File] and [info] Delegates: [info] compile:fastOptJS The [sbt API documentation for `Attributed`](http://www.scala-sbt.org/0.13.11/api/index.html#sbt.Attributed) reveals that we can get the underlying `File` with `data`. So in the body of your `Task`, `(fastOptJS in Compile).value.data` will get you the generated `File`, exactly as [/u/sschaef_](https://www.reddit.com/user/sschaef_) [says](https://www.reddit.com/r/scala/comments/473imk/its_absurd_that_sbt_has_simple_in_its_name/d09yvqc). In other words, I'm sympathetic to a point, but ultimately, the documentation on `Task`s _does_ answer your question, and `inspect` of `fastOptJS` and a quick look at the API docs tell you everything else you need to know. So my question is, I guess, what, realistically, would have made this _simpler_? NB: I don't mean "more appealing to intuition brought from other tools;" I mean _simpler_.
Western wind / Eastern wind. Western wind comes from the north. Foldleft comes from the left.
Well, you know, many proponents of the Scala community are also interested in the innovation and research aspect of Scala. That's why we are not just a Fizz-Buzz language. If you are not interested in that part, you are free to skip over anything that links to EPFL and CS based stuff.
I've been using Scala for most my professional work since 2012. I want it to thrive. For this to happen, the language must appeal to the 99.9% of developers who will never add anything to the language. There's a 0.1% who will be interested in Dotty and development of the language. Scala public relations needs some urgent information architecture lecturing. Give the 99% what they want. Give the 1% what they want in a lower visibility section. Priorities need to be up front. Scala is getting fame as a complicated mad scientist language, this is not good for the community as a whole. It's all about priorities. Dotty should not be the main publicized feature in SBT. SBT needs speed and simplicity first.
I'm not going to start anything. If Scala continues with this attitude I'll simply switch languages. Java 8 is out there so watch your back.
`/:` domino bricks fall [from the left to the right](http://simplefinanciallifestyle.com/wp-content/uploads/2014/08/SFL-Domino-effect-on-finances.jpg). val ☞ = () (☞ /: "domino")((_, c) =&gt; println(s"Left to right: $c")) `:\` domino bricks fall [from the right to the left](http://www.scottfbarnettconsulting.com/wp-content/uploads/2014/07/Stick-Figure-Holding-Up-falling-dominoes.jpg): val ☜ = () ("domino" :\ ☜)((c, _) =&gt; println(s"Right to left: $c")) 
A few follow up things I wanted to get out. What could be simpler? Anything. I like gulp.js from what I've used of it. I wish sbt had a simple idea of an event, instead of all of this reinvented nonsense. I wanna write something like: when(fastOptJS).do((file) =&gt; {...) sbt's syntax is just honestly sinful. It looks like something the germans would have come up with... 70 yrs ago... in a submarine. Follow up question: why can't we just have a build tool that simply piggie backs off of maven? something that's basically just a converter from scala code to maven xml? 
You are sending yourself away. I am arguing that Scala is a broad community of multiple interests. You pretend that your own interest is the standard for all.
You still can't properly combine multiple projects the way you can with Maven. If you do IDEA will pull in the jars from the artifact repository instead of depending directly on the code. You can override this to make it work but it's brittle since a manual Sbt refresh will overwrite this once again. Personally I just went back to a one project per window approach but yeah, I really shouldn't have.
I have no complex with academia, I published a great paper this month by the way, many citations and praise from friends. There's a place for academia, and there's a place for popular speak. The Scala community can't seem to discern, especially given that Odersky and the rest of the heads are all heavyweight academics.
I know the book says that (I have it in front of me) and that it is SBT's birth name. What I am saying is that it *should* be called the Scala Build Tool. Some people call it that already. Keep the acronym by any means, but remove the (absurd, as the original poster says) "simple" from it.
Don't let the doorknob hit your ass on the way out, concern-troll.
&gt; Scala.js - A safer way to build robust front-end web applications! It isn't non-vm. I'm thinking about Scala being compilable to machine code, like with [scala-llvm](https://github.com/greedy/scala) while being maintained.
Typesafe was a much better name IMO
Scala wouldn't be as popular as it is now without JVM compatibility.
You talked about JVM compatibility so I thought you mean JVM. Scala.js has already steered Scala development in a direction which is no longer JVM-only, which is great. The JVM dependency is effectively gone. This said, I heard there is concrete work on something called Scala Native. I can only guess this means a new effort towards a LLVM backend.
I don't think the comment implied completely abandoning JVM compatibility. But there is a case to make that the web, Android, and iOS platforms make a really large potential deployment base which Scala has yet to conquer.
Hope they stay committed to Scala. They've bailed me out a number of times with great examples.
I'm barely in the Scala community and I've known about Dotty for over a year. It's pretty well publicized, including on this subreddit.
VT100 terminals
We considered having an `isDotty` sbt setting but this cannot easily be added to sbt 0.13 without breaking binary compatibility, this decision will be revisited when binary compatibility is broken for sbt 1.0, see https://github.com/sbt/sbt/pull/2344 for the discussion.
Ouch, that is... going to take some time to adjust to, at the very least
Using 3.0 as a version number would imply that we have something stable and production-ready which isn't the case, we'll continue using 0.x for a while.
This is great. Thank for sharing this. Just entering the Scala ecosystem (and with a project in mind), I have been on the hunt for good guides to implement a REST API. What advantages/drawbacks would you say Akka HTTP have for creating a REST API for a CRUD app, compared to using Play (which is what I am considering)?
There's `com.typesafe.config`
That's the point: it doesn't make much sense when you look at it.
I wonder if part of the change involves type safety being a concept and they wanted more Google searches coming straight to them rather than wikipedia articles on type safety. 
Changing a company name for SEO purposes would be pretty lame IMO anyway. I always thought Typesafe was a great name for a company.
Branding is hard, but "Lightbend" feels so arbitrary.
You're right. I thought of Akka, Play, Slick and SBT ...
I've problems with those languages(don't want to start a flame-war): Haskell: almost good, but I dislike pure FP as much as I dislike pure OOP. Haskell has an overly minimalistic syntax which makes the code monotonic + its module system is too primitive - code completion for types isn't there. With pure FP and a ton of category theory the [code could turn into](https://github.com/blitzcode/rust-exp/tree/master/hs-src) C++ fast. OCaml: the syntax is almost good but it contains some weird things, its module system isn't as good as advertised and it lacks the abstraction level of Haskell/Scala. SML: almost the same as OCaml... What' appealing to me is [Nim](http://nim-lang.org/), if it would have a proper abstraction system with HKT and type inference... That's the platform I want! Edit: I dislike most Java libs too because of their poor engineering... Edit2: + I'm really interested in the downvoters' view(did I hurt your fandom?)!
Well, it's not really *supposed* to make sense. In the sbt model, you depend on a task because you need its result. Depending on a task and throwing its result away does not make sense to begin with. I am therefore comfortable with the fact that the syntax to make that work looks weird.
Ever considered using Gradle? Works for me... (Although I didn't get Scala.js to work, I don't think they support Gradle). Intelij allows me to run Gradle commands from it, and for medium sized projects you can split up into subprojects. It does become quite complex but not neciserly hard to understand (its just a hierarchy following the file system). The major disadvantage of Gradle would be that it uses Groovy. I'm building Scala code with Groovy, which is just sacrilege.
Judging from the [blog post](https://www.lightbend.com/blog/typesafe-changes-name-to-lightbend) it seems like the company is positioning itself to be more language agnostic because their business is coming from Java enterprise clients.
&gt; MY NAME IS TOMMY AND MY DIORAMA IS ABOUT LIGHTBEND
&gt; This said, I heard there is concrete work on something called Scala Native. I can only guess this means a new effort towards a LLVM backend. That is correct. Announcement to come on next Scala Days in NY. Stay tuned. 
Like I said before, I think that mavens underlying design is quite good, but the use of XML is whats holding it back. The distinction that Maven makes between "declaration" and "plugins" means that most builds are kept in a declaration data driven way, and plugins create a structure that is easier for users to pick up. It also creates the attitude for people using maven, where if they do so something slightly wrong they get to they get to the conclusion they need to write a plugin, they often realize they have been doing something incorrectly. The other difference, is that with Maven, you can at least do that custom thing that you need to do, and if you find yourself resorting to plugins that gives a nice message that you are probably doing it wrong. With SBT, you spend hours trying to figure out how to do what you need to do, and most people give up here
I think you seriously underestimate how much Scala (as a platform) relies on JVM: - High performant GC comes for free. And good GC is not trivial to implement, it can easily take several years of constant tuning and testing. - Excellent native optimizing compiler for many architectures. - Need to connect to a database system? Choose from any available JDBC driver. - Need to call a native library? JNI is here for you. - Even for simple things like File I/O Scala needs to use the standard Java library. An alternative backend is certainly interesting project though. But I doubt it will be as popular, mature and performant as JVM backend.
I think that for Android Scala just needs smaller standard library.
 I think people overestimate the JVM. Almost all of your mentioned points could be accessible by a typesa*cough lightbend native interface. The GC is a strong point, though.
 Mostly You'll run into tep at pattern matching and overloading. One can overcome it with the reflect api but it's still problematic.
Personally, I found maven much faster to learn, and I only learnt maven fairly recently (due to being forced to in order to make some webjar packages) With maven there is def a google fest, but I found myself fixing/learning why much faster. However with SBT, I still have questions on SO that are unanswered for years (I had to personally ask people on gitter/irc, and I get an immediate answer)
I like the name, I'm a bit concerned about the "Java First" aspect. I hope it's nothing to be concerned about, time will tell. 
Well that's too bad, hopefully it will be a short lived limitation :)
For the most part, just because you're using SBT, doesn't mean you have to use SBT's IO library. You can depend on your own IO library and use that since SBT IO is just a bunch of type aliases and wrappers around `java.io.*`(for better or for worst).
Duralumin is right about `copy` but I'd add that if you think a bunch of mutable fields is the right solution, then a bunch of the surrounding code is probably not structured paradigmatically. If you can give an example of where you think you want mutable fields we can probably give you suggestions on how to write it more functionally. 
My goodness this. How can the documentation for Typesafe be *so* bad??
how does it get simpler than name := "my-project"
A `yield` in python is basically a c style long jump, not is scala. In scala the `for` and `yield` syntax is sugar for a series of `flatMap`s such that: val list: List[Int] = ??? val map: Map[Int, String] = ??? for { id &lt;- list name &lt;- map.get(id) } yield s"$id: $name!" is equivalent to: list.flatMap(id =&gt; map.get(id).map(name =&gt; s"$id: $name!")) which obviously becomes quickly unwieldy as the number of nested calls increases. In scala delimited continuations mimicking `setjmp`/`longjmp` were implemented with `shift` and `reset` briefly around 2.8 (edit: they're still there but you need to enable a compiler plugin) but were depreciated in favor of trampolines. Trampolines enable the same functionality through a functional data structure rather than a compiler level construct. Basically the idea is you have a function that returns a result with an anonymous function representing the next call. Delimited continuations can also be implemented monadically. See: https://apocalisp.wordpress.com/2011/10/26/tail-call-elimination-in-scala-monads/ for a more complete discussion. It's worth pointing out, that through lazy instantiation through `Iterator`s, a lot of the functionality of a `longjmp` can be achieved with what I think is a much cleaner interface.
it's rather obvious, the sbt community is much smaller than maven. ask in the right place, and I never consider stackoverflow to be the right place, personally.
The SBT community (by this I mean the amount of people that use SBT) is not small enough to justify the fact that there are probably around 5-10 people that understand SBT properly (or to a degree that they can answer questions properly) This is in stark contrast to Maven and even other build tools that don't have the same size as Maven. It also doesn't have to do anything with SO, the people that get tagged on SO are the same people in Gitter/irc/mailing list. Look at it this way, there are a huge number of people that use SBT, its the de facto build tool for Scala (and there are a lot of Scala developers now). There are also a lot of people that use Maven. Proportionally however, the amount of people that **understand SBT from using it to a reasonable degree** is much smaller and due to how opaque and "magical" SBT is in how it does stuff
Can't wait for the refractive manifesto!
Can you share some details, please? Scala on llvm is a game changer. Is it open source project or a product like robovm?
The meaning of life is line #42.
I think everything on GitHub is open for contribution, that's the nature of open source. For sure, if you are interested in computer music, I have [lots of projects](https://github.com/Sciss) to explore and contribute to :)
You can read about some tooling libraries that need help in Iulian Dragos' summary of ScalaSphere conference that took place two weeks ago https://dragos.github.io/2016/scalasphere-impressions/
Thanks. Making more sense to me now. One of the challenges I have had is: I have spent some time thinking of my application, and the various objects involved, and how they are related (DB schema). I am hoping to expose the CRUD operations on these models first as REST APIs, and then build out the more traditional web layer. The challenge with Play I have found is: Assuming I have a decently-modeled PostgreSQL database (e.g. 5-10 primary db tables, with about 5-10 "supporting" tables, for relations, metadata, etc), it feels like the amount of boilerplate &amp; work to expose these as REST API endpoints is quite large. So I have been looking for a pretty straightforward approach to do this. Many examples I have seen very rapidly jump into the deepend. I feel that my usecase is pretty basic - again: boring, business-oriented CRUD app with a bunch of interrelated tables, and generally views of tabular data combined in various ways. Any help to point me in the right direction would be helpful!
In that case, Play might make more sense as it has an official integration module for the Slick-framework: https://www.playframework.com/documentation/2.4.x/PlaySlick Slick is backed by Typesafe/Lightbend/whatever and has paid enterprise level support if that is important to you. You will have to create Slick-models of your table structure — [which can be automated](http://slick.typesafe.com/doc/3.1.1/code-generation.html) — but after this it should be pretty straight forward to write a service/db layer which controllers can use to access your data. There is a plethora of other options as well. I have used [scalikejdbc](http://scalikejdbc.org/) myself and had good results. Many people here will vouch for [doobie](https://github.com/tpolecat/doobie) which is a functional/stricter approach to the same thing. Also worth looking at is [quill](http://getquill.io) which is similar to Slick but doesn't require as much boilerplate as it inspects your database and prevents compilation if things don't map up. Quill is under active development but still in an experimental phase so some features are missing. Also, it doesn't have support for as wide a range of databases as the other options mentioned here. I still think it is a very interesting approach that carries great potential! Slick and Quill both aim to abstract away SQL by providing a fluent-like interface, but has "escape hatches" in case you want to write custom SQL queries yourself. In contrast, scalikejdbc and quill work with raw SQL but handles transactions for you.
Or my preferred way to explore a new API: start sbt, then: &gt; set scalaVersion := "2.11.7" &gt; set libraryDependencies += "..." %% "..." % "..." &gt; console and then `import` and noodle around in the REPL. The sbt hatred is just _unhinged_. Completely irrational.
[Gravity lenses](https://en.wikipedia.org/wiki/Gravitational_lens)
[ypg-data/sparrow](https://github.com/ypg-data/sparrow) solves the typesafety issue of DataFrame. it generate a macro to convert DataFrame to RDD. `toRDD: DataFrame =&gt; scalaz.ValidationNel[String, RDD[T]]` 
It seems odd that the biggest Scala pusher is now launching a new product Java-first and Scala-later-maybe. That might be reason for concern. 
I'm glad you're happy with your set up. Honestly. Development should be fun. I stuck with SBT and it's actually starting to make sense now, to the point of being able to define/do not-exactly-trivial tasks like downloading the appropriate version of PhantomJS depending on platform. It's been a great success in one project which I develop in OS X and build/deploy on linux servers. I have no idea how I would do the same thing in Maven even though I'm sure it's entirely possible. I guess what I'm trying to say is stick with what keeps you content. For me, the initial slippery slope was well worth it :) 
Not a scala library but works remarkably well http://jsoup.org/
If you are interested in cryptocurrencies, i'm working on a bitcoin wallet and a sidechains implementation in Scala. [Bitcoin-S](https://github.com/bitcoin-s/bitcoin-s)
A big +1 for this library. It can be a bit inconvenient/confusing to work with at first (at least it was for me), but nothing the creation of a nice helper can't fix. You can do fun stuff like this (return on Option[String] for the og:title of a document: lazy val ogTitle = doc &gt;?&gt; attr("content")("meta[property=og:title]") 
There is going to be a real world performance difference. 
Of course, it is just an example. In the log, you can add your application name or any other identifier. The other option is to have different log files, each for each spark application, but in that case, then you need to point splunk to each of them, something we wanted to avoid.
:= as an assignment to a setting is cryptic? ok you win.
yes, it is
so you would use something else to crawl, and then pipe over to jsoup to parse?
 With my experience with the typical java shops is that they'll never switch to anything. The average java shops: 1. always reinvent the wheel when possible 2. barely write unit tests - if they try it'll be a mock 3. don't have a clue about the current technologies - not even in java(java5-6 companies, struts users etc.) 4. never make the code further compatible 5. produce god-father classes filled by functions with 1K lines 6. create their own concurrency library which is pretty much an immature object-locker; they rewrite it every year because of undefined behaviour 7. if something doesn't work they'll a) go to more meetings b) blame management c) blame estimations d) blame business analysts; e) blame everything except their DIY web framework which is perfect! 8. love boilerplate code. . Of course, this is in Hungary, I don't know about other countries but when looking outside it seems to be the same.
I don't think Scala can eat the Rails/Django market. People using dynamic language are unlikely to switch to a language with a type system like Scala. If anything I think those two should fear Node.js rather than Scala. As the strategy to go after enterprise: I don't like it because that means I'm no longer in their target, but for Typesafe as a company it probably makes sense.
&gt; Change the strategy and before you know it, Scala will be in the top 5. Yes, but the strategy seems to be to no longer focus on Scala. The goal is to make money and Java is probably the better way to sell to enterprises.
I'm glad to see that our work on porting JUnit to Scala.js paid off so well for Shapeless :-)
Don't feed the recurring sbt troll.
I agree with you. 
Yes, that's correct and I like the solution you gave :-)
I agree. What if the data is a strict parent/child relationship though?
I'd say if you can come up with crisp one-word names for intermediate results of compositions, go ahead and do so. Your six-month-future self will thank you. OTOH, I have had colleagues fail to recognize/internalize that when using monads, we build up computation as a value, because we split the composition up. Or they'll look at a for-comrehension that is based on anything other than a container type and be confused. "Wait, you can't `yield` a `FooBarBaz`!" Well, yes, you can, because it's a monad, just not a container. So it's a mixed bag, and you kind of have to see what really confuses your team least. I was certainly surprised when separate lines confused the composition issue more than it helped readability, on more than one occasion.
Your post would make sense if they were implementing a Scala strategy. They aren't. If anything, they have moved away from a Scala strategy because it has become lucrative to devote efforts elsewhere. 
The simplest way is to not use stdlib collections ... scalaz provides a bunch of safe data types. You might also look at wartremover, which disallows some (but not all) of these methods. There is also a new project called dogs that aims to replace the standard library, but it's still very early going.
Excellent points! I've never though about their work on Scala IDE from this perspective. Still, I would try to work with JetBrains. After all, Netflix uses Amazon infrastructure even though Amazon Prime could be seen as a competitor ) Twitter is not a start-up anymore, but they were in a sense a start-up in 2008, because at that point they were more concerned about the growth than profit. My point was that they were initially a Ruby shop, not J2EE.
It has ... very much appreciated :-)
&gt;. People using dynamic language are unlikely to switch to a language with a type system like Scala. I would have thought this too, but my (anecdotal) evidence from attending meetups has shown otherwise. Not sure I know the reason, it could be just that they heard 'twitter switched from ruby to scala', it could be that they like succinct code, who knows. But I'd say up to 50% of the attendees are either from existing companies using dynamic languages looking to switch to scala, or have some scala for new projects and are supporting older python/php/node code bases. 
Also, hate things like `.max` which throws an exception on empty collection! `.max / .min` should return Options (i.e. `None`) on empty collections. Another gripe is not with exception but plain wat-ness of `.indexOf/.indexWhere` etc. which return `-1` when not found. `.indexOf` should return `Option` i.e. (`None` when not found)!
Not to mention that `.max/.min` are broken for types with partial equality: scala&gt; Seq(4.0, 1.0, 0.0, Double.NaN, 2.0, 3.0).min res1: Double = 2.0 scala&gt; Seq(4.0, 1.0, 0.0, Double.NaN, 2.0, 3.0).max res2: Double = 3.0 They should either discard `NaN`, or return `NaN`.
One thing to begin with: Odersky and Lightbend are not the same entity. It's clear to me that Odersky is committed to the future of the very underpinnings of Scala, through Dotty. He's largely let the ecosystem drive itself, which I think is the right thing to do. Lightbend sells a solution stack and consulting, and as far as I can tell, it remains very interested in providing smooth on-ramps for Scala and Java developers. But I don't think they particularly care about converting users from either language to the other. I think that's really savvy, because it allows them to target the massive number of Java shops out there, while also connecting with companies that want to use more advanced and innovative languages, all built on the very solid JVM. As far as the name change, any big branding change is weird and confusing when it happens, so that's given. I think we'll forget it happened in 6 months, and it'll just be the new normal. So the question is really, in 6 months, is Lightbend a better name than Typesafe. I think so. It's less coupled to any particular technical feature, which seems appropriate, since the company has a pretty wide product range, and type-safety is hardly the main feature, IMO.
&gt; It's clear to me that Odersky is committed to the future of the very underpinnings of Scala, through Dotty. I may be a no-name beginner, but I'm not certain to this fact. I feel like Odersky depending on how the proofs and how well Scala translates to Dotty may make a Scala like language that deviates enough, and takes Scala back to "it's simple core (at least as far as the proofs go)". Whether it will be similar enough to be marketed as Scala 3 (and possibly repeat the mistakes of Python 3) or be such a complete rewrite as to need a new name remains to be seen.
If you are interested, here's a repo where we have been playing with different implementations of lazy vals: https://github.com/DarkDimius/lazy-val-bench/tree/ https://github.com/DarkDimius/lazy-val-bench/blob/CallSites/src/test/scala/example/package.scala#L238 - this is the final version used in Dotty See also discussion here: https://groups.google.com/forum/#!topic/scala-internals/4sjw8pcKysg
You could add your own methods: implicit class MinMaxOptions[A](private val in: Iterable[A]) extends AnyVal { def minOption(implicit ord: Ordering[A]): Option[A] = if (in.isEmpty) None else Some(in.reduce(ord.min)) def maxOption(implicit ord: Ordering[A]): Option[A] = if (in.isEmpty) None else Some(in.reduce(ord.max)) } 
5 seconds on desktop is a pretty long typical incremental compilation time, should be more like 1 or 2 seconds (i7 laptop here). CPU clock speed is single biggest factor in compilation time, clean build or incremental.
My favourite game, Baduk, is named "Go" in the western world. 
Enums are the only thing which come to mind.
Here's the best third party article about the lightbend strategy I've come across : https://www.voxxed.com/blog/2016/02/typesafe-rebrands-as-lightbend-debuts-with-java-microservices-framework/
That's not really true, i had problems with pattern matching.
&gt; Whether it will be similar enough to be marketed as Scala 3 (and possibly repeat the mistakes of Python 3) or be such a complete rewrite as to need a new name remains to be seen. Martin has been careful, at all times, not to commit to Dotty simply _being_, wholesale, "Scala 3." However, he and the team have also said, at all times, that it's reasonable to expect Scala 3 to express ideas developed in Dotty. With sbt 0.13.11 offering explicit support for Dotty, I would venture to guess that the relationship between Dotty and what will be "Scala 3" is quite close in practice—it would just have been too risky to have _committed_ to that, and may still be.
Yeah that makes a lot of sense. Managing the community on a situation like that seems like an utter nightmare, even if it makes for a better language. I hope whatever it turns into goes well, as I've enjoyed reading the posts about dotty as it's opened my view of programming as a whole. I couldn't see using Dotty in Scala not being a major version change, but maybe they will still use 2.x if they can get enough compatibility to justify it for managing the community. I do realize that there has been significant effort to make sure that Scala as is, can somewhat shim onto Dotty's proofs.
I've been bitten by that one, coming from Java originally.
The problem in Scala is complicated type system and many programmers considered it WOL (Write Only Language). Here's my proof -&gt; https://en.wikipedia.org/wiki/Scala_(programming_language)#Criticism
&gt; seems like scalac is one of the few languages bound by cpu all statically typed languages are cpu bound, scalac more so since abstraction doesn't come for free (or at least not in current incarnation of the compiler; Dotty promises improvement in this area). &gt; Do you happen to know how effective the scala compiler can use multiple cores? look at output of `top` or similar and you'll see that all cores are utilized (on my Linux system at any rate). Regardless, scalac isn't fast so get the highest clock speed you can manage. SSD may help as well, though IO is not the main bottleneck. Apparently the Scala 2.12 functional interfaces implementation reduces class file generation which should help speed things up (though not drastically, I'd be pleasantly surprised if 2.12 is even 10% faster than 2.11 for example).
Really? The only bigger projects I have experience with were in Java, but there I found that SSDs improved compilation speeds way more than a faster CPU. Yes, with 2-4 cores I have the same experience. However, my 4 core i7 doesn't quite use all 8 logical cores, but this could be due to the hyperthreading being a bit funky on this particular (5 year old) laptop, so that's why I asked. Thank you again for the detailed response! 
It's almost certain that there's going to be a discontinuity with Scala 3, like there was for Python 3, Dotty or not. There's a lot of dead weight in the language that everybody is anxious to drop. I think it's almost inevitable Dotty will be used to redesign the core of the compiler, and it already covers a great deal of the major features of the Scala type system. The only question seems to be how much of the rest of the language can be similarly formalized. But for every remaining feature, I expect they will be formalized where possible, and bolted on to the formalized core otherwise. They've been careful not to make Dotty synonymous with Scala, but even Odersky floats between the two: http://www.scala-lang.org/blog/2016/02/03/essence-of-scala.html. The goal isn't to remove power from Scala so much as it is to encode Scala onto a smaller set of primitives, which will be easier to reason about, manipulate, and optimize. I have to imagine this is a crowd pleaser for the people who maintain the compiler and the major libraries. I'm an outsider, too, so this is just my analysis.
try-with is much more concise in Java; scala-arm is probably more powerful and composable, but hardly "easier".
As an aside, can you point me to any blog posts discussing any pitfalls of using value classes, per `extends AnyVal`? Or are they entirely safe to use?
Bear in mind they can be useful. For example if you can prove by construction that a set isn't empty, you might legitimately choose to use `head` to avoid the ceremony of `headOption.getOrElse(sys.error("something broke"))`.
&gt; For example if you can prove by construction that a set isn't empty, you might legitimately choose to use head to avoid the ceremony of headOption.getOrElse(sys.error("something broke")) If the type of your collection is List, then you by definition haven't **proven** that it is nonempty.
You can't compare to raw Netty though right? It's kinda sad how most framework sucks so bad when compared to the raw potential. But on the other hand, how many websites need over 1000 concurrent users and can't afford a few more servers?
I would say that in my experience, Typelevel-style Scala is actually a rare thing and most people try to avoid libraries like ScalaZ/cats. But maybe yeah, Scala would've been more popular if it didn't promote the FP side that much. I suppose that now most outside people associate Scala with something exotic while in reality it could be used as a general-purpose language that helps save money on maintenance.
Thank you for the link, really interesting ) 
Business logic in Directives? No, no, no.
Think about it this way: what *would* be the definition of `andThen` and `compose` on `Function2`? Can you give me the definition? You'll see that you can't come up with any satisfactory types. And that's because these concepts are inherently about one-arg functions. Both take the (only) result type of one function and feed it as the (only) parameter of another function.
Agreed. Those libraries definitely proved out the innovations in Scala the language, like Rails did for Ruby. There's something about being able to express something that used to be painful the way you used to do it in a much more direct way that nails in the benefits of a new language. But Lightbend knows not everyone's going to bite on a language upgrade. It's obviously got to incur some significant cost to them to manage multiple big frameworks for two languages. Though I'd have to imagine that after all this time, they're probably just about as efficient at doing so as they could be. Their big bets now seem to be on reactive and vertical integration (Lagom and ConductR).
That's not proof, those are anecdotes. It definitely can be a WOL, but so can anything. My experience with the language is that it can be challenging to decide which language elements to use to build a system. Invariably, big refactors need to be made. But the type system minimizes the risk of regressions due to these refactors, and the language seems to have a property of shallow slope toward better factoring. In other words, as your code gets better, it rewards you by looking simpler and "feeling" better. Refactors of dynamic languages are much more fraught, in my opinion, with broken references and regressions.
Why do you want it non-VM? That's not that interesting imho.
That's more than interesting to me. VMs come with worse performance and naive type systems.
Could someone explain how that's even possible that play is somewhere in the middle while it's running on top of netty? 
Wtf? Typesafe was so fucking relevant. There was no reason to do this
Static typing gets rid of a lot of unit tests. I am not saying it gets rid of all of them, but you can get a long way without unit tests when using a language like Scala
You can actually prove that a List won't be empty in certain circumstances, its just that the proof is not in the type system or the compiler. You can write a formal proof of it, but Scala is not Idris or Coq so you should not expect all possible proofs to happen in the type system. Like with the following example val l = List(5) val head = l.head The scala type system/compiler will not prove the above is correct, but you can write a formal proof (with certain assumptions) that it is correct. In any case, there is a use case for methods like `head` instead of `headOption`. Its when you know that the List will not be empty and you need performance.
A shorter and more efficient alternative: implicit class AnyEx[T](val v: T) extends AnyVal { def |&gt;[U](f: T ⇒ U): U = f(v) }
He said Morgan Stanley has about 200 Scala developers. And still people are saying that Scala developers are impossible to find :)
Yeah, 200 Scala developers which is really amazing. I am from Melbourne in Australia, and I guess you can't even find 200 Scala developers in Melbourne. :-(
That's a myth. It's not the VM that is taxing performance. And in fact any effort to compile Scala to bare metal will inevitably lead to slower binaries because of Scala's profile.
&gt; OOP isn't interesting in Scala - but the mature modular system is. Not sure what the "mature modular system" is, but I'm going to assume it's about the things that OOP makes possible.
&gt; That's a myth. It's not the VM that is taxing performance Then what? JVM apps' performance are unacceptable at small and large size. &gt; And in fact any effort to compile Scala to bare metal will inevitably lead to slower binaries because of Scala's profile. Why? I think it would be far faster in binary form. Maintained binary languages' always beats the VM/interpreted languages' performance.
I know, that was what I explained to my friend, yet we sat together to add |&gt; just for fun :)
Being a full stack framework adds some overhead. This overhead is especially obvious when you do micro-benchmarks with no application logic. A more interesting question is why akka-http and spray-es are both at the bottom. These are platforms and they shouldn't suffer from framework overhead. Besides, spray was at the top till round 8.
The other problem is that you are focusing on collection only. But |&gt; should be applied to everything on the language. I should be able to do: 100 |&gt; factorial |&gt; genList |&gt; map (square) | foreach |&gt; println 
What about twitter and foursquare? They are supposed to be almost 100% Scala.
False, all the functions are defined by me, they are not part of the api, so it wont work
 Have you defined map, foreach and println? What's factorial and genList then? Anyway, I've asked for real-world cases.
Filled out.
As I understand it (but I don't have the inside information my source has), Twitter isn't anything like 100% Scala, and Foursquare isn't as big as we are. I'm not particularly hung up on being the biggest—in fact, the context in which this came up originally was kind of a "huh, we might be!" conversation with Tim Perrett. But there's no getting around the fact that we're big (and there are some advantages to it).
"Able to be reasoned about," a pun on referential transparency I'm sure Rúnar Bjarnason and/or Tim Perrett are responsible for.
factorial(n: Int): Int genList(n: Int): List[Int] how are you going to chain them? 
Or just use Twitter @githubstatus
Quiet! If you convince lihaoyi to get a scala job he may not do as much scala open source! :P 
Never hurts to ask, especially if it potentially makes you a stronger employee.
Good catch :-)
Liberal use of scalaz is precisely what makes the code literally "reasonable," that is, able to be reasoned about, that is, referentially transparent.
I think the point is more about chaining new functions on established data types. That is, `x |&gt; f |&gt; g` is not meant to be an alternative to `x.f.g`; it's meant to be an alternative to `(f _ andThen g _)(x)` Granted you can accomplish the same thing by adding methods through implicit classes or other ad hoc polymorphism, but this is hardly the only instance of there being more than one way to do something in Scala. It strikes me as a fun little exercise.
It's probably a low priority, but it might be worth updating your website https://tumblr.github.io/colossus/, since it looks pretty drab. Edit: I'm now actually confused which website I should be looking at: http://tumblr.github.io/colossus/ https://tumblr.github.io/colossus/ (http and https pages look different for the same URL). https://github.com/tumblr/colossus 
Honestly, I don't want such a change. I use r/Scala for getting news about the Scala ecosystem and I don't want to see people asking questions here. There is the [weekly ask anything](https://www.reddit.com/r/scala/search?q=weekly+scala+ask+anything&amp;sort=new&amp;restrict_sr=on&amp;t=all) thread where people can ask there questions. And of course there are the mailing lists, especially [scala-user](https://groups.google.com/forum/#!forum/scala-user), and even [gitter](https://gitter.im/scala/scala), which are the best places to ask questions - I don't see which questions you would like to ask but are inappropriate there. All in all, we already have tons of sites where people can ask questions but only r/Scala to get news. There is also Twitter but one needs to be an experienced Scala user in order to know which people to follow to get the news they are interested in.
Lightbend also thanks for the overwhelming and flattering amount of congratulatory messages and compliments they received. No, that's not a joke, they really said that. Check out yourself.
I agree with Simon that /r/scala should keep focused on news and pointing out to interesting projects, but I don't mind occasional questions. I think the new ask-anything-weekly is a great addition that exactly addresses this function, though. P.S. &gt; that result in public criticisms From an author that [thinks Groovy is the future](https://www.linkedin.com/pulse/scala-vs-groovy-functional-programming-showdown-owen-rubel) ;)
I agree. I vest my Akka-Http layer with the responsibility of purely acting as the HTTP bridge to my data layer (handing [un]marshalling, status codes, parameter extraction, etc.), and then immediately drop down to another layer for business logic. It keeps the business logic decoupled from the library code and much more testable.
~~OK, this may be personal, but seeing such a wording as the official lightbend position is as sad for me as the move to java itself.~~ The comment may be over-emotional, I tried to explain my opinion in the comment above.
The slides are also available: http://files.meetup.com/18712511/Scala2016.pdf
&gt; Abstract classes are retained mainly for Java interop and for optimization I don't understand why you need both `trait` and `abstract class` now in the Scala language? Couldn't Dotty automatically add a synthetic abstract class for each trait that could be used from Java? And what kind of optimizations can abstract classes perform that a trait cannot? &gt; Union types How do union types behave in pattern matching compared to sealed traits? Will it be possible to get exhaustiveness checks? &gt; Stewardship As abstract as it is at the moment, Scala Center sounds like a good idea.
Honestly, I wouldn't use Scala for this, partly because of the JVM overhead and partly because I know of no good Scala e-mail API. I'd write the program in OCaml with [this](http://opam.ocaml.org/packages/smtp/smtp.0.2/) SMTP library and the appropriate database library, and use [Aurora](http://aurora.apache.org/) to schedule its runs.
My approach to human timeframe scheduling is usually to write a program and invoke it with cron (or for a server process have cron poke the program with curl to initiate batch jobs). This allows admins to change scheduling as desired, and it does sensible things when there are time changes, leap years, and so on.
Akka scheduler is not the best choice for the use case you specified. /u/tpolecat has already suggested best practical option (cron). On the other hand, if you consider this more as a learning exercise, then I would recommend looking at something like “Quartz Scheduler” (https://quartz-scheduler.org/). [This article](http://blog.knoldus.com/2016/01/18/code-dissection-akka-quartz-scheduler-scalas-way-of-scheduling/) has good details and concrete code examples.
As simple as that! Thanks
It's pretty cool you did it without sbt or dependencies! I think this project idea is spot on. I want to add custom dependencies to scalakata.com and I definitively see myself using your project.
Are you sure? When i try to compile this: sealed abstract class Move case object Cooperate extends Move case object Defect extends Move /* a Round is a move by both players */ type Round = (Move,Move) /* a Log is a list of Rounds -- it is what has happened in the game so far */ type Log = List[Round] I get these error messages: $ scalac Pris.scala Pris.scala:8: error: expected class or object definition type Round = (Move,Move) ^ Pris.scala:12: error: expected class or object definition type Log = List[Round] ^ two errors found 
Thanks for pointing that out, looks like there was a `http` in the template where there should have been a `https`. 
You need to put an "object MyModule {...}" around your type aliases
Type aliases can't live at the top level. One solution is to put everything in a module. object stuff { sealed abstract class Move ... type Round = (Move, Move) ... } Or just put the aliases in a module and then import them (`import stuff._`).
This is what I mean. I am about to (try to) hire devs and need to try to be as efficient as possible in onboarding; if they are coming from Java it would be nice to have a community to lean on
&gt;&gt; Who’s working on all this? &gt; Scala Center I'm starting to feel that Professor Odersky is trying to fool us, the Scala community. I feel that at the very least the final slides and final message in this presentation is a lie. Does it mean that contributors of the Dotty project https://github.com/lampepfl/dotty/graphs/contributors are employed by Scala Center? As Scala Center is a part of EPFL here's the list of its employees: http://search.epfl.ch/ubrowse.action?acro=SCALA-GE It does not look like people in this list Scala Center are actually working something that was presented in this presentation. Just like Typesafe is not working on scalac, they are working on Akka\Play(If you say I'm lying, consider the sizes of teams working on Akka\Play and scalac. The *team* behind scalac seems 20x times smaller) I've tried to use projects that come from ScalaCenter, authored by Heather Miller. They are awful crap, that does not work: - scala-pickling fails to serialize trivial classes. If it succeeds, it has awful performance. - scala-spores, that she was talking a lot about, simply do not work. Even the examples provided in the paper do not work. Frankly speaking, *stuff* made by Heather Miller is the worst code that had ever been put into *scala* package. If she heads ScalaCenter, and ScalaCenter builds future for Scala, Scala is doomed. I have a feeling that Odersky has a very strong favoritism towards some of his students, but some others are left forgotten. For example, the neat stuff that Hubert Plociniczak did that would have simplified life of many developers fighting the compiler never was incorporated into Scala. Why do I have my right to write this? 6 month ago I proposed to help Prof Odersky with Dotty. I have 3 years of compiler experience(though not Scala compiler). I also took a step from my side and started fixing issues in Dotty without his reply. And he simply ignored me and my work. Martin asks you for help? That's a lie. He's not going to accept your help. Martin says that Scala is a community project? Hell no. Consider SIP\SLIP, they are nothing but honest. How is SIP committee selected? I do not know those people and I do not feel that my opinion is represented there.
&gt; Then what? JVM apps' performance are unacceptable at small and large size. The first rule of fixing poor performance in software development is that you should never assume what's the cause without extensive profiling. As it happens benchmark after benchmark have shown Java code being close or even exceeding C/C++ performance in certain cases. Unfortunately in the real world, compared to C/C++, Java suffers because the real problem when it comes to performance are the *memory access patterns* and for one in C/C++ you have more opportunity to optimize those but also because: 1. Java has a garbage collector and no matter how awesome that garbage collector is, it's not suitable for [real-time applications](https://en.wikipedia.org/wiki/Real-time_computing). This is the curse of any platform that relies on having a GC and includes things like break systems in automobiles, but also audio/video codecs and such. That said the JVM is amongst the very few environments that's suitable for "*soft real-time*". I've personally used Scala and the JVM for a real-time bidding system. Worked great. 2. because it has a garbage collector, another effect is that it doesn't scale out of the box to many GBs of heap memory per process, because a stop-the-world phase can end up freezing the process for seconds or even minutes, depending on the managed heap size. That said, the JVM is amongst the few environments that scales beyond 4 GB (no shit, it's that bad) and amongst the very few with solutions [for scaling to 1 TB](https://www.azul.com/products/zing/virtual-machine/) of managed heap. This is an interesting discussion actually, because in C/C++ for long-running processes, you can easily end up with a fragmented heap, which is why big applications can leak memory over time. Firefox has had memory problems for years, which they solved with object pools and probably reimplementing their own defragmenter. In other words, synthetic benchmarks aside, for average developers C/C++ ends up being more taxing for big apps that have to maintain a heap. &gt; Maintained binary languages' always beats the VM/interpreted languages' performance. You're confusing "*binary languages*" with C/C++, which is old, low-level and an industry standard, which means organizations like Intel, Microsoft, Apple, GNU, etc. have had at least 3 decades to optimize it. Java beats Go.
&gt; *Think about the true nature of OOP ... polymorphism(something like generic programming)* OOP's true nature is [subtyping](https://en.wikipedia.org/wiki/Subtyping), or in other words a form of [ad hoc polymorphism](https://en.wikipedia.org/wiki/Ad_hoc_polymorphism). Everything else is secondary. For one, don't mistake ad hoc polymorphism with [parametric polymorphism](https://en.wikipedia.org/wiki/Parametric_polymorphism) (generics). The two notions are fairly orthogonal, albeit complementary in practice. &gt; *inheritance(problematic)* Because of inheritance, in Scala you can have a "*MonadError*" type-class, inheriting from the"*Monad*" type-class, inheriting from the "*Applicative*" type-class, inheriting from the "*Apply*" type-class. So in Scala, when creating such type-class instances, you don't have duplicate operations, laws and tests for "*Applicative*" versus "*Monad*", this versus Haskell. Because of OOP being used for implementing type-classes, in combination with implicit parameters, in Scala type-class instances are *actual values* instead of being special things with special treatment. And because we are dealing with values, that are passed around as function arguments, we can also override a default type-class instance in a certain lexical scope. Again compared with Haskell, where type-class instances are not values, but special things with special treatment and for a type-class you can have a single definition per type per project. For this reason Haskell's type-classes are kind of anti-modular. This isn't to say that usage of type-classes in Scala isn't problematic at all. There are problems, but the trad-offs you end up making versus Haskell are interesting to say the least ;-) Also in Scala, again by means of OOP inheritance and type members, we can have abstract modules, like in SML, except that in Scala because of OOP, module instances are ... tam, tam ... *values*. Which again, it's cool because you can pass these around as arguments to functions. This is the famous *Cake Pattern* actually. Pretty cool, except people use it as a poor's man dependency injection mechanism and do it poorly and I personally recommend against it, but it's a showcase of what OOP makes possible. There are also some cool effects of OOP and subtyping. For example in Scala a `Set` is also a function returning a Boolean. Pretty cool if you think how in mathematics sets can be characterized by functions. And as you can see, compared with languages like Ocaml, in Scala you don't have two type-systems in the same language, which is horrible in Ocaml because they don't mix well. Turtles all the way down man ;-) &gt; *the encapsulation is a good feature* Well yes and no. Encapsulation is good for libraries to choose which API is exposed and supported and which isn't. On the other hand encapsulation isn't so needed for pure functions and immutable data-structures, because you no longer have a mutable internal state that you can easily break by mistake. Encapsulation is also NOT a special property of OOP, because you can achieve the same effect just with closures. Though don't get me wrong, encapsulation is useful. &gt; *oop is a failure in practice because it failed to describe a proper type system* I personally can't parse that. In what regard is Scala's type system improper?
Several other languages have /r/learn____, but there might not be enough popularity for /r/learnscala.
Judging from the lack of acitvity at the learnscala subreddit, you might be right.
&gt; As it happens benchmark after benchmark have shown Java code being close or even exceeding C/C++ performance. C++ is famous because of its zero-overhead abstraction(which is really thin). Java could catch up with c/c++ but the idiomatic and/or enterprise code will be far worse. Don't get me wrong, I wouldn't use any of them in production. &gt; You're confusing "binary languages" with C/C++, which is old, low-level and an industry standard, which means organizations like Intel, Microsoft, Apple, GNU, etc. have had at least 3 decades to optimize it. Java beats Go. When I'm thinking in 'binary languages' I'm thinking about Nim(and Rust or maybe Haskell) and I would like to see a similar platform for Scala.
&gt; She is simpleminded and very shallow If you have technical input on her work, fine. But this kind of comment is not ok.
In F# you can't do `things |&gt; map(square)`. You have to be specific about the interface, so `things |&gt; List.map(square)`. And this makes it less useful. If you want to abstract over things with "map", Scala has higher-kinded types and implicit parameters, by which you can work with type-classes. So you can have an `Applicative` type-class and have a "map" operation that works on collections as well as other types that aren't collections. Checkout the [Cats](https://github.com/typelevel/cats) library (along with [Simulacrum](https://github.com/mpilquist/simulacrum)).
&gt; OOP's true nature is subtyping, or in other words a form of ad hoc polymorphism. Everything else is secondary. For one, don't mistake ad hoc polymorphism with parametric polymorphism (generics). The two notions are fairly orthogonal, albeit complementary in practice. Polymorphism can be 'universal' and 'ad-hoc'. Universal polymorphism meant to be a part of OOP: parametric pm and inclusion. Subtyping relates to inclusion and it is NOT ad-hoc pm. Ad-hoc pm is coercion and overloading. &gt; Because of inheritance, in Scala you can have a "MonadError" type-class, inheriting from the"Monad" type-class, inheriting from the "Applicative" type-class, inheriting from the "Apply" type-class. For OOP inheritance means subtyping - explicit relations between concrete types(theoretically). What you've described are relations between abstract types which doesn't seem to be related to the general oop approaches. &gt; Also in Scala, again by means of OOP inheritance and type members, we can have abstract modules, like in SML, except that in Scala because of OOP, module instances are ... tam, tam ... values. Which again, it's cool because you can pass these around as arguments to functions. That's the part of the modular system I like. &gt; There are also some cool effects of OOP and subtyping. For example in Scala a Set is also a function returning a Boolean. The apply method? &gt; Well yes and no. Encapsulation is good for libraries to choose which API is exposed and supported and which isn't. On the other hand encapsulation isn't so needed for pure functions and immutable data-structures, because you no longer have a mutable internal state that you can easily break by mistake. Encapsulation is also NOT a special property of OOP, because you can achieve the same effect just with closures. Though don't get me wrong, encapsulation is useful. I thought I've misunderstood you or the [concept of encapsulation](https://en.wikipedia.org/wiki/Encapsulation_%28computer_programming%29) but it's when we restrict a types' data to its methods. It's a nice thing both in syntax and with the IDE(through the 'dot' call syntax), that's all: without encapsulation class A[T](x: T) def y[T](a: A[T], b: T) = ... val a = new A(...) y(a, myB) with encapsulation: class A[T](x: T) { def y(b: T) = ... } val a = new A(...) a.y(myB) &gt; I personally can't parse that. In what regard is Scala's type system improper? Is Scala pure oop? I think it's far beyond that... For summary I don't like that we can define strong relations between concrete types - it can(**will** in practice) lead to spaghetti hierarchies. This is what I've tried to tell.
&gt; C++ is famous because of its zero-overhead abstraction Don't get me wrong, but that's just marketing speak from marketing brochures. As a counter-point, C++ doesn't inline virtual methods, whereas the JVM in most cases does. Mentioning this as a clear and pretty important example where C++ does have an overhead that doesn't apply to the JVM. Another example is the overhead of malloc/new. On top of the JVM the cost is exactly the cost of incrementing a pointer, same as the call-stack. &gt; When I'm thinking in 'binary languages' I'm thinking about Nim(and Rust or maybe Haskell) and I would like to see a similar platform for Scala. The JVM beats Haskell in any benchmark, usually by an order of magnitude, in both CPU and memory used. For many problems it doesn't matter, but when you compare, the difference is either so big that it's not even funny, or if Haskell is on par, then the code is very strict, very low-level and GHC compiler and version specific enough as to be incomprehensible and unportable. Rust beats Java, but only by a very small factor, which is shameful at this point, given that Rust has the aforementioned properties of C++ (e.g. no GC, system language). Don't know about Nim, but if it's faster, I wouldn't be surprised to find special treatment of memory that makes it hard to do FP ;-)
&gt; I also think there is huge need for a new "standard" in learning resources and blog posts (not specific to scala): context oriented. Absolutely. Scala has so many different scenarios where you can use it, sure there is no one-size-fits-all tutorials. Organizing the existing materials in a context-based way would certainly help newcomers determine where to look.
&gt; it would be nice to have a community to lean on I think the community on IRC is pretty great. Lot of folks willing to engage and answer questions with realtime help (because of the REPL bot). 
&gt; Of course it is. It's ad hoc polymorphism with late binding (solved at runtime). It's as ad hoc as it can get. If you consider type-classes to be ad-hoc, then the hint is that if you have subtyping, you can also do type-classes. Much in the same way that if you have multi-methods, you can also do subtyping (which is nothing more than single-dispatch after all). There was an interesting study in pm for me in [this pdf](http://lucacardelli.name/papers/onunderstanding.a4.pdf) - quoting "introducing a new form of polymorphism called inclusion polymorphism to model subtypes and inheritance". Inclusion is universal which isn't ad-hoc according to my understanding along with the pdf linked. &gt; Why not? The Monad provides a default implementations for "map" based on "flatMap", which you can override if you think you can do better (e.g. efficiency). That's pure OOP imho. Because I always try to abstract away generic programming from mixed paradigms like oop(generic+modular(+structural)). As with the Monad I model the generic type system to be similar to Hask. &gt; Oh, wasn't saying it's all good, hell no. Of course it isn't. All I'm saying is that for an FP language, its blend of OOP makes Scala interesting. Definitely true - there are things to be learned from oop languages for fp langs and vice versa.
There, here's a slightly more useful example than what I pasted before: http://scastie.org/15260 Do let us know if you get stuck!
I like it!
I disagree entirely. I come here for the Q/A and could care less about most of the news.
The community is probably too small to really support this.
&gt; Don't get me wrong, but that's just marketing speak from marketing brochures. As a counter-point, C++ doesn't inline virtual methods, whereas the JVM in most cases does. Most benchmarks I've done(don't think about serious studies) clearly showed zero-overhead's presence(mostly the template system). But it was easy to beat that optimization by [Nim](http://nim-lang.org/). &gt; The JVM beats Haskell in any benchmark, usually by an order of magnitude, in both CPU and memory used. For many problems it doesn't matter, but when you compare, the difference is either so big that it's not even funny, or if Haskell is on par, then the code is very strict, very low-level and GHC compiler and version specific enough as to be incomprehensible and unportable. Of course, the ghc isn't so good at perf, mostly because of the logic behind it. But I was thinking about the possibility - would the ghc be better if Scala would be the base? &gt; Don't know about Nim, but if it's faster, I wouldn't be surprised to find special treatment of memory that makes it hard to do FP ;-) You can manage memory manually but the language propagates immutability which makes it obsolete generally. Currently, the biggest problem with nim is its type system - while better than the average it still doesn't have a proper abstraction system and HKT. [This is](http://nim-lang.org/docs/manual.html#generics-concepts) the thing it have instead - 'concept generics'...
try IRC (freenode)
So are the people who work there going to be called Lightbenders?
&gt; Why didn't he show RedMonk or Indeed Trends? Oh, right, in this case Scala would have been more popular than Groovy. I've showed him the 2016 redmonk rankings and I've called tiobe naive - he gone mad. There is an active flame-war [here](https://www.linkedin.com/pulse/scala-way-out-owen-rubel?trk=hp-feed-article-title-comment). ;D He thinks groovy is generally faster and more functional than Scala...
I think it's only to you. Probably what they do in the future can prove you are wrong :-)
&gt; Couldn't Dotty automatically add a synthetic abstract class for each trait that could be used from Java? It could *emit* them, but then you'd have 2 incompatible JVM types; one seen by Java, the other seen by Scala -&gt; interop dead. At best, you could make the Java class inheriting from the interface. But still, that means if Java declares something as its class, you cannot give it an instance of the Scala trait. &gt; And what kind of optimizations can abstract classes perform that a trait cannot? Mostly less bytecode size. There might be performance optimizations, but I'm not sure; I'm definitely not a JVM performance guru.
OK, I have to be more clear on such a delicate topic. I'm not intending to spread panic. In fact, I like the language very much. But I think we should be wary with saying stuff that's close to disinformation. The other way around we may fall into ignoring real problems, ranting on all alternative opinions etc. Just - be careful, and don't say things you can just avoid saying. Please.
When looking at the different types in Scala I'm a bit confused about the proper usage of Either. In every example I see or in the documentation, Either is always used as a way to return success/failure. Is it a bad practice to use an Either for anything else? For example: in our organisation we have 2 types of members: natural persons or organisations. There are a couple of operations that I would need to perform on either one to end up with a common result, which is what I'm ultimately interested in. Would this be a good use of Either? 
Is it possible to rename left and right to better represent the options? So left is organization and right is person? 
I like certain kinds of questions; mostly ones that correlate with interesting language features.
Look very decent. Although you use a lot of mutable state. Perhaps you could write `game` as a recursive function without mutable state.
One trick you can use is nested pattern matching. For example, instead of `case r::rs =&gt; r._2`, use `case (_, r2)::rs =&gt; r2`
&gt; I would express game as a sequence instead of accumulating "log" and returning it Could you expand on this?
1. I'm not sure, but maybe "history" would be a better name for the current "Log". By "logging" people generally assume printing stuff to stdout (and friends). 2. Do not use `var`-s unless necessary. If you can, use a val. It helps readability (especially in large blocks of code). 3. _ /* get the score for player 1 */ def getScore(log: Log): Int I think you should reflect such important details in the method name, not [only] the comment. If the method gets the score for player1, name it so.
I don't think this will affect trait linearization. I think this will only affect how you specify types not how you define classes. When you define classes you will still use 'with'.
If you keep a log for each player and pass them both to nextMove, you can avoid the need for switchSide by just reversing the order of the logs. You can zip the logs together at the end if you really want tuples of moves. I would use Iterator.range(0, numMoves).foldLeft in game() and avoid all the mutable variables, but some people would find that less readable. 
1. Maybe it would be easier to create an organized github repo instead of a gist, but minor detail :) 2. as everyone said, too much var instead of val. Scala brings together objects and functional programming (OO + FP). While it's scala valid, it's not FP acceptable (it may take a while until you start thinking functional) 3. I personally don't like these lines: https://gist.github.com/cabalamat/dc3c8d3b652d04514173#file-pris-scala-L53-L58 . If you have defined a class, you may well define a method that tells you if the Log is empty (abstraction jjust), instead of pattern matching (while great and powerful, pattern matching may make code verbose in bigger programs) 4. you can do it recursive :) https://gist.github.com/cabalamat/dc3c8d3b652d04514173#file-pris-scala-L64 5. here you could do a map (cleaner): https://gist.github.com/cabalamat/dc3c8d3b652d04514173#file-pris-scala-L75 It's a simple and small game, so to be strictly FP may be overdue, but a nice exercise for practising. I can make some code examples for any of the bullet points above if you want
While this isn't necessarily the *wrong* place to post this, it's possible you'll get better/more in depth feedback on this kind of thing at http://codereview.stackexchange.com/
Wow, thanks. I didn't know about any of these.
&gt; He thinks groovy is generally faster and more functional than Scala... Oof. In arguing for Groovy's functional capabilities he points to an example of pattern matching -- of regular expressions. I'm not sure he's up to the task of his choice of polemic.
As a good Scala practice you could pass only head of log to the Strategy.nextMove() method, to minimize what can be done in that method (I recommend reading [Principle of Least Power](http://www.lihaoyi.com/post/StrategicScalaStylePrincipleofLeastPower.html) which describes such practices). If you develop new strategies that require more than the last move then you can refactor the code to support it.
an interesting thing to play with is extending the concept to allow you to work with tuples and functions with more than one parameter. for example def f(i:Int, j:Int) : Int = i + j (1,2) $ f won't work because `(1, 2)` is a tuple, and `f` doesn't take tuples. We have a `$$` operator that allows us do the above
Or via [`Stream.iterate`](http://www.scala-lang.org/api/current/index.html#scala.collection.immutable.Stream$@iterate[A]%28start:A,len:Int%29%28f:A=&gt;A%29:scala.collection.immutable.Stream[A]).
&gt; When creating an empty `List`, it's better form to use `List.empty` Why? `List.empty` just turns around and returns `Nil` anyway. 
&gt; Maybe it would be easier to create an organized github repo instead of a gist, but minor detail :) Maybe OP will understand what you mean, but I don't. What's wrong with a Gist? --- &gt; If you have defined a class, you may well define a method that tells you if the Log is empty (abstraction jjust), instead of pattern matching (while great and powerful, pattern matching may make code verbose in bigger programs) I actually think pattern matching here is fine and very similar to what you might see in other functional languages. Alternative formulations might include: def nextMove(log: Log) = log match { if (log.isEmpty) { Cooperate } else { log.head._2 } } or def nextMove(log: Log) = log match { log.headOption.fold(Cooperate)(h =&gt; h._2) } Of the three, I find pattern matching to be the most readable, especially if you follow the [advice](https://www.reddit.com/r/scala/comments/48hhze/critique_my_scala_program/d0jmor8) of /u/void_fraction and use nested pattern matching (though some people really like using `Option.fold`). --- &gt; here you could do a map (cleaner): https://gist.github.com/cabalamat/dc3c8d3b652d04514173#file-pris-scala-L75 The for-comprehension *is* a map. These are equivalent: for ((m1,m2) &lt;- log) yield (m2,m1) log.map { case (m1, m2) =&gt; (m2, m1) } Again, I think the for-comprehension is easier to read.
I would have a question regarding the use of the strategy pattern in scala. Is it really usefull ? In which case would you use them, instead of simply passing the appropriate nextMove function as parameter ? 
Overall, it's good. Apart from using `var`s where `val`s would work in a couple of places, it's clear and succinct. One thing you might look at is `getScores`... and specifically, `switchSides`. The approach you've taken - using high-level collection traversal functions - is perfectly reasonable, especially for small datasets. But consider what happens if your datasets get big: `switchSide` calls `List.map`, which will immediately build a new list with the left and right player moves flipped. `List.map` is not lazy. Then, `getScore` will also call `map`, which will again build a list, this time with just the scores (and that's called twice). So, to find the player scores, you need to build three intermediate collections. If large datasets are a possibility, you might instead want to do this iteratively. To that end, we might want to instead reformulate `getScores` this way: def getScores(log: Log): (Int, Int) = { val init = (0, 0) log.foldLeft(init) { case ((accLeft, accRight), round) =&gt; val leftScore = moveScore(round) val rightScore = moveScore(round.swap) (accLeft + leftScore, accRight + rightScore) } } Another possibility is to use views. `List.map` is eager, but `List.view.map` is lazy. I have not personally used views much, though, so I'll leave it to you to investigate if you're interested.
What do people think of breakOut? I stumbled across it at some point and it appealed to my inner premature optimizer, but I haven't really noticed it being used. 
Unless I'm mistaken, the code uses `List.apply` rather than an explicit `Nil`. If you trace the code of `List.apply`, you'll find that this results in creating a new list builder instance and returning its result which, while not exactly expensive, is certainly more costly than not doing it. As for using `Nil` directly, it's not always convenient: it's a `List[Nothing]`, which is not terribly helpful for the type inferrer. val a: List[Int] = Nil val b = List.empty[Int] I find the second one to be clearer, but that might just be me. 
Really cool. Cheers! 
It's called a strategy because it is, well... literally a strategy. But as for the pattern itself, it's still pretty useful: * it creates a semantic differentiation: you know that they are to be used for a specific purpose: for example `StringEscaper` is more meaningful than `String=&gt;String`. It's not Javascript, we have types, let's use them. * easier to refactor when you need to add more arguments, related to the above – you don't need to double-check all instances of `String=&gt;String` * a strategy class can do more than one thing, which would be hard to add if you used bare functions I often create strategy hierarchies with overloaded toString, because it makes debugging easier: `AllD` and `TitForTat` look more readable than `Function$1@38d036` and `Function$1@679376` 
You could use scaladoc style comments instead of simple code comments. Also it may be better to actually use mutable collections instead of immutable collection and var. I like such exercises so I made my own version: http://scalafiddle.net/console/ad7030d0d43a7f5903f38cc76af762a5
I find it very useful. When using `map` or `flatMap`, you can cast the result directly into a different target type, like going from a sequence to `Set` or `Map`, or from a `List` to a `Vector` without the extra cost of an intermediate collection and separate `toSet`, `toMap`, `to[Vector]` call. I don't see how it has to do with premature optimization.
&gt; Try to prefer val to var, since vars are mutable. I wasn't aware of the difference -- thanks.
My own opinion (fwiw) is that the use of Either is just wrong in the situation you are discussing. Either is for two utterly distinct cases: success and failure, being done or not, going forward or going backward. The two cases in your example, Person and Organization, are different in someways, the same in others. Both probably have a name, an address, some identifying information, a type. They differ in other ways, of course; an Organization might have Persons, or even other Organizations, as members. This is the classic case for polymorphism. Someone asked if you might some day add a third type, but I would add, even if _you are absolutely certain_ that there will never be a third type, the question is, would a third type even make any sense? Here, it clearly could. You could subdivide Organizations into Companies, NGOs, and Government Agencies, or you could add Dogs, or Ghosts, or anything. You have two now, because you happen to have two, not because logically those two are diametrically opposite and the only conceivable values. So it's not an Either. &gt; "You know the old saying: you win some, you lose some. And then there's that little-known third category." &gt; — Al Gore
In Scala an "object" represents a stateless singleton in the program. In the Java world it is "static" functionality. Because your classes aren't doing anything other than holding onto a function that is independent from the rest of the class you could rewrite the code as: object AllD extends Strategy { def nextMove(log: Log) = Defect } Then when you reference AllD you don't need to instantiate a new instance of it via the "new" keyword. You can simply call AllD.nextMove(log) This cleans the code up from instantiating things where there is only one instance of them to begin with, hence the term "singleton". Hope that helps.
Martin mentions that work has already started for an llvm-backend by @densh, however I can't seem to find the repository for it online, does anyone know if its public?
I'd start with reading what scaladoc is and how to use it. That might give some info aboit how your comments differ from scaladoc comments and why the command resulted in errors. Generally, I meant only the style of the comments, not actually building whole documentation. :)
Edit: removed.
This is by far the best ever explanation about `Coproduct`s I have ever read! Ever!
Wow, thanks! I'm glad it's helpful!
&gt; If you develop new strategies that require more than the last move then you can refactor the code to support it. The Haskell code that this is based on contains such strategies, so I have to!
It is the same except functional and tail recursive.
Play Json is very hard to read. A number of examples from the documentation look cool but unreadable. &gt; val jsonTransformer = (__ \ 'key2).json.pickBranch( (__ \ 'key21).json.update( of[JsNumber].map{ case JsNumber(nb) =&gt; JsNumber(nb + 10) } ) andThen (__ \ 'key23).json.update( of[JsArray].map{ case JsArray(arr) =&gt; JsArray(arr :+ JsString("delta")) } ) ) What does above do? It seems obfuscated code. 
Fantastic stuff, thanks. By the by, I failed to find any mention of "security" in the article, which was my primary motivation for jumping there post haste. Still wildly useful stuff, though.
Are you a new user who just registered to ask this question? Because your user page is deleted. This should answer your question. http://www.indeed.com/jobtrends/scala.html 
&gt; When I worked on medium-big apps in JS, Python, and Ruby, there were all sorts of type problems at runtime. Your nested map is no longer nested, so foo[bar][baz] doesn't give you a Widget, it gives you a number? I hope you remembered to change every reference. I've worked on huge enterprise Python applications. You avoid the runtime issues by improving your code coverage. The issue you stated will only occur if you haven't tested the code.
Anyone in the room has experience with #sublime + #ensime + #scala? Should I give it a try? Seems promising: https://github.com/ensime/ensime-sublime
Not yet. Official announcement and further detailed to come during my [talk on ScalaDays in NYC](http://event.scaladays.org/scaladays-nyc-2016#!#schedulePopupExtras-7571). Stay tuned.
ok thanks. I think this is the best solution.
Yep. This will do. Thanks
In my mind, Shapeless most obviously comes up in a couple of contexts: 1. I have some process that I'd really like to be generic in its type constructor(s), or even just have real polymorphic functions. Many times, it'll start with "I should use a `poly` here," and that will lead to "should I make a `Coproduct`? An `HList`? Go whole hog to `Generic` or `Record`?" Once you internalize that _anything_ can be represented as a `Coproduct` of `HList`s, the world's your oyster. 2. I/O boundaries. Often, I/O-heavy code is Stringly-typed (JSON) or at least forces you into non-domain types (e.g. case classes generated from XSDs with scalaxb). Shapeless is great for writing [safe mappings](http://stackoverflow.com/questions/29242873/shapeless-turn-a-case-class-into-another-with-fields-in-different-order) between arbitrary case classes. It also offers safe type casting, etc. There are entire [validation frameworks](https://github.com/fwbrasil/bond) based on Shapeless. It's really one of those frameworks, like scalaz, that I reach for on essentially every project.
What is the difference between akka-http and Play? Why did lightbend build 2 http server frameworks?
How complex? if it's too complex maybe you should be defining functions / classes / objects / traits to handle the different behaviour, possibly passing them into the constructor, and using the companion object as a factory in order to simplify it to users of the class.
&gt; You avoid the runtime issues by improving your code coverage. Yeah, obviously. Maybe you've worked on better teams than I have, but in about 15 years, I'd say only 10-20% of the teams I've worked on have made testing a priority and had good test coverage. The projects written in dynamic languages were all the worst in this regard, sadly. If testing is optional, people opt out. It's saved me an enormous amount of time over the years to have mandatory basic soundess checks.
You sir are technically correct (the best kind of correct).
[Actor Platform](https://github.com/actorapp/actor-platform)'s server-side. We are not listed in various scala tops because our platform is written in at least 5 languages and taking into account that scala is laconic and expressive language github does not consider actor-platform as a project written in Scala. So with 2.5k stars and platform widespread in the world (mostly outside of USA, unfortunately) we are making call here :)
As someone without LLVM experience, can someone explain the purpose/value of this? It sounds interesting just on its appearance.
It depends on what you mean by "famous." I can say there is an AOL mobile property that came from my team at Verizon Labs that is 100% Scala running at Verizon/AOL scale.
About 4.5mil lines of Scala @Twitter
We already have Scala.js for client-side browser development. Native compilation would open new platforms to Scala. One example I can think of is iOS support without the need for a VM.
&gt; One example I can think of is iOS support without the need for a VM. + fast(at least in startup time) command line and ui apps.
Cheers!
Having native iOS support would make Scala my de facto language of choice moving forward. Per /u/ebruchez it seems there's a new native project announcing in May at Scala Days, so crossing my fingers!
WTF is Play?
I know I'm a bit late, but your program was interesting and I spent some time with it. Please check my comments -&gt; https://gist.github.com/AlxScala/1f2519bb48004a4a72c5
And Java, though Scala is their preferred language. In fact, this bullet point is especially relevant this release: &gt; - Introduced equivalent Java APIs for features that previously only existing in the Scala API, such as implementing filters and custom body parsers.
This is a great opportunity to try to get in support for green threads. llgo has goroutine support, so that may be a great resource to use for this. 
p.s.: About to finish my BSc and gonna go for a Data Science/Machine Learning Master. Can't wait to use Scala for this. Something tells me this is a perfect match.
They teach Scala these days?! I feel like such a renegade when I tell classmates about Scala.
Does someone know whats the reason to migrate from Iteratees to Akka Streams?
Thanks for that. It's less flexible in that a strategy can only depend on the other player's last move.
Akka Streams has a good Java API, Iteraees didn't as folding isn't a Java operation. Play wants to work well for both Java and Scala users. I know Play having Java &amp; Scala support was important for my team, as we couldn't move 100% from Java to Scala overnight. Full Details: https://www.playframework.com/documentation/2.5.x/StreamsMigration25
Yeah, this project is completely dead. It's not related to the ScalaDays talk, which hopefully will be about something with more momentum.
Statically checked builds written in vanilla Scala code. It's supposed to be a faster and simpler than sbt - that being said the devs plan to support sbt interop.
Yeah that fact that sbt stands for "simple" build tool is pretty insane
No, the processes itself of reading the cache and then executing it would actually add time. 
It's simpler and far greener.
This is great. The scala build tool field needs more competition and simplification. With that said, **why on earth would you copy sbt's idea of overloading the "%" and "%%" operators on strings?** Every time I teach a course, it's just one of the needless, unintuitive detours that I have to take. All I can do is grimmace as the whole class rolls their eyes about the superfluousness of it all. It seems so minor but this is the kind of stuff that builds up into an unnecessary mess. Why not just: Dependency(group = "com.typesafe.play", name = "play-json", version = "2.5.0", scalaCrossBuild = true) Simple and intuitive. Maybe even a dependency ADT with different types like: GitHubDependency(project = "milessabin/shapeless", hash = "539d9ebb6defba16e040081f703a848aea1c3987") Anyway, great job. I hope it goes far. Just please be really careful about ergonomics. Take it from someone who has had to teach sbt multiple times to all kinds of devs: **saving a couple of keystrokes is not worth it**. Especially in a world of IDE's with auto-complete. And when you consider that build files are relatively unchanging, we should **prioritize readability over writability**. People (including me) don't always have the time or care enough to learn our personal choice of cryptic operators. We need to be empathetic to that. P.S. This is not a call to follow sbt's other major failing of making multiple, slightly-different ways to do the exact same thing. I'm saying you should consider completely replacing the %% operator. The defaults and examples matter. And once you make these decisions, it is very difficult to go back.
&gt; SBT [...] is conceptually able to also run tasks within single project to run concurrently. If I wanted to do that in CBT, it would require an API change [...] and I am actually skeptical about the benefit. How often to you need to run tasks in parallel within a single project? What?! ALL THE TIME. Nearly every minute of my working day. I'm quite surprised the author is sceptical. In my case, I work on a large project with around 15-20 modules with many dependencies.
It hasn't become sbt yet.
I expect it should be related to the dotty version of the language?
[removed]
It hasn't for about 2 years.
&gt; Please fuck off Calm down and/or grow up. &gt; All it takes a single example illustrate what the operator does All it takes is a single example to demonstrate that /: is foldLeft. And all it takes is a single example to illustrate what my #@$#@$@ operator does too. So what? It takes no examples to intuit what my proposed alternative does. And why are we trying to save characters on a build file anyway? &gt; It's not like the crossBuild() method doesn't exist or that ModuleID isn't a case class, but no one uses it Re-read my P.S. about defaults, examples and standards. A grab bag of alternatives to do the same thing isn't the answer. One of the biggest complaints about SBT is that everyone's build looks significantly different. People who like it can easily define their own implicits to overload strings with these amazingly useful operators. I doubt anyone would do that tho... &gt; because despite the constant anti-symbol circle jerk Wouldn't be Reddit unless someone called something they don't like hearing a "circle-jerk". Once again, grow up. This is just my opinion, and I don't care for your dick-grabbing references or if you feel a lot of people have said this before and it deeply bothers you. &gt; it's not better to use english language equivalents. Look, I didn't say all overloaded operators should be removed. I think it should be taken on a case-by-case basis. I've long learned what %% is. But, like I said, I've taught this to hundreds of people (in grad school, corps and government) and it's always one of many unnecessary issues. And nobody's ever better off after having learned it - just slightly less annoyed with it and eventually resigned to it. So, lets just say I'm speaking for some of the thousands of Scala engineers who don't bother engaging in the community because of the over-the-top, caustic responses from it's legendarily, anti-social minority (see: your response). Hell, I barely like engaging. Have a good night, go grab a drink or something.
[removed]
X-Post referenced from /r/java by /u/r0bertas [jstatplot - Visualize `jstat -gc` results.](https://www.reddit.com/r/java/comments/49703g/jstatplot_visualize_jstat_gc_results/) ***** ^^I ^^am ^^a ^^bot ^^made ^^for ^^your ^^convenience ^^\(Especially ^^for ^^mobile ^^users). ^^P.S. ^^negative ^^comments ^^get ^^deleted. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
Good god, 25% better performance.
&gt;Composite Naah, the C I've been looking for is Complex
I didn't go to typelevel, but I heard it was really good as well. NEScala was a lot of fun, everyone was really nice and the day1 talks were fairly informative. It's a lot of interesting things to try, but at some level I thought some of the stuff might not be something you could go back to work on Monday and see how you could fit it in somewhere. Not that it's a bad thing, just something to keep in the back of your head. It was also cool to see some of the companies using Scala like Verizon Labs, X.ai, Apple, Driver, Accuweather and probably some others I'm forgetting.
The question I was asking myself during the presentation was "why would I switch?". I mean that in the more innocent way, although I don't feel that he ever really addressed that. It seemed more like a fun side project which he hoped other people might make use of than anything else, not that there's anything wrong wtih that.
The JVM and JS components should probably count as different modules, just like they are in sbt.
* Faster loading time due to nailgun (keep jvm running). * File Watcher is improved. (faster trigger time) * Any change to the build reloads cbt * Easier to understand codebase (currently 1500 LOC, no fancy scala features).
Perhaps it is just me but none of those seemed like reasons to switch a project, which could explain why I didn't see an answer to "why would I switch?" during the talk. I could see why I'd use it for certain side projects however, which is why the interop seems like a key feature coming up.
It doesn't look like in http4s web APIs are first-class as in Servant. The nice thing about it is that web APIs are Haskell types and they do lots of cool stuff with it, like generating clients, documentation, etc. I was wondering if someone attempted to implement this in Scala.
The only thing I can think of is https://github.com/http4s/rho which provides enough (type-based) data to create both a http4s service, and Swagger documentation for it. I'm not a huge fan of the syntax, but appreciate the idea. https://github.com/finagle/finch is another functional-style HTTP server, but I don't think its high level abstraction provides much more than http4s.
If you need stuff like generated documentation (or support for documentation tools like swagger) than you probably need to look at frameworks like Scalatra or Play if you want something "stable". These aren't very purely functional in design however (the pure functional web frameworks like http4s are still fairly new, but there is rho if you want to use http4s for document generation)
You might want to look at the history of [slick](http://slick.typesafe.com/). I think they were trying something similar at one point.
If you want to run `getContents` on all of your URLs in parallel, simply use [`Future.traverse`](http://www.scala-lang.org/api/current/index.html#scala.concurrent.Future$@traverse[A,B,M[X]&lt;:TraversableOnce[X]]%28in:M[A]%29%28fn:A=&gt;scala.concurrent.Future[B]%29%28implicitcbf:scala.collection.generic.CanBuildFrom[M[A],B,M[B]],implicitexecutor:scala.concurrent.ExecutionContext%29:scala.concurrent.Future[M[B]]): val contents: Future[List[String]] = Future.traverse(list)(getContent) 
Let me recommend [http4s](http://http4s.org/). What you want looks like [this](http://scastie.org/15490).
The Guardian news site: https://github.com/guardian Linkedin (though they are supposedly trying to gradually move back to Java) https://www.youtube.com/watch?v=8z3h4Uv9YbE Tumblr http://tumblr.github.io/colossus/
Or just build a List[Future[T]] and use Future.sequence which will give you Future[List[T]]
The thing to keep in mind with asynchronous programming in general — Futures no exception — is to never block. Your code example is blocking in two places: When you get your data with `Source.fromURL`, and when you're doing `Await.ready`. Concretely, Futures run on a thread pool configured through an instance of `ExecutionContext` that you are responsible for passing for most methods on Future. By importing the global ExecutionContext as show on line 6, you implicitly provide this instance to all Future operations in your code. The global (default) ExecutionContext is dynamically configured to hold a small number of threads optimal for your CPU configuration. It holds something like [number of available virtual CPUs + 1] threads, IIRC. When you issue a blocking call inside any operation on Future that takes an ExecutionContext, the future will be assigned a thread from this ExecutionContext and then blocked until it returns. **This means that the number of concurrent operations will be limited to the number of available threads, and surplus operations on the same EC will be postponed until a thread is freed up.** If you're not sharing the same ExecutionContext in other parts of your code and only fire off a small number of Futures, this might not be a problem for your application; sometimes it will, especially when you start a larger number of Futures and expect them to all run in parallel. For this case, you want to make sure that the Futures you are creating are non-blocking. The usual approach when doing REST-requests is to let an appropriate framework handle them for you, like [Play's WS library](https://www.playframework.com/documentation/2.5.x/ScalaWS). As a rule of thumbs when working with Futures, all methods generating a Future should do so in a non-blocking manner, and all your methods depending on the result of an asynchronous computation should in turn return a Future.
Congrats Eugene! I'm happy to hear that development on scala.meta will continue :)
You should create an issue to report this problem. It can be fixed in a minor release. 
Well that was enlightening! I knew that we should not block while creating a Future, otherwise we lose the opportunity for parallelism, but I'm very surprised to hear that we should not block inside a Future either. My understanding of the Future abstraction is that it makes it easy to put a long-running computation in a separate thread so that the main thread can continue along without blocking. It also makes it easy to compose such long-running computations into longer ones. But if those long-running computations aren't blocking, why are they executed in separate threads? The only alternative to blocking I can imagine is a Javascript-style callback system in which every blocking computation is replaced by a continuation-passing call, and in that system, there's no need for threads, which is why Javascript is using it. Furthermore, such a system requires every single blocking primitive to support an alternative callback-based API. Javascript provides such an API, but I don't think Scala does, especially since many of us depend on Java libraries which definitely don't. So what's the alternative then? If you've got to make a blocking call because that's the only API available, and stuffing that blocking call in a Future is not proper, what would be the proper solution? Manually creating my own thread so it doesn't take one from the global pool?
Congratulations!
So there are a couple of observations I'd make about this: 1. Using the global `ExecuctionContext` is probably a bad idea when you can reasonably expect to need 50+ threads making HTTP requests in parallel. It's _definitely_ a bad idea if the rest of your code is also concurrency-heavy and relies on the global `ExecutionContext`. 2. Prefer [`Task`](http://timperrett.com/2014/07/20/scalaz-task-the-missing-documentation/) to `Future`. `Task` doesn't run immediately on creation, so it lacks `Future`'s fork-bomb nature. It has better application-level failure handling, as Tim's post explains. It offers `Task.async` for wrapping callback-y APIs, which I used [here](https://www.reddit.com/r/scala/comments/3xavvi/scalaz_and_scalazstream_simplify_things/) to wrap ftp4j. [Here](http://scastie.org/15490)'s my take on the OP, using http4s' client library, which is `Task`-based.
The important parts are: // a Task which actually runs your code generator val myCodeGen: Task[...] = ??? // add your Task to things which should be run to // generate code (i.e. before you compile it). // Extra complexity not shown, if you don't want to run // it every time sourceGenerators in Compile += myCodeGen.value // set to output directory of code generator // this adds it to directories which have code // which has to be compiled managedSourceDirectories in Compile ++= { ... } You can also set `watchSources` to note if your file has changed, but you don't need to if you put it somewhere like your resources directory (SBT already looks there for file changes). The `inspect` command is good for investigating what different keys do, and what their current values are, e.g.: $ inspect sourceGenerators [info] Setting: scala.collection.Seq[sbt.Task[scala.collection.Seq[java.io.File]]] = List(Task((taskDefinitionKey: ScopedKey(Scope(Select(ProjectRef(file:/Users/username/project/,root)),Global,Global,Global),buildInfo))), Task((taskDefinitionKey: ScopedKey(Scope(Select(ProjectRef(file:/Users/username/project/,root)),Select(ConfigKey(compile)),Global,Global),twirlCompileTemplates))), Task((taskDefinitionKey: ScopedKey(Scope(Select(ProjectRef(file:/Users/username/project/,root)),Select(ConfigKey(compile)),Global,Global),playRoutes)))) [info] Description: [info] List of tasks that generate sources. [info] Provided by: [info] {file:/Users/username/project/}root/compile:sourceGenerators [info] Defined at: [info] (sbt.Defaults) Defaults.scala:197 [info] (sbtbuildinfo.BuildInfoPlugin) BuildInfoPlugin.scala:50 [info] (play.twirl.sbt.SbtTwirl) SbtTwirl.scala:54 [info] (play.sbt.routes.RoutesCompiler) RoutesCompiler.scala:93 [info] Dependencies: [info] root/*:buildInfo [info] root/compile:twirlCompileTemplates [info] root/compile:playRoutes [info] Reverse dependencies: [info] root/compile:managedSources The project that you point at is a bit out of date, style-wise. It should be an `AutoPlugin`, among many other things. I would expect such a plugin to just require the plugin to be added to your project, and then put your `.proto` file in the correct location.
Sorry; the link is the `Task` link, which goes to my friend and colleague Tim Perrett's [Scalaz Task: The Missing Documentation](http://timperrett.com/2014/07/20/scalaz-task-the-missing-documentation/).
You don't need to run Play to run Play WS either -- you can just include the library and run it independently. Also, take a look at https://tersesystems.com/2014/07/10/composing-dependent-futures/ for how to compose futures when one future is dependent on the result of another -- this is frequently the case in REST calls.
I have less of a problem with the dependency methods than the task map operator in sbt. They make what is typically either a magic string in other dependency management tools (gemspec and package.json) or an overly verbose xml entry (maven) concise and easy to parse. That said, ``` string.withScalaArtifact(string).withVersion(string) ``` and the optional ``` .inConfig(listOfConfigNames) .withSources() .withJavaDoc() .exclude(exclusionDependenciesList) ``` isn't terrible.
Implicit objects are used to define instances that will be required as implicit parameters for methods that require implicit parameters. An example pattern that uses implicit objects is the typeclass pattern. http://danielwestheide.com/blog/2013/02/06/the-neophytes-guide-to-scala-part-12-type-classes.html Essentially, because a typeclass must be an instance, and the instance to use in the method depends on the type being passed to the function calling the typeclass, you can implement polymorphism by defining an implicit parameter that you resolve by having the appropriate implicit instances in scope.
ridiculous rant
The learning curve thing cuts a totally different way for me: it means you should aim for something better than just "better Java" to justify the cost. That's why some of us treat Scala like "worse Haskell:" because worse Haskell is still &gt;&gt; better Java, and the cost of learning worse-Haskell flavored Scala is only ε higher than learning better-Java flavored Scala.
This guy has a bit of an obsession with the idea of proving Scala to be terrible (he seems to prefer Groovy, of all things). I'm not sure I'd give this much consideration.
I think you should look at the TASTY support for Scala : "The goal of this project is to implement serialization and deserialization of Scala compiler trees into TASTY to help us establish the new metaprogramming platform for the Scala ecosystem." http://scala-lang.org/gsoc/2015.html
 I'd a long 'discussion' with this guy. He's biased and he provides false statistics everywhere. He thinks groovy and java are fp languages and he also thinks tiobe index is the defacto standard for pl popularity why calling my other sources* shit. Don't take this guy seriously - he also lacks the general concepts about programming. Most probably he'll continue his trolling crusade on Scala... *Sources: http://redmonk.com/sogrady/2015/07/01/language-rankings-6-15/ http://pypl.github.io/PYPL.html https://www.google.com/trends/explore#q=%2Fm%2F02js86%2C%20%2Fm%2F091hdj&amp;cmpt=q&amp;tz=Etc%2FGMT-1 http://www.indeed.com/jobtrends/Scala%2C+Groovy.html ps. Somebody at /r/programming made a theoretical [explanation](https://www.reddit.com/r/programming/comments/498644/tiobe_index_for_march_2016/d0q05p1) about groovy's emergence on tiobe index. 
Is there a way to have Akka actors be able to reference the sender of a message? Lets say I have an actor who sends a message, could I have that actor store a string and reference that actor and check the contents of that string? Is such a design even desired? 
well maybe scalameta will help ? https://github.com/scalameta/scalameta/search?p=2&amp;q=dotty&amp;utf8=%E2%9C%93
For me, Scala is a language that fits the "easy to learn, hard to master" motto. If you pick up Scala from scratch, and you work with code that isn't too fancy, you can actually start using it proficiently quite fast. But to master the language, takes a very **long** time, and I think that may take some people by surprise (especially when compared to languages like Java, where you can pretty much master the language in a few years. The bigger learning curve in Java is keeping with the ecosystem and how frameworks evolve rather than the language itself)
From anecdotal evidence, I'm recently seeing a lot more positions for Scala engineers along with seeing a lot more recognition towards Scala. I remember in 2014, there was hardly anyone who I talked to who knew Scala. This is no longer the case in 2016, everyone I talk to now has either used Scala or knows about Scala. I remember reading back in 2014 that Scala was dying, I keep reading about it now, what I don't understand is why do people keep saying that Scala is dying? I see scala as a niche language, essentially a modern Haskell or Earlang. While I don't see Scala replacing Java, it will always have its niche. 
&gt; However, the whole point of macros is to be able to essentially extend the compiler arbitrarily. You can't and shouldn't build everything into the compiler, and that's where macros can help. Macros don't extend the compiler. Macros only transform syntax trees. In that regard I don't see why anything would change in dotty if you have a simpler syntax tree that can express the same thing.
&gt; Using the global ExecuctionContext is probably a bad idea when you can reasonably expect to need 50+ threads making HTTP requests in parallel. It's definitely a bad idea if the rest of your code is also concurrency-heavy and relies on the global ExecutionContext. Global execution context is fine if your Future's internally don't use threads (i.e. if you use dispatch to make your HTTP requests, which is backed by Netty) or if they use threads, they internally use Fusion to minimize the use of threads (Slick) &gt; Prefer Task to Future. Task doesn't run immediately on creation, so it lacks Future's fork-bomb nature. It has better application-level failure handling, as Tim's post explains. It offers Task.async for wrapping callback-y APIs, which I used here to wrap ftp4j. These points explain why Task is different to `Future`, not why its preferable. For the task that the OP is trying to solve, `Future` is completely fine.
What are you trying to do?
&gt; unlike Ceylon, which a programming language that is actually designed instead broken by implicit hacks. ;D Trolls never sleep... Edit: why the rookies want to propagate their half-baked languages by bashing Scala?
The reason you want to execute non-blocking computations concurrently is to utilize all of your processor's cores. Frameworks like node.js do this by running a separate process for each core, which is then issued a request to handle. The Future model basically does the same thing, but with a thread pool instead of a preconfigured process pool. Indeed, if you don't do any heavy processing of your non-blocking requests, you can create an ExecutionContext with one single thread and let it handle everything. Likewise, if you know beforehand that you will have to make a large number of blocking requests, you can create an EC with a larger number of threads. Note that in this case you will have an overhead of RAM usage for each created thread, context switching and so forth. You can use `.onComplete`, `.onSuccess` or `.foreach` for those situations where you want callbacky handling of your future results, which is basically what you get in JavaScript frameworks. I like the Scalaz `Task` concept but Futures are more common in the wild and *slightly* easier to understand. Again, knowing the costs and tradeoffs of using either is key to picking the right one for your situation. When interfacing with existing libraries that use Future it might just be easier to stick to it, while http4s really makes you appreciate Task :)
Where does he say that Groovy and Java were functional languages?
You can always reference the sender of a message through the [`sender`](http://doc.akka.io/api/akka/2.4.2/index.html#akka.actor.ActorContext) reference. Is this what you're asking about?
We did pretty much the same, except the explore Shapeless or Scalaz bit.
 I don't remember in which post but on groovy: ["and JVM functional Language Groovy moved... "](https://www.linkedin.com/pulse/scala-way-out-owen-rubel).
https://github.com/cvogt/cbt
The problem with calling Scala "a modern Erlang" is that Erlang has never been really popular. Scala is a completely different story. Yes, it still has fewer jobs than say Ruby or PHP, but the difference is not that huge. I think it's high time we stopped calling Scala a niche language as it's one step from entering the mainstream.
As even TIOBE mentions itself, some languages end up with poor rankings because TIOBE searches for "$lang programming". In some communities, other phrases are more popular, for instance "programming in Scala". Just search for both in Google and have a look at the number of results.
I got it! It's not a FUD. All those posts about "scala is dead", "scala is going nowhere" are written by exquisite AI, which searches for negative posts about scala, its ecosystem, community, etc. It also likes to show graphs as a proof. I guess, this AI is fully written in Scala, and creators are just testing it.
Thanks for replying. &gt; You can use `.onComplete`, `.onSuccess` or `.foreach` for those situations where you want callbacky handling of your future results, which is basically what you get in JavaScript frameworks. Oh, I wasn't saying that I wanted to use a callback-style API, but that I wanted to use a callback-style implementation. For example, consider, the following code: val myComputation: Future[Int] = for { x &lt;- compute(42) y &lt;- compute(x) } yield (x + y) Suppose `compute` is implemented in terms of a blocking call. Something like this: def compute(n: Int): Future[Int] = Future { myBlockingCall(n) } Then `myComputation` will use a thread from the pool and will hold on to it while performing the blocking call, there's simply nothing we can do about it. On the other hand, if the library providing `myBlockingCall` provided the same service using a callback-based API instead, then I could implement `compute` like this instead: def compute(n: Int): Future[Int] = { val promise = Promise[Int]() val callback: Int =&gt; () = {r =&gt; promise.success(r)} myNonBlockingCall(n, callback) promise.future This time we're only borrowing a thread from the thread pool for a short time, and then we're releasing it until the non-blocking call executes our callback and fulfills the promise. Both implementations expose the same nice monadic API, but the one which is implemented using callbacks uses fewer threads. Since `Future` exposes `onComplete` etc., I guess both implementations also expose a callback-based API, but that's no help if the underlying implementation is implemented using `myBlockingCall`. &gt; I like the Scalaz `Task` concept but Futures are more common in the wild and slightly easier to understand. Oh, me too. The first time I heard about Task, I asked what the difference between Future and Task was, and I didn't even need to hear the full response in order to be convinced. ExperiencedScalaPerson: Well for one thing, unlike Future, Task doesn't launch its thread immediately as it is defined, it's a descript- Me: Future does *what*??? What were they thinking!! It just so happens that our codebase uses Future everywhere, so I'd like to make sure I use it properly.
So are you hiring Ceylon programmers? I mean I pretty much agree with all of that (assuming HKTs have been standardised now? I couldn't work without HKTs). But I've gotta eat and I don't like laziness, so until Ceylon or Idris goes mainstream, Scala is the best language around that I can write for a living. At least I don't have to use SBT.
I know how it feels, I only know one other person at my uni who actually cares about what a monad is, and he writes haskell..
It seems that akka-http is for web services which use HTTP, whereas Play is a web framework for web applications. akka-http is a lower-level abstraction, and there is actually an experimental server backend for Play written using akka-http.
For some reason, I was glad to see Verizon as a founding member )
We've talked about taking Finch in a more Servant-like direction, but right now it's not really trying to capture this much information in the types. In Finch you can compose endpoints into an endpoint of a coproduct (a generalized either) where all the alternatives are (or at least can be) meaningful types. We find this to be a good compromise between the usual take-everything-all-the-way-to-an-HTTP-response-type approach and a more complete Servant-style representation of the API (which is likely to result in horribly painful compile times in Scala for non-trivial APIs).
https://www.youtube.com/watch?v=RO8kDSJb-Gs
https://twitter.com/lvicentesanchez/status/707239838634926080
Perhaps that's a good sign. I thought Scala Center was essentially an EPFL initiative, not one of a bunch of lightbenders. I feel more comfortable that an academic body like EPFL hosts Scala Center and not the new JavaEE shop. __Edit:__ FWIW, the [Internet](https://finance.yahoo.com/news/lightbend-supports-launch-scala-center-130000027.html) was faster.
It was configured to Meta+Shift+L by default (no idea what "meta" button might be, I don't use Mac Os). Ctrl+Shift+L conflicts with "Move to previous occurence". Remapped it and now it seems to work.
Would love to hear feedback or constructive criticism. :)
Since curried functions, by definition, only take a single argument, partially applied functions only really make sense in the context of uncurried functions: def add(a: Int, b: Int) = a + b // Uncurried val onePlusFive = add(1, 5) // 6 val addFour = add(4, _ : Int) // Partially applied val twoPlusFour = addFour(2) // 6 assert(onePlusFive == twoPlusFour) // true [This blog post](http://danielwestheide.com/blog/2013/01/30/the-neophytes-guide-to-scala-part-11-currying-and-partially-applied-functions.html) explains the concepts in Scala better than I could. This is the key part (my italics): &gt; What this means is that, when applying the function, you do not pass in arguments for *all of the parameters defined by the function* I.e. the function needs to have multiple parameters, whereas curried functions are expressed as a series of functions with one parameter and which return the next function when applied (aside from the last in the series, which returns a non-functional value).
I can see what you're saying, but don't you think it can be applied to uncurried functions as well? Correct me if I'm wrong but does it not apply to standard haskell functions, which are curried by default? https://wiki.haskell.org/Partial_application add :: Int -&gt; Int -&gt; Int add x y = x + y addOne = add 1 In this example `add`is a curried function, no? 
*Easy to learn, hard to master* is the key here. Once you start climbing the learning curve, which is steep, and looking back you see the beauty of Scala. I've written a lot of Java, and when I look at that code the urge to simplify it with Scala is alway rather strong.
Whichever you choose, it might be a good idea to not use Meta, at least on (not OS X), where it's not normal for individual programs to have shortcuts using the Super/Win button.
Interesting links. As someone forced to do Scala rather than be a fan boy, I am secretly hoping this technology fails. Scala promises to be fast and efficient and great but it's actually very difficult to measure and reason about scala performance which is a frustrating problem.
In Haskell the situation is complicated by the fact that all functions are unary - they take one value as an argument and return one value. Functions which operate on multiple arguments do so either by being curried, or by taking a tuple as the solitary argument. So, in that context *partial application* is usually used in reference to curried functions. I.e. your article would make more sense if it were describing Haskell. Scala directly supports n-ary functions (for all n), so in that context partial application is normally used in reference to un-curried functions. At least, that's my experience - happy to be proven wrong. 
Would also love for someone to weigh in on this :)
Tried this out on some of our code base at work. It seems to do some weird formatting for def/val private[this] things. Is this by design or just some bug (using 0.1.1 version from sbt) - private[this] val root = Path(s"/$path") + private [ this] val root = Path(s"/$path")
Appears `Long.hashCode` is only in Java 8. Filed an issue https://github.com/olafurpg/scalafmt/issues/112 Will try to fix asap. Thanks for posting.
How do you think google guice? Looks like it's the first class citizen in Play since 2.4.x
I've just started to get my hands dirty with Scala (just completed the functional programming principles course on Coursera). I've been using IntelliJ up to this point, but looking to switch over to Vim. What are some good plugins I should look into? 
ensime will give you IDE-like features in text editors. There's a vim client here https://github.com/ensime/ensime-vim
If I treat the type parameters like regular parameters then your example is formatted like this def myMethod[F[_]: Functor, G[_]: Applicative, A : DecodeJson : TypeTag : Meta, B : DecodeJson : TypeTag : Meta, C : Meta : TypeTag : UrlParameterEncode](gfa: G[F[A]], b: B)( f: (A, B) =&gt; C): Foo[C] I don't really know how is best to format the second parameter lists (gfa and f). What do you think?
It appears that he just writes the same article over and over. https://www.linkedin.com/pulse/scala-vs-groovy-functional-programming-showdown-owen-rubel?trk=pulse_spock-articles
Great. Looking forward to trying it our with our code base once its fixed. This really would be a great tool if it gets good enough results.
I format my code like this as well. Its not really specific to context bounds, but whenever you have a huge parameter list
Are you seeing Scala positions outside of big data work?
Most of the scala positions I see are for backends or for using Apache Spark. Mind you I live in the Silicon Valley which is not always representative of the rest of the US when it comes to the types of tech jobs that are around. 
Significant changes since 2.11.7 include: * The Scala REPL now has robust and flexible tab-completion (details below) * An assortment of bugs have been fixed Compared to 2.11.7, this release resolves 44 issues. We merged 175 pull requests. As usual for minor releases, Scala 2.11.8 is binary compatible with other releases in the Scala 2.11 series. The last planned 2.11.x release will be 2.11.9 in late 2016. **New tab-completion in the Scala REPL** The implementation of tab-completion in the Scala REPL has been rewritten and now uses the same infrastructure as for example Scala IDE and ENSIME. There are a number of improvements: * Reliable completion, also in partial expressions and syntactically incorrect programs: try class C { def f(l: List[Int]) = l.&lt;TAB&gt; * CamelCase completion: try (l: List[Int]).rro&lt;TAB&gt;, it expands to (l: List[Int]).reduceRightOption * Show desugarings performed by the compiler by adding //print: try for (x &lt;- 1 to 10) println(x) //print&lt;TAB&gt; * Complete bean getters without typing get: try (d: java.util.Date).day&lt;TAB&gt; * Find members by typing any CamelCased part of the name: try classOf[String].typ&lt;TAB&gt; to get getAnnotationsByType, getComponentType and others * Complete non-qualified names, including types: try def f(s: Str&lt;TAB&gt; * Press tab twice to see the method signature: try List(1,2,3).part&lt;TAB&gt;, which completes to List(1,2,3).partition; press tab again to display def partition(p: Int =&gt; Boolean): (List[Int], List[Int])
edit: Hmm I'm not sure what would be good. What if the type parameter list and the value parameter lists were formatted similarly, eg each aligned to the first [ or ( ? sorry i'm again uselessly on a mobile editor
I use the SORM and it is good library. Thank you for work. I hope that the project will be all right.
Thank you.
"Kinda" Actors communicate through messages. In order to get the state of an actor you need to ask for it by sending it a message. The actor asked for its state need to accept this message and send its state back in another message, which needs to be handled by the asker. You never access the state of an actor using `actor.getInterestingState()` or something similar; you can't since what you're holding onto is actually an `ActorRef`that doesn't know anything about the internal state of the actor it is representing.
Glad to see others come to same conclusion. I inherited code written by one of the scala consulting companies (The ones that sponsor scala events) . 25% of the code was boiler plate DI code. Ripped out the DI and created plain old classes and constructor parameters. Made the dependencies easier to understand and test. 
This is wonderful! Thanks for the link.
Is there a way to run `sbt` from the command line, and still get nice syntax highlighting like I do in Intellij? Using Git bash for windows. When I do `sbt clean compile test`, all text is one color. But on intellij, errors are red, other info is blue, etc. Also, for some reason Intellij can't pick up an environment variable that Git Bash can.
My congratulations to Twitter! And also to Zhenja of course.
How long could it possibly take? I've only programmed in Scala for roughly two years, and aside from stuff that's doing insane type-level gymnastics or crazy macro manipulations, I feel like I have a pretty advanced understanding of the language. Enough at least for it to be my top tag on Stack Overflow. Every language has a frontier like that. Non-trivial metaprogramming in Python or Ruby is just as hard to master.
Learning curve, difficulty finding programmers who can or are willing to take on FP, additional tooling on top of normal Java development, ecosystem which is focused on sbt rather than industry standard dependency management tools, binary level breakages in Scala upgrades, additional compilation time, difficulty in pinpointing performance issues, and slightly worse performance for idiomatic FP functions on average (as in: it's too easy to use way too much memory accidentally). I know all of the above can be mitigated and eventually made moot, but that takes effort. Some of that effort is normal for taking on a whole new language and ecosystem of course, but some of it is specific to Scala and it's those bits that scare me off recommending it for anything other than big data. The productivity gains to be had in other areas aren't clear enough to really differentiate it.
Yeah, sorry. [Once upon a time](https://github.com/scala/scala/commit/363a1456f671) things were different. Wow November 2010, where does the time go. Two annoying REPL things made less annoying: * ctrl-C will no longer kill the repl unless you hit it again * ctrl-Z will no longer make the repl useless because of jline
just the way I like it
tldr inexhaustive match is a compiler warning not a failure, so author wrote a macro to introduce formal enums. Exercise of writing a macro might have been cool but the article lost me at the point I realized the motivation for the exercise. I don't think there's ever a reason to write real scala code without -Xfatal-warnings
I skimmed a didn't find any mention of the Free monad. More like only 5 notches.
Thanks! It works now.
Exciting! One thing I'm wondering is about build.sbt. That was one of the things I found most difficult to wrap my head around when picking up Scala and trying to roll my first web app. It was a huge mystery to me what kind of Scala "worked" in my build file. Problems were solved by copy-pasting inscrutable incantations from blogs and StackOverflow answers. I wasn't around in the days when there was only Build.scala, so I'm not sure how exactly that failed. But it feels like the better answer is to find a fresh approach to writing build code in pure Scala.
Yeah, I'm fine with that, being familiar with the topic. But it prevents it from being something I could readily recommend to beginners to grasp this concept.
I'm really looking for the template system. At work we have been thinking of creating an actual template over "clone this skeleton project and rename packages as you need to" Too bad we don't have an idea in release dates
Addressing only your last sentence: &gt; I don't think there's ever a reason to write real scala code without -Xfatal-warnings http://stackoverflow.com/a/28327439/409976 The first comment says: &gt; [Using -Xfatal-warnings] technically answers the question, but it's often not a viable solution. I'd personally be interested in seeing answers that don't require failing on all warnings, even if they're messier.
I like cmder. It's just a gui really. I use cmder to open git bash
Scalafmt covers broader cases for parameter lists in the newly released 0.1.3. Here are some [crazy examples from the unit tests](https://github.com/olafurpg/scalafmt/blob/6c4e5165bcbfa3a932cc112d7e87a1e919fcaf99/core/src/test/resources/default/DefDef.stat#L63). I don't know how much new rules always make sense. If you see funky output don't hesitate to file an issue.
I think the difficulty of Scala is vastly overstated, in a way. A Java developer can learn everything they need to know to do anything they could do in Java in a few days. It's not going to be pretty or idiomatic, but it didn't give me the feeling of hopeless despair I felt when first learning Haskell, I couldn't even figure out how to do the most basic things. One doesn't have to know "the whole thing" to be productive. I like that it always seems like there's always more to learn, but I never HAVE to learn it to accomplish some task.
Hope by the time sbt 1.0 comes out there is a saner alternate and no one has to care or use sbt ever again.
The difficulty problem is social, what happens when you've feel you've learned enough, but come across another developer who uses more advanced features? Suddenly while productive before, you're not. That said while I can rationalize the frustration, I have little empathy for those prioritize productivity over craftsmanship.
Is the server `hw.premii.com` the official one? It didn't work with JS disabled in my browser (uMatrix), but that page works: https://news.ycombinator.com/item?id=11264454
Yeah sorry, I shared the link from my mobile Hacker News app to reddit, and didn't realize that it didn't give the normal link.
Hn.premii.com is a widely used site and mobile app that redesigns HN entirely.
Huh? This seems to have ended up as a monad for completely impure, side-effect IO, not Pure IO.
Yes but yours is non referentially transparent, it breaks the definition of purity given in the first sentence.
Sorry, may be i am missing something. How does it lose referential transparency?
* the (non incremental) compilation could be faster, yes. but the languages that are much faster have most of the time vastly simpler type systems. it's a tradeoff I guess. takes the entire test 15 seconds, or does it take 15 seconds before the test even starts running? * do you use sbt multi projects? * since the community version of Intellij is free you should give it a try. Like the others who have replied to your comment, I use it as well, and it's good (intellisense could be faster sometimes amongst other things). The Scala IDE people should switch to Intellij like google did with Android Studio.
&gt; slow compiler. Waiting 15 second for a test to run interrupts the flow. &gt; slow build times (again!). On a fairly small project I am working on compilation takes longer than running all the tests that are quite I/O heavy. I don't know, but I don't have a big problem with this. Maybe I organize my projects different or my SSD works really well or I rely on incremental compile too much. It's definitely slower than Java but it's never been remarkably slow to me. And since I'm working in a very type safe way, I really don't have to compile that much to make sure my code works anyway. The good news is that I've been reading about some major improvements that are on the way: https://twitter.com/gkossakowski/status/702650030856003584 and https://twitter.com/purefn/status/708368490210713601 &gt; poor IDE support (even basic functionality like "Organize Imports" and "Go to definition" is broken in Scala IDE) It's not perfect, but IntelliJ has been more than good enough for me. Of course, I don't use a lot of fancier IDE features so my opinion probably isn't useful here. My major complaint is how frequently something will work (like spray/akka-http directives) in one version, then show up as errors in the next upgrade. &gt; binary incompatibilities of 2.10 vs 2.11 (and 2.12 if it ever appears) Used to be a problem, but 2.11 has been so stable and slow moving that's it hasn't really been an issue for a while. Hopefully TASTY fixes this. &gt; many libraries create their own DSLs and overuse implicits, using them is like learning another language Yeah, I did a lot of research to find my favorite libraries for general purpose web programming and I ignore the rest unless they have compelling reasons to switch. I can see how a newbie would feel lost in the many different ways people propose to solve problems with Scala. &gt; too many ways to handle errors (Future.failed, Either, Option, Exceptions, Try, ...) Ideally, you should make your own little ADT to handle errors in your domain. I.e.: sealed trait BusinessStatus case class BusinessSuccess(someImportantNumber: Int) extends BusinessStatus case object BusinessFailure extends BusinessStatus Future.failed and Try are both just ways to handle Exceptions. They're useful for handling third party code that can throw Exceptions (Future.failed in particular is for async Exceptions), but I believe you shouldn't be throwing Exceptions yourself anymore (much like you shouldn't be using nulls). Option is for handling optional values, not errors. Either can be useful when you want your business statuses to be composable. In which case, your business failure is left, business success is right, and now you can map/flatmap/etc them.
Added a constructor syntax close to what you proposed. https://github.com/cvogt/cbt/pull/84
Hi MasGui, Thanks for your finding. We have updated it already and we will cover DataSet[T] in next Spark Tutorial Thanks, Anand
Considering that partial application is really just wrapping a function of multiple values with one that takes fewer values, the same concept applies whether the original function is curried or not. If the argument you want to pre-apply isn't the first, then you still need to explicitly wrap with a new function. That's why I think currying is of limited usefulness. It's basically a shortcut to partial application in the special case of parameter order working out nicely for you. Handy occasionally, but rather overblown as a core language feature. 
There are lots of reasonable ways to end up with warnings you don't care about. Deprecations are one of the most obvious. It's very easy to get stuck in a situation where you really need to use deprecated methods (often because a third-party library you depend on has been sloppy about deprecations), and it just doesn't make sense to me that you should have to pick one policy to apply both to these warnings and to ones that indicate real problems in your own code (like non-exhaustive matches).
How is this any different in the java world? Some people are using SPRING, others JBoss, some use AOP frameworks, some are using built in proxies, etc. The complexity doesn't go away, it just shifts from being in the language to being in frameworks. 
Do you have any resources on learning/using Scala as a "worse Haskell"?
Sure! NB: I haven't taken any of the courses I'll list, but know and/or trust the instructors implicitly: 1. [Functional Programming Principles in Scala](https://www.coursera.org/course/progfun) from Coursera 2. [Advanced Scala With Cats and Essential Shapeless](http://underscore.io/training/) from Underscore.io 3. [Functional Programming in Scala](http://amzn.to/1phBc7d) by Chiusano and Bjarnason 4. [Learning scalaz](http://eed3si9n.com/learning-scalaz/) by Eugene Yokota 5. [Herding Cats](http://eed3si9n.com/herding-cats/), also by Eugene Yokota 6. [Introduction to scalaz-stream](https://gist.github.com/djspiewak/d93a9c4983f63721c41c) by Daniel Spiewak 7. [The Typeclassopedia](http://typeclassopedia.bitbucket.org/), by John Kodumal 8. [Programs as Values](https://tpolecat.github.io/presentations/lambdaconf-15.pdf), by Rob Norris 9. [Compositional Application Architecture With Reasonably Priced Monads](http://functionaltalks.org/2014/11/23/runar-oli-bjarnason-free-monad/), by Rúnar Bjarnason A few additional comments: 1. Especially if you want to use scalaz or Cats—and you do—actually studying Haskell would be helpful, especially considering that Eugene Yokota's wonderful series both use "Learn You a Haskell for Great Good" as a launching-off point. 2. I highly recommend following Eugene Yokota's "Learning scalaz" with Rob Norris' "Programs as Values," which is really a master class that should be called "how to write programs with scalaz." It's the best exposition of the Free Monad, ever. 3. Rúnar's "Compositional Application Architecture" answers the "how do I use more than one monad at the same time?" question much more nicely than monad transformers do. Hope this helps!
That is a good way of making that case - thank you.
Looks nice from glancing over it. How does this affect current usage such as in mutable map (`map(key) = value`) and STM with implicit parameter list (`ref() = value`)? I see an issue with RHS varargs: def update()(bs:T*){ // OughtTo() = bs:_* // OughtTo() = Nil:_* // OughtTo() = (b1,b2,b3) } This would mean there is an ambiguity with tuple syntax. You would have to introduce some auto-untupling, not sure this is a good idea given that auto-tupling was just deprecated.
&gt;This would mean there is an ambiguity with tuple syntax. Probably not, in Scala curried functions must always be able to resolve ambiguities using preceding parameters only. &gt;not sure this is a good idea given that auto-tupling was just deprecated. Oh, I was not aware of that. Do you know when or where that was announced? That may well solve a lot (but not all) of the issues I mentioned above... &gt;How does this affect current usage such as in mutable map (map(key) = value) and STM with implicit parameter list (ref() = value)? Right now this is just a suggestion, but if implemented: it depends. Either this curried version would be enabled alongside the current system, in which case nothing needs to be changed, but otherwise the method signatures for update within such libraries would have to be modified to use currying.
Umm.... not trying to be an inflammatory jerk, but I've written a couple different versions of this and started over. Really, the fact that it can happen still is a deal breaker for anyone evaluating Scala for use beyond it's current niche in big data. Also, I don't want my ecosystem to dictate whether or not I can integrate to component providers that provide closed source components. It should be capable of either regardless.
Well, unless you believe white males are uniquely equipped to program in Scala, the language is failing to reach a broader demographic. Or perhaps that particular group is. I haven't been to other Scala conferences to compare, but based on the handful of meetups I've been to by other groups, I'd say it's likely the community as a whole. 
The issue I see is that people are trying to push diversity for the sake of diversity, instead of the sake of pushing technology forward. If the main demographic showing up for Scala meetups happens to be white males, then be it. No one is actively excluding other groups as far as I can tell.
No, not nutty, and I appreciate the recognition that this isn't a trivial question. If we could turn back the clock to sbt 0.7ish, I might even say then—before there was so much `%` and `%%` in the wild, as it were—geez, guys, is `ModuleID` really so bad? &gt; Ordersky asked "Who likes the /: operator!?"... how come Scala detractors frequently wield it to demonstrate "complicated" Scala one-liners? Good question. I guess my general thought is that operators are reasonable when they're associative. For example: val firstSuccess = (cursor --\ "outerKey" --\ "oldkey2") ||| (cursor --\ "outerKey" --\ "newkey2") My guess is you can figure out that `--\` represents some kind of traversal and that `|||` represents some kind of "or" or "alternative," so this means "outerkey then oldkey2, or outerkey then newkey2," and replacing the symbols with words would be verbose and _less_ readable. But I'd agree that `%` and `%%` are different in that you're not chaining some kind of operation in using them. Anyway, thanks for taking the question in the spirit it was intended, and who knows? Maybe it _is_ worth spelling `ModuleID` out in sbt. If you try it with some newcomers, I'd be interested in hearing your experience!
Finally the proper announcement, thanks! My extract from this: - institutionally / infra-structurally placed at EPFL - currently organised by Heather Miller and Jon Pretty - (co-)financed by five companies with stake in Scala - aims to support Open Source and Education around Scala - Scala.js being the first announced project that receives financial support; and two new Mini-MOOCs around parallel programming and big data coming - has a pretty new website with some attractive logo and typography (Lightbend CI designer should take a look at this); and a Gitter channel So what's this thing with "making open source libraries more discoverable using a package index"? That got me curious!
Actually the page looks pretty much like a `Future[ScalaCenter]` ;-) But I like the idea.
The package index is the first project of the Scala Center :) We need a better map of community libraries and resources
&gt; Scala has seen a steady rise in adoption. This is reflected in the number of open Scala jobs and in Google’s search trends. In the Redmonk rankings, the language currently ranks 14th. If [Owen Rubel](https://www.linkedin.com/in/orubel) would see it ×D [Origin](https://www.reddit.com/r/scala/comments/49ecm0/is_scala_on_the_way_out/)
I wonder if financial support for Scala.js will mean more officially supported façades. I almost chose it for a project until I tried to use it with Angular 2 or Vue.
Of course he has seen it, he is obsessed with scala after all
Hi Heather. You can use [this tool](https://github.com/metadoc/metadoc/blob/develop/bintrayScape/src/main/scala/1_BintrayListPoms.scala) to download poms for all scala libraries on maven central.
Hi Martin, in intellij's scala plugin page we can find the total download count. I used archive.org to find older data point: https://raw.githubusercontent.com/MasseGuillaume/ScalaMontrealPanel/master/IDE-race.png
&gt; Do you know when or where that was announced? I think he's talking about [SI-8035](https://issues.scala-lang.org/browse/SI-8035) and [SI-6675](https://issues.scala-lang.org/browse/SI-6675) which were both announced as deprecated in the [2.11.1 release notes](http://www.scala-lang.org/news/2.11.1/)
It look like Scala is growing at an exponential rate. intellij's scala plugin 2013 + 500 000 2014 +1 000 000 2015 +2 000 000 [source](http://web.archive.org/web/*/https://plugins.jetbrains.com/plugin/?id=1347)
Thanks. Those changes make sense. It looks like auto-tupling in general is here to stay then.
Hi. Send me your GitHub account details over email. I'll then introduce you to the other guys who have already signed on.
Could you give more info into the motivations for this debugger? On the jvm you can ask the current thread for a stack trace at anytime. Asserts are built into the JVM. As for printing, in Scala you could use something like this [library](https://github.com/adamw/scala-macro-debug) to print expressions while debugging or better yet, drop into a interatactive repl with [Ammonite shell](http://www.lihaoyi.com/Ammonite/#Debugging).
I found these posts to be very helpful: https://nrinaudo.github.io/2015/11/21/tcgu-part-1.html
This counter seems to be the accumulated download number of all releases.
Because these print statements have hyperlinks so that when you click on them, it takes you to the location of the print statement in IntelliJ. When you want to get rid of them, you can just do Ctr-R and get rid of all instances of "trace". Also, the JVM asserts don't give you the option between fatal and non-fatal assertions, they just kill the current thread. With this you can turn things (asserts, traces, etc) on or off at runtime if you like instead of specifying extra command line options. Finally, sometimes you don't want 100 lines of stack trace. Sometimes you just want 10. With this you can limit the number of lines of stack trace. Try it.
&gt;Because these print statements have hyperlinks so that when you click on them, it takes you to the location of the print statement in IntelliJ. When you want to get rid of them, you can just do Ctr-R and get rid of all instances of "trace". That's what logging frameworks are for, you redirect println's outputstream to a logger for that and many other benefits. &gt;Also, the JVM asserts don't give you the option between fatal and non-fatal assertions, they just kill the current thread. With this you can turn things (asserts, traces, etc) on or off at runtime if you like instead of specifying extra command line options. A nonfatal assert is an Exception. More specifically unchecked exceptions in Java. &gt;Finally, sometimes you don't want 100 lines of stack trace. Sometimes you just want 10. With this you can limit the number of lines of stack trace. Try it. That's also something loggers will format. 
This implies you have multiple versions of this class in the classpath. You need to take a look at all you transitive dependencies to determine why this is the case.
&gt; I need Main.scala because automated test cases are woefully insufficient You could move `Main.scala` to the test-sources, you can then still run it via `sbt test:run` and that class doesn't end up in a published library.
Thanks for your help. I'm reading about transitive dependencies in the sbt documentation and running inspect tree But still not totally sure how to proceed. Can you suggest some next steps, things to look for? 
I'd love to see something like Hoogle as well!
Talk nicer to me, I'm only 22. That being said, let's say we wanted to do it your way. I want to type this: Debug.enableEverything_!() "Hello World 1".trace // 1 line of stack trace // "Hello World 2".traceStdOut "Hello World 3".trace(3) // 3 lines of stack trace Debug.trace("Hello World 4") Debug.trace("Hello World 5", 2) // 2 lines of stack trace "foo".assertNonFatalEquals("bar", "assertFailure1", maxLines = 2) "foo".assertEquals("foo", "assertFailure2") 2.assert( _ + 1 == 3, "2 + 1 = 3") Debug.fatalAssertOff_!() // disables fatal assert "foo".assertEquals("bar", "message3") // assert cancelled And get this output: "Hello World 1" in thread pool-4-thread-6-ScalaTest-running-StackSpec: at info.collaboration_station.debug.testing.StackSpec$$anonfun$8.apply$mcV$sp(StackSpec.scala:149) "Hello World 3" in thread pool-4-thread-6-ScalaTest-running-StackSpec: at info.collaboration_station.debug.testing.StackSpec$$anonfun$8.apply$mcV$sp(StackSpec.scala:151) at info.collaboration_station.debug.testing.StackSpec$$anonfun$8.apply(StackSpec.scala:147) at info.collaboration_station.debug.testing.StackSpec$$anonfun$8.apply(StackSpec.scala:147) "Hello World 4" in thread pool-4-thread-6-ScalaTest-running-StackSpec: at info.collaboration_station.debug.testing.StackSpec$$anonfun$8.apply$mcV$sp(StackSpec.scala:152) "Hello World 5" in thread pool-4-thread-6-ScalaTest-running-StackSpec: at info.collaboration_station.debug.testing.StackSpec$$anonfun$8.apply$mcV$sp(StackSpec.scala:153) at info.collaboration_station.debug.testing.StackSpec$$anonfun$8.apply(StackSpec.scala:147) "assertFailure1" in thread pool-4-thread-6-ScalaTest-running-StackSpec: at info.collaboration_station.debug.testing.StackSpec$$anonfun$8.apply$mcV$sp(StackSpec.scala:154) at info.collaboration_station.debug.testing.StackSpec$$anonfun$8.apply(StackSpec.scala:147) ^ The above stack trace leads to an assertion failure. ^ ^ How would you do it if you were using Logger4J ?
great, thanks!
Thank you so much
I highly recommend Scala should corporate with Jetbrains to make a better Scala Studio. I don't think there are a lot people using Scala IDE.
&gt; That's what logging frameworks are for, you redirect println's outputstream to a logger for that and many other benefits. Would you like to fork my repo, implement that feature, and then make a pull request? Because your method of configuring a logger to do these things is unbeknownst to me and I would really appreciate said feature.
Hi Martin, can Scala and Jetbrains work together to build a better IDE for Scala. (Same as Google and Jetbrains did for Android Studio). So developers can unify their IDEs as well.
&gt; I wasn't around in the days when there was only Build.scala, so I'm not sure how exactly that failed. It didn't fail as much it was a never ending source of ambiguity for users.
I'm very happy with the current IntelliJ Scala plugin. They seem to be doing a pretty good job independently.
Question regarding the courseera courses. Is there any info on weather these courses will be released all at once and if they will be self paced or artificially paced (lectures released week by week). I have a very flexible module in my Msc in Computer Science and I would like to try and do the mini-degree as that module but I would need to be able to do it on my time frame and am just wondering might that be possible. Also is there an estimated time frame for the release of those courses?
Also I don't get the hate for IntelliJ + Scala plugin, it's all open source no?
&gt; Not only is Scala a second class citizen on Intellij, it's counter to the company's corporate strategy to give it proper long-term, and free support. Hear, hear! It's good to see a counter to the Intellij-cheerleading we usually see here. The above is the best rationale I've yet seen for being wary of Jetbrains. They wouldn't be putting so much money and effort into Kotlin if it wasn't part of their long-term strategy.
Thanks again. Using the sbt-dependancy-graph plugin I get a tree that is also several thousand lines long (is that a red-flag in itself?). Some things, for example, I see: [info] +-com.datastax.cassandra:cassandra-driver-core:2.1.9 [info] | +-com.codahale.metrics:metrics-core:3.0.2 [info] | | +-org.slf4j:slf4j-api:1.6.4 (evicted by: 1.7.10) [info] | | +-org.slf4j:slf4j-api:1.6.5 (evicted by: 1.7.10) [info] | | +-org.slf4j:slf4j-api:1.6.6 (evicted by: 1.7.10) [info] | | +-org.slf4j:slf4j-api:1.7.10 [info] | | +-org.slf4j:slf4j-api:1.7.5 (evicted by: 1.6.5) [info] | | +-org.slf4j:slf4j-api:1.7.6 (evicted by: 1.7.10) early on. But then nearly identical block show up elsewhere, nested much deeper, like: [info] | | | | | | | | | +-org.slf4j:slf4j-log4j12:1.7.5 (evicted by: 1.7.10) [info] | | | | | | | | | +-log4j:log4j:1.2.16 (evicted by: 1.2.17) [info] | | | | | | | | | +-log4j:log4j:1.2.17 [info] | | | | | | | | | +-org.slf4j:slf4j-api:1.6.4 (evicted by: 1.7.10) [info] | | | | | | | | | +-org.slf4j:slf4j-api:1.6.5 (evicted by: 1.7.10) [info] | | | | | | | | | +-org.slf4j:slf4j-api:1.6.6 (evicted by: 1.7.10) [info] | | | | | | | | | +-org.slf4j:slf4j-api:1.7.10 [info] | | | | | | | | | +-org.slf4j:slf4j-api:1.7.5 (evicted by: 1.6.5) What sort of investigation should I be doing here? Are there any resources you can point me toward?
macwire actually agrees with all of that. It encourages you to use the dependency as plain-old-scala class parameters. Macwire _only_ provides you with a macro that given all the puzzle pieces, puts the right piece in the right whole. It's just a tiny convenience. From the macwire guys: http://di-in-scala.github.io/ I also strongly recommend this: http://www.lihaoyi.com/post/StrategicScalaStylePrincipleofLeastPower.html#dependency-injection
Sounds like this should be good for [scala.js](http://www.scala-js.org/). If the scala.js project could influence the development of [webassembly](https://webassembly.github.io/) into a viable compile target, that could be huge for the adoption of scala in general. Or inevitably someone will port a JVM to webassembly, but that will have a lot of overhead. Still, if such a JVM could be installed as a webassembly browser plugin, that might not be so bad. 
I would really fancy a trip to Venezia :-).
Have you tried tweaking the continuation indent under code style &gt; scala &gt; tabs and indents? (shameless plug) you can also try the IntelliJ plugin for [scalafmt](https://olafurpg.github.io/scalafmt/). It's very new and it doesn't give you any configuration options (yet). But maybe you like it.
I'd be very interested in scalafmt, but I must admit, I am a little concerned about the potential performance issues? I'll give it a shot and see how it does, because if it does solve this problem for me, then it'd be great :)
Jetbrains have free version.
Yeah, I am happy with it as well. But it would be great if they can work together and make it much better.
&gt; If the scala.js project could influence the development of webassembly into a viable compile target That's part of my personal plan to conquer the world :-p
Hey guys! I'm jumping into Scala and I'm trying to create fast and (hopefully) efficient library for (linear) regression. I've created this repository - [regressor](https://github.com/otobrglez/regressor) - and would absolutly love to here some comments / tips from you guys!
&gt; I think it means the community is leaving a lot of potential talent and insight on the table, both from a technological and social perspective Is there any evidence that this is really the case? I feel that people rush to such a conclusion, and I don't know if there are any studies that actually indicate that talent is being left behind. If anything, attempting to include groups by force (ala affirmative action) may very well result in the opposite effect happening. We should just let things happen naturally.
Just like they'll never try a subscription model for IDEA again, so you can continue to get updates and use your editor? That was a pretty shady move, even if it was aborted. Do I think they will charge for the language? No, because it won't ever become popular enough to produce a large profit, but they might start making you pay for any part of their platform at any time that becomes popular enough to generate revenue; they've shown that they can at least think about changing the way developers pay for their product, and that means that you can't remove anything that may possibly generate revenue from the realm of possibility. I've seen it in other technical industries where a tool becomes a standard tool and isn't really open -- Photoshop (and InDesign,Flex/Flash ides), SolidWorks, etc. Some of those things had base tech that was open source, but additional tools that required subscriptions to operate. Some are just inherently subscription-based products. I'm not against paying for things if I need to - I carried a Flex dev licence for a few years when I worked in that, I payed for Photoshop when I did more front-end work. I pay for lastpass, github, etc. I would prefer not to have to pay to make another company's revenue producing product better via free dev time. I don't understand why someone would both pay for their product and give then free development time when there are other viable alternatives, but meh. Just don't expect me not to speak up when someone suggests that IDEA should become the default official IDE of the Scala community. It may be open, but none of the corporate environments that I have worked in use the free version - because if you do Scala you also do Java, and Java is not a free part of their platform.
Try { // your code here }.toOption
I doubt that using Future for one arithmetic expression is a good idea. Actually it may be slower. If you want a Seq of pairs, it is more type-safe to use Seq of tuples
In addition to Try { /* code */ }.toOption there's also scala.util.control.Exception http://www.scala-lang.org/api/current/index.html#scala.util.control.Exception$
You can be more specific about what Exceptions you expect to happen on the left side of the Either.
`Either` has left and right projection so you can decide to map on one side or the other.
see also https://www.reddit.com/r/scala/comments/4acqj6/announcing_the_scala_center/d0z8mii
https://www.jetbrains.com/idea/features/ Java, Kotlin, Groovy, Scala are free in Community Edition... plus Android, Maven, Sbt, Gradle, Git, Svn and others. Again that's FUD. I get that you don't like it and/or you don't want it to be standard, that's fine. But you aren't checking facts before publishing 
This is exactly what makes Either unusable in my opinion. If you give me a monadic interface with short-circuit semantics, don't make me jump through hoops to handle a short-circuit
awesome! this is what I was looking for, but didn't find.
I briefly thought about building a quick function signature parser and loading it up into a postgres instance. I don't think it would be too hard.
Either is unfortunate when you are flatMapping over it because it has no bias. scalaz provides Disjunction ( \\/ ) which gives you the ability to carry information about a failure, but also has a right bias (similar to behavior of None in a for-comprehension, except it yields the Left value instead.) What I would probably do in production code is import scalaz.syntax.option._ Try { somethingThatThrows }.toOption.toRightDisjunction("failure message") // or more realistically \/.fromTryCatchNonFatal { somethingThatThrows } Then you have Validation as an applicative for accumulating failures when you don't need to stop on the first one. Very useful for most of the kinds of code you will ever write. Edit: special chars
What's the distinction between `Exception` and `NonFatal`, Dale? scala&gt; try { ??? } catch { case scala.util.control.NonFatal(e) =&gt; e } res3: Throwable = scala.NotImplementedError: an implementation is missing
Use Slick and the slick-pg library. I've got a sample Play project using them here: https://github.com/wsargent/play-slick-3.0
in my example, I'm doing ETL and expect plenty of crummy data. I don't really care why I couldn't parse the date or number - I just want to move on with the process. In Scalding I created sinks for bad data that threw exceptions. I'm not sure what to do in Spark
you could have found it here: http://www.scala-lang.org/api/current/index.html#scala.util.Try
See: https://github.com/djspiewak/shims Which tries to be a compatibility library between Cats and Scalaz, but _also_ provides a right-biased syntax for the standard library `Either`, for those times when you want a usable `Either` without needing to use a large ecosystem to make use of it. YMMV, it's very new. But it's certainly an option to consider.
Or an either to consider.
&gt; It’s usually considered bad practice to catch Throwable instead of Exception. &gt; &gt; I'd be interested to learn more on why it's bad practice though. This is inherited from the Java Virtual Machine architecture. A Throwable is either an Exception or an Error, and Errors include VirtualMachineErrors like OutOfMemoryError and StackOverflowError.
I expect I'll give that a go. Thanks.
It may not be Hoogle, but I think Codatlas is pretty neat. For example, [here](https://www.codatlas.com/github.com/scala/scala/2.11.x/src/library/scala/util/Try.scala?keyword=toOption&amp;line=159) you can look for references to `Try.toOption` in major open source Scala libraries.
most people use slick, its not flawless tho
I use ScalikeJDBC and have no complaints. Here is the blog post I wrote recently about integrating it with Play (using H2, but configuration is the same): http://appliedscala.com/blog/2016/scalikejdbc-and-play
Look at [Bond](https://github.com/fwbrasil/bond), maybe?
Mac OS X: [Dash](https://itunes.apple.com/us/app/dash/id449589707?ls=1&amp;mt=12) Linux, Windows: [Zeal](https://zealdocs.org/)
Have a look at: http://sorm-framework.org/ 
Hmm, looking at the linked pages, it looks like those products allow you to lookup the documentation of a function if you know its name. What we're talking about is looking up the name (and maybe also the documentation) of a function if you know only its type signature.
Interesting project, looks like it is suffering for documentation. When you say adds right-biased syntax for std Either, does that override behavior of flatMap? right-bias is great but it kind of needs to work in for-comprehension to be practical IMO. If you have a link to the source that does this I'd love to see the implementation.
I think I've never seen intellij formatting code that way. But offtopic: I would actually prefer the current style, very much even. It makes the line with opening bracket `{` and equals sign `=` be indented less or equal to the closing `}`.
I recently went back through the ecosystem trying to find the ORM I wanted to use with Play. Ultimately, I didn't like the balance struck by any of them and fell back to using jOOQ instead. If your application is anything more than a toy, you're going to hit some serious problems using the slick, sorm, sclaikejdbc based options: - Some tables have more than 22 fields. It won't fit in a case class anymore. You are stuck. - Complex queries are really common in a real application and a cute wrapper over a scala loop construct stops being helpful and starts forcing you into writing all your SQL as strings. - You probably want a mature schema management solution anyway (you know, to migrate your SQL), and it's now 2x the effort to manually translate your schema into SQL and scala. - Good support for custom type mapping is pretty rare, especially for postgres (fancy data types won't help you if they're all "AnyRef" or "String" once you get your hands on them) I like jOOQ because it generates classes based on your SQL schema directly, allows more than 22 fields, easily supports complex joins and aggregations, and allows you to customize the generated code with custom type mappers; all while retaining type safety in your query expressions and generated records, pojos, tables. Obviously, this approach is not bulletproof. I'm annoyed by jOOQ because: - use of java.lang.{Integer, Long, Boolean} in the generated classes is fine most of the time but occasionally requires explicit casting when coming from scala's primitives - there's no attempt to support joined record types, so you still occasionally have to write your own result mappers to handle relationships. Thankfully, those mappers aren't terribly painful- but still annoying. - you have to fall back to using jackson JSON mappers instead of the Play JSON utilities (because you have no case classes anymore). Obviously, YMMV depending on what you're building and the amount of functionality that you need from your database. The more simple your DB interactions, the better the scala ORM solutions start to look.
Ah, right. Good point!
You need the Ultimate edition to get [JavaEE and Spring support](https://www.jetbrains.com/idea/features#chooseYourEdition), which has been used on every large business Java app at the enterprise shops I've been at. Do you technically *need* it to compile the code? But you don't technically need anything other than a text editor, a build script, and a shell to do that either. The only reason nobody complains about it is because their employers buy their tools for them. Which is good, because it's an expensive tool. And I like the tool for Java -- I just don't think it would be a wise move to abandon the free ones. To navigate the codebase of an enterprise spring banking application efficiently, yes, or at least I do. But that's why I use STS. And everybody's sbt support is terrible. You have to use the command line to do anything beyond compile and test.
Play framework and Slick work really well together. Slick provides an easy way to map objects to database objects. Here's a tutorial for Play + Slick + MySQL. While it's not Postgres, it should be pretty straightforward to adapt from MySQL to Postgres: http://pedrorijo.com/blog/play-slick/ (or just the code example: https://github.com/pedrorijo91/play-slick3-steps)
If you look at: https://github.com/wsargent/play-slick-3.0 It uses Slick, slick-pg, sbt-slick-codegen, and Play. All of it. It's all set up. I've done the work for you.
It's my understanding that the compiler supports more than that now, but over that limit it stops generating certain important methods on the companion object. Specifically 'unapply' if I recall correctly. For slick, this used to mean that you had to start hand writing your field mapping and exactly duplicating the column names and types a 3rd time. Failure to do so would result in extremely cryptic compiler errors coming deep from within macros somewhere.
hi I'm very new with scala and I tried out play since it had alot of templates. but I found that there are so many options for everything it becomes very hard to work. Can anyone suggest a lightweight framework that you can build on? one that is hopefully more opinionated. Best Regards Stevenson Lee
Of course that is possible, but I would argue that it contradicts the purpose. If you have `def x(player: PlayerId, energy: Energy) = ...`, you don't want to reintroduce the problem of accidentally flipping the arguments in `x(3, 4)`. What I often do without wrapper type is force myself to use named arguments, like `x(player = 4, energy = 3)`.
So you would assume we've lucked into the optimal demographics of Scala programmers, and need a study to convince you otherwise? When you say "happen naturally" you might also inadvertently be saying "maintain exclusivity". And I don't think there's anything unnatural about a programming language community acknowledging that its demographics aren't representative of the larger engineering world, let alone broader society. You may note that I haven't called for anything remotely like affirmative action. At this point, my argument is simply that maybe people should bother to give a damn, yet you resist even that. 
Honestly I don't like these examples much. I feel they skirt around the point of flatMap, which is basically what if the helper function you're trying to use on your wrapped type also returns that wrapped type? If you tried to use map you'd end up with a container of a container, which often isn't what you want, so instead of map you use flatMap. The first examples rely on implicit conversions of strings to something Seq-like, and likewise with the list of options example, which further clouds the issue if you're a beginner. 
Its a nice side effect having your fireballs expressed in MW.
OP here, thanks for posting this to reddit. I was wondering why suddenly I got so many visitors to the blog :) Hope my post is useful, especially to Scala beginners
The 4 and 3 can be used directly because in your example, the class is marked implicit. So in `def X(player: PlayerId, energy: Energy)` You can simply call it with `X(4,3)`, and the implicit classes will wrap your `Int`s. That is, assuming they're in scope.
Well, since you can't study all things at once, you have to start with something to get going. "Forget about NullPointerException" is both a good marketing point and a good way to start tuning your brain (in my opinion, anyway).
It certainly would be convenient to think so, because then there'd be no reason to want to do anything, would there? That's kind of like working backwards from apathy as a disposition towards a theory for the present state of the world that supports that decision. In my view of the world, people don't randomly become curious. They get exposed to various possibilities via their social circumstances. Meaning that what an individual sees as a possibility for themselves depends on what other people expose them to. And for many reasons, including "like me" bias, people who are insiders in a community like that of Scala may not be engaging a wider demographic.
&gt; I never HAVE to learn it to accomplish some task. ... from scratch. To interact with existing code is a different question. 
What frameworks did you end up landing on?
Ah I totally forgot that you have to flatMap a projection with the usual Either, I was confused how you'd enhance something with a method that was already on the original but now all makes sense. Very cool!
I'd like to see the following charts as well: - Javascript suicide ratio - PHP suicide ratio - Javascript/Depressions ratio - PHP usage by IQ - highest education/PHP developers
In SBT an evicted dependencies are harmless. When SBT detects a version conflict SBT will attempt to pick only the newest version that artifact so that only 1 of them will show up in the class path. What you want to look for are conflicts SBT may have missed. The most common cause of this is that a dependency has multiple names. For example, from personal experiance I know that the [asm](https://search.maven.org/#search%7Cga%7C1%7Casm) project has several different IDs, my project had `org.ow2.asm % asm` and `asm % asm` as transitive dependencies causing multiple versions of a class at runtime. Another thing you'll have to look out for is project embedding their own versions of other projects in their jars. The easiest way to find these is to probably switch your [MergeStrategy](https://github.com/sbt/sbt-assembly#merge-strategy) in `sbt-assembly` to log the source of duplicate classes, otherwise you have to search through every jar in your classpath to find classes which might not belong.
C has its place. C and Scala are not used in remotely the same areas.
I use the time to open a PHP-project, skim the code and bless my lucky star that I'm working in Scala.
Use sbt/activator and: `activor ~ compile` or `sbt ~ compile`
http://scalatra.org/ And an example sbt-based project https://github.com/laurilehmijoki/sbt-scalatra-skeleton
Like check up on Reddit :)
&gt; Errors in Go are in your face. You can't imagine how many times our PHP application has failed to work because someone forgot to catch an exception. If you call "if(err != nil) {" error handling then I don't know what to say - it's pretty primitive. You can do the same in Scala but it won't be appreciated. &gt; The syntax of Go makes people write code in a specific way. In a repetitive, primitive and horrible way. Go is almost the same as java 1.0. DSLs aren't present - you only call functions and that's it. It makes your code 10-20x larger compared to Scala. "Boilerplatism" doesn't build readability, except when your coworkers are rookies. &gt; If you use stuff like go metalinter, you can prevent bad code from ever making it to your git repository. Most go code I've seen are bad(dumb and repetitive) - it's pretty self-entitled from go programmers to call their code good by default. &gt; So what I'm saying is, I think Go is better when scaling the number of developers, and Scala is awesome when the developers know what they're doing. The point of language development is to reduce the developers' work and not to increase their 'amount'. More developers = more trouble and if those developers write stuff like 'if(err != nil)' then you've more problems. The more complex application you write the more you'll appreciate a decent typesystem and enhanced error-handling tools. But go is only present because google made it and advertise it heavily. &gt; Of course, the price is that in Go, apart from the fact that some things take more effort to write, you don't have access to the huge number of libraries and frameworks available in the Java ecosystem. Just more? I've used go for some test projects but my fingers almost died. &gt; Have you faced these issues with Scala? No, I haven't. Most go brogrammers came from php/python and they're happy because they've met with the mysterious concept called 'statically typed'. That's why all this 'productivity' ad goes for go. &gt; I'm more worried about having to constantly check the libraries I pick and the code my team writes, to see if they are not doing something the wrong way, which would end up making the codebase unreadable. Your team's code quality/readability will depend on their skills.
I agree with your points. However, what I meant with errors being in your face is that you know when a piece of code is going to cause an error. For example, take this line I just found on the Internet: ``` val response: HttpResponse[String] = Http("http://foo.com/search").param("q","monkeys").asString ``` What happens if this fails? I don't mean that `if (err != nil) {` on its own is the perfect error handling method. All I'm saying is that when you have to write a piece of code like this: ``` response, err := http.Get(...) ``` you have to consciously make a decision, because the `err` variable is forcing you to do so. The fact that error handling is repetitive is not pretty and it requires you to type a lot, but so does Linux. As a Windows user, I hate having to type in my password all the time when I have ssh'd into a Linux box. However, I do understand the security implications of not having such a feature, and not being forced to enter my password – if nothing else, it is just a gentle nudge that, hey, what you're doing might possibly make something stop working. I am not attacking anyone or anything here. It's just that having beginners in my team has proved to be problematic in PHP because the language is unpredictable if you don't know what to watch out for. I'm afraid that Scala would be something like this but falling down from the other side; giving you a lot of power without teaching you to use it, first.
More important than the syntactic sugar of async/await is the hidden implementation of those techniques. Instead of making them explicit so you can deal with them. I would try not to use any of them favouring others concurrency models like Actors and Communicating Sequential Process. Async/await, callbacks, Futures and Tasks are all the same thread-base model.
"by design"
HttpResponse will likely encode the error in its type, thus forcing you to use combinators to handle it. `val result: Option[String] = maybeFail()` vs `result, err := maybeFail()` is the more fair comparison. In this case, Option wins already because you are forced to handle both the Some and None cases (as much/more than Go required you to handle err, at least). And this is not even considering how you **compose** possibly failing functions. This is an area where Go falls over embarrassingly in comparison.
I could use some advice on studying for Scala interviews. Some of the traditional interview questions (I'm using Cracking the Coding Interview to study) require solutions that aren't very Scala-esque, like mutating arrays in place or accessing arrays with indices. Should I study these questions from a Scala mindset or the more traditional Java mindset?
Agreed. Back to my original question: how has Scala worked within teams? Have you had any problems with it? How have you solved them? What really worries me are the points raised in this [Quora answer](https://www.quora.com/Scala-vs-Go-Could-people-help-compare-contrast-these-on-relative-merits-demerits/answer/Nick-Snyder-1?srid=5kfF) by someone who knows what he's talking about. I know both languages have their strengths and weaknesses. However, what I'm specifically asking is *how* you guys handle the weak points of Scala every day. On an unrelated note, do I need to create an entirely new post for this since this is getting long?
What happened at 2015-12-14?
My team has fluctuated between 4-6 or 7 devs in the last couple years. We went from nobody knowing Scala to everyone preferring it for any development task its viable for. I had some hobby/university experience in Scheme and Haskell before coming to this job. I pushed for scalaz and have been a go-to resource for any pure FP questions. Stuff like "how do I do this without &lt;the impure way&gt;?". I've also been pushing my code to be more and more pure and incorporating new things I learn. I always make sure to be available to explain the principles of it. The results have been very positive. I've gotten positive feedback from my peers and the team's code as a whole has moved more and more towards pure FP. Note that we do have CRs on every commit, and the CR email goes out to every team member. So I try to review a lot of code and suggest ways to change types, use scalaz/stdlib features, etc to make the code more pure and total. As more of my team members have picked up the scalaz/pure way of writing scala, they have also been more prone to making these sorts of suggestions as well. So speaking from experience, if you have a team of people who buy into immutability/purity/totality/etc and you have at least one member who is either experienced somewhat in FP and/or is willing to dive deep into pure FP (read scalaz/cats/shapeless scaladocs, blog posts, source code), then I think Scala is a great choice of language for your team.
&gt; I'm afraid that Scala would be something like this but falling down from the other side; giving you a lot of power without teaching you to use it, first. /u/ItsNotMineISwear already explained the Scala-way in that case and I would add that go doesn't force you to handle the error but Scala do. That's something to think about.
Were they written in Scala? Because then you could argue it was relevant content.
Actually, reddit went and removed all deleted users from subscriber counts. If you look at any large and old subreddit, you'll see a large dip at that time.
Right. I definitely recommend `Task` instead, in general. I just didn't want to get completely distracted with a lot of "scalaz... ewwwww!" nonsense. :-)
Thanks for the blog spam that is pretty much slightly altered copies from the documentation. http://spark.apache.org/docs/latest/sql-programming-guide.html
As a junior Scala developer (~6 months from 0 knowledge of Scala, though I had some Haskell exp), I would say it totally depends on the requirements of your project. If you're writing a small microservice will very well defined interfaces to other services, then Go can be excellent for you because the ecosystem is really mature for that kind of work. There will be no problem getting other devs up to speed. If the project is very business-logic heavy, then I would totally recommend Scala. Scala does have a lot of features, but over time you will learn how to use them in the right scenarios (and often times you can write a small library to hide the advanced features behind a simple interface). For me picking Scala over Go is an investment - I'm trading away work done right now for a more maintainable codebase, as well as learnings that will help me to be a better problem solver. As an anecdote, I currently work on a Scala codebase that was totally hacked together in the early days of the company by multiple (other) people, but I am having no problem navigating around the codebase and performing major refactors. The strong type guarantees and tooling support is what enables this, which I am not sure the Go ecosystem provides. In terms of 'bad code', imo it's not a language problem but more of a culture thing that needs to be fixed (code reviews and developer culture). The one advantage is Scala is that it is clear and concise (as well as being type safe), greatly reducing the code you need to read and understand. To balance out my argument, here is a blog post of a team [migrating away from Scala to Go](http://jimplush.com/talk/2015/12/19/moving-a-team-from-scala-to-golang/)
This looks amazing! Getting quite excited about 2.12 now.
wouldn't go that far quite yet. People copy and pasting these dependencies should be supported without annoyances I think.
It appears to have very little activity, and it does have its limitations. I wish it composed more nicely with collections. But I still find it quite useful as-is, and generally prefer it as my default way of operating on Future values. Quite often, I'm working with Futures of collections, and it's easy to end up with an inscrutable `map`/`flatMap` soup, and `await` provides a nice visual distinction.
Scala != pure FP. It's totally fine to use Scala as a better Java, without the fancier scalaz/cats... stuff. If you come from a PHP background, val + scala.collection.immutable is already a huge boost in safety --- and can be grabbed without much fuss if you come from an imperative background. Before dipping in scalaz/cats, give the [FP in Scala book a try](https://www.manning.com/books/functional-programming-in-scala), it the best programming book I bought.
If a hitman researches their target's movements, figures out their routine, stashes weapons in place for the future, practices their skills for the next hit, are they not assassinating? Well, maybe. But I think it's still correct to say you can't assassinate without killing people, even if you're not doing that at every moment of an assassination. 
Sometimes it's useful to look up docs while you're thinking about a design or problem, which is not always when you're in front of a computer. 
To the extent that we're talking about deficiencies in Scala or new language features, these things are universally applicable. So I'd say the only legitimate use case for macros is as an experiment/prototype for something that's intended to become an SIP.
The thing that stops me leaping completely into this model is that lazy Tasks are much harder to understand at runtime. A Future contains a concrete promise value that's relatively easy to inspect at runtime, and you have a reasonable hope of finding the corresponding PromiseCompletingRunnable. A Task is utterly opaque, and so less amenable to reasoning about, particularly if you're trying to e.g. understand where a computation has blocked.
I'll often sketch ideas on my phone or iPad, so scalaz scaladocs help with that. But often the methods won't scroll even on the iPad. 
Scala isn't inherently pure FP but my team at least is pretty much in agreement that a pure FP approach works best. We see the learning curve as a static cost that goes to 0 as our codebase grows. Not to mention that there's not a single competent dev I've met who can't end up compiling scalaz and shapeless in their head relatively quickly. And that's all it takes to grok even the most complex Scala. 
I was under the impression that they wanted to include it in Scala, but there are some blockers in Scala sync that are prevented it from doing so. In any case, Scala async is being used, and I think its not being worked on because everything has been done that is possible with Scala's current type/macro system. Probably retronym could provide better insights
Hey guys, I am trying to advance my learning to the next level of scala. I started with *Value Classes*, *Type Classes* and this lead me to *Value Types* and then to *Implicit Classes*. I came across some good links on SO and SIP but in the end wound up not understanding how/where to use them. What foundation do I have to build before I go re-learn and properly understand the above said topics. EDIT: added some text
If you are a good programmer or developer you have not wasted any time. If you don't like scala anymore you can apply what you have learnt to another eco system. If you like rust now, become a rust developer. Your 5 years experience of scala will give you a big jump start with any other language. Being negative and spreading FUD you will only hinder your own progress in life and your chosen career. As being happy will motivate you do more things in life unlike being bitter :-) 
hmm, clearly you dont have a family to feed and you will always remain a slave called employee.
Seems like you all are students who have no idea what it takes in terms of tools for maintaining professional software development practice , unless you are among the losers who are making inteliJ super rich.
Just proves your desperation, but all bad things eventually come to an End. Scala will die so will Reddit.
Hey! I just saw this in the spam filter just now and approved it, but you might want to resubmit this because it's been a few days now.
Agreed. I've often stumbled upon posts from this blog whilst searching for something and they've always been rather poor in their content, correctness and helpfulness. Don't get me wrong it's nice that they are putting in the effort in blogging but sometimes poor examples or worse than nothing at all, especially for beginners. 
Sure. I started a business that's now turning out a solid profit, have ten employees, a well fed family, and have been mandating all new developments be in Scala for the past few years. I have no doubt that you'll somehow twist that around to match your world view, and am curious how you'll do it. Am I a liar? Did I succeed *in spite* of my obvious stupidity? Do you reckon all developments are secretly done in Rust (a very good language, by all accounts) with a thin layer of nonsensical Scala to keep me happy? Am I on the brink of failure but only you are clever enough to see that?
What scala framework do you use for cassandra? I used phantom a few years ago but didn't know if something better has come out since then.
For 2) you can use [RDD.zip](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD), given that your *a* and *b* have same number of partitions and records per partition and share same order. If you have a key that links the two, like an article id, it would be better/safer and you could simply [PairRDDFunctions.join](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions) or combine them. For 3), you should split your page manually - it's a string, [use string methods](http://alvinalexander.com/scala/scala-split-string-example).
I'm working on an application that seems to make the most sense as a combination of Akka Streams and Actors. Essentially a RESTful API using Akka Http's streams for the CRUD operations, and then some backend processing that is best handled in distributed actors. I'm new to Scala and new to Akka. I am having a hard time finding examples of Akka Http where actors are used alongside the streams themselves. For example, some of the backend processing involves Scala calling out to an external binary. What I would like to be able to do is have one of my RESTful endpoints using Akka Stream to send a message to an actor to kick that process off and receive back a job ID. I'd then like to be able to create a websocket stream where the actor can feed back real-time output from the external process back through that stream. Does anyone have any advice on this type of architecture? Any examples that might show some similar types of architecture, or, at the very least, some examples showing how Actors and Streams can interact within an Akka Http application? Thus far my searches are coming up pretty empty. 
this particular example can be boiled down to: def compare(other: Student): Int = name.compareTo(other.name)
Other people have given you the practical answer, but I think it's worth emphasising the concept behind 1: a key functional programming idea is that *functions are values* and you can use them as ordinary values. In particular, the argument to `flatMap` *is a function* - you can write methods that do things with functions without ever calling them (e.g. a method that takes two functions as arguments and returns a function that's the composition of those two functions), because functions are just another value.
The thing with these kind (or type?) of posts is that they are too difficult for people who have no idea what functors are and too basic for those who do. But still, the more stuff like this on the web, the better. You got my upvote.
So, for fun I tried to encapsulate both ways of generating types here https://github.com/devshorts/scala-tiny-types I'm relatively new to scala, so would love a peer review on it as well :)
while you have a point, this pretty much hit the spot for me
&gt; Functors are like homo-morphisms between categories. And I'm done.
Here is a project that i am currently working on that is similar to what you described (i think). https://github.com/Thangiee/MARS-back-end For the CRUD operations to a DB, I am using Slick, although, you might want to check out quill(https://github.com/getquill/quill). It looks really nice and has a lot less boilerplate compair to Slick. Oh, and here a small part of my project where i used akka stream and actor together to do some real time stuff (probability not the best code as I am new to akka stream too). https://github.com/Thangiee/MARS-back-end/blob/master/src/main/scala/com/utamars/ws/ClockInTracker.scala And here is the code that sets up the websocket connection using a REST endpoint. https://github.com/Thangiee/MARS-back-end/blob/master/src/main/scala/com/utamars/api/WebSocket.scala Lastly, Intellij 16 currently has this annoying bug where it marks certain good akka-http codes as errors and the only work around that i know is to switch to a specific older version of the IDE and scala plugin. Feel free to ask me any questions. Hope you find this helpful.
Interesting, but what are some of the advantages over a library like squeryl? 
it seems Scala developers are hard to find. My team is resorting to finding a Java developer to fill our Scala development position, and have them train to learn Scala. Chicago seems to not be a hot spot for Scala developers.
What is the best way to do some web-scraping with Scala? Also, is there a way to use `curl` via Scala? I'm asking because I want to scrape a website fairly frequently, and I want to keep my data bandwidth that I'm using up to a minimum (aiming for under 1 M/minute).
Man, thanks so much for sharing your code. I'll share my proof of concept, as well, when I get something working and perhaps we can compare notes. :) I may take you up on that 'ask me any questions' offer. 