[TextFlow](https://docs.oracle.com/javase/8/javafx/api/javafx/scene/text/TextFlow.html) is a type of container that makes your different types of texts (plain, styled and also links) flow seamlessly together.
Sorry. Rookie mistake....i withdraw my comments, counselor! 
What are Zurich salary ranges for Scala devs? Or for any decent devs?
The way to solve dependency injection for algebras, is to just, well, use dependency injection: `distage` framework was made specifically to address this problem, unlike MacWire it handles higher kinds easily: https://izumi.7mind.io/latest/release/doc/distage/index.html#tagless-final-style-with-distage Testability is achieved by simply swapping the implementations for tests, e.g. * Production SQL repository - https://github.com/ratoshniuk/distage-sample/blob/develop/domain/users/src/main/scala/com.github.ratoshniuk.izumi.distage.sample/users/services/production/PostgresUserPersistence.scala * Test in-memory repository - https://github.com/ratoshniuk/distage-sample/blob/develop/domain/users/src/main/scala/com.github.ratoshniuk.izumi.distage.sample/users/services/dummy/DummyUserPersistence.scala Integration test that tests _both_ by just flipping the `useDummy: Boolean` switch to wire different implementations: https://github.com/ratoshniuk/distage-sample/blob/develop/domain/users/src/test/scala/com/github/ratoshniuk/izumi/distage/sample/services/UserServiceTest.scala#L23 Instead of services, the target monad can be easily swapped for tests as well.
&gt; unlike MacWire it handles higher kinds easily: Fixed as of 12 hours ago in 2.3.2. Macwire now works perfectly with HKT and tagless final. https://github.com/adamw/macwire/pull/144 
&gt; I don't really care for Eql as a name IIRC, it's because Cats already uses Eq, which is kind of tail wags the dog -- there will be many changes in Dotty, shouldn't the clean slate prioritize language over library in this case?
I can see valid arguments for not wanting to make migration life harder for users of a high profile library. It's just that "Eql" feels weirdly terse to me. "Eq" I get because it's common even in other non-programming domains. I think in the end there would be little confusion between Cats and the standard library, but if you can't have that or don't want that then two or three more letters to have "Equal" or "Equals" feels like a really small thing for something more natural to read and recall..
In my experience the main difference has been: * Do a Scala job and you may be doing Play, Akka, or a functional stack. * Do Kotlin and you will work with older developers and use Spring, Jackson, aka the Java stack. The other developers will fight tooth and nail to stop you from using Arrow or anything "fancy". (I am sure the Android world is different)
Cool. Thanks!
Where's the neuroscience? t. someone who actually uses scala for neuroscience
You'd probably get something that works if you learn some Python and use it with the scrapy library. Scala, although in many ways superb to Python, might be an overkill. Especially if you're not experienced in programming. Someone could probably write such a program for you, but the truth is that many of us already do a lot of coding at work and we're not necessarily eager to spend their free time doing that for free, especially if it's a relatively boring project (although I'm not saying this one is).
[https://neuvoo.ch/salary/?job=Scala%20Developer](https://neuvoo.ch/salary/?job=Scala%20Developer). 1 BR is around or above 3000 F a month there.
Thanks for you help. I will check it out.
After giving it a closer look: I'm novice in ScalaFX/JavaFX world. How would I do what you told me to do? Do I create Buttons which I make into something called Links to which I add plain text after which I add this whole thing into TextFlow? Does this create new window menu which has clickable help texts?
By "link" i mean [Hyperlink](https://docs.oracle.com/javase/8/javafx/api/javafx/scene/control/Hyperlink.html) control which is essentially text with button functionality. So what you need to do is to split your text into parts representing plain text and links, wrap former in [Text](https://docs.oracle.com/javase/8/javafx/api/javafx/scene/text/Text.html) and later in Hyperlink (with action being changing the content to whatever you need) and then insert them as children of TextFlow. JavaFX is not dissimilar to HTML model, if you're familiar with it
Run scalafmt outside of your editor. Works great! [https://scalameta.org/scalafmt/](https://scalameta.org/scalafmt/) On my team we run it through an sbt plugin, but there might be other ways to invoke it.
I've just realised I can use this with gradle (my project build tool). 
I've done a *lot* of this work at my actual job, and as much as I hate to say it, you want to use Python. The other guy mentioned Scrapy, but also look at regular selenium and beautifulsoup and requests. You also might want to look into some of the browsers for js like headless firefox/chrome depending on use case. You might also find CasperJS useful. I'm not interested in side work or doing this any more than I have to these days, but honestly, you can learn Python yourself and do it. 
It shares the same problems that every other framework like that has though: As soon as you do something that the framework does not account for, you are screwd. When MacWire was made, Final Tagless did not exist, so they didn't (and couldn't) account for it. Now with distage it is the same. It might work with Final Tagless, but what if there will be a different way to do it next year? Using a framework might still be a good decision, but it really depends on the specific case.
have considered using metals? I believe latest version has scalafmt built in it. &amp;#x200B; I am a neovim user and I can't recommend using metals enough: &amp;#x200B; [https://scalameta.org/metals/](https://scalameta.org/metals/) &amp;#x200B;
Thank you
Awesome! The only thing left for full development speed is semantic-ui components. 
I didn't know about Lichess. Thanks for the link. I'll check on it later. Nostalgia's engine is also free of side effects.
I'm glad you liked it so far.
Hmm.. What's wrong with \`class Main\[F\[\_\]: Monad\](console: Console\[F\]) { def run(): F\[String\] }\`? Why \`object Main { def run\[F\[\_\]: Monad: Console\](): F\[String\] }\` is over it. can we use \`class Main\[F\[\_\]: Monad\]( implicit console: Console\[F\]) { def run(): F\[String\] }\`
We now have an instance type, say, `Binding`, and a type class, say `Bindable`. The naming is horrible, unfortunately. Ideally we should name an instance type as an adjective (e.g. `Observable`, `Comparable`), and a type class as a noun or a gerund (e.g. `Ordering`, `Comparator`). I hope we can have a chance to swap their names.
This is a joke post btw (the news is true). A tongue-in-cheek-totally-not-true comment that came to my mind- this is what happens when you work with slow-as-molasses-sbt
Same here, big fan of tagless-final. Initially I used it a lot but stack-safety was getting tricky and Free was increasing extra objects being created and adding to GC workload. Performance is priority. &gt; stay unopinionated and don't over commit to any external dependency This is good advice. May be just having a simple stream implementation (`db.stream`) which provides async iteration API (similar to existing blocking `Iteration[T]` API) would be simple and easy to work with in Scala and Java.
That's great! Thanks for letting me know.
Have you heard of Mill? I like it a lot as it builds on concepts that are already familiar to all programmers (Scala objects as modules). And it is pretty fast too. We use it in the team for new projects (although SbtModule allows the old maven layout). 
Neat
Mill creator uses Bazel so that kind-of keeps my confidence down. Also, lihaoyi is prolific but sometimes he abandons his projects and you are left hanging. I mean the guy is genius but ultimately his tools are for his own use.
Do you have a link to the announcement?
No, Z√ºrich isn't that expensive.
https://www.reddit.com/r/rust/comments/aytalh/tools_team_changes/ei51vb9/?context=3
Does this mean that Dale has left LightBend and is full time on Rust tooling, or is this in addition to his work on SBT, like maybe in a side project capacity?
That's great! However, there are more reasons to prefer distage: 1. Debugability. All operations are pre-computed in a separate step. Any errors in wiring are reported _before_ startup is even attempted and a list of operations is a first-class value available for [rendering as a graph](https://camo.githubusercontent.com/0c617fc98f2a12d3570561f0d74f02d307519b1b/68747470733a2f2f692e696d6775722e636f6d2f734163345765392e706e67), [printing all steps](https://izumi.7mind.io/latest/release/doc/distage/index.html#debugging-introspection-diagnostics-and-hooks), [compile-time checks](https://izumi.7mind.io/latest/release/doc/distage/index.html#compile-time-checks), [rewriting to create extensions](https://izumi.7mind.io/latest/release/doc/distage/index.html#config-files), etc. distage does not rely on laziness to define order, so your startup can't hang and the order is always exactly as written. 2. Low compile times. distage is primarily runtime, not compile time, which addresses the most common pain point I've heard about MacWire. This does not mean its unprincipled or unpredictable though due to the point above (besides, there are optional compile-time checks too). 3. Garbage collection. In tests you can create only the components required for the fixture and nothing more. `lazy val`'s in MacWire let you do the same of course, but they're ad-hoc and undebugable - distage GC does not rely on laziness - as always you get full information on what happened, which components were collected, which retained and the final operations list after the transformations. 4. Lifecycle management. Global state &amp; lifecycle is an unfortunate fact of life, but it's required in nearly every non-trivial application ‚Äì if you don't carry global state, usually you'd at the very least have to connect to external global mutable state. `distage` supports this natively so that modules with integrations with external state can be shared between projects without rewriting connector logic in every project's `main` from scratch. 5. (upcoming @ ScalaUA conference) Monadic &amp; Resource bindings - these let you wire an `X` from a monadic action `F[X]`, or integrate cats-effect's `Resource`'s into the global lifecycle e.g. start/stop an http4s server, execute doobie DDLs on startup without `unsafeRunSync`, create mutable state with `Ref`s for in-memory repositories, etc. MacWire will never be able to do this without a major redesign since that would require generating a `for` comprehension and nested brackets. 
Nope, still at Lightbend. I've just been observing and contributing to the Rust community, focusing on the tools because I enjoy working on them. So I started learning Rust and using cargo as the codebase to hack on. Recently also been look at the rustup codebase. My experiences as a maintainer brought value to the coordination side of things, so I was invited to join the Cargo and Rustup Teams and then, as of that post, to "Core Tools Team" which is for cross-team/WG coordination (we've yet to actually meet). It's been very insightful to me and I've been cross-pollinating both ways based on my experiences and observations. I'm wondering if the topic has enough content and if it's of general enough interest to be able to make it into a talk for Scala World this year... We'll see.
That's true, but how likely is that you'd rewrite a mature project into some other new fad paradigm once it's settled? Also, MacWire makes it easy to jump off ‚Äì just dump the generated code and remove the dependency completely. `distage` doesn't currently do that, but it's on the [roadmap](https://github.com/pshirshov/izumi-r2/issues/453). Besides, `distage` makes it _possible_, not necessarily easy to adapt to new fads, since you get a first-class `Plan` you can interpret. In theory, you could write an interpreter that instead of passing parameters, would join up the dependencies into a cake for ZIO Environment, for example. Though I would instead recommend [cakeless](https://github.com/itkpi/cakeless) project for composing cakes for ZIO, tbh.
In the spirit of sbt-extras, I've written an "scalafmt-extras" script: https://github.com/dwijnand/scalafmt-extras/blob/master/scalafmt It was mostly for the small hiatus when Scalafmt 2 didn't have sbt support (I was eager to use Scalafmt 2 and configure CI for it) but that's now resolved: as of v2.0.0-RC5 Scalafmt has sbt support again.
I bought the book on pragprog and I find myself asking often if I am programming in c or scala when working on the example code. I sort of question why I would use scala at all if I'm using strlen et al. Hopefully over the course of reading the book this will be clearer.
&gt;That's true, but how likely is that you'd rewrite a mature project into some other new fad paradigm once it's settled? Actually pretty likely (I did that in a 2 years old project), especially with lightweight approaches like final tagless. You don't have to convert all your to use FT at once. It can be gradually adopted. &amp;#x200B; &gt;Besides, distage makes it *possible*, not necessarily easy to adapt to new fads, since you get a first-class Plan you can interpret. That's cool. However, in my experience (which can't be generalized of course) I have never seen a project where using a dependecy injection framework paid off in comparison to simple constructor injection in the end. And I have worked in medium size codebases, not only microservices or alike. Maybe it pays off for really big code bases, but I am yet to experience that.
Well, the projects I've worked on would be impossible or unnecessarily hard without DI, due to: 1. On a previous project: Sheer size, 30k lines, 250+ modules. Current projects are multiple smaller services up to 10k loc each, but they share a sizeable amount of common integrations through modules. 2. The paradigm of integration testing with real and dummy implementations both. If you don't do integration testing at all (logic only) or settle on just real or mock implementations only, I can see how explicit construction can work, otherwise you'd have to rewire ad-hoc and would just implement a bespoke DI anyway.
Hi, a bit too late, I know :), but regarding not using `Id` to replace `IO` while testing, I've just seen this: https://mobile.twitter.com/jdegoes/status/1104767626063085569?s=09. I've also seen it here: https://gist.github.com/jdegoes/1b43f43e2d1e845201de853815ab3cb9.
&gt;otherwise you'd have to rewire ad-hoc and would just implement a bespoke DI anyway. Don't get me wrong, I'm not against DI. I am just not convinced that using a framework gives more benefits than it takes. Because, while using constructor injection (you call it ad-hoc rewiring) might involve more code because dependencies have to be passed all the way down, ... * everyone can easily understand it (because they know how constructors work) * Compiletime safety is retained * Normal language features can be used, no language extensions needed The last point means, that if I have a dependency graph and I want to swap out one of the depedencies for a specific integration test, I can use a ¬¥myService.copy(subServiceA = TestSubServiceA(...))¬¥. If I want to change something down in the leafes, I can use general techniques like lenses. &amp;#x200B; I doubt that using a specialised framework is worth the cost. Especially that there are so many outside and I always have to learn a new one. Losing compiletime safety is another dealbreaker for me personally (however I didn't read about your frameworks' compiletime checks in detail, so maybe it might not be an issue). &amp;#x200B; My conclusion says the same: it might make sense for really big projects, otherwise I don't think it will have net benefits over the whole project lifetime.
Thanks Kudah. I gave DIStage a go and thought it was quite a well thought out framework. I ended up going with Macwire as I wanted to avoid the overhead of runtime reflection during bootup, as well as being able to compile to Scala.js and Graal native-image without issue. If I didn't have those constraints, I'd have likely gone with DIStage. 
I still haven‚Äôt been able to update my app to Scala 2.12 because not all of the libraries I use have been updated. I‚Äôm starting to think they‚Äôve been abandoned which I feel like I‚Äôm seeing happen more often now. 
I've played around with a few personal projects and been pretty happy with it, but I would strongly advise against using it in production just yet. It's been fairly stable, but as the language is still evolving there's likely to be further breaking changes before we see a 1.0. I believe they are aiming for backwards compatibility with 2.12 binaries to avoid repeating Python's mistakes with 3.0 (Which is to say, libraries compiled for 2.12 should work correctly in 3.0, but not the other way around). 
I‚Äôve used Promises when I wanted to use the result of some other async container type as a Scala Future. You create a Promise, add callbacks on the original to set the value or error on the Promise, and then you get a future with the .future method. You could think of the Promise as a setter, and its Future as the getter.
A Promise is a way of creating a Future. Typically, a function or class will expose a Future to calling code, and that Future represents the outcome of some process. You'll use far more Futures than you will Promises, because most async APIs return Futures. The only time you really use Promises is when you need to turn a callback-style API into a Future-style API. &amp;#x200B; Confusingly, if you're used to JavaScript, Scala's Future is the same as JavaScript's Promise, and Scala's Promise is the same as what's often called Deferred in JavaScript.
No, If you run into obstacle using Future, look into \`Monix\` and you could just look it as Future2.0.
Hmm.. What‚Äôs wrong with \`class Main\[F\[\_\]: Monad\](console: Console\[F\]) { def run(): F\[String\] }\`? It is work as you said ‚Äî ‚ÄúEffect tracking is about making dependencies ***explicit***to the use sites‚Äù. Why \`object Main { def run\[F\[\_\]: Monad: Console\](): F\[String\] }\` is over it.
Out of curiosity, what libraries are those?
Put simply, a Promise represents the write-side of a Future (or, conversely, a Future represents the read-side of a Promise). Promises become necessary when you want to return asynchronously but may not yet have a Future to map over. In the following example a Promise is used as a bridge to "reify" an asynchronous event into a Future. class GUIComponent { private val onClosePromise = Promise[Event]() def onClose: Future[Event] = onClosePromise.future def closeButtonClicked(e: Event): Unit = onClosePromise.success(e) }
Yeah, I don't intend to use it for anything mission critical, but only for experiments and things that I know will be thrown away in the end anyway. &amp;#x200B; AFAIK, the backward compatibility goes both ways. If the idea is to keep TASTY stable and compile them both down to it, then shouldn't 3.0 code also work with 2.12?
I agree with what he is saying there, but I don‚Äôt think he put it in an understandable way. If you can use Id for your F, then do it, it makes your test much more readable, and if there is a motive to test it with something more powerful, then something is wrong with your abstraction, as the whole point of polymorphism is that you can replace your implementation with something of the same shape. Now, in practice, more often than not, you‚Äôll have to constrain your F to at least Sync, at which point you stop being able to use Id during the test. I think John‚Äôs point here is that if you‚Äôre not doing this then you‚Äôre not using your F ‚Äòs capability of handling side effects in a pure way.
migrating our apps to scala 2.12 was a no brainer for us. What is missing ?
Spark is the biggest one for me. Even though there are experimental releases, I don't want to take any chances.
Spark 2.4 is on 2.12 already (spark-testing-base is still not but should be in a few weeks I think)
All our learning content it open to public access, so I am not sur what article you're referng to?
The platform basically enables people to progress faster by accessing undocumented human intelligence and at the same time enabling real-time access to people, skills, knowledge, and solutions within corporations, communities, and the world at large. So tracking people' behaviours, their psychology and why they act/work/navigate how they do in a work environment...I presume is the neuro-aspect!
I think I'm having a stroke
Also, the latest Dotty 0.13.0-RC1 was released with Spark support: https://dotty.epfl.ch/blog/2019/03/05/13th-dotty-milestone-release.html
TASTY support isn‚Äôt coming until 2.14, I believe, but otherwise that‚Äôs my understanding of the plan. 
When I click on the above link. it shows me the partial job ad. next when I click on show more it asks me to login or create account.
Oh I see, when you said article I was a little confused as we have a public content section too. You're not the first person to mention the 'creation of an account' to view a full job description in a negative light tbh, however the clients and partners we collaborate with use our platform because it's a cultivated community we've nutured. If we allow everyone and anyone to just apply to roles/have company access without some sort of background or information there, then it would make us a little redundant and defeat the object of being able to advertise your roles to our pretty awesome and niche community. We are working on making this more transparent though, as we are aware not everyone likes to 'create an account' on a platform, this is why we have github integration too, so if you have sourced repos on git you can sidestep quite a bit of the sign-up flow but as with most platforms...there is always some sort of 'sign up' or 'adding of details'. &amp;#x200B; Feedback has been noted though :)
As it was mentioned before, Spark is the biggest issue, but now that 2.4 is compliant there's a way forward. unfortunately, upgrading entire spark clusters is not a trivial matter, so people are still behind because of this.
So if you're using Reactive Streams or a callback API, a promise is how you can represent that callback as a future: class Foo { private val promise: Promise[Hello] = Promise() def setHello(hello: Hello) = { promise.success(hello) } def helloFuture: Future[Hello] = promise.future } val foo = new Foo() // add foo to timer task and call foo.setHello(hello) at some later time // and the future will complete val future = foo.helloFuture
Thanks for the feedback! I understand the limitations and we've actually hit them too. Fully compile-time interpreter will happen sometime soon-ish because we need it to use distage in the [IdeaLingua](https://izumi.7mind.io/latest/release/doc/idealingua/index.html) compiler which targets Scala.js too.
Sorry for my impoliteness, but why should I care?
Ok, didn't knew. Good luck with spark then.
Have you used the  ºIor º data type from Cats and for which use case? 
If you're already familiar‚Äîand working‚Äîwith [Akka Streams](https://doc.akka.io/docs/akka/current/stream/), I'd recommend [Alpakka's S3 connector](https://doc.akka.io/docs/alpakka/current/s3.html).
That's true of any single-maintainer project. That's why a project needs enthusiasm and momentum so a community can be built around it and multiple people can maintain it. Don't forget the original author of sbt is long gone. It has changed maintainers several times. Also, Mill makes use of almost all his other projects (at least transitively) so they're maintained too. It's true upickle languished for a while but that's not been the case for a while... if that's what you were referring to. Anyway just because he's employed at a large company and that company uses Bazel... that's a pretty silly argument. Actually Bazel inspired certain aspects of Mill (see the docs). 
If you're already using Akka streams, Alpakka has an [S3 connector](https://doc.akka.io/docs/alpakka/current/s3.html). Otherwise I imagine that wrapping the official Java client in your favorite asynchronous effect type might the way to go. A quick google search brings several results that use fs2 and Cats IO.
Having tried many of them, I recommend you stay away from existing scala libraries and just wrap around the official Java library. 
I've used [awscala](https://github.com/seratch/AWScala) and found it serviceable. It mostly gives the Java client a more Scala-like interface.
&gt; You create a Promise, add callbacks on the original to set the value or error on the Promise I generally don't see this in practice. Can this be thought of as similar to composing Futures? &gt; Promise as a setter, and its Future as the getter This is a very nice analogy! That really helped to explain the difference for me. Rephrasing again to look at it from a different angle, a Future is generally the end result of a Promise and how the outcome of a Promise is accessed! 
&gt; callback-style API into a Future-style API I don't think I've seen a callback-style API before. So there are APIs that expose functions that return Promises? Is the benefit of that to save on threads by compose Promises together then use only 1 Future in the end to encompass all that logic?
Thanks! I'm probably just going to use the official java library. I'd like to use Alpakka but we're using an ancient version of Akka so I'm a little scared of doing that.
I've used it with the MTL typeclass [MonadChronicle](https://typelevel.org/cats-mtl/mtl-classes/monadchronicle.html) which allows to both accumulate values and also short-circuit computations with a final output. That's a very good use-case.
Version 2.0 of the official sdk from amazon uses non-blocking IO, so there's less of a reason now to use anything else. &amp;#x200B; [https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/s3-examples.html](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/s3-examples.html) [https://github.com/aws/aws-sdk-java-v2](https://github.com/aws/aws-sdk-java-v2) &amp;#x200B; &amp;#x200B;
I think your description of this video is misleading. It is not a "simple introduction to category theory". The video doesn't cover any significant parts of category theory at all. It doesn't even explain well, what is a morphism. Hence, it is not an introduction. At least, not to category theory. The presenter has spent barely 5 minutes covering category theory and the rest of the time was allocated towards discussing hot news and political views.
the lack of macros hampers it way too much for me, bah, not the actual lack of them, but the fact that the libraries I use haven't upgraded to use the metaprogramming facilities that dotty has.
I meant in the sense that he has no incentive to work on mill since he's already being paid to work on bazel. I do not mean to denigrate his efforts- I use his amazing stuff everyday (for free) but there are places where I don't want to invest in using his products because I have been bitten in the past. 
I wish the talk/production quality of the Seattle edition lambda world was on this level...I guess we get the test run. thanks for sharing!
He's not "being passed to work on Bazel." He's an employee of databricks. If he liked Bazel more than Mill he wouldn't have written it. I hear one of Lightbend's top SBT devs contributes to Rust tooling. And it's not a bad thing. It's not a zero sum game. In fact as he pointed out, cross-pollination occurs, which is of mutual benefit. So I'm not going to worry just because someone contributes to two "competing" projects, regardless of which one may be their day job. Now, what you can do is try to read the tea leaves about whether they will abandon one or the other in the future. But personally I'm not a big believer in anyone's knowledge of astrology... üòÅ
Agreed. They generally don't offer enough to be worth it. If you use the Java client you always have the latest and greatest and you only have to learn one library, whereas if you use a wrapper you are probably going to have to understand the wrapper and parts of the underlying aws sdk at some point.
I would probably look for something in the fs2 ecosystem. I remember seeing sample code on how to upload a file for example.
nice I am into this!
Try to use tsec lib for http4s. It supports many types of authentication including jwt tokens and the documentation is pretty good 
Well it generates enough curiosity into the subject, think that's more than enough.
I haven't watched it yet but I'm guessing orange man bad?
I think it can be useful in big monorepos 
wow, the dislike:like is very high \~ 1/5
Yes!üòÇ Please try if you are fed up with.
It is still incomplete.
Hi, I can try to explain for you. Normally in unauthenticated http4s you define your routes as function from Request to Response wrapped in IO. This looks a bit like ``` val service: HttpRoutes[IO] = HttpRoutes.of[IO] { case GET -&gt; Root / "someroute" =&gt; Ok("bla") ``` These are put in a Kleisli which helps the library put them all together. You dont need to know much about that though. To have authenticated routes needs some way of authenticating, maybe http basic auth or some magic header cookie. Then you can define our routes as a function which takes the Request and a user/session and returns a response. This is where AuthedService comes in. ``` val service: AuthedService[Session, IO] = AuthedService[Session, IO] { case GET -&gt; Root / "someroute" as session =&gt; // do something safe trusting the session Ok("bla") ``` Now we need a way to take a raw request and pull out the session. For this we need a function to get the session from the request (which may fail), and put that in a middleware. ``` def findSessionFromAuth(headerValue: String): IO[Option[Session]] = ??? val authUser: Kleisli[IO, Request[IO], Either[String, Session]] = Kleisli({ request =&gt; request.headers .get(headers.Authorization) match { case Some(authHeader) =&gt; findSessionFromAuth(authHeader.value) .map(_.toRight("unable to find session")) case None =&gt; IO.pure(Left("unable to find session")) } }) val middleware: AuthMiddleware[IO, Session] = AuthMiddleware.defaultAuthFailure(authUser) ``` Now that we have our middleware we can wrap that around our service and run it. ``` val authedRoutes = middleware(service) val builder = BlazeServerBuilder[IO] .bindHttp(8080, "localhost") .withHttpApp(authedRoutes.orNotFound) ``` Hopefully that helps show how you use authentication in http4s. Let us know if that helps or what type of authentication you want. :) 
`val service: AuthedService[Session, IO] = AuthedService[Session, IO] { case GET -&gt; Root / "someroute" as session =&gt; // do something safe trusting the session Ok("bla")` I don't really understand what the Session is? And I am currently looking for basic Auth.
Not to be combative, but the parent poster mentioned that he *has* previously abandoned projects (no concrete examples, but IIRC upickle was abandoned for quite a while), so it's hardly fair to call this astrology... It's based on actual evidence.
Session is your own type, you get to make it. It can be whatever you want. And you can authenticate different routes different ways if you want.
Evidence of what? That there are not in fact 3 Haoyi Lis for that he isn't superhuman? So again: Does having a different project at work threaten about your commitment to a side project? No. Should we assume that because in the past some of the many libraries that he wrote weren't maintained for a while, that he will abandon Mill one day? No, one does not follow from the other. That said, of course there isn't anything close to a guarantee. In software there never is. The best we can do is either never take risks, or generate enthusiasm and try to help build a community around it, so that there will be more maintainers.
Evidence that he sometimes abandons projects.
So for testing purposes can I make he session type a string?
Yea for sure, or a case class.
Yes but that isn't the question.
Callback-style APIs take callback functions as arguments which say ‚Äòwhat to do next‚Äô, that‚Äôs how they achieve sequencing. And so on ad infinitum. There are no Futures or Promises involved. It‚Äôs basically continuation-passing style.
I'm working on extending this example (https://github.com/pauljamescleary/scala-pet-store) to include authentication via tsec at this very moment. But I'm running into many of the same issues as you, though mostly on the tsec side. I'm hoping to have something that "works" later today. PM me and I'll send you the link.
Yeah I was looking through that example and was sad that there wasn't any auth in it. Cool I p'md you now
The tsec docs regarding actual integration and practical use-cases with http4s are effectively non-existent. For example, how do I write a simple "sign-in" endpoint? Try as I might I can find a single example of this. 
Your question prompted me to check again, and it‚Äôs not as bad as it used to be. Still some road blocks, though. These libraries changed names due to significant updates (so difficult to update but not impossible): akka-http-core-experimental scala-logging-slf4j diffson And this library seems to have been completely abandoned: com.josephpconley:play-jsonpath_2.11 And there were 11 other library updates that could have potentially new/updated APIs, but that‚Äôs just regular updating. I probably need to find a replacement JSONPath library.
I've even used a `sealed trait` in the past to represent different behaviors of the same routes depending on the authentication state
Http4s and tsec aren't enough alone though, OP should be thinking about larger design decisions. The last time I wrote this, I took in a case class of user creation parameters from the API edge auth endpoint, created a salt+hash and put them in my db in a login table. Websec is hard so look into OSINT for their best practices suggestions. I responded with a 303 and a `Set-Cookie` header, whose value was the sessionId that I could retrieve from the table. You may want to use a JWT or some other mechanism - depends on your needs. Now the user is logged in my `getUser` function just took the cookie from the request object and tried to find the value in the db. For me, I wanted routes with different behaviors whether the user was logged in or not so my `User` type was actually a `sealed trait Session` with `case class AuthedUser(userId: String) extends Session` and `case object Unauthed extends Session`. Now I can pull the user out using `as user` and pattern matching over it. Much of this isn't http4s specific, but if you've never built one before there's a lot to take in. Hope this helps someone.
We're using AWS ask V2 and convert the completable futures to IO. From there on everything is cool.
Try increasing stack size for your compilation jvm. Scala sometimes require big stack size to compile code that is using macros, etc.
I would be interested in attending this talk, Dale. Keep up the good work and hope learn something about how the Rust people are doing tooling and how their approach compares to ours.
Wanted to follow up. I have a mostly working, though likely flawed example, here: https://github.com/littlenag/scala-pet-store. It is based on https://github.com/pauljamescleary/scala-pet-store and adds a ScalaJS+React+Bootstrap+webpack front end. I will be polishing this example with the intent to have it merged back upstream. I'm happy to accept contributions and advice on best practices.
* basics: traits, case classes, sealed traits and how they differ * Pattern matching (match expression) * Map, filter, maybe fold * Type parameters/generics - what they mean eg in collections * Implicits - really basic - what's their purpose. On your first day I'd hand you the "Scala Programming Language" book and ask you to read it. If you already had by the interview I'd be really impressed. Good luck!
Thanks for getting back to me, really appreciate it! I‚Äôm going to do my damnedest to put a dent in that book by Friday...
Thanks for getting back to me, really appreciate it! I‚Äôm going to do my damnedest to put a dent in
When I interview juniors I basically don't care about their existing knowledge of the language, especially if they know another language. By that I mean I might ask some questions to see how much the know, and count that as a benefit, but if they don't know much I do not count that as a negative. Juniors are expected to be learning. I'd care more about their ability to discuss any projects they've actually done, and be able to make progress on some coding question. I wouldn't even care if they completed the question correctly so long as they were able talk about why they were attempting what they were and showed some ability to incorporate any feedback I gave to make a little bit more progress. If I had to pick a minimum bar for a junior who only knew Scala, it would probably be knowing what you can and cannot do with Scala's most common aspects: traits, case classes, pattern matching, for expressions, Option/List/Map/Set (maybe Future), map + lambdas, and core concepts like inheritance and expressions. You'd get bonus points if you can discuss why you'd choose any one option over another, and bonus points if you can discuss implementation details about how those things work.
I find implicits are a tall ask for juniors. They have so many use cases and there isn't much of a parallel in other languages so they tend to be seen as scary magic. Just knowing that if something is implicit means you don't have to pass it explicitly at the call site would be enough for me, even if they didn't know about implicit scope and its associated rules.
Sorry, could I ask for a link to, or the authors name, of the "scala programming language" book?
I have a little bit of experience with implicits, so hopefully that'll be enough...
Thanks for the advice, it's really useful, I appreciate it
Everything recommended here is good. I‚Äôd also add monads as a concept, especially Option‚Äôs, Futures and their use in for comprehensions. And advantages of being pushed to immutability when developing in Scala (as opposed to more imperative, stateful Java)
Tried that. still throwing that error when I try to run: package in the sbt shell. This is my first time programming in scala and I'm not gonna lie, all the problems I'm running into with such a basic script is EXTREMELY discouraging. I *really* wanted to dive into scala/spark but this is a bit much. 
Hey there, I think the issue is that you have so many method calls in one expression (`... :: ... :: ... 70 fields later... :: Nil`). However, if you simply instantiate the sequence with `List(...)` or `Seq(...)` then the compiler won't have an issue with it. For example: object cosSchema { val schema: StructType = StructType(List( StructField("UserId", IntegerType, nullable = true), StructField("UserId", IntegerType, nullable = true), StructField("UserId", IntegerType, nullable = true), StructField("UserId", IntegerType, nullable = true), StructField("UserId", IntegerType, nullable = true)) ) } 
Try to specify your fields as a List(field1,...,fieldN) instead of using :: cons method. Take a look at this StackOverflow question: https://stackoverflow.com/questions/35596697/spark-sql-table-max-column-count 
Ahh this looks very promising! Thank you so much!! 
One example use case would be to model an outer join, for example `def outerJoin[K, V1, V2](left: Map[K, V1], right: Map[K, V2]): Map[K, V1 Ior V2]`
https://www.artima.com/shop/programming_in_scala_3ed
Can you elaborate more on how you implemented that authencation. And what other libraries did you use ? 
Is there some trick that would allow defining a type like that? type Rec[I, O] = I =&gt; (O, Rec[I, O]) The compiler chokes on that with "illegal cyclic reference involving type Rec" I know i can make it into a trait like trait Rec[I, O] { def apply(v: I): (O, Rec[I, O]) } But is there a way to represent it as a type?
I find it very troubling that an _object_ method (and an explicitly-`final` one to boot!) generates a call to `invokevirtual`. Why on earth would that be? Thankfully in Dotty we'll get `inline` methods with guaranteed inlining, for whenever we want to make sure trivial forwarders of this kind are consistently removed.
This worked! I really appreciate your help on this. 
It has it in the function signature but it never actually uses it If you check the implementation, it creates a new promise and just completes it with the value that you are transforming.
Sorry for the late response, was a bit busy 1. Regarding point 1, I think the best course of action, if indeed a driver was to work around Future perf problems would have to be to open an Issue and start collaborating in fixing it. :) I'm glad to see perf in 2.13 having become as good as it has and I see little-to-no opportunity for further optimizations at this point in time. I already suggested such changes and possible collaboration around a year ago, however someone else mentioned that the change would be too breaking (this was on Scala contributors) &gt; Regarding point 2, I answered that in my reply above: I think we are going around in circles here. I don't disagree with the statement, I just think that this case is an exception but I guess we can agree to disagree.
No problem!
Great read and never thought of using Colab with Scala. I need to look into Almond more. Is there any reason to use scalapy-tensorflow instead of these bindings: [https://github.com/eaplatanios/tensorflow\_scala](https://github.com/eaplatanios/tensorflow_scala) ? &amp;#x200B;
\`@inline\` itself does nothing. You should try turning on the optimizer ([https://developer.lightbend.com/blog/2018-11-01-the-scala-2.12-2.13-inliner-and-optimizer/index.html](https://developer.lightbend.com/blog/2018-11-01-the-scala-2.12-2.13-inliner-and-optimizer/index.html)), even without using \`@inline\`.
That's a really good question! The main advantage is that ScalaPy-based bindings are effectively "always up to date" because all the API calls just go directly to the Python library. Especially if transitioning over Python devs who are comfortable with the libraries in that ecosystem, this can make the migration a bit more smooth since the exact same APIs will be available in Scala. tensorflow_scala is a really awesome library. I would probably use that for evaluating models where the Scala code takes up a significant amount of the total computation. I've modeled a lot of the static types in scalapy-tensorflow on it!
This reminds me of the pattern for specifying the unboxed fixed point type. It requires an indirection through abstract types but it might work for you. package object rec { val Rec: RecModule = RecImpl type Rec[I, O] = I =&gt; (O, Rec.Recur[I, O]) } trait RecModule { type Recur[I, O] def apply[I, O](r: rec.Rec[I, O]): Recur[I, O] def unrecur[I, O](r: Recur[I, O]): rec.Rec[I, O] } object RecImpl extends RecModule { override type Recur[I, O] = rec.Rec[I, O] override def apply[I, O](r: rec.Rec[I, O]): Recur[I, O] = r override def unrecur[I, O](r: Recur[I, O]): rec.Rec[I, O] = r } You then use `apply` and `unrecur` whenever you need to convert between the full or the abstract type, but the types are the same and these are just identity methods. I don't really like the module/impl terminology here but it's the same as what the example I saw did and I don't have anything better.
&gt; I find it very troubling that an object method (and an explicitly-final one to boot!) generates a call to invokevirtual. Why on earth would that be? Uniformity. it doesn't matter one way or another anyway, HotSpot has no trouble devirtualizing calls when the receiver class is statically known. 
&gt; Why on earth would that be? I assume its related to objects being singleton instances in static fields. There's only one instance, but it's just another instance of a known type and so you get `invokevirtual`. I have always thought it would be nice to get static fields and methods where possible (which I suspect is anything defined directly and not coming from a super trait). But I can understand concerns around complexity and binary compatibility. I've also heard "the JIT deals with it just fine", but I find that to be a somewhat lazy response; to my mind the JIT shouldn't have to deal with it in the first place. That's an interesting edit about summoners. I'd never really considered returning the type like that. I like it.
I expect keeping the context bound and summoning only once in the implementation would be a happy medium both in terms of the benchmark and in terms of the implementation; you keep the implicit list out of the visible signature and eliminate a few calls to `apply`. def p1[F[_]: Applicative: Console]: F[Unit] = { val c = Console[F] c.putStrLn("a") *&gt; c.putStrLn("b") *&gt; c.putStrLn("c") } I'd expect the optimizer to be able to resolve repeated `Console[F].apply` calls to this after some inlining too.
I used the baked-in java libraries for crypto, doobie for the db connection, and circe for decoding json off the endpoint. Can you be a little more specific as to what you're looking for? I can't release that code if that's what you're asking.
Basically I‚Äôm looking for a well documented way to implement basic auth since I got everything else to work without a proper understanding of that intense category theory stuff. All the sources I have found are a bit dense. And I still lack a bit of understanding what a Kleisli type is which is why I‚Äôm struggling to follow most of the docs around auth. 
The "imp" summoner is interesting! Will look into this. Nice name too. ;)
&gt; it doesn't matter one way or another anyway, HotSpot has no trouble devirtualizing Well, according to the blog post even in a **microbenchmark** there is a non-negligible difference. Also, even if there was no difference on the steady-state running program after devirtualization (which doesn't seem to be true), I'd still find your argument very lousy. You're still asking for the JIT to do something at runtime that you could have done _completely trivially_ at compile time with no cost at all. As it is, there _is_ a cost, even if it's mostly a cost in terms of warmup. Why would you think it's a good idea, to add to the JIT's plate? Think about a real app, where there's thousands of object calls the JIT has to worry about devirtualizing, in addition to doing the "real" optimization work it's supposed to do... 
None of wh
I tried that too (need to update the blog post) after being suggested on [Twitter](https://twitter.com/kaidaxofficial/status/1105660445711585280). Here's the repo with the code: https://github.com/gvolpe/summoner-benchmarks The generated bytecode was still the same (no optimization whatsoever) but somehow the benchmarks were favorable so I would like to understand what's going on. 
That'd be great and doesn't sound too crazy to implement. If you look at the JVM bytecode the same happens for `*&gt;`, there's a call to `ApplyOps` every time it appears so that should be inlined too. 
Ok. Sorry, I was under the misconception that JVM bytecode had an instruction for statically dispatching calls to instance methods. Scala would have to insert static methods and forward to them in the object's instance methods, which would increase the size of class files. So it's not all black or white. 
&gt; and forward to them in the object's instance methods Assuming the static methods existed, why would forwarders also need to exist? I can imagine a world where the compiler resolved things correctly, e.g. `Object.method(param)` would invoke the static method if it existed or the instance method if that's what was available. Is it just for the case that the methods are defined in a supertype and so could be used in a non-static context?
Did you also include `-opt-inline-from:**` by chance?
Yes, I tried both `-opt:l:inline` and `-opt-inline-from:**` and the bytecode remained unchanged.
Hmm okay. Just to be clear, does "and" mean you tried both separately? Because they're supposed to be used together.
Oh are they? That's a good point, I tried them separately. Will give it a try using both (damn why is Scala so complicated? XD)
Just tried it out and effectively the bytecode has changed. It has now a bunch of new instructions and it's indeed longer. Running the benchmarks once again. Thanks for pointing that out!
I updated the blog post and source code accordingly. Thanks again!
A design question: Me and a coworker had a chat about some pains in testing Akka actors and he mentioned that there are better patterns to managing state than actors. While he didn't elaborate too much on that he basically said that actors are mainly (State, Msg) =&gt; Task(State) and that streams are the better option I agree that the actor is just it's receive fundtion and that's basically it's signature but it's a bit simplistic for me. Could you please show how I can get an actor-like functionality (meaning a single-thread mutates the state and what would hold the state if not inside an actor object) can be achieved in a more stream-style?
I doubt this makes a huge difference. Hotspot is already doing lots of optimizations when JIT-compiling and it's pretty trivial to know that a class has no subclasses. In fact it can do that for non-final classes that have no subclasses loaded yet, and de-optimize if this assumption is invalidate later on. I don't think the compiler should worry about this low-level optimizations and guess what the JVM would do. 
&gt; Is it just for the case that the methods are defined in a supertype and so could be used in a non-static context? Not only that, but there are probably people out there who access object methods reflectively (say, for dependency injection or some other obscure reason). I still think it would have been a good idea to mandate (before people start relying on the current encoding) that objects methods be implemented as static method, and only put forwarders only if necessary. But that is indeed more complex.
OP's name fit way too well for this sub \^\^
It is not exclusive. One can use both tools! ;) Each for its use case and different groups of people. Mill gets attention from him and community e.g. on gitter regularly. You are welcome to join and contribute too :) 
What kind of stream do you want? IME the nicest way is to use an iteratee library like FS2, and then you can use e.g. `Stream.scan` to turn an initial state and a stream of `Msg`s into a stream of resulting states. But at a basic level if all you want is a piece of state and a mutex protecting it then I find the best way to represent that is, well, a piece of state and a mutex protecting it. You can have a dedicated processing thread and a queue of commands if that's what you want (and at that point you essentially have an actor, though I'd still prefer to implement it by hand and avoid having to give up type safety), but IME that generally just moves the problem to what you do before putting things onto a queue (and even if using akka actors, you still have the problem of what to do when an actor's mailbox is growing too fast). That part is something that iteratees or other steram libraries can solve for you.
scala.rx
Yes, I'm aware of the benefits of (back-pressure) streams and such. I was just asking if there's an alternative representation to actors when you want that.. state and mutex. As for what kind of stream do I want? well, it's not really a question about what stream but how do I represent my problem space. For example if I'm building a bank I could represent each account as an actor, this way transactions will always be atomic on the account level (and with back-and-forth acks on money transactions between actors). What I guess I'm asking is is there a different way to represent the problem with streams? where would the mutexes be in such a scenario?
What is blog spam?
&gt; The first answer doesn‚Äôt seem that helpful It is the correct one, however, maybe if incomplete if the person who asked doesn't understand what a function is. And they often do not. &gt; t‚Äôs often rebated with the argument that in OO developers also program with functions That would be incorrect, Object oriented paradigm programs with objects. &gt; This meant that other classes depending on this data required the class to expose some of its internals, Why? This is just asserted without explaining how it's a result from the previous statement about encapsulation. &gt; Value Objects, are pure value representations without associated exposed behaviours. What's pure in this context? Purity has a meaning in functional programming. This sentence is also has several superfluous words, making it more difficult to understand than need be. It should be just "Value Objects are pure values without behaviours." &gt; In short, what I just described, is what FP is. No you didn't. &gt; Of course, there is a lot more to it, but in essence FP in OO terms is, dependency injection with segregated interfaces and data/behaviour separation. This is so off base it's not even wrong.
Going to try to reply to the points that are worth addressing &gt; It is the correct one, however Yes it is. It‚Äôs not claimed anywhere that it is wrong. It‚Äôs just unhelpful, and being arrogant about it doesn‚Äôt make it any less unhelpful. &gt; That would be incorrect, Object oriented paradigm programs with objects. Which are aggregation of properties and methods, so data and functions with a specific enlarged scope and a (sometimes) implicit instance parameter. &gt; Why? This is just asserted without explaining how it's a result from the previous statement about encapsulation The article tried to explain FP to OO developers, not explain OO to new developers. If someone doesn‚Äôt understand how exposing the data encapsulated in an object breaks encapsulation, and they‚Äôre interested in developing their OO skills, I recommend they look for resources in OO rather than at this blog post. &gt; What's pure in this context? Purity has a meaning in functional programming. Purity has a meaning as a property of functions. There‚Äôs no mention of functions in that context, so ‚Äúpure‚Äù in there stands for what it means in the English dictionary. For clarity, and stated in a different way ‚Äúpure value representations‚Äù can be worded as ‚Äúthey simply represent values and nothing else‚Äù. Describing VOs as pure value representations is very common when teaching the concept in OO. 
&gt; I was just asking if there's an alternative representation to actors when you want that.. state and mutex. I'm not aware of any library or framework but honestly I don't think the pattern is complex enough to warrant one? One just writes a class with some `private var`s and some `synchronized` blocks. Frankly my experience of actors is "there is no there there"; whenever I've seen them used in a codebase I've replaced them with plain code and never seemed to lose anything by doing so. &gt; What I guess I'm asking is is there a different way to represent the problem with streams? where would the mutexes be in such a scenario? IME you end up "pushing them to the edges", or ideally eliminating them entirely. Usually the reason you want a mutex is, broadly, to ensure that you process a bunch of commands one at a time, but by structuring your code as a stream transformation that happens inherently and naturally. E.g. for the bank account example you might write a stream transformation that turns a stream of transactions into a stream of account balances after those transactions; you don't have any state as such (the statefulness is all in the stream transformations) and you don't worry about mutexes, because the very nature of a stream transformation is that it processes messages one at a time. The only parts where you might fiddle with mutexes are turning incoming transactions into stream events and getting the final result in the form you want, and if you keep pushing those to the edges then all of your business logic can live in the nice stream-transformation world.
&gt; Which are aggregation of properties and methods, so data and functions with a specific enlarged scope and a (sometimes) implicit instance parameter. Methods are not functions. Methods are not procedures, even though is how Java and other popular OO programming languages encode methods. Methods are mechanisms for sending messages to objects. Objects contain state and the act upon messages. There is no concept of a function anywhere in object oriented programming. &gt; The article tried to explain FP to OO developers, not explain OO to new developers. If someone doesn‚Äôt understand how exposing the data encapsulated in an object breaks encapsulation, and they‚Äôre interested in developing their OO skills, I recommend they look for resources in OO rather than at this blog post. I'm fairly familiar with object oriented programming, yet I have no idea what you're talking about when you say including behaviour in a class breaks encapsulation. I however don't want to say you're wrong when an argument for it hasn't been put forward. &gt; Describing VOs as pure value representations is very common when teaching the concept in OO. What is a value representation? Why do you keep adding that word and what does it mean to you. That is not common terminology at all. 
*Ok, this is epic.* It's your **3rd Cakeday** tim-zh! ^(hug)
&gt;&gt; That would be incorrect, Object oriented paradigm programs with objects. &gt; Which are aggregation of properties and methods, so data and functions with a specific enlarged scope and a (sometimes) implicit instance parameter. OO largely doesn't use *functions*, but instead relies on *methods*. A function is a mapping of values in a domain to values in the codomain. For example, the function `head` maps the value `List(1,2,3)` to the value `1`. Methods, on the other hand, are a sequence of effectful statements you execute in order. It's not immediately obvious how to do anything useful with it, given that simple definition, but it does succinctly describe what the difference is. 
This description of methods is very biased against OO, methods don‚Äôt have anything inherently effectful about them nor are they sequences of statements, in fact frequently they contain one or more expressions. In Scala, it being an hybrid language what we use to create the behaviour of pure functions are methods. Your definition of function, is correct as defined in maths and FP, but not by the imperative definition where functions are what you describe as methods (except the part of them having to be effectful). Now the important thing here, is that this is an explanation for people who need to ask the question ‚Äúwhat is FP?‚Äù . These are not IMO non-developers, as for them there‚Äôs no previous bias that requires them to differentiate FP from other paradigms. The people usually asking these questions are imperative developers (mostly from OO). That is the reason the background presented is based on the imperative definition of functions. Hopefully I‚Äôll get around to a second and maybe third step where I plan on introducing the difference between functions and procedures (sequences of statements), purity, etc... Also, the definition of FP stated in there is very simplistic and incomplete, but I think it‚Äôs a good first step at explaining the most basic idea of ‚Äúprogramming with functions‚Äù, in a way that relates to concepts that are considered good practices in OO, without going into concepts that will not resonate with non-fp programmers (pure functions, total functions, partial application, currying, or even returning functions).
Don't do multithreading in static initializers (object constructors/bodies). It's a well-known deadlock \[bug\]([https://github.com/scala/scala-dev/issues/195](https://github.com/scala/scala-dev/issues/195)).
Perfect, thanks for your help. I wasn't aware of this :)
Thanks for making new users feel welcome with super constructive criticism. Fuck off.
Scala can be a good language for personal projects. In my opinion, the best language to model the data structure of an application, especially an API. The problem is that you can get lost with the big picture, especially when you find some conflict with the java libraries that you do not know how to solve. &amp;#x200B; With python, things may be easier for you; but soon you will start to miss the functional programming and the great type system that scala has. There is a lot of code done in python, but very little style and too difficult to maintain. &amp;#x200B; As an alternative, typescript is a programming language that combines a powerful type system as has scala with the ease of use offered by some IDEs and code generators. Even so, you can also find many conflicts between javascript modules that can ruin your work. &amp;#x200B; I think the way to fullstack is to combine the best of both worlds. For the frontend use typescript with angular or react, and on the backend use scala with play and akka.
My answer to the question "what is functional programming?" is "writing programs with **composable** functions." And I may follow that up with how you can create interesting abstractions through clever use of higher order functions, like: * a function that feeds the output of one functions to the input of many functions, or, * a function that composes several functions together in parallel and merges the outputs together using another function * a function that can compose several functions together, but rearrange the ordering of composition according to some logic (e.g. to minimize memory usage). * a function that not only composes functions together but also passes along a stateful value and provides you with a choice of whether or not you want to modify the state before outputting the value. I'd explain that this allows you to think of programs like electrical circuits, where you can think more about how to join components together and less about the individual electrons that will be flowing through the circuit.
If you think using Python is easier than using Scala, you are not alone. I think so too, in many cases. That's why I ported a bunch of the popular Python libraries to Scala so I can keep using them: - [Cask](https://github.com/lihaoyi/cask) instead of Flask - [uPickle/uJson](https://github.com/lihaoyi/upickle) rather than `pickle`/`json` - [Requests-Scala](https://github.com/lihaoyi/requests-scala) rather than Requests - [OS-Lib](https://github.com/lihaoyi/os-lib) rather than `os`, `shutil`, `subprocess - [PPrint](https://github.com/lihaoyi/pprint) rather than `pprint` It should be pretty easy to use these to set up a simple API server, with almost exactly the same syntax/semantics/simplicity as using Python, but with the advantage of the very fast performance and type-safety that Scala gives you. One hole that is missing is database connectors; I've heard good things about Quill, but I don't have a clone of SQLAlchemy (the de-facto standard in python) of my own right now to recommend right now. Perhaps someone will write one Scala definitely has a problem with overly complicated libraries making it overly difficult to do even simple things. This discrepancy doesn't need to exist: at it's core Scala looks a lot like Python, with objects, functions, and methods with default/named parameters. Things like SBT, `scala.sys.process`, akka-http-client, and others are very powerful but also much harder to get started with than they really need to be. I've spent a similar number of days totally befuddled with Play Framework's websocket API, back when I still used it and it was built around Iteratees. I have tried to correct that in my own libraries, which I use heavily in my own work, and would not want to write Scala without them. You should give them a try! 
That‚Äôs a really good explanation. I‚Äôm hoping to go into what make them composable in another post, so that I can dive into composition once the readers understand why some functions are composable and why some are not.
If you know Java, you can always write the things you would write in Java, in Scala. The way I learnt was to stay productive by only changing one thing at a time: I started out by writing Scala but in a very Java-like style, using all of the Java frameworks I was used to. It was only gradually that I started using Scala features (even very basic things like immutability or case classes, I didn't use at first) and Scala libraries (and I only changed one thing at a time there, e.g. maybe using a Scala web framework but still using Hibernate for the database part). Some people prefer to "jump in at the deep end", and there's always more to learn (I've been doing Scala for 10 years now and it's only in the past few months that I've got a really good handle on iteratees, for example), but IMO it's better to start from what you know and change a little at a time.
Martin Odersky's course on Coursera helped me. Also; learning Haskell sort of "refactored" my understanding of the subject :) [https://www.coursera.org/learn/progfun1](https://www.coursera.org/learn/progfun1) [https://www.futurelearn.com/courses/functional-programming-haskell](https://www.futurelearn.com/courses/functional-programming-haskell)
I have gone through Martin Odersky's course. That was my first scala lesson. 
This is missing the OO solutions to the expression problem, such as object algebras, but most importantly covariant overrides - in the ['Expression Problem, Trivially!'](https://i.cs.hku.hk/~bruno/papers/Modularity2016.pdf) covariant overrides alone are shown to be sufficient to solve the expression problem, even in languages with no generics.
Hi! I made my path from C# to scala several years ago, went into writing production scala code more than 3 years ago. That was my path: 2 coursera courses (the old ones, don't exist anymore, but you could find youtube videos from these courses) I started doing some pet project using play framework, and using scala just as "better java", and it was great fun, and I realized how convenient it is to be able to express all data structures as proper types When I started working as scala developer, I had almost no idea about advanced functional concepts, so I never used them. The company I worked for, at the same time, just started going into functional scala, which was a great co-grow of my and colleagues knowledge &amp;#x200B; Scala is actually pretty fine to write projects of any size. You do pay productivity cost initially, comparing to say, Ruby on Rails when you write first couple of pages of your app. But you get return on your investment later, by having no NullReferenceExceptions, "undefined is not a function", etc... &amp;#x200B; This was just a humble opinion :)
A miserable pile of closures.
This is the exact way I was able to hang on to Scala, I also tried it the language out on/off for about 2 years, building small pet projects. What forced it out really was when I tried to build a full blown project that interacts with DB. At first the build was a little horrible as it was more Java-like, I added Scala feels by continuous refactoring and looks like I am more comfortable with the language.
Thanks for sharing. I do follow you on twitter and believe it when I say I do check your blog from time to time for Scala inspiration. Thanks for writing and sharing your thoughts. 
I think this is the approach I am slowly using. I think I worry too much about being functional. :)
Constantly think "is there a way of writing this that is more functional than what I did previously"? The answer will almost always be yes. What would be really helpful is finding someone who does know all the fancy FP stuff but can explain it to you in an approachable, helpful way.
1- You might try learning a library like scalaz or cats that has "fancier" Haskell-like functional concepts, or maybe Akka. 2- The name "Scala" literally is supposed to mean it's scalable. The *intent* (maybe not always the reality) is that you can use it for anything from quick and dirty scripting to large distributed applications. It sounds like maybe your issues were more with MongoDB than with Scala, perhaps? Maybe there is a more self-contained project you can work on where you don't have to worry about database queries, I dunno.
Chill. Think of yourself as an apprentice learning a craft. In the past, this would take quite a few years, and IMO this is still the case now. Writing idiomatic code in any language takes a couple of years at a minimum. To say nothing of mastering OS/IDE/JVM/DB/REST etc etc. Scala has so many tools in the toolkit that uncertainty about which one to pick is guaranteed: there is "more than one way to do it". Keep watching the vids of the Scala conferences would be my suggestion for the moment: what appears obscure initially will over time gradually be absorbed.
As someone who loves scala, don't do it yo, just stick to stupid shit like python and js... I'm being serious dude, it's only heartache going forward
&gt;This description of methods is very biased against OO, methods don‚Äôt have anything inherently effectful about them But functions in FP are inherently "non-effectful" (or rather: pure). In OO the methods are sometimes pure, but often they are not - so you can't claim " are aggregation of properties and methods, so data and functions".
I‚Äôm the context of imperative programming functions are not inherently pure, OO is a subset of imperative programming. OO devs are very rarely even familiar with the notion of function purity, so I‚Äôm not even sure what the point of this discussion is.
&gt;I‚Äôm the context of imperative programming Well, your headline was "What is FP?". It is not surprising that many people will assume you use the FP definition for "function" and be confused if you claim that methods and functions are the same thing.
How is it a fair assumption that someone‚Äôs going to try to teach something to someone using the concepts they‚Äôre not familiar with rather than the ones they are? It‚Äôs literally in the first sentence that this assumes the question is asked by people with a background in other paradigms, as FP developers should know what it is, and non-developers will not have a comparison basis so for them FP is just programming as they‚Äôve always knew.
But you are not teaching *us* here. We do differentiate and you should have clarified that you use the terminology as OOP developers usually do. But instead of clarifying it in your answer(s) here, it made the impression that you are unfamiliar with it. Not explaining the difference between functions and methods in your blog post just adds to that assumption. I just want to explain to you why people here reacted like they did.
That wasn‚Äôt written to teach _you_, it was to help those who don‚Äôt know what FP is and are trying to understand it, and that‚Äôs why it doesn‚Äôt go deeper than it needs. It wasn‚Äôt written to show what I know, that‚Äôs wouldn‚Äôt be trying to help anyone, that would be masturbation.
I‚Äôve been using Obsidian Blade for a few months now, I find it quite nice: https://github.com/staslev/ObsidianBlade
really interesting. A bit thin on documentation, but great work overall!
Most sane companies don't tend to focus on language specific questions in interviews, instead they usually give a coding problem to solve and you write code using Scala to solve it. Obviously this requires knowledge of the language so you are using the right tools to solve the problem. I would question companies that are asking knowledge based questions rather than assessing problem solving, algorithms and data structures.
I‚Äôve since had my interview, it was mostly scala specific questions, done verbally or by hand on paper. It wasn‚Äôt too intense, though I have a second interview, where I‚Äôve been told I‚Äôll have an algorithm test. Which I assume will involve me implementing an algorithm in scala?
Are there pics?
Yes, in the [repo](https://github.com/fdietze/sabuni).
I clicked the repo before I put that comment. I didn‚Äôt see it. I saw screenshots in the other repo obsidian blade. 
If you don't know Free monads and shapeless programming, then you are finished. ^/s
I don't think context bound vs implicit evidence makes much sense :-) imho they are meant for different purposes. The former is for when you want to _forward_ the implicit into another method, the latter is when you want to _use_ it in the same method. So e.g. to write the method with a context bound I would do this: def p1[F[_]: Applicative: Console]: F[Unit] = Console.putStrLn("a") *&gt; Console.putStrLn("b") *&gt; Console.putStrLn("c") Where: object Console { def putStrLn[F[_]](string: String)(implicit ev: Console[F]): F[Unit] = ev.putStrLn(string) ... } (Note that the `Applicative` bound is also being used to forward the `Applicative[F]` implicit into the `*&gt;` method.)
&gt; Scala definitely has a problem with overly complicated libraries making it overly difficult to do even simple things. Glad to hear someone else saying this! I love Scala as a language ( I believe it's the most powerful one i've used yet ). However, I've grown really disillusioned with the Scala ecosystem as a whole due to this same exact problem of complexity and complicated libraries.
i am trying to create a dataframe based on 4 lists i have. i have to use scala only (we can't use SQL for various reasons). all lists have 3 values, and the column_head list is a list of the column names. column_head master_in master_out master_max ive tried: val values =Seq(columns_head,master_in,master_out,master_maxweight) val master_df= values.toDF() but i get an exception saying: java.lang.ClassNotFoundException: scala.Any I can't import any other libraries outside of: import org.apache.spark.sql.functions.desc import org.apache.spark.sql.functions._ case class edges(Source: String, Target: String, Weight: Int) import spark.implicits._ how do i make a df from the lists i have? 
Why do you want to represent it as a type alias?
Have you ever replaced an actor system distributed over a cluster, with plain old synchronized blocks?
When it comes to testing actors‚Äîimho actors are actually the wrong thing to test. What you ideally do is implement your business logic in pure-functional, immutable code, then use an actor as a wrapper around state updates to that functional business logic. Then you just unit-test your pure business logic code and skip testing the actors because they‚Äôre trivial and you probably want to test your app functionality at a higher layer anyway, like say set up contract tests for service endpoints.
It's just about aesthetics and personal preferences IMO, so using an implicit value is as valid as using context bound + summoner :) Note that in this example you're adding a convenient method in the companion object that is just boilerplate whereas in the former example we are directly accessing the `putStrLn` method defined in the interface after summoning the instance. 
One thing I don't like about this is that `Add` needs to be generic, If I had an existing library that looked like trait Exp class Num(n: Int) extends Exp class Add(l: Exp, r: Exp) extends Exp I'm not sure how I could implement `Eval[Exp]` without pattern matching which gets right back to the original problem with FP.
Do you mind illustrating these use cases some code snippets? Maybe pointer to library docs/examples would be very helpful.
This is how I was testing in the beginning however many cases of a race condition between 3-4 actors required me to do some tests on the state of the actors themselves.
I want to start building up a portfolio for a PhD application and I want it to be about scala and math, what's a good way to start and to get up to date with the state of the art? For example, I had an idea of doing complex analysis theory in scala, how do I know if it is already done? 
Are there other projects like scala.js and scala native which are NscPlugins and compile scala into another programming language? I've seen macro based DSL's like JScala and compilers written in scala (they don't compile scala but other input formats, like kaitai-struct), but no NscPlugins like scala.js and scala native (I don't mean production ready stuff, but not even hello world or basic arithmetic). I've searched github for NscPlugin and similiar things but could't find anything interesting.
Yeah I guess it is aesthetics or philosophy. Programming in Scala in general leads to a lot of boilerplate, e.g. someone wrote the boilerplate `*&gt;` syntax method that you imported and used instead of summoning the `Applicative` instance and using its `ap`/`apply` directly :-)
Hey can you give me an overview about how Rust differs from Scala interms of FP features /or/ how is Rust in supporting FP?
Well, I am more of a Haskeller than a Scaller, but I'll give you specific examples for each of the higher-order functions I listed: ### A function that feeds the output of one one function to the input of many functions: The simplest example of this would be to use List as a monad. The `&gt;&gt;=` is the monadic bind function, and for the List data type `&gt;&gt;=` is defined as `concatMap`, you can apply an input `a` to a few different functions like `(+ 5)` which means "add by five" or `(* 2)` which means "multiply by 2. After mapping all of these functions to an input value, the results are concatenated (hence `concatMap`): [1, 2] &gt;&gt;= [(+ 5), (* 2), negate] -- Outputs: [6, 2, -1, 7, 4, -2] The ["fan-out"]( https://hackage.haskell.org/package/base-4.12.0.0/docs/Control-Arrow.html#g:1 ) function, which can be written using the `&amp;&amp;&amp;` infix operator would be another example. This copies an input to two functions and returns a 2-tuple. The infix operator is right-associative, so fanning-out to several functions in a row will produce nested 2-tuples where the right-hand value will contain the next level of nested tuple. ((+ 5) &amp;&amp;&amp; (* 2) &amp;&amp;&amp; negate) 1 -- Outpus: (6, (2, 1)) ### a function that composes several functions together in parallel and merges the outputs together using another function In Haskell, all functions that return a type in the Semigroup type-class are also Semigroups. This means you can use Semigroup functions like `sconcat` to compose functions together in parallel, similar to above but instead of returning a list, the composed function returns the Semigroup concatenation the result of all the functions applied to the input. In this example, the `&lt;$&gt;` operator is the infix notation for the `map` function, the `show` function will turn integers into strings, and the `Sum` function provides an instance of `Semigroup` that replaces the Semigroup concatenation operator with the `(+)` function. sconcat ((show .) &lt;$&gt; [(+ 1), (* 2), negate]) -- Outputs: 62-1, the string concatenation of the strings "6", "2", and "-1" sconcat ((Sum .) &lt;$&gt; [(+ 1), (* 2), negate]) -- Outputs: (Sum 7) ### a function that can compose several functions together, but rearrange the ordering of composition to satisfy some goal (e.g. to minimize memory usage) In Haskell, re-arranging composing functions to minimize memory usage is referred to as "fusion." The [conduit]( https://hackage.haskell.org/package/conduit ) library on Hackage makes use of this technique. (See the [Data.Conduit.Internal.Fusion]( https://hackage.haskell.org/package/conduit-1.3.1.1/docs/Data-Conduit-Internal-Fusion.html ) module for code examples). Similar techniques are used for the [accelerate]( https://github.com/AccelerateHS/accelerate/ ) linear algebra library, and fusion does a lot to make matrix computations as efficient as possible on GPUs. A simplified explanation of how this works would be if you had some functions `f`, `g`, and `h` that operate on the hard disk and you have metrics for how difficult each one is, and so you want to ensure less difficult functions are evaluated first. data DifficultFunction = DF{ difficulty :: Int, execute :: IO () } instance Eq DifficultFunction where -- Define equality for 'DifficultFunction's. a == b = difficulty a == difficulty b instance Ord DifficultFunction where -- Define an ordering for 'DifficultFunction's compare a b = compare (difficulty a) (difficulty b) -- Suppose you have a list of actions to perform but they have not been sorted. runActions :: [DifficultFunction] runActions = [f, g, h, h, f, g, g, f, h] -- In main, we sort the actions (which is defined according to the instance of 'Ord' -- to sort by difficulty), then after sorting we evaluate 'execute' on each one in the -- sorted sequence of actions. main :: IO () main = sequence_ $ execute &lt;$&gt; sort runActions ### a function that not only composes functions together but also passes along a stateful value This describes the purpose of the [State Monad Transformer]( https://hackage.haskell.org/package/mtl-2.2.2/docs/Control-Monad-State-Lazy.html ). How it works is that it allows you to construct all of your stateful functions as a functions which take at least one state value as an input and return that state value as a tuple along with the output. But you don't need to write any extra code to do this, passing the stateful parameter and wrapping it up in a tuple is done automatically using the Monadic type class instance. So for example, the Monadic `return` and `&gt;&gt;=` (bind) functions are defined to construct a function that takes an implicit state value and returns an implicit state value. There are also two functions which can act on the stateful value, `get` which copies the state to a bound variable, and `put` which replaces the current stateful value. If you define all of your functions in terms of the state monad, all of the work of passing around a stateful value and returning it with the function output is done automatically, so you can define your composable function API in exactly the same way you would define any other composable Monadic function. 
Can you explain to me what is the difference between callback-style and Future's map/foreach style. Aren't those callbacks too?
This approach would give faster reality check on feasibility of the endeavor.
No, I've never seen them used that way (and if they aren't intended for local use then this should be documented much more clearly).
Akka supports both uses cases: single machine and distributed over a cluster.
What kind of "complex analysis theory"? 
Trying to read this functional pearl since many people I know recommended it: [http://www.staff.city.ac.uk/\~ross/papers/Applicative.pdf](http://www.staff.city.ac.uk/~ross/papers/Applicative.pdf) &amp;#x200B; And I am attempting to rewrite some of the snippets that was originally from Haskell into Scala. Without default lazy list thus having to convert to haskell, I found my attempt produces unreadable code. Starting with transpose, maybe you guys have a suggestion how to write it clearer? [https://scalafiddle.io/sf/gYdJ398/1](https://scalafiddle.io/sf/gYdJ398/1) &amp;#x200B; // Scala version of [http://www.staff.city.ac.uk/\~ross/papers/Applicative.pdf](http://www.staff.city.ac.uk/~ross/papers/Applicative.pdf) &amp;#x200B; val Empty = Stream.empty type S\[A\] = Stream\[A\] type Z\[A\] = S\[S\[A\]\] &amp;#x200B; def repeat\[A\](a: A) = Stream.continually(a) &amp;#x200B; def transpose\[A\](in : Z\[A\]) : Z\[A\] = in match { case Empty =&gt; repeat(Empty) case h #:: rest =&gt; [h.zip](https://h.zip)(transpose(rest)).map { case (h, l) =&gt; h #:: l } } &amp;#x200B; def zapp\[A,B\]( sf : S\[A=&gt;B\], sa : S\[A\] ) : S\[B\] = (sf, sa) match { case (fh #:: ft, ah #:: at) =&gt; fh(ah) #:: zapp(ft, at) case (\_, \_) =&gt; Empty } &amp;#x200B; def tranzpose\[A\](in : Z\[A\]) : Z\[A\] = in match { case Empty =&gt; repeat(Empty) case h #:: rest =&gt; zapp(zapp(repeat((a : A) =&gt; ((s : S\[A\]) =&gt; a #:: s)), h), tranzpose(rest)) } &amp;#x200B; def printL\[A\](in : Z\[A\]) = println(in.map(\_.mkString(" ")).mkString("\\n")) &amp;#x200B; val input = Stream.tabulate(5)(\_ =&gt; Stream.range(1,10)) &amp;#x200B; println("Input:") printL(input) &amp;#x200B; println("Transposed with zip") printL(transpose(input)) &amp;#x200B; println("Tranzpose with zapp") printL(tranzpose(input)) &amp;#x200B; &amp;#x200B;
Haven't looked into the whole thing but here are a couple of things I'd suggest: - Prefer to use `IOApp`. - Reading environment variables is a side-effect, should be wrapped in `F` not in `Option`. - Reading configurations is also a side-effect. Wrap it in `F`. - Don't expose `Seq` in your API. Also the empty parentheses are unnecessary in `def list(): F[Seq[Todo]]` - I personally don't like to see names like `impl`, reminds me of Java. Prefer something like `TodoService` and `LiveTodoService` instead. - Wrap arbitrary side-effects like [this one](https://github.com/scf37/fpscala2/blob/master/src/main/scala/me/scf37/fpscala2/dao/sql/TodoDaoSql.scala#L43) - Database access should use a blocking execution via `ContextShift#evalOn`. - I don't think using a custom `Later` typeclass is a good idea. A lot of things should be wrapped in `F[_]: Sync` at least. - The `I[_]` type parameter is odd. Having a single `F[_]` would be more common.
What I called callback-style might be more accurately called continuation passing style. When you invoke some asynchronous process, the expectation is that the callback you provide will create all effects that are the result of that process. In a Future-style API, the process gives you back a value of type `Future`, which "contains" the result. You can pass this value around in subsequent statements and return it up the call stack. So Futures let you write asynchronous code in a way that is similar to synchronous code. Or at least analogous. With syntactic sugar like `for...yield` or [scala-async](https://github.com/scala/scala-async), you can get even closer to synchronous style.
Now do Enterprise FizzBuzz :o hahaha, jokes aside thanks for this
Memory and battery consumption. Those are the two factors that seem to limit the horse power of a laptop these days. I switched from a Linux desktop to a Windows 10 laptop as my primary development machine. Aside from the above ... I found the only other thing was libraries written making lots of assumptions about the hardware that would be running and compiling the code. Easy was to contribute back to the community was to add Windows support. 
Windows 10 is notoriously plagued with BSOD issues with a wide range of laptop models. Check how many people have reported these issues for your model. &amp;#x200B; Disclaimer: I have HP Omen and get BSOD at least once a week.
As other people have pointed out, the issues with a Windows laptop will depend on your model. &amp;#x200B; I've got an XPS and it works fine, except for less than great battery life. I also have a Surface Laptop 2, andI have been honestly surprised with the performance and battery life. &amp;#x200B; Also WSL is your friend .. it actually provides a better Linux/bash experience than macOS.
With Scala itself? Nothing. It's JVM - it "just works". Since you seem to not use ScalaJS or Native - there shouldn't be any issues in building, as for testing - do you use any sorts of scripts or external tools? Win10 has the "Linux subsystem", but it's kind of an unstable mess so you might encounter issues with those.
Ahh alright, thanks. I think I get it. So what you referred to with callback style is an API where you trigger something async and give one single function that gets called on completion, whereas with Futures you get the Future instance and can do all the things we know and love about futures.
The only thing that'd matter is testing dev-opsy stuff locally - bash scripts, docker files etc.
You might investigate spire: https://typelevel.org/spire/ If anything numerical you need isn‚Äôt there, which I would surprise me, I would encourage you to send a PR instead of starting a separate effort. 
I've never used it, nor do I do much math stuff so you'd be the better judge, but does [spire](https://typelevel.org/spire/) not fill these needs? Its a more general math library, not specific to arbitrary precision, but it does seem to have arbitrary precision as well. &amp;#x200B;
One thing that is still painfully unbelievably shitty with WSL is the way they handle networking. Which means that if you use any kind of vpn to do your work, and in particular if you have a setup with multiple vpns to different envs etc, say managed by a proxifier, you will be in a world of pain. So much so that a bunch of us are still just making do with a mix of cygwin, mingw, containers, and tunneling, until MS can get that particular shit in order, especially considering just how seamlessly docker itself manages low level networking via vpnkit 
I/O is quite a lot slower on Windows so you may experience slower compilation and worse IDE performance. You may also hit on random problems building projects where the main developers don't use Windows.
Compiler in windows is slower than in WLS Git is slower, fast in WLS but has issue with file permissions Docker is painful Emacs is slow So with windows machine i have to install basically every Dev tools duplicated in both windows and WLS If not for gaming and let me choose again, Mac or XPS with linux
*Hi human!* It's your **13th Cakeday** behrangsa! ^(hug)
You have a problem with your classpath/build system, not with your code. Where are you defining dependencies for your code, how are you building your code, and how are you deploying it? Specifically it looks like you might be building for one version of scala and then deploying to a spark cluster that's running a different version of scala.
I'm interested in dessins d'enfants over the riemman sphere
I think you need to google harder! Spire's been around for a long time.
the same old windows platform stuff; different line endings and path separators, annoying proprietary shell, lack of a decent package manager ecosystem, lost work because the machine decided to ‚Äúupdate‚Äù and closed your open apps, etc. Scala and the IDEs work fine. 
There was [Ozma](https://github.com/sjrd/ozma), arguably the technical precursor of Scala.js. Although it was implemented as a subclass of `Global` at the time, it could have been refactored as an `NscPlugin` instead.
I'm working on a SQL query generator. I'm doing it because I want type safety and predictability. I want to be able to read Scala code and know the query it generates without having to look at the logs. This means I'm trying to make it as close to SQL as possible. I don't have a way to run the queries right now, it just generates the String in the end. For now it's like this so it can be integrated with any library like slick, etc.
I don't think there's anything like this in scala now. (For that matter, I'm also not seeing much of anything turn up in sage, magma, or mathematica). My main worry would be how much supporting infrastructure you'd have to build to get to where you want to be, but it's good praxis and if grad admissions isn't impressed by it you probably don't want to go there anyway.
Not strictly a Scala question, but: what would be an correct way of naming a function trait Container[A] { def foobar[B](A =&gt; Option[B]): Option[Container[B]] } 
Is there anyway I can utilise Scala Spark's ML library for a school home psychiatrist project? What I'd like it to do is notice for example names and the writer expressing feelings differently. In case I can, how? &amp;#x200B; Also, how can I make ScalaFX's TextArea update the area with the text that the writer writes in a TextField? 
TOP 5 CLICKBAIT BLOGSPAM TITLES OP, read http://reddit.com/wiki/selfpromotion
OK, this has been very helpful. May I ask where have you looked for related libraries? 
For learning purposes, nothing should stop you from rolling your own.
sqrt was introduced in JDK 9+, and most of other functions are implemented in the following Java library: https://github.com/eobermuhlner/big-math
You mean in WSL. On regular Windows there's no problem with IO
 trait Container[A] { def foobar[B](f: A =&gt; OtherContainer[B]): OtherContainer[Container[B]] }
Exactly. Most people find `Future` both more ergonomic and more composable.
Object Oriented programming is not a subset of imperative programming. Object oriented programming is typically associated with imperative languages, but not exclusively(take QML for example, which is an object-oriented/declarative language for designing UIs with Qt). Interestingly OOP cannot exists, or at least does not exists outside multiparadigm languages. That is, there are no exclusively object oriented languages. So while many text about imperative languages in recent decades has been lazy in it is language about differentiating functions from procedures, it is imperative(pun intended) to define those differences when talking about functional programming. I think the fact that functions, procedures, methods, and routines are similar but not equal is worth emphasizing even when talking about functional programming, it helps to be precise in the language you choose to use in all programming disciplines.
Looks good in general. I noted that in several implementation classes (for example, TodoControllerImpl, TodoServiceImpl and so on) you require cats.effect.Sync while cats.MonadError is enough to these implementations. Restrictions should be kept as small as possible. Have you looked at doobie? It is cats friendly functional library for working with SQL databases. Maybe you should use this instead of writing own code for JDBC. Another good functional libraries which you may use in your project are log4cats, http4s.
google, github, sage-devel. Did find this : http://www.math.purdue.edu/people/bio/egoins/Dessins%20d'Enfants.html (n.b. Goins is now at a Claremont, so don't rely on that page staying up long-term)
WSL networking is indeed a pain in the ass, but so is Linux's multi monitor handling. So I'm stuck with a dual boot setup, still trying to decide.
On windows mostly you can use / for paths and windows handles it - some applications (which are crappy) moan and won‚Äôt accept them but the actual win32 api‚Äôs support \ or / 
these are really minor to the actual headaches he's gonna face in other areas... line endings have been managed and well understood for a long while, ditto path separators.. there are many great shells available out there for windows if you look around.. there are long standing simple fixes to take control/block windows updates etc... package managers, if you use cygwin or WSL, its a minor issue, if you use choco, its pretty much the same as elsewhere.. for actual jvm work, ofc it doesnt matter.. and ofc, there are a great many benefits to windows too, esp over linux, but over mac as well.. many many more handy apps and utilities.. if you can think of something, someone has probably made it for windows, and even if it was for win xp, it will probably still run ok if you need to.. the same cant be said for mac, and for linux, the maintenance hell makes it a sadistic exercise in never-ending tweaking and tinkering.. and surprisingly, customization in windows can be incredibly enabling if you dig a little.. I've basically remapped my entire keyboard to avoid almost ever having to use pinky fingers for instance, with many layers of macros/shortcuts/overloading via auto-hotkey, and there still isnt a good workable solution in mac/lin after looking for many years. Multimonitor ease, access to extremely powerful cheap/used workstations, and ofc the gaming system maturity are yet to approach equivalence for lin (and even mac) systems. As to the actual issues that are gonna fire up his/their noggin over time.. win10 seems to have shit issues w being on top of virtual filesystems, so shared/virtual drives set up for docker etc syncing up w HyperV/Win is gonna give them grief once in a bluemoon, networking in WSL is still an unending pain, so the lure of WSL might leave them in misery if the right shitstorm brews up, and occasionally, the lack of the right packages in cygwin will be a pain, but these days w quickly spinnable containers and WSL, its really not that big a deal anymore, even for folk working completely on a nix stack
Are you doing this for fun or for cereal? Has this been done before?
For fun, at the moment. And still have quite some features to go before it's usable.
&gt; For fun, at the moment. And still have quite some features to go before it's usable. Put a link up, I'd love to see/work on something like this. I've been hankering for it forever!!
I wrote scalarelational, which sounds a lot like what you're trying to accomplish. I'd welcome the support.
What's wrong with exposing `Seq` in your API? What's the alternative? Is `List` or `Vector` better?
[removed]
You are going to be accessing via the interface and you might use it like this: ```scala // the interface method def foo: F[Seq[Int]] // call site foo.map(_.toList.headOption) ``` Now if the implementation uses a `List` great, works like a charm. But what if the interpreter uses a `Stream`? Calling `toList` could cause an `OutOfMemory` error pretty quickly. This is a huge issue and it could happen in other cases as well, i.e. a recursive function that needs to finish but instead the underlying type is a `Stream` that can represent infinite values. `List` and `Stream` are completely different, yet they have the same parent `Seq`. So the takeaway is to never expose `Seq` in your API and be rather explicit about your intentions. `List`, `Vector`, `Chain` or `fs2.Stream` is what I would choose.
Well done, tbh I would ask the company exactly what to expect, they should be transparent enough to give you that information. Good luck on your next stage!
This also serves as great documentation for manually writing Scala.js facades!
Author here, feel free to ask any questions. In particular, if you're just wondering what it's good for have a look at the [demos](https://github.com/oyvindberg/ScalablyTypedDemos)
My short answer to the question "What is FP" is programming with equations instead of instructions.
That‚Äôs good to move away from using the word ‚Äúfunction‚Äù and its ambiguity in the software world, and maybe then some explanation of how to achieve something that would happen in a real application. One of the things I see often when people are told FP via maths examples is that they can‚Äôt make the leap from that to the type of stuff they‚Äôre doing daily. That is also why I‚Äôm aiming to try to always keep effectful statements on the table, and gradually remove them into their own thing, in the way I‚Äôm explaining.
Wow! I have nothing but the utmost respect for this effort :)
It does! The goal has been to avoid that since it's pretty boring work, but of course feel free! If you want much customizations I've been working on two ways of extending the generated code: - "contrib libraries", where ScalablyTyped will continuously publish manually written code with dependencies on the newest generated code, see for instance the [react-contrib](https://github.com/oyvindberg/ScalablyTyped/tree/master/contrib/react) library, which is used throughout the react demos - a custom converter phase. I've implemented one, also for react, which collects all react components (and props) for a whole library in a single file, see for instance [semantic-ui-react](https://github.com/oyvindberg/ScalablyTyped/blob/master/s/semantic-ui-react/src/main/scala/typings/semanticDashUiDashReactLib/semanticDashUiDashReactLibComponents.scala)
That sounds like a special case of `traverse` (with `F` being `OtherContainer`). https://typelevel.org/cats/typeclasses/traverse.html
From a glance at the project using my phone, you're providing full database access. If the queries are totally abstracted from the runtime, then I might just use your project. Kudos for it, anyhow. Looks pretty cool!
It's still very early stage. But since you asked so nicely, here goes the link: https://github.com/xplosunn/PQL
OMG, it looks like prayers have been answered, or at least it's a step in the right direction toward Scala.js Nirvana. Have been agonizing over having to ditch Scala.js for TypeScript on the frontend in a new project that requires Ionic -- perhaps all hope is not lost, thank you!
&gt; Is there anyway I can utilise Scala Spark's ML library for a school home psychiatrist project? What I'd like it to do is notice for example names and the writer expressing feelings differently. In case I can, how? This isn't really a Scala question - Spark is a reasonable platform for implementing that kind of thing on, but the hard part is how you do the sentiment analysis etc. which is more of a question of what algorithms etc. to use rather than a question of programming language. E.g. http://classes.ischool.syr.edu/ist718/content/unit09/lab-sentiment_analysis/ is written in pyspark but I would expect that to translate directly into the Scala spark API. Of course if you have questions about how to do something in Scala specifically then feel free to ask here, but I suspect you've got more chance of getting help in somewhere that knows specifically about text analysis.
Thank you for this huge effort! I believe it will be greatly appreciated by all Scala.js users! Very impressive.
Thanks for the answer, totally forgot about Ozma. I've seen it mentioned in your PHD thesis that was posted here some time ago.
Hmm... Yeah, that kinda looks like a `traverse`, thank you!
Hi! Regarding your comments: \- re cats.MonadError - fixed. It is a shame cats does not have alias for MonadError\[F, Throwable\] though. \- doobie/log4cats - I want to demostrate that functional logging and database access is easy so I try to avoid using existing libraries where possible. No magic. \- http4s - it could be a possibility. I don't need its routes, only performant and feature-rich HTTP server \- Route.matches is performance critical method. I'm not sure how I can make it fast without couple of returns
Hi! \- re IOApp/env/config - fixed \- re Seq - list is far from perfect as all-around collection. Did you mean "most generic collection for input, most specific collection for output" apporach? I.e. \`def process(a: Seq\[Int\]): List\[Int\] \- re LiveTodoService - I prefer suffixes, they allows to list interface implementations via autocomplete. \- wrapping side effects - aren't they technically wrapped since they are inside of for comprehension? \- \`I\` is totally different effect from \`F\` with different requirements. \`I\` must memoize result by default, also different effects help to split application initialization from execution. 
I found, most people have an easier time understanding `.map` and `.flatten`. So I usually start with those and explain that `.flatMap` is "map and then flatten".
I bet that was fun to debug
&gt;oh, re evalOn: why ExecutionContext over thread pool? I believe switching threadpool boundaries should be as explicit as possible.
Author of DefinitelyScala here - great work! I've been toying with a brand-new version of the parser that works off of TypeScript compiler ASTs instead of source, but it's nowhere near ready. The original parser is great, but misses a few intricacies of modern TypeScript. Once it's ready, I'd love to work with you to get it used in ScalablyTyped
I couldn't find \`tso\`, your parser - is it available on Github?
Thanks Kyle! I've been thinking about that rewrite as well, and ultimately haven't had the time to look much into it. The only big negative I can think of off the bat is that we would get a dependency on node. We already have a hard dependency on scalac, so it would mean that we would have to orchestrate the two somehow. If we could reuse more logic than just the parser I have no doubt that it would be a net win, however! Feel free to join the gitter channel so we can talk more about it :)
So I answered you on gitter, but for everybody else: it will be public and open source in some weeks, I'm not comfortable enough yet
intriguingly, it took me a long time to come to terms with monads -- not until i used monad transformers. i think at that point the idea of encapsulating an "effect" really clicked. 
&gt;Route.matches is performance critical method Performance is not changed if you add these if/else branches: if (req.method != method) { None } else { val parts = path.split("/") val reqParts = req.path.split("/") if (parts.length != reqParts.length) { None } else { val pairs = parts.zip(reqParts) if (!pairs.forall {case (part, reqPart) =&gt; part.startsWith(":") || part == reqPart}) { None } else { Some(pairs.filter(_._1.startsWith(":")).toMap) } } } But I would write something like that if (req.method != method) { None } else { val parts = path.split("/") val reqParts = req.path.split("/") val areTheSame = parts.iterator.map(Some(_)) .zipAll(reqParts.iterator.map(Some(_)), None, None) .forall { case (Some(part), Some(reqPart)) =&gt; part.startsWith(":") || part == reqPart case _ =&gt; false } if (areTheSame) Some(parts.iterator.filter(_.startsWith(":")).toMap) else None } In some cases it can be faster than your version because `parts.zip(reqParts)` or `pairs.filter(...)` creates new array while iterator doesn't create. Though it looks like premature optimizations :)
If I ever open a Tex-Mex restaurant, I'm definitely going to call one of the burritos on the menu , "The Monad". 
I want to do something (without external libs) like `x.map(f)` , where `f` returns `Try[T]`, but stop processing elements as soon as `f` returns a `Failure`. `f` has side effects so that a simple `map` is not enough. Right now i'm using a `breakable { for ... }` loop - is there a more idiomatic way to do it?
How can I write this more idiomatically, and without external dependencies - ``` var rs: List[Option[T]] = Nil breakable { for (v &lt;- vals) { val fv: Try[Option[T]] = f(v) fv match { case Succcess(r) =&gt; rs = rs :+ r case Failure(th) =&gt; th match { case ex: SpecificException =&gt; error = ex; break() case other =&gt; throw other } } } } ``` Its roughly equivalent to `rs = vals.map(f)`, but `f` has side-effects that mean I need to stop evaluation as soon as it returns a `Failure`. Is there a nicer way to write this without the `breakable`?
I think the encapsulation of effect is just one way you can use monads, but like the blog post states, you can have pure monads. A monad just needs to satisfy the monad laws. 
How do I write this Java code in Scala: ClassName.class.getSimpleName()
I never really understood "no return rule". "return" clearly states intent of early function termination. Your first example is less clear than original, second adds quite a bit of code just to avoid array length comparison... Alternatively code could be split to lesser functions but I think it will hurt readability as well. This code executes up to \`n\` times on every request, where n = total number of routes, optimizing it is generic wisdom of avoiding O(n\*m) complexity that can be an issue. Funnily enough, FP approach is to structure code in for comprehension similar to my linear "code with returns", encoding returns as effect. I ended up with following: // intentionally imperative implementation // this method is called multiple times on every request so speed is more important than style def pathVariable(part: String): Boolean = part.startsWith(":") if (req.method != method) return None val parts = path.split("/") val reqParts = req.path.split("/") if (parts.length != reqParts.length) return None val pairs = parts.zip(reqParts) val sameParts = pairs.forall { case (part, _) if pathVariable(part) =&gt; true case (part, reqPart) =&gt; part == reqPart } if (!sameParts) return None Some(pairs.filter(kv =&gt; pathVariable(kv._1)).toMap) 
It's _little_ pile.
 scala&gt; classOf[List[_]].getSimpleName res1: String = List 
What is the advantage of using def unit[T](x: T): Monad[T] instead of: def unit(x: T): Monad[T] when the type `T` is already in the `trait Monad[T]` definition? &amp;#x200B;
None at all, that's a typo! Thank you for mentioning that, I've fixed it :)
&gt;Set is a monad I thought `Set` failed to satisfy monad (or even functor) laws?
If this pushes through to release and stays maintained, I think it'd be huge for Scala. This is the type of effort needed for the language to be competitive with the likes of TypeScript, or even OCaml with ReasonReact. &amp;#x200B; Is there going to be some level of documentation added to these libraries? For instance, I'd like to know how to use the React bindings, such as the HTML elements, and how the generated bindings might compare to the contrib ones.
That's where all of you come in! :) The only documentation so far is the demo project, and while useful, it's hardly enough. I could imagine that instead of filling out the readme files with stray comments from the typescript code, we rather provide a way for users to contribute documentation and put it there. Or perhaps it's more urgent with docs on how to use *all* the libraries, to explain the structure and so on. Feel free to drop by gitter if you want to be part of that discussion.
Agreed, Sets are not functors so they can't be monads either.
&gt; - re Seq - list is far from perfect as all-around collection. Did you mean "most generic collection for input, most specific collection for output" apporach? I.e. `def process(a: Seq[Int]): List[Int] No, see my response on why you shouldn't expose `Seq` in your API. &gt; - wrapping side effects - aren't they technically wrapped since they are inside of for comprehension? They are inside a container indeed but performing side-effects using `.map` is wrong. Same goes for `pure`. ```scala IO.pure(10).map(_ * 2).map(x =&gt; println(x)) // WRONG IO.pure(println("hi")) // WRONG IO.pure(10).map(_ * 2).flatMap(x =&gt; IO(println(x))) // RIGHT ``` &gt; - `I` is totally different effect from `F` with different requirements. `I` must memoize result by default, also different effects help to split application initialization from execution. Doesn't seem necessary. Building the application / dependency graph should not require "memoization". &gt; oh, re evalOn: why ExecutionContext over thread pool? I believe switching threadpool boundaries should be as explicit as possible. I don't know what you mean. I suggested using `ContextShift.evalOn` to perform blocking operations such as accessing a DB and for that you need a specific `ExecutionContext`, not the same one where your application runs which could be `global`.
They do have a library it's called "download python " if you want help, I am diving into Scala as a primary language so let me know if you want some grunt work done on it. It is a good idea.
I‚Äôm not sure that I *fully* understand monads yet, but I can say without a doubt that learning about the `Reader` and `State` monads was really helpful in gaining intuition about what monads can be used for.
Scala beginner writing a service that reads a large payload from a remote server then merges with local data to return a complete endpoint. The service should perform well and not waste memory. The question is how best to handle fatal errors while parsing the first calls payload? 1 =&gt; Define a var = None:Option[Payload] as placeholder payload Parse the payload in try/catch. Reassign to the var upon successful parse. Return error condition for parse exceptions or missing data. (Problem: now I must use Some everywhere or reassign to non-Option val, both seem wasteful since we know the object is safe at this point) 2 =&gt; Surround the entire merge functionality in try/catch (Problem: We now know the code is safe, why must we keep the try/catch going for the entire block?) 3 =&gt; Use var = try/catch assignment where error case creates a dummy object, then generate error condition if dummy object is returned (Problem: seems wasteful creating dummy objects just to work around language) Don't like any of these cases and feel am fighting the language. There must be a better way? 
Why not use `Future` or `Try` and just map over the result?
re \`I\` effect - my solution is non-standard. Please look deeper if you have time. &amp;#x200B; re \`ContextShift\` - it is not implicit \`ContextShift\` using global execution context. It is constructed explicitly from separate ThreadPool.
re effects. For my example: for { st &lt;- Resource.fromAutoCloseable(Sync[F].delay(conn.prepareStatement("delete from item where uid=?"))) _ = st.setString(1, id) rows = st.executeUpdate() } yield { rows &gt; 0 } We know that first effect in for comprehension is Resource monad with deferred evaluation. Lifting every line to Resource[F] would be a lot of boilerplate: `Resource.liftF(Sync[F].delay(...))` Is there better solution? 
Woow! Thank you so much for the tremendous effort put into this! As other comments already pointed out, this not only served as type facades used in code but also as helpful references if anyone want to write their custom facades.
Well, A monad is just a monoid in the category of endofunctions. What's the issue here?
Username checks out 
&gt; Is there a better solution? ```scala Resource.fromAutoCloseable(Sync[F].delay(conn.prepareStatement("delete from item where uid=?"))).use { st =&gt; Sync[F].delay(st.setString(1, id)) *&gt; Sync[F].delay(st.executeUpdate()).map(_ &gt; 0) } ``` &gt; It is constructed explicitly from separate ThreadPool. That's fine but the idiomatic way of doing it with `cats-effect` is by using `evalOn`.
what does sbt-assembly even do? I mean the program I write runs with "sbt run" so all the information needed to run the program and understand it, is right there, and yet, I have to write a merge strategy, which makes no sense, about things I've not needed to understand to get sbt-assembly to work, even though it can't be important is deciding how to run the program, given it already runs. So it literally creates pain, where pain otherwise does not exist.
Impossible to say without trying these out, but on paper it looks like s step in the right direction - since you don't overload word \`implicit\` with several meanings it should be easier to explain things to people. Right now Dotty is a work-in-progress - it will be less likely to change as it will be closer to a stable release, but things are not set in stone. If a better idea appears then it is possible that it will get adopted. So probably nothing about Dotty can be considered "final". Though features marked with checkbox on a landing page and/or described are unlikely to change drastically. Personally, I wouldn't build anything for a long-term maintenance with Dotty (yet!), but I could try out some ideas with it as it is already better than Scala 2 language-wise.
It's worth remembering that every change in dotty has to individually go through the SIP process to be included in Scala. I would expect nothing to be final until the SIP that defines that feature has been fully accepted.
Take your time it's your work. You have already done an incomparable service to the community 
Can I define an unary operator for the Double class? Can I define an unary operator other than ! - +? I am trying to create a numeric type similar to Long but for complex numbers so if I write 3i it works. Right now I have defined I as a val and that's it and I wonder if there is a better way of doing it. 
As someone already said, it‚Äôs definitely a step in the right direction, because it‚Äôs more limited in what it does and more aimed at the specific use case. Personally, I think the keyword`implied` is a poor choice, as it‚Äôs still a bit too close to `implicit`. I wonder why not use the same keyword as in Haskell though, `instance`.
&gt; I wonder why not use the same keyword as in Haskell though, instance, since this is declaring an instance of the type class for a type. Mostly because `instance` already has a meaning in the JVM world, overloading that meaning is likely to lead confusion. This was debated in https://github.com/lampepfl/dotty/pull/5458.
I don‚Äôt really see a problem there. Scala already does similar things with for example `for` having a different meaning that in other languages, and type classes are a feature used by people who are likely familiar with the concept and know what instance does.
Yes, but "an instance of a class" is something that people talk about in Scala. Imagine seeing "instance" in some Scala code and not knowing what it does, you'd google "Scala instance" and get hopelessly confused.
and then you'll still be hopelessly confused when you google "Scala implied" and everyone is talking about instances. I'm not sure what it solves.
Exactly, when talking about type class instances everyone uses the word instance (I‚Äôm not even aware if there‚Äôs another word for it), so it just adds a level of indirection to confuse even more those who don‚Äôt know what this is.
"implied instance" sounds pretty good to me. It reflects both the fact that it's still an instance (potentially named) of some class (that implements a trait) and the fact that it can be summoned when needed.
&gt; it actually provides a better Linux/bash experience than macOS Out of curiosity, what setup do you recommend here? When I was using a surface laptop I've tried several different console emulators for interacting with the WSL, and they were all incredibly flimsy and unreliable. I sorely missed the solid and versatile iTerm3 setup on my Mac, where everything Just Works, it saves my windows and tabs, lets me search the console output, etc.
Note that _type class instances_ are _still_ instances in the JVM sense (they're instances of the corresponding type classes). And _type classes_ are themselves classes in the JVM sense. Instantiating a type class is orthogonal to having that instance implied ‚Äì which just means it will be picked up automatically during type inference. Therefore, the keyword should be `implied`, not `instance`. The terminology works out nicely, IMHO! 
``` def sum[T: Monoid](xs: List[T]): T = xs.foldLeft(Monoid[T].unit)(_.combine(_)) ``` &gt; Monoid[T].unit &gt; [T] le sigh
I wish there were a way to separate `trait`s that you would use like java interfaces, vs `trait` which uses typeclasses. Actually, perhaps even better is instead of `trait Monoid[T] extends SemiGroup[T]` we could have `trait Monoid[T: SemiGroup]`, i.e. go full typeclass and use haskell's "subtyping" mechanism
Or `typeclass trait Monoid[T: SemiGroup]` hahaha that would be kind of funny though, can you imagine `type class trait` that would be pretty wild
Hi, i recently switch to scala for a small app. Pardon my ignorance if some question may be stupid. &amp;#x200B; So, i needed to connect to a database and i'm using Anorm for that which i've successfully for now. I used case classes and i'm using mostly Macro.namedParser. But, some tables in my DB has some columns with the exact same type and name and i would like to share this definition across some case class. I used a trait having all those fields and my case classes are extending it but when i poll the database, those common fields are empty. It seems Anorm don't feed those fields. &amp;#x200B; On Java/JPA i was using a common class describing those fields with @MappedSuperclass annotation. &amp;#x200B; How is the best strategy to modelize those inheritance using Anorm. I searched the web but i see only basic samples without this kind of inheritance. Thanks for your time kind stranger to help me on this! &amp;#x200B; PS: i cannot change the model of the database
Does it enforce instance canonicity? Does it solves the problem when there are two subclasses and compiler can't give you (implicit) superclass because it doesn't know that instance to pick?
&gt; Note that type class instances actually are instances in the JVM sense That sounds like a good argument to call them instances &gt; Instantiating a type class is orthogonal to having that instance implied ‚Äì which just means it will be picked up automatically during type inference. Therefore, the keyword should be implied, not instance. Passing the instance as an implicit parameter is just an artefact of how Scala currently does it. If the language implements type classes then the compiler looks for instances of the type class in scope, no implicit parameters are passed around. 
is it like defer in Golang?
oh nice, `Reader` wrecked me for the longest time.
&gt; pure monads not sure I understand what exactly you mean? I don't mean effect as in like a side effect, even `Option` is the "effect" of having possibly nothing (sorry if I'm overloading the term)
Even in Haskell type classes get compiled to just record parameters in the end. Scala's first class treatment of implicit values is a feature, not an artefact
I meant an artefact when type classes become a language feature.
That works but would have to declare the variable that stores the parsed results as Optional. If that's wrong can you please show an example? Would the following assignment to parsedPayload copy the values or just the reference to preParsedPayload? `val preParsedPayload : Option[Payload] = parsePayload() //can be None` `//handle None case, return error` `val parsedPayload : Payload = Some(preParsedPayload.get)`
You're probably overloading the term. When you encapsulate a side effect within an `IO` monad, it no longer is a side-effect, but is an effect. Most people wouldn't refer to representing the possibility of a missing value with an `Option` as an effect.
Future/Try catches thrown exceptions and, by convention, map and flatMap doesn't happen over the failed execution. Kinda like this (`F` standing for either Future or Try): def receiveRequestBody(request: Request): F[RawBody] // throws ConnectionError or MissingBodyError def parsePayload(raw: RawBody): F[ParsedData] // throws ParsingError def handleData(data: ParsedData): F[Outcome] // throws InvalidInput and then: def pipeline(request: Request): F[Outcome] = for { rawBody &lt;- receiveRequestBody(request) parsed&lt;- parsePayload(rawBody ) outcome&lt;- handleData(parsed) } yield outcome and ultimately just `match` result pipeline(request) match { case Success(out) =&gt; responseOk(out) case Failure(MissingBodyError) =&gt; responseBadRequest(message = "Missing request body") case Failure(err: Throwable) =&gt; // Pokemon clause logError(err) responseInternalError() } Something like that. Because exceptions (including body missing or being invalid) are caught inside Future/Try - their positive branches, ones we map over, are guaranteed to always contain actual data. And in case some of those failures are non-critical (say you want to handle some default or empty ParsedData if there was none provided but NOT if something was provided but failed to parse) - you can use `recover` or `recoverWith` on both Future and Try to coerce them back into successful state: def pipeline(request: Request): F[Outcome] = { (for { rawBody &lt;- receiveRequestBody(request) parsed&lt;- parsePayload(rawBody) } yield parsed).recover { case MissingBody =&gt; getDefaultData() }.flatMap(handleData) } Something like that. Obviously rather simple and contrived example, but i think it gets the point across. You don't need mutability or some explicit container for present or missing data - just use map/flatMAp
&gt; That sounds like a good argument to call them instances No, why? What you're saying is basically akin to "strings being sequences of characters sounds like a good argument to call the string type `Sequence`". That's using a name that's too general for a specific concept. &gt; Passing the instance as an implicit parameter What? Where did I talk about implicits?!
&gt; perhaps even better is instead of trait `Monoid[T] extends SemiGroup[T]` we could have `trait Monoid[T: SemiGroup]`, That's already possible in Dotty. The reason it's not recommended is that it's worse performance-wise, and that there is actually no particular reason to do it (that I know of). Note that Dotty's inference mechanism has been tweaked, and as it is, this pattern works well enough.
Sort of built in: `groupBy(importantInfo).map(_._1)`
you'd have to 'lift' yourself into the kitchen to eat it though..
&gt; It's worth remembering that every change in dotty has to individually go through the SIP process to be included in Scala. I would expect nothing to be final until the SIP that defines that feature has been fully accepted. Just because something goes through process doesn't make it bulletproof. Or even something that was previously good isn't guaranteed to be currently good.
Hi! Maybe you should take a look at equivalence aware sets [https://typelevel.org/blog/2017/04/02/equivalence-vs-equality.html](https://typelevel.org/blog/2017/04/02/equivalence-vs-equality.html) [https://github.com/TomasMikula/hasheq](https://github.com/TomasMikula/hasheq) ``` /* in build.sbt: libraryDependencies += "com.github.tomasmikula" %% "hasheq" % "0.3" */ import hasheq.{HashEq, Equiv} import hasheq.immutable.{HashSet} object Main extends App { // just some named tag for your custom equivalence relation sealed trait MyEquiv // custom equivalence over strings // for instance, // two strings are equivalent iff they contain the same number of '*' characters implicit object MyEquiv extends Equiv[String, MyEquiv] { def info(s: String): Int = s.count( _ == '*') def equiv(a: String, b: String): Boolean = info(a) == info(b) } // Custom hash function (equivalent strings must have the same hashcode) implicit object MyHash extends HashEq[String, MyEquiv] { def hash(a: String): Int = MyEquiv.info(a) } // create a HashSet based on you custom equivalence relation val filtered = HashSet.of[String, MyEquiv]( "*", "zoeijoz*ize*ozedozned", "**ziezuedze*zeznez", "**", "*ze*", "caoejao*", "-√πz√π*" ) println(filtered) // HashSetoid(*, zoeijoz*ize*ozedozned, **ziezuedze*zeznez) } ```
There's an outstanding dotty ticket for this: https://github.com/lampepfl/dotty/issues/4234 TL;DR: Well known problem that people want to address, but a solution is still being worked out.
&gt; slower performer wise can you guys compile the overhead away? :D
So the issue here was writing unaligned values with Unsafe doesn't work properly? I wonder how the DirectByteBuffer class handles this. Looking in eclipse, I see this code: private ByteBuffer putInt(long a, int x) { if (unaligned) { int y = (x); unsafe.putInt(a, (nativeByteOrder ? y : Bits.swap(y))); } else { Bits.putInt(a, x, bigEndian); } return this; } The unaligned instance field corresponds to java.nio.Bits.aligned(), a package-private method that reports apparently whether the CPU architecture supports unaligned accesses or not? 
I think it's already in Scala 3/Dotty
I honestly suggest you don't try to use any inheritance for this. Let each case class represent the table as it is (or maybe the subset of fields you care about). Some columns might happen to be the same, but that's okay; not all duplication is bad. Keep the simple 1-1 mapping and the mental model that goes along with it.
&gt; Can I define an unary operator other than ! - +? From _Programming in Scala_: &gt;&gt; The only identifiers that can be used as prefix operators are +, -, !, and ~ So, yes, you can also define `unary_~`, but it won't help you much. &gt; I am trying to create a numeric type similar to Long but for complex numbers so if I write 3i it works That's pretty similar to a postfix method call, so I would probably just define an extension method. implicit class ComplexConversion(val l: Long) extends AnyVal { def i: Complex = Complex(0, l) // or whatever } At least with this you could write `3.i`, which is pretty close. You might also be able to define something like `def *(i: I.type): Complex` to allow the syntax `3 * i`.
If you're already in the world of side effects here I think embracing it will give you the cleanest code. val it = vals.iterator var error: Exception = null val buf = List.newBuilder[Option[T]] while (it.hasNext &amp; (error eq null)) { try { buf += f(it.next) } catch { case ex: SpecificException =&gt; error = ex } } I'm struggling to come up with any standard methods that both short circuits and yields the value which caused the short circuit, and it may not even be as simple as just writing the 10 line function.
This will be available as the `distinctBy` method on `Seq` or `Iterator` Welcome to Scala 2.13.0-M5-1775dba (OpenJDK 64-Bit Server VM, Java 1.8.0_191). Type in expressions for evaluation. Or try :help. scala&gt; List("hello", "world", "!").distinctBy(_.length) res0: List[String] = List(hello, !) Otherwise you could just implemented it with something like def distinctBy[A, B](list: List[A])(f: A =&gt; B): List[A] = { val set = new collection.mutable.HashSet[B]() list.iterator.filter { a =&gt; val b = f(a) val duplicate = set.contains(b) if (!duplicate) { set += b } !duplicate }.toList }
Thanks very much for taking the time to write such a detailed and elegant example. Really appreciate your help! I learned a lot from this post and it's very motivating to use more functional techniques.
God damn I would crave currying at the type level. This was actually a problem for me whilst translating some Haskell code (forgot what it was...). 
Nice! I ended up using this with a slight change. &amp;#x200B; If we use the code you provided, then what we get is equivalent to `L.map(importantInfo).distinct`, which is more like the image of the `importantInfo` function restricted to `L`. What I was looking for was more like a representative of each class in `Ker(importantInfo)`, which is given by `L.groupBy(imporantInfo).map(_._2.head)`. &amp;#x200B; So thanks! Definitely a nice, concise way to get this done.
Thanks, that's really interesting. I've been wondering if something like this could be done well in Scala, and I guess so! Have you had a chance to use this in a project?
Great to see this will be a built in part of the language! Thanks for the implementation as well.
No, pretty different. \`defer\` is meant to "schedule" cleanup of resources lexically close to where those resources are acquired. \`Future\` is a way of representing an anticipated result, such that it can be passed into other functions or returned to the caller.
Oh that's cool, I just started Scala to hopefully do data engineering with, do you have a recommendation? I see scala for the impatient and the pragmatic book. I have experience in C++, python, React, etc. I just started writing a linked list since you need a framework for any decent web scraping stuff, from what I read. Let me know if I have any misconceptions. Thanks
I've used Scala for full-stack app development, so I don't have much knowledge of where is best to start for data engineering or scraping. You might find Spark or Akka Streams to be the sort of thing you're looking for. I got my start in the language through the Odersky Coursera course and the Functional Programming in Scala book (aka The Red Book). But check the subreddit sidebar for a bunch of resources.
thanks, yea I have spark and the documentation. I guess it's just an abstract process that takes time and research, reminds me of when I was trying to learn Cisco stuff.
If the SIP doesn't get approved it would have to be reverted back out.
What's your point here?
Nice elegant solution, good job! 
Yes, at least for me. I think almost all changes regarding type classes are a step in the right direction. Especially the extension methods avoid a lot of boilerplate for 'object syntax' on type classes. \`deriving\` is also pretty cool. I cannot really comment yet on the new syntax, it seems reasonable, but I haven't really tried it. Naturally, there is always something left to be desired, but I think these are pretty huge improvements on the status quo.
That sounds like a case for composition rather than inheritance. If you write a `case class` to represent the common fields and other `case class`es for the specific parts, can't you then just use `namedParser` as you were and `~` the parsers together? Something like: case class Person(name: String) case class Soldier(rank: Int) val soldierParser = namedParser[Person] ~ namedParser[Soldier] map { case person ~ soldier =&gt; (person, soldier) }
The discussion in the github issue makes it sound like this is already done and not just a proposal. Can‚Äôt say i‚Äôm sad to see them go.
Hm... Using them with akka-http. An offered replacement (sym") looks cumbersome.
Hi again, yes I routinely use data structures that allow to maintain equivalence classes, where the equivalence relation is a user-definable parameter (for instance when writing an optimizing compiler for some language L you can need to maintain sets of terms that are equivalent modulo some reordering/rewriting/partial evaluation of subterms, etc). Maybe a simpler way would be to box your raw strings in a type which overrides the equals/hashcode methods as needed: \`\`\` import scala.collection.immutable.HashSet object Main extends App { case class CustomString(s: String) { private def info: Int = s.count( \_ == '\*') override def hashCode: Int = info override def equals(that: Any): Boolean = that match { case that: CustomString =&gt; this.info == that.info case \_ =&gt; false } } val raw = HashSet( "\*", "zoeijoz\*ize\*ozedozned", "\*\*ziezuedze\*zeznez", "\*\*", "\*ze\*", "caoejao\*", "-√πz√π\*" ) val filtered = raw.map( s =&gt; CustomString(s) ).map(\_.s) // Set(-√πz√π\*, zoeijoz\*ize\*ozedozned, \*\*ziezuedze\*zeznez) } \`\`\`
the continuation of type annotations like that [T]. if someone could explain why exactly that cannot be inferred, that would be appreciated, because i'm guessing it can't be for good reason.
In this case it's because `foldLeft` itself is generic. The first parameter does not have to be of type `T` and the reducing function can operate on any two compatible types. Recalling that `Monoid[T]` is actually `Monoid.apply[T]`, if you wrote `Monoid.apply.unit` then the compiler cannot assume the type parameter you wanted for `apply` was actually `T` because it's in a context where the type parameter could be anything. If there were a more restrictive method like `Traversable[T].foldLeftSame(init: T)(op: (T, T) =&gt; T)` and there were a `Monoid.unit[T]`, then you should be able to write `xs.foldLeftSame(Monoid.unit)(_ combine _)` because the compiler knows the types must match what is in `xs`.
Oh yes the .apply makes a bunch of sense, thanks. due to the return type of the method tho, wouldnt the first parameter of the foldleft be required to be type T?
Excellent, Miles had already been a great representative for the community on the board, looking forward to what Rob will add.
Oh good point - totally skipped over that. In that case just having `Monoid.unit` without the `foldLeftSame` should do it, barring any issues in the flow of the type-inference algorithm. Indeed, even in 2.12: @ trait Monoid[T] { def unit: T; def combine(l: T, r: T): T } defined trait Monoid @ object AdditiveIntMonoid extends Monoid[Int] { def unit: Int = 0; def combine(l: Int, r: Int): Int = l + r } defined object AdditiveIntMonoid @ object Monoid { def unit[T](implicit M: Monoid[T]): T = M.unit } defined object Monoid @ implicit class MonoidOps[T](val l: T)(implicit M: Monoid[T]) { def |+|(r: T): T = M.combine(l, r) } @ def sum[T: Monoid](l: List[T]): T = l.foldLeft(Monoid.unit)(_ |+| _) defined function sum @ implicit val MI = AdditiveIntMonoid MI: AdditiveIntMonoid.type = ammonite.$sess.cmd12$AdditiveIntMonoid$@4a89ef44 @ sum(List(1, 2, 3)) res15: Int = 6
You have a miss understanding about what a statement is. `readLine("Enter a number: ")` is not a statement. `val num = readLine("Enter a number: ")` however is. In this case the statement performs an assignment with the result of an expression `readLine("Enter a number: ")`. `readLine("Enter a number: ")` is not a referentially transparent expression, you cannot use the substitution principle on it. You are correct in the implication therefore it is not a function and not functional. There is an old school of thought however that statements are inherently non-functional, or statements are sources of side-effects. The latter position I think is a discussion worthy topic, even if I think it is ultimately untrue. There a number of things I could nitpick, but I think this is much more informative article than your last. You state the next in the series is going to go into detail about properties of functions. As such, it seems you're going beyond just defining what is functional programming. Is there an introduction that missed that describe the scope and objective of this blog series?
Many people have said this, but I fail to see strong evidence for it. Perhaps there's a better reason for it than what I could find, but so far I'm only half convinced. Here's what I've been able to find. [This post](https://blog.ploeh.dk/2018/12/03/set-is-not-a-functor/) and [this gist](https://gist.github.com/tpolecat/7401433) argue for the same point: that if `.equals` behaves strangely, then you can break the second functor law. They both have a bit of discussion around them, which is worth a read. But [this response article](https://giacomociti.github.io/2019/01/02/Abstract-types-are-more-equal.html) lands particularly close to my appreciation of it. It argues that if you're breaking the equality contract, you're breaking substitution of equality, and then all bets are off anyway; it feels like cheating. The gut reaction is that it's not very far from supplying impure functions, which could also break functor laws. Then again, I appreciate that the functor laws say *for all* `a`, and that wonky equality in and of itself isn't impure. So I don't really know!
Nice. i still find myself trying to grasp when and how scala's type inference breaks.
You mean that guy on Gitter always answering my questions?
Your InfoString idea is very good. Pull the parts of each string that matter for your idea of uniqueness and put them into a data structure. A case class will take care of the equality and so on for you. case class InfoString( s: String, t: Int ) object InfoString { def valueOf(l: String): InfoString = { InfoString(importantPart0(l), importantPart1(l)) } } A cool thing about Maps is that the keys are a Set. So you can use the property of the keys to get the distinct InfoStrings, and use the values method to get the corresponding values. val L: List[String] = ... val factorsToStrings: Map[UniqueFactors, String] = L.map(l =&gt; UniqueFactors.valueOf(l) -&gt; l).toMap val uniqueStrings: Iterable[String] = factorsToStrings.values A bonus of this method is that factorsToStrings lets you answer, what string has these factors, if any?
I believe you got your nomenclature backwards with `foldRight` and `foldLeft`. They specify the side it starts from, not which direction it traverses the sequence.
You can have multiple Monoid types and you need to disambiguate them, this is a contrived example, but it illustrates the point def sum2[T: Monoid, U: Monoid](xs: List[T], ys: List[U]: (T, U) = (xs.foldLeft(Monoid[T].unit)(_ combine _), ys.foldLeft(Monoid[U].unit)(_ combine _))
There are two real simple options for running your main. You can do: ``` object MyApp { def main(args: Array[String]) = { println("Hello World") } } ``` or ``` object MyApp extends App { println("Hello World!") } ``` When you extend App your main method is considered anything that is declared in the body of the class.
Your main method has to be in an object, not a class. That's because objects contain what would be static methods in Java. &amp;#x200B; Instead of having a main method, you can just write whatever code it might maintain directly into an object that extends App. &amp;#x200B; Your starting object can have a companion class, i.e. a class with the same name in the same file, as usual.
Not your entire class, no. You can *either* make an object that extends `App`, *or* an object which does *not* extend `App`, but which has a `main` method. From there, just create an instance of your class and call its main method.
So is MyApp being treated as a class here whose main method is executed on invoking the object?
&gt;Your starting object can have a companion class, i.e. a class with the same name in the same file, as usual. A class with the same name as the object? Can there only be one such object in a file? Does the name of the file have to be &lt;name of object&gt;.scala?
Akka HTTP has great support for websocket both on client and server side. [Client](https://doc.akka.io/docs/akka-http/current/client-side/websocket-support.html) [Server](https://doc.akka.io/docs/akka-http/current/server-side/websocket-support.html)
So it performs similar to Python's `if __init__ == __main__` ?
If you extend App, then yeah, whatever code you put in there is what runs. If you make a main method in your object instead, it'll just run the main method. 
He also answers 80% of mine, across all typelevel channels and the scala one. I couldn‚Äôt think of a better person for that role. Congrats Rob, well deserved.
I need only websocket server. The question is, how to keep the session from the client on the server. I can not find anything. 
No. You can have as many top level objects and classes in a file as you want. If you have an object and class of the same name in a single file, they count as companions and can see each others private members. This emulates Java's behaviour of having a static and instance members in a single class. 
hey, i've done a scala chat with websocktes, it's currently handling 60k concurrent users in production. We have started with Play framework but then switched to Akka HTTP. You can handle the session state with actors :)
First of all, I have to learn AKKA. Is there any good book about it?
https://github.com/tenorviol/play-c100k-test
Hi! Do you have any discount code for some devalued Argentinians?
Agreed! But that solves an orthogonal problem. Having the ability to disambiguate is sometimes needed but shouldn't be required when it is unambiguously inferable. In fact I expect this contrived example could be inferred too.
Likely everyone will change to use String rather than Symbol with new syntax.
YouI has very straightforward WebSocket support
Including Scala.js support
[What's the longest keyword sequence in Javascript?](https://gist.github.com/lhorie/c0d9fd9b2aa215f4984f3ce1c8fd01bf)
&amp;#x200B; How can I start learning akka?
No, no and no. MyApp is an `object`. `object`s are singletons: they are a replacement for Java's `static` stuff. ``` object A { def x = 1 } ``` is essentially the same thing as the following in Java ``` public class A { public static int x() { return 1; } } ``` The only rule for an entry-point in a scala program is that 1. it is an `object`, and 2. that is has a `def main(args: Array[String]): Unit` method Pretty much the same as Java which requires a `public static void main(String[] args)` You can name your object anything you want, as long as you follow both rules. You can have as many objects (or classes/traits) as you like in a file. It does not have to be named anything special.
I do have java experience, but the objects here and the objects in Java seem to be different? Can you elaborate on the differences? (Or link me to a good source explaining the same?) And I assume you can also create objects of classes like in Java? (Else how would you even use them) &amp;#x200B;
Yes "Reactive Messaging Patterns with the Actor Model" by Vaughn Vernon is great.
Mastering Akka, Akka Cookbook and Akka Concurrency are the best ones for me :)
We tried to put a price accessible for the region, but send me an email to [gabriel@scalents.com](mailto:gabriel@scalents.com), maybe we can work out something... 
Great read, thanks.
Sounds great. Nice work. 
Would you be so kind to tell me how you approached this? I'm doing something similar and so far for each view, every WS connection has Actor assigned to it and there is one Actor holding Map with ConnectionInfo case classes for each connection. Have you came up with something smarter than me?
5-6 years or more of exclusive development experience in Lagom.... I guess only Konrad Malawski qualifies then :)
Hi, thanks for your response. How much Akka and Lagom do you have? And, how would I contact Konrad Malawski?
Okay, Konrad is on the LightBend team :) 
1. Start by coding in a style that comes naturally to you, and concentrate on learning enough Scala to code in that style confidently. Second, learn how Scala allows you to express that style better in some ways than your previous languages. Third, start to absorb the idiomatic Scala style that combines OO and strong preference for immutable data. (Before the FP fanboys pile on me, this advice is for somebody who is motivated to learn *Scala* and is struggling to become comfortable.) 2. With regard to your MongoDB comment, try to separate your Scala difficulties from your difficulty learning the domains/libraries/whatever. I haven't used MongoDB and can't tell from your comment where your difficulty in that case came from; it should be clear whether you were having trouble with the language or with something else, and if *you're* not sure you should eliminate one unknown. 3. Let yourself practice. You may have read that growth is all about challenge and difficulty, but it's actually unnatural and unhelpful to always be doing difficult things. A great deal of learning is just about practice. That's why professional baseball players still play catch and take batting practice, and why professional musicians play scales and do other technical exercises. Don't think you have to be pushing intellectual boundaries all the time. The reason it's easy to get good at a language you're paid to write is that you repeat each easy thing 10,000 times because somebody is paying you because it provides business value for them. *tl;dr* While you're learning you should spend the vast majority of your time dealing with 0 or 1 things you don't fully understand. And don't neglect the 0 case. 
Actually Lagom is optional for the Junior. If they have done Lagom , any experience on Lagom is fine
Did you see JOOQ? It is almost damn perfect java DSL for SQL queries.
heres an akka http sample project i did that shows how to handle web sockets https://github.com/ludflu/akka-http-simple-test/blob/master/src/main/scala/WebServer.scala
We have started with something like you said. A singleton actor across the cluster that whatches all connections and closes them if for example floods the server. Then we switched it to a sharded actor. But we try to encapsulare all conection info into connection actor. The sharded one is only for supervision.
My best shot: [https://github.com/search?l=Scala&amp;q=sparkml+scala&amp;type=Repositories](https://github.com/search?l=Scala&amp;q=sparkml+scala&amp;type=Repositories)
Now if only their import cleanup would actually work :(
Yes: https://github.com/coursier/coursier/blob/master/modules/core/shared/src/main/scala/coursier/util/Monad.scala no dependency on cats or scalaz =&gt; profit
I used Spire before when I was at a Fintech startup, can recommend it highly (especially considering how fast it is when using arbitrary precision numbers such as real) Can't recommend this library more.
`sbt new someGiter8Template`
First let's get one thing out of the way: The `object` keyword in Scala defines a singleton object. This is exactly like what you would do in Java by using the singleton pattern, but it has its own explicit keyword in Scala. When I mention `object` I mean this keyword. To avoid further confusion I'll use *instance* for an instance of a class created using `new`. &gt;I do have java experience, but the objects here and the objects in Java seem to be different? Instances of classes in Scala work like instances of classes in Java. &gt;Can you elaborate on the differences? (Or link me to a good source explaining the same?) Scala has no \`static\` keyword. Methods that are meant to be accessible without first creating an instance of a class needs to be members of an \`object\`. `object` creates (and **when accessed** instantiates) a singleton: \`\`\` object MyThing { def addTwo(x: Int, y: Int): Int = x + y } \`\`\` Is mostly equivalent to the following Java-code: \`\`\` final public class MyThing { private static MyThing \_instance; private MyThing() {} // this is in reality synchronized to avoid race conditions. public static MyThing getInstance() { if (\_instance == null) \_instance = new MyThing(); return \_instance; } public int add2(x: Int, y: Int) { return x + y; } } \`\`\` \&gt; And I assume you can also create objects of classes like in Java? (Else how would you even use them) That is correct. You use \`new\` to create an instance of a class in Scala just like you would in Java. &amp;#x200B;
The truth is that Scala lacks language support for enums, and so users use different solutions based on their need. In the standard library you have `scala.Enumeration`, a trait which you may extend to create an *enum-like* type. Most people I know of instead chooses to create an algebraic datatype (commonly referred to as an ADT) It looks like this ``` sealed trait Shape case object Square(side: Int) extends Shape case object Rectangle(width: Int, height: Int) extends Shape ``` While less succinct than a Java enum declaration, ADTs have more expressive power as members of the base type (in our example `Shape`) can be defined to take arbitrary arguments. Working with an ADT is done through pattern-matching ``` someShape match { case Square(side) =&gt; println(s"Square with side of $side") case Rectangle(width, height) if width == height =&gt; println(s"Also a square of side $width, but defined as a Rectangle") case Rectangle(width, height) =&gt; println(s"Rectangle of width $width and height $height") } ``` Using a `sealed` trait as the base type ensures that Scala will output warnings if a match isn't complete.
Are you asking about this? ``` val x: Any = 1 def func(x: Any): Any = x ```
You should check enumeratum, it's a library that gets enums right.
Ammonite's core "result" type is a Monad: - https://github.com/lihaoyi/Ammonite/blob/master/amm/util/src/main/scala/ammonite/util/Res.scala#L7 This makes it much easier to manage a pretty complex do-thing-in-REPL pipelines where things can "abort" all over the place: - It forces you to handle the failures or explicitly propagate them - It clearly demarcates which parts of the code are expected to abort and which parts aren't. We still have an uncaught catch-all exception handler for unexpected failures, but those are very very very rare - It forces you to give proper error messages when things fail, so users see something nice/custom like "parse error: expected end of input" rather than barfing internal stack traces all over the user's terminal. I don't use Monads all over the places, but in certain cases like this one, it definitely pays for itself
Care to share the Twitter account?
The two folks who have replied to you so far have been library authors. As regular ol' application developer, my answer is "no I have not". I believe Scala HTTP client `sttp` has its own monad (here enhanced to be monad error) https://github.com/softwaremill/sttp/blob/master/core/shared/src/main/scala/com/softwaremill/sttp/MonadError.scala
[https://twitter.com/IntelliJScala](https://twitter.com/IntelliJScala)
https://docs.scala-lang.org/tour/unified-types.html &gt; If Scala is used in the context of a Java runtime environment, AnyRef corresponds to java.lang.Object. 
Assuming you are using sbt. `target` is where your compiled class files end up. The sbt build files (`build.sbt`, and any scala files you put in `project/` also have to be compiled to class files, and those go into `project/target`. Usually I'm lazy and ignore any folder named `target` anywhere in the source tree. If you do that, just don't name a package `com.daredevildas.target`!
A java troll says to use checked exceptions.
The target directory is the default directory sbt uses to place its products. The project directory holds the source code of the program that will build your software. The project/target directory is the directory that sbt uses to place the binaries that will build your software.
So those are generated automatically when someone builds the pre-existing project using sbt right? In that case I do not need to share these directories?
Yes.
Another question - I noticed that project/ has [build.properties](https://build.properties) in addition to project/target/. Should I add the entire project directory to my gitignore or just project/target/?
Just the target. `build.properties` is a source file.
I know this is a Scala subreddit, but I wrote a monad in JS for composing react render props: https://github.com/pfgray/chainable-components
Totally! You can do it whenever your application is or component built up of a bunch of functions that all rely on some special context or capability. For example, I have a monad (and a monad transformer) for composing computations that can return two different kinds of error (client errors and server errors, which are reported differently by the application) as well as success. In another case, a monad for composing computations that handles DB transactions differently depending on whether they are read-only or read-write ‚Äî you mark the primitive operations correctly, and then you can easily figure out whether the composition is read-only or read-write before it‚Äôs time to transact. You don‚Äôt have to make your own monad to do the same things: the first one is equivalent yo `Either (ServerError, ClientError)` and the second is just a wrapper around `Free` with two constructors, but having your own custom monad can make your code tidier and easier to read ‚Äî provided that the reader is comfortable with the idea of custom monads! Sorry I don‚Äôt have permission to link to the source.
Yes, I use the basic scala giter8 template for very simple projects, and I crafted my own templates for more complex setups. 
It's not uncommon to ask oneself if using a stack of monads in a Monad Transformer, should I combine this stack into my own monad? It's also very common to be able to write a Monad instance for datatypes, even if you don't have an immediate use Monad, you do find uses for `Functor` and `Applicative` more commonly.
There is no math definition of a function and programming definition. There has only ever been one definition of function. Colloquial use of the term for years does leave does leave a lot of people ignorant of the actual definition of a function. However, no paradigm for programming has ever actually given it another definition from the one you learn in 5th grade pre-algebra class.
On my current project there is a custom-written asynchronous validation monad. It was written before Scalaz got popular. Nowadays it would be an `EitherT` transformer on top of a base `Future`. Or maybe even just a `ZIO`.
One option is to just write the enum in Java. Scala will understand it just fine.
I have to admit that I have: https://github.com/scala-js/scala-js/blob/master/linker/shared/src/main/scala/org/scalajs/linker/backend/emitter/WithGlobals.scala And the funniest is that this is for application-like code. It is a very specialized, "business"-model-specific monad, as opposed to generic ones you'd find in a library.
Not a Monad, but an Applicative Functor for a connection with a system that needed an acknowledgement of processing. There might be a meaningful monadic operation but we didn't need it. ``` trait Ackable[T] { self =&gt; def value: T def ack(): Try[Unit] def map(f: T =&gt; U): Ackable[U] = new Ackable[U] { val value = f(self.value) def ack() = self.ack() } } object Ackable { def apply(val: T): Ackable[T] = new Ackable[T] { val value = val def ack = Success(()) } } ```
I wrote a small blog post covering the scala enums topics, looking at the advantages and disadvantages of the most known alternatives. I hope it helps you: * https://pedrorijo.com/blog/scala-enums/ * https://pedrorijo.com/blog/scala-enums-part2/
In addition of the other useful responses of this thread, I suggest you to consult the \`.gitignore\` file proposed by [gitignore.io](https://gitignore.io) for SBT: [https://gitignore.io/api/sbt](https://gitignore.io/api/sbt). Checking this website usually helps to understand what are the temporary files that can be safely ignored when using git.
I don't think enum is a keyword in Scala is it?
Thank you. I actually liked this way and tried it but then, it seems the way to access to field is * result.\_1.name * result.\_2.rank &amp;#x200B; I aimed to access to field like : * [result.name](https://result.name) * result.rank &amp;#x200B; &amp;#x200B;
Is your Windows machine a work one ? Because it sure looks you have an issue where your company firewall is using self signed certificates. Either that or maybe the date is wrong. 
You start your post with &gt; [In my previous blog post](https://medium.com/@adamgajek/oop-vs-fp-the-pursuit-of-extensibility-part-1-31029591c3b4), I introduced the definition of the Expression Problem by Philip Wadler, along with two implementations of its solution. &gt; &gt;I suggest you rephrase that. The two "implementations" in your first post are not solutions, they are approaches (as you correctly name them yourself in that post). This wording can be confusing. So instead of saying "solutions" and "real solutions" go for "approaches" and "solutions" instead.
I mean write it in a Java file and put it in the Scala project.
Used it for a presentation to check the snippets, very happy with it.
You can do something else in the `map` block, or you can unpack the tuple when you do the query: val (person, soldier) = doSingleQuery() // if itreturns (Person, Soldier) // or for a query that returns List[(Person, Soldier)] doListQuery().map { case (person, soldier) =&gt; ... } Generally I'd say thread the composition all the way through. If you want to transform them into a single combined item you'd need a type for it, which would go back to being repetitive. For completeness I should say that there are techniques you can use in shapeless, [like this](https://github.com/milessabin/shapeless/blob/master/examples/src/main/scala/shapeless/examples/labelledgeneric.scala) - you could turn the two `case class`es into records and combine them, and then you'd have a single result that you could access with [record operations](https://github.com/milessabin/shapeless/blob/master/examples/src/main/scala/shapeless/examples/records.scala). But I wouldn't recommend this approach to a Scala newcomer; it makes heavy use of macros etc. and can be very difficult to follow through the types (e.g. compilation error messages are likely to be unhelpful unless you have a lot of experience reading Scala type errors).
I've been porting Mallet and StanfordNLP into Scala, I'm going to give this a shot for sure. 
Since substitutability is not necessarily a requirement for equality, sets aren't really functors. You might say that equality should imply substitutability, but there are many cases where we want two values to compare as equal even when their underlying structures are different, which would violate substitutability. An example of this would be graphs, since you can have two graphs that are equal (same vertices and edges) but oriented differently. Another thing is that we say that Functors are structure-preserving, because if they weren't, it would violate the parametricity of `map`/`fmap`. In Haskell, the Functor class is defined as: class Functor f where fmap :: (a -&gt; b) -&gt; f a -&gt; f b This definition is general enough that we have no way to relate values within the Functor to one another, we can only apply the given function to each element within the Functor. This necessarily means that we cannot alter the structure of the Functor, because to do so would require more information (typeclass constraints) about the values within. More concretely, it would be impossible to write an instance for Sets given this definition of Functor since it would require you to, at minimum, put an `Eq` constraint on `b` in order to preserve the Set semantics. Consequently, Haskell does not have a `Functor` instance for `Data.Set` (though it does provide the `Data.Set.map` function separately), and by extension does not have an `Applicative` or `Monad` instance, either.
It does for me. What is your issue?
Basically the following are constantly seen as unsused, while actively being used: import cats._ import cats.implicits._ import doobie._ import doobie.implicits._ Means that any time I refactor or copy a class, they get removed
I see, you can tag those import so that they'll never be removed
You're the second person to tell me that so I guess I finally did. But it still baffles me that the compiler gets this right, but IntelliJ indexes the code tree, yet isn't able to do the same.
(you mean Lars, not Miles)
You created this account just to spam this?
Implicit indexing seems to be way more difficult and I intuitively understand why. That being said, I foud that Intellij is getting better at it. Kudo to the scala intelliJ team for their efforts !
Intellij doesn't use the scalac compiler to do all of its type inspections, instead they wrote their own typechecker (which is why the organize imports sometimes gets it wrong)
His last 'self' commit to scala.rx is in 2016 beginning. It's his life and his code, and it's for free. But I don't want to risk using something stale.
How does one deal with implicits in larger projects? Specifically, other than having a social contract, is there a compiler flag that one can set so that others cannot accidentally put an implicit into scope that will have preference over the "correct" implicit. Example: trait Algebra[T] { def subroutine(a1: T, a2: T): T val unit: T } implicit val IntSumAlgebra = new Algebra[Int] { def subroutine(a1: Int, a2: Int): Int = a1 + a2 val unit = 0 } implicit val IntProdAlgebra = new Algebra[Int] { def subroutine(a1: Int, a2: Int): Int = a1 * a2 val unit = 1 } def calculate[T](xs: List[T])(implicit algebra: Algebra[T]) = xs.fold(algebra.unit)(algebra.subroutine) One way I could deal with this, is to have `calculate` take a non-implicit instance of Algebra. But let's say that I use a library that gives me `calculate` and I supply `IntSumAlgebra`. Then another developer adds a `IntProdAlgebra`. Is there a way to tell the compiler to allow only 1 instance of `Algebra` for `Int`. If not, where is there a better design pattern to not fall into this type of problem?
I meant Miles, just didn't realize those we're two different comitties.
Scala!
Check out how \[Cats deals implicit instances for type classes\]([https://github.com/typelevel/cats/tree/master/core/src/main/scala/cats/instances](https://github.com/typelevel/cats/tree/master/core/src/main/scala/cats/instances)). It's mostly just organizing your implicit instances into well named and organized traits that are extended by objects that need to be imported in. Looks like for your case you are creating instances for a Monoid-like type class. You probably want a trait called \`Multiplicative\` and another named \`Additive\` which contain these different instances for this particular example.
I think I'll just remove this one because the previous post you made a few hours earlier should be enough, as /u/mr___ said
I'm glad this is going in after the discussion on [https://github.com/scala/collection-strawman/issues/175](https://github.com/scala/collection-strawman/issues/175)
How does one do that?
I don‚Äôt think there‚Äôs any difference from Scala‚Äôs point of view.
Could you please just update the body of the previous post? It's still on the front page.
How does this compare to [tut](https://github.com/tpolecat/tut)?
Sure. I will do that.
Thanks for the post, do you find it difficult to recruit for FP/Scala in a City like St. Louis? I feel like the candidate depth may not be that great compared to a coastal city, but that might just be my narrow world view
I have been trying to recruit a Scala candidate from St Louis since January. Networking, job portals, LinkedIn, ATS software, etc. I even started my own meetup to see what kinds of Scala talent we have out here. But I have not found anyone. Candidate depth in St Louis is not that much. So you are right,. At least this is partially true.
&gt; 5-6 years or more of exclusive development experience in Scala, Akka, and Play. I live on the coast and I think this requirement is pretty crazy... Don't get me wrong, I really enjoyed what little I've done in Scala and Akka (haven't done much with Play)... but expecting 5-6 years of "exclusive development experience" in languages and frameworks that were fairly esoteric until the last few years is maybe a bit too much. You're targeting an extremely narrow subset of people who either already have their dream job or have been working on one of those 3 technologies for Lightbend. &gt; 1- 4 years of exclusive experience in Scala and Akka. For Junior to Mid-Level positions? This is absolutely an insane requirement. Juniors should be expected to be willing to learn something new. Mid-level should at least be familiar with the platform and language, but requiring "exclusive experience" in it is short-sighted. If you're having trouble finding talent, maybe try searching in a larger pool and update your stated requirements to include parallel/adjacent technologies to your current stack?
&gt;You construct the primitive operations correctly, and then you can easily figure out whether the composition is read-only or read-write before it‚Äôs time to transact That sounds pretty neat - would you be willing to share a small example?
Great feedback. I will modify the requirement. I appreciate it. I did find an "exclusive" candidate this evening with the same JD but in a different place, after an exhaustive search. 
I have edited the post after your feedback.
&gt; I did find an "exclusive" candidate this evening with the same JD but in a different place, after an exhaustive search. Like I said, people that meet your requirements *do* exist, but they're basically unicorns and you're going to have to spend a ton of money to convince them to move to STL from wherever they are currently. More than would really be worth it IMHO. Note: I grew up in STL but moved to Long Beach, CA after college (~12 years ago). Even though I still have a lot of family in the STL area, I wouldn't move back unless the offer was significantly more than I could find in the LA Metro area. Even ***then*** it wouldn't be an easy decision for me. I work for a fairly large company that also has offices in the area. We have a really hard time recruiting people even for Java/Spring stuff (which is a pretty common skill-set).
There are many Dev shops around that have Scala experts. I'm sure you couldn't lure them away from their current company, but you might talk to the shops to write up a statement of work.
Being originally from the St. Louis area, I have a few questions: * Most of the Scala talent in the St. Louis area is working at a handful of companies. Have you tried reaching out to people at these places? What does Propellant Software offer over them? * Why is Propellant Software's website's About page a photo of a strip mall in suburban St. Louis? (I first thought it was out in Chesterfield, but it turns out it's one in Brentwood.) * Why are the social media links generic links to Facebook's, LinkedIn's, etc.'s homepage? * Why does the company's Facebook page list Propellant Software as a "Driving School in St. Louis"? * This job req reads like something a non-technical recruiter or HR person might blast out. As others have pointed out, the skill set being asked for is not particularly common on the Coasts, let alone in a mid-sized Midwestern city. Why would someone to see themselves as working at Propellant Software? In short, your job req might have unrealistic expectations, and even if a possible candidate is within the mostly qualified for the position, the website might be scaring them off.
Thank you for your great feedback. I have already found my candidate. So I don't need any post anymore. Sure, my website isn't anywhere near perfect, and needs a lot of work. Sure, the website might scare people off, but I found a candidate. And yes, i ALSO run a driving school practice. "This job req reads like something a non-technical recruiter or HR person might blast out. " I am no Non Technical person or HR person. And I am quite a competent techie with an excellent command over English. :) But all your incisive comments are all taken in a very positive light. You ask great questions. And thanks for your keen insights. 
Thank you again for all the great comments. :)
I learned a lot today. What are the salaries like in LA Metro area?
&gt; Why is Propellant Software's website's About page a photo of a strip mall in suburban St. Louis? Great question: Answer: The website started off as a personal website. Okay, the website is now being upgraded after your great feedback. I thank you for taking the time and effort to do this. 
[https://scalameta.org/mdoc/docs/why.html#program-semantics](https://scalameta.org/mdoc/docs/why.html#program-semantics)
I've implemented dozens, though several could have been replaced with existing library implementations if the client in question was willing to use those libraries. Generally any secondary "cross-cutting concern", anything you might use aspectj or the like for. * Database transaction management (layered over hibernate/JPA/eclipselink) * Operations on a shared/synchronized piece of state * Access control * Recording statistics about what operations were performed * A remote query/service layer, similar to Haxl * Stateful tree traversals
Windows JVMs don't use a system certificate store, so have difficulties with a number of sites. I don't have a good answer other than asking these sites to fix their SSL certification path.
This is very cool. I think it should open the way for a brand new approach to doing user-friendly modular programming ‚Äì with more encapsulation, less coupling and better compilation times than the inheritance-based cake pattern. Sort of solving the problems that were described in the [Revisiting the Cake Pattern: Scaling ‚ÄúScalable Component Abstractions‚Äù](https://files.b-studios.de/revisiting-cake-pattern.pdf) Scala symposium paper.
Great framing of an issue that was a little difficult to put my finger on. I don't think it should be underestimated how impactful it can be to minimize cognitive overhead for that first running program and that first useful script. This is one of the major strengths of Python, for example. You can get a lot done before you need any structure at all. It seems like an \`object\` wrapper or \`main\` method aren't that big a deal, and that's true except that you're immediately introducing elements without any explanation. It's just an incantation.
Can you give a fully worked example?
I think the most general thing about Scala is that people always complain about FP stuff like ‚ÄúDon‚Äôt use Akka Http use Http2S because functions and compositions and whatever‚Äù. So ‚Äústay pragmatic not dogmatic‚Äù I guess will be the best advice around. 
guys. You‚Äôre spamming too much
When I started as a developer, my objective was to learn all the features of the Scala programming language. Specially the fancy things. Despite writing unit tests I found that in many places the code crashed in production for simple things like doing Int == Option(Int). The unit tests didn't catch it because they were mocked and my team was full of java programmers who happily wrote 2000 line long classes with 200 line long methods. Now, I will go slow on learning fancy features and spend more time in gaining domain knowledge of the solution, spending a lot of time on breaking apart large chunks of code and make sure each chunk is testable. Don't use mocking frameworks as a drug-habit just to get off the hook from testing. Really challenge yourself to test your code. 
Value classes are kept around in case project Valhalla takes off in Java. Though I don't know any details it basically allows you to create zero-overhead structs in Java (and as a consequence could be used in Scala). Basically value classes with more than one value without boxing. opaque aliases are not going to be used for those, so that's why value classes are not deprecated. Though, until project Valhalla happens they are not preferable for anything as far as I know.
^(never tried it but can you use opaque types with extension methods to have something that dispatches method calls statically ?)
I just Erik Osheim's talk \[1\] about opaque values and looked up the documentation again -- value classes seem to be used when enrichment of opaque types is needed. &amp;#x200B; This example is taken from the SIP-35 \[2\]: package object opaquetypes { // The previous opaque type definition opaque type Logarithm = Double object Logarithm { // These are the ways to lift to the logarithm type def apply(d: Double): Logarithm = math.log(d) def safe(d: Double): Option[Logarithm] = if (d &gt; 0.0) Some(math.log(d)) else None // This is the first way to unlift the logarithm type def exponent(l: Logarithm): Double = l // Extension methods define opaque types' public APIs implicit class LogarithmOps(val `this`: Logarithm) extends AnyVal { // ^^^^^^^^^^^^^^ // This is the second way to unlift the logarithm type def toDouble: Double = math.exp(`this`) def +(that: Logarithm): Logarithm = Logarithm(math.exp(`this`) + math.exp(that)) def *(that: Logarithm): Logarithm = Logarithm(`this` + that) } } } \[1\] [https://www.youtube.com/watch?time\_continue=1254&amp;v=3a5oE3p3jDA](https://www.youtube.com/watch?time_continue=1254&amp;v=3a5oE3p3jDA) \[2\] [https://docs.scala-lang.org/sips/opaque-types.html](https://docs.scala-lang.org/sips/opaque-types.html)
Extension methods in Dotty don't need implicit classes: https://dotty.epfl.ch/docs/reference/contextual/extension-methods.html
lmao are you replying to the right post?
For noob questions, you can always hop onto gitter chat: https://gitter.im/scala/scala Lots of helpful people there :)
What kind of questions do you think you will have? Just want to shoot the shit? Remember when IRC was used precisely for this?
https://doc.akka.io/docs/alpakka/current/
Yeah, I mean, shoot the shit with the occasional (probably stupid) scala/dev question...
Not come across that before, I'll definitely check it out, thanks!
That's normally solved \*newtyping\*. I'd personally recommend \[newtype\]([https://github.com/estatico/scala-newtype](https://github.com/estatico/scala-newtype)). &amp;#x200B; So you would create two different types: \`\`\`scala @newtype case class SumInt(toInt: Int) @newtype case class MultInt(toInt: Int) \`\`\` &amp;#x200B; And then safely define instances for these types: &amp;#x200B; \`\`\`scala implicit val intSumAlgebra: Algebra\[SumInt\] = ??? implicit val intMultAlgebra: Algebra\[MultInt\] = ??? \`\`\`
If one wanted to be able to upcast to `Any` and pattern-match back at runtime etc. then a value class would still make sense. I'm not convinced that those use cases are good ones, but the cases where a value class boxes (and an opaque type is forbidden from being used at all) are presumably things that someone somewhere wanted to do.
Good point!
Quick performance question about Akka : I'm using Actors for a project. Almost all my actors subscribe to the Event Stream for a specific Event. When using the unsubscribe(subscriber: ActorRef) method of the Event Stream, I can have more than 200k actors subscribed at the same times with no issue. But when using the unsubscribe(subscriber: ActorRef, channel: Class) method I can barery reach 10k to 20k actors before I get deadletters issue blocking my whole program (even though not all unsubscribe at the same time, myabe 10% to 20% of them) I there a know difference in performance between those two methods ? 
terse-logback, an attempt to get structured logging solution out of the box. There are other goodies in there as well. 
More specifically see https://doc.akka.io/docs/alpakka/current//file.html
I just started learning Scala a week ago. I enjoy talking more conceptual, like how the ideas behind the syntax work, as those ideas transpose over to multiple languages, and sometimes mathematics as well. It's fun to hang out. I wouldn't mind. You're welcome to throw me a PM if you want. But, as far as technical questions go, I usually ask Stack Overflow these days, or file a bug in a library's bug tracker or like github or similar.
The find implicit usage feature is so good
Scala's gitter channel is a good place for that. Lots of helpful and knowledgeable people hang out there.
... `coimport` or bust!!
You are doing a great job making Scala easier to use. Keep it up! :)
Thank you!
Now this is some great additions that were really missing. Great work. That search for implicits usage is delicious.
 [error] Check the spelling of the generator's name and try again.
As someone who is forced to use a Mac at work - it gets in the way of work a lot. So unless you're willing to give Linux a try (Arch is nice, just saying) - stick to Windows. I have Win7 at home (so without even Linux Subsytem) and i have not encountered a single issue while developing with Scala, Kotlin or Java. &gt; lack of useful things like Page Up/Down buttons. Oh, you sweet summer child... That doesn't even scratch the tip of an iceberg of issues anyone coming from Linux/Windows will face using Mac...
Why not just install some GNU/Linux flavor on a partition and try it out? Just get ubuntu 18.04 and try it out a little
I'm a professional Scala dev and use a Macbook Pro at work. The ecosystem is great IMO compared to Linux in terms of window manager (no tinkering with resolutions, peripherals, etc), package manager (brew is so nice), driver support (the Macbook touchpad does not compare to the Thinkpad touchpads, for instance). I grew up using Windows until starting my first job, and would never go back (especially for development work in Scala).
Here's what I've done in the past for WSL: https://gist.github.com/wsargent/072319c2100ac0aea4305d6f6eeacc08 These days, I don't bother with WSL -- instead I use Virtualbox and Windows. and that works fine for me. No lag, overhead is minimal. The advantage is that I can still run all my Windows tools, like 1Password and Yubikey Hello support, and I can package my development experience a bit more easily. Even if you're running on a cloud service, you should still be able to run everything locally, and be able to check experiments and use a debugger etc locally. I use localstack for all my exploratory testing, for example. It is much, much faster to develop locally and then go to AWS after I know what I want. Get a i9-9900K (compiler is still mostly single threaded) and an NVMe like Samsung 970 Pro (don't forget the M2 mounting screw). You can fit it into a pretty small space (see Puget Sound Echo Pro for details).
The last version of intellij is amazing!!! Finally working kind projector and also the inference is amazing. Finally MapK semigroupK kleislis etc working like a charm. Also the implicits much better these days. Good work! 
At my job we you can use whatever machine you like for Scala development and we have programmers with Windows, Linux and Mac. There have been very little problems so far. The only things we occasionally encounter are scripts written in Python that are apparently OS specific. So if you want to stick with Windows I don't think that should form a problem. (written by a Linux user)
In my company I work with \~500 other scala devs. We are free to choose our own hardware/os. Half of the people use MacOS and the other half uses Linux. They are both fine; %99 of the time tools support both. I tried both during my career; I decided to continue with MacOS to avoid spending time keeping my system stable since it just works. During my day-to-day work my only issue is docker; uses too much resource compared to a native solution 
I‚Äôm a Scala dev, and all the others I know and work with use Macs, apart from a couple who use Linux. No-one I know uses Windows out of choice, thought some are forced to by their employers/customers. 
I use Windows with out much issue, after using Mac and Linux (a very long time) I really am enjoying Windows. Don't really run until any issues
I prefer linux. But for a work environment I'd say go for what the majority of people you're working with is using
What is this company if this is not indiscreet?
[removed]
Is that a bottle of gin Bombay sapphire? I'd like to work there too! 
Thanks for the perspective! Useful.
Thanks. I've used Ubuntu a bit before. I'd have to check there aren't any security issues about making the machine dual boot, but I might give this a try. Cool quad-monitor setup!
I feel like I should give Macs another go at some point - maybe this is the time to try it. Then I can blame my incompetence on the unfamiliar OS.
Thanks. Maybe I should start with Windows and then see if there are any problems. I'm pretty sure that the data science team uses Python a fair bit so that might be a consideration.
What if it's so bad I have to drink to get through the day? 
For personal / freelance topics I prefere linux. Some enterprise companies are based on m$ crap so it's difficult to exist without win. 
Can you elaborate on how a Mac gets in your way of work?
\+1 to Mac -- the handful of coworkers I've seen try to get started on Windows have had A Bad Time of it (for the setting-up-workarounds reasons you describe as well as our own in-house-made blockers). The transition from working on Windows -&gt; working on Mac shouldn't be too awful! On Mac it feels like there are much fewer hoops to set up/jump through when working with scala.
At work I have a Windows and a Linux machine, for development the Linux is much better. For a start you don't need to install the winutils.exe . I barely us the intellij, I don't like it and I prefer atom as editor. 
&gt; I have a slight preference for Windows based on historical prejudice around 1-button mice and a lack of useful things like Page Up/Down buttons. No one in their right mind would use Apple's idiotic mice and keyboards when third party ones are compatible and work even better. If you prefer windows machines, there is no point in switching macs and having learn their workflow. I personally prefer Macs because of the workflow and other niceties. But I use linux to do scala and java development. If you are having issues running Scala on windows, try dual booting any of the linux distros. Linux distros have come a long way. &amp;#x200B;
&gt; We will likely be using a Spark / Cassandra / Kafka type stack If you plan on running the entire stack locally for development and debugging purposes, being able to run Docker natively on linux is a huge advantage over the two others. Also in my opinion, using Homebrew or Chocolatey doesn't come anywhere close to having your entire OS managed by a package manager like APT.
My workplace is Linux-only, not because it's a rule, it's just that the kind of people they hire happen to also be the kind of people who will immediately install their favorite Linux on any new computer they are given (the exception is our secretary, who uses windows, but like, fair enough). So obviously I'm biased, but I think it's a much nicer system for developers than Windows is (depending on which Linux you get and how you set it up, of course - that's the beauty of it, you can get an out-of-the-box Ubuntu, and then you can go as far down the rabbit hole as you like). Also, if you want to learn more about system administration and how your OS works and such, installing Linux is a good starting point. 
This is great! julien-truffaut (OP) also makes [Monocle](https://github.com/julien-truffaut/Monocle), an excellent scala library.
If you prefer Windows just stick with it. I don't like being forced to use Windows, I don't want to see people being forced to use Mac if they don't like it! The main benefit of Linux and Mac, for developers, is that being Unix they're closer to the servers you'll be deploying to, especially Linux. So when you need to install a stack to test locally, it's easier to do on Mac than Windows and even easier on Linux. That said, JVM development in particular is an area where the OS matters the less. You'll be running on the JVM anyway, adherence to the OS is minimal. In the other hand if you want to do Ruby, is going to be much more painful on Windows. In short: try Linux, it's great. You can try a Mac, but it involves buying hardware. But don't be ashamed to stick with Windows if you prefer it.
Don't use windows. You will get weird problems in all small things and spend hours debugging. That goes for anything programming related anywhere. Never use windows, that should be always the answer.
Hi, I'm curious, did you have ergonomic keyboards like the Kinesis Advantage, Maltron or Ergodox before you got your keyboard.io Model 01? And if so, how does Model 01 compare?
You'll have no issues on Linux or Mac. Windows you will. I use both Linux and Mac. Recently though I built a new computer since Apple hasn't upgraded their Mac Pro since 2013. Tired of waiting. I've been on Kubuntu LTS now for about 4 months. No problems. Also I think using Linux as a desktop is invaluable since you're using the exact operating system your Scala software is going to run on. We have 1 Scala dev on Windows and he constantly has issues with things that those of us on Mac or Linux never experience. Most recently he is unable to start Apache Ignite over VPN to pre-load our database for local testing. But everything works perfectly fine on Linux and Mac. So basically he can't do his job at the moment because of some Windows specific issue that obviously none of us can help with because we don't use Windows. &amp;#x200B;
Perfect suggestion. To the OP, steer clear of direct Actor coding, the Streams abstraction is much more reasonable in all senses.
You brave man! How do you memorize all the imports?
My employer provides a Mac for my development. In production our code runs on Linux servers. I've had no issues, even though I have tests that spin up Cassandra, Kafka, Zookeeper, or HDFS. I wouldn't go with Windows, because I think I'd end up working in a virtual machine or replacing it with Linux. Hell, even Mac has an occasional conflict due to differences between the GNU and BSD userland. Mac supports 2 button mice. You can plug one in and it will work, or turn it on for the touchpad with a setting. The context menus in IntelliJ are exactly the same. Linux laptops are an option, also. [https://system76.com/](https://system76.com/)
He can run it in a virtual machine. It sucks to have to do that, but it'll work at least.
We don't do rocket science. Most of the imports for spark are always the same and the project libraries are easy to remember/always the same. Sometimes I struggle a bit with when reducing and aggregating values in scala but now I¬¥m used to. &amp;#x200B; We use maven as building tool and IntelliJ with Maven has given us some headaches with the corporate proxy and jdk parameters. IntelliJ was a great idea but I have the feeling that they have gone too far and now is repeating the worst habits of Eclipse. &amp;#x200B;
Yeah... We basically have CNAME's that resolve to internal IP's when connected over VPN. So there is an external IP as well, but on VPN it resolves to internal IP (so you can access shit like the DB's) I am not even sure of the exact issue. Its a very interesting issue he has as the internal VPN IP's resolve correctly when doing `InetAddress.getByName` but pre-loading the cache over JDBC connection it times out for him. Who the fuck knows honestly, its Windows... Ignite is new for us so we are still in discovery phase which means its not in a container or anything yet because its in active development, etc. He'll have to setup everything on the VM. Thats the point of my post though. You will run into random shit on Windows that just works like its supposed to on Linux and Mac.
Sounds like a firewall or route issue. Can he open any socket to the internal server? What interface do the outgoing packets go through?
He's on a laptop so I'd imagine he's using wifi. (we all work remotely) Our VPN is unique in that only internal traffic gets routed across the VPN. This might be related. He can access this specific cluster fine through other software. For example I wrote a Scala wrapper for us around the entire JDBC library about a year or so ago. It works fine for him. I looked at the Ignite source code and its not doing anything special. Standard JDBC stuff. Ignite has IP discovery built-in, this might be related. What specifically, I couldn't tell you, he would have to step through the code in Ignite I would imagine when its starting up and attempting to do the pre-load. So, I helped him that far, basically narrowing it down to Ignite and most likely related to Ignite's IP discovery. But it is most definitely Windows only. I'm on Linux and it works fine for everyone on Mac.
Windows is used by 91% of desktop users. Most languages treat Windows as the first target (e.g. Rust). Windows is definitely a first-class target for Scala, Java and Co. You're going to be just fine. It's easy for people to give you advice that seems helpful but is really just an fandom toting chance for them
* Different weird keyboard layout that you simply can't force even with non-Apple keyboards because it's an OS issue (~ being in some random place instead to the left of 1 as it is on every single other keyboard). * Not having tiling window support, or even Window's emulation of that feature where you can "stick" windows to the side of the screen for it to be stretched to half of the screen. On Mac you have to adjust windows manually if you want to look at something side by side. * Home, End (and by extension Ctrl+ that key), PgUp and PgDn not functioning the same way they do on every single bloody device in existence. * Ctrl+ arrow not navigating "by word". * Having to use Apple's own key instead of Ctrl for quintessential functions like copy/paste/cut/undo. After 20 years of **every single device and every single os** on this planet doing those actions through Ctrl - suddenly doing them through different key (while also still using the traditional Ctrl at home and everywhere else) gets in the way a lot. * Ctrl + Space to change language. And you can't change it to something sane and traditional like Alt+Shift because OS then treats every action containing those 2 keys and some other key as you changing language. * Not being able to set something to run at startup (Windows - create shortcut in Autostart, Linux - dozens upon dozens options, but most universal being add command to .%shellname%rc file) without jumping through hoops with clunky and awkward "automation" software. And those (sans last one) are just the issues i was reminded since beginning work today an hour ago. Given time list would be about ten times longer. P.S. And obvious one that you can't use same key combos in something like IntelliJ as you can on any normal OS (Windows/Linux) and have to learn separate ones for just Mac, while still using the normal ones on every other machine (say, at home)
Can you help answer [this](https://stackoverflow.com/questions/55411772/how-to-get-value-from-nested-map-of-type-anyref) questions here of mine?
Oops.. sorry. Please download a newer version of the JAR (snapshot) instead. I've updated the instruction above. &amp;#x200B; [https://oss.sonatype.org/content/repositories/snapshots/org/openapitools/openapi-generator-cli/4.0.0-SNAPSHOT/openapi-generator-cli-4.0.0-20190328.175824-475.jar](https://oss.sonatype.org/content/repositories/snapshots/org/openapitools/openapi-generator-cli/4.0.0-SNAPSHOT/openapi-generator-cli-4.0.0-20190328.175824-475.jar)
I have been using Mac OS, Linux (various Debian-based distros, currently Mint 19.1 Cinnamon) and Windows (7 and 10) for Scala development and haven't encountered any problems I can remember. I use Intellij IDEA for anything but small edits, it's available on these three platforms. I've found WSL bringing more problems than it solves, so I just don't use Ammonite on Windows. Both Intellij worksheets and Scastie have served as a substitute for the sort of thing you'd usually do in a REPL. Most of Scala projects on Github use sbt. I didn't have a hard time contributing to them (but there were some minor issues like [this](https://github.com/monix/monix/pull/827)), and my projects work pretty much the same way across all machines and systems. As a long time Windows and some time Linux user I personally like Mac OS least of all these options, specifically b/c keyboard is too different and it makes it hard to adjust (and OS these days, I don't find being any better). Of course, you can run Linux on a Macbook and that works surprisingly well out of the box for some distros. I suggest staying away from Macbooks if you are working with code on Windows in your spare time and intend to continue using Windows (or Linux) - I've been working on one for three years and my habits haven't fully adapted yet. That being said, I find Linux to be the most enjoyable OS to use personally, including for development purposes. If it wasn't for the games, I'd kiss Windows goodbye.
Hate my life, basicly
[https://xkcd.com/303/](https://i.imgur.com/1dyqCC7.png) 
Hah. I used to complete [Project Euler](https://projecteuler.net/) problems in [Racket](https://racket-lang.org/) while waiting for compiles (which took 1-2 hours after we finally stabilized the build infrastructure) to finish. That and go have conversations with coworkers; pretty sure my talking to coding ratio was at least 3:1. The project I worked on was quite large with at least 100 developers having touched the code with many only working in that code base. It was also quite well designed in both the "business domain modelling" sense as well as the "we have a small, core technical philosophy to use when solving problems" sense. This project was adjacent to an A+ (APL derivative) project that was being deprecated. As A+ is interpreted and has quite the "code while the application runs" feature set, I was quite jealous of the A+ developer productivity.
Working on micro services via the play framework, compile time is absolutely not an issue for me.
I used to develop ray tracer in Scala. The compilation was pretty slow due to slow dual core Celeron and lots of small files of code and the number of lines was about 5,000. It ran about 4 or 5 mintutes after indexation. That time I was reading Wiki or working another project. The most terrible when you forget to put some brace somewhere...
Browse reddit
The scala compiler is relatively slow but this should not necessarily translate to slow builds. &amp;#x200B; Break up your builds into smaller modules. Gradle supports this, as do bazel and sbt. They also support build caching. &amp;#x200B; At work we build over 100,000 lines of scala in about 8 minutes on a little jenkins worker. It helps that it's broken down into about 150 gradle modules.
Keep working because incremental builds are fast.
After switching from sbt to pants, i barely have enough time to make a cup of tea during the compilation
Even better than IntelliJ in term of correctness
My incremental builds are rarely more than a few seconds. I usually use that time to alt-tab to the browser window I'm about to refresh.
Work on another repo that isn't compiling.
How do you module your code?
Pants ? What's this? I never heard about it ?
Do you do Spring dev in Scala? Why?
Oh god no. I used to work on a Spring team that was adamant we had to use Java because Scala's compile times were apparently too slow. They'd bitch about a 2 second Scala compile time, but consider it completely acceptable to go grab a coffee every-time they needed to restart Spring in development.
I know in our codebase we have some shapeless stuff that results in O(n^2) compilation times. I spend time reading articles that I don‚Äôt understand well enough to apply about profiling and optimising compile times. I think there is some implicit caching that we‚Äôre missing somewhere..
[Pants Build System](https://www.pantsbuild.org/index.html) Basically you split your codebase to a virtual "packages" (i.e. controllers, storages, services, repositories, models, records and so on) by defining the structure in a BUILD file(s). These "packages" are cross-compilable and can cacheable, which makes compilation much faster. You can see a simple example [here](https://github.com/pantsbuild/pants/tree/master/examples/src/scala/org/pantsbuild/example) Moving a big project from sbt to pants is such a pain in the ass, but after you're done you'll never want to get back. By the way, there's a pretty good pants plugin for an Intellij IDEA &amp;#x200B;
Put all your shapeless generated stuff in an object and used cached implicit. You don't want to import shapeless all over your project because macro expansion will seriously degrade compilation times. &amp;#x200B; Once we started doing this (for example for shapeless-scalacheck arbitraries) we chopped our clean compile time down to approximately 3 minutes on a 15000 line project and incremental builds went back to 1-2 seconds.
In our team, we turn off `scalafmt` imports clothing cleaning and mandate a teamwide intellij config. Spent hours trying to get them to play nice before that with no luck.
If you build with gradle, you can organize your source tree with gradle subprojects as modules. In your project root, settings.gradle.kts tells gradle about your modules: ``` include( // common modules used for all your services/applications ":common:auth", ":common:metrics", // ... // applications split up into: transport-independent service code, client for that service, and entry point ":hello:app", ":hello:client", ":hello:service", ":world:app", ":world:client", ":world:service", ) ``` In each module directory, a build.gradle.kts file configures it -- for example world/service/build.gradle.kts might say: ``` plugins { scala } dependencies { // goodbye service uses our common libraries for metrics etc implementation(project(":common:metrics")) // ... // goodbye service calls hello service via the hello client implementation(project(":hello:client")) // ... } ``` In that module you could define a class GoodbyeService that implements some interface defined in thrift, protobuf, swagger, graphql, etc, along with supporting code. In world/app/build.gradle.kts might say: ``` plugins { scala application } dependencies { // the service code implementation(project(":world:service")) // our own common server code implementation(project(":common:auth")) // ... // third-party server libraries implementation("com.typesafe.akka:akka-http\_$*scalaVersion*:$*akkaHttpVersion*") // ... } ``` In that module you might implement GoodbyeApp which extends scala.App and binds GoodbyeService to your favorite HTTP server. 
I read and respond to Reddit posts.
I usually try to understand the code I just copy pasted from some random scala blogpost on The Internet into my program and that scalac is currently compiling.
I think it might be due to `val operators: Array[String] = Array("/", "*", "+", "-")` `for (i &lt;- 0 to operators.length) {` If I'm thinking correctly, operators has only 4 elements, but now you're going from 0 to 4 =&gt; covering 0,1,2,3,4, that is five elements. Try changing `to` to `until`?
why not bazel?
Scratch that, are you ever changing the boolean of the first while loop?
That's an opinion I don't see often. Care to share some of the things in your opinion Windows does better? Not to start a holywar, just curious if there are some things I don't use or appreciate enough about Windows.
Watching a movie, then having something to eat and sometimes I have time to go to the gym as well...
why not maven? :D
No, the design is not okay. If this is some kind of training exercise, you are doing it all wrong, and even if this program did work you would not get any marks for it. If you find yourself doing one of these things in Scala, most likely you better think again: * `var` * mutable collections * `for`as an imperative loop * `while`loop (in most cases) In the best scenario this program would work for single-digit integers only, but then it might be part of the task. Input string might be efficiently split using regular expression instead of by indices. Converting `strings` to `ints` and then back to `strings` again is also usually not a sign of great design. Then you are storing your intermediate results in the same array as the initial data, and then you are trying to access element that is out of bounds in the `elems(j + 2)` bit. I think what this exercise was intended for (if this is an exercise) is to demonstrate the usage of recursion and immutability.
&gt;Having to use Apple's own key instead of Ctrl for quintessential functions like copy/paste/cut/undo. After 20 years of **every single device and every single os** on this planet doing those actions through Ctrl - suddenly doing them through different key (while also still using the traditional Ctrl at home and everywhere else) gets in the way a lot. Nothing stopping you from changing keyboard shortcut for those functionalities. OS X lets you do that. For me, using cmd key with my thumb is a lot comfortable than ctrl with pinky. &gt;Not being able to set something to run at startup (Windows - create shortcut in Autostart, Linux - dozens upon dozens options, but most universal being add command to .%shellname%rc file) without jumping through hoops with clunky and awkward "automation" software. You can write a plist and use launchd to start scripts at the start up or even add it to login items of your account. Not as easy as adding a script to a folder in Linux, I admit. But its far easier than on windows last time I checked. &gt;P.S. And obvious one that you can't use same key combos in something like IntelliJ as you can on any normal OS (Windows/Linux) and have to learn separate ones for just Mac, while still using the normal ones on every other machine (say, at home) Most IDEs like Intellij lets you change keyboard shortcuts. They even provide you with a few shortcut schemes for you to choose from if you don't like the Mac shortcuts. &amp;#x200B; Most of your complaints seem to be about Macs having a different workflow from linux and windows. And having to learn it. I am sorry that you being forced to use Mac at work. Perhaps you should find a different job. I personally wouldn't work for a company that forces you to work an operating system I am not comfortable with (with some exceptions). &amp;#x200B;
Reddit - &gt; twitter - &gt; mastodon. Get depressed about the world and the state of the codebase. Try not tho think much about it and survive another day. Then coffee - &gt; hacker news - &gt; lobsters. Should be finished. Now run tests, quick, integration tests, go back to step 1, go cry in a corner. Now run acceptance tests - &gt; complete the cycle again but this time also check email. Get depressed I already went hover all the internet again.
For no reason, actually. Just tried pants and stayed with it
Better is a difficult thing to gauge honestly, but I don't find it as brittle and unusable as many people like to think it is. If you want a solid workstation with little futz but limited customizing(compared to Linux) and lots of hardware support and software backwards compatibility it's not a bad choice. I don't really run into anything that impedes me from doing what I want to do. 
I work on a few Scala projects that are 100k-200k lines, and they don‚Äôt take more than a minute or two to do `sbt clean compile`. We use lots of implicits, some macros, and other compiler-intensive stuff, so I‚Äôm surprised to hear it takes eight minutes. Does that include dependency resolution?
I should have mentioned that the build includes a lot of tests with coverage reports.
Ah, that makes a lot more sense! 
Thanks, I've tried Virtualbox and Ubuntu on your suggestion. I found that IntelliJ felt very laggy in Linux, and it took about 3 times longer (9s, vs 3s on Windows) to run a hello-world type program. I might be doing something wrong. I gave it 2 GB RAM which I assume is enough.
Take a look at https://github.com/lightbend/scala-sculpt and https://www.iteratorshq.com/blog/scala-compiler-phases-with-pictures/
This is what my experience was on a desktop, even on a desktop 5820k -- I think it's due to the SSD transfer rate. What I did eventually on that machine was to run Linux natively, and poke to the Windows installation to make it appear as a Virtualbox install (which is Not In The Manual). When I'm running on i9-9900K with a Samsung 970 Pro, I don't notice any lag or overhead at all, so it doesn't apply. It's around $2000, which should be a reasonable expense for an employee's main source of work. Have you tried the WSL install instructions at https://gist.github.com/wsargent/072319c2100ac0aea4305d6f6eeacc08 and how is that working?
Stare patientienly at the terminal
I read this as "how do I stop bleeding every time I cut myself". The answer is you shouldn't be having this problem. Get a good computer with fast cpu with a big cache, fast ssd with a fast connection, and tons of fast memory to run everything you need. Beyond that, what everyone else said in this thread.
Javalin. It's a Java library but very productive and easy to use.
What are the reader and state monads?
The Reader monad is useful for composing computations that all depend on a shared value of a certain type, often called the *environment*. For example, say you had some code that talks to your database, and it uses a connection. You have multiple methods in this section of code that all depend on having a connection, and ideally you'd like to call multiple methods in turn (sometimes using the results from previous methods in the input for new ones) and pass them all the same connection object. You could add the connection as a parameter to all of the methods, and manually pass the same connection through all of them as you write your code. But that's a bit cumbersome, and sort of obscures your main logic (and the type signatures of your methods) by having all of the cognitive noise of passing connections through. If you were to use the Reader monad, instead of directly returning a result, you would return a `Reader[Connection, ResultType]`, which conceptually is like the method saying "I can't tell you exactly what I compute when you call me, but if you ever give me a `Connection`, I can give you the result back!" Now, since `Reader[Connection, A]` is a monad, it by definition gives some way to sequence operations that all return `Reader[Connection, ?]` together, which is usually its `.flatMap` method in Scala. So if we had methods to get a user given an id, get an account given a user, etc. that all returned `Reader[Connection, ?]`, then putting them together in another method might look something like this: def getUserAccount(userId: Long): Reader[Connection, Account] = { for { user &lt;- getUser(userId) account &lt;- getAccount(user) } yield account } But how do we get the result out once we have a `Connection` handy? Well, we just provide a method called `run` on the Reader object that, when called with a `Connection` , will give you back the result of the whole computation, passing the `Connection` object into each subcomputation that uses it. So we could do val readerResult: Reader[Connection, Account] = getUserAccount(userId) val connection: Connection = database.getConnection() val actualAccount: Account = readerResult.run(connection) and `actualAccount` would hold the result of actually running the whole computation. The State monad is pretty similar, but instead of the thing that we thread through our computations being a shared environment that we read from, it's a shared (immutable) state that we can read from and write to as we progress through the computation. I won't go through as much a spiel for State as for Reader since this is already a bit long, but a good example of using the State monad is using it in a purely functional RNG. You would have operations that use the current integer value of the state to return the operation's result, and also transform the input state value to an output state value (the next seed for the RNG). My explanations sort of explained the usage, but not the implementation as much. I think the implementation is better to understand if you'd like a more intuitive understanding of it. The long and short of it is that `Reader[Connection, A]` is basically just a wrapper around `Connection =&gt; A` (meaning that instead of returning an `A`, you return another function that gives you the result when you pass it a `Connection`. Similarly, `State[StateType, A]` is a wrapper around returning a function from the state type to a result and a new statetype (essentially `StateType =&gt; (A, StateType)`). If you're interested, there are some really good talks on monads like this that are helpful. [Rob Norris' talk on monads](https://www.youtube.com/watch?v=30q6BkBv5MY&amp;t=2665s) is cool and gives an alright understanding of what monads are used for in general. If you'd like to understand the Reader monad, then there's a [great talk by Runar Bjarnason](https://www.youtube.com/watch?v=ZasXwtTRkio) on using it for dependency injection.
This is wonderfully clear. Thank you! The reader monad is immediately useful to what I'm doing. Going to put that to work on Monday.
Catch-up unread emails, filling the timesheets...
&gt; Nothing stopping you from changing keyboard shortcut for those functionalities. OS X lets you do that. For ALL of them? And about about new bindings clashing with something program makes use of? Also what about Ctrl+S? Not every application (well, almost none, to be precise) allow remapping of things like that. &gt; You can write a plist and use launchd to start scripts at the start up Not really much better than equally clumsy and complicated way of doing it through "Automation" app. &gt; even add it to login items of your account Nope. You can do that on Windows or most DE in Linux, but on Mac you can only do that with "App"s. With normal software - you're fresh out of luck. &gt; But its far easier than on windows last time I checked Maybe you checked it back in Windows 3 days? Because ever since **at least** Win95 (so for the past 25 years) it was as simple as creating shortcut pointing to executable and dragging it into "Autostart" folder in your start menu (both can be done at the same time if you drag with RMB and select "create shortcut" at the end). It literally doesn't get any easier. And, unlike Mac, it works with any type of software or even normal files. &gt; Most IDEs like Intellij lets you change keyboard shortcuts. Except that some of them clash with system ones, other straight up don't work for inexplicable reasons. And, by now, you need to reassign dozens of shortcuts in every cross-platform program, then also reassign every system shortcut, and then also reassign shortcuts in other software so they don't clash with new system ones... And at that point you spent days tweaking system and suffering instead of working. &gt; Most of your complaints seem to be about Macs having a different workflow from linux and windows. From EVERY other OS, you mean. Having to basically ditch every other hardware and software in existence to be able to comfortably use Mac is a fairly step price for using something that provides equal or even subpar experience. Also one that is 100% Mac-unique and does interfere with work and is not related to learning arcane workflow - read file limits. Yesterday i spent couple hours debugging issue that was caused by Mac just deciding to fail all file operations due to me having too much files open simultaneously. For an alleged "OS for professionals", having such pathetic open file limit (that is not even dictated by hardware as it can be increased through creating some arbitrary config files in random directories) that merely running couple IDEs, browser and dev database causes file operations to fail.
Blink.
I don't think you will notice a huge difference. I find it a little better than ergodox, especially in the programmability department. If you already have an ergodox I'm not sure switching is worth it.
My builds are fast... Stop small project shaming! Seriously, somewhere around scala 2.12.* and sbt 1.*.0 release (IIRC), there was substantial improvement in incremental compilation speed. It fell below the threshold, where it was no longer an issue. I even wondered why this progress wasn't adequately advertised by Scala team. What remains a PITA, is sbt's startup time and hostile takeover of command line.
Impressed by how many videos with complex topics. Nice post
I wish every Scala conference would publish videos with such a speed and quality.
The bazel talk is really nice. If you are curious about why bazel (TL;DR: it's fast), Wix's experience in a 10M line scala repo is very interesting: &amp;#x200B; [**https://youtu.be/lT8zpzyJW7I**](https://youtu.be/lT8zpzyJW7I)
What does UA stand for? Even their own website doesn't obviously explain.
I guess it's https://en.wikipedia.org/wiki/.ua
I'm probably getting a laptop so the situation would be worse on that. Maybe I will need to persuade them that we need a server room with some powerful linux boxes in it for local testing, then just connect to those from Windows. Would an i9 be good for a server or do people use Xeons for that kind of thing? I have no idea. I will take a closer look at your WSL guide when I have the chance. I haven't started the job yet so I'll just be playing around with my personal laptop at home in the meantime.
Thanks, not thinking about switching at the moment, but was always curious about the Model 01. What I like about the Kinesis is the bowl shaped key layout. Don't you miss that? It was the things why I don't like the Ergodox. Though my small fingers might play a role here.
miss it a little yeah. I like the thumb configuration on M01 a lot more though.
UA is Ukraine. Western European country. Chernobyl, Crimea.
For compilation, you want the highest clock rate you can get, and the number of cores isn't as important. Hyperthreading usually adds about a 20% improvement on top. So i9 as a single-job CI machine or a remote XClient works fine. For servers that have multiple things going on, like a full on build server that runs multiple CI pipelines at once, you want more cores, more parallelism, more throughput. So going with Xeon is pretty much mandatory there.
Thanks!
Thank you!
I don't know but I don't count the teeth of a gifted horse. 
Thanks and would you remember how that's done? The setting seems quite hard to find
Do you know about this https://izumi.7mind.io/latest/release/doc/logstage/? 
I had the Kinesis Advantage before and have the ergodox now so I can agree with you the bowl layout of the Kinesis Advantage is the best format I've tried so far. (It's too bad they don't try innovating on that end by making the keyboard smaller or layers of programmable keys)
Yeah, and you seem to be not alone in liking the thumb config a lot more. Have read that from others as well. 
Yeah, ever since trying it using a flat keyboard feels... "wrong". I still have the hope that someone takes the open source dactyl keyboard and uses the advances in 3d printing to produce it as a consumer product (including layers and maybe a different thumb layout like the Model 01).
I did not. It looks cool, but I have an aversion to frameworks that layer their encoder format (json / text / avro) etc on top of SLF4J, instead of below it, because it means that library dependencies that are only SLF4J aware will not be able to use the same format. I do think that SLF4J would be much easier to work with if it just had generics, i.e. public &lt;T extends MessageWriter&gt; void debug(T message); or something that was more "typeclassy", but that's another topic.
There might be, but will it be enough of a performance but to matter? Sometimes getting code written well and maintainable is more important than optimization. Use play-json and if it's not fast enough, use something else. :) 
If you aware about efficiency and safety then try jsoniter-scala: https://github.com/plokhotnyuk/jsoniter-scala It has integration with akka-http: https://github.com/hseeberger/akka-http-json/pull/205 And can be easy integrated with play-framework too: https://github.com/plokhotnyuk/play/commit/f891822d695c270df5179e3d7664c267ae3cf8db Here are latest results of benchmarks which compare parsing and serialization performance of Jsoniter Scala with Circe, Play-JSON, Jackson, uPickle, AVSystem's scala-commons, etc. on different JVMs: https://plokhotnyuk.github.io/jsoniter-scala/ Here are the same numbers for jsoniter-scala with OpenJDK 11 which are normalized to number of parsed/serialized bytes: https://docs.google.com/spreadsheets/d/1IxIvLoLlLb0bxUaRgSsaaRuXV0RUQ3I04vFqhDc2Bt8/edit?usp=sharing
You can replace var found = 0 elems(pos) match { case ... =&gt; found = ... case ... =&gt; found =... } with val found = elems(pos) match { case ... =&gt; ... case ... =&gt; ... } because \`match\` is an expression in Scala, not a statement.
`for (i &lt;- operators.indices)` is a nice way to indicate the intent more clearly, \*and\* avoid off-by-one-errors but actually you aren't using the index, so you might as well just `for (op &lt;- operators)` and not have `i` at all
Python. Got fed up with so many types and stuff. 
Not unusual at all in my experience. 
If it is a dataframe, you can use `limit`. Or `sample` to reduce the number of row for testing. ``` def downSampling(df: Dataframe, targetQuantity: Int) : Dataframe = { def.limit(targetQuantity) } ```
I kind of glossed over it because I didn't want to get hung up of the implementation details but using quite a bit of logic to choose which rows to keep in the data sample. 
Limit will take the top N rows so order matter. But sample will do the sampling for you. You can do `sample(true, 0.5)` to keep 50% of the rows. 
Lucid Software | Software Engineer in Application, Dev Tools, or Site Reliability Engineering | Salt Lake City, UT, USA | Onsite | Full Time Lucid Software is the creators of Lucidchart and Lucidpress - world-class web applications that push the boundaries of what is possible in the browser. The entire application back end is written in Scala. The frontend stack uses TypeScript, Angular, WebGL, and the Google Closure Compiler. The build system is Bazel. We are hosted in AWS. We are a ~500 person company outside of Salt Lake City Utah, that is growing like mad. We are looking for - Application engineers to help build applications that users love. - Development tools engineers to help build a development experience that engineers love. - Site reliability engineers to help build a scalable, reliable, and performant production system. More information and the application can be found here - [Application Engineer](https://www.golucid.co/careers/f9cb83be-e016-4be5-91dc-598e17e8d04c?team=Engineering) - [Development Tools Engineer](https://www.golucid.co/careers/c8de139c-6da7-44dc-a4af-95052aa2a086?team=Engineering) - [Site Reliability Engineer](https://www.golucid.co/careers/be16cacc-4cd3-4be0-9ec0-070646f9ec69?team=Engineering) Please DM me if you would like to chat about any of the positions. Please mention this Reddit thread if you apply :D
Please instead post this in the Who's Hiring thread, which is currently the very top thread in the subreddit. 
[OpenLaw.io](https://openlaw.io/) | Software Engineer (Application) | Global | Remote | Full Time Hi all! I‚Äôm VP Eng at OpenLaw.io ‚Äî we‚Äôre focused on the creation and execution of smart legal agreements on the blockchain, using a domain-specific language written in Scala. Essentially we are providing an international platform where people can share and collaborate on legal agreements, lowering the barrier of entry and friction involved in many legal services. We have a strong focus on open-sourcing our work as well. We‚Äôre a 100% remote-first team, globally distributed and diverse. We care immensely about inclusivity and humane development in all aspects of our daily engineering and company practices. In short, we care a lot about ‚Äúhow we work,‚Äù not just the work we produce. Currently looking for a Sr. Engineer with existing Scala/FP knowledge to help us scale our core application development. Experience with distributed remote teams is a strong plus. We‚Äôre still a small team, so everyone coming in will be a big part of helping us establish our culture and practices. Feel free to also message me directly with any questions you might have! [https://careers.openlaw.io/p/41ce1da19956-software-engineer-application](https://careers.openlaw.io/p/41ce1da19956-software-engineer-application)
So the problem of having more than one instance of a typeclass for a type and any issues that arise from it is called "typeclass coherence". In Haskell, typeclass coherence is rigidly enforced by the compiler, when people want to use more than one instance they create what are called `newtype`s. `newtype`s are similar to phantom types, they exists only at compile time and have no runtime representation. Officially there is no support for `newtype`s in scala, however there are a few ways to encode them still. There are some people that typeclass coherence isn't a problem in scala, as you can always just explicitly pass in typeclass instances, or rely on explicitly importing instances instead of resolving an instance via the parts of the type.
To make a suggestion to change to play-json, the performance difference does matter. Even if it's the same performance
Eastern European, not Western
I do this regularly just by setting a function with Dataframe type in and out. You could also consider writing your own Spark Transformers too. Actually another nice thing is that you can use implicits to create methods for you Dataframes even. So you can chain methods. 
Looking at the implementation, `unsubscribe(ActorRef, Class)` can do a lot more work than `unsubscribe(ActorRef)`. The former does extra subclass checking, recursive function calls, and rebuilding of data structures. This is the main workhorse for `unsubscribe(ActorRef)` def removeValue(value: V): Changes = mergeChangesByKey(subkeys flatMap (_ removeValue value)) This is the main workhorse for `unsubscribe(ActorRef, Class)` def removeValue(key: K, value: V): Changes = // the reason for not using the values in the returned diff is that we need to // go through the whole tree to find all values for the "changed" keys in other // parts of the tree as well, since new nodes might have been created mergeChangesByKey(innerRemoveValue(key, value)) map { case (k, _) ‚áí (k, findValues(k)) } // this will return the keys and values to be removed from the cache protected def innerRemoveValue(key: K, value: V): Changes = { var found = false val ch = subkeys flatMap { n ‚áí if (sc.isSubclass(key, n.key)) { found = true n.innerRemoveValue(key, value) } else Nil } if (!found) { val n = new Nonroot(root, key, values) integrate(n) ++ n.removeValue(value) } else ch } protected final def findValues(key: K): Set[V] = root.innerFindValues(key) protected def innerFindValues(key: K): Set[V] = (Set.empty[V] /: subkeys) { (s, n) ‚áí if (sc.isSubclass(key, n.key)) s ++ n.innerFindValues(key) else s } private def integrate(n: Nonroot[K, V]): Changes = { val (subsub, sub) = subkeys partition (k ‚áí sc.isSubclass(k.key, n.key)) subkeys = sub :+ n n.subkeys = if (subsub.nonEmpty) subsub else n.subkeys n.subkeys ++= findSubKeysExcept(n.key, n.subkeys).map(k ‚áí new Nonroot(root, k, values)) n.subkeys.map(n ‚áí (n.key, n.values.toSet)) } protected final def findSubKeysExcept(key: K, except: Vector[Nonroot[K, V]]): Set[K] = root.innerFindSubKeys(key, except) protected def innerFindSubKeys(key: K, except: Vector[Nonroot[K, V]]): Set[K] = (Set.empty[K] /: subkeys) { (s, n) ‚áí if (sc.isEqual(key, n.key)) s else n.innerFindSubKeys(key, except) ++ { if (sc.isSubclass(n.key, key) &amp;&amp; !except.exists(e ‚áí sc.isEqual(key, e.key))) s + n.key else s } } And the recursive part // this will return the keys and values to be removed from the cache override def innerRemoveValue(key: K, value: V): Changes = { // break the recursion on super when key is found and transition to recursive remove-from-set if (sc.isEqual(key, this.key)) removeValue(value) else super.innerRemoveValue(key, value) } override def removeValue(value: V): Changes = { val kids = subkeys flatMap (_ removeValue value) if (values contains value) { values -= value kids :+ ((key, Set(value))) } else kids } override def innerFindValues(key: K): Set[V] = if (sc.isEqual(key, this.key)) values else super.innerFindValues(key) It's kinda hard to follow, but they both call `mergeChangesByKey` and `subkeys flatMap (_ removeValue value)`. But `unsubscribe(ActorRef, Class)` does all that other stuff too. On top of it that, the implementation uses mutable references to immutable data structures instead of mutable data structures, which can mean a lot of intermediate not-strictly-necessary allocated structures. So as you get more and more subscriptions, every `unsubscribe(ActorRef, Class)` is going to have a lot more work to do. On top of that, this sits inside of a block synchronized on all the subscriptions, and `unsubscribe(ActorRef, Class)` calls take longer than `unsubscribe(ActorRef)` calls, so as you make more you are more `unsubscribe(ActorRef, Class)` calls you are more likely to end up in contention and waiting for the synchronization to allow the thread through, slowing everything down. I'm not surprised you're seeing a performance drop, though a 90% drop is perhaps more than I would have thought.
What about performance against spray-json? Do you plan to add it to the benchmark?
Phantom types == opaque type == value classes? They seem to have lots of names in Scala. 
I have a lot functions with dataframe as parameters for this reason. The difference is we use a small testing dataset with only the cases to test in unit testing and reduced datasets for smoke tests and acceptance testing.
No they're not the same thing, they do have overlap in the problems they're attempting to solve. Value classes in particular are the most different, they do have runtime representations. The objective of value classes is to influence the layout of objects in memory and prevent unnecessary allocations and indirection where possible. JVM limitations makes the Scala implementation of value classes look like a lot like `newtype`s, since the ability to affect object layout in memory from bytecode is limited. Project Valhalla is Oracle's attempt at this, and because they can change the VM, will be much better at addressing issues of layout. Opaque types are the closest thing to a Scala `newtype`, where accomplishing what `newtype`s do in Haskell for Scala is the explicit intent. The objective is to create a new type from the existing representation, that have no other relations the original type had. You can think of it as the dual to inheritance, instead you disown everything from the "super" type. Phantom types also exists in Haskell and pretty much any other language with parametric polymorphism. It's just a type parameter that doesn't exists or isn't used on the right hand side of a definition. When combined with type erasure(a JVM feature specifically) these can be used to create a large number of types that all share the same runtime representation.
Databricks | Software Engineer (Multiple Roles) | San Francisco, Amsterdam | Onsite | Full Time Databricks is one of the fastest growing startups (recently valued at [$2.75B](https://databricks.com/company/newsroom/press-releases/databricks-250-million-funding-supports-explosive-growth-and-global-demand-for-unified-analytics-brings-valuation-to-2-75-billion)), and we are creating a multi-cloud unified analytics platform. We are the creators of the popular Apache Spark cluster computing framework, and are pushing forward the boundaries of Big-Data and AI as well as building the infrastructure needed to democratize access to these technologies. Our systems are heavily Scala based, from Spark, to our backend services, to all our tooling. We have one of the best Scala developer environments in the world, with [very fast builds](https://databricks.com/blog/2019/02/27/speedy-scala-builds-with-bazel-at-databricks.html) and [declarative infrastructure](https://databricks.com/blog/2017/06/26/declarative-infrastructure-jsonnet-templating-language.html) letting you focus on designing your code and systems rather than spending time fighting your tooling. Databricks is built on a lot of deep tech, and continue to face a lot of difficult technical challenges as we push forward to give everyone access to the most cutting edge Dig Data and AI technology. We're hiring for all engineering roles, and need people to work on [web applications](https://databricks.com/company/careers?gh_jid=4037010002), [backend services](https://databricks.com/company/careers?gh_jid=4019852002), [data engineering](https://databricks.com/company/careers?gh_jid=4103098002), [Spark](https://databricks.com/company/careers?gh_jid=4019857002), my own team of [developer tools](https://databricks.com/company/careers?gh_jid=4023153002), and [many other things](https://databricks.com/company/careers). Happy to answer any questions!
[Python 5](https://www.youtube.com/watch?v=BvECNQRrjCY) is the best programming language!
Note that if you did \`\`\` def downSampling(targetQuantity: Int)(df: DataFrame): DataFrame = ... \`\`\` &amp;#x200B; You can do something like \`df.transform(downSampling(10))\`
Yup!
Do you have any engineering roles in Singapore?
Unfortunately not, engineering is primarily in SF and Amsterdam
No problems! I actually hadn't seen this - thanks
I have started to add benchmarks for spray-json: https://github.com/plokhotnyuk/jsoniter-scala/pull/274 Feel free to review or contribute for that branch. BTW, spray-json maintainers react positively on feedback from jsoniter-scala benchmarks. About 4 months ago the have fixed following security issues based on provided pull requests: https://github.com/spray/spray-json/issues/278 https://github.com/spray/spray-json/issues/277 Moreover, they reused code for fast generation of strings with 0 hash code in their tests: https://github.com/spray/spray-json/blob/c8e106fe41dad3916d54dcbf90e3aa5599d4d461/src/test/scala/spray/json/HashCodeCollider.scala And, have opened an issue for Scala team to provide a hash map that will not be so sensitive for collisions: https://github.com/scala/bug/issues/11203
Thanks for this detailed answer. Indeed, there seems to have a lot more going on when unsubscribing of a specific class. I think that in my case, the performance drop comes from the fact the unsuscribe are all simultaneous and the it end up breaking a timeout in a ask to one of my actor down the lane. Althought I'm not sure about this, the drop could even be worse than 90%, as I managed to break 300k actors using the unsubscribe(ActorRef) and I haven't manage to make it break 
Lol, common mistake here. 
[Scienaptic Systems](https://www.scienaptic.com) | Scala Developer - Application Development | Bangalore, Karnataka, India | ONSITE | Full Time Scienaptic is a AI powered credit underwriting company equipping banks with sharper tools to improve credit decisioning processes. We are looking for Scala Engineers with 3+ years of application development experience in one of the Web Frameworks for our products at Scienaptic Systems. Please share your detailed resume to [**kusumakar@scienaptic.com**](mailto:kusumakar@scienaptic.com) 
Does anyone know if there's anywhere to find the slides for some of these presentations? I couldn't find them on the ScalaUA conference website.
This is a really cool project! i've long thought about how useful a something like this would be. &amp;#x200B; Do you have any thoughts about how you set up all your unique types to use instead base types? Like using UserId instead of String for example? Do you just have a bunch of case classes that extend AnyVal? I could never figure out how to do that without introducing a lot of boilerplate.
&gt; I could never figure out how to do that without introducing a lot of boilerplate. Unfortunately I think it's just a lot of boilerplate. At least it's 'write once' boilerplate. I've found namespacing them inside the companion object (ie `Account.Name`, `Payee.Name`) makes it a lot easier to manage. Implicits, such as `Atom`, `JsonCodec`, `Show` etc can all be derived programatically given functions `String =&gt; Account.Name` and `AccountName =&gt; String`, so you can have some class your companion object can extend that gives you all the same typeclasses that your inner type has, that you care about.
Opaque types are on their way: [https://github.com/scala/scala-dev/issues/504](https://github.com/scala/scala-dev/issues/504)
https://github.com/estatico/scala-newtype has worked well for us
What about something like, case class Account(name: String @@ thisFieldOrSomethingIdk, ...) case class Info(name: Account#name) case class OtherThing(asdf: Info#name) // equivalent type to Account#name Almost like a type projection except it goes to the type of the field.
Short .. right to the point. Its a good one. Would love to see a full length video on the same topic! 
Great talk especially for those who are unfamiliar with the concept. tl;dw don't throw exceptions, use a sealed trait to enumerate error types and return \`Either\[CustomError, Result\]\` instead.
Scala needs proper support for union types before this can be a reasonable expectation. `Either` does *not* count.
We went with spray-json in the past for performance reason. Worst decision ever -\_- It took a lot of pain for use to switch to Circe but the pain was worth it :)
It's a great 10 minutes presentation and `Either` is great for small examples but not for large applications. For example, in this talk `IO` effects (reading the file) are not being considered (it might be due to time constraints though). If you follow the rabbit hole you'll soon end up with `EitherT[IO, MyError, A]` and here you have two error channels: the failures in `IO` and the left side of the `Either`. Also working with monad transformers is very cumbersome and most of the time you need to specify the types cause the scala compiler can't infer them. Error handling is hard and there's not a single way to get it done. This is not even solved in Haskell where you also have async exceptions even though there are some conventions. Nowadays there's `ZIO[R, E, A]` which defines a way to handle errors or you can just use `IO[A]` and use the `ApplicativeError/MonadError` instances to do so. In both cases you could use classy prisms to derive instances and benefit from typed errors.
CCRi | Software Engineer, Data Scientist | Charlottesville, VA, USA | Onsite | Full Time CCRi provides analytical development services with a geospatial focus for government and commercial clients. We're about 130 people and are always looking to hire people who want to work on tough problems. I also personally think we have great retirement benefits and vacation policy. Nearly all of our projects involve writing in Scala and one of our biggest is the opensource [geomesa](https://www.geomesa.org/) which is for indexing and querying spatio-temporal data on various cloud platforms. Other things we tend to work on are applications with streaming data (Kafka), analytic pipelines (Spark). We also do machine learning on text, imagery, and video (mostly in python but would be a bonus to find someone to help improve our cross language interop). I should also mention that many of our contracts require US citizenship and we generally can't sponsor foreign workers. If that all sounds cool please apply at http://www.ccri.com/jobs/
What's wrong with (from what I understand is) the suggested approach of using a `sealed trait` enumerating the error type and doing `Either[ErrorType, ResultType]`?
* It's a run-time performance hit. * Pattern matching the return value of every single call that can fail is ugly, especially if there are several such calls in a row. * The above problems get exponentially worse if you have more than one `ErrorType`, which you almost certainly will. * Explicitly wrapping every return is ugly. * Unwrapping and re-wrapping errors from every single call site is ugly. Long story short: Because you'll cause the problems that exceptions were invented to solve.
&gt;It's a run-time performance hit Premature optimization is the root of all evil, as they say. I'd dare say most application code won't suffer significantly from additional abstraction (since most of your performance bottlenecks will be in hotspots anyways), so you shouldn't be so quick to dismiss that, especially considering how poorly performing most exception creation/throwing is. &gt;Pattern matching the return value of every single call that can fail is ugly, especially if there are several such calls in a row. And this is why `Either` was made to be monadic, so that you can make longer chains of operations without having to pattern match every time. Granted, you'll still have to pattern match later, but it's not as if it's much more verbose than checking a return error code. And if you're looking for something only as verbose as an exception, you can probably do the same thing by ensuring the operations that would regularly be wrapped in a try catch block all fall under the same `ErrorType`, chain them all together, and handle failures at the end. &gt;The above problems get exponentially worse if you have more than one ErrorType, which you almost certainly will. That's pretty fair, it tends to get much more hairy at the boundaries or when trying to lift other error types into higher error types. `Either` definitely isn't a perfect solution, but it can be nice at the micro level. &gt;Long story short: Because you'll cause the problems that exceptions were invented to solve. Erm, well exceptions as they're realized in most languages solve it rather poorly. They're convenient because you don't have to think about the specifics of where to return what, but they make code much harder to reason about. At least if they're unchecked exceptions. Checked exceptions have the advantage over this sort of monadic error handling because they provide the same amount of verification with less worry about the boilerplate. As for your original comment about proper union types, [does this feature in Dotty look similar?](https://dotty.epfl.ch/docs/reference/new-types/union-types.html)
&gt;how poorly performing most exception creation/throwing is. On the JVM, throwing is not slow. What's slow is constructing `Throwable` objects, specifically generating the stack trace. Still, you have a valid point. One extra heap allocation isn't going to matter much, compared to the stack-trace overhead. &gt;Checked exceptions have the advantage over this sort of monadic error handling because they provide the same amount of verification with less worry about the boilerplate. Indeed. Scala should have checked exceptions, but integrated into the type system. For example, suppose you have a function `readSomeText` that either returns a `String` or throws an `IOException`. In my opinion, checked exceptions should be part of the return type. def readSomeText(): String | throw IOException = ‚Ä¶ Then, when you call `readSomeText`, the return value you get is not `String`, but the aforementioned union. You can get the String, but this will potentially throw the `IOException`. // The type of `text` is String | throw IOException val text = readSomeText() // You can explicitly narrow the type to String, but IOException // may be thrown from here as a result. println(text: String) But you can only do that from a scope whose return type is also assignable from `throw IOException`. def printSomeText(): Unit = { // OK val text = readSomeText() // Compile error: `throw IOException` incompatible with return // type `Unit`. println(text: String) } def printSomeTextOrFail(): Unit | throw IOException = { // OK val text = readSomeText() // OK, but IOException may be re-thrown from here. println(text: String) } You can handle both success and failure at once, by pattern matching. This would replace the `catch` construct (except for unchecked exceptions). readSomeText() match { case s: String =&gt; println(s) case e: throw IOException =&gt; e.printStackTrace() } If you pass a union of `T | throw E` to a generic function, such as `Some`, it is boxed. // The type of `text` is Some[String | throw IOException] val text = Some(readSomeText()) But if you simply discard the result of a call that has checked exceptions, then the checked exceptions pass through the call site. def readButDoNothing(): Unit | throw IOException = { // OK. If IOException is thrown, it passes through to the caller. readSomeText() } def readButDoNothing2(): Unit = { // Compile error: `throw IOException` incompatible with return // type `Unit`. readSomeText() } If all else fails, you can force the exception to become unchecked. val text = readSomeText() // Unchecked IOException thrown from here. println(text.asInstanceOf[String]) You can define extension methods for these unions, making them act like monads. (This will still involve a heap allocation, to box the thrown exception.) def (v: T | throw E) map[T, E, U](f: T =&gt; U): U | throw E = { v match { case e: throw E =&gt; e case v: T =&gt; f(v) } } // Of course, the mapping function can itself throw a checked exception: val y = readSomeText().map(text =&gt; { if (text.isEmpty) throw new IllegalArgumentException("String is empty!") else text.toUpperCase }) // Type of `y` is String | throw IOException | throw IllegalArgumentException &gt;As for your original comment about proper union types, [does this feature in Dotty look similar?](https://dotty.epfl.ch/docs/reference/new-types/union-types.html) Yes, I know Dotty has union types, and I expect they'll be a great help for error handling in Scala. Dotty isn't Scala yet, though.
What was wrong with Circe? As for me it is more handy and efficient than both (play-json and spray-json). But if performance and safety are also required you definitely should try jsoniter-scala :)
Recently just watched video about ZIO in Scala UA, and the idea of it excites me a lot. Therefore, now I end up trying to learn Scalaz and ZIO
Oooohh, the extension methods for union types is something I hadn‚Äôt seen before, that is *super* cool! Also, that does look neater in general. How would you handle methods that can potentially throw a few exceptions? Would the exception types all be unioned together in the `throw` clause as well?
&gt; If you follow the rabbit hole you'll soon end up with `EitherT[IO, MyError, A]` and here you have two error channels: the failures in `IO` and the left side of the `Either`. This is true, but I don't think it's such a big problem in practice. I often see errors separated into two categories; errors that the application is expected to handle, and errors that should cause the application to crash or be handled by a generic high level handler (the reactive manifesto calls these errors and failures at a service level). The errors go in the left side of the `Either` and failures go in the `IO` or `Future`. It would be really nice if `IO`/`Future` started having typed exceptions after we get union types in dotty. Then the above wouldn't just be convention.
&gt; Got fed up with so many types and stuff. Curious to know what exactly you got stuck on. Maybe we can help.
&gt;How would you handle methods that can potentially throw a few exceptions? Would the exception types all be unioned together in the throw clause as well? Right. `A | throw B | throw C` &gt;also, do you think union types without checked exceptions will still help with error handling? Yes. You can do some of the stuff above in Dotty right now (in theory, anyway; I didn't try). But then there's no distinction between returning a `Throwable` and throwing it, and exceptions have to be manually checked for and returned.
So you could do a slightly improved version of `Either` right now in Dotty (like there are no checked exceptions, but union types prevent some of the pain)? Also, I‚Äôd be interested to see how interop with Java would work in this case, since Java binaries wouldn‚Äôt contained checked exception info (if I had to guess).
That's exactly what we do but using the `MonadError` instance instead. We handle the business errors that need handling using classy prisms and threat other errors as unrecoverable failures (let it crash) that might be or not handled at the top level of the application. Union types are promising. I don't have any hope for `Future` as I'm not an user but I think we'll be all set to improve typed errors in `IO/Task`s.
Same here :P
So instead of \`possiblyFailingFunction().map(x =&gt; doSomething(x))\` you want to have \`val x = possiblyFailingFunction; doSomething(x))\` or \`doSomething(possiblyFailingFunction())\` under the condition that the context indicates that the same or a compatible exception might be thrown. I agree that this syntax can be more convenient. However... 1. It makes error handling less clear. Imagine someone calls \`possiblyFailingFunction\` twice. When only looking at the local code (not even the signature of the method in which the function is called twice), they might think everything is fine. However, in reality, they might want to execute the function a second time, even if the first function fails (and then throw/return one of the exceptions, or maybe a specific one), instead of not having the second call being executed. I think this alone is a very good reason not to do what you suggest. 2. Is the nicer syntax really worth all the problems that come with it? You will have to define a scala internal error type (e.g. \`Throwable\`). What if someone want their own/custom errortype, that is more restricted or less restricted? Do we want to make one type special? I'm don't really think it is worth it.
I'm crossposting this if anyone is interested in a story. They (re)wrote some Scala services in Rust.
&gt;It makes error handling less clear. Imagine someone calls \`possiblyFailingFunction\` twice. When only looking at the local code (not even the signature of the method in which the function is called twice), they might think everything is fine. However, in reality, they might want to execute the function a second time, even if the first function fails (and then throw/return one of the exceptions, or maybe a specific one), instead of not having the second call being executed. But that's exactly what would happen. val x = possiblyFailingFunction() val y = possiblyFailingFunction() // At this point, possiblyFailingFunction has been executed twice, // regardless of whether the first one succeeded. Execution continues // to the match block below, even if one or both calls failed. (x, y) match { case (e: throw _, _) =&gt; // Throw the exception from the first call, if any. throw e case (_, e: throw _) =&gt; // Throw the exception from the second call, if any. throw e case _ =&gt; // If both calls succeeded, return the result of the // second call. y } If anything, this could be confusing for the *opposite* reason: one would ordinarily expect that, if the first call to `possiblyFailingFunction` throws, the second call does *not* happen, because that's how exceptions currently work. But you'll have to deal with the potential exception in order to use the function's return value, so the exception probably won't get lost. But there's one scenario where exceptions *could* be lost: val x = possiblyFailingFunction() val y = possiblyFailingFunction() if (someUnrelatedCondition) { // If y is an exception, it is silently lost! x } else { // Likewise, if x is an exception, it is silently lost. y } I'm not sure how best to fix this pitfall. &gt;Is the nicer syntax really worth all the problems that come with it? Nicer syntax isn't the only reason for making this change. It also adds compile-time safety to the language, and Scala is all about compile-time safety. &gt;You will have to define a scala internal error type (e.g. \`Throwable\`). Why? `Throwable` already exists. &gt;What if someone want their own/custom errortype, that is more restricted or less restricted? Do we want to make one type special? I'm don't really think it is worth it. You mean to make an exception class unchecked? There could be an annotation for that. @unchecked class ExampleException extends Exception def doStuff(): Unit = { // Allowed, because ExampleException is always unchecked. throw new ExampleException } It could also be applied to individual exception objects, to make normally-checked exceptions unchecked. def doStuff(): Unit = { // Compile error throw new IOException } def doStuff2(): Unit = { // OK throw (new IOException(): @unchecked) } If it's done this way, you don't have to add any syntax or types to the language at all. `@unchecked` is already in the standard library, and the type ascription syntax (`new IOException(): @unchecked`) is already in the language. [See the API docs.](https://www.scala-lang.org/api/current/scala/unchecked.html) Of course, a new annotation could be introduced instead of overloading `@unchecked`.
&gt;If anything, this could be confusing for the &gt; &gt;opposite &gt; &gt; reason: I think I misunderstand your proposal then. So, what is the benefit of `Result | throw Error` over `Result | Error` then (assumed that `Error` is monadic)? Only performance? &gt;You mean to make an exception class unchecked? No, I mean I don't want to use `Throwable` in my code, because it e.g. offers methods that I don't want my error type to have. Or why am I forced to make my own errortype extend `Throwable` if it does not give me anything?
Honestly I find this a bit of a disappointing read; it teases a lot but mostly covers boring bits (we tried a few times, people didn't let us finally people let us, problems went away) and didn't really cover any of the interesting topics that I would be interested in if I was considering moving a service from Scala to Rust: - Why did people not let you initially? - Why did people change their mind? How did Rust end up going from "Asses" to "Adopt" on the Technology Radar, or did it not? - It describes implementing tooling, and says the there were concerns if the tools were production ready. What tooling was implemented, how long did it take? - What does "Rust Team" mean, and how did you end up being labelled such a team without even knowing it? - How complex was the service you replaced? Taking "just a few days" to implement the application, how big was it? That seems like an incredibly short time. - How much more load could it handle without crashing? 2x? 10x? 100x? - Why was the original thing consuming great amounts of memory anyway? Was it a bug? A memory leak? An inherent property of the everything-is-a-boxed-object nature of the JVM? - When the original thing crashed with 100% CPU load, was that 100% caused by GC or were there other inefficiencies? - It concludes that Rust is "if it compiles it runs"; most people refer to Scala the same way. Is there a difference between them, and if so then what? Overall it claims to be a success story, but without further qualification I don't even have enough information to know if it was a success, a sideways change, or a failure by heterogenizing the organization's code to solve problems that could be solved just by fixing bugs. The same would apply if someone moved from Rust to Scala with the same justification (or lack thereof). In particular, if I was someone trying to judge whether/how to adopt Rust in my own projects, this article doesn't really give any actionable insight at all about the things I would definitely want to know.
&gt; Oooohh, the monadic extension methods for union types is something I hadn‚Äôt seen before, that is super cool! It won't work, or at least won't well, though. First, this will pollute _every single type_ with a `map` method, since any type `T` can be upcasted to `T | throws Nothing`. This will likely make every single `map` extension method ambiguous as well. Second, Dotty doesn't know how to destructure union types during implicit search. And for good reason, as it's an impossible problem in general (would require backtracking in the type system). So any solution could only ever be a partial kludge. So this proposal is mostly wishful thinking.
Have they tried: - to use efficient HTTP server for Scale like Blaze or Colossus? - to use efficient JSON or binary serializers like jsoniter-scala or Boopickle? - to use efficient profiler like JFR or async-profiler? - to use efficient load balancer and elastic scaling? - to use efficient algorithms and technologies for their Scala services? 
The article starts off with &gt;But there was also something I really missed: No Nulls and no Exceptions. and then doesn't continue with that train of thought. I care more about how they adjusted to this than if they built a project in Rust or not.
Taking the position of the devils advocate here, at least for the issue they are describing (CPU hitting 100% and causing issues with the JVM memory, having to massively overscale), Rust is going to be miles ahead of anything that JVM can do here, even moreso if we are talking about Scala. The majority of the JVM performance comes from having an overly aggressive escape analysis inliner, which is even designed to handle massive shortcomings like no true value types apart from the core primitives. That and the fact that the JVM you have to massively oversubscribe on memory due to it having a GC. Rust has none of these issues, it has incredibly efficient data-structures (i.e. \`Vec\`) as well as no defaulting to slow immutable datastructures (yes, even an immutable List is slower than an \`Vec\` in Rust because Rust never boxes unless you tell it to do so, furthermore \`Vec\` does cache padding). To deal with the concurrency issues with mutable data-structures, Rust has linear type system. All of this means that Rust is as lean and as fast as C/C++, while having much more sanity in both the language design and the type system.
The videos are well done. I'm working my way through the presentations. The topics so far are intermediate to advanced level. Good conference and topics. Thanks for posting. 
I recently got hooked up on the effect library for Scala, but there are so many libraries to do pure functional programming that makes me feel lost. Particularly, I'm looking at: * cats (and cats-effect, maybe?) * Scalaz 7 (v8 looks very promising but still a long way till release date I guess) * ZIO (Which is described as "Scalaz 8 IO Monad" on [John's blog](http://degoes.net/articles/polymorphic-bifunctors)) I wanted to learn about it and get on the train of FP, but at the same time, I don't know where to start. Right now, I'm playing with ZIO and reading [learning-scalaz](http://eed3si9n.com/learning-scalaz/learning-scalaz.pdf), and I'm not sure if I'm catching it in the right way. So I appreciate if someone can give me some guidelines? Thank you
None of the points you mention necessarily imply that Rust will have a higher chance of successful projects. Because if that was true then every C/C++ project would have succeeded and there would be no such thing as the JVM. 
If this is a case of "We couldn't be arsed to figure out the problems with our Scala app, so we re-wrote it in Rust" then it makes it look like a bad place to work.
The Cats documentation is pretty great. I suggest starting there. https://typelevel.org/cats/
Scala can solve a lot of the issues you want solve. Scala has a stronger type system than TS or Java while having pure functions. It has a decent ecosystem of Scala libraries, but it piggybacks on Java ecosystem which means the actually ecosystem is very large and a lot of good quality libraries. Google is generally your friend for finding them. Threading is a bit of work for most non system languages (C, Rust, Go), but there tools and libraries that can help, like Akka and its actor model. Every toolkit for compilation will have some sort of trouble, but imo sbt and Mill are easier to use, more understandable, and more customizable than the pipelines you need for JS languages. There is a web framework for Scala called Play and there are definitely application frameworks, though they are more likely to come from the Java side. To see if it will really work for you, you should try to build a decently sized application (500-1000 lines) and see how it feels for you. 
Disclaimer: I work in the same company that the blog poster does &gt; In short you seem to be stating that native code is a "silver bullet". Nope, just stating that if you are in his situation, i.e. dealing with extremely high load which forces you to over-provision for JVM like languages, there are better options. &gt; If that was true then every C/C++ project would have succeeded and there would be no such thing as the JVM. Bit of a strawman, I said that C/C++ (and other memory managed languages) have other limitations, i.e. C has no real type system and has too much undefined behaviour, and C++ is a smogusboard of complexity. Rust more or less solves these issues, but also has issues in its own (when it comes to abstraction complexity)
You might also consider Kotlin. It feels a lot like Typescript with many similar benefits. 
How far down the FP route are you thinking of going? Scala with cats can probably take you much further (though I confess I am yet to try the fp-ts library). I so far (with only a little recent experience) don't find TS's type system to be quite as nice as Scalas but that may just be a matter of familiarity. One thing is that I find working with/decoding/encoding json to be harder with scala than JS/TS. If that's a huge part of what you are doing then maybe play around with circe or another scala json library and see how you feel about it. I personally have not much preference between npm/maven or gradle vs similar JS tools - all seem to work well for simple cases. Gradles buildSrc and custom tasks is useful but not always needed. I think scala allows for more terse code too, or at least I've found myself writing more terse scala than TS. Overall I like scala better so far but I'm still new to typescript so it's not the most informed decision comparing my experience with scala to my first impressions of typescript.
I went from TypeScript and Nodejs to Scala. You'll have a very long learning curve ahead of you. You'll need to learn all of Scala, all of FP, all of concurrent programming, much more about type systems, much of reactive programming, much more of OS and computer architecture, much more about data structures, some OOP, some Java, and some JVM. It's a very instructive journey though, and often times the teams you will work on among the way have got brilliant peers to learn from. A lot of the most people I know are know are currently working with Scala. 
I've spent a lot of time with both Typescript (FE) and Scala. Here's what I think: ### Programming Style &amp; Type System You can definitely consider FP to be mainstream in the JS/TS ecosystem, with object spread and libraries like [immer](https://github.com/mweststrate/immer) making immutable copies easy (Immutable updates using immer is nicer than what's in Scala/Haskell!). However, Scala/Haskell offer many cool things which you don't find in TS/JS: * Immutable by default - you can freely pass your data around (and to multiple threads) without worrying about things changing under you. * Nominal typing: I think nominal typing is the right default. I find myself spending a lot longer deciphering type errors in TS than in Scala, because typescript will tell you some specific field deep inside your type hierachy is missing, when what's really happening is that you passed an object of completely different "type" as the input. * First class types (vs bolting types to existing JS libraries) means you never have to question whether you're going crazy or the type definitions from `@types` are wrong. This one is huge for me. * Better type system features leading to highly composeable and reuseable abstractions like * type classes * extension methods * monoids, applicatives, the M-word and many more. These concepts will really open you to new ways to solve problems and because they're well undersood abstractions, it is very easy to understand/use code that relies on these abstractions too. * Scala has better type inference, in my experience but TS is getting better. * I'm a bit fan of union types and literal types so TS definitely wins on this front. Scala 3 will add union types as well as better support for literal types (called singleton types in Scala land) ## Ecosystem * Scala has a fantastic ecosystem for backend development. You can find stable and battle-tested libraries from both the Java and Scala world. Due to the various type system features that Scala has, I personally find it way easier to solve hard problems with them vs Typescript because i'm able to abstract easier and break down the problem to manageable chunks. * Effect types (`IO`) gives you good control over the side effects of your system. It also brings easy parallelism, concurrency, safe resource handling and more! This allows you to make full use of your hardware without needing to run multiple processes. * For frontend, TS definitely wins here unless I know I need to write complex logic in the frontend. There are some great developments in the Scala.js ecosystem (e.g. multiple bindins to React as well as libraries for state management) and I think there's a lot of potential there. * Haven't really used JavaFX (and its Scala wrapper ScalaFX) in anger, but may be a valid alternative for cross platform desktop UI framework to Electron. ## Tooling * Intellij is nice. In terms of intellisense I'd put it on par with TS editing experience. (There are other OSS alternatives too) * SBT and Webpack are probably...annoying in their own ways. Both have a pretty high learning curve and can be quite confusing at times. (There are several other build tools for Scala too) ## My Conclusion For what I do (backend), I'll take Scala over Typescript/node.js any day mainly because the language is more suited for logic-heavy work than TS. I think it's also safe to say that Scala/JVM ecosystem is more mature for backend work and will likely give you better performance as well. (Especailly for CPU-bound workloads)
&gt; Immutable updates using immer is nicer than what's in Scala/Haskell!). Looked at the library and it seems interesting! Have you ever done a comparison between it and using lenses in Haskell/Scala?
Thank you, I will check that out. 
&gt; Scala 3 will add union types as well as better support for literal types Sadly, standard TS approach like the following won't compile: def takesUnion(x: "A" | "B" | "C") There's an open issue somewhere but unclear whether or not it will be fixed. 
huh. What about "A".type | "B".type, etc?
Scala.js, while amazing at thge language level, is limited by: 1) lack of lazy loading support (i.e. the single giant module problem) 2) poor IDE/editor support (which it inherits from Scala) compared to TS + VS Code (phenomenal aid to developer productivity) 3) tiny ecosystem of libraries/frameworks compared to JS/TS (yes, there are some projects that ease the pain of having to manually create facades, but it's far from seamless compared to life on the TS side of the fence). I'd love to use Scala across the board, but until I can draw on the vast JS ecosystem with something akin to `npm install`, *and* have the resulting application feel idiomatic/seamless (without myriad compromises and workarounds), then TS it is on the frontend. That, or the Scala.js ecosystem of native libraries and frameworks evolves hugely in the coming years.
As someone who used both TypeScript and Scala for back-end production code I'd suggest just trying Scala. Some things will be better, some things will be worse: &amp;#x200B; \&gt; the highly variable quality of packages on NPM / Yarn Unlike JS Java has a great standard library, so you end up using way less dependencies. Libraries are pretty good and for some of them there are Scala wrappers available &amp;#x200B; \&gt; leveraging threads in Node is an exercise in patience This one is pretty easy, there're multiple ways to write programs that utilize async I/O and multiple CPUs. Scala standard library includes support for Futures/Promises, and there are libraries to use higher level abstractions like actors and streams. &amp;#x200B; \&gt; the language hews very closely to JS, which isn't always very terse I'd say there's slightly less code because of better support for pattern matching, other than that it's comparable &amp;#x200B; \&gt; JavaScript tooling / packaging / compiling is a bit of a nightmare It's ok if you're writing a standalone application, and a nightmare if the application has to run inside a container (e.g. Spark job). 
Didn't you read the article? The tried: * To come up with reasons for switching to Rust. 
It essentially "records" the mutation you performed on an object, so in theory anything you can do with lenses you can do on a "shapshot". I'd say it's strictly more powerful while being also more ergonomic.
IntelliJ has better support for Scala than VS Code has for Typescript.
Really, I use Eclipse for Scala.js and would be shocked if IntelliJ were anywhere near the sheer speed of TS on VS Code. If you're talking IDE features, sure IntelliJ will win that battle, but in terms of complete lack of lag, VS Code all day every day.
Same - https://github.com/lampepfl/dotty/issues/1551
Well, there's your issue. Writing Scala in Eclipse is like writing JS in Atom. Of course it lags. It took me a while to make the switch to IntelliJ but once I figured it out I never looked back. I haven't used or thought about Eclipse for a long time, but when I compared them IntelliJ definitely had better performance. 
Impressive if true, assumed IntelliJ would lag just like Eclipse. At any rate, current project is Ionic + Angular so TS and VS Code it is. Would love to go seamless hybrid pwa/native with Scala.js but that's not in the cards right now.
It's really terrible compared to Typescript, see this comment: https://github.com/lampepfl/dotty/issues/1551#issuecomment-450602373
I'd love to have a Scala backend, Scala.js frontend, and write the apps in either Scala Native or Scala.js. But sadly that's probably not a widespread opinion in the Scala community, considering 2.12 dropped Android support without batting an eye.
Your choice is React Native and really nothing else, and even then RN requires a fair bit of work/knowledge in iOS and Android. Scala Native is likely years away from being a viable target for native mobile.
Scala Native does not target mobile at all, so it's never going to be viable. I think one mistake they made was trying to reimplement the Java standard library, they should have left that to library authors. Scala developers are probably more likely than average to build their own library when something is missing. Scala.js on React Native just feels like too high of a pile of leaky abstractions. I'd rather write two apps with Kotlin and Swift, or use something like Flutter. 
that's a bit of a shocker but okay lol
Only somehow related to TO's question, but piped up my mind: how does ReasonML fit into the picture? I have years of Java and JavaScript experience, some basic Scala experience. My impression about Scala is: it's past peak. Maybe I am wrong, but odersky and the all supporters will never have the financial background and manpower compared to Facebook to bring forward the language and ecosystem. I have just lurked s bit into reasonml's intro documentation. Looks interesting. What do you think?
Not actively being worked on so unlikely to make it for 3.0, for a recent overview of what's likely to be in 3.0 see https://dotty.epfl.ch/docs/reference/features-classification.html
What's a "stoic/pure function"? I've never heard of this phrase. How is it different than "referential transparency"?
Is this related? https://github.com/liufengyun/stoic/blob/master/README.md
I'd say one should start comparing not syntax nor features but a compiler and runtime. TypeScript compiles down to JS which is being run inside some VM (say V8) which is optimized for certain operations and code executed in a single thread through event loop. Scala alike TS has its own compiler which compiles code into JVM bytecode. Therefore it's just more correct to compare JVM to JS runtime implementation. Thus, the question is: how does JVM compares to V8 (threat both as concrete standard implementations). As the first step I suggest to research in that way to get a correct background. As the second step you should look into actual differences between TS and Scala. Both OOP and FP are merely abstractions over hardware. 
Yeah, Lightbend/EPFL seem to be following Haskell's "avoid success at all costs" by not persuing Android and iOS. Maybe Scala really is a research language, one that accidently found relative success via Akka and Spark. &gt; I'd rather write ~two~ three apps with Kotlin and Swift (and a PWA), or use something like Flutter. Or use a hybrid framework that gives you 3 apps for the price of one (yes, embedded webview won't compete with native performance wrt to raw speed, but for the vast majority of use cases it makes sense if you don't have a team of developers/ton of time to work with). 
I also have years of experience working with both TS and Scala, and can attest this answer is a very good illustration of the diff. 
&gt;Disclaimer: I work in the same company that the blog poster does So instead of playing devil's advocate why not answer some of the questions? ;)
Sure sounds like it. &gt; A main trait of the calculi under study is the introduction of stoic functions. Compared to normal functions which can capture anything from the environment, stoic functions don't capture capabilities or non-stoic functions from the environment. In this sense, they are capability-disciplined.
I have been using Scala and TS for ~5 years and I'm soon leaving my JS/TS job for Scala one. Some quick points: - ScalaFX is an okay option for desktop apps, but distributing that is quite a pain. For mobile dev, Scala isn't an option. - Scala.JS is IMO quite solid, but it's still behind JS. I'd say, it's where JS/TS has been about three years ago. Server-side rendering is non-existent right now, though there were some experiments by author of scalajs-react. However, sharing code that can be shared is almost trivial, and a lot of libs support Scala.JS. - Where I live, TS jobs are more common than Scala jobs, though more often it's a mixed codebase. - A point that I don't like about TS is how it handles boundaries of the application. Deserialize some JSON and you have to make a choice between tons of boilerplate or JS-style obscure runtime bugs. IMO, Scala is much better in that regard. More importantly, &gt; wondered if I was missing out on other typed functional languages Yes. That's very possible and it doesn't make sense to just compare languages feature by feature. Statically typed category-theoretical pure functional programming is a paradigm shift. The model of thinking itself is quite different, and depending on you, it might be a huge boon or a pain in the ass. Personally, I found that thinking with pure functions and types is easier and more straightforward for me, and leads to high productivity, less bugs and easier fixes, and code that isn't a pain to reuse and modify even after I haven't touched it in a year. That isn't to say it's quick or easy. I have been accreting knowledge and slowly going more and more FP for about 3 years or so (though it wasn't my goal from the very beginning to go FP), and people I've been working with/mentoring have various levels/ways of understanding it and sometimes have problems with their old habits. So, it might be beneficial for you as a programmer to invest time into learning pure FP. It can make you a better programmer in any language, but also will last you for quite some time as that flavor of FP isn't particularly tied to one language (though Haskell makes it way easier than Scala, and Scala makes it not as painful as Typescript). From that perspective, Scala might be a better starting point than Haskell, because if all else fails, you can just write code in a way you already know to at least make something work.
That is probably the new direction they're taking with Dotty. Java compatibility is something you do for increased adoption, by offering the Java ecosystem to early adopters along with a better language. I haven't seen too many PWAs in the wild, but you're right, I'd be building a web UI and two app UIs for a sum of three. I'm not convinced Ionic would actually increase productivity by 300%, though. 
I love the concept of property based testing, but I'll be damned if I can find a single good use-case for it in actual business software. There are just no properties that I can think of that aren't just a resentment of the problem. I've seen the talks and I fully believe in it being a great but I just can't apply it in the real world.
You can write Scala.js cross platform mobile apps using Apache Cordova. (I haven't tried that myself yet)
I feel the same, haven't found the right business use case yet. Or you end up building/tweaking your generators that they are a copy of the logic you want to property test...
It's probably possible but it seems to be uncharted waters. 
I answered the ones that I could answer? Or are you insinuating something else? BTW as a starting point, any webserver written in Rust (i.e. take Rocket) is miles ahead of any of the other web servers mentioned in this thread (particularly if you look at memory usage). Experienced same results with Go and OCaml (which is still single threaded)
&gt; I'm not convinced Ionic would actually increase productivity by 300%, though. You're right, would be closer to 900% :) Seriously, hybrid approach allows one to be hugely productive, you write the UI *once*, and with how much work is done on the frontend these days, being able to share code between platforms (like domain model and validation) is vastly oversold compared to the sheer amount of work required to build reactive frontends (that's why I'm not a big believer in the promise of Kotlin Native). Wrote a PWA in Scala/Scala.js, was quite enjoyable and performs well, but not nearly as fun as getting 3 apps for the price of one, with a slick UI to boot. Ionic can be used without Angular, React, etc. -- maybe one of these days it would be worth massaging `ScalablyTyped` Ionic facades into a usable state for Ionic + Scala.js development.
Sounds a lot like [spores](https://docs.scala-lang.org/sips/spores.html) which are, I believe, dormant as of now.
it takes practice to get the hang of surfacing properties that don't re-implement the code under test or assert truth, but once you do it's just about always available, and orders of magnitude more meaningful than testing fixed inputs. in my experience building this habit aids in recognizing the underlying lawful, compositional primitives that your software is always built upon, which lets you treat them explicitly instead of having an implicit reliance that only gets acknowledgement when things are broken because laws were not upheld. a simple trick i've found that helps to surface properties which don't require re-implementing code under test, is to assert against the inputs instead of the outputs. those of us coming from unit tests with fixed inputs, we've built a strong habit of passing the fixed input to the code under test, and asserting against the result. in generator driven testing, you don't know the inputs. it's just as meaningful in this case to pass the unknown inputs to the code under test, examine the output, and _use the state of the output to assert against the input_ reversing the relationship (output -&gt; input vs input -&gt; output) even conceptually helps keep you from reimplementing the code you are testing, and often gets you to a meaningful set of relationships between input and output that should hold generally over a broad set of possible inputs (useful, non-tautological properties.) 
We only use randomly-generated inputs in unit tests. It's still not the same thing as property-testing though
How is it different? 
Sorry this reads like a non-sequitur to me. Are you saying that my original comment specifically describes unit testing with generated inputs, and therefore does not describe property testing? If so, can you explain why you believe that's the case? From my view, random inputs in unit tests just means you have overly-specific properties, and the distinction is on a spectrum rather than along a concrete definition. Good properties stay as close to universally quantification for domain under test as possible, and my original comment is in service of just those kinds of properties. Is there a more formal definition of property testing that you are operating from, at odds with mine? If so, mind sharing?
I do think you can effectively shoe-horn generated inputs into unit tests, by describing overly specific properties, and certainly if your observations are not total. If you have a ton of narrow conditions you are inspecting in your assertions between input/output, you eventually can observe narrow enough cases to be little more powerful than unit tests with fixed inputs. I can't speak for /u/kudah whether this is what they were referring to, and if so why they thought that's what my original comment was proposing.
&gt; Is there a more formal definition of property testing that you are operating from, at odds with mine? If so, mind sharing? No, in fact I thought you'd give a more specific definition in response to my comment. However, I think I can list the differences I have in mind between these random input unit tests and what I usually see being called property/law-based tests: 1. The properties are not expressed algebraically. i.e. instead of equivalence checks the tests follow usual [setup-mutate-assert pattern](https://blog.ploeh.dk/2019/03/25/an-example-of-state-based-testing-in-f/) - note that the blog author also uses `Gen` for the inputs, yet doesn't refer to these tests as property-based. 2. The tests are rather heavy integration tests that may involve external services, it's not a great idea to run them 100-1000 times, they're only being run once. 3. The content of the random values usually doesn't impact the answer, where it does matter the generated values are modified post-generation to create a specific situation. 
It looks like a superset, meaning it's more ambitious and expressive. You can not only disallow closing over variables, you can also disallow side effects, e.g., access to stdin/stdout, IIUC.
It sounded like you were stating general truths. If you answered /u/lihaoyi's specific questions (the bullet points) it's not clear to me which ones you answered and where.
OK I am 100 percent guilty of responding to the top level comment here without reading the linked article, so I can't speak intelligently to it. My original comment is entirely in response to the challenge /u/tryx had expressed finding properties to observe in business software. I'd say that of the differences you've listed, the third is the most closely related to the spectrum I described, where the extreme end of overly-specific properties ends up fixing certain parts of the generated inputs to create essentially known inputs as far as the code under test is concerned. At that point you're just using the generator to construct filler and make the compiler happy, and your code under test might have a more complex input type than it actually needs to boot. The point seems pedantic b/c it's kind of like saying if you use generators in your tests and throw away the generated values in favor of static inputs, you're writing unit tests. The first difference you list seems to me to be captured by the third, in that a sufficiently general property observed by a test requires little more setup than threading generated values through to the code under test, and the second difference you list opens the conversation beyond what is a property vs a unit test to what even is a unit test. I can't imagine trying to define properties _or_ unit tests without the requirement that the code under test is pure. Ultimately I think we mostly agree on what is a property vs what is a unit test, and I do think that conceptually reversing the arrow from asserting on output based on observation of input, to asserting on input based on observation of output, is a generally helpful thought process in surfacing the kinds of relationships between input and output for a function that can be expressed in a way we'd both agree constitute good properties.
Spent a few hours this weekend playing around with ZIO and made this blog post about it. Very pleased to see how things are shaping up with ZIO, wish it was my day job :D [http://justinhj.github.io/2019/04/07/hacker-news-api-5.html](http://justinhj.github.io/2019/04/07/hacker-news-api-5.html)
Well I can't answer his points specifically because I am not the person who made the blog post, all that I can say is that in general if you write a webserver in Rust and put it under extremely heavy load, it handles much better than anything you can do in Scala currently. There are definitely more steps you can do on the JVM, but it would require your code being Java style and extreme tuning of the JVM GC (at which point you are halfway towards manual memory management). We did our own internal testing there, and languages such as Rust, Go and OCaml really do blow the JVM based languages in this regard. The point is, there are some facts, GC type languages do require a \*\*lot\*\* more memory, and JVM itself does very little AOT compilation (fun fact, the JVM was initially designed from a smalltalk style VM which is designed primarily for dynamic languages). There are other things as well, for example while Scala has a concept of immutability (i.e. \`case class\`), the JVM doesn't understand this distinction. \`case class\` juts gets desurgered to a normal \`class\` which is all that the JVM recognizes at runtime. Compare this to OCaml, where it knows what datatypes are immutable at runtime and abuses this for performance/memory (i.e. if you have immutable datatypes, then basically any structural change to your immutable data type you can easily put into your G1 collector; you don't need complicated scanning to jump through the different generations)
Great, thanks a lot!
&gt; At that point you're just using the generator to construct filler and make the compiler happy, and your code under test might have a more complex or specific input type than it actually needs to boot. Yes, I suppose. Encoding the input requirements in a newtype will make the test look more like a property test, yet it's only a form, not substance change. &gt; I can't imagine trying to define properties or unit tests without the requirement that the code under test is pure. I think that's too strict of a requirement without truly observable benefits ‚Äì it may well be enough that the tests are _repeatable_ without them being fully pure. And how pure is pure? Is StateT purer than IO+Ref, and does it matter if you can't observe the difference? Either way, typelevel people go as far as calling their [impure tests](https://github.com/typelevel/cats-effect/blob/master/laws/shared/src/main/scala/cats/effect/laws/ConcurrentEffectLaws.scala#L47) - laws and recommend law-testing for effectful code that calls the database [in some blog posts](https://www.iteratorshq.com/blog/tagless-with-discipline-testing-scala-code-the-right-way/), so I suppose effectful tests aren't viewed as heathen in general. 
I still count parametricity on `F[_]` as pure, StateT/IO+Ref are probably interchangeable at that point. Interesting note from that blog post the definition of the laws themselves are pure, effects are only introduced where they are exercised at the end. My gut says you can show definitively that being able to define pure laws for a peice of code means that code is pure. And while instantiating your tests to an effectful context can have value (like catching schema errors as mentioned in that post) I probably would save that for special occasions over a regular build.
Hey, beezeee, just a quick heads-up: **peice** is actually spelled **piece**. You can remember it by **i before e**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
i'm a little surprised the release announcement took this long. RC1 was actually released 3 days or so ago
ha i usually avoid that word at all costs for exactly this reason. fixed comment, will definitely not remember.
Maybe Monday is just better than announcing on a weekend, for visibility? 
cats-effect laws are not pure whatsoever, with copious amount of var, scala Promise, Ref, Deferred, unsafeRun(A)Sync etc. Parametricity can't save you (and doesn't really apply) when you're dealing with Sync/Async etc. classes and making your effect algebras polymorphic on \`F\` doesn't make them behave purely when they're backed by an external entity. &amp;#x200B; \&gt; My gut says you can show definitively that being able to define pure laws for a piece of code means that code is pure (barring cheap tricks like wrapping the whole bit of code under test in a new deferred construct). &amp;#x200B; I'm fairly sure you can define pure laws for anything, especially if you're allowed to use any effect as long as it's parametric... &amp;#x200B; \&gt; And while instantiating your tests to an effectful context can have value (like catching schema errors as mentioned in that post) I probably would save that for special occasions over a regular build. &amp;#x200B; I would argue that your tests aren't useful if you're not running them with real effects. The real value of tests is not as much in verifying behavior, but in affixing the correct behavior for \_FUTURE\_ changes to the system. Tests enable a successor to your codebase to refactor, delete or update your code or dependencies without a fear of breakage. Your external connectors are the most fragile piece of the system, they likely come from Java, are badly typed, can be broken by updates to any part of your stack, if you're not testing them, your successor will not know that they're broken after changes or updates to the system and your code will fall under definition of legacy code. You may not run heavy tests on every build, but you must have them and they must be a part of CI, IMHO.
hah, thanks for the link. good joke
I've been tidying up my old SQL Server to PostgreSQL migration and replication service.
That and allow some of the core libraries (such as testing libraries) to be available.
Hm, so Shapeless won‚Äôt be compatible with 2.13?
[https://www.techempower.com/benchmarks/#section=data-r17&amp;hw=ph&amp;test=json](https://www.techempower.com/benchmarks/#section=data-r17&amp;hw=ph&amp;test=json) &amp;#x200B; Top 5 on this list are Java or Scala webservers. &amp;#x200B; Rocket is number 85. &amp;#x200B; I like Rust, but its async story is still a complete mess compared to what's available on the JVM, nor is it that much faster (or at all) for network bound problems.
Looks like Miles already published it https://contributors.scala-lang.org/t/2-13-0-rc1-timing-january-2019/2375/22
You provided a benchmark on JSON serialization.... * This is rarely the bottleneck on web servers * It is one of the few areas where you can hyper optimize in Scala because because people hand write serializers using byte arrays (the point here is that the actual business logic of your webapp is rarely going to be shufflying around ByteArrays) and provide an interface * The latency (which is arguably as good, if not higher metric than raw throughput) puts Scala in a terrible position. The best webservers in this spot are either Rust or Java/Kotlin, with the caveat that the Java/Kotlin based frameworks are written in Java/Kotlin style (i.e. not pure functional, no immutable data structures etc etc) In any case, you need to take these benchmarks with a grain of salt because while do a very good job of pointing out bottlenecks of frameworks (as well as strengths and weakness'es) it misses the bigger picture which is application logic which is the elephant in the room. The slowdown happens not in the ultra tuned serializers/webframeworks but in the weblogic (and this is what we found ourselves).
You can't just look at latency either - of course e.g. nickel has great latency by comparison, when it's doing a fraction of the work. Totally agree that being able to integrate application logic into an ansync framework is more important, which is why this is such a shitshow: https://areweasyncyet.rs/ As someone who really wishes I could justify using rust at work, wake me up when people are done bikeshedding, it's been 3 years.
Oh I agree that the situation with Rust when it comes to async is less than ideal, but its good to put things into context 1. You can do async right now, using the Tokio Future library (which is actually what the standard library will use as their base async implementation). The most annoying part right now is the fact that there is no standard async type/language feature and the main one is constantly moving 2. Rust has a linear type system and for similar reasons how dealing with async types in Scala can get complicated due to HKT's, Rust has the same issue when moving around references + Future. There are some real QoL issues when using Future's in Rust when combined with traits, but they are adding support for this in their compiler (its not like Scala doesn't have QOL issues when it comes to their typing, look at Monad Transformers or things like unapply-unification or kind projector Its unfortunately a complicated solution in a language like Rust because its tracking memory management via its type system, this is a lot harder then doing it in languages like C/C++ (although such languages don't provide such guarantees).
For Validation there is a very clever pattern called Validation. It makes the validations objects implementing `Validation[T]`. https://blog.leifbattermann.de/2018/03/10/how-to-use-applicatives-for-validation-in-scala-and-save-much-work/ If that is too big a gun, I'd go with helper methods. As for your first question: depends a bit on your perspective. Is the target type made from the starting type? Then a factory method in the target's companion object might work. If would like to a more transformative approach you can give your starting types a `toFoo` method. Either directly or through an implicit class.
Neither Scala nor Java are something that should be used in real competitive programming, unless bigints are required and python is not available or too slow. The vast majority of problems is created with c++ in mind, and in most major competitions (for example ICPC or IOI) it is not guaranteed that a task is solvable with anything but c++. In fact we don't even allow the usage of anything but c++ in the German competition which selects our IOI team.
Regarding the place where to put methods. I see in lot of places that methods are placed in traits and then one create object of the same name that extends that trait. So when you have to provide such methods to existing class, you will add trait to this class, but when you need those methods separately, you will use created object that extends your trait.
Hi, I have recently started working on Scala. Kindly bare with my silly question. &amp;#x200B; I have been trying to write the entire output of my scala test (FunSuite) to a single html file. How do I do this ? I was to write certain things like -- throughput of the test, data proessed, time taken etc in case of test Success and write the reason for Failure in case of failure -- not just success or failure as it is otherwise. &amp;#x200B; I believe there must be an option in ScalaTest to write these kind of details in test reports generated out of the test (html), but I can't find details in documentation. Could someone please guide me on the ways of achieving this ? Thanks
c++ is faster, I am not disputing that. However, the key in most competitions is to find the optimal algorithm and at that point the language you choose does not make a significant difference.
To expand on what jacekbeny said, you example would then look like: &amp;#x200B; \`\`\`scala trait Transformers { def transform(bar: Bar): Foo = ??? def transform(bazz: Bazz): Foo = ??? } &amp;#x200B; object Transformers extends Transformers \`\`\` &amp;#x200B; Now you give the users of this code the choice what works best for them. As an advantage you can either mix in multiple traits, or simply use the stand-alone object. So it is both pretty powerful and simple regarding on your use case.
Well yeah the hardest part is usually to figure out the algorithm. However there are 2 main factors why you will never see someone who does good in these competitions use anything but C++, unless you need bigints: &amp;#x200B; 1. The speed difference really can't be underestimated. It is not as significant in a lot of practical applications because you usually have a lot of IO in between short computations, but in instances where you literally do nothing but calculations, the JVM is just ridiculously slow. If the input is large (linear with expected running time), the Java stl classes literally won't even be able to read the input before the time limit is reached. I'm really not exagerating this, people that use Java in online competitions usually use their preprogrammed 120 lines of codes input parsers. This is of course not an option in real competitions. Input is not the only thing where the JVM is just straight up too slow though, you can't use any sort of generic collection either, because boxing is just too much of an overhead, and caching just gets waaay too bad, this is especially a problem in DP tasks. Again, people use their preprogrammed collections for primitives here that circumvent boxing, but again, this is not an option in offline competitions, and only builds a bad habit. 2. The second really big thing is just the verbosity of the language. Most tasks are build with the capabilities of C++ in mind, and are solvable in under 100 lines of C++ code. However in JVM languages, you are usually missing the tools which are required to solve the task, which means you have to program them yourself, which is just a huge waste of time. Also, most competitions don't allow Scala, they only allow Java, and 100 lines of code in C++ translate to around 200-300 lines of code in Java, just because of how verbose the language is (ICPC actually allows the use of Kotlin, which might be a viable alternative to python in tasks with small input where bigints are needed, but I haven't seen anyone use it yet). &amp;#x200B; If you're just solving these problems for fun this is not a problem of course, but in actual competitive programming, using anything but C++ is just too much of a disadvantage. It would be like competing in a bike race with your 10 year old bike: of course you might enjoy the experience more, because the saddle is comfortable and you're used to it, but it will make you unable to compete with everyone else and their race bikes (which is kind of the point in a competition).
Note : I am using pegdown library for reports. I see it is deprecated. Is there any better alternative ? &amp;#x200B; Stackoverflow has questions on this which are not answered : [https://stackoverflow.com/questions/20346971/how-to-generate-custom-html-report-in-scalatest](https://stackoverflow.com/questions/20346971/how-to-generate-custom-html-report-in-scalatest)
You have some very good points. I suppose it depends on the actual competition. If it accounts for slow jvm startup and allows Scala then you can absolutely be competitive with it. In any other case, you'd be better off with c++
If you're in a competition and you have time to write up a sliding stream iterator in java (with a synchronized Vector of all things) and follow it with a wall of even more unreadable java, you'll have time to write a simple for loop with two counters. &amp;#x200B; As for scala, I find it best to err on the side of readability: 1. loopWithIndex is not more readable than (1 .. n).foreach. There is no need to introduce extra clutter. 2. l.lengthCompare(1) == 0 is a... creative but much less readable way of saying l.length == 1 3. name your variables, use pattern matching to deconstruct stuff: &amp;#x200B; walls.sliding(2).foldLeft((0, 0)) { case ((highJumps, lowJumps), left :: right :: Nil) =&gt; if (left &gt; right) (highJumps, lowJumps + 1) else if (left &lt; right) (highJumps + 1, lowJumps) else (highJumps, lowJumps) case (jumps, _) =&gt; jumps
It is a valid point and I have met problems in online competitions where you need an optimized c-style bare-bones solution just to the pass time limit due to i/o overhead. That being said, I believe the competition should be in the knowledge of algorithms, not languages or their intricacies. If you can implement the solution with expected time and memory complexity, it should not fail on i/o. As far as I remember, icpc allowed longer runtime for java solutions back in the day.
[https://github.com/QuarpT/monad-liberator](https://github.com/QuarpT/monad-liberator)
&gt;In a competition you need to write correct code and fast, and you need to be able to reason about this code. Scala provides great abstractions that can help you implement your solution easier. A better example of where scala excels would be anything with recursive searches, for instance. Just don't write more code than you need to. I completely agree with your thoughts, the only thing that I wanted to differentiate was the amount of code required to write in Scala vs Java. And how easy it's to write code in Scala neat and concise.
You can limit your imports. import cats.syntax.bifunctor._ import cats.instances.either._ val v: Either[Int, String] = ??? v.leftMap(...) Does that make it faster?
I won the first in a French competition using Python, while C++ was a choice and used by many people. Scala was not allowed in that competition at the time (and also I did not know Scala existed). I was able to win because I wasn't spending half the time of the competition dealing with memory issues and other nonsense. I could focus 100% on my problem domain.
&gt;l.lengthCompare(1) == 0 is a... creative but much less readable way of saying l.length == 1 lengthCompare will not compute the full length of the collection and is a good option in performance-sensitive code. &amp;#x200B; Quoting the ScalaDoc: &amp;#x200B; &gt; *The method as implemented here does not call* \`*length*\` *directly; its running time* *is* \`*O(length min len)*\` *instead of* \`*O(length)*\`*. The method should be overwritten* *if computing* \`*length*\` *is cheap.*
Don't send very large messages in messaging systems. Send pointers to appropriate storage for the data (s3, hdfs, etc).
I'd say try VS Code + Metals (or any supported text editor + `metals`). I used to make use of *a la carte* imports (`syntax._`, `instances._`, etc) just because of Intellij but we shouldn't be changing our code because of our IDE. I'm a happy `NeoVim` + `Metals` user these days and many of my colleagues are either using `vim` or `VS Code`.
Take a look at [Scala's Selfless Trait Pattern](https://www.artima.com/scalazine/articles/selfless_trait_pattern.html) by Bill Venners
This is what my coworkers keep telling me too! My thoughts are that I want to limit connections to the data source so several services continually fetching from a single source is not ideal but may have to be my solution. I was just wondering if anyone on here did have any success in a streaming system with large messages.
Your coworkers are right. :) If your source is S3 and you're saturating S3... that's probably a good problem to have. If they're objects, and your source isn't S3/Google Storage/Spaces/etc, make it one of those.
Are you using the latest and greatest IntelliJ, Scala plug-in, and Cats?
Hi guys, as a java dev for quite a few years and recently joined a scala team, I think there are 2 points which should be considered, when discussing performance. 1. JVM JIT - the jvm continuously optimizes running code, it adapts to current cpu instruction set, etc. In some perf tests they show to make code run even faster than c++. The price you pay is bigger memory footprint and bigger stratup times, but once you get a JVM running, it adapts to your hardware, regardless of OS, write once run everywhere kind of thing 2. Although fast after it warms up, scala wants to start instantly and run as natively as possible, so they are looking into it right now [http://www.scala-native.org/en/v0.3.8/](http://www.scala-native.org/en/v0.3.8/)
They always do that, I think it's to give time for essential libraries to publish before everyone tries to use it.
&gt; Maybe Monday Umm, actually, it's `Option[Monday]`.
I am indeed
That'll certainly make a huge difference, I'm just learning and don't always know exactly what it is I need. This is probably the best solution though.
I do recommend getting to know the typeclasses at a conceptual level first (what problems they solve). https://typelevel.org/cats/typeclasses.html I tend to think about what typeclass I need to solve my problem, and then lookup what the method names are by going to their corresponding `*Ops` class that provides the extension method (e.g. https://typelevel.org/cats/api/cats/syntax/FoldableOps.html). Hope it helps
Thanks for the pointers, im sure it will :)
For low latency and large messages, you might want to check out Pravega. It has a byte stream API that allows for messages of unlimited size. The caveat is that you need to handle your own framing.
If this interests you, I would recommend checking out https://github.com/fthomas/refined. A lot of what is shown in this blog is built into refinement types.
This is just a long shot and maybe it doesn't even make any sense at all :), but I've had situations where IntelliJ got a bit confused and after deleting the .idea folder and reimporting the project things got into place. The reason I'm suggesting this is because I use IntelliJ CE, my personal Mac is far less powerful than your computer and I haven't tweaked IntelliJ at all. I also always import cats.implicits._ :p and my IntelliJ worked fine this last weekend when I was hacking on a personal toy project. Let us know once you find a solution ;)
The latest intellij release was a fair bit slower than the last, and I believe there's a patch version coming soon, which may help.
Why not just extend the specific trait where you need it everywhere? It sounds like that is doing both approaches at once
That seems a bit redundant though. Why not one or the other?
Try disabling all IDE plugins you aren't using. Some of them are quite resource hungry. After the latest update IntelliJ started locking up for 10+ seconds at a time every minute or two whenever working with Scala source code. I ended up going and disabling every plugin I wasn't using, which fixed the issue. IntelliJ us now running better than it ever has. Based on the stack traces IntelliJ dumps when it freezes up, one of the biggest culprits was actually the JUnit plugin - it appears to do some realtime analysis of the source code as you type. Disabling this plugin alone made a dramatic difference in performance. Regardless of performance issues, avoid importing the entirity of `cats.implicits._`. It's a bit of a code smell, you're better off importing just the modules you need.
You may try using this client. https://github.com/linkedin/li-apache-kafka-clients .
Nice distinction, I read about this before on O‚ÄôReilly I think, with all the hype of ‚Äúreactiveness‚Äù there was a misunderstanding about reactive systems and reactive programming and your article explain all the concepts very well, nice work!
&gt; I used to make use of a la carte imports (syntax._, instances._, etc) just because of Intellij but we shouldn't be changing our code because of our IDE. How is that even remotely related to IDE? If you don't know where implicit you need is - you import whole "default" package. And if anything, IntelliJ can import the precise implicit required if you use completion assistance.
People shouldn't be changing the code just because their IDE is slow unless you're the only person working in a project where you can do as you please but I think most people work in a team. Using *a la carte* imports should be a team decision.
The implicits feature is a recent feature in Idea. I've never needed much more than what the Scala compiler offers. Metals already supports all the features I need including autocompletion and I don't need to give just 8GB to an IDE.
Good to hear!
Metals are recent too (about 2 years) and IntelliJ had good implicits support for *at least* a year ,so i'm not sure what you mean there. And IJ doesn't use 8Gb even with our fairly large project loaded in, so i'm not sure what you done to it to reach that RAM consumption. &gt; I've never needed much more than what the Scala compiler offers. Metals already supports all the features I Well, maybe that's the issue, because: &gt; Metals does not support the following features: &gt; * Completions &gt; * Show type of expression &gt; * Show symbol docstring &gt; * Rename symbol &gt; * Remove unused imports &gt; * Refactoring with Scalafix And for most people that want to use something more sophisticated that coding in a notepad those are fairly crucial features well worth the 2-3Gb overhead that fully powered IntelliJ takes.
UPDATE: The scala-play-server generator has been included in the 4.0.0-beta3 release: [https://github.com/OpenAPITools/openapi-generator/releases/tag/v4.0.0-beta3](https://github.com/OpenAPITools/openapi-generator/releases/tag/v4.0.0-beta3)
Implicits support is a nice to have not gonna lie but it doesn't justify the amount of resources required. In my past experience I couldn't run Idea without giving it 8 GB but also the project I was working on was huge :shrug: &gt; Metals does not support the following features: &gt; - Completions &gt; - Show type of expression &gt; - Show symbol docstring &gt; - Rename symbol &gt; - Remove unused imports &gt; - Refactoring with Scalafix This is not correct. Metals supports many of these features including completion in the latest snapshot (and also previous snapshots). I currently use it, no reason to lie :)
I just copied what they say on official site
Right, that refers to the stable version. But the latest snapshot is amazing!
When I run `sbt run` on a project I get: [info] Resolving com.gu#management-play_2.11;7.2 ... [warn] module not found: com.gu#management-play_2.11;7.2 [warn] ==== local: tried [warn] /home/phill/.ivy2/local/com.gu/management-play_2.11/7.2/ivys/ivy.xml [warn] ==== public: tried [warn] https://repo1.maven.org/maven2/com/gu/management-play_2.11/7.2/management-play_2.11-7.2.pom [warn] ==== local-preloaded-ivy: tried [warn] /home/phill/.sbt/preloaded/com.gu/management-play_2.11/7.2/ivys/ivy.xml [warn] ==== local-preloaded: tried [warn] file:////home/phill/.sbt/preloaded/com/gu/management-play_2.11/7.2/management-play_2.11-7.2.pom [warn] ==== Typesafe Releases Repository: tried [warn] https://repo.typesafe.com/typesafe/releases/com/gu/management-play_2.11/7.2/management-play_2.11-7.2.pom [warn] ==== Artifactory Snapshot Realm: tried [warn] &lt;redacted&gt;/artifactory/libs-snapshot-local/com/gu/management-play_2.11/7.2/management-play_2.11-7.2.pom [warn] ==== Artifactory Release Realm: tried [warn] &lt;redacted&gt;/artifactory/libs-release-local/com/gu/management-play_2.11/7.2/management-play_2.11-7.2.pom [warn] ==== Typesafe Repository: tried [warn] http://repo.typesafe.com/typesafe/releases/com/gu/management-play_2.11/7.2/management-play_2.11-7.2.pom [warn] ==== Sonatype Snapshots: tried [warn] https://oss.sonatype.org/content/repositories/snapshots/com/gu/management-play_2.11/7.2/management-play_2.11-7.2.pom [warn] ==== Sonatype releases: tried [warn] https://oss.sonatype.org/content/repositories/releases/com/gu/management-play_2.11/7.2/management-play_2.11-7.2.pom [warn] ==== Spy Repository: tried [warn] http://files.couchbase.com/maven2/com/gu/management-play_2.11/7.2/management-play_2.11-7.2.pom [warn] ==== Guardian Github Snapshots: tried [warn] http://guardian.github.com/maven/repo-releases/com/gu/management-play_2.11/7.2/management-play_2.11-7.2.pom [warn] ==== mandubian maven bintray: tried [warn] http://dl.bintray.com/mandubian/maven/com/gu/management-play_2.11/7.2/management-play_2.11-7.2.pom [warn] ==== scalaz-bintray: tried [warn] https://dl.bintray.com/scalaz/releases/com/gu/management-play_2.11/7.2/management-play_2.11-7.2.pom [warn] ==== statsd-bintray: tried [warn] http://dl.bintray.com/readytalk/maven/com/gu/management-play_2.11/7.2/management-play_2.11-7.2.pom [info] Resolving jline#jline;2.12.1 ... [warn] :::::::::::::::::::::::::::::::::::::::::::::: [warn] :: UNRESOLVED DEPENDENCIES :: [warn] :::::::::::::::::::::::::::::::::::::::::::::: [warn] :: com.gu#management-play_2.11;7.2: not found [warn] :::::::::::::::::::::::::::::::::::::::::::::: [warn] [warn] Note: Unresolved dependencies path: [warn] com.gu:management-play_2.11:7.2 (/home/phill/&lt;redacted&gt;/build.sbt#L52-113) [warn] +- &lt;redacted&gt; sbt.ResolveException: unresolved dependency: com.gu#management-play_2.11;7.2: not found at sbt.IvyActions$.sbt$IvyActions$$resolve(IvyActions.scala:320) &lt; more stack trace &gt; But if you click on the url with "The Guardian" it seems to be a valid, working POM file, so I am unsure why this doesn't work. There's nothing wrong with the library import and my internet works (the link opens in my browser, and I don't have a proxy configured)
Hey, one thing I‚Äôm curious about. I‚Äôve been trying Metals for a couple days (the snapshot release with completion and hover) and while I really like some parts of it, I found having to write all imports manually really annoying (package as well but it‚Äôs only one line, imports are often 10-20 lines). Do you have a magic trick for it or do you just do it by hand?
What editor are you using? The completions in the latest Metals snapshot provide auto-imports for symbols that are not in scope but some editor clients (like Sublime LSP) ignore the auto-imports. The imports are placed locally so it still requires some manual work to move it to the top of the file, but most of the time you don't have to type out the imports themselves. I'd like to improve this workflow down the road...
First, I'd like to thank you for your wonderful work on Metals! I'm using VS Code and yes, using the completion is helpful even though I have to move the imports to the top of the file. But what I found myself doing a lot was to write the code first (without completion) or copying some line from another file and needing to add the import afterwards. With IntelliJ I would just use the quick fix shortcut to add the missing import right away but here I was stuck having to type them. Any way this would become possible with Metals?
Thanks :) I'm planning to work on "code actions" (LSP equivalent of IntelliJ quick fixes) for the next release and "insert import for symbol X" is high on the list. Until then, a workaround is to run a completion on the identifier with a missing symbol error to insert the import.
How do you run completion on existing code? Happy to hear code actions will be coming!
Found it (Ctrl+Space). That helps, thanks!
You can a completion on the compile error like this https://imgur.com/a/cWBFKNd
Hey, I know scala *and* (some) clojure, and I just started looking for a job in Seattle. Anybody wanna hire me?
If you're serious, send me a resume, we're not hiring in the US anymore but I know a bunch of people who are.
Bump that guy ^, my team is hiring Scala devs in Seattle.
Can you provide an example of what you're currently doing and why you don't like it?
Anyone hiring NYC?
The company I work for is looking for Scala devs in Chicago, DC, SanFran or Minneapolis. Scala experience is a plus but you can learn on the job. You'll want a strong background in Java/.NET/similar or functional languages, strong CS fundamentals and problem solving skills, all the usual stuffs. Great benefits, great people, great mission, great technology in a collaborative environment. Let me know if you're interested.
This is interesting. Thank you for sharing
That's pretty interesting. I love Scala, it's my go to hobby language, I've published a couple of API wrapper libraries as well with it. I always think to myself I should make the switch professionally, and it seems like it might be a good time.
https://www.harrys.com/en/us/careers We‚Äôre hiring, we do scala, and Harry‚Äôs is a great place to work. Check us out and dm me if you have any questions that you think I might be able to answer or would like me to put you in touch with a recruiter. Cheers.
Thanks. Ill check it out
Hmm no one is concerned that kotlin is taking a lead as popular language.
Reddit for the win
All programming language popularity measuring means being flawed, according [google trends](https://trends.google.com/trends/explore?geo=US&amp;q=%2Fm%2F0_lcrx4,%2Fm%2F0dsbpg6,%2Fm%2F091hdj) nope.
reason it doesn't exist is because its not a great idea to do that on a 'messaging platform'. Curious what ur usecase is though?
&gt;Anyone hiring NYC? &amp;#x200B; \*\*Disney Streaming Services\*\* is hiring! &amp;#x200B; [https://jobs.disneycareers.com/search-jobs?k=scala](https://jobs.disneycareers.com/search-jobs?k=scala)
Sure, right now it looks like this : ``` final class Interp[Op[_, _]: Op, F[_]: Sync: Config.Provider]( client: Client[F]) extends Function2K[Op, EitherT[F, ?, ?]] { ``` I don't like it because it's not easy to discern type parameters from value parameters.
It's an interesting data-point. Intuitively, I could have easily guessed our average pay-scale would be higher given a lot of people start Scala after having already gained a decent amount of experience elsewhere (like Java). Salaries tend to also increase with experience. I'm curious if anyone here thinks they would earn less, if they had to go back to working in Java.
Holy shit, I'm on the wrong continent. Why does the US pay so much more?
http://www.scalatest.org/user_guide/using_scalatest_with_sbt mentions the `-h` option. Maybe it works without pegdown?
thanks for your reply. I was eventually able to solve it using informer. [http://doc.scalatest.org/3.0.1-2.12/org/scalatest/Informer.html](http://doc.scalatest.org/3.0.1-2.12/org/scalatest/Informer.html) This adds all the details I want to the html created by pegdown.
You and me to. 2 to 3 times salary than where I am plus bigger variety of work. If I search for Scala jobs I get a handfuls across the country and they are either spark essentially running queries / etl, or some blockchain / crypto currency startup.
Look at the history of JVM languages, where are groovy and clojure these days, how about jruby etc? I don‚Äôt think there is a new killer JVM language, that will always be each new Java release., The JVM languages gain usage the. carve out there niche. Kotlin is no doubt gaining popularity but I think there is no concern, it‚Äôs very different to Scala so will both have the own set of users / fans and can co exist. If you learnt Scala, Kotlin should be trivial to pick up as well.
The [list of new features](https://github.com/scalameta/metals/issues/598#issuecomment-482017381) is pretty impressive! I particularly liked [displayed the hover info](https://camo.githubusercontent.com/5bb0c014feda394284c48b1656910bc601b9e088/68747470733a2f2f692e696d6775722e636f6d2f7267326752414f2e706e67), which looks super useful. At this rate the plugin should become competitive with IntelliJ pretty quickly!
I think Groovy inventor himself declared that if Scala was there sooner he would never do that.
No one think they would earn less, but they earn more than their functional competitors: clojure, elixir and F#
you are missing a few important points here, and those could be summarized as **cost of liviing**. $180K in SFBA is not the same as ‚Ç¨80K, actually it could be worse than ‚Ç¨70K, because of - insane rent - broken healthcare - sky-high education costs and student debt
As long as your transform methods are pure (ie they don't have side effects like IO or anything), I would keep them in an object and just call them from there. This is simpler and you don't pollute your object's type. If they aren't pure, I would put them in an object and pass them in to my classes as a dependency. &amp;#x200B; I'm not a big fan of using a bunch of mix-in traits. I think if you're not careful you can end up with classes that are just a big trait soup and it's difficult to understand how everything works together. That might be a controversial opinion though.
This is definitely the year of tooling in Scala, thank you so much for your work!
Many thanks to /u/olafurpg
Not really no. It might be even better as the people who like to write Java in Scala are more likely to go to Kotlin. And those that appreciate Scala for Scala stay. With all the stuff that is happening around FP in Scala lately I think it might even attract more functional programmers than before. Naturally when too many people move that would be a problem, but I don't think that is likely to happen any time soon.
Please note that this is only a preview release to get some early feedback. I hope to have a stable release out in the next week with updated documentation on the website and detailed release notes.
Have been using metals for a month now with Emacs' lsp, so far I've been *thoroughly* impressed. I've been actually using it a work to get real production stuff done! I don't think I'll go back to IDEA anymore... The best part of it is that /u/olafurpg has been implementing so many features that I keep finding new major lsp features every time I download a snapshot build. And I've been doing that almost *daily*.
This is so great.
Scala programmers spend more time on Google? üò¨
If you're looking for a Scala job in Austin, DM me
Me too. It's so beautiful.
Typical `Observable` based RX API provides a single type to unify both the usages and a mixed implementation, which is horribly complicated. What is worse is it weaken the type system, as you cannot distinguish a one shot `Observable` and a continuous changing `Observable` from their types. I don't like this kind of API design, because its weak type system tends to produce buggy programs. We have [asynchronous tasks](https://javadoc.io/page/com.thoughtworks.dsl/dsl_2.12/latest/com/thoughtworks/dsl/domains/task$.html) to handle events and [data-binding](https://javadoc.io/page/com.thoughtworks.binding/binding_2.12/latest/com/thoughtworks/binding/Binding.html) to handle continuous values. Also [some utilities](https://javadoc.io/page/com.thoughtworks.binding/binding_2.12/latest/com/thoughtworks/binding/FutureBinding.html) for converting between events and bindable values are useful. They are different types, which you can safely use them in need. Even though, those types can be unified as `Monad` or other type classes. So why do we need RX?
Having fun writing a scala/akka project on the side. API-based with a react frontend. It's about time to start adding users/membership and authentication. What's a good fp-friendly choice for this from a scala perspective? I have OAuth experience.
Why would that be a concern? Kotlin is specifically designed to be easily picked up by Java and Scala users.
Can anyone compare this to ensime on emacs?
Very cool. Is there already an ETL when the recordings of the talks will be uploaded?
[https://github.com/vivri/Adjective/blob/master/library/shared/src/main/scala/com/victorivri/adjective/Adjective.scala](https://github.com/vivri/Adjective/blob/master/library/shared/src/main/scala/com/victorivri/adjective/Adjective.scala) is also a very nice and lightweight alternative.
Especially with S3 you are not going to saturate it. If the throughput becomes a bottleneck you can introduce entropy into the paths and make this a non-issue. [https://docs.aws.amazon.com/AmazonS3/latest/dev/request-rate-perf-considerations.html](https://docs.aws.amazon.com/AmazonS3/latest/dev/request-rate-perf-considerations.html) And a very interesting discussion about this here: [https://issues.apache.org/jira/browse/FLINK-9061](https://issues.apache.org/jira/browse/FLINK-9061)
dm me if you're good with scala in Atlanta, and actually a passionate dev...we've basically exhausted the pool here
I really like Kotlin and I'm primarily a Java user (I know very little Scala) and IMHO the community for Java and Scala is HUUUGE (StackOverflow and Reddit) are very helpful, Kotlin, not so much.
Hi! Is it possible to write a match where the cases are the result of functions? For example, how would I go about writing something like this using match instead if a chain of if-elses? def isInSomeList(numbers: Seq[Int], number: Int): Boolean = { numbers contains number } def isDivisibleBy47(number: Int): Boolean = { number % 47 == 0 } def classifyNumber(numbers: Seq[Int]): Option[String] = { if (isInSomeList(Seq(1, 2, 3, 4, 5, 6), 4)) { Some("RangefulCompliance") } else if (isDivisibleBy47(594)) { Some("Fourtyseventiple") } else { None } } It would be way snazzier if I could write the last function in this way instead: def classifyNumber(number: Int): Option[String] = { number match { case isInSomeList(Seq(1, 2, 3, 4, 5, 6), _) =&gt; Some("RangefulCompliance") case isDivisibleBy47(_) =&gt; Some("Fourtyseventiple") case _ =&gt; None } } Is it possible? Thanks!
Thank you for sharing! Means a lot to hear that :)
The majority of kotlin's popularity is in Android, which is mainly a side effect of Google still not updating their platform to Java 1.8 (you don't even have closure's when working on bare Java with Android)
&gt; Implicits support is a nice to have not gonna lie but it doesn't justify the amount of resources required. It actually does, the Scala language/type system is so complicated that in order implement the kind of features that Intellij provides you need a lot of memory and CPU.
I've been using ensime/emacs for about 1.5 years before I switched to intellij last year, and I've been trying out Metals recently. Ensime was very usable as a daily driver, but I don't recall it to be very polished. Choosing that over Intellij made sense because I made heavy use of the other emacs/commandline tools. Unless you are familiar with Ensime already, I would recommend to go with Metals.
Unrelated - what IDE is that?
Looks like vscode
Could be Intellij with Material UI and rainbow brackets plugins.
I think the values method of the mutable Map returns a Stream, causing it to never end. Calling toList on values, forces it to be a finite sequence. Not sure why the return type is inferred to be Stream though.
Can reproduce. Not sure exactly what's going on, but the stack trace indicates the Combiner never returns, as the ForkJoin task is just waiting for the combiner to return: java.lang.Object.wait(Native Method) java.lang.Object.wait(Object.java:502) scala.concurrent.forkjoin.ForkJoinTask.externalAwaitDone(ForkJoinTask.java:295) scala.concurrent.forkjoin.ForkJoinTask.doJoin(ForkJoinTask.java:346) scala.concurrent.forkjoin.ForkJoinTask.join(ForkJoinTask.java:673) scala.collection.parallel.ForkJoinTasks$WrappedTask$class.sync(Tasks.scala:378) scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.sync(Tasks.scala:443) scala.collection.parallel.ForkJoinTasks$class.executeAndWaitResult(Tasks.scala:426) scala.collection.parallel.ForkJoinTaskSupport.executeAndWaitResult(TaskSupport.scala:56) scala.collection.parallel.ExecutionContextTasks$class.executeAndWaitResult(Tasks.scala:558) scala.collection.parallel.ExecutionContextTaskSupport.executeAndWaitResult(TaskSupport.scala:80) scala.collection.parallel.ParIterableLike$class.map(ParIterableLike.scala:499) scala.collection.parallel.ParMapLike$DefaultValuesIterable.map(ParMapLike.scala:106) $line18.$read$$iw$$iw$$iw$$iw$$anon$1.run(&lt;console&gt;:17) java.lang.Thread.run(Thread.java:748)
Awesome! I have started using Metals today in VSCode and have been looking for type at point.
Straight from the Future, backported from 2020 :D
This
Thank you. I've been using Ensime for about 9 months now. Just trying to decide if I should take a hard look at metals now or in a few months
Don't do multithreading in object constructors/bodies. It's a well-known deadlock [bug](https://github.com/scala/scala-dev/issues/195). AFAIK, it relates to how closures created in an `object` constructor and scheduled to run asynchronously refer to its instance "from outside" causing its initialization lock to be waited on again.
Well, type of `cache.values` is `ParIterable` whose `hasDefiniteSize` method returns `true`. And calling `toList` returns regular non-parallel collection, I don't think it has to do something with indefinite size of stream-like things
Don't use \`ParTrieMap\`?
Ah, you're right. I've scrolled through the implementation, and it looks like the \`executeAndWaitResult\` of the map method executes the task on the fork join pool but never reaches 'sync'.. Can't help you further ;) Possible SO explanation: [https://stackoverflow.com/questions/15176199/scala-parallel-collection-in-object-initializer-causes-a-program-to-hang/15176433#15176433](https://stackoverflow.com/questions/15176199/scala-parallel-collection-in-object-initializer-causes-a-program-to-hang/15176433#15176433)
Yes because that will help him understand this.
Anyone preferring this over IntelliJ ?
Nope, that‚Äôs not the case (I checked this when printed ‚ÄúInit finished‚Äù. I traced execution down to fork-join pool impl and found that it‚Äôs not a deadlock but rather an infinite sub-splitting loop. Thanks for help anyway!
How does Scala native compare with Kotlin native?
Don‚Äôt want to throw shits here but what were you trying to achieve with such answer? BTW what would you use for a concurrent cache?
All of the parallel collections are broken, don't use them. As for a concurrent cache I'd use `ConcurrentHashMap`.
In idiomatic Scala code? Like, for real?
Don‚Äôt get me wrong, not a blood purist here, but I like Scala a lot and it‚Äôs hard for me to believe that parallel collections are really that bad implemented, it just hurts my heart
 (Off-topic, sorry. This is a sore point for me.) Ah, `hasDefiniteSize`. What the everloving heck were they thinking with that method? Is there *any* reasonable code that actually going to call that and decide *at run time* what do based on that information? WTF?
Do you want something that works, or don't you? (The Scala parallel collections have nowhere near the amount of real-life testing that ConcurrentHashMap has. So, yes: Use that instead.)
The whole collections hierarchy in Scala is a prime example of Beautiful in Theory -- Bad In Practice. For example, it makes absolutely *no* sense to try to "unify" mutable and immutable in a single hierarchy[0]. It makes for a great paper about how clever you are, though! I think the language designers/implementers may have learned the lesson. See PaulP's talk at https://www.youtube.com/watch?v=uiJycy6dFSQ for more information. [0] For one thing is actually pretty hard to tell when a method returns an entirely new collection or just modifies the collection and returns "this". It's a *huge* wart and pain if you actually *want* to use mutable collections for their performance -- only to discover that what you're doing is actually just returning a copy.
Curious why not IntelliJ?
This is the correct answer. The Scala concurrent, parallel, and view collections are a tire fire. Generally written by one person, merged without code review, not well tested, unmaintained for a decade. Code that would never make it into the Scala repo if submitted today, and much of which is explicitly being *removed* from the Scala repo as we speak. It doesn't really matter what you want to believe or what you want to think is idiomatic. If you use the concurrent, parallel or view collections, you are going to have a bad time. There's nothing much else to understand.
Doesn‚Äôt work with sbt 2.11 :(
That won't work with these method names. Your methods all have the same operator precedence, because they're all "word".
It seems possible however ... no ideas how ?
I don't see the point of context bounds. Sure, if there's exactly one it might look a little neat. * But they're obscure - it's _really_ not obvious what's happening. * They munge your clearly defined implicit list with extra crap that might be confusing * They hide the name of the parameter making debugging harder * They get mixed in with `&lt;:` and friends making everything harder to read * They have to all be on the same line or it's _even worse_ I think it's a failed syntax. But I know people who like them, so I doubt they'll be going away.
Having used ensime-vim, how does this compare?
The compiler would need a way for you to tell it the precedence of the method names.
Yep! Part of idiomatic Scala is to use libraries written in Java. It's a core selling part of the language. "its JVM and JavaScript runtimes let you build high-performance systems with easy access to huge ecosystems of libraries." &amp;#x200B; [https://www.scala-lang.org/](https://www.scala-lang.org/)
One day I was working on some parser combinators and had a strong use case for refined types. I added Refined to my project and started working on some types. Next thing I know compilation time of a relatively simple scala file goes from a few seconds to half a minute. I double checked that it was really due to Refined. The code was certainly safer, but my IDE and the compiler were struggling. This was only the start of the project. What would you have done?
The Scala compiler is unfortunately slow by default. If it's both slow in your IDE and also in the compiler there's no much to do (change the programming language maybe?).
I created a question on stackoverflow with piece of code : [https://stackoverflow.com/questions/55663511/scala-custom-operator-precedence-with-same-identifier](https://stackoverflow.com/questions/55663511/scala-custom-operator-precedence-with-same-identifier) if you find something
I personally don't like to use IntelliJ as I like simpler editors. VSCode doesn't try to hide how things get compiled/executed like IntelliJ does. It just automates simple tasks that could perfectly be done by hand in the command line. Moreover, it does not take half a minute to startup, and it supports way more languages than IntelliJ products.
I haven't used it as my main editor yet, but the fact [it supports macros smoothly](https://contributors.scala-lang.org/uploads/default/original/2X/8/8f548d988d8014b1563e4cecbd7198814d461b17.png) could be a game changer for me.
Because it gives you choice. It is one line of code and can make life a bit easier. I use this approach a lot when defining JSON formatters for example. If just need the formatter for the one object simply import it from the object. But if you create another object that uses my object you can extend the formatters and get everything for free (nested formatters will not work with just import).
Yes, reliable diagnostics are a game changer
This is just a language server, you would need to pair it up with an editor to prefer it over IntelliJ
The entire point of the upcoming Scala 2.13 release is that the collections are kind of all a mess and need to be rewritten. The normal List, Vector, etc. are mostly fine, but the concurrent collections are truly a mess. Scala is built by human beings, and sometimes those human beings, despite being very smart people with good intentions, don't get it right the first time.
It is possible with extractors! On cellphone so can't write a lengthy description but Google it and you'll find what you're looking for
Thanks, I'll definitely give it a shot then! For me, I actually come from an Emacs background, found ensime to be buggy / finicky and that led me to try intellij which just worked.
Right. I thought about it some more and my confusion is the cost of doing that. That way of programming works but the object doesn't come for free right? It takes a certain amount of memory (not sure how negligible) and that was also another aspect of this pattern that I'm unclear about
You can get pretty close just with the existing functions and guards. def classifyNumber(number: Int): Option[String] = { number match { case i if Seq(1, 2, 3, 4, 5, 6) contains i =&gt; Some("RangefulCompliance") case i if i % 47 == 0 =&gt; Some("Fourtyseventiple") case _ =&gt; None } } But if you want something close to that syntax then you can make custom extractors. case class ContainedIn[T](s: Seq[T]) extends AnyVal { def unapply[T](t: T): Boolean = s contains t } case class DivisibleBy(denom: Int) extends AnyVal { def unapply(i: Int): Boolean = i % denom == 0 } def classifyNumber(number: Int): Option[String] = { val contained = ContainedIn(Seq(1, 2, 3, 4, 5, 6)) val divisible = DivisibleBy(47) number match { case contained() =&gt; Some("RangefulCompliance") case divisible() =&gt; Some("Fourtyseventiple") case _ =&gt; None } }
The cost is negligible. Every case class for instance also generates a companion object. And case classes are widely used. Creating one is pretty cheap. That is not to say you should always use this pattern. But generally, if you design for mixing in traits I would at least consider also providing a companion object so it can also serve as stand-alone functionality.
There are a bunch of people using it with \`vim/nvim\` (including myself) without any issues, I definitely recommend it over ensime. It works using the standard Language Server Protocol.
This is the format we use at work (using `scalafmt`) and that I also personally adapted for my OSS work: ```scala final class Interp[Op[_, _]: Op, F[_]: Sync: Config.Provider]( client: Client[F] )(implicit cs: ContextShift[F]) extends Function2K[Op, EitherT[F, ?, ?]] {} ``` Note that I added an extra implicit so you see how it's formatted as well. If you like it feel free to copy this [scalafmt config file](https://github.com/gvolpe/fs2-redis/blob/master/.scalafmt.conf). PS: In order to get the parameters list formatted like this you might need to introduce a "new line" after opening parens and another "new line" before closing parens.
I don't think I'll ever be fully satisfied, but that is arguably better than what I currently have, thank you ! That is very helpful.
Hi! &amp;#x200B; I'm new to scala, I have to submit a project for tommorow, I've done the hardest part, but I struggle with something simple.. If you can help me (sorry for my poor english) &amp;#x200B; I have a txt file with some words, I have to read it. In the file there is some document separate by 10 "=" How can I put these in an Array with i document, without losing the "\\n" (I guess I have to do an addline function?)
Hey, takeshi1213, just a quick heads-up: **tommorow** is actually spelled **tomorrow**. You can remember it by **one m, two rs**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
Hey /u/CommonMisspellingBot, just a quick heads up: Your spelling hints are really shitty because they're all essentially "remember the fucking spelling of the fucking word". And your fucking delete function doesn't work. You're useless. Have a nice day! [^Save ^your ^breath, ^I'm ^a ^bot.](https://www.reddit.com/user/BooCMB/comments/9vnzpd/faq/)
delete
Are remote scala jobs popular ?
Hi all, I have a question and I'm sure that this one asked many times but I couldn't find good answer on google. ```scala var list = List(2,3,4) var list2 = 1 :: list ``` how this usage can be possible? I mean List have `::` method but using it we write like `list.::(1)` right? or some methods we can use like `list apply 1 //returns element in index 1` but I don't understand how `1 :: list` is possible, is it some kind of special syntax?
&gt; I haven‚Äôt seen this approach to abstracting on data used anywhere Looks quite similar to [Higher-Kinded Data](https://reasonablypolymorphic.com/blog/higher-kinded-data/). [Trees that grow](http://www.jucs.org/jucs_23_1/trees_that_grow/jucs_23_01_0042_0062_najd.pdf) is the same technique extended to full-blown type functions - it will be quite usable with match types in Dotty, however you can emulate it with GADTs in current Scala, if you really need it.
One to many data migration
Methods that end in a colon a right-associative, meaning they get invoked as a method for what's on their right-hand side instead of the left, as is more common. So `1 :: list` is precisely the same thing as `list.::(1)`, but reads a little better.
I think you may be tracking the document counter incorrectly. Right now, if it's not the doc separator you move on to the next document, and if it is the separator you start back a t the first document. This would be fine if these records were interleaved, e.g. the first line corresponds to the first doc, the second line corresponds to the second doc, and each section fills is a different part of each document. But it sounds like each section is fully contained in between the equals, which can be done easily be moving `i = i + 1` into the `else` and deleting `i = 0`. In this way you build up a single document until you reach the separator and then you move on to the next document.
Is this rule only for '::' symbol, or any others should I know?
It's literally any method ending in a colon, of which `::` is just one. I don't have an exhaustive list of such methods, but some other common ones are `:::` to concat two lists (same as `list.:::(other)` or `elem +: collection` (same as collection.+:(elem)` to add an element to what's on the right hand side.
Great! Extractors solved the problem for me. Thank you for your feedback.
Great! Extractors solved the problem for me. Thank you for your feedback.
I would typically do something like this: (isInSomeList(list, input), isDivisible(input)) match { case (true, true) =&gt; println("both!") case (true, false) =&gt; println("in list, not divisible") case (false, true) =&gt; println("not in list, is divisible) case (false, false) =&gt; println("not in list, not divisible") }
Interesting and a good read, thanks!
I'll take a look at these, thanks!
Thank you! Glad you liked it.
Yes, all the talks were recorded, today we published the opening keynote by John De Goes and Wiem Zine Elabadine: [https://www.youtube.com/watch?v=d6WWmia0BPM&amp;list=PL8NC5lCgGs6MYG0hR\_ZOhQLvtoyThURka](https://www.youtube.com/watch?v=d6WWmia0BPM&amp;list=PL8NC5lCgGs6MYG0hR_ZOhQLvtoyThURka) More to follow soon!
I love that hkd blog post. You should really check out this talk too https://youtu.be/tJNU1H9XewM
Answering for my own organization, we have about a dozen engineers. We have a lot of Scala in our codebase, but also a lot of Java. Our most senior engineer, who was a strong Scala component, left under a cloud last year. He was a mild FP proponent and introduced Scalaz in a few places, sometimes appropriately, sometimes not. Scala style has not been addressed formally at all ‚Äî to our great detriment. There are several very strong and very senior engineers who never used Scala prior to working here and still prefer to write Java, as well as engineers of varying levels who prefer Scala. Only two of us used Scala prior to working here. A few of the Scala proponents are, I would say, still learning the language and prone to misuse language features that they have less experience with. Recently we had an explosion of implicits thanks to one engineer who learned that they ‚Äúshould‚Äù be used in a situation and then used them consistently in that situation despite it making the code worse. (We don't have formal rules about who can review what kind of code, just that it be reviewed.) Some of the older usages of Scalaz in our codebase similarly reflect an engineer learning constructs from the red book and then discovering on the job how they can make code worse or better. The engineers who prefer Java have no patience for this. I think they feel like bad Java is more tractable and straightforward to deal with than bad Scala. I would say their greatest annoyance is encountering Scala code that is difficult to understand and not knowing if it‚Äôs hard because they‚Äôre encountering a learning curve they will find worthwhile or it‚Äôs hard because they're encountering a learning curve they will resent climbing or it‚Äôs hard because it‚Äôs just shitty code. There is a perception, not entirely unwarranted, that many choices in our Scala codebase were made for the sake of an individual‚Äôs intellectual development rather than for the sake of the team or the system. So Scala is at severe risk in our organization right now, and those of us who favor it are attempting to right the ship. We‚Äôre considering adopting a formal style guide and producing internal materials to promote a unified philosophy. I‚Äôm looking to gather ideas and experiences to (hopefully) create a new path for us.
&gt; Scala is built by human beings I thought it was built by academics? /s
Does anyone find akka-http usable? Like it has all these directives like setCookie and getCookie but how to you construct real application logic around that? Has anyone actually built a non-trivial real website with akka-http and if so, any links to sources?
We are using scalaFmt, ScalaStyle and ScalaFix to enforce styling in my company. Intellij is able to read all three and combine the rules. So all code looks similar and there is only one learning curve instead of a maze. We have also developed an internal SBT plugin that is mandatory to include to enforce library dependencies, as well as all the build and styling plugins, such as sbt-assembly and the above mentioned styling library. This plugin allow to start up a brand new project much faster since the build.sbt file is mostly written by the plugin.
This unfortunately doesn't fit my use case. I have some quite expensive functions to run, so I would ideally like to run as few as possible. Thank you for your input, though.
I am currently working at a Scale up (\~6 years old, 32 employees) that uses Scala as its primary language. It was introduced I think about 1 or 2 years after the creation of the company. Most developers learned Scala at this job, with I think only two exceptions (me being one of them, as I explicitly searched for another Scala company). Over time we are getting more formal about style, as we are slowly maturing. So in the last year we introduced ScalaFmt and are about to introduce ScalaFix. Since this is primarily a Scala shop almost everyone is in favor of a more functional style. We have one larger Java application, but most actually don't really want to work on that as it doesn't really embrace a more functional style. Though most code is impure functional Scala which is slowly diverging to a more pure style, through libraries like Cats and Shapeless. However their is some discussion in how far we should go. Generally, what I think helps in creating one style, is to invest in libraries that encourage one. We have micro-services and all heavily make use of Akka, Akka Streams, and Akka HTTP. So everyone feels quite comfortable with these libraries, which makes it easy to work on a micro-service you don't know really well, because they have a similar architecture. As a company we have enough experience with these libraries that it is easy to bring someone up to speed and avoid common pitfalls, as we have already stepped into all of them once. Personally I would like to go a bit more purely functional, but for the company I think where we are is good. This is a style that everybody is now proficient in, and seems like a good compromise between purely functional, and a better Java leaning a bit more towards functional programming.
Team: About a dozen people and only some had used Scala before. Usually rather experienced people but diverse backgrounds. Codebase is fully Scala on the server-side and several years old overall. We introduced an internal styleguide last year and have had a common `.scalafmt.conf` for a while before that. The styleguide is actually less about style and more about common patterns that we know worked well in the past while avoiding the ones that caused trouble. It was started, so we could write down our "unwritten" rules that were only perpetuated through pairing and code-reviews. Scalafmt already does solve a lot of the common problems (how to indent stuff and the like). The only problems we sometimes face is the discussion about over- and underengineering of solutions. Usually we try to keep it basic unless we already know that product wants a specific extension in a few weeks/months. The codebase isn't exactly new, so you will find almost all things that Scala has to offer somewhere, often introduced by people long gone. It's usually fine. There are some patterns that are unfortunate (e.g. cake-pattern, scalaz operators) and you either have to live with them because they are hard to replace or you replace them steadily when you touch that part of the codebase. We are generally open to use new libraries and patterns as long as there is a tangible benefit. One example where this couldn't really be demonstrated was the tagless final approach, which led to lots of confusion even for experienced devs and groaning by others. There are two small tools written in that style, but the mental cost was not worth it, so we will probably not write any new stuff like that (even though one or two people really like it). Overall we are very very happy with it. It's rock-solid compared to Java and similar languages, but way easier to hire and train people for than Haskell. We also use a lot of big systems like Spark/Kafka/ElasticSearch and since most of those are also JVM-based or have good JVM-clients it's straightforward to just use Scala for everything on the server-side. Product Managers don't have any say in the technology as long as we deliver features quickly and without many bugs.
**TLDR; Warning, unpopular opinion here**. **There is nothing wrong with using Java instead of Scala. There is something wrong with using Scala as a better Java in a commercial setting. If you aren't using "advanced" features of the Scala programming language, you are not leveraging Scala as a technology enough to pay for the learning curve and compile time overheads; have a different definition of complexity than a lot of experienced Scala programmers; are different than the open source enthusiasts who are the vocal majority attempting to teach others within the community; and are dependant upon a silent majority who doesn't share knowledge that have, by convention, design strategies that actually require knowing more semantics than the FP style espoused by Hascalators like John de Goes, Miles Sabin, et. al, which value substitution-based programming based on provable mathematics (that's why the names are weird (Functor instead of Mappable)).** If you think using scalaz and implicit parameters and typeclasses are bad things, your organization should not be using Scala. You aren't getting enough bang for your buck, and you obviously have not invested in a comprehensive enough Scala training program for your engineers. Your code quality in Scala code will continue to devolve, because you don't appear to value the features that make Scala's compile-time productivity penalty worth it, and you have actively pushed your most experienced Scala engineer out of your company "under a cloud." The vast majority of advertised, active, quality (low defect) open-source libraries outside of the databricks ecosystem in Scala use functional, categorical programming. Anecdotally, after over 10 years of experience using Scala, and using every library from dispactch, slick, and playframework to cats-effect, eff, and fs2; and using every coding style from cake/better-java to tagless final; the more typesafe and categorically functionally pure the library is, the more likely that it does the thing it says on the tin (the type signature). The more pure Scala the library is, the fewer defects the library is [likely to have](http://macbeth.cs.ucdavis.edu/lang_study.pdf). The closer to functional core, imperative shell your application is, the better it is for maintenance in the long run, because such application architectures are naturally modular and can leverage other modular libraries written in the same style. Scala takes way too much time to compile if you are merely using it as a "better Java" or as an "OCAML on the JVM". Here's how I define that: * Using it merely to reduce keyword boilerplate * Distinguishing between features of the language necessary for "library code" and "application code" in large, long-lived applications * Not attempting to make your code referentially transparent everywhere except for in the main method of your application * Not using FP libs like scalaz or cats, trading off learning how to use re-usable, tested, principled, RT code used by thousands of users in the wild for familiar, in-house, that is more likely to be buggy in unexpected ways because fewer eyes have been upon it * Using the [broken](https://www.youtube.com/watch?v=uiJycy6dFSQ), standard library, at least, at least pre-redesign, is and using cats/scalaz helps ameliorate those issues * I haven't had the opportunity to use the new collections library, because many libs that I depend upon for work are still stuck on previous versions of scala (thanks databricks!) * Coding to the least-powerful interface in the standard library pre-redesign is extremely [difficult](https://www.47deg.com/blog/adventures-with-scala-collections/) due to there being so many mixins * [https://raw.githubusercontent.com/xuwei-k/sbt-class-diagram/master/sample/list.png?\_sm\_au\_=iVVDQH0ZjW5VQJVF](https://raw.githubusercontent.com/xuwei-k/sbt-class-diagram/master/sample/list.png?_sm_au_=iVVDQH0ZjW5VQJVF) * Using classes and mutating the internal implementations instead of making typeclasses for your behaviors * Not encoding effects and coding to higher-kinded generic container/effect types with implicit parameters likely violates interface segregation, inversion of control, open-closed, and parametricity principles. A symptom of this is a large amount of code churn in your repositories. Note that these require enforcement by convention, the compiler can't guarantee RT for you in Scala. * Not using Refined and Shapeless to further constrain your input parameters at compile time rather than using runtime validation and to generate boilerplate code on-demand at compile time Your scala incremental builds take orders of magnitude longer than your java builds, and you aren't getting more compiler verified code than you would in Java, you aren't getting more modular code than you would in Java, and you aren't really reducing boilerplate any more than you could reduce it by using Java with vavr or Kotlin. If you find yourself agreeing with the [Databricks style guide](https://github.com/databricks/scala-style-guide), use another language. You aren't using the features available in the language you have chosen to write in. You need to have a reason to use one language over another, and from what you've typed you don't have a company culture that would support using scala as a language to its full advantage. If you don't find cats and scalaz and FP "simple", you don't know enough about the language to take advantage of it, and you are making judgements about the appropriateness of using libraries before admittedly fully understanding the use cases of those libraries. Twitter's is slightly better, though it predates newer practices like effect encoding that have emerged over the last few years. Complexity has many definitions. Familiarity is only one metric, though it seems to be the only one anybody actually cares about in the real world. Number of moving parts, number of inhabitants, LCOM4 cohesiveness, lines of code, code churn, algebraic-reasoning (basically, substitution is the only model for evaluation and refactoring), cyclomatic complexity, and halstead metrics, and binary compatibility are some others. A popular rebuttal to this argument is "just go use Haskell or Frege or eta" instead of Scala. Haskell's ecosystem has some [build and portability problems](https://wiki.haskell.org/Cabal/Survival), eta is very young, and there are a LOT of high-quality Java libraries out there that you can wrap in effect and error-handling to make them RT. You have FFI in those other languages, but that's tedious to maintain as the underlying library changes. Using good old clean-code guidelines to wrap your external libraries in a pure interface is easier (takes less effort to code), in my opinion. Scala 3 will make a lot of the weird notation disappear, but will require a lot more learning and redesign of libraries and applications to move to a more "native" Scala encoding of many of the current FP practices. This is a good thing! But it is yet more education your organization will have to undergo and it is SCALA SPECIFIC education. Categorical FP is knowledge that is portable to many languages. The particular way of encoding categorical FP in Scala is what is Scala specific. There is nothing wrong with making this technical decision for your organization. There's nothing wrong with using Java! If you don't like the community ("FPers are just vocal"), the libraries "scalaz and cats have no use-cases", the ecosystem ("SBT sucks"), and aren't willing to provide non-FP alternatives that have as high of quality with OOP encodings that are as modular as FP libraries, you'd be more productive and have fewer arguments coding in a language where you can get programmers with common experiences. If you devalue the programmers with the most experience in your language of choice and their development practices, you are not getting the best bang for your buck in that language, and should probably not be using it. This IS THE RIGHT DECISION FOR YOUR ORGANIZATION! Don't use Scala to save on keywords or to code in a purely OOP style. It's just not worth the productivity trade-off. Also, fighting for Scala use within such an organization is futile. Your opponents have 20 years of production code to argue against any correctness arguments you may make. It's a losing battle and will likely result in you being ostracized for being an ivory tower wonk. Go with the flow.
We are ~15 developers in our team. Our complete backend codebase is written in Scala (200-300 kloc), divided into 50 services or so. We have started using Scala 6 years ago because I refused to code in Java ;-) In the first few months, when there were only two other developers besides me, Scala caused major headaches as the learning curve was extremely steep and tooling sub-par (we used Scala IDE and Maven). It came as it always does and when our skills improved, we tried to use all features available. There were type classes and custom monads at many places, sophisticated type constraints, and much implicit trickery in general. We used some features from scalaz but nothing too fancy (mostly Validations, ValidationNEL, and Applicatives (at a few places)). When our team grew, the new developers, which usually had a Java background, adopted the new language quite easily/happily. I think, what made it easy for us, is that our services all had a similar structure with lots of examples to copy / learn from. In my opinion the best parts of Scala are also those ones that are instantly accepted by former Java developers. Who would not favour case classes over clumsy hand-made value objects (or crutches like Immutable.Value)? Who does not instantly fall in love with pattern matching or the Scala collection framework? We also have a mandatory code review process, which helps hinting new team members at how they can code in a more idiomatic way. Funnily (but also consequential in hindsight), the most clever parts in our code, e.g. type magic, implicit overuse, or something like the cake pattern, did either not stand the test of time or got buried so deep that the "common developer" never gets to see it. All in all, we are very happy with Scala (we do also some development in external Java projects and coming back to Scala always feels like coming home), and I have never regretted the decision to use it. However, there are also some things (more or less Scala-specific) that we are actively struggling with. When we started in 2013, most things were modelled after the book "Implementing Domain Driven Design" by Vaughn Vernon, which bases on Java. Following this design made our code not look very Scala-esque. Over the years, the most complex and concurrent parts of our machinery have been rewritten with Akka, which is not easily adaptable to a standard DDD structure. I am still not completely sure if Akka makes the world easier or more complicated for us but for a new developer, there are more than a few opportunities to shoot yourself in the foot (e.g. using Futures in actor code). We are also using Akka streams and RxScala at a few places, and to be honest this stuff (at least Akka streams) is complete senior level (we have a few custom GraphStages in our code and I don't think there are more than two developers who understand what happens there). Maybe one last thing. I think, what makes or breaks using an advanced language such as Scala is that you have good mentors / benevolent dictators, which actively participate in the code review process and enforce a consistent style, architecture, code structure, and use of idioms. Maybe even better than "good mentors" is "one good mentor" because in my opinion for Scala the old Perl motto "There's more than one way to do it" holds more than for Perl itself. I am sceptical that you will be able to reach that level of consistency with a style guide (For instance, I would consider it difficult to communicate in a style guide that developers should chose a monadic style with for-comprehensions over extensive pattern matching). I wish you good luck :-)
Thanks for the response, I guess, but if you could answer some (or any) of the questions I posted, or describe the experiences by which you came to your opinions, the extra context would help people determine the relevance of what you posted to their own situation.
I think you forgot to link something.
The actors were deleted before Future[Post] resolved
It's fascinating that people were fine with custom monads and "much implicit trickery" but are less sure about Akka. That's quite the opposite from my experience, so thank you for sharing.
 Atomically? what do you mean by that?
Even though they forgot the link, I‚Äôm going to take a wild stab in the dark and say it‚Äôs about replacing actors by an effect system, one by one. This being by John De Goes, I‚Äôm going to take another wild stab in the dark and say the effect type is going to be ZIO.
&gt;Maybe one last thing. I think, what makes or breaks using an advanced language such as Scala is that you have good mentors / benevolent dictators, which actively participate in the code review process and enforce a consistent style, architecture, code structure, and use of idioms. Maybe even better than "good mentors" is "one good mentor" because in my opinion for Scala the old Perl motto "There's more than one way to do it" holds more than for Perl itself. I am sceptical that you will be able to reach that level of consistency with a style guide We're wrestling with this now and working to create an internal document. So far, working by example seems to be the most effective way to communicate style preferences, and code review the best way to (softly) enforce them.
I am sorry, but I have to comment on that. John is being **intellectually dishonest** about the example he is giving in his talk and the comparaison he is giving out. &amp;#x200B; Yes actors are a primitive for concurrency and they have pros and cons like every tool we have at our disposal. Are we going to code banking app with actors ? No. Everyone knows that. You build something based on actors when you want to take advantage of clustering so you can scale by adding more nodes without caring where your actor is located. Can you do clustering with STM ? No. So if you want to compare tools, you have to do it coast to coast (with a comprehensive matrix for instance?). &amp;#x200B; John, if you are reading this, why do you have to compare things the way you are doing it ? You are doing self-advertisement for the libraries you develop and back-up, fine ! But do it with honesty. This is tilting me so much, because I see so many juniors falling into the shiny toy trap.
Most excellent! Love the steady progress. Very excited for Scala 3.
i need `export` so bad! really looking forward to scala 3 now. gonna start doing my personal projects in dotty when able.
What's that[1]? Thanks! class StringBuilder(s: String) { def this() = this("") // &lt;-- [1]: what's that? } StringBuilder("abc") // same as new StringBuilder("abc") StringBuilder() // same as new StringBuilder()
[removed]
a secondary constructor. instead of `class StringBuilder(s: String = "")` they define a constructor with 0 params that has "" as the string passed into the primary constructor
sure, but shining toy exactly why 99% of teams are picking akka (multiplied by Lightbend marketing)... so dishonesty from both sides
This is factually not true. Pure FP Scala is a tiny minority, look at the popular Scala projects on github - [https://github.com/trending/scala?since=weekly](https://github.com/trending/scala?since=weekly) \- 80% are not pure FP, the remaining is foundational \_libraries\_ like cats-effect, not applications. There isn't a single pure FP software suite under the Apache umbrella ‚Äì but there are multiple Scala applications. Like it or not, 'better Java' is what drawn and continues to draw businesses and open-source contributors in and trying to appropriate Scala away from non-FP community (aka 'sacrifice half the community') would only decimate Scala as a language and destroy it as the only popular contemporary FP platform.
Actors are being used for local concurrency though - akka-streams, akka-http, etc. There's nothing dishonest about promoting a better tool for these scenarios and John does openly admit that "procedural programming" is dominating distributed systems right now and there's no pure FP answer to that yet.
&gt;If you find yourself agreeing with the [Databricks style guide](https://github.com/databricks/scala-style-guide), use another language. What in particular is "wrong" about that style guide? At a cursory glance it seemed reasonable to me
I maintain the following: - Actors are currently the best solution for distributed programming in Scala - Actors are used extensively for single-node concurrency - Functional Scala (not just ZIO but the whole ecosystem, like FS2) is now the best solution for single-node concurrency All three can be simultaneously true, and I'd argue they are; that I didn't go into depth on all these topics is function of focus and talk length, but I think anyone familiar with my work already knows my views on these subjects (they aren't a secret). The transfer example in the talk is _pedagogical_. It's neither realistic for actors nor for STM, because no one is going to build banking software with either. Nonetheless, because everyone knows about banks, you don't need to introduce the domain, and you can focus on the actual technical issues (deadlocks, races, caching, and most importantly, compositionality of transactions). In a short talk, that's a huge win. Hopefully, people walk away from the talk not believing you would use actors or STM to build banking software, but understanding that actors give you transactionality inside the state of a single variable (the actor state), while STM gives you transactionality across the state of many variables. Combined with `retry` and the declarative semantics of STM, that's a potent brew and a powerful incentive to not (ab)use actors for single-node concurrency.
\&gt; Pure FP Scala is a tiny minority Yes, it is. It's the only part of the community using scala as a fusion language, though. Everyone else on that list of applications avoids using the advanced OOP parts of scala as "too complicated." It uses the advanced OOP parts of scala (higher-kinded polymorphism, typeclasses, implicit evidence, path-dependant types) to encode FP libraries that are more correct than what is available in pure Java code. That's why the libraries are so "foundational." Because they work, because they are extremely re-usable, extremely maintainable, and extremely high-quality, and because their semantics aren't contextual on things that can't be expressed in the code and type signatures of a program. Most better java programs eschew even basic principles of OOP, like SOLID. Everything is concrete. &amp;#x200B; Popular open source applications, some of which are on the github list: Playframework -- java and scala app. Spark -- java, scala, and python interpreter. Flink -- java, scala interpreter. akka -- java and scala actor programming application runtime. All of these things TARGET JAVA because java is a bigger user base and because there are more Java devs in the world. They could just as easily be written in Clojure or Groovy or any other JVM language to avoid the boilerplate. What is uniquely Scala about any of these applications? What makes Scala a particularly good candidate for any of them? How does using Scala actually make them easier to maintain or develop? So why did they use Scala? What does it make easier for them? Taken from [here](https://blog.softwaremill.com/why-scala-a6ac8c98c541): \&gt; Scala is an **immutable-first language.** Those popular apps you listed don't really use that feature. They use mutable classes assigned to immutable refs, meaning that the state will change but the global name will not. What does that really buy you, in terms of developing an application and maintaining one, over Java? Can't final do that already? \&gt; Scala‚Äôs support for **type constructors, higher-kinded types and typeclasses** (through implicits) make it much easier to work with wrapper/container-like types, such as Promises, Futures or Tasks. Those concrete implementations could just as easily be defined in Java (and are, with CompleteableFuture and its brethren in the Java standard library. The rest of the applications above eschew the parts (typeclasses, higher-kinded-types) that can't be done without AOP/other annotation driven programming methods in Java. Again, there's no need for scala to be able to use these constructs. What's so special about Scala here? \&gt; John de Goes mentioned some of the OO features which are useful in the purely-functional approach as well: **first-class modules** (via object composition), **dot syntax** (calling methods on objects) and **first-class type classes/instances**, among others. Literally every new language must have dot syntax to survive. Most OOP/better java enthusiasts eschew "**first-class type classes/instances."** Object composition is/should be standard practice for Java programs. So, striking typeclasses, what is left that is a Scala feature? \&gt; Like it or not, 'better Java' is what drawn and continues to draw businesses and open-source contributors in and trying to appropriate Scala away from non-FP community (aka 'sacrifice half the community') would only decimate Scala as a language and destroy it as the only popular contemporary FP platform. Every single feature that is better Java is being implemented in Java currently or could be implemented with regular user-implemented classes in Java, now. By using Scala, all you are doing is forcing contributors to learn a new language to avoid keywords and maybe some decent syntax with implicit classes. Is that really worth an entirely new language? I don't think so. I don't understand why you would reach for a new language for that -- those two features are not worth the compile time and the increased risk, and binary compatibility headaches, from an engineering perspective. For legacy applications, when those features or libraries using those features weren't popular in Java, I understand. Spark is one of those cases. Play and Akka and Flink are distinctly not, even though Akka and Flink are use-cases for which FP would shine and produce really modular, maintainable code. An example from metals, fairly high on your list: [https://github.com/scalameta/metals/blob/master/metals/src/main/scala/scala/meta/metals/Main.scala#L16-L27](https://github.com/scalameta/metals/blob/master/metals/src/main/scala/scala/meta/metals/Main.scala#L16-L27) The **MetalsLanguageServer** isn't an interface. There's 0 indirection there. If it's the main imperative shell, then why is Main itself so complex? If it shouldn't have been implemented in Java, then why are there vars all over its implementation? I know that performance is a reason. I know that choice is important, but I don't see anything there that cannot be implemented in Java and compile faster. Maybe all that was profiled and benchmarked to prove that giving up local reasoning and cohesion was worth it. Maybe it was just easier to model the state that way without thinking of an alternative way to do it. But that class could absolutely be written in Java and almost nothing would change. You could certainly still call through to Scala (albeit with some ugly syntax) when you absolutely needed to get access to the scala semantics from scalameta. So why does that class have to be written in Scala to work? What advantage are you getting there? I'd argue none. So why pay the Scala compiler penalty? My argument for sacrificing half of the community is this: If you don't, eventually all the above applications for scala will just transition to or converge on code you could implement in pure Java, because they can, because it is more familiar to Java developers, and because the Java community is MUCH, MUCH larger. At that point, the question should be asked by the maintainers, why is any of it written in Scala? What are we gaining? Scala won't just be decimated. It will cease to exist. As FP scala is the Haskallator (it's not, really, Java has too many good libraries to wrap for that to actually be true), OO scala is the Javalator. All our features are belong to Java, eventually. You've seen it with Future, with lambdas, with streams, with val, with value classes, with pattern matching, with actor systems, with traits, with type inference, etc. The only things left are singeltons as a first class language feature, implicit syntax extensions, path-dependent types, and implicit paramater lists/evidence/extension objects/typeclasses. Implicit syntax extension dsls and basic type inference, for someone that went through the DSL craze epitomized by [dispatch](http://www.flotsam.nl/dispatch-periodic-table.html), probably aren't the most compelling case for creating correct software, but [they are the core reason why Spark chose Scala](https://www.quora.com/Why-is-Apache-Spark-implemented-in-Scala). The question of what are we gaining without FP and encodings like Tagless Final/ZIO reader monad is increasingly not much, compared to cost of productivity and programmer ramp up time on engineering projects I am involved in. Of course, people don't really like to develop OO code in a modular style, either, at companies. I could be wrong. Ask yourself this question: if scalaz/cats/monix/shapeless ceased to exist, would you use Scala? If they stop being maintained because the community at large has decided that they just aren't worth the complexity, and you had the choice of Java 11 and Scala 3 for your new greenfield open source project, would you still use Scala 3? I honestly don't know the answer to that, if we aren't leveraging features that make the code easier to maintain and more correct.
I kinda thought so before but now I _really_ think that extension methods should support a dot, since method applications do.