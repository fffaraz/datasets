 SQL("SELECT `col14` FROM `sel_50` WHERE `col44` IN ("+strnums+") ") You're not supposed to do that.
People keep doing that mistake. Where did you see that?
I feared you might say that. I'll add it to my todo list. It's FIFO. ;)
You can use build.scala instead. Personally I find build.sbt easy enough but its probably stockholm syndrome.
That's even worse. See above regarding build definitions being declarative, which `build.scala` most certainly isn't.
I don't know. I spend most of my time writing applications and very very little time futzing with my build.sbt. It takes considerably less effort to configure a proper build with SBT than it does in gradle or maven or ant. On top of that its tailored to you as a Scala dev with all the nice fixins. Why not just use maven if your so keen on its philosophy?
I would much prefer a straightforward applicative API that does not obscure the underlying abstractions (such as they are; I am being generous) and that does not wire things together by out-of-band stuff like reflection and macros. I would be happy to write a program that describes my build; the DSL is confusing as all hell.
I like the fact that you can basically use valid Scala expressions anywhere. The problem is you don't want the ceremony of `import sbt.Keys._; object Bla extends Build { ... }`, so I came to prefer the `build.sbt` version. But then to forbid blank lines within a block statement is just… very annoying. Also having always at least three ways of expressing the same thing makes it very difficult to remember one consistent way of doing things. `project()` versus `Project()`, `settings()` versus `settings :=`. Then stuff changes all the time. `Project.defaultSettings` is now deprecated, and apparently the new cool way of getting that information is `Defaults.coreDefaultSettings`. I mean, really?? The cognitive load required for mastering sbt is just two magnitudes too high. I personally don't think that having a nice Scala-based build description and simplicity are contradicting goals. I'm not interested in Maven, Gradle, HOCON, whatever language, I really like writing Scala expressions. I think what sbt needs is a radical reduction of the API. I am using that stuff since five or so years, and I still can't remember what this configuration versus scope versus… really is. `(A in B) in C`, sometimes you need to qualify things with `in Compile`, sometimes you don't. Sometimes you need thisProject, then you have `ThisBuild`. It's just one big mess. Then you start to mix `build.sbt` and `Build.scala`, and it gets worse. Which is seen by which, how are they "glued" together?
Give up on SBT ever being usable. Its religion. Accept the stupidity and get on with your work. You're not the only one who thinks the situation is bad, but everyone else is tired if infinite academic arguments and has figured out how to make it do what they want it to do.
&gt;I like the fact that you can basically use valid Scala expressions anywhere. Why on Earth would you want to? The build file is supposed to *describe* the project—what it's called, what it's made of, how it should be packaged, where it should be published, which plugins should be applied to it. Why do you need to use Scala expressions for this?
Why would you want to write a program that describes your build, instead of writing a high-level description of it and leaving the details to the plugins? That was Maven's original purpose, and it was a laudable one. I don't understand why we've abandoned that ideal.
Then I'm not completely crazy for wanting to write a (highly declarative) build tool myself? 'Cause I do, and I do feel crazy for it. I feel like everyone but me has completely lost the way. But surely that's not possible… Edit: Then again, maybe my ideas really are that rare and awesome. In order for cool stuff to exist, *some*one has to invent it. But little old me? I don't know. And there doesn't seem to be much interest in this, or it'd exist already…
"The cognitive load required for mastering sbt is just two magnitudes too high." Amen Scala needs a new build tool. End of story.
That last part sounds more like a language feature issue. Perhaps `sealed` should be able to take a scope, like `private` and `protected` can? For example, `sealed[foo] trait Whatever` would mean that `Whatever`may only be (directly) extended by something living inside the package/class/etc `foo`. This would be along the lines of how `private[foo] trait Whatever` makes `Whatever` *visible* only within `foo`, but applying only to extending the trait.
&gt; I hope we can all agree that the syntax of SBT's build definition files (build.sbt, etc) is terrible. I don't agree. &gt; but it got one thing right: the build file should be as declarative as possible, with actual build logic belonging in plugins or scripts. Why is this right, in what way are POM files more declarative than sbt files? SBT's DSL is nothing but declarations. &gt; If SBT build definitions could be written in something like HOCON[1] from Typesafe's Config[2] library, that'd be great. From this example, I can only assume you're confusing declarative with structured. XML and HOCON are structured. SBT is isn't. 
I just don't know if a build can be done in a declarative fashion. There always ends up being some special case. If you look at the biggest build tool of all, make, it's essentially just a wrapper around shell. I used to hate sbt as well, now I have come to respect it, I feel like when my build is a mess it means i need to write some plugins to refactor it and whip it into shape. Everyone's projects are doing a lot of different stuff that I think it will be a while before things settle enough that there can be a declarative. This is the talk that really changed my mind on SBT, https://www.youtube.com/watch?v=y-_h_m4GjVo Banno made an in-house plugin that turns sbt and there release process into something simpler. If you want HOCON, maybe take the same approach. It's probably a couple hour project to write an sbt plugin that reads a HOCON file parses it and add its settings into the build. Write that plugin and then use it for all your builds, then put it up and github, and maybe try to get some traction. And ultimately that's what I like most about SBT, it makes it possible to write a plugin like that, natively.
I'm with you on your criticisms of SBT, but I would remind you that you can use Maven to build Scala projects. I do this all the time. Build tools end up complex and thorny because real-world builds are complex and thorny, as you probably know too well.
Really interesting! Just recently I fell into that .toDouble, .toInt trap so it was good to see why that smelled so bad and how I could fix it.
Totally agree with you about writing a plugin. The only thing I want to add that judging by the comments, it might be worth a look at the practice of the Scala and sbt and make plug-in for both approaches (declarative / imperative)?
Yes, and I do use Maven. But there's a problem: Maven is dead, and the carcass is starting to smell. Nobody's working on it. * Nobody's adding support for Ivy repositories (so I can't use Scala.js from Maven). * Nobody's tightening up the POM syntax. Having to write `&lt;groupId&gt;com.example&lt;/groupId&gt;` instead of `groupId="com.example"` is stupid, as is the absurd amount of nesting required for plugin configuration. * Nobody's converting it to use a DAG-based build plan instead of the overly-restrictive lifecycle phase system. * Nobody's cleaning up the three different dependency-injection systems (Plexus, Guice, and the plugin configuration thing) Maven bizarrely uses at the same time in different places. Maven is broken, and no one cares enough to fix it. I need a build system with a future. It has been obvious for a few years now that Maven doesn't have one. It's being abandoned by pretty much everyone, and rightly so. I keep hearing good things about Gradle and SBT, only to look at them and recoil in horror…
The principle that Maven tried to realize was that imperative build logic belongs in plugins. The POM was to be purely declarative. By moving out actual build logic, your POM represents an overview of your project, without getting too deep into the nitty-gritty of how to build it. As we all know, Maven didn't really achieve that. That was the goal, however, and I see no reason to give up on that goal.
I hear you on the sealed issue, it's pretty annoying. From what I understand the problem is that the compiler has to be able to find all the subclasses. Has anyone proposed an annotation or some other way of making the dependencies explicit? @inheritedBy(Bar, Bam, Bippy) sealed Foo Foo could then be inherited by anything in it's file + the classes specified in the annotation.
&gt;This is the talk that really changed my mind on SBT, https://www.youtube.com/watch?v=y-_h_m4GjVo You mean like dependency sets, plugins augmenting build configuration, that sort of thing? That is pretty cool. But those SBT build file snippets are hideous. I mean, `Blahblah.settings` on a line by itself? *Really?* What awful syntax. &gt;If you want HOCON, maybe take the same approach. It's probably a couple hour project to write an sbt plugin that reads a HOCON file parses it and add its settings into the build. Write that plugin and then use it for all your builds, then put it up and github, and maybe try to get some traction. Well, that's an interesting idea. I also just happened upon [a section of the SBT documentation](http://www.scala-sbt.org/0.13/docs/Build-Loaders.html) that includes a partial example of how to configure an SBT build from a Maven POM. Very interesting. But then, when investigating this possibility, I ran headlong into another problem: API documentation is almost nonexistent. Sigh. I finally find a possible way to fix what's broken about SBT, only to run into another brick wall…
&gt;Because sometimes you need to perform specific tasks that go beyond compiling Scala our java code. That's what plugins and/or scripts are for. &gt;Maven tried the full descriptive way with XML, we all know where it led. Yeah: tantalizingly close to success. But then Maven fucked it all up with that horrendous "Mojo" API, the POM schema being way too verbose (`&lt;build&gt;&lt;plugins&gt;&lt;plugin&gt;&lt;groupId&gt;com.example&lt;/groupId&gt;&lt;artifactId&gt;…`), the strictness of the POM schema making it inextensible, and so on. Worse, the developers don't seem at all interested in flushing all of the cruft and giving Maven the redesign it desperately needs, so there is no chance of this situation improving. Still, those flaws could be remedied. Maven is broken, but the concept of a declarative build file is not.
Is this ever going to be published into a Maven repository? I don't see any mention of anyone doing that…
How do you run it form the command line, since you can't run it form sbt???
I think expressions can be perfectly declarative. We're in a functional not only imperative language. Just to give my most common cases: - Changing dependencies based on Scala version (e.g. adding a module that was outsourced in a newer Scala version, or matching library versions). Like `val libVersion = if (scalaVersion.value startsWith "2.10") "1.2.3" else "2.3.4"`. - Using placeholders and composing strings. Like `def myPrefix = "baba"; name := s"$myPrefix-root`". - Setting publish repository depending on whether I'm working on a SNAPSHOT or release version - Defining common sub settings that can be re-used in different sub-projects Being able to do this with plain old Scala expressions makes it very straight forward. Please lets not invent a new language for that. As a side-effect, I can have IntelliJ IDEA type-check my build-file, add auto-completion and what not.
Between Github, the talks and Scala in Action, you can usually find something decent. But I agree, the API needs better scaladoc / examples. Wrote up a blog post here: http://tersesystems.com/2014/06/24/writing-an-sbt-plugin/
i'm too busy to watch a full hour of video and slides are not available. What is this "scala basis library" supposed to be and what is his overall approach? https://github.com/ReifyIt/basis doesn't have any documentation. It looks like he is trying to make his own scala standard library?
Declarative, similar to maven? that's a whole different kind of hell :) 
Type-checking is as simple as telling me that a settings key is misspelled or parenthesis missing. So to be precise, I mean parsing and presentation-compiling.
&gt; API documentation is almost nonexistent. Totally agree here. The [API docs](http://www.scala-sbt.org/0.13.5/api/) are a _joke_. They don't have _any_ human documentation. It's just: Look here's the classes and their methods, figure out what they do. It's all in the source code, yeah.
I used to think SBT's syntax was terrible, but then I tried to use Maven. Especially after writing some Build.scala files, it becomes more clear what's actually going on in build.sbt. 
You can get all the saneness of maven's configuration (seriously, I don't get why people complain about it because you usually have some dependencies, a standard source layout and some resource files to bundle in a jar, and nothing more) and sbt's incremental compilation with the maven plugin and [zinc](http://typesafe.com/blog/zinc-and-incremental-compilation) Bonus: it's built-in to the Scala plugin for IntelliJ ;)
I don't have a single comment to reply to, so I'll just reply at the root but summarize other comments. You seem to want a purely declarative build definition with a syntax that's lighter-weight than Maven. You seem to dislike sbt (and other build tools like Gradle) because they aren't purely declarative, and are amazed that anybody prefers them. You would use Maven, but feel that everyone is abandoning it. I think that many people would agree with [this guy's rant](http://kent.spillner.org/blog/work/2009/11/14/java-build-tools.html). I used Maven on a relatively simple project once, and that experience convinced me that Maven isn't just awkward in some situations; it's model is fundamentally broken. Sure, conventions are great, but not when they wreck flexibility. I'd happily deal with a few lines of boilerplate if it means that I can get my build to do what I want. I have limited experience with sbt and no experience with Gradle, so I'm going to say things that might not be entirely true. Feel free to correct me if I'm wrong. My impression of these tools is that they strive to hit a middle ground between Maven and arbitrary code. They realize that there is value in having standardized structure to your build, so they make you express your build with build-oriented concepts (tasks, task dependencies, filesets, etc.). But at the same time, they recognize that they can't have thought of everything, so they provide a way for you, the build engineer, to concisely express more complex things inline using an actual programming language. Used correctly, inline, functional expressions can actually make a build more readable (than pulling it all out to an external plugin). In my mind, embedded build DSLs strike a good balance between standardized convention and free-form script. I see this as similar to the balance that Scala strikes between purely functional and imperative. Sure, you should prefer the functional approach, but when you are faced with a problem where the functional approach is actually harder to understand, you can always fall back on a more imperative solution. When a purely declarative build is becoming too much of a hassle, you can fall back on a little functional code. But in the end, if you don't like these tools, and you're afraid that Maven is going to die, go ahead and write your own. You can make it as specific to your project or as general purpose as you want. If you want to make it purely declarative, you can do that. Go nuts. But if your plan is to make "Maven, but with a better syntax", don't be surprised when people seem disinterested. Many (most?) people have moved on from Maven.
While SBT's syntax is a mess, with far too much macro and implicit magic, with too much re-invention of standard concepts, I think the fundamental approach sound. For example, in my [Scala-Js-Fiddle build](https://github.com/lihaoyi/scala-js-fiddle/blob/master/project/Build.scala), I do things like having: - 5 different plugins - Multiple submodules - Which depend on a huge number of various third-party libraries - Some submodules having a compile-time dependency on others - Some submodules have a run-time dependency on the artifact of others - Some submodules have a runtime dependency not on the artifact of others but *their dependency' classpath* - The whole thing has to run in three different modes: using `re-start` during development, using `stage` during deploymend, or using `assembly` to generate an uberjar when I'm futzing around with OSv. How much did that cost me? That costed me 130 lines of SBT code overall. Consider how much you can get done with 130 lines of maven/ant (e.g. [this one](https://github.com/xetorthio/jedis/blob/master/pom.xml)) if you include your plugin internal code in that count! Some people would say "just don't have a complicated build!" but that's just dodging the problem. It's not like I'm making it complex for the hell of it. &gt; the build file should be as declarative as possible, with actual build logic belonging in plugins or scripts I think this is probably where we disagree. In Java land, it's normal to write overall terrible code, but sweep most of the mess under the rug as "helpers" or "plugins". This works great until you want to do something ever-so-slightly different, and then you find yourself needing to modify code written in three languages (Java, maven-XML, bash/ant) in 5 separate files to get it working. With SBT, the superficial layer is messier and more convoluted, but there is no "under the hood" for you to look into later. There is no pretending that "everything is declarative" while the plugin internals are all full of messy, imperative, fragile, non-generic code. The plugin internals look the same as the code you're using: not great, but OK and much more declarative than the inside of a maven plugin written in Java. 
I'm torn, we moved to gradle, from Ant (and a brief unsuccessful stint on Maven), and both cases are right: you want as much as possible to be declarative, but I've NEVER worked on a product where you didn't need to tweak the build and add tasks that plugins didn't support. In Maven, doing those tasks with plugins was stuff of nightmare, it would have required changes all the way to the customer's deliverable and deep refactorings that would make maintenance of 3 major branches (representing active, supported versions of our product) impossible unless done in all branches. And now the cost of doing this migration 3 times in branches that are already diverging would never past management (and frankly, it shouldn't).
I was thinking that myself. I'm hoping that `Vector`s and other `Array` backed structures will have very similar speedup to that of the `Array`.
It does look very exciting with a lot of potential. Waiting to see how it develops.
Because so far humans have failed to produce any such DSL that is adequate, but a well-designed API is well within our technical grasp.
I saw this in the github instructions, but where are the binaries and how do you run them? I don't want to run it via Eclipse. Here's what I'm getting now: scala -cp ./editor/target/scala-2.11/classes/:/editor/target:./editor/target/scala-2.11/classes/scalalogging-slf4j_2.10-1.0.1.jar ./editor/target/scala-2.11/editor_2.11-0.1.jar java.lang.ClassNotFoundException: com.typesafe.scalalogging.slf4j.LazyLogging at java.net.URLClassLoader$1.run(URLClassLoader.java:366) at java.net.URLClassLoader$1.run(URLClassLoader.java:355) at java.security.AccessController.doPrivileged(Native Method) 
Binary Releases: Exe for windows, tar.gz file for Linux/Mac. https://github.com/tommycli/rpgboss/releases
The build instructions here show you how to run it from source using SBT: https://github.com/tommycli/rpgboss/blob/master/README.md
PMed you.
Very well said. I think the underlying idea and architecture of SBT is correct, the DSL is where it fails. I think the latter could be improved quite a bit, even if it means forcing everyone to write simple scala code that returned a configuration trait of some sort. 
&gt; That's what plugins and/or scripts are for. I don't agree that every time you ever need to have some logic in your build you should make a plugin. Making plugins carry a maintenance cost and there are plenty of situations where having a few lines of code is cleaner and more cost effective then having to build out a plugin just do some rather simple and trivial modifications. Having to make a plugin in any build tool will require another level of sophistication with that build tool, when it would be far more useful and nice to have a middle ground that allows you to extend the build and be expressive without having to get into plugins and learn build tool internals.
&gt; As we all know, Maven didn't really achieve that. That was the goal, however, and I see no reason to give up on that goal. If that was the stated goal, and despite trying hard to accomplish it Maven couldn't, doesn't that tell you something about the goal?
Looks great, I actually used an earlier version for a while and saw good results. I wonder out of this and Scalaxy Streams ( https://github.com/ochafik/Scalaxy/tree/master/Streams ) which one will get mainstream adoption first. Both focus on rewriting inefficient collection operations. Just as a curiousity more than anything, as neither requires significant buy in.
Thanks for the link! I've submitted a separate post/link for that now.
Did anyone do any benchmarks?
What is the relationship of this project with ScalaBlitz? They seem to share a common root—both provide a macro called `optimize` that rewrites the collection calls. Scalaxy in addition seems to have a complete compiler plugin.
Maven did come close. There's a reason I'm recoiling in horror at SBT and Gradle, despite having previously used Ant and Make. Maven brought me closer to simple, declarative builds, and SBT and Gradle are a step backwards in that regard. Besides, no great achievement was ever made by giving up when it got tough.
I haven't looked too hard at it. My first reaction was "lol, Ruby". Still, that's not really fair, so I'll have to give it a harder look. Thanks for reminding me!
For me, it's pretty heavenly until the declarative façade breaks down. Which it does, almost immediately, because nobody's been fixing the years-old problems with it. Sigh. That doesn't mean it *can't* be fixed, but it does mean that it *won't* be. So I have to look elsewhere for my solutions…
According to [slide 58 on the Scaladays presentation](https://scala-blitz.github.io/talks/scaladays2014-final.pdf), fusion is when you have a lot of operations that independently iterate a collection (say you're calculating the average by checking the size and sum of elements in a linked list) and transform them to use a single iteration. Edit: wording
Good to know. Thanks.
Why is it so hard, anyway? Maven, fundamentally, does only a few things: 1. Resolve and fetch dependencies 2. Compute effective POMs 3. Load and run plugins in the right order Of these, #1 is already done and available in library form (Ivy, Aether) and isn't horribly hard to do from scratch (flatten a graph, download some files, parse an XML document or two). #3 can be tricky, but it's been done a million times, too. They aren't necessarily trivial, but I don't see why they're so insurmountable, either. What about SBT? Does it do anything special?
That would be a lot easier if Scala.js was available in a Maven repository somewhere…
Yeah, if only it was as simple as [`"org.scala-lang.modules.scalajs" % "scalajs-sbt-plugin" % "0.5.0"`](https://github.com/lihaoyi/workbench-example-app/blob/master/project/build.sbt#L2) it would be way easier than having to compile the Scala compiler from source every time using a potato
SBT is an abomination. No way in hell am I going to use that crap. Show me a build tool that doesn't suck, and I'll be all over it. So far, however, Maven seems to be the least-stinky of a collection of turds. Gradle is worse. SBT is *much* worse. Ant is the bad old days. Edit: If you want to know more about my opinion of what's wrong with SBT, please see [this thread](http://www.reddit.com/r/scala/comments/2945vw/will_sbt_ever_have_a_sane_builddefinition_syntax/).
Really? That's wonderful news! Thank you for telling me.
Awesome! Maybe I'll get my wish yet.
Agreed. Pattern matching, while more verbose, often communicates intent much more explicitly - especially if there's a large amount of code behind each door.
My body is ready.
I think this was already covered in Mr. Odersky's Coursera course about [Principles of Reactive Programming](https://www.coursera.org/course/reactive). I remember having used aync and await in one of the exercises.
Unordered should have a branch to allow duplicates...
The default for the mutable case should be AnyRefMap.
Well, you can try and see how hard it is. Covering the 80% that a tool to scratch your personal itch will need to cover will probaby be as easy as you think. But that other 20% to cover all the 8 zillion use cases and exceptions to exceptions that a general-purpose build tool will need to cover will likely be hard. For example, "computing effective poms" can get hairy in light of pom inheritance, profiles, different config files, etc. Now you might not want all of that - I'd scrap profiles at least if it were me - but you'll almost certainly want submodules and some way to factor out common build information, have per-submodule configurations, keep things like credentials out checked-in build files, and stay DRY. 3) Could get tricky if you want to give people an easy way to plug in new functionality, or when people want to define their own "right" orders. There's an 80/20 rule here too. I'm with you that 1) is probably "solved". Good luck! (Just to be explicit, I don't mean any sarcasm, I'm totally serious.)
A shame you can't resist spamming completely unrelated threads with it. I'm beginning to suspect you're one of Cedric Beust's sock puppets.
Last I checked, `"org.scala-lang.modules.scalajs" % "scalajs-sbt-plugin" % "0.5.0"` is SBT syntax. How is that unrelated? Also, who the hell is Cedric Beust, and what the hell does he have to do with my criticism of SBT and desperation for a better build tool?
Hear, hear. I guess staying with 2.11 wouldn't be so bad if a Java 8 JVM wasn't an option.
&gt; Last I checked, "org.scala-lang.modules.scalajs" % "scalajs-sbt-plugin" % "0.5.0" is SBT syntax. How is that unrelated? Still just an expression, of type `ModuleID`, as documented [here](http://www.scala-sbt.org/0.13/tutorial/Library-Dependencies.html). But by all means, keep up the performance art. Very entertaining.
Especially since JDK 7 will stop receiving public updates in April 2015.
This functionality is part of my tiny collections extensions library [KollFlitz](https://github.com/Sciss/KollFlitz#on-any-type-of-collection-sequential-or-not-iterable) val mm1 = pairs.toMultiMap(_._1)(_._2) // Map[Int, IndexedSeq[String]] You can even enforce the aggregation type, e.g. val mm2: Map[Int, Set[String]] = pairs.toMultiMap(_._1)(_._2) 
An expression that is only meaningful within the context of SBT. Ergo, SBT syntax. Ergo, related.
_Of course_ an _expression_ is, _by definition_, only meaningful in a particular context! You seem to think waving your hands in the air and yelling "syntax!" while ignoring _how expression-based languages like Scala work_ is somehow significant, let alone profound. It's not. Once you learn that Scala doesn't even have operators—those "%" signs are just good old-fashioned methods, just like everything else—and understand how implicits can make types that don't implement the method (e.g. String) act like they do, this whole house of cards you're trying to build comes tumbling down. It's pretty funny: you complain about sbt and say you want a build tool whose project definitions are declarative. But sbt build definitions are just lists of transformations of a `Map` from `Keys` to `Settings`! They're utterly declarative! So here's the thing: you either don't really understand sbt, in which case you have some learning to do, or you do, but you're trolling. At this point my money's on trolling, so this is the maximum extent of my willingness to play along.
&gt;Some submodules have a runtime dependency not on the artifact of others but their dependency' classpath If you need a single dependency to effectively be shorthand for a set of dependencies, you can do this in Maven by writing a POM with `&lt;packaging&gt;pom&lt;/packaging&gt;`, declaring your dependencies in it, and then depending on that POM. (Note that the `&lt;dependency&gt;` will need to have `&lt;type&gt;pom&lt;/type&gt;`.) It's pretty hackish, and Maven really ought to have proper support for dependency sets, but this is a halfway decent workaround. &gt;This works great until you want to do something ever-so-slightly different, and then you find yourself needing to modify code written in three languages (Java, maven-XML, bash/ant) in 5 separate files to get it working. Any project that involves both "maven-XML" and "bash/ant" is doing it wrong. Not the fault of the build tool that some programmers are incompetent.
Or you could invoke that flexible scripting tech *from* your build tool, and keep that clutter out of the main build file. Scripting languages are already a thing. There is no need to pollute your POM/`build.sbt`/whatever with complex scripts.
As I recall, the `scala-maven-plugin`'s Zinc support is broken because it brings in two different `scala-library` versions. Failtality. I hope that's been fixed, because it was pretty embarrassing when I ran into it.
&gt;I used Maven on a relatively simple project once, and that experience convinced me that Maven isn't just awkward in some situations; it's model is fundamentally broken. Could you be more specific? &gt;Sure, conventions are great, but not when they wreck flexibility. They don't. With Maven, you are expected to write plugins if you need any non-standard behavior. Of course, this would be a more reasonable expectation if Maven's plugin API wasn't so terrible…
The signature that I'm after is something like: Seq[(A, B)] =&gt; Map[A, Seq[B]] That is, I have a list of pairs. I want to find the set of unique `_1` values. Then, I want to group the `_2` values by their corresponding `_1`. A longer and less efficient implementation would be: val keys = pairs.map(_._1).toSet keys.map { k =&gt; k -&gt; ( for { p &lt;- pairs if p._1 == k } yield p._2 ) }.toMap That for expression could be replaced by a call to `collect`, but I don't know that it would be any more concise. `foldLeft` is powerful enough to do it all in one step (no need to generate the key set first), but that would just end up being more code than the `groupBy` that I showed originally. pairs.foldLeft[Map[Int, Seq[String]]](Map.empty.withDefaultValue(Seq.empty)) { case (acc, (k, v)) =&gt; acc.updated(k, acc(k) :+ v) } So in the end, I was just wondering if there was an even more concise form than the `groupBy` that I originally had. 
Why only mutable collections?
A side effect of requiring Java 8 is that you can no longer use Scala for Android, or your libraries developed in Scala, because only Java 6 bytecode is supported. Which is a bummer now that we have devices that can cope with the additional bytecode Scala often produces. 
&gt; The signature that I'm after is something like: Seq[(A, B)] =&gt; Map[A, Seq[B]] Ok, sorry for side-tracking the conversation a bit, but it seemed worth checking. Just to reinforce your guess and get back on track: &gt; That for expression could be replaced by a call to collect, but I don't know that it would be any more concise. Yes, the "if" syntax within a for {} is the equivalent of _.withFilter , which also (conceptually) is much like collect in that it allows for a single traversal along with map(_) - it's lazy. It's possible that many/most/all of the standard collections are actually using withFilter to implement *collect*, I don't really care =P Check the relevant collections doc for withFilter when you want to see it. &lt;/tangent&gt; From your example val keys, it seems like groupBy is doing exactly what you want, except extracting the tuple...? Any other result desired would require a more complex function to pass to groupBy - so I'll try to give you a way to expand on the idea: As for your groups: Have you taken a look at the example function I wrote, "myPairFunction"? I was focusing on your original post, but the result type you mention here is a little more straightforward to work with. groupBy can't express the behavior you're looking for exactly. Depending on how well encapsulated you are and how much performance you need, a MultiMap might work: val pairs = Set((1, "one"), (1, "uno"), (1, "a"), (2, "two"), (2, "dos"), (2, "b")) import scala.collection.mutable.{MultiMap, HashMap, Set} val mm = new HashMap[Int, Set[String]] with MultiMap[Int, String] for( (k, v) &lt;- pairs ) { mm.addBinding(k , v) } If you are concerned with client-control, you can limit access to immutable inferfaces. Otherwise, you might want to mix up your own collection types, which is probably over-kill, or try starting from a different collection type than you already have. Personally, I'd prefer composing a better function to use with fold or groupBy/map/unzip/whatever, rather than using a mutable collection, but there's the code right there if you want it. I shouldn't be giving advice when I'm this tired, the orangered popped up just before I shut down. Good luck, and let me know if you need more.
This is going back like 5 years, so I don't remember exactly. If I remember correctly, we had our code split into several projects, because we needed to generate several JAR files. For example, one JAR was strictly interfaces, one JAR implemented those interfaces, and a third consumed the interfaces (but not necessarily the implementations). If I remember correctly, we were finding that Maven would try to build dependant_project against an out-of-date version of dependency_project that had been cached in the .m2 directory. We spent probably a day trying to figure this out and, in the end, we wrote a thing that would simply delete files out of the .m2 directory, and we ran that at the start of our build. That sounds like a terrible solution, and it is a terrible solution, but like I said, we worked on this for a little while and couldn't find a better answer. And it seems like the sort of thing that Maven would do automatically, but like I said, we were having problems. None of us were Maven experts, but what we were trying to do shouldn't be that complicated. Maybe we just ran in to a Maven bug. Maybe we had something in the wrong pom file. Who knows? That and other nonsense caused me to drop Maven and never look back.
Was it a multi-module project?
Yes.
Did you `mvn install` the needed submodules and/or the whole project first?
What is the problem updating to JDK 8?
Alright, just for you, I dredged up some notes that I had made at the time. This is not 100% accurate or correct, but it went something like this: So we had several modules, each with their own POM. We also had a separate POM (which I will call the "everything" POM, even though I'm sure it had a better name) that named all the other module POMs (as `&lt;module&gt;`s). Each module POM also had explicit dependencies on the artifacts from the other modules (as `&lt;dependency&gt;`s). We wanted to be able to `mvn compile` or `mvn test` (is that even valid?) on the everything POM and have Maven build everything that was out of date. My recollection is that Maven would not do this. Suppose A depends on B, and they had both been previously built, but have both have had source changes since then. My recollection is that Maven would say "oh hey, I need B to build A, but there's already B in my cache; I'll just use that". Which I don't think is what it's *supposed* to do, but it's what was happening to us. We just got tired of all the random failures. I wrote a shell script (which I called "marvin") to clean out files from the `.m2` directory at the start of every build, and although things took longer to build, the builds were more predictable and we ended up wasting less time. Now, like I said, it's completely possible that we were using Maven incorrectly. We might have missed some key point, or we might not have read the right web page. Who knows? The important thing is that Maven's syntax and structure were sufficiently opaque to us that we ended up working around Maven in order to use it. This is the problem that I have with the notion that "declarative build is best build". It only works if the declaration syntax is expressive enough and if the engine that is driven by the declarations is transparent enough. In my experience, Maven fails both of these tests. (And, to your original point, so does sbt.) I could say a lot more, but at this point I'm just sharing my opinion based on admittedly limited experience. I don't know whether Maven is a good idea with a bad implementation, a bad idea from the core, or a wonderful idea that my tiny brain can't quite grasp. But my opinion is just that - my own. If you think Maven had good ideas behind it, and do actually write your own build tool, I would love for you to report back here on Reddit somewhere when you have something to show. Obviously, you have no obligation to prove anything to me, but I would be delighted if you could convince me to change my opinion. Good luck!
&gt;We also had a separate POM (which I will call the "everything" POM, even though I'm sure it had a better name) that named all the other module POMs (as &lt;module&gt;s). That is generally referred to as a "parent POM", FYI. &gt;We wanted to be able to mvn compile or mvn test (is that even valid?) on the everything POM and have Maven build everything that was out of date. If you do that, they won't see each other's newly-built jars. You must use `mvn install` instead, to install the new builds into `~/.m2/repository`. It's kind of stupid, honestly. Maven really ought to be smart enough to wire together dependencies among modules without requiring them to be installed to the local repository first. But it isn't, so that's what you have to do. &gt;The important thing is that Maven's syntax and structure were sufficiently opaque to us that we ended up working around Maven in order to use it. No arguments there, I'm afraid. &gt;This is the problem that I have with the notion that "declarative build is best build". It only works if the declaration syntax is expressive enough But you can create your own expressions (i.e. plugins) to do any custom work you need. How can you possibly be limited by the declarative syntax (other than its verbosity, which Maven has a really bad case of) when you're allowed to add to it?
&gt; But you can create your own expressions (i.e. plugins) to do any custom work you need. How can you possibly be limited by the declarative syntax (other than its verbosity, which Maven has a really bad case of) when you're allowed to add to it? Indeed, you are correct. I could, for example, use the Ant plugin to actually express my entire build's logic in Ant. But I wouldn't use that as evidence that Maven is expressive. 
I'm afraid I don't understand your reasoning. Running plugins is what Maven is *for.*
So suppose that, for my particular project, the normal src/main/java and src/test/java separation isn't good enough. I want to build three JARs, and those three JARs need to share some class files, but also each need some unique files. (Maybe we make a product that we offer with three different configurations: Free, Pro, and Ultimate.) Now, ideally, I'd like to compile each .java file once, but then I want to package them into separate JAR files. Or maybe, to ensure that I don't create a `ClassNotFoundException`, I want to compile the java files that go into a single JAR together; in this case, the shared classes will get compiled multiple times. But whatever the case, I want all my source files to occupy a single file tree, because I don't want to maintain separate copies and because my filesystem / source control system doesn't properly handle hard links. That's easy to do in Ant - or more precisely, I know exactly how I would express that in Ant. I don't even know if it's possible to do in Maven. Well, OK, to your point, I could definitely do it in Maven... but I might need to write my own compiler and jar plugins, unregister the default ones, and register my own. Alternatively, I could (with probably far less work) just write the Ant script that does what I want, and then I could probably ask Maven to invoke my Ant script. But that's clearly cheating! Sure, I'm technically using Maven, but I'm opting out of everything that makes it Maven. Now, the correct response would probably be something like "that's not how Maven is meant to be used" or "you should restructure your build to better match Maven's default rules". Maven is an opinionated tool. It says "sure, I'll build your software, but you're going to do it on my terms". There is value in that, but it also cuts down on the flexibility. Or indeed, to your point, it doesn't actually limit Maven's *potential* capability, but it does make some things hard enough that it's easier to just switch to a different tool, which creates a limit on Maven's *effective* capability. 
To do that, make a multimodule project, with three modules: `free`, `pro`, and `ultimate`. The module `pro` should depend on `free`, and the module `ultimate` should depend on `pro`. Since you want three standalone jars, use the `maven-shade-plugin` to merge the contents of the lower editions into the `pro` and `ultimate` jars (and whichever other libraries you want to merge in, if you want that). You don't even have to write any plugins to do what you want there. That's basic stuff.
What about creating a better DSL and provide it as an addition to SBT? If people are switching to your (better) DSL it could become the standard.
Yeah, I'm still not seeing it. You seem to be trying to demonstrate that a free-form build system is better and a declarative build system is too restrictive, but I remain unconvinced that this is actually the case.
Yeah, that has been mentioned elsewhere on this thread. The problem with that idea is that SBT's API documentation is basically nonexistent, which makes it really hard to figure out how to do this.
Oh, wow, a lot of new projects since last time I checked!
Then I think we're going to have to agree to disagree. I feel like I haven't done a very good job of explaining my thoughts, but I still believe strongly in my position. Anyway, the conversation was fun!
It's not just about the API, it's about translating high-level functional and object-oriented expressions into low-level bytecode. Scala 2.12 only going to produce Java 8 bytecode. Android is a strange duck, because it has nothing to do with Java bytecode, instead your machine converts the bytecode the Java compiler produces into a bytecode Dalvik / ART can consume. And that converter maybe can support Java 8, but I have the feeling that Oracle would not be overly happy to see the Java ecosystem growing. I do hope that we won't stuck with Java 6 bytecode and the Java 7 API forever and ever on Android. 
That's exactly what I was trying to say. Given that Scala 2.12 does not use Java 8 API but merely emits Java 8 byte-code, you can still use retroweavers to convert the Java 8 class files into Java 6 class files, as far as I know, and hence feed them afterwards into the Dalvik compiler.
Seems incomplete.
I miss at least http://www.scaladays.org/#schedule/Scala--The-First-Ten-Years and http://www.scaladays.org/#schedule/Simplifying-Scala---The-Past--Present-and-Future
http://www.reddit.com/r/programming/comments/29tala/crosslanguage_performance_benchmarks_java_vs/ciohc4v
https://news.ycombinator.com/item?id=7988738
Thanks, I'll find out what's happened to them.
Author here. Thoughts, comments, questions? Let me know.
Generally, people tend to avoid using alphabetic methods without periods, so your intuitions are shared by majority. Symbolic methods (aka "operators") are usually used without periods, exception being postfix operators (like `!` and `!!` from scala.sys.process) The main reason for using periods is precedence: if you have a chain `a.b(c).d(e).f(g)` and you remove periods in one place, you must remove them in all positions to the right: `a.b(c) d e f g`. It becomes harder when you have a method with no parameters, like `reverse`: `a.b(c).d(e).reverse.f(g)` cannot be `a.b(c) d e reverse f g` or `a.b(c) d e.reverse f g`. Of course sometimes omitting periods leads to cleaner and more maintainable code. For example, `2+2` is cleaner than `2.+(2)`
Thanks for the explanation! That's helped.
I use IntelliJ, and SBT with the "android-sdk-plugin". Although certain parts are new and weird and bizarre, I ultimately found it quite breezy and comforting. The SBT build config file is a little heavy for a beginner, particularly since SBT let's you configure using real code instead of, say, XML, and because the android setup is inevitably going to involve some calls that are difficult to track down and understand. So some of it you sort of have to take on faith early on or straight up copy from documentation :D There's some caching magic that makes Proguard a little faster as well. The first build is kind of crazy, but it's not a big deal since incremental building is so quick. SBT makes dependency management SO MUCH FUCKING EASIER that I can't believe that I never used similar tools for earlier projects (like Maven, CocoaPods, etc.) Aside from the SBT and "android-sdk-plugin", IntelliJ hooks up to my device just fine through its own great Android plugin. So capturing screenshots and just basically sensing the device in real-time happens through the IDE. I set up a simple external build option in the IDE that calls out to a command made available by the android-sdk-plugin to build &amp; install to the device. Pretty painless. So really, IntelliJ acts mainly as an editor, not a build tool in this case. You turn "Make" off. SBT handles the building, with the help of "android-sdk-plugin" to actually install the APK on your device. The whole process of Run -&gt; Compile -&gt; Proguard -&gt; Install to Device is pretty quick and painless. There is a lot happening for you behind the scenes. Proguard is configurable through your build.sbt file. IntelliJ CE 13 has a pretty nice feature set, good Scala and Android integration. I have NOT tried the Eclipse Scala IDE but am interested. I never cared too much for Eclipse, but IntelliJ (after I increased memory size for the application) has been very snappy and fun to use. It finds new files added through the filesystem very quickly.
It totally is. Try IntelliJ with SBT. There are a couple of good SBT android plugins out there. Just try to follow the instructions and force yourself through it, you'll get there.
I'm skeptical about Scaloid. I really like having the ability to preview my layout files. I don't like the idea of defining UI in code. Back in '09 and '10 I had a lot of egotism against using Interface Builder, but eventually got around to using it and found it to be so much easier than trying to use a "forward-kinematics" sort of mentality for defining relative positioning in code. I can't believe I did all that, when you could just drag and drop controls and use springs &amp; struts. Obviously AutoLayout is one step ahead of that (of course, with its own learning curve) but these core tools aren't created to be casually ignored, you really have to pay attention or pay the price. 
I find that functional constructs, specially ones that are meant to be chained, look better called without dots, specially if spanning multiple lines Seq(10, 20) map { _ * 10 } map { _ + 20 } vs. Seq(10, 20).map { _ * 10 } .map { _ + 20 } Unfortunately things get a bit ugly if you need to call 0-arity methods. 
You are confusing _postfix_ with _infix_ syntax. Postfix means the method has no arguments. The example is `reverse`. This can cause problems with the semicolon inference and is thus not recommended. Whereas `map` takes one argument and may thus be used in infix syntax (`receiver method argument`).
You're right, thanks for the correction.
Folding is said to be a core-FP technique. I also "like the idea" of folding and I occasionally try to use folding in my code. However, for non-trivial cases, often I get really hard-to-track type errors and type inference problems. As it's sometimes the case with scala, it takes so much time to fix those, that the joy of FP-elegance is a bit ... clouded in the end. What's your experience?
Agreed, unnecessary marketing hyperbole. Fortunately, he doesn't at all talk like a rawkstar during the interview. Not sure what SQL has to do with functional programming though. *Declarative* programming perhaps...
I don't mind people talking like this. It's like stamping your forehead with "ignore me!". Saves me a lot of time on deciding who to listen to and who to ignore.
Scala team has been hedging quite a bit around Dotty, probably a good idea, don't want to give the impression that the language in its current state is unmaintainable (as a certain PP has indicated on a "few" occassions). the tl;dr seems to be: at some point in the future Dotty features *may* make their way into mainstream Scala; if so, they'll provide automatic migration functionality (there's a Github issue on this in the Dotty repo). As an added bonus the simplified type system will it make it easier to improve on existing tooling (esp. in the IDE department). Rod Johnson's controversial keynote last year doesn't seem so controversial now. In a few years this talk will have become reality.
&gt; Scala team has been hedging quite a bit around Dotty, probably a good idea, don't want to give the impression that the language in its current state is unmaintainable (as a certain PP has indicated on a "few" occassions). An odd conclusion to draw from an interview that discusses the _success_ of the 2.11 release and the _commitment_ to a successful 2.12 release. But by all means, keep spreading the FUD. &gt; As an added bonus the simplified type system will it make it easier to improve on existing tooling (esp. in the IDE department). Yes, especially for tools that _don't use the actual Scala parser or typechecker_, e.g. IntelliJ IDEA. &gt; Rod Johnson's controversial keynote last year doesn't seem so controversial now. In a few years this talk will have become reality. I presume you mean the one discussed [here](https://www.youtube.com/watch?v=hZlxBRnxzDc). I'm curious which of Rod's comments you think are reflected in anything Jason said, or, to broaden the topic as charitably as possible, how anything any of the other panelists said contradict anything Jason said.
Yeah, I know. I wanted to draw attention to the fact that there was a follow-up, with a panel discussion, that I think helped clarify Rod's points, as well as offering some of us (I was one of the panel participants) the opportunity to explore the issues with Rod. To the point of this thread: having done that, I don't see the connection the OP made between Rod's keynote and the interview with Jason. That doesn't mean it doesn't exist. But having participated in the panel discussion with Rod, I think I'm in a reasonable position to question it.
Ah, ok. I thought you intended to link to the keynote instead of the discussion about it. I think I have some ideas about which connection there is between the blog entry and the keynote, though I will wait with sharing them until I have watched the discussion about the keynote.
That's certainly fair enough. Again, I won't insist there _is_ no connection; I don't think expatcoder is either delusional or dishonest. Only that, like the rest of his post, I think it's quite a stretch. :-) But I'm open to being shown. **Update:** I should try to be clearer: expatcoder and one or two other people seem to believe that, somehow, Paul Phillips' frustration and departure from Typesafe and/or Rod's keynote signal some sort of doom-and-gloom end for Scala. Not only do I not believe either of these is true in isolation—I don't believe either gentleman intended to be read that way, and have first-hand knowledge of that in Rod Johnson's case—attempts to lump them together to bolster this "insight" immediately smack of desperation in chasing a chimera to me, and that's primarily what I'm responding to here. OTOH, I should let it go: the very fact of Scala's increasing industrial adoption is its own rebuke to the FUDmongers.
 The main perspective that I believe /u/expatcoder has in regards to the keynote is in regards to the keynote's presented views and claims regarding the evolution of Scala and changes to the core language (and less on the keynote's discussion of other topics such as FP and OOP in Scala and styles of programming). The keynote claimed that the development of Scala both should and will slow down the changes to the language and instead focus more on general compatibility and improvements to the runtime, compiler, IDEs, tools and libraries, among other things. From this perspective, the blog's discussion about Scala and version 2.11 and 2.12 fits well with the keynote's predictions, since both versions focus a lot on compatibility instead of changes to the language. It also fits with Dotty and future potential major changes being handled carefully with considerable migration and compatibility focus.
Yes, but the fact it's a Scala-lookalike is irrelevant: the bottom line is that the creator of Scala has moved on to work on another language, which is not a good sign for Scala. 
From Dotty's GitHub page: &gt; Dotty is a platform to try out new language concepts and compiler technologies for Scala. ...it's a research project specifically for Scala. How do you come to the bottom line that working on Dotty is not working on Scala, or that it is not a good sign for Scala?
Updated to 0.2.0. You can infer type at with Ctrl+. (mac: Cmd+.) and you can insert it as a comment at the end of the line(#10). Also I fixed a issue where the classloader was not picking up the project classpath (#13).
I guess I can see this—but it feels to me like claiming the validity of horoscopes when they're so broad as to cover anything. _Of course_ changes to the language will slow down, both because of convergence on a sensible design and due to increasing industrial pressure. _There already were improvements_ to the runtime, compiler, IDEs, tools and libraries by the time Rod wrote his keynote, so that's a _retrodiction_, not a prediction. From where I sit—as a Scala user literally every day for the last 8 years or so, 3 of them professional—this _still_ looks like quite a bit of sniping-from-a-distance, and claims of validation by reference to Jason's interview... self-serving, I guess, is how I can best put it. But since my question was "how do you get there from here?" I have to thank you for taking a stab at it.
The specific issue with `contains` is due to `List` in the standard library being covariant; the straight-forward type-safe signature isn't allowed due to it otherwise having an argument in contravariant position. A simple alternative would be to have an invariant `List` instead, but this would not be as flexible or convenient. The more general cause seems to me to be that the Scala standard library sometimes prioritizes flexibility over type-safety. Another example is `reduce`, which throws a runtime error if the collection in question is empty. The Java implementation of `reduce` returns an `Optional` instead, and thus is more type-safe (I personally use `reduceOption` in Scala). For a library that is more focused on type-safety, I believe Scalaz is a good option.
I generally roll my eyes at PP's ranting, but List.contains *everyone* will be bitten by at some point. It's what I meant by edge cases you must keep in mind when working in Scala. Every language has their gotchas, Scala is no exception, have to learn the ropes, what to follow and what to avoid.
This really cool. Going to try it out. Thanks :)
Nice post, though I have a couple thoughts: Imo, the Option transformer itself should follow monad laws itself, which it does not. If you do this, you can also avoid using the type lambdas by using higher kinded type parameters on your type class hierarchy. 
No, `nextBoolean` is a method on the object `scala.util.Random`.
true. I should have specified... does it _contain_ a closure, such that using the method introduces a closure into my code... For instance, Predef.println("close") is certainly a closure, even though it is a method of the Predef object.
Good point, it should be fixed now - thanks for reporting :)
I do indeed know what a closure is in the mathematical sense: FP seems to have a somewhat different definition... I would claim that println leaves side-effects on the screen/stdout-- References and alters an environment outside of the function's scope/ arguments/ return value. Moreover, any function that contains or is composed of a closure is itself a closure. What do _you_ think a closure is?
But it is something that is a closure. They are indeed NOT orthogonal concepts! I could have just as easily posted those exact same links to support my claim that println _is_ a closure. From the link you were kind enough to post: &gt;A closure—unlike a plain function pointer—allows a function to access those non-local variables even when invoked outside its immediate lexical scope. As I was saying: stdout is beyond the lexical scope of the arguments and return value of the statement-- unless you consider the entire machine to be "in-scope" in some perverted sense.
No, that's still not a closure. What you are trying to describe is called a pure function (yet another orthogonal concept), a function that only depends on its arguments. u.R.nb takes no parameter and returns a different value every time it's called, so obviously it cannot be a pure function. That answers your question. Now, does it really matter?
Prevention of side effects is not (cannot) be enforced by Scala's type system. That means it is your responsibility to put mechanisms in place if you need to protect against unwanted side-effects. Detecting something like printing to console is impossible in Scala (unless of course, you redirect the console output and thereby detect writing). A good coding style will be to make side effects visible, for example in the method signatures, and to contain these as much as possible. You can document requirements via Scala doc, but that's about it. There was a research project at EPFL, [Capabilities for Uniqueness and Borrowing](http://lampwww.epfl.ch/~phaller/capabilities.html), based on a compiler plugin, but I think that remained mainly a research project and it is not maintained any longer.
Some more thought, would it be feasible to roll back the new tree structure into the core compiler in case it turns out to work well for macros? If what we right now have in scala.reflect is a "reflection" of the compiler AST it would seem a lot of sense to replace it with this vastly simplified model.
Does anyone know what the problems are with scala.reflect that motivated `scala.meta`? 
There is some information at the scala.meta site. http://scalameta.org/ Specifically the link to this presentation and the slides http://www.parleys.com/play/53a7d2c6e4b0543940d9e54b/chapter0/about http://scalamacros.org/paperstalks/2014-06-17-EasyMetaprogrammingForEveryone.pdf 
I mentioned some really high-level characterization of the situation in section 7 of the ScalaDays talk: http://www.parleys.com/play/53a7d2c6e4b0543940d9e54b/chapter7/about. In short, scala.reflect is: 1) Overcomplicated, because when implementing scala.reflect we've cut corners by reusing existing infrastructure from the compiler, and that one is sometimes more complex than it should have been. As shown in the talk that's linked nearby by Doikor (http://scalamacros.org/paperstalks/2014-06-17-EasyMetaprogrammingForEveryone.pdf), instead of the language model of scala.reflect that includes Trees/Types/Symbols/..., in scala.meta we have just Trees. Issue-wise there are e.g. SI-8222, SI-8220 and SI-6267 (that's by far not the complete list). That's just one example of the simplifications that can be made, others include simpler syntax for macros, removal of the separate compilation restriction, etc. 2) Brittle, which is a direct consequence of #1, because compiler internals require a number of underspecified invariants to be satisfied in order for its APIs to work correctly. That's a pain even for compiler developers who know these invariants by heart, but people who just want to get things done with a metaprogramming API shouldn't be exposed to such problems. There are three very notorious bugs in this department: SI-5464, SI-8066 and SI-7046. A good practical example is shown in the second half of commits in https://github.com/scalamacros/macrology201/tree/part1 (starting from step 19). 3) Locked-in, which is again a consequence #1, and that precludes alternative implementations, e.g. in Intellij. That's why scala.reflect's macros can't expand in Intellij (and as a result, macro-based error reporting doesn't work and whitebox macros, including quasiquotes, don't work). Well, theoretically they can work if someone builds a bridge between Intellij's internal language model and scala.reflect, but that's just too complicated because of #1.
Thank you!
You can't. If I give you an opaque third party class class Foo { def bar: Int = { println("Hello"); 1234 } } then you can't find that, unless you create a monster machine that analyses the byte code of each class and has a notion about which methods are side-effects and which not. The people that wrote the "Manchester University Transactions for Scala" STM library use byte-code rewriting, if I'm not mistaken, and they claim they can automatically handle side-effects. I'm not exactly sure how that is true and to what extent. Might be interesting to look into their research as well.
Thank you, I really enjoyed your talk. I particular like the ideas of a single, syntax-driven abstraction and of complete information preservation. It sounds like you work on the Scala compiler; hindsight being what it is, could the design of scala.meta have been useful for implementing the compiler itself? Would it make sense to build a core that exposes this style of consistent API then layer more advanced language features on top using the same API exposed to third party developers? I ask because I'm writing a compiler and want to make metaprogramming a first class feature from the start. 
MIT license :) https://github.com/pathikrit/dijon/blob/master/build.sbt
If you're using sbt too install sbt-eclipse and have it generate the eclipse project, which you import directly in eclipse. That insures right classpaths for your project. I used Scala for Apache Spark, so my experiece may not match up with Play Framework app...
Does all this mean that I should not install JDK 8 on my linux desktop development machine until scala is ready for it? What about the other JVM languages I use? Do they all have to wait, too? Isn't scala supposed to play nice in multi-language projects?
Since your using play framework did you use the eclipse function in the play console before importing?
Just a reminder for everyone else: the same applies to Intellij IDEA. If you intend to use sbt, add the sbt-idea plugin and have it generate the IDEA project for you.
You left out power set.
I'm working on a project that performs gobs of code generation, but I'm waiting for scala.meta to consider transitioning to macros. It sounds very promising and I can't wait to try it.
Scala works fine with JDK 8. It just doesn't use the new features until 2.12.
Great! Btw what deters you from using macros in their current form powered by scala.reflect? Maybe there might be an easy fix for your particular use case that we could come up with?
Use import _root_.scalaz.X
Great to see people pushing Scala into multimedia and real-time scenarios, putting concerns such as performance, GC efficiency, low-latency, desktop applications on the agenda.
Is OSGI a "thing" in the Scala community? I only see people running away from it faster than they did J2EE.
There are two related problems I have with using scala.reflect, which are human and not technical: 1. I'd have to learn it, and 2. someone else will have to learn it to read my code. I'd prefer to wait for scala.meta and see if it's easier or cleaner, and if so, learn that instead of scala.reflect. Generating Strings and writing them to .scala files is something most programmers can understand, so I'm sticking with that until I can evaluate scala.meta.
Thanks @thebrainbr, it worked great: https://github.com/julien-truffaut/Monocle/commit/1703786918e31421c380aa2d23344417c7baee7a
Yeah, I ran the "play eclipse" command to create the Eclipse project files. So, I did get it to (kinda) work by using the latest version of Play (2.3.2) which replaces all the "play" commands with "activator" commands. I wonder if there is something about Play 2.3.x requiring Scala 2.11 while 2.2.x requiring Scala 2.10. I can't find documentation on that, but that's what I'm experiencing.
To save others some googling: [Plastic SCM](http://www.plasticscm.com/home.html) - Version Control for large-scale software projects.
Any "sampling" of what this looks like before I give out my email address?
Nevermind, just found one from your Twitter: http://us2.campaign-archive1.com/?u=ba834c562d82d9aba5eaf90ba&amp;id=d1c00a5906
Sadly, not there. It's an e-mail newsletter, no RSS (not until I get a simple archive up and running).
Grand, hope this made you give us your e-mail address. &lt;diabolic laugh in the distance&gt;
Looks cool. Not sure if you're the author but could the "Jsonable" thing be implemented with typeclasses rather than mixin/inheritence? I'd rather not pollute my domain models with view code if i can help it. 
Yeah I agree. Spray does a good job with its Marshaller and Unmarshaller system.
+1 for scalatra, but I can see where you guys are headed. As a newcomer to Scala I started down a very similar path based on Scalatra due to it being a micro-framework with less of a learning curve (in fact I am working on my own as a side project to learn: https://github.com/mefellows/respite/tree/multi-module). Spray looks good but still rather verbose. Play is the other end of the spectrum (monolithic / rails equiv). I'll certainly take a peek for inspiration ☺
This seems to go against its own design principles, it has a few heavy dependancies, but it says it doesn't want to have heavy dependancies. Secondly, Spray with Akka is fine and works well and will become the major player. If you want to serialise to and from JSON to/from objects theres Argonaut.
Thanks for the information. Good luck with the project. I'll check it out.
Using feedly heavly and it's bad that doesn't have a rss, either way I've subscribed to that, but didn't received the activation link
That's strange, could you send me your e-mail at scalatimes@softwaremill.com? I'd add you manually.
After 10-15min the mail arrived. I'm in :) 
[aww yisss](http://ih0.redbubble.net/image.12869641.5244/sticker,375x360.png) Hope the reddit will like it. Could provide you with some upcoming stickers if it's nice, all hail Scala! ;)
For sure man. I'm a dev manager with Java backend migrating and stimulating my team to learn too.
We're are you based? We've organized [Scalar](scalar-conf.com) this spring and will probably repeat it in 2015, put it in your calendar ;)
Spray is the opposite of verbose in that it has a DSL inside Scala. eg https://github.com/jacobus/s4/blob/master/src/main/scala/s4/rest/S4Service.scala The main problem with Spray as I see it is knowing the DSL, its best to use examples to start out and adapt the examples.
Is it the thing nowadays, to have the shortest group id - "io"?
So I was curious about the names behind these releases. It turns out "Aida" is a an opera in four acts by Verdi and "Scala 'Aida'" has four primary focuses. "Don Giovanni" is an opera in two acts with by Mozart and Lorenzo Da Ponte, however whereas "Scala 'Don Giovanni'" has five primary focuses the opera only has two acts. Maybe I'd have to be more familiar with the opera to catch the link between the two, or maybe it is just a name. Anyone have any insight? 
Or why they decided on Opera? I kind of assumed it's because La Scala is a famous (maybe the most famous) Opera house?
Scala will have union types?? My body is ready. Boo to eliminating the subroutine syntax, though. Having to say `: Unit =` everywhere is gonna suck. It's extra typing, and it adds syntactic noise, so it makes code harder to write *and* harder to read. Terrible idea. I hope they reconsider.
And so it begins, the notion that Dotty is "just a research project" has been squashed with this announcement; it's going to happen, just a matter of when, at this point (looks like 2018-ish). Love almost everything here, except for string interpolated XML literals. In the extreme minority on this issue, I know, but man, html markup with Scala's XML literals support (warts and all under the hood) is pretty awesome. I've ditched Play's handcuffing and very limited (for me) Twirl templates in favor of XML literals based templates. Will be a hassle to convert to string based version, and much noisier, triple quotes and `${}`s *everywhere* -- oh well, looks like can milk 3 years or so out of current implementation.
Hear, hear. I have so many tests like @Test def testFoo { ... } That it will be a real pain to migrate. Hopefully Typesafe will provide a tool to make this easier.
I'm with you. My current work project makes heavy use of XML literals, and the interpolation approach would be much worse, especially because I don't have much faith in the Eclipse plugin doing highlighting and auto-completion well for XML embedded in strings.
Many subroutines will evaluate to something other than `Unit`. Type inference is of little help here.
The community will be stuck at 2.11 and Java 7 for a long time. Maybe that's not a bad thing?
Why would they be? Just put a jdk8 download in a local folder for Scala. Fix refs and only scala usesmit.
We'll get some life out of literals, I believe they have a GSOC student working on the intitial implementation now. Current literals support probably won't be dropped until Scala 2.14/Scala 3/Don G/Dotty, but it might be dicey along the way, the library has not been touched since forever, we'll be lucky if it works through 2.12 and beyond ;-) Author of ScalaTags did say on the ML that IDE support won't be that hard to pull off for string based literals. We'll see, no auto completion and a sea of green triple quoted strings would be tough on the eyes and fingers.
I fail to see your point. There is no instability in using a localized JDK. In fact it is far more stable, decoupling your application from global OS change. I have run production systems for years and fail to see any merit in your comment.
You have run production systems where you were free to upgrade your jvm anytime you wanted to. That's not super common in the world of java.
The only risk is running a bleeding edge version of Scala. That alone would hold me back from putting this into production. Not the virtual machine it runs in. Would like to see some time for it to stabilize. 
I wonder if they overestimate the rate of adoption of Java 8. I actually wonder what the rate of adoption of Java 8 is. 
The intention is that all the parsing, validation and namespace resolution of XML should be kept as is. IDEs already do already a pretty good job with syntax highlighting of interpolated strings, no reason why they should not be able to do the same for xml"..." strings. 
[The Scala 2.12 release is planned for January 2016! not 2015](http://www.scala-lang.org/news/2.12-roadmap) 
Unit types have exactly one value. Bottom types have none. You can't return a bottom type if there's no value to return.
i thought perhaps finch.io would be the website, but it's some personal website. awkward?
`Unit` is so called because it is the empty tuple, representing no information. I would have preferred `Void`, for the sake of not confusing Java programmers too much, but whatever.
That's because a Scala "subroutine" doesn't return nothing. Scala doesn't have subroutines (which don't return anything), but Scala does have functions (which must return something). Hence, a subroutine is modeled as a Scala function which returns a value of type Unit.
There is still no backwards compatibility on the roadmap.
If you're returning a value you're not returning nothing.
Bold move. I fear it might be *too* bold
Even if prevention is not possible, or feasible, i have to say that compiler warnings would be useful, and probably possible to do. Warn if the function assigns a value to a variable that is not defined in the function, if a function with Unit return type called, etc. That might be not bulletproof, but it at least gives you and indication.
This is the umpteenth duplicate post of this... e.g. http://www.reddit.com/r/scala/comments/1wjoay/scala_collections_why_not/ and http://www.reddit.com/r/scala/comments/24fehq/scala_collections_why_not_talk/ 
"Scala is what I was looking for when I found Groovy"
The missing item: "Closed-minded Java programmers"
Groovy gives too many liberties without any of the safety. I'll never be able to use it for production code.
&gt; I can honestly say if someone had shown me the Programming Scala book by by Martin Odersky, Lex Spoon &amp; Bill Venners back in 2003 I'd probably have never created Groovy. — James Strachan, creator of Groovy 
and now author of the Kotlin standard library, ironically enough, guy gets around ;-)
I started with Groovy in 2009, and shortly thereafter "graduated" to Scala. Groovy's a nice language for scripting I guess, Gradle seems to be what keeps it afloat, not sure where else it's used, except for maybe the living nightmare, Grails? Heh, I really found Grails to be such an unbelievable POS during the 1.3.x release cycle. Thankfully it forced me to learn Scala ;-)
&gt; I stopped reading at that. [I know. America doesn't read anymore](http://www.npr.org/2014/04/01/297690717/why-doesnt-america-read-anymore)
He's also the one who did Jelly. I wouldn't hold that against Groovy however, he's been out of any sort of role in it for years and years.
Spock is a very good unit testing framework that's worth looking into. With recent versions of groovy you can all but eliminate a lot of the dynamic issues people have problems with, and still keep a lot of the FP goodies. Its integration with Java is much tighter than Scala's, which for a lot of things I do works out nicer. 
That's fair - it's not appropriate for every project.
We are all smarter in retrospect - this quote is cute, but hardly insightful.
REPL, really ? Poor bafoons form the 80s era.
Finally Java will die out ;-)
What about it? I'm not very good with the *nix shell beyond `cat`, `grep`, and `|`. Maybe I should start learning `awk` and `sed` soon, but for now I just open the Scala shell and fiddle with files using `map`, `filter` and `foreach`.
You missed out on a good read
There is one mistake: Scala doesn't have top-level functions. &gt; symbolic method names are most often abused. Take the parser API for instance, which features method names like \^\^, \^\^\^, \^?, or ~! How should these method names be written otherwise? Instead of \^\^ one could write applyLhsAndForwardItsResultToRhsIfItSucceeds and instead of \^\^\^ one could write applyLhsAndDiscardItsResultButRetursRhsIfItSucceeds but I can't see how that would be more useful. These method names are easily understandable and written for compiler guys - they are not for people who have to use SQL the whole day and being happy with that.
Article forgot: * Weaksauce pattern matching (i.e. `switch`) * No `implicit` values or typeclasses * No `TypeTag`s * No macros * Interfaces can have method implementations (friggin' *finally*) but not fields or initializers * No singleton `object`s * No abstract `type`s * No abstract fields * No type aliases * No symbol renaming (as in `import com.example.{Foo =&gt; Bar}`) * `import` of values uses different syntax (`import static`) than `import` of types, and can only be used on `static` values * No way to have package-level methods or fields (as in Scala `package object`s) * No scoped access modifiers (like `private[foo]`, making something visible only inside `foo`) * No multiple parameter lists * No named parameters (except annotations) * No default parameter values (again, except annotations) * Annotation parameters can only be of a handful of types * Annotations cannot have type parameters * `public` access is not default * Only one `public` class/interface per source file * No non-trivial `for`-comprehensions, `for`…`yield`, etc * Checked exceptions are a terrible idea that Java, for some unexplainable reason, has not done away with * Documentation is written in a bizarre, ugly quasi-HTML * No proper support for getter/setter methods * No way to override fields with more specific types (e.g. `val foo: CharSequence` overridden by `override val foo: String`) * Constructors that initialize fields must do so manually (as opposed to `class Foo(val x: Bar)`, in which `x` is both a constructor parameter and a field) * No way to call an object as if it were a function (as in Scala `apply` methods) * Interfaces cannot extend classes * You cannot `catch` on an interface (like Scala `ControlThrowable`) * You cannot `catch` on a pattern (like Scala `NonFatal`), either * No intersection types (e.g. `val x: Foo with Bar`) Article mentions but doesn't actually list: * No `implicit` views * No declaration-site variance * No value classes * No scoped `import` As we can see, you lose *a lot* by moving from Scala to Java. Article also says this: &gt;There are lots of little features and gimmicks that seem nice to have, but will inevitably blow up in your face, such as: &gt; &gt;* `implicit` conversion. &gt;* symbolic method names are most often abused. This only applies if you're an idiot. Scala is not a language for idiots. Scala is a language that empowers those who are intelligent enough to use it, as all programming languages should. Dumbing down languages for the unwashed masses is how we got most of Java's failings in the first place, and I do not care to continue suffering from that mistake.
The most annoying thing about some Scala developers, their arrogant attitude. I've been developing in Scala for quiet awhile now and having worked with a number of former Java developers to get them into Scala I can definitively say the attitude expressed in these comments is *not* very helpful. This sort of attitude is part of what turns them off in the first place. But of course, you can just keeping saying things like: "This only applies if you're an idiot. Scala is not a language for idiots." and "The missing item: "Closed-minded Java programmers"" and go on with your lives. You took what was actually mostly a pro Scala post that at the end listed some reasons (which were a bit misguided but had some validity) for still being uneasy with the language and reacted by calling him an "idiot" and "closed-minded". Nice guys, keep up the great work.
Are these really standard symbols for anyone that deals with compilers and parsers? I don't have much experience there so I really don't know. But either way, you have clearly chosen the most convoluted example method names you could. Just because you can camelCase a convoluted sentence doesn't mean that's the best and only way to name a method. Do you honestly think something like this is what the author was suggesting? If you look at `^^` in the docs it's very similar to `map`, the signatures are the exact same. Just a cursory example of what might be a more descriptive name would be something like `mapIfSucceeds` or `mapSuccess`.
&gt; The most annoying thing about some Scala developers, their arrogant attitude. Then make a difference. &gt; "The missing item: "Closed-minded Java programmers"" Maybe you should check the r/java xpost for a reality check if you disagree. There are plenty of non-Java programmers on this planet, as well as people who have never programmed before. I think the effort Java developers usually demand from other people to work around their intellectual laziness is offensive, and I can understand when Scala developers prefer to spend their time with people who don't need to be spoon-fed. Yes, it would be possible to drop the "Java" from "Closed-minded Java programmers", but let's not try to paper over issues which are usually quite Java-centric.
What a lot of people don't realize is that the very fact that this list is so long is the reason why Scala is struggling to impose itself in the mainstream. This is the kind of list we used to read when Ada advocates were comparing themselves against C and C++. Clojure, Kotlin and Ceylon are making a decent attempt at providing 80% of the power that Scala offers with one tenth of the feature list. 
Interesting, where I find the arrogance-ometer to reach astronomical proportions is in the *Java* community. Heh, totally kidding, Haskell users shitting on Scala left and right, now that is annoying, the f-ers ;-) As for Scala users coming down on Java in this thread (and elsewhere), I suspect that's some backlash in reaction to the, "who needs Scala, Java 8's pretty much the same thing" chorus sometimes seen here, and often on HN.
&gt; unwashed masses that is just wrong ;-) I agree with your bullet list, but not with the idiot reference, no need for that, Scala is for *everyone*; in fact, I'd say everyone is an idiot when first starting out in Scala, there's a lot to learn if coming from imperative OO side of the fence.
Indeed. Unwashed masses, like I said.
…among the aforementioned unwashed masses, whose opinions I do not care about.
Your love of the language is blinding you to the fact that a lot of this complexity that you embrace is unnecessary and largely here for legacy reasons instead of being purposefully designed in the language. 
[link to r/java thread](http://www.reddit.com/r/java/comments/2cc5ql/the_10_most_annoying_things_coming_back_to_java/) for those interested. Wow it's crazy how much both communities rag on the other. As someone who uses both, I never realized the communities were so polarized.
I have written some larger parsers using the parser library, and in my experience the usage of operator names in the parser library make a lot of sense for a number of reasons. The same methods are used again and again in parsers, especially larger ones, and thus having more concise methods by using operator names is a nice bonus. Furthermore, clarity is increased due to visual differentiation between the regular names of the user's parsers and the operator names of the parser methods. The names are also somewhat intuitive once you have learned the API. For instance, methods like `^?`, `^^` and `^^^` transform a single parser and its result, while the methods `~`, `~&gt;` and `&lt;~` combine parsers sequentially. For `~`, `~&gt;` and `&lt;~`, the methods make sense visually: `~` keeps the results of both combined parsers, while `~&gt;` and `&lt;~` discards the result of the left parser and the right parser respectively, which fits with the direction of the arrow. Some of the naming also fits with standard usage in compilers and parsers. For instance, the `*` and `+` are common symbols for parsers and regexes, meaning "repeat zero or more times" and "repeat one or more times", respectively. For example usage of the library, `"a".* ~ "b"` matches a string that starts with an arbitrary number of "a"s followed by a single "b", such that it matches strings like "b", "ab" and "aaaab". Another example is `("def" ~&gt; identifier &lt;~ "=") ~ methodBody`, where the resulting parser matches the strings that starts with "def", followed by an identifier, followed by "=", and followed by a method body. The parser also only keeps the results from the identifier and method body parsers. **TL;DR:** Operator names in the parser library are awesome and makes writing parsers a lot more concise and clear.
[Source](http://james-iry.blogspot.dk/2009/05/brief-incomplete-and-mostly-wrong.html): &gt; 2003 - A drunken Martin Odersky sees a Reese's Peanut Butter Cup ad featuring somebody's peanut butter getting on somebody else's chocolate and has an idea. He creates Scala, a language that unifies constructs from both object oriented and functional languages. This pisses off both groups and each promptly declares jihad. EDIT: I personally think Scala is a great language that continues to get better and better, and I am happy to see that both Java and Scala continues to improve. I also think the toxicity is a waste of time, and that constructive cooperation and competition between the language communities is the way forward.
Forgot about Spock, that was a pretty cool test framework as I recall. re: Groovy and static types, tacking on an optional type system, we'll see where that leads to. Clojure has done the same (apparently with some success).
Let's not get into language wars; they are tiresome and offputting. It's good to compare languages on the technical level, but we don't need an "X is better than Y" attitude. Some people find a feature essential whereas others won't touch it. That's a personal choice. Since we saw the features listed that Scala has over Java, it would be instructive to also see the opposite: What features are there in Java that Scala lacks? I made a list in my recent [Evolution of Scala](http://www.slideshare.net/Odersky/scala-evolution) talk. Here's my list, but maybe I have overlooked something. (As you can guess, the first three were there to make a pun). public static void Enumerations Annotation Syntax Wildcard types Raw types Primitive types Array types Definite assignment rules Statements: break continue synchronized assert for (C-style) try (resource) super(...) Expressions: primitive operators cast syntax conditional x ? y : z array selection a[i] 
I am not sure whether there's work planned to make string interpolation play better with XML. In my mind, the boilerplate is not that big a deal. Having XML in the language makes for a huge chunk in complexity, and also strongly pushes you to use Scala's built in way to treat XML, which not everybody likes. With XML being an interpolator we open the doors for alternative XML handling libraries (such as Daniel's AntiXML). Having XML in the language is also the antithesis of the Scala's philosophy, which is to focus on general composition and abstraction principles, instead of providing an array of predefined solutions. 
Given the number of replies you've offered up here, I'd say you're almost obsessed with it.
I said I don't care about the opinions of the unwashed masses. I said nothing about the opinions of the redditors participating in this discussion.
&gt; but we don't need an "X is better than Y" attitude Maybe, that's what usually happens when these kinds of articles appear, but in this specific case, the article was really just essentially saying "hey, if Java had multi-line strings (and the other 9 things), that would be awesome".
&gt; (which were a bit misguided but had some validity) I'm interested in what you mean by the reasons being misguided... &gt; by calling him an "idiot" and "closed-minded". Nice guys, keep up the great work. Don't worry... These things don't matter that much. :)
&gt; because everyone who can has moved on already. [Maybe not? :)](http://www.tiobe.com/index.php/content/paperinfo/tpci/index.html)
I agree. Specifically, because this article is just wishing for 1-2 features from a lovely language to be integrated into another one. This has happened numerous times before. E.g. try-with-resources was stolen from C#, generics were inspired by C++ (although implemented quite differently), lambdas from a variety of other languages... Yet, so many commenters think that there is an innate superiority in a language, compared to the other ones. As if all languages were completely independent islands.
Language popularity is not a good measurement of the skills of their users. Unrelated to that ... using TIOBE for popularity "measurements" ... why not just use a Hitler comparison if you want to end the discussion? :-)
I also think the article was OK. I was referring to some of the comments here.
Here's what I've tried so far... I downloaded junit-4.11.jar and scalatest_2.11-2.2.1.jar. I created a /lib folder within my project and added the jars to the folder. Then I right-clicked on the project, went to build path -&gt; configure build path -&gt; libraries and added both jars to the build path. My project is named 'progfun', package is named 'week1', and I created a class within that package named 'TestSuite'. My code is below: -------------------------- package week1 import org.scalatest.FunSuite import org.junit.runner.RunWith import org.scalatest.junit.JUnitRunner @RunWith(classOf[JUnitRunner]) class TestSuite extends FunSuite { test("one plus one is two")(assert(1 + 1 == 2)) } ------------------------- I right-click on TestSuite and run as JUnitTest, and I get the following error: "Class not found week1.TestSuite java.lang.ClassNotFoundException: week1.TestSuite". At this point I have no clue.
If it works the same way it does in intellij, you can annotate the class with @RunWith like in the scalatest docs. Then it will use junit to run it. I'd find links but I'm on my phone.... Well I went and found them anyway. http://scalatest.org/user_guide/running_your_tests There should be enough ways on there that one of them works. Just be sure it still works from sbt, otherwise you might not get credit when you submit it to coursera. EDIT: oh this is for your own project. Then disregard the sbt caveat. :) 
I see. Yes, it's really interesting how some modern languages unnecessarily attract elitism. But then again, for every-day (Java) programmer folks, there's still a lot of joy in discovering what *can* be done on top of the JVM. For some use-cases, Scala is just a wonderful fit. Writing a parser using the Parser DSL is one of those cases, at least for me. I've used ANTLR before, but being able to connect the grammar directly with the AST and the semantics of transforming the AST feels much better. Long story short, it's great for Java to have a whole set of "language labs" on top of the same JVM to experiment with more modern ideas, which might eventually make it into the JLS as well. I think the ecosystem diversity is beneficial for all stakeholders.
&gt; the cross talk between the communities is how you got lambas in java 8 for example. Yep. And `invokedynamic` was implemented for many other languages first, not for Java...
I'm referring to a specific subset of Java programmers which I encounter who insist on never considering alternatives (even Java lib. alternatives). I'm talking about people who use Java in the same way it was used a decade ago and refuse to use new language features and libs. in Java or even look at other languages. I don't think it's unfair to refer to people who refuse to use any features newer than JDK1.4 as closed-minded.
&gt; * Insert-or-update support which makes use of native databases features where possible, falling back to a client-side emulation otherwise. That's so nice!
I've been developing in Scala for the better part of the last 3 years and loved every minute of it. That said - implicit conversions ARE indeed problematic, especially the ones defined in Predef and symbolic method names ARE abused. As the community matures I'm finding less and less instances of such abuses happening and certainly such features are useful in the right context, but it is our job as experienced Scala developers to guide beginners into adopting good design practices when developing their APIs. The comment about Scala not being a language for idiots is unwarranted and just mean. "Idiots" are idiots because of a lack of education. If you want a better future, guide them towards the better way of doing things you believe in, instead of behaving like a dick, a choice that's without benefits.
I wonder what it does for Postgres.
Selectively disabling warnings is something that will come in 2.11.x together with the new work on linting but that release is also for the end of this year (if I remember correctly). I understand your pain but you're using cutting edge (in your case bleeding edge) libraries. Sometimes you have to give the ecosystem of libraries some time to stabilize &amp; converge. Especially now that the scala ecosystem is getting pretty big, this kind of thing will happen more often. In your case, staying with 2.10 would be the more conservative choice. What revolutionary library for 2.11 do you expect to see in the next 5 months?
That's a quite selective reading of "it will be fixed in the upcoming version".
Not familiar with the source, but it looks like it starts a transaction, tries an update, if that fails then does an insert, then commits the transaction https://github.com/slick/slick/blob/43ccb1436e59c98af437bf6af99632718f76b232/src/main/scala/scala/slick/driver/PostgresDriver.scala Also see override protected lazy val useServerSideUpsert = true override protected lazy val useTransactionForUpsert = true override protected lazy val useServerSideUpsertReturning = false
Cutting edge scala stuff tends to do this. Hardly the first library.. I think anorm works well with 2.11, but it has a very different feature set.
At work, we switched our project from Slick to Squeryl, and it's been good, modulo a few warts. The porting wasn't trivial, but it wasn't that hard either. Oracle support was the main driver for us. 
&gt; "Class not found week1.TestSuite java.lang.ClassNotFoundException: week1.TestSuite". At this point I have no clue. Do you have any build errors? ScalaIDE (and scalac, I believe) generates bytecode on an all-or-nothing basis. If you have any errors, even in classes that aren't your test, week1.TestSuite.class won't get generated, and the error you see will be "right". When I took the Coursera course, getting things working in the IDE was fairly easy, as each week's projects came with proper Eclipse metadata such that I could do Import -&gt; 'Existing projects into workspace' and be good to go. Munging your classpath manually makes me fear you're veering into the weeds.
I wish I had some numbers, but I don't, unfortunately. In our app, the DB-access parts aren't super performance-critical, so we've never dug into it. Subjectively, going from Slick to Squeryl hasn't made the app "feel" slower, FWIW. We don't do anything very heavy-duty with the DB, just CRUD stuff, so who knows how broadly applicable my experience is. It's funny that you mention caching statements, because it looks like Slick 2.1 just added features that would have allowed me to cache statements when I was using Slick. We always had to re-generate things due to wanting to call take() ,etc, which couldn't be parameterized like other parts of a lifted Query.
I'm not interesting in disabling warnings. I wouldn't want to do that unless I was certain that I would only be disabling the one particular warning type and only when it's omitted due to Slick. I would happily accept it as a temporary workaround but I agree that it's something that we should expect and then be able to say "oh well, it's a scalac problem". It's not. It's a Slick problem. I honestly don't understand this cutting/bleeding edge argument. 2.1.0 final was just released, I'm not talking about nightlies here. No other library has flooded my compiler output with warnings and then told me "it's a tradeoff," bad luck, wait until we build new-shiny-thing in 5 months. I'm not frustrated that the library doesn't do all the things, or isn't fast enough, or doesn't support database X; I'm frustrated that when every other library had a 2.11 build come out within a few weeks, usually days, of 2.11's release, it's been months now and Slick's new release still doesn't adequately work with 2.11 because they've prioritised new features. I don't see how cutting edge explains or justifies any of this. I use many other libraries, all releasing new versions so cutting edge too, and haven't come across this kind of thinking. Finally, it's important for me to switch to 2.11 because 2.10 is very slow to compile and there's a small gain in 2.11; secondly, scalac has a crazy amount of bugs and 2.11 has less of them, including fixes to a few real bugs I bump up against with my own code.
First I've come across this attitude, maybe I've just been lucky. Even so, if it's common it shouldn't be. There's too much instability and low prioritisation of quality in the Scala ecosystem and Typesafe aren't exactly being good role models. I'll give anorm a search and a read. Cheers.
The upcoming version was just released. It isn't fixed.
I think I looked at that *aaaaages* ago, I'll give that another look. Thanks.
Squeryl is a little "scruffier" - for lack of a better word - than Slick. That is, Squeryl seems more biased towards getting things done that theoretical and type-level purity. I bet Slick's approach is better in the long run, but Squeryl's works well now.
I'm not using Slick but I was wondering this as well based on their comment about connection pools in the release notes. Looking at it closer it looks like it can use a DataSource, so in theory you could use an Apache DBCP data source... and... here's a blog post about someone doing this with C3P0: http://fernandezpablo85.github.io/2013/04/07/slick_connection_pooling.html and Apache DBCP: http://stackoverflow.com/questions/15534777/connection-pooling-in-slick So it seems the "but no support for connection pools yet" comment only applies to using a properties file thingy to instantiate your Database.
Yup, I've used Slick with both c3p0 and Hikari DataSources and it works fine.
It's from Typesafe and it's 2.1.0. How is that bleeding or even cutting edge?
Honestly, your attitude towards software engineering will make you a bitter, frustrated person. My attitude comes from the java world, where my project uses &gt;30 libraries and one giant framework. If we switch to a new stable version of the framework it usually takes us a while before things build again, then I notice that some library dependencies have changed &amp; a newer version of a library has a bug in it or slightly changed behavior or there are conflicting library dependencies. Typically these issues are already known but it can takes a few months before all issues are resolved. I wish things could be different but I don't think this is avoidable. Your attitude is that of a little child "I want everything and I want it now", unfortunately that's not how the world works. If you're not paying for Slick, send them a PR. I believe forking the project is also an option.
I'm going to summarise your reply. 1. _Just accept that things suck._ 2. _Things suck for me regularly. I'm used to suck. Just accept that things suck._ 3. _Grow up, idiot. You should know that things suck. Accept it. If you're not paying for Slick, send them a PR or fork it._ Firstly, I *know* that things suck but I won't be bullied into believing that that's ok and we shouldn't strive for better. Secondly, I do indeed have the ability to create a PR or fork and I am indeed guilty of not having done either. Correct. Understand though, that the fact that I haven't contributed (at least not recently) to their codebase doesn't mean I can't opine that new features should *not* be prioritised over fixing existing functionality, nor warn people who invest time into changing all their code trying to upgrade that they won't be able to rid themselves of a mountain of compiler warnings. I wish somebody had warned me of that. The upgrade isn't trivial.
How have you been doing it with Hikari? Saw a couple of Play plugins recently, am very interested in trying out Hikari over Play's default pool, BoneCP.
ANORM will leave you wanting, sqlTyped and ScalaLikeJDBC are both far better alternatives for stringly typed query DSLs, IMO.
Right, they did add cachable take/drop in 2.1, you fool, see what you've lost? Heh, kidding ;-) I suspect that Squeryl does just fine for most use cases. Inertia, the devil you know, etc., have hundreds of queries, many built upon composed snippets; the thought of switching to another DSL does not appeal, maybe for a new project... I'm holding out for the query DSL to rule them all, something with Squeryl-y syntax, Slick composability/cachability, and blazing performance. Could be awhile O_o
Oh, I absolutely agree that the *quality* isn't exactly industry grade stainless yet. I agree that Stefan Zeiger has been doing some very cool stuff, but I've decided against using much more relational algebra type stuff for now. I thought the original comprehensive comprehensions proposal was by Chris Hodapp, and I vaguely remember they hadn't quite figured out the sweet spot yet, so I wasn't holding my breath for any of that to appear in any of the operatic Scala versions to come. Anyway, Scala-wise, [Doobie](https://github.com/tpolecat/doobie) is next on my list of things to try. It requires you to write your own (damn) SQL, and I'm fine with that after a slow start with Slick. Doing Haskell stuff now though.
&gt;Why not treat class constructors as every other method/function? Short story is constructors aren't methods in the JVM. Long story is constructors aren't methods in the JVM, and adding the feature is in backlog limbo until someone gets around to doing it.
I like the idea, and also wondered that occasionally. @Milyardo: Functions are no real first-class objects on the JVM either. So why does it matter whether constructors are methods on the JVM?
Woh, Doobie looks FP out there, I'll have to try one this evening. If you're on Haskell looks like [Esqueleto](https://github.com/prowdsponsor/esqueleto) is the type safe query DSL du jour, although it lacks a string based SQL interface to drop down to when the underlying query is either too complex or database-specific for the DSL to generate accurately. Choice of operators is also a bit odd, but hey, it's Haskell, symbol soup goes with the territory ;-) Philip Waddles et al recently [published a paper](http://homepages.inf.ed.ac.uk/slindley/papers/practical-theory-of-linq.pdf) that looks extremely promising in terms of Haskell at some point having a majorly kickass query DSL. I might jump ship if that happens; for the time being, Play + Slick's predecessor + Coffeescript/LESS fulfills my web hackery needs well enough.
The short story is wrong, the part about "adding the feature is in backlog limbo until someone gets around to doing it" is correct.
&gt;To be honest here, I'm not 100% sure what I did. What I think is happening, is the for loop is creating a set of prepared statements as an object executing all at once. Is this right and this is proper? No, the loop appears to execute separate updates. `for` in Scala returns `Unit` (and `Unit` doesn't have `executeUpdate` method), unless it's `for…yield`. So since it compiles, entire `{…}.executeUpdate` is inside the loop. You can always try to see what happens if you add some explicit parentheses to remove any ambiguities. I do not know how to make a batch update in whatever database access library you're using.
&gt; Could you point me in its general direction? Check out the paper (linked in my comment to you above). AFAIK there is no project per se, they've just gotten the ball rolling by proving they can, in some cases, do better than LINQ (although I don't believe they have group by and sort by implemented yet). The proof is there, however, and they used F# as host language, so I'd imagine Haskell would help fill in some of the gaps (i.e. more expressive than F#). re: Karamaan's OpalEye, do + arrow notation is, dare I say, readable ;-) I think HaskellDB has to get with the modern era though for projects like OpalEye to take off. Looking at the issue tracker it appears HaskellDB doesn't support insert/returning, doh, that's kind of a must-have. Haskell's been blowing up (in the good sense) of late, I've very curious to see how Haskell and its ecosystem look 2-3 years from now.
Have you thought about using something like [play2-auth](https://github.com/t2v/play2-auth) for your authentication? It might clean your first method up a bit. For your second method, you don't want to use a for loop, you want something like: imgs.foreach { img =&gt; SQL(...).executeUpdate } if executeUpdate returns Unit in your Library, or use .map if it returns a value. Assuming, of course, that your update statement does what you want it to.
Did you really link to a pdf? Downvoted
A bit off topic, but still an interesting slide deck. I hope they don't reinvent the wheel, but look at Scala when trying to figure out how to do value types and specialized generics. Arrays 2.0 was the most interesting for me, should keep the JVM at the numerical computing forefront.
This approach is significantly more comprehensive than scala specialization, miniboxing or value types. Oracle has a lot more engineering resources &amp; they control the jvm spec. The scala team just can't compete with that. I think scala will benefit more from this than java will but every solution that is implemented in scala before this stuff lands in the jvm is a stopgap solution. 
Why not just use Applicative or Monad (or MonadThrow) to lift the value into a context? Identity, Try, Either, Option, Seq, these all have Applicative (hence Monad) instances. They come with useful laws, you can map over them, flatMap (Monad), etc. trait Functor[M[_]] { def map[A, B](context: M[A])(f: A =&gt; B): M[B] } trait Applicative[M[_]] extends Functor[M] { def apply[A](value: A): M[A] def join[A, B](contextA: M[A], contextB: M[B]): M[(A, B)] } trait Monad[M[_]] extends Applicative[M] { def flatMap[A, B](context: M[A])(f: A =&gt; M[B]): M[B] override def map = ... override def join = ... } Wrap just captures Applicative.apply. Care about reporting errors too? trait MonadThrow[E, M[_]] extends Monad[M] { def throwError[A](error: E): M[A] } If you use these typeclasses instead, other methods in your classes can do useful things to wrapped values. Want to change the wrapped value? Use Functor.map.
I primarily meant all the effort that went into those implementations, including the things that succeeded and those that didn't. Value types have been working out quite well in my experience, whereas the original specialization is just horribly broken and unusable. But they should look at what was tried with specialization, and where the problems were, and how that led to a reboot under the label of mini-boxing.
My body is so very ready. The Oracle acquisition is starting to seem like a good thing, surprisingly enough. Sun would never have considered making the JVM so C++-like.
That's a whole lot of words to say absolutely nothing. So what are the differences? Did ADHD kick in and you forgot what you were writing about? 
I don't know what sort of meaningful answer I could give. Scala will continue lumbering along with everything being a lot harder than it ought to be. Whether that constitutes hope, resignation, or somewhere in between is in the eye of the beholder.
Though the implementation is much less of a disaster, in broad strokes value classes fail in the same way as does specialization and as do other scala features (implicit conversions, package objects, type classes, case classes, macros, long list) in that they cannot be composed either at all or without a long list of long-tendril conditions, which makes reasoning about code difficult-to-impossible and guarantees that a design which uses them will always be the wrong design, if not today then tomorrow. I'd point at some illustrative tickets but https://issues.scala-lang.org/ is non-responsive.
&gt; Selectively disabling warnings Here we are two years ago: https://groups.google.com/d/msg/scala-language/gcGGjkDazwE/qEUQRB6AhN8J And that conversation is the tail end of at least two more years of effort on my part. We could have had adequate warning suppression infrastructure in scala 2.8.
Fair enough. It is a bit ironic that you may be having more influence on Scala's evolution after having left Typesafe (new collections coming in 2.13, and Dotty to follow). You should burn more bridges ;-) 
I don't think those developments have anything to do with me, which is not to say I don't have more influence now - I do, even if we need a micrometer to measure the difference. I knew going in (I mean, going out) that by spending my last bullet I'd be a lot harder to ignore and that the outcomes I sought would be becoming more likely just as the relevance to me was plummeting. That's the way the cookie crumbles sometimes.
Well, despite not enjoying seeing your frequent barbs jabbed into Scala's corpus, if it's in some way helping Scala morph into a language that even you would consider using, all of us here in the trenches should be thankful. Will be interesting to see where things are at in 3-5 years here on the JVM and elsewhere (like Haskell taking off or remaining niche).
A rebuttal would be much more effective if it contained technical arguments and concrete examples. That talk is easy to debunk for example since the presenter is very superficial in its understanding of Scala and makes countless of mistakes when discussing the merits of Go by comparison. This blog post is weak since the whole thing is a bunch of completely subjective statements and yes, it doesn't say anything - could have been a single tweet.
That's the same thing as a for, is it not?
The squeryl dev team isn't any better. They've had "RC"s out for 0.9.7 for over an entire year now (I think). Not to mention the fact they make lots of additions/removals/etc between them. Hint: that's not what an rc is. Oh and they "accidentally" removed a major feature (views) from 0.9.7 but still haven't fixed it even though it was brought to their attention quite a while ago. Hope you weren't using that feature. I was about ready to call it abandoned before they thankfully started committed again (for a few weeks only) and upgraded it to 2.11. Honestly I was waiting for this release to port everything over to slick but I don't think I can deal with the issue the op brought up. Le sigh.
Very fair points. I certainly don't endorse those practices. For us it's a case of "least worst".
There is not a single example out there on this so chill, this is all an elaborate HOAX by typeSafe to get everyone on Play bandwagon, an Tyranny of MVC. Good for Sheeple though.
Thanks for posting this, there is a *lot* to like (and learn from here). He's using Scala while selectively [disabling various features](https://github.com/paulp/psp-std/blob/master/std/src/main/scala/PackageLevel.scala) that cause problems for Scala users in the wild (an obvious one, `any2stringadd`). From there it looks like [true equality](https://github.com/paulp/psp-std/blob/master/std/src/main/scala/Eq.scala) can happen. Haven't dug in too deep but am liking this project so far (side note: the code itself is super clean and the high level comments *very helpful*). 
I feel like the whole "Paul Phillips" thing went down like an overly charged emotional adolescent tantrum on an episode of "My super sweet 16". It's good to see he's backing it up with some good work rather than just sitting on twitter hurling insults at everybody. Don't get me wrong I feel that Scala has a lot of issues that need major breaking changes to get right - But I wish we could address these things without the constant bickering and drama. This is perhaps finally a step in that direction. Anyway, I digress. Looks good from a first impression. At the very least, yanking out a whole bunch of implicit conversions and implementing type-safe equality fix two pretty big warts that have burnt me numerous times.
I thought he quit scala.
He quit Typesafe
There is a tendency especially among the young to unconsciously assume that history began whenever it is that they started paying attention. Maybe "we" tried to address those things in lots of ways during the six years before you started paying attention.
That's a fair call - I know of a few people personally that have expressed similar thoughts having been in the ecosystem for a longer period of time that myself. I've only been using Scala for a bit over a year now, and have already run into many of the same frustrations. The way paulp went about it was frankly embarrassing, although perhaps his intention was simply to make his rants go viral to raise awareness of the problem. In either case, he's a much better developer than I'll ever be and is actually delivering the goods to backup his rants, so I can put up with a little drama if the end result is an improved Scala.
Ah, the irony, @extempore42 is probably having a private chuckle right now, and paulp as well if he's around. I agree that this extempore character has serious chops, he seems to have come out of nowhere to be honest -- maybe Typesafe will hire him if he brings the collections prototype further along. Would be nice, don't really want to wait until Scala 2.13 (sometime in 2017). 
Roflmao. I take it @extempore42 is paulp then? I had him tagged in RES as 'Troll'. Can't recall why, but it's rather hilarious in hindsight. I might re-tag him more appropriately.
If you are fortunate, the day will arrive when you view the notion of going along with things as you found them to be an embarrassment well in excess of what you think I should be feeling today.
And gave a presentation on how Scala is irrevocably broken.
Looks like none of the alternatives are much better ...
What an astoundingingly stupid idea!
I think there are a few useful utility types like Index, but I'm not seeing the huge break through. What am I missing? In my opinion the most interesting aspects of the code are the comments like "I'm doing it this way, but approach X would be much better, but that doesn't work due to Y" ... the Scala team should have a look at those.
&gt; I'm not seeing the huge break through. I started Friday morning. It has been three days, two of which were a weekend and one of which was my birthday. How many huge breakthroughs have you published since Friday morning? Why are you talking about huge breakthroughs? &gt; the Scala team should have a look at those. Or they could look at the 1800 open tickets (https://issues.scala-lang.org) 150 of which were opened by me, because those are designed for the transmission of such information. The comments are echoes.
Twitter has a very useful stack-- I have used some of their util components with plenty of euphoria.
Christmas! Thanks for posting, /u/extempore42, and /u/_Sharp_.
I don't know what his middle name is. Probably much the same way as nobody knows (or cares?) what the 'L' in Samual L. Jackson is for. I've always thought it pretentious to use your middle initial for anything other than formal documents.
Nice post by Dan James (@dwhjames) describing Scala's roots in ML in light of Martin Odersky's attempts to avoid Scala being pigeonholed as either functional or OO.
You know what they say: it's funny because it's true!
&gt; There is a larger discussion to be had for type parameters versus type members, but we’ll shelve it for now. I would love to hear such a discussion because I've always been confused about the pros and cons of each approach. 
&gt; If you are fortunate, the day will arrive when you view the notion of going along with things as you found them to be an embarrassment well in excess of what you think I should be feeling today. What an iconoclast. Bravo. All progress depends on the unreasonable man, &amp;c. No, my eyes aren't rolling, that's just my physiological response to feelings of extreme admiration.
Impossible to read on a smartphone..
http://blog.pellucid.com/rss
Using the scalaz library one could also work with type classes: import scalaz._ import Scalaz._ object Main { def rule(i: Int, s: String)(n: Int): Option[String] = if (n % i == 0) some(s) else none def fizzbuzz = rule(3, "Fizz")_ |+| rule(5, "Buzz")_ def applyfizzbuzz(n: Int): String = fizzbuzz(n) | n.toString def main = println((1 to 100) map applyfizzbuzz) } Here `|+|` is the assocative operation of the monoid type class. The rules have type `Int =&gt; Option[String]` so `|+|` operates on the monoid constructed by making the Int-Function monoid of the Option monoid of the String monoid. scalaz seems to provide monoid instances for the basic types, like String, and somehow generically derives the monoid instances of derived instances, as with the Option- or Function-Monoids. `fizzbuzz(n) | n.toString` is just an alias for `fizzbuzz(n).getOrElse(n.toString)`. **edit**: I just came up with a second version, which I think is a bit easier on the eyes: object Rule { type Rule = Int =&gt; Option[String] def run(r: Rule, n: Int): String = r(n) | n.toString def mk(i: Int, s: String): Rule = n =&gt; if (n % i == 0) some(s) else none } object Main { def fizzbuzz = Rule.mk(3, "Fizz") |+| Rule.mk(4, "Buzz") def main = println((1 to 100) map { Rule.run(fizzbuzz, _) }) } **edit2**: The second example also shows the structure of the Fizz Buzz Rule concept a little bit better. There is - an introduction form `Rule.mk` creating new rules out of nothing - a transformation form `|+|` with which one can assemble complex rules out of simpler ones - an elimination form `Rule.run` which then consumes the rules to create a result when leaving the Fizz Buzz domain in the end.
nice post
Thanks! I really appreciate the feedback. In my concluding paragraph, I suggested some future directions. I need to dig a little deeper into my copy of ‘ML for the Working Programmer’, and then maybe I’ll have some material for a follow up article.
Thanks, but is there a point in having these two similar constructs? Is there anything you can express with type parameters and not with abstract types? Same question with the other way around. If the answer to these two questions is not "yes", then one of these constructs is superfluous... 
See http://docs.scala-lang.org/tutorials/tour/abstract-types.html “Please note that it is often possible to turn abstract type members into type parameters of classes and vice versa.” I’m not sure if I can precisely characterize for you when this is not the case. Also worth looking at is http://www.infoq.com/presentations/data-types-issues and DOT/Dotty. If/when Dotty becomes the core language for Scala, type members will be a construct of the this core language, and type parameters would simply be a surface convenience that is reduced to type members.
**Abstract.** This article shows how to realize the concept of type classes in the Scala language. As an illustration the algebraic structure "monoid" is modelled using type classes in both Haskell and Scala. Familiarity with the Haskell language should not be required for understanding. Additionally the topic of "generically" deriving new type class instances from existing ones is discussed for both languages. The article quickly covers both the external properties of type classes, i.e. how they can be used as an abstraction mechanism, and the internal properties of type classes, i.e. how they can be expressed as a combination of simpler structures and get evaluated. I originally wrote this article to introduce a friend of mine to the concept of type classes. I hope you enjoy reading. Feedback, additions and discussions are welcome :) **edit:** Blogpost moved to [this](http://m0rphism.zankapfel.org/posts/2014-07-22-typeclasses.html) URL.
Interesting read, well written, thanks! There's actually a workable way to make an implicit ProductMonoid. In your post, you're solely (I think?) working with implicit parameters, but you could also abuse implicit type transformation somewhat to achieve what you want. The following implicit function is capable of creating an instance of Monoid[(A, B)] for any types A and B for which there's an implicit Monoid implementation in scope: implicit def productMonoid[A, B](implicit a: Monoid[A], b: Monoid[B]): Monoid[(A, B)] = new Monoid[(A, B)] { override def mzero = (a.mzero, b.mzero) override def mplus(m1: (A, B), m2: (A, B)) = (a.mplus(m1._1, m2._1), b.mplus(m1._2, m2._2)) } // Prints (6, "abc") println(mplus3((1, "a"), (2, "b"), (3, "c"))) 
Thank you very much for the feedback and the solution for automatically bringing the product monoids in scope. I was indeed solely working with implicit parameters. I will extend the article with your information as soon as I find time.
And please do keep posting - I really did enjoy reading your post, and it happens to discuss a subject that I've recently developed a strong interest in (Haskell, Scala, type classes, and how Scala wishes it could do them as well as Haskell).
Thanks, I feel flattered :) I have just recently started this blog, after the friend, I originally wrote this article for, suggested me to share this article with other people, and it is the first time I have released something I wrote into the wild. I really enjoyed writing the article and I am planning further posts on software design and programming language theory, especially with respect to Haskell and Scala. I think my next few articles will be about how basic concepts from category theory can be used as abstractions in software design, especially about the Functor-Applicative-Monad type class hierarchy. I think I will keep using both Haskell and Scala for code examples.
Parameters can also be more verbose when existentials are involved; e.g. List and you don't care how T is bound. Type members are also better when refinement is gradual. 
Are you using Scala 2.11 or 2.10 in your project?
Hi, thanks for the feedback and contribution! Interesting code you have posted. I have to admit, I had to read it a few times until I got a feeling for what you have tried to do ;) I feel like there are a few problems with that approach: - The bundling of value and monoid instance functions in Element and Zero creates an (for monoids) unneccessary space overhead, since for a monoid there is one function, which covers all elements. Does any one know if and how today's compilers optimize space properties? - Distinguishing between the non-zero and zero elements by wrapping them explicitly in the data constructors `Element` and `Zero` seems not neccessary, since the combination function of the mathematical monoid already treats the neutral element as neutral. - Since the monoid combination `++` has type `Monoid[M] -&gt; Monoid[M]` one can combine values of different monoids for `M`, which probably is in most cases unwanted behaviour, e.g: `Element[Int](2, +) ++ Zero[Int](5)` which evaluates to `2`. I don't know if there's really an integer monoid with 5 as zero, but in general a type can have multiple monoids with different operations and neutral elements. This problem is also present in the other approach, where multiple instances are simply not allowed, so the common approach, I have often seen in Haskell code is, as you have also suggested, to wrap the values in different boxes, as can be seen in the following code, which implements two monoids for the `Boolean` type: . case class BoolAnd(v: Boolean) object BoolAndMonoid extends Monoid[BoolAnd] { override def mplus(b1: BoolAnd, b2: BoolAnd): BoolAnd = BoolAnd(b1.v &amp;&amp; b2.v) override def mzero: BoolAnd = BoolAnd(true) } case class BoolOr(v: Boolean) object BoolOrMonoid extends Monoid[BoolOr] { override def mplus(b1: BoolOr, b2: BoolOr): BoolOr = BoolOr(b1.v || b2.v) override def mzero: BoolOr = BoolOr(false) } object Main { implicit val bm1 = BoolAndMonoid implicit val bm2 = BoolOrMonoid def fold[M: Monoid](ms: List[M]): M = ms match { case (m :: ms) =&gt; Lib.mplus2(m, fold(ms)) case List() =&gt; Lib.mzero2[M] } def main(args: Array[String]): Unit = { println(fold(List(true, false) map BoolAnd)) // ==&gt; BoolAnd(false) println(fold(List(true, false) map BoolOr)) // ==&gt; BoolOr(true) } } 
That's true. Now that you mention it, could one define a monoid in a better sense? The elements themselves are just symbols, but the *structure* seems important in a monoid. I'm still new at category theory but a monoid seems to define only the special element, the binary operation, and everything else. The problem with going to symbols like integer and strings is you have to embody the monoid operation *and* the combinator on the symbols. Like in your example, I can easily define the "5" as a zero. The symbol combination function I gave it won't match up and respect monoid structure, but the classes will. I guess what I'm trying to ask is, it there a strong specification that within the system, both respects monoid structure in terms of the value of classes and the classes themselves?
&gt; That's true. Now that you mention it, could one define a monoid in a better sense? The elements themselves are just symbols, but the structure seems important in a monoid. I'm still new at category theory but a monoid seems to define only the special element, the binary operation, and everything else. I think the set theoretic definition as a set of things whose semantics is defined by an associative operation, which treats one of the elements as a neutral element is already quite compact and intuitive, since it only relies on very basic set theoretic concepts. Building on category theory instead of set theory, one can view a monoid `M` as a category `C[M]` which - has only one object `M`, meaning that we can compose any arrow with any arrow - has the elements of the monoid set as arrows `f: M -&gt; M` - has the associative monoid operation for the associative arrow composition - has the neutral element of the monoid as identity arrow `id_M` From this pespective a category is simply a generalization of a monoid, where the associative binary operation has only to be defined on some values, which have compatible types, meaning that the values are arrows with composable "object signatures". This definition is also quite self containing, since it also builds on very basic mathematics. Another way that comes to mind is to describe it in terms of other set theoretic structures. For example a monoid can be considered a semi-group whose operation has a neutral element. A semi-group is a set with an associative binary operation, but not neccessarily a neutral element. &gt; The problem with going to symbols like integer and strings is you have to embody the monoid operation and the combinator on the symbols. Like in your example, I can easily define the "5" as a zero. The symbol combination function I gave it won't match up and respect monoid structure, but the classes will. &gt; &gt; I guess what I'm trying to ask is, it there a strong specification that within the system, both respects monoid structure in terms of the value of classes and the classes themselves? I am not sure I understand you completely here, but the usual way one ensures that a monoid instance really satisfies the monoid properties, is to write the expected properties somewhere in the type class documentation and expect programmers to make sure their instances are correct. Bringing advanced proof techniques such as model checking in scope one may be able to let the compiler prove at least some of those properties. 
Yeah. It seems I've been running into these weird situations a lot lately where only some of the properties of the system can be proved within the system. Like for these infinite sets like the integers, it'd obviously be impossible to check whether the identity law holds for every integer. It seems to require a proof outside of the system (the part where you said expect programmers to make sure their instances are correct) and knowledge of numbers to show for all integers, the identity holds. It seems checkable if its a finite monoid though.
Finally read through these, quite nice. Can you really express type class laws with dependent types (assuming scala had them one day?)
That I'd like to know too. There are some nice Scala jobs out there but unfortunately I can't move currently and I haven't found one where I could work remotely yet. Instead I'm working with Ruby right now.
&gt; What's your opinions about this? You know, there's a [reason](http://whyjavasucks.com/) no one uses java / scala / whatever JVM stuff for client-side applications (Android doesn't count since it's not real java). The future of the JVM (if there's any) will be on the Server side, like it's always been. If you need client-side applications targeting Windows, look into WPF / XAML. If you need client-side applications targeting anything else, look into GTK or QT. If you need a JVM based solution for the above, you're pretty much f*d up. Not to mention your Windows-based users will be [pretty upset](http://www.reddit.com/r/funny/comments/2dn346/my_buddy_is_a_sales_rep_at_oracle_this_is_an/) about having to install java in their machines.
I agree that Java sucks at such purpose compared with C#. But there are a few useful apps written in Java like Eclipse and GUI is useful for library tests. So you mean, for that purpose, 3rd-party support is enough?
There is the option of bundling a JRE with the application, like Matlab does as well as several other prominent softwares. That way the user hardly even notices that they are running a Java app, other than the strange uncanny UI. But the point still stands, yeah...
You may be interested in the youtube video mentioned in the following thread: http://www.reddit.com/r/haskell/comments/24pjlo/verifying_the_monoid_laws_using_idris/ It shows how to prove the monoid laws using dependent types in the Idris language.
I rarely have to write Gui code but last time I did, I used https://github.com/scalafx/scalafx ... it's a que nice DSL and the result was fairly good looking.
also I guess on careers.stackoverflow.com is possible to find that job but not so many post is created for international developers
Yup, that was my experience when trying ScalaFX out too. JavaFX8 is the closest that Java ecosystem now has to WPF. Subjectively speaking, I think it's not on WPF level, but it's way better than Swing.
God it looks just like the discussion in TTFP. Requirement of an Identity type. Carrying around the proof that it meets specification in the object.
Recently I have to build simple gui tool and it was big surprise for me that scala doesn't have any officially supported gui library at all. I think that might be scala not so good for commercial client side applications, but anyway for some in house system utilities, tools etc is important to have some stable gui library in standard library - like Tk in python or Wx in erlang. 
&gt; some client side application on JVM has good enough quality of UI, IntelliJ Idea for example. Yes. That's why everyone is rushing out and going crazy and running and leaving their wives and children to go develop java-based client-side applications, right?? &lt;/sarcasm&gt; NO. NO ONE uses java for client side applications (developer targeted stuff doesn't count). java sucks. It sucks even more for client side apps. Face it.
In those examples, Tk and Wx are actually wrappers, required because the languages are not designed to be transparently interoperable with languages the GUI libraries were written in. In case of Scala, you can assume Java's stdlib as always available and you can call Java code without any problems, so there's simply less need for any wrappers – Java has in fact not one, but two GUI libraries in stdlib, and that's even without counting JavaFx. I wrote several smallish Scala GUI programs and I used standard Java API for all of them. This way, I had no problems with adding custom 3rd-party widgets or layouts, Stack Overflow questions about Swing in Java were directly applicable, and I didn't risk an additional layer of potential bugs and abstraction leaks. I just wrote one file of helper functions that provided me with syntactic sugar for doing layouts.
Why use shapeless when scala provides a native solution? val structureToOperateOn = List(List("a1","a2","a3"), List("b1","b2","b3") , List("c1","c2","c3"), List(10,1,11)) val struc0 = structureToOperateOn map (xs =&gt; xs.zipWithIndex) flatten val struc1 = struc0 sortBy (t =&gt; t._2) val slideValue = structureToOperateOn.length val operatedStructure = struc1 sliding(slideValue, slideValue) map (x =&gt; x.unzip._1) toList
android. 
&gt; android Which is NOT real java, it doesn't support java's latest features (I.E lambda expressions where java has finally catched up to C# 3.0 from 2007). Not to mention that there is [**PROOF**](http://blog.xamarin.com/android-in-c-sharp/) that **if Android used a decent language instead of retarded useless java** it'd be not only much easier to write in, but also [**faster**](http://tirania.org/s/71de890b.png) and the whole API would probably be **better designed** (such as real events as opposed to java's "listener" crap, etc). Sorry, java sucks and is a worthless piece of crap. Face it. It might be ok for server side stuff, but it sucks and is useless in the client side.
 Lots of trading apps do.
&gt; Lots of trading apps do Lots of banking stuff is also developed in COBOL. That doesn't make COBOL an option to create any new software in 2014. Sorry, java sucks and is a retarded worthless piece of shit. Prove me wrong ;)
jesus christ chill the fuck out
&gt; Sun would never have considered making the JVM so C++-like. Could you expand on that? What do you mean by making the JVM "so C++-like"?
I wasn't saying it was good or bad, just that it is used to develop client-side applications. As for C#, Google would never use a Microsoft-controlled technology as a base for their platform. Besides, you can use a language to develop for Android that is better than Java or C#: Scala. Also, C# didn't invent lambda expressions. They've been around longer than computers - since the 1930's, and Lisp had them in the 1950's. There was a decision made not to include them in Java to make the language simpler. A bad decision, maybe. 
&gt; Google would never use a Microsoft-controlled technology as a base for their platform Right, I'm sure it's better to use an oracle-controlled one? sorry, that's a non-argument, to be honest, given the current state of affairs. oracle sued google about Android, and chances are that if they used C# they wouldn't have had that problem, since it's under a legally binding community promise. &gt; Scala Which proves my point that in order to avoid / work around java's imbecility and retardedness you need a different language. BTW, if we talk about functional-first languages, there's also F#, which beats the SHIT out of scala...
At the time that Android was released, C# didn't exist. The reason they wouldn't use it anyway is the same reason that Microsoft released the completely unnecessary Windows phone. I'm not talking about functional-first languages, because Scala isn't one. If you want to talk about functional-first languages F# is just a gimped version of Ocaml. In that case you can do better with Lisp or Haskell depending on your preferences. I don't have too much experience with either one but my perception is that they're both just kitchen sink languages, C# is object oriented with functional programming bolted on and F# is functional programming with object orientation bolted on. Scala was started with the express purpose of finding rational ways to unify the paradigms and not just throw shit together. 
&gt; At the time that Android was released, C# didn't exist BULL-SHIT. From Wikipedia: &gt; The version history of the Android mobile operating system began with the release of the Android beta in November 2007. while C# 1.0 was released on 2002. You know, you might want to check your statements before speaking in public. Otherwise people might think you're either a liar, or an idiot. Anyways, none of that makes java less retarded and useless. &gt; The reason they wouldn't use it anyway is because they're bunch of arrogant assholes, and they prefer to get sued by shitty oracle than admitting that a piece of technology by Microsoft is actually a good, well-designed technology. &gt; not just throw shit together. LOL, WTF. F# is a really well-designed language designed and developed by competent professionals rather than a bunch of unknown anonymous hippie weed smokers like several open source projects, or managed by and endless stream of bureaucracy which completely cripples its evolution like java. F# was designed from the ground up to compile to CIL, which is purely OO. So your statement that &gt; F# is functional programming with object orientation bolted on is pure bullshit. On the other hand, Scala sacrifices a lot of potential when it comes to Type Inference, not only because it's design decisions, but also because it needs to run on the (rather lacking) JVM. See http://stackoverflow.com/a/2977953/643085
There's actually a better solution at the bottom of the page, but I don't blame you for not getting that far. They said: &gt; val operatedStructure = structureToOperateOn.transpose which resulted in: List(List("a1", "b1", "c1", 10), List("a2", "b2", "c2", 1), List("a3", "b3", "c3", 11)) The correct answer is not have that structure in the first place. There's no way that someone is passing that List[List[Any]] to him, and I guarantee the problem was earlier in his code. There's also no reason to end up with nested lists in the end, so he could have used something like this to all three intermediate collections: val struct = List(List("a1","a2","a3"), List("b1","b2","b3") , List("c1","c2","c3")) val xs = List(10,1,11) val result = for { (strs , x) &lt;- struct.transpose.zip(xs) if strs.size == 3 (a,b,c) = strs match { case List(a,b,c) =&gt; (a,b,c) } } yield (a,b,c,x) (assuming that compiles, it'll give the right answer... could be shorter, but I think this is pretty enough.) If he wants to name a case class for this monstrosity, the name of it goes right after "yield". This title is bad, and the article is bad, but he can use that if he finds this comment. Even if he *absolutely* has to start with the List[List[Any]], it shouldn't be too difficult to work out from there. If it has to result in a List[List[Any]], then add "List" after yield... but that would be dumb. Like the article. Honestly, I think we should just ban dzone from this and hopefully all programming subs. It's not even blogspam, it's 99% stolen articles, when it's not garbage like this. I wouldn't be surprised if this is actually a poorly generated post, and there's no real person named Sidharth Khattri. edit: got curious and ran this. It compiles, but changing the match line to List(a,b,c) = strs is better. I've never done that before, but got curious about the extractor there. Learned something because of this article, cool!
&gt; `def absurd[A, B](a: A): B = absurd(a)` &gt; This is the halting problem No, it isn't.
I think you've got your terminology mixed up a bit. These aren't pointers in the C sense, and lambdas are definitely *not* function pointers. I agree with specialization though, and value types, can't wait for these things to arrive.
&gt; Is the former actually worth maintaining? Absolutely! 1. The event system is _much_ easier and _way_ less boiler plate. 2. The property names are Scala'ish (`var text` instead of `def getText / def setText`), yielding a simple style of creating hierarchies by instantiating anonymous subclasses and adjusting the properties. If you have used both, you will almost certainly not want to go back to `javax.swing`.
There is a Scala Swing module for Scala 2.11, and community "outsourcing" cannot slow down pace any further, as previous development has almost halted. But `javax.swing` also develops very slowly with each Java release, so it's not that Scala will become "outdated" or anything.
&gt; If you need client-side applications targeting anything else, look into GTK or QT. What exactly is that advantage of a JVM application hooking into natively compiled C libraries like these? Swing API is good enough for almost all desktop applications. Missing components like web view can be added via JavaFX (you can mix both).
Scala-Swing _is_ a stable and quasi-standard library (it has been part of the standard library since very recently).
Sorry, you're right on that first part, at least in terms of the two dates, and you've forced me to actually look stuff up to continue. So, Android development started much earlier, it's not clear exactly what happened when, but Android Inc. was founded in 2003, and bought by Google in 2005. It's not unlikely at this point that they had gone too far with Java to start over. This puts it not much after the release of C# 1.0, at which point it was not only a completely unproven technology, but a completely unproven, Windows-specific technology. (Some, including myself, would argue that it essentially still is - despite the existence of Mono - 99% of Java applications will run on any Java platform, can't say that for .NET applications. A "cross-platform language" is worthless if it relies on a proprietary, platform-specific standard library). As for Oracle, they didn't even purchase Sun until 2009 so that's not at issue here. I would agree that C# is better than Java. It should be, considering that it had several years to look back at Java's mistakes and start over, without any requirement to maintain backwards compatibility. The same could be said for Scala - except that by running on the JVM, Scala can seamlessly call legacy Java code. I've brought up Scala where I work (enterprise Java) and the main concern is just the ability to bring the rest of the team up on the language and the availability of programmers. One thing that is notably NOT a concern are the business plans of Oracle and Typesafe. The specifications of C# may be open, but the standard implementation is not, and without continued support from Microsoft, users will be up shit creek. Ask anyone who built their business on a VB6 codebase how they feel about being that reliant on Microsoft. On the other hand, despite what you say about "admitting that a piece of technology by Microsoft is actually a good, well-designed technology", the opposite is true - nobody would even be using C# if it weren't from Microsoft and being pushed as the standard language of their ecosystem. It's better than Java, sure, but that's not saying much. As for that Stack Overflow question, you linked to the one response that agrees with what you said - every other response says pretty much what I did. And, FWIW, Scala's weaker type inference has absolutely nothing to do with the JVM. It is a strictly compile-time process, and the decision was that the ability to have subtypes was more important. 
Why not just convert them to lists and concat them all into 1 big list, then convert back to a tuple?
&gt;Xamarin Proved that Android would benefit both technically and non-technically by switching from java to C#. I'm not sure how concerned they are with binary tree performance, but it's interesting to note that Google is moving away from Dalvik on its upcoming releases. JVM performance on the PC is on par with the CLR so it's not apparent that it is the language providing a benefit here. &gt; Otherwise, if java was a really "open" platform as java fanboys often like to claim, the oracle versus google lawsuit would have never existed. I suppose it depends what you mean by "open". Yes, C# has an ECMA/ISO spec and Java does not. But, Java's implementation is more open - the standard implementation of C# is closed-source. The claim in the Google lawsuit is that Google took Java code that was released under the GPL and then re-released it under an incompatible license. The controversy was whether Google did in fact copy significant code, but the fact remains that had Google released their code under the GPL there would have been no basis for a claim. On the other hand if you develop in C# and use anything that is not covered under the spec, you may end up SOL should Microsoft change its mind. In practical terms, unless you are modifying Java itself and distributing your modifications, it is a more open ecosystem. &gt;If this was true there would be no Mono If the existence of Mono proved that .NET was an open platform, then the existence of Wine proves the same for Windows, which is ridiculous. The spec lags far behind the MS implementation, nothing implemented in Mono not specified in ECMA (from 8 years ago) is covered. &gt;What's there to ask? VB6 based software still runs on Windows 8.1 today. Not according to [this article](http://www.infoq.com/news/2014/04/VB6-Crisis), in many cases. It would seem that VB6 is responsible for many of the applications that function poorly in more recent Windows that have made the XP end-of-life such a big issue. In any case, anecdotal evidence indicates that a lot of VB6 developers feel pretty well shafted by the whole thing. &gt; If C# would have been open source and cross platform from the beginning, literally NO ONE would be talking about retarded useless java by now. Not likely. There are plenty of better languages out there, people use Java because it's entrenched in certain areas. A lot of the reason for this is what is perceived to make the language bad - its lack of features can make it more approachable to mediocre programmers. Only having one paradigm available means the programmer only has one paradigm to understand. &gt; If it wasn't "saying much", do you think a Xamarin license would cost $1000 US dollars? People pay for Xamarin because it allows them to develop for multiple platforms with a single codebase. If it used Java or even COBOL it would have the same benefit. If C# were driving this we might see more interest in developing for Windows Phones. &gt; F# exists because it is intended to solve a different set of problems than C#, not to replace C# All programming languages are intended to solve the same problem - writing computer programs. The different approaches they take make them more or less suitable for certain types of programs, so in the case of a mixed-domain application you end up either making tradeoffs or getting stuck writing different parts in different languages and gluing them together with foreign function interfaces, etc. Not being in the Microsoft ecosystem I'm not too familiar with how well they mix together, but from what I've read on the issue, mixing F# and C# code in the same project is not trivial. This means that when developing a mixed-domain application with one part more suitable to OO and one more suitable to FP, it's more likely they're just going to pick one language for both and deal with it in the case where their chosen language is less appropriate. Using Scala it's easy to pick the most appropriate solution for any given problem at a fine-grained level. up to mixing imperative and functional code in the same method using nested methods for encapsulation, etc. This is why Scala exists. C# exists because Java isn't owned by Microsoft. while it may be well designed as a matter of opinion, it brings nothing new to the table. 
So, why shouldn't I use GoF patterns, precisely? 
I think the sentiment is more that you should not turn as readily to GoF in Scala as you would in java, since scala has language features that often solve problems better than a GoF design pattern would. I've heard it said that design patterns are really just ways to iron out a language's shortcomings, and in that regard, if you can achieve your goal clearly using native language constructs, then this is likely to be more productive than resorting to a design pattern.
That meant to be a rethorical question, but a valid point was raised, thank you very much. Indeed, there are patterns in GoF that are trying to overcome a certain language shortcomings. But those are few, and at the same time the book (and lots of works after it) carries a lot of language independent patterns - ones that valid for every OOP language out there. The author just put it in a way as if GoF is some kind of a crutch for java people specifically, and I don't agree with that. 
&gt;This stands out as the longest rule, which is a result of specifically and separately condemning coding style from other programming languages (Haskell), This doesn't make sense to me. We should avoid functional programming because it's from haskell, we should avoid OOP because it's from C++, wtf? Scala's supposed to be a fusion of two somewhat orthogonal paradigms but he's arguing we explicitly avoid using a style from both of those paradigms? &gt;scientific words (category theory) Or multiplication, modulus, factorial, recursion, *gasp* function? I mean, this is so ridiculous I'm embarrassed for this guy. &gt; or jargon (‘monad’ and ‘functor’). Orwell is not arguing against functional programming: he merely demands that this be done within the standard Scala idiom, without dragging other disciplines into it. Because of how poorly written this blog is, it's hard to understand what the disconnect here is, but I'm curious what he'd propose for calling a type class that contains a map method, or one that has a flatMap, and point method? Because if he doesn't have a better suggestion, it's kind of ridiculous to say we avoid using names with established meanings. &gt;As with written English, code that uses unnecessary theoretical terminology looks pompous and fails to achieve its original goals. Jargon from computer science and mathematics is especially inappropriate in business software, where the language is better derived by domain-driven design. Absolutely wrong. Why would business jargon be better than something that has *cross cutting* meaning across multiple businesses, or multiple aspects of a single business, etc? The benefit of principled, type class driven development is that once you *learn* the type classes, they translate to almost any domain or problem set. It doesn't matter if I need to write some code for the part of my software that deals with automotive data or financial reports from web ads. If I can see that they're both monoids and traversable, I can write code for both. I can *forget* about the domain. Life is *easier*. 
http://jobmote.com/tag/scala http://www.jobisjob.com/scala+remote/jobs
Tuple -&gt; List -&gt; Tuple should not work: A tuple has a known length, a list doesn't. Even if it worked, it would destroy the type information: Tuple[A,B,C] would result in List[Any] and this would result in Tuple [Any,Any,Any] Edited: Grammer....
&gt; I've heard it said that design patterns are really just ways to iron out a language's shortcomings This is nonsense. Design patterns are nothing more than standard solutions to recurrent and very frequently design requirements, which provide valuable features that minimize refactoring. Plus, they are a way to add semantics to a set of language components so that the interaction between components can be easily explained in a concise way. I'm starting to believe that the only people bitching about design patterns are those who are the most clueless about them and how they're used. So, they put up these absurd and nonsensical excuses to shy away from them, while resorting to hackish ad-hoc solutions, just to avoid taking the time to understand a standard solution to standard problems.
Quite true. The [builder pattern](http://en.wikipedia.org/wiki/Builder_pattern) springs to mind as one of those design patterns that are often labeled as a fix to a language's shortcomings (see C++'s named parameter idiom). Yet, what these critics miss about the builder pattern is that it's a clean way to support constructors that take multiple parameters, provides a way to recall a function that takes multiple parameters or pass the same parameters to functions that only take a subset of them, and minimizes refactoring when any of those functions is rewritten. Naming parameters is the least useful thing about the builder design pattern, but some people still complain that it only exists due to C++'s lack of support for named parameters.
&gt; Orwell's admonition against using "the passive" is especially embarrassing considering that analysis of his writing reveals that he uses passive constructions more than the average writer. These comments are supposed to be guidelines, not hard rules. Additionally, the rule states that the passive voice should be used whenever possible, not always. &gt; No one should take his prescriptions about writing seriously. Some smart people do. Some reference academic journals explicitly include Orwell's guidelines in their style guide.
&gt; Because of how poorly written this blog is, it's hard to understand what the disconnect here is, but I'm curious what he'd propose for calling a type class that contains a map method, or one that has a flatMap, and point method? Because if he doesn't have a better suggestion, it's kind of ridiculous to say we avoid using names with established meanings. I agree with your criticism, including this part, but if there is an obviously better name than the categorical one then we should take that. Examples of that includes: * `flatMap(f)` is better than `f*` * `flatten` is better than `μ` * `point` is better than `η`
&gt; These comments are supposed to be guidelines, not hard rules. Additionally, the rule states that the passive voice should be used whenever possible, not always. But I just stated that Orwell *empirically* breaks his own damn rule! If he can't even follow it, why should anyone else? &gt; Some reference academic journals explicitly include Orwell's guidelines in their style guide. Well, many also uphold the preposterous [Elements of Style](https://chronicle.com/article/50-Years-of-Stupid-Grammar/25497) as some sort of definitive reference, so this assertion is meaningless. The Elements of Style is especially embarrassing as it does things like provide at least three examples of the passive voice, none of which are actually in the passive voice. If E.B. White can't even competently determine what clause is in the passive voice, why should we trust his admonition against it? Another stupid rule is that writers must use "which" to introduce nonrestrictive clauses and "that" to introduce restrictive ones. Of course, no such grammatical rule has existed in the history of the English language. Fowler merely suggested that such a rule might make simplify the language for a writer, and E.B. White and others took Fowler's musings as law. Of course, Strunk had never heard of such a rule! So when E.B. White revised the book, he had to remove every instance of Strunk using the word which "incorrectly". Intellectually bankrupt.
This is too much of a fluff piece. It might be interesting if the author actually took the time to demonstrate with actual code and explain why it would be better.
&gt; This doesn't make sense to me. We should avoid functional programming because it's from haskell Partially that doesn't make sense because you didn't read the full paragraph. From the article: &gt; Orwell is *not arguing against functional programming*: he merely demands that this be done within the standard Scala idiom, without dragging other disciplines into it. I'm not good enough in Scala to comment with experience, but at first blush the article appears to be rather ... bad, but let's not ascribe to him things he didn't say.
&gt; &gt; I've heard it said that design patterns are really just ways to iron out a language's shortcomings &gt; This is nonsense. Amen - it's a platitude that's easily remembered and simply makes people sound smart by saying it; like "use the best tool for the job". Gee, thanks; no shit? Patterns are just larger idioms. Some are designed around language quirks and sharp edges, sure, but this stupid saying covers them all with the same brush. It's faux-erudite claptrap. 
&gt; These comments are supposed to be guidelines, not hard rules. Then perhaps he should call them Orwell's Six Guidelines. 
Well said. Design patterns are simply good practices that have emerged from the use of your language. Each language will have a different set. To paraphrase Stroustrup, there are two kinds of languages: languages that have design patterns and languages that nobody uses. 
But he doesn't explain his contradiction. If he says "let's use parenthesis and multi-parameter functions unlike Haskell style" then I'd say "oh ok, that's a fair point". If he's against the use of non mathematical symbolic operators I get it. But he says "i'm not arguing against functional programming" but then quite vacuously says "but don't be haskell". 
You've linked to the documentation of the abstract class Source which is not directly usable, instead you want it's [companion object](http://www.scala-lang.org/api/current/index.html#scala.io.Source$) zpowers@zpowA:~⟫ echo "hello" &gt; myfile.txt zpowers@zpowA:~⟫ scala Welcome to Scala version 2.11.1 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_60). Type in expressions to have them evaluated. Type :help for more information. scala&gt; import scala.io._ import scala.io._ scala&gt; import java.io._ import java.io._ scala&gt; val mySource = Source.fromFile(new File("myfile.txt")) mySource: scala.io.BufferedSource = non-empty iterator scala&gt; mySource.getLines foreach println hello scala&gt; 
To actually find the companion object of a type, have a look at the (C)-label in the top left. If it looks like it's coming off that's because there's an object beneath it (click it ;))
good, i hope you get a divorce, and she screws you over :-)
Part of this has to do with knowing the language in general. If you look at the documentation for the class, you would see it was an abstract class (cannot be instantiated), furthermore if it is called as Source.fromFile("filename") then it must be an object, as a class would need to be instantiated first - Scala doesn't have static class members. 
Not really.
It is important to understand that (generally speaking), Scala provides all of the essential nuts and bolts you need to do *absolutely nothing*. As soon as you need to leave the abstract ideal of a computational language (e.g. doing some I/O), you need to be looking for a library, as this is mostly beyond the scope of Scala's standard library. (Note that you have access Java's standard library by default.) This is a good thing, as a tight scope hopefully prevents the stdlib from becoming a bloated monstrosity full of deprecated methods down the road. Scala differs from Java in that it has separate namespaces for types and values. `scala.io.Source` refers to a class in a type context, and an object in a value context. You can switch between types and their companion objects by clicking on the class/object symbol at the top of the page or in the left margin of the search results. A lot of people tend to complain about the Scaladoc format; apart from the abomination that is `@usecase`, I find it is quite good. Certainly miles better than Javadoc.
&gt; The Scala language is still new and young Er... what? Scala is more than ten years old. 
On scala-lang.org, companion objects of classes or traits with the same name will be documented on different pages. You can access them by clicking on the "O" next to the "C" or "T" next to the class name on the left of the page. If you're already on the page and want to get to the page of the companion, click the big file name at the very top of the page to go the companion documentation. Alternatively, add or remove a $ to the end of the URL. So, the page you're looking for is [here](http://www.scala-lang.org/api/current/index.html#scala.io.Source$). This is admittedly not at all obvious to a new user.
That was a interesting yet fun, cool yet helpful, read. I find it awesome that so many people are happy about Scala :)
I love the first diagram and that thick tendon that connects scala straight to java. Then there's pretty much only one other offshoot - to haskell!
When compared to Java or C, it's newer. I'm aware that there are newer languages than Scala. I should have added the qualifier "relatively".
Because a tuple can have different types. It doesn't work. 
Hey, there was a small but noticeable connection to python too :p
The chord diagram is interactive, and built with d3, so that's cool.
One could interpret that to mean that the Scala community is nothing more than a splinter of the Java community whose communications are necessarily dominated by the same concerns as the Java community and that they therefore wouldn't have an outlook noticeably different from the Java community's. Hey, I just lurk here. :D
Well I actually mod on java. It seems like a natural progression from oo to functional for most java devs as Scala let's you ramp up the complexity nicely. While something like clojure feels like it might be quite daunting for a java dev with no lisp experience. Also we have the ability to run Scala and java together thanks to the jvm. 
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Hawthorne effect**](https://en.wikipedia.org/wiki/Hawthorne%20effect): [](#sfw) --- &gt; &gt;The __Hawthorne effect__ (also referred to as the __observer effect__) refers to a [phenomenon](https://en.wikipedia.org/wiki/Reactivity_(research\)) whereby workers improve or modify an aspect of their behavior in response to the fact of change in their environment, rather than in response to the nature of the change itself. The "Hawthorne effect" study suggested that the novelty of having research conducted and the increased attention from such could lead to temporary increases in productivity. &gt;==== &gt;[**Image**](https://i.imgur.com/Vn8bbtD.jpg) [^(i)](https://commons.wikimedia.org/wiki/File:Hawthorne_Works_aerial_view_ca_1920_pg_2.jpg) - *Aerial view of the Hawthorne Works, c. 1920* --- ^Interesting: [^Hawthorne ^Works](https://en.wikipedia.org/wiki/Hawthorne_Works) ^| [^Pygmalion ^effect](https://en.wikipedia.org/wiki/Pygmalion_effect) ^| [^Reactivity ^\(psychology)](https://en.wikipedia.org/wiki/Reactivity_\(psychology\)) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cjwd645) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cjwd645)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I'm fond of [IdeaVim for IntelliJ](https://github.com/JetBrains/ideavim). It's the best of both worlds.
I can agree that IdeaVim is the best Vim integration in an IDE (also heard that Vim plugin for Visual Studio is pretty decent too), but there are still several issues with it. The good thing is that IdeaVim is [open source](https://github.com/JetBrains/ideavim) and JetBrains guys are actively working on it, but there will never be support for Vim plugins and even the .vimrc support is/will be limited. On the other hand IntelliJ has excellent plugins and functionality out of box that reduces the need for Vim plugins.
Same sad story with emacs... I am forced to use emacs keybindings in IntelliJ -- and while not bad, the downside is that a lot of IntelliJ short-cuts get overriden by emacs shortcuts. It seems like emacs/vim already have so many shortcuts built it there is no more room left for programming/refactoring/ide-like shortcuts.
The story is not that sad - try [Ensime](https://github.com/ensime/ensime-server) It may have some pointy edges, but is currently being actively developed and improved (bug reports and pull requests are always welcome :) )
We (the [Ensime](https://github.com/ensime/ensime-server) team hope to fix this in the nearish. Ensime is currently targets emacs, but the backend (other than using lisp for its communication protocol) is actually editor agnostic. I believe their were ensime/vi plugins in the past but they are probably stale/dead. - If somebody wants to develop one you will get active support from the ensime team. 
Lol, more of Apple's weaksauce ARC nonsense. No, thanks. GC or GTFO.
Interesting! Is it similar to the Vim version of headless Eclipse server (Eclim)?
Objective-C is part of the GCC collection, unlike C#. You can use the GnuStep libraries with it on Linux. Edit: Objective-C 2.0 is available through Clang Objc + GnuStep.
Yes. It can be compiled in other OS than Mac OS. However, the popularity difference between C# in non-Windows and Objective-C in non-MacOS/iOS is quite large. Is there something like Unity3D and Sony PlayStation Suite SDK, which use C#, in Obj-C community? A lot of C++ programmers like C#, but they don't like Obj-C due to the unique syntax of Obj-C, such as square brackets everywhere, which is far different from the traditional mainstream OO languages like C++ and Java. I know that a lot of Obj-C progammers like Obj-C, but that also applies to C# programmers. You can search *C# shit* and *Objective-C shit* in Google. You'll see search results like "C# is bad for games dev" or "C# performance sucks" in the first one, whereas "Objective-C is a Piece of Shit" or "I hate objective C" in the second one. I don't even predict the future of Obj-C as bright as C# after the appearance of Swift. A lot of developers will go to Swift as they did so for Obj-C years ago.
If you don't have any desire to code specifically for Apple platforms, it's probably not worth your time to participate in any thread about Swift.
But I want to talk smack about stuff I don't use. :(
They descended from the same ML...of course they are going to be similar. You could cherry pick near exact matches from other ML-descendants like OCaml, Haskell, F#, and Rust. 
At a high level they are similar, but I think they have taken a fundamentally different approaches to provide the support. (headless eclipse vs directly integrating the presentation compiler). 
Looking a bit deeper they are more fundamentally different - I had not realised that Eclim allows support for all the languages supported by Eclipse. Ensime is purely focused on Scala support.
I knew about Ensime but for some reason thought it _wasn't_ maintained anymore. Was it unmaintained and this changed, or was I simply wrong?
Obj-C and C++ both appeared in 1983. C++ wasn't formally standardized until 1989. Anyway this explains the different syntax between the two. Java was inspired by C++ and C# was inspired by Java. I don't play the which language is better game because it's silly. I'm just pointing out some facts that you weren't aware of. 
I never understood the need to emulate the Cocoa library at the expense of creating a more generic library. There are generic non-cocoa/non-gnustep programs in the wild but I'm positive their number is extremely small. Anyway, I'm curious about the general community's need to create completely new languages and yet have very little desire to augment some of the more interesting ones with better more general purpose libraries. My being on a Scala reddit board should serve as evidence that I'm guilty of the same thing. EDIT: If the rumors about Swift being open-sourced after the release of iOS 8 are true (which I doubt), I may spend time making libraries for it and Obj-C 2.0 during my limited spare time. EDIT^2 :The GnuStep libraries are still being maintained.
That was my thought as well. It doesn't look any closer to Scala than to any other vaguely modern language.
The point of C# is for Microsoft to have a modern programming language that they control. As a result of that control, they have been able to advance it much more quickly than Java has advanced. If you're a developer in the Microsoft ecosystem (or if you can run on Mono), it's an excellent language to use. Apple got Objective-C came from NeXT, which is the company Jobs founded after getting kicked out of Apple. Apple bought NeXT in order to get NeXTSTEP, which you know today as OS X. (They probably also wanted to get Steve back.) The only reason Objective-C is popular today is because it's the first-class way to program the Mac and iOS devices. If Apple decided to drop support for Objective-C tomorrow, it would quickly fade into relative obscurity. Apple controls the spec (as much as there is) for the language and the library. It seems perfectly reasonable to call it an Apple language.
&gt; The point of C# is for Microsoft to have a modern programming language that they control. That may be fine for microsofties, but the rest of us consider that control to be a negative. &gt; able to advance it much more quickly than Java has advanced I hope the irony of that comparison is not lost on you. Java is still trying to catch up to the 1980s. I've heard really good things about F# (the MS knockoff of OCaml), but when I took a quick look at it, it looked more like Java than like OCaml.
&gt; That may be fine for microsofties, but the rest of us consider that control to be a negative. Your loss. It's a good language. Java, under Oracle's stewardship, has barely moved; C# has grown by leaps and bounds. All other things equal, if you asked me to choose between C# and Java for a new project, I'd pick C# every day. (Things get murkier when Scala is on the table, but for some teams, I'd still recommend C#). &gt; I hope the irony of that comparison is not lost on you. Java is still trying to catch up to the 1980s. And everything is still trying to catch up to Lisp from the 60s. But such statements are meaningless, because not everything should be Lisp.
&gt; choose between C# and Java I think you missed the point. If you tell me McDonald's shoe tastes better than poop, you may be right, but that's still not going to convince me to eat it. 
It went through a quiet patch, but is now in active development by several developers (myself included). We are doing some fairly major refactors to ensure that it is up to date and bulletproof before we start hacking on new features in anger. Take a look at the [issue tracker](https://github.com/ensime/ensime-server/issues?q=is%3Aopen+is%3Aissue) to see the stuff we are focused on right now. 
What has C# gotten recently other than LINQ? I mean something that's actually leaps and bounds better than what Java has... I really don't pay attention to it.
I'm not completely up on Java 8 yet (I've been doing C# and Scala more recently), so some of these might actually be in Java. Expression trees are pretty cool, and probably my favorite. Basically, you pass a lambda to a function, but the function doesn't receive the lambda, it receives the expression tree that the compiler generated for that lambda. They enable many kinds of metaprogramming without needing a custom classloader or other bytecode injection tool. (This is the magic underlying Linq). C# (really .Net) doesn't lose generic parameters to type erasure. The generic parameters to a type are carried with the type, and can be interrogated at runtime. I don't think Java has local variable type inference, but it's pretty handy in C#. So instead of `IEnumerable&lt;IGrouping&lt;string, Tuple&lt;int, Date&gt;&gt;&gt; f = foo`, you can just say `var f = foo`. Along those same lines, C# lets you create instances of anonymous types. So when you have some collection `c`, you can call something like `c.Select(x =&gt; new { Value = x, Name = x.ToString() })`. It's like a tuple with named properties. C# has concise syntax for initializing objects and collections. More importantly, it's not tied to the built-in collections. You can implement your own type and make it compatible with the collection initializer syntax. Extension methods let you "glue" extra methods onto existing classes, even classes that you didn't write. On the surface, it's just syntactic sugar for static methods (it takes the thing on the left side of the `.` and uses that as the first parameter to the static method). But if you squint a little bit, you can use it to add methods - with implementation - to interfaces. Non-overrideable methods, granted, but this is still pretty cool. C# 5 has async/await, which allows you to write an asynchronous function in a synchronous fashion. The compiler rewrites your code into more of a continuation passing style. Think Node.js without the ceremony. There are rumblings of adding pattern matching to a later version of C#, which would be just amazing. There are other things that I've omitted or forgotten, but that should give you a taste. I tried to stay away from things that apply to any .Net language, like the base class library, but of course these are things that will affect your day-to-day use of the language as well. 
As the [Github README for ensime-sbt](https://github.com/ensime/ensime-sbt) says, you need to: Add the following to ~/.sbt/0.13/plugins/plugins.sbt : resolvers += Resolver.sonatypeRepo("snapshots") addSbtPlugin("org.ensime" % "ensime-sbt" % "0.1.5-SNAPSHOT") Note the empty line between "resolvers" and "addSbtPlugin". Putting the above in ~/.sbt/0.13/plugins/plugins.sbt makes the plugin available globally. Now go to your project directory and start sbt (just run the "sbt" command). Then give it the following commands in order "reload", "update" and finally "ensime generate". The last one will generate the ensime configuration files for your project, based on your sbt build configuration.
Thanks. I did read the Github documentation for ensime-sbt, sbt, and ensime. Sorry if I did not make that clear. PS For those wondering, it appears that gen-ensime is the magic incantation once ensime-sbt SNAPSHOT 0.1.5 is installed. Edit: added PS after making it work.
Thanks so much. No idea what I put in the wrong place but I reinstalled sbt with the script (the version matched the one I removed), added plugins and intitalized it with sbt, put in plugins.sbt and shazam, it worked. Now I only have to fight with the fact that my brain is not Scala yet. 
This is no longer necessary. The default SBT install comes with a script based on the paulp's script.
Turtle! I love this turtle if this is the same as the one in http://www.bfoit.org/Intro_to_Programming/IntroCmds.html 
It's that one. I link to the page in de README.md
It would be better to create a simple DSL for this. Scala, the JVM, functional and reactive programming might be too much, too soon for children. There is a great turtle graphics implementation for the Racket programming language: &lt;https://www.cs.utah.edu/plt/snapshots/current/doc/turtles/index.html&gt;
It isn't reactive actually, this name is just for marketing. I don't spect the turtle to handle that much traffic. And I want the kids to learn plain Scala creating a simple Seq[Command], I don't want them to learn a DSL.
I think mixing the imperative nature of turtle (pen up and pen down) with the functional aspect of Scala is counterproductive, especially as an introduction to programming. You want to introduce concepts slowly and in an order that allows later concepts to build on earlier ones. In this case, the approaches are philosophically too far apart to accomplish that goal.
I don't want to mix both paradigms. I think exactly like you, they are too different approaches. You are contradicting yourself when you say, as I understand, that imperative concepts are previous to functional ones and you have to introduce them in a progressive way. I think that FP must be teach from the very beginning you will be able to do all the programming without control structures and state mutation. I know about the imperative nature of the turtle, what I propose here is not to hide that, but defer the action up to the end and just describe (list) the instructions in a FP way, that part isn't imperative I'm just creating a list composing pure functions and using well known FP constructions. Then we have the Remote Control to act as a bridge between the two worlds.
If you want to learn the functional part well, I highly recommend this [book](http://www.manning.com/bjarnason/). It is extremely well explained and has exercises that get gradually harder (and if you get stuck, you can just check the github out).
Hell with the naysayers, man. I started learning programming by learning CamL, a functional language. I worked 2 years as a Java programmer, and during this time I've never stopped boring my colleagues with how functional is so much better. Your initiative is just brillant. I really hope your kid will be interested enough to get the ball rolling and keep learning. I'm convinced we need more guys like you. Keep it up ! 
You should have joined forces with the author of [Kojo](http://www.kogics.net/sf:kojo) methinks.
I saw it during my previous research, but it's a complete dev env, and I was interested in something simpler for integrating in your env of choice.
Possibly Scala did not do anything about this since Java "ignored" the problem too. Play framework uses netty so I suspect it is not affected as netty has a patch for the attack but looking at the source I really could not figure it out, I am not familiar enough with the internals/attack method. Edit: Looking at the scala code, maybe they did something about it: https://github.com/scala/scala/blob/2.11.x/src/library/scala/collection/immutable/HashMap.scala#L82 But it looks like that it is not random and a String is a simple java.lang.String.
As I understand it, the Haskell and Scala actually compute the addition in production using Peano arithmetic (so computing n + m takes time in O(m)), while the Agda and the Idris use Peano arithmetic in the type to prove the type signature, but at runtime use the native plus operator. The latter would be acceptable for real life applications, the former would in most cases not be.
So does it debug in eclipse with akka and spray yet, or are they still hung up with Play and Lift, pathetic MVC
Can you come up with more details of that attack? any article describing what has happened and which frameworks/languages/etc. were affected would do. 
Nice!
::pukes rainbows:: This is an awesome little site!
https://codebrew.io/ &lt;- I like this one a bit more but wandbox is awesome
If you run that code in the scala repl (2.11.2) you will see t = 1. Not sure what you did there when you tested.
Codebrew is a bit weird: var t = 0 implicit class RichInt(i: Int){t = t + 1; def ** = i * i} t This evaluates to 0. Then doing this: var t = 0 implicit class RichInt(i: Int){t = t + 1; def ** = i * i} t val x = 2 ** t For some reason the first t will evaluate to 1 and the second to 2. Coupled with the fact that this web display is bugging out, I think CodeBrew is a bit unstable. I wouldn't recommend it as an exact replication of the compiler.
What I do in my project: skip that if it is used internally or if it is not meant to part of external apis
Can you suggest good scala resources that are not that well known. I'm new to scala. I'm watching the video lectures of coursera's scala course by Martin Odersky. I've also downloaded the scala books from O'Reilley. I want to know about good dummy projects for practice.
Check out "scala school" from Twitter. It's short but worth a read. 
Thanks. :-)
I found Martin's course to be a tough introduction to the language, hard core focus on functional style. It felt more like a lesson in algorithms towards the end, some of the exercises would have been tough for me in java, my native language
I think I'll still go ahead and watch all the tutorials
I would add that I think it's fair to drop the type when the value is clear. If you stick to defining the API always abstract, then this case will never pop up in the API's traits anyways, but only possibly in the implementation. E.g. def isEmpty = false def name = "foo" 
http://docs.scala-lang.org/style/types.html
Definitely worth it just don't be discouraged is all I am saying 
Just remember that if you use a function recursively it has to have a defined return type. Also if it's part of a public API I would also define the return type.
Due to variance it's quite easy for Scala to infer a return type that you did not intend, so I think it's a good habit to provide it, whether or not it's a public or top-level API. I do this for all `def`s and also for nontrivial `val`s. The comments on documentation are also valid; types are the **best possible documentation** because they are proven correct by the compiler; this is a kind of doc that can never be out of date. 
When would someone use this over the existing Scala templates?
Same template language for both client side and server side is pretty appealing to me.
My reasons mainly boiled down to better enforcement of separation of concerns and it means you have templates that front end devs can use. The default template need too much Scala knowledge and it's pretty hard to find an expert in JS and CSS who also knows Scala (though they do exist of course). I wrote up by reasons more here http://michaelallen.io/using-mustache-on-register-to-vote/
Then why not just use https://github.com/Amadeus82/sbt-handlebars ? Handlebars is mostly compatible with mustache.js anyways...
For the purpose of learning ...What would be the advantage to using this over Guice? 
&gt; Suppose we built type A1 which is subset of A (i.e. A1 extends A), in that case PartialFunction[A, B] would be equivalent to A1 =&gt; B: PartialFunction[A, B] =:= A1 =&gt; B // (1) Wait, what? I think you would have to clarify this step.
Can someone help with tips how to best promote a new OSS project or attract contributors?
Interesting, well-written read. Thank you. I am quite new to Scala, so I can't judge your arguments in detail yet, but they seem reasonable to me. &gt; We believe that the same infrastructure (community builds, MiMa) that will help the merge-compatible Typelevel compiler stay close to the Typesafe compiler will also be of great assistance to people who want to experiment with more radical changes. This seems like an interesting approach. A problem I see here is that when the compiler is forked multiple times for extensions with more radical changes, then it is probably hard to use these changes together. An alternative would be to have an extension mechanism, as used by GHC (Glasgow Haskell Compiler), where the community can propose language extensions, which when accepted are included in the compiler and can optionally turned on by the users on a per module basis. But I guess this also has drawbacks, like centralization and possibly broken extensions after merging a new version of the original compiler. And afterall there is still the problem of making the extensions, which are incompatible with original Scala, work together. But it would make it easier for the community to share code using one or more of those extensions, without having to reproduce a compatible merge of the corresponding compiler forks. It might be worth a thought to combine the approaches by forking the proposed merge-compatible fork to add an extension mechanism, which then could be used to collect the radical changes, once they have reached a certain level of stability, and investigate how they interact with other mature extensions.
Couple of things, for example type-safety - the object graph is created at compile-time, so any missing/ambiguous dependencies are detected at that stage. Secondly, you don't have a container, there's no run-time reflection involved. This gives you more flexibility with special cases. Also, you only use language constructs, which gives you even more flexibility, and doesn't tie you to a specific container implementation. Finally, you don't need to modify the classes in any way (no annotations required). Only "old plain constructors" are used, which is simpler to understand and "less magical". A more detailed version forms a large part of the guide :).
Sorry didyoumean, I didn't mean to post this, since it's unfinished yet. I thought if I press `hide` this post will be hidden, but it looks like I was wrong. Dmytro
Thanks this was helpful. 
The Scala compiler also supports plugins. Certain suggested features like the type lambdas + byte / short literals could possibly be implemented by a compiler plugin that only requires those compiling source using the feature to have the plugin installed, clients of the library would just see it as the de-sugared version. As for singleton-types, I think that even if it could be fit into a compiler plugin would require clients of the libraries to have the compiler plugin installed, I am not sure a compiler plugin would work for that though because it's a change to the type-system and is probably beyond the power of what a compiler plugin can achieve.
I think this is exactly what the Scala community needs. An increasingly large portion of the community has needs and desires that differ significantly from Typesafe's, whereas Typelevel is sympathetic to and better to champion them. There is great potential for improvement and advancement, despite the seemingly-unavoidable mess it will introduce. If nothing else, this will be a noble experiment, worth doing. Fingers crossed.
Martin's answer is very carefully worded but I'm having a hard time believing that Typesafe is as excited about this fork as he's trying to make it sound. If anything, there must be much consternation at Typesafe seeing Scala being open to yet one more criticism. We saw a similar scenario with D a few years back, when the library splintered and created two very different ecosystems. The D community has never really recovered from the damage caused by this fork, and I think things are looking pretty grim for Scala with this announcement. What's sad is that the damage is already done, regardless of whether the Typelevel fork succeeds or fails: plenty of people will use this announcement to justify not picking Scala for projects, citing the uncertainty and the fragmentation of the community. 
&gt; when the library splintered and created two very different ecosystems As mentioned in the article, that's not what they are doing. The compiler might be different, but the libraries and the produced bytecode is the same.
An interesting project, but an unfortunate name choice. I found it hard even to read the blog post correctly, sometimes having to backtrack to read the correct suffix to "Type". I can only imagine how confusing this is going to be for newbies to the Scala ecosystem (Typesafe and Typelevel really seem to be more or less equivalent entities - based on their name).
You certainly have a point there, however I'm not sure how likely this community separation is in this case. In the D scenario you describe, it seems like the different standard library versions are relatively unrelated to each other, making it a pain to compose third-party libraries depending on different standard libraries. I think the scenario here is different, because the Typelevel compiler implements a superset of the language implemented by the original compiler, so if you want to use libraries written for original Scala in the Typelevel Scala, you have direct source compatibility and the other way around at least binary compatibility since both compile to JVM byte code. I think it is a bit more like C++ compilers offering preliminary versions of a new standard via the "--std=c++11" flag, which gives interested users, let's say from academia or small projects consisting mainly of language geeks, the possibility to test bleeding edge ideas in the wild, before they officially get in the standard or not. Of course the difference here is that, in the case of Typelevel Scala, the version is not certainly related to the next official standard, but if used for projects, where people are willing to trade stability for bleeding edge technology, I think this shouldn't be a big problem. Nonetheless I'm also sceptical about whether a fork is the right approach, since as /u/kingcub has suggested, there is also the possibility to write compiler plugins for the original scala compiler. However I don't know for how much change they'll allow. I think you are certainly right with your concern, that it sends a signal to outside of the Scala community, which may be interpreted as instability and splintering, whether this is really the case or not. But I can't really estimate this, since I am lacking experience of how "the industry" thinks in detail. 
Would be nice if you could replace the insult with arguments for your thesis, i.e. why a singular conservative perspective is better than exploring multiple directions. (Not that I couldn't think of any arguments, but insulting someone without bringing arguments is wrong on two levels in my opinion.) **edit:** To be fair you bring some arguments, but I think the insult is still unnecessary. I think if the community has no interest in those features, then the project will simply not take off. It seems to me that all he did, was to ask if the community would be interested in this approach, and he then collected the answers and wrote an article from his perspective. I'm sorry but I can't see what's wrong with that.
I guess from a functional programmer's point of view, Java compatibility might not be that important, and from a language theorist's point of view, stability might not be that important. I think those groups, allthough they are relatively small, are fairly attracted to Scala, because it has an expressive, complex type system, and some very progressive features and ideas, including the possibility to write, in my opinion, both elegant FP programs as well as elegant OOP programs. At least this is the reason why I'm attracted to Scala :-)
Perhaps I'm misinterpreting http://typelevel.org/blog/2014/09/02/typelevel-scala.html where a focus on compatibility with Java was listed as an issue they had with TypeSafe's current approach?
The difference comes from prioritization of issues, not a conflict of implementation. Typelevel is more interested improving Scala semantics(ie, issues with type inference and functional dependencies) than fixing existing issues with Java compatibility(ie, Java 8 and unifying implementations of first class functions between Java and Scala).
Scala gets its advantage over other languages from being compatible with Java. That said I don't see why improving semantics and remaining Java compatible should be mutually exclusive. In fact, if semantics do get in the way of Java interoperability then I'd say they are doing it wrong. 
I read the article. I was responding to your "Typelevel is more interested improving Scala semantics(ie, issues with type inference and functional dependencies) than fixing existing issues with Java compatibility..." I was stating that both entities could do a little of both.
 Not sure, I'm wondering if erasure is making the two instances indistinguishable. Also, did you know there is a popular library "scalaz" that has functors? https://github.com/scalaz/scalaz/blob/series/7.2.x/core/src/main/scala/scalaz/Functor.scala https://github.com/scalaz/scalaz/blob/series/7.2.x/core/src/main/scala/scalaz/Composition.scala
First of all, *fmap* in *Compose* should take two type parameters. I presume you meant it like this: def fmap[A, B](composed: Compose[F, G, A])(f: A =&gt; B): Compose[F, G, B] = { Secondly, when you have ambiguous implicits, you can always explicitly specify them. Banal example: implicit val s1: String = "asdf" implicit val s2: String = "zxcv" def f(s: String)(implicit evS: String) = s + evS f("test") // ambiguous implicit values f("test")(s1) // Compiles Finally, to address your problem, final line in *Compose*'s *fmap* should read: new Compose[F, G, B](fgb)(F, G, F, G) I have explicitly specified F and G as needed implicits. However, I have no idea why it requires them twice. And one last note. While not *wrong*, it's pretty confusing to give same names to type parameters and arguments. I would name the two implicits *evF* and *evG*, just to avoid confusion. 
Oh, your implicit example helped very much, thank you. Also, I can see how the implicit F &amp; G could be confusing. Is prefixing implicit parameters with "ev" idiomatic scala? You are right about the two type parameters in fmap (I forgot to add A back while playing around trying to see if it could pull A from the class definition). I also don't know why it needs new Compose(fgb)(F, G, F, G) instead of new Compose(fgb)(F, G) // Fails but using the compose function def compose[F[_]: Functor, G[_]: Functor, A](unCompose: F[G[A]]): Compose[F, G, A] = new Compose(unCompose) allows compose(fgb)(F, G)
Here is an article that describes how implicits are resolved, for reference. http://eed3si9n.com/implicit-parameter-precedence-again
The lack of type safety in default akka patterns has always bothered me too. But at the same time, I see it as a pressure-release valve for the strictness of type safety. Sometimes you just want to get things done. You see this pattern more commonly when people start using strings to escape the type system ("stringly typed") Thanks for sharing!
It is possible to do much more in compiler plugins, actually. See my comment at https://github.com/typelevel/typelevel.github.com/pull/27#discussion_r17035237 for more information.
The problem (more of a concern) I have with typelevel's forking (other than having a name too similar to type safe) is the potential for incompatibilities between the official version (typesafe) and the other version (typelevel). This is a very large possibility considering typelevel's insistence that they can implement better syntax. Sure they promise merge compatibility from Typesafe's Scala, but they say nothing about the reverse being true.
&gt; Miles Sabin is a bit of a self-absorbed twit and the reason I left the Scala community in the first place. I'm almost certain you are confusing him with someone else. To the best of knowledge, Miles has been an early adopter that was always helping the Scala development and promoting the language. He is also a very polite person, so I am sure your insult was targeted at someone else.
And we all know who that someone else is...
Answering the first part, that **val logList** needs to be **def logList**, otherwise it's eagerly evaluated during the construction of your exampleLog object, and will always be empty, i.e. equal to *ListBuffer[String]().toList*.
My apologies, I didn't notice sbt-handlebars was client side only. Any plains to extend your mustache plugin to support handlebars server-side?
thank you, such an obvious fix. it helped illustrate when to use vals though, so still useful.
and dataLog can be a val (the reference to the ListBuffer never changes, just its contents) 
I specify return types for public methods, and omit them for most others.
Well, it is not much different from promoting a commercial product when you are bootstrapping your venture. It is called marketing and it is an activity that needs system, time and persistence. If you have no budget whatsoever, invest your time in educating people about your problem domain. Not everyone in the industry knows what BDD is, what are the benefits and tradeoffs, how does it stack against / combine with other approaches, what tools are out there and so on. You can put together informational articles, slides, podcasts, videos and so on. As BDD Assistant is an open source project, the audience will tolerate much more plugging than if you were trying to sell a commercial offering, but don't go overboard. To attract contributors, throw in the mix content concerning implementation details: how you are working with Scala, Play!, and any other Scala tools/frameworks you are using, how they made you more productive and improved code quality, and so on. In short, tell the audience why working on your project is fun and rewarding, what they would learn, etc. Make sure to place all text content on your project's Web site, embed videos and slides, then spend time on link building to attract more organic search traffic. ~~Get a speaking slot at each and every local developer event that would give you one. Make sure that all your talks are recorded and put online. If they are interesting, you will begin getting invitations from event organizers with offers to pay for your travel and lodging sooner than later.~~ Okay, I see you are already a recognized speaker, but I'll keep this paragraph here just in case someone else reads my reply. Now, if you have some money to spend on marketing, there are a few shortcuts. For instance, a press-release can give you lots of incoming links, at least from news sites. If you want to discuss this further, my Twitter handle is the same as my reddit username.
Is the point of this fork to feed the type level fork? Or has Paul been planning a drop of a fork the whole time, independently of the type level fork, and released now only because of the type level announcement? If Paul decides to work with the type level compiler team and all of them can come up with an amenable working agreement on direction, that's a strong indication that this is the way scala should go.
He already said that he's no interested in that.
In the readme it says: &gt; It's still in development, in every imaginable sense. **I would prefer not to publish code in this condition, which although way ahead of scala/scala** is still far short of anything I'd want to put my name on. However since typelevel has also forked the scala compiler, publishing now and giving them an opportunity to exploit my work seems the lesser evil. &gt;So for now please resist reporting bugs if it's something most likely already obvious to me. So i suppose he has been working on it for some time now. By the way Paul, now you have no justification to not start your own programming blog.
I hadn't thought of that. You could use the sbt-web JavaScript runtime (I forget what it's called) to use handlebars server side. Would be slower than using mustache.java however. 
Thanks for the reply and your work on scalac. I haven't found the time yet to understand the code in detail, since I'm not familiar with the scalac codebase. Is there a quick way to describe where the limits are of what can be done using those plugins? Are arbitrary syntactic and type system changes possible? Can you estimate how much performance overhead is usually introduced by using plugins instead of directly manipulating the core? &gt; If this approach could be made more principled, probably with some participation of the Typesafe folks on the scala/scala side, then that would be a major improvement over the state of the art of extensibility. This seems like a potentially nice alternative to the overhead of dealing with different forks and the fear of community separation.
&gt;In the meantime, this is a fork. It isn't the kind of fork that hopes eventually to be folded back into the original. The leadership of scala has shown itself unfit stewards of the core technologies and the total price paid by scala programmers (actual and potential) is too high. I failed for half a decade to change that from the inside. Now I'll try from the outside. Ouch 
I like the `@enum` thing: @enum class Days { Monday Tuesday Wednesday ... }
No: as it says in the readme I wasn't ready to release it. Someday I'll be the guy submitting the story and that'll be a good day to try it out. 
Use Try[T]. Way better than Javas error handling IMO. (It pretty much wraps try catch blocks but lets your work with it in a monadic manner).
Enumerations are the only feature in Scala which I feel is easier and more efficient in Java. Odersky has had a lot to say about the complexity of the addition of Enumerations in Java, but it's not uncommon in our systems for the only ".java" files to be enumerations because the Scala ones are so counter-intuitive and heavy.
a python 2/3 situation?
&gt; especially the ones leading to all the features in Java 5, generics You realize that this is pretty much a counter-example?
A counter example of what? 
Of JSRs "creating brilliant features".
Generics are indeed an example of a JSR that was a massive success: it delivered on time, shipped with a JDK, managed to maintain backward compatibility and the feature was adopted and embraced by the Java community within just a few years. On top of that, generics contributed to making Java code much safer than it had ever been until then. 
I think you are completely unaware of the fact that Generics were prototyped and implemented before and outside of the JSR process. They were rubberstamped after the Pizza/GJ implementation proved to be a massive success. Additionally, the worst parts of Java Generics (the way wildcards are treated) were not in the original code, but added later. So, yes, Generics are a counter-example of how great the JSR process is supposed to be.
&gt; I think you are completely unaware of the fact that Generics were prototyped and implemented before and outside of the JSR process. I've been using Java since 1996 and I'm fully aware of Pizza/gcj and even other compilers you probably never heard of (e.g. jikes). Don't make assumptions on what people know, they will lead you to commit ad hominem attacks. &gt; They were rubberstamped after the Pizza/GJ implementation proved to be a massive success. Pizza was never a massive success, it was a research project that pioneered a lot of the ideas that ended up in Scala but it was never meant to be more than that. There was no rubber stamping, JSR 14 took five years from creation to release and it was a lot of hard work. Pizza certainly had some impact on it but most of what ended up in it was customized for a JDK release with all the backward compatibility burden that this implies. You are welcome to continue to think JSR 14 was a massive failure, you're just on the wrong side of history. 
&gt; Don't make assumptions on what people know [...] &gt; [...] and even other compilers you probably never heard of (e.g. jikes). Pot. Kettle. &gt; I'm fully aware of Pizza/gcj [...] You are so fully aware of them that you can't even keep GJ and gcj apart? Sounds legit. 
&gt; Pot. Kettle. Fair enough. &gt; You are so fully aware of them that you can't even keep GJ and gcj apart? Yeah, silly me for confusing technologies I haven't used in fifteen years. 
Then you should probably drop that condescending attitude and stop lecturing other people about it.
It's calling a toString method to produce that output. Casting wont change the implementation of that method, which uses the real class -- casting just changes the reference, not the object that underlies the reference.
I think you misunderstand what casting does: its sole purpose is to tell the compiler / interpreter to treat an instance of a class as an instance of another, but it does not in any way change the instance itself. Think about it this way: an instance brings its methods and fields with itself. You can cast it to another class if you feel like it, but that won't change these methods and fields. Since methods are not changed by casting, `img.getClass` returns the exact same value, whatever class you cast `img` to. You've changed how it's perceived, not how it's implemented.
&gt; You've changed how it's perceived, not how it's implemented. You are right. In OP's example, it's very likely that `img.asInstanceOf[Image]` is simplified away by the compiler (it certainly is once processed by the JVM) as `&lt;value of type A&gt;.asInstanceOf[B]` where `A` is a subtype of `B` does not "do" anything **in this case** (in other cases it might affect the static dispatch mechanism aka ad-hoc polymorphism!). 
if you come from C++, in Scala (and its parent, Java), all non-private methods are virtual, that is, they use a table to map the object's real type to which function should be called
Enumeration should have been deprecated a long time ago. In hindsight I regret contributing to its lifesupport by fixing a reflection bug. :) I think people coming to Scala make assumptions about the code quality of the standard library. Enumeration get used in introductions so people assume it's recommended and that the implementation is well tested. There are several problems with its implementation. First is the use of reflections internally to enumerate the values, hence the problems with exhaustive match and erasure mentioned. The second is [the number of bugs reported](https://issues.scala-lang.org/browse/SI-7206?jql=project%20%3D%20SI%20AND%20issuetype%20%3D%20Bug%20AND%20component%20%3D%20Enumeration) for its ~150 lines of actual code. See [enumeration.scala](https://github.com/scala/scala/blob/2.11.x/src/library/scala/Enumeration.scala) for the actual implementation. In closing: Please lobby for the deprecation of Enumeration. Thank you in advance.
Excellent and concise response... that makes total sense. In fact, I'm a *little* embarrassed I couldn't realize that on my own. Thank you sir!
I wouldn't mind making a pull request (just not right now right now) but I think it would be nice to have all the objects extend a common trait, to illustrate, hey, these all have the same contract. Or there might be different contracts. * Generic sort (highest trait) * Un/stable * Binary
It absolutely does have an effect on the dispatch mechanism, of course. This can easily be verified: class Foo1 class Foo2 extends Foo1 def print(f: Foo1) = println("Foo1!") def print(f: Foo2) = println("Foo2!") val f = new Foo2().asInstanceOf[Foo1] print(f) // prints Foo1! This is precisely what you were saying, and casting does have an effect on ad-hoc polymorphism. But it does not have an effect on the instance itself. In my example, `f` does not change in any way (its `getClass` method will not magically start returning `Foo1`, for example). I think the way someone else stated it in the thread is perfect: casting changes a _reference_, not the _instance_ being referenced. And since static dispatch (didn't know that word) works with the type of the reference, not that of the instance, then it follows that casting does have an effect on, for example, ad-hoc polymorphism.
https://gist.github.com/Arneball/0e47ce989aa928afe055 Functional sorting of immutable datastructures. 
I wonder why you chose Scala for this. I do not mean to be unpleasant or to criticise your (interesting) work, but it feels like you've implemented these algorithms in a distinctively imperative fashion, which sort of defeats the purpose of using Scala, doesn't it? Typically, sort algorithms in a functional world are recursive and non-destructive - instead of modifying your original structure, you create a new, sorted one. The following is a demonstration of insertion sort: def insertionSort[A](as: List[A])(implicit ord: Ordering[A]): List[A] = { as.foldLeft(List[A]()) { (as, a) =&gt; val (h, t) = as.span(ord.lt(_, a)) h ::: (a :: t) } } Odds are good this is slower than your imperative implementation, but the stated goal of your repository is to be educational, not to provide blazingly fast performances. Again, I'm sorry if this makes me into kind of a dick - I do not mean to put your work down, just suggest areas in which I feel it can be improved.
Hi, great point! This is one of my first Scala projects from over a year ago when I was a sophomore in college. I just posted the project because I joined Reddit a few days ago. :-) I'd be interested in implementing these in a more functional style, and filed an issue on the project to remind me.
I'm not sure what are the advantages of this project. The OP motivates the use of Apache Camel from the fact that Akka requires a non trivial amount of setup to work on Heroku. However the project depends on SQS (an Amazon service) and the instructions on the readme are for running it on AWS. If you are going to be using AWS anyway, why not just use plain Akka? 
I posted it. It's because I haven't moved onto AWS yet and still using Heroku. I'd say that getting deployment on AWS after having been on Heroku for a while is not trivial... there's a reason why Heroku is so pricey... :) *Edit The awesome thing about camel, is that as soon as we migrate, I can immediately replace the SQS endpoint and my application's architecture remains unchanged.
I'm still fairly new to Scala, and I had the same feeling as you. Thanks for providing a convincing counter point.
Can you explain why do you need SQS in this solution
Now my actors can talk to each other across hosts (distributed ) via SQS while I am still on heroku. Once I move to AWS I can just move back to akka protocol. 
https://news.ycombinator.com/item?id=8311398
https://news.ycombinator.com/item?id=8311398
I am not too familiar with either language but since nobody has responded yet I'll at least comment. In order to broaden the audience it might be a good idea for you to provide an example / a more concrete explanation of what you are looking for. For ... yield is Scala's syntactic sugar for monadic computation / like do notation in Haskell. I only checked the examples on Wikibooks regarding sequence expressions and it looks similar, i.e. a generalization of list comprehension. What you describe however reminds me more of views / streams (Java) / etc. Is there a special syntactic construct in F# that allows these sequence expressions that doesn't seem to exist in Scala?
I know Scala better than F#, but according to [this pdf](http://www.itu.dk/people/nh/FuncProg/2013/fsharp-computationexpr.pdf), sequence expressions are syntactic sugar that gets compiled down to calls to the function `Seq.collect`, which is the same as for for-comprehensions in Scala, which is syntactic sugar that gets compiled down to calls to the methods `map` and `flatMap` (`collect` and `flatMap` are the same in regards to functionality). As you note, sequence expressions in F# are lazily evaluated and avoid intermediate allocations. In regards to collections that are lazily evaluated and avoid intermediate allocations in the standard library in Scala, there are both the [Streams api](http://www.scala-lang.org/api/current/#scala.collection.immutable.Stream) ~~and the `views` part of the library (which you get by invoking `view` on a strict collection)~~, though neither of these solutions have good performance by default compared to the strict collections (optimization options exist, however). EDIT: Views are deprecated as /u/alex_ndc has pointed out.
Check out Functional Programming in Scala. Chapter 5 focuses on building a non-strict Stream class (structurally equivalent to Cons-cell lists).
Would RxScala work? it's a port of reactive extensions on the .Net platform.
&gt; collect and flatMap are the same in regards to functionality That's not true. They've got overlap, but no, flatMap is a much more powerful operator - as in, whatever you can do with collect, you can do with flatMap, but this doesn't work the other way around. &gt; there are both the Streams api and the views part of the library Views are deprecated. Stream is cool, but it does memoization and you may not need or want that, depending on use-case. In case you want lazy operators, use Iterable.
That is true. Currently we crawl mvn central and a couple other repos. Step by step we add more repositories and parsers. Which repository we should add next? 
The sbt plugin looks good. There is a "VersionEye-Maven-Plugin" and a "VersionEye-Gradle-Plugin" as well. Would be cool is somebody writes a VersionEye SBT Plugin against the VersionEye API :-) 
Great course. I'm going through it right now (even though I'm going through the older course, simply because it has all the material already available, not released week while the assignment grader/tester works just fine there) and it's actually pretty hard. It's interesting because it certainly doesn't feel like a book about Scala or anything. I think it focuses on (to me) rather obscure things you can do with the language or you can know about the language but then provides assignments where they are put into use. Overall, I'm having fun with it. I'm only on week 4 and I've already had happened to me that I spend literally hours trying to figure out something that then takes 35 characters worth of single line of code. That never happened to me in other languages.
Just curious: what does it say about tail calls? 
Tail recursion is amongst the first topics covered. (and also one of the "techniques" used throughout the course extensively). It goes relatively in depth about reasons behind reusing stack frames, underlying compiler optimization and appropriate use cases..
I took this last year. Pretty good intro to the topics covered but I wish that the ordering had been a little different. If I was giving it I think I would move the collections stuff closer to the beginning. Anyways I got like a 97% or some since I use scala as my primary language at work. Feel free to pm if anyone has a homework question.
Are they going to have another session of the Reactive Programming class? The only time it was offered was when I was taking 18 credit hours to finish out my degree and it was during final exams. 
They aim to do it again in spring 2015 according to a [recent tweet](https://twitter.com/odersky/status/502075940286246912).
If you do this: var buffer = ListBuffer[String]() Then you can change the contents of the buffer, as in: buffer += "foo" That's likely what you want (seeing as you picked a mutable ListBuffer in the first place). *But* you can also change the *entire buffer reference* itself: buffer = ListBuffer("entirely", "new") which is not usually desirable because this may have big side-effects, depending on if some other bit of code was using the previous buffer instance, etc. Defining it as a val: val buffer = ListBuffer[String]() does not change the fact that a ListBuffer is mutable - you can still update its contents: buffer += "bar" But you can't overwrite the buffer itself: buffer = ListBuffer("compile", "fail") The whole val vs var thing is mainly about self-protection: help the compiler help you to not do things you didn't intend. In general, mutability is something you want to avoid, if you can. And when mutability is necessary, try to keep it tightly scoped and in a class that is (hopefully) going to be as safe as possible to use. In this example, using a var to define buffer adds one more mutable thing, and potentially adds another opportunity for errors. 
Interesting! I've been working on a non-trivial app for awhile and, after doing my research, have been attempting to use immutable data structures as often as possible. It's forced me to think about how to handle state in an entirely new way (which has been awesome) but it's also been a pain in the ass since my app is inherently stateful. Could you give me your opinion on an implementation? (It's relevant to var vs val) Here's a sample DO case class Tournament( game: Game, event: Event, details: TournamentDetails, users: Set[TournamentUser], teams: Set[Team], id: Int = 0) I've been using case classes for all my DOs, they are quite handy. Now for some of my parameters I absolutely want to use immutable data structures -- game, event, and id because these are structures I never want to change unless I'm creating a new Tournament. However users and teams are parameters that are constantly changing -- *but only their contents is changing*, I'm never *conceptually* creating new sets/lists. Right now I have them as immutable sets and I'm using lensing and case class's .copy() to modify them before returning a new Tournament and then replacing the old Tournament in my DB with the returned copy. To me it feels like way more work than I should be needing to do. Would I benefit by changing the sets to Mutable Lists or something similar? Preserve the val status of the parameter so I'm never pointing to different data, but allow the data's contents to be changed?
I wish Iterable was lazy, but while implementing Project Euler solutions I found at that it defaults to creating Lists eagerly for most operations. I also don't like using iterators because they carry mutable state and it is easy to accidentally use an iterator twice and get the wrong results. Honestly, If I were to start coding in Scala for a real project I would write my own simplified version of views that does exactly what C#'s Enumerable class does. Simple, consistent, non-strict evaluation for all methods.
Im doing it!
Meijer is teaching a Haskell class on EdX in October.
really cool. Just be carefull with you pickling because `case class A(a: String)` and `case class B(a: String)` both pickles to `{a: "a string"}`
Does it say anything about the lack of tail calls in the JVM, Scala's inability to do tail call elimination in the general case or provide any workarounds for common functional programming design patterns like continuation passing style? 
I'm not sure on the terminology, sorry. It does explain when can the scala compiler produce "while" bytecode for tail calls, I'm pretty sure I've seen an example of what looked like continuation passing style, but it certainly doesn't ring a bell too much.
Very nice presentation, the slides were pretty straight forward but is their a video of the talk?
Through Linked-in you can find tons of jobs in london for scala programmers. Also absolutely make contact with http://www.functionalworks.co.uk/ and http://www.scalajobs.org/
Functionalworks are definitely worth talking to! They're that rare thing - A recruitment firm who are actually useful and know their stuff. I'd also recommend getting along to the [London Scala User Group](http://www.meetup.com/london-scala/), and signing up for the [london-scala-jobs](https://groups.google.com/forum/#!forum/london-scala-jobs) mailing list.
Twitter and Guardian do Scala
Not much since the absolute number increased from 11117 to 20730.
Those are the numbers for VimL, the numbers for Scala are 3864 to 9846.
It's showing the language position against other languages. The fact scala does't grow as fast as other languages doesn't mean anything about adoption. Codebase is still growing.
They added TeX and CSS which accounts for two places down, only Go and R overtook, and Emacs Lisp dropped below.
Yeah, I had to look at the overall positions of graphs and titles to figure out what belonged where. I think moving the title of the graph down below it such that there is not such a large empty space between a graph and its title when the values are low, or inserting a grid/boxes to separate the different graphs, could make the graphs clearer.
Impressive concern trolling.
Scala IDE is free as is the IntelliJ community edition. Scala also has a built-in REPL (if you just want to take the language for a test drive to get your feet wet).
Eclipse can be used to compile and run Scala programs - first you install [Eclipse](https://www.eclipse.org/downloads/), and then you install the [Scala IDE for Eclipse](http://scala-ide.org/) plugin for Eclipse using the update sites (you can download a pre-configured version of Eclipse on the Scala IDE website, which might be more convenient). If you want a REPL (Read-Eval-Print-Loop - basically an interactive interpreter), you can download the latest distribution of Scala [here](http://www.scala-lang.org/download/), and then after unzipping navigate to the "bin" directory and run "scala" from the command line. You can also get a REPL inside Eclipse: Create/open a Scala project, right-click it in the file tree, and select "Scala -&gt; Create Scala interpreter in [name of project]". [StackOverflow](http://stackoverflow.com/) is also a good place for asking questions.
Both Scala IDE (eclipse) and Intellij IDEA can not only compile Scala projects and access the Scala REPL, but they also have a concept of [Worksheets](https://github.com/scala-ide/scala-worksheet/wiki/Getting-Started), which is like a multiline REPL. Very convenient for prototyping ideas and getting to learn the language.
Its an increase in the maturity of libraries.
I think it's fairly "about Scala". It's just that Every time I use Scala I feel like the language was designed with some serious thought and care, it just feels like it was very smartly designed. That means the course can focus much more on the functional paradigm side of things, while it actually uses some pretty Scala specific stuff. You don't notice that very much though because the language simply doesn't get in your way. You don't need to bend it, learn some "gotchas" and other stuff to make the course material work. 
http://joinit.springer.com/ Please excuse the cheesy recruitment site. Oh and mention that CJ found you, I like recruitment bonuses. 
Assembly is only a semi-readable abstraction of "binary" or machine code. They're the same thing in a symbol-for-symbol translation. Instead of something like MOV AX,'00', it would be something like A1 00 (A1 being the code for "Move to AX" and 00 being the data.) Machine code is different for each architecture (ie- x86, x86_64, PPC, ARM, etc...) so the actual translation is different from architecture to architecture, but the process is the same. The point of that is to say: the JVM translates the bytecode straight to machine code, rather than translating to assembly between. There's no need to make the human-readable step of ASM before going to Machine Code. So the steps are: Source Code --compiler--&gt; Byte Code --JVM--&gt; Machine Code. C, specifically [compiles to object files (.o)](http://www.lurklurk.org/linkers/linkers.html#ccompiler) which contain architecture-specific machine code. So there the process is: Source Code --compiler--&gt; Machine Code That's overly simplistic, the run-time environments vary distinctly, but at the bare-bones, JVM languages like Scala, Groovy and Java compile to an intermediate bytecode that is more portable than writing architecture-specific C code. In theory.
Java and scala only compile halfway: instead of producing a binary specific to the architecture that can be executed, we produce an architecture independent bytecode. With something like c, the binary is only executable on the architecture it was compiled on. With Java, the bytecode is executed by the jvm. Thus, we can run the application on any system that runs a jvm, but it will likely have more overhead, but a jit can probably reduce that.. 
This is JVM dependent. There are JVMs like Aonix that can compile to native code.
This is an implementation issue. The Oracle official JVM and the OpenJDK stop at the bytecode level. Then they make use of three execution modes. Until the threshold cout is not reached (you can control this) the bytecodes are interpreted, then they are JIT compiled with the C1 compiler (aka client JIT), if the code continues to be heavily used, it is compiled once more with the C2 compiler (aka server JIT). Certain factors like loading new classes, make the JIT selectively throw away the native code and start again fresh. Oracle also has other JVMs that have only interpretation (e.g. Java Card) or that compile directly to static binaries (Substrate VM). Other Java vendors JVMs like Aonix and Jamaica, just two possible examples, do have compiled JIT caches and direct compilation to native code as part of their JVM features.
Have you tried to set default jdk for your new projects here : Configure/Project defaults/Project structure ?
Java and Scala compilers emit bytecode. Then the JVM may elect to interpret it or (selectively) compile to native code using a so-called JIT (Just-In-Time) compiler. JavaCard and other small-device JVMs only have interpreters, whereas server-side JVMs: Oracle's HotSpot aka conventonal JRE and [JRockit](http://docs.oracle.com/cd/E13150_01/jrockit_jvm/jrockit/webdocs/index.html), [IBM JDK](http://www.ibm.com/developerworks/java/jdk/), and [Azul Zing](http://www.azulsystems.com/products/zing/whatisit) include quite sophisticated JIT compilers. As a developer, you also have an option to precompile the bytecode into a native binary using the likes of [GCJ](http://gcc.gnu.org/java/), [Excelsior JET](http://www.excelsiorjet.com), or [RoboVM](http://robovm.org). This is called Ahead-Of-Time (AOT) compilation.
In reality, Java bytecode is machine code -- for the the java virtual machine. C compiles to machine code for the native CPU. To bridge the gap, the JVM can be thought of much like any other virtual machine (i.e. vmware, virtualbox), except that it's highly specialized to run a single application at a time. There is a JVM compiled for each of target architecture, which contains all the platform dependent details. Initially all the JVM bytecode is run through an interpreter, and after a given segment of code is called enough times (or gets hot), the JVM will compile it into it's own little native routine (just in time compilation) to make it faster. 
My favorite trick so far is the `??? = Nothing` definition thrown in to the assignments. It lets the assignment include partially implemented code that is still valid Scala. 
http://thread.gmane.org/gmane.comp.lang.scala.announce/881
I dont know what you're saying
&gt; Java and scala only compile halfway: This is a matter of what implementation one is using, it has nothing to do with the programming language.
Oh yes, you are right, I was just talking about the most common implementation. If you don't target the standard jvm then you also loose portability which was one of the reasons for creating Java. 
It is still an implementation issue. You can implement a compiler for Java in whatever form, as long as it can consume .class files as input. The standard doesn't prescribe it MUST be a VM. The proof are the dozen of certified JVMs that use other formats and execution forms that what the Oracle JVM does. Even Oracle has alternative implementations. An example is the OS/400 JVM. Java bytecodes are translated into the bytecodes used by OS/400, TIMI. Then they are compiled to native code via the kernel JIT, which OS/400 uses for all its binaries. All of this at installation time. Yet it is a certified JVM. I can provide dozens of similar examples. 
I didn't realize there was such a big ecosystem for jvm implementations. 
Here is a small list, http://en.wikipedia.org/wiki/List_of_Java_virtual_machines As you can see, there are many JVMs out there in the wild. If you wish I can forward same extra info. Otherwise just follow the wikipedia links.
Scala is growing in industry though.
Almost all the head-hunter requests I get regarding Scala are for positions in London. So it should not be so hard ;-)
his twitter: https://twitter.com/easyangel his github can also be found in the link
Nice!
They also have SVG versions
Hey! we're looking for Scala devs in ATX as well, should we schedule a turf war :P
I hope there are more than two in this town! =)
Incredible work. The syntax seems incredibly close to what one might find in research papers (I really enjoy being able to simply apply an argmin based on a loss function). Hope that this project reaches version 1.0 soon.
Is anyone working on a comprehensive Findbugs ruleset tailored towards Scala?
I'm going with a mouse... seems like a better projectile. hah
What command kills it? activator clean compile?
Create a new project using Activator. See if you get the same error. If you don't, move over everything a bit at a time until you do.
I've tried it through: * activator ui * activator * aviator clean * sbt compile * sbt clean * sbt "reload plugins" clean Fails no matter what. I have been using the Play 2.2.1 Project setup on Activator pretty much through the entire development, because the early 2.3.x was buggy (I can't remember what bugs I ran into). I figured it was time for an upgrade. 
Yeah, that's my next step I think. I've already done this with the build.sbt. 
I had the same problem. It was caused by a .sbt file in the /project directory. There was one for the gen idea plugin and another that I forget the name of. I deleted both files and it immediately began working.
Argh play can be tricky sometimes :/ 
You're awesome. This wasn't it specifically, but this helped me fix it. In activator-sbt-echo-play-shim.sbt it was set to: addSbtPlugin("com.github.mpeltonen" % "sbt-idea" % "0.1.1.3") I changed it to what it was in the 2.3.4 app I created with activator: addSbtPlugin("com.github.mpeltonen" % "sbt-idea" % "1.5") And it compiled, which it automatically changed to: addSbtPlugin("com.github.mpeltonen" % "sbt-idea" % "1.5.2") I also deleted the idea and eclipse .sbts in that folder. Now it looks like I have some anorm issues I need to work out, which hopefully won't be a big deal. I'm going to bed now though. Thank you. ---- Edit: I answered my own question on SO. I offered mininija the chance to answer it and he declined.
You're making several mistakes here. Firstly, when matching against the empty list, you simply want case Nil =&gt; //whatever. Secondly, and more importantly, you want to use higher-order functions, like map. You're using map, but you're using it all wrong. The signature of map is essentially this: def map[A, B](xs: List[A])(f: A =&gt; B): List[B] So, it takes a List of As and a function from A to B and returns a List of Bs. the map function works for any List, including the empty List (or Nil) so you don't need to do any pattern matching to return the empty list if your original List is empty. You're mistake is to try to do low level programming when you already have the map function. You should be able to avoid pattern matching for a LOT of things (I'm not saying pattern matching is bad, but that there are usually higher-order functions that can do what you want). You simply need to supply map with a function which goes from String to a tuple of (String, Int). So all you need is: List("a", "aa", "aaa").map(s =&gt; (s, s.length))
You can use `zipWithIndex`, then look for the first matching case, and grab the index from the `(value,index)` tuple: scala&gt; ((1 to 100).zipWithIndex dropWhile { _._1 &lt; 5 }).headOption map { _._2 } res0: Option[Int] = Some(4) 
Not sure if you're just doing this as a learning exercise, but there's an indexWhere method defined on List in the standard library: scala&gt; List(1,3,5,7,9).indexWhere(_ &gt; 4) res0: Int = 2 Not that this method returns -1 if no matching element is found.
Its for learning and school both :) This solution was really simple and worked. edit: ah crap, my function needs to be recursive, no bueno
 def master(a: Int, xs: List[Int]): Int = { def foo(boo: List[Int], e: Int): Int = boo match { case Nil =&gt; e case head :: tail =&gt; if (head &gt;= a) e else foo(tail, e + 1) } foo(xs, 0) }
It looks like your question has been answered. As for style, I'd personally leave off the `case _ =&gt;` clause. The match operator already throws an exception of none of the cases matched the value. I'd also consider, instead of throwing when checked against an empty list, returning -1 instead... or even better, change the return type to Option[Int] and return None when there was no match. Finally, I also personally try to avoid the return keyword. In Scala, `if` is an expression with a value. So you can say things like: val foo = if (bar) 1 else 2 (In fact, Scala lacks the ternary operator, so this ends up being very important.) So you can turn this: if (a &lt;= y) return ??? else return firstIndexNumGreaterThan(a, xs.tail) into this: return if (a &lt;= y) ??? else firstIndexNumGreaterThan(a, xs.tail) into this: if (a &lt;= y) ??? else firstIndexNumGreaterThan(a, xs.tail) (Also worth noting: ??? is actually a valid value in Scala. In fact, it can be used to stand in for a value of ANY type. So it's an easy way to get your code to compile. But if the value is ever accessed, it will produce an exception... so don't let it into your production code.) For your next step, you might consider generalizing your function from `firstIndexNumGreatherThan` to `firstIndex`. Instead of baking the predicate (element &gt;= some threshold) into the implementation, turn that predicate itself into a parameter (of type Int =&gt; Boolean). After you have that working, then you could try making the `firstIndex` method generic. So instead of working with Lists of Ints, it could work with Lists of arbitrary Ts.
- your `case _` is never reached, because the other two cover all possible cases - your last line is an `if` without `else` clause, its resulting type is `Unit`. What happens if `xs.isEmpty`? In the `aux` you seem to decide that it should throw an exception in that case. Then simply call `aux` without the `if(xs.nonEmpty)` check. - alternatively, you can designate a special `Int` value to indicate "not found", such as `-1` (done by `indexWhere`). Or you could return an `Option[Int]`.
FWIW, the `incBy` example can be made to work with extra parentheses 1 |&gt; (incBy(5, _)) __Edit:__ Also you have that in [ScalaZ](http://eed3si9n.com/learning-scalaz/scalaz-cheatsheet.html): &gt; import scalaz._; import Scalaz._ &gt; 1 + 2 + 3 |&gt; {_ * 6} res1: Int = 36 
No, quite the opposite. I work at a large corporation that is utilizing Scala heavily. Most of our backend services (written in java/c) are being replaced by Scala code. 
Unlike the people over in /r/haskell, we're too busy writing actual software products.
I don't think so. The Reddit activity is approximately the same as a year ago if I'm not mistaken. One could argue that it should grow, but well… in terms of subscribed people we're on par with Clojure and I think the gap is indeed more narrow than a year ago. In terms of [GitHub and Stackoverflow activity](http://langpop.corger.nl/) Scala maintains its position of "leading a second tier group". There is only a hand full of general purpose languages more active with respect to this measure. (__Edit__: Actually, you could say that it closes the first-tier group now; or that it leads the second-tier except for Perl which backdropped from first-tier) I do have the impression, though, that we're more to "business as usual". The growth in user base, especially with industry adoption, seems to come with a more indifferent and less passionate attitude. If you search for Scala, it pops up in many more scenarios and gets mentions in-passing, i.e. my impression is that it is "more normal" now to use Scala, people start taking it for granted. This may be good or bad. Personally, I miss a bit of passionate people that do creative things with Scala other than just talking about Big Data, Cloud, Reactive, and bla-bla. But well… 
The big difference compared to a couple of years ago is that there aren't new big scala features/libraries every few months.
As someone who works for a lot of tech companies in The Bay, this is true. Actually I'd say more tech companies in San Jose and Palo Alto use it than in SF. 
Well, asking such a question on a /r/scala is going to bring you a "No" as people subscribing to this subreddit are actually using scala. People that stopped probably already left as well. So if you want a better answer, look at the progression of scala line codes on github, ans ask on more general boards.
And that's how you start a functional flame war. . .
Oooh, flame war. Can I try? Maybe, if you used a proper language, you would be so productive you wouldn't have to be busy when writing software products?
Hrmm... let's see, there are well known anti-scala advocates on some weird crusade against the language who post under various aliases, and you have no post history... 
Activity in this subreddit seems much higher than it was a year or two ago, or at least that's my experience.
We see Java code largely as legacy with Scala for new systems.
harsh
What's wrong with Jekyll? What does it matter what language it's in if it's just a static site generator
I just found it quite impenetrable once you need to do something non-trivial. The whole ruby gem stuff I dislike. I would prefer to use a build system that I know how to handle, and a language that I know very well. I'm giving Octopress a shot now, people say it does away with the difficulties of Jekyll. __Edit:__ This kind of shit from minute one: /var/lib/gems/2.1.0/gems/execjs-2.2.1/lib/execjs/runtimes.rb:51:in `autodetect': Could not find a JavaScript runtime. See https://github.com/sstephenson/execjs for a list of available runtimes. (ExecJS::RuntimeUnavailable) That's why I want a sane build system, and a sane statically typed language.
Functional flame war... Functional flame war never changes... ... because it uses pure functions and immutable data
Jekyll is not a build system. It's not supposed to do dependency management. That's a job of the package manager. It doesn't require root for anything- you've done something horribly wrong.
gem is the build system. And running any `gem install` doesn't work without `sudo`. To fix the error above, I had to run `apt-get install nodejs`. You must admit that is really silly.
Until recently `gem install` didn't even bother to mention how to install things locally. Must be because their Macbook is the only device these Starbucks-Hipsters are allowed to administrate anyway.
Oh for sure I think it is way better than ruby or Node.. but ugly parts? * SBT is way too complicated but it is the only way to get incremental compilation * The collection frameworks are a cluttered mess * Type inference falls down seemingly at random and requires explicit typing * Eraser * Parallel collections mess * XML as a first level language feature mess * Stack traces can get insane and be hard to debug * IDE support is better but still not 100% * Compile times are horrible (see SBT) Many of these are on the roadmap to get fixed.. but some can't be fixed due to Java limitations (like eraser)
I don't agree on pretty much all of this.
Soapbox works great for me! (Author :-) It is just like using Jekyll with the added requirement that you have to understand sbt. Good for the soul. 
Same deal with IRC, #haskell is triple the size of #scala. I suspect that once teams get grounded in Scala they just get on with it, which is to say there are far fewer questions to ask, the tools are in place, projects are worked on, completed; rinse, repeat. Kind of sad to say, but the excitement is gone ;-( If you look at the typical SO Scala post it's some user with low rep has yet to get their feet wet in X Typesafe framework (usually Play or Slick). Haskell is different, there is no end to the learning curve when libraries like Lens exist ;-)
and in [psp-std](https://github.com/paulp/psp-std/blob/567db06f230b4f924a87674f4774eee1a2d63f92/std/src/main/scala/Extensions.scala#L140)
While some of what you say is true, I think you're trotting out a few strawmen here. For example, how are you affected by, "The collection frameworks are a cluttered mess"? Provide examples where you, in your daily code, are vexed by Scala collections. The only valid criticism I've seen of Scala collections is with `contains` and Any; that bites everyone sooner or later, and badly. Otherwise, for *general use* Scala collections mask their complexity, which is to say, consumers can just take advantage of map/flatMap/reduce,etc.,etc. functionality that users of most other languages can only dream of ;-) "Type inference falls down seemingly at random and requires explicit typing", so what? Hover your mouse over the inferred type in your IDE; if you see something like `YourType with Product with Serializable`, specify the explicit type and move on (your compile times will improve with explicit types anyway, so better to get in the habit of at least annotating return type of public methods). "Eraser", you mean Erasure. That has nothing to do with Scala and everything to do with the JVM on which Scala runs. "Parallel collections mess" see above. "XML as a first level language feature mess", as one of the rare users of Scala XML it is indeed truly a labyrinthian mess, one that I happen to love for generating XHTML markup. It's going away (sadly) to be replaced by a string interpolated version, looks like in Scala 2.13 if not sooner. "Stack traces can get insane and be hard to debug", you probably are new to the JVM, it gets easier, you can filter out the noise and find the real problem fairly quickly. Also, try Haskell, those guys don't even have line numbered stack traces! "IDE support is better but still not 100%" coming from the stone ages (4 years ago) IDE support is flipping awesome right now. Most new users have automatic builds turned on in their IDE while `sbt&gt; compile/test/run`ing in a separate terminal. Let SBT be boss and turn off automatic build in the IDE. Performance will improve (i.e. no blocked UI nonsense) and errors will be accurate since SBT is running the show. "Compile times are horrible (see SBT)", false, incremental builds are snappy, generally in the order of sub second save-compile cycle where the dependency graph is limited. Where Scala compilations are and will be slow for the forseeable future is with `sbt&gt; ;clean;compile`. For local dev you shouldn't need to be doing that too often, however. Despite Scala's warts there is no language more powerful, with the exception of perhaps Haskell. With the recent forks of the Scala compiler (if Policy gains traction we may see a seriously less warty Scala sooner rather than later) and Dotty down the road, Scala as we now know it will change for the better, guaranteed. For the time being though Scala is a great general purpose language that is seriously under appreciated.
Thanks, I'll give it a shot!
Yes, but I think it has always been that way. Some communities resonate better with a specific platform. I just don't see how that indicates that interest in Scala is waning. It's not like /r/scala has _ever_ been as large as /r/haskell.
BTW in my perception, SO quality has also declined, which would be another indicator that the audience is widening to more "regular guys" from Java etc. Luckily, it's not yet as bad as Java-SO.
&gt; And no, that is not silly. You didn't have a JS runtime installed. It is not the place of a ruby package manager to install non-ruby programs. This is also the same for Scala- sbt will not install node for you. I think we can stop arguing here. The question was anyway _not about_ Jekyll. Let me just finish with saying that you get Jekyll _runtime_ errors when specific _Ruby_ packages were not installed (some header files). Clearly the dependency management either is broken or sucks by their definition. This would not happen with a compiled language and a proper build system.
This may be of your interest: https://github.com/planet42/Laika
True, Haskell is immune to the SO quality plunge since everyone goes to /r/haskell or #haskell. \#scala is pretty much the only forum where one can get into the nitty gritty of a problem (not to disparage your excellent posts here on /r/scala) and potentially get feedback from seasoned Scala developers. Google groups are a poor format, IMO, so much noise without any real sense of order (see play-framework on google groups, just a sea of posts rarely responded to, if even read, by Play core devs). The general take away is that teams break out on their own once a certain knowledge threshold has been met.
How earth did you install Jekyll without the dependencies? Ruby has several very robust dependency management systems, this is clearly a user error.
You need to set up a ruby dev environment first. Try rvm, it's very powerful.
**TL; DR**: Scala developers need to stop unprofessional idiots at oracle who don't know shit (and get paid to come up with the crappiest possible solution for anything) from fucking the JVM up so much that it affects Scala's ability to grow up properly (which it already does in so many ways).
I've shipped more Haskell than Java, Scala or Clojure personally, so I can not agree.
 gem install jekyll jekyll --version // -&gt; runtime error 
The only evidence presented that supports the proposition that Scala is dying is also anecdotal, is it not? If I can provide my anecdote, my company doesn't use Scala and I don't live in the Bay Area, but I have noticed companies that are switching to Scala in the last several months.
Read the stack trace.
Did you set up a ruby dev environment this time? What does the stack trace say?
Yes I managed to get everything going eventually.
Slightly off-topic, but my strong preference is for: var good = ImmutableCollection() good += foo // sugar for good = good + foo over: val bad = MutableCollection() bad += quux // calls a method named "+=" on bad ...because references to `good` can always be published safely without copying; whereas you need to be very careful not to let direct references to `bad` escape to another thread, since the vast majority of mutable collections are not thread-safe.
Who needs documentation when you can just read the type signatures! /s
Right, it was a joke. :-) But types do answer/forestall a great many questions that would be left to documentation in less-robustly-typed languages. "Can this return null? Just see whether its return type is Option." "Is managerId a string or an int? It's a PersonId, and PersonId's constructor takes an Int." "How do these functions and data types fit together? Just look at the functions's type signatures." "What side-effects does this have? Just look for monads in the type signatures."
Just yesterday I published a blog post regarding 2.2 -&gt; 2.3 migration http://lauris.github.io/scala/migrate-play-framework-2.2-to-2.3/
Haskell certainly has the edge over Scala in the "just follow the types" department (less type sig noise), but any type system worth its salt will give the developer clues at to what the intent of the code is. Where Haskell stands out is in what the type system prevents you from doing. Perhaps if Oracle evolves the JVM, and Scala irons out the, errrm, wrinkles, we'll be seeing a new entry in the mainstream languages department within 5 years. Haskell is a bit too foreign for mainstream use I suspect. For the next generation I could see a pure FP language gaining widespread adoption, but would be shocked if all of sudden legions of developers saw the light and flocked to Haskell.
Play is so cool when it works and so not cool when it doesn't. So far I keep sticking my foot in the fire. I hope one day I figure out how to not get burned ;) This is kind of why I migrated from slick back to anorm. Slick is "better" but too hard to fix when it breaks, anorm is simple and generally just works. Only got so much time in my day to fight a framework, now I can focus it on Play fighting ;)
&gt;Play is so cool when it works and so not cool when it doesn't. This sums up how I feel. I mean I love it, but when it breaks... man does it break. And every solution you find is different and none work for your situation. I've only been using it for personal projects, so no real stress. But stuff like this is why I don't think I'm going to suggest it for actual production code at work. It has a lot of maturing to do.
I was able to follow along for some of it but then it just turned into a giant mess. 
The thing is, play 2.3 is 100x more mature then play 1.0. I kind of am accepting it is not going to get any easier down the road... But I like scala and I like the idea of play.. so guess I gotta stick to it ;)
&gt; The only valid criticism I've seen of Scala collections is with contains and Any; that bites everyone sooner or later, and badly. As I'm tinkering around collections quite heavily now, can you say about what bites? 
That's why I have stuck with it. Headaches aside, Scala is awesome and as someone who came to the Java world from the C# world... Play is amazing and twirl is even more amazing. Nothing really compares.
It is somewhat ironic that this post on the [lack of documentation] (http://www.reddit.com/r/haskell/comments/2i1z9u/improving_haskellrelated_documentation/) issue just showed up on /r/haskell ;-)
That is why i love Scala, its so cool.
I haven't jumped into 2.3 yet, but I HAVE been running production apps on it with 2.2, both anorm and slick. We even throw in a little Akka to make it more challenging. I gotta say the migration from minor revs sucks. 2.0 to 2.2 sucked also. But between good functional scala and actor systems, damned if we don't write major functionality quickly with far fewer bugs with 4 guys than the python team and their 10 guys.
So better to List(1,2,3).exists(_== "hello") (which will raise a warning) ? 
 this orElse that http://www.scala-lang.org/api/current/scala/Option.html You may also want to look at http://blog.originate.com/blog/2014/06/15/idiomatic-scala-your-options-do-not-match/
The idiomatic way would be to use an [Either](http://www.scala-lang.org/api/current/#scala.util.Either) type.
As you've noticed I've edited a bit to try and clarify my intent (hence the `this`/`that`). The fields are different types and there's some distinct processing applied to each, though in both instances I end up with a string. So either I have `object.field1` and so I end up with my string being `f(object.field1)` or I have `object.field2` and my string should be `g(object.field2)`. Currently I've written it as `map { f }` and `map { g }` and then the `getOrElse` in my original post.
I do believe you want to aggregate `field1` and `field2` as a single `Either` field. I've not used `Either` in a while, so anybody with more up-to-date knowledge of it please correct me if / where I'm wrong. Let's assume that `field1` is of type `Int` and `field2` of type `String`. Let's further assume that, for some odd reason known only to yourself, your process needs to: * return the string representation of `field1 * 2` if `field1` is set * return the reverse of `field2` if it is set This is your process function: def process(field: Either[Int, String]): String = field.fold(i =&gt; (i * 2).toString, s =&gt; s.reverse) // "field1" println(process(Left(10))) // "field2" println(process(Right("test"))) 
`Either` is not the best choice for this since it's traditionally used to represent either a success or a failure. Based on OP's question, none of these two fields represents a failure. 
Thanks. I think that does sound like what I'm after.
That blog post was informative! I'm curious about using infix notation with fold and I can't seem to find a clear answer.. When using arrity-0 or arrity-1 using [infix notation is easy](http://docs.scala-lang.org/style/method-invocation.html#arity-0), but how would you approach it with the fold method used in the blog? The blog's approach for fold: val c = opt.fold("a")(_ + 1) I want to do something like: val c = opt fold(my default)(f _) map (mostly because I like infix notation)
Either is a disjoint union -- it's not required to be a success or failure.
Sure, at least you get a warning there. I've gotten in the habit of just never using contains on String values.
It's not required but it's a convention, one that's even [specified in the ScalaDoc](http://www.scala-lang.org/api/2.9.3/scala/Either.html): &gt; Convention dictates that Left is used for failure and Right is used for success. 
If you already have functions `f` and `g`: def f(i: Int) = (i * 2).toString def g(s: String) = s.reverse def p(e: Either[Int, String]) = e.fold(f, g) scala&gt; p(Right("abc")) res1: String = cba scala&gt; p(Left(3)) res2: String = 6
You can take the course with a Certificate of Achievement (50USD min) or free
If you don't want to use `Either`, I'd propose a slightly more symmetric version of what you have: field1.orElse(field2).get Or, using infix notation (field1 orElse field2).get Aside: Infix notation looks slightly nicer here, but lately I have come back to almost always writing the "." because I don't want to constantly have to choose and micro-optimize. 
You could make a case class that contains either field1 or field2 and then have that case class be a member of obj's type. I can't do scala off the top of my head so here's Haskell that does the same thing. -- field1 is of type TypeOne, field2 is of type TypeTwo, obj is of type MyObj data Field = One TypeOne | Two TypeTwo data MyObj = MyObj Field OtherType AnotherType Then you can pattern match on Field to get it out case obj of (MyObj (One x) _ _) -&gt; doStuff(x) (MyObj (Two y) _ _) -&gt; doDifferentStuff(y) If you can't get the gist of the Haskell, lemme know and I can translate it to Scala.
&gt; SBT is way too complicated but it is the only way to get incremental compilation I can't stand SBT either. My org has a pretty large Scala project that we build with Maven, using a Zinc server if one is available. The new Maven plugin does incremental compilation just fine. Using a Zinc server reduced our build times by 60-70%. That's still slower than Java, but fast enough that no one complains anymore. &gt; The collection frameworks are a cluttered mess Maybe, maybe not, this is subjective. From a user's perspective, the collections are great; what complexity there is is largely hidden, and using other collection libs feels impoverished by comparison. &gt; Type inference falls down seemingly at random and requires explicit typing This happens, but very rarely in my ~3 years of full-time Scala work. When it happens, I just add an explicit type and move on. From what I understand, to get better inference, we'd have to give up subtyping, so I'm ok with the current tradeoffs. &gt; Eraser I presume you mean erasure, and yeah, it's lame. I'd love to hear alternatives to the status quo, because all the ones I've heard to date have meant dropping the JVM, good Java interop, or both. &gt; XML as a first level language feature mess I'm one of the few people that really likes this. The lib is complex and weird, but it makes dealing with legacy services that speak XML much less painful. Incidentally, first-class XML support will go away in a future Scala version. That will make me sad, but you and others happy. &gt; Stack traces can get insane and be hard to debug I've been using the JVM as a platform for 10+ years, and stack traces from Scala code aren't much better or worse than any others. &gt; Compile times are horrible (see SBT) I wouldn't say this is *fixed*, but it's better enough that it's no longer a problem for us. Our 30kloc app, with ~40 maven modules and ~900 sometimes-very-involved tests builds in 2 minutes, largely thanks to Zinc.
Have u checked out this? http://twitter.github.io/effectivescala/
Scala for the Impatient
The book Effective Java? [Scala Books](http://www.scala-lang.org/documentation/books.html) I can't recommend the first two enough. Martin Odersky designed the language, so his book is a must. And Scala for the impatient walks you through use cases and covers most of what you can do with the language relatively concisely. &amp;nbsp; Edit: If you're trying to learn Scala, I recommend learning it by learning functional programming. [There's a great Coursera course by Martin Odersky](https://www.coursera.org/course/progfun)
Thanks I will definitely take a look at these two.
I highly recommend ["Scala for the impatient"](http://www.horstmann.com/scala/index.html) If you're coming from C++/Java, this will make sense to you
This seems to be a winner :)
&gt; For example, that when a `Vector[Int]` is added to a `Vector[Double]`, I should get a `Vector[Double]` If that's a statically guaranteed type, all you need to do to "test" that is write val res: Vector[Double] = intVector + doubleVector The compiler will not compile this if the result type is not as you proclaim. Otherwise property based testing might be useful: - http://www.scalatest.org/user_guide/property_based_testing - http://www.scalacheck.org/ Here is another useful question on Stackoverflow: - [Testing an assertion that something must not compile](https://stackoverflow.com/questions/15125457/testing-an-assertion-that-something-must-not-compile)
Ah, but it's not paranoia is it. Cedric Beust has been caught using sock puppets to troll Scala forums, on reddit and elsewhere: http://www.reddit.com/r/scala/comments/25kwb1/cedric_beust_continues_to_troll_rscala_and_hacker/ 
Twitter has some good docs intended for experienced java devs. A lot of it is mostly aimed at twitter's projects (ie finagle), but overall it's a pretty good intro. https://twitter.github.io/scala_school/
This is a problem specifically with the Scala IDE I've had. I'm not sure I know what causes this, but themese don't really work for scala ide (as you've tried, it colors some things, usually everything is completely off). This can be adjusted a little bit by tinkering with the colors for different type of variables in options, but it is still pretty bad. Again, no idea why. These themes work flawlessly with regular Eclipse / java.
@MadFrand – can you point me to the Github issue you raised? I'll take a look.
Well, back to Intellij. Worked out 3 odd bugs so far. Wonder how many more I'll find.
I mean, intellij is most likely the better ide, unless you're really used to eclipse (I am still more comfortable with it).. Maybe if I run into more issues, I don't mind the themes too mcuh. 
If you're on Linux no need for a color theme, just install the `xcalib` (a screen inversion application) package and bind desired hot key(s) to target monitor. That way you can invert the *entire* Eclipse screen and instantly go from blinding white background on black text, to wondrous black on white across the whole interface ;-) Windows has a similar application, can't remember the name offhand, search for something like, "Windows screen inversion program". Otherwise, without the screen inversion route you'll need to setup a custom Eclipse using the built-in CSS editing functionality (and maybe create your own plugin if you want to do things like hide gutters, scrollbars, panels, etc.). Screen inversion is far and away the easiest approach, IMO...
https://github.com/playframework/playframework/issues/3045 https://github.com/sbt/sbt-native-packager/issues/362 https://github.com/playframework/playframework/issues/3234 (the new project wasn't working for me either) Then there was another one that was merged with several others that I can't find again. 
OK thanks. The first two tickets look like the same problem, caused by adding packageArchetype.java_server to the configuration, which overrides the way Play packages up its static assets. The fix is to remove the setting. It sounds like that fix didn't work for you, right? The third ticket looks like an interaction with IDEA. That issue is still open, waiting on a [fix in the sbt-idea plugin](https://github.com/mpeltonen/sbt-idea/issues/293). Are you using IDEA? Did you comment on any of those tickets? The comments are from lots of different users so I couldn't tell. If you want help with your issue it would be great if you could raise an issue or comment on an issue so we can help track down what's happening for you. As usual, the more info you can put into the ticket the better, *especially* minimal projects to demonstrate the problem are really helpful. :)
If you do add an issue or a comment, cc [@richdougherty](https://github.com/richdougherty/) in the comment text so I can take a look.
Thanks, I missed this one. Yes I use IntelliJ with the Scala/Play plugins, but only as an IDE. I don't have my project integrated with it. I also don't think I ever even opened the new Play project I created through Activator in IntelliJ. The problem I have with raising a ticket is I'm still very much learning Scala and Play, so it's hard to tell when it's a PEBCAK Error. :) I'll branch my project later this week and see if I can recreate the issue and raise a ticket. 
No worries. Don't worry we don't mind if people report issues that don't turn out to be Play bugs. Sometimes, the "fix" turns out to be writing some better docs. :) If you do have the time to recreate the issue, that would be great. One of the things I like about writing up a really detailed bug report is that about half the time it helps me to find a solution myself.
A handful of type errors in that otherwise nice looking blog post.
Wow, this is the kind of role I am looking for and have a hard time finding it here in Berlin. You mentioned that you prefer locals, but do you consider H1B + relocation if the background fits very nicely?
Obviously our preference is local, but for the right background we would consider it.
Screencast and other 'getting started' resources here: http://scala-ide.org/docs/current-user-doc/gettingstarted/index.html
Is there any particular reason you're using Eclipse over IDEA ?
If you're not invested in Eclipse go for IDEA. It's a much more pleasurable experience regardless of the language used.
 This sounds very interesting. At which version will scala achieve this?
The only meetup I know of locally is: http://www.meetup.com/OC-Scala/ We just found it recently and were very bummed to miss the last meeting. Other than that we have travelled to Santa Monica for the LA Spark User Group: http://www.meetup.com/Los-Angeles-Apache-Spark-Users-Group/ Admittedly the travel to Santa Monica makes it pretty painful. In general we have not found a strong scala community outside of the Bay Area. 
This is honestly more truth than parody.
I didn't realize that! Although by changing a few characters, they could be Scala examples. (That's what I thought they were supposed to be.)
Last year's appear to be online, so I'm guessing this year's will be too. 
Come to the OC Scala meetup! It has a decent turn out and seems to be growing. 
Just looking at the release date is the wrong mindset IMO. These are far-reaching changes. The time to start working on them is now, and surely there will be developer releases/previews long before the eventual release. In fact there will probably be developer releases soon after people start working on it in earnest. So the critical part is to decide that that's what we want to do and to get enough qualified contributors. The rest will follow.
It doesn't add an overhead, because if you look at how `ListMap` is implemented, then `get` and `apply` simply iterate over the linked list. So it seems that `ListMap` is just a `List` with a bit of a map interface. Every addition or update means the new key is at the `head` of the backing list. Moreover, the `iterator` implementation is crap, it creates a full `List` copy and then a `reverseIterator` on that. How bad can it get? __Edit__ It is only used in two or three places across the Scala code-base. As a backup for `HashMap` when (very rare) a collision occurs. And somewhere inside the compiler for carrying some annotations or symbols. Probably it has some benefit there such as preserving insertion order. I don't think it's a go-to data structure.
Sure, but then again it's only natural to want later now ;-) Typelevel and Policy forks are at least in part motivated by a desire to speed up the Scala evolution process. Meanwhile newer languages like Ceylon (who just had their 1.1, btw) and Kotlin benefit from Scala having blazed the innovation trail, while avoiding the weight that Scala currently carries. Hopefully Oracle will continue bringing Java into the modern world; the corresponding JVM improvements will surely help Dotty based Scala deliver on the promises of faster compilation and better performance. Really looking forward to seeing how the JVM landscape evolves over the next 3-5 years, and of course, thanks for creating Scala! 
There's no time schedule listed. Does anyone know what time it ends the second day? Trying to decide if I need to have a hotel room for one night or two.
Scala tends to be more readable, faster to write and easier to test when written by experienced programmers. There is less boiler plate code than in Java, collections are more straightforward... Functional programming helps a lot. Scala is Java on steroids. Java 8 introduced concepts that exist in Scala for a long time. Lambdas and streaming are badly implemented features that Scala handles much better.
In comparison to Java: &gt;reliability Depending on what exactly you do, it's on Java's level or much higher. Less reliance on dynamic bytecode generation frameworks and sacred unenforceable rules, more reliance on the type system and immutability. &gt;readability &amp; writability Very writable. The code is concise, usually follows the flow of thought, autocomplete works okay. It's easy to write both clean, readable code, or an ASCII soup. Code reviews recommended in the initial phase (if you code only by yourself, review your old code too, it does miracles). &gt;cost Not sure about what you mean here. If you mean hardware cost, without doing any special optimisations, CPU usage is negligibly higher than in Java, memory usage is noticeably higher, GC is stressed a bit more. Generally, it's not an issue for most tasks. 
&gt; Lambdas are badly implemented Source?
i can affirm that the course is great, i'm completing it right now, Scala is quite intriguing, I like the functional mindset, although it can be pretty hard to get it right after imperative programming.
 @tailrec def firstIndexNumGreaterThan[T : Ordering](a: T, xs: List[T]): T = xs match { case x::_ if x &gt; a =&gt; x case _::xs =&gt; firstIndexNumGreaterThan(a, xs) } 
I feel like slick is just another ORM and kind of ugly
This game is amazing, i wanna play it now!
Please join, a match is ongoing!
My experience with it (and every other ORM) has been like to trying to speak an unfamiliar language through Google Translate, rather than just learning the language.
That's a low blow @lukaseder, everyone knows you're the author of JOOQ ;-) Slick will iron out the performance issues sooner rather than later (as Zeiger points out in his reply). The DSL itself could be a bit more pleasant, however. A cross between Squeryl's syntax and Slick's functionality would be an interesting hybrid, IMO.
Won't argue with ugly but Slick is not an ORM.
Right, and just `select * from foo whre id = ...`, I mean what could go wrong? How about understand sql AND eradicate typos at the same time? How about never wasting time writing `insert into foo (a,b,c,d,...,z) values (...)` boilerplate again? I have pretty much zero interest in non-composable string based sql, the future is type safe across the board. 2cents
interesting, by why /r/scala ?
I totally get the allure of an ORM. I want typesafe. I don't want to write silly updates in String. I try over and over again, but always end up sad in the end. I think anorm is a little closer to the raw SQL while still doing SOME of the boring stuff for you, so I think it is more my cup of tea right now. I know how to write fast SQL. I know how to write fast code. I don't always know how to speak a specific ORM, nor do I want to have to go down these crazy paths to make the generated code good. Maybe if I forced myself to use something like slick for 2 years and learned all the quirks, it would be fine...
[sqlTyped](https://github.com/jonifreeman/sqltyped) may be of interest if you don't want to go down learn-another-dsl road. It's string sql but typed (via macros).
That's not to say that nothing can go wrong, but rather that I find it significantly more cumbersome to use an ORM than to use SQL directly. This is especially the case when done in a composable, monadic style.
I've heard from the organizers that it should be done by 6:30 pm Saturday.
i will need some time to understand the Nomyx lang, as i've never developed in Haskell. For now, i will just watch some games.
&gt; That's a low blow @lukaseder, everyone knows you're the author of JOOQ ;-) ... which makes the topic even more interesting, no?
Depends on what you mean by interesting ;-) JOOQ seems to be a more or less 1-to-1 translation from Java to SQL, whereas Slick is attempting to abstract away the code-to-sql representation, the end goal presumably being to use the DSL on any type of data store (i.e. not just traditional relational databases). Slick is held back a bit by the Scala language itself (i.e. can't get nice LINQ to SQL/Objects syntax without the late binding machinery M$ built in to C#) which is manifested in loss of table aliases when threading for yield{} through to groupBy, sortBy, etc. Perhaps in future this issue will be resolved, but that likely won't be for quite some time. If the linked performance issue can be solved then it just comes down to whether or not one prefers the syntax.
What I personally find interesting is this "just one simple performance issue" perception that seems to spread across the Slick user base. It's true that these are "edge cases" when your main model of thought is a Scala collections one (or a C# IEnumerable one, if you're using LINQ). In those cases, the occasional "bad SQL" can be accepted. But the OP of the linked thread really wants to write SQL, as it seems, but then why doesn't he? He'll be disappointed time and again, as he wants this or that SQL feature that can simply not be expressed in Slick / LINQ etc... Few of those frameworks / alternative query languages really take all the richness of SQL:2011 into account, and they'll always lag behind. But long story short, it then really seems to depend on whether one perfers one or the other syntax (with all implications)
I would assume they are running Spark on top of HDFS (part of Hadoop), so I'm not sure the reporting in this article is wholly accurate. It's really more of a comparison between Map/Reduce and Spark, if that's the case.
More details in the original source: http://databricks.com/blog/2014/10/10/spark-breaks-previous-large-scale-sort-record.html
So it was on top of HDFS, but 3x faster on 10x fewer machines... wow.
Good points. "just one simple performance issue", is just that, MySQL face plants when presented with extraneous sub selects; other databases have superior query optimizers which eliminate the performance hit. Also, the sub selects occur only when performing explicits joins, something that you can do away with via implicit inner joins in Slick, leaving outer joins + MySQL as the sole down-the-tubes performance hit. It's a big deal of course, I wouldn't touch Slick at this point if MySQL were the production database. As for being able to fully replicate the sql standard in a dsl that attempts to abstract code away from sql syntax, not an easy task (if even possible). More likely the goal is to get 90% of the functionality without killing performance in the process.
A.scala: import java.util.function.{ Predicate =&gt; P, Function =&gt; F, BinaryOperator =&gt; BinOp } import java.util.Arrays._ import java.util.stream.Collectors object Test { def test(f: F[Int, Int]) = f.apply(1) def cond(p: P[Int]) = p.test(1) test(x =&gt; 2 * x) cond(_ % 2 == 0) asList(1, 2, 3).stream.filter{ i: Int =&gt; i % 2 == 0 }.collect(Collectors.toList[Int]) val binop: BinOp[Int] = _ + _ val i: Int = asList(1, 2, 3).stream.reduce(0, binop) } $ scalac -Xexperimental A.scala profit
and it was written in...Scala ;-) Spark is a much needed shot in the arm for the language, brings more enterprise strength into the picture while further widening the ecosystem gap between the JVM up and comers (read: Ceylon and Kotlin) that would (dare!) attempt to usurp Scala as the possible successor to Java.
Yes, I'm well aware of MySQL's limitations, although Oracle is really investing a lot of effort in that area, doubling man-power and tackling all the important stuff that they have inherited from all this legacy. I've recently met Morgan Tocker, Oracle's MySQL community manager to learn about where MySQL will go. The future is bright :-) My personal prediction for Slick is that these kinds of caveats will happen time and again, and I'm personally calling it the functional-relational impedance mismatch (where, by relational, I mean SQL). Even when you're using Oracle, the database with probably the most sophisticated optimiser out there, it's always better to be in control of the actual SQL once you have a bit more than your odd cat / pet, author / book database. Something that people often only realise when they go to production... Not that the average Java/Scala developer would care, though ;-) &gt; More likely the goal is to get 90% of the functionality I really insist that few APIs out there do reach that 90%. Ask any of those vendors if they know about analytic functions, ordered aggregate functions, grouping sets, the MERGE statement, time periods, or even common table expressions. I'm going to trade your 90% against roughly 20-30%.
Ceylon and Kotlin are interesting in their own ways, but I don't know of a single project using them that would serve as a flagship POC for them. With Scala though, we have Play, Akka, Spark, and probably some others I've never heard of; not to mention the exposure it's received by being used at Twitter and being taught by Odersky himself at Coursera. It's doesn't get any more real than that.
&gt; Yes, I'm well aware of MySQL's limitations, although Oracle is really investing a lot of effort in that area, doubling man-power and tackling all the important stuff that they have inherited from all this legacy. I've recently met Morgan Tocker, Oracle's MySQL community manager to learn about where MySQL will go. The future is bright :-) MySQL 5.6 has been a breath of fresh air, Oracle is clearly not letting it gather dust as they did with Java until they *finally* did something with Java 8. "functional-relational impedance mismatch", awesome ;-) you may have a point there, although the jury is still out, IMO. F#, Haskell, and Scala communities have been addressing the problem, let's see where things stand in 3-5 years. "it's always better to be in control of the actual SQL", totally agree, it's why I'm not using Slick. If a dsl doesn't replicate what I would have written by hand, it's a no go. As for expressing the more advanced/powerful features of the underlying database, unlikely that's going to happen anytime soon with the LINQ-like approach. For Slick the suggestion is to dropdown to raw sql, which does come in handy for the edge case scenarios. 
&gt; let's see where things stand in 3-5 years. Precisely. Most of these things can only be really agreed upon in hindsight. Such as "composition over inheritance". &gt; If a dsl doesn't replicate what I would have written by hand, it's a no go. So, what's your take on [jOOQ](http://www.jooq.org), then?
&gt; So, what's your take on jOOQ, then? The same as before, where's SOOQ? ;-) I'd love to see a Scala equivalent of JOOQ beyond omitting the parens and semi-colons.
Agreed, although Kotlin has JetBrains and Ceylon has RedHat, so both will be kept afloat even if they gain little traction in their early days. Ceylon is a really well designed language, falls short of Scala on the functionality front but has a solid foundation on which to build (whereas Scala is going in the other direction, an overhaul). Next 3-5 years on the JVM are going to be quite awesome ;-)
The runners-up to traction on the JVM will not be Ceylon or Kotlins, these two languages IMO are dead born, they contain nothing significant enough to make them interesting compared to a battle tested and mature environment such as Scala's. Simply removing functionality (and then sneaking it in and tacking it on again in dot releases!) isn't going to work. Don't be fooled by corporate backing such as RedHat or JetBrains. The interesting developments to watch are Clojure, which despite being a dynamically typed Lisp revision seems to gather a solid fan base, and Frege that still has to show what it wants to be other than a Haskell-clone on the JVM. In terms of Spark and number crunching, my guess is we will see competition from the strong contenders of lower level languages, e.g. Rust, Go, etc.
Both languages have been around not just for a month, but for years now, even if in alpha, beta stage. Both were born in 2011, that's already three years ago. They were either admittedly or not designed as simplified versions of Scala or better versions of Java. In the three years that have passed, the landscape has massively progressed, with Scala having gone from 2.9 to 2.11, and Java 8 having been introduced which raises the threshold to take the risk in those two languages without any major benefit. The only benefit I can see right now is that both have JS back-ends, I don't know how they compare to Scala.js. And there are many more options if you target JS, from Elm to Dart. The comparison with C++ and Java is, frankly, stupid. Java was much more than removing functionality from C++. It revolutionized the PL landscape with its virtual machine, write-one-run-everywhere etc. I'm not saying that marketing and other factors do not play a role compared to technological benefits, but given the competition, I think you better have a strong technological argumentation as well. The innovation potential of Clojure and Frege is magnitudes higher than Ceylon/Kotlin.
v1.0 is irrelevant. The languages have been planned from the perspective of 2011. With the human resources of their respective teams and slow or inexisting early adoptions, they will simply not compete with the pace of Scala, Java, Clojure, all of which are very active at the moment and better staffed (I don't know about Clojure, but the community force is quite felt). Now that reality begins to sink in, all the lovely promises diffuse. NPE safety in Kotlin? [Just abandoned](http://blog.jetbrains.com/kotlin/2014/10/making-platform-interop-even-smoother/). Simple type system? [Just abandoned](http://ceylon-lang.org/blog/2014/10/09/ceylon-1/) (two types of variance now). Anyone remember how Kotlin will show the world in terms of reified generics? By the time Ceylon becomes useable, Scala will have overhauled its type system, probably supporting Java 9(?) tuples straight away and having union types. Although I'm a proponent of static typing, I don't see how dynamic typing will go away. Please look at the current popularity statistics, you have JS, Python and Ruby quite on top. Clojure is not a niche language. And it's a _much_ better language than Groovy which is just a syntax-nice scripting facility for Java. You can start to see that people do build larger systems with Clojure.
That's a fair point, but even Scala has a tough road ahead; despite being a proven platform. Java 8 and beyond are going to move the state of the art ahead by so much in the Java community, that competing languages risk being obviated completely. I honestly don't know if any of these options are going to survive for the next 5 years; much less emerge as strong contenders.
Well, Scala did have an [actors library](http://www.scala-lang.org/old/node/242) in the standard library as early as 2007, 4 years after Scalas first release in 2003. Back then, Scala's actors was a major selling point of the language, and it helped popularise the actor model in mainstream programming languages. That said, I think it is always good to have more competition and new approaches in programming languages.
Fair enough :)
Lift Web (same time as actors library) was also an earlier example of buzz around a new web framework.
And I'm in a small shop in Canada... we're also using Scala for our backends and loving it.
If only actors didn't break type safety!
I am just curious, what sort of query/results would you expect to see in a SOOQ? JOOQ without parens and semi-colons is already pretty neat looking to me.
Agreed, jOOQ's syntax with Scala is definitely an improvement. Saying that, given Scala's powerful dsl capabilities, sOOQ could be better. For example, the table aliasing bit in the [scala example](http://www.jooq.org/doc/2.6/manual/getting-started/jooq-and-scala/) is a bit of a hack. One should be able to write the same query with *in-place* aliases just as one would do with string based sql. I know the linked example is contrived, but in a Slick-like dsl the same query looks something like: val q = for{ (b,a) &lt;- Book leftJoin Author on (_.AUTHOR_ID === _.ID) if ( b.ID &lt;&gt; 2 || b.TITLE inSet Set("O Alquimista", "Brida") ) } yield(a,b) q.list.map{(a,b)=&gt; // do something with author/book rows } Basically I think sOOQ could replicate the concision of algebra based DSLs, but without the non-optimally generated sql.
Not very. Just looks like a script. The program is too small and simple for it to have any significant structure beyond the list of instructions it has. Set yourself a larger goal in my opinion; build something that requires some structure and design. 
Thanks. I will put together something bigger. 
In term of style, you can spread a definition or expression over a few lines to help readability. case class DividendRecord( exchange: String, symbol: String, date: String, dividends: Double) dailyPrices .filter(!_.startsWith("exchange")) .map(_.split(",")) .map(parseDailyPrices(_)) edit: `filterNot(_.startsWith("exchange"))` might work too This is read as "filter away any that starts with 'exchange' " and would this compile? `map(parseDailyPrices)`
There is some hope there... http://lampwww.epfl.ch/~hmiller/scala2014/proceedings/p23-he.pdf
Thank you so much. That was the valuable input I was looking for.
Thanks for the warning. I had not tried IntelliJ yet.
The same thing happened with Mavericks. In a day or so someone will post the fix; I believe it's a .plist file that needs changing.
I didn't have this experience. I started IntelliJ and it told me I needed a legacy version of Java. I clicked an ok button and the problem was solved. I'm using the newest version of IntelliJ.
It works fine. Just edit your plist. Took 1 second to fix.
Thanks for the warning. I just bought a Mac Mini today. Hopefully this gets sorted out by next week before it gets here.
Mavericks apparently had similar issues on launch according to my coworkers. While it's not policy, it's been made well known at my current workplace that we shouldn't update to the latest OSX.
Reinstall Apple JDK6: http://support.apple.com/kb/dl1572
Yeah, you need to change the required JVM version from "1.6*" to "1.6+". (And install a JDK, obviously.) Why it's configured to use only JDK 6, I don't know, but it is.
It's configured to use JDK 6 because JDK 6 (the last version built by Apple) provides the best font rendering quality so far. JDK 6 is still available on Yosemite, and all the "manual intervention" required is installing it.
Well, that's odd. Shouldn't the Oracle implementation be delegating to the platform for font rendering?
&gt; Why it's configured to use only JDK 6, I don't know, but it is. I read somewhere IntelliJ was only built to support 1.6. Obviously many people have run it successfully with other JDKs. I wonder what they are waiting for?
http://www.reddit.com/r/scala/comments/2jgqtr/warning_regarding_os_x_yosemite_and_intellij/clbz7dd
It was never a problem.
So, wat do? We can't expect Java software to just run on JDK 6 forever.
This is an easy fix that anyone who needs to use IntelliJ is capable of doing: (**Use the following at your own risk** and I highly recommend you make a copy of info.plist prior to editing it. You can mess it up and the application will fail to start. You've been warned) (This assumes you have Xcode installed) Here are the steps: 1. In finder, goto the Applications folder and right click (or ctrl-click) The IntelliJ Application and select "Show Package Contents" 2. Inside the Contents folder just double click info.plist 3. Expand the dictionary object named "JVMOptions" 4. Change JVMVersion from "1.6*" to "1.8*" 5. Quit Xcode (the changes are autosaved) You should now be able to run IntelliJ If you don't have Xcode installed you can edit info.plist with a text editor and search for JVMOptions and edit the file from this: ... &lt;key&gt;JVMVersion&lt;/key&gt; &lt;string&gt;1.6*&lt;/string&gt; ... to this: ... &lt;key&gt;JVMVersion&lt;/key&gt; &lt;string&gt;1.8*&lt;/string&gt; ... (EDIT: The instructions also assume that you installed JDK8 from Oracle)
It's because Sun/Oracle JDK7 had some nasty font rendering bugs so they continued to use JDK6. JDK8 on Yosemite should be fine.
It's just the IDE that requires JDK6 to run, you can target any Java release with the code you write. So it really shouldn't matter what JDK the IDE uses, as long as it's still available.
You have to **reassign the value of n**.
 var n = 0 def counter = { n += 1; n }
thanks
Is there a video of this talk?
Very close; try this: val counter : () =&gt; Int = { var n = -1 () =&gt; { n += 1 n } } 
Really interested in the platform databricks is building. I want to use Spark but don't have the resources to maintain a cluster full time. Can't wait till it's more widely available or actually get an invite into the beta, filled out the form awhile ago but yet to get any response :-(
Link goes to a 404
good to hear from you again Rob ;) too bad things didnt work out for me at CargoTel in your Perl days. how are things in the raw food world for you?
I had a weird and scary installation experience. It took forever to complete; I was afraid it never would. Almost as if I wanted my battery to finish charging, before calling the installation complete. (??) So don't panic if it takes a long time. Hours. Or maybe charge your battery first. Anyone else have this?
I noticed that too. Apparently they aren't supporting https anymore, try typing in just http://codebrew.io. That works for me
Thanks! The page comes up for me in Chrome now, but doesn't seem to respond. I'll try it in another browser later.
Works fine in firefox. (aside from the fact that I canno't write '&gt;' with my 'altgr+.' anymore which renders it basically useless for me.
As a basic example, let's use a case class and a case object to implement a linked list: sealed trait List[+A] case object Nil extends List[Nothing] case class Cons[A](head: A, tail: List[A]) extends List[A] We represent the empty list as `Nil`, and a non-empty list as an element of type `A` prepended onto another list whose elements are also of type `A`. Now let's use pattern matching (and property extraction) to implement a function that computes the sum of a list of integers: def sum(xs: List[Int]): Int = xs match { case Nil =&gt; 0 case Cons(head, tail) =&gt; head + sum(tail) } Given a list of integers, its sum is zero if it is the empty list, otherwise its sum is the sum of its head and the sum of its tail. The pattern match syntax lets us get our hands on the `head` and `tail` fields so that we can use them in the expression `head + sum(tail)`. We can test this via: val y = sum(Cons(1, Cons(2, Cons(3, Cons(4, Nil))))) // 10 
If you implement an unapply method in the companion object to your class it can be used as an "extractor" which allows you to decompose your object for the purpose of destructuring assignment: scala&gt; :paste // Entering paste mode (ctrl-D to finish) class Junk(val x: Int, val y: Int) { // ... } object Junk { def unapply(instance: Junk): Option[(Int, Int)] = { Some((instance.x, instance.y)) } } val j = new Junk(10,20) val Junk(a,b) = j // Exiting paste mode, now interpreting. defined class Junk defined object Junk j: Junk = Junk@58bf8650 a: Int = 10 b: Int = 20 This destructuring can be used in match expressions as well, which is nice... scala&gt; j match { | case Junk(a,b) =&gt; a + b | } res1: Int = 30 You get this behavior automatically if you create a "case class". So use your imagination. 
This is kinda ugly but: val counter : Int =&gt; () =&gt; Int = { (n:Int) =&gt; { var acc = n () =&gt; { acc += 1 acc } } } Gives you an inner var to hold the incremented value. You might just want to make a tiny class out of it though.
For prototyping I like to pickle my objects, a bit of pain when you want to do complex queries. But for a prototype I don't see why you can't just pickle giant object hierarchy
I need something more advanced.
I like JOOQ a lot for java you can also use it for scala http://www.jooq.org/doc/3.4/manual/getting-started/jooq-and-scala/ You can auto generate DAO objects to handle basic crud. There is also slick which is made to act like a normal scala collection. http://slick.typesafe.com/
This is close, but not totally working. It seems to return 1 more than it should each call. I am not sure that it is returning solely n (without the increment) for initial calls?
Here's my stab at it: def counter(n:Int): () =&gt; Int = { var acc = n-1 () =&gt; { acc += 1 acc } } EDIT: try using it like this: val c = counter(1) c() c() ...
Been wanting to try this myself. 
Slick is ok till its not
You might want to elaborate on your requirements...
I didn't find any idiomatic Scala ORM with features that I am used to in Java. That's why I continue using old good Hibernate with Scala. You can apply some wrappers to treat nullable attributes as Option and Java collections as Scala collections. This is what I have been doing for the last two years. You can go further and try to apply the Active Record pattern with traits.
&gt; Somehow this worked! Do you understand why it works?
After thinking about it more yes
&gt; The performance should match whatever your jdbc and connection pooling frameworks can handle. That's why I ask because there are no data points to compare against. &gt; There is no magic under the hood with JOOQ. The thread I mentioned above points to exactly that, reflecting on a class on *each request*. Of course the author pointed out that that was an exceptional case and that there was some work underway (2013) to try caching the meta data. I like JOOQ's expressivity, most type safe DSLs have some limiting factor that requires one to dropdown to string based sql for the edge case scenarios. As for, "there is no real reflection magic" that's what they all say ;-) I'd be shocked if there were any type safe dsl that was truly reflection-free. In Slick for example, as soon you see a structural type, isInstanceOf, or any other reflectoramic operation, there's a run time hit. Would be nice to see a type safe query dsl performance breakdown across languages. How do the Scala offerings stack up against those of Java, C#/F#, and Haskell? That would be some interesting data ;-)
Thanks for the clarification! That does seem like a pretty glaring speed issue.
I think the joins optimize a little better if you do the generator format instead of the DSL format for statements. The way I see ORMs.. Is they make db access easy.inserts and updates and basic finds are easy. If you really need the power of SQL, you should code in SQL.
Ahh yes you are correct. JOOQ does use reflection in several places. However when you turn on POJO generation and use the DAO objects there are auto generated RecordMappers which do not use reflection. I'm not sure how well this works with scala. I assume you may want case classes out.
Agreed! Slick has fantastic composability. And some of its true power can be really exposed with the codegen features. I'd like to add (and vehemently) that Slick is NOT an ORM. You can ask Chris Vogt (co-creator) this directly. It's so much more powerful than an ORM because it allows you, in a typesafe way, take your tables and construct ~projections~ from them, which are not objects in the sense of classes. In that way you have a lot more freedom and power than an ORM, and the DSL is closer to SQL. Slick does get a little funky around joins. When in doubt, throw this in your application config to watch the queries that Slick is generating: logger.scala.slick.jdbc.JdbcBackend.statement=DEBUG 
IntelliJ IDEA works totally fine with JDK7. OpenJDK 7. On Linux. Oops. Sorry Apple users.
This explanation sounds a bit too simple for to me. Actually there could be a lot to talk about, even Martin Odersky doesn't consider his language as mature as you do.
Create a Bloomberg terminal version 0.0.1 for the web. * Download some stock data from here: http://eoddata.com/ (about $10-$25 for end of day stck price data for last 5 years) * Load the above data into Spark: http://databricks.com/ * Use Akka to schedule jobs to download regular data from Yahoo or Google finance. You may need to write some web scraper. * Use Play! to write a simple web app that would let me write queries (maybe write a DSL using parboiled) to query the Spark for financial data from a web browser. * Optional: Use ScalaFx/ScalaJs to write the front-end too
Just want to point out that while you could technically say that Vogt is a co-creator of Slick, it's really the product of Zeiger's ScalaQuery transformed into a scala collections backed dsl: https://github.com/slick/slick/graphs/contributors I'd say that Zeiger does the hard core engineering while Vogt performs a variety of tasks not limited to coding -- e.g. he is effectively the project evangelist, highly active on Stackoverflow and the mailing list, whereas Zeiger is mostly behind the scenes.
You can use persistent actors from [akka-persistence](http://doc.akka.io/docs/akka/snapshot/scala/persistence.html). The only problem is that the data will not be directly queryable from the DB, as what is persisted in reality is the result of a serialization (but you can plug your own serializer). There are a lot of DB connectors so you can use a lot of different backends (mongo, hbase ...). You can use persistent-views to replay the data that was persisted (in the same order). We used this at work for event sourcing and didn't have to worry at all about the backend or data access (which was great as we didn't know what DB would suit best or performance requirements). I really liked it, it was dead simple. 
Mostly sane I would say. I partly disagree with the traits, though. The advice is ok for immutable data, but for more complex objects, I prefer as a library user to read a pure trait, like trait Machine { type Foo def foo: Foo } and then you can put `class MachineImpl` anywhere and I don't want to see it. The other thing is, abstract vals are useful where Scala expects stable types. For example trait Foo { implicit def context: ExecutionContext } trait Machine { val foo: Foo } trait Scenario { val m: Machine import m.foo._ // ... } This would not be possible without a `val`.
In practice it is better to do it like this: if (malformed(input)) Left("bad input") else { // ... Right(result) } This is because the branches are more explicit this way and this is one area I've found where no compromise is acceptable. Because what usually happens in practice is complicated logic like: while (doStuff) { // after 30 lines ... if (someRuntimeConditionFails) return Error("bla") // ... } And that makes it really error prone, really easy to miss and your head explodes if you want to reason about the branches in that logic. And if those branches get complicated, well - that's a really good thing, being a sign that you need to split that into multiple functions instead of short-circuiting the logic. And another thing ... when calling a function, it's always better to assume that the input is already valid and do that validation before you call that function. As in ... validateUserInput(input).right.map(myFunction)
On usage of "useless traits" I marked that with a "should not", meaning that the rule is relaxed - sometimes there are valid reasons for polymorphisms and abstract interfaces, but people go overboard with it. And defining traits for immutable data doesn't make sense at all. On abstract vals, you're trading control over initialization semantics for syntactic sugar and after experiencing the pain of hunting down bugs of initialization, I cannot agree with that :-) 
A BitTorrent client. The base specification is pretty light, you get to do parsing and also concurrency.
occasionally I exercise scala by coding solutions for this list of real world bioinformatic problems http://rosalind.info/problems/locations/ The site is well documented, offers various levels of difficulty and example sample data &amp; solution for each problem. However, it's probably more useful to train writing small FP algorithms, but less for concurrency.
Has the redundant syntax been fixed yet? I had the impression that DRY was thrown out during the design phase last time I checked slick out (which was about a year ago).
I am not looking for compensation, just a good project and experience. I'm not specifically looking to use Akka, but would be a preference. I am comfortable with Git, Github, and Maven. I haven't used SBT yet, but would have no problems doing so
I'll send you a PM then.
The notion that a procedure should have exactly one exit is certainly not a new one (i.e., one can argue that `return` is problematic in *any* language) and people have been arguing about it for decades. But in the context of FP (and Scala's implementation in particular) I think the problems are really too severe to ignore and there's not really much of an argument in favor. I wrote up an analysis a while back that you might find helpful. http://tpolecat.github.io/2014/05/09/return.html 
hi..the link seems not works now...
No, for now use Joda-Time, since for now Joda-Time is the de facto standard and a de facto standard that's also good beats a newcomer any day - plus this new date API from Java 8 is just a Joda-Time with some architectural changes, but it even has the same author - so when the time comes, I'm sure it will be easy to migrate.
Doesn't seem a logically consistent argument to me. threeten isn't a newcomer if it's just Joda time with some changes by the same author is it? It's not hard to migrate but since the standard is there and Joda has helped it mature I'd advise everyone to use it.
1. Stock data includes historical data (either end-of-day price or minute by minute ticker price). Regular data you can get live from scraping but old data you may run into limits if you scrape. 2. I might be interested in showing all stocks that corelated (went up or down) with say GOOG, &gt;70% of the time. Other ones would be to find stocks which have a pattern e.g. up, down, up, down etc 90% of the time. Or simply what if instead of buying a Model S, I had bought TSLA stocks, what would have been my net worth now?
Dude, are you trying to get free labor or if a guy trying to learn? Not cool.
Here's the list of arguments: 1. ThreeTen is a JSR-310 implementation, but the Java SE 7 backport isn't a compatible JSR-310 implementation - as a consequence, at least one difference I could tell is that it is using a different package (org.threeten.bp) 2. Does that back-port even work on Java SE 6? At the very least, it doesn't mention that as a goal, so I have doubts. 3. Eventually everybody will be using JSR-310 by way of everybody migrating to Java 8 eventually, but by using the ThreeTen backport that's not much different than using Joda-Time in terms of the effort one would need to port a codebase to JSR-310. 4. Joda-Time being the de-facto standard is already used as a dependency in most libraries that need time handling, like Play Framework and people use it when deserializing date values coming from JDBC when using Slick and so on and so forth, therefore in most cases this is not a boolean choice - you either use Joda-Time, or you use both in the same project, with conversions between one another ;-) 5. I'm still not getting why people should use it. I'm sure Joda nurtured it, but that's not a good argument. I'm sure it has a better design, but that's left to be seen. I'm sure it will be the standard, but that backport is not it. 
Sure. But what if we just have an error check at the start of the function. No, only there, not inside of other blocks… Your alternative results in either deeply nested ifs, or a huge explosion of tiny methods in the code (in your example, Left and Right, plus whatever subroutines are required to implement them).
Implement something from work in Scala? Is there anything that involves concurrency? Or isn't there anything you personally want to build? You'll do a much better job, I think, if it's a project you came up with and want, than one someone gave you on reddit...
lol I'm actually not I'm in the same position. I'm finishing up the Coursera and want to do an easy project. Its open source too and simple.
Why don´t you tell us more about the project here? I think this might be interesting for all of us.
This is great! Thank you. Going to direct all my co-workers to it immediately. I'm still on the fence about 4.4, however. I think it should be downgraded to "SHOULD" status. If my understanding is correct, "blocking" simply allows the future to allocate another thread in the thread pool even if the thread pool's max has been reached. Mandating that developers always use it, in order to avoid deadlocks, seems like overly defensive programming to fix a symptom (deadlock) at the cost of ignoring the cause (poor architecture). But my main concern is that it makes it harder to control resources (thread pool utilization) when all future calls have this "escape hatch". After doing some reading, it seems like the 2nd and 3rd bullet points of this document back up my claim: [Blocking Needs Careful Management](http://doc.akka.io/docs/akka/2.2.3/general/actor-systems.html#Blocking_Needs_Careful_Management). But I'm curious about your thoughts. Also, does 4.3 and 4.4, in combination, imply that all futures should always use "blocking"?
&gt; "blocking" simply allows the future to allocate another thread in the thread pool even if the thread pool's max has been reached The "blocking" call also serves as documentation. Many times you cannot spot synchronous calls that block for I/O. However your suggestions are good - that rule needs more detail. For example I think that you cannot expect developers to remember to use "blocking", therefore for tasks such as SQL calls you should build helpers like ... def withSession[T](f: Session =&gt; T): Future[T] = { val p = Promise[T]() ioThreadPool.execute(... blocking(f(session)) ...) p.future } And then mandate that JDBC calls happen by means of this helper, which shoots 2 rabbits in one shot ... you enforce the "blocking" call and you execute the JDBC query on top of a thread-pool meant for I/O. But then, this forces us to work with asynchronous Futures, which is healthy but not for everybody :-) Could we discuss this in an issue? Lets improve the doc. Open an issue here with what you've just said ... https://github.com/alexandru/scala-best-practices/issues
Came back to say ... I added a note in [Rule 4.4](https://github.com/alexandru/scala-best-practices/blob/master/sections/4-concurrency-parallelism.md#44-must-use-scalas-blockcontext-on-blocking-io) mentioning that the purpose of "blocking" is also one of documentation. I also squeezed another rule in there, [Rule 4.6](https://github.com/alexandru/scala-best-practices/blob/master/sections/4-concurrency-parallelism.md#46-should-use-a-separate-thread-pool-for-blocking-io) - SHOULD use a separate thread-pool for blocking I/O. Read those and let me know what you think. Thanks,
Second parameter to that function must be a function from Int to Int. Try passing in "i =&gt; i + 1".
Int =&gt; Int is a function from int to int. I subconsciously read `=&gt;` as "to". Set, in this case, seems to be a type alias for Int =&gt; Boolean: the map method explicitly returns a Set, and implements the return value as an Int-to-something function. `exists` takes a Set and a function Int =&gt; Boolean (which can be observed as Boolean is the return value of the `==` method). The second parameter, `f(_) == e`, is shorthand notation for `x =&gt; f(x) == e`, in other words a function that compares the result of f(x) to a given Int e.
The cake is a lie (e.g scalac). Looks cool, but in large, serious projects it's a pain in the back... Typeclasses with modules are more effective and flexible
Thank you for your explanation, it helps me understand it better.
That's why I use a very simpler pattern, that looks like the cake pattern but without service traits composition. Even with a lot of services it remains very manageable. Less flexible than the real cake pattern but very easy to maintain.
Modules? You mean Scala `object`s?
Yep. 
It doesn’t matter. The problem is in the essence of the cake - inheritance. When you have thousands of traits to mix together you have a large graph of different dependencies, instanity which should be compiled...
The term `Modules` is used interchangably. It's a bit confusing..
Is it only for single day?
Yes, a Scala Saturday :) Might change if you decide to stay at the after party for a bit longer...
As traits cannot have constructors, self-types provides a means to demand that a trait, when instantiated, is mixed together with another type. They are used when it is not desirable (or possible) to declare a class.
Could you give a small example (or a link to an example)? I tried to read up lots of that topic but have yet to find the one I deem _worthy_.
Two questions: 1. **4.3. MUST NOT wrap purely CPU-bound operations in Futures**: if I do want to parallelize work then, what is the issue with using futures? Say I'm doing image/matrix processing on data that is loaded into memory, and I want to assign a future to each 1/8th of the image to speed things up. 2. **2.5. MUST NOT use "var" inside a case class**: how does this break equality? scala&gt; case class A(var i: Int) defined class A scala&gt; val a = A(0) a: A = A(0) scala&gt; val b = A(1) b: A = A(1) scala&gt; a == b res0: Boolean = false scala&gt; a.i += 1 scala&gt; a == b res2: Boolean = true
I've started a new project using Spray.io framework. It will be pretty much a web service to register addresses that you can lookup to have mail delivered too. https://github.com/fzakaria/addressme I just started and I am new to Spray. If you want to chat more about it and work on it with me please PM
Funny, I recently made a project in spray for the first time as well. Looking at your project, I'm not following why there are so many factories and abstract traits. It can probably be much simpler without them. This obviously depends on where this project is going and perhaps you have something in mind that requires this pattern (DI, or mocking in tests). Even still, I think it can possibly be avoided. 
addOne is strictly speaking a method. You can convert it to a function by following it by _, like the error message says: `val addOneF = addOne _`
This is great - being new to scala I can already see some mistakes I have made identified here and good solutions. For example, I just wrote some code today that catches all Throwables. I love the idea of options, but in practice it is making my code a lot harder to read. I used to have code resembling this: if (bla != null) { xx = ... if (xx != null) { //do stuff } } else { //other stuff } and now its bla match { case None =&gt; //other stuff case Some(blah) =&gt; { xx match { case None =&gt; {} //do nothing case Some(xxx) =&gt; //do stuff } } } So using options leads to significantly more nesting which can get hard to read and having 2 variable names to represent about the same thing (one for the option, and one bound to the content of the Some e.g xx and Some(xxx)). Do you have any suggestions for using Options more effectively? (one I just found - http://stackoverflow.com/a/10040992/803923. Option.apply can be used to wrap java style objects (null/not-null) into None/Some easily) 
I guess he's taking the Coursera class. You can define `type Set[A] = A =&gt; Boolean`. I think here he means `type Set = Int =&gt; Boolean`.
 val addOneF: Int =&gt; Int = addOne
Just do what is says and add _: scala&gt; def addOne(m: Int): Int = m + 1 addOne: (m: Int)Int scala&gt; addOne _ res0: Int =&gt; Int = &lt;function1&gt; 
Ah, that makes a lot of sense. Thanks. 
&gt; addOne is strictly speaking a method. What class is it a method of?
first one is an instance of Function1[Int, Int] the other is a method
That's just ... for (bla &lt;- blah; xx &lt;- xxx) { doStuffWithBoth(bla, xx) } In the words of a great master: "flatMap that shit".
First is variable of function type which can be passed as a parameter or returned as a result from other high order function like def modifyZero(a: (Int) =&gt; Int): Int = { a(0) } val b = modifyZero(addOne) // 1 And the second is just a method and you can not do such tricks with it
The method/function (or `def`/`val` if you prefer) distinction is fundamental, but Scala tries to sweep it under the rug and most instructional texts don't say much about it. Short version is, functions are values but methods are not; you can turn a method into a function using the _ postfix operator. Many more details here: http://tpolecat.github.io/2014/06/09/methods-functions.html 
Can you give the example in the article using type classes and modules for dependency injection instead of the pattern used in the article. This would be useful to drive the point home that typeclasses are the more flexible method.
You can do it with futures, but by using actors you can easily split computation across execution context's, processes, or nodes. Also, code readability. Futures tend to be messier as you start dealing with error handling from a large number of asynchronous operations.
Awesome. Here are some questions I have: 1 - You mention that you started with cake pattern but then moved to a different pattern. Can you elaborate or show examples ? I"m curious to your thoughts on the pattern and what you decided to use instead 2 - What did you use for DB Access ? Slick ? I'm also having a tough time figuring out a sweet DAL implementation thats clean and will let me easily test. 3 - I'd like to hear more about how you might have used the actor pattern in your project. for instance I broke my routes via traits however should they each have been an actor? Should the main HTTPServiceActor just pass the context to sub route actors? If you have any open source code would love to see it :)
All those factories at the moment are for the 'cake pattern' so i can somewhat dependency inject mocks later. I'd love to learn more about better alternatives
But you can make it into a function: scala&gt; def fooMethod(x: Int) = x + 1 fooMethod: (x: Int)Int scala&gt; val fooFunction = fooMethod(_) fooFunction: Int =&gt; Int = &lt;function1&gt; scala&gt; def applyFn(f: Function[Int, Int]) = f(5) applyFn: (f: Function[Int,Int])Int scala&gt; applyFn(fooFunction) res0: Int = 6
This may help: http://tpolecat.github.io/2014/06/09/methods-functions.html
When first learning Scala, I read the excellent Functional Programming in Scala. Then, I read learnyouahaskell.com (completed exercises and typed out the examples in Haskell's **ghci**) I strongly recommend LYAH as it teaches the fundamentals. 
&gt;I disagree, since actors mean you lose static typing. Um, no. You can only receive messages of a type, and you know what that type is.
Some time ago i started writing application for aggregate news with spray, spray a good framework, but have a little verbose, and for more comfortable work i wrote a small lib. If you interested: [lib](https://github.com/fntzr/spray-routing-ext), and small example for work [example](https://github.com/fntzr/spray-routing-ext/blob/master/sample/src/main/scala/example.scala) If you have any questions, I will answer.
You get no help from the compiler regarding what messages an actor takes, though, especially now that typed channels are gone.
And to elaborate more.. You can group params in as many sets of ( ) as you want. So 3 parms could be (a, b),(c), or (a)(b)(c) or (a,b,c) or (a)(b,c). You can call them all like a normal function. Where it comes in handy like people said is when you want to curry
Sure. It called [ETA expansion](http://gleichmann.wordpress.com/2011/01/09/functional-scala-turning-methods-into-functions/)
Is there a difference in doing it this way? scala&gt; def mul(m: Int, n:Int) = m * n mul: (m: Int, n: Int)Int scala&gt; def mul5 = mul(5, _: Int) scala&gt; 25 == mul5(5) res19: Boolean = true
Just because of the crummy syntax, I suppose. In Haskell it is the default. 
That has the same effect as currying, so no.
[You can still do effectively the same thing with a partially-applied function.](http://www.reddit.com/r/scala/comments/2k9wn1/def_multiplym_intn_int_int_m_n/clji76y)
I am surprised this is so upvoted, as this will not compile. In order to do what you intend here you would have to partially apply the curried function: def multiplyBy5 = multiply(5)(_) 
 Partial Function Application is not Currying http://www.uncarved.com/blog/not_currying.mrk
Partial Function Application is not Currying http://www.uncarved.com/blog/not_currying.mrk 
In Scala functions may have multiple lists of parameters. Defining more than one list of parameters make it possible to curry the arguments like in a "classic" functional language. The reason for why you have to use the syntax explicitly is in part an implementation detail (a limit of the JVM). Multiple parameter lists are however used for other purposes: for instance, they signal to the compiler that some syntactic shorthands can be used * e.g., when the second parameter list contains one argument which is a function, you can use the method invocation like a control flow structure; for instance: def MyWhile(b: =&gt; Boolean)(code: =&gt; Unit) = ... MyWhile(x &gt; 0) { println(x) } * when an *implicit* val is in scope, you can leave out the parameter list entirely: def sum(x:Int)(implicit y: Int) = x+y implicit val MyInteger = 100 sum(5) // 105 (this is a stupid example: implicit vals should have a very specific type) 
You're right, a curried function is the target of partial application. Thanks for pointing out that detail, while substantively ignoring the rest of my comment. 
A backing class that the REPL provides invisibly. It doesn't really matter: All identifiers defined with `def` are strictly methods, either on an object, on a class or weakly defined in traits (they may be implemented as `var`s or `val`s in an implementing type however.) In fact, all identifiers defined as vals or vars are also strictly members of a type. This is an implementation constraint/detail. The only concrete literals that can exist on the outermost hierarchy are `object`s.
I have been using this in [a project](https://github.com/hrj/abandon) and it has been a good experience. Relatedly, [Scalaxy](https://github.com/ochafik/Scalaxy/tree/master/Fx) seems to have macro based wrappers for JavaFx, with no run-time overhead.
Inspired by a post by /u/zxamt in /r/haskell, [original post](http://www.reddit.com/r/haskell/comments/2k51kk/flocking_behaviour_simulation_written_using_helm/). [source code](https://github.com/makemeunsee/akka_boids)
Nice! I'd like to see it in real-time, though (I assume it's a recorded video / gif?) More people need to do creative stuff with Scala. I was very disappointed by some ignorant remarks in the last Scalawags hang-out, that were like: "Why are people doing so much fun stuff in Clojure, like live coding, overtone etc., but not in Scala? Because Scala people are actually doing paid work, blabla, we need to hire a clown for the next conference." Making digital art neither needs to amount to unpaid work, nor is it useless (certainly more useful than programming banking systems that eventually harm our society), nor does it have anything to do with "being clowns". For me, the clowns are Fizzbuzz people. Cheers!
&gt; It enforces decoupling It doesn't, since you still need to be able to access the messages.
A) Why should concurrency be avoided? Maybe it should be like, do concurrency correctly. Why not take advantage of concurrency? B) The "avoid CPU-bound futures" only makes sense if you're doing a web/request-based app that already is built on asynchronicity. I have a CPU bound local script that totally benefits from concurrent calculations because it is CPU intensive. So it does not fit that recommendation. It should be re-worded/re-scoped.
That is not true, if `addOne` is defined as a `def` you can just pass it directly to `modifyZero`.
A) because concurrency is not something to be taken advantage of, parallelism is but that's different B) I agree, that needs more explanation, thanks for the feedback
So maybe I/someone else may mistake the difference between concurrency and parellelism.
It seems to have the same API as SecureSocial. I don't really understand why all the frameworks require modification of the controller, why they can't simply have `SecuredAction[RuntimeEnv]`? At least it's easier to replace default views in Silhoutte.
&gt; Also the authentication page isn't very pretty because I'm using secure social's out of the box. Yeah, that's one of the problems I have with SecureSocial. Writing a plugin to use custom views sounds a bit too much for me.
Oh, it looks like with Silhouette I have to write authentication controller as well. 
Silhouette sucks as much as Secure Social. Both require a lot of coding/configuration to make them work. Plus Silhouette doesn't support auth based on tokens
That's just fucking insane. The part about custom views in SS documentation is outdated by half a year. Overall it looks like it was written by someone who have never seen a web framework before.
&gt; But that means coding oath stuff yourself Then why exactly do I need the plugin?
Activator is not required, many of us continue on as always with SBT. Anyway, if you're relying on a fresh-off-the-presses web based UI to inspect the request, built-in browser developer tools would probably be more suitable. Can appreciate frustration when learning a new language and framework, but please realize that it's lack of experience and not (entirely) the fault of the framework that brought you to write this post. Can guarantee that if you take the time to learn Scala and Play you will sing a different tune -- the words "PHP" and "Rails" will be nothing more than bad memories; they are for me ;-)
&gt; I really want to like Scala but so far it's an exercise in frustration with both Web and non-web apps. Was in the exact same boat a few years ago, frustrated, argggh, Scala sucks, etc. It's simple: you have to learn the ropes, both with Scala and Play. Personally I avoid Activator (no need for UI starter templates) and use plain SBT instead. I use GruntJS in place of Play's web asset manager (i.e. sbt-web) which is brand new/green in Play 2.3, and am not a huge fan of the Twirl template layer, so avoid that as well. Not sure if you're a vim/emacs/sublime type or prefer and IDE, but regardless, always run SBT in a separate terminal and *turn off* automatic build in editor/IDE. In other words don't trust your editor/IDE to tell you whether the code is correct or not, SBT is the ultimate decision maker in the correctness department. As for documentation, the Play docs themselves are actually pretty decent to get going (see logging setup, for example, to get "proper" logging ;-)), but they do not fill in all the blanks for you. Play is a building blocks framework, be prepared to roll your own. Keep at it
Basically, I was exactly the same when I first had to work with Scala. I thought I was a more-than-average programmer and thought of Scala as "another language to learn", without knowing anything about it. Frustration is what I experienced, and I had to start with Scala and Lift, which is, in my opinion, much difficult to grasp than Play. I didn't understand most of the stuff going on, couldn't even read code to try to figure it out myself... I ended up hating Scala at that point. However, after some proper introduction to the language, studying a little bit of functional programming and doing small simple projects, Scala became my favorite language so far. And once I got it, I started to read Play! and found out that it was much more straightforward than Lift (which is not bad, but takes more time to learn). From experience, and working with a Rubyist in the team, I can see why people who have worked with Rails don't like Play's approach (maybe the same is true for Rubyist learning and applying Scala). My recommendation is the same as the others said: use SBT, go through the documentation, and above all, dedicate some time to learn the basics of Scala. Once you get it, maybe your perception will change. Don't give up!
I'm quite comfortable with language itself, I mean I'll probably won't understand scalaz sources but I've done enough C# and Haskell to use traits, variance, monad comprehensions and stuff. The problem is quality of libraries.
What do you mean by "you have to turn your controllers into classes and implement a controller factory for no clear reason". Why just mixing in SecureSocial and turning Action into SecuredAction as described in http://securesocial.ws/guide/securing.html isn't enough?
I don't really know how to answer this. Because it produces a compile error?
I'd reexamine the premise, that decoupling and types are at odds. The ideal from a typed/functional perspective would be to express the contract in types, no? 
There are various approaches to make something meaningful of that: 1. Describe your problem in a detailed, reproducible and as emotional as you like way (would be super amazing to also compare with rails stuff that makes this much easier). Something like a blog post linked from reddit would fit better for such a thing. Then people start trolling scala-"fanboys" by sending link to this post in chats/tweets/etc and eventually someone clever and experienced enough will read it and respond with an detailed-answer post or will contribute to play or write a plugin or something. 2. Write an issue in play repo with compact but clean description of problem without emotions but also without spending much time on that. I guess, current post isn't detailed enough even for experienced play-boys to help you.
An issue about one of the problems I've encountered is more than half a year old so writing bug reports won't help. Basically my experience with Play ecosystem is similar to my experience with PHP - it's not like the problems are hard to solve, it's just frustrating to deal with all that crap. Sometimes I'm like "Seriously? This? In 2014?"
&gt; The ideal from a typed/functional perspective would be to express the contract in types, no? Ideal, yes. Currently possible in the jvm, no. It's not that decoupling and types are at odds, it's that the runtime type information would be lost if the contract could be specified in a decoupled nature. Since the workaround for the language is to define the contract in terms of the objects being sent, I'd rather have that then a strong contract with coupled interfaces.
Sounds like "it's very different, I have to learn lots of new things, it's a lot of work!" mixed with "I tried it and since I didn't know what to do, I had to do a bunch of complicated stuff (which may not actually be necessary)". E.g. If play had an ORM bolted on (and not trivially disposed of), it would be a turn off to me. 
Well it does then auth pattern of make a token, store token in db, etc. For someone doing say author via password, its good. You can make the oath calls in not that much code.
I use SBT and java 8 on Mac fine (no activator) , and activator with java 8 on windows fine. So not your exact setup but close. I suspect you need to make sure SBT_home and whatever environment vars activator used are pointing to jdk8. I bet some crap is resolving to jdk7 and some to jdk8 which is breaking it.
This is the most common cause and fix I've encountered regarding this error message. Expanding on this, the proper way on OS X to find the path to a given JDK is using /usr/libexec/java_home &lt;version&gt;, with version being in 1.x-notation.
But I think its best to also set java and SBT home because some stuff doesn't respect weird osx home patterns
There's a proof of concept here with Slick: https://github.com/lunatech-labs/lunatech-securesocial-poc
I haven't said that bolted-on ORM is either a good thing or a bad thing. 
You use that tool to set JAVA_HOME, like: export JAVA_HOME=$(/usr/libexec/java_home)
I tried setting JAVA_HOME in the same terminal before executing activator (i also confirmed the correct path using /usr/libexec/java_home). First using JAVA_HOME=... then export JAVA_HOME=... First try didn't have any effect, which should have solved that. After trying export, even after restarting Terminal, activator fails to start with this new exception: Checking for a newer version of Activator (current version 1.2.10)... java.lang.NoSuchMethodError: scala.util.matching.Regex.unapplySeq(Ljava/lang/CharSequence;)Lscala/Option; at activator.ActivatorLauncher.downloadLatestVersion(ActivatorLauncher.scala:176) at activator.ActivatorLauncher.checkForUpdatedVersion(ActivatorLauncher.scala:218) at activator.ActivatorLauncher.run(ActivatorLauncher.scala:27) at xsbt.boot.Launch$$anonfun$run$1.apply(Launch.scala:57) at xsbt.boot.Launch$.withContextLoader(Launch.scala:77) at xsbt.boot.Launch$.run(Launch.scala:57) at xsbt.boot.Launch$$anonfun$explicit$1.apply(Launch.scala:45) at xsbt.boot.Launch$.launch(Launch.scala:65) at xsbt.boot.Launch$.apply(Launch.scala:16) at xsbt.boot.Boot$.runImpl(Boot.scala:32) at xsbt.boot.Boot$.main(Boot.scala:21) at xsbt.boot.Boot.main(Boot.scala) Error during sbt execution: java.lang.NoSuchMethodError: scala.util.matching.Regex.unapplySeq(Ljava/lang/CharSequence;)Lscala/Option; 
This looks like you are mixing different Scala versions now.
Silhouette 2.0 supports auth based on tokens : http://docs.silhouette.mohiva.com/en/latest/how-it-works/authenticator.html#jwtauthenticator
If u need a OAuth provider, here is a nice one: "OAuth 2.0 server-side implementation written in Scala" https://github.com/nulab/scala-oauth2-provider
1. Play is automatically setup with LogBack 2. It's very easy to setup a Play filter that just dumps all request/responses 3. I noticed that SecureSocial actually moved to a new major version however they haven't updated the docs on the site (they dramatically changed the setup) 4. You're largely lamenting about an open source plugin for Play rather than the framework itself. I have done a Play! Framework project but recently I've enjoyed working with [spray.io](https://spray.io) you can check out some new project I started (has oauth2 and userpassword auth) [here](https://github.com/fzakaria/addressme)
Please feel free to provide feedback, improvements, pull requests. I'm hoping this will make it easier for people new to Play/Slick/Scala to get up and running.
This is great! Play-Scala really needs more like this.
What exactly is *new* about it? It's 2014.
Came here to say the same thing
I do not like the Scaloid trait based way. it is totally ugly, if you really try to use it. I have a alternative, but have no time to open source it yet also the treat of intent is ugly, why not use dynamic types? or even better Acttivity[T] T is intent type. in short words, you should dump the RichView class, and use trait TView extends View.OnClickListener with View.OnLongClickListener { self: View =&gt; } Then you do not need to write STraitView[_] every time you want a view as parameter, but instead write TView
I and a few people I know have all tried out slick and none of us have stuck with it. I don't know a single person who uses it for real work. Does anyone here actually use it?
Yeah, not really digging the whole "new" slogan. I agree it's "better", but hardly groundbreaking.
The release notes: http://www.scala-lang.org/news/2.11.4 
I'm having the same experience, it's still there .... for now.
Maybe I should've framed the article better to make it clear that I'm targeting new Scala adopters. It's certainly true that Slick has been around for a while now, but for many people (even in the Scala world) it's still very much new. For example Scala, while it's almost ancient as it first appeared in 2003, it's only been gaining traction since the last years and is something completely new for many developers who adopt it now. I was mainly targeting the sort of java developer who's been used to his Hibernate/Spring stack for years and is now exploring Scala and database query solutions. For them Slick is completely new with completely new concepts (not ORM but FRM). Personally, I've used Slick on two projects now, but all of them didn't have complex query requirements (max 3 joins). For those cases I think Slick is a nice library. For more advanced cases I think it might become a little bit tedious to 'merge' those join results in a nice object structure. But aside from Slick being a good library or not, the concepts it's using are still interesting for many people used to ORMs.
LINQ to SQL with its strongly typed queries (`var alice = db.Users.Where(user =&gt; user.Id == 1).First()`) and ability to save object graphs has been around since 2007. "FRM" for me sounds like a fancy way to call an ORM that lacks features. As you've already noticed selecting or saving an object with lots of relations requires a lot of boilerplate while full-fledged ORMs it's the same single line of code.
anorm is a fairly sane wrapper around SQL. Depends if you want the ORM feel, or the raw SQL feel. In an ideal world, I want the full power of SQL, and type safety, without having to do a bunch of hacks.
Do you really though? Have you ever used a Java ORM and gone down this route, where it started generating joins for you? It works awesome for a while and then assplodes.
My team uses slick for any time we're stuck pulling data out of a relational DB. Most of our data lives in a couchdb instance at this point. Once we started to figure out some of its stranger idiosyncrasies we all started to really like it. To me it's what I always wanted hibernate to be. A way of getting data into and out of the DB without all of hibernates bullshit dirty checks and cascading. 
Yep. I worked with multiple ORMs and I've seen generated queries more 250 KB in length, that's right two hundred and fifty kilobyte query, Entity Framework sucked that much. In case of the app I'm implementing I'm pretty sure ORM will do fine.
[ScalaKata Code](https://github.com/MasseGuillaume/ScalaKata) [Tour Content](https://github.com/ScalaKata/TryScala) Scala Kata is also a [sbt plugin](https://github.com/MasseGuillaume/ScalaKata#sbt-plugin), you can run it locally and add dependencies. You can also host a server internally via a docker container. It's just a [one liner](https://github.com/MasseGuillaume/ScalaKata#1-its-also-possible-to-run-scala-kata-in-a-docker-container) to install. Regarding the tour, It's not the best way to present Scala. I want to iterate with the community to build something good. I would love to have your feedback on how to improve this part. 
Neat!
For a start, the contrast in colors between the background and the text on the linked page is very hard to read.
maybe I have spent too long in cassandra, but I have moved away from perfect 4th normal form. Why put CC in it's own table linked to user by a FK. Do you ever want to actually use CC on its own? I guess in a data breach, but not often do you want your app to go "Grab all CCs in the DB and charge them!" So I would just use a json column or something to ram the CC details in the user row, thus keeping me from needing to mess with joins.. of course I don't think slick handles this that well either, so not sure it actually helps..
/u/MasGui said he had to turn off the server.
RDBMS is perfectly suitable for lots of tasks and using a NoSQL DB for such tasks will be either an overkill or an underkill (yes, it's a word now).
True but like I said you can model the feel with say postgresql + json columns. Keep the CC and and Address as json fields right on the user. Saves a ton of joins to mess with.
Of course. Though it's kinda ironic to see this suggestion in a sub obsessed with type safety.
I am not as hardcore scala as most, I am pragmatic ;)
The lack of plain links is frustrating.
What do you mean ?
Scala 2.11.4 is a bugfix release that is binary compatible with previous releases in the Scala 2.11 series. The changes include: * Scala shell (REPL) is more friendly to Crtl+D. It leaves your terminal in a clean state and suggests using `:quit` the next time (see #3902). Kudos to @gourlaysama! * REPL uses different colors when printing references to vals and types. Pass `-Dscala.color` to enable that behavior (see #3993). Thanks to @puffnfresh! * The Scala specification received a fair amount of love and became much more beautiful. It has got syntax highlighting (#3984), linkable headers, and a side bar with TOC (#3996). A few final touches has been merged that fix typos and mistakes stemming from automatic Latex to Markdown conversion we’ve done a while ago. Thanks for attention to details @gourlaysama, @som-snytt and roberthoedicke! * Non-deterministic pattern matching warnings has been fixed (SI-7746). Many thanks to @gbasler for diving deep (#3954) into logical formulas constructed by our pattern matcher implementation! Compared to 2.11.2, this release resolves 54 issues. Out of 120, we merged 95 pull requests: 90 for 2.11.3, and 5 for 2.11.4. The next minor Scala 2.11 release will be available before the end of the year, or sooner if prompted by a serious issue. **Do Not Use Scala 2.11.3** Due to a binary incompatibility in Scala 2.11.3, we recommend upgrading to Scala 2.11.4, which resolves the incompatibility, as well as another blocker issue that was discovered in the days after the 2.11.3 release. We have analyzed the mistakes that lead to the breakage (human error), and are taking measures to prevent this from happening again. We apologize for the inconvenience, and thank everyone who was involved in reporting and diagnosing these critical issues.
We use it in production. It's got warts and takes some finesse, but it works for us really well and cuts down on our code complexity in our service layer
Is there a quick way to project multiple outer joins to something more convenient?
My team started to use it, but switched to squeryl shortly after. You should check it out. 