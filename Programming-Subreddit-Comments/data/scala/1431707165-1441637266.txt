Good luck
* Cay Horstman's Book [*Scala for the Impatient*](http://www.horstmann.com/scala/index.html) is a kickass intro to the language, with exercises galore. The first few chapters are free. * [Project Euler](https://projecteuler.net/) is a great set of problems for any language. * [99 Scala Problems](http://aperiodic.net/phil/scala/s-99/) looks pretty promising, but I haven't spent much time in it yet. 
ORMs suck no matter how "functional" they pretend to be. Using slick 1.x on a project was the worst experience I've ever had using scala (and I've used both JPA and Lift, so that should tell you something). 3 different ways to do the same thing, with horrible performance differences for non-obvious minor syntactic differences. Even if theyve worked around tuple22 by now, I wouldnt touch it.
Slick 1.x was a painful experience no doubt. Even the early versions of slick 2 were more hassle than they were worth. Ive been using the recent slick 2 versions in production and slick 3 in another project I'm working on and have found that they have both matured to a point where I actually enjoy using them. My biggest gripe with slick is how hard the underlying code is to read through (particularly when you want to extend or modify slicks behaviour in certain situations). Its certainly not for the faint of heart. I still find it one of the easier to use/more natural abstractions in scala though. Just has a relatively steep learning curve.
http://exercism.io/ is a good source for practice assignments. The great thing about it is that you can submit your solutions and have people review it. And of course you can look at other people's solution as well.
If you are able to use Scala then you don't need Lombok. However if you have a Java team of any significant size, and want to encourage the use of immutable Objects then Lombok (or a similar project such as Immutables, Google Value Objects etc) is pretty mush essential. Without something to make it simpler, it just won't happen.
thanks. i was going to activator ui
I do the same thing and it is incredibly useful. 
Really glad I could be of some help. I'll be sure to submit more Posts as I finish them.
You probably missed the `build.sbt` SBT project definition. You may paste it here so we'd be able to check it.
Interns aren't expected to know anything besides, what they need to learn more about the subject at hand, and maybe become productive eventually(depends on if it's paid or not). Unless the position is competitive, then go and learn all the you can.
As far as actual Scala is concerned, probably nothing. Scala devs are super hard to find, so to expect an intern to be proficient in Scala is pretty crazy. That being said, some good things to be able to talk about in any interviews early in your career are algorithms, object oriented programming, and basic data structure stuff. As long as you're able to hold your own in those topics, everything else is a plus (though they might ask some functional programming stuff since this is a Scala shop). Honestly, the best thing you can do in an interview for either an internship or for a junior dev job is just let them know how stoked you are to learn and start hacking away. I'm still super early in my career, yet every interview that I've had and done well in was because I let them know that I was passionate and wanted to learn and get better. Your interviewers probably don't expect you to be a great programmer. What they do want is to bring in someone who they can make great. And if you're open minded and excited to learn and get better, then you'll crush it. Also, be yourself. I know it's hard to let yourself shine through in an interview when you're thinking about what you can say that'll land you the job, but you're doing yourself a disservice if you're not being 100% yourself. Think of it as you interviewing them to see if you'll fit in. If you walk into a place and the whole vibe sucks and you're not into it, then be ready to turn them down. You're the prize, not them. You're in a career field where you can find a good job easily, so there's no reason to settle with a place that sucks. Just remember, make sure that you like the place and they like you as a person. It'll help you keep your passion and get better. And it'll make your job fun. 
&gt; Actor B is a function logically &gt; Whereas functions and values give us nice constraints to help us reason about our program, actors rip everything apart and demand that the developers do all of the work. Not sure the author gets the point of using Actors. S/he seems to prefer FP, but is thinking in terms of single process, single machine semantics.
I don't agree that Actors should not be used for concurrency. There are cases where the actor model helps you get predictable results due to *controlled concurrency*. Hammering the CPU with new threads and experiencing unpredictable load vs. a stable setup with predictable performance. We built a scale-out friendly distributed search engine using Akka. Getting more throughput out of the system is as simple as changing the config. If we had Futures littered all over our code, that would be a nightmare and we'd have no option but to scale up.
I see your point, but I don't think actors help you there as such: if you're looking for controlled concurrency, an executor with a resizing thread pool and a feedback loop will be sufficient. While you can get that with Akka, it's still missing the point of actors as such.
If you leave newly-grads to any system they're unlikely to write perfect code, Akka or not. Therein lies the problem I think. 
&gt; In addition to forgoing static typing, this also means actors are only useful if they produce side-effects. I think the author missed one of the main benefits of actors. The ability to reason about side effects in a concurrent system.
When people repeat "actors don't compose", I feel as if there's some formal definition of *composition* that I'm unaware of. Can't composition be achieved in numerous ways? For example, the future monad: for { a &lt;- (actorA ? msg).mapTo[Int] b &lt;- (actorB ? msg).mapTo[Int] } yield (a + b) Or, putting a ref to the next actor within a message to the first, and making the first actor send its results to that ref? Doesn't that effectively "compose" these units of functionality into a larger unit of functionality? Regardless, I've personally seen no better model for maintaining mutable state in a concurrent and/or distributed system. If I need mutable state, actors are my go to tool. If I just need concurrency on pure functions, I wrap said functions in futures and move on. Both are useful types of ammo, it would be a personal failing for me to believe that either is a silver bullet. I'm genuinely interested about the more functional approach to solving the problem of mutable state in a concurrent system, but haven't gotten a straight answer from anyone yet. For example, how could I maintain a HTTP server session cache functionally? In actor world - I create an actor per session; in OOP world - I whip out a concurrent hash map that all my threads side effect on.
&gt; I believe that video lectures are a great way to pretend you're learning something. This is true if it's all you're doing. Those Coursera and EdX courses you mention also have reading and programming components. Not saying they'll make you an expert in machine learning (they won't), but it's more than *pretending* to learn something.. 
Actors have a preferred return type of Unit. All complaints about actors boils down to this stupid abstraction, where you lose all type safety. Untyped actors have no place in modern typed functional programming. I took one look at Scala actors and stayed the hell away from it. I simply don't understand why Odersky promoted actors so heavily in his introduction to scala book. A Future is a superior solution to actors virtually anywhere.
&gt; I took one look at Scala actors and stayed the hell away from it So then you don't actually know what you're talking about.
&gt; If you are able to use Scala then you don't need Lombok True, but if there is existing code in Java and you don't want to rewrite the whole thing into Scala just yet.
Scala is growing quite rapidly. You'll be fine. On a meta level, you should follow your interests. If you keep your skills up to date, you'll always be employable. And the best way to learn new things is to work on interesting projects. If you're interested you'll be motivated to learn.
You should be able to explain: "A monad is just a monoid in the category of endofunctors". Just kidding :-D
/r/scala is going to have a biased view of course ;) I love Scala and use it whenever I possibly can. With that said, I learned it AFTER I had the Java thing down. Knew standard library inside and out. Knew GC tuning inside and out. Knew all the popular MVC frameworks. Knew Spring. Spent a good 4-5 years doing the Java thing. Then went to Scala.. breath of fresh air. A lot of what I learned in Java isn't useful (say Spring), but still good to have some background so I can understand why I don't want to try to use guice in Scala even though I think you can technically make it work somehow. I also have a deeper skills (GC tuning) over say a Ruby dev that switched over to Scala... 
If you're willing to relocate, you'll have your pick of jobs, and that isn't likely to change anytime in the next 10 years, if at all. Scala just makes it too easy to build distributed, relatively bug free applications. If you're not willing to relocate, then it is dependent on where you live. There's quite a few opportunities here in Denver, and I've had requests to interview in Seattle, San Francisco, Chicago, New York, and Toronto. Other devs might be able to chime in with other locations. Main piece of advice I'd give you whether you pick Java or Scala is to get familiar with the garbage collectors of the JVM. The GC's have a large impact on performance, and you may need to split applications into smaller micro services if portions of your application use GC differently.
The Scala growth has been stagnating for a while, I'd be cautious (some people say it's actually regressing ever since LinkedIn recently declared they were moving away from Scala and going back to Java). Intellectually, it's a language very worth studying and reading about, it will challenge your understanding of software engineering in general and it will probably make you interested in (IMHO better) other languages such as Haskell. Professionally, it's just not doing well at all. Don't take my word for it, do a quick job search in your area and see what you find. Just don't expect to make a career out of it, especially as someone with little to no experience. My advice: keep studying it but get comfortable with Java, it's probably going to be your work for the few years to come. 
I'd say instead that, because Scala is not in Java's position of being the default choice with literally no thought given to alternatives, the distribution of its industrial use is Zipf, with concentrations of adoption in the obvious places (Silicon Valley and London, for example). I highly recommend finding the nearest Scala Meetup to you—SFScala, for example, has ~2,000 members—and getting to know the community, who's doing what, and seeing where might be a good fit. Finally, I would suggest committing to FP in Scala with the typelevel (scalaz, Shapeless, etc.) stack. It's a much better/nicer way to write software than to continue down the OO path. Java is best left by the side of the road, and even OO in Scala should be avoided as much as possible (which is, unfortunately, not completely). Don't waste time integrating Java libraries into Scala, either—find or write Scala native ones. You'll be better off. Finally, we're hiring at Verizon OnCue. :-)
&gt; If you're not willing to relocate, then it is dependent on where you live. There's quite a few opportunities here in Denver, and I've had requests to interview in Seattle, San Francisco, Chicago, New York, and Toronto. Other devs might be able to chime in with other locations. In my area, this is the popularity of listings, in order: * Java * More Java * C# * ASP Microsoft web shit-stack * PHP + JS web shit-stack * Perl * COBOL / MAINFRAME / AS400 / ridiculous legacy shit * "iOS" * Everything else, which is almost never That's the Enterprise beat, though. IDK enough about the local Startupistan refugees to tell about those... There are more COBOL listings in the area (a medium-sized city on the East Coast) than Scala. Not a joke.
If your area is big on traditional banking (e.g. not hedge funds/trading), you'll see a lot of COBOL. Most scala jobs are in big data, hedge funds, trading, and large scale web applications.
Good article BTW, thanks! *Added it to my bookmarks: it represents my own thoughts very close.
Why would you need guice in a scala app? 
&gt; Because implicit parameter passing is so much better Maybe so, but that's dependency passing (like `Reader`), not dependency injection (like Guice provides). Dependency injection is valuable, regardless of the language. 
I think to be honest you're probably overthinking it. The choice of language you make early in your career shouldn't make too much difference. For the record, my first job was in PHP, then C#, now Scala, Go and a bunch of other rubbish :) What you should do is do what you *enjoy* because that's how you will learn how to write code better. Anyway, I dont think any (sane) shop would look at a Scala developer and go "He couldn't possibly work in our Java codebase".
Can you view console output and see which tasks take the time?
&gt; Professionally, it's just not doing well at all [UK IT Jobs mentioning Scala are at an all-time high](http://www.itjobswatch.co.uk/jobs/uk/scala.do) and is currently sitting [~8x more popular than Microsoft's F# programming language](http://www.itjobswatch.co.uk/jobs/uk/fsharp.do). 
Isn't the java integration a major part of the appeal of scala? That's the main reason I'm using it at work instead of haskell/ml/whatever other language without the oo baggage... at least until the frege tooling gets better.
If you know Scala well, you already know Java, but not the other way around. The only problem will be that working with Java will be more frustrating than if you didn't know any better. That said, my company uses Java only, and I haven't seen many Scala jobs in my area (I've seen a couple that have it in a laundry list of languages). Yet, I use Scala on a daily basis for prototyping and testing, I just have to write the production code in Java. Even with having to port back the final product, the entire development process takes less time because it's so much faster and clearer to work it out in Scala until the design and implementation are sound. Porting back is pretty mindless work, so if you can work from home once in a while, you can just get a case of beer and do it at home. If you don't remember doing it, it's almost like you never had to. This also leaves me with two implementations of everything, so I can compare them for testing purposes, just make sure they both give the same output for the same input. 
That was my impression as well (that Java integration is a major part of Scala's appeal) 
lol very true too :) 
I'm presenting facts, not an argument. I don't even use Scala: I earn lots of money using other things that are even less popular. 
I suggest to investigate the server. Perhaps you're hitting swap. (Start with `htop` tools and similar.)
 no thx. Adding a library to make all my refs lazy. Don't need lazy most of the time. Too much lazy adds up. 
Just realizing, that name is already taken. D'oh!
If I see a car without windows in it, I don't have to take it out for a test drive to understand that that would probably not be a good idea. This takes some experience, but it saves a lot of hassle.
reactive-boner.com isn't taken yet. Ay, don't be nasty, precious.
Or they can give a job to the now unemployed Guillaume Laforge and call it 'Réactif' with some French flair. Or 'Reactiv8' and go with the techno revival that should happen now for the 25th anniversary. https://www.youtube.com/watch?v=2_bL0hFyslg - new motto: Top1 Nice1 Get Sorted
When I saw the title, I figured it was a joke because [reactive banana is a functional reactive programming library in Haskell, written by a guy named Heinrich Apfelmus](http://hackage.haskell.org/package/reactive-banana). Yes, the author's name is basically "Henry Applesauce" in German.
You should turn on SSL debugging with -Djavax.net.debug=all so you have more detail available. Also checkout the following links for debugging: * https://docs.oracle.com/javase/7/docs/technotes/guides/security/jsse/JSSERefGuide.html#Debug * https://docs.oracle.com/javase/7/docs/technotes/guides/security/troubleshooting-security.html * https://docs.oracle.com/javase/7/docs/technotes/guides/security/jsse/ReadDebug.html * http://www.smartjava.org/content/how-analyze-java-ssl-errors On a more general note, your protocols, certificates and ciphersuite setup almost exactly the opposite of what you might want. Look at RFC 7525 for the recommended configuration and checkout https://github.com/wsargent/java-rfc7525/blob/master/src/main/java/com/example/RFC7525SSLEngineFactory.java for an example, and configure your certificate using the ServerAlternativeName (-ext SAN) as described in https://www.playframework.com/documentation/2.3.x/CertificateGeneration
Five years ago, no question. Today we have native web back-end stacks, native SQL access, native JSON support, native big data support, and even scala.js. In other words, today—and realistically for the last year or so—it's hard to make the case for integrating Java code at the bytecode level apart from in highly custom, vertical domains. That said, no doubt there are organizations with big investments in Java code that's performance-oriented, highly-tuned, etc. and at least on an incremental basis, if not an ongoing one, there's a good argument for wrapping it. I'm really just reflecting on our experience at Intel Media/Verizon OnCue, where most of our issues have seemed to stem from the inevitability of mutation, bad exception handling, and bad concurrency architecture of Java, and we've solved it by going more native Scala or, necessarily in some cases, building our own monadic API around the misbehaving system.
I'll go out on a limb here and say that if you can solve your problem as quickly (in total lifecycle of the product) in Go as in Scala, then you should, because that means your problem domain doesn't benefit from abstraction much at all, but might benefit from Go's fast compilation, POSIX API support, and CSP concurrency. I'm not joking, BTW: it's entirely appropriate that, e.g. Docker is written in Go and not Scala.
What is the problem with lazy? It seems like a useful abstraction to me. Also macwire doesn't require lazy.
If it's in a hot path can be a huge perf hit. If you need it sure. But you don't need to wire. 
Reactive Banana is the only name i will acknowledge
Might help if you read the article.
I commented on the blog, but I'll mention it here too… I wrote something like this for [Play Framework](http://www.playframework.com/). It runs one task at a time, but otherwise it's very similar. It could be adapted pretty easily to run more than one task at a time. The other difference is that it uses an atomic reference for concurrency control; there's no locking at all. You can see the code here: https://github.com/playframework/playframework/blob/2.4.x/framework/src/iteratees/src/main/scala/play/api/libs/iteratee/RunQueue.scala
I've always found it ironic that Akka, with it's strong support for untyped actors and only a tiny bit of support for typed actors (added on after the fact), comes from a company that calls itself Typesafe.
Not just because of Java8, but because a lot of people wanted (and still wants) something just a bit smarter than Java. So they can order business applications in that language and rejoice in the increased soundness guarantess, without forking over serious money for competent programmers. There are hundred(s of) thousands of Java devs who want faster compilation, because they do google driven development fueled by compiler errors. And even if supporting these use cases should not be a primary goal for any programming language, the criticism is still valid, that there's no Simple Scala. The community, when faced with a question of how to do this or that goodheartedly offers awesome Scala solutions, that compose well in the minds of experienced Scala programmers, but are rather intimidating and frustrating for those who just want the good bits of Scala, but otherwise don't really have a clue about this reactive functional funkyness.
I have something similar here - https://github.com/monifu/monifu/blob/master/monifu-core/shared/src/main/scala/monifu/concurrent/async/AsyncSemaphore.scala
I also wrote something similar: https://github.com/ExNexu/akka-actor-locking :-)
I like the approach your presentation takes. Thanks! I'll give that a listen tomorrow while working. That said, you and Pas seem to believe that trained monkeys can and do work in the industry. :) Seriously, I would consider eliminating that kind of rhetoric from your repertoire. It's ... not flattering to our industry and especially yourself. Resorting to that sort of verbal self-flagellation is really counter-productive when it comes to promoting ourselves and assigning proper value to our contributions to society in general. We all understand that there can be a couple of orders of magnitude difference in productivity between programmers, but even the lowliest programmer needs and deserves some respect; particularly if you're going to be instrumental in bringing them along for the ride to the next level of productivity. Ultimately, as someone who can command an audience of programmers, you're already an outlier and you'll be instructing those who probably are not at your level of productivity yet. They know that, but they'll thank you for not talking down to them and calling them trained monkeys. My apology if that's not your normal tone, but you get the gist. 
The phrase "trained monkey" was poorly chosen. I didn't mean to imply that programmers are trained monkeys, but that the patterns are so simple *and* well defined that they can be applied in an almost mechanical way. Internally we say "keyboard cat it out" -- you'll see why if you watch the video.
We're running Scala on JVM on Yocto Linux. It'd be ridiculous to ask JVM to handle WiFi and Bluetooth 4.0 low level communication ;-)
Regarding the indeed stats though, do you think there's something funky going on at the tail (where popularity shoots to the moon)? If you search for many languages or search terms in general, you see the same pattern at the same time as Scala's apparent upshoot in popularity. See [here](http://www.indeed.com/jobtrends?q=scala%2C+python%2C+angular%2C+MongoDB&amp;l=). If the data is messed up, and we just take the trends up to but not including that last upshoot, Scala jobs actually do look stagnant - not significantly better than late 2011.
It's a very simple and quite dumb tool but it's **so** useful and time-saving. :)
Can the downvoters comment on why this was downvoted? I would like to know the issue is. Thanks.
&gt; we want to prevent one service from accidentally DOSing another This is one of the goal of the reactive streams API (back pressure managements) and of Akka-Streams.
I've always thought Typesafe was possibly the most aptly-named company, up there with Tesla.
I think that's the case: judging by my inbox, demand for Scala programmers is exploding
Yes, for appending you must copy the structure of the list.
Tanks! This makes things much clearer.
Is this really Slick-specific? I don't have experience with Slick but to me it looks like standard pattern implicit classes to add methods but applied to Slick code.
* In theory, you can use Java thinking while coding Scala, and it'll work well. In practice, you probably won't be willing to do that. Scala alters your thinking so much that most people just don't want to return. So yes, my personal opinion is that, if you'll dive into Scala, your Spring knowledge would mostly be wasted.. Your HTTP knowledge will do you good though, and your knowledge of alternatives will give you a broader view in general. That is of course my personal opinion on this. * 'Programming in Scala' is a nice book, yeah :-) * Note that, of course, Scala reddit channel is biased about Scala, so you have to make your own decision anyway.)
Might indicate a general uptick in IT jobs on indeed.
I don't know why everyone complains about how difficult sbt is. I thought it was way easier than Maven.
Those are the best kind IMHO.
I think my article is probably not clear enough. Although I never used Maven extensively, sbt is for me the best build tool for Scala/Java projects. It is very simple to setup and has lots of amazing features such as the dsl being Scala like lang, the possibility to use REPL with your code and libraries, and on and on. My idea with the article was just to give some tips for you to do some optimizations to keep your build configuration more maintainable with the increasing project complexity.
When Typesafe first came together Akka was their big push with almost every conference, tweet and interview pushing Akka. Then that phased into wedging the word 'Reactive' into every possible setting / retweeting every credible mention of 'Reactive' anything. That segued into 'Big Data' with Spark and now there's lots of Spark noise. Outwardly they seem very scatter gun and lacking in focus and long-term strategy. Not sure their biggest concern should be the name.
1. We are wanting to expand our team. A growing customer base requires more developers. 2. Send us your resumé. 3. We have a brief sprint meeting in the morning to keep us on track. Afterwards for most developers it is open time to get things done. 4. I do not know of any developers that are not on salary, but we keep rather steadfast to keeping a work life and private life separated. 5. This is hands down the best company I've ever worked for. 6. As mentioned above, our project is pretty hush-hush. I can't disclose more than what we're looking for in terms of skillset. 7. We utilize open source projects (and provide full attribution) where needed, but we're working on rather cutting-edge projects, so few open source projects are applicable for our team. 8. There are no requirements for IDE or OS. Whichever tools help in getting the job done are the tools a team member can use.
As a developer who works from home and loves it, what is your policy on remote employees. If none is in place, what your is your personal opinion on it and do you see your company moving towards it? Quick pros /cons for employer Employer pros * No office space needed for that employee * In my case I am using my own computer, so company didnt have to buy a pc for me * I am in constant contact with my coworkers through skype, who are all also remote developers in a different time zone. * Might also be tax advantageous depending on state Employer cons * Person is not face to face * If person works in a different state, company may need to do something different with their taxes Employee benefits * Salary and health benefits just like any other job * Flexible hours * No commute
&gt; I thought it was way easier than Maven. I don't, but that's probably related to how log SBT has been around. Using SBT reminds me of the Bad Old Days when Maven was new-ish in the early-to-mid 2000s. There's no or very little IDE support, and as such, SBT's almost-but-not quite-Scala DSL isn't very discoverable. With Maven, even though I *loathe* XML, I can hit crtl-space when editing a POM and see what options I have. I recently needed to copy a file to a slightly non-standard location as part of the build for a project I was working on. The project is built with SBT - it's Scala.js, so it has to be :( . With Maven, this would have been an enormous PITA. With SBT it was a similarly enormous PITA, just different. The solution ended up being "simple", but figuring it out from the available docs was not.
I ported a large Java app that was built with Spring over to Scala bit-by-bit. During that time, the app used Spring to wire up Scala and Java classes, as well as do basic configuration. This all worked just fine, but once the porting was done, there wasn't much need for Spring, so we took it out. App wiring was more easily expressed in a Scala. Config management too. Since you're just starting out, don't get hung up on a particular lib; they're a dime a dozen, and come and go rapidly relative to the scale of your career.
FTA: &gt; Looking for a Scala developer in or wanting to move to Seattle I think your conceptions of remoteness are very off base. There is close to zero benefits for the company to have remote employees, and the few companies that allow this will usually only permit it for employees who've been at the company for a while and have earned some merit. More specifically: &gt;No office space needed for that employee Pretty much never an issue. &gt; In my case I am using my own computer, so company didnt have to buy a pc for me For legal and security reasons, companies will usually require you to use company owned gear. &gt; I am in constant contact with my coworkers through skype, who are all also remote developers in a different time zone. That's not a pro, that's a con. You are missing out on a lot of essential chatter that happens within the confines of the office and you are forcing your coworkers to use Skype or whatever whenever they need to talk to you. The bottom line is: if you really want to be using a certain technology, be ready to compromise and to relocate. At least until you've proven yourself. 
To be clear I wasn't asking if they would consider me for a remote position at this company. They said ask them anything, and I was curious about their thoughts on remote work as it becomes more popular and just wanted to spark discussion. Noted about your opinions but where I work, the entire development team is remote. Every brick and mortar company I've been at has had some sort of chat instant message program. The company I'm at now uses skype, so being remote isn't forcing anyone to use it. In my career experience I can attest that there are times being in house with the team is valuable but the other 90% of the time everything can be handled through the internet.
Is this a presentation you can, or would be willing to, share?
I suppose it depends what you're trying to do. I work on a large Java application that uses an Ant build with multiple modules, a non-standard file layout, and no dependency management. Even with no more than a very basic knowledge of sbt I was able to get it all working in a few hours (most of which involved finding repos for the hundred or so jars that were sitting in the project). I never got Maven working at all.
What methods does it not belong on?
The Functor and Monad methods, like `map` and `flatMap` are the most commonly cited example. `map` and `flatMap` have well defined definitions that don't include fundeps like `CanBuildFrom`. In addition, instances of `CanBuildFrom` violate the algebraic laws those methods are expected(by some) to maintain. Like how the `CanBuildFrom` instance that represents the natural transformation from `List` to `Set` violates the second functor law `map` is expected to uphold. EDIT: I should clarify that `CanBuildFrom[List,Set,T]` doesn't really represent a natural transformation because `Set` is not a Functor to begin with.
I often see people hosting presentations on github, though I know nothing of the processes to author those presentations.
On mobile but had similar thoughts. Let's compare notes.
&gt; This is all you need to specify a different configuration file for your test environment. This is really useful because you can just copy conf/application.conf, and change the database credentials to match your test environment, and it will automatically be picked up when your tests run For the record, you can use `include &lt;file&gt;` statements in HOCON to avoid needing to keep everything else in sync manually. My current pattern tends to be making a `local.conf`, file that my `application.conf` includes, containing all the sensitive and user-specific stuff (API keys, db config, etc).
:)
Thanks! 
What would that look like in Maven? It looks like a lot of the complexity there is because it's doing a lot of file manipulation to "build" css/js.
This library should add play json for a serialization/deserialization piece. I used this a bunch for ingestion scripts in an ETL project. Super awesome nice work!
/u/stonecolddevin, iSOcH wants to send you a Bitcoin tip for a donut (1,517 bits/$0.35). Follow me to **[collect it](https://www.changetip.com/collect/847172).** -- [^^what ^^is ^^ChangeTip?](https://www.reddit.com/r/changetip/wiki/tipping-on-reddit)
Ahh. Sounds much more advanced than what I was working on haha. My stuff is just toy Scala then. My hypothesis was that you could strip away some of the complexity of CBF and make a simpler, slightly less powerful, but easier to understand version. Still TBD on that.
if was going to move to seattle wouldn't want to do scala :\
Timezone?
Nice tool, it's simple but it does the trick for certain JSON structures.I did try it with one of our JSON response that I get with one of our internal web services, and the case classes generated here would not compile due to them having more that 22 constructor arguments. You can chalk it up to a bug ;) : case class SubscriberData( MSISDN: String, IMSI: String, STATE: String, AUTHD: String, NAM: String, IMEISV: String ) case class PermSubscriberData( OBR: String, SOCLIP: String, TS22: String, TS11: String, BOIEXH: String, SOCFB: String, SOCFU: String, OFA: String, SOCFRY: String, SOSDCF: String, MPTY: String, HOLD: String, SODCF: String, TS21: String, CAW: String, CLIP: String, TSMO: String, SCHAR: String, REDMCH: String, CFU: String, SOCB: String, PWD: String, OBO: String, CAT: String, BAIC: String, SOCFRC: String, CFNRC: String, BAOC: String, BOIC: String, CSP: String, DBSG: String, CFB: String, CFNRY: String ) case class LocationData( vlrAddress: String, mscNumber: String, sgsnNumber: String ) case class QualityOfService( APNID: String, PDPADDRESS: String, EQOSID: String, VPAA: String, PDPTY: String, PDPID: String ) case class HlrResponse( subscriberData: SubscriberData, permSubscriberData: PermSubscriberData, locationData: LocationData, qualityOfService: List[QualityOfService] ) case class R00tJsonObject( HlrResponse: HlrResponse )
Is the work office in Seattle or Bainbridge Island? A ferry every morning might be a bit annoying. 
It was written by one of the publisher's colleagues... should I explain any further? -_-
We are on CST and AST, but work with developers from all over really, so as long as the candidate is flexible, timezone shouldn't be a big problem.
By local, what exactly do you mean? Siberia or Venezuela? What's wrong with Namibia?
Interesting to see Rich Hickey on there.
The work office is in Seattle.
I logged in via twitter &amp; was able to see beyond 10 people, &amp; same with articles tab. Nothing beyond 10 till you login. Would have liked a magazine view better though, or more ways to sort etc the people, select multiple, &amp; then see only their articles, or see relation between the community. An API to access their graph will be been fun.
Apologies for problem you faced. but cookies is enabled to avoid relogin. &amp; currently only twitter/linkedin/fb login is supported. Would talk to the team to provide a full list view for reddit. cheers, 
I was not aware of the 2.11.1 fix, thanks for pointing that out. Cheers!
Nice. There's a similar post about a [type-level selection sort](http://milessabin.com/blog/2012/01/27/type-level-sorting-in-shapeless/).
Slideshare, speakerdeck.
You can perform those side effects with a future's foreach method. Personally, I think it's also an easier API in every way imaginable, compared to Threads. I don't think anyone recommends using Threads in scala. I'm trying to think about what you might be missing, and out of context it's hard. My gut says you want a way to perform some type of join that isn't reasonable with flatMap, and haven't spotted the functions available in [Future's object companion](http://www.scala-lang.org/api/2.11.5/index.html#scala.concurrent.Future$)? Using Future.sequence gets the job done. The type looks complicated, but M is a traversable, so... val futureFoos : List[Future[Foo]] = ... val howToJoin : Future[List[Foo]] = Future.sequence(futureFoos) // what I'm guessing you wanted. So if you can't get your computations done with map/flatMap, your side effects done with .foreach, and joins done with that, you'll have to reply here and be more specific.
That's a false dichotomy. The concept of futures and threads are orthogonal. A future may run asynchronously on a different thread, or asynchronously on the same thread. This is governed by the ExecutorService passed to the future, usually through an implicit.
Very interesting but for some reason I can't see the code examples very well. The format looks messed up.
 &gt; I don't think there's ever a case where you'd prefer a Thread over a Future (or alternatives, such as the ones found in scalaz-concurrent). When you work with legacy code you need to start something in a different thread(from the ui thread) and probably you can't stop it from the outside...
That's twitter messaging which makes everyone suspicious, but actually we never initiate any posts. The write creds are taken because users shares numerous posts from our platform to Facebook, LinkedIn &amp; twitter which requires write creds. ALL Posts are ALWAYS user initiated. 
I had thought of case classes, and that immutable classes with fields can be created in a single line. Would you theorize that Akka isn't really designed for Java usage? edit: I wish I knew enough Scala to be comfortable introducing it at work. 
You may want to have a look at the [Akka Distributed Domain Driven Design with CQRS](http://www.typesafe.com/activator/template/akka-dddd-cqrs) template for Typesafe Activator. It takes good advantage of Akka Persistence and Event Sourcing. Relatedly, see [Eventuate](http://rbmhtechnology.github.io/eventuate/), but be aware that it's early access. Finally, see Debasish Ghosh's [Functional and Reactive Domain Modeling](http://debasishg.blogspot.com/2014/11/functional-and-reactive-domain-modeling.html) and maybe [follow him](https://twitter.com/debasishg) on Twitter and get to know him. In addition to being brilliant, he's a really nice guy. To be perfectly frank, though, my bet is that you have big cultural issues, rather than technical ones, to overcome. A shift is required, whether it's from OO to FP or OO to dataflow, e.g. with [Akka Streams](http://blog.michaelhamrah.com/2015/01/a-gentle-introduction-to-akka-streams). If you're experiencing "bugs, race conditions, etc." then something is definitely amiss, and it's worth some hard pulling back to ask how to get more benefit from Akka. Two more things to consider: 1. Professional Akka training. Probably especially valuable for a Java team. 2. Transitioning to Scala. I won't sugar-coat this: both Java-the-culture and Java-the-language are problems. What you can realistically tackle, when, is going to be hard to answer. But at least think about it (which it seems you are). Good luck, and please don't be shy with more questions!
Thank you for the articles and information; it'll probably take me some time to get through those resources, but as I have questions I'll let you know! &gt; Professional Akka training. I'll have to look for it, and I could probably even expense it to my current employer. &gt; I won't sugar-coat this: both Java-the-culture and Java-the-language are problems. I strongly agree, and could probably rant for some time on that subject. I've read 2 scala books, but just haven't had the time for hands-on yet. I'm undecided whether next-steps should be attempting to build an App with Scala, or doing the Corsera class. I'd almost take a pay-cut to join a Scala team that was willing to mentor me. I have noticed that the majority of innovation in the JVM world right now seems to be written in Scala. My goal for this next-year is to learn Scala and C++ on a level I feel comfortable using in production.
From what I've read, a lot of scala shops are moving away from using akka actors for everything. Actors are a great way to manage in memory state and remoting. It's worth the extreme verboseness and giving up type safety in these situations. In other situations it isn't, and futures with callbacks are used instead. In my own project I replaced akka actors with futures and saw a greater than 75% code reduction. I've seen other open source projects going on the same direction. Does Java have futures with callbacks? 
Ya I really am liking Akka cluster for an in memory work sharing dealio I am using it for. Tried it for other stuff and ripped it all out. But happy with the cluster part ;)
&gt; import java.util.concurrent.Future Futures are Java concepts.
Learning both C++ and Scala on a production level in a year is certainly quite ambitious.
Despite of whatever you choose to use to gain experience with Scala, I suddenly suggest you also read the book Functional Programming in Scala. It is an amazing book, with many exercises that will help you learn functional programming (won't teach you a lot of Scala though).
&gt; This results in code that is quite difficult to debug, test, navigate, refactor, and reason about. Our previous Akka-application had all of these issues, along with bugs, race-conditions, etc. We just started another new application, and I'm seeing the exact same patterns &amp; it's making me want to scream. It's not just you. Every Akka-based prototype we've built at my work has ended up the same way. (All of these were written in Scala, so it's not Java's fault if that's what you're using.) Even the tiny Akka-based assignment in the almost-finished current iteration of the [Reactive Coursera course](https://www.coursera.org/course/reactive) led to code like you described. Akka actors give you a nice way to turn asynchronous calls into an ordered application of operations. This is a nice way to wrap and access mutable state, and a big step up from low-level locks and synchronization. The remoting and supervision features are also really, really cool. But the downsides are huge, at least for all the projects I've tried Akka on. You give up type safety in lots of ways that matter; actors end up behaving like Smalltalk objects. become() is clever but in addition to being mutable, ends up spreading related logic around in ways that make it hard to reason about your program. After writing Scala in a functional style for years, using Akka feels like a big step back: it's mutable all over the place, more or less untyped, and I end up spending much more time thinking about and writing *how* to do things, instead of *what* to do. This is in contrast to the benefits I've seen from using functional APIs in Scala generally: with those, I spend much more time expressing *what* I'm doing than *how*.
&gt; Even the tiny Akka-based assignment in the almost-finished current iteration of the Reactive Coursera course led to code like you described. I would politely disagree with your assertion that actor spaghetti is the inevitable outcome, both in general and in that particular assignment. Everyone's mileage will vary, of course, but my impressions were different. My solution wasn't as elegant as solutions for previous assignments, true. But I'd suggest this assignment boasted a *much* higher complexity and is a decent approximation of real-world dev problems. So while my solution doesn't feel elegant at the line-by-line scale, I am impressed by its *efficiency* in a "features per line of code" scale. e.g., I imagine you *can* do periodic-retry-with-timeout with futures/callbacks, but I don't expect you could do it as concisely. To be fair, it took me a few tries and some face-palming to get where I wound up, but this is not a surprise in a learning environment. What I took away from the course was this: when designing with actors, there are non-intuitive ways to reshape the problem that will yield much better code. Patterns like "actor per transaction" and "coordinating actors" were concepts that wouldn't have occurred to me naturally, but now that I've seen them it's a bit of a lightbulb moment. I think the natural first approach to actor systems is to think in terms of only long-lived, concrete actors that break up work like other design paradigms, which often leads to actor spaghetti. But I've come to see this approach is not the end-all of actor design. I don't feel like actors are the tool to solve all problems, by any means, but neither should they be cast aside. There are some important strengths here for the right applications.
Yes, but I'd say that type level quicksort was quite a bit more challenging than type level selection sort.
A future is an abstraction over threads. Maybe if you need more fine-grained control? In general I'd keep with Futures until they don't work.
&gt; scala shops are moving away from using akka actors for everything. That's quite interesting. &gt; Does Java have futures with callbacks? Somewhat. There are Futures in Java8, but they're not quite as clean or native as what I've seen in Scala.
What do I gain for using a Task? It looks like it gives me finer grain control over the execution model at an expense of a slight increase in complexity. But I haven't really read into it much yet.
&gt; Does Java have futures with callbacks? Futures have been pretty much obsoleted by RxJava in Java these days, which does the job much better and has the benefit of seamless composition. 
Personally I find Task as pointless, for 2 reasons 1. Scala already provides semantics to deal with construction vs execution in this context. Its called `val` vs `def`. You can just as easily create a `"Task"` using a `Future`, you just do `def f: Future = ...` 2. Future is part of stdlib, and its basically used everywhere apart from the few places where scalaz is used. For something as central as control flow of asynchronous code, you really don't want to be using something that ins't part of stdlib unless you absolutely have to. Note that if `scalaz-stream`/`Task` wasn't part of `scalaz`, this would be much less of an issue Something like `Task` makes more sense in Haskell, where everything is lazy by default. However in Scala, everything is strict by default, so in this sense, `Future` is much closer to being idiomatic Scala than `Task` is. Its also much more battle tested 
In regards to the stdlib comment, it becomes more significant the more libraries that you use. I have had many issues regarding library incompatibilities, and being unable to upgrade due to some library down the chain depending on `scalaz` Thats the PoV I am coming from, if something is bound to be used very often, it is going to be used very often, and that should be part of the stdlib, thats how you get good interoptarability
Hah, I get yelled at any time I create something even slightly interesting, no matter how clean and simple. I understand the "libraries are supported" argument, but I also often find libraries are often poorly documented, break easily, take a bit of time to learn, often require significant debugging and testing to use properly, and may not be designed well for the problem at hand. My greatest annoyance however is, how is anyone ever supposed to learn or become good at creating things if they're never allowed to create? Though when there are challenging or creative problems, I often find myself ~20x as productive.
Just want to +1 this comment. I know many projects that bought into the "use actors everywhere" philosophy and regretted it. Actors are fine as a low level tools for managing state and concurrency in small parts of your code base. I wouldn't expose them as a module level API though. Futures, scalaz-streams, or Akka streams are better tools in most situations. I'm not sure where this leaves you as a Java shop -- perhaps JavaRx mentioned in this thread is the moral equivalent of the stream abstractions in Scala.
You always can do Try(Enum.withName("foo")).toOption . I think is more clean solution. 
@fsloki that is a valid alternative but you are still relying on exceptions underneath. Exceptions are a bad principle since they break code execution and just make it jump to some place where they are caught. I think they should be avoided and replaced by cleaner solutions such as Eithers to return errors.
I could've sworn `Enumeration` was deprecated. I don't think I've ever used it in Scala code.
"Play 2.4 gives you more modularity and flexibility. Or you can embed it in another application" Newbie here. I have a requirement to use jboss as a server, but have no tendency to use Spring/whatever. Does modularity gives a sane way to use Scala and Play in such environment?
Why do people still require jboss in this day and age? I am really at the loss for a valueadd.. As to your question.. I know this worked for play 2.3: https://github.com/play2war/play2-war-plugin/ It may need an update to support 2.4? Or maybe the built in stuff is enough, I am not sure.
Ok that's also an idea. I think they have their purpose for simple use cases and a withName returning an Option would be a good idea.
In case it wasn't clear, the theme is intended to look like the website, www.scala-lang.org
Despite the accuracy of your them (great job, by the way), I'm not wild about that green highlight used for buttons. I figured the "cyan and red" Typesafe theme would have been a better bet. Which ironically looks like Fring out of the box.
Is this more what you had in mind? http://www.reddit.com/r/joshlemer_themes/
Nice effort, but needs work if looking to approach above examples. Maybe max out the Typesafe logo and stick it right column /r/rust style? Oh, just noticed Typesafe has a new (to me) [website](http://www.typesafe.com/) with a new logo. Hmmm, well, whatever they're going to change the company name, Akka's getting types, Scala's getting overhauled with Dotty, everything's changing ;-)
I'm cool with the green for the buttons, it's the soft red for submit links that seems off; would prefer something safe like a dark blue, or maybe, as you say, Typesafe red, matching ~~the logo~~ (which has apparently changed o_O, see my reply to [predef](http://www.reddit.com/user/predef))
Yes, you are right. For me withName should return Option or they should provide different method in Enumeration class. Maybe it will be nice to make some ticket for that in scala repo? 
Like https://github.com/aloiscochard/enum-paradise?
You can already do arithmetic on `Nat` in Shapeless, but maybe you mean something I'm not seeing. You might also want to check out [refined](https://github.com/fthomas/refined).
I've just been calling them "variables". I know `val`s cannot vary. People know what I'm talking about anyway. Another term I've used is "names" or "identifiers". e.g. "Find the places where this identifier is used and rename it" or "Use longer names for identifiers in wider scopes but shorter names for identifiers with narrow scopes". This applies to `def x = ...` too whereas "variable" does not
I love Scala, but am wondering if it's the right career move for me, or if I should focus my energies elsewhere. Due to being rather busy, I just haven't had enough time &amp; energy to start a Scala side-project. That said, I'd absolutely love to learn it on the job, hands on, as part of a team with more experienced Scala-developers. I'm presently seeking a new job, but don't know if I'd stand a chance of landing a job at a Scala shop. I'm also curious as to the long-term career implications, weighed against other options. I doubt it would be worse than remaining as a Java-specialist, but I'm wondering if it's any better. For example, many of the more 'mathematical' job listings I see tend to be C++. Even if it's a clumsy language, the problem space would be more interesting and challenging than web. I'm also curious how the culture and daily work differs. My greatest gripe about Java is the culture opposed to creation. I only ever do two things: 1. implement business logic, and 2. wire together apis/libs. Now, I've created interesting, creative, challenging side projects in Java, but almost never on the job. Now, when creative tasks DO appear, I see many senior/architect, highly educated, well paid Java engineers unable to tackle problems which I consider simple. My worry with going the Scala direction, is that even if the coding is nicer, and productivity is higher I might still be stuck the same boring web+business logic.
Binding. They bind a name to a value. This is the term typically used in the programming language literature.
Just addressing jobs, they are lots, with a bias towards more senior engineers. We've started listing some at http://underscore.io/jobs/ Bit short on time right now. Might return and comment in more depth later. 
The training on that website looks interesting; since I have some time today I'll look through it.
&gt; My worry with going the Scala direction, is that even if the coding is nicer, and productivity is higher I might still be stuck the same boring web+business logic. You might be, as some amount of boring stuff is the norm for almost all professional developers regardless of language used. But given that, wouldn't you want your workday language to be as pleasant as possible? A big upside to Scala for me is that it made programming fun again. The language is a pleasure to use, and if you're coming from Java (or Python, etc), there's a ton of new things to learn, which I really enjoy. (Of course, you can keep using the strategies and paradigms from Java-land, too.) But all that learning comes with a cost: it's tough to go back to Java after programming in Scala for a while. (Even Swift feels anemic, feature-wise, after spending time in Scala.) Out of 7 or 8 colleagues who've switched from Java to Scala, only one has gone back voluntarily, and he's in a management role and barely codes anymore.
"identifiers"
FP in Scala is a fantastic book! Thanks for reminding me about it. I was looking more for something I can sit down and read as a book but with more emphasis on code than traditional programming books; exercises imply sitting at a computer to play with it.
There is [Scala By Example](http://www.scala-lang.org/docu/files/ScalaByExample.pdf).
That sounds inticing, if you do, please share! I hope to notice it when you do (I'm not much of a reddit regular)
This looks like it's the closest to what I'm looking for. Appears as if there's code on just about every page after the obligatory intro stuff. Helps that it's written by Odersky too. Thanks!
Mods have a little console where they can edit the stylesheet of their subreddit, and upload assets like spritesheets and other images. It would be simply a matter of copy pasting some text and uploading 2 images. I'm still not sure if I like the green buttons more or the red buttons. Maybe that's what the vote could be for. Also the upstream Fring theme is under active development so I'll have to keep merging in their updates. Just as a FYI before anything gets set in this sub. The mods seem to be still active, but haven't posted since before this post so we'll see when they get back.
ElasticsearchClientUri("10.0.5.12:9300") Is 10.0.5.12 your ip? It looks like you're actually 10.0.2.15 from the elasticsearch logs you gave: ```... [Gigantus] bound_address {inet[/0.0.0.0:9300]}, publish_address {inet[/10.0.2.15:9300]}``` If that wasn't just a typo, that could be the culprit. Are you using the same version of elasticsearch inside your app as you have running locally?
Good article, was just thinking about this very topic today. Does anyone happen to have insight on if there actually are optimizations that relate to private, immutable, and in this case final members/classes?
Just use plays macro for that 
Good article! What happens when new cases are added to an ADT and code compiled against an older version of the ADT is used alongside the new version of the ADT? Also, the lack of exhaustiveness check in: sealed trait Base final case class SubtypeOne(a: Int) extends Base final case class SubtypeTwo(b: Option[String]) extends Base SubtypeTwo(Some("oops")) match { case SubtypeTwo(None) =&gt; "Yeah!" } is explained by: &gt; * SubtypeTwo is not sealed; &gt; * therefore the compiler cannot guarantee it knows everything about SubtypeTwo (there could be subtypes defined in another file); and &gt; * thus we do not get exhaustiveness checking. But changing the code to sealed case class SubtypeTwo(b: Option[String]) extends Base ~~does not lead to a compiler warning either~~ (see noel's reply below). Also, &gt; You might argue that the compiler should give us a warning about the None case here, since Option is sealed, but doing so would give unpredictable behaviour in general – we would sometimes get the checking and sometimes not depending on how exactly we defined our types and matches. It’s much better to have predictable semantics than to build a more complicated system that leads to surprises noel or someone else here, please describe examples where the compiler is unable to make such exhaustiveness checks?
I think what Noel is saying is one wouldn't have a method signature of foo(n:None) rather we would use Option - foo(o:Option). Another example would be declaring a value, we'd use Option, rather than one of it's suptypes: val foo:Option = ??? over val foo:None = ??? // It can only be None! 
What /u/jonoabroad said is correct. When you define an algebraic data type sealed trait Base final case class Foo(a: Int) extends Base final case class Bar(a: String) extends Base you should almost always just refer to the `Base` trait when you declare types, not the subtypes. Some good reasons: * to ensure you get exhaustiveness checking * to avoid issues with invariant type classes and invariant containers like `Future` * it's often just doesn't make sense to declare a subtype (why would a method ever declare return type as `None`?)
We ported a lot of code from java to scala at work, and had as our main rule that scala calls java, java does not call scala. This implies starting with the outermost layer, typically controllers for a webapp, and working yourself inwards. We also kept «java friendy» APIs between modules within the systems, which means no type bounds, implicits, scala collections, etc. Only after migrating all the code did we rewrite module boundaries to use those features. That way, we never had to know anything about «$» :)
There are two JQUERY libs, one is more strongly types and less complete, one is more complete and has Anys all over.
Binding is more broad, though. def f(x: Int) = { def f(x: Int) = {...} ... } In this snippet I have two bindings for the symbol x...but also two bindings for the symbol f. Neither binding is introduced with the keyword "val." Which binding is in scope depends on lexical location. Also, in an imperative language "binding" isn't the relation between a symbol and a value. It's the relation between a symbol and its "meaning." For an immutable variable that's not much difference. But for a mutable variable, the meaning is, conceptually, more or less a location in memory. var x = 0 x = x + 1 x = x + 2 Here x takes on many different values, but never changes bindings.
Dependency injection needs to die already.
Not only have you hit the nail on the head, you've hammered it flush in one stroke ;-) Really, macros open up an *accessible* world of compile-time programming opportunities for Scala developers. If ScalaMeta brings a cleaner/simplified API, I'm all for it. IDE support needs to catch up, but progress has been made (believe Scala IDE latest release ships with macro support). Otherwise, down the road Dotty should at least lead to improved tooling and compile times, so perhaps type level programming will be less painful in future.
What's so bad about this? It's just using classes and constructors the way they were meant to be used, which I think is both better than everything being static objects, and better than cake and runtime DI.
It's a little more tricky, as the Routes constructor is generated dynamically by Play (at compile time) depending on the controllers referenced in the route file. Before that the default method was to define a Scala object yourself for each controller (and this object could extend some class with some constructor parameter of course). 
:-) https://www.typesafe.com/company/news/typesafe-recognized-in-three-gartner-hype-cycle-reports http://www.itnews.com.au/News/390837,vendor-sues-gartner-over-8216pay-to-play8217-magic-quadrant.aspx
What would you use instead?
A penny for your thoughts! 
I know this is a short notice, but how goes it? :)
Completely agreed, I am actually against the movement of trying to push further and further into type level programming, I actually think that Scala is pretty much hitting the limit of how far you should delve into type level programming. My personal main points are - Really abstract, weird and complex error messages. Having done Haskell in the past, I think a lot of people can sympathise with the pain of getting some completely weird error message that you have no clue what it means, especially when you are using someone elses library and they decided to use abstract term - Using macros actually helps keep the compiler clean. The more type abstractions you put into the compiler, the more weird corner cases you start hitting/creating. Not only that, but its antithetic to providing a stable compiler for a sane period of time. Again similarly to Haskell, don't want scalac to go back to the old days where the scalac breaks every 6 months because someone wants to push their new Keleisi abstraction into the tree - A lot less magic (tm). Types are fantastic when there are very few levels of abstraction. What that may mean can vary from person to person, but when you there are certainly limits where the abstractions get too much. You then end up reading code which is very succinct, and you can kind of get what its doing (usually only because you have some preconceived notion of what the code is meant to do, i.e. its a library for something), but you have very little clue as to how its actually the code (and ending up having to figure it out usually means reading some obscure PHD paper in PDF format).
It turned out to be a lot more work than I expected, but I'm getting there. Still taking a while, though :/
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Tom, Dick and Harry**](https://en.wikipedia.org/wiki/Tom,%20Dick%20and%20Harry): [](#sfw) --- &gt; &gt;The phrase __"Tom, Dick and Harry"__ is a [placeholder](https://en.wikipedia.org/wiki/Placeholder_name) for multiple unspecified [people](https://en.wikipedia.org/wiki/Person); __"Tom, Dick or Harry"__ plays the same role for *one* unspecified person. The phrase most commonly occurs as "every Tom, Dick and Harry", meaning *everyone*, and "any Tom, Dick or Harry", meaning *anyone*, although [Brewer](https://en.wikipedia.org/wiki/Brewer%27s_Dictionary_of_Phrase_and_Fable) defines the term to specify "a set of nobodies; persons of no note". &gt;Similar expressions exist in other languages of the world, using commonly used first or last names. The phrase is used in numerous works of fiction. &gt; --- ^Interesting: [^Tom, ^Dick, ^and ^Harry, ^Rock ^Again!](https://en.wikipedia.org/wiki/Tom,_Dick,_and_Harry,_Rock_Again!) ^| [^Tom ^Dick ^and ^Harry ^Mountain](https://en.wikipedia.org/wiki/Tom_Dick_and_Harry_Mountain) ^| [^Tom, ^Dick ^and ^Harry ^\(1941 ^film)](https://en.wikipedia.org/wiki/Tom,_Dick_and_Harry_\(1941_film\)) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+crzbxa2) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+crzbxa2)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I'm 12 and what is this?
Why everything has to be about gender these days is beyond my knowledge :-/ Good read though. Really makes me want to go back and learn some math :)
jeeze, did everyone but me already know there's an apache commons simplex solver? http://commons.apache.org/proper/commons-math//apidocs/org/apache/commons/math3/optim/linear/SimplexSolver.html
Its an optimization problem. In olden times this was called "operations research" http://en.wikipedia.org/wiki/Linear_programming
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Linear programming**](https://en.wikipedia.org/wiki/Linear%20programming): [](#sfw) --- &gt; &gt;__Linear programming__ (__LP__; also called __linear optimization__) is a method to achieve the best outcome (such as maximum profit or lowest cost) in a [mathematical model](https://en.wikipedia.org/wiki/Mathematical_model) whose requirements are represented by linear relationships. Linear programming is a special case of mathematical programming ([mathematical optimization](https://en.wikipedia.org/wiki/Mathematical_optimization)). &gt;More formally, linear programming is a technique for the [optimization](https://en.wikipedia.org/wiki/Mathematical_optimization) of a [linear](https://en.wikipedia.org/wiki/Linear) [objective function](https://en.wikipedia.org/wiki/Objective_function), subject to [linear equality](https://en.wikipedia.org/wiki/Linear_equality) and [linear inequality](https://en.wikipedia.org/wiki/Linear_inequality) [constraints](https://en.wikipedia.org/wiki/Constraint_(mathematics\)). Its [feasible region](https://en.wikipedia.org/wiki/Feasible_region) is a [convex polytope](https://en.wikipedia.org/wiki/Convex_polytope), which is a set defined as the [intersection](https://en.wikipedia.org/wiki/Intersection_(mathematics\)) of finitely many [half spaces](https://en.wikipedia.org/wiki/Half-space_(geometry\)), each of which is defined by a linear inequality. Its objective function is a [real](https://en.wikipedia.org/wiki/Real_number)-valued [affine function](https://en.wikipedia.org/wiki/Affine_function) defined on this polyhedron. A linear programming [algorithm](https://en.wikipedia.org/wiki/Algorithm) finds a point in the polyhedron where this function has the smallest (or largest) value if such a point exists. &gt;Linear programs are problems that can be expressed in [canonical form](https://en.wikipedia.org/wiki/Canonical_form): &gt;==== &gt;[**Image**](https://i.imgur.com/CjsVdcV.png) [^(i)](https://commons.wikimedia.org/wiki/File:Linear_optimization_in_a_2-dimensional_polytope.svg) - *A pictorial representation of a simple linear program with two variables and six inequalities. The set of feasible solutions is depicted in yellow and forms a polygon, a 2-dimensional polytope. The linear cost function is represented by the red line and the arrow: The red line is a level set of the cost function, and the arrow indicates the direction in which we are optimizing.* --- ^Interesting: [^Successive ^linear ^programming](https://en.wikipedia.org/wiki/Successive_linear_programming) ^| [^GNU ^Linear ^Programming ^Kit](https://en.wikipedia.org/wiki/GNU_Linear_Programming_Kit) ^| [^Nonlinear ^programming](https://en.wikipedia.org/wiki/Nonlinear_programming) ^| [^Hilbert ^basis ^\(linear ^programming)](https://en.wikipedia.org/wiki/Hilbert_basis_\(linear_programming\)) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+crzihr7) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+crzihr7)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
How does this compare to JOOQ (it is Java, but has nice [bindings](http://blog.jooq.org/2011/12/11/the-ultimate-sql-dsl-jooq-in-scala/) for Scala)? [edit]I just now noticed that you are aware of JOOQ (and discovered anorm. Thanks :) . What did you solve that aware/JOOQ cannot offer?[/edit]
 That bindings seem to be nice! I've worked with jooq at my java-time and I've enjoyed it. Mostly jooq and anorm inspired me to create pocket-sql. I think the advantages of pocket-sql over jooq: 1. Easy start; 2. Scala's wonderful features and type system which can enhance it further and make it possible to use the implicit- and macro system; 3. Rich entities(will be enhanced and shortened soon); 4. No DSLs just SQL generation by standards -based on mostly SQL 1999 but can be overridden(StandardSqlDsl); 5. FREE to use with any compatible RDBMS.
Somebody's found religion.
I didn't downvote you and I agree with you that we should be more welcoming to women in our profession, but that story is just not about gender at all and it's only four people, so it doesn't really matter. Your question is like "Why is there no vegan?".
Hm, I came from a math background and I like to code. :)
To be truly representative the article should have been written in a mixture of languages, with Chinese being the most common. We also need to consider the religious beliefs of the candidates. Are any of the candidates Hindu, Buddhist, Scientologists, Muslim or atheist? Were the Amish represented? What about members of the flat earth society? How about race? Were any of Tom, Dick or Harry disabled? Vegetarians? What about country of origin? Did a representative portion of the candidates come from African countries or South America? Were there a mixture of short and tall candidates? What about different levels of education and wealth? Gender and diversity are important - I don't think anyone here would disagree with that, but trying to pull it into this discussion was just silly. Everybody recognized the names for what they are - meaningless placeholders. 
I BET NONE OF THEM TALKED ABOUT THE FACT THAT NO AVERAGE GUYS CAN USE SCALA platform AND THAT ITS A COMPLETE FAILURE EXCEPT FOR THE ILLUMINATI FUNDED CORPORATIONS.
You know ridiculing it cheap.
Is telecommuting possible? The drive from Denver is tough.
You say you're using play, but your error says you're using jackson. Which is it?
It must be! I couldn't even find "Demver" on the map! /s
It seems Scala opportunities everywhere in North American and Europe, however nothing in Australia :-(
 val array = Array(1, 2, 3, 4, 5) val median = array.sortWith(_ &lt; _).drop(array.length/2).head is the simplest way I can think of 
Does that work with an array with even number of items? val a = Array(1, 2, 3, 4) Median here would be 2.5. I guess it depends a bit on what the OP is looking for.
If spending time to sort the whole array is OK for you, it's easy to finish the idea: val initialArray = Array(1,2,3,4) val sorted = initialArray.sort // assume the array is non-empty val median = (sorted(array.length/2) + sorted(array.length - array.length/2)) / 2 // return the rounded median
I like that Underscore is quite active in posting Scala blog posts. On a related note, the excellent teacher, eed3si9n, posted a tutorial on learning cats - http://eed3si9n.com/herding-cats/.
`head` is unsafe. It should not be used - http://stackoverflow.com/a/23184020/409976.
obligatory note about integer overflow
As I recall, Cats is less ambitious than scalaz. That is, it probably won't offer all the typeclasses, operators, and even whole subsystems that scalaz does. I found Stew O'Connor's [blog post](http://stew.vireo.org/posts/state-of-cats/) I thought I recalled. That does a much better job than I can.
You can find some background [here](http://stew.vireo.org/posts/state-of-cats/). I'm not going to try to interpret it for you. For me Cats is both technically and socially superior to Scalaz. YMMV.
I believe there is a plan to migrate `algebird` to the `algebra` project on which Cats depends.
&gt; How about the interviewer being female? Unimaginable? How would that matter if all three candidates are still male? Tom, Dick, and Harry could be pseudo-nyms for Suresh, Malik, and Donghai for all you know. It's just as likely as not in IT these days. it wouldn't change the gender of the applicants either way though.
Nope, I missed it too. The last time I came across a problem like this, we dealt with it using constraint programming using [JaCoP](http://www.jacop.eu/). There are subtle differences between CP and mathematical programming though: http://www-01.ibm.com/software/integration/optimization/cplex-cp-optimizer/mp-cp/ Seriously, I would like to be at a point where I can consider these problems to be trivial job interview fodder. That blows my mind that anyone would.
 You can try this for your example: (0 to 4).slice(2, Integer.MAX_VALUE) Or define pipelining: final implicit class PipeLine[A](arr: Array[A]) { def |&gt;[B](f: Array[A] =&gt; B) = f(arr) } (0 to 4).toArray |&gt; (a =&gt; a.slice(2, a.size)) |&gt; (_.length) 
The idea that naturally everyone is male is what I find irritating. But I guess that's Scala culture. Have a look over at Twitter and #scaladays, 99.7% mostly white dudes. I think there are other programming cultures which are a bit more aware of the gender problem.
Finding the index of the median, and I'd like to make sure the median and not the mean is what you're looking for (comments have made me uncertain), isn't too bad: length / 2 for even-length arrays, and (length + 1 ) / 2 for odd-length arrays. val arr = Array(1, 2, 3, 4, 5) arr.length =&gt; 5 (5 + 1) / 2 = 3 // element 3 is the one you want val arr2 = Array(1, 2, 3, 4) arr2.length =&gt; 4 4 / 2 = 2 // element 2 is the one you want This method assumes 1-based indexes, but it's just a matter of subtracting 1 to get the actual index. This helps you avoid having to string together a bunch of methods.
I get that. I'm not sure the industry per se can really deal with it though. We get that a lot with different industries. Want to be a "nurse"? (I use quotes because that title covers a lot of different qualifications these days.) Well, men can be, but they are in the minority and they take a lot of crap if they do. It's not so different with programming in general. 
What's the point of having your examples assume 1-based indexes when Scala's Array is 0-based? The term "index of the median" is also confusing as there is no indice of a median number in an even-length array.
I think EitherT is great! you can always newtype it to provide a little easier API for your users. 
We use EitherT for this, works great. Just write some helpers/shorthands to make using it cleaner.
What's wrong with SBT?
For this specific example, you may use *drop* function instead of *slice* to avoid referencing to array. Here is api docs: http://www.scala-lang.org/api/current/index.html#scala.Array@drop(n:Int):Repr
Depends on the context. If you're outside of a programming contest, you should have chosen an appropriate integer type earlier. As they say, choose Int for numbers that are "laughably smaller" than Int-s maximum allowed.
[It is decoupled, actually](http://www.scala-js.org/downloads.html)
You've tempted me to implement this as well and you can even define PipeLine more general: final implicit class PipeLine[A](a: A) { def |&gt;&gt;[B](f: A =&gt; B) = f(a) } note that it's not |&gt; because that apparently already defined somewhere in scala land (atleast when i tested it in the console) it also allows you to do: scala&gt; (0 to 4).toArray |&gt;&gt; (x =&gt; x.slice(2, x.size)) |&gt;&gt; (_.length) res3: Int = 3 
This is the job for which monad transformers were invented, so I don't see the problem. Something like this is what I usually use: type Result[A] = EitherT[Task, MyErrorType, A] Then define things in terms of `Result` and `scalac` will be happy. If you've had issues with monad transformers I'm happy to help.
bad searching, try this suoıʇısod ɐןɐɔs :D
Very nice! Wish it was closer to the present though. Late September is a long wait.
&gt; Its build definition (.sbt files) syntax has some extremely bizarre rules For some definition of bizarre, last I checked there wasn't a common style of syntax among build tools, and it's not as if SBT is alone in the applicative builder style of declarations. Boot and Cabal are two popular build tools with similar syntax. &gt; most obviously the requirement of blank lines Hasn't been true for almost a year now. Besides are blank lines really so horrible?
Barely. That sure as hell isn't a simple API for integrating with other build systems. I remember trying to make sense of it to write a Maven plugin for it, and giving up after spending hours reading that thing's undocumented maze of code.
`scalajsld` is not.
Hmm. I definitely don't want the slowdown to occur every time I actually use the feature...presumably I can set it to only ever run completely manually? Thanks for the help!
Seems like a fairly natural extension of ScalaJS-react. Might just take a while for someone to build it.
I don't like the idea to declare variables without an special identifier because it gets harder to find out where the variable was initially declared. 
array.sum / array.size 
There's a free edx course on spark that just started by the way if anyone is interested 
Link to said course: https://www.edx.org/course/introduction-big-data-apache-spark-uc-berkeleyx-cs100-1x
All the action is on IRC (#scala) and Gitter these days. For some reason the community has migrated there.
scala-lang.org is open source -- you can and should submit pull requests! http://www.scala-lang.org/contribute/documentation.html#updating_scalalangorg
Any progress on this yet? I'd really like to see this change! 
Reddit does play a much larger role within other communities (some, like /r/Haskell, even wholesale "migrated" their community to Reddit), while most community action in Scala happens on 3-4 different mailing lists and probably a dozen of Gitter channels. That's why /r/Scala has not as many subscribers. (Another point is probably the non-existing moderation and the subsequent, constant and unfettered trolling by well-known persons in this subreddit.)
Still no word from the mods after PM'ing them the day of this post. Also no public activity from either of the mods for the last few weeks :(
Some gitter channels I hang out in, roughly from least to most project specific. Cats is possibly the most active, followed by Shapeless. * https://gitter.im/scala/scala/scala-user * https://gitter.im/underscoreio/scala * https://gitter.im/non/cats * https://gitter.im/milessabin/shapeless * https://gitter.im/http4s/http4s Outside of Reddit and Gitter, LinkedIn has a reasonably active Scala group. It has a very different feel though. Interested to hear of other mailing lists / forums / channels / etc. that are active.
Hmmm, didn't get the chance to test that, but I found a way by adding the test folder path inside the managed resources variable. I think it amounts to the same result (It getting compile). But thanks, if I ever get some other issue like that I'll try this also.
Haha, no hard feelings at all. After all this is a very opinionated question based on the industry and company size your work in.
&gt;As an aside, this also means Scala doesn't have nearly as much open source work done in it as others Play? Spark? All 50 of Twitter's hugely popular open source projects? 
This is a restricted site. In order to access this magazine, you must be an authorized subscriber.
nope avoid scala and typesafe at all costs because of the whole slick mssql/oracle thing...shady
Or.. to put it another way, yes, the /r/scala subreddit could be doing a lot better, because there's so much to work with.
I disagree with pretty much everything here and the original post. There's nothing wrong with the growth of the scala community as a whole, but this subreddit just is fairly mediocre. Content wise it's good, there's no shortage of trolls and abusive personalities in the comments.
You have misinterpreted what I wrote if you think I meant you were trolling or being abusive.
[Scala.js](https://gitter.im/scala-js/scala-js) is probably the most active compared to above list, but yeah, Cats is picking up steam fast -- looking forward to a Scalaz replacement ;-)
&gt; increasing failure to measure against newer languages do tell, outside of Haskell I'd be hard pressed to find *any language* that measures up to Scala. &gt; we hear more bad news about Scala than good news these days All news is good news ;-), if your language is not news worthy, it's dead in the water. When people stop talking about Scala I'll start getting worried. &gt; forks Two of them I believe, both dormant. &gt; big companies abandoning it Yeah, LinkedIn; they switched back to Java, Play Java that is, so they're still in the fold so to speak. Typesafe has invested heavily in Java support for their stack. When they took over Play it was more or less a pure Scala project, and now has strong Java support. Slick will have a Java API in the not too distant future. Rope them in with Java, then convert to Scala ;-) &gt; Scala just feels like old news and new languages are appearing and learning from Scala's lessons, the good and the bad, and some of them are really taking off. Swift is the only language that has borrowed heavily from Scala and has a chance of taking off (Apple + billion iThings helps a wee bit). Kotlin, meh, maybe if they achieve massive success on Android; otherwise Java 10 will kill it. &gt; I'm really curious to see what this landscape will look like in five years from now. Yes, curious as well. In @3 years Dotty will be making its way into the Scala ecosystem, and in @4 years we'll have Java 10. Microsoft should by then be well positioned on *nix. Oh, and Haskell will probably have an IDE.
Why are you browsing a scala forum then? You should start by taking your own advice.
I fully agree that the documentation on scala-lang.org is probably the biggest issue for adoption. It is simply disastrous.
I think it's a good book, Peter Hilton has written a lot of good articles on Play and the table of contents looks good. The only problem I see is that it has been written 2 years ago and Play APIs has changed a little since this time. So it could be very good to understand Play concepts and how it works, but you may need to follow [migration guides](https://www.playframework.com/documentation/tr/2.4.x/Migration24) and the latest documentation to avoid some issues.
Peter Hilton has a good reputation for Play content. I imagine it's a fine book, though I haven't read it. My colleague Dave Gurnell has a book on Play that you might want to consider. It covers Play 2.3 (current in 2.4, released very recently) and because it's all digital, you get free updates. http://underscore.io/training/courses/essential-play/
It's a decent book. I read it in conjunction with the Play docs (because the Play docs generally suck) to get familiar with how Play works. By the end of it all, I could build a Play app with little difficulty, so I guess the book must have been good enough.
 Yours is like [the one](http://stackoverflow.com/questions/7717691/why-is-the-minimalist-example-haskell-quicksort-not-a-true-quicksort) advertised in Haskell. But this is a slow implementation. Is it for educational purposes?
alright, thanks
That depends on who you ask. [Here](https://vimeo.com/16541324#t=13m13s) Guy Blelloch argues that it is a quicksort, and Wikipedia agrees, in that it mentions both versions.
Yeah, I'm trying to implement various sorting algorithms using Scala, but in a Scala-like way. It's definitely not going to be used in some real case scenario. EDIT: I just now checked out the Haskell version, it indeed is the same as mine :) thanks for the link!
 (For learning) If you want to improve it you need a [better partitioning algorithm](http://www.java2s.com/Code/Java/Collections-Data-Structure/Quicksortwithmedianofthreepartitioning.htm). To make a far better - there is [introsort](https://en.wikipedia.org/wiki/Introsort). For sorting lists I recommend [merge sort](https://en.wikipedia.org/wiki/Merge_sort). 
Pattern matching is definitely more the Scala way though.
this is great... but it doesn't say that the course is for scala. What language do they use to teach? are they using Java?
The limit scalaz-style programming is very likely about performance and code clarity. The former is a constraint that they have to take into account when dealing with a user facing service at absolutely massive scale (read: abstractions aren't always free), and the latter relates to large teams and ramping up new/non-FP-experienced devs. For the non-Twitters of the world, sure, Scalaz/Cats/Shapeless, etc. are all viable approaches, but for "industrial" Scala there are tradeoffs to be made. Look at Spark, DataBricks posted their Scala style guide here, which was met, not surprisingly, with derision by FP advocates. In the end, Scala is not one thing, it's many, which means there are myriad approaches to working with the language. The side effect is a divided community, and that won't change until the language forces us to.
The whole purpose of call-by-name parameters is that you don't see at the caller site that the parameter is lazily evaluated. If you want to see it, then you have to use `() =&gt; A` as parameter type and not `=&gt; A`. In Scala you need to assume that everything is lazily evaluated or that it is evaluated on multiple threads because Scala wants to make these things easy and straightforward. When you want to make your own applications safe against these properties, you need to apply some coding guidelines. Call-by-name exists to make lazy evaluation easy, therefore you should not write `foo { println(x); y }` when you want to ensure that the side effect happens only once. You have to write `println(x); foo { y }` instead. When you use a `Seq` in Scala you also need to keep in mind that it can not only be mutable or immutable, but also lazy and strict.
Scala appears to have very strong adoption in the industry for being a second tier language, and you can mainly thank akka/spark for that. The issue that Scala appears to have is one of community, there is an overall persuasive feeling of elitism in various sects of the community, and its doing the language more of a disservice then actually being helpful. Not going to make names, but places like #scala + mailing list in terms of respect and community guidelines are really much lower than what they should be. I haven't really seen any of this sought of stuff (kind of reminds me of the attitude I find in online games) in other language communities (Haskell/Clojure/Go). I mean, if you have a look at the the following reddit thread about the data bricks style guide (http://www.reddit.com/r/scala/comments/2ze443/a_good_example_of_a_scala_style_guide_by_people/), that kind of stuff is not on and its plainly disgusting. Disagreement is fine, but learn to do it civilly and that is an example of exactly not how not to do it. Thankfully, stuff is getting better. Projects like cats are being released https://github.com/non/cats, which (appears) to have bene released as a response to scalaz's latest non helpful attitude. Gitter has been excellent in managing discussions related to specific projects, so its great minimising unnecessary discussion. Stuff like Gitter isn't really Scala specific though Honestly I feel like Scala needs a strong community leader, who sets down really strict guidelines about what behaviour is expected. In terms of technical direction, Scala is finally taking the correct path of providing a stable API following semantic versioning, and focusing on cleaning up the compiler and reassessing certain features. This new direction may displease people, but imho, its just the result of Scala transitioning from a "research" language to one that has more significant industry adoption
[andThen](https://www.youtube.com/watch?v=GKNX6dieVcc)
I know nothing about Scala, but shouldn't new Scala developers dive headfirst and get themselves into messes on toy projects that don't necessarily matter in order to learn all of the language rather then limit themselves to what is safe for a particular organization? Once they know the language I understand keeping a style per project, or per organization when needing to work on something huge and maintainable, or if they are recruited into a company without knowing the language, otherwise when they see the corner cases they will be stumped?
Check out https://github.com/ochrons/boopickle for more information
Looks pretty awesome. Its projects like this that make me think scala.js is going to get popular.
Is there any possibility making a chrome plugin that could render the messages. Im not asking anyone to bother, just wondering if its possible from the data format, or do you really need compiled code on the receiver. Or are there similar protocols that do that. That would be pretty good. A lot of people like JSON because of the low barrier of entry, and that would help.
Can I please be that one guy that likes DataBricks style guide _and_ likes to write code as algebraic data types and type classes? I'm a big FP advocate, I come from a ML and Java background and have yet to find a reason to use a monad in a Scala program. [+1 to noel's sibling post] 
The point is that lazy evaluation is not the only property your program can have. You don't know what the callee is doing with the parameter. Do they call the call-by-name parameter at all? Do they call it twice? Do they call it only once and than cache the result and use that one instead of further function evaluations? You can't express all of these properties by syntax, therefore there is no point by only expressing call-by-name parameters with syntax. You as a developer need to get aware of the side effects of your program and how to control them. If you express that clearly it doesn't matter anymore if the code is lazy or not or if it is executed on different threads. Beside from that Scala IDE can show if parameters are call-by-name.
If you care more about readability of the protocol rather than speed/size, there are other serialization libraries for Scala/Scala.js that do that, e.g., [uPickle](https://github.com/lihaoyi/upickle) and [Prickle](https://github.com/benhutchison/prickle).
It's not really possible to decode BooPickle serialization format without knowing exactly what's in it. This is the price you pay for efficient coding :)
I think "blowing up", if you mean throwing Exceptions, is a pretty big antimatter. Taking the median of an empty list should (arguably) return an empty value, which is nicely represented by None. 
This is a good way to learn if you have no time pressure, but when you want to get new hires productive ASAP it helps to focus your efforts.
Median is fundamentally a partial function. Whether you prefer using the raw pf or a lifted function to Option is entirely dependent on the situation at hand. A case can be made for either solution. If you know you have no empty Arrays, even if you can't express that in a type, the pf is fine. If you don't care about empty results you can collect over your set of arrays, leaving you with just the non empties. If you do care about them, the lifted function is better. Actually defining median as a pf might be the nicer solution, but carries the penalty that in Scala PartialFunctionN is by historical mistake a subtype of FunctionN.
Are there any options for backward compatibility? Let's say client and server both knows `case class Foo(a: Int)`. But times change and now we need `case class Foo(a: Int, b: String)`. What happens to an old client who doesn't expect `b`? What happens to the server who expects `a` and `b` but receives an old version of Foo?
Why not use something like Capn'Proto? Because this supports more Scala-specific types?
&gt; "limit 'scalaz-style' programming" What does this mean? Probably something about not being abusive and obnoxious to developers.
&gt; require declaring your messages in specific language Good point, you don't want to require up-front schema declaration. So why not MessagePack?
I'm currently using protobufs in a few projects and would love to see this projects encoding compared to it in size and perf. As for the boilerplate in protobufs, I've found it to be pretty minimal. I create a separate project with sbt-protobuf to produce the serialization library that my other projects depends on. I really just declare the schema once and that's it. I've got an example of this on github for my [play2 protobuf body parser](https://github.com/stusmall/protobufbodyparser/). This looks like a great project. Thanks for putting it together and I'm looking forward to checking it out.
In project I work with we use Kryo and its `TaggedFieldSerializer`. Classes looks like: case class MessageReceived( @(Tag @field)(0) receiverUserId:Int, @(Tag @field)(2) date: Long, @(Tag @field)(3) receivedDate: Long ) extends Message It gives an ability to safely remove and add fields with no errors in (de)serialization step. The downside is that if the field is removed, the other side which expects this field will receive null. But in real life we never remove fields from objects which may be sent to old clients. And the server should serve old clients and should expect null values for new fields from them and, for example, replace them by default values.
Yeah, you could do similar thing in BooPickle by encoding additional information (field tags) for each field. Should be even quite easy with the macros. I might look into that in a future version if there is demand for it :)
Ah, I'd never tried scala.js so didn't even think of that. Thanks.
&gt; (new HBox{}): Node That's what I do whenever this sort of thing comes up. It's a minor hassle, but I don't need to do it very often.
Within scalaz context, no, I never felt the need to do "List(true, false).ifM(List(0, 1), List(2, 3))" or anything not in standard library. flatMap/map/filter/reduce/for comprehensions are sufficient for my needs.
I'd rather not have any more noise like '=&gt;' at call sites, even though that's one of the more unobtrusive options. ScalaIDE (and I imagine IntelliJ) indicates when a by-value param is created. Does that help?
&gt; in order to learn all of the language I think the problem here is that Scala is, in a way, fractal. Learning "all of" the type system could take... a life-time?
This is really nice, question though. I noticed that this used `scala.runtime.reflection`, however is this just for the compiler to verify this is correct at compile time, or does this method actually use reflection at runtime Mainly asking this for both performance and stability reasons (have had issues with reflection in the past)
We can do better! I don't care what the other subs are doing, we should really focus on promoting Scala. Our language is so fun and powerful. You make a good point about the website, too. There's no immediate call to action.
Even if call-by-name parameters were given a special syntax (or banned) then you could still replicate the same functionality with def macros. (And, with def macros, the function could be doing totally arbitrary things to the incoming parameters.) As with functions in your libraries that may use def macros, the best defense is better documenting the functions when particularly relevant. (I am slightly curious what libraries/APIs you encountered where this call-by-name or call-by-value was confusing. Your example, while valid, is a bit too contrived.) Otherwise, the syntax would just end up too cluttered and confusing. To some degree, call-by-name is almost redundant now that def macros are part of the base language (there are some restrictions on overriding macros and they cannot be used to ). Although, using call-by-name is much more preferable as it is lighter weight and much easier to maintain/understand.
It's used for `TypeTag`, which would fall under the compile-time parts of reflection.
I'm reading Mastering Play Framework for Scala (http://www.amazon.com/Mastering-Framework-Scala-Shiti-Saxena/dp/1783983809) and it's quite good and updated (May of 2015). You need some previous experience with Scala and a basic knowledge of what Play Framework is because, in my opinion, it's an advanced book, but I'm finding it very usefull. 
see also: https://github.com/cvogt/compossible/blob/master/src/main/scala/TMap.scala#L9
Wouldn't `map` be the most straighforward? val list = List(1, 2, 3) val indices = (0, 2) val result = indices.map(list) // result = List(1, 3) 
Perfect! I guess I need to read the docs of the map api more thoroughly. Thank you! 
This is actually a very unusual thing to want to do, and the problem is underspecified. So I have a few questions. - Why are you doing this? Indexing into a structure is extremely rare in Scala. - What type do you want back? What do you plan to do with the results? - What kind of value do you want to return if an index is out of bounds? I'm not trying to be irritating or pedantic, but this is truly an unusual question. Feel free to find me on the `#scala` IRC channel if you want to chat about it. 
List has a O(n) lookup. Use a vector for a O(1) lookup val items = Vector(1, 2, 3) val lookups = List(0, 2) lookups.map(items) // List(1, 3) Also `items.slice(0, 2) // Vector(1, 2)`
Do you ever want to have a Future of Eithers? 
&gt;have yet to find a reason to use a monad Future, Option, List, Either(ish) are all monads. So do you mean to say something different? 
&gt; Look at Spark, DataBricks posted their Scala style guide here, which was met, not surprisingly, with derision by FP advocates. The derision had nothing to do with them not being FP advocates and everything to do with them wallowing in complete ignorance of how he language works. (IE, not understanding what a for comprehension was, confusing them with loops, not understanding they can un-nest flatmaps, confusing the reasons for flatmaps, etc.)
Could even do indices.map(list(_)) _ in the context of a lambda is shorthand for the variable passed in, without naming it. 
Why the use of scalaz? object Person { def create(name: String, age: Int, gender: Person.Gender): Try[Person] = { ... } } case class Person [private] (name: String, age: Int, gender: Person.Gender) You want the constructor private (protected, etc.), not the class.
Try indices.map(list)
just a note: slice has different semantics and results 
Glad you said use Vector. Given that it seems the person is coming from Ruby, it really should be re-iterated more not to use List, and instead use Vector. There's a number of performance impacts that can occur from not properly using List.
Programming Scala, 2nd Edition from Wampler &amp; Payne was released Dec 2014 Atomic Scala from Eckel &amp; Marsh is also at his 2nd Ed. released Apr 2015 This is what I found for the moment
I disagree. There is no reason to separate the \\/ concept in two (poor) different implementations. Either is not right-biased, and as such is not a monad - heck, it's not even a functor. I dislike having to use left- and right-projections. The only reason I can think of for this design is for cases when the left side is not an error, which, fair enough, but that to me says that Either is not meant for error handling. Try, on the other hand, is made for error handling - and is properly right-biased, it's a monad, everything I expect of Either. But it forces me to use exceptions to encode errors, which brings me back to my initial point: I agree that I don't *have* to pattern match on all possible errors, but if I want to, and I sometimes do, then I can't. Or at least, the compiler cannot guarantee that I have dealt with all cases. I also don't like to pattern match on types, I like my type errors to be spotted at compile time. Finally, pattern matching on NonFatal is not useful. First, because that's already what the Try.apply method does, and second because it has a very weird notion of what is a non fatal error. Stack overflows are fatal, I should think, as well as IOError (hardware failure), to name only two 'NonFatal' errors. You don't have to agree with me, of course. You might not see all these as limitations, or might find them acceptable. I don't, and thus: the fact that Try and Either are arguably a bit crap is one reason for bringing scalaz into OP's code.
I'd also recommend the first few chapters of Mannings book Functional Programming in Scala
My favorite Scala book, the focus here is to learn functional programming not properly Scala language. So I don't recommed for a first contact. Highly recommeded.
I am currently reading Programming Scala (Wampler's), and I would highly recommend it. 
&gt; Scala is a very dynamic language As in rapidly evolving? 
Love these books. Cannot recommend enough.
&gt;Note that in that case I'd have used Validation rather than \/ Good point to note. Here's the rest of the code: def create(name: String, age: Int, gender: Gender): \/[NonEmptyList[InvalidPersonError], Person] = (validateName(name) |@| validateAge(age)) {(n, a) =&gt; Person(n, a, gender)}.disjunction
Yes.
In fact, there was a talk by Marconi Lanna at the last ScalaDays titled "What's new since "Programming in Scala". I took notes, because I was interested what happened ;-). Here's how according to him the language changed: - Try-catch-finally takes expressions instead of blocks - Allow implicit as a class modifier - Value classes - String interpolation In fact, that seems to tell that Scala has been extraordinarily stable since 2010 - that's only a few additions in details. Other changes he listed affected the libraries. But an intro book like "Programming in Scala" would not cover many of these anyway. - DelayedInit (deprecated) and the App trait - Range.foreach optimization - Parallel collections - Class Try and Future 
&gt; Procedure syntax deprecated &gt; It's not yet deprecated. That will have to wait until a rewrite tool becomes available. 
Some people dislike Enumerations but there is no official statement that their use is discouraged. I still use them from time to time, although I agree that with better Macro support they could be more robust. 
 implicit class MwithIdentity(m: Multiplication with Identity) { def one: T = m.identity }
F#.
I usually don't like books from Pakt publishing because their authors are mostly unproven. I like publishing houses like OReily because they choose authors which are known in the field for which they are writing the book. 
Given that `Either`, `Left`, and `Right` are effectively reserved words in Scala, I went with `Or`, `Fail`, and `Succ`. Simple, lightweight, here's [the Gist](https://gist.github.com/godenji/bd38c732ddfaab7a696d). Cat's `Xor` looks interesting as well; that library/community is very active right now, looking forward to a streamlined Scalaz. Oh, and existing non-biased `Either` implementation should be deprecated now and removed in Scala 2.12 ;-)
Java's implemention of exceptions left a lot to be desired, but their separation of checked and unchecked exceptions (and Errors) is an important one. Java defines unchecked exceptions to be logic errors - mistakes made by the developer that likely correspond to bugs. Something like an `IndexOutOfBoundsException` or a `NullPointerException` is something that should never actually occur in correct code, but it's also the sort of thing that could occur anywhere. Similarly, Errors correspond to runtime failures that are completely unpredictable. An `OutOfMemoryError` could be thrown anywhere. Both unchecked exceptions and errors represent unexpected failures. On the other hand, checked exceptions are meant to represent expected failures. It's totally believable that I encounter an IO error while trying to read from a file, or encounter a UriSyntaxException when trying to parse a URI. Functional error handling can be great, but it can only really handle the same kinds of errors as checked exceptions handle. Even Haskell, everybody's favorite purely functional language, distinguishes between predictable failures and unpredictable errors. It's also worth noting that using functional error handling will cause `Option`s or `Try`s or whatever you use to snake throughout your codebase. Just like checked exceptions, you force everybody who calls into your code to consider both the success and failure cases. That's not necessarily bad, but it's the exact same justification as used for checked exceptions in Java. You will likely run into the same sorts of problems that checked exceptions cause.
I would rather see Either[FailClass, SuccessClass] over .\/./\./...///\ that scalaz provides, but maybe that is just me ;) Either is a little bit verbose, but it seems pretty OK....
crap
The play docs are very good, just kinda short about a lot of things. Reading play docs + poking in the source worked for me.. but I could see where others would prefer a book.
I worked with a terrible programmer who published his first book to OReily. It was pretty terrible. ;)
Thanks :)
It's not just cute. If you aren't using these abstractions then you're either rolling your own for each concrete base or you're falling back to using vars or mutable collections and therefore probably can't get guarantees like that if you fail you have a NonEmptyList of errors. If you ban Scalaz, you are going to want to get Monads, Applicatives, Traversable Functors, etc somewhere. So I suppose you can write your own but you're probably going to do it worse than Scalaz anyways. If you say you don't want those things then you aren't reaching high enough and are definitely writing annoying and/or less safe/robust code. Also Scalaz is far from banned across industry. Just because Twitter doesn't like it doesn't mean that it isn't used in notable Scala shops.
I'm not negative on `Try`; I use it in some of my code. My point is that, if you have a function with signature: def foo: Try[Int] What can possibly happen? Well, you can get a `Success`, a `Failure`, or an uncaught exception. `Try` doesn't isolate you from all exceptions. Using `Try.apply` to construct all your `Try` instances will handle all catchable exceptions, but you can't necessarily do that (it makes it harder to construct `Failure` instances). Just because a function claims to return a `Try` doesn't mean it and all the code it depends on are correctly implemented.
https://gist.github.com/anonymous/594f7b8fc3425793a244 How would you do something like that? The meat of it is parsePhoneSpec. It both 1) has potentially failing actions that depending on each other and short circuits accordingly in the for-yields (for instance, it needs to get a fields out of the map to parse an int out of it, and it needs to parse an int to confirm it's &gt; 0) and 2) it collects all the errors from all the fields properly. Note how if there's an error produced, it has a NonEmptyList of errors. Nil makes no sense for a list of errors, yeah? Also, there's a traverse that allows us to parse a collection of specs and collect all the errors in all of the specs, or return a fully parsed list if there are no errors. This isn't necessarily the best way logically to handle this (we can probably live if we drop a few specs here or there and just report the errors in parallel with our best attempt at parsing all the specs. Writer monad is perfect here). It's more meant to show another thing we get for free by using common and understood abstractions instead of making stuff up as we go. There are two ways to do this without things like Applicatives and Monads and Monoids. 1) You can use a mutable.Buffer or something and then conditionally update it with hanging ifs. You can't really guarantee NonEmptyness in the same way here. 2) You can have a bunch more variables in scope and do some crazy pattern match / size checking of a bunch of lists. If you have a way in vanilla Scala that comes close to the Scalaz way in terms of safety and clarity, let me know!
Sorry if I implied that you were negative about Try; the author of the article repeats the usual functional zealot argument that Try is somehow inadequate, and we need non-standard alternatives like \\/. I think Try is very useful, but then I don't mind using exceptions either. However, your argument that Try doesn't protect from all possible exceptions isn't a big concern of mine. Any code in the JVM could theoretically throw an exception, therefore we put try-catch blocks at a suitable place in the code to handle unexpected exceptions. In fact, none of the alternatives to Try can give you 100% guarantees that no exceptions will be thrown either... It is quite easy to return a Failure with Try.apply; you throw an exception which will be converted into a Failure. Functional guys might cringe in horror at the thought, but the side-effecting exception doesn't propagate outside of the function, so it is fine in my book.
I believe that was https://github.com/playframework/playframework/pull/3060
That is cool, have not seen an example quite like that. Ultimately, I am a pragmatist and not an idealist. The normal way I would handle something similar is a single var errors = Array.empty[Error] That I mutate within my function to accumulate the error, and then return if filled. This preserves the following ideals that I hold important * The code works * The function is pure from the outside world. Same input is always the same output. Easy to test, compose, etc. etc. * The code is easy to read, even for someone new to Scala (aka no weird symbols to throw them off) * The result that is published from the function is fully immutable I realize an idealist would rather import a library and learn some functional song and dance to avoid a single var internal to a function, but that is not my cup of tea. Cool for it being yours, I always learn cool things from the crazy scalaz guys... but does not mean I am going to touch it ;)
I use LESS, like coffeescript, zero type safety, thus the allure of the Scala alternatives. As for complexity, the only syntactic noise I see is with the react library extension; otherwise pretty straightforward. Saying that, you could probably get away with defining your css `class`es and `id`s in Scala, generating a LESS file from that, and then relying on Grunt/Gulp linter + LESS to catch some of your typos. Not ideal, but a step in the "right" direction if you're not ready to go all-in on the type safe approach.
fyi, scalaz does not have any weird symbols you must use anymore. They did in 6.0, but as of 7, symbols can *only* be additional syntax, not a method itself. So we use Scalaz at our work but refrain from using any of the symbolic operators, and even default to more verbose ways of using the language since we have some folks without much scala background. 
Always used SBT in a console, never tried a IDE plugin.
What was the rationale? For me it would seem intuitive that using sbt directly you don't have to worry about the IDE at messing things up. Which IDE or text editor do you use?
probably becaue sbt isnt really a data format making parsing and updating of it probably hacky and buggy. plus console version works 100%.
Cool, thank you.
Any differences will be irrlevent in the near future with SBT 1.0, which will include a client-server model SBT.
Thanks again.
Thank you so much. So is there anything like http://blog.paralleluniverse.co/2014/05/01/modern-java/ for scala?
I know people that do both, personally I like to keep it seperate and in a terminal window. I use intellij for purely ide
I just started developing in Scala and I also open intellij for syntax highlighting, click to declaration, find usage, etc. But I only compile and test from the terminal. It's like 100x faster this way. 
Has anyone here used Shapeless for anything serious or semi-serious? If so, why Shapeless and what were the results?
I honestly prefer the user experience of the the running the console, there are often problems with running more than one sbt instance at the same time, so if I had the choose one, a shell like UI is more powerful for me than a graphical one.
You are right integration of a build tool into an IDE is mostly problematic and needs a lot of time to mature. I am using IntelliJ IDEA. Note: As i know, it is planned to provide a SBT server functionality, so every IDE can use this, and there will be no difference between console and IDE anymore. But this will take some time.
I'm not sure I understand. How do the errors get lost? If you are just throwing the Either away immediately, then you aren't even map, flatMap, foreach, etc anyways, right? What about cases where you cannot deal with the error right away? Usually error handling is dealt with somewhat high up the stack, which is why things like Either and checked exceptions are so important.
Does this compare using a same thread executor service for futues?
If I understand correctly, you use the IntelliJ for syntax highlighting, code navigation (control + click to view source), etc. **only**? You actually compile in sbt with `~compile` in a command-line windows or within IntelliJ's CLI itself?
[Image](http://imgs.xkcd.com/comics/real_programmers.png) **Title:** Real Programmers **Title-text:** Real programmers set the universal constants at the start such that the universe evolves to contain the disk with the data they want. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/378#Explanation) **Stats:** This comic has been referenced 420 times, representing 0.6086% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_csf133f)
Thanks, that'd been bugging me while I was working with it but makes sense. 
My assumption is that the program represented by the return value will potentially side-effect when it is run, which is not something you can represent with `Option`.
I used it in a sample project at https://github.com/cretz/scala-web-ideal just to get a feel for it. It was a little slow going at first, but I really like being all-Scala and getting to build the CSS-combining logic in Scala.
The graph is on the order of 10^-3 s. Is this even a significant difference then?
1. Yes! Makes code like `val offset = 1_000_000_000` easier to read than `val offset = 100000000`. I cant use `1e9` either because of rounding errors. The underscores can be placed anywhere in the number. Java 8 already does this. 2. b"011001" seems more readable to me. 3. Why not simple ADT (e.g. `type Knob = On | Off | Broken`) for declaring enums? Much less verbose than sealed trait + case objects... 4. Minor annoyance... 5. This belongs to scalac optimizations than language features? Can probably be optimized by libraries working ASTs (tasty trees?) See: https://scala-blitz.github.io/ 6. Code with breaks and continues are easier to write maybe but completely hard to read later or modify/debug etc because of changing state... 7. This belongs in a library? type Closeable = { def close(): Unit } implicit class CloseableExtensions[A &lt;: Closeable](r: A) { def doAndClose[B](f: A =&gt; B): B = try { f(r) } catch { case NonFatal(e) =&gt; throw e } finally { r.close() } } 
There's at least 2 orders of magnitude difference at all points in the chart, of course that's significant.
I'd vote "hell no!" to probably most of the original list _and_ this new list. (Except the stuff that's already planned/implemented.)
&gt; Language simplification ideas: &gt; Simple ADT declarations (borrowing syntax from Haskell): type Json = String | Int | Boolean | Map[String, Json] That's an interesting use of the term "simplification". How is adding another way to do things simplification? It's not a rhethoric question. I am sometimes puzzled by what people find simple and what not.
I wrote a ~big text about the old plugin and alternatives first, but I guess you'd rather have a simple straightforward answer. The only recommended way in intellij-idea is its built-in plugin. You have to click the SBT tab and press the "Reload" button. I sometimes had to purge the "/.idea/modules" directory for things to work (idea did not want to invalidate old versions of the libraries).
That's great to hear, thank you for mentioning! BTW, what's the textual representation of `\/` ?
Take a look http://spray.io/ 
The notion of simplicity can be orthogonal from the perspective of the language designer (for him or her it probably means smaller grammer, moving responsibility off to libraries through macros than to language keywords, unifying features etc) vs from the perspective of someone like me who uses it in the industry every day (for me, "simple" means that it is concise expressive yet obviously meaningful code e.g. `type Knob = On | Off | Broken` vs sealed-traited enums and not spending too much time researching and upgrading what is the best library to use and relying on the standard lib a lot e.g. for common things like json handling, time handling and file I/O).
Why the "hell no" for enhancements to the standard library? I believe they belong in [SLIP](http://docs.scala-lang.org/sips/slip-submission.html)s vs the SIPs? A lot of languages like Go, Python, Ruby etc have really good libraries for common things (json handling, datetimes, file I/O, http) in the standard library. 
Go carefully read the instructions on how to setup sbt. Sounds like you forgot to run sbt eclipse. I agree using sbt with Eclipse is kinda odd if you are used to java development using just Eclipse.
Disjunction. https://github.com/scalaz/scalaz/blob/4fa9d9fce7cec05c85c3e99a707c47ed9d0e6b05/core/src/main/scala/scalaz/package.scala#L292 
Any other, just example works fine
I forgot to mention that I'm on IntelliJ. I ran sbt gen-idea and problem still occurs
generating new project without any problem(using sbt gen-idea)
If you write a library, shouldn't it be up to the caller to decide how to handle errors? It's quite often that I end up writing a library for my coworkers to use that can have intermittent errors when processing something, and sometimes they want to fail fast, othertimes they want to ignore, other times they'll want to print and continue or inspect the errorr. This is one really good use case of monadic error handling. You seem to make the decision for the user if something should die immediately or be swallowed. 
Well I tend to not write libraries, so I tend to not need the bloat or the complexity. Different solutions for different problems I suppose (though I would not use any library that exposed scalaz to my... fine if they use it internally, but I do not want forced to use it).
That implementation of 7 uses reflection; this one doesn't: def using[In &lt;: AutoCloseable, Res](closeable: In)(f: In =&gt; Res): Res = try f(closeable) finally try closeable.close() catch { case _: Throwable =&gt; } I guess it would be nice to have in predef though
Yep! 
Without using any IDE. Just download the example, go to sbt console, clean, update, compile. Does it work?
Everything works fine.
I think there is so much happening in this space (just look at how different third-party libraries which handle the same task are), that picking one would just mean more obsolete stuff in the standard library in a few years. I would at least prefer to wait for the dust of reactive streams to settle, before doing this.
What changes? I dont understand. I tried to Update dependiences but scalaz core cross something error doesnt let me go into project. I'll look for group it's good idea.
In most of these cases "easy to use" != "simple", and the alternative you discard is simpler. Enumerations: Need to introduce new forms and types and clarify the interactions with all other types and with inference, which becomes a quadratic problem. Lookup how much space is spent in the Java language specification and then again in the JVM specification on enumerations. You'll be surprised about all the hidden things that have to be specified. For loops: The compiler can do a pretty good job nowadays. No need to introduce special syntax. Trailing comma: Two ways to do the same thing. I agree with the underscores, that's a net improvement. Scala was always the opposite of a grab-bag of features. It was always conceived as a "growable language" where we value abstraction and composition over particular features. The for me most influential talk about designing growable languages was Guy Steele's at OOPSLA 98. "Growing a Language". By all means look it up if you have not already done so. 
&gt; Simple ADT declarations (borrowing syntax from Haskell): type Json = String | Int | Boolean | Map[String, Json] We don't need any enums then (unless we want to do integer arithmetic on them?). A lot of sealed trait usages would disappear too and make code more readable... Note that Haskell has two ways to do the same thing. In simple cases an ADT works well but for more complicated case you need a type class hierarchy, which is something completely different. Not something to emulate, if you ask me. People get hung up about the verbosity of data type declarations in Scala. And maybe we can do something about it, it's not a shut case. But how important is this, really? In a typical program, how much space is taken up by the data type declarations? &gt; We don't need the case in case class anymore. We can have an annotation @case macro annotation now. Would simplify the language with a library feature? No, i think macros do not count. Standard macros are essentially language features. It does not matter whether it's the macro engine or the compiler that translates the feature. &gt; Standard lib enhancements: Most of these are worthy to have. And all of them require your active contribution. So please, get involved! &gt; indexOf, lastIndexOf should return Option[Int] i.e. None instead of -1 when not found. I strongly disagree with this one, for reasons ranging from backwards compatibility to code style. &gt; Idiomatic I/O in Scala. See: http://www.reddit.com/r/scala/comments/30r9fq/what_is_the_apache_commons_equivalent_in_scala/cpvay6g I would _love_ to see a great IO library for Scala. Jesse Eicher made good progress towards one, but I am not sure what the current status is. &gt; Synctactic sugars: &gt; Kotlin style ? for flatmapping through options e.g. request?.headers?.get("auth)? We have flatMap and for (...) which both work for all monad-like types. If you ask me there's no need to come up with special syntax for a special type here. In fact, that would again run counter to Scala's design philosophy. &gt; Probably can be a macro too? It would be nice if String? could be a short-hand for writing Option[String]... Or maybe String? for String | Null. I could see this coming if we made types not have null. Types without null is the kind of question that we should be asking ourselves when we look at the evolution of Scala. &gt; Params for traits e.g. selaed trait Pet(name: String) Are already proposed and implemented as SIP 25: http://docs.scala-lang.org/sips/
In regards to other languages and features, every language has a complexity budget, whether it is Scala, Java, Rust, C++ or other languages. And the more of the budget you spend on special-case features, the less of the budget you have for more general features. In regards to Rust in particular, according to Paul Phillips [it has already blown through its complexity budget](https://twitter.com/extempore2/status/608437675343929345) (for more on that topic, see some of his other tweets). Of course, some special-case features may be worth it, but it is important to consider that there is a non-trivial cost to adding more features to the core language, and more general features that covers many features not already covered tend to be a better way to do things (I think Bjarne Stroustrup in an interview once said that when designing and developing C++ in the early days, when people proposed features to him he didn't consider them unless they could be used or changed to be used to handle two or more different problems that people came to him with).
In regards to binary literals and thousand separated number literals, I think the solution with using string interpolation with macros is a better solution than them being built into the language. And I personally prefer `b"01101"` over `0b01101`, since there is no new syntax to learn and the former solution is not significantly more verbose than the latter solution (and it works with Scaladoc out of the box). EDIT: I made a simple implementation for thousand separated number literals: https://gist.github.com/anonymous/219cbf50f8b5216083a0. EDIT: Ah, a more flexible underscore separation as implemented in Java could be very nice, yes: http://docs.oracle.com/javase/7/docs/technotes/guides/language/underscores-literals.html.
I agree. Java doesn't have the batteries included concept, hence Apache Commons came in. Scalaz is the "functional" Apache Commons, but we are lacking (for now) a "balanced" Apache Commons for Scala. if you take the entire eco system it is divided between very functional and operator riddled syntax (dispatch for example is a great library, but a little too functional IMHO) vs common sense libraries such as wrappers to existing Java libraries (e.g. the wrapper around Yoda time) where use of operators is done to help the user and not confuse them. Here is my "dream": I would love to see an initiative for a well defined *interface* for a standard library, with a pluggable implementation. e.g. I want a File.readFully , File.copyToDir, File.unzip, URL.post, string.isMatch(regex), File.asJSON/asXML.find(xpathAsString) etc. Once the API is agreed, various people can contribute implementations. I don't think any language standard lib did that (well JAVA EE is close, but it's not standard lib...) 
still unresolved dependencies.
Can you show the output of sbt and your build.sbt (or equivalent)?
As soon as I got Home I'll sens everything. 
&gt;&gt;Types without null is the kind of question that we should be asking ourselves when we look at the evolution of Scala. YES!!!!!! We can have `String` to mean a non-nullable string and `String?` to mean a nullable string. That would be awesome.
What's the compelling argument for trait contructor parameters? Seems to make the language more complicated from what I read. I have almost entirely abandoned abstract class constructor parameters, only using traits with abstract members, and I have become a happier person.
Yeah I struggled with that too. Makes no sense to me a mere lamen. 
I think they are just having fun with saying its more embeddable. In the post to the mailing list it is only 200x more embeddable. In the thread he mentioned trying to "quirkify" the release notes.
I don't know what to think of this. 2.11.6 was released four months ago, and in four months, with the team that Typesafe has, this new release has only four noteworthy release note items, one of which is a doc update?!? Anyone else wondering what the engineering team is actually spending their time on? Are they more busy with Dotty than Scala? 
So one complicated thing is replaced by another? I think one can do perfectly fine without early definitions. There are enough approaches to not require them.
https://www.dropbox.com/sh/pbjwzbaxo52wu33/AABd_UDSO9qW0ywPj2iix-DSa?dl=0 Here it is. I added also errors messages after using this _2.10 style. It's pretty weird because this course required scala 2.11.x.
Can you follow up on that a bit? 2.10 doesn't ship with any JDBC or Kafka love either. Are you using somebody else's libraries that are stuck on 2.10?
I am using both jdbc and kafka on 2.11, what am I doing wrong? 
Nah it's all in old java drivers, I've just been holding off upgrading until that gets fixed
True, though I have seen review requests for scalac team members (usually Jason) in Dotty issues and PRs.
I guess they will publish the videos very soon.
Um. Spark != Scala
Until...what gets fixed?
I don't think that scala is to complicated if you use an IDE, but I can see how it's too complicated if you try to use vim our sublime. I would never want to see it become more opinionated or, even worse, develop the the extremely overbearing conventions of java. I love it's lack of opinion. It makes the language suitable for highly complex enterprise applications, small microservices, and quick and dirty prototyping. I wouldn't want to see that change. 
At least in the case of IntelliJ it does, mainly due to inspections. If you do something "wrong" i.e. use `isInstanceOf/asInstanceOf`, it will recommend you replace that with pattern matching. IntelliJ also does stuff like telling you to use method() on methods that have side effects, where as to just use method for accessors. IntelliJ has its own issues, but over the years it has actually helped a lot in regards removing the conceptual burden on Scala
Yup, someone the scalac team has said "that the days of submitting your feature into the tree and expecting it to get pushed into release" are gone. Scala has to actually care about stability, which means maintaining an ABI, which makes it significantly harder to just throw new features into the compiler
Unifying traits with abstract classes, and then you can remove abstract classes from the language. (Like you I don't program in a way that uses abstract classes, but I imagine they have uses somewhere.)
I totally agree about the conceptual simplicity part, and this is the most important aspect when it comes to good software design. Basically you should use traditional functional programming constructs (ADT's + functions + type classes) as much as possible, and keep your behavior and types separated (the opposite to what Java has been trying to teach us). But there are use cases where subtyping (using traits) and mutation are very useful, and I'm glad Scala allow me to use these concepts together with pure FP.
It means that the jline dependency is now shaded. Other projects (notably, Spark) can now embed it without breaking other modules that pull in an older jline (notably, Hive and Hive thirftserver CLI). But they didn't stop there: a "plain" jline on the classpath will be picked up (if it conforms to the expected interface), so those bleeding edge users can drop a newer jline and get whatever fixes they needed, without waiting for a Scala release.
It's in the works: https://github.com/apache/spark/pull/6903
Yes, stable identifiers is the only exception. You also need them for imports.
Interesting idea. One drawback would be that abstract classes can pass parameters to other abstract classes, while traits would not be able to pass parameters to other traits, so replacing abstract classes with traits would reduce the expressiveness in that regard.
That's why now I fully support the decision to guard more advanced language features with `import language._` directives – they are not necessary for everyday code, so if your team doesn't need it, you can just explicitly ban them.
Definitely
But I think 'advanced' is the wrong term. I've written both heavy OO code and heavy functional code (now that I'm invested in Scala) and I can tell you, the latter is *much* easier. It's just unfamiliar to those coming from Java. To say that higher kinds are 'advanced' (and sort of implicitly discouraging them from being used in some places) is really doing a disservice IMO. Just off the top of my head, I wonder if it wouldn't have been better to have a 'java style' or 'functional style' import/annotation so at least a single class could keep one style, without passing judgement on which is more 'advanced'. 
Sorry for the delay. That is the same link.
There are a couple different either implementations in Scala. In your case you're specifically looking for what's called a biased either. That is an either who's behaviour assumes you want the right side of the either most of the time. One such right-biased either in scala is the scalaz's(a library for functional data structures) `\/`(aka disjunction). Given the following disjunctions: type Error = String val result: Error \/ Int = 7.right val failure: Error \/ Int = "An Error occurred".left calling the `map` method on `result` will evaluate the given function changing the signature of the right side, ie: def intToFoo(n: Int) = new Foo(n) val result2: Error \/ Foo = result.map(n =&gt; intToFoo(n)) //Foo(7).right however, calling map on `failure` results in a no-op, returning the error which originally occurred: val result3: Error \/ Foo = failure.map(n =&gt; intoToFoo(n)) //"An Error occurred".left Typically instead of calling `map`(and `flatMap`) over and over again, a for comprehension is used when working with a large number of disjunctions. val result4: Error \/ Foo = for { n &lt;- result m &lt;- failure } yield { new Foo(n + m) } The net effect is that if an error occurs anywhere within the for comprehension, any further evaluation is effectively terminated(because calling `map` or `flatmap` results in a no-op). When you want to instead work with the error type, you can either call the `leftMap` method or `swap`. However when it comes to accumulating error values like in the example, an entirely different either-like structure is used. In scalaz, This is called a `Validation[L,R]`. `Validation` comes with the restriction that `L` must admit a `Monoid` which allows the left side to accumulate errors. Like disjunction, `Validation` is right biased. However unlike the example you gave, `Validation` is disjoint, meaning you will only ever get a Error values or success values, but not both. In the case where you could have both a success and a failure there is the lesser used `\&amp;/` in scalaz. As you can see, there are a lot of either types(more generally known as union types). If error handling with a union doesn't seem right, or is frustrating for some reason, you're probably not using the right kind of union. &gt; My primary frustration, however, is that coworkers have started rejecting code-reviews because I'm not using this pattern in every place a failure might be possible, even in cases where there has never been an exception or null. This is correct. The signature of your method is a contract. If it's possible to return an error, the signature of your method should reflect that an error is possible, even if you've never seen that error before.
In Scala, there would be no need for a new class here where a type alias would instead suffice if your only aim is to cut down on the verbosity of the type signature. type MyFail[T] = Seq[Either[Error,T]] def query[T](q: Query[T]): MyError[T] = ...
What's the inherent weakness of putting behavior in the same classes with data? It helps with organization. Why have a separate class using implicits to house behavior? Isn't that needlessly complex? 
Your "MayFail" is basically `scala.util.Try`.
I'm in the same boat. I work on several sbt projects and all but the biggest one are perfectly fine with the auto-refresh setting.
Here's the code you posted: public List&lt;Either&lt;Failure,R&gt;&gt; method2(List&lt;T&gt; obj) { List&lt;Either&lt;Failure,T&gt;&gt; result = method(obj) List&lt;Either&lt;Failure,T&gt;&gt; result2 = new ... result.left.forEach(failure -&gt; {results2.add(Either.left(failure))} try { result.right( item -&gt; { results2.addAll(method3(item)); } } catch (Exception e) { results2.add(Either.left(e)); } return results2; } The first big problem with it is that you're referencing the field `left` and the method `right` on `List`, even though they don't exist. So there's already some confusion in your code about either you have a `List&lt;Either&lt;A,B&gt;&gt;` or an `Either&lt;List&lt;A&gt;,List&lt;B&gt;&gt;`. The second problem is generally speaking, things have the *potential* to fail multiple ways (e.g. when trying to read JSON from a file, you might have an `IOException` if the file doesn't exist, or a `JSONParseException` if the file is actually a JPEG or an MP3 instead of a JSON file), but they don't actually fail in multiple ways (i.e. you don't get both exceptions happening in a single invocation of the function), so it very rarely makes sense to have multiple failures in the way that you've described. Another aspect of this same problem is that you're implying that `method2` can actually do useful work even if `method` fully failed, implying that `method2` doesn't actually need any data from `method`, in which case why are you bothering to invoke `method` inside of `method2`? You might have to give a more concrete example of what you're doing such that multiple failures are occurring. For example, if your "multiple failures" are actually validation, then you probably either want to use the `Validation` applicative instead of the `Either` monad, or you want your `Failure` type to be a monoid so that you can combine multiple failures into one. See http://bugsquash.blogspot.com/2011/08/refactoring-to-monadic-c-applicative.html for more details on that.
in the folder buildsettingss you have appropriate files
You're in the same place I was a year ago. It looks alien but you get used to it and soon start to rely upon it. If you're using Scala anyway. I never enjoyed trying to shoehorn FP into Java myself. However, as an old Java hand myself, I'm more alarmed that you're passing around a Map&lt;String,List&lt;Something&gt;&gt;. I might actually do that in Scala with a Value class for a key and a type alias for the map but I'd never have dared in Java! An Either looks simple in comparison!
No I hadn't considered any kind of translation for this lib. Mainly I'm focused on spinning off open source versions of code I use in my daily work. (US only focused atm). The messages are not targeted at end users, in general. But I could see the desire to show validation error messages directly to end users. Do you have any suggestions on how best to accomplish this in Scala?
In Scala or Java 8 (or any language the uses closures), it is not reasonable to preserve the "throws" list for checked exceptions in the closure since composition of functions becomes difficult for the language. That's why in Scala all exceptions are unchecked exceptions. But this doesn't remove the need for what checked exceptions did previously: checked exceptions reified the "expected errors" of a method to callers. To me, an expected error is anything that I can imagine a caller or user doing wrong when using the abstraction I present to them. Something that they could correct with a proper error message. Some common examples of "expected errors" (this is focused on web services since thats mostly what I do -- will vary according to your domain/use): * Bad input from user/caller * Unauthorized/forbidden * Entity not found In Scala, typically I reify expected errors in the type signature of the return type (e.g. with Either or \ /). Note: this does have consequences to code style as it implies getting used to monads and for-comprehension syntax. Trying to deal with them explicitly leads to almost unreadable code. Also, this doesn't mean "unexpected errors" still don't occur. Unexpected errors are things the caller/user can do nothing about. To me, the set of unexpected errors is so big that its not time/cost effective to deal with them explicitly in code. If something unexpected happens, the vast majority of the time just letting the unchecked exception bubble up to some top level error handling logic is the most time/cost effective method. Some examples of "unexpected errors": * Database is down * Bad/buggy return value from called code (e.g. null) * Out of memory Since the caller/user can do nothing about these errors, they can be relieved of the burden of dealing with them. This means they don't need to be reified in the type signature. 
Maybe. It's only when you have to curry types (like fitting an Either[A, B] into an F[_]) that you need the ugly syntax that they will be changing. 
import scala.math.BigInt.probablePrime import scala.util.Random
Yeah ScalaDoc is awful. Under the search box there is a list of letters; click the `P` and scroll for it. If you're on a Mac you should buy a copy of [Dash](https://kapeli.com/dash) which lets you do a proper search across Scala, Java and other docsets.
i dont see it either but when i click on to show me BigInt source it's there... not sure whats up with the docs. ScalaDoc does indeed need some love its like trying to navigate some IBM doc website
Ok guys seriously. Just go to http://www.scala-lang.org/api/rc/index.html#index.index-p and then scroll down. It's there, I promise.
The docs are kinda jank
The thing is, Higher Kinded types *are* more advanced concept in category theory, at least compared to what most people used to. Of course thats not an issue, having stuff that is more "advanced" happens all the time in languages, its just a question of payoff. I lean more towards Martin in regards to having it as an explicit export, and thats mainly as an effect of the code you typically see produced. A lot of people who say Higher Kinded types aren't that hard, and show a completely trivial example of it in use, kind of miss the point which is that the majority of code that is read don't use Higher Kinded types in trivial circumstances, instead its often a deeply nested type hierarchy. So for me at least, I definitely do not think that Higher Kinded types should be removed, but at least with how they are in scala (due to stuff like `#λ`), when I read code that uses Higher Kinded types *generously*, I often have to try really hard just to find out how stuff `really` works. I think what `Dotty` is doing with existential/higher kind types to try and simplify it down is great work, the current rendition of "Higher Kinded types" seems more of just a tack on in Scala because people wanted higher kinded types, and it seems it was added without putting much thought into Scala's complexity budget.
http://www.scala-lang.org/api/rc/index.html#scala.math.BigInt$ http://www.scala-lang.org/api/current/#scala.math.BigInt yes the p takes you to the /rc/ version of the docs, not current
By trait vs type class I assume you mean "A extends TRAIT" compared to "implicit ev: TYPECLASS[A]" because type classes use traits too. The implementation of a trait has to be coupled with the type by defining methods on the class. So if I make a trait Monad I can't make Scala Lists implement it. But I can make Scala Lists typeclass Monads.
One weakness is that it might make the data type less useful. For example, you might add dependencies in your data type methods that are not needed when you just use the raw data type. Another weakness is that it's not obvious where to place methods that use many parameters of different data types. With sealed traits and case classes you can separate the data type and the functions operating on it which increases the possibility for modularization. So IMHO it enhances code organization rather than the opposite.
&gt; I don't understand what this means. In the category of Scala types they're objects like any other type. Sure, but understanding something like `List[String]` is a lot easier to *properly understand, than dealing with something like `State[T[_]]`. *By properly, I mean not just a shallow understanding of the concept, but how it interacts with everything else. In Scala, this means we have to deal with subtyping, amongst many other things. This is kind of what I mean by blowing complexity budget, and its a problem that another language (i.e. C++) has a very serious problem with, in that they tacked on advanced features that people wanted, without giving second thought as to how users interact with the features.
&gt; You cannot express "this method takes/returns a value of the same type as the method receiver" in terms of subtyping, but this [very useful] constraint is straightforward using typeclasses. This is the f-bounded types problem. You can express f-bounded polymorphism with subtyping and f-bounded type parameters, of course. Whether this plays well with type inference is another story, but it is totally feasible, which is the main problems type classes in Scala seem to be attacking. 
If you're writing an object oriented program and your methods are take many parameters then your design is bad. Less dependencies could be helpful in highly modular libraries. Your users could take one jar and not need as many sub dependencies. It seems like it wouldn't be helpful for single jar libraries or applications no matter how they're split up. 
My claim is that f-bounded polymorphism is not properly representable in Scala (or any other language I know of) because it is not possible to constrain the type parameter to exactly "my type". The linked article above discusses this in detail.
I am going to hijack the example given in the f-bounded link. This pattern is convenient when you have control over the original classes (and/or want to enforce that all classes in a hierarchy implement the functionality) compared to type classes which are 'optionally' defined. It usually ends up looking like the following: abstract class Animal { type Self &lt;: Animal def name: String def renamed(newname: String): Self } abstract class Mammal extends Animal { type Self &lt;: Mammal // Not strictly needed, but indicates all subtypes of Mammal will have renamed return a Mammal instead of Pet } class Dog(val name: String) extends Mammal { type Self = Dog def renamed(newname: String) = new Dog(newname) } One annoyance is that, at this point, you can't really subclass Dog and adjust the type of Self. (As far as I know, all subtypes of Dog will have a renamed that is typed to return a Dog.)
Typeclass instances being extrinsic and "optional" is a *good* thing. You need not implement the instance unless you need to perform operations that the typeclass defines, as opposed to subtyping where you are forced to implement operations that you may never use.
Good point. I wish people would use the name "typeclass pattern" instead of "typeclass", as it is not actually part of scala, and searching for it brings up no authoritative reference.
&gt; Typeclasses allow you to provide evidence that a type outside of your "control" conforms with some behavior. Someone else's type can be a member of your typeclass. I find that this attribute of typeclasses is the most useful in my work. Without it you would have to implement the Adapter pattern to apply an operation over someone else's type along with your types... for each of the "someone else's type" you have.
My guess is it was downvotes just due to no further explanation. Because "separation of concerns" is definitely not wrong.
Let's not misuse the term here please. 
Why would you implement an interface if you didn't actually need its methods? In my years of experience with java, I've never run into that. It's true, that sometimes I haven't needed all of the methods that were defined in a badly designed interface, but I've never needed none of the methods defined and still had to implement the interface. Type classes would be exactly the same.
I didn't downvote but I do disagree. Well designed objects contain the behavior and data necessary to handle a concern. If you separate them, then you're separating one concern. There may be a good reason to every now and then but doing it just to do it seems counter productive. If not counter productive than at least no better. 
"Isomophic web pages," just like "lambda architectures," are such bullshit meaningless terms.
My favourite example is this: You have some user type final case class User(id: Id, name: String, email: Email, ...) and you want to send emails to users. Do you implement a method `email` on `User` that sends emails? Then your `User` class has to know about SMTP configuration, MIME types, and all the stuff that goes into sending an email. And probably every one that uses `User` now has to supply configuration parameters and so on. What a mess! I hope you don't do this. I hope you implement object EmailService { def email(user: User) = ??? } and isolate all that complexity into its own little unit. Some behaviour in the same class is good. All the behaviour is not!
Typeclasses give you several things that traits do not: * polymorphic values / return type polymorphism You can have a value of type 'MyTypeclass[A] =&gt; A'. This means, for example, that you can have a Read[A] typeclass that turns a String into an A. This tends to work better in Haskell due to Haskell's better inference. * conditional implementation of a typeclass: You can implement things based on what your generic parameters implement. trait Semigroup[A] { def |+|(x: A, y: A) } trait Monoid[A] extends Semigroup[A] { val id: A } // You can 'lift' a Semigroup[A] into a Monoid[Option[A]] implicit def optionMonoid(implicit S: Semigroup[A]) = new Monoid[Option[A]] { def |+|(optX: Option[A], optY: Option[A]) = (x, y) match { case (Some(x), Some(y)) =&gt; Some( S.|+|(x,y) ) case (Some(x), None) =&gt; Some(x) case (None, y) =&gt; y } val id = None } * conditionally available methods: You can offer methods iff something implements a typeclass: trait List[A] { ... // use the monoid to combine all the elements of the list together def foldm(implicit M: Monoid[A]): A } edit: * Ambient values Consider foldm on the empty list. Since you have an implicit monoid instance, you can return id. If you just extended from the monoid trait, you wouldn't have an instance to call id on, so you'd need to return a Option[A] instead.
&gt;Why would you implement an interface if you didn't actually need its methods? In my years of experience with java, I've never run into that Yes you have, you don't realize it. Look at the Java collections library, it's filled with examples of methods that aren't compatible with all collection types or throw exceptions depending on what the implementor is. 
I've been using Scalajs with angular on a Play Framework project and it works surprisingly well. I'm kind of blown away by how seamless the integration is. What's great is I can read the angular docs in Javascript and translate pretty easily to Scala. The same probably goes for ReactJS.
That's just bad design, so it's a straw man. The object oriented approach would make an email object. That makes sense since the email holds content and senders and receivers as well as metadata. Edit: maybe the email object doesn't hold the sender and receiver, but instead takes them as parameters to a method. In any case, it does separate concerns. 
You can keep Dog's self type open and only tie the loop at the very end when you know what Dog is. When you start having a real subtype of Dog, like say bulldog and golden retriever, you've stepped into the realm of family type polymorphism. Still very expressible in scala (or at least it used to be). 
You can download the slides separately from the videos. Under each video there's a *Downloads* tab with a link to the slides.
Ok, my statement above was imprecise. The self-type constraint (which is the goal) cannot be represented by subtype polymorphism in any language I know of. F-bounded types are as close as you can get but they're not sufficient.
Your statement is still a bit imprecise. Try "self-type constraints at the strength that you desire them cannot be represented by ...". There are of course OO languages that support self types (see Kim Bruce's LOOM), and the [binary method problem](http://lucacardelli.name/Papers/Binary.pdf) has been studied well enough. I think why you don't see self types in production, however, is that the f-bounded encoding (if ugly) is good enough for most use cases. Heck, the imprecision that you are against are even somewhat demanded in industry (e.g. see [this paper](http://www.cs.cornell.edu/~blg59/resources/doc/effing-bound-polymorphism.pdf) by Ross Tate's group at Cornell). The main challenges with F-binding to do self types tend to be (a) type inference and (b) variance. Type inference because manually closing the loop on your self types is annoying, and variance because self types necessarily require unification (a type parameter used to encode a self type cannot be used co-variantly). 
To be fair, I think you are completely ignoring context. There are so many instances in English where people using words as metaphores (in which case they don't mean the exact mathematical definition of the word) Its clear that the article had nothing to do with the mathematical concept of ispmorphism, if it did, then you would have a point. Isomorphism in context of the article is client/server rendering of the same content. This isn't a case of Javascript developers trying to sound smarter than what you think they are. This is a case of people using metaphors/similes (and making generic comparisons) in the English language. So conversely, I would argue that the Category Theory practitioners learn how to distinguish between people using terminology in the mathematical literal sense vs as a simile/metaphor. EDIT: Also, the author didn't come up with this term, its being used everywhere in frontend development to mean what the article is stating
Can't agree with this more, there are definitely a certain class of errors which you don't want to deal with in the typesystem. You can also add other stuff to that list, like - Network is down - Timeout errors (this one is debatable) I good way of going about it is, if you are working with business logic, you should try to match that in the type system as much as possible. Validation falls into that area, the contract (lets say in the case of a webserver), is that if something is missing from a POST request, you should return an error. However, dealing with database not working isn't really "business" logic (unless you are writing something like a connection pool). There are also good arguments about whether the type system should (or shouldn't) capture stuff like DI (a lot of people intentionally conflate dependency injection with dependency parameter passing as well, which doesn't help)
Tooling, workflow and binary compatibility issues are the three things preventing me from becoming a Scala fanatic. Even in my dabbling, I encountered so many road blocks trying to leverage shared/community code. Library X was one version, library Y was another version. Basically forcing me to choose. SBT seemed totally redundant, I'm not sure why they couldn't have just officially thrown it all behind gradle. It's such a shame, because the language is so neat. But the planning is both too slow and seems misguided.
&gt; which is the main problems type classes in Scala seem to be attacking. [They attack several other problems, as well](https://www.reddit.com/r/scala/comments/3bh5g8/what_makes_type_classes_better_than_traits/csmprzo)
Wait; which of the two is your favorite Scala book?
Programing Scala 2nd
I bet the reason the Scala compiler is so complex is that Scala has a huge amount of features. It's practically passed C++. It's almost like the should stop already and call it a day and just fix bugs for a while and let all the tooling and such catch up.
&gt;$ grep -r -i "probablePrime" $SCALA_HOME ~ ../Scala/api/scala-library/index/index-p.html:
Yeah, I've been on the fence for a couple of years now, electing to go with traditional server-side generated markup for desktop and mobile sites instead of heading to the SPA. Saying that, Scala.js is intriguing, the thought of having a type safe client-side layer is very appealing, particularly when I look at our growing Coffeescript salad that is becoming increasingly difficult to maintain. Perhaps lazy loading approach can help with Scala.js' the large generated sources, though I imagine not really, if initial page load is quick, surely the user will want to click soon thereafter -- downloading hundreds of KBs of javascript over a mobile connection is not going to make for a great first impression I suspect. After everything is loaded, however, sure, snappy SPA time ;-)
&gt; Note that in that case I'd have used Validation rather than \/. You don't need to import Scalaz for Validation -- you can use Scalactic and have a lower footprint: http://www.scalactic.org/user_guide/OrAndEvery
Either is a disjoint union. It's good for handling a single error, but doesn't compose very well. If you need error validation, use Scalactic's Or/Every. Also checkout [Error Handling in Scala](https://tersesystems.com/2012/12/27/error-handling-in-scala/) 
The thing regarding loading time, is that (for example), Google has just announced that their search algorithm will punish sites that take too long to load, which is what is mentioned in the article (i.e. https://developers.google.com/speed/pagespeed). So, even though (in total), you still download the same, that algorithm will punish you because the initial load was too long. The slow load is also an issue on mobile clients, because you can't assume that everyone has great internet, and there are cases where have had users think our site was down when in fact it was loading.
For a one man (I guess...) project this is really impressive. Especially the concise and readable code is nice.
Yea, at least I am impressed.
Not quite. Monoids and Annihilators as described here *are* both Semigroups. But Monoids have an identity called mzero: A s.t. forall x:A, x |+| mzero == mzero |+| x == x Where if A is an Annihilator, it has a terminal value called azero: A s.t. forall x:A, x |+| azero == azero |+| x == azero 
Really well done, there is actually a compelling case for CurioDB due to it leveraging so much of akka (automatic clustering/persistance etc etc) I have to say, well done for a one man project!
I guess not: scalaJS does not support file API-s. I don't know who'd be interested to write emulators for those.
Typo in the last identity. Should be forall x:A, x |+| azero == azero |+| x == azero Otherwise correct.
All feedback is appreciated
nice
I never used scalajs, but what you suggested seems to be the way to go. I will certainly consider that in the next development cycle. Thanks!!
Count your curly braces to see if your IDE inserted an extra closing brace somewhere.
I do not use a ide yet. Im using the scala prompt. 
What do you mean? Just make the p's the same case. 
okay, then here is what I get when I type it in with the change to make the feetperMile variable the same across both lines: scala&gt; var miles = { val feetperMile = 5280 | val yardsPerMile = feetperMile / 3 | yardsPerMile / 2000 } miles: Int = 0
Can you explain how?
I don't have the expertise to say, but you'd pick a starting token (`type` is reserved so I'd match haskell and say `data`), then parse until the end of expression. I'm not 100% sure it works but I think it could.
So start using a text editor? This should be a solved problem. You aren't the first person to write programs.
Don't forget [FPiS](http://www.manning.com/bjarnason/)!
yea really this is probably the single most important book
Ah, I see, thanks!
&gt; To chain computations together, one must be careful to use type signatures which encode the information that is known about the result set What happens when one is not careful?
My guess and hope is it doesn't compile
&gt; When your app grows, the size of the outputted JS (in total) is always going to grow. Thus the "a new version of the application is available" message seen in Gmail, Google Groups, Gitter, etc. client-driven apps. Assuming that the client device is able to cache large-ish assets then client-side approach scales well, less work for the server(s) to do, and therefore lower costs...at the expense of user device becoming a hand warmer and/or lag machine ;-) As for reduction in generated Scala.js code IIRC it's mostly due to the Scala collections library. In the early days of Scala.js there was talk of offering a "light" version, one that would only ship with a small subset of collections operations. In the end they opted to mirror the entire Scala language, a decision that in the long run will, IMO, prove to be a solid choice. For now the generated file size is fairly large, although most users seem to say something along the lines of, "yeah, it's 1MB, but gzip'd only 250KB!", and just accept poor user experience on first load (if not taking the "isomorphic" approach). When Scala collections overhaul comes in Scala 2.13, and Dotty thereafter, Scala.js file sizes should come down significantly. Still on the fence, really want to get away from Coffeescript, but when you've got an existing client application that is very lightweight and fast, it's hard to justify overhauling. Will probably take a non-crucial project and experiment with Scala.js there first.
yeah, totaly agree. in my opinion it's the best mainstream book for an introduction to monads etc. other people seem to think so too: http://fsharpforfunandprofit.com/rop/#comment-2022140861
nice, thanks for sharing
Ah, then so multiplication is both a Monoid and an Annihilator, but addition is only a Monoid?
do you ever sleep?
What's the point of making it run on Node.js instead of the JVM, besides making it 5x slower?
Super useful!
Indeed. It's not only easier to understand than the typical output it looks like it is formatted to be cut and paste back in, unlike the default repl. Awesomeness. 
&gt; I will show a few codestyle ideas that will make your code easier to debug foo match { case bar: Bar if bar.isOk() =&gt; bar.doIt() case baz: Baz if baz.isOk() =&gt; baz.doIt() case _ =&gt; ??? } If you avoid this style of type-casing, you won't need to debug your code in the first place.
The type that `getAllPhones` returns is a `List[Phone]`. But the `convertToJson` function has a type parameter of `[A &lt;: Phone : PhoneToJson]`. A `List[Phone]` can have mixed implementations of `Phone` as its elements. Whereas a `List[A &lt;: Phone : PhoneToJson]` can only have the implementation provided by `A`. So the types don't match and hence the evidence parameter can't be found. I think you need a converter that works on a `Phone` like /u/dave4420 provided. I don't think that not owning the `Phone` is a problem, just have a case where any other `Phone` implementation throws an exception.
Very happy to see the focus on optimisations at compile time. The reliance on JVM for run-time optimisations always bothered me. I would like to see one more type of optimisation: when a final class has a `val` in it, there is no need to generate &amp; call a getter for it. The JVM is probably good at optimising it away eventually, but some help from the compiler can reduce startup times.
Thats the implementation I currenlty have. I wanted to find out if there is a way to do compile time checking for newly added type rather than having a runtime exception. Thanks for the reply.
You can't get compilation for some types of phones to fail if you don't know what types of phones are in the list. What you would need instead of is a well typed heterogeneous list of phones.
Would changing a value to lazy then break binary compatibility? Or does it already break compatibility?
I haven't tried to follow the steps but I glanced through the whole thing and it seems like a great start!
That's funny. I wanted to remove that but didn't have the time yet. It's too playful and does not work with line breaks. I will consider adding a couple of svg animations instead, for the easily amusable ;)
You are right, I should point out the importance of contributions more prominently. Basically, I'm happy about any kind of feedback. You may fix spelling errors, clumsy phrases or just create an issue if you think some topic is poorly explained.
Black powder.
not for the buzzword... but to learn... to understand :)
Yes, like it, if you call it "Micro-services" you can attract more attention. How does it compare with this? https://github.com/phedoreanu/spray-slick-swagger
P.S. any podcasts you guys would recommend?
Just read through the source. I really like it. 
http://www.scalawags.tv/
There is no specific way to learn Scala for the enterprise. There is no Scala equivalent of Java EE. Though at the same time, you can use pretty much all of the Java EE technologies from Scala, usually there isn't anything different required from the implementations to use Scala. So what does Scala in the enterprise actually look like? Not any different from Scala anywhere else, though if I had to name any Scala based technology for being particularly "enterprisey", I'd have to mention Akka and Spark as examples.
Basically, when using typeclasses for ad-hoc polymorphism, instead of classical inheritance based polymorphism, the evidence is resolved at compile time instead of invoking a method runtime, that will dispatch to the actual dynamic type. That mean, only one instance of `PhoneToJson[A]` will be injected as an evidence parameter into the whole `convertToJson` invokation, depending on the inferred type for `A` at call site. As another reader suggested, you can use pattern matching to provide some kind of dynamic dispatch on top of your typeclass, but that mean writing boilerplate and limited compile time check when introducing subclasses (if your `Phone` type is sealed you can always have scalac warn you of missing cases in the match clause, and treat warning as errors). A solution, I have been looking into, is to use a scala macro to let write the pattern matching boilerplate for you, and prevent compilation in case of a missing type class implementation. This was a good occasion for me to dive into macro so I wrote a little toy project : https://github.com/alexd6631/TypeClassMacro Beware it will only work with sealed types, so it may not work for you, but could be a good base for using macro to solve your issue. 
I would recommend Func Programming Scala [here](http://www.goodreads.com/book/show/13541678-functional-programming-in-scala). I got started writing enterprise scala a few months ago and this book has helped me grasp the finer things about scala, totally recommend it. EDIT: Make sure you also do the exercises in each chapters.
This is really helpful. Thanks for taking the time to give me code sample. I guess its time for me to learn some advanced scala :) 
He's on reddit and frequents this sub! His username is /u/odersky
You may also have success contacting him through [the Typesafe company's contact page](http://www.typesafe.com/company/contact).
Try also works very well, as opposed to Either, it works better with for comprehensions, and you can use custom Exception classes and recover/recoverWith to translate them to a more appropriate response if needed.
Scala is awesome its support for concurrency is a big reason it's a popular language, however using the actor model is somewhat controversial in the Scala world. http://stew.vireo.org/posts/I-hate-akka/ http://noelwelsh.com/programming/2013/03/04/why-i-dont-like-akka-actors/ Just using Future or Task can give you a *lot* without having to delve into the world of actors. There are some good use cases of Akka IMO, but I think of the Actor Model as a last ditch effort when I've avoided all other possible designs. 
The comparison table that you linked is pretty old, [scala actors are officially deprecated in favor of Akka](http://docs.scala-lang.org/overviews/core/actors-migration-guide.html), and scalaz and lift actors are a part of larger framework and not as feature-rich as Akka, as a actor framework. So if you'd like to use actors, Akka will be the easiest path with a lot of resources. Whether you need actors is a entirely different question. You'll have to re-organize almost every aspects of your program into a quasi-finite-state-machine-y component called actors, and the flow of the program will not be clear as in imperative or future-based programs.
I think Try should only be used if you **have** to deal with exceptions (like due to some sort of Java API). Otherwise, scalaz's options are strictly better. I think recover/recoverWith were recently added to ```\/``` as well.
Can I read/watch this without registration? Where can I download the slides (or whatever is shared there)?
InfoQ should allow you to just play - I don't think you need to register. Some of these talks have slides - some may not. The description of the talk should contain the slides, if there are any. 
I browse the typelevel fork from time to time.. it doesnt look like there is much going on there.
There is nothing going on with the fork, it's the typelevel libraries that are at issue really; namely, the pure FP bent on which these libs are based and how that may fracture the overall Scala ecosystem. Saying that, it's a non-issue, not sure what the panel was about really, seems like rehashing old news since typelevel is effectively doing research that in some cases will make its way into Scala/Dotty. p.s. Brian Clapper is a boss mediator.
Thanks for this. I've been trying to get into Scala and want to make a little web app and the DB end of the stack has me throwing fits. The Play folks are schizophrenic on settling on a backend SQL solution. I'm even more amazed there's no ORM for at least quickly scaffolding out CRUD operations considering how many Scala evangelists talk about how much more productive the language is. Coming from PHP/Doctrine, Java/JPA/Hibernate, and Grails/Gorm before this it just seems strange. Maybe I missed something along the way. That being said this post has pulled me back from the brink of giving up on it. Slick has been my favorite SQL interface, however I'm a little disappointed that in 3.0 you have to specify the driver in the import. I wanted to prototype out with in memory H2 then go to Postgres once things settle out. Having to do a find/replace just to change DBs really just rubs me the wrong way. But that's just me :)
Just make it protected: protected def extortion: A 
His concern is that people who use the class can still see, via its inheritance hierarchy, that this method/trait is in play.
&gt; If you need to control over how your concurrency is handled, there is no better alternative (at least for the JVM) than actors. How is an actor better than concurrent.LinkedBlockingQueue? 
I'd say the fact that an ExtortionStream gets its values through extortion is precisely the kind of implementation detail that you should hide. The question here is probably: is there any case where we may legitimately want to restrict some Stream to be an ExtortionStream? There are two reasons why we may want to do this: either we want our stream to have an extortion method or we want to ensure that our stream does indeed get its elements by extortion. In the first case, I'd say you'd be better off using two separate traits Stream and Extortion. In the second case, however, I'm not sure anymore. It will no doubt depend on the particular application but, a priori, I'd be inclined to say that no, ExtortionStream shouldn't be its own trait. One reason would be simply avoiding the possibility of writing code that depends on this particular implementation detail, but another would be the fact that you can easily break this invariant: i.e. you can define a FakeExtortionStream which extends ExtortionStream but overrides next, and you'd be able to make instances of ExtortionStream which violate its supposed invariant. But then again I'm an academic and the only languages I actually write are Haskell and LaTeX...
&gt; One reason would be simply avoiding the possibility of writing code that depends on this particular implementation detail You sound like my coworker, haha. He's more of an academic. Whereas I, an engineer, am inclined to just refactor all instances and then magically end up with an extortion trait, only has a consequence of it being common to two streams. The duplicated code/extortion just bothered me. But yes his stance is a) don't tell people b) don't give them a chance to extend it.
They talk about cats at the very end of the video btw.
I expect Dotty would just become a new core of the Scala compiler. While it may break backward compatibility, it wouldn't do so the extent that it would represent an entirely new language. Rather, I expect it would just be the equivalent of a "major version number" change. I expect the difference would be less than even Python 3 vs Python 2. I'm just a regular user so I have no special insight, but that's my understanding of the aims of Dotty.
\^Throwaway account &gt; If Scala's future is Dotty, then Scala is going away since Dotty is designed to break backward compatibility with Scala in order to address all its design issues. No, rather than generating java bytecode directly (as scalac currently does), they'll be generating typed abstract syntax trees (TASTY) for *both* scalac and dotc; binary compatability issues will boil down to the removal of existing language-complicating features like `forSome` types. In other words, the "sky is falling" that you're alluding to is largely imagined ;-) &gt; The simple fact that Martin is spending most of his time working on Dotty should have everybody worried about Scala's future. On the contrary, he's doing what he does best: innovating. Jason Zaugg et al run the Scala show and will likely take over when the transition to Dotty occurs (which is a ways off; i.e. late 2018 seems optimistic).
&gt; The most used alternative currently is with Future/Task composition. They definitely have their place, particularly if your code is side effect free, but both of these are lacking when it comes to areas of failure/self healing/rerouting etc, which is where actors come in. Tasks deal with managing side effects, and Futures are almost the epitome of side effects (creating a Future usually causes some arbitrary side effect to be kicked off, which will eventually fill the appropriate Future). I would generally not use them for side-effect–free code, except when using them as a container for parallelism (which should happen at very few points in one's code). I disagree that they are lacking for failure/self-healing; they just have different constructs and APIs when compared with Akka actors. Generally, self-healing involves catching and dealing appropriately with Throwables (which are, after all, the only way a section of code can "die" in a recoverable way in JVM land). They don't deal with actors' idea of internal state, but then Akka provides a kitchen sink of tools (service discovery, routing, finite state machines, clustering, etc.)… on a straight battle of features, Akka will win ;-) But there are disadvantages to the model as well as advantages, so be reasonable in evaluating the options, considering the features you need.
It uses path dependent types right here def insertPost(user: UserLike)(post: user.shard.BlogPost) The type of 'post' is dependent on the choice of 'user'.
Thanks man, I think the main difference is the use of Webjars, also the integration tests. I like its DI solution. 
I would say that activator seeds are like the maven archetypes, I don't know if that answers your question. Thanks 
&gt; Regarding the execution of code... This doesn't seem relevant to the point I'm trying to make, which is that I would say the opposite to "They definitely have their place, particularly if your code is side effect free". For side-effect free code, I would say, just use a function, Futures have no place here unless you need them (you may need to then use them in map/flatMap, but that's as-needed). But perhaps we're looking at different definitions for the phrase... I suspect now that you're referring to the hidden state of the actors, and using its receive queue to manipulate that safely... an orthogonal issue that Future/Task doesn't explicitly deal with. There may or may not be state stored behind whatever Future/Task does... For the discussion on self-healing/error handling, I feel like we would get into a loop in that argument, I think people should check out the API, and consider what's possible. &gt; the design of Task (moreso then Future) means that it can't deal well with situations that Akka deals with. Task assumes that your defined execution code executes in a way that is referentially transparent. It doesn't make that assumption, where my assumption is that by "defined execution code", you mean the code that Task will run on your behalf. &gt; Task's run on a ForkJoinPool Task does not run on a ForkJoinPool by default. Concurrency is an explicit request, and when requesting a threadpool, the default is a FixedThreadPool. Though you should certainly consider the best ExecutorService for your use case. Most of the time, one hopes your code is just registered as a callback for some asynchronous service, so a minimal number of threads are actually tied up! &gt; I am just seeing a lot of non sensible akka hate recently Some people like the model, some people don't. I think people being aware of the wide variety of options, and pros and cons of each, is good.
&gt; This doesn't seem relevant to the point I'm trying to make, which is that I would say the opposite to "They definitely have their place, particularly if your code is side effect free". For side-effect free code, I would say, just use a function, Futures have no place here unless you need them (you may need to then use them in map/flatMap, but that's as-needed). Well I am talking about code that needs to be parallelised, as well as running asynchronously, so you do need Future for that (or something along those lines) &gt; But perhaps we're looking at different definitions for the phrase... I suspect now that you're referring to the hidden state of the actors, and using its receive queue to manipulate that safely... an orthogonal issue that Future/Task doesn't explicitly deal with. There may or may not be state stored behind whatever Future/Task does... Yes correct &gt; For the discussion on self-healing/error handling, I feel like we would get into a loop in that argument, I think people should check out the API, and consider what's possible. I have. I mean I have checked out Task's API, and I don't see anything regarding this area. Would love to be proven wrong, but it seems one of those things which Task ignores (and it probably needs to, to remain functionally pure) &gt; Task does not run on a ForkJoinPool by default. Concurrency is an explicit request, and when requesting a threadpool, the default is a FixedThreadPool. Though you should certainly consider the best ExecutorService for your use case. Most of the time, one hopes your code is just registered as a callback for some asynchronous service, so a minimal number of threads are actually tied up! I am talking in context of concurrency, apologies if that wasn't explicit. If you have no need for concurrency, I don't believe there is much use case in Task, since you can simulate the same effect using thunks in Scala &gt; Some people like the model, some people don't. I think people being aware of the wide variety of options, and pros and cons of each, is good. Of course, but the comments that people were making wasn't of the nature where they acknowledged that the tools have pros and cons. I think this is a moot point now, the point I am making is that there is a current "hip" movement of saying akin to "Akka actors will eat your children"
&gt; namely, cats Looking forward to that going out of experimental status and being published!
I've been taking a look to your code and I have some advices for you: * Avoid null checks. Use Option[T] instead of dealing with nulls. * Avoid using a lot of "if else" clauses. Use pattern matching instead. You can improve a lot your code by using more recursive functions and collections provided by the Scala API. Take a look at this guide for code conventions and clean coding -&gt; http://twitter.github.io/effectivescala/ Cheers, Gabriel.
Good timing. Just yesterday I ported all my code to spray. What will this mean for spray? Should I move to this now? Also, do we know if this supports proxies under ssl? Spray doesnt :(
I set this up a couple of weeks ago and it works really well. The only thing that bugs me is having to run a server in the background (outside dependency). Being the lazy ass that I am, this means most of the time I just don't bother and just start writing code. By the time I realize / remember / care, I'm already done with whatever it was I had started in the first place.
I believe that Spray will be discontinued in favor of Akka HTTP. The situation shouldn't be too terrible for you -- the high level Akka HTTP API is very similar to Spray's, especially the routing DSL. There is also spray-json support baked in, if you use that.
I was super excited to see the announcement on the mailing list this morning. Does anyone have any trip reports about using this in production? I know some folks are already doing so. My organization is going to start building all new services on top of this. I know there is a note about performance, but I wonder how much of a practical difference it makes. 
There are of other online repls/compilers out there. I'd highly recommend [scala-js-fiddle](http://www.scala-js-fiddle.com/) first just because it has the great benefit of being able to do stuff with the browser. [scala kata](http://www.scalakata.com/) has a very nice and minimal editor with markdown support, pretty good linking quick tutorials to people. [scastie](http://scastie.org/) is great because it front end SBT's scripting interface, allowing the use arbitrary third party projects, and show off more complex examples. Also great if something fails compilation and you want ask someone why is that is.
In retrospect all of these various repls/compilers should be in the subreddit sidebar. Perhaps a mod can add these and any other resources anyone mentions.
That is expected behavior of this IDE. It works that way.
Intellij 15 EAP is even worse. It reindexes and keeps my laptop quite hot.
I'm really impressed with slick. Make sure to use the autogenerate schema feature. It saves a ton of time on big data models.
This is known as MyType problem. There's several solutions to it: * http://slides.com/arturasslajus/quest-for-composable-immutable-objects * https://tpolecat.github.io/2015/04/29/f-bounds.html Or you could just have rate as a parameter.
That's a great alternative
I'm assuming you want to instantiate an anonymous version of SlowAdd because you want to concisely replace the default value, similar to how you would in Java. In Scala however, this isn't necessary, you can just add rate to the constructor with a default value. Welcome to Scala version 2.11.6 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_45). Type in expressions to have them evaluated. Type :help for more information. scala&gt; case class SlowAdd(value: Double, rate: Double = 0.5) { | def +(that: Double): SlowAdd = SlowAdd(value + that * rate) | } defined class SlowAdd scala&gt; SlowAdd(5) res0: SlowAdd = SlowAdd(5.0,0.5) scala&gt; SlowAdd(5) + 3 res1: SlowAdd = SlowAdd(6.5,0.5) scala&gt; SlowAdd(value = 5,rate = 0.75) res2: SlowAdd = SlowAdd(5.0,0.75) scala&gt; SlowAdd(value = 5,rate = 0.75) + 3 res3: SlowAdd = SlowAdd(7.25,0.5) scala&gt; 
&gt; That doesn't work because you can't call a constructor on an abstract class. Well, you cannot **instantiate** an abstract class, because ... it is abstract. But you can call the constructor of an abstract class as part of creating an anonymous, concrete subclass instance. The following works: abstract case class SlowAdd(value: Double) { val rate: Double def +(that: Double): SlowAdd = new SlowAdd(this.value + that * rate) { val rate = SlowAdd.this.rate } } case class HalfAdd(value: Double) extends SlowAdd(value) { val rate = 0.5} Of course internally this will not really generate an actual new type every time + is called! 
&gt; Java enums are about the most overengineered version of enums there is. Everywhere else enums are just a small syntactic wrapper over numeric constants. So, adopting Java enums is definitely out. They are exactly the opposite of Scala's philosophy - an over-complicated solution for a marginal problem. Martin, don't you think that exhaustive pattern matching check for enums would be useful?
maybe Extraction.decompose(g)
via http://letitcrash.com/
If you change dependencies frequently, turn off auto-import.
You mean interesting for him, or we need another JSON parser?
This is completely untrue. People who *only* "learn by doing" will pick up the idioms of the language much slower than people who take the time to learn them in a comprehensive treatment of it. http://blog.codinghorror.com/programmers-dont-read-books-but-you-should/
I don't think we need another JSON parser but with third-party libraries the task is just too easy.
Exactly, the end goal for me is to learn Scala, with a nice side benefit of having some software that will save me some time in the future. I could easily implement form generation in Java in half the time but I already know Java :)
Thanks, I am really enjoying it so far :)
Hi folks, There are openings at Functor, Sweden, including also remote work, except for Scala consultants who must immediately relocate: Do you want to be part of the journey as the Functor startup research spin-off innovates the future of software engineering? Do you want to make a difference? Do you want to devote your talents where it can have incredible impact on the entire software industry? Functor, Sweden, is again looking for brilliant minds, essentially co-founders as a generous equity program will after a certain threshold time make sure developers, building the company indeed, also own what they are building. Please apply on LinkedIn, closing soon take action if interested: https://www.linkedin.com/jobs2/consumer/overview/60296037 We use Haskell, OCaml, LLVM and our tools are closely tied to the C programming language and indeed to functional programming. Embedded software market is one target market, and skills in compiler design, type systems and operational semantics is key to our teams though we look for optimised teams as a whole, and your particular skill set may or may not include a PhD, but surely industrial experience. We have openings for Research Engineers and have some renown Research Engineers already. Research collaboration is key to our success and projects planned including a large EU project CONSTRUCTOR next year. We have strong industrial partners and some very high-profile customers internationally. The customer-driven journey is still at an early stage, while founded in 2011, and your contributions would be key to our success. Scala consultants will be sent straight from the top down into projects at Ericsson for very challenging work. For these three consultants we require an exceptionally strong background with Scala projects as we team up with Typesafe and secure projects that can only be matched by exceptional Scala developers. Our Functor Scalor™ is oriented somewhat differently than Scala, see www.domainspecific.org for some initial information on that products that appeals to very large companies at this stage, while Functor Prevent™ is suitable for just about any software development projects, currently doing static analysis with dependent types and automatic testing for C code, such as the Erlang code base, Twitter’s MySQL branch or embedded software at large, see www.functorprevent.com or www.static-analysis.org, and also the standalone tool www.functor.se/prevent which secures systems including a project at a customer with a range of 100 MEUR/each equipment investments, all relying on the VxWorks C code where our Functor Prevent™ delivers its value to prevent up to 50% of the bugs in certain projects, already with its current R1 feature set! AAEAAQAAAAAAAAJyAAAAJDY0ZmQ2NDc1LTY5ZjAtNDBlNC1hN2JmLTNmYzllZTllMjg5OA.jpeg Instructions and information, please read carefully the last paragraph on what we need to evaluate candidates adequately: https://www.linkedin.com/pulse/openings-functional-programmers-swedish-startup-johan-glimming Read up with links above to our webpages (last link), and postings on LinkedIn and Facebook: https://www.linkedin.com/pulse/future-software-engineering-johan-glimming?trk=mp-reader-card Facebook eg: http://www.facebook.com/functor Webpage has more information, linked to one the main posting above for some key webpages to check: www.functor.se 3230fbd.png Welcome to apply and be part of an exciting journey ahead with a very important mission to turn software engineering into a discipline at last, backed by industrial productification for years and R&amp;D that have never reached the software industry due to its inherent complexity, now mature, and now with proven market fit with Functor Prevent™ and Functor Scalor™ being used in heavy duty projects but much more to come! It’s Martin-Löf / dependent type theory inside our tools. Yours Sincerely, Johan Glimming, PhD Chief Executive Officer at Functor
I just increase the allocated ram for Intellij and it works fine. I suspect the CPU shooting up is all of the memory swapping in/out of your drive. EDIT: Just saw that it was because of re-indexing. That's to be expected. If you re-index constantly from ever-changing dependencies, see what /u/hyperforce said. 
Yes, but be careful ... can you **prove** it's the only valid thing? Here is a good [discussion](https://www.reddit.com/r/haskell/comments/2bj7it/let_me_tell_you_about_the_types_of_data/cj5y701) if you're want to learn how to do this.
I believe the confusion comes from currying and partially applied functions. You have: def averageDamp(f: Double =&gt; Double)(x: Double) = (x + f(x))/2 This is just some syntatic sugar for: def averageDamp(f: Double =&gt; Double): Double =&gt; Double = { (x: Double) =&gt; (x + f(x))/2 } Which is a function that receives a function as an argument and returns a function. So when you do averageDamp(y =&gt; x / y) This has the type Double =&gt; Double, or in other word a function that receives a Double (the x in the averageDamp declaration) and returns a Double. And it is this function that is passed as the argument f to the fixedPoint function. Since f is only used once inside the fixedPoint body (in the line val next = f(guess)), the value that is passed to the second argument list of the function averageDump (the x) is guess.
This is a know problem for IntelliJ, not sure if there is a way around this but I have made a bug report on IntelliJ for the issue
This is actually a tricky piece of code, at least trickier than one usually uses for real tasks. Sometimes useful however, so here's how my brain type checker works: * the return type of `iterate` is `Double` * hence, the return type of `fixedPoint` is also a Double * `averageDump` takes two arguments and returns a Double. Using the "currying" syntactic sugar, if you only pass one argument, the type will become `Double =&gt; Double`. * in the last line in question, `averageDump` received only one argument and is therefore `Double =&gt; Double` * fixedPoint receives two arguments, a `Double=&gt;Double` and the last `Double`. It returns a Double. (the sqrt function in this exercise)
Or hope your teacher gives partial credit if you write "14C, where 'C' is the constant I forgot (and would look up in the real world)".
[Thank you](http://media.giphy.com/media/1Z02vuppxP1Pa/giphy.gif)
I agree, complex domains become simpler with each unit of effort you put into them. Eventually it clicks together and all those hours become worth it. Good post, thanks for sharing.
Rich Hickey did an excellent talk on this http://www.infoq.com/presentations/Simple-Made-Easy Personally I take it a bit further, and apply the same concept to type hierarchies. Its not a popular concept here in `Scala`, but I have similar qualms to deep type hierarchies like I do with overuse of subtyping/inheritance (and other examples of trying to be easy) This approach is somewhat harder/more nuanced in a static language than Scala vs a dynamic one like Lisp, but it helps greatly in regards to keeping the amount of "magic" to a minimum.
While perhaps not scala-specific, an ex-professor of mine has a talk on exactly this. https://www.youtube.com/watch?v=UfzafIeALW8
&gt; Tunneling through the learning barrier [...] I smell a physicist.
I recently used https://github.com/FasterXML/jackson-dataformat-csv for CSV parsing. Apparently there's a RFC standard for it.. who knew? Have you tried it before? https://www.rfc-editor.org/rfc/rfc4180.txt
Would be nice if you would name your states using enums or case objects. Otherwise the code is fine. Have you all the corner cases of [RFC 4180](https://tools.ietf.org/html/rfc4180) in in your parser? I am thinking especially of double double quotes for escaping double quotes inside of double quotes :-)
I've not used that, no, I should have a look. Thanks for pointing it out! I must admit that while I know about the RFC, my implementation is mostly from the wikipedia entry and testing against different versions of the same file saved with different editors. Right now, it parses everything I have tried, but this absolutely does not mean it parses everything, period. Should you use my lib and find data that should parse but doesn't, please let me know so that I can fix the issue and test for it!
&gt; 52 requests, 2,875.56 KB, 14.86 s Evidently simple *Web design* isn't easy.
name, age "jones, jon", "27" 
Close---electronic engineering. Writing about undergrad definitely triggered thoughts of electron tunnelling.
details, i'm too agile for that
I will test it and give you feedback. Oh, and I forgot about the post important point: **Great work and thanks for sharing!**
To the answers here, let me add a bit more. If you have a function `def f(x: A)(y: B): C`, this is a _curried_ function. In short, a function that takes an argument of type `A` and returns a function of type `B =&gt; C`. In other words, it's a syntax sugar for (roughly speaking) `val f: A =&gt; (B =&gt; C)`. Why does the syntax sugar look the way it does? It mimics the way you'd _call_ the curried function, then call the result of _that_ to get the final value of type `C`.
As an alternative you can use Twirl the templating engine from Play Framework which can be used in a standalone aplication. https://github.com/playframework/twirl
Upvoted for Twirl. It's a great templating engine in my opinion primarily because it is typesafe.
Twirl kills performances. We did some benchmarks and it is like really really bad compared to custom function generating string
Then what do you suggest? ... 
I worked with scalatags[1], liftweb[2] and twirl[3]. Here's my opinion on them: * scalatags is the only one that can be compiled to Scala.js The recent versions got a bit more complex, but it's nice overall. * liftweb is the best if you don't need scala.js support. I enjoyed templates being pure HTML. * twirl is usable enough. You have to mix HTML and Scala code, but it may be OK depending on circumstances. At least in simple cases, it works. [1] https://github.com/lihaoyi/scalatags [2] http://simply.liftweb.net/index-7.10.html [3] https://github.com/playframework/twirl
Scala is farther down this path than might be apparent on first glance. You might enjoy this [talk](http://www.infoq.com/presentations/scala-idris) by Miles Sabin and Edwin Brady comparing implementations of dependently-typed structures in Scala and Idris.
thanks for your help but i will be using the library i posted, its the only i can see at this moment that can be used for Handlebar. Tried using mustache.java but to me is a little complicated to used in scala.
Scala is a fully dependently typed language, even if dependent types are no where near as pleasant to use as they could be. You should take a look a the shapeless for [examples](https://github.com/milessabin/shapeless/).
Dependent types are types which depend on values. Scala is **NOT** dependently typed. You can certainly emulate them, but that doesn't make Scala dependently typed.
I don't see any "kills performance" with twirl http://lihaoyi.github.io/scalatags/#Performance Apart from Scalatags and Scala-XML, Twirl is the fastest engine I could find
I don't know of specifics, the scala [roadmap](http://www.scala-lang.org/news/roadmap-next) has in it's `Don Giovanni` release includes some some general features that can reduce accidental complexity like the unification of syntax for existential and partial type application, or intersect and union types. &gt;"Tuples can be decomposed recursively, overcoming current limits to tuple size, and leading to simpler, streamlined native support for abstractions like HLists or HMaps which are currently implemented in some form or other in various libraries." This seems like a promise to improve dependent type features directly in some way, how exactly that will be remains yet to be seen. It may be worth pinging /u/Odersky or Miles Sabin for something more specific.
at work we use google soy. very performent. also compiles to js for client side.
Hey , i am open to learning scala and support a project in any fashion. any one wants to mentor me in this new language .. ? will be good to learn from the Pros.
From a technical point of view, Scala has dependent types. From a practical point of view, they're nearly unusable. Indeed, in Idris they're regularly used to prove the correctness of programs, whereas in Scala they're relegated to an overly complex library that only a few people fully understand and that only solve specific problems. Imagine a language where objects are possible but so difficult to define that there is an overly complex library which defines a bunch of objects that normal programmers can use. Would that be satisfactory? IMHO, a language is *practically* dependently typed if dependent types "are first-class citizens" and the code which uses them is as concise as possible.
Yeah, I've seen a video about dependent type in Scala, and about a quarter into it I gave up trying to understand the code sample. Would macros help in generating the code, or is that impossible?
&gt; Dependent types are used in one way or another in most popular scala libraries. The libraries use dependent types but what about the normal application code written by regular programmers? How easy is it to prove that a particular function is correct? Is it worth it? &gt; Many programmers find C to be satisfactory. :) Many programmers don't know enough to judge if a language or a solution is satisfactory or not. &gt; That's a awfully arbitrary definition that would only leave Idris and maybe Coq if you apply the term loosely. Indeed one of the goals of Idris is to make dependent types practical and easy to use so that you don't need a Phd and that you're still productive. Many claim that they're way more productive in dynamic languages than in statically typed languages. If I could choose between C++ and Python I'd choose Python any time, but between Python and Haskell I'd choose Haskell because type inference makes it almost as concise as Python. So it's not obvious that working with dependent types is worth it for normal applications.
Regular programmers may not care for formal verification of software but as apps become more and more complex they contain more and more bugs. As a hacker/pentester/web developer, I think that more effort should be invested into developing secure applications.
wont be a shock if they still force us to use SBT
Whats the use of writing anything if we cant use Scala due to SBT, First let them fix Scala with Eclipse and by removing SBT from the picture, then you come back.
Maybe ready the "Effective Scala" guide by the guys at twitter. Other than that just keep coding. 
Out of curiosity, what are you using to create the diagrams?
What's wrong with sbt? It does it's job pretty decently; and as for eclipse, I've never been a fan of IDEs.
The diagrams were made with Gliffy https://www.gliffy.com/. Really it's just one diagram that I deleted different pieces from and exported several times. I stumbled across Gliffy years ago and have managed to get by just in their 5-diagram free tier by deleting old diagrams as necessary, but really should pay them at some point; it's not easy to get a tool like that right and they do a pretty reasonable job, though there are some rough edges :)
I'm not sure dependent types in Scala are as practical as they could be. For instance, if I remember correctly, the classical `Vect n a` is not implemented using dependent types in Scala. The implementation of dependently typed structures is extremely verbose in Scala. IMO, Scala support for dependent types falls short even for uses other than theorem proving. Simply put, *full* dependent types are not first-class citizens in Scala. Path dependent types are a very weak form of dependent types. Regarding Haskell, see [this](https://ghc.haskell.org/trac/ghc/wiki/DependentHaskell).
&gt; Sadly, in programming circles a lot of language discussions revolve around appeals to “intuitiveness”, which is usually a short-hand for “works like other things I know”, even if those other things have complex models. I loved this, and the comparison with math, which reminded me of this quote (from John von Neumann), which I also love: &gt; Young man, in mathematics you don't understand things. You just get used to them.
https://news.ycombinator.com/item?id=9948906
I would love to use something like this but my concern is that we would miss out on any changes/improvements to the UI. Given how rapidly spark is evolving e.g the performance metrics/DAG visualizations in 1.4, or perhaps a change in the listeners interfaces, seems like it would be a decent bit of work to maintain something like this. I'm curious - do you guys have a strategy and people to dedicate to keep this up to date? Of course, it might just be reasonable to stick to this UI if not that much is going to change.
I'm still a scala newbie, so any comments/suggestions are appreciated. The full source code is here: https://gist.github.com/dpapathanasiou/b9d85685a0381f1deea0
&gt; Remove ":" to invert the binding of methods. It is not that useful in practice and I cannot see any benefit of writing 1 :: 2 :: Nil instead of List(1, 2). The latter is much more expressive. Even more than that, writing ``` Nil * 2 * 1 ``` is *exactly* as expressive as `::`, and comes for free! The rest of the world has stacks that grow to the right, I don't think making Scala's stacks grow to the left is really worth the additional syntax. &gt; Abstract type members. I really like the idea, but in most cases I see type parameters, and the effect is the same. They're already merging them in Dotty, so presumably in some future version of Scala this'll be fixed already =D &gt; I'm not sure about that, but could Scala remove the keyword new and use always the apply method syntax (new X(1) vsX(1)`), like Kotlin does? This'd be nice. As @mingp mentioned there are problems doing it naively, but I agree it would be a nice place to get to. Coming from a Python background, every constructor simply is an apply method for that type. Something like Ruby's `MyClass.new(...)` works too. ---------------- Here's some more: - `match` should be turned into a trivial infix method. At least then it'll have sane precedence and chain-ability with other infix methods. With even naive optimizations this would be zero overhead - All the extra extension methods Predef adds to `Object` should be removed, except for `-&gt;`. When's the last time someone used `x.ensuring` or `x.formatted("")`? Even IntelliJ knows enough to dump them at the bottom of the autocomplete list now. If people really want them they can import them manually. - Don't import `java.lang.*` by default. This contains a million useless things for Scala-JVM programs, and even more useless things for Scala.js programs! Alias the ones we care about and stop importing things wholesale. - Have the compiler properly escape `$` signs to avoid collisions with synthetic code. People have been doing escaping to avoid in-band meta-data since forever, why do we still need to tell people "don't use $"? - Get rid of import-ambiguity in favor of last-import-wins. The amount of code used to implement this in the compiler is ridiculous; the amount of code trying valiantly and failing to work-around it in the Scala REPL is even more so. All for a feature nobody really wants. - Unicode escapes should be narrowed down to only occur in string/char literals. - The "methods with 1 param lists can be called with 0 or 1 param lists" rule should be killed. If a method has 1 param list it should need 1 param list to be called. If you want to call it with zero them define it with zero! For Java interop we should pick one (either 0 or 1) and enforce it. This would remove most of the confusion from newbies like http://stackoverflow.com/q/8303817/871202 - Once methods take a consistent set of parameter lists, broaden eta-expansion to work anywhere a method is missing a parameter list, e.g. if a method should be called `println()` then I should be able to do `val x = println` and have `x` become a `Function0`. I should be able to add extension methods to `FunctionN` to allow e.g. `math.max.liftA(Some(1), None)`. I can do this in Python and I can do this in Javascript and there's no reason I shouldn't be able to do this in Scala. - Every Term should be a value. Even methods (through better eta-expansion) and packages. I should be able to do `val lols = java.lang` and have it create a structurally-typed proxy for me. I should be able to do `val adder = 1 +` and have it create a structurally-typed proxy with two overloaded apply methods. I would *then* be able to define nice APIs like a generic `help` method that can do `help(scala.collection.mutable)` or `help(assert)` - The for-comprehension translation is one of the most ridiculous things in the world. There is no reason for local assignments to create and de-structure millions of tuples. Local assignments should become... local assignments, like what you'd expect. - For-comprehensions should allow local defs, vals, lazy-vals, and code blocks `{...}` just like pyramids of `flatMap`s allow all these language features anywhere within them - For-comprehension generators that do not bind anything should be writable without the `_ &lt;- ` on the left. This would not be ambiguous with anything - Once the above happens `if` syntax in for comprehensions should be removed. It is trivially representable by an object with a custom `flatMap` that does the filtering for the types for which a filter makes sense. For the types where a filter doesn't make sense, then having it be gone is a good thing. Even the name of the type [FilterMonadic](http://www.scala-lang.org/api/current/scala/collection/generic/FilterMonadic.html) should be enough to tell you something doesn't really belong - `private` should translate into what `private[this]` does now, and the same with protected, since this is 99.9% of the time what you actually want. "private with companion object scope" could be given its own name e.g. `private[ClsName]`. This is especially confusing when you have problems with co/contra-variance, since it's easy to accidentally make things `private` instead of `private[this]` and wonder why the compiler is still complaining. - Top-level type-aliases, defs, lazy-vals, and even vals should work. The only risk is generated class collisions when you have multiple separate compilations dumping stuff in the same package, which is a problem that already exists with normal classes objects and package objects. Creating an object just to wrap my type-alias and then importing it everywhere is a silly dance that only makes sense to people who've done it for a long time.
No luck. I also tried making it a type lambda, but without success: extends Functor[({type λ[α] = Amount[α]})#λ] It seems like Leon is getting confused about the number of type parameters in the super/sub class definitions.
Agreed. Many of the early ideas from Scala were a bit half baked. But since enums are just another library, we can build better! Check out: https://github.com/lloydmeta/enumeratum
Close to implementing your suggestion. Just clean up to do. Check out: https://github.com/S-Mach/s_mach.data and let me know if that fits your needs. MessageForRule type-class is as you described.
Also, functional interfaces in Java.
So you write code in a 3rd party language for the JVM that is then compiled into a language that usually executed inside a webbrowser. That code then runs in a native VM on a mobile phone and drives the UI by calling an asynchronous API. Yep, sounds reasonable.
sealed trait 
I find something like `val coord = Coord 1 2` hard to "parse". Parenthesis help me to recognize certain patterns in code. I don't like the "dot less" syntax too. The syntax becomes irregular with some methods called with a dot and some without.
Wow thats almost just like ada. Im in love! Seems likely to conflicts with dotty union types, though.
I would like to see packages, package-objects and objects being merged into one concept: modules. Under the hood it could compile into several bytecode artifacts like how traits with implementations are handled. Leaf node modules would be singletons/static classes; branches would be a combination of package, singletons and dynamically initialized forward references for extensibility. 
I don't know what you mean, but assuming that you aren't just posting snark perhaps you could elaborate on your point?
Although this reads like a snide remark, I'm going to give you the benefit of the doubt and assume you meant to post something like &gt; I noticed you web site was rather slow loading (it took 14.86s to render the page for me). Perhaps you want to look at speeding up page load? I benchmarked the page and found it rendered in about 2s, and most of the requests were from third party add-ins (and most of them were Disqus). Where are you located (I'm wondering if a CDN would help) and is that 14.86s till page rendering or until the page is fully loaded? The latter isn't really relevant IMO.
Case objects generate a class file for every value, increasing memory usage. You don't want to use them if you don't have to.
&gt; people want explicit syntax for new features, and terse notation for established features That's a very interesting point. I just think that data modeling is so fundamental to a programming language that it should hold a special spot. It should essentially always be an "established feature". However, I see where you're coming from. &gt; In regards to inheritance, I think it is important to distinguish between subtyping (if one type a is a subtype of another type b, then instances of a can be used where instances of b are expected) and inheritance (one class inherits code from another class) I never thought of this distinction. And I'm definitely a fan of the module system. Thanks for enlightening me.
Thank you, that's a much better way to phrase it. Pardon my frustration, but it's a pet peeve when websites spend so much effort doing work that isn't related to content. The big news sites are especially guilty of this, and it's a drag to see great sites like underscore.io do it too. In this case, the amount of data it takes to render is roughly 1000x the size of the content (~2.7MB vs. ~2.9KB). I'm located in San Francisco on a broadband connection, and 14.86s is the time for the page to fully load. The content itself takes roughly five seconds to load, then the content disappears while the page rearranges itself for a few more seconds, then the browser chokes and becomes unresponsive for a couple of seconds, then gradually the rest of the pieces fall into place.
Thanks. I'll see if we can do anything about this. The core of our site is fairly optimised, but I think adding a CDN and possibly dropping some of the 3rd party plugins would help. 
 Not really, GADT and easier typeclass usage aren't Haskell-only things.
I personally do not use hibernate, but seems nice. Might be useful for those who mix Java(+hibernate) and Scala.
Yes to the abolishment of `new` as a special keyword. It should be `Foo.new()` as if it is a regular method, or even shrink to `Foo()` like `apply`.
Good initiative!
I'm usually very wary of these things (plot twist - I'm a woman), but this seems ok. Keep the standards high and focus on encouraging more people. That way if I ever give a talk, people will be more likely to think I deserved the spot instead of thinking I got it to complete some "diversity" checklist.
I believe I found it; https://github.com/gvolpe/light-play-rest-api
It also plays a small role in [this one weird trick for implementing abstract interfaces and classes](http://scastie.org/11171).
"never (completes normally)", rather than "never completes, normally".
I'm not sure what you're interested in, but if you take a look at Activator you can get an idea of what's out there.
Gitbucket?
Here's some open source projects you could start yourself. 1. Make a constraint solver in ScalaJS to solve school timetables within the browser etc. (here is a Java one http://choco-solver.org/). 2. Make a peer 2 peer (p2p) Scala library. (or wrap a Java one or an API to one). 3. Integrate HyperScala into Play Framework. HyperScala provides a nice abstraction over HTML. Do this as a new github project. http://www.hyperscala.org/ 
Look like this could be used with this idea as well? https://github.com/lloydmeta/slim-play
There's a ton of fascinating work being done at all levels, from the language up to Akka Streams and HTTP/2. However, there's a ramp up time when moving between platforms, so it's probably going to take you a bit to get familiar with the different systems. Since you've got a background in web applications, I'd start by downloading web applications from Typesafe Activator, going through the demos. Once you're ready, I'd take a look at Lila Chess, an application that's built on Play, is open source, and has a number of awesome features to help people play Chess online. Website is here: http://en.lichess.org/ Project is here: https://github.com/ornicar/lila 
I could use a helping hand here: https://github.com/hrj/abandon A new developer started contributing recently, so I am writing a [getting started](https://github.com/hrj/abandon/wiki/Developer:Overview) document to help new developers.
Hey thanks, I came here to post a link to this repo and found out someone already did, which is nice. I put a couple templates online as well to make it even easier for people to get started: - `g8 lloydmeta/slim-play` for Giter8 users - `activator new my-slim-project slim-play-scala`for Activator users.
Hi! We have a [full-stack messaging platform](https://github.com/actorapp/actor-platform), free and open-source alternative to [Layer](http://layer.com). We adapted Telegram's best practices and working on making it even better. I've recently posted an overview of our tech stack: https://www.reddit.com/r/scala/comments/3c9blu/messaging_platform_with_actors_in_its_heart/. We use Akka Cluster, Akka Streams, Event-Sourcing. We already have a community of mobile devs but server-side still missing community contributors. It has lots of challenging tasks. We would be glad to work with you!
I would hang around one of the more lively projects such as http4s or Cats. They both have active Gitter channels that are a good way to get a feel for the issues before you're ready to contribute. I have a project that is designed as a case study for beginning Scala developers. It's here: http://github.com/underscoreio/doodle It's just a few of us working on it, so it's much less active than the projects I listed above, but it might be more approachable for you.
Looks great but would be interesting see a benchmark: although play use netty the performance is not so great as I would expect..right now I'm using finatra (they release a new version a few weeks ago) and it's really great, fast,testeable and full async... personally I never feel confortable with spray but a slim play sounds good to me
finatra provides a similar api (they release a new version a few weeks ago) include DI and it's full testeable, async by default (using futures everywhere) , looks really great although you'll end outside typesafe ecosystem, maybe you can check this...
As a library author, scala makes it possible to do some amazing things and make life very nice for users of the library. Problems arise when clients start to become interested in the details of the library. Traditional languages like java just hid this complexity in the language itself instead of within the library. I'm guessing the blogs were complaining about CanBuildFrom?
&gt; In order to good at Scala Do I need to have complete understanding of Scala type system? yes (for some value of *good*). this is true of any language, i think. &gt; Will it be hindrance if I know a little about Type system? yes. on the other hand, no-one starts as "good".
Checkout [json4s ](https://github.com/json4s/json4s)
The pull parser is close to what I want. If it were a `Parser =&gt; Error \/ A` instead of just `Parser =&gt; A` I think it would be better. Along with if it had `flatMap`, `map`, and some other combinators to avoid the tedious nested matches and manually creating errors like "key not found."
I was wishing for this the other day!
Seems pretty cool. However, if you don't need Scala.js support https://github.com/nscala-time/nscala-time is pretty great. I've been using it for some time now with no major problems. It adapts joda time to many Scala idioms pretty well.
Actually the idea is that https://github.com/nscala-time/nscala-time would depend on Soda Time for a `Scala.js` release. There is already an issue for this on github https://github.com/nscala-time/nscala-time/issues/82
Ah, that makes a lot of sense. This seems like a really great project.
Ha! Cool name. I'd be interested to know by how much the output JS size increases when using it. I presume Scala.JS's DCE would be able to eliminate most of it if you're only using the basics.
I have made an effort to recode the `Javascript` to mainly use `Scala` collections. `JodaTime` as a library actually has zero dependencies, and apart from the use of some `Java` collections (which I am converting to Scala collections), the majority of code is basic math + creating Java classes. When some final things are done, I would also be interested what the outputting `Javascript` size will be, particularly for just minimal use. The DCE should hopefully do a good job eliminating `Java` style code
Great! I wanted to port a pet project to Scala.js but was blocked by missing joda-time bindings.
Did you try Akka Streams? You can streaming whatever you need.
Understanding the following is probably pretty useful: + How javac (or scalac) compiles code to bytecode for the JVM + How and when the JIT compiles bytecode to machine code + The Java memory model (heap allocation as a default) + How garbage collection works, what the different collectors do + How generics are handled by the compilers (erasure) + Classloaders and classpaths Here's a few quick links that seem to have relevant material -- but keep in mind you will find out of date material out there: http://www.oracle.com/technetwork/java/whitepaper-135217.html looks like it has some good broad strokes. http://www.oracle.com/technetwork/java/javase/tech/memorymanagement-whitepaper-1-150020.pdf http://www.javaworld.com/article/2077260/learn-java/learn-java-the-basics-of-java-class-loaders.html
Basics of the inliner. Look into the jvm flags FreqInlineSize and MaxInlineLevel. You can't (well shouldn't, it causes a ton of bugs) change them, but knowing what the inliner can and can't do with highly nested calls and big functions is important for writing efficient jvm code. 
Here is my list (which isn't so focused on performance as the other comments are) * Resources/class path (how they work, especially in context of `jars`) * Access modifiers, and the difference between `scala` and `java` access modifiers * How binary compatibility works (i.e. usage of `sealed abstract class` rather than just an empty `trait`) * Ivy, what it is, and what problems it tries to solve * How `ClassTag`'s/`asInstanceOf`/`isInstanceOf` works, particularly in its representation in the `JVM` * The basic's of reflection (would avoid it unless needed, but it is definitely needed in certain circumstances) * Since you are in web stuff, knowing how `ExecutionContext` works, especially in the context of `Future`/`Task`. They are pretty much used whereever you see `async` code in `Scala` * sbt Although its a hugely complex tool, its one that you need to learn, particularly in web infrustructure due to how complex build's get * Configuration. Seems simple, but there are many solutions, and things get less than trivial when you have to deal with stuff like `zookeeper` vs `environment variables` vs `java style system -D flags`
Thanks, that's a good list. I'm interested primarily in "quality of life" stuff, not with intricacies of Java GC cause pretty much everything about it could be inferred from my experience with other technologies. In fact learning about WARs, JARs and class loader is my top priority. Problem is finding a concise description.
&gt; WARs A *.war* file is just a *.jar* file (which is just a *.zip* file) with a certain file/directory structure that is understood by Servlet containers (e.g. Jetty, Tomcat, etc.). The contents and layout are all determined by conventions set in the Servlet specification. A lengthy tutorial with lots of info is available at [https://docs.oracle.com/javaee/6/tutorial/doc/bnadx.html#gjwux](https://docs.oracle.com/javaee/6/tutorial/doc/bnadx.html#gjwux). Here's a simplified breakdown: In general, a *.war* file contains a *WEB-INF* directory that holds a *web.xml* file, where the container finds information on how to configure the application. Compiled classes and libraries, if any, are kept in *WEB-INF/classes* and *WEB-INF/lib*, respectively. The *.war* file may also contain static resources (e.g. *.html*, *.js*, *.css*, images, etc.) in the root (or in any other directory), which will be served directly to users. To use *.war* files in conjunction with Scala projects, check out [https://github.com/earldouglas/xsbt-web-plugin](https://github.com/earldouglas/xsbt-web-plugin).
And tbh CanBuildFrom isn't even that hard to use. It's pretty simple to use it to write generic collection operations.
I corrected this by adding the proper resolver order. Update and you should be good, thanks for the feedback!
Sorry I missed this! It's a fair question; the short answers are: 1) I plan to continue using it and maintaining it, 2) I don't think that will be too much work; little development on the parts of the Spark UI / metrics stacks I care about has happened in the year I've been following the project, 3) being outside of Spark cuts both ways: it's easier to add things to Spree (and get them "released") than to change Spark's UI, and indeed Spree already has various desirable (imho) features that Spark doesn't (and likely won't any time soon), 4) there is not really any switching cost between the two. There is already at least one change in the JSON protocol coming in 1.5.0 that I know I'll have to port to Spree, but that should only take an hour or two; my plan is to do it once they start cutting RCs. Finally, I believe that Spark *should* be making it possible and easy to do things like this / not be beholden to one web UI that they don't really develop actively. If basic maintenance of something like Spree turns out to be out to be onerous because they offer no stable APIs to this kind of data, that's a bigger problem with Spark and that's a conversation "we" should all have if that turns out to be the case. Thanks, let me know if you have any issues using it!
I ran into a road block: after checking out the skeleton, I get hit up with an error in sbt: set ANDROID_HOME or android update projects -p C\foo\bar...' However, sh: android command not found I'm running this on Cygwin on Windows. Any ideas? EDIT: adding the ANDROID_HOME environment to Android SDK via windows (I have cygwin set up to use Window's vars, don't recall if it does that out of the box) Then I ran sbt run: ... bunch of output... then... [info] [SUCCESSFUL ] org.scala-lang.modules#scala-parser-combinators_2.11;1.0.4!scala-parser-combinators_2.11.jar(bundle) (895ms) [warn] :::::::::::::::::::::::::::::::::::::::::::::: [warn] :: UNRESOLVED DEPENDENCIES :: [warn] :::::::::::::::::::::::::::::::::::::::::::::: [warn] :: com.android.support#appcompat-v7;22.2.1: not found [warn] :: com.android.support#cardview-v7;22.2.1: not found [warn] :: com.android.support#design;22.2.1: not found [warn] :: com.android.support#gridlayout-v7;22.2.1: not found [warn] :: com.android.support#recyclerview-v7;22.2.1: not found [warn] :: com.android.support#support-v4;22.2.1: not found [warn] :::::::::::::::::::::::::::::::::::::::::::::: [warn] [warn] Note: Unresolved dependencies path: [warn] com.android.support:design:22.2.1 (C:\Users\MyName\Projects\scala-on-android\project\Build.scala#L19) [warn] +- helloscala:helloscala_2.11:0.1-SNAPSHOT [warn] com.android.support:appcompat-v7:22.2.1 (C:\Users\MyName\Projects\scala-on-android\project\Build.scala#L19) [warn] +- helloscala:helloscala_2.11:0.1-SNAPSHOT [warn] com.android.support:gridlayout-v7:22.2.1 (C:\Users\MyName\Projects\scala-on-android\project\Build.scala#L19) [warn] +- helloscala:helloscala_2.11:0.1-SNAPSHOT [warn] com.android.support:support-v4:22.2.1 (C:\Users\MyName\Projects\scala-on-android\project\Build.scala#L19) [warn] +- helloscala:helloscala_2.11:0.1-SNAPSHOT [warn] com.android.support:cardview-v7:22.2.1 (C:\Users\MyName\Projects\scala-on-android\project\Build.scala#L19) [warn] +- helloscala:helloscala_2.11:0.1-SNAPSHOT [warn] com.android.support:recyclerview-v7:22.2.1 (C:\Users\MyName\Projects\scala-on-android\project\Build.scala#L19) [warn] +- helloscala:helloscala_2.11:0.1-SNAPSHOT [trace] Stack trace suppressed: run last *:update for the full output. [error] (*:update) sbt.ResolveException: unresolved dependency: com.android.support#appcompat-v7;22.2.1: not found [error] unresolved dependency: com.android.support#cardview-v7;22.2.1: not found [error] unresolved dependency: com.android.support#design;22.2.1: not found [error] unresolved dependency: com.android.support#gridlayout-v7;22.2.1: not found [error] unresolved dependency: com.android.support#recyclerview-v7;22.2.1: not found [error] unresolved dependency: com.android.support#support-v4;22.2.1: not found [error] Total time: 178 s, completed Jul 30, 2015 3:29:45 PM
that was a really nice description, thanks 
We could really need some help with https://github.com/scala-ide/scala-refactoring or https://github.com/scala-ide/. You can reach us through https://gitter.im/scala-ide/scala-ide or https://groups.google.com/forum/#!forum/scala-ide-user.
&gt; Cannot run program "node" Seems like you need to install node :)
&gt; I have made an effort to recode the Javascript to mainly use Scala collections. What's your experience with using Scala collections in Scala.js in terms of speed and output size?
This is a thing it never does: complete normally. Expressions that can **possibly** complete normally cannot be typed `Nothing`, even if they almost always don't.
Is there a good reference for the Java memory model? I'm particularly curious about the semantics around data races. Ie, what is Java's [consistency model](https://en.wikipedia.org/wiki/Consistency_model)?
Each object get's it's own lock, which is employed using the synchronized keyword. Other than that there are various classes in `java.util.concurrent` that allow you to employ more sophisticated synchronization strategies. The oracle guide covers the basic stuff pretty well: https://docs.oracle.com/javase/tutorial/essential/concurrency/sync.html This page talks about the intrinsic locks on objects: https://docs.oracle.com/javase/tutorial/essential/concurrency/locksync.html
&gt; Is there a good reference for the Java memory model? Nothing beats [the JLS](https://docs.oracle.com/javase/specs/) for this. 
If you really want to dive deep into this subject, by far the best book on it is Java Concurrency in Practice http://jcip.net.s3-website-us-east-1.amazonaws.com/ The Java Language Spec also has a lot of information, but it can be some dense reading.
Such a great question. Java ecosystem is my bane as well. Do you know the difference between "percent" and "double percent" in SBT syntax? Helpful if you co-mingle Java dependencies with Scala ones.
Community chat sounds cool, but I must admit I'm hesitant to share my phone number :-/
You don't have the android SDK installed properly. Run "android sdk" in the command line and make sure that the support library repositories are installed. Maybe you just need to install some updates, because 22.2.1 has been released very recently. http://scala-on-android.taig.io/prerequisites/
Scala.js does use a DCE, which while being conservative, does a great job in reducing a lot of code. Personally my typical applications are outputted around 100-200kb in size, which is acceptable The DCE works best when all of your code reuses as much of the same library as possible, hence why I am recoding the Java collections to use Scala, because the clear majority of `Scala` developers do use Scala collections. In regards to `SodaTime`, the first pass I am going to do is to just use Scala collections, then I wan't to see if the business logic actually works fine, and then I will consider changing all `mutable` collections to `immutable` ones As an example, with the following code object ScalaJSExample extends js.JSApp{ def main(): Unit = { List(34,3243,324,234).map(_ * 3) } } The fully optimized output for that specific section is (there is of course the runtime ontop of this) Jg.prototype.main = function() { $c(); var a = (new C).ha([34, 3243, 324, 234]), b = $c().oa, a = Qe(a, b), b = $c().oa; if (b === $c().oa) { if (a !== F()) for (b = a.K(), b = Ne(new Oe, A(3, b | 0), F()), a = a.r(); a !== F();) var c = a.K(), c = Ne(new Oe, A(3, c | 0), F()), b = b.Od = c, a = a.r() } else { for (b = Te(a, b); !a.i();) c = a.K(), b.hb(A(3, c | 0)), a = a.r(); b.bb() } }; As you can see, in terms of speed, it would be fairly similar to the use of Scala collections (i.e. just like Scala collections, the Scala.js version does use CBF, and it does build intermediate objects to do that map) If Scala.js were to use something like this (https://github.com/nativelibs4java/scalaxy-streams) than I suppose it would be faster, until it at least gets `JIT`'ed (most modern javascript VM's do `JIT`'ing similar to JVM, the difference is that pre `JIT`ed code is more of a concern on Javascript than it is on server side JVM) In regards to output size, the full size of the example I just wrote is 160kb, and thats because `Scala.js` had to output the runtime for all the collections library. However if you were to add another thousand of lines of code, which just uses standard collections + standard scala stuff, it wouldn't add that much more code to the final output, hence why I want the `Javascript` version to use as much idiomatic Scala libraries as possible EDIT, there is a fantastic online tool http://www.scala-js-fiddle.com/, that lets you write Scala and shows you the output of Scala.js code, you can see the commands here http://www.scala-js-fiddle.com/gist/9443f8e0ecc68d1058ad/LandingPage.scala which allows you to show what the fully optimized output is
I think your approach should be to transform the parent node rather than the child node. That is, when traversing the parent check for the existence of the child and add the new element in the parent. Also, you can consider using [scala.xml.transform](http://www.scala-lang.org/api/2.11.7/scala-xml/index.html#scala.xml.transform.package). You need to express the transformation as a [RewriteRule](http://www.scala-lang.org/api/2.11.7/scala-xml/index.html#scala.xml.transform.RewriteRule) and then let the RuleTransformer do the traversal.
Having to rely on a nominal definition of Rank less than ideal. But off the top of my head you'll need other definitions of Rank2 for covariant and contravariant versions of A and B.
I just which people would move to the new Java 8 time classes and do these wrappers for those. *sigh*
From the amount of rejections I get for Scala positions, it doesn't seem to need me that badly. :(
Not the answer you want, but I have a rough thing that makes extensive use of the loan pattern to implement fully streaming parsing (including streaming string values), but am not entirely happy with the abstractions I have in place and wants a lot of cleanup. Anyways. This kind of parsing approach has very specific usage scenarios; namely where you are either concerned about the memory overhead of marshaling your entire JSON data structure into an intermediate form in memory (i.e. `JObject` or equivalent), or you have a data source which truly supports streaming. Otherwise you don't really win anything as a result of the memory and stack pressure from the closures. Encoding: writer.putObject { userWriter=&gt; userWriter.putString("firstName", user.firstName) userWriter.putString("lastName", user.lastName) userWriter.putObject("attrs") { attrsWriter =&gt; user.attrs foreach { case (n, v) =&gt; attrsWriter.putString(n, v) } } } Decoding: reader match { case JObject(userReader) =&gt; val firstName = userReader.property("firstName") { case JString(v) =&gt; v } val lastName = userReader.property("lastName") { case JString(v) =&gt; v } val attrs = userReader.property("attrs") { case JObject(attrReader) =&gt; attrReader read { case (name, JString(value)) =&gt; (name, value) } } ... } case _ =&gt; throw new Exception(s"Expected object at ${reader.path}") } Decoding is obviously the interesting part, here `objectReader.property` uses a `PartialFunction` to create what I call a `capture`. This is like a combined Future/lazy val in the sense that accessing the value of a capture causes the reader to be consumed, discarding uncaptured properties. There is also a `collect` method you can use to manually consume the reader and deal with these.
I think the article was talking more about committing to open source projects like tooling, essential libraries, or scala itself. I think part of the problem you may be having is relying too much on scala experience for the positions. We hire developers to write scala, but we are looking for great engineers -- specific scala experience is just a plus. In fact, getting to learn scala is one of the perks we offer to potential candidates.
Quite an awesome project!
Note: If you are using Firefox with restrictive cookie settings, the site fails to load because of a `SecurityError` related to Web Storage API. As outlined in [this super-user question/answer](http://superuser.com/questions/629525/how-to-control-websites-use-of-localstorage-in-firefox#771799), the trick is to add http://scalakata.com/ to the allowed websites (whitelist) in the cookie exceptions settings. @MasGui - perhaps the best approach would be that you set a test cookie, because that will trigger the cookie acceptance dialog in Firefox.
&gt; Scala Kata is an interractive playground. Genuine question - what does this provide that the REPL doesn't (other than pre-included dependencies)?
* render html * edit multiple lines * working autocomplete * type at position * syntax highlight * zero configuration (just need a web browser) * [and much more to come ... ](https://raw.githubusercontent.com/MasseGuillaume/ScalaKata2/master/IDEAS.md)
https://github.com/MasseGuillaume/ScalaKata2/issues/3
Personally very interested in a subreddit like this! though not sure how popular it would be
Any idea about the key differences to [json4s](https://github.com/json4s/json4s)?
I don't this subreddit gets enough traffic to warrant more specialized versions.
Errr, if you want to write a string to a file, it looks a little like this: val outputFile = new File(URI object/Path String here) val writer = new PrintWriter(outputFile) writer.write(yourStringHere) writer.close() If you want to easily save an object to a file, I like to use [scala pickling](https://github.com/scala/pickling) unless I need to be saving a lot of values. How to pickle to file: import scala.pickling.Defaults._ import scala.pickling.json._ ... val pkl = yourObjectToPickleHere.pickle val outputFile = new File(URI object/Path String here) val writer = new PrintWriter(outputFile) writer.write(pkl.value) writer.close() How to unpickle from file: import scala.pickling.Defaults._ import scala.pickling.json._ ... val inputFile = new File(URI object/Path String here) val outputObject = Source.fromFile(inputFile).mkString.unpickle[OutputObjectTypeHere] I'd recommend reading up on the documentation first before really putting this stuff to use though. This is all really very not production ready code and should only serve as an example
This is some great advice but my biggest takeaway isn't that mocks are bad (in some cases), but that developers should strive to separate their concerns. *Why inherit if you can pass in an object? Why pass in an object if you can just pass in a function? Why pass in a function if you can simply pass in a value - the results of calling said function?* My experience in the industry is that the biggest velocity-killer in an engineering team is dealing with a system with poor SoC. Developers are too willing to code what's easy to write as opposed to what's easy to later read and grok. It's almost a lack of empathy. If I'm changing some business logic, why do I need to understand how the persistence layer and/or the http layer works?
Flip side is some people overengineer to the moon, and you need to read 642 classes to see what is going on. If you look at his starting code to his ending code.. the ending code is smaller and tighter, but you need to trace back the method and think a lot more to figure out the flow. In this case I think it is clearly a win, but you can take it too far and end up with a mess.
thanks i really appreciate your help as beginner things get confusing and choosing between libraries is difficult 
Oh awesome, thanks
No problem! Happy to help C:
True, but passing in values can turn into the path of 154 fields inside the object you pass in, or 128 nested classes. In any of the cases, you need to try and keep the interface as simple as possible.
XPost Subreddit Link: /r/programming Original post: https://www.reddit.com/r/programming/comments/3frhv4/interview_with_matei_zaharia_creator_of_apache/
While this series sounds like it's going to be very interesting, I can't find any value in the existence of this "Day 0" post. Just start at day 1 with some actual content.
You are right. To be truthful, I posted this to twitter to let my friends know about the series I was starting with no expectation of much interest, then went to bed. Woke up, and it has a few thousand reads and load of shares/retweet, my head exploded and the result was "I'll post this to reddit!". I may have gotten over excited.
Hey all! This is the first release-grade anything I've ever put out there. I could use feedback on both my technique and how the tool handles. Thanks C:
Thanks! Well written introduction, looking forward to the next bits.
Hello, guys! This is my first post on reddit. I recently started using the functional programming paradigm after taking the course on Coursera and I tried to make a small library for parsing robots.txt and sitemaps. I would really appreciate a code review from somebody who has time! Thanks!
Very interesting! Can you please explain a bit, why did you decide to move to Pants?
Im debating doing this as an absolute last resort. 
I posted the code that worked for me. Let me know if it works. I had a similar solution to yours at first but the scala.xml.XML.withSAXParser(factory.newSAXParser).load(FileInputstream) didn't seem to work for me either.
&gt;If you look at his starting code to his ending code s/his/her/g
This is a common-enough concern with high-level languages in general that I wouldn't expect an article to provide context before addressing it.
This reminds me of my own small macro library: https://github.com/vn971/macro-format ("Logging based on Scala macros that gives line numbers and other") I wonder if my `typePrint` method does essentially the same as `trace` of yours. https://github.com/vn971/macro-format/blob/master/src/main/scala/net/pointsgame/macros/TypePrint.scala#L20
Unfortunately not yet. The talk was accepted in the Spark Summit Europe and I expect they will record the talks.
It looks like `typePrint` gives the type of the expression whereas `trace` gives the source code of the expression. I added `trace` with an eye toward debugging macros from other libraries after finding bugs in many macros like the Play-Json ones. I can think of a few non-macro situations where `typePrint` would have come in very useful though, I might consider adding such a function to Macramé.
Hard to believe that they did not mind that you had three years of Java and seven years of programming period. Thanks for answering.
And how do you get the x experience with stack y if you do not het the job. 
Well I was at a big Corp, and I started writing one off utilities in Scala... and some tests.. and slowly worked it into my job as a Java Dev.
Thanks for sharing. What type of utilities?
Whatever kind you want. Main thing is just to be programming. If you can thing of something related to a company you want to work for, even better. Stick it on github, so that employers can see the project and your progress.
As a scala shop, we'd hire a Java developer, if they know enough about big data/massively parallel/some other buzz word, and have actually tried to work at that scale. That usually involves a lot of concurrency work, wrangling the jvm, and dealing with io/cpu/memory bottlenecks. Having some functional programming experience also helps. A lot of programmers (even Java ones) don't have that level of experience.
Threads pop up like this every few weeks it seems, and the answer still remains the same. If you know Scala, you have your pick of jobs. If you're looking for a Scala developer, you have a long search on your hands.
ya I'd be one of them. Concurrency you really need to be in an environment where at least one person has wrestled that beast effectively before. Which sadly are places that usually don't hire you unless you have a lot of years doing exactly that and have a degree, at least in my small sample size of looking around.
Great, thanks for sharing.
Thanks
Seems to be quite hot: http://www.indeed.com/jobanalytics/jobtrends?q=scala&amp;l=
I haven't been able to find anything... but it would have to be remote and have reasonable hours for me to consider it.
Then the demand is not good.
Its not Scala's demand dropping, its that the tech sector is starting to begin its decline and the first sign of that is a reduction in demand for engineers. The number of open positions are down from what it was a year ago, its not bad right now, but it is decreasing. 
Reasonable hours?
Around 40 hours a week. Not 60 or 80.
Have you seen data for this? 
Well, it depends. I suppose if you are willing to move to SF or NYC and work 80 hour weeks, there are jobs to be had. I'd rather write Scala than Java, but not that much. 
Should be plenty of 40h jobs. Not everyone is crazy :)
Where do you live?
Interesting facts: * 2.9.X is dying slowly after two years * 2.11.X have a lot of traction * more than 60 000 scala artifacts are available In the last 3 graphs, the vertical lines represent Scala releases (milestones and release candidate are dashed).
I live 10 minutes from NYC, but working 80 hours per week is not in my list..
What tech are in demand in. Orlando, FL? Thanks.
I talked to a CTO recently who said if he were betting on a Java-killer, he'd put his money on Kotlin and thought that Scala had already 'jumped the shark.' So there's one data point. I, however, will be leading a hiring push again soon for our team in charge of a Spark/Scala analytics engine. So there's another. 
Not really. I relocated from there about 3 years ago because the market was pretty abysmal there. More supply than demand, especially with a flood of people out of UCF and UF. Most of it is older tech, especially since there's so much defense related work.
Most people are terrible at hiring. If you have someone who is a good team fit and smart they can pick up anything. One place I worked at gave me a bunch of CV's to sort through. I pulled out the good ones and handed then back. The manager came up to me with one of then and said "we can't hire him he doesn't have a degree", despite the fact that he had about seven years of directly relevant work experience. 
I know of three big investment banks in London, UK, who already have several years of investment in Scala. Demand here seems to still be increasing. 
I'd say the demand is higher than the supply, but both are still very low (probably one Scala job for a hundred Java jobs). 
This graph shows that the demand went from 0.02% to 0.06% over a period of three years... 
Kotlin? Lol. He must be an idiot. 
The typical stuff, Java, C#, PHP, C++. Java/C# for business type stuff, PHP for smaller websites, C++ for simulation. There's a lot of simulation stuff around here. The Scala job I saw was at EA, but I've heard really bad things about the hours there. There are probably defense places using Ada but I haven't seen them come up when I've been looking. FWIW, I'm doing the first, enterprise Java. It isn't too exciting but it pays the bills and I'm home for dinner every night.
I would think this has a lot to do with the fact that even though they are both billed as general purpose, Java is a whole lot more general. If you're a scala shop you're probably in the big data/distributed system space.
That's an odd claim, what can you do in java that isn't easier in scala? Or course actual usage is more general in java but that's inertia.
Oh, yea I just meant in cultural inertia. The variety of Java jobs is much higher than Scala jobs
Yeah, it seem like the primary advantage over Scala is its focus on Java-equivalent compile times (which is hasn't achieved, but is still much faster than Scala.) They also have a simple and terse approach to handling nullable types, though I don't see that it's all that different from using Option aside from only using one character (?). 
Yeah any canonical services using the typesafe stack would be great. I'm transitioning from Ruby on Rails to Play, and I'm curious as to how robust it is.
Ya so a case class works best for just pojos. Once you get super complex like a dao you want a normal class or class plus object. Just like in java it should live in another file. Object does singleton part for you so it is a bit less code than java... but for the same reasons putting daos in a controller is bad in java, it's bad in scala
http://lichess.org is written in Play + Scala + Akka and is open source: https://github.com/ornicar/lila
The thing is, using Slick, saving something to the database is as simple as using +=. This is one line of code. Moving that line of code into a DAO (separate file) seems so unnecessary. Edit: I may have mixed up my terminologies. I understand if I have a User Entity, I would have it in a separate file. It would include all the column mappings and also a UserTable definition. When I think DAO I think of it as containing functions such as find, insert, etc. Using Slick, in my Controller, all I need to find a User with a particular id is to do a filter: users.filter(_.id == id) Does it make sense to put that bit of filtering code in a function called findById inside a file called UserRepository? Or is it okay to keep that line of code in the Controller?
Great. Please keepp /r/scala posted. :)
i was wondering the same thing recently
I think it might only run once a year. I completed it in September and then had to wait about 9 months to take the Reactive Programming course that follows on it.
You shouldn't worry about that right now. As you gain experience, you'll discover new ways of doing stuff generically. Some take a lot of inspiration from mathematics. If you follow some tutorials, you'll soon find something called monads. You don't have to really know a lot about monads to use them, but if you're curious you'll probably end up reading some math on them. What's great with Scala is that you can choose what you get out of it. I know people who don't know much about math but were quite happy to use it. If you want to push things very far, it still allows you to. 
Sure, after you set up your build tool (maven of sbt) to pull the library (as specified in the link you gave), you'll just have to import the right classes to use them. Translating the java snippet they give to scala should take you very little time and will get you started. 
I would suggest using spray or akka-http instead of finagle. Finagle is much lower level and the documentation isn't as good.
To add on to this, the problem with using Scala to learn FP is that you can write a lot of Scala code without ever writing functional code which leads many to believe, incorrectly, that FP == lambdas + higher ordered functions or something along those lines. By using Haskell, on the other hand, you are *forced* to learn about programming without side effects, using persistent data structures, etc. and will come away with a true understanding of FP that can be applied elsewhere.
What is better for microservice webapplication scala or java? Which of both language has more support? I've hear about, that Scala is more suitable for research thing instead for restful web application it is true?
Scala sounds to be very complex language. How about compile time? 
Thanks for the update!
It's d3. The source for the site is [here](https://github.com/MasseGuillaume/masseguillaume.github.io/blob/master/index.html#L22). To collect the data I did it with [metadoc](https://github.com/metadoc/metadoc/tree/develop/bintrayScape/src/main/scala) and a [scalakata snippet](https://github.com/metadoc/metadoc/blob/develop/notebooks/3_distribution.scala)
Well compared to java I would say less code, fewer bugs, more easily maintained code. For example at lower levels of granularity if you use Options properly you get rid of null pointer exceptions. At a slightly higher level of granularity, learn to use immutable collections and probably most of your business logic can be handled with map, filter, foldLeft and friends. There is kind of an open-ended learning curve but its up to you how far you want to go with that. IMO if you learn the things I mentioned above day to day coding tasks become much easier in scala than java. Also you get very clean high level code easily comparable to say to ruby in expressiveness (for want of a better word), and much more powerful than say javascript, if dynamic languages are your comparison.
Do you have the link? 
&gt;There's more than one Scala. By that I mean it's almost entirely possible to redefine the language by operator overloading, and very easy to miss the import that's telling you this. Maybe, but i don't know if this is exclusive to Scala. Have you ever worked on a java codebase making heavy use of AOP and point cutting each method with additional functionality? It's worse than badly written Scala. You can screw up any language with irresponsible programmers. &gt;Scala is too young. There's not the support you need out there in any way that isn't condescending to read. I don't know what this means, Scala has been around a long time and there are a lot of best practices. &gt;Maintainability, if you're a java shop you're going to have a bad time. Depends on the level of programmers. I do think that it's easier for bad java programmers to ship a semi-working java application than a semi-working scala application. I consider this a feature. However, I've had no issues having smart folks jump right into a scala project and contributing without prior knowledge. &gt;Almost everything you can do in Scala you can now do in J8. Why would you bother? This is patently false. 
Scala nlp wraps around boilerpipe so you can extract text from non js web sites with it . It's probably the most complete solution you will find, but it's a bit hard to get into. The only thing is that boilerpipe tries to extract the main text without metadata. You might want to parse the HTML yourself for that.
Compile times are longer than Java, because the compiler does much more. However, it isn't really a problem any more, if you use an IDE with incremental compilation.
It is fun! I've been coding in Scala for a couple of years now, and there is no problem I haven't been able to find a creative way to solve with scala. It is an extremely powerful language and there is a lot to learn, but it is easy to get started. But if we were to compare Scala to the likes of Java, Three things stand out: - Readibility: Scala code tends to be to the point and not verbose. Especially when it comes to functional programming, although powerful and quick, Java 8 streams are still disgusting to look at. Its quite easy to understand a lot of library code without too much knowledge of the language (Just don't go headfirst into ScalaZ or Shapeless) - Anti-Null: Scala has developed a very strong "Don't use null" principle because of how easy option types are used. This makes your code much, much safer, no more null pointer exceptions! - Scrap your boilerplate: Take case classes for example.... A single line case class definition can replace 20 - 100 lines of boilerplate Java code. In terms of web services, Scala does exactly what it set's out too. It scales... really well. Scala frameworks may not be quite as barebones and simple as something like Python's Flask or Javascript's NodeJs. But id rather stick to a type safe language like Scala. But it really depends on exactly what your projects needs are. TL;DR It doesn't matter what you are doing now, Scala is an extremely powerful language that is worthwhile for every programmer to learn.
Remember you have all the java libraries/projects that can be easily used from Scala. If you are doing large scale web crawling [Nutch](http://nutch.apache.org/) (Java) is great but is overkill for anything that doesn't require a cluster. For modest crawling with detailed web scraping I usually create a small Scala program using the Apache [HttpClient](https://hc.apache.org/httpcomponents-client-4.5.x/index.html) and [Tika](https://tika.apache.org/) as well as [jsoup](http://jsoup.org/) libraries. For particularly difficult or tricky page crawling [Selenium](http://www.seleniumhq.org/) may be necessary but as the most complete configurations are not headless [PhantomJS](http://phantomjs.org/quick-start.html) that MasGui mentioned may be better.
I'd start your own project
Build more and more. Refractor, rethink and redesign. The more you build the more experience you gain. 
Don't HLists already map to case classes or tuples through the `Generator` object? How is this new?
I used [Scala-scraper](https://github.com/ruippeixotog/scala-scraper) for a personal project and I think it's good. It uses Scalaz behind the curtains.
Yeah, like I said: &gt; I don't see that it's all that different from using Option Though you didn't get it quite right. In Kotlin, a nullable type can be declared like String? instead of Option[String]
I may suggest looking at Spark. Big data is one of the areas where functional languages are most useful.
If you liked that course also take a look at Principles of Reactive Programming. It's considered a sequal to FPPiS. Not as good in my opinion, but definitely worth going through.
Scheme 😀
JDK8 provide new features like streams, can I use it in scala 2.11?
&gt; yes but I think akka-streams are superior I have searched in internet what akka is, but could not find good explanation. What is akka and for what is good for?
...ctional. Okay, I'll see myself out...
really or I do not understand.
If we are looking for java streams replacement/integration, isn't scala.collection.immutable.Stream closer than akka-streams?
You are probably better off using one of the [existing JSON libraries](https://github.com/lauris/awesome-scala#json-manipulation) for what you are trying to do. The reflect api is far from being usable without understanding a lot on scala's inner representation of types.
Well, but you didn't actually solve the problem, since you claim to not understand how your solution works. Instead of spending 18 hours to make that work, you could've spent a couple (probably much less) only looking for [this](https://github.com/json4s/json4s/blob/3.3/tests/src/test/scala/org/json4s/native/SerializationExamples.scala) and spent the remaining 16 on something different. 
Well done
Scala-2.11 requires JDK6+ to compile and supports JRE6+ Scala-2.12 requires JDK8+ to compile and supports JRE8+
great article, thanks for taking the time to write it
I enjoyed this and the example. I would encourage you to keep writing more articles and posting them :)
Shouldn't you pass along a `ExecutorContext` when playing with Futures ?
Awesome! At HuffPost, I led the project to rewrite our desktop content rendering engine using Play with its standard template system, SASS and JS, but if I could do it again, I'd use Scalatags, ScalaCSS, and Scala.js on top of Play. Looking forward to reading through this. Is there a good way to save the tutorial as one long page? I typically read stuff like this on Pocket.
Leads here: http://scalameta.org/ and here: https://docs.google.com/document/d/1Wp86JKpRxyWTqUU39H40ZdXOlacTNs20aTj7anZLQDw/edit#heading=h.foemem8hq66y.
&gt; it's unnecessary Yep. That's right. I've fixed an example in the article and the code in github
What's the advantage of doing that instead of setting a breakpoint and inspecting the values in your debugger? 
How similar is Scala.JS to actual Scala that is on JVM itself? 
The impact there is small. 23 seconds vs 28 seconds - the better score is with using case classes. Don't know why the performance gain for case class approach.
Interesting. Perhaps you're doing some pattern matching, which is an easy ride for case classes due to the way they're implemented. Anyways, glad you resolved the mistery :)
Remember Scala specialization. For 2 ints, there's Tuple2$mcII$sp class, and it has two primitive fields, specialized apply and specialized unapply. Unless matching happens in badly-typed context, it should perform no boxing. In fact, I tested that, no boxing happens: case class Field1(x:Int, y: Int) type Field2 = (Int, Int) def test1(f: Field1) = f match { case Field1(0,0) =&gt; "" case _ =&gt; "a" } def test2(f: Field2) = f match { case (0,0) =&gt; "" case _ =&gt; "a" } def main (args: Array[String]) { test1(Field1(2,3)) test2((2,3)) } compiles to the following: public String test1(TestTuples.Field1 f) { TestTuples.Field1 localField1 = f; if (localField1 != null) { int i = localField1.x(); int j = localField1.y(); if ((0 == i) &amp;&amp; (0 == j)) { str = ""; break label39; } }String str = "a"; label39: return str; } public String test2(Tuple2&lt;Object, Object&gt; f) { Tuple2 localTuple2 = f; if (localTuple2 != null) { int i = localTuple2._1$mcI$sp(); int j = localTuple2._2$mcI$sp(); if ((0 == i) &amp;&amp; (0 == j)) { str = ""; break label39; } }String str = "a"; label39: return str; } public void main(String[] args) { test1(new TestTuples.Field1(2, 3)); test2(new Tuple2.mcII.sp(2, 3)); } As you can see, both specialized constructor of the specialized class (`new Tuple2$mcII$sp(int, int)`) and specialized accessors (`._1$mcI$sp()`) have been used. There's virtually no difference between `(Int,Int)` and `Field1`... except for two extra unused fields in `(Int,Int)`, which are null.
Case class is smaller. The tuple `(Int,Int)` has 4 fields: `_1`, `_2`, `_1$mcI$sp`, and `_2$mcI$sp`. The first two are unused and null, the latter two are your ints. Your case class has only two fields, `x` and `y`. Also, if you are doing pattern matching in a context, where the type of the value which is typed against is unknown, it will box the fields of the destructured tuple: def test3(f: Any) = f match { case (a: Int, b: Int) =&gt; "T" * (a+b) case Field1(c, d) =&gt; "C" * (c+d) case _ =&gt; "xxxxx" } In the snippet above, `a` and `b` will be boxed, and `c` and `d` will not. If the pattern matching is in context which knows that you are using an `(Int, Int)`, it will not box the fields needlessly.
Thanks for reply. My background is ETL development with Oracle + Python in Unix environment. Why Spark? -&gt; jobs with pure ETL tool drying up, pure DB development pays less $$. I can cite Google trends and avg salary rates in USA [dont have them on me right now] edit: Hive etc seem easy for someone coming in from db development background. Question about hadoop distros is just because there is so many of them.
Since the Clojure discussion threads were cross-linked across subreddits, I figured the new Scala discussion thread might as well be, too.
lihaoyi you are a cornerstone of the scala community man! 
As mentioned by some people at ScalaDays, it's likely that new or existing bytecode converters will pick up as the differences between Java 6 bytecode and the Java ecosystem out there become larger. So when you decide stop compiling for 2.11 (which is not really a pressing need, because 2.11/2.12 are even more compatible than the usual major releases) you can just pick whatever third-party tool is popular at that time and use it to create Android-compatible bytecode. You could also just let the 2.12 compiler compile to Java 6 bytecode, it's not like you have thousands dependencies on Android anyway.
It would be more interesting to hear from languages that learned from or were inspired by Scala, e.g. Rust, Swift. What parts did they take, which ones they modified, which ones they decided not to pick up, and for what reasons. I don't think there is a single Haskell user that thinks Haskell could learn something from Scala (other than wishing for commercial success), so the number of interesting statements goes towards zero. Odersky quite nailed it with the Haskellator joke.
I don't think they were that smug. There are many valid and/or interesting critiques there. And I'm happy I read and learned from them. What I find incredibly amusing/ironic is the complaint about the "unpleasant"-ness of the Scala community when a significant portion of that unpleasantness comes from the Haskellers who used to feel deeply compelled to fill the Scala community with negativity, vitriol and snark, ad nauseam. Years ago I immediately would have agreed that the Scala community was incredibly unpleasant. But I kept pushing through and eventually realized the community also contained many of the most brilliant, positive developers I've ever met. And that the pessimists were a vocal minority - the usual suspects - community poison.
I've never used such an learning algorithm, can someone tell me what's possible with that particular library? 
Weka is a widely used machine learning library in Java. My understanding is that the author here tries to create an ML library that is better suited for Scala, but also better performing, while wrapping Weka for things not yet implemented. A typical task is to take samples of input vectors and then group them through analysis (e.g. regression) into categories / clusters.
Oh dear.
I think it's instructive. The Clojure subreddit did a reverse post and everyone was very willing to learn from how others viewed Haskell. I do agree with you that the idea comes across as smug but I think in practice people have managed to keep it civil.
Sadly not enough :-) ... see insane stuff like `&lt;T&gt;` for generics and the whole range of bad consequences that brought with it ... or repeating Scala's mistake with procedure syntax.
I spent a bit of time on StackOverflow [scala], and there are some very knowledgeably people on there. Questions are answered very quickly. I think they're nuts. You need to be able to separate a real difference in technical understanding from a personal attack.
+1000 I mean, the whole comment I find about `Scala` people being unfriendly coming from Haskell people I find hugely ironic, because at least personally, the unfriendly people in `Scala` are the ones that come from a Haskell mindset (heavily push for pure functional programming) Also, their common criticism of TCO seems to display a lack of knowledge as to why Scala doesn't have full TCO. There is a no fundamental design reason why Scala doesn't have full TCO, its a limitation of the JVM in regards to the security model (you can't just `jump` in the JVM to another method/function without allocating stack). Every single language that targets the JVM has this problem. Clojure doesn't have full TCO (it has its own workarounds). Heck, not even https://github.com/Frege/frege, which is a Haskell clone on JVM, doesn't provide full TCO (they do the exact same thing as Scala, they convert local TCO into a while loop, but just like Scala, they are unable to perform full TCO) Reference: http://stackoverflow.com/a/10031879/1519631
You're absolutely right. Thanks for the heads up on this.
&gt; "it's familiar, that means it has to be good!!!" I hate this so much.
&gt; Either the symbol before a &lt; is a type-name that requires a type argument, or it's not. Which is nothing a parser should decide. &gt; What am i missing? https://doc.rust-lang.org/reference.html#paths
Providing syntax which looks like a standard method when coming from Algol-like languages but silently discards its result instead.
That's true, but also an unconstructive generalisation. There are specific things about "programming in Haskell" that Haskellers like (otherwise they probably wouldn't be programming in Haskell) and figuring out which those are in relation to other languages is a useful activity if you're interested in PLs. It's not about "it's not Haskell!" It's about "It's lacking so-and-so feature, which I think is important because so-and-so, and so-and-so replacement doesn't give me quite the same reasoning capabilities." The counter-threads and arguments are also a useful time and place to learn about misunderstandings people have about languages. The Clojure threads lead to me learning a bit more about how to go about Clojure development in a way that makes you stay sane, to the point where I'm curious about giving Clojure a second shot. That wouldn't have happened without the discussion about what makes the languages different/similar. ---- N.B. Although I pop into this subreddit every once in a while, I'm not a subscriber to it and I followed an np link here from /r/haskell. Just thought I should be honest with that.
When I come to the scala page, I always see this ad for "deeplearning4j". What is the main difference between the two? Do they have different goals ? Anyway keep up the good work I like the idea of having a faster Weka! 
Nonsense, you can pull out yacc and make a LALR parser in a few minutes that can differentiate between the two cases. It's a state machine not a simple parser like you would make for general purpose use in your programs.
I don't think you are getting it. As I have already mentioned, C++ and C# have shown that you can do practically everything during parsing, but that still doesn't make it a good idea.
Take a look at @kmett's answer - https://www.reddit.com/r/haskell/comments/1pjjy5/odersky_the_trouble_with_types_strange_loop_2013/cd3bgcu
What your saying is making me think that you're confusing lexers and parsers. Lexers just break the text into tokens, parsers put the tokens together according to a grammar. This grammar normally includes how to define a type (assuming your language allows it). There may be simpler parsers out there, but C++ and C# are not special cases. 
For god's sake, please at least try to understand the problem, instead of simply assuming other people are stupid.
You've had a few posts now to demonstrate any actual knowledge on the subject. I dont see any real problem with &lt;T&gt;, and i guess i'm leaving this conversation with that perspective intact.
The problem is not that it is not possible to parse, but that it for multiple languages makes it more difficult to parse and handle than it could have been. It requires involved solutions, such as complicating the syntax of the language (for Rust, in the example /u/luigisfriendship linked, `id::&lt;i32&gt;` instead of `id&lt;i32&gt;`, and for C++ in earlier versions, using `&gt; &gt;` in template usage to distinguish from the operator `&gt;&gt;`) or complicating parsing considerably (C++, though the front-end is already very complex for C++).
Rust has numerous elements which are similar or identical to those in scala, and they have more on the way. That said, I don't think they were inspired by or learned from scala - which is not praise. They had this amazing guinea pig full of lessons about what works and what doesn't, what buoys the language and what anchors it, where features intersect synergistically and where they intersect antagonistically, etc. As is par for the course among language designers, they acted in effectively complete ignorance of scala. It's easy to verify this via their archived discussions. When there's a lot to do, people usually throw themselves into the doing, and the first casualty is any knowledge of what has been done before. [Here's an example](https://github.com/rust-lang/rust/issues/26187). There's no excuse for working out fundamental namespace considerations as they go.
&gt; other than wishing for commercial success Let's not pretend like Scala comes to mind when people start building new servers as a potential go to. *Some* people use it, doesn't make it commercially successful compared to Java, Python, (even PHP) etc. 
permute or mutate?
It's shortened from "create a modified copy", seriously though, it's the most fitting short name.
Mutate's pretty good: reproduction with modification.
I would use 'modified-with' instead of 'modify-using' but both are reasonable.
A limited form of TCO that compacts several recursive calls to one method into a single stack frame might not be *too* bad, but full TCO which eliminates the stack frames at any tail call (even non-recursive ones) sound like it'd be really weird on the JVM.
You do it yourself.
If you don't/can't process more messages while waiting for the ACK, the ask pattern can help, as it gives you a Future you can Await.ready() on. Ideally you would use ! and write your code in a way where you can send the query, go do something else, and then deal with the response when it comes later. (EDIT: you just add the ack response handler as another case in your receive) Don't spend too much time in in the ?, especially if you're sending lots of messages.
I mean, if you start using Synchronized inside an actor you are likely doing something wrong. An actor can have private mutable state. Either a var of something immutable (list? vector?), or a val of something mutable (ArrayBuffer?). In neither case do you need wait or notify or synchronized (unless maybe you need to do some reaching into shared mutable state, but in most cases that is a sign you are doing it wrong). Maybe something like the work request pattern is a better fit for you? A master has a bunch of work to do.. workers ask for work when they are free. Few links about it, for example http://letitcrash.com/post/29044669086/balancing-workload-across-nodes-with-akka-2
I know, but i have an actor that can receive several messages but that can handle just one. I'll try to read the example
well part of your problem is probably that you are implementing some method called act, you should be implementing Actor's abstract method receive. you shouldn't need while(true), you just define the receive behavior case by case and then have the actorsystem instantiate the actor and it should stay running until it has context.stop() called on it. maybe play with this simple ping pong example to make sure your actors keep running: http://alvinalexander.com/scala/scala-akka-actors-ping-pong-simple-example no matter what your actors should not be sharing any mutable state across one another. you want to share by communicating, not communicate by sharing.
To add to /u/TunaBoo 's message, step back and really think about your whole problem. If this is kind of a low key problem then a simple ack will work. If it needs to be dependable and maintainable, then it takes careful consideration. Akka is the assembly language of building distributed systems. You want layers and layers to build actual robust working systems. My preference is to build a nice dsl for statemachines and have that be my distributed building block. Distributed systems are nothing like writing regular robust code. Anything at any time can and will fail, and often under heaviest load, ie when you need it the most. Think about all the code paths. Now, imagine power going out on any given machine at any particular point, your code needs to handle that. Log everything, from all machines and pipe it into something like elasticsearch. Make your messages [idempotent](https://en.wikipedia.org/wiki/Idempotence#Computer_science_meaning) so they can be resent and reapplied to things. Also, GUID everything, states, messages, db transactions, whatever prompted the message to begin in the first place, etc. But dont be discouraged, we have to start somewhere. Its a lot of fun, and a great skill to have. 
I really liked to read this, fun and useful
I wonder why Typesafe didn't write it in Scala in the first place? I'm new to Scala, so I don't know that much about Typesafe, but they are clearly big Scala users.
But then we end up needing all these stupid wrapper libraries…
If you are using ENSIME, the debugger often doesn't work. (Harsh but true.) And jdb doesn't support that. So it's useful for people who prefer to live in emacs / command-line (or whatever else ENSIME supports, like Sublime Text).
[Knobs](http://oncue.github.io/knobs/), a purely functional config library, also supports the Typesafe format.
I also use ficus, whats the difference between the two (if any?)
Really great, thanks :)
Semigroups and monoids are not category theory.
I wrote something like this once, but unfortunately it wasn't open sourced before I left my last employer. It built upon the typeclass approach to deserializing configs, but was also designed to allow for a chain of configs that override each other, for use in defining environment-specific configuration. It also let you essentially define a schema for your application's configuration in terms of a Scala class, and fail immediately upon startup if there were any unused or absent keys (usually a sign of a human error in editing the config).
Yeah, but that concept is much more general than normal monoids. The monoids described here are a of [abstract algebra](https://en.wikipedia.org/wiki/Monoid).
Yet another monad tutorial, and a pretty mediocre one at that. Case in point: &gt; So a Functor maps from A =&gt; B whereas an applicative functor maps from F[A =&gt; B]. The first example maps from "A" to "B", ok. The second example maps from... "F[A =&gt; B]" to... what exactly? 
When someone says "semigroups and monoids", you can be reasonably sure that they mean "something like a group but without an inverse", not the generalization to "an object from a monoidal category along with two particular morphisms". It's unfortunate that people often play fast and loose with terminology and use the same term for both. 
Poorly worded. You have an `F[A=&gt;B]`, you give it an `F[A]`, you get an `F[B]`. Because of currying, this can be applied to n-ary functions.
No, what you are describing is not `F[A=&gt;B]`, it's `F[A] =&gt; F[B]`: a function which, given an `F[A]`, produces an `F[B]`. `F[A=&gt;B]` is not a function, it's a type. For example, it could be a list of functions that take an `A` and return a `B`. 
Maybe english isn't his native language. (I share your irritation about mundane things like this, but it's not really worth the outburst..)
I'm assuming this is for fun? Because I believe there are server/client libraries out there which will hide the implementation details (websocket/long polling) and use the most efficient one with the same code base.
&gt; You might be looking at that explicit iterator and thinking OMG, why do we need this? Think about it. "OMG, why do we need this?" We have [take while](http://www.scala-lang.org/api/2.11.5/index.html#scala.collection.Iterator@takeWhile) ;)
Yeah, when I started I assumed the iterators for mutable collections were mutable as well (as they are in Java) but they aren't :( Looks like I forgot to change back to take while.
I will rest on the stupidity that started the conversation: &gt; All languages ever created had to invent elaborate hacks, like C#'s "let's just keep parsing until we get an idea what &lt; was supposed to mean and go back and fix up the parse tree retroactively" Then i corrected you and said most parsers have context, and don't need to do this. To which you replied with some gibberish about context-free parsing, and that: &gt; That ambiguity has to be dealt with. Language implementers sometimes add context to the parser and sometimes live with an ambiguous parse that must be disambiguated later. Either solution is painful and complicated. I replied by saying that it was neither painful nor complicated, and gave examples of popular modern languages that use context, including Haskell. I also asked for examples of context-free grammars in wide use today -- to which you replied with zero examples and this nonsense about Turing completeness that is completely off topic. I don't believe for a moment that you aren't completely aware of how stupid your argument actually is. But you really got me good with the down-votes.... great job. EDIT: and for your edification, Lisp is homoiconic, meaning that it's syntax representation is the same as its abstract syntax tree -- they do this so that rules/commands can be rewritten on the fly, allowing them to make powerful macros and the like -- so yes, context free parsing has everything to do with how the code will be interpreted because you cant blindly rewrite rules if you dont have all the context, making such a macro system impossible. Perhaps you should learn a few more languages before you go out and try to debate people about them. 
You call me stupid, but you can't even tell comments made by different authors apart? :-) You had at least three people in this thread trying to correct you. Do you have an estimate how many people are needed for reason to win over your hurt ego?
For me the design of Akka Streams is ... conceptually ugly. The Typesafe folks are doing the same mistakes as with Play's Iteratees and with Akka IO pipelines. Akka Streams is hard to understand, hard to use and needlessly complicated. A common trait here is that the source-code is very hard to understand and this isn't about not knowing or understanding concepts, because I personally do, but because the source-code is ugly and disorganized, with internal interfaces that don't make sense. And as for design, the whole explicit "fan out" thing defeats the point of using streams. A stream of information is like a river. Does the river care who observes it or who drinks from it? No, it doesn't. And yes, sometimes you need to share the source between multiple listeners, sometimes you want to create new sources for each listener. But the listener shouldn't care what sort of producer it has on its hands. In Akka Streams the sources have a "single output" port and what you do is you build "flow graphs" and sinks. In Rx (Rx.NET / RxJava) terms, this is like having single-subscriber Observables and then working with Subjects (which is both a listener and a producer) and people that have used Rx know that working with Subjects sucks and when you do, you usually encapsulate it really well. This design choice of Akka Streams has actually leaked into the "Reactive Streams" specification, as that Processor interface is irrelevant and probably unusable in Rx. And then there's the whole thing that the library depends heavily on the whole Akka library, so for example it won't get ported on Scala.js, though granted, the reactive streams specification makes it interoperable with other libraries. And I get it, it's a cycle - they keep throwing experimental things over the fence, then they deprecate them when new things come out. But in this case there was a totally usable design already there, that needed only minor modifications for supporting back-pressure and it would have worked just fine. Instead they preferred to reinvent the wheel.
Thanks for making us aware of this site and adding the group. Looking forward to meet you on Tuesday.
I think there are some other bug fixes related to Scala (actually for now it just seems to be https://github.com/scala/scala-asm/issues/8, which I hit myself, but there may be other changes)
What would you recommend instead? RxJava? Scalaz streams? Orleans? Something else?
Wow, guys, have you googled "scala Spark" before picking that name ? 
Seems that you can solve you problem typing the messages and changing the behavior context: [http://www.deadcoderising.com/2015-05-26-akka-change-an-actors-behavior-using-context-become/](http://www.deadcoderising.com/2015-05-26-akka-change-an-actors-behavior-using-context-become/)
If you do a change of context, the messages will be received and you will have to handle them, so M3M4M5 are received in the stop context, you can do what you want with them :P If you just print in start context and discard in stop, it will print M1,M2,M6,M7 and discard the others. If you want to print the ones received while in stop when you become "start", you will have to save them and print when the start arrives, before changing of context probably.
You can also benefit from reading http://doc.akka.io/docs/akka/2.3.12/scala/actors.html#become-unbecome and http://doc.akka.io/docs/akka/2.3.12/scala/actors.html#Stash The official documentation is simply great. Those two paragraphs should be enough to do what you need.
Thanks, seems interesting! Offtopic: does anyone know how to jump to `unapply`-s using an IDE?
Not mentioned in the article (or anywhere else as far as I can tell -- I recently searched for it), the same works for `unapplySeq`. I had to dig up the original PR which contains an example: https://github.com/scala/scala/blob/b3d9dfa9857aeb937a987536b3e2029d3be0030b/test/files/run/string-extractor.scala
Hm. At least for me, it doesn't jump with the following code: val Some(a) = Some(1) And my real use case is with pattern-matching: Some(1) match { case Some(1) ⇒ 1 case _ ⇒ -1 } That's not a critical question though, I usually find the right method by inspecting the accompanying object.
Which IDEA version are you using? For me it jumps to the `Some` case class. Since it's a case class, there is no source code for `unapply`.
Sorry, what is the theme used here for the code snippets?
Ah, right, sorry. (It's a case class, there's no separate `unapply` visible.) Thanks)
Agree with you that this is kinda a hack, but the JVM doesn't work well with value classes (well the custom ones that aren't primitive values). Even when you do use a value class, Scala doesn't guarantee you that it won't box (http://docs.scala-lang.org/overviews/core/value-classes.html) `Some(null)` is actually mainly used to avoid a runtime check, it doesn't make sense if `Option` were an actual value class
Scala.js integrated with play framework is almost a killer scala app. It makes it so easy to write javascript apps. 
The `x: Foo | Bar` syntax seems awesome. What is preventing (or at least discouraging) the addition of unboxed unions to ScalaJVM?
Activator is an extra layer on top of sbt, though. Most concerns about sbt's ecosystem apply equally to activator.
Simply check the version of sbt it's written for. I would say if a plugin works only for sbt 0.7.x, it's probably stale. If it works for 0.12.x or 0.13.x, probably it's fine. Are you having a particular plugin in mind? I would simply ask the question which functionality do I need, then I look if a plugin exists. I'm no worried about stale plugins just because they exists (I'm sure there are, because it's in the nature of open source projects, but I don't see a problem). &gt; Should I use Gradle? No. Unless you enter a situation where sbt can't help you, which I doubt exists. &gt; A perfect example of this is sbt-proguard Last updated a year ago. I wouldn't call that stale. It runs with current sbt versions, I am sure it's in heavy use for Android development. No reason to expect updates on a monthly basis if "it works".
Well, I take it back. One *can* implement the same unboxed pseudo union type in user space on the JVM. One just has to `import Union._` to make it work (and not just `import Union.|`), and you need to enable higher-kinded types. Implementation: http://www.scala-js-fiddle.com/gist/7d777698fa4d85f5932a (yes, I know, it's a Scala.js fiddle; but it doesn't use any JS feature, so it typechecks the same on Scala/JVM)
Ah ah! Yeah, right, the *inner* `Som` is actually boxed in a boxed `Opt`, but the outer `Som` isn't. That's cool! Small improvements: you probably want: * `Opt[+A]` * `val Non: Opt[Nothing] = (new Opt[Any](null)).asInstanceOf[Opt[Nothing]]`
Well looky [here](https://github.com/EsotericSoftware/kryo/issues/189). I was under the impression kryo is a fairly commonly used library for scala projects, surprised there is such an issue. Guess I will need to convince everyone to try to trust the newer version(but based on this trusting the older version was probably meaningless).
I've used both for quite some time (not a professional dev) until relatively recently and honestly, both of them have their quirks and flaws. I haven't encountered any problems that would be significant enough to make me switch either way solely because of them, so I would recommend choosing based on which IDE you prefer.. (Eclipse/IntelliJ)
https://github.com/lauris/awesome-scala
This is exactly my experience as well. I use Eclipse, and while it basically works, some things are broken. My coworkers that use IntelliJ report that it basically works, but a different set of things are broken.
&gt; Should I use Gradle? If you want, go ahead. Or use Maven, even. Gradle is a decent tool, modulo some problems (like any build tool). SBT is often put forward as *the* Scala build tool, but there's no requirement that you use it (except for Scala.js, grr). 
Of what year? 
I'm sorry, but it's my first time using scala swing. The documentation is old and there isn't anything useful for my application :(
You need to find the solutions on github, I have done the course but I have no way to access my solutions. https://github.com/tonyskn/coursera-scala
The compiler does define two different functions and decide at compiletime which one to call. The problem is, Scala wants compatibility Java, and Java wants eternal backwards compatibility with itself. This means that functions are named *after* their types have been erased. So, the method with the source name `def f(s:String):Unit` is the same method with the classfile name `f(Ljava/lang/String)Z`, `def f(s: Seq[Int]):Unit` becomes `f(Lscala/collection/Seq)Z` and `def f(s: Seq[Double]):Unit` becomes `f(Lscala/collection/Seq)Z`. Both Seq-parameter methods want the same classfile name, and a classfile isn't allowed to have two methods with the same name. Now, why couldn't the scala compiler give `def f(s: Seq[Int]):Unit` the classfile name `f$$SeqInt(Lscala/collection/Seq)Z`? Again, java compatibility: it would be weird for a method to have a normal-looking name in Scala, but to be have a name with dollar signs and other magic when called from java or other JVM languages.
Maybe test the generated unapply? `val Point(a, b, c) = Point(1, 2, 3)`
&gt; val Point(a, b, c) = Point(1, 2, 3) I had tried simply calling unapply with a Point, and that didn't work, but alas this didn't do the trick either. However, you still earn about a thousand points because my mind is blown by this declaration--still learning Scala from Java and... what exactly is this doing? Assigning the three doubles to local ~~variables~~ values a/b/c? EDIT: Nevermind, Google answered my questions. This is neat! Thanks for the tip off.
What was the answer?
Oh, sweet grammatical ambiguity... I meant that Google answered only the questions I had posed to /u/tpolecat, not that the thread itself had been answered. Indeed, I really stuck it to Google trying to figure this one out but couldn't find the right search terms, I guess. This thread exists simultaneously in several places and I have yet to receive an answer, but rest assured I will update when I do.
I got halfway through the article before realizing when they're talking about NLP they don't mean "natural language processing", they're talking about the widely criticized/discredited pseudo-science ["neuro-linguistic programming"](https://en.wikipedia.org/wiki/Neuro-linguistic_programming#Scientific_criticism). 
both: &gt; Internally we use Natural Language Processing algorithms to parse incoming text and then we apply our sentiment analysis to it. &gt; [...] I have been decrypting the deep hidden meaning of people’s communication using my knowledge in Neuro Linguistic Programming (NLP) technology. I wonder if maybe the founder only said "NLP" during the entire interview, and the the journalist helpfully expanded it out for their readers, but looked up the wrong NLP? I don't know anything about neuro-linguistic programming. Does it make even make any sense to "use neuro-linguistic programming technology" to do sentiment analysis?
Stop shooting for 100% coverage. Code covered doesn't mean the test is useful, trying to achieve 100% at all cost will make you write useless tests. Likewise, just because your code is already covered doesn't mean it is correctly tested.
In terms of long hanging fruits that is pretty much the solution anyway. I normally reserve full compile cycles for whenever i change branches, update dependencies and so on. for normal development sbt brings the compile time down to a few seconds, depending on how deep down in the graph you changed code.
Ahhhh, ok. Godspeed!
Yes, OP, this. As it is your current tests are virtual cut/pastes of the code it is testing so has marginal utility anyway. 
Thanks for the correction! If I understand correctly, the method to be invoked is determined at compile-time with compile-time types. At runtime, dynamic dispatch on the receiver of the method will look for the method in the runtime class of the receiver, and its superclass and so on, until it finds an implementation.
this is like asking for a better way to pound nails with a wrench over using a hammer. why aren't you using sbt? it's kinda wonky but incremental compilation is insane. can take a 60 second compile to 3 seconds.
Everyone will say switch to sbt, and unfortunately they'll probably be right. Sbt is hell to understand and maintain but its incremental compile works really well, even on big multi-project setups. The speedup is (usually) so huge that it's actually worth putting up with all the warts. source: six years and counting of using sbt in (often real) anger 
There isn't anything specific to the scalac compiler that will magically make it go faster (which is what ant is using, I assume). You can do changes in the actual source code which will make scalac go a bit faster (a basic example is specifying return types of functions explicitly rather than making scalac's type inference figure it out). The thing is, and as Martin has specified many times, the scalac compiler is quite slow (especially when compared to java compiler), and thats because the scala compiler has a lot more work to do when compiling code. This is why more effort has been put into the incremental compiler (which is what sbt uses) to make it smarter. Note that there is work in making the scalac compiler go faster, but a lot of that is being put into the new implementation of dotty. scalac is so massive at this point, that apart from addressing regressions, any major improvements to compilation speed would probably require a very significant rewrite
Why do you need Ant ?
https://gist.github.com/kevinmeredith/1e899f38717be37c321e perhaps will help
You can allways build it with standard java swing. I managed to make an UI for a game in scala swing but moved on to javafx.
A choice of tools isn't necessarily based on a notion of "good." Oftentimes, it's based on what one knows. Personally, I find Ant/XML awfully ugly but ugly is in the eyes of the beholder.
Since you have handcuffed yourself to a bad tooling solution (lack of IDE and Ant, two really bad choices for Scala) about all I can suggest is working out how to split your project into a series of sub projects so you can avoid compiling them when you don't need to. Its never going to reach the incremental speed of SBT or Eclipse but its a broad stroke towards what they do on a much more granular level.
Thanks for getting back to me! &gt; This is why more effort has been put into the incremental compiler What do you mean when you say "incremental compiler"?
I don't like the XML either. Simple things like copying files is a pain. But Ant does not force my hand in how I layout or compile my projects, and that is one of my biggest values in a build tool.
I definitely don't need it, but it allows me to do things the way that I want to (e.g. not requiring a particular file system layout). 
It only compiles changes. Sbt can be setup to do this. 
I understand you have your reasons, but I would seriously doubt that it is less effort to restructure your code base simply to gain a few seconds of compile speed, versus converting the `build.xml` into a `build.sbt`. If you really need Ant for some reason, perhaps you can run sbt as an ant task somehow?
*It will by default unless you do a clean
Also if you embrace convention over configuration.. you just learn to put your crap in the right place, and then need 0 work to build. Very seldom do you REALLY need to name your src folder MEH_SOURCES over src (and if you do, you can configure it in SBT.. but why?)
Thanks!
I had a tough time with SBT when I had two dirs with jars (runtime and build-time dependencies). This was ~1yr ago. Maybe it's easier now.
&gt; You are using source control, right? I do have an aversion to some standard tools, but I'm not crazy :)
you can use [sbt-protobuf](https://github.com/sbt/sbt-protobuf) to remove half of this boilerplate
Good to know
&gt; but have always walked away after a couple hours of banging my head against the wall. I hear you!
They write: &gt; Most code is easier to reason about with a simple loop and explicit state machines. Expressing it with tail recursions (and accumulators) can make it more verbose and harder to understand. For example, the following imperative code is more readable than the tail recursive version: // Tail recursive version. def max(data: Array[Int]): Int = { @tailrec def max0(data: Array[Int], pos: Int, max: Int): Int = { if (pos == data.length) { max } else { max0(data, pos + 1, if (data(pos) &gt; max) data(pos) else max) } } max0(data, 0, Int.MinValue) } // Explicit loop version def max(data: Array[Int]): Int = { var max = Int.MinValue for (v &lt;- data) { if (v &gt; max) { max = v } } max } Both versions are ridiculously ugly. Maybe they should learn functional programming *properly* before writing a Scala Guide. Better version: def max(data: Array[Int]): Int = data.fold(Int.MinValue)(_ max _)
Thanks. From what @blarg_industries has shared, zinc is the incremental compiler that SBT uses (or maybe it's zinc is the incremental compiler that has been pulled out of SBT). I've been looking for an incremental compiler that does not come with a bunch of other bells and whistles. zinc may be just that.
&gt; apply Method Nope. Sometimes useful. &gt; Call by Name Nope. Often useful. Ex. logging, requirements, thunk args. &gt; Multiple Parameter Lists Nope. Sometimes useful. Esp. trailing function arg + type inf. &gt; Symbolic Methods (Operator Overloading) The reason they call this "operator overloading" already indicates that they haven't really understood the difference between Scala and Java. And yes, symbolic methods are useful. &gt; Implicits Use them 100% of the time. A core feature of Scala. &gt; Traversal and zipWithIndex Wrong. Don't use `while` loops. Unless you have a performance bottle-neck. In the other 95% of the cases, use Scala collections they way they are intended. Safe yourself from stupid errors. In summary: Yes, perhaps that company should use Java or Kotlin. Because apparently they don't want to use some of the core functionality of Scala. But perhaps they are better off using a Java'ish Scala and at some point when the team is more mature, they enable these functions and they don't regret they don't exist. Or perhaps these guidelines mean: For a novice Scala programmer who is designing some API, think carefully if the above features are necessary. You don't need them all the time. But rejecting them categorically is plain wrong, they are really part of a good Scala style. ------------- __Edit__: Reading again through the original document, I think you must also consider the bigger picture. First of all Spark is operable from Java, so probably they are afraid of introducing too much API that is cumbersome to call from Java. Second, many words of cautioning are qualified by saying "for a novice programmer" or "for someone not familiar with Scala". So I would say the intent here is to maintain a codebase that is easier accessible to people who are unfamiliar with Scala. Ergo, I wouldn't call this a style-guide applicable for a general Scala project. Thirdly, the examples the OP has chosen make up only a small fraction of a lot of other recommendations, many of which make a lot of sense.
Well, for what it's worth, Kotlin's for loops are fast :)
That's cheating. How would you implement the method `max`?
This looks great, I've been putting off writing unit tests for a while now for my web app. I'm going to give this a shot, thanks for sharing.
That databricks style guide is garbage. The fact that 1) they don't differentiate between implicit parameters and conversions and 2) they only mention Classtags as an example of implicit parameter usage shows their lack of proper understanding. 
For what it's worth, there is no reason for-loops cannot be optimised for well-known cases in Scala, too. https://github.com/nativelibs4java/Scalaxy/tree/master/Loops
This method is already defined for `Array`. Anyway, if it were not, using the proposed `fold` seems to be a much better solution than the 9 lines of code above.
The catch may also be: they write "Databricks guide", not general-purpose "Scala guide". It may be that they target lots of Java developers and Scala newcomers, and they don't expect to change that in time. This goes in contrast to Scala as the language, which also targets Java developers, but converts them to Scala developers by showing all the good stuff.
Interesting. As I see it, some kind of crawler or endpoint triggering script might come handy.
The problem is `reduce`'s signature in this case. Because Int.Min doesn't make in sense in the case of a empty collection, Int.min is not a member of the collection, so why return it. reduce(and thus also max) should return `Option[A]` instead of `A`.
First of all, the point was to give an implementation equivalent to the one written in the guide. That's why I used fold and not reduce. Secondly, I prefer to work with pure total functions. Last but not least, returning Int.MinValue for an empty array makes some sense because it's the identity for max. Equivalently, in math, an empty sum is 0 and an empty product is 1.
Or you could do something smart, and make the signature def max(data: Array[Int]): Option[Int] and return None when data is empty.
I am no mathematician, please elaborate. My own reasoning, as a layman, is that a mathematical integer is unbounded; that is without a defined lower bound. Thus, it would make no sense to return a fixed value as the minimum out of a set of nothing (empty array)
Compare: def sum(data: Array[Int]): Int = data.fold(0)(_ + _) def prod(data: Array[Int]): Int = data.fold(1)(_ * _) def max(data: Array[Int]): Int = data.fold(Int.MinValue)(_ max _) They all have the same form: def f(data: Array[Int]): Int = data.fold(identity)(_ op _) where `identity` is the identity of `op`, i.e. identity op x = x x op identity = x for all x of type Int. The advantage of this convention is that many theorems become simpler. For instance, P subset of S =&gt; max(P) &lt;= max(S) i.e. if P is a subset of S than the max over P is &lt;= the max over S. Another example: max(A U B) = max({max(A), max(B)}) where `U` is the union of sets. With our convention, many functions are easier to define because there are no corner cases. Anyway, returning an Option[Int] is perfectly fine if that makes more sense to you (and to the users of your functions).
&gt; I know that I'm not the only one who don't like symbolic operators (methods). They make APIs unnecessary hard to read and understand. Mathematicians use symbolic operators all the time and they don't think they're making math unnecessarily hard to read and understand. And I'm not talking about basic math (+, -, *, /), but advanced math. It's a trade-off. The disadvantage is that one needs to learn the meaning of all the operators to be able to understand the expressions, but the advantage is that the expressions are much more readable and compact once you know the symbols.
I've yet to see scala api that uses nulls. Nulls are there for java compat, that's it.
We enforce non-use of null at my company using a scalastyle check. It works great. http://www.scalastyle.org/rules-0.7.0.html#org_scalastyle_scalariform_NullChecker
Yes. That does not mean they are used though.
Great! The big problem is Java interop though :( After all, if it wasn't for Java interop we wouldn't have `null` at all in Scala!
A null Option just isn't a worry in practice. That's just a fact. We've only run into null at the Java interop barrier. But very rarely. Option.apply takes care of things nicely. But there's no reason to be paranoid about your Options being null. 
No. It can also be enforced at runtime. (worse, but nevertheless useful). For instance, if you use the `Option.apply` smart constructor, it checks for null. If you forbid the usage of `Some.apply` (eg. scalastyle rule), then it is easier to write a safe facade. If you super paranoid with that, you could just wrap any non-primitive return value in `Option(_)`.
I think this is a pretty good solution. If a java method returns T and is clearly documented to never return null then go ahead and pass it through. Otherwise wrap it in an option. Then there's a single point where you have to worry about null. Furthermore you if the java method returns a java option or a guava option you could switch it to a Scala option. Same thing with things that throw. You can wrap them in a try.
The problem is that humans are fallible so while this approach reduces bugs, it doesn't eliminate them. That's why I'm interested in safe languages such as Haskell and, in particular, Idris.
Just because addition, multiplication, and max are all monoids for `Int` doesn't mean they're monoids for `Array[Int]`.
you just need a shim layer between java apis that return null and scala
That's irrelevant. Do you understand what's an empty sum and an empty product? Here we have an empty max.
How can you say monoids are irrelevant and then ask about the empty sum and product. Do you know what monoids are? Unlike sum and product, max is not a operation on `Int` it a query on an `Array[Int]` about the elements in that set. It must return a value in the domain of the given `Array[Int]`, `Int.Min` isn't necessarily in that domain.
The !! operator alone tells me that Kotlin's nullable is no more safe than Option. You'd need strict linters for both to be absolutely safe. The nullable is more concise for simple cases like the one illustrated in the article. Option is more verbose, but it is consistent with the collections ( Array[T], Set[T], List[T] ), which makes it easier to learn. As things get more complicated, reasoning with Option is easier. The rules are simple, and there's no special cases to learn.
It is true that every convention has to start more or less unpopular. But even if it would be the same principle in programming as in math, I think that symbolic operators doing more harm than they are helpful. They lead to a higher entry barrier and are meaningless by themselves. Essentially it is the same as symbolic languages like Chinese vs. character based languages like English. English is much more approachable than Chinese, because the building blocks of the written language are much simpler. I wouldn't be surprised if Kotlin will have been surpassed Scala in popularity in two years, because it is simply more approachable and doesn't encourage "try to be clever" programming style as Scala does. In other words: with great power comes great responsibility, but it seems like many (API) developers are not responsible enough. To be clear, I like Scala, but it makes me a bit sad to see how the "Scala culture" hinder Scala adoption. I've met more than one developer scared away by Scala code.
I much prefer scala futures to go blocks. Go blocks are just slightly better than JavaScript style callbacks. Futures are much cleaner and nicer to use. 
 Scala is the **Sca**lable **La**nguage - it aims to do right various DSLs used in creating web and client apps and to satisfy different kinds of statistical purposes. It's very good at high level generalization and composing OOP with FP - therefore you can create safe code really fast(if you or your team is experienced). If you're in Scala or in any other language which is capable of handling generics and high-level features then you don't need Go.
I come from golang and not sure if it would better to write microservices in scala then in golang.
&gt; It is true that every convention has to start more or less unpopular. But even if it would be the same principle in programming as in math, I think that symbolic operators doing more harm than they are helpful. They lead to a higher entry barrier and are meaningless by themselves. Mathematicians don't care about entry barriers. They use what makes *them* more productive in the long run. &gt; Essentially it is the same as symbolic languages like Chinese vs. character based languages like English. English is much more approachable than Chinese, because the building blocks of the written language are much simpler. Ehm... characters are symbols. English is simpler because it uses symbols which are related to the sounds of the spoken language. Actually, English is a bad example :) &gt; I wouldn't be surprised if Kotlin will have been surpassed Scala in popularity in two years, because it is simply more approachable and doesn't encourage "try to be clever" programming style as Scala does. In other words: with great power comes great responsibility, but it seems like many (API) developers are not responsible enough. Math is for smart people. Why should Programming be for everyone? Because of money (*)... I know, I know... I'm a dreamer :) So, yes, you're probably right, but I wish you weren't. (*) It's better to have many mediocre programmers working with an easy language than a few excellent programmers working with a powerful language.
&gt; Mathematicians don't care about entry barriers. They use what makes them more productive in the long run. It's fine to be productive and invent what is necessary to become so. But as I see it, in programming (especially in Scala, because it's so easy and part of the culture) exists an egocentric approach namely inventing your own language (nobody else speaks) for everything. And that maybe increase the developer of an API / framework, but hurts all others. &gt; Ehm... characters are symbols. English is simpler because it uses symbols which are related to the sounds of the spoken language. Actually, English is a bad example :) Maybe, but as you can see, English is pretty wide spread. And why should the thing that makes English successful not work for programming language? &gt; Math is for smart people. Why should Programming be for everyone? Isn't that the arrogance (please don't take it offensive) that is perceived as the "Scala arrogance"? You could see it from a different point of view: a programming language is a tool to help humans to achieve certain goals. And the lower the entry barrier is, the more people are able to reach their goal. Of course it is always a trade off, to make something simple to learn and powerful enough for experts. But that is exactly what I'm talking about: I think, for example, that if we would waive symbolic method, we wouldn't lose much but we would lower the entry barrier. 
I know, but where can I find more tools for microservices in Go or Scala?
I know 10+ languages very well, and with that experience, I recommend you avoid Go unless you have a very specific need for its goroutines. Scala will save you a lot of time and trouble. There's a Java library for everything you could ever want.
Interesting tool - but the writeup gives an impression of being a replacement for unit tests - which is a bit mis-leading, IMHO.
&gt; With the JVM's concurrent GC, Scala might even have more consistent performance overall. FWIW, Golang (very) recently got a CMS-ish GC. It hurt throughput a bit in some cases, but apparently it's now incredibly rare to see a &gt;50ms stop-the-world pause, even for heaps &gt;10GB. [Here](https://talks.golang.org/2015/go-gc.pdf)'s a slide deck on it if you're interested.
&gt; However, I currently work at a small startup and we aren't really working with the kinds of scaling problems that Spark has to deal with. So what would make you think I'm not working working at that scale? Just because a corvette is faster than a pinto doesn't mean that the corvette may not have performance issues. The corvette could fail to optimize collection operations instead defaulting to views, which for almost all cases are slow. The corvette could focus on jmh gains of 5% for code paths that are hit 10% of the time. The corvette could decide to ship unneeded data to all of the nodes. Or the corvette could be getting all of its performance gains because it used the new engine from Typesafe. Spark has a great design for usability, but it does have a number of performance issues in its implementation. That is why it is the best **open source** solution, but also forces companies like twitter to implement their own solutions. A focus on a micro (non) optimization like while loops just indicates how far Spark still has to go in terms of understanding performance improvements. You can still maintain the elegance of scala while achieving equivalent or better performance of while loops. You use while loops because it's the easiest path to decent performance.
I replied to Roland's comment. I personally do not believe in automatic parallelism for CPU-bound tasks being accomplished by a library that is meant for manipulating streams, because for that purpose you need to talk about things like GPUs and SIMD. For example I believe Scala's parallel collections have been an awful idea. Monifu also tries to make the best decision on how to execute those operators and even though you might say that optimizing individual operations is missing the bigger picture, I also cannot see how Akka Stream's design can lead to better parallelism, especially because working with Akka Streams is actually more explicit on splitting and joining. The other problem is that the operators for manipulating streams are inherently concurrent. This is not like a design such as map/reduce where you've got stages that can be cleanly parallelized. Concurrency kills the parallelism possible and if you want parallelism, then the API has to restrict concurrency, but then that is contrary to what we want to achieve with streams. Of course, I can't really argue against Dr. Roland Kuhn, he definitely knows what he's talking about and I'm definitely interested in where this is going. But the primary purpose of a streaming library is to filter, transform and transport packets over asynchronous boundaries, with the primary performance boost coming from thread management (by efficiently multiplexing between between threads in a non-blocking way in the face of I/O operations) and of course, from optimizing memory access patterns (i.e. fixing things in the face of the resulting concurrency). And Monifu does a wonderful job in doing this, with the article giving a glimpse of it, although there's always room for improvement (Monifu is in no way pulling the hard-core tricks that the LMAX-Exchange Disruptor is pulling, but that has been the goal). On Channel - yes, it does buffering. The difference between Monifu and RxJava is that Subjects are bound by the back-pressure contract that is baked in the Observer interface, so you cannot use Subjects the way you'd use them in RxJava. There is no such thing as "*back-pressure not supported*" in Monifu - if a piece of functionality cannot support back-pressure and cannot be redefined in a way that does, then that feature does not get implemented (the `groupBy` operator almost didn't make it). It helps that Monifu is a new library and saying NO can be done without upsetting too many people :-) So yes, for that purpose you've got channel. And yes, you can choose the strategy on overflow. Is it unbounded, does it trigger an error, should it drop new or old elements, should it drop the entire buffer? The strategy has to work with synchronous pushes of course, see here [OverflowStrategy.Synchronous](https://github.com/monifu/monifu/blob/v1.0-RC1/monifu/shared/src/main/scala/monifu/reactive/OverflowStrategy.scala#L124) and cannot work with say the [BackPressure](https://github.com/monifu/monifu/blob/v1.0-RC1/monifu/shared/src/main/scala/monifu/reactive/OverflowStrategy.scala#L67) strategy. This strategy can also be specified on some operators, like `merge`, or by using the `withBusyBuffer(overflowStrategy)` operator.
&gt; Spark is essentially implementing a local database, and so micro optimisations can and do matter. Perhaps the performance optimization is not to implement a local database? And it's not a local database, it's actually a replicated database, with that replication leading to some of their performance issues. &gt; (as in, do you know that in fact their usage of loops offer trivial gains, or are you just making that point to try and make an argument?) Yes. We are one of those companies with our in house spark alternative because of these issues that I specifically call out. If there weren't these performance issues, then you wouldn't have companies implementing their own alternatives, and blog posts from twitter talking about their alternatives. 