Thank you. That is a nice feature. I used to see that a lot. Recently I saw in `cats` library which prompted to learn whats the advantage. I'm putting an example below for myself; package server final case class ChatResponse(message: String) package server package api object Api { // ChatResponse is available to use without having to explicitly import def chat = ChatResponse("hi how can i help you?") }
What does support consist of?
security updates and bugfixes
It's now here with some modifications: https://typelevel.org/blog/2018/06/07/shared-state-in-fp.html
Scala might arguably be the better language, kotlin has the better on-boarding. I just hope that with dotty the dust settles and the tooling (ide support, buildsystem) and ecosystem (macros in limbo) will stabilize.
I know fs2 has it (and had it for a while :), but I was interested to find a way to do memoization given only `F[_]: Sync` without falling back to impure APIs. That post has originated from my experiments with it :)
JetBrains is in the business of selling IDEs. They support Scala not for love of the language or any other altruistic reason you may come with. They support Scala because it makes them money. Let's be honest about it and not fool ourselves here. It is exactly the same reason Lightbend supports Java, for that matter.
Has anyone used Scalding for Hadoop instead of Spark? How did it go? Are there real advantages ove Spark?
Genuine question: do you find Javascript's async+await more|less intuitive? ``` for { â”‚ (async function() { a &lt;- myFutureA â”‚ const a = await myFutureA; b &lt;- myFutureB â”‚ const b = await myFutureB; } yield (a, b) â”‚ return [a, b]; â”‚ })(); ``` 
But `safeMemoize` uses `Async`, doesn't it? and you can do the same with `once` by having `Deferred.uncancelable` instead I think
xs(m) is take: https://www.scala-lang.org/api/current/scala/collection/immutable/IndexedSeq.html#take(n:Int):Repr for insertion you are looking for patch method: https://www.scala-lang.org/api/current/scala/collection/immutable/IndexedSeq.html#patch(from:Int,that:scala.collection.GenSeq[A],replaced:Int):scala.collection.immutable.IndexedSeq[A] you need to create some convenience method around patch method to do exactly what you described. The bad news is that Vector, which is the default IndexedSeq implementation, is slow at concatenating other vectors: https://github.com/scala/bug/issues/4442 There is a mention of RRB-Vector in comments. RRB (Relaxed Radix Balanced) Trees provide efficient immutable vector concatenation. There is a prototype: https://github.com/nicolasstucki/scala-rrb-vector Finger trees look good on paper but tend to have bad memory locality meaning performance is usually bad in practice. But they might solve the problem. One alternative is to use Red-Black tree based Vector implementation. Red-Black trees are bit mediocre solution for linear random access structure. But if insertion performance is important then the red-black trees might be one option. So, you most likely a RRB based vector implementation would be the right one. Finger tree or red-black tree based version might do the job as well.
Your JS example seems to have more decoration. Ignoring that, it seems to be more intuitive. Scala has `Await` as well. But, from looking at your JS example, JS's await might work a little bit differently. Scala's Await actually blocks the thread. I'm not sure what JS' await does. 
Those are escape codes. They are usually used for colors or formating on the console.
start sbt like this to avoid the shell escape codes: sbt -no-colors
@oleg-py Can I get a more in-depth explanation of how `Semaphore` is helping provide safe access here? I think I'm missing the benefit it is providing. 
Test are programs, and you can abstract over tests the same way you abstract over anything else. Define a set of laws for your Queue (like `q.push(a).pop === a`) and associated property-based tests (check out Scalacheck if you have not done so) defined in terms of the abstract interface. This set of tests can be a concrete class that takes an implementation as a constructor argument, or an abstract class that requires the implementation to be specified by filling in some abstract definitions. Anything more complicated is probably a distraction. Note that Cats and scalaz both provide setups for law-checking so if you're using either of those you already have a leg up.
Consistec GmbH | Scala Developer | FULL-TIME | SaarbrÃ¼cken, DE | ON-SITE Interested in developing a scalable analysis system for network data? We work with a high-performance multithreaded environment which can be distributed over several systems. Different NoSQL databases help us to save the data depending on the scaling and to make it available for further analysis over as long a period as possible. A central REST-API connects our systems with each other and offers a uniform interface to the outside. For further analysis we use our dynamic web UI which can be configured individually. We use the following technologies, among others: â€¢ Akka &amp; Kafka â€¢ ElasticSearch &amp; InfluxDB â€¢ Scala &amp; Play Framework â€¢ Typescript &amp; React Apply at bewerbung@consistec.de http://www.consistec.de/de/stellenangebote.html
An asynchronous [Twitch Scala client](https://github.com/maciej-adamiak/twitch-scala-sdk). I am working on a data science project. I would like to use Twitch game and stream data during analysis. Unfortunately, I did not find a suitable library written in Scala and simultaneously supporting the newest API version (helix), so I've decided to write my own. I would be grateful for your feedback. Thanks!
Does anyone have a Scala and Sbt docker image? One that preferably has SBT actually installed, and not one where it's just the install script.
You can do a less -SR foo.log to make less interpret the ANSI color codes correctly.
Whatâ€™s the current state of GUI programming in Scala? Iâ€™m making a Scala app thatâ€™s basically an interactive spreadsheet, for learning purposes, and would like to understand my options. Scala Swing and ScalaFX do no longer seem to be maintained in a way that would inspire me to learn them - do I go for Scala.js with something like Bindings.scala?
&gt; Your JS example seems to have more decoration IIEF is necessary for accurate comparison with Scala's variant - we want a `Promise`, not a function that creates a `Promise`. &gt; Scala has Await as well. But, from looking at your JS example, JS's await might work a little bit differently. Indeed. JavaScript's `await` is syntactic sugar analogous to Scala's `&lt;-` arrow: - JavaScript's `await` is only allowed in body of `async` function, just like Scala allows `&lt;-` only inside `for` comprehension. - In JavaScript, `await` is desugared to `then` method call, just like in Scala `&lt;-` is desugared to `map`&amp;`flatMap` calls. Effectively, `async` IIEF is JavaScript's `for` comprehension, or `do` notation. Except it only works for `Promises`... In JavaScript world, it is being discussed to extend the language to allow using `await` at top level. With this, your code could look like: const a = await doA(); doB(a); or simply: doB(await doA()); However, under the hood this extension doesn't bring anything substantially new. It simply wraps *entrire body of a module* in an `async` IIEF. The goal is to make asynchronous `import` easier.
Will `ensime-gradle` be available? I am currently interested in looking at the source code of `kafka` and in it turned out it uses Gradle build tool. Unfortunately, `ensime-gradle` is officially broken! Is there any plans to solving it?
When did you realize the years of using and learning Scala were precious?
\&lt;joke\&gt;When you need to go back to Java occasionally :) \&lt;/joke\&gt; Seriously though, when you see more and more languages adopt features first appeared or popularized by Scala. Or when you see just by learning Scala you start to understand a lot of concepts in CompSci in general, just because the core of language is simple and lots of things are explicit.
when i get my paycheck
This is in Java, but is still relevant to Scala unless you're trying to write pure functional test: https://webcourse.cs.technion.ac.il/236700/Spring2017/ho/WCFiles/02-Testing_fixed.pdf#page=16
http://www.scalatest.org/user_guide/sharing_tests
It... doesn't seem related to the Google-Oracle lawsuit though? Kotlin does not escape either Java or JVM.
Interesting. I think the examples here are describing cake pattern. Will look into this more.
This screams for Property based testing. Look for scalacheck. 
&gt; Is this a case for dependency injection? I.e., I pass in (or "inject") the appropriate implementation to the same group of tests and see if they all run? Yes, but don't overthink it. DI often boils down to passing parameters, and the usefulness of DI frameworks is *not* a matter of consensus. If it were me, I'd do something like trait Queue { ... } final class LinkedListQueue extends Queue { ... } final class StackQueue extends Queue { ... } final class ArrayQueue extends Queue { ... } ... def doQueueTest(queue: Queue): Unit = { // assertions about what all Queues should do, like assert(queue.push(a).pop === a) //ScalaTest-style // more } doQueueTest(new LinkedListQueue) doQueueTest(new StackQueue) doQueueTest(new ArrayQueue) Or in other words, put common, repeated code into a method, and call it with different params.
1on1/docker-sbt
Also, there might be overhead in creating the function object. OTOH, if you plan to pass it around as a function (e.g., to map), especially if more than once, then there's an advantage to defining it as a function value up front, so you don't have to create it later.
TIL!
I was a Java/Python programmer before picking up Scala, and learning Scala has been so helpful for me in terms of embracing new paradigms. I love functional programming now, although it's not something I ever would have understood before.
What do you think about dotty compiler? Is it going to be merged back to scala(scala 3.0) or going to be separate compiler?
Dude, you're publishing some great work. Keep it up, and thanks!
&gt; 1on1/docker-sbt This seems to have same issue: &gt;Getting org.scala-sbt sbt 1.0.0 ... I want one where that part has been done and is already committed. 
The dart and flutter will kill kotlin:)
&gt; https://developer.android.com/kotlin/ Google will then promote Dart and Flutter.
Oh I see. You realize that will make pulling the docker image take that much longer? Also, how many versions would you include? Just 1.1.6? Everything up to there? Some user-specific set? All in one image, or one docker tag per version? In any case it's possible to do. If you're familiar with docker you can fork https://github.com/nafg/docker-sbt and make it run `sbt -sbt-version XX exit` in the Dockerfile -- that should suffice. If you want multiple versions as an all-in-one, use a bash for loop to do all of them. Otherwise, you can either have separate git branches and map them to tags in a dockerhub automated build's build settings, or use a CI like gitlab or travis to publish the versions as tags programmatically. Maintaining git branches may seem more tedious, but that way you don't have to re-publish all versions all the time. Then again, you can use some higher-level logic in the CI script. Maybe use an sbt plugin. :)
Yeah, it's an odd request. Basically we use Docker and Docker compose at work for all our dev flows. Scala is kind of the exception, just because SBT is such a pain. I only need to support a single version. I would prefer a 1GB image with SBT fully loaded. Thanks for your help
This is cool, though I really really wonder how they got these results, given that 2.13 isn't released yet has 30% of usage. I don't think these results can be taken at face value.
It's plausible that many Scala programmers are really willing to experiment with beta versions. Note that replies on this questions aren't exclusive. But also plausible that the people answering interpreted the "use regularly" somewhat liberally. Methodology at the bottom: https://www.jetbrains.com/research/devecosystem-2018/demographics/
I use docker-compose a lot, but for interactive things it's annoying. Also, last I checked monitoring files for changes from within docker didn't work so well. Let me know if you need any more help.
Yes, Dotty will become Scala 3.0 :) https://www.scala-lang.org/blog/2018/04/19/scala-3.html
Did anyone benchmark the different approaches? Would be interesting to see, how the behave with regards of throughput and latency. And in the case nobody did this: how would a good approach look like, that gives a meaningful result? Benchmarking is hard, especially when dealing with concurrency.
What they implement is a rate limiter, so benchmarking that would be kind of interesting ;\-) I figured they are focused on things other than sheer performance.
What is NeoPipe ?
presumably this? https://github.com/coachshea/neo-pipe it does sound interesting, I use neovim for scala dev, I'd be interested in any experiences of neopipe/ammonite
I hope they continue work on types for autocompletion purposes. When I was starting with Scala having only done a little bit of Java, I couldn't understand anything the IDE was telling me about the type signature.
It's a bit strange asking someone to just put a bunch of technologies together without discussing how it solves the problem at hand. What is the problem at hand, anyway? If it's about just writing an example application to demonstrate the understanding of different technologies then it's a different topic altogether. Personally, I'd stay away from someone who likes to use something for the sake of using it.
Thanks for this post. I've seen bullet point style comments on how collections would change, but I didn't quite understand the nuances of how that was any different from current state. This laid everything out quite clearly and has made me quite excited to upgrade. 
I like the new design, and I'm glad that [my proposal](https://github.com/scala/collection-strawman/issues/42) for saner grouping methods (`groupMap` and `groupMapReduce`) has been followed through! However, I really don't get the reasoning behind the last point: &gt; mutable collection types do not inherit immutable insertion and removal operations. Having both `+` and `+=` makes total sense, and I'd wager to say it's one of the few things that should be intuitive for almost all programmers new to Scala, as many other languages and Scala types use the same convention for 'in-place addition' versus 'immutable addition'. In fact, not having `+` on mutable maps only makes their design less consistent, and will sow confusion for no good reason at all. Also, a simple use case: if I want to populate a mutable map and then pass it somewhere with only a slight temporary modification, before going back to the original unmodified map, I may want to use `+`. As an example, I may want write a recursive function that threads some inductive context contained in a map, where the context between two recursive invocations is distinct, but it is in addition _still_ mutable within one given invocation...
&gt; This is a change because this was not the case before Oh. So that's what a change is!
I did it the following way: there's a [shared test for all the queues](https://github.com/alf239/okasaki/blob/master/src/test/scala/okasaki/QueueSpec.scala) there are, and it describes the expectations for the interface: abstract class QueueSpec[E, Q](queue: Queue[E, Q]) extends Specification with ScalaCheck { implicit def elements: Arbitrary[E] "A queue" should { "Maintain the order" ! prop { xs: List[E] =&gt; val xs1 = drain(fromList(xs)) xs1 === xs } } "An empty queue" should { "allow snoc" ! prop { e: E =&gt; val q = queue.snoc(queue.empty, e) queue.head(q) === e } "be empty for head" ! prop { e: E =&gt; val q = queue.empty queue.head(q) should throwAn[IllegalStateException] } "be empty for tail" ! prop { e: E =&gt; val q = queue.empty queue.tail(q) should throwAn[IllegalStateException] } } def fromList(xs: List[E]): Q = xs.foldLeft(queue.empty)(queue.snoc) def drain(q: Q): List[E] = iterate(q)(queue.tail) .takeWhile(!queue.isEmpty(_)) .map(queue.head) .toList } Then there are specific test classes like class BatchedQueueSpec extends QueueSpec(new BatchedQueue[Int]) with IntElements for batched queues, class HoodMelvilleQueueSpec extends QueueSpec(new HoodMelvilleQueue[Int]) with IntElements for Hood\-Melville queues, etc. So as long as you can provide the implementation of Queue, you're all set.
##r/mxnet --------------------------------------------- ^(For mobile and non-RES users) ^| [^(More info)](https://np.reddit.com/r/botwatch/comments/6xrrvh/clickablelinkbot_info/) ^| ^(-1 to Remove) ^| [^(Ignore Sub)](https://np.reddit.com/r/ClickableLinkBot/comments/853qg2/ignore_list/)
`+=` can be a bit confusing, consider ``` val mutMap = mutable.Map.empty[Int, String] mutMap += 5 -&gt; "hi" println(mutMap) // 5 -&gt; "hi" val immutMap1 = immutable.Map(mutMap.toSeq:_*) // immutMap1 += 6 -&gt; "world" // illegal var immutMap2 = immutMap1 immutMap2 += 6 -&gt; "world" println(immutMap1) // 5 -&gt; "hi" println(immutMap2) // 5 -&gt; "hi", 6 -&gt; "world" ``` Or, what they could be getting at is that if you're passing around a mutable map, it's unclear if it should be mutated all the time, or if sometimes it should be copied. 
`op.toRight("error message")`
This doesn't really work in a for comprehension though
I have for { userLoginInfo &lt;- userLoginInfoOpt.toRight("failed") } yield ( Logger.info(s"Login request with email: ${userLoginInfo.email}") ) where `.email` throws a value map is not a member of Product with Serializable with scala.util.Either[String,models.UserCredentials]
Avoid the cake pattern. It has *very* few *very* specific use cases. This is not one of those.
Sorry, I apologize. So as far as I know this is to be used for handling json requests which would contain filtering parameters and would access a database in order to return a result fitting the request. For example if there was a database filled with thermometer temperatures and times associated with them, a json request would be able to be sent that would request a daily average on a specified thermometer. Obviously spark would probably be used to do the averaging, however I'm not exactly sure where statsd would fit in at all.
You need Scala 2.12 to do this. In a for-comp you can say `op.toRight("blah").right` in 2.11 and earlier.
actually, I believe the request is sent as an event so there is the statsd portion but I'm not exactly sure where I would need to use akka.
Sorry for the long response. `Semaphore` lets you limit how much `F`s are allowed to run concurrently. In this particular case I'm using a `Semaphore` which has 1 permit - that means, if you're trying to evaluate memoized `F[A]`, only a single thread can start evaluating it, and all others will asynchronously block until this one is finished. And when it's finished, the value stored will be just `F.pure(a)`, the already memoized result. This is exactly the behavior I want - if `F[A]` is expensive to compute, I don't want to do it twice in parallel. The final code snippet uses parallel execution - you can just replace `safeMemoize` with `memoize` and observe that effects happen multiple times. --- As another cool example of `Semaphore`, you can use it to do parallel evaluation with limited number of jobs allowed to run concurrently: val jobs: List[IO[String]] = ??? val results: IO[List[String]] = for { sem &lt;- Semaphore(5) res &lt;- jobs.parTraverse(sem.withPermit _) } yield res A common alternative is to split a list into batches of required size (5 here), but that would mean a single slow job in the beginning of list will prevent next batch from starting. Using `Semaphore`for this is both simpler and more efficient. You might want to take a look at docs as well: https://typelevel.org/cats-effect/concurrency/semaphore.html
https://scastie.scala-lang.org/udbYLgZvQVqO8mz11f4K2g doesn't seem to work in complicated for comprehensions
Any specific rationale or examples you can point to? I have a type erasure warning in a different project that I was thinking cake pattern was the answer to?
Something about this sounds really weird. What you described could be php talking to a mysql db.
something you \*might\* do, is have a stream of thermometer temperatures over something like statsd, and want to do stream processing on it. I don't know what's appropriate for processing statsd data, but spark streaming mode is \*a\* solution to taking data from \*some kinds\* of streaming sources, doing some kind of stream\-oriented processing on it, and saving it elsewhere, as part of a greater data pipeline. Given that you're married to making spark streaming work with statsd events and wanted to write a presentation layer for the results: If I had to guess I'd say akka is just being used as the http app stack, probably out of spite. This could be where the statsd metrics are coming from, if it's an IoT stack. But, tbh, I think you can solve the spark streaming part of the equation with the statsd stack by itself, yeah?
Not 100% sure if I follow, but you can parameterise the trait with Report[T], then you can define cells[SpecificWorkbook] in each extending class
You have that set to Scala 2.11.8
/u/rberenguel is right, you need to put the type param on `Report[T &lt;: Workbook]` like trait Report[T &lt;: Workbook] { def cells(wb: T): Unit } class ReportXSSF extends Report[XSSFWorkbook] { // how do I specify that I want the generic to be an XSSFWorkbook here? def cells(wb: XSSFWorkbook): Unit = ??? } 
Yeah! I mean it might work. One other thing I thought could be is that the statsd is just for clocking metrics on the timing and efficiency on the spark operations?
It's almost always unnecessary, it comes with a large compilation time cost (this may have improved), it's usually overall bad design because it encourages implementations to become tightly coupled, if you're doing a service where different portions may want to have different lifecycles you often end up with convoluted workarounds. Source: Have made this mistake once. Never again.
So that's a weird one I encountered recently in an actual project too. If you remove the _ = println(o1.s) From the middle of the for\-comp it works. The alternative is to replace it with _ &lt;- Right(println(o1.s)).right
Announcing the removing of `Traversable` is disappointing to me, considering https://github.com/scala/collection-strawman/issues/15 is still open.
But this works: ``` case class Foo(s: String) val opt1 = Some(Foo("hi")) for { o1 &lt;- opt1.toRight("bad").right _ &lt;- Right[String, Unit](println(o1.s)).right a &lt;- Some(Foo("two")).toRight("bad2").right } yield (println(a.s)) ```
To date, I sometimes have to give up on auto-completion in many operations in Scala. I love the language, but it can be unforgiving sometimes.
I'm very excited with scalameta/metals, and want to know when it's planned that metals reach the production\-ready stage. I'd like to contribute but right now it's impossible for me (maybe in a couple of months). Thanks.
&gt;Oh. So that's what a change is! Basically all changes work this way...
It really surprised me that Mill doesn't appear as a build tool. Given the complexity I thought Mill had a stronger adoption. Maybe Mill is too young? Or maybe Scala programmers aren't afraid of sbt?
\&gt;LazyList Is Preferred Over Stream \&gt;Stream is deprecated in favor of LazyList. As its name suggests, a LazyList is a linked list whose elements are lazily evaluated. An important semantic difference with Stream is that in LazyList both the head and the tail are lazy, whereas in Stream only the tail is lazy. what's the benefit of having both head and tail lazy?
It's less surprising. With `Stream` e.g. calling `filter` will consume the stream up to the first item that matches the predicate, which might not be what you'd expect.
There are no great answers. ScalaFX is fine IME, but Scala.js might indeed be a more marketable skillset going forwards.
There are languages that make async yield points completely implicit and invisible, e.g. Go. The trouble with that is that in the (rare, but not so rare you can ignore them) cases where you actually do want explicit control over the yield points, you have no way of doing so. I find the `for`/`yield` syntax strikes the best balance: it's pretty much the minimum amount of syntactic overhead without being completely invisible.
The problem is: `filter` will *still* consume the stream up to the first item that matches, because it needs to know right away whether the resulting `LazyList` is empty or non-empty. And if no element matches the predicate, then the result will be empty. I mentioned that `LazyList` was not yet quite lazy enough, but it hasn't been addressed: https://github.com/scala/collection-strawman/issues/367
I'm still concerned about removing an operation without a way to do the same as efficiently. The workaround I can think of is to do `mutMap.toMap + (k -&gt; v)`, but that's going to create an additional copy of the map compared to `mutMap + (k -&gt; v)`... I don't know if that's too important, though.
For me, our build system is dependent on a number of sbt plugins that would need to be ported to Mill or replaced. It simply hasnâ€™t been worth the effort yet to go through that process. Thereâ€™s too much application code to write. 
I think the survey was planned/conducted before Mill was even released.
Thank you! This helped a lot.
\`groupMap\`, FTW! Existing collections are pretty fantastic by the standards of most programming language standard libraries (\*cough\* JavaScript \*cough\*). I'm looking forward to an even more pragmatic new collections lib!
This approach works really nicely with fs2 streams. I've been having a much nicer time testing with that structure
I do agree with you there. Maybe a `.mutable` and `.immutable` would be handy to quickly and clearly convert between the two.
How would `.immutable` differ from `.toMap`?
It makes things slightly more correct. Overall, I regret even suggesting the rename, it should have been removed without replacement, because it tries to (poorly) do too many things at the same time. It - "buffers" results - it's a function to generate an unlimited amount of elements - it tries to be "lazy", but many methods are substantially less eager than users would reasonably suspect Each of these points is hard to do correctly on its own, and `Stream`/`LazyList` is basically a whole separate collections implementation (like `collection.immutable` or `collection.mutable) dumped into a single class. The way it is integrated into the collections hierarchy also means that you pretty much lose all reasonable assumptions you might have. I'd guess that 80% of the code written in Scala that accepts something like `Seq` is unprepared to handle `Stream`/`LazyList` and will break/hang forever.
IMO it's more clear, especially if there is a method to go the other way (like `.mutable`). Without looking at the signature, code like `myMap.toMap` seems quite odd.
Yeah, that's true. It would be nice to have both of these. Maybe it's not too late to get them?
Iâ€™m working at a new place and using casbah mongo for the first time. I wrote a test that checked some mongo collection fins command was working with testOnly and it was. When I ran the whole test suite my app failed with a class cast exception that joda DateTime cannot be cast to java.util.Date. I eventually this down to a unit test that used: https://github.com/mongodb/casbah/blob/master/casbah-commons/src/main/scala/conversions/ScalaConversions.scala This function, which I canâ€™t tell if used by a mongo library we depend on, but isnâ€™t in our app, but is our test suite, when hit, changes the way mongo results are returned Globally, and predictably. Does everyone else agree this is really bad behaviour and library design? Given my limited understanding of every library my app depends or changes that may occur in the future in them.. I cannot reason about how a simple mongo query would respond and thus am forced to handle the issue by doing a case match on both java.util.Date and org.joda.time.DateTime!
If you have any question, I'm here to answer.
I love to see such initiatives! I have one question: do you know how many people this can help, roughly? Is it 10, 100, 1k, 10k or more? Do you have any statistics? And maybe a second one: is it a thing in other languages as well?
That's what one of my projects is using
&gt; I have one question: do you know how many people this can help, roughly? Is it 10, 100, 1k, 10k or more? Do you have any statistics? There is the StackOverflow developer survey: I am blind / have difficulty seeing: 1.4% (1,702 responses) source: https://insights.stackoverflow.com/survey/2018/#developer-profile-disability-status (Physical Differences) I would say between 10 and 100. &gt; And maybe a second one: is it a thing in other languages as well? I know this project for Python: https://github.com/MaxwellBo/python-verbal-descriptions/tree/add-verbal-from-neoreader And on a similar topic: Using Python to Code by Voice https://www.youtube.com/watch?v=8SkdfdXWYaI
I only had a cursory look at the article, but I'm failing to see how this has anything to do with the [decorator pattern](https://en.wikipedia.org/wiki/Decorator_pattern). Or is this another "decorator" concept?
**Decorator pattern** In object-oriented programming, the decorator pattern is a design pattern that allows behavior to be added to an individual object, either statically or dynamically, without affecting the behavior of other objects from the same class. The decorator pattern is often useful for adhering to the Single Responsibility Principle, as it allows functionality to be divided between classes with unique areas of concern. The decorator pattern is structurally nearly identical to the chain of responsibility pattern, the difference being that in a chain of responsibility, exactly one of the classes handles the request, while for the decorator, all classes handle the request. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/scala/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
nothing to see here
To me, a big problem is that `mutMap + (k -&gt; v)` takes linear time but looks like the persistent and asymptotically faster `immutMap + (k -&gt; v)`. That's hard to spot in a review, and I think it makes your `foo` use-case a bad idea, performance-wise â€” if you want that in your use case, you should use `+=` on a `var` pointing to an immutable map. That's because (as is likely clear) implementing `+` on a mutable collection must copy the entire thing (as `mutable.Map.+` is documented to do) and then call `+=` on the result. If you want to pay that price, I'd argue you should explicitly copy the collection and invoke +=, via e.g. `mutable.Map.from(mutMap) += (k -&gt; v)`.
Maybe not. Where are people opening these kinds of requests? Github?
`Map`'s `mapValues` and `filterKeys' are still lazy, in otherwise fully eager collection. These are boobytraps. There should be no surprise-lazyness. Especially now, when `View`s are advertised for that role. At the very least, please don't let it make into Dotty. 
A few steps further and you'll end up with a tagless final design :)
:)
Looks like COBOL
Yeah, good point. Though it's far from being the only complexity trap in the collection... it's literally full of them, such as allowing to inductively decomposing a `Seq` with `:+` (if it's a list, it will have quadratic complexity) or allowing indexing into a `Seq` with the same syntax `xs(i)` as into an `IndexedSeq`, whereas the complexity might again be dramatically different.
As a scala beginner I always wanted this kind of info: seeing how one would rewrite actors into other abstractions.
Would you say that Discipline is a good tool to do property-based testing? As someone that is comfortable with cats / http4s / doobie / circe stack I feel like my tests are often weak, unflexible or lack robustness
I was skeptical when I saw the word "simple "and sure enough this isn't simple at all. &gt; Itâ€™s quite easy to understand what it represents. Each symbol &lt;Exp&gt; &lt;Term&gt; &lt;Factor&gt; is defined "::=" by an expression (symbols, literals, combinations). Stop saying things are simple or easy! I'll decide that for myself. Now if it seems difficult am I supposed to feel like even more of an idiot? I have no idea what that crazy "::=" symbol means.
You'd use spark history server for that. Really, this whole thing is just weird, like who the fuck pulls 3 random technologies out of a hat and makes people brainstorm what fucked up system could possibly be using all 3?
You mixed up the s and a in the example text.
Hey, sorry about that. Indeed, I didn't realized I was saying this that much. Clearly a bad wording, I'll work on it, thanks for the feedback!
Yeah for sure. If you create cats instances for your data types like `Monoid[MyThing]` you should definitely use the discipline checks provided by cats-testkit; and if you create new lawful abstractions (like the codec relationship between `Encoder` and `Decoder` in Circe for example) then you should definitely define your own laws. The mechanics of doing this is kind of obscure though, so check out the doc [here](https://typelevel.org/cats/typeclasses/lawtesting.html) and look at libs like Circe and Monocle to see how they define new laws.
there is also `Either.fromOption(myOption, "error message")` but it sounds like you want something more like what is described from tpolecat. Personally I love using the more verbose in cases like this since most of my team needs a little more info about what is going on. 
What is that task? The .save call? 
Have you tried running the Spark code on a Zeppelin notebook with a subset of the data? Where are you ingesting the data from? How are you triggering the job? Hard to say without looking at the clusterâ€™s performance during the write operation but, running it in Zeppelin and breaking down your data frames in smaller chunks will allow you to more easily debug the issue - it could be one of a million things but blindly throwing memory at it doesnâ€™t sound like a good solution. Good luck!! 
But its just simple calculs 
Here's hoping it catches on like LSP did.
broken link -- should be https://www.scala-lang.org/blog/2018/06/15/bsp.html
Doesn't this fall outside of the scope of what a JIT compiler should do?
I'm trying to figure that out myself, but spark's logs are so incredibly verbose and I can't seem to squelch them. It's either a join or a write.
This looks really promising. When BSP support arrives for multi-language build tools like Gradle, Maven, Pants, and Bazel, how will it handle different languages? Will the BSP implementation for those tools need to know about each language that the build tool supports?
The other `groupBy` variation I end up using a lot is transforming each group into a single thing: def denormalize[B, C](grouping: A =&gt; B)(projection: Seq[A] =&gt; C): Seq[C] = this.groupBy(grouping).values.map(g =&gt; projection(g.toSeq)).toSeq def denormalizeOpt[B, C](grouping: A =&gt; Option[B])(projection: Seq[A] =&gt; C): Seq[C] = this.groupBy(grouping).values.collect({ case (k, as) if k.isDefined =&gt; projection(as.toSeq) }).toSeq def denormalizePartial[B, C](grouping: PartialFunction[A, B])(projection: Seq[A] =&gt; C): Seq[C] = denormalizeOpt(grouping.lift)(projection) rows.denormalizeOpt(r =&gt; Option(r.getInteger("user_id"))) { case g @ Seq(r, _*) =&gt; UserEntity( id = r.getInteger("user_id"), name = r.getString("user_name") ) } 
Do you run Spark History Server or anything like that? It should be able to tell you what the task is. I canâ€™t imagine itâ€™s the save failing, at that point executors basically have a block in memory theyâ€™re writing to disk. Can you post any of the code from before the write?
In this specific case, probably yes. (Though the idea of shipping library-specific optimization code is as old as it is bad.) What they are effectively trying to do in this case is to undo the performance damage required by the existing collection semantics, and make them work under-the-hood more like the way collections should have worked in the first place, but wasn't. If you look back you can probably see half a dozen of failed projects to make Scala collections fast, this is just the newest incantation.
Alright, makes sense about the laziness. Looking through the history of the tasks, nothing seems particularly crazy. I can't screenshot it because it's work and I'm iffy on doing that, but here's the stage detail for the Job that failed: Job 771 (Tasks 11288/12135): Description: 'parquet at &lt;myfile.scala&gt;' Stage ID: 774 Tasks (Succeeded/Total): 5163/5610 Input: 100.1MB Ouput: N/A Shuffle Read: N/A Shuffle Write: 782.7MB Stage ID: 773 Tasks (Succeeded/Total): 200/200 Input: N/A Ouput: N/A Shuffle Read: 51.7MB Shuffle Write: 42.7MB Stage ID: 772 Tasks (Succeeded/Total): 5925/5925 Input: 82.6MB Ouput: N/A Shuffle Read: N/A Shuffle Write: 51.7MB These shuffle values are all so small and we have so much memory allocated to the executors and driver. I just don't get it.
I haven't but that's a good call. Thanks
All the examples could be written using Applicative parser combinators rather than Monadic parser combinators. You only need Monadic parsers if you're doing things like parsing indentation-grammars (e.g. Python) or grammars containing length-prefixed-strings (more common in binary than textual formats) Applicative master category!
Following my old post, I took off all core and memory settings in our scripts and am just letting everything run with defaults. That means the driver, 2 executors with I think one core each, and 1gb per executor. And you know what, it's not bombing out. There are stages failing, but Spark is doing its damndest to retry them and keep it going. I've never seen it do this before. The error dead executors are throwing is this: "Container killed by YARN for exceeding memory limits. 1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead." Seems fine. I think maybe I'll tinker with that, dynamic executor allocation, or spark.default.parallelism / spark.sql.shuffle.partitions. This is encouraging.
Are there any plans to make work with SBT without going through bloop? I don't need a tool like bloop, it's too much of a hassle, and doesn't suit my needs.
This is not dissimilar to Haskellâ€™s rewrite rules. I canâ€™t think of why rewrite rules statically are okay but dynamically bad. If anything I would argue the opposite: at runtime you have the possibility of profiling to compare. You can imagine a bandit type system to choose between several possible rewrites of code. For long running systems like servers or data jobs this could be a pretty significant win.
When is next part out ? Looking forward to see how Task handle complex communication.
was going to say... that's not a very impressive server
AFAIK, adding bloop is a single line in you global plugin files and a single command in sbt. You dont need to use it more than that. 
Interesting stuff, I guess the other major limitation is for those with physical disabilities that make it hard to input code using a conventional keyboard. I am aware of people using voice recognition for coding but there are still barriers with this. It would be great if there was more "intelligence" surrounding voice to code. I think there are major productivity and health benifits to be had, even for those without physical disabilities.
Rewrite rules work ok when the thing being rewritten is small and self-contained. And even then, they are not great from a design and maintenance point of view, because now you pretty much spread the implementation across the code that is written, the library parts that code is supposed to use, and a rewrite rule that does something different. Using rewrite rules to fix by-design problems of a collections framework â€“ good luck with that. I'm amazed by the effort people go through to pretend that the collection design is a-ok, and then turn around and try to escape its consequences.
I have 2 main problems with bloop. The first is that it is just what it is, not a build tool. It will compile my code, and run it, but from my understanding it won't do any of the other tasks associated with the build, like generating resource files, or running the correct run task (you can have more than one). To do that I also need to keep an instance of sbt up, which kind of defeats the purpose. My second problem with bloop is that I don't see what advantage it gives. Compiling one of my projects for the first time with a fresh instance of sbt, 19 seconds. Clean and compile again 9 seconds, 9 again, then 6 seconds. After that it never gets faster, or maybe goes up to 7 seconds even. If I now reload, bloop's documentation tells me that I'm throwing away a lot of speed. So how long does it take to compile after a reload? 7 seconds. If there is any difference at all, then it's likely less than a second difference. That difference I also gain back after that single compilation. I've seen similar results for longer compile times too. As long as you're not an idiot and invoke sbt separately for each compilation run, then I don't see what advantages bloop gives. In the end, it boils down to this, if I use a tool, I want to use it, not just have it sitting around to be pretty.
any progress? doesnâ€™t work for me at all atm ðŸ‘½
impressive!
I have similar experience, a very little speed improvement. But if it gives me 0-effort bsp support which means faster intellij import and reliable errors (no intellij-presentation-compiler involved) than its enough for me to run it. Im not gonna use it for running tasks, but who says I have to?
I think that the whole `Fusion(...).map(...).map(...).run` approach is not much different API-wise than monad transformers - most people I know that ever used them, decided they prefer to rewrite their code so that they won't have to use them. Besides, wouldn't it be possible to use method fusion internally in *lazy* collections? Streams sound like something that could use them without much issue to the user. Additionally, AFAIR there is an implicit assumption, that your collection follows functor laws, while if I am not mistaken e.g. `Set` doesn't follow. The last thing, method fusion cannot work any longer when you start using flatMaps. Considering, than in some contexts `map` is a minority of transformations (IO and async computations, Try, Future, Task, other IO monads) I can imagine, that method fusion would only have chance of being used in lazily-evaluated-lawful-functor collections.
The point isnâ€™t collections. They serve a nice example. Map being lazy on List would not have been the right choice. It is just that something needs to do map fusion. Maybe you say scalac should. But how should it know this without the library declaring how? I think Twitter will be interested in map fusion on Future and another Fetch-like type they have. Scalding, and I think Spark, wonâ€™t benefit from this because they can do fusion at runtime before scheduling.
On haskell I did this challenge where I must read a log and tell the activity and the duration. example log : -- wheee a comment # 2025-02-05 08:00 Breakfast 09:00 Sanitizing moisture collector 11:00 Exercising in high-grav gym 12:00 Lunch 13:00 Programming I wonder if I can make the same with scala and how it then looks like 
&gt; The first is that it is just what it is, not a build tool. It's just a process that reuses compiler instances. Sbt does incremental compilation, ie, keeping track of what files have or have not been compiled, and only compile files that have changed/ With bloop, you get a faster compilation after you clean a project, because the compiler is already hot and running. It's a second generation of `fsc`, which is the hot compiler already shipped with the standard scala distribution. So because bloop is a better `fsc` it enables things like the build server protocol. Because bloop actually has a API that lets you connect to it and query the status of the build, queue things, explicitly reload instances, hot load compiler plugins, etc. I imagine bloop is going to replace `fsc` or `fsc` is going to get dropped from the standard distribution in the near future. My wildly uneducated is guess that they'll probably keep it separate since they've been focused on keeping Scala modular and the distribution small in the last few years.
Thanks /u/lihaoyi. You are right. Recursion is also a case where the monadic flow is necessary (to short-circuit). Is that the case with the parsing indentation-grammars? (not sure I understand why, except because you are doing some recursion according to the level of indentation?)
I did some research on the topic and I found that the limitation is the availability of good voice recognition software. In the video I linked above. The developer had to run a window vm to run a software called dragon naturally speaking (DNS), you also need a good microphone and a lot of time to customize voice input shortcuts.
You don't need monadic flow for recursion; Fastparse's arithmetic, scala, etc. parsers are all recursive and do not have any `flatMap`s in them. You need to have recursive references between your applicative parsers, but that can be done with laziness. You need flatMap when parsing indentation grammars because you cannot know the indentation level of a block until you parse the first statement (and see how much indentation is in front of it). This is actually not unlike length-prefixed-bytes grammars where you cannot know the length of a data field you're parsing until you parse the length field in front of it
This is wonderful work but as a user, as the performance of Scala Native gets better and better, the lack of multithreading looms larger and larger as the blocker to moving real workloads onto it.
Where is spark in this new development? 
&gt; It is just that something needs to do map fusion. The point is that the collection design is not amenable to fusion. The whole design backs the implementation into a corner, and regardless of what you do, some theoretical fusion attempt would have to decide whether some simple debugging statement will either cause an almost arbitrary performance drop-off or a change in behavior compared to "non-fused" operations. &gt; Maybe you say scalac should. But how should it know this without the library declaring how? That's the point. If you want collections to be fast, they need to be designed this way. Instead the design specifies them to be slow and inefficient by demanding a specific, visible order of side-effects that prevents a fast implementation.
There is also [Dragon](https://www.nuance.com/dragon/dragon-for-mac/software.html) for OSX (which is also expensive). With deep learning, voice recognition accuracy has improved greatly in recent years. However, much of that is lost when applied to coding by voice. 
Yes, it makes sense. Thanks.
Sounds really promising! Although it would have been cool if all those optimizations would be available for all three backends... 
Spark is unrelated to scala native
Have you tried GraalVM's nativeimage tool, which supports most of the Java's features including multithreading?. If you are trying to AOT compile existing java/Scala code, try GraalVM's native image.
Similar question: What are some good "passive listening" resources (podcasts, audio books, youtube lectures, etc) you might recommend?
Probably the "red book": https://www.manning.com/books/functional-programming-in-scala
For books take a look at underscore's free open source books they put out, especially the essential Scala one and the one that covers the cats library. For podcasts, checkout CoRecursive with Adam Bell.
Iâ€™m confused. If you have List(...).map(f).map(g) when is it not safe to convert to .map(f andThen g)? You know the intermediate List never escapes and thus we donâ€™t need to allocate it. This can be communicated by the List library author or an external package in terms of a rewrite rule, which is what they propose. I know your whole shtick here is pooping on scala, so itâ€™s probably a waste of time to discuss, but can we talk specifically about their proposal and why the List example fails?
Spark relies pretty heavily on the JVM. It would be a large effort to get any of the native solutions to work for it. Also, not worth it. See the benchmarks above. A warmed up JIT is very hard to beat and they almost never do (nor does native image in their tests). Spark jobs run long enough to warm up the JIT.
Reading it right now. :)
I appreciate the suggestions. I'll definitely check out that podcast, and had no idea those free underscore books existed.
Read Sam Halliday's book on Scalaz [https://leanpub.com/fpmortals](https://leanpub.com/fpmortals) I'd say it's the ideal "sequel" to the Red Book and may even be better in some cases. I've read it and fully recommend it.
&gt; I'd say it's the ideal "sequel" to the Red Book Very nice! I'm currently going through the Red Book, and my next question would have been where to go next. &gt; They often talk about various topics relating to FP and category theory that underlies FP. Very nice, I think I will actually do that! I do occasionally hear people alt my local meetup talking about these topics, and I wasn't sure where to start. I think some of those same people are active contributors to Scalaz.
&gt; If you have List(...).map(f).map(g) when is it not safe to convert to .map(f andThen g)? def f(i: Int) = { println("f"); i } def g(i: Int) = { println("g"); i } Unfused: f f f ... g g g ... Fused: f g f g f g ... 
By "most languages", do you mean Haskell and its derivatives, or am I missing something?
Non-strict: Java with streams in Java 8, Python switched with Python 3, Ruby had `Enumerable` since forever, C# introduced LINQ, Rust uses `iter()` (and has similarly non-eager extensions for stuff like `group_by`), C++ is working on ranges, D has it in `std.algorithm`. Strict eval: JavaScript, PHP.
Thank you! Thatâ€™s a very helpful example (and underscores why pure FP is so much nicer).
I loved [Scala with cats](https://underscore.io/books/scala-with-cats/) so much that i went back paid for it.
used this with intellij today. one of the problems was with indexing times, though that might be because of some of my source files being overly complex. another problem was compilation errors **not** being highlighted. I'm not sure how that happens, as bloop was picking them up fine, but whatever. what i'm hoping for most with bloop is that it can be subbed in as handling sbt's basic compile phase. right now that does not seem to be the case. but in any case, a warm jvm really speeds up scala compilation, and that's especially true if you're using graalvm.
Same - highly recommend Scala with Cats. 
By far the best way to learn this stuff is to hang out with people who know it, and ask questions. And this turns out to be pretty easy. Get on the `scala/scala` and `typelevel/cats` Gitter channels, and go to conferences if you're able to (in particular those held in conjunction with a Typelevel Summit).
Impressive work. I'm starting to believe idiomatic Scala can match imperative C.
Still in early development so the API is subject to change. For now I focused on a limited amount of features mentioned in the README file such as `PubSub`, `Streams` and a limited support for basic operations. Feedback very welcome :)
+1 on this. Although reading a book (the red book is great) is cool it takes time until the click happens. In the Gitter channels, let me also include `fs2` and `cats-effect`, you will find invaluable assets that will accelerate your learning process by pointing you in the right direction. There's always someone ready to help you. And if you feel like contributing back to some open source project that's also great :)
&gt; Edit: Oh, you edited your top-level comment. Now my comment looks stupid. :D No problem, I didn't put that in the OP, only because I was curious if it was still "The Scala FP Bible," and didn't want to anchor the conversation. I bought it something like 2 years ago and never read past Chapter 1. The confirmation does help, since I wanted to make sure if I only go through about 2 books, before my next interviews, that I'm spending my time wisely.
I'm thinking I might do both a `cats` book and a `scalaz` one after finishing `FP in SCala`. It seems only logical to give back. A really good technical book could save you countless hours and pointless frustration, while also increasing your productivity and salary.
&gt; hang out with people who know it, and ask questions. I had no idea all of these glitter chats existed and were active until today. :) I'll try to not get too excited, but there are so many times I've wanted to run Scala ideas by others, understand a concept in more depth, ask about Scala clean-code, or classic "Am I crazy, or is this wrong" moments. I appreciate you pointing me in that general direction. 
Those chats do sound pretty awesome. For open source, I was working on some FP Libraries in Java-8 shortly before I found a Scala job. I'm fairly sure I'll start contributing here once I become more familiar.
Feel free to jump in with that kind of question on Gitter. That's what we do all day.
Great progress. Is there a published artifact on MavenCentral yet? Thanks
Not as such, however, I am going to be concentrating on publishing to Maven Central before 0.2.1 is published. 0.2.1 concentrates on the rest of the feature set that I was wanting to do, but there may be things in there that constitute a 0.3.0 or 0.2.x subsequent release. Since you're the second person to ask about it, I'll probably publish in the next few days. Just need to get a Maven Central account! :)
Er, yes? Every Scala team Iâ€™ve worked in have used IntelliJ. Perhaps you could explain whatâ€™s not working?
There are a ton of conference videos online. You might look at * [Typelevel](https://www.youtube.com/channel/UC-CzKrmtV55SlW2eL3k1RRQ) * [Scala World](https://www.youtube.com/channel/UCc0j7uOItUDh7vEvPb-TeCg) * [By the Bay](https://www.youtube.com/user/FunctionalTV/videos) * [Lambda World](https://www.youtube.com/channel/UCEBcDOjv-bhAmLavY71RMHA) 
Yup, it works when your POM is configured properly, however I remember doing quite a bit of trial and error too. Many examples online are outdated. Once maven manages to build your project on the cli, intellij should just work after a project reimport.
FP in scala is a must. I was a Java developer and started Scala with this book, and right from the beginning you learn to solve problems with features specific to Scala, therefore avoiding the whole "Java in Scala syntax".
Also r/ScalaConferenceVideos is where you can find most of those talks in one place. Kudos to /u/know_not_much for maintaining that.
Here's a sneak peek of /r/ScalaConferenceVideos using the [top posts](https://np.reddit.com/r/ScalaConferenceVideos/top/?sort=top&amp;t=all) of all time! \#1: [\[Devoxx 2017\] Plain Functional Programming - Martin Odersky](https://www.youtube.com/watch?v=YXDm3WHZT5g) | [1 comment](https://np.reddit.com/r/ScalaConferenceVideos/comments/7btuzu/devoxx_2017_plain_functional_programming_martin/) \#2: [\[ScaleByTheBay\] The Design of the Scalaz 8 Effect System - John A. De Goes](https://www.youtube.com/watch?v=wi_vLNULh9Y) | [1 comment](https://np.reddit.com/r/ScalaConferenceVideos/comments/7f2n1y/scalebythebay_the_design_of_the_scalaz_8_effect/) \#3: [\[ScalaCentral\] Category Theory: in theory and practice - Ausmarton Fernandes](https://www.youtube.com/watch?v=Wp37Q0X-Zv8) | [0 comments](https://np.reddit.com/r/ScalaConferenceVideos/comments/7swb2f/scalacentral_category_theory_in_theory_and/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/7o7jnj/blacklist/)
Interesting.But I don't need those feature so I'll stick with lightbend scala. That being sait, the project seems interesting. Will some of those improvements be backported to the lightbend scala compiler ?
We are working with an awesome Fin-Tech company based out of Tokyo, Japan. They are changing the way people pay for products and services in Japan using Scala. BIG fans of functional code and functional architecture, using such technologies as Eff Monad and Effect Stacks, they are hoping to find engineers who feel the same way. So, if you are fed up of using Scala in an OO style, and have dreamed of a company who thrives on functional code, then we are keen to hear from you. All relocation support provided including a healthy relocation budget, full visa support (just a signature needed) and temporary housing for 2 months. ðŸ¡ Let me know if you have any questions
Yes, the idea is that you can try the features without waiting for the release or b until they are merged - to PR being merged to TL it has to have reasonable chance of getting merged to LB. I'd say inductive implicit heuristics itself is a feature worth using. With LB you need to wait for 2.13.
Anything you can do in Haskell you can translate fairly directly into Scala. What's your specific question?
ðŸ’¯ Happened to work with Sam at a previous company as well. He is an excellent teacher. 
Podcasts: - 'Functional Geekery' is pretty consistent with lots of interviews and 1 on 1 conversations with various folks from the community. - 'LambdaCast' is less frequently posted and more novice oriented, but still a really fun podcast to listen to.
Bloop was created not to replace SBT, but to rather report more accurate performance findings of how long scalac takes to compile projects (along with Zinc). It turns out that sbt adds a non trivial amount of overhead to compile a project (even with a raw compile with cached dependencies), this is even taking into account the reload problem you are talking about.
What kind of Scala experience you have to have? 
Yes, the idea is that you can try the features without waiting for the release or b until they are merged - to PR being merged to TL it has to have reasonable chance of getting merged to LB. I'd say inductive implicit heuristics itself is a feature worth using. With LB you need to wait for 2.13.
How I can make the best a timedate object which contains the date and the time
If this is Scala-only project, maybe it would be easier to use sbt to generate POM? Like write a simple build, make sure it compiles, generate POM and then remove sbt files? I am assuming that you condidered sbt, mill or gradle and didn't want to use any of them.
In a real project, just use JodaTime. If you want to write your own, think carefully about what you want to represent - a machine instant? A human appointment in a particular timezone? - and then represent it. If you're just asking about how to have a composite value that contains two values, use a case class, something like: case class DateTime(date: Date, time: Time)
You're 100% right. Global mutable state is always bad, and it's especially infuriating when it could be avoided easily by using typeclasses instead. I suspect this was written in the style of a Java library where that isn't an option. In their top-level readme they do point towards a more Scala-oriented alternative.
Does the company expect people to work like a typical Japanese salaryman? 
I'm trying to figure out a way to use Scalaz 8 to build a purely functional GUI program via JavaFX ([https://github.com/JordanMartinez/JavaFXFunctional](https://github.com/JordanMartinez/JavaFXFunctional)). In the process, I hope to become better at writing pure code.
JodaTime or Java 8 java.time? I would go for the latter unless there's a good reason not to. 
I prefer to stick to JodaTime. The Java 8 API has at least one footgun (making it easier to conflate local dates with machine instants) that JodaTime carefully avoided.
oke, I need to use the time so I can calculate the duration of a event so I think a machine instant is well but the outcome needs to be a human readable one 
Where can I learn some more about the Company in question? 
Do I need to know Japanese? Or English is enough? 
&gt; In the process, I hope to become better at writing pure code. ðŸŽ‰ðŸŽ‰ðŸŽ‰
I would look at Functional and Reactive Domain Modeling. It illustrated a lot of important functional programming concepts that would be applicable across a lot of disciplines (although Scala is the focus of this book). I haven't read the red book yet so I'm curious to know how they compare. I would also check out 99 Scala problems online 
Most of the BSP endpoints are language-agnostics and the language-specific methods are grouped under the "Extensions" section. Some language-specific methods like `builtTarget/scalacOptions` are required for IDE support in for example IntelliJ while generic methods like `buildTarget/test` require no knowledge of targets underlying language https://github.com/scalacenter/bsp/blob/master/docs/bsp.md#build-server-protocol It depends on the application whether you need to use language extensions or not. If you are writing a Scala language server then you definitely need `buildTarget/scalacOptions`. If you are writing a pretty UI for running tests via a local website (something like https://github.com/Raathigesh/majestic) then you can ignore the language extensions.
It's a known limitation that error messages reported via BSP are not highlighted in IntelliJ. I think it's on the roadmap but it's a challenge to integrate BSP errors smoothly with the built-in IntelliJ typechecker. For example, how do you handle conflicting errors from BSP and the IntelliJ highlighter? When do you invalidate errors from the build? Error highlighting will likely be smoother to begin with in editors like VS Code and Atom that natively support LSP.
https://github.com/scala/scala/pull/6582 backport to 2.12
I might have seen it, I recognize the comments. But at this point, I got to used to the fact that nearly merged PRs sometimes go unmerged for months. I cross my fingers for this one to be done soon.
Today begins my journey to refamiliarize myself with Scala after a few years of almost exclusively using ^^^^Java and ^^^^^^^^JavaScript (please don't hate me). I'm mostly just going to be working on toy projects from /r/dailyprogrammer to get started, but as long as I'm here, any hot tips on what I've missed out on since ~2015?
This is a great question with kind and helpful answers. Really encouraging as someone just starting out learning scala. I have a JavaScript background so interested in diving straight into the functional programming patterns (there's some of it in js but scala goes further). These resources will help me find my way around. Thanks all :)
How many years experience are you looking for?
This is easily the biggest thing getting in the way of even thinking about working in Japan for me :/
OTOMH: * Scala 2.12 was released with support for Java 8 (SAM!) * sbt 1.0 * Akka HTTP get out of experimental * scalafmt took over scalariform * cats matured to 1.0 * scalaz rewrite started - scalaz 8 should have better IO (now extracted to a separate library) * basically Typelevel ecosystem appeared and grew * bloop * IntelliJ support for Scala improved signifficantly * basically scalac's speed improved * scalameta grew as a replacement for macros... and became basis for tools like scalafmt, macros are still used * dotty is getting closer, some features are backporting into 2.x * Akka Streams are production ready, you don't have to do everything with untyped actors * typed actors * Alpakka aka enterprise integrations for Akka * Monix 2, and RC of Monix 3 There is more but I cannot remember at the moment.
I asked this from an intermediate perspective, so it might also be worth looking at: * [Scala for the Impatient](https://www.amazon.com/Scala-Impatient-Cay-S-Horstmann-ebook/dp/B01MR67YSO) The "Red Book" is also fairly decent for beginners as well, but does spend much less time on syntax.
Thanks! Scala for the impatient looks excellent. I'm glad the author wrote a condensed version of his 800 page tome. That would be a bit much for me. (I skimmed the preview on Amazon) :)
Gotten what to work? What error do you have? need more info 
That was the first question I asked before joining. The answer is no. It's a very international team and English is the spoken language.
https://engineering.paidy.com/
English is enough. Though you might want to learn Japanese to have a better experience in the country.
Although Scala experience is nice to have (better if it's in the FP field) the company is more focused in people who can understand the business and solve problems in a pragmatic way.
&gt; I'm glad the author wrote a condensed version of his 800 page tome. I misread that as "condescending version" for a second, hah! It's been a few years since I ready this book, and I remember it being an easy read.
Where to send my cv then? Job offers on LinkedIn is not accepting requests anymore. 
Best is to ask in their [Gitter channel](https://gitter.im/scalameta/metals). 
Hiring manager here. TLDR, no. People in the team do approx 40 hours. There's some flexibility on when you come in and leave the office. We have 20 days of holidays, and I encourage people to take these. No need for suits, no need for being in the office just for the sake of being in the office, ...
not at all. Very much a European work culture, they are not in the office past 18:00. 
Well, this is not the case :D They are very much against the whole working until 20:00 to get things done. 
If you follow the link you can hit apply and upload your CV. 
Some commercial experience is required, but they are very willing to train and develop peoples skills. 
You can either send them to the agent who posted here (through FW), or send them directly to us (pjan at paidy dot com)
Or just shoot me a message with your questions. FWIW, there's Dutch speaking people in the team as well.
I'd be more interested on producing that log
I want to upgrade a Play application from 2.3 to 2.6. The app depends on a hand full of libraries themselves depending on a handful of libraries. To perform the upgrade I apparently need to cross compile each library for scala 2.12 (as well as the former 2.11). Why I can appreciate the flexibility it gives the language designers, it is the opposite of write once, run anywhere. It is, write once, have to recompile continuously. Iâ€™ve run into a number of defunct libraries too as a result of this, which is further increasing the time a small play upgrade should take. Iâ€™m am forced to rewrite code to get each library to the minimum supported Scala 2.12 compiled library. Maybe there is a â€œbetter wayâ€. (I mean the source code for these libraries IS generally available)
&gt; maven
[See charts from v0.3.1](https://user-images.githubusercontent.com/890289/41622234-45471596-740f-11e8-9cae-8a60150c3428.png)
\&gt; There are languages that make async yield points completely implicit and invisible Thank you. I think you described what I wanted to say here. Most of the time I feel explicit yield points are distraction. But implicit yield points doesn't support all possible situations.
Depends what you're doing. Joins can run out of memory as can writes. How many partitions are you writing to? A common problem with big files is that the default 200 partitions is too few to handle the volume of data (since 1/200th of your data ends up on a single executor)
This is holding me back also
Here's the second part: https://blog.softwaremill.com/akka-vs-zio-vs-monix-part-2-communication-9ce7261aa08c Not sure if it covers "complex" communication, but I think the general pattern is there. Though if some aspect would be missing, please let me know eg through comments - or even better, a PR with an example in Akka which would need translating.
o, that one was given in a challenge of a book that I have used to learn haskell 
Yep. Here's [a comment of mine](https://www.reddit.com/r/scala/comments/4jkuea/weekly_scala_ask_anything_and_discussion_thread/d393x0q) from a couple years ago on the topic explaining a pom setup I used. I made [a gist of the parent pom](https://gist.github.com/anonymous/bf179eebc6a153eb4c4c9e9a56b7d693) when I last mentioned this [a year ago](https://www.reddit.com/r/scala/comments/4sk4j2/can_someone_help_me_get_started_with_scala/d59ybjn). I've been stuck in SBT land since then and haven't maintained the pom so the versions are likely to be outdated and the compiler args are not what I would use today, but hopefully that's enough to get you going. Let me know if something doesn't work; I might recall enough Maven magic to help. 
Which footgun? I have generally had a better experience using Java 8, especially parsing. Possibly a configuration issue, but I recall it was actually JodaTime that was too liberal and would fill in defaults for things that weren't there, e.g. converting a local date into an instant during parsing by setting it to midnight in some zone. Java 8 was much stricter and would fail. I'd even expect fewer footguns overall compared to JodaTime since they were primarily designed by the same person who (presumably) learned from his mistakes. The JodaTime project even encourages people to use the Java 8 types if they can saying they replace JodaTime itself.
I can't remember the details, I think it made it too easy to regard a local date as an instant or something on those lines. It was a while ago but it was enough to make me not bother with Java 8 time. I can only go by my own experience.
Fair enough. If you ever gave it a second shot I'd be interested to hear what you think or if you encounter the same issue. For me Java 8 wound up being strictly superior in no small part because it made blurring the lines between local and non-local dates harder.
We need a minimum of +3 years commercial experience to get the Visa sorted. 
We need a minimum of +3 years commercial experience in an engineering role to meet the Visa requirements. 
Because `Either` has two type parameters, the compiler can't figure out how to treat `Either[String,Option[Long]]` as an `F[_]` type properly unless you build with `-Ypartial-unification`. The best solution is to build with `-Ypartial-unification`. If that's not an option, you can pass the type parameters explicitly: `OptionT[Either[String, ?], Long](findUserById2(id))` if you can use the kind-projector plugin. Without kind-projector you have to write it as `OptionT[({type L[A]=Either[String, A]})#L, Long](findUserById2(id))`. Or a separate type alias might be more comprehensible: type EitherStringOr[A] = Either[String, A] OptionT[EitherStringOr, Long](findUserById2(id))
?????
Where can we find the Mac and Linux native executables for the Scala 2.12.6 compiler as generated in this article? Seems wasteful to have everyone compile it themselves. Does the Graal team foresee native-image outputs being vended as Maven/Ivy artifacts as well?
I don't think the GraalVM team should get into distributing native executables. However, it might be interesting for Scala project themselves to add these. They definitely know best how to compile them and test the resulting binaries, they know the details about the versions and compatibility, they could know where to package these so people would intuitively find them, etc. 
+1 for sexual freedom +1 for Scala +1 for sex with Scala
Very cool! Is there a great way to configure this in IntelliJ for running SBT, compiling, and running? Would doing the first thing take care of the other two?
&gt; don't think the GraalVM team should get into distributing native executables. You say that but they already distribute executables for a bunch of other languages however. 
It would be nice if, well, politics were kept out of the professional programming community. Especially since some pride events have elements like those shown in these images (should be safe for work): [https://imgur.com/a/2zW6jRG](https://imgur.com/a/2zW6jRG).
I feel like using Monix streaming for another implementation of this behavior is a clear next step. 
The fact that you are getting downvotes is troubling. I donâ€™t understand why programming has to be conflated with politics, because it will probably only lead to (further) polarization. Anyone remember the whole â€œCode of Conductâ€-gate of Github? Thatâ€™s what you get if you bring (a very nasty kind of) politics into play.
Being proud of who you are has nothing to do with politics
Being proud of who you are has nothing to do with politics
Thank you very much for the clear and throughtful answer !!!
I really do not understand how someone would feel the urge to be "proud" of having a certain sexual identity, skincolor, gender, or any other attribute one is **born with**. Why a technical community centered around a programming language would be the appropriate place to display this, is simply beyond me. You can be proud of yourself anytime, in any way you want. The question is whether it's appropriate and desireable to associate an entire technical community with it, which fundamentally has nothing to do with politics or sex whatsoever. It would be equally inappropriate to start "**Scala â¤ï¸ Black Lives Matter 2018"** (being proud of having a dark skin) or something else like that. I think it's dubious, unproductive and stupid. We shouldn't mix tech and politics.
1. autowire is rpc, it may be good if thats what you need (may be hard to call from other langauges) 2. never used 3. never used but seems to be specific to udash and hard to use without it 4. its higher level api that leaves the choice of actual client up to you (for now only xhr client is supported) and would give you the single definition of api for both client and server 5. rpc, see point 1. There are also 2 other options: 6. typedapi - seems to be quite new project, similar to endpoints but heavy-using typelevel programming 7. sttp got scala.js support recently if I recall correctly.
Udash is nice, but it's not a light dependency. I use it for my project, but it's not for everyone, and I had to do some work to wrangle it into my project 
that's for the polyglot functionalities.
If you can easily implement something using IO/Futures, you shouldn't use akka at first place. However there is the cases when you really needs actors, and if you try to stick with Futures, you will be doing all queues/supervision/routing by-hand. Actors are just more powerful, so this article is more like comparing apples to oranges.
If you've just woken up from a long coma, I have some bad news for you.
I do not mind this one, the only way the mixing between politics and TI triggers me is when there are special opportunities only for woman. If I was born with a vagina, with the same computer skills I have know, I would have a job in some big company now due those programs. LOL
&gt; However there is the cases when you really needs actors, and if you try to stick with Futures, you will be doing all queues/supervision/routing by-hand. I'd like to see a comparison that shows implementing those things by hand. To be honest I've never understood what akka is supposed to give you; you can put state in an actor to ensure that that state isn't modified concurrently, but you can achieve that just as easily with a lock. People talk about things like supervision but I've never seen a convincing business use case that it's supposed to solve.
Would you care to elaborate on what the problem is with said elements? Also, itâ€™s not even like this is being shoved down your throat - itâ€™s just a nice nod to the LGBT programmers within the Scala community. 
Your `Node` definition looks good except that `next` shouldn't be a `var` (you don't want to mutate these things in place, you want to form new lists with changes). You could use Matryoshka to define it as a recursive type and that would provide a lot of standard traversal methods for you if you wanted, but that probably defeats the point of the exercise. Rather than the extra wrapping of a `case class`, I might define `List` as a type alias. I *think* you can do this in a mutually recursive way: case class NonEmptyList[T](data: T, next: List[T]) type List[T] = Option[NonEmptyList[T]] Don't use an `isDefined`/`get`, that way you give yourself an opportunity to mix them up and accidentally do an unsafe `get`. The simplest step up is to use a pattern-match and tail recursion: @tailrec def traverse(l: List[T]): Unit = l match { case Some(Node(data, next)) =&gt; traverse(next) case None =&gt; () } Note that this way you don't need a mutable `var` either; `data` takes a different value on each step through the list but the language is handling that for you.
The goal was to find exactly such cases - where actors are the most "natural" solution, and see what it takes to implement them using IO/Task. Of course, I might have failed finding the appropriate examples - if you have any suggestions of what use-case would be better, and where the additional work with using IO would be more visible, please let me know! 
Appreciate your complete summary. I probably do not want to use RPC ones. I love sttp and you are correct that they just added scala.js support in RC (1.2.0-RC1) - https://github.com/softwaremill/sttp/issues/57. I did not any scala.js mention on their README so was not sure. Probably it made to to 1.2.0 as well. I will check that out. 
Thank you for sharing your experience. Yeah, udash did not inspire me much either. I think sttp just had scala.js support beginning End of May so I will probably go with it.
This implementation is going to double the object overhead for List, which is already pretty high. Since for every Some(List(t)) you're allocating 2 objects instead of one. This will also probably end up being less optimizable by the JIT. &gt; Although I think the second object creates a null equivalent by using MyNil and allowing MyList to accept covariant param +A I don't understand the equivalency you're trying to draw. Why would `None` also not be equivalent to `null` by your logic? `Nil` is the empty list. Nothing more, nothing less.
I know we are engineers and we would like to keep politics out of our way. But we will have to face the truth: From the moment when two or more people come together in a community or project *there is politics involved* since we have to decide who should be part of our community. An simply allowing everyone is also no solution since the [tolerant must not tolerate the intolerant](https://en.wikipedia.org/wiki/Paradox_of_tolerance). That means that inclusive and tolerant communities (and this is what we actually mean when we talk about "keeping it free from politics"; that everyone can just be welcomed no matter their race, gender, sexuality, etc.) don't come for free. They have to actively be worked for. So lets work for them together.
Is it "intolerant" to not accept rape of children and actively fight against it? Please compare and consider the images I linked regarding that.
I don't own this but I've had my eye on it for a bit: https://shop.lightbend.com/products/scala-t-shirt
What is the context of the image? What is your cultural context? Is it inappropriate in your cultural context for a dad to kiss his son?
Sorry, but this sounds like something straight out of a political pamphlet. Itâ€™s rhetoric. What do you mean with the idea that â€œeveryone can just be welcomed just doesnâ€™t come for freeâ€? What means having to â€œactively working for thatâ€ exactly? I was in Berlin this year at Scalacon, with all sorts of people, with varying backgrounds and identities. People like Holden Karau, a Canadian transgender held the stage multiple times and gave talks and was, to my understanding, treated with the same respect as anyone else. No one was being excluded, no one was treated differently because of who they were. Youâ€™re trying to fix a problem that doesâ€™t even seem to exist. Specifically in this case, how are LGBT people excluded in the first place, in the context of the Scala community specifically, and how does printing T-Shirts with rainbows on them fix that? Did the LGBT community actually _ask_ for this?
Regarding the elements, please inspect the images I linked more closely. Regarding LGBT and support, LGBT != "Pride" events and organizations, in multiple different regards and ways. Regarding showing support, there are people that are evil that are non-LGBT as well as people that are evil that are LGBT, and likewise with non-evil or good people (and yes, this is very simplified). One could argue that focus should be on supporting non-evil people and not blindly support a certain group, lumping good people in with evil people. This is of course a very limited and simplistic argument and only really useful as a starting point for further debate, investigation, etc. But that whole discussion are definitely politics. And again, after you may have inspected the images I linked, it may show one reason (out of IMO very many reasons) why keeping politics out of technical communities and discussions is a very good idea. But I claim that I have no idea whether you are the slightest bit sincere or not regarding these topics and issues.
You reveal yourself.
Thank you for your analysis! I definitely think the traversal using tailrec is very elegant. However, I do have one question. If I want to set the next value, how can I do that if next is a val? Wouldn't it be overriding an immutable? Should I copy the object? 
As far as I can see, LGBT != "Pride" events and organizations, in multiple different regards and ways. And all "Pride" events and organizations are very much not the same. See for instance the images I linked.
"actively working for that" means that communities have to be moderated and moderation needs to have rules and these rules are for some reason considered politics (even though I would love to call them common sense). You said that you don't understand why programming has to be conflated with politics and I tried to give my view on why that seems to be the case with any type of community. And with that I am equally unsatisfied like probably everyone else who just loves to code and build awesome things (with Scala). I did not see in your post that this was a rhetoric "I don't understand" because I see this coming up a lot and it's a valid question.
And you reveal yourself that you think everyone sympathising with the gay community is a child rapist. **This is why we need these shirts**. This is why more people need to publicly sympathise with this community. Because people who do get shit like this right now. And I am lucky that I am a white cis male and a confident software engineer. Otherwise I would probably not speak up against you. :)
\&gt;And you reveal yourself that you think everyone sympathising with the gay community is a child rapist. This is a complete lie, and you know well that it is a complete lie, and there is no doubt about that. But I will let it be the responsibility and choice of others to seek to figure that out. You are clearly an extremely insincere lier, and a lier regarding a topic that one does not ever lie about. And child rape is very much real and does happen. And that there are child rapists that hides among the LGBT community, and that some "Pride" organizations and events that seem to tolerate or even encourage them, does IMO not "help". What instead would "help" would be taking responsibility and help stop and get child rapists and worse arrested. And many LGBT are very much taking responsibility, and I assume that many or at least some "Pride" events and organizations are too, though without a doubt not all. See also this image, which is very easy to verify and find articles on by searching online: [https://imgur.com/a/3rGQZmY](https://imgur.com/a/3rGQZmY).
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/ifDqXP7.jpg** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20e123ond) 
I learned about Monads and all I got...
You should copy yeah. A `case class` generates copy methods for you, so you can do `someList.copy(data = someNewValue)`. As for `greater` and `less`, I'd pass them up and down through the `traverse` loop rather than having them in `var`s outside the loop - that way again you can have them be immutable and make the language's own stack frames do the work of tracking when they should take different values for you.
well since there is graalvm with native-image, which is probably superior in many use cases, I doubt that anybody will use it for a large project.
[The Scala Code of Conduct](https://www.scala-lang.org/conduct/) starts with the following: &gt; We are committed to providing a friendly, safe and welcoming environment for all, regardless of level of experience, gender, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion, nationality, or other such characteristics. &gt; Show empathy towards other community members. I believe it's important we respect the concept of the code of conduct. I don't think it's acceptable to say: let's keep politic out of tech because it does not fit your custom/morals. The role of the CoC is to protect developers from abuses of other developers (harassments, etc). We should strive for having a healthy environment.
it would be amazing if this would have 2.11 and 2.13 support as well.
&gt; which is probably superior in many use cases From a recent post on the Scala Native optimizer called "Interflow" (http://www.scala-native.org/en/latest/blog/interflow.html) &gt; Native Imageâ€™s implementation of PGO obtains impressive speedups, but it is still behind JDK8 (geomean 0.73x). [ ... ] Interflow (geomean 0.89x) outperforms Graal Native Image statically. With the addition of PGO, Interflow gets quite close to the throughput of a fully warmed JIT compiler (geomean 0.96x). We recently added support for Scala Native in Scalameta and I look forward to build instant startup command-line tools https://github.com/scalameta/scalameta/releases/tag/v4.0.0-M1 Other people have been successful at running web servers https://tech.ovoenergy.com/scala-native-webserver/ There's a lot to be excited about in Scala Native if you are a Scala Developer: - The sbt plugin makes it seamless to integrate Scala Native with your normal workflow - You can use ScalaTest and utest to test Scala Native binaries like on a normal JVM - The configuration to run Scala Native binaries on Travis CI is a simple one-liner - Library authors can publish Scala Native modules like normal JVM artifacts - Users can install Scala Native binaries with `coursier bootstrap --native $MAVEN_COORDINATES` (https://github.com/coursier/coursier/#native-bootstrap)
For the record, I am also excited about graalvm native-image! The ability to build AOT binaries with the Java ecosystem opens up a whole new category of applications. My comment was primarily to share that I think Scala Native is exciting on it's own merit regardless of graalvm native-image.
And you have exactly 1 thread ðŸ˜
That one never gets old!
It's incredibly frustrating to keep seeing people use the Tolerance Paradox as justification for all kinds of incredibly intolerant, controlling, thought-policing behavior. There is a disturbing trend in the modern world where people who are supposedly pro-tolerance, are the ones going around calling everybody who disagrees with them "bigots" and "nazis", even rationalizing and justifying punching people whose opinions they find odious. But because they can always link to some Wikipedia article / authority opinion, they are (in their minds) absolved from having to really philosophically defend all the ramifications of this far-from-universally-acknowledged belief. Besides, it's trivial to turn this idea on its head and say that the current Orwellian situation (where people lose their jobs for having unsanctioned opinions on social media / outside of work) came about **precisely** because moderate, rational people were entirely TOO tolerant of intolerant, radicalized belief systems (such as were being incubated on college campuses in the 90s and 2000s). And now they're forced to either adopt those belief systems themselves, or at the very least be extremely discreet and circumspect in voicing any unfavorable political ideas. What percentage of the apparent consensus on modern liberal ideals is actually just the result of people being afraid to voice their true opinions for fear of social ostracism and professional consequences? It's demonstrably not zero. I have my own version of Popper's hypothesis, and it is this: Society is composed of varying, overlapping levels of structure. Any structure needs boundaries and semi-permeable membranes in order to persist. Any structure that is not convinced of its right to its own boundaries, will eventually be taken over by other structures which DO believe in their own boundaries. Long before they were a recreational Internet drug, Richard Dawkins proposed "memes" as a unit of belief which was self-reproducing, analogous to genes. What we are seeing playing out in society is a battle of memes, incompatible units and systems of belief which are constantly jumping to and from human hosts, battling for supremacy. In my view, the Tolerance Paradox is just another meme which has been weaponized to support certain beliefs at the expense of others. If you replace the CONTENT of what people are being tolerant/intolerant of with placeholder variables, it all just boils down to "[A] is currently in a position of power, and must maintain its vigilant intolerance of [B] because [B] was formerly intolerant of [A]. And [A] is on the right side of history so [B] must never be allowed again." ... which is all well and good, until/if ever [B] comes back into fashion, in which case the whole scenario repeats again in reverse (while still adhering to the Tolerance Paradox - funny, huh?) But there is no such thing as "absolute tolerance", merely tolerance relative to whatever the majority/minority beliefs are at any one time. Formerly entrenched belief systems have now fallen into disrepute precisely because they WERE tolerant of contrary belief systems. "Cis white males" created and cultivated the university systems where women and people of color refined the belief systems of intersectional feminism, which eventually deposed them. European Christianity is likewise on the way out, vs. Islam which is growing at a rapid pace. (Guess which one is tolerant of cartoons) So "tolerance" ends up being a semantic weapon to convince the enemy that their boundaries are immoral and should be dismantled, while strengthening one's own boundaries. Pretty effective.
The horror! If this was a picture of a kid kissing a woman (such as his Mom?), I'm guessing you wouldn't have any problem with it. Context matters.
Itâ€™s clearly not a lie though is it? Youâ€™re completely deluded and you clearly have a problem with LGBT people in general. If you have a problem with a *t-shirt* of all things I think that the Scala community would be much better off without you. I sincerely hope I never have to work with anyone with this kind of attitude. Itâ€™s disgusting. 
Sure! 2.13 support is definitely planned. 2.11 will take a small amount of refactoring, as the code base currently uses a 2.12.2+ language feature for defining \`case classes\` that perform custom validation in \`apply\` and \`copy\` -- namely, a private constructor, overridden \`copy\`, overridden \`apply\` method result in scalac \*not\* generating the default \`copy\` and \`apply\`. Anyway, nothing that can't be encoded differently if folks want a 2.11 release. I'll open some issues for 2.11 and 2.13 cross-building and hopefully get a new release out tomorrow. Thanks for taking a look!
I'm trying to learn Free Monads with little knowledge of Functor and Applicative Functor. Read [article: Free monads - what? and why?](https://softwaremill.com/free-monads/) but did not grasp much at all. Recommendation and real life example would be helpful.
A bunch of smug white dudes getting triggered as fuck in this thread.
There is nothing *at all* inappropriate about those photos. You reveal yourself to be a bigot. I refuse to tolerate bigotry in my professional life, and I will not tolerate you. 
You have never stated what you think is wrong with those images. What exactly is the problem with them? 
The point of the stickers and shirts is to show that members of the LGBTQ community are welcome and invited to the Scala community. Not only that, but all of the proceeds are donated to [The Trevor Project](https://www.thetrevorproject.org/) to provide support to at-risk LGBTQ youth. Can one really argue with raising money for charity (during pride month especially)? I'd also like to mention that using "transgender" as a noun is dehumanizing and this post is a good example of why inclusion in tech is so important. It would be correct to instead refer to Holden as a transgender Canadian or Canadian transgender woman. And, lastly, &gt;Did the LGBT community actually *ask* for this? Does it feel better to be invited to a party, or to ask if you can come? I think it's a great gesture that *invites* LGBTQ people to participate without having to ask for representation. Proactive inclusion is especially important now given that the tech community largely consists of white, cisgender, heterosexual men who feel welcome by default since they belong to the majority.
Itâ€™s insane to even suggest that I am dehumanizing this person. Youâ€™re trying to control and police another persons language and it is simply obscene. Iâ€™d like to point out that you, on the other hand, seem perfectly fine with referring to others as simply being â€œwhite cisgender heterosexual menâ€. Itâ€™s the pot calling the kettle black; you must see the irony in that. This entire conversation shows precisely (along with the cat calling of the ever evil â€œwhite cisgender heterosexual manâ€ Iâ€™ve seen brought up multiple times now) why I want politics (since it obviously brings incredibly toxic and unproductive views to the table) as far away from my professional life as possible. Because fundamentally, some people nowadays seem to regard the world as a place where there are oppressors (the white cisgender heterosexual man) and the oppressed (literally everyone else). Thatâ€™s a hell of a way of looking at reality.
kinda sounds like somebody at typelevel needs to get off their bottom and get some merch for their projects.
Thanks for you in depth answer! 
Fantastic! Have you considered some kind of `Hostname` type with a means to `resolve` to an `IpAddress`? I assume that as this would likely require a dependency on an effect type (cats-effect/scalaz) the omission was deliberate?
(typedapi author) Hi, typedapi currently has no support for ScalaJs. It is in the pipeline but not ready yet.
Yeah, I've thought about adding a hostname type. Feel free to open an issue and we can discuss in more detail. Generally, I think it would be a wrapper around a string that enforces the syntax requirements of RFC1123/RFC952. Adding a \`resolve\` method that's only available on the JVM would be one option, like \`IpAddress#toInetAddress\` and \`SocketAddress#toInetSocketAddress\`. I'm hesitant to add a dependency on an effect library though as I like the idea of keeping ip4s dependency free to help interoperability.
ip4s 1.0.1 is now cross-built for 2.11 and 2.13.0-M4. \- 2.11 support: [https://github.com/Comcast/ip4s/commit/66e26e1fe6b1752b801a3d61c685b20ecb5acf1a](https://github.com/Comcast/ip4s/commit/66e26e1fe6b1752b801a3d61c685b20ecb5acf1a) \- 2.13 support: [https://github.com/Comcast/ip4s/commit/712cf9196003e882290d7567ffbd25ecf02b73ae](https://github.com/Comcast/ip4s/commit/712cf9196003e882290d7567ffbd25ecf02b73ae) I just published 1.0.1 to Sonatype so give it a few hours to appear on Maven Central.
The bunny is out of the bag, you hate LGBT people and trying to mask that under "let's not talk about politics here"... what an asshole
He is getting downvoted because he is trying to mask his homophobic view under "Let's not talk about politics!". He should have stopped at "It would be nice if, well, politics were kept out of the professional programming community. " But since he continued the rest of the sentence, it is a clear signal that he is against two same sexual couple in having a family. And the rest of his comments here even solidified that he hate gay people, very deeply. So yeah, I hope he eats my downvotes that homophobic fucker.
Good materials for Node.js (though kinda functional programming leaning) developers migrating to Scala? I'm mostly interested in a "roadmap" of sorts. I'm not fond of Coursera and already read through underscore's free eBooks. I've done some easy guides on Akka, event sourcing and CQRS but I just need more info on the language and libraries, etc.
I think you revealed yourself. And I feel no shame in calling you an asshole the world doesn't need.
WTF is Dotty? Is it something like sbt?
Hey, why don't you post the news where opposite sex couple abused/molested their adopted children as well? Or, to you, it is Okay for heterosexuals to abused their children, because Adam &amp; Even. I wonder if you even know what statistics analysis is. Did you miss that course in your high school, dickhead?
I mean, he made a throwaway account and upvote his own comments. Doesn't that tell you what a scum he is?
I have this shirt, it came surprisingly fast in the mail and also is really soft too. If lightbend were to want to send me another just to confirm this Iâ€™d be more than happy to test. 
Any Spark/Scala positions open?
Leaving scala
Thanks! 
Scala3
Say no to akka. If u plan on doing alka you mights as well do nodejs
Explain pls
From what I remember from a Scala Center meeting a long while ago, IBM was planning on getting Spark running with scala-native. Outside of that, depending on what your definition of large is, coursier and scalafmt have had native ports for a while now.
My guess would be that it's a reference to scala native being single threaded at the moment.
Here here.
Who knew Jordan Peterson knew scala. What a bunch of hullabaloo over supporting marginalized communities with rainbows on a t shirt.
&gt; â€œwhite cisgender heterosexual menâ€ Your example specifically qualifies "man". When you refer to someone as a "transgender" you don't even give them the dignity of calling them by their gender, you just identify them as their gender expression.
Why do you think so? Akka for building a distributed system seems very appealing. Also how would you work with a lot of data coming in (transactions, gaming servers, etc.) without some form of distributed system.
I know it's in Scala 3. Is it a compiler or more of a build tool?
&gt; IBM was planning on getting Spark running with scala-native Wow! That really would be huge!
It's the name of the research project that will eventually become Scala 3.
Och, ok. Thanks.
In my experience Akka is primarily useful if you need clustering or if you need shared mutable state. Both of those needs are rare, and if you think you need them you'd probably be better served designing your system so that you don't. If you truly do need them, Akka should still be mostly an implementation detail wrapped up in a better interface. For me, working with raw actors loses a lot, particularly type safety, and does not give enough in return to justify it.
I'm thinking of building systems with CQRS and pushing commands as events to event store and so on. Wouldn't Akka make perfect sense for CQRS/event sourced systems? I'm a bit lost here.
Supervision works great... * If threads cannot cause side effects in other threads. (By circumventing the actor system.) * If threads can be trivially killed with no chance of causing a (globally) inconsistent state by doing so. * If threads cannot be spawned "around" the supervision tree. Erlang has all of the above properties. Scala does not and will never. So, you're basically right.
Why do you think Akka makes perfect sense? It might for you - I'm just curious about your reasoning. CQRS is basically separating your read path from your write path instead of doing them both through the same path. Event sourcing is keeping a journal of state changes such that you can replaying them to build up your state again at any point in time. None of that strictly requires clustering or shared mutable state. So, to me, it's not a perfect fit for Akka. For what it's worth, I am working with an Akka-based, clustered, event sourced system using akka-cluster and akka-persistence for my job right now, and I can't say I love it. It's main benefit for us is that actors inherently sequence their messages and the clustering means the state is all on one machine so we can rely on the current state while generating events and treat updates as somewhat atomic, but we could also create an alternative CQRS/ES architecture that had different tradeoffs and didn't rely on Akka.
such hard workers, they look exhausted
Really nice presentation - I've used Monix's Kafka integration quite a bit and found it to be really pleasant and easy to work with.
for your specific use case, I would just a map with valid moves and check it before actually moving, hopefully there is a better way with cats.
A lot of strawmanning, insincere claims and tactics. And that is extremely inconsiderate and abusive of both the community as well as its members at large.
That comparison is extremely false and manipulative as well as fully intentionally loosely defined and you are fully aware of that. But I will let it be up to others and let it be their responsibility whether they seek to figure out how things are or not.
You are misrepresenting me to an extreme degree as well as insulting me. And you are fully aware that you are lying and there is no doubt about that.
You show an extreme willingness to sacrificing the world. Sacrificing the fundamental systems that help us all avoid total breakdown or even complete extinction, such as finding truth, protecting truth and its integrity, protecting and preserving the systems that find and protect truth, etc. How can our species in any way survive without identification of threats, problems and challenges? And sacrificing those systems in some places can sacrifice and destroy them elsewhere as well.
Lies, strawmen, tactics and ruthlessness overall. You do not even believe in your own arguments, and you are fully aware of that, and yet you continue.
&gt;you hate LGBT people 100&amp;#37; false and lies, and you are fully aware of that, and there is no doubt you are fully aware of it.
You've used this "false and you know it" retort a few too many times in this thread (and you know it ðŸ˜‚). It's a perfectly fine analogy and you're either too much of a socon to acknowledge it, or a troll. Either way, you're not worth the attention you're getting in this thread.
Unlike you and the other commenters here who show extreme ruthlessness and lying among many other things, I have not lied once. And you know that well.
That seems like a spelling error.
It is extremely ruthless of you (among other things) to bring up statistics, for I do not see any possibility of you not being fully aware of what the statistics show regarding these kinds of evil. And more strawmanning among other things.
doesn't like politics in professional programming communities baits professional programming communities with more politics
Except it (among many other parts) clearly is a lie, and you are fully aware of it clearly being lies, and there is no doubt about it. And you come with more lies that you know well are complete lies. And there is no even slightly OK community on earth that benefits from child rapists and their proponents like you, including the benign LGBT communities which you mask yourselves as and hold hostage to your advantage and to their great burden.
Yet another complete lie. But I cannot help but wonder if it is not just a lie, but projection.
Misrepresentation, misdirection, fully intentional lies, manipulation, etc. Your ruthlessness is extreme, and you are well aware of that, and yet you continue.
This comment and other comments indicate that you either are a child rapist or have strong sympathies for child rapist, among other, intentionally seeking to blend the as much as possible the (very clear) differences between LGBT and child rapists. If you have hurt and damaged children, I hope you will be locked away for the rest of your life, and rightly so, and there is no doubt about that being fully right.
&gt; Despising child rape &gt; "So triggered!"
It is not a retort in any way, it is a fully accurate description of the situation. That it so frequently is fully accurate is extremely problematic. And you know that 100&amp;#37;. And you knowingly lie repeatedly again in this comment.
So when others bring politics into things to a very large degree, I should keep silent, else it is me and not them that are bringing politics into things? Are you even trying at this point?
You're an insane bigot and I've reported you to the moderators. I hope you're banned and whoever you are, you should be ostracized from the scala community. 
`State[S,A]` is an alias for `StateT[Id,S,A]` and `StateT[F[_],S,A]` is an alias for `IndexedStateT[F,S,S,A]`. You might want to look into the latter one. Here's a [quick talk](https://www.youtube.com/watch?v=JPVagd9W4Lo) explaining it. You don't need to know about CT to understand this. If you already understand `State` it shouldn't be difficult to understand `IndexedState`. Good luck!
Yes, we have a Data Engineering team.
Dude you should reread all your recent comments here. Were you high or were you attempting a bad Donald Trump impression?
Scala.js is production ready
TL;DW ?
&gt; Lightbend Shop &gt; Email: shop@typesafe.com Typesafe is so much cooler than Lightbend!
[https://doc.akka.io/docs/akka/2.5.0/intro/use-cases.html](https://doc.akka.io/docs/akka/2.5.0/intro/use-cases.html) Because of this, mostly. As I said, I have limited experience with Scala (I'm a Node guy) so when looking at the future ecosystem I have to rely on descriptions (basically ads) on the projects' websites and community's feedback (which I'm doing now). 
When you think everyone around you is lying that's a sign that you may be suffering from mental illness known as Paranoid Personality Disorder. I sincerely hope you have someone to talk to and have access to professionals that can provide the help you need.
Gotcha. In that case my personal feedback is to delay using raw Akka actors. It's popular and widely used and has good marketing, but I do not think it lives up to the hype in practice. If you want to use something built on top of them, like Akka streams, that's a bit better. But actors in general are more of a primitive for concurrency than anything else, and you _usually_ don't want to deal with primitives directly. As I mentioned earlier, using raw Akka actors loses type safety, and I think taking advantage of Scala's type system (quirky as it may be sometimes) is one of the best ways you can effectively use the language. To that end I'd say look at some of the stuff being done in the Cats and ScalaZ ecosystems. They emphasize the pure functional programming side of Scala and the techniques used to achieve that are valuable tools. For the language itself I liked the _Programming in Scala_ book by Martin Odersky. I found it extremely readable and a good intro to the individual language features. Understanding the individual pieces is helpful for understanding how they're combined to achieve certain goals in projects like Cats/ScalaZ.
Oh goes.. you're giving out Trump-ish signalling... Jesus, are you for real?!
Voting his own comments as well.. it's comically ridiculous 
You can go on this path I think: https://www.scala-lang.org/old/node/8610 This is a bit old, so disregard XML literals. Start with A1 then A2 and probably pick stuff from L1, A3 as you need them. A few more comments to this list. * From Collections you want to mainly use the immutable collections (which is the default). You want to get to know at least List, Set and Map. (I will have a link coming up with a lots of exercises for this) * To understand "for expression or comprehension" you need to understand how map and flatMap works. With other words you need to know what a monad is. There are infinite amount of monad tutorials, not all of them are good. Check out a few different articles and book chapters, or ask here. The types are very important here, so use intellij, it can tell you the types (on 'alt' + '='). If you understand when to use map and when flatMap, you can go to for comprehension and see what it does for you. * You will also need to understand Future which is not on the list, but it's quite important today. It can be a bit weird at first. The trick is that it's two monads in one. (A Try hidden inside the asynchronous effect). Once you have a basic grasp of map, flatMap you can start playing with Future I think. * Learn the basics of implicits. (Implicit parameters and conversion) I found this article pretty good: https://www.theguardian.com/info/developer-blog/2016/dec/22/parental-advisory-implicit-content . What they call type enrichment is commonly referred as extension methods. If you don't get type classes first feel free to skip them and return months later. They are not very important initially. Solve some of these: http://aperiodic.net/phil/scala/s-99/ Don't need to go through all of them, but the first part is quite useful I would say. (The solutions are under the links (P01 and so)) 
&gt; rape You don't give a fuck about the rape of children. You're using the rape of children as an excuse to attack the gay community. You're a monster.
Improvement goes hard )
That's a good idea.
What the hell are you even talking about. You didn't respond to the practical points I raised, and instead decide to spout some nonsense about "truth" as if gender essenitalism is fundamental to the human experience. Our species has survived a lot of crap and if you think redefining notions of gender that are entirely societal and have been around for a small fraction of humanity's existence is an existential threat to our survival then you're fooling nobody except yourself with your empty prose.
Thanks, as someone who uses more of the functional side of JavaScript, I think monads (maybes, eithers and promises mostly), immutability, maps, flatMaps, reduces, etc. are kinda things I can already grok. Thanks for the roadmap, it looks pretty good. I'll get right into it.
Yeah dude. Just be silent. Think for a moment on whether _everyone_ else is wrong, or you might be. And really, get help.
Iâ€™m not quite getting the usage here. Maybe I just need to read all the way through, but it seems like â€˜capabilitiesâ€™ here are being used like ordinary traits. One use was also the Cake Pattern by another name. The basic thesis looks like what Iâ€™ve read before in Olegâ€™s â€˜Lightweight static capabilitiesâ€™ paper, but Iâ€™m not quite seeing the crux of it hereâ€”that capabilities are marker types for enforced business logic.
Heather is playing three-dimensional chess. On top of supporting the LGBT community, we get to weed out some trolls ðŸ˜‚
It really only starts coming through once you specify that the capability is the single point of entry, and that your capability is potentially revocable. So here, we've got a bakery which will give you a cake you can only `eat` once: https://wsargent.github.io/ocaps/guide/construction.html and here we've got a capability on an expiring timer: https://wsargent.github.io/ocaps/guide/management.html#managing-lifecycle-with-expiration 
I've been working on this little lib for a while and I finally got the things I wanted there to be. If you're not familiar with the idea, I suggest watching [this talk](https://www.youtube.com/watch?v=GZPup5Iuaqw). It's Haskell, but fairly penetrable :) Feel free to open an issue or poke me on Gitter if something is unclear or you have something to suggest.
Extend the http4s StreamApp object Main extends StreamApp[IO] { override def stream(args: List[String], requestShutdown: IO[Unit]): Stream[IO, ExitCode] = ??? } 
You can either use StreamApp for older releases, or IOApp if you're on the latest 0.18, I recommend using `sbt new` to print out an example program to get you going, like it says in the Quick Start.
In addition to the `StreamApp` suggestion by /u/cheriot to address your `while` issue, your route matches a distinct path /hello/{name}, but you're curl doesn't request it. Try `curl http://localhost:8080/hello/world`.
I've been waiting for this for a long time, can't wait to dive in! :)
I actually recently did a talk on combining the free monad and free applicative. The first half of the talk motivates it's usage and explains how it works. Hopefully you find it useful! https://youtube.com/watch?v=Qg48XucSvlg
Yes this was the problem!
This looks great, fantastic work Oleg.
[removed]
Love this. Thanks so much !
wow, VERY in depth. Thanks for turning me onto this channel, Ill check out his other videos as well.
Full disclosure: It's my channel :) Thank you! I hope you enjoy the rest!
Got a question regarding deploying to Bintray, if anyone knows. I've been spending about 3 days trying to get Scattersphere to publish to Bintray, and I keep getting "Unauthorized" messages. What I've boiled it down to is a faulty API Key, but the API Key I've tried using is what I've been given by JFrog. Ultimately, the error I get is: Failed to deploy artifacts: Could not transfer artifact io.buildfactory:scattersphere:pom:0.2.1 from/to bintray-kensuenobu-scattersphere (https://api.bintray.com/maven/kensuenobu/scattersphere/;publish=1): Failed to transfer file: https://api.bintray.com/maven/kensuenobu/scattersphere/;publish=1/io/buildfactory/scattersphere/0.2.1/scattersphere-0.2.1.pom. Return code is: 401, ReasonPhrase: Unauthorized. Hoping someone can help. This is endlessly frustrating.
My colleague and I have been working on a Scala mutation testing framework for a while now. It was his graduation assignment and he did a great job! We finally made it open source, there is still a long way to go till it's fully functional and have the required speed it needs. But the future seems bright! Take a look if your interrested [https://github.com/stryker-mutator/stryker4s](https://github.com/stryker-mutator/stryker4s) !
Where is `Value` coming from? I'm not sure I get the examples.
FYI, the second link under "getting started" on the github readme is returning 404.
It is still well known as the book to do. I mention it in phone interviews as "The Big Red Book" and the interviewer always knows what I am talking about. It's like a right of passage into FP. FYI, I found doing FP in Scala makes the Odersky courses very easy.
Scala, better than sudoku and you are getting paid playing that 
What will happen to all scala tools once dotty is out? Scalameta, scalafix... all progress on perf optim on scalac... all new compiler flags, linters... is it maintained 1:1 with Dotty?
Cool! One note tho: those screenshots are *tiny*.
How long will you be looking for people? I am not moving on yet, because my current work needs me to complete my work, but maybe late next year.
Noted. Will fix. Thanks.
Kojo is one of those projects that's been around since I started out with Scala and I'm really happy to see it's still alive and kicking. I think the project is selling itself short/needs more recognition for what it provides. It's a really cool platform!
https://www.reddit.com/r/scala/comments/8d5xlw/consequences_for_scala_with_the_graalvm/dxkj2bx/?context=3
Yeah, good catch. I made the change to the documentation. Forgot to change those links, as I had to change the domain due to Sonatype's requirements. 
Posted, since it mentions a shift from Scala to Elixir. But one of the things I'm interested in is whether it's possible to help manufacture the same warm &amp; fuzzy feeling about Scala as people seem to be getting with Elixir and Kotlin. I guess Scala's a bit unique in that it arguably overlaps both of those languages, and then some. Maybe that generality makes it more difficult for people to feel the same happiness ramping up. I do think Dotty is a big step in the right direction as it makes the language less quirky, IMO. Collections will be simpler. Type design will be simpler (e.g. \`trait\` params and \`enum\`). SBT is already simpler than a couple years ago.
For what it's worth, I heard a rumour that this was actually just one guy, and that they're now rewriting those services in Scala :-P
That's pretty wild, if true. But I can certainly vouch for the anecdata that people coming from Ruby seem to more readily latch on to Elixir. Such has been the case at my company. Although, to be honest, Ruby is still favored by many over both Elixir and Scala. The other thing I've noticed is that things that seemed really out there about Scala and its paradigms are starting to pop up elsewhere. Our front-end people are using types, in the form of TypeScript. Event sourcing has caught on in the form of Redux. People are using service architectures and data access objects instead of the active record pattern. As new innovations pop up, I often point to code a couple years old in one of our Scala projects that does the same thing :) But that said, that slower path to joy is real, too. I think maybe because most of these other languages have dominant frameworks, such that there's a lot of documentation on The Way to do X. 
I've been continuing working on my programming language targeting Commodore 64 and other 6502 machines (including other Commodore computers, Apple II, NES, BBC Micro, and Atari computers): https://github.com/KarolS/millfork The goal of the project is to have something that is almost as efficient as assembly, but also almost as convenient as C â€“ and in some aspects even more convenient. I just released version 0.3.0 and this is the first version that I can say is actually almost production-ready. No more stupid code generation bugs as in the previous version. I have two C64 game projects in the works and I caught most of the compiler bugs thanks to them. I also improved the code generation and the optimizer a lot. According to my benchmarks (which I might publish in the future), Millfork is now faster than C (at least than what CC65 generates). Millfork also generates smaller binaries, but that was a feature from day 1. The future of the project is not so clear now. I have at least the following things on mind: * Complete the standard math library. * Improve the libraries for platforms other than C64. * Add compound datatypes. * Complete the 65816 and/or HuC6280 support so I can at least run a "hello world" on SNES and/or NEC PC-Engine. * Add support for a totally different CPU architecture, like Z80 or 8086. * Re-write the parser, so it's faster; I'm currently using Li Haoyi's [fastparse](https://github.com/lihaoyi/fastparse), but it's not actually that fast.
Those patterns are way older than Scala. Haskell was doing it in the 90s, and ML in the 80s. Good ideas just take a while to catch on 
I think one of the biggest things going against scala is the perception that it's an academic language. People think that it's too complex, and not simple. I think it's a very unfair reputation, as imo it makes many things much easier, especially correctness and maintainability, but a lot of people just don't like anything that's different from what they already know.
I can see that perception both ways. On one hand, Scala has some really elegant features. On the other hand, it eschews pragmatism in favor of consistency in ways that sometimes make simple things really hard. Like, it's really clever how `copy`works and how it supports immutability, but it falls apart when you need to copy nested objects, and there's not a great answer without resorting to lens libraries. The answer in other languages is "just mutate the damn thing". And I also think the language isn't so free of arbitrary decisions. Most of those decisions are really sensible, but as a newcomer, you have to drill through to some nuanced concepts to understand why. Take the 22 limit, for example. Or `CanBuildFrom` in the soon-to-be superceded collections lib. Or the fact that traits can't have value parameters. Or implicit scoping rules. Or some of the quirks of pattern matching syntax. Yet it's still somewhat of a mystery why Scala suffers so much for its quirks when lord knows it can be challenging to reason about `this` in JavaScript or metaclasses in Ruby.
So.. I've been pretty much on the full spectrum.. I've used mostly clojure on prod and scala as hobby, both scala and clojure on prod and now scala on prod and clojure as hobby. I believe both languages have good (different) strengths and it's totally worth learning both. You'll know where to use them. I was thinking on moving to clojure over scala, but I can't get any more excited about the upcoming scala 3, so I guess I'll keep swinging between both for some time. I think clojure is better for rapidly having things up and running. It is less bureaucratic in its build system and faster to write (once you master paredit/vim-sexp/parinfer). On the other hand, scala gives you additional guarantees due to type safety. This can be really helpful when you actually need to distinguish between types in the detail. Interacting with external parties, specially on non-standard protocols is much better with scala in this sense. Hope I helped you, but feel free to ask anything else. Cheers 
\&gt; there are so much concept I don't know especially the Functional concepts from category theory, still no cats or Scalaz on any of my projects. I'm in a similar position, which is why I created this thread: [https://www.reddit.com/r/scala/comments/8rsm89/preparing\_for\_scalafp\_engineer\_interviews\_and/](https://www.reddit.com/r/scala/comments/8rsm89/preparing_for_scalafp_engineer_interviews_and/) Regardless of whether you go with Scala, Clojure, Haskell, or some other language, you will probably need to read up and study these concepts on your own if you aren't learning those on the job. Personally, I'd recommend picking one, and focus on that one until you feel more confident about your FP skillset. Splitting your efforts across two would probably only slow you down.
Thanks for sharing, I have the same experience, quick for getting things up and running, a very small code base can do a lot. Though I am still wary of adding more features, and growing the code base. I still need to learn how to properly break down domain problem and compose Clojure components. I did small prototyping with Clojure, one shot script to move around Alfresco documents, connecting to Netflix API and comparing with IMDB, processing stream of socket IO, it was fun and the rapid interactive development is enjoyable. Where I stuck with it is whenever I started to think about growing the small scripts I have into actual application :D. With Scala, I haven't done anything from scratch, it's mostly maintaining existing Play + AngularJS apps, or Scalatra code base. And the types, give confidence and comfort in refactoring, but also sometimes get in the way when you have mix code base between Java and Scala. About anything else to ask, do you also use vim-fireplace for Clojure? no need to switch to Emacs I suppose? :D
Scalameta / Scalafix already support Dotty: https://github.com/scalameta/scalameta/blob/master/scalameta/dialects/shared/src/main/scala/scala/meta/dialects/package.scala#L203-L221. Since Dotty syntax evolves pretty quickly, it's a bit lagging: https://github.com/scalameta/scalameta/issues?q=is%3Aissue+is%3Aopen+Dotty+label%3ADotty but definetively not a blocker.
You should try playing with shapeless/scodec. Those are nice scala frameworks that take types more seriously. As for clojure, take a look at hexagonal architecture/ports and adapters. It allows you to cleanly grow the code base. It is basically a layering scheme that allows you to split the code into cohesive layers with true separation of concerns. As for vim, I'm the creator of acid.nvim,a neovim plugin that tries to bring asynchronous clojure development to neovim. Cheers, Henry 
`CMD sbt run` should do it, provided your working directory is the project root and you have installed sbt in a preceding docker image step.
&gt; Like, it's really clever how copyworks and how it supports immutability, but it falls apart when you need to copy nested objects, and there's not a great answer without resorting to lens libraries. The answer in other languages is "just mutate the damn thing". I agree, but at the same time the Lens Libraries can be avoided if you build some helper functions, but can also become nasty. I have the same issue with ReasonML and have been avoiding lens libraries for as long as possible! &gt; Yet it's still somewhat of a mystery why Scala suffers so much for its quirks when lord knows it can be challenging to reason about this in JavaScript or metaclasses in Ruby. The devs I work with are happy with `then` for promises in JS, but struggle with`flatmap` on futures....
I switched to Clojure so here is some pro-Clojure koolaide. The big idea is Clojure's culture of simplicity means in 20 years, mom and dad may be able to program. Karl and my project http://www.hyperfiddle.net originated many years ago as a Scala/Play prototype. I remember spending like a week trying to get the JSON payloads to work the way I needed. I switched to Clojure and was done in an afternoon. The typed FP culture causes some weird rabbit holes. Scala has these SQL query type checkers, so you can compose up these monsterous queries and keep them straight in our heads with types. Clojure solves the same problem with a new kind of database that uses Clojure as the stored procedure language [for example a generic clojure graph traversal library running inside Datomic](http://www.hyperfiddle.net/:cookbook.recipe!datomic-query-loom/), so we don't need mosterous queries but rather can just write regular code on regular in memory graph/maps/sets, except they are durable. (If I had some monster legacy database, I'd definitely choose Scala) Setting aside Scala's complexity, Clojure has some other unique properties that may or may not matter to most projects. clojure.core is very simple so there are many efforts to bring it to more platforms, it doesn't take much work comparatively. Many people don't care about platform reach but I care a lot: Hyperfiddle is a monadic interpreter that runs on browser/node/jvm/Datomic stored procedures, same portable codebase in all these places, which means we can automatically predict and coordinate I/O in ways a client/server architecture cannot. Also we expose eval to userland and store lots of usercode in the database - instead of files on the filesystem and in git, a very forward thinking model. We actually believe that 20 year old "wordpress freelancer" type kids will be able to make web applications without much programming knowledge. Obviously, they will not be building fault tolerant video streaming systems with backpressure or whatever.
Thanks but I'm not using sbt, image FROM openjdk:8 Any other solution?
I haven't worked much with Clojure, but enough that I learned the language and got a taste of the ecosystem, plus given my experience with Scala, along with about a dozen of other programming languages, I feel confident in comparing them. Clojure is a dynamic language and while it is much, much saner than other dynamic languages that I worked with due to its FP tendencies, namely Ruby, Python and JavaScript, in my experience it's not helping enough in reducing accidental complexity and bugs. While using Clojure I did not feel like I learned anything new over what I learned already in Scala's ecosystem and my productivity did not improve. &gt; I like Scala compared to Java, but still after 3 years, there are so much concept I don't know especially the Functional concepts from category theory, still no cats or Scalaz on any of my projects. That's a pity. For me learning functional programming has been the single, biggest boost for productivity I've had since the start of my career and Scala is in fact much better at it than Clojure, in spite of Clojure's marketing ðŸ˜‰ You don't need to know category theory btw. I bet that's nice, but I still don't know much category theory, whereas I know the ins and outs of the Cats library, being an occasional contributor, I helped implement Cats-Effect and I've been the original author and the ongoing contributor of Monix. That you have to know category theory is a myth. But you do have to get familiar with abstractions popularized by Haskell's ecosystem and implemented in libraries like Cats â€” because they are great and you're missing in on a lot of great tools that you can use in your day to day. If you're getting bored, learn actual FP instead. The [red book](https://www.manning.com/books/functional-programming-in-scala) is nice, but if you really want to also learn another language, then I recommend [Haskell Programming](http://haskellbook.com/), as the concepts you'll learn will definitely help in Scala â€” and here I'd like to say Haskell helps with Clojure, but no, not really.
&gt; The devs I work with are happy with `then` for promises in JS, but struggle with `flatmap` on futures.... Yeah, when I realized `then` was a `map` and `flatMap` (with the assumption that a nested promise isn't useful), that's what made monads click for me. That reminds me that I think people find hard to understand at first where you want to `match` vs. `collect`, and why you have all the methods on `Option` when in other languages, like Swift, optionals are dealt with using special syntax. It just seems to add up in people's heads to a feeling of being overwhelmed by new concepts.
For what itâ€™s worth, thereâ€™s a million JSON libraries out there for Scala now and theyâ€™re all pretty easy to work with, including Play-JSON. I donâ€™t know what things were like in 2013, but Iâ€™d say thatâ€™s an area Scalaâ€™s quite good at now. 
Well what exactly do you mean by "dev mode" then? sbt is used for the hot reloading features of Play Framework. Give some more context to what you're trying to do and what your docker setup looks like or it'll be hard to give advice :)
I don't know about how to incorporate it into IntelliJ, sorry. 
I mainly used Scala in production, but did a lot of coding in my spare time with Clojure, my immediate take aways (which are mainly due to the dynamic vs static axis) * Clojure is much simpler, and they really try to reinforce this. You don't have to deal with complex type hierarchies, weird compile errors (by weird I mean that getting some really obfuscated error about types lining up), monad transformers, etc etc. For this reason its quite easy to learn for reasons why Python is easy to learn * Tooling seems to be better (although this is generally a side effect of being a dynamic language). In Clojure you don't have to deal with slow build tools (leiningen is much nicer than SBT), you also don't have to deal with IDE's being slow. * A Scala project is much easier to maintain. Although the cognitive overhead of having to work with types/typeclasses (and other things) are harder, this has the benefit that maintaining Scala projects are ridiculously easy. Refactoring is easy (and often total), making additions are also easy. In 80-90% of cases you can often rely on just the compiler, and then just before you commit you can run your integration tests to see if you have broken anything. In clojure you spend a lot more time having to verify properties of your program (although this is now remedied with things like `clojure.spec`) * There is less divergence in what is considered idiomatic Clojure which I think is a net benefit. Typical clojure style roughly corresponds to ML/OCaml with LISP syntax/expressions + hygienic macros. There aren't really endless debates about the merits of pure FP vs better than Java style. * Both languages are really good when it comes to DSL's, in clojure its easier to create DSL's but in Scala you can verify them much more at compile time * Clojure tends to be slower unless you really try to optimize. Although its true that early optimization is an evil, with idiomatic Scala code you will generally have good performance * Both have very good support for concurrency The biggest takeway/differences is that Scala is more complex but also more correct in a mathematical sense. It takes longer to learn Scala but if you are working with systems where correctness is a very high priority (banking/telecoms/defence, etc etc) this matters. On the other hand since Clojure is much simpler (and also has a better definition of whats considered idiomatic clojure), clojure may make more sense for projects that have to rapidly iterate and change. Due to also the fundamental differences in the languages, there are some things which Scala will be superior in Clojure. Since Scala heavily relies on erasure, its much easier for Scala to target platforms like Android and Native, where as Clojure for Android is pretty much a no go because the produced jar's are enormous (and tools like proguard/techniques like DCE are not as effective because its really hard to tell which methods are called in LISP like languages)
There were period where I was bored and was quite determined to try to master Red book and Scala with cats, but I think having no chance to apply it at work on production, and being not imaginative enough to come up with my own use case, I lost this determination at some point. Though I managed to capture traces of that determination in this exercise microsite, with last commit 3 months ago :D : https://wibisono.github.io/fp-oops/docs/exercises.html :D I'll get back to it someday. Not so sure about going with Haskell Programming, its opening another book I am not sure I can finish.
I haven't ever really used Akka, but I have used erlang professionally. The big advantage of actors is the ability maintain state and pass messages to synchronize those states across multiple nodes trivially. If everything you are doing is on a single node then there really isn't much reason to choose actors over another solution unless it's what you are more comfortable with. Obviously it's possible to build cross node communication and supervision using IO or Monix, but erlang's OTP (and I assume akka) have a wealth of features built for exactly this purpose.
I agree, the sane approach is to focus on one language and try to master it, and since it's available at work I should have focused on Scala. Unfortunately, I sometimes can't avoid temptation of instant gratification from Clojure's REPL and interactive development :P
Clear idiomatic Clojure, is something I really miss when working on Scala project. If you work on a team where developer come and go, you can have Scala code base with completely different style.
what is bin/run? As far as I know you have to use sbt if you want to use play in dev mode (and for building) is this play 1?
Well, in my experience learning is faster and more fun when you're a part of a community. I like to hang out on Gitter on [typelevel/cats](https://gitter.im/typelevel/cats), [typelevel/cats-effect](https://gitter.im/typelevel/cats-effect) and [monix/monix](https://gitter.im/monix/monix), although my interaction tends to vary depending on workload. Once you get a little familiar with a library and with the people talking about it on Gitter, or contributing to it, you can then start contributing small patches of your own for things you want. Doing small contributions is amazingly effective for getting to know a library.
And the bad: Clojure people have this knee-jerk allergic reaction to category theory, because they see how Haskell's approach has heavy cost (as problem gets harder, stuff you need to know approaches infinity), and Clojure's BDFL likes to mock typed fp for this reason and it gets parrotted a lot. But sometimes a sprinkling of CT has a very high bang for buck. So in Clojure the mainstream community voice kind of throws the baby with the bathwater here. But there are people like me who just do it anyway and don't tell anyone that the thing they're using is built with CT and nobody is the wiser.
This is play 2.5 with activator. 
Development mode implies you're running in SBT and recompiling the code on every page load. This typically doesn't happen in Docker, because Docker's philosophy is to have static images and ephemeral containers. If you want to run Play in development mode from code, then running it embedded with and setting the application's mode to Dev explicitly with `GuiceApplicationBuilder` is the surest way to do it. But it's not designed to be run like that, and you won't get the reloading behaviour, if that's what you're after. The actual code starts here, and you can see it's working with the reloader to start a new server every time: https://github.com/playframework/playframework/blob/master/framework/src/sbt-plugin/src/main/scala/play/sbt/run/PlayRun.scala#L80
You should really try the more functional stuff like scalaz + cats + http4s, it really makes development more principled and can get you a greater level of correctness for little cost.
Yeah, circe is hands down the best JSON library I've ever used in my life.
For sure there are warts in Scala, but it's actually a very elegant language. Like the design of `apply` is genius. The fact that we don't need special syntax for stuff like different types of object initialization. You can see that a lot of thought went into the design of the language.
You should ask the same question on /r/clojure for balance. 
\- Used both in production. Came from mostly Java/Javascript in university, to my first job in Scala and now working with Clojure. \- Definitely worth it to learn both (at least for me). Both are great languages with different approaches. \- I have no definite plans to stick to one. I am happy working in any of them. I agree with a lot of what was said here, but I think (from what I read) that no one mentioned what for me is one of the biggest draws of Clojure: the REPL. Coming from a background of write, compile, test and repeat, the feedback you get with the REPL, and how interactive it is, is eye opening. A summary of what I see as their biggest strenghts: \- Clojure: tends to lead us to simpler code; developing with the REPL is amazing; it's usually faster to develop things; the development of the language itself seems more focused; ClojureScript and awesome libraries for frontend development. \- Scala: Awesome type system; less potential to break things; easier refactoring; Dotty looks like it's going to be a big improvement.
Lenses are great, I don't know why you'd go back to mutating things directly, even if you cheat and have the lens implementation do mutation for some extra performance. Which is relatively easy to do once you're consistently using lenses everywhere, those few places you do cheat are easy to manage.
slf4j + log4j2 does the job perfectly. Didn't get from the article why should I try this lib. 
If you need to show source code line numbers along with log messages, log4j2 needs to produce a stack trace and it has some overhead. airframe-log generates this information at compile-time, so it's can be done efficiently. If you don't need to see source code location, using slf4j + log4j2 is no problem. 
I usually use Scala or Java (Java when I work with people who don't know/like Scala), but a colleague and mine built a bigger webapp in Clojure just to give it a try. It turned out to be a pain to develop in Clojure compared to Scala: - 95% of the errors we got would have been prevented by a type system. Sure, these errors are easy to fix but it always takes some time to discover them and figure out what the real input format of a function or the invariant of a datatype is. - Surprisingly the time between changing code and seeing the changes in the browser is higher than Scala/Play or Java/Spring, which usually is one of the few advantages of dynamically typed languages. (there are some solutions for hot code reloading but in combination with macros they often did not work as advertised) - For me coding is much slower, since I always have to lookup the documentation of functions before calling them. In Scala/Java I directly see it in my IDE. - Refactoring Clojure without breaking stuff is very complicated The result was that we ditched Clojure and reimplemented the project in Java. The project now has twice the lines of code, but also less bugs and more functionality. The only plus side I saw for Clojure was the design of the collections in the standard library. For every kind of data manipulation that we wanted to do there was some function that already did most of it. Transforming data kind of feels like working with SQL queries but with a more regular syntax. I think that is kind of difficult to replicate in Scala since every intermediate result needs a type. 
What are you doing in the Clojure REPL that is not possible in the Scala REPL or in a Scala Worksheet?
&gt; Like, it's really clever how copyworks and how it supports immutability, but it falls apart when you need to copy nested objects, and there's not a great answer without resorting to lens libraries. The answer in other languages is "just mutate the damn thing". You can have `var`s in your `class`es and `case class`es.
Do you get any synergy between them? I want to learn a lisp, but I'm not sure if it should be clojure if I'm not going to mix clojure and scala code anyways. Any opinions?
I feel that's a fair critique, getting stuff like JSON to feel ergonomic is not a solved problems, but it is much better now. I'm very happy with how doobie does sql in scala, but I will for sure look up the clojure db solution
Actually, I worked on a project that used both. It was a library in scala being called (and using its case classes with Option and so on) in clojure. It was tricky to interop, but the end result was great. It was type safe in the end result and dynamic to write the business rules. The bottom line is, it is feasible with some effort and could be done had one have strong needs for the strengths of both languages. I also believe that there's intangible benefits in learning another language, such as developing the functional mindset and the required abstractions and the understanding of core principles that truly make the most of each language (or philosophy/rationale backing that language). Those can be reusable even on non (originally) functional languages.
You're 100% right on learning different languagues/paradigms, but I'm leaning towards SBCL at the moment, but scala interop would tip the scales.
The Scala REPL is a process by itself, you can play with it, evaluate things and so on, but it is isolated from your program. That makes it useful only for small things. When you're actually developing, if you change a line of code then the file needs to be type checked, compiled and all dependent classes need to go through the same. All the values/instances that you had in your program that were dependent on any of those classes are wiped clean. The Clojure REPL meanwhile, allows you to evaluate everything in the context of your running program due to the way Clojure was designed. So if you're developing something you can evaluate any code in the context of your application, while mantaining all of the state. You can call your functions, change them on the fly, interact with the state, inspect it, change it and so on. You can build your program while interacting directly with it. I'll post two links of videos that give an overview of the REPL driven workflow in Clojure, which I hope might explain it better than I can: \- Clojure [https://youtu.be/AmP6rW30wjE?t=12m](https://youtu.be/AmP6rW30wjE?t=12m) \- Clojurescript in a mobile context [https://www.youtube.com/watch?v=toGEegAzrZA](https://www.youtube.com/watch?v=toGEegAzrZA)
I agree about the errors part and the refactoring one, but the coding part I have to disagree. &gt;Surprisingly the time between changing code and seeing the changes in the browser is higher than Scala/Play or Java/Spring, which usually is one of the few advantages of dynamically typed languages. (there are some solutions for hot code reloading but in combination with macros they often did not work as advertised) This is probably true if following the same change, compile, reload cycle that we use in other languages but developing with the REPL should provide a much faster feedback than Scala or Java for sure. &gt;For me coding is much slower, since I always have to lookup the documentation of functions before calling them. In Scala/Java I directly see it in my IDE. Again, this also depends heavily on the way you use it. Static analysis of Clojure code is, I agree, pretty poor. But if you're using an editor connected to the REPL then you should have as much information as you have with Scala/Java in an IDE.
Are there any logging frameworks that make testing logged statements easy? I am using grizzled-slf4j and logback-classic, but mixing in a trait makes mocking impossible, and there are no other easy ways to test logging with it. And yes, I know not all logging statements *should* be tested, but in some cases it can be important
Never posted anything there yet, and I still feel more familiar here, feel free to cross post though.
Yes indeed... Fast and concise
Cats is just two lines in build.sbt away and will you reward with great power. I did a similar approach. Drive adoption slowly. Explain the why to other devs in team.
but but... lens for coping only is like 10 lines of code, you really do not need the whole thing
Isn't activator a light layer over sbt? Should be able to use activator run Might even be deprecated now...
Newish functional programmer here and I agree. It was somewhat of a pain using it in 2.11 sometimes because right biased Eithers weren't available yet and I had to use matching statements but once we were finally able to get our projects to 2.12 life and circe got better.
I believe the advice here is to use a custom appender 
For me the gateway drug to cats was the [data types](https://typelevel.org/cats/datatypes.html). In particular, I found `OptionT` to be super useful since I was writing a web application that ended up with a bunch of instances of `Future[Option[T]]` and `DBIO[Option[T]]` (`DBIO` is the a data type used by [slick](http://slick.lightbend.com/) to represent database operations). `OptionT` made writing code around these data types much clearer since I only had to unwrap one monad instead of 2 every time I wanted to write transformations on the underlying type (via `map` and `flatMap`). For me the type classes in cats didn't seem super useful (why would I want a `Functor` type class on `Future` when I already have a `map` method?) until I started using the cats data types. Once you start to see tools that can only be implemented with type classes, the library starts to make more sense.
why wouldnt you at least use a wrapper over slf4j like scala-logging
Elixir is great, I want to see it get traction. That said, it's interesting to compare these kinds of articles. A few years ago, people were describing this on-boarding experience about Scala. Here's an example from a Toronto-based company that switched from C#: http://seanglover.com/blog/2013/10/technology-change-net-to-scala/
That would be sad, because it's likely that they just can't find Erlang/Elixir people in the market to maintain the codebase. As difficult as hiring Scala people is, there are at least a few.
Also wrt testing: when I have a failing test case, itâ€™s very nice to be able to see the logs generated during that test case, neatly separated from the logs generated during other test cases. I have no idea how to do this in JVM-land. Iâ€™m having to write a load of Python at work at the moment :( and one of the bright spots is that the logs are displayed neatly alongside failing test cases.
Clojure and scala can interop transparently with java abstractions. Scala classes are pretty normal for clojure as well, only companion objects that get clumsy (`ClassObject$. MODULE$`) but still works. There's a framework called `from-scala` that tries to solve this kind of thing and seems pretty decent. On the other way, clojure can generate java classes with `(gen-class ...)` and `(ns .. (:gen-class ...))`. That should be more than enough to expose your clojure functions to scala. Bear in mind that not only the calling is different but you need to convert the types as well. Of course you could create container objects but that would be unnatural on clojure side. I'd add a macro (which is pretty powerful) that ensures types can be converted and use maps with keywords. That'd be natural for both languages. Another thing is that `clojure.spec` is your friend. It could allow you to shape your data in a way that can be used by the converting macro. I think clojure can give a lot of flexibility to some scala projects and that is good. The interop thing is a reasonably high price to pay (in terms of maintainability), but nonetheless should be worth in some specific scenarios. Knowing both will allow you to understand the nuances and know when to pick each. Cheers, Henry 
Small feature additions required large wholescale changes. But I have hope that 3.0 will be the last "breaking" update for the foreseeable future once the global state has been got rid of. 
yes, it is. We will change it to sbt
i know this won't help for every developer, but IntelliJ does this by default. 
I developed a highish-frequency trading bot that I eventually wrote both in Clojure and Scala. I wrote the initial version in Python, which was basically a proof-of-concept, and then, after a detour in Erlang, landed on Clojure as my language of choice. Trying to build something that robust (finance is a domain where failure is expensive, to say the least) in Clojure was, in a word, nightmarish. The amount of NullPointerExceptions was hellish. On the other hand, the libraries I used were mature and the concurrency features were powerful yet simple. Regardless, Scala plus Akka made Clojure look like a toy. Honestly, there is no replacement for Scala's blend of functional and object oriented goodness. One of the things that I really appreciated in Scala is the ability to effectively and efficiently accomplish major refactors to code. In Clojure I would rather die than refactor, but Scala makes it simple to clarify assumptions and dependencies in a safe and succinct way, so that, when the times comes, all a refactor takes is a new type signature and everything else falls into place after that. Scala is magical.
Introducing Cats or ScalaZ to my team, would be like trying to teach algebra to a person who refuses to learn and/or use multiplication. The problem I've been facing for the last year is every time I try encourage extremely basic and common FP principles, my manager &amp; another coworker loudly complain: * The manager scolds me for not following conventions, and then implies/criticizes pure FP as unrealistic and anal. * The other loud coworker argues that I'm doing Scala wrong, citing some supposed best practices that don't actually exist. How do I know they don't exist? The patterns are riddled with code-smells like returning unit, no pure functions, etc. &gt; Explain the why to other devs in team. That's one reason I've decided to "hit the books." I feel I understand what these basic principles are, and why they're useful, but my explanations of "why" could use some work.
If you're building with maven, they have a snippet that shows what you're supposed to do. Remember that the credentials go in your local settings file (but with a server id that matches the one in the pom you're using).
Well, most of the time such micro-optimizations doesn't matter. Hardly ever are you sorting 10m objects on backend. I'd say most of the time you are only dealing with small number of objects - so all micro-optimizations with imperative stuff doesn't matter at all. So you write things in a declarative way, chop pieces of behavior into small functions and if there is something slow you need to just focus on that one part. When you are doing REST backend I would risk the statement that most of your slowness can come from what the database (and other external IOs) and how you query it. Any significant speed up will be about either improving schema, or about what you do with queries results: stream instead of fetching all data upfront, cache results, avoid recalulations and n+1s... To be blunt you'll find that all you do is just put a layer of glue code combining outputs from external IO which does the heavy lifting for you. (Performance-wise, the domains knowledge is still mainly in your code). As such most of the time it doesn't matter whether you use imperative stuff of declarative fr handling 100-item-arrays. (Besides, the libraries usually use imperative code deep inside to make it fast while having declarative API). Focus on writing the most readable code, and later on just take a closer parts if they will *really* slow anything down.
I would seriously look at [Finatra](https://twitter.github.io/finatra/). We use it for a very high-performance REST endpoint that receives about 1 billion requests/day. Works very well, but you have to be aware that you can't spend a long time processing the requests without using async. Because it achieves high performance by being [event-driven](http://berb.github.io/diploma-thesis/original/042_serverarch.html) it only has a few worker threads. We've also used Play in Scala, and that was fine for a web application, but IMHO it doesn't give you much for a REST service. And in the end we had to abandon that application because the code Play generated kept causing the scala compiler to hang. We never managed to find out why, and in the end rewrote in Finatra.
Clojure has this thing called Onyx that I had no time yet to explore, but I heard rumors some dutch banks are using it for fault detection : https://github.com/onyx-platform/onyx
Scala.js has been production ready since February 2015, so arguably that wasn't worth mentioning in the list of things that have changed since ~2015. :-p
&gt; What should be considered for performance if we are using scala(playframework) for a REST backend. 99.9% of the time, nothing. Or rather, the only important consideration for performance is maintainability: if your code is maintainable then you will be able to optimise performance in the future, and that will give a much better return than trying to optimise performance now. Write simple, direct, clear code. Get it working right, get it tested. Then benchmark. 99.9% of the time you'll find performance is more than adequate. In the rare case where it isn't, profile and then you can optimise the specific hotspot.
I find that problem quite solved with circe. The idea is to parse the json into a case class that just describes the json structure (with the json types like string, number (as double), list, null (as Option[_]) and so on. After that you convert that raw data case class into your domain case class which contains the domain types like UserId, DateTime, Text and so on. This is really easy and comfortable and sufficient in like 99% of the cases. No need to handle json AST or anything like that. 
I consider it a solved problem too. One might argue that a model where the chance of failure is hidden is more convenient, but really, to me that's just arguing that calling .get on an option feels shameful.
No lisp has a modern library ecosystem except Clojure
In regards to the article you mentioned - Quicksort *by definition* requires in-place sorting. There is no such thing as an immutable Quicksort. It cannot be implemented that way. The "Functional" version is useful for teaching functional programming by giving an example of something similar to quicksort, but it's not actually quicksort and is otherwise useless for real world purposes. If I wanted to use quick-sort in a pure functional language, I'd have a function that internally copies and then sorts in-place. This is still a pure function, and you can use an ST monad to enforce referential transparency if you wish. tl;dr Functional implementations of Quicksort perform identically to imperative implementations of quicksort, since Quicksort is by definition an imperative algorithm.
/u/raghar and /u/m50d are absolutely correct. Your database is going to be the bottleneck. For an asynchronous web framework like Play, there's basically two things to consider: * Are you using a custom execution context for JPA, so you're not doing database calls with the same execution context that Play uses for rendering * Is your CPU utilization at around 70%, at which point you're going to get lag spikes. If you're not blocking on database access, and your load is low, then you're fine. Here's a Play REST API example in Java: https://github.com/playframework/play-java-rest-api-example Note the JPA repository uses a `PostExecutionContext` so that there's a different thread pool specifically for database access: https://github.com/playframework/play-java-rest-api-example/blob/2.6.x/app/v1/post/JPAPostRepository.java and that is sized appropriately for the database connection pool: https://github.com/playframework/play-java-rest-api-example/blob/2.6.x/conf/application.conf#L10 See "[the formula](https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing)" for how you size your database thread pool appropriately. 
I think for that you can capture standard out and err.
You might be intererested in the [talks](https://www.youtube.com/watch?v=j7BArZJxL9M) of Dr. Eugenia Cheng. I don't know if she covers application of category theory to music specifically (I know someone has, I just can't recall where I've seen that presentation before).
I'm dying to find more. Specifically interested in musical flow and how that can be represented as categories. Humans have been writing music for a long time and the notation used is standard. tl;dr music as a way to describe computational systems
Scala is slower in the general case AND uses lots more memory for that specific use-case. If you can distribute your code across several cores or servers by using a distributed techniques or algorithms your solution could be quicker. In place sort with a couple of thousand rows may not qualify but for heavier workloads, distributed is the only way to go. In that Scenario, Scala code is easier to write correctly and less likely to go wrong compared to languages that rely on shared memory locking or exception handling. Take your code for example.. what happens if you want to add a new record? You have to copy the array to a larger one.. and means any references to the old array may cause program exceptions and crashes.
I would really like a logging library that could: * Log key-value information `info("message", "key" -&gt; value)` * Support context passing through MDC `withCtx("key" -&gt; value) { ??? }`, this should work with Twitter and Scala futures * Emit JSON with key-values included * I don't need any log rotation or anything, just stdout is sufficient, since we use Docker logging collected with Filebeats * As few dependencies as possible So far I have not been able to find a library that would fulfill all of these.
That's really interesting and it will be the next-generation logger. - We need some standard for mapping structured log data like info(message, key-value pairs) into json format (or other structured data) - Supporting Future will be useful - We may need a custom serializer for mapping objects into JSON. This logger needs to accept mapping configuration (similar to ObjectMapper in Jackson) 
Hello folks, this is my first first time I used Scala annotation macros for some real world usage, and inspired by tons of forgotten TODOs like *//FIXME later* in our codebase, I decided to create this small library. Any idea, improvements and criticism welcomed :-) Hope it will be useful for someone.
This is a great idea! Thanks!
When I hear a Bach fugue, it's obvious it's a proof: subject = proposition, episode = lemma, counter-subject = contrapositive, stretto = proof assembly, cadence = QED. 
Vibes right? There's so many different ways to look at music though. And the fact the switching keys was a revelation, progression, new thing it was clear that though he had an idea of how it would be there's was excitement in figuring out what it actually was. He found joy in the mystery of solving the riddle.
While this doesn't provide the modeling I was looking for this is exactly the type of thing I need to know to find out how to ask better questions. Holy shit that video is good.
I don't mean to be a stick in the mud, but the use of to-do comments _and_ this new annotation are bad practices, at least in the professional environment. If one finds themselves writing a to-do in their code, one should stop. If it's a requirement, it should already be captured in a ticket or whichever tracking tool is getting used. If it's just a nice to have, or a new idea, but isn't yet captured anywhere, then capture it! Raise a ticket, get it prioritised, do the work. The only exception should be using these comments as a reminder during development of a feature, like a bookmark to remind you where to come back to. These things should never be merged into trunk/master/release branches. I've seen far too many code bases littered with old to-do comments that developers forgot about.
One other parallel (!) might be seen in the domain of harmony: the progression VII7 -&gt; V-&gt; I could be seen as a sequence of monad transformations in the domain Harmony\[\_\] where common practice sequences were available implicitly and unorthodox ones required special intervention. Maybe that's just the Bordeaux talking ;)
Thanks for your comment. Youâ€™re absolutely right that spreading TODOs (and forgotting them) in the codebase is usually bad practice and this library isnâ€™t meant to support it. But for any reason, when youâ€™re in the situation that you need to put such comment in the code, you can instead use this annotation, because what this annotation does and the comment cannot is that it will force you by triggering compiler error ro review such piece of code, fix it and actually remove the annotation. So regardless how good or bad was your intention to put there such annotation, it wonâ€™t allow you to forget about it. 
Second. I used this with logback and it was fairly straightforward to get it working even without injecting a custom logger.
Maybe include a version parameter also. Like, @reminder(â€œv3.0â€) which checks if the current project version is below v3.0 and throws a compiler error otherwise. 
This sounds great. People will scream don't have TODOs blah blah. I understand that as I myself like to keep code clean but sometimes I find it useful to TODO/FIXME sometimes (specially small projects/ personal projects) than to spend an hour to create Jira ticket.
Give it back the mic!!! What a fantastic observation.
A tool that transforms these annotations into tickets during code reviews would be golden...
It takes an hour to create a jira ticket?
Log4J2 supports generating JSON from the key/value pairs in the MDC, though not at the point of logger invocation invocation. It shouldn't be too hard to define an implicit class that adds methods to the Logger to accept the key/value pairs, add them to the MDC, log the message, then revert the MDC. The problem with that -- as I'm sure you're aware -- is that the MDC is a ThreaLocal and so not tied to the co text the Future is executed in. It seems like you can [set up an ExecutionContext to manage passing the MDC around] (http://code.hootsuite.com/logging-contextual-info-in-an-asynchronous-scala-application/), but that seems error prone if not everyone uses that implementation. Possibly outside the responsibility of a logging framework. Maybe it's a sign that Scala needs an ExecutionContextLocal that is handled by the global instance? Take this as agreement with some thinking aloud on possible solutions.
 git grep TODO
I think there's a significant difference between adding `// TODO try to handle case X` after a given line of code, and opening a proper ticket that clearly documents the issue and refers to the code using some basic file/line reference (that may go out of sync) or a permanent file/line reference (that will be blind to further changes to that part of the code). Of course, `TODO`s should not end up in the master branch of a serious product, but for development branches and personal projects they're just much more convenient.
Sorry to hurt your feelings but I invest about an hour or more going through jira route. \- I have to login to JIRA which most of times I struggle with password. \- Then I have to figure out should it be a task/ bug/ story. \- Assign it an epic out of 100 in a list. I have to understand which one is which \- Decide whether it should be in next release or not. Write an essay on Acceptance Criteria. Estimate the points. \- And at the end of the day manager will "JIRA review" and ask every possible question in the world why is it assigned to this epic, why do want it in this release, why is it a story but not a bug. And I have to re-do all the work. I rather love to fix TODOs whenever I have time or create one generic JIRA ticket for clean up after each sprint and assign it enough points so that I can breathe good air. 
&gt;git grep TODO Nice, did not know about this flavour of git. I am going to use this a lot going forward.
Iâ€™m glad you had the time to invest in that reply
Well, I am only sharing how I find it slow to go through JIRA ticket for every TODOs/ FIXMEs instead find it productive to fix those whenever I have time. I would love to learn from you or other programmers here. \_Don't take my opinion too serious.\_
Hi, please take a look of my Play docker image, https://hub.docker.com/r/ysihaoy/scala-play/
Your company is doing JIRA wrong.
Yeah, that's rather ridiculous. 
Writing documentation on [ocaps](https://wsargent.github.io/ocaps), which seems to just keep growing...
i had the same thought.
Recently migrated an API from Spray to Akka-http... Quite impressed from the different (lower) performance. 
&gt; The manager scolds me for not following conventions, and then implies/criticizes pure FP as unrealistic and anal You need to get a new job or a new manager.
I agree. I recently told my manager's boss that I want to switch teams, and that this was more important to me than a raise or promotion. Given the number of times I've seen people given the runaround in similar situations, I'm well aware that this switch may not happen, or may be delayed indefinitely. Until that time, it's only wise of me to start job-hunting.
That sounds cool, but I guess it won't be probably as simple. First that comes into my mind, we must expect that any possible (if even) build tool can be used and properly extract the build version. I'm not sure if comparing the version numbers itself would be also as easy as it seems to be. Anyway, if you (or anyone else) if interested in working on that, you're highly welcomed :-)
# [spark submit finished without completing thread based task within app](https://stackoverflow.com/questions/51076578/spark-submit-finished-without-completing-thread-based-task-within-app) I am doing some doing some seperate thread based work with spark submit app. In client mode application waits till scala future completed but in cluster mode application finished without completing scala future task. **I tried some spark conf** --conf spark.yarn.submit.waitAppCompletion=true **scala future to do some separate copy task** val hdfsCopyProc = Process(Seq("hadoop" ,"distcp" ,"-overwrite", s"$filenameWithLocation" , s"$destinationLocation" )) val hdfsCopyFut: Future[Process] = Future { hdfsCopyProc.run } val aggFut = for{ hdfsCopyRes &lt;- hdfsCopyFut } yield (hdfsCopyRes) aggFut onComplete{ case tr =&gt; println(tr) } but in client mode it is fine , only issue is in cluster mode
Hey, tombraideratp, just a quick heads-up: **seperate** is actually spelled **separate**. You can remember it by **-par- in the middle**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
This is expected behaviour. What are you trying to achieve?
Dr. Martin J.M. Codrington's YouTube videos may be of interest. It has been a while since I watched them but I believe he uses music for his examples. Category Theory: The Beginnerâ€™s Introduction (Lesson 1 Video 1) https://www.youtube.com/watch?v=P6DvIfTJhx8
Would be interesting to see a mode of the macro, where they cause compile errors on release, but not in development.
If you are doing Scrum and Story point estimations, you need to remember the 5min it takes to read, comprehend, and estimate, and then possibly another 5 min to discuss, * by 6 team members.... is already an additional half an hour onto the time that a ticket takes up.
i want to complete some non spark related async work along with normal execution of spark code.
I don't think there's any way to do that with yarn, since that's oriented towards running the whole thing on hadoop and once you're running on the cluster you can't expect to have control of custom threading stuff. If you really need to do this, use the lower-level spark APIs and do your async work outside of the within-spark part.
Agreed, regardless if the manager is wrong or right (or whether or not FP is the right solution), this decision should be made by the team, not by the manager. Its the teams responsibility for what languages/technologies they should be using to solve the job, not the managers.
I should've anticipated the knee-jerk reactions to my comment about JSON. My intent was for JSON to be a sample instance of a culturally entrenched blindness to dynamic solutions.
Well that is kind of like saying that Ruby people have a knee-jerk allergic reaction to static typing, or that Scala people have a knee-jerk allergic reaction to dynamic typing, or that C++ people have a knee-jerk allergic reaction to automatic memory management (GC's) The point is that languages have certain design principles, and in many cases Clojure's design principles conflict with CT (one of Clojure's strongest emphasis on design points is to be as simple as possible). I mean its fine to disagree, but I think its a stretch to say its an allergic knee jerk reaction
There is [TaskLocal](https://monix.io/api/3.0/monix/eval/TaskLocal.html) and [MDC support for it](https://olegpy.com/better-logging-monix-1/).
Check out [logstage](https://github.com/pshirshov/izumi-r2#readme). We have structured logging (including JSON output), colored logging, source position, log rotations, custom templates, etc. No external dependencies, but integrations are available for slf4j et al.
Sounds a lot like https://github.com/nestorpersist/logging except the dependency on akka. 
I'd say that your ideas are more in the domain of mathematics than programming. Euler has done some work on music and mathematics, might be of interest to you: http://eulerarchive.maa.org/pages/E033.html.
Feel free to ask any questions here. Thanks
Thank you for the detailed reply.
I'm not familiar enough with the standard collections to answer that question, and part of my motivation is to learn. My use case is to prototype function composition: each symbol in a user-defined language has a signature (a list of types and a return type). To put a symbol in an argument position, its return type must match the position's type. Say G(a,f,_) is a composite. If "a" has signature (; A), "f" has signature (B,C,D; E) and G has signature (A,E,F; H), then the written composite has signature (B,C,D,F; H). I want these compositions to be fast because they'll happen a lot and at a large scale.
"As a functional backend developer Iâ€™ve always been surprised by how **DevOps** stayed away of all the **functional programming paradigm".** I think there is some fear, some skepticism. Total misunderstanding. FP ideas are constructed from the top down as categories and the bottom up as functions. In the middle is just more functions. That's scary to some people because you're not talking about an object at a specific address you're talking about a hypothetical. Everything from the first effect becomes speculation. probabilistic. Concepts become more abstract because you're describing execution instead of performing it. The most frustrating part of this situation for me is that using pipe in terminal is the only evidence anyone should ever need. The problem is we're not good at explaining things to each others across domains. FP could do this but that would mean FP would have to be the foundation of knowledge for tech and not an ad-hoc thing that only the mathy people messed around with. I will say that I think the examples people use are so foolishly trivial that it's hard to put the big picture FP stuff together and that kinda sucks for new learners. 
That should all be done during a planning meeting. You have already proven why it shouldnâ€™t be done on entering a ticket.
Would be nice to benchmark interflow against ocaml-opt, and to have benchmark engineered to measure native code quality and garbage collector efficiency somhow independently.
 import cats.syntax.either._ fixes this. 
Thank you, this looks very promising.
There is the Kamon implementation that uses AOP https://github.com/kamon-io/kamon-futures
\&gt; Alright, letâ€™s have a look at the UI and see how **beautiful** it is Heh. I mean I really like the idea and everything. Especially defining the UI in code and not having to worry about how it is rendered. I will definitely give it a try. But beautiful is not the word I would choose [here](https://i.imgur.com/Re5n9l0.png).
I assumed charitably and read "beautiful" as sarcastic. 
Really cool project!
I haven't had time to take a closer look, but so far looks great
This is one of the cooler things I've run across!
In this general area, a must-read text is of course [GÃ¶del, Escher, Bach: An Eternal Golden Braid](https://en.wikipedia.org/wiki/G%C3%B6del,_Escher,_Bach) .Hofstadter's areas of interest cover things like sets, recursion, self-similarity, fractals and so on. At the time of writing (1979), category theory was (I imagine) a bit of a niche area, and so the insights it might provide weren't something on his radar. Nowadays, I'd say (and hope) it would be different: maybe you can start this synthesis! However, I see little chance of the miraculous achievements of the masters of the classical canon (thankfully!) being systematized: that's taking us into the AI/human dichotomy which is of course another kettle of fish, so to speak.
**GÃ¶del, Escher, Bach** GÃ¶del, Escher, Bach: An Eternal Golden Braid, also known as GEB, is a 1979 book by Douglas Hofstadter. By exploring common themes in the lives and works of logician Kurt GÃ¶del, artist M. C. Escher, and composer Johann Sebastian Bach, the book expounds concepts fundamental to mathematics, symmetry, and intelligence. Through illustration and analysis, the book discusses how self-reference and formal rules allow systems to acquire meaning despite being made of "meaningless" elements. It also discusses what it means to communicate, how knowledge can be represented and stored, the methods and limitations of symbolic representation, and even the fundamental notion of "meaning" itself. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/scala/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
This looks very interesting, thanks.
I worked somewhere with a similar annotation for feature switches. When the master build broke because of an expired switch, someone would get annoyed and then the date would just be pushed back 99% of the time, and the dead code would live on.
What you say maybe counts for 2011-2013 but now? Json is not a problem anymore at all. In fact it's the opposite and one of the things where working with a typed language makes things much more easy to understand and comfortable to change. Also, with the actual SQL libraries, you will not write SQL but write Scala code just like you work with collections. And you are not limited to a specific database. So, the same thing would be possible in Scala, just write a database and use Scala to execute the code. Spark is not so far from this. But usually there is no need to do this and it's better to just use mature and bulletproof SQL databases like postgres. About platform reach: there is Scala.js and Scala Native, so you can use your Scala code in node or your browser or on other platforms. Not sure if Clojure has the edge here, but from what you say in that post, it doesn't appear so to me. The last thing is the only one where Scala still struggles - that is, evaluating user given code at runtime. There are solutions for that but I suppose they are far inferior compared to dynamic languages like javascript, clojure or probably most other lisp derivates. So, all in all, dynamically typed languages have there corner. And I'm not saying that Scala is the better language or anything like that. But the points that you make like "simplicity" or others are either not valid anymore or are not really convincing ones, except for the last one.
It's not on entering a ticket, but that time still has a cost.
Any idea when itâ€™s been rescheduled to?
http://localhost:8080/hello/Phillip is the kind of url it will match. Thereâ€™s no root -&gt; response for / which is what your curl is asking for.
Reach out to us, likelihood is we will still be searching for people. 
[and Scala as the functional Java.](https://i.imgur.com/Qg4HfwR.jpg)
I bet Flutter will use Kotlin Native when that becomes stable.
Good work, I have been looking for a replacement to the awful. `.*4j` family. I have one question though if you could answer- how did you conclude that logback source position is slow? What happens behind the scenes there? 
val me: Witness
A short answer is logback officially says so: [https://logback.qos.ch/manual/layouts.html#line](https://logback.qos.ch/manual/layouts.html#line). Its implementation acquires the line number by generating a full stack trace. So each logging code of logback will end up generating several objects for stack traces if this line number option is used.
Thanks! That's DAMN expensive! 
nice
Is there no way to adjust the playback speed on this slideslive site?
Sadly there isnâ€™t .... Typesafe didnâ€™t publish the original YouTube URL. So we have to see the videos using their viewer which doesnâ€™t allow to change speed. 
isnt it overly complicated? like you can do it, but why even bother?
Are there any talks which are especially recommendable/"must watch"?
ISTR reading an article with a very similar title a year or so ago, but couldn't find it when searching for it a few months ago. However this article is an excellent and comprehensive toolkit for addressing Java API adaptation.
I'd say no. Most stuff needs to be rewritten. Some things have already been, some will be, others will just stop being supported, and some already are practically unmaintained (e. g. it's an open question whether Ensime will even release a version to support 2.13 at this point. While some performance optimization translate well, all the individual profiling work is lost and will need to be redone. Concerning compiler flags â€“ they are actively being killed off in scalac proper, so there might not be too many that will need to be supported across scalac/dotc. Certainly nothing 1:1.
The ones that are getting upvoted?
If you (and other team members) are hesitating to open tickets because of the time cost involved, then your system is broken. Period.
If you are on Chrome, this extn might help to vary the playback speed. [https://chrome.google.com/webstore/detail/video-speed-controller/nffaoalbilbmmfgbnbgppjihopabppdk?hl=en](https://chrome.google.com/webstore/detail/video-speed-controller/nffaoalbilbmmfgbnbgppjihopabppdk?hl=en)
Being frank: I find this is so insanely overcomplicated. \- \[Type-safe claims\]([https://github.com/jmcardon/tsec/blob/master/jwt-core/src/main/scala/tsec/jwt/JWTClaims.scala#L37](https://github.com/jmcardon/tsec/blob/master/jwt-core/src/main/scala/tsec/jwt/JWTClaims.scala#L37)). You don't need to differentiate \`Expires\` from \`NotBefore\` at the type level.... There's almost no situation where you'll use those directly for some reason, other than checking stuff like "is it expired". If you \_did\_ need to do this, you could do it at translation time, and not enforce this tax onto every single user. \- You have covariance in your JWTClaims. Why? It just leads to \`JWTClaims\[Any\]\` inference down the line. \- There are no such thing as "private claims" in the standard. \- I can sincerely tell you, that from implementing JWS tokens, that the implementation of signed JWTs (or JWS) with compact encoding (which is the dot encoding) is far simpler than your entire labelledGeneric and it won't make the compiler significantly slower. There's a lot of instances where type safety is something you want and love, and there exists overabstracting for the sake of "wow I can express this with the compiler". I find this to be the latter.
Depends on the library. When I saw Java SDK for Bing or Google Analytics I knew that using it without any adapter would be a hell. This post is IMHO a bit of a shapeless showoff, and it is not justified for a small number of case classes... but if I knew that number of cases to support would grow and grow, I would prefer to generate type-classes using shapeless.
[I should've replied to your comment... ](https://www.reddit.com/r/scala/comments/8urtxg/how_to_turn_ugly_java_apis_into_elegant_typesafe/e1ivjgf/) By all means, I agree. This is just shapeless jackoff.
Thanks for the comment. Author here. Well, there are "private claims" in the standard, RFC 7519 section 4.3. As for the covariance, I felt that "if you can encode C1 &lt; C, then you can encode C" is a correct reasoning. But that's not really important. And I feel that being able to tell apart `expires` from `NotBefore`, even though the same representation is used for both (Long/Instant or whatnot), is quite an important thing - it saved my ass more than once and, honestly, I don't feel there is any "tax" to be paid - what would that tax be? If you have `val expires = Instant.now` it's not that hard to imagine that you can accidentally assign it to `notBefore`. Not to mention that it really helps in refactoring (imagine trying to re-order params). But these are just small details. The more important thing is the "insane overcomplication". Now, quite frankly, there are better examples to demonstrate the technique than JWT - agreed. But the technique is almost algorithmic in its essence. The whole shapeless business you can almost copy-paste - `HList`s, `Witness`es, structures of implicits - these work the same regardless of your domain. The only thing you need to think about is how to express your domain as types. Anything else, like "shapeless jackoff" - just copy it. And that's the point of this article, I believe. 
Actually, I don't think it is "overly" complicated. I tried to demonstrate a technique on an example. The essence of this technique is that the whole shapeless stuff (which seems complicated on the surface) will be the same always - if you work with `HList` then you need to provide implicit for `HNil` case and the other for `::` case etc. And the only stuff that is not "algorithmic" is your domain; modelling it with appropriate type-classes. So, depending on your use case, you might want to be bothered because: * it's easy once you realize that shapeless is not a problem, * it pays off - because writing `.setField("a", 10)` `getField("a").asInt` is really stupid when you can write `serialize[C]`
Download the iPhone app and you can change it in settings.
Mine, obvs: https://slideslive.com/38908776
Neat idea. Does it work with an arbitrary line of code?
The top 5 on my playlist are 1. Preparing for Scala 3 https://slideslive.com/38907801/opening-keynote-preparing-for-scala-3 2. Differentiable Functional programming https://slideslive.com/38908214/differentiable-functional-programming 3. Functional programming with Spark https://slideslive.com/38908149/keeping-the-fun-in-apache-spark-datasets-and-fp 4. API with Finagle https://slideslive.com/38908129/building-resilient-and-secure-apis-with-finagle 5. Kafka and Akka https://slideslive.com/38908154/kafka-microservices-with-kafka-plus-akka-and-kafka-streams I watched the keynote from MO today. the rest I play to watch over the coming week.
Are you Will Sargent? Why didn't you finish your book "Play in Practice" ?
Really sad that these aren't on YouTube. I would like to add a bunch to my Watch Later list.
Exactly. Never understood the ass backward logic of these sites ..... they are so proprietary. Just put the content on YouTube or Vimeo. Thatâ€™s it .... what is the need for a third party. 
I'm gay, I'm also a Scala geek who ordered a rainbow scala shirt after seeing this post because it defines who I am rather well at this point in my life. To me a rainbow shirt isn't 'politics' or an 'urge', it represents decades of my life and my family. Having lived my life as an openly gay immigrant, the knowledge that the rainbow flag existed and what it stood for gave me strength once to keep going. After facing some challenges straight couples do not have to face, figuring out functional programming in a language that encourages an an overabundance of underscores is... well, just another challenge in life, and a fun one. I'm proud of having survived this far in the world of IT and in the world in general despite everything life threw at me, and also really want to support LGBT youth suicide hotline because it's a cause worth supporting. Does that answer your question?
Scalacon? Cool! By the way, transgender isn't a noun. Using it as such shows disrespect. I write code in scala and am a part of an LGBTQ community. Did I ask for a rainbow shirt? Um, actually, I just saw this post with a link to support the Trevor Project, it brought a huge grin on my face, and I clicked the buy button.
Thanks for much for the subreddit! Really appreciate the effort you've spent on posting all the Scala conference videos there. 
I would just do this in SoarkSQL rather than DataFrames API: SELECT NVL( (df.val2 - df.val1), df.val2) AS Diff FROM df This works so long as val2 is never null. Your StructType should enforce that. Replace the 2nd parameter with " NVL(df.val2, 0)" if val2 is nullable as well
Looks great. I'll give it a shot. Thanks.
If someone really wants an YouTube URL they can get it by inspecting the player. Here is an example: [D1 opening keynote](https://www.youtube.com/watch?v=OU-WMRFTh8g)
The videos on SlidesLive are actually hosted on YouTube. For example the video for https://slideslive.com/38907801/opening-keynote-preparing-for-scala-3 is https://www.youtube.com/watch?v=OU-WMRFTh8g You can grab the youtube url like this: document.getElementsByClassName('player-video-content').item(0).getAttribute('src') 
Use when(&lt;all non null&gt;, value 1-value2).when(&lt;first null&gt;, value-2).otherwise(&lt;value for rest of cases&gt;)
Looks cool but a config library that brings scalaz does sound a bit overkill
So - as I have heard in the previous "Ask here" Akka is not a good thing. If so - how would you go about creating a browser based game? I wish to create multiple microservices that would take on different tasks: player characters, world events, simulating economy, etc. everything pretty simple, but that would give me a good idea on how to structure larger systems. I was thinking about: 1. Scala (duh). 2. Lagom (it has Akka "inside"). 3. MongoDB (for event sourcing?).
Make a right click on the start/play button in the middle of the video and pick "inspect video". Remove the div with the class "player-click-handler" and then you can use the youtube controls or watch the video on youtube.
Once you decide to use scalaz or cats, you typically consider them standard libraries that you base everything off of. It's like saying a config library in c++ that brings in boost is overkill.
I guess that is a a valid thing to say as well 
Awesome man, thanks for this! :D
AFAIK Scala annotations can be placed only together with definitions (variable, method/function, class).
\^ case in point why identifying yourself online can be risky
This works, too. Could've sworn I tried this when I was at work, but testing at home I'm getting the result I was after. Going to do some speed tests and see how this works vs the spark sql implementation.
I agree that such reporting is a useful feature but can't it just be added to an existing library?
Looks cool indeed. What I think is cool: - printing config values as a table to showcase overrides Field for improvement: - detect mistyped configuration parameters even for environment variables. Idea is to fail on unknown parameter starting with known prefix `db.` - help. Any good software must be self-documenting, at least print help on parameters - typesafe config is the best config library I know. Can you generalize your implementation so it can be used with typesafe config? - custom operators generally suck. They confuse IDE, they provide no hint of their meaning in code or autocomplete list. Consider having alternative way to define config using method names - is it possible to get rid of `import japgolly.clearconfig._` ? IDE autocomplete can not help with this import, user just must know to add it. - converting tuples to case classes via shapeless is not a purpose of config library. Is it possible to isolate that? - masking keys and passwords in report
can you include a dashboard for TODOs after compilation, so as to give information about order by priority or deadline or group by issue types or packages.
Should be warning, not error. Otherwise it will hurt build reproducibility. If your colleagues ignore compilation warnings, this annotation won't help them as well.
I gave this a shot, by my familiarity with SQL/Spark SQL is not great. At the moment, this implementation takes about twice as long as the when(...).when(...).otherwise(...) method suggested here. Here's what I'm testing with (just on my home pc with fake data). The "count" can be ignored - it's part of the mocking to get the fake data working. def sqlDifferenceCalc(baseDf: DataFrame, altDfs: Seq[DataFrame]): DataFrame = { altDfs.foldLeft((baseDf, 1)) { case ((base, count), alt) =&gt; base.createOrReplaceTempView("base") val newValueColumnName = s"value $count" val altRenamed = alt.select("id", "value").withColumnRenamed("value", newValueColumnName) altRenamed.createOrReplaceTempView("alt") (spark.sql( s""" |SELECT base.*,alt.`$newValueColumnName`, |NVL((alt.`$newValueColumnName` - base.`value`),NVL(alt.`$newValueColumnName`, 0)) AS `$newValueColumnName Diff` |FROM base LEFT OUTER JOIN alt ON base.id = alt.id """.stripMargin), count + 1) }._1.na.fill(0) } Any improvements I could make?
flip side would be re-inventing everything. Which is IMO worse.
I built something not to dissimilar. I am also in the process of writing it up and putting it on github but have been very slow about it and some way off. The missing piece of the puzzle is coming up with a better applicative builder in Scalaz as it's limited to 12 or 13 args if i remember right. I like the syntax as reads as a mini dsl and so have been thinking maybe i could use a shapeless hlist to remove the arg limitation but haven't had the time to play / learn shapeless some more yet.
Akka-core which is just the Akka actors framework is very difficult, because you lose all type safety with them. But the other frameworks built on top of Akka like Akka streams... are pretty decent. I highly recommend this thread https://www.reddit.com/r/scala/comments/84ec2l/are_akka_actors_overkill_for_doing_data/
Hi all, just trying a simple scala project for the first time and I've got a bit confused with versions and how scala works. On my system I installed scala (from apt repos) but also used the sbt. I had real issues where on system my version was 2.11.6 and on sbt was 2.12.6. This introduced some weird issues- removing scala from my system however made everything ok. Point being, is the correct way to run scala through the sbt? Coming from a Java/python background it doesn't feel quite right not having a monolith installed on my PC somewhere... 
Thanks for the these videos, they are really helping me revisit some of my basics
Hearing feedback like this is what keeps me motivated. Thanks!
You can specify the version of Scala you need for every individual project and I suggest letting sbt manage that for you. For me, a system-level Scala installation is only useful for the extra tools, like the REPL (for which the Ammonite REPL is superior) or \`scalap\`, and occasionally running \`scalac\` directly on a single file.
finally a comprehensive resource on scala implicits! Iâ€™ve been wanting to get a better handle on these.
It will be complete once I post part 4 ;) I planned to do it in one go, but friends explained to me that no one would read one nearly 9k words/45 minute long post. However, if there will be interest I can always put somewhere the original single-post version.
&gt; typesafe config is the best config library I know. Can you generalize your implementation so it can be used with typesafe config? Typesafe config has some huge drawbacks IMO. Have you ever used it in situations where you want to mutate the document? It uses a completely different set of API's in order to maintain document formatting. I've additionally ran into issues with ordering of config children not being preserved.
`val` establishes an immutable binding from a name to a value, but the value may itself have internal mutable state (as with `StringBuilder`). So the *reference* is constant.
That is such a clear explanation. Thank you.
I've done some benchmarking on my own code and graal-native executables are slower than scala-native executables (I write compilers). Neat thing however with graal-native is that you can compiler a Java-Scala hybrid to native.
You generally don't want to have a system-wide install of Scala, you want to only use it as part of a built tool. (A bit like how when doing Python you'd want to always work in a virtualenv).
"A complex system that works is invariably found to have evolved from a simple system that worked. A complex system designed from scratch never works and cannot be patched up to make it work. You have to start over, beginning with a working simple system." Cassandra and Kafka are good tools and you may eventually reach a point where you need them. But start with the simplest, monolithic structure you can think of, and just get the most basic version of your game running. Know what problem you're introducing these tools and structures to solve. One of Scala's greatest strengths is that it's easy to refactor your code with confidence, so you can leave structuring decisions until later when you have more information.
Yes, you are right. This is what I'm intending on doing since this is just a learning exercise (learning Scala and text based sandbox RPGs are close to my heart), but I was interested in learning how the "big picture" could look like. Thanks for the good advice though!
Heya. I created this library years ago. This actually predates most alternatives. I was just show to open source it. Over the years I've seen other config libraries pop up but I consistently prefer the design decisions and usage of clear config, so I'm noticing personally inclined to port it to another library.
Sound nice but just wondering how many people will actually do it and use it to just solve a problem?
Well, I would actually use it :-) And I think that, if you're bothered by object-as-a-hash-map APIs, you do not need to shy away from using typelevel solutions. I found out that lots of folks felt that it's hard and would tolerate cons of Java APIs. But it doesn't have to be like that - while it's not the simplest thing in the world, it's actually not that hard to come up with a good solution, especially once you know how Shapeless works. So I wrote this piece to help people overcome the fear of this kind of code :-) 
Already spark team is working on model serving . Then why work on this .
Would be great if you can share the benchmark numbers.
Thanks for this feedback! Luckily, we are working tightly with the spark team to get this code into Spark core. Other serving frameworks work be leaving the Spark ecosystem and exporting Spark code for use elsewhere. Ours does not leave the Spark ecosystem and makes use of the underlying Spark cluster. This makes the it 1) Faster because it does not need to export or spin up other machines 2) Cheaper because you only need 1 cluster 3) It works with other spark features like elasticity 4) You get spark's fault tolerant 5) You dont need to change your code, its the same API as Batch and Streaming. 6) because there is no exporting it works with **anything** that works with spark streaming, even if it does not have bindings in PMML or other languages Hope that helps motivate the work!
Yeah, json4s is particularly poor in this regard; definitely not designed with performance as a primary goal. It's doubly bad in the case that your serializer matches because this fold gets executed twice via, essentially, `if (findCustomSerializer isDefinedAt elem) { findCustomSerializer apply elem }`. And it does this for every element so the more fields in the object you're serializing (recursively, because it serializes sub-objects) the more this gets executed. Probably your best bet is to pre-compose all your custom serializers into one big one and register that instead of registering them individually. At least that way there's only one thing to fold over instead of `n`. The situation is not much better for field serializers where it traverses a linked list trying to find matches instead of using any kind of lookup. So you might try to do a similar thing there.
# Teikametrics | Software Engineer III | Boston MA, US | ONSITE | Full Time ##Teikametrics## Teikametrics is a leading maker of software for online, third-party sellers. The company is profitable, with significant monthly-recurring-revenues and has not had to raise any capital. Teikametrics is on target for over 100% revenue growth this year. Online, third-party sellers account for over half of Amazonâ€™s sales volume and 80% of Amazonâ€™s catalogue. The addressable market for Teikametrics, in North America alone, consists of over 2.5 MM sellers accounting for $200 BN in sales revenue. Teikametrics provides broad-ranging tools for sellers that cover supply logistics, inventory management, marketing, advertising, sales and competitive intelligence. If youâ€™re looking for an opportunity to join a proven, profitable, early-stage startup with massive growth potential, Teikametrics is a unique opportunity in the Boston job-market. ##Software Engineer III## Teikametrics is looking for a software engineer with strong computer science fundamentals and a background in application development. Our primary tech stack is built on Scala with cats, fs2, akka-http, slick, and typescript with react and redux. We also use ruby, python, javascript, and postgresql. We follow a "functional first" programming paradigm. Strong candidates will have - 7+ years of experience working as a professional software developer. Comfort with working on a SaaS system at scale. - Proficiency in Scala, Java, Javascript, Haskell, or related languages - Knowledge of databases and experience with writing code that interfaces with the database layer. SQL/RDBMS experience required; experience with various NoSQL databases desired. - Experience writing well designed and testable code, and writing effective unit and integration tests. - Experience working in a mature production environment (Deployment, CI, Monitoring/Alerting) - Passion for working with a small team of world-class developers, solving challenging problems. - A desire to work in a collaborative environment focusing on continuous learning; participating in mentoring, tech talks, code review, and some pair programming. 
Hi. How do we apply? Thanks :D
# Arcadia.io | Software Engineer | Pittsburgh, PA, USA | ONSITE/REMOTE | Full time Arcadia.io is a privately-owned healthcare analytics company founded in 2002 and based in the Boston, Massachusetts area with offices in Burlington, Massachusetts; Rockford, Illinois; Seattle, Washington; and Pittsburgh, Pennsylvania with dozens of remote employees nationwide. Phrased succinctly, we use patient records to help doctors tell patients how they can be healthier and how they can get better when they're sick by enabling those doctors to see a patient's record with every doctor they see. We have a variety of positions available: * Senior Software Engineer * Software Engineer, Systems Generalist * Software Engineer, Backend Web Development * Software Engineer - Data Warehouse * Software Engineer in Data Pipeline Integration The company has a handful of web services written in Scala and a ton of Spark code also in Scala. I'm the manager on the team with the Scala web services. There are also some other positions open on our Ruby on Rails teams, including a manager position. Our [careers link](https://careers-arcadia-io.icims.com/jobs/search?ss=1&amp;searchLocation=12781-12822-Pittsburgh) is the best place to read more and apply. Feel free to ask questions via PM, too.
I'm not currently looking for work, but I'm a full-time Scala dev and fellow Vermonter. It's good to see more of us here!
Wow, this is a great release, well done! Semantic Versionning dsl + Project matrix!
Edited that in
Remember when you used to heat up the metal edge on a school ruler by rubbing it on an eraser and then you and your friends would see who could hold it on their arm the longest? Thatâ€™s what I would consider writing scala in vi. I mean, itâ€™s cool to suffer stoically. But you donâ€™t have to. IntelliJ took a lot of time and effort to write, no sense in letting all that work go to waste just to see the children of Uganda message. Not to mention all the hints and suggestions that IntelliJ provides to help you learn scala and visualize all the functions and sugar the variable youâ€™re working with provides. But donâ€™t get me wrong, I love vi. Iâ€™ve been using vi for more than twenty years. I get to laugh at people trying to use vi like they get to laugh at me using emacs. But when it comes to anything more than messing with configuration files or quick edits, i fire up a proper IDE. But...vi does provide scala syntax highlighting last I looked.
Regarding #4, could you please expand on how HA works if the driver goes down? Also, what's the recommended cluster manager, I'd assume doing it via Azure databricks isn't possible since it's a notebook only service? 
Good question! for #4, the system is built on top of Structured Streaming so the same fault tolerance guarantees from streaming apply to serving, with the exception that connections that are lost cannot be re-made. For driver node fault tolerance, you can use a zookeeper for driver failover. See this gist for more info: https://gist.github.com/aseigneurin/3af6b228490a8deab519c6aea2c209bc For usage on azure databricks you can use the option for a head node balanced cluster as this will work without additional setup. If you would like to use the custom load balancer option, which spins up services on each of the workers you will have to contact databricks to get them to unlock your resource group so you can add your own load balancers. We are actively working with them to provide this kind of control out of the box! 
Thanks for sharing. Wanted to give you a heads up that I got a 404 on this link: &gt;The full code that extracts the 50-day subsequences, performs vectorization, and builds and trains the neural network is available [in a Zeppelin notebook using Scala](https://github.com/deeplearning4j/deeplearning4j/blob/master/dl4j-).
I am not quite sure what you are asking. Are you asking if there is a way to pass a lambda function to an actor and have that actor execute that function, but only if that actor "recognizes" that function? I think that could be done with case classes as well, as you mentioned above.
Yeah, count me in as another big vim/emacs fan who still uses intellij for scala. I use emacs or vim any time it is reasonable to do so, but for scala...no. 
Hi, under your senior scala engineer position you have a malformed list... \-&gt; * tweaking the performance of the high-velocity status endpoint where minutes down means potential data * loss
Thanks, I'll look into it.
Still working on [Scattersphere 0.2.2](https://www.github.com/KenSuenobu/scattersphere). Lots of motivation to head toward distributed architecture in the next major releases. Next release should include: - Ability to start a job with parameters (prep work for CLI) - Controllable, Pausable JobExecutor as a controller class, not a master class - Introduce docker support - Ability to register a job by name with the JobExecutor class - Ability to run a job by name - Distribution to Maven Central/JFrog Lots of exciting stuff coming soon. I hope to have tighter integration with Spark and Mesos in the next few releases!
(Forget what I said about second argument lists and eta expansion. It's easier just to encapsulate the actor method call in an inline lambda function.) For example, if the ability to send a message to the actor is mediated through an "actor reference" object, that object could have a subclass that is particular to the actor, and which exports methods which comprise the actor's public API. These methods could take their arguments and construct zero-argument lambda functions which call corresponding methods in the actor that do the actual operations. Then queue these lambda functions on the actor's mailbox as messages. When the actor receives a message, it must be one of these zero-argument lambda functions created by the actor reference, so it should be safe to call it. This gives you typed actors, but also may be more efficient than using case class instances as messages. I'm thinking particularly of Scala 2.12 and its improved implementation of lambdas. 
Vim works fine, I use it more than intellij. I don't find myself sticking for very long with any plugins for Scala. I sometimes leave a split running a terminal emulator with a warm sbt instance. That's about it. Intellij is fine for an ide, but people make it sound like writing Scala without an ide is this painful thing. I think this is mostly projecting Java's problems (unfairly) onto Scala.
If you want to learn Scala, then I don't know, but if you know Scala and just want to use it while learning about algorithms, try Stanford's Algorithm courses by Tim Roughgarden. * [Engineering Algorithms Part 1](https://lagunita.stanford.edu/courses/course-v1:Engineering+Algorithms1+SelfPaced/info) * [Engineering Algorithms Part 2](https://lagunita.stanford.edu/courses/course-v1:Engineering+Algorithms2+SelfPaced/info) A major advantage is that the exercises are marked based on answers produced by your algorithm implementations and so you're free to use whatever language you want. 
Thanks I found multiple courses but they were forcing me to do submissions in Java or Python which is very annoying . 
A colleague of mine is using vim for almost everything (including Scala development). I think his current setup boils down to running sbt with ~compile. Not sure how good the Ensime integration is. I for myself use exclusively Emacs for all my work (including Scala with Ensime) and I have to say it is great. Very small resource footprint, fast and just a huge amount of plugins/features you can install. I basically switched all my task I do on a notebook to Emacs, except for browsing the web. Furthermore, I get the impression that productivity increased after improving my Emacs skills over time (highly subject comment). I would say give it a try.
Excellent post with a strong focus on solving the actual problem in an as precise manner as possible. Too often programmers just hammer around at the screws they see, wondering why they bent in such strange manners ;). 
Erm, you guys do know you can use Vim as your default editor ....in.... IntelliJ right? Makes life a WHOLE lot simpler... Heres a link to a plugin... not entirely sure if its the correct one for your env.. believe there are a couple, but result is the same. [https://plugins.jetbrains.com/plugin/164-ideavim](https://plugins.jetbrains.com/plugin/164-ideavim) And here is an alternate with some examples for configuring terminal shortcuts: [https://www.jetbrains.com/help/pycharm/using-product-as-the-vim-editor.html](https://www.jetbrains.com/help/pycharm/using-product-as-the-vim-editor.html)
Have you seen https://www.scala-exercises.org? You can try the Scala Tutorial and FP in Scala courses. 
An actor that doesn't encapsulate state is pointless, isn't it? And since scala doesn't have second-class functions, there's no way to make an actor's state available to functions defined in other classes without, well, making it available to functions defined in other classes, which would break the encapsulation/isolation of that state which is the purpose of the actor. Of course you can make an actor that accepts zero-argument functions and runs them. But at that point why use an actor in the first place? If you just want a mutex, use a mutex, and then you don't have any type-safety issues. If you're going to get any use out of the actor then there's no way to get away from having to be able to send the actor a representation of a command which is not just the actual invocation of the command, as far as I can see.
Silly question, but why not on Github or will it move there eventually?
Hi Scf37. Thank you for the suggestions but it seems there are a number of misunderstandings. Allow me to clarify. &gt; fail on unknown parameter starting with known prefix db. Yeah, nice idea :) PR welcome &gt; typesafe config is the best config library I know. Can you generalize your implementation so it can be used with typesafe config? It's, by far, the worst config library I've seen in Scala in my opinion. For unpleasant reasons (that thankfully vanished) I did toy around with interop with it though and it seems impossible. &gt; custom operators generally suck I don't define any. They come from Scalaz/Cats and are consistent. &gt; is it possible to get rid of import japgolly.clearconfig._ ? IDE autocomplete can not help with this import, user just must know about it. No, that's not Scala works. All Scala libraries require an import. &gt; converting tuples to case classes via shapeless is not a purpose of config library. Is it possible to isolate that? clear-config doesn't do that; Shapeless isn't a dependency. Scala provides an apply method to companion objects when you create a case class, which is what you pass to Scalaz/Cats' applicative builder (the `|@|` operator stuff). &gt; masking keys and passwords in report Indeed and already done, check out the README.
I have. I was specifically looking for a "data structures and algorithms" resource which allows Scala submissions.
**Tray.io | Backend Software Engineer | LONDON UK | ONSITE | Full Time** Tray.io is ushering in the era of the automated organisation We believe that any organisation can and should automate. With Tray, citizen automators throughout organisations can easily automate complex processes through a powerful, flexible platform, and can connect their entire cloud stack thanks to APIs. Today businesses like IBM, GitHub, Forbes, Lyft, and Digital Ocean rely on Tray to connect and automate data flow between the tools they use every day. With Tray's visual workflow builder our customers create automations to drive their business processes without writing a single line of code. Our challenge is to build a cutting-edge product that is powerful and complete while also being beautiful and easy to use. You'll contribute directly to this mission with a team that fully supports you to do your best work. You'll join humble but fiercely ambitious people like yourself, who also take great pride in what they do, working in a culture built on friendship, transparency, and above all, looking out for one another. You'll have endless opportunities to learn and grow professionally in a fun, fast-paced, and open environment. Plus, you'll get to make your mark at a rapidly-growing company positioned to completely reinvent a multibillion-dollar industry. **Your mission** Tray's backend infrastructure processes millions of requests per day and is a mission-critical component of our customers' businesses. As a Software Engineer working in the Platform team at Tray, youâ€™ll be responsible for designing, building and running the software and systems which underpin our large-scale, real-time, distributed infrastructure. We expect you to build flexible services and tooling which allows Tray to rapidly scale whilst delivering a seamless experience to our customers. The Platform team is responsible for providing a production environment where connectors integrations and automations can run reliably and at scale. This involves dealing with compute providers, networking, packaging, storage, monitoring, logging, and security. This necessitates building the services and APIs that expose these services to internal and external users of our infrastructure. **Responsibilities:** * Leading the development of flexible services &amp; tooling that allows people to store and run integrations at scale * Building internal and external facing tooling and APIâ€™s that allow our users to fluidly build on our platform * Working collaboratively with Product managers to deliver key security, scalability and reliability features * Growing a motivated, high-performing team * Automate the testing and deployment of your work * Envision new features that help our users connect services faster and easier **REQUIREMENTS** Minimum qualifications: * BS degree in Computer Science or related technical field, or equivalent practical experience. * Solid experience in a stand-out production environment * Expert knowledge of at least two programming languages and paradigms (e.g. Scala, Java, Kotlin, Groovy, Go) * An irrational passion for building distributed systems * The desire to learn, improve and work together * Good knowledge of internet networking and performance * Passionate about troubleshooting, debugging, and automation * Experience building web services and APIs **Preferred qualifications:** * Experience launching cloud-based services * Experience with real-time, distributed systems * Experience with writing multi-threaded software * Passion for performance and tuning * Experience in capacity planning and load testing * Experience with clustering technologies (e.g. Kubernetes, CoreOS, Mesos) * Previous IaaS or PaaS experience * Tech Stack **Our current tech stack:** * Scala, Go, JavaScript, TypeScript * PostgreSQL, Redis, ElasticSearch, Cassandra, AWS SQS, AWS Kinesis * Docker, Terraform, AWS Lambda, Serverless Framework * Jenkins, Grafana, Prometheus * AWS &amp; Linux **BENEFITS** Working at Tray offers many perks, but most importantly we are a talented team with a passion for the product we are building. Benefits include: * Competitive salary * Stock options * Unrestricted holiday policy &amp; work from home days * Flexible working hours * A fun and supportive working environment * Top of the range equipment budget * Drinks fridge &amp; stocked kitchen * Social events (team breakfasts/lunches, evenings out &amp; trips) * Employer contributory pension scheme * Cycle to work scheme * Private healthcare * 50% off Virgin Active gym membership
TensorFlow is a C++ library that has a Python wrapper. It also has Java and Go wrappers.
My understanding is that the Pythong wrapper is quite a bit more full featured then the other ones though. e.g, they seem to build the C++ as much for the wrapper as the reverse.
[https://github.com/Azure/mmlspark](https://github.com/Azure/mmlspark)
Thanks. 
Hi I use neovim for Scala development. I have to admit I do occasionally use Intellij still but do try to mostly stick to neovim. Basically main pointers about my setup are: * Use ensime [http://ensime.github.io](http://ensime.github.io) * I use [https://github.com/pjrt/stags](https://github.com/pjrt/stags) * I have a terminal window open and I use SBT to compile and run tests and I use this to display the errors inside vim: [https://github.com/aloiscochard/sarsi](https://github.com/aloiscochard/sarsi) (note building this broken with latest version of Haskell you may need older version) Feel free to take a look at my neovim setup dot files here: [https://github.com/softinio/dotfiles/tree/master/vim](https://github.com/softinio/dotfiles/tree/master/vim) (I keep my plugins used in a separate file to my vimrc) Let me know if you have any questions. VIM support can only get better especially as both scala tools team and contributors of the ensime project are working on adding full LSP support: [https://github.com/ensime/ensime-server/pull/1951](https://github.com/ensime/ensime-server/pull/1951)
Last time I was looking for the same I came across this: [https://www.amazon.com/Purely-Functional-Structures-Chris-Okasaki/dp/0521663504](https://www.amazon.com/Purely-Functional-Structures-Chris-Okasaki/dp/0521663504) Have not had chance to buy and read but on my wish list to do so when time. If you get let me know what you think of it ? 
count me out. I've been programming in VIM for quite a while, and i choose to use VIM for all of my scala code. I do fire up IntelliJ from time to time but still prefer to use VIM for the majority of my editing. Chances are when LSM gets better integrated in VIM i wont even have to fire up IntelliJ, or if i figured out how to get Ensime to reeeeeally work well inside VIM, i wouldn't need it. The only things i rely on IntelliJ for is type hinting on things that become a little complicated from reading the code.
You can use a vim *emulator* in intellij, but you can not use vim directly. There is a very big distinction between this. my vimrc would not work properly in the intellij editor as some features I've used for quite some time would break while in IntelliJ's ex mode. 
I've been a VIM user for quite some time and do all of my development in VIM. For work I use Scala 100% of the time and in some side projects I've been toying around with C/C++11. There are some changes to the way you may have to think about things, but for the most part it works well. Some of the workflows that I do... Finding Usages of a function or variable: In an IDE like IntelliJ they index the entire project and use a massive index file to be able to tell you detailed information about where variables are declared, where they're used, and everything in between. In VIM you don't have this, and this is the main difference between an IDE and a text editor. This isn't to say that you can't get the same level of functionality with a little more work. Since I'm in the unix command line i take advantage of all of the unix tools to figure this out. This particular issue can be solved with a variety of tools including `grep`, `ack`, or on mac `silver searcher` and there should be various plugins in VIM that show you the information you need. For example, for me if i type `:Ags "myFunctionName"` it will show me a snippet of all the places with that function and a few lines above and below Type information: Normally in the editor you can hit "alt-enter" and it will show you the type information. This is quite a bit more work and if you really rely on this functionality and don't want to ensure that `sbt ~compile` gives it to you, then you can try a language server or ensime. Both of these are good but require some setup. Ensime works fantastically in emacs but i've had some issues with it in VIM. I mainly rely on `~compile` Auto completion: Many many many different ways to accomplish this, but the built in auto-complete in vim is really good. `:h ins-completion` has some information if you want to look this up. So yes, you can do a lot in VIM if you really want to. I never say "going to an IDE is bad" because to me, being a programmer is using the tools you're comfortable with and the tools where you feel the most productive. If thats vim, awesome.. if its an editor like intellij, keep at it. 
For pure Scala projects it works fine, I've never been successful in getting a good experience with projects mixed with Java and Scala.
Good: https://blog.philliptaylor.net/vim-as-a-scala-ide/
SBT doesn't use system install of Scala. The project project definition contains a setting for which version of scala to use, which SBT will download, cache, and use. By default, this version is the same version of Scala SBT is compiled against. You should fix the version of Scala you want to use in the project definition, and you should also fix which version of SBT is used as well. The launcher will then download the correct versions of both for each project.
yes its a great book, but after first few chapters it became very dense for me. For me, video lectures combined with lots of exercises works well. I only wish that someone takes the content of Okasaki's books and makes a MOOC out of it. it will really help people with half a brain (like myself). 
Hey there, Ive seen your project before but cant grasp my head around what it actually does. Is there something easy to digest that explains the purpose? It seems very interesting. Thanks!
Author here, feel free to ask me any questions here that you might not want to ask on Medium. Hope this is useful.
I use both * **Intellij-with-vim-mode** \- great for Jumping around source code you're not familiar with and has a nice "code-review" feature, but it gets prohibitively slow overtime * **Vim** \- great editing tool but has its limitations. vim knows nothing about the object graph in the source. All it sees is a bunch of text. Well, you can try to solve that with ensime but it is slow, and doesn't work that well (I've used it for over a year). So, my solution is to keep them both open and mainly use vim however every time, I wanna check source code quickly switch to Intellij. Plugins I use, YouCompleteMe, vim-surround, vim-scala, vim-taglist (with ctags), ctrlp and a few others. Given that lightbend is now working on improving scala tooling, I am hopeful, eventually things will get better.
Recently stumbled across this https://github.com/DimaSamoz/mezzo I don't know if it's specifically what you were thinking, but it seems very relevant and as a former music student and current FP dev, it's on my shorter list of things to dig into.
How are functions in Scala "first-class"? I get that they can be passed around as arguments to other functions and even returned by a function, but how different is this from Java - which most assuredly does not seem like a language with first-class functions? That is, if every function in Scala is really a FunctionN trait object (0...22 arguments) then what's the difference between doing this, in Scala: ``` def a(a: (Int, Int) =&gt; Int):Int = ??? a((x:Int, y:Int) =&gt; x + y) ``` and this, in Java: ``` interface IFunc2&lt;T&gt; { T apply(a: T, b: T); } int a(func:IFunc2) = { } a(new IFunc2&lt;Integer&gt; { Integer apply(a:Integer, b:Integer) { return a + b } }) ``` The only difference seems to be the type inference and the verbosity (my Java's a bit rusty so I'm not really sure if I'm missing something else out, though.) TL;DR if every scala function is an object with `apply`, what makes it a first class function, when there's an almost 1:1 correspondence with Java anonymous classes with a single apply() method, and Java doesn't support first class functions? Is the difference purely syntactic sugar?
In my experience feedback from ensime-vim is super slow when compared to emacs. I've used spacemacs for a while, eventually ensime borked . InteliJ with vim emulator works fine 
[removed]
I'm using [Scaffeine](https://github.com/blemale/scaffeine) to cache HTTP calls and it's worked well for me so far. 
Functions being first class usually refers to functions being values, just like any other. They are in Scala. I don't know Java so I don't know how that compares.
Thank you! i'll check it out. 
I would store the data in Redis without a TTL. Then, have another process on a timer which updates the data in Redis every X seconds. Your service will always use/return data from Redis.
&gt; Pythong Thats a great merch idea right there.
Why would it matter what language they are in. Language is irrelevant to this topic
Well I cannot get credit for completing the course. I can not submit my final assessment because the course accepts only Java and Python submission. I would hate to start writing Java just to pass the course. 
You might consider making videos for the intermediate audience if you have time. I know it's takes a lot of time and effort to put these out. I've watched a few and they're well done, but I think there's an audience out there that has, probably out of necessity, had some exposure to Scala but missed out on any formal onboarding to the language and could benefit from the level of detail you provide. That audience is a little too advanced for the current pacing but would really enjoy the coverage you give topics. Just my two cents, thanks for making the ecosystem better!
Also lot of algorithms books and courses teach by doing inplace mutations which is optimal but as a Scala programmer I always think in terms of immutability. Also there is always a conflict between me and the course. Even though I want to become a better programmer by learning algorithms. I find the course hideously teaching mutability at each and every step of the algo. 
When it comes to algorithms / data structures, you're only gonna have to learn syntax and both Java and python have trivial syntax.
Fuck that. I will finish the standford course and then based on those learnings I will go and finish Mr. Okasaki's wonderful book.
TL;DR I realize this question is splitting hairs, but it's worth asking: Is first class function support simply syntactic sugar? Other languages which require the programmer to emulate the same functionality (which are "not first class") versus languages which have it built in (which are "first class") - where is the line drawn? That is, if I create a macro preprocessor which goes through all my X code, and replaces a special block (e.g. `({ })`) with whatever the equivalent of a function is in that language (e.g. whatever I've written above in the case of Java), does that language X now offer first class function support - because I'm passing functions around as values? --- &gt; Functions being first class usually refers to functions being values, just like any other. They are in Scala. Yes, but that's what I'm doubting: If functions in scala are really objects with trait Function1...FunctionN, then it is effectively the same as an anonymous class in Java. You can do the same thing - albeit with more typing - in Java, then; however, Java does not support first class functions. By this logic, then, does Scala also not support first class functions? Since a Scala function is really just a class / trait with the function `apply()` (such that `function(args) === function.apply(args)`), what differentiates it from Java's `Callable` or `Runnable` which also has a single method that you can run? This is more regarding the "under the hood" aspects of Scala, because on the surface, it seems like Scala has first class function support, but really all you're doing is just passing around objects of classes with "a special consideration" (i.e. apply() is equivalent to just calling it directly). Yes, that's "first class function" support, because you're passing functions as objects, but then so is Java which also does the same thing, but in a much longer syntax.
It's basically a way to coordinate a DAG of jobs programmatically using Scala. You can construct a DAG by creating a job that has a list of tasks that depend on one another. Once you have the DAG generated, you tell the Job Execution engine to run the job. It can be used to start one task, then once that task is complete, starts three others asynchronously, then an additional two after all three finish, etc. It's similar to other libraries, but I've tried to keep mine concise, small, and efficient. It's going to run jobs and tasks, and that's what it's designed to do. I'm simply adding more features to it to make it more robust and easier to use in a server environment. (I just added Spark support with the last release!)
You can also use an in-memory cache such as the one provided by Google/Guava. Set a X second TTL on the cache, have each request check the cache, if there's a hit, return the result from the cache. If there isn't a hit, fetch from HTTP, store result in cache/return response to end user.
Guava cache also has support for preload and you can configure it to either expire after read or write
This has been mentioned a few times to me and I'm currently digging in. What FP has taught me is that if I can solve one problem (music notation) I can solve problems across other domains with the same program, I just need to find the maps. Like I said people have been composing music for much longer than they've been writing programs. I have this strange intuition that if I can learn the why the decisions of composition with music there are concepts which I can apply to writing my programs. Since this project is Haskell I assume you're a Haskeller? I have greater ambitions than just writing music however. Something something NP complete ;D
If a actor had the job of just calling a function, whats it really doing and where does that fit into the design? That may be hard to read that code later on, rather than it being with the function creation.
I am looking at utilizing the incremental compilation aspect of sbt. I have done a bit of research and it would seem that the most apt tool for the job is Zinc, the documentation is not as comprehensive as I may like though. Does anyone have any experience with using zinc that they would be willing to share ? 
&gt; Is first class function support simply syntactic sugar? If from the users perspective functions behave just like any other value, they are first class in the language. The implementation of a specific compiler is not bound to the language. &gt; That is, if I create a macro preprocessor which goes through all my X code, and replaces a special block (e.g. ({ })) with whatever the equivalent of a function is in that language (e.g. whatever I've written above in the case of Java), does that language X now offer first class function support - because I'm passing functions around as values? That probably depends. Can you have a function type as A in a `List[A]`, in exactly the same way as you could any other type? Can you have a type that's a function from one function to another? If so, then yes, you probably have first class functions. &gt; If functions in scala are really objects with trait Function1...FunctionN, then it is effectively the same as an anonymous class in Java. You can do the same thing - albeit with more typing - in Java, then; however, Java does not support first class functions. I really don't know much of anything about Java, so I really can't say much about that. &gt; what differentiates it from Java's Callable or Runnable which also has a single method that you can run? I have no idea &gt; This is more regarding the "under the hood" aspects of Scala That would be an implementation detail of the specific scala compiler, and could differ from compiler to compiler. But if functions would be somehow "special" and treated differently from other values for the end user, they wouldn't be first class anymore. 
I see, thanks. I guess it's different for Scala since everything _is_ an object, but way I see it, "first class" not only means that it can be passed by value, but also that it is more or less like a primitive - in other languages, you'd have int, double, and other primitives which you cannot extend but can pass as values, and to me those are truly "first-class", whereas object types (user-defined) are "second-class" because of polymorphism - you can extend and pass as values, whereas functions and so on are "third-class" because they can't be extended meaningfully (e.g. what's the point of extending a function when you can't declare its body like a normal function?) nor can they be passed as values.
I'm not entirely sure what you mean, but in scala, you can't extend objects. You can only extend class types: ``` C:\Users\martijn&gt;scala Welcome to Scala 2.12.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_161). Type in expressions for evaluation. Or try :help. scala&gt; object Foo defined object Foo scala&gt; object Bar extends Foo &lt;console&gt;:11: error: not found: type Foo object Bar extends Foo ``` I'm not sure what you mean by everything being an object in scala
hi, don't know if I understand your problem correctly. If you use sbt to build your program, it already uses zinc to decrease your compile time
Hey yeah I guess it is not phrased well. I am very new to the area. My experience to date with SBT is that it has the potential to be really powerful but quite slow. When you make a small change in the code you have to recompile it all, this can be quite time consuming. My understanding of Zinc is that it allows incremental compilation. Ie when you make a small change it tracks which files are affected and only recompiles them. Leading to faster builds. I am looking to get a better understanding of this. Runtimes without Zinc and with. Wrt to I Zinc being built in, my understanding is that it is built into pre 1.0 versions of sbt which the project is not built on. I have read that you can incoporate a version of Zinc that is compatible with this, but I am unclear as to how one would, or how one would measure the improvements .. 
All programming language features are "syntactic sugar" in a sense, because any Turing-complete language can emulate any other. Your `IFunc2` is "a function" in some sense, but it's not what a Java developer would call a function because a) you can't invoke it like a normal Java function b) you can't pass a normal Java function to a function that takes an `IFunc2` (in particular, you can't use the normal Java function declaration syntax to instantiate an `IFunc2`). What I'd consider "true" first-class functions is when, as well as being able to pass and return functions everywhere, you can also form new functions using the language's normal function syntax anywhere you can put an expression. Scala has this (you can do `def myFunc(...) = ...` anywhere) whereas in Java functions can only go at class level.
sbt already uses zinc, scala is just not very fast to compile. To test this you can compile, make a small change, recompile, stop the program, delete all target folders and use sbt clean, recompile. You will see the speed difference
Yeah the documentation is unclear, but my understanding of it is that it may be part of 1.0 its pre- that where the issues are. But like you say I should really boot up both versions and do some comparing. I'll plug away on that and hopefully gain more insights on the way :) Thanks for your input. 
Ctrl+C fixes wow. Not expecting things like that to ever happen. Thanks &lt;3 
I find with Scala you can take a monolith much further than you can in other languages, because you have so much less global state and much better enforcement that things are segregated from each other. You can use a multi-module project to enforce that certain parts of the codebase physically can't interfere with other parts of the codebase, but still have a single deployment artifact. So even the largest projects I've worked on didn't tend to use microservices in the same way you would in a dynamic language. Likewise with code layering, I've never felt the need to have a strict "model/view/controller/DTO/DAO/..." layering in a Scala codebase, because the language is easy to safely refactor. So it's fine to have some services using one split and others using another, because you can always change the way the code is organised quite cheaply if you suddenly want to e.g. reuse an abstraction between two (initially) differently-structured services. I appreciate this isn't really the answer you're looking for, but ironically enough the very structured-ness of Scala makes it very flexible. There's no particular way to structure a Scala project in general because it's very easy to adjust the structure to fit exactly the problem you're solving.
Thanks! Much appreciated! I totally understand the potential frustration for someone already familiar with Scala. I do intend to cover intermediate topics as well, but at least for this very specific playlist I would really like to keep things as they are. See I did not intend this playlist to be an introduction to Scala, I wanted it to be an introduction to programming, which is why it is called "... as a first programming language ...". Having said that the more we progress with this one the more the focus will lean towards Scala. I'm already working on videos for higher kinds, implicits and so on. I understand that this is not exactly what you meant. I can only ask you to bear with me for a little while. I suggest making use of YouTubes 2x speed button, I do it all the time ;) Thanks again!
Are you running sbt interactively or executing `sbt compile` each time? SBT has a high start-up cost as it has to parse your project definition and (possibly) compile it. You should run SBT once, in interactive mode: `sbt` then simply execute targets within sbt's shell: e.g. `compile` or `test`. Compilation will be incremental (if you make a small change, you'll see that the number of files it reports as being compiled will be very small - usually just one.
I am running sbt compile on each iteration. Does this incremental change happen in pre 1.0 versions due to zincs inclusion or has this always been the way ? 
I didn't knew Microsoft used scala. How much is scala in use there ? Only for spark related stuff I gess.
To clarify, "everything being an object" in the Java sense of things, sorry. That is, there's no distinction between primitive types (int, etc.) and non-primitives (classes) in Scala whereas in Java, C++, etc. there's int, double, bool types etc. which are primitives and user-defined types, which are not primitives.
Ah, I see, thanks. Does this mean that the main reason that it's implemented as a Function1...N trait in Scala (i.e. `apply() === call`) is because of compatibility between Java and Scala?
The recommended workflow is to use the "sbt shell" by typing in the terminal `sbt` without arguments. This starts sbt in an "interactive mode" from where you can run compile/test/run https://www.scala-sbt.org/1.0/docs/Howto-Interactive-Mode.html Inside the sbt shell, I frequently use `~compile` and `~test` and `~testOnly` to trigger a re-compilation on file save. This provides a decent edit/run/debug workflow. The most annoying part of sbt shell is that Ctrl-C exits the shell and brings you back to the terminal. If you prefer the terminal and want fast edit/compile/test workflow you can also try Bloop https://scalacenter.github.io/bloop/ It uses zinc behind the scenes just like sbt.
SBT has had an interactive mode pretty much always. It's how it's designed to be used. This has nothing to do with Zinc or interactive compilation; it's the startup cost of SBT that's making your build take so long. Try out running SBT in interactive mode and running `compile` a few times. It should be much faster than what you're used to. If you're using a recent version of SBT (e.g 0.13, 1.0, 1.1, 1.2) incremental compilation should work out-of-the-box. Zinc was a project years ago for older versions of SBT that didn't support incremental compilation. It's now been integrated in to SBT so you don't have to worry about all that.
I think so yeah. We want functions to be values, and in Java and on (older versions of) the JVM the only kind of (custom) values are objects. I see those traits as an implementation detail more than anything, analogous to the boxed primitive types in Java.
That isn't the normal meaning of those terms. If anything I'd say primitives are less first-class than normal user-defined types, if you can't use them everywhere you could use a user-defined type (e.g. in java you can't use primitive types as generic type parameters). Ultimately it's all just semantics, but https://en.wikipedia.org/wiki/First-class_citizen gives some idea of the consensus meanings of these terms.
&gt; The most annoying part of sbt shell is that Ctrl-C exits the shell and brings you back to the terminal. `cancelable in Global := true`
"objects" generally includes at least all instances of classes, not just values created by the `object` keyword. "Everything is an object" means that all values are objects - in particular all values support method invocation and all values have a class at runtime.
Is this loss?
I've tried that setting but it doesn't work as I expected when you have multiple parallel tasks running.
These seem unfortunate implementation details - having methods on `Any` is not ideal (and may change in dotty). Checking runtime classes of values is rarely a good idea. I'm not sure how these things relate to functions being values.
True, at least in the case of Java, primitives are not always first-class.
Yeah I think I was a little murky on the details and it is becoming clearer. Thanks for the accurate and helpful response. 
I have tried that and I am seeing what you are saying . Thanks for the input.
&gt; These seem unfortunate implementation details - having methods on Any is not ideal (and may change in dotty). Checking runtime classes of values is rarely a good idea. I don't necessarily disagree, but to the extent that Scala wants to remain an OO language I would expect it to continue to regard all values as object instances; I'd expect at least `getClass` to remain on `Any`, and I'd expect all ways of interacting with values to continue to be conceptually equivalent to method invocation. &gt; I'm not sure how these things relate to functions being values. If all values are objects and vice versa - and in Scala they are - then functions being values is the same thing as functions being objects. So it is related. E.g. I suspect that we wouldn't have the `FunctionN` traits in the same way if it weren't for everything being an object. (Of course we would want to have the `FunctionN` *types*, but maybe we wouldn't regard function application as conceptually being invocation of the `apply` method, and maybe function values wouldn't have a runtime class).
Defining a type alias also works with Kleisli composition. For this example, the value must be extracted from the option context explicitly like below def findAddressByUserId = Kleisli(findUserById2) andThen Kleisli(findAddressByUser2).local((x: Option[Long]) =&gt; x.get)
I agree with everyone else: scalac is slow and sbt adds its own overhead. With such simple project best you can do is keep JVM warm: use bloop or run sbt in shell and don't close it. If your project grow bigger there might appear other opportunities to optimize (or actually, there will be opportunities to slow things down that you need to look out to avoid). I've written a [post about the topic](https://kubuszok.com/2018/speed-up-things-in-scalac-and-sbt) some time ago, but in you case bloop and/or sbt shell is the best call. You can have some speedup (in my case \~15&amp;#37;) if you replace OpenJDK with GraalVM, but don't hope for any order-of-magnitude one-liner optimization.
But then you have to maintain a redis instance. I'd start with something simpler, the akka caching seems fine
July 12.
Scalameta-based tools will be able to work with Dotty, both syntactic and semantic. Compiler independence is a core principle of Scalameta. This means for example refactoring and linting rules written with Scalafix will work with Dotty. Syntactic rules should already work, and semantic rules will work once there is a SemanticDB generator for Dotty https://lamp.epfl.ch/cms/site/lamp/lang/en/teaching/projects/#semanticdb-generator-for-dotty The syntactic API is lagging a bit behind current Dotty master since the Dotty syntax has been going back and forth lately. Once syntax stabilizes we can update the Scalameta parser. Semantic capabilities are also increasing, SemanticDB now supports types https://github.com/scalameta/scalameta/blob/master/semanticdb/semanticdb3/semanticdb3.md#type
Ahah, that's right, it was sarcastic. The tech behind the UI is good (Scala.JS, React.JS...), we focused on the backend and API ergonomics first. I hope a better frontend dev will make PRs to improve the UI :)
&gt;littlenag I really glad to hear that! I'll be presenting it in London at the LSUG Meetup the 9th July, if anyone is there. Thanks
It's not for the light hearted - after a few trivial exercises it gets progressively trickier, and by the middle of the book I felt as if I was trying to run through a tar pit. The result of that, if you're interested, is here: [https://github.com/KamchatkaLtd/okasaki](https://github.com/KamchatkaLtd/okasaki) (spoiler alert: many exercises are solved there, so if you don't want to lose the joy of solving those yourself, postpone visiting :)) Another resource that can be useful if you focus on purely functional data structures is [https://cstheory.stackexchange.com/questions/1539/whats-new-in-purely-functional-data-structures-since-okasaki](https://cstheory.stackexchange.com/questions/1539/whats-new-in-purely-functional-data-structures-since-okasaki) 
You really need to do EPFL's course on parallel programming ([https://www.coursera.org/learn/parprog1](https://www.coursera.org/learn/parprog1)) - among other things, it teaches to use mutable data structures when necessary. Also, make sure to work through the red book ([https://www.manning.com/books/functional-programming-in-scala](https://www.manning.com/books/functional-programming-in-scala)) - it handles the immutability and purity questions with elegance.
Have you given any thought to integration with Ammonite?
Agreed! Definitely a nice approach. 
Puppet is surprisingly FP in it's core design: you construct an immutable graph of objects derived from "classes" that the runtime then interprets. In most cases you use/write idempotent actions rather than one-shots. Puppet has also been largely dismissed, ignored, or shunned in favor of frameworks like Ansible or Chef, both of which are much more imperative in their mindset. And both have found themselves with more adoption than Puppet for, I think, precisely that reason. Now personally I like puppet, despite it's strange relationship with ruby. But I've also worked with Puppet enough to understand why folks in IT or OPS would choose not to use it. For even simple tasks Puppet asks someone to think in completely new terms, which isn't really acceptable when on average you make few changes to your CM scripts. Suddenly every change becomes a slog as you try to shift mindset and reason through what will happen. When typically trivial actions, like copying a file, become a major slog then even a reasonable tool becomes a hindrance. 
I was thinking about this idea but never took time to look into this. This would definitely make sense. Couple of things that might block us are things like executing a shell script into another container. I'm not sure how we can make Ammonite do that. This needs investigation.
I think the same content is also available through Coursera thought I mention in case useful: [https://www.coursera.org/specializations/algorithms](https://www.coursera.org/specializations/algorithms)
You can have ops install Varnish in front of your web service with TTL of X seconds. 
I like this solution. And provided he has several nodes, he can also have a local cache in each node. But I'm not sure if he needs that level of granularity in his cache. 
Intellij Community Edition (free) integrates well with SBT. You'll get incremental compilation by default, and it will spin up a persistent SBT instance which means you pay the startup cost only once. It also has a ton of features which, in my opinion, will help you learn Scala better and faster. For example, the ability to infer the type of anything that is a valid expression really helps when you start writing in a functional style.
Try jsoniter-scala instead. It is designed for safety and high performance. Also it is handy in derivation of codecs for standard cases, while has ability to use custom user defined codecs. Here are results of benchmarks which compare it with other JSON libraries for Scala: http://jmh.morethan.io/?source=https://plokhotnyuk.github.io/jsoniter-scala/jdk8.json Moreover if there are no lot of fractional numbers it can compete on par with the best binary serializers for Java and Scala: https://github.com/dkomanov/scala-serialization/pull/8
I would use Play to handle most of the web backend stuff that's needed. Create a SPA with Javascript that deals with the views. For anything processing related, you have akka built in. 
Oh that's interesting. I have been writing everything in a directory and running it off cmd. The thinking being that I'll get a good idea of the structure of how it works. But will definitely try it the other way and all. 
That's interesting. Will it always break or will it be an instance of working with some libraries and not with others ? Like your man above, I've fixed a number of strange errors by uninstall ing the version of sbt I am using. Which is nuking the problem - if what your saying is the reason for the erratic errors :D
Interesting. I don't know too much about Puppet but I know Ruby. Ruby claims to have functional support with operations like map and the concept of blocks, procs, and lambdas (still to this day I have to look up what each really is if I'm curious). But Ruby as a langauge never pressed much further than that into FP territory. It is still very much OO and the communities show. FP design is different, absolutely, but I feel that if the design of Puppet becomes a slog to deal with simple things that is the mistake of Puppet, and not FP. I'll have to look into Puppet's design more and see if my theory holds up, however. I've been thinking about this kinda thing a lot lately.
I always wished I could build binarys out of ammonite. If you could do that it would be awesome to just scp a file and you're in business. Otherwise a proper daemon would be required I think.
Awesome!
Wow this looks really amazing! 
I think it is still a bit limited, cause at the end you are at the jvm, so on the edge of your code type will probably have to be erased, but "inside" can be specialized, but maybe i am (hopefully) wrong. I am referring to the array example: ```scala abstract class MathLib[N : Numeric] { def dotProduct(xs: Array[N], ys: Array[N]): N } object MathLib { transparent def apply[N](implicit n: Numeric[N]) = new MathLib[N] { import n._ def dotProduct(xs: Array[N], ys: Array[N]): N = { require(xs.length == ys.length) var i = 0 var s: N = n.zero while (i &lt; xs.length) { s = s + xs(i) * ys(i) i += 1 } s } } } ``` If this class should work as usual `dotProduct` has to be regular virtual method, so i cannot think of a way to avoid erasure here.
Elasticache if on AWS but yeah, principle of least power. 
I was very pleasantly surprised when I joined and I could keep my whole Scala stack from academia. Its hard to say absolutely how much microsoft uses Scala vs the C stack though a lot more has been moving to Java, Scala, Python, and R. Especially in teams that use / work on Machine learning applications. A lot of internal teams use Spark though so its safe to say its permeated a good bit of the company at this point!
Keeping with my initial example a very crude approach could be to use a transparent function to return `Option[String]` then just pattern match on the String outside the transparent function.
Have you used elasticache on aws yet? Just curious, I recently had a project where we were considering it but we went with aurora postgresql instead. Easy to use/manage?
It looks like it! Did you catch this part a bit further down? transparent def toInt[N &lt;: Nat]: Int = anyValue[N] match { case _: Z =&gt; 0 case _: S[n] =&gt; toInt[n] + 1 } here, in the case that the value being matched is a `S[N]` for some `N`, that type is being bound to the type identifier `n`
I've used ElastiCache for Redis but only for volatile data and some pub/sub event stuff surrounding it. Worked well for our use cases.
no one is bothered by the similarity of transparent and inline? 
Inline was renamed to transparent, AFAIK. 
I don't think transparent functions solve that, as `Option[String]` would still be erased to `Option[_]` at runtime, so you can't pattern match on the type parameter, as usual.
Ok I figured out how to integrate with the \`workDir\` of Orkestra. All we need to do is: val wd = Path(workDir.path)/'ops/'target/"scala-2.11"/"test-classes"/'example2
If anyone is interested in following the development of this fast-moving document, the conversation around it appears to largely begin here: https://github.com/lampepfl/dotty/pull/4616#issuecomment-402703134 There's a bunch of background further up in that thread and spread across several older issues and PRs. The link above is for the discussion of the design introduced in the document.
I've used zinc in maven and gradle for a while. I didn't find it reliable enough (not a zinc issue per se: incremental compilation in SBT has the same issues), since most of the time when I use a command line build it's for a release. In my normal edit-compile-test cycle I use my IDE which has its own incremental compilation.
It is boilerplate. Usually you would have more than one persisted model, and this approach doubles the number of types you need to define and likely requires you to manage some kind of transormation code from X to PersistedX for each. You could just do case class Persisted[A](id: Long, data: A) And now you can model Persisted[Customer] or any other persisted type you need.
Thank you! Thats actually a good idea wrapping an entity in a persistence context...
Yeah I have used this approach before for adding fields to an existing modem, but it is unsatisfying in that it's not scalable. If you have to attach three new fields to a model, you have to have a highly nested structure like Persisted [Timestamped [WithAddress[User]]] and not to mention, that you have to arbitrarily decide which order the layers nest in and keep that consistent everywhere unless you want to add a lot of implicit conversions. 
There are a few things here. First, an even more FP idomatic approach is, to not use inheritance but typeclasses. Like `trait Customer[A] { ... }` (with some syntax from an implicit class) and make your application then use it like `doSth[C: Customer](customer: C)`. If you have complete control over the code all the time, then inheritance is also okay. Second, use different case classes for different things. That is, in your application, you have some csv serialized form of a customer? Well that's a `case class CsvPeristedCustomer(...)` to me, probably with csv formats automatically derived from this class. Later there might be a `case class JsonTransmittedCustomer(...)` or something like that, with json format generated from e.g. circe. And then, you have a Customer how you business people see it like. This is your domain model your use within your whole application. On the boundaries of your application you convert all the json/csv/whatever things into your domain model customer and your are done. Some for requests, responses and literally everthing else which is about input/output. Your domainmodel should never change because there was a new output/input format added. And third, you might want to take a look into how you can model multiple views on one customer from a domain perspective - that means we are now talking only about the domain model customer, no input/output/csv/json stuff. So, from your business view you still have customers in a context where they can be identified with an id. And you have them in a context where they don't have an id. You can give it two different names, but chances are high that, semantically, they are both the same entity and just one of them has an additional information (in this case the id). How to model this? /u/tpolecat has held a great talk about that. I think it was this one: https://www.youtube.com/watch?v=7xSfLPD6tiQ I really recommend to watch this. You will very likely stumble across the problems addressed in this talk in almost every application. 
But at runtime you would already know `Option[_]` would be a `Option[String]` as you ensured it to be so.
It doesn't scale without care. We're using quite successfully, maxed out at three layers where the middle layer is one of a sealed set of around 5 different types. It took several group discussions to get consensus and break out, but it's held up well over 2 years and substantial product growth with minimal adjustments needed. I would agree it has pitfalls insofar as it cannot be applied blindly, but careful application brings a lot of advantages (we used it to ditch a bunch of generic code that relied on shapeless and absolutely killed our compile times.)
[Un]fortunately no, since that operates only on compile time.
GraalVM should solve your issue no?
It might be possible with graal to build a program that consumes the class files but I donâ€™t know if you could go directly from ammonite to graal...that would really help me replace all of my local scripts
You could also consider to use an ID generated by the *client*; or a [mixture](http://blog.ploeh.dk/2014/08/11/cqs-versus-server-generated-ids/) of this approach.
Can I ask where you work? Seems like you guys adopt a great approach to this kind of problem solving.
Inventory management is a near perfect use case for akka cluster sharding. Each SKU is a persistent actor and only gets loaded when an event hits. You can use Lagom to manage the CQRS and clustering for you and that will help with ordering of events and the eventual consistency issues as well, which is important in inventory.
Although I've only used akka sparingly, having one actor per item in a warehouse seems very strange to me. If that is a clean way to model the problem, I'd love to see some example code.
That is fine, altough I would use akka typed with akka persistence. You can either using akka cluster or stop irrelevant actors with a timer.
Happy to hear this kind of approach validated, since I've used it on a smaller scale. I'm curious what kind of information typically goes in that tightly controlled middle layer. Care to provide an example?
For us it's things like bookkeeping and multi-tenancy. Anything that is _nearly_ ubiquitous across the data that flows through your system. We put things that are completely ubiquitous on the outermost layer, nearly ubiquitous (with some degree of variance) on the middle, and unique per data type on the innermost. With some effort and consideration, we found we were able to effectively model the vast majority of our cases with a reasonably small set of types for the middle layer, and provided an escape-hatch for the very few cases that just don't fit at all (placeholder in middle layer, everything goes to inner.) Common behaviors that interact with the middle tiers are typically implemented using typeclasses.
Interesting. Should you ever feel tempted to write a blog post about this, don't forget to post it here, I'd be very interested in seeing a concrete example. Thanks for the explanation.
write a scala macro that tells whether a piece of code has an infinite loop
I'm not sure which one is more desperate â€“ finding a solution to the halting problem, or writing a good Scala macro /s
What is your favourite feature about scala? What is your least favourite feature? What things do you think they should remove from the language? What do you think they should add? This tells me a lot about what they value, and how they write code. It also tells me a bit how there depth of knowledge on various parts of the language, and often leads to good followup discussions. 
I like asking them to write a function which simply reverses a List. The function should not use loops nor the built-in â€˜.reverseâ€™. Iâ€™m basically looking for a recursive solution without saying it explicitly. That may sound simplistic but youâ€™d be surprised how many candidates fail at it.
I get that we would load an actor when an event hits, but when should the actor stop? Immediately after processing the event? Assume we're not using akka cluster, for simplicity sake. 
Your best bet is shutting down the actor after some period of inactivity
In that case, if we do run multiple instances, we risk multiple actors representing the same item, each actor having different states right? 
Thatâ€™s downright malicious if not cruel. Youâ€™re kidding right?
I think recursion and linked lists should be the basis for all Scala interviews.
Here's my favorite first question to determine a candidate's approach to Scala: Given a list of tuples `(A, B)`, return a `Map[A, List[B]]`. I don't proscribe any philosophy nor forbid any use of standard library - if they know to do it with `list.groupBy(_._1).mapValues(_.map(_._2))` so much the better. But if they do it in a Java way, with a mutable hash map collecting the results, it opens a conversation. The way they've done it is perfectly practical and will totally work, so I don't count it against them at all. But I ask if they can do it without mutating, even though it will be less efficient in all likelihood. It's a great way to see how people think without giving them a stupid "gotcha" algorithm test. And it's really surprising how many candidates spend the whole hour thrashing on the original question, no matter how much you engage or how much you try to nudge them. Side note: I try to avoid whiteboarding coding questions. So these people are working in an IDE with completion and access to Google if they don't assume it's off the table. Even so, most candidates either get it within 5 minutes or sounds the whole hour struggling.
If you create an actor every time you get a request yes, but ideally you would look up a running one first and only start a new one if there isn't one already. I definitely agree with /u/amazedballer on the Lagom recommendation. It manages all of that for you (on a single node or across a cluster)
&gt; Given a list of tuples (A, B), return a Map[A, List[B]] That sounds like a great template for asking Scala or FP questions: * It has only two `degrees of flexibility` (made-up term) being `groupBy` and `_.map(_._2)`. Candidates can sometimes lock up on easy questions, because their anxiety and stress is high, people are looking over their shoulder and judging them, and all of that stress means they currently only have the head-space to handle 2-3 things in their head at once. * Given it's a small question, you can ask them more small questions that could also be solved quickly.
If someone asked me that question, I would actually call them out: 1) "I have a question: How often do you write Scala macros here? What do you use them for?" 2) "Are you aware that the people who work on Scala want to eliminate macros?" 3) "I mean this as a genuine question: Do you actually want me to write that macro? Or was this some sort of test to see if I pay attention to the Scala community?" If it was merely a deceptive test, I would find that insulting and cruel. If they genuinely wanted macros, I'd be worried their code is a mess.
"If you were going to do &lt;recent major project listed on resume&gt; again, what would you do differently?" In 15-or-so years of interviewing, I've found the interview questions with the least predictive power are the algorithmic ones, and the most useful ones are where you tease out what the candidate _actually accomplished_ in previous jobs, and what they learned in the process.
Haven't seen udash before. I might give it a try. Seems interesting. Although I don't like the API in one regard at least already: ``` div( TextInput.debounced(input, placeholder := "Type a number and press enter...", width := 270 )( onkeyup := { (ev: KeyboardEvent) =&gt; if (ev.keyCode == ext.KeyCode.Enter) parseInput() } ) ) ``` The options for everything like `placeholder := "Type a number and press enter..."` are just not very discoverable. If it were actual named parameters the IDE could help you out with auto completion but like this you have help and don't know what you can actually pass.
Agreed. If they're trying to hire someone to work on scala compiler internals or something like that... ok, maybe that's sorta valid to ask? Maybe? (I mean, ignoring the fact that they've just hilariously asked you to solve the halting problem.) Otherwise I would run away, fast. They either are ok with having some really questionable code in their stack, or they think it's cute to ask unreasonable interview questions that have nothing to do with the job at hand or your ability to do it.
NB: mapValues returns a view. In Scala &lt;= 2.12 the return type is a `Map[K, V]` despite being a view in reality. In 2.13, the signature is corrected with `MapView[K, V]`. Therefore, what you really want to do is: `list.groupBy(_._1).mapValues(_.map(_._2)).toMap` to force the evaluation of the collection. In both 2.12 and 2.13 this will return a strict `Map[K, V]` as expected.
Fun fact, in 2.13, you might have to update your question :). They are adding list.groupMap(_._1)(_._2) which returns a Map[A,Seq[B]].
Tysvm! That was excellent! From each different perspective I can learn and understand FP terms like Monad as they are practically and pragmatically applied. And that helps me grok and integrate FP even more effectively! Thank you for your time investment here.
Where do you put street?
https://www.scala-lang.org/blog/2018/06/13/scala-213-collections.html#groupmap Very nice! I personally wasn't aware of that, but I'd imagine if you brought that up in an interview, it would get you bonus points. I think at some point I wrote an implicit conversion that did the same thing, which would also be a good interview topic.
Language discussion is super important I think. This is a great approach.
In our field experience is worth it's weight in gold. But I still find it important to get a sense of a candidate's readiness to jump into my code. This line of questioning plus talking about language design and features seems to crack that open for me.
&gt; In that case, if we do run multiple instances, we risk multiple actors representing the same item, each actor having different states right? Right, that's what [Akka Cluster Sharding](https://doc.akka.io/docs/akka/2.5/cluster-sharding.html) does for you -- if you run multiple instances, it'll route to the same actor through the cluster, and it will passivate (shutdown) the actor for you after some amount of inactivity.
Not a favorite, just something we ask during phone screening interviews: What is a for comprehension in Scala? Looking to hear that it is syntax sugar over flatMap, etc, and that the interviewee understands how it differs from a for loop. 
I always like to question about the most appropriated data structure for a given problem. It's somehow a easy question, but important on efficient code, and a good filter for candidates. I also like to know if the candidate can understand the potential for code reuse with higher order functions. 
Interviews like these often show how the candidate has matured based on the projects (s)he has worked on. I find that interviews like these are more dead-on on determining if someone can really code, and think like an architect. Questions like these are a sign that the person actually knows _how_ to interview. Asking someone to code something in front of you is often a waste of time. Do you want to ask a nervous developer how to write an algorithm from the top of their head, or do you want to ask a nervous developer about the things they're most proud of? Nervous developers often fail in the heat of the conversation: 10 sets of eyes on them. It's like a CEO sitting in the room asking someone to explain - and fix - why something is broken. Right now. With them staring you down. LEAST favorite question: anyone who asks "how would you traverse a list of X items" with a 40 year old developer staring at them needs to be given a reality check. Last time I was asked that, I said "are you serious?" Most favorite questions: the questions I like answering are questions that deal with problems that the developers are _currently_ struggling with. If you can solve a problem that they have an issue with - by talking it out - they can often hear how you think about a problem, and most importantly, how you might approach a solution. Often times, when I approach an interview, I ask the developer to share a project (on GitHub) that they are working on - outside of work - that they're most proud of. You'll be amazed at what you come across.
Fun anecdote: Once upon a time when I was a lot worse at interviewing, the company I worked for acquired a small team (2-3 people) who had built a popular third-party add-on for our product. As a formality, I was asked to give their principal developer our old "general knowledge and algorithms" standard tech interview. They failed. The weird part is that it still took me a years to internalise that "person who built software that made us a ridiculous amount of money failed the coding test" was a fault with the test (and how I was delivering it), not the person.
By the time someone is sitting in front of me I already know they can write a program. We can establish this by looking at OSS contributions, by asking for a code sample, by giving a *small* homework problem, etc. So then we can talk about the code they wrote, consider alternatives, etc., and just kind of chat about programming for an hour. I try really hard to make it relaxed and fun because by far the most important thing to learn is whether we want to work together or not. I realize this is probably not a helpful answer but I'm honestly disgusted by the ritualized hazing that we call "interviewing" in this industry.
Itâ€™s really a rushed process with almost no proper feedback cycle. I like that you try to find out as much about the candidate before your conversation. I feel thatâ€™s very important but a github profile doesnâ€™t do somebodyâ€™s knowledge base justice. Some personality types OSS just doesnâ€™t mesh with OSS. But in a more connected work environment they can thrive. So much more to a person and how they will work with you than how they write their code.
Can someone tell me how good the compilation performance is compared to 2.x?
I will be using this thanks
It's about on par with Scala 2.12, though I've just opened a [PR to add parallelism](https://github.com/lampepfl/dotty/pull/4767) with some promising results. It's also worth noting that both Scala 2 and Dotty benefit greatly from being run using [GraalVM](https://github.com/lampepfl/dotty/pull/4767), especially the Enterprise Edition (cold compilation is slower with Graal, but hot compilation is up to 40% faster).
Thanks for the kind words and happy you found the post useful :)
I'm that asshole that goes against the grain and uses an ML / C# like package naming convention, and only uses com.xxx.xxx for the releases in sbt, honestly Java has pretty much shut everybody up, with most of their grievances towards it, but it's packaging system will be the ugly thing that remains for eternity. 
Is akka typed production ready? Last time I checked their site they said the api is still changing too frequently.
We ask a similar question in front end (I.e. JavaScript) interview. If it's going particularly well we may ask them to implement left-pad. Anyone following the community gives us a lol and a discussion about what's wrong with js package management. It's never a strike against you if you miss it, but for the ones who are getting an offer and moving on to close, it's a fun transition to the "see we have a sense of humor and it would be fun to work here" phase. 
I think HOF is a great focus area for asking FP questions. If you're doing FP on your projects you definitely need to establish this area of knowledge.
[Only minor API changes are expected, and Lightbend thinks it is stable enough to start development](https://akka.io/blog/news/2018/02/23/akka-2.5.10-released) I've started a project with it 4 weeks ago. The core seems quite stable &amp; complete, but the documentation is incomplete and the persistence module seems to contain a few bugs. 
Can you write an `OFormat[SaveableModel]` that decodes into the correct subclass based on the fields in the JSON?
You could use a union type: https://github.com/hmrc/play-json-union-formatter
Cool! Missed that. Thanks!
Love this approach. So much of a dev's day to day interactions with teams and others is that communication aspect. Being able to break a problem down and discuss issues/limitations/failures is not only great for teams but also show a mindfulness about their journey as a developer. If we can discuss problems together without reaching for all the buzzwords and jargon I can get a good sense of how a dev internalizes a problem domain. I feel like that is where interviews should focus and not just a code level "traverse x collection."
It's more about learning about the person and how well they communicate. Communication in any team is critical. They could be a _brilliant developer_, but you want someone who can not only communicate with the team, but also offer insight and constructive criticism. That comes from wisdom and being in the field for a longer amount of time. I'm not afraid to argue my point, or put my foot down on certain topics, if it makes sense. I'm also not afraid to call out someone who's being argumentative for argument's sake vs. being constructive. Sometimes that won't get me the job. But it will also make that arrogant person lost theirs in the process. (It's happened before.) If you want a "yes man" to your job, show them code challenges - that I promise you, they've studied for - and ask them algorithm and theory questions. If you want a _strong developer_, ask them about their achievements, what they've done in the past, what they would change, and challenge them to open a dialogue about things you're passionate about. If you are passionate about your work, and they are too, it will be a good fit.
Career wise? I don't see why not. I don't know where you're located, but most cities with a high demand for software engineers will have Scala opportunities. 35 is only ancient if you're the kind of coworker who insists on using whatever stack you got comfortable with when you started your career (which doesn't sound like you). As for if it's a good language for your taste, hard to say. Try it and find out. My pointer would be to nail down the basic (classes, objects, inheritance, pattern matching, etc) Scala equivalents to the C# concepts you already know before diving into the standard library (it's big, and the collections library can be intimidating if you're not already familiar with type classes).
By reading your post above, I see that your only motivation seems to be money. Now you can make money by doing react and node. you can make money by Go and definitely with Scala. but that's a bad motivation. Find a good motivation to learn Scala. Do you find functional code more succinct and beautiful? do you hate factory of a factory of a factory. Do getter and setter methods and boiler plate code to convert an object to JSON make you angry? If yes, Scala is a good choice. if no, then you can easily get good money by doing React and Node.
I work at AWS, which uses plenty of Java and most of my peers are moving away from it and are mostly developing new projects in scala. Many of its constructs and concepts render the language very powerful and its compitabilty with java makes it very quick for it to get adopted for developing new features that depend on legacy java code. An added benefit is scala is pretty good for developing distributed applications and addresses some of the shortcomings of parallel programming in java. On a personal note, I found it to be a fun exercise learning and working with scala. 
If your primary motivation is job prospects, Scala is not the right language, realistically. There are probably 50x the opportunities in one of the really major languages like Java or Python. The majority of Scala jobs are also based around spark, so that's another thing to keep in mind. The flip side of this is that there aren't comparatively many people who know Scala, and data engineering is pretty in-demand, so if you do end up with one of those jobs they can generally pay pretty high. But it sounds like you're mainly looking for a safe bet, and that's probably not Scala at the moment, as much as I wish it were. I love the language and I use it for all of my personal projects, but the pool of companies using it is just so much smaller that it's quite hard to find one that ticks all the other boxes too.
Dude/dudess, please, I'm way older than you, and I started learning Haskell, and I'm going to try to get a project with Haskell as main language. I was way older than you when I've learned Scala, and I'm now in my first Scala project. My point is I guess, it's not too late, learn Scala, it's an awesome language, incredibly powerful, and rewarding. And I'm pretty sure it'll be used more and more in the industry, so it's worth it.
By adopting scala you are leaning in the correct direction. A strictly typed language with functional aspects will give you a good grasp of most things. Choosing a language is not a career choice, however. Your career is learning. 
Didn't knew AWS was a scala shop. How much scala is in use there ?
it's still very much a java mall, but many teams are setting up new stores in scala :) Dont think i can quantify the amount though
Here's a sampling: https://www.amazon.jobs/en/search?base_query=scala&amp;loc_query=
I'm a huge Scala fan and have been using the language for nearly a decade. I think on a technical/ecosystem level it's the best language going at the moment. I bet on Scala and it's gone very well for me, both subjectively and monetarily. But honestly I'd hesitate to jump in right now. I feel like the language has lost a lot of momentum in the long gap between 2.11 and 2.13, and the shadow of Dotty takes away air while threatening a difficult migration (and I'm scared of the effects proposal and expansion of implicit parameters, which to my mind threaten the things that make Scala great). There are more options in a similar language space, which is good but makes your choice harder - Swift, Rust, a resurgent OCaml/ReasonML - and a dirty-tricks campaign from Kotlin pushers. The cats/scalaz split in the ecosystem looks like it's here to stay, with everything on top having to go to extra effort to work with both - competition has its upsides but a lot of this particular competition is just wasted duplication of effort. There are grounds for hope: 2.13 seems like a restart of real language improvement with the collections rewrite. Perhaps Dotty will be released soon and migration will be easy. Few other languages have higher-kinded types, which give Scala a huge amount of flexibility in adopting new ideas without major language changes, and the tooling and ecosystem situation is better than most languages, for all our constant complaints that IDE support could still be better. The language remains popular and lucrative, and if anything I've seen more acceptance of older Scala developers than in other languages. But it'd be a roll of the dice. I would definitely recommend picking up an ML family language - at a minimum, doing so will make you a better programmer and broaden your repertoire of techniques. I'm not sure Scala is the best option for a first ML-family language, particularly if you don't have JVM experience already - it's a relatively messy language and has some awkward corners that exist for Java interop (these things serve the language well in a pragmatic context for writing real business code but can make it less good for learning). But there's no perfect option - F# may be cleaner but is harder to find jobs in and lacks HKT, Haskell forces you to jump in at the deep end and has limited tooling, OCaml has limited tooling and limited jobs, Rust has limited jobs and no HKT and limited tooling and is immature. So maybe Scala's as good as it gets. I feel like the whole industry is in a weird place at the moment and could go in many different directions, so there really aren't any safe options. I think Scala has the technical merit that I hope will shine through, but a reasonable person could certainly pick a language with a bigger name behind it, or stick closer to the herd, or...
I have also noticed a really significant downturn in activity in Scala over the last two or so years unfortunately. The most concerning thing to me is that it seems like very little exciting new real big open source projects (large frameworks and/or applications which would draw in users from other languages/communities) are being made in Scala these days, even projects that are squarely in Scala's domain seem to be opting for Java, Go, Python, Rust. I am really hopeful though that 2.13 and 3.0 features can blow away the competition, while removing a lot of the footguns in the language. Especially the new Typelevel Functional Programming proposal that Martin Odersky posted a few days ago looks like a huge leap forward.
Iâ€™ve been a developer for about 5 years now (primarily in java, C and C#, doing application development and creating web services). With that, Iâ€™ve been using OO paradigm and have wanted to branch my horizons toward other paradigms. Functional programming caught my attention and Scala seemed like the appropriate choice since itâ€™s similar to java syntactically. The syntax is easy enough and Iâ€™ve been able to make small applications with ease. My biggest hindrance is I donâ€™t naturally think in curried functions. I realize this is an important and powerful aspect of functional programming and I want to develop a perspective to approach problems this way when using a FP language. I would like to know what helped you develop a mindset to see problems in this style? What are good problems to go over to exercise this thinking? Is there any other advice that could aid me with this that I didnâ€™t ask for? Thank you for your time.
Currently working on a dogstatsd project in scala and I'm having some trouble really understand what is going on. I'm not exactly sure why the dogstatsd's default hostname is localhost considering it has to be sent to the datadog website. I thought maybe I am missing something and I need to run a statsd server on the localhost, but then I woudn't exactly know how to then send to datadog. Does anyone have experience with dogstatsd with scala that can help me out?
I have used statsd and datadog separately via kamon. Conventionally one often runs statsd on localhost. Reading the website I think dogstatsd is essentially a "fake statsd" that implements the statsd API but actually sends the data to datadog, so the idea is that you can run dogstatsd and then run something that would normally report to statsd and have the data go to datadog instead. Since kamon has a "direct" datadog backend I don't think it makes any sense to use it with kamon, but maybe you're using something else? What is it you're trying to achieve? You say "a dogstatsd project" but what does that actually mean?
Currently I'm just trying to send ANYTHING to datadog from something besides databricks. I have a databricks cluster running which is being monitored by datadog, but now I need to be able to use other platforms besides databricks. I'm currently trying the example dogstatsdclient code at for [https://github.com/gphat/censorinus](https://github.com/gphat/censorinus), just to see if I could send. Could I use a datadog agent running on localhost to send to datadog?
I don't think currying specifically is all that vital? I've done a lot of functional programming but I'm happy to treat currying as syntactic sugar that occasionally lets me avoid having to write out a lambda, nothing more. I'd say take it slow and look to adopt functional tools as they solve problems for you or simplify your code. That said, I'd suggest: avoid mutation, avoid (explicit/custom) control flow, avoid statements - the "programming without ifs" exercises are notionally an OO thing but I find there's a lot of similarity with functional style. Try to limit yourself to functions that are one expression of at most 3 lines - this will help get into the habit of small, simple functions that are often more reusable. One progression you might make is loop with mutable state -&gt; recursive function -&gt; `foldLeft` call -&gt; more specialised transformation e.g. `map` or `sum` - these are the cases where partially applied functions might be useful, and if you're decomposing into small functions then the thing you want to call might already be a function. When you want to do something that seems like it would be impossible to do as a plain, pure function/expression, that's when a monad might help you out. I wrote a few things in http://m50d.github.io/2017/01/23/becoming-more-functional that might be useful examples. (The way I actually learnt myself was by learning ML first, but I can't really recommend that)
&gt; Could I use a datadog agent running on localhost to send to datadog? Yes, that's the idea. Configure your datadog agent to have use_dogstatsd: yes dogstatsd_port: 8125 (or whatever port), have the datadog agent running on localhost (restart it to pick up the config change if it was already running), and then run that dogstatsdclient code - your scala program sends events to the datadog agent (pretending to be statsd, sort of) running on the same machine, and the datadog agent forwards them to datadog.
Thank you. That makes a lot more sense. 
I'm sure I could! (If I knew what you meant.) Are you saying to pass the model type in json? 
You can use shapeless records if you need to combine these structures in a flatter way, though it's a little fiddly and can slow down compilation.
Thanks once more for the help. I have been stuck trying to figure this out for a while and now I finally got the it to send and can view it on datadog! You're awesome!
If you just are interested in lots of job prospects, you should probably focus on one of the major top 5 languages (Java, Javascript, C++ Python, C#) as your primary tool. Scala is a great language and I love working in it (have been for about 5 years, remotely for companies in the Bay Area) but if you are interested in application development, it hasn't got quite enough critical mass yet. It feels to me like all the oxygen in the application development room has been sucked out by Spark and other data frameworks. I'm in my late 40s and still doing software. Just don't on the sidelines, keep learning even if it isn't something you plan on using right away. Meet other software folks (meetups, conferences or whatever) and say engaged. Good luck!
Currying in Haskell and similar languages is pervasive (all functions take exactly one argument, and higher arity is expressed with currying) and functions remain polymorphic even after partial application. This makes point-free style and combinators like `&lt;*&gt;` useful and it's a big part of the FP lifestyle. But in Scala we don't have higher-rank types (yet) so currying ends up being a minor syntactic convenience and that's about it. Sometimes it makes things read better, and you can use it to influence type inference. But it doesn't do anything fundamental in terms of the language's expressiveness so you can probably ignore it as an issue for now. Take notice when you see it and maybe ask yourself (or others, here or on https://gitter.im/scala/scala) why it's done that way, but otherwise don't sweat it. The best way to lean to think this way is to hang out with functional programmers (in real life, at conferences like the Typelevel Summits; or virtually at https://gitter.im/typelevel/cats) and work through https://www.manning.com/books/functional-programming-in-scala, which does a very good job motivating functional style. 
Where does the community look for hiring opportunities? I haven't really been able to find much that's specific to the Scala community. Maybe even somewhere mkre tailored towards the FP flavor of Scala, but that might be a lot to ask for. ðŸ¤ž
I personally don't use it. But my good friend is a vim user and developed a library to facilitate his usage of it with Scala. Hopefully it's of use to you. https://github.com/pjrt/stags/ 
There are in fact [monthly who's hiring threads](https://www.reddit.com/r/scala/search?q=Who%27s+hiring&amp;restrict_sr=on&amp;sort=relevance&amp;t=all) here. In addition, I see a lot of postings on LinkedIn, Indeed.com, as well there are more links to job boards in the "Scala Jobs" section of the sidebar. 
Thanks! Argh, too bad the sidebar is harder to access on mobile, or I probably would have seen that sooner.
Got an answer, posting here for visibility: There's a link in the sidebar As well as a monthly "Who's Hiring?" thread 
No worries. I'd also check out glassdoor, and the monthly "Who's Hiring" threads on hacker news.
Anything that speeds up scalac is worthy of an upvote
I see them on https://functionaljobs.com/ sometimes
These options come from [Scalatags](https://github.com/lihaoyi/scalatags) library. This is an example of almost raw HTML creation in the Scala code - sometimes it is useful to write it that way, it gives you more control. Take a look at [Bootstrap](https://guide.udash.io/ext/bootstrap) module, it provides Twitter Bootstrap components with a typesafe API.
Not necessarily. Perhaps the different types have differently named fields and can be distinguished that way. Itâ€™s been a while since I worked with Play so Iâ€™m a bit rusty and may have the names wrong: `OReads` has an `orElse` method that you can use to combine instances for decoding the subclasses.
Why AWS doesn't release a pure Scala SDK?
Seems to leap to a conclusion without really justifying it. I don't disagree, but if you're going to make the argument that we should use cats because it has other useful functionality, you really ought to show what that other useful functionality is.
The conclusion reached was to consider rolling your own Monads as an alternative to having to deal with nested flatMaps/Maps - this is the thrust of the post and what the conclusion was about. `Cats` was mentioned in the conclusion since if you use a library like `Cats`, then you would not even need to roll your own monad wrapper since it comes with `Monad Transformers`. But regarding providing a motivating argument regarding the other useful functionality of `Cats`? hmmm...that sounds like an idea for another blog post - which I might be writing next :)
I think this is what you're implying: https://gist.github.com/mandubian/6051831 
Tldr?
Hey man! * Hacker News threads * Threads here * Stack Overflow careers * Functional Works
I guess I'm one of those people who don't exist. I don't care for Haskell-style FP, and very much appreciate the mix of OOP and FP that Scala allows for. In my view, Scala is a very general and a remarkably unopinionated language. It efficiently encodes and integrates multiple programming paradigms in one language, letting you pick and choose what you want. Yes, you can make another Haskell-on-the-JVM language that is better suited for that specific paradigm than Scala is, but then it'd be worthless for anything else, whereas Scala is useful to a wider range of programmer preferences and skill sets. It's a feature, not a bug.
Seconded. I'm writing complex math algorithms in Scala and love being able to switch between FP-style correctness and dirty mutability tricks (yes, that includes null and arrays) under the hood. The talk is worth watching though.
Scala should focus on FP features and not OO
On a single slide :) https://imgur.com/a/0vnIjWJ
- Scala is losing interest, mind share and contributors. - Scala 3 is not the savior. - Focus on addressing issues people actually have. - Sacrifice half the community, send them to Kotlin. - Focus on having fewer, better features to make Scala a great FP language.
&gt; Haskell-style FP He did mention contributors who brought many of Haskell's tools over to Scala, but John is also a proponent of doing FP in a Scala style, instead of forever mimicking what Haskell does. The perfect example of this is his stance on Monad Transformers, or BiFunctor IO.
That's not quite the same thing being a proponent of the fusion of paradigms at once.
Correct - dirty mutability tricks are just as possible in Haskell. I imagine John's stance is one of tackling OO (subtyping in particular) and Scala's current lack of compiler-enforced Referential Transparency.
I would also ask doing dirty mutable tricks isn't OOP, it's imperative programming, and is usually at odds with functional programming because of constraints on referential transperency. OOP however is usually at odds with functional programming because of how inheritance and models type checking and method dispatching work. I think the Scala community is pretty unified in not liking uncontrolled imperative things, regardless of how they decide to utilize the type system.
* valuable contributors have left scala * features where invented without a target audience
If Scala focuses entirely on FP features I think that will be Scala's death knell. Why not then focus efforts on Frege or something designed to be FP from the ground up? Of course, if Scala becomes purely FP and doesn't innovate, it will die anyways. The number of people who think coding in monads is a good idea for any medium to large scale organization is, in my experience, very small. Like Haskellers, you may be able to work at a few organizations but you'll never be close to mainstream. I remember reading originally that when fusing OO and FP, Martin was surprised that the FP work was mostly unoriginal and most of the innovation was in the OO space with things like traits. See for instance this presentation with the quote "More innovation on the OOP side": https://www.slideshare.net/Odersky/scala-evolution I think Scala ultimately fails because it tries to tackle exceedingly hard problems, far too hard for the resources invested in the language. Oracle itself can't solve the problems Scala has directly or indirectly tackled at one point and is still in the process of investing in solving some of these problems. They include: * Specialization. Java 8 entirely punted on specialization. * Value types * full tail recursion on the JVM * Better escape analysis for functional code that wastes memory because, well, it's functional * Fibers/Continuations, or a better async programming model Scala's specialization attempt ended up being a joke. Delimited continuations were one man's research project that got abandoned after the paper was written. Scala macros, to the credit of the contributors, have had a lot of effort put into them, but they still pale compared to macros in languages designed from the ground up to have macros. Kotlin, to it's credit, doesn't really try to solve any hard problems. I don't know if kotlin will succeed either, honestly. It feels like Java is only 5 or so years behind Kotlin in features but has the advantage of stability and Oracle's backing. But Scala's approach of "reach for the stars, well, at least until you lose interest or your paper is submitted" approach doesn't seem to work either.
&gt; whereas Scala is useful to a wider range of programmer preferences and skill sets. It's a feature, not a bug Agreed. I think this idea of a messy, imperfect, Jersey-over-MIT landscape is being undervalued. Like, if the FP world and Haskell were *so great*, what is preventing Haskell from dominating the entire job space that Scala occupies today? Whatever that answer is is what's missing from people's model of comparing Scala to Haskell.
Is it a coincidence that Thanos and John are both large, muscular, bald men?
All of the with the benefit of being able to use the endless number of amazing libraries built for the JVM. I think a lot of people don't appreciate this until they leave the JVM.
Thanks for sharing! Awesome!
&gt; Why not then focus efforts on Frege or something designed to be FP from the ground up? Frege is DOA, and Eta isn't production ready yet. This was addressed in the talk that if nothing changes, Eta is going to cannibalize Scala from the FP side. &gt; See for instance this presentation with the quote "More innovation on the OOP side" That's really disingenuous to say a slide highlighting improvements of Scala over Pizza is proof that Scala as whole innovates more in the OOP side.
He talks about Scala3/Dotty and I can't help but think to Python2/3. Today, almost all new projects are started in Py3, and most of the libraries on the python3 wall of superpowers are in the green. A few years ago Django totally killed all it's py2 backwards comparability imports. At the same time, Python is a much more used language. It also took several years to get everyone on board with python3, and many academics still use python2 (as do old, closed, proprietary apps that embed Python). And let's not forget the classic failure of Perl6, which nobody migrated to. 
IMO the job space isn't jumping towards Haskell because people view it as a niche, mathematics/academically driven language (which is mostly BS), and are scared to peek inside. And still, people who learn the FP side of Scala and feel that paradigm empowering tend to eventually end up writing Haskell. Let's remind ourselves that the job space wasn't jumping on the Scala bandwagon either before Spark came along and gave it a major boost. 
The JVM already has a great FP programming language in Clojure, which is surprisingly lacking any mention in the presentation. Doing what this video suggests will torpedo Scala's popularity. At that point you may as well just send OOP to Kotlin, and FP to Clojure, then kill the language.
Clojure due to its dynamic typing is pretty much a no go for a very big part of the FP crowd.
Typed FP != FP, it brings different approaches
Yes but the "FP crowd" in this context (/r/scala) is the "Scala FP programmers" which very much prefers the typed FP over the dynamic kind. At least in my experience (almost 6 years full time Scala coding) Personally I would probably go back to Ruby if I would have to abandon Scala and have to pick a dynamically typed language (or just join the Javascript bandwagon due to its popularity).
So, GraalVM CE is crippleware? That's disappointing.
&gt;`java++ 10!` What in the world is that syntax supposed to mean?
The remarks on dotty are somewhat FUD. There's going to be tooling for moving scala 3 to scala 2 code, calling scala 3 a different language is an exhageration, and dotty aims to be binary backwards compatible with scala 2 so gradual adoption has been planned for.
So there you go. The effect of people's perceptions (regardless of their accuracy) should still be taken into account.
Everything that uses macros or scala-reflect will still need to be rewritten
The day I cannot mutate arrays in place to e.g. perform Gaussian elimination, or perform string rewriting in place, is the day I stop using Scala. The JVM is still optimized for imperative programming. But at the end of the day, the surface seen by my users is a nice referentially transparent interface. (To be fair, 99% of the bugs I introduce are in those dirty areas, -- but these areas are what make the use of Scala worthwhile).
For example, I really considered to learn Haskell. But then I found that: - there is no stable IDE with autocomplete and debugging - haskell builds are not reproducible - I had hard times building cabal/stack projects from github - there is no simple way to install ghc and invoke it directly - Haskell programmers tend to write no documentation to their functions of 2-5 characters - Haskell programmers tend to use libraries implementing some concept from some scientific paper. And all you have is concept name and no way to find original paper. Can't say it was wasted effort - many Scala libraries are largely influenced by Haskell. But I can't see Haskell itself as a production language.
\&gt; That's really disingenuous to say a slide highlighting improvements of Scala over Pizza is proof that Scala as whole innovates more in the OOP side. Nope, basically no statically-typed OO language right now comes even close to Scala's OO system expressiveness. Most languages don't even have mixins, and path-dependent types and singletons are a distant dream.
Fair enough; not sure to which degree a compat layer for old scala-reflect is achievable. I think the new meta programming stuff is pretty great and I'd be willing to bite this bullet for that. Of course, if you happen to sit on a lot of macro code, that sucks.
Also his personal bucket list seems unreal on the JVM. I find it difficult to imagine removing subtyping and exceptions in a way that does not sacrifice ease of use of interop between scala and Java code. Sure, from a purist FP POV that makes a lot of sense but it misses the mark that people do scala because they can easily pull in JVM libs.
I know, in this context is definitely typed, but is always worth remembering there are other flavours of even FP (not to mention programming paradigms). I don't think there is any reason for anybody to leave Scala, though.
This talk really resonated with me. I feel embarassed everytime I need to onboard a new development into our scala code base. The tooling, sbt, docs, type inference issues, the compile times... Ugh. 
&gt; Focus on addressing issues people actually have, instead of producing papers with academic novelties. I think /u/jdegoes is being unfair here. If producing papers is really our secret goal, then we're really terrible at achieving it ;) Look at [how many papers LAMP publishes in a year](https://lamp.epfl.ch/publications), now compares this to [how much code we write](https://github.com/lampepfl/dotty/graphs/contributors). I've personally spent a lot of time and energy working on things like Java 9+ support, sbt 1 support, better error messages, helping people out on gitter, etc, that. We do these things because we care about Scala 3 being a great tool, and not just an academic exercise.
&gt; type inference issues Do you have any in particular that you could illustrate with an example? I'm always on the lookout for ways to improve type inference in Dotty!
Hmm. I don't have any at this moment, but I'll try and come up with one. At the end of the day, my understanding is that if you want subtyping, you are always going to have type inference issues
My experience has been the opposite - that the ecosystem was mostly empty and true quality lay elsewhere.
For Haskell in 2018, these are mostly baseless memes. &gt; there is no stable IDE with autocomplete and debugging There's the [Haskell IDE Engine](https://github.com/haskell/haskell-ide-engine), but Spacemacs, vim, and VSCode (at least) have good support. In recent months, [ghcid](https://github.com/ndmitchell/ghcid) has been a game-changer that Scala has no analogue to. &gt; haskell builds are not reproducible - I had hard times building cabal/stack projects from github For example? The whole point of `stack` is for things to be reproducible. Are you on Windows? `sbt` actually has reproducibility issues: many a time a `sbt clean` did not produce a state for me where legal source would compile. I had to manually delete `target/`. &gt; there is no simple way to install ghc and invoke it directly By installing it via your system's package manager, unless you're on Windows. &gt; Haskell programmers tend to write no documentation to their functions of 2-5 characters "tend to" is strong at this point. Certainly this is true of the past, but a good number of us take good documentation seriously. See: any library written by [Gabriel Gonzales](https://hackage.haskell.org/user/GabrielGonzalez). &gt; Haskell programmers tend to use libraries implementing some concept for some scientific paper... Most libraries that are implementations of academic papers do list the source. I'd say overall though, most libraries that are in regular commercial use today (of which there are thousands) are not based on fancy papers. &gt; But I can't see Haskell itself as a production language. Many people feed their families by writing Haskell professionally in 2018.
Any sufficiently powerful type system will have type inference issues, some of these issues are fundamental but often it's just a question of engineering work. Subtyping is challenging but so are features like rank-n types in Haskell.
There's also a [gitter room](https://gitter.im/scala/job-board).
&gt; Competition for adoption comes from multiple angles: Kotlin, Java, Haskell. A couple more: Go in the "bored of Java and Python" angle, Reason in the "OCaml for Java and JavaScript developers" angle. Maybe also Rust in the performance angle. See for example Buoyant recently abandoning Scala/Finagle in favor of Rust for the next version of Linkerd: https://blog.conduit.io/2018/07/06/conduit-0-5-and-the-future/
I appreciate the great work you do, /u/gmartres, but you've got to admit that many historical features in Scala have been half-baked, abandoned, and not commercially useful; and that the constant churn in language, syntax, semantics, macros, binary compatibility, tooling quality, and IDE / editor support, all drives away contributors, users, and library authors, and impedes commercial adoption. These are all areas in which Java and Kotlin are getting things right. I personally hold out great hope for Dotty as a better Scala, but we can't yet count Dotty as being a step toward better support for the needs of industry, because Dotty represents an unfinished abandonment of Scalacâ€”i.e. *another repetition in a history of unfinished and abandoned features.* If Dotty is replaced by something else in 7 years, it will surprise no one. I know you and a number of other people have worked hard to make Scala useful and more production-ready. But historically Scala has an unfortunate history here, and I think we should learn from these mistakes to not repeat them. Instead of asking what new thing we can bolt onto the language or the standard library, maybe we should be asking: what can we **not** add to either, so that we can focus on making what's already there better and more commercially useful? The answer cannot always be that "the next XYZ" will magically make all the problems disappear and then things will be stable and smooth. Nor can it be that we need just one major change in syntax or semantics before we get things right. We need to stop doing so much so we can do better job at what we *do* have resources for. And yeah, I think that probably means less novel work and more boring work. That's the price of mainstream success.
&gt; And yeah, I think that probably means less novel work and more boring work. I'm confused, who is doing novel work that should be doing more "boring" work? The few PhD students at EPFL? That doesn't seem like a great use of resources. Everybody else is already doing as much as they can to concretely improve Scala today given their resources. Consider how much the Scala Center has already done (scastie, bloop, build server protocol, scaladex, sbt and zinc improvements, documentation, driving the SIP process, scalafix, scalafmt, new collections, sprees to get new external contributors, ...) when they only have a handful of engineers! I personally think the best way to get more done is to find way to fund the Scala Center more and encourage external contributors to invest themselves.
The funding issue was on my mind while I was watching the talk. The BigCos may very well decide to split the community by staying on Scala 2, but in the longer term that's just self-sabotageâ€“they'd be much better off investing in the Scala community by funding people to work on the language.
Not to mention Elixir from the 'let's use a real concurrent, fault-tolerant system without the limitations of the JVM' angle.
Keep in mind that referentially transparent FP is also quite possible while doing 'dirty mutation'â€“it's just that the mutations cannot be externally visible outside the called function. Everyone allows thisâ€“even Haskell has vector which you can 'thaw' and mutate, then 'freeze' to prevent mutation.
No, I don't think EPFL is the savior of Scala, as I mentioned in the keynote. But as you'll remember, Scalac has lost some pretty great contributors through disillusionment. If the process for attracting and retaining high-impact contributors improves, then we can make a difference. Personally, I'd focus more on this process, as raising money for the Scala Center will always be difficult and a short-lived solution, at best. It's a tragedy of the commons problem. A lot of individuals want the benefit, but no company wants to fund it. Scala Center has done some great work (I'm quite happy to see the effort), but how much of this work will be classified in 2 years as abandoned or still not production ready? Some of these projects are already not very healthy (numerous open tickets with no response, months since the last commit, etc.). I'm not saying any of these issues have easy answers, only that problems are apparent and we should do our best to learn from the past when trying to direct the future. We all want Scala to succeed. Yet all observable measures indicate the Spark bump is fading and that industry adoption is contracting. I know a dozen or more recognizable Scala developers who will moving on in the next few months. This is neither the time to blame those who have worked hard to get us where we are today (including you and countless others!), nor to close our eyes and pretend there are no issues. There are most definitely issues. The only question is, will we pool our collective brain power and resources together to figure out how to make the most of what we have, to give Scala the best chance of succeeding? I think it's possible but not if everyone becomes defensive or starts playing the blame game or closes their eyes and pretends everything's awesome.
It's a matter of setting sensible defaults. Here's a simplified minimal complete example of what I've seen in Akka HTTP routes: trait ToJson[A] { def apply(a: A): String } object ToJson { def apply[A](a: A)(implicit ev: ToJson[A]): String = ev(a) implicit val int: ToJson[Int] = new ToJson[Int] { override def apply(int: Int): String = int.toString } implicit def tuple2[A: ToJson, B: ToJson]: ToJson[(A, B)] = new ToJson[(A, B)] { override def apply(tuple2: (A, B)): String = s"[${ToJson(tuple2._1)}, ${ToJson(tuple2._2)}]" } } def complete[Resp: ToJson](resp: Resp): Unit = println(s"COMPLETE: ${ToJson(resp)}") complete(1, 1) // COMPLETE: [1, 1] complete(1, new Foo) // &lt;console&gt;:13: error: too many arguments (2) for method complete: (resp: Resp)(implicit evidence$3: ToJson[Resp])Unit // complete(1, new Foo) // ^ What's happening here is that Scala is implicitly adapting the caller argument list to match the receiver argument list, if everything else is fine. But if something goes wrong, like it can't find a type, it doesn't try to do that, and you're left scratching your head as to why the first one works and the second one doesn't.
The main strength of Scala is that it is a bridge to FP. I knew next to nothing about FP when I started using Scala about 7 years ago. Over time both my understanding and programming style have progressed more toward FP. But I still have a ways to go, so I'd hate to see Scala wither and die. I think people like me should be the main target audience for Scala. I suspect there are lots of OO programmers who would like to learn FP. And not necessarily all at once by moving to Haskell. Another thing with the potential to greatly expand the Scala base is Scalajs. At some point webasm is going to be a viable target for a number of languages, and there are huge numbers of JavaScript programmers who have known nothing but JavaScript. So once again, Scalajs could be their bridge to a "real" programming language. The Scala community should make it a priority to court JavaScript programmers with Scalajs. I don't have any experience with Scala Native, but it sounds like it also has the potential to greatly expand the reach of Scala. From my point of view, the problems with Scala are what they've always been: tooling, documentation, and library standardization. Yes, tooling and documentation have improved a great deal since I started, but tooling in particular still is lacking. By "library standardization" I mean the problem of multiple libraries for any particular area of functionality, be it FP or HTTP or database, or any number of things. The community really needs to get better at making libraries which have the mantle of "standard". That doesn't rule out people experimenting with alternative libraries, but the focus should be on making standard libraries better. So I say, let Scala be Scala. 
I think the argument adopting (auto tupling in this case) is one of the bigger mistakes in scala. Thankfully it is easy to disable by giving scalac the -Yno-adapted-args flag. Though I think they should just remove the feature and give a rewrite to fix the codebases.
I think this is a very good point. When I started with Scala I didn't know much about FP either, but now I love writing code in a more functional approach. One thing that I really loved about Scala is that I did not need to know Functional Programming to get started, but somehow I was using all those FP features and taking their benefits already. Having said that, when I look at the code written by Java developers who moved to Scala, it's very disappointing. I think we should continue focusing on things that help make Scala implicitly functional so the transition is smooth, but also forces you to not make bad decisions. I know how difficult that sounds, but there is work being done in the community that already helps us in that area, and I think we should keep heading in that direction.
&gt;es macros Macros are experimental feature.
**Very important factor for scala is to bring tools that can convert OOPs code into functional code for debugging and learning e.t.c. That way new breed of OOPs guys from JAVA world can pick up scala and start maturing into Functional prototyping.** Currently due to time constraint with projects and lack of senior flocks in industry that appreciation is lacking. Put effort in above words your future self will give me gold .
 !remindme 1 days 
I will be messaging you on [**2018-07-12 08:27:42 UTC**](http://www.wolframalpha.com/input/?i=2018-07-12 08:27:42 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/scala/comments/8xrgnr/live_coding_session_on_refactoring_procedural/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/scala/comments/8xrgnr/live_coding_session_on_refactoring_procedural/]%0A%0ARemindMe! 1 days ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Will this be recorded so people can watch later if they don't have time to watch it live etc?
&gt; If the process for attracting and retaining high-impact contributors improves, then we can make a difference. Propose ways how to improve it, please. Everyone would be happier if contributors stay. &gt; Personally, I'd focus more on this process, as raising money for the Scala Center will always be difficult and a short-lived solution, at best. Are you suggesting that a community of developers can do better than a focused set of engineers with funding working full-time on the language? All your examples of "successful" languages like Rust and Go and Kotlin have huge financial backing and way too many engineers working on them (I think that only Kotlin Native engineers outnumber Scala Native engineers by more than 20x, and yet the latter is considerably better). All these examples suggest that an organization with money and people is required for its evolution. Donating money to the Scala Center is something you should be encouraging if you want more people to work on the problems that you have pointed out, because our major problem is not identifying the problems, mind you, but the lack of resources. &gt; Scala Center has done some great work (I'm quite happy to see the effort), but how much of this work will be classified in 2 years as abandoned or still not production ready? Some of these projects are already not very healthy (numerous open tickets with no response, months since the last commit, etc.). All our tooling effort is been done to support both Scala 2 and Scala 3. In fact, we're the ones pushing for ways we can improve the life of all Scala developers now. Just have a look at the blog posts in https://scala-lang.org. &gt; Some of these projects are already not very healthy (numerous open tickets with no response, months since the last commit, etc.). The only projects that are not currently worked on are Scastie and Scaladex because we're all focusing on tooling. To remind you what we do, in case you haven't kept up with it: - Major contributions to Scalameta and Semanticdb (Olaf collaborating with Twitter) - Scalafix, a refactoring and linking tool - Bloop, a build-tool-agnostic compile/test server - BSP, a build server protocol to improve the Scala IDE integrations for people that don't use IntelliJ but only editors like vim or Sublime or viscose - Zinc, major contributions and improvements to the incremental compiler - scalac-profiling, a tool to help people profile compiler inefficiencies and fix them - Scalac, contributions mainly in the area of performance and build tool support Saying that we're not working on tooling is disingenuous at best. &gt; We all want Scala to succeed. Yet all observable measures indicate the Spark bump is fading and that industry adoption is contracting. Can you please point to "these observable measures"? You keep claiming Kotlin is gaining more adoption than Scala. Well, Google [trends disagrees heavily with you](https://trends.google.com/trends/explore?geo=US&amp;q=%2Fm%2F091hdj,%2Fm%2F0_lcrx4,%2Fm%2F0dsbpg6). TIOBE 2018 [too](https://www.tiobe.com/tiobe-index/). Sure, no metric is perfect, but at least these are conventional sources to measure adoption of programming languages. &gt; The only question is, will we pool our collective brain power and resources together to figure out how to make the most of what we have, to give Scala the best chance of succeeding? Oh, I think it's possible too. Do you know what we need? More proposals, backed up by experiments and prototypes, not only words, to assess how we can improve Scala as it is today. Miles Sabin, seriously involved in pure FP in Scala, has been really successful at getting many language features merged into the core language at a time where most people thought it wouldn't happen. I have not yet seen a serious proposal coming from the Scalaz community that doesn't ask for impossible things like "remove sub typing from the language". I would be happy to be proved otherwise.
&gt; There's the Haskell IDE Engine, but Spacemacs, vim, and VSCode (at least) have good support. In recent months, ghcid has been a game-changer that Scala has no analogue to. Not true, Ensime is. &gt; For example? The whole point of stack is for things to be reproducible. Are you on Windows? sbt actually has reproducibility issues: many a time a sbt clean did not produce a state for me where legal source would compile. I had to manually delete target/. If you want reproducibility, no matter in what language, you use something like Bazel, Pants or Buck. Stack doesn't cut it. 
I agree with you. Scala 3 is not a different programming language because the fundamentals are the same. On top of that, all features, removals and additions will be reviewed by the Scala Improvement Process Committee (SIP Committee) in a rigorous review process. A new compiler is not a new language. An example of this is the C++ community where both Clang and gcc are mainstream compilers, and the former was developed much more later than gcc. 
If you're having problems with compile times, make sure you're not misusing implicit and macro expansions: https://scala-lang.org/blog/2018/06/04/scalac-profiling.html If you're having problems with sbt, use another build tool. There are many at your disposal.
&gt; But as you'll remember, Scalac has lost some pretty great contributors through disillusionment. If the process for attracting and retaining high-impact contributors improves, then we can make a difference. OK, so how would you improve the process concretely? (As an aside, it's true that I wish some people didn't leave, but some turnover is inevitable in any project, it's natural for people to want to move on at some point, you can compare https://github.com/scala/scala/graphs/contributors with https://github.com/rust-lang/rust/graphs/contributors or any number of other projects and see similar patterns).
Thanks, that profiling link was helpful
Yes, auto-tupling is confusing, which is why there are plans to get rid of it (not fully worked out yet): https://github.com/lampepfl/dotty/pull/4311
Will I be able to pass `Nil` in folds in Dotty?
&gt; For example? The whole point of stack is for things to be reproducible. Are you on Windows? sbt actually has reproducibility issues: many a time a sbt clean did not produce a state for me where legal source would compile. I had to manually delete target/. Stack honestly is a terrible solution, its only reproducible because it creates a frozen snapshot of dependencies, which means you are kinda stuck if you need to upgrade any of your dependencies outside of the snapshot. &gt; "tend to" is strong at this point. Certainly this is true of the past, but a good number of us take good documentation seriously. See: any library written by Gabriel Gonzales. Noting exceptions isn't really proving your point, if you read documentation for any general purpose library in Python, Ruby or Java vs Haskell the difference is really night and day, there isn't a comparison &gt; Many people feed their families by writing Haskell professionally in 2018. Sure, same is true of COBOL, PHP and Visual Basic, not sure what you mean by this statement 
I've also always been frustrated that this doesn't work since I first learned Scala :). I've been thinking about it again recently and there's some stuff I want to experiment with that may make this finally work, but no promise, it's tricky. On the other hand, there's a lot of situations where Dotty does a better job at type inference with lambdas than Scala 2, I gave a talk two years ago that goes into details: https://www.youtube.com/watch?v=YIQjfCKDR5A
&gt; Miles Sabin, seriously involved in pure FP in Scala, has been really successful at getting many language features merged into the core language at a time where most people thought it wouldn't happen. I have not yet seen a serious proposal coming from the Scalaz community that doesn't ask for impossible things like "remove sub typing from the language". I would be happy to be proved otherwise, and for this trend to change, of course. This point is really sticking out as a sore thumb. Regardless of where on th FP/OOP/Imperative spectrum you land, if you want and you are willing to be realistic/intellectually honest/communicative, you can make improvements to scalac.
&gt;There's the Haskell IDE Engine, but Spacemacs, vim, and VSCode (at least) have good support. In recent months, ghcid has been a game-changer that Scala has no analogue to. It's very bare and unstable. They still haven't fixed the bug when hitting Undo in VSCode causes desync between code in the editor and code that HIE tries to compile, so I basically have to hit `Reload Window` every 5 minutes. Barring that, it's missing crucial features available in competitors (such as purs-ide): Go To Definition to a third-party library source code, renaming/refactoring (at least it doesn't work for me), **auto importing**, type-aware auto-completion - How I wish I could write `&amp;` and get the same auto-completion as for Scala's `.` \- all the functions applicable, listing all type class instances for a type, etc. &gt;Many people feed their families by writing Haskell professionally in 2018. There are more people doing the same in Perl. There's even a [commercial IDE](https://twitter.com/Edument/status/1002535468091748352) just released for fucking Perl6, a dead-on-arrival language by all accounts, yet somehow more popular than Haskell!
Yet almost every single project depends on macros through transitive dependencies. They're almost entirely unavoidable, unfortunately. You might say: "Why do I care? My dependencies will fix that!"... but it's looking like not all use cases of the Scala 2.x have any equivalent in 3.x macros (whatever they'll end up being).
C++ has an actual standard.
Thanks, I'll take a look! Also, good luck :)
A shared screen feels like a much more realistic programming environment than a whiteboard, so I'm happy about that, though less happy if I'm obliged to solve a problem without a proper IDE. Some people seem to worry about whether things like looking up APIs will make them look bad which I frankly don't understand. The way I see it I'm confident in the skills I have and if your interview process doesn't help you figure out whether I have the abilities you need then that's a problem with your process. Looking up the API is what I'd do for a real programming task, you bet it's going to be what I do in an interview situation. I haven't rote-memorised a bunch of APIs and frankly I'd be suspicious of a programmer who did. Other people seem to have a chip on their shoulder about being asked to do basic coding exercises which I also don't understand. Of course an employer wants to check that I can actually write programs. I'd be wary of an employer that didn't check that.
Scala has an specification too, maybe not as precise as the C++ one, but a specification notwithstanding. The SIP Committee will review Scala 3 changes to include them in the specification of the to-be Scala 3.
Which ecosystem has more (and equal or better quality) libraries than the JVM?
Last I heard it was so imprecise as to be useless, but maybe things have changed.
## **SeamlessDocs** | Software Engineer (Backend) | New York City (SoHo) | *$120k-$165k* | Onsite ### We fundamentally believe that government is beautiful. Too often we hear the opposite angle, but we really do believe in the power of a well-run, well-designed, well-meaning government. One that exists in the physical world, but embraces the digital one too. That, to us, is a truly beautiful thing. We are committed to debunking the myth that interacting with government has to be an experience citizens dread. We are working to spread our vision that government can, and should be beautiful. As it deserves to be. ### What it's like working with the Engineering team - **SeamlessDocs &lt;3 FP.** We make liberal but pragmatic use of many FP concepts and are no strangers to pushing on the type-system. We'd be happy to talk your ear off about math and would be very interested to hear what ideas you have to bring to the table. - **Learning is front-and-center.** We participate in weekly code golf exercises to play with new techniques and sharpen our skills. We engage in weekly company wide learning sessions where someone gets to share an idea or learning they think is worth sharing. - **Well fed and hydrated (and optionally caffeinated).** We've got some of the best food spots probably in the whole world right in our back yard. Catered lunches are supplied daily. Fridges and pantries are stocked. - **Flexibility to work how you need.** Unlimited vacation and flexible scheduling. Core hours are between 11:30am and 4:30pm. ### Our Tech - Scala with a lot of FP niceness - Kubernetes for manageable deployments and infrastructure - Flow-typed React on the front-end - Some* (actually not that bad) legacy PHP ###Finding out more - **Apply here:** https://grnh.se/df7b17b32 - **Contact:** `talent@seamlessdocs.com` - **About:** https://www.seamlessdocs.com/about 
Haskell, certainly. It's been my experience that Scala has orders-of-magnitude fewer actively maintained, documented libraries. As for Java deps - well, you've got the Java Wall to think about. `null`s and Exceptions lurking around every corner. I personally want a language where I don't have to constantly account for those things. If there is some trove of amazing JVM libraries laying around that solve everyone's problems, I'm willing to have my mind changed. I'll admit I did enjoy `joda-time` back in the day.
Hi there i joined a team, they often (mostly) use sync scala and sometimes Future. The team is very much open for improvements. I think to start using monix.Task could be one big improvement, but i am not sure how to explain the benefits and not confuse them. I started to work on some presentation but its too abstract. Any ideas or old presentations? The typical effect in our project is db read/write.
I agree that `purs-ide` is fantastic, might be best-in-class. As for the general JVM problem of "knowing what's available" (thus needing top-notch auto-complete), I find a repl session or Hoogle call sufficient. &gt; Are you even serious? Completely. Red squigglies in any editor aren't equivalent to a fast typechecker cycler. That's what `ghcid` is and sbt's `~compile` isn't. Ensime is in a similar situation where it has to constantly be recompiling all your code in the background.
&gt; Not true, Ensime is. Ensime has to recompile your code constantly in the background, while `ghcid` does not. The typechecking feedback cycle is much faster. Also, Ensime isn't maintained and will break completely with Scala 3 (Sam is happy about neither of those things). &gt; If you want reproducibility... Can you name a repo where the given stack configuration didn't work for you?
Thanks, everyone I managed to find [this month's monthly hiring thread](https://www.reddit.com/r/scala/comments/8vi5nq/who_is_hiring_monthly_rscala_job_postings_thread/) as well!
The current Scala standard is: "Any compiler which compiles the set of programs acceptable by the current Scala compiler."
&gt; I have not yet seen a serious proposal coming from the Scalaz community Luca's alternate typeclass proposal being rejected by Martin was a bit of a slap in the face. 
I could potentially see some benefit in having something similar to @tailrec, except intended for pure functions and/or referential transparency. If you consider `var` and `val` you might also imagine there also being `def` vs `...` (not sure what name to use).
&gt; As for the general JVM problem of "knowing what's available" (thus needing top-notch auto-complete), I find a repl session or Hoogle call sufficient. It's not a 'JVM problem'. IMO it's much more visible problem in Haskell - i.e. * after you add a package, you have to go read haddocks to see what modules you have... * Ok, you imported a module, now you have to go search haddocks, what symbols you have now... * Ok, if you used HIE's autocomplete and discovered some new data type, you have to go read haddocks to see what instances it has.... And so on, and so forth, the constant switching between browsing docs and code is hurting concentration, even with multiple monitors. &gt; Red squigglies in any editor aren't equivalent to a fast typechecker cycler. Except IDEA runs a full typecheck itself. It's not just syntax errors that get red squigglies.
Not to mention things like `lazy`, which matters a lot in this style of programming because initialization when doing composition via mixin's/traits is big concern
No. Stop exaggerating. The spec is not complete and lacks details. Some of them are too implementation specific. But the spec is there to be the driving force, especially when it comes to the fundamentals of the language.
Has it been rejected? I thought Luka didn't show it to Martin yet.
&gt; Propose ways to improve it, please. Everyone would be happier if the handful of contributors that don't keep contributing to the language stay. I assume you've watched my talk, in which I propose numerous concrete steps we can take to improve the situationâ€”one of which being, in the case of contributors, we let them have say in the development of the language, tooling, and website proportional to their contributions. If we had done this, I'm pretty sure that both Paul P. and Simon O. (and maybe others) would still be active maintainers, and the language would be in a better place. &gt; Are you suggesting that a community of developers can do better than a focused set of engineers with funding working full-time on the language? No. But you can't solve the funding problem without solving the language problem. Go, Rust, and Kotlin are **industry programming languages**, solving industry pains, in a way the industry wants to solve them. They are not academic or research languages. We can't just go out and "sell harder" and bring in millions of funding for Scala development. It doesn't work that way. We can, however, make changes to the contributor process to help ensure we don't lose highly-engaged, productive contributors. We could go beyond that, too, and try to replicate the Go / Rust / Kotlin model. But to do that, we'd need to commit to becoming an **industry programming language**. For example, prioritize work not around language features or new calculi, but around pains that, say, Twitter has that have led them to the development of Reasonable Scala; or around pains that Apache Spark has which that have led them to drag their feet on 2.12. If the roadmap is driven entirely by industry pains, then we have a better chance at attracting an industry partner. That requires a lot of BD and may conflict with the desire to actively explore the landscape of possible solutions to problems at the intersection of FP/OOP. &gt; The only projects that are not currently worked on are Scastie and Scaladex because we're all focusing on tooling. So there are only 2 abandoned projects so far. Possibly, more projects should be abandoned so the focus can be sharpened further. The emphasis on tooling is is spot on, although I question decisions to reinvent wheels instead of contributing to existing solutions (BSP versus LSP, Ensime). Please understand that my skepticism is driven by a long history with Scala, having seen numerous projects abandoned or released half-baked. This doesn't mean I don't support the work being done by the Scala Center or EPFL. I absolutely support it and want any project that satisfies an industry need to be successful. If there are (low-cost) ways I can help, please let me know. &gt; Do you know what we need? More proposals, backed up by experiments and prototypes, not only words, to assess how we can improve Scala as it is today. I am not going to contribute to Scalac or Dotty right now. Do you know why? Because if I contribute something, I have very low confidence it will be accepted. Because my vision for Scala is to be an excellent, stable, industry language for functional programming on the JVM. That vision is not compatible with a middle-of-the-road, let's fuse FP/OOP at every juncture and do some research in the language and standard library. The FP community in Scala pushed for real type classes with Luka's proposal. That didn't go anywhere because it didn't have sufficient "fusion of FP/OOP". I contribute in my own way: building libraries that show FP in Scala has attractive benefits to businesses. More great libraries in the Scala ecosystem will attract more users, and more users can solve all other problems given sufficient time and investment. &gt; Can you please point to "these observable measures"? You keep claiming Kotlin is gaining more adoption than Scala. I have never claimed that Kotlin has more adoption than Scala *right now*. What I have claimed, and backed up with numerous sources, is that Scala is **receding** on numerous observable measures (RedMonk, State of Java, TIOBE, PYPL, Indeed, etc.), and that Kotlin is gainingâ€”in fact, gaining so fast, it's by far the fastest growing AltJVM language. The trend lines are not positive. Yes, maybe people are locked into Spark, and there's Twitter, etc., but these factors merely slow attritionâ€”they do not guarantee success. I'd rather deal with these problems now while they are still possible to head-off. I'm doing the best that I can with the resources I can spare, but it's not enough; and I know you are doing what you can. For us to really make the best possible change, the whole community should be aware of these problems and invested in fixing them.
&gt; Scala's specialization attempt ended up being a joke. Delimited continuations were one man's research project that got abandoned after the paper was written. Scala collections continue to have major usability problems because designing collections turns out to be really hard. Scala macros, to the credit of the contributors, have had a lot of effort put into them, but they still pale compared to macros in languages designed from the ground up to have macros. To clarify, specialization wasn't a joke, its the same model that is used in C++ where it works beautifully. The difference is that in a JVM environment, we work with dynamic libraries by default and there isn't any linking stage, which means you never eliminate the unused specializations that are generated (in C++ you often generate a huge amount of specializations, however the unused specializations get removed in the linking step, which happens to be a lot of them) 
Ensime only runs the typechecker for the files you're currently editing, just like the Eclipse plugin, it's not a full compilation.
I don't think anyone's proposal has been rejected so far.
Ah, I see where you are coming from: Haskell/Purescript has more 'pure functional' libraries than Scala. Thing is though, sometimes it can be something as simple as: do my language have drivers for _Database X_ . Without this, you can't even get in the game. The JVM has you well covered for things like this. 
Set `javaHome` used for forking to JDK 10 regardless of the content of `crossJavaVersions`.
Weird, I could have sworn [Luka's proposal](https://github.com/LukaJCB/typeclass-proposal) was linked in the original [typeclass traits discussion](https://github.com/lampepfl/dotty/pull/4153) and subsequently dismissed. Apologies for misremembering. 
&gt; It's not just syntax errors that get red squigglies. This is similar to the usual editor integrations: you get squigglies for both type error locations and syntax problems. &gt; It's ghcid here the one that's compiling your code all the time. `ghcid` doesn't recompile. But if IntelliJ doesn't either, than that's good news. I didn't know they had an in-house typechecker.
RT also unlocks a lot of cool fusion tricks / rewriting and inlining rules, something else that I miss.
Just want to say that you are not alone and agree with you. Scala is not Haskell on JVM. For those people like this guy, he should do ETA or just Haskell. Those kinds of people make Scala community so negative.
&gt; Go, Rust, and Kotlin are industry programming languages, solving industry pains, in a way the industry wants to solve them. They are not academic or research languages. I really don't know what you're talking about. Scala is an industry programming language. An insane amount of people and companies use Scala today and are happy users. John, really, you need to get out of your bubble, get to know who uses Scala now and stop pretending that the only reason why people use or would like to use Scala is pure FP. It's not. &gt; We could go beyond that, too, and try to replicate the Go / Rust / Kotlin model. But to do that, we'd need to commit to becoming an industry programming language. For example, prioritize work not around language features or new calculi, but around pains that, say, Twitter has that have led them to the development of Reasonable Scala; or around pains that Apache Spark has which that have led them to drag their feet on 2.12. I'm sorry but this is what we've been doing for more than a year now. Working closely with backers of Scala like Twitter, Stripe and other big and medium-sized companies that have come to us to tell us their tooling problems. As a response, we've been working on tools to alleviate them and make the Scala tooling experience pleasant for all the Community. **Nobody is working on papers, calculi or ways to fuse FP/OOP at the Scala Center (and mostly LAMP)**. At the Scala Center we're all engineers working for a better Scala, with more industry adoption than the one we have now. &gt; If the roadmap is driven entirely by industry pains, then we have a better chance at attracting an industry partner. Everyone's working to address industry pains. &gt; The emphasis on tooling is is spot on, although I question decisions to reinvent wheels instead of contributing to existing solutions (BSP versus LSP, Ensime). BSP has nothing to do with LSP. They are independent protocols. Read our [blog post](https://scala-lang.org/blog/2018/06/15/bsp.html) and [the protocol FAQ](https://github.com/scalacenter/bsp/blob/master/docs/bsp.md#faq). For the record, we're chatting and working with LSP maintainers (Microsoft, Sourcegraph, Google) to find ways in which both protocols can integrate better. This communication is done in the open in LSP's and BSP's issue trackers. &gt; Because my vision for Scala is to be an excellent, stable, industry language for functional programming on the JVM. This is literally the vision of many people working on the Scala team and the Scala Center. The difference is that you want to do this by making Haskell on the JVM, and the people in charge do not believe in your vision. Don't judge the intentions of the people that disagree with you, we all have good intentions. &gt; I'd rather deal with these problems now while they are still possible to head-off. You talk about this as if it was novelty. Believe me, you're not the first one to come up with the problems in your keynote nor the first one to worry about them. Many people have identified them in the past and they've been working actively to fix them. The fact that you haven't seen these efforts doesn't mean it's not happening. You haven't done a good job at knowing what we're doing at the Scala Center either, otherwise you wouldn't have talked so harshly about tooling in your keynote. &gt; I absolutely support it and want any project that satisfies an industry need to be successful. If there are (low-cost) ways I can help, please let me know. Yeah. Say something positive whenever we get something right in the area of tooling. You complained that the arrival of Scala 3 demotivated people to improve Scala 2 tools. I don't know if you realize, but your negativity demotivates probably even more.
&gt; Haskell/Purescript has more 'pure functional' libraries than Scala By definition, yeah, since those two can't have non pure FP libs. Sure the [OpenGL](https://hackage.haskell.org/package/OpenGL) bindings are pretty low level and don't really resemble idiomatic Haskell, but the fact remains that all the functions are pure functions (i.e. referential transparency is maintained). I do want to make the distinction between Scala libs and general JVM libs, though. Sure, the overall JVM library ecosystem is massive. For comparison, can you list (if you're able, considering NDAs and whatnot) the top 10 Scala-only libraries that your main projects use (excluding Spark and Akka)? &gt; do my language have drivers for Database X The JVM likely has better DB support than Haskell, yeah. The community self-diagnoses as having ["okay" DB support](https://github.com/Gabriel439/post-rfc/blob/master/sotu.md#databases-and-data-stores). There *are* good bindings to many of the major stores, but notably there's no Microsoft SQL server nor Oracle. I suppose though your overall point was that the JVM ecosystem always has your back when it comes to "commercial" needs. Given its lifespan and history, that's almost certainly true. Haskell might need some polish in this area, but it's certainly not a write-off. 
&gt; reinvent wheels instead of contributing to existing solutions (BSP versus LSP). To clarify, BSP is complementary to LSP. LSP abstracts over the editor while BSP abstracts over the build tool. I believe one reason why there doesn't exist yet a high-quality Language Server for Scala is because it's too hard to integrate with the major build tools (sbt, gradle, maven, pants, bazel) to support even the most basic functionality like goto definition and completions. IntelliJ Scala struggles with the same problem, and it's been great to collaborate with them on BSP to make sure it also meets their needs.
Ah, looks like you're right. I just confirmed with Sam. My mistake.
You should probably &lt;s&gt;&lt;/s&gt; your previous message. 
&gt; As for Java deps - well, you've got the Java Wall to think about. nulls and Exceptions lurking around every corner. I personally want a language where I don't have to constantly account for those things. As bad relying on Java "FFI" is, relying on C "FFI" is many orders of magnitude worse. A misbehaving Java library might return null or throw an exception, a misbehaving C library might do anything up to e.g. silently corrupting the memory of unrelated threads. Whenever I've tried to use Haskell, even fairly basic things like connecting to a database or decoding common image formats relied on C FFI.
&gt; Yet almost every single project depends on macros through transitive dependencies. They're almost entirely unavoidable, unfortunately. What macros are commonly used other than shapeless? I think that's the only place where any of the codebases I've worked on depended on macros (except one client that insisted on using scalatest). I guess slick for projects that use it? I just don't get the sense that there are a large number of critical or custom macros. As long as there is a release of shapeless for 3.x I don't see the ecosystem having any trouble moving.
&gt; solve a specific situation in a given time while the interviewer(s) watching you no
Reasonable. Done.
I can't/don't watch videos, so apologies if this has been covered in some video-only channel. Can you say what happened with the `-Zirrefutable-patterns` that was at one stage implemented in typelevel scala? I don't understand exactly what happened with typelevel scala but it seems like at some point it was rebased to be a set of PRs into mainline scala and this feature was lost at that time? An improved distinction between safe and unsafe pattern matching is something that would really help me as an industrial if somewhat FP-minded user of the language, and I don't think I'm alone (lihaoyi described it as the biggest wart in today's scala). So if it's just a case of dusting off a stale branch or some such I'm happy to put a bit of work into this. But I assume there's more to it given that the existing work was abandoned?
Absolutely true that FFI barriers can introduce unseen naughtiness. The difference here being that Scala encourages free use of Java libs without protecting you, while most of the Haskell ecosystem doesn't use its C FFI. I'm sorry to here about your issues. When in the past did you try it? [JuicyPixels](https://hackage.haskell.org/package/JuicyPixels) is the accepted image format converter, and uses no C calls. I can't say what the common DB libs do, though.
&gt; ghcid doesn't recompile. `ghcid` supports running expressions via `--test` flag, so it has to emit bytecode. Btw, `ghcid` is not a new tool or concept, at all, I've been using `hdevtools` with `-fno-code` way before ghcid was written.
&gt; For example, prioritize work not around language features or new calculi, but around pains that, say, Twitter has that have led them to the development of Reasonable Scala; or around pains that Apache Spark has which that have led them to drag their feet on 2.12. I still don't see who you think is prioritizing their work wrong, can you be more specific? Reasonable Scala is about speed and basically everyone (Lightbend/Scala Center/EPFL) is working on ways to speed up the compiler. The situation with Spark is being worked on by Lightbend and Spark folks collaborating. &gt; The FP community in Scala pushed for real type classes with Luka's proposal. That didn't go anywhere because it didn't have sufficient "fusion of FP/OOP". Do you have a link? I don't think Luka has finalized his proposal yet, I don't think it's even been mentioned on the original typeclass PR thread yet, let alone rejected for any particular reason. &gt; Because if I contribute something, I have very low confidence it will be accepted. So write a proposal before implementing it, then we can discuss it and if we agree on something you can have high confidence it will be accepted. https://contributors.scala-lang.org/ is a great place for this kind of things!
I haven't been in the loop of this one. Would you mind coming over the scala/contributors Gitter channel to discuss about it? I suppose people there could fill you in better. Some help in this area could be useful, thanks in advance.
&gt; I really don't know what you're talking about. Scala is an industry programming language. Agree to disagree. Haskell, Scala, and many other languages are primarily research languages â€” active experimental playgrounds to test new ideas (such as the DOT calculus, linear types, etc.). Twitter and Spark pushed Scala into industry, but its origins, development, and roadmap are still firmly entrenched in academia. &gt; Nobody is working on papers, calculi or ways to fuse FP/OOP at the Scala Center (and mostly LAMP). At the Scala Center we're all engineers working for a better Scala. I think [you know what I'm talking about](http://github.com/lampepfl/dotty/issues). You seem to be very defensive, but please understand I'm making comments about the entire Scala ecosystem, not about Scala Center in particular. I'm not blaming Scala Center for all that's wrong with Scalaâ€”in fact, I think if you read my replies more carefully, you'll see I've said a lot of positive things about Scala Center. &gt; This is literally the vision of many people working on the Scala team and the Scala Center. I can quote numerous [issues](http://github.com/lampepfl/dotty/issues) in which suggestions are rejected on grounds they "too FP" (e.g. type classes as a separate entity), and not "FP/OOP" enough. The reality is that _my_ vision for Scala is concerned _only_ with FP, and while I love traits-as-modules (which is _not_ Haskell on the JVM!), I do not like OO-style inheritance or the many problems that come with this complexity. I'm sure you can understand why someone who wants to focus on a simpler, cleaner subset of Scala that targets the FP sub-community is hesitant to devote significant effort to the compiler(s). &gt;Believe me, you're not the first one to come up with the problems in your keynote nor the first one to worry about them. Many people have identified them in the past and they've been working actively to fix them. I'm glad to hear you agree with the problems I identified in the keynote, but your response sounds like, "Trust us, we know about the problems, we'll fix them for real this time. Please don't ever talk about the problems." I talk about the issues that I and others have seen in the Scala ecosystem, which have existed for more than a decade. I'll keep talking about these issues to raise awareness. I'm not going to stop just because someone somewhere is working on a solution that may or may not materialize, and if it does, may be abandoned or release half-baked. I hope you (and others) do solve all of the issues, and as you solve them, I'll be happy to give credit, as I did in the talk for Lightbend's work on `scalac` maturity. Until then, people should know what's happening in the Scala job market and why it's happening.
John I wanted to ask about your proposal to double down on the FP side of Scala while as you say, sacrificing half the community (the OOP half). It seems to me, that literally 100% of the great success stories in Scala that are so well known as to attract people from outside the community and even to be useful to people well outside of it, are not written in a pure FP style. They are: * Spark * Kafka -- to the extent that it is still written in Scala. * Flink -- to the extent that it is written in Scala.. * Akka * Linkerd -- now being rewritten in Go/Rust unfortunately * Graphicool and Prisma * Play framework * A few other less popular apache projects may fall in this category * Gitbucket * Maybe GeoMesa? Feel free to add more to the list, but among these, not a single one is written in pure FP style. This suggests to me that the sweet spot for scala applications is more in the middle of the ground mostly-fp-with-side-of-oop style. I feel like sacrificing this side of the community would be literally sacrificing literally every outward-facing accomplishment Scala has ever made. 
&gt; IntelliJ Scala struggles with the same problem, and it's been great to collaborate with them on BSP to make sure it also meets their needs. ðŸ‘ I think the identification of "corporate sponsors" for new development work is extremely wise, and is a pattern that could be pushed all the way into the language. Corporate sponsors can contribute feedback that helps ensure the solution is useful to real pains they have, and if the project is successful and those corporate sponsors become users, then the work becomes more likely to be maintained rather than abandoned.
The PR was closed for inactivity, hopefully someone will pick it up at some point: https://github.com/scala/scala/pull/5617 (Dotty implements this behavior by default).
&gt; I can quote numerous issues in which suggestions are rejected on grounds they "too FP" (e.g. type classes as a separate entity), and not "FP/OOP" enough. I'd be interested in seeing such quotes actually, I don't think this really happens that much. Note that the typeclass proposal hasn't been merged, integrating typeclasses into the language is an interesting challenge and I don't think anyone has come up with a perfect way to do it yet, it's possible that we can't come up with something good enough to add to the language in which case we shouldn't add anything and keep the status quo of typeclasses being handled by libraries.
&gt; I'm glad to hear you agree with the problems I identified in the keynote, but your response sounds like, "Trust us, we know about the problems, we'll fix them for real this time. Please don't ever talk about the problems." No, that's not what Jorge said at all. You say "Here are these problems. People are working on academic things instead of trying to fix these problems", Jorge said "That's wrong, we're working on these problems", no one said that you shouldn't be talking about the problems themselves.
The number of pull request is pretty good in Github for Scala #12: [GitHut 2.0](https://madnight.github.io/githut/#/pull_requests/2018/2)
I find currying not overly useful and remember you can do this in other languages too. Maybe itâ€™s called Closures in your language. For good style, look towards mutable data structures everywhere, monads as a pattern to do data mutations in a way thatâ€™s flexible and mutable too.
First, some facts: Flink is almost entirely Java, Kafka is mostly Java (despite starting as 100% Scala), Play is 1/3rd Java, and Akka is nearly 40/60. In other words, many of the libraries you cite as "Scala libraries" are actually Java libraries, and 100% of them have Java APIs and are nearly as usable in Java as they are in Scala. The trend is clear: libraries which were initially written in Scala or for the Scala community have pivoted. They're being written in more Java, with Java-friendly APIs, or even being rewritten in languages like Go/Rust. It's important to understand that 10 years ago, the features that Scala had with mainstream appeal (including lambdas, pattern matching, local type inference, and data classes) were rare. They are common and many of them have been baked into Java (or will be soon). Languages like Kotlin and Ceylon have their own versions of these features too, in much simpler packages. They're not as powerful as Scala, but they hit the sweet spot for mainstream developers. As a result, there are fewer and fewer reasons to choose Scala. Even if you choose Scala, if you want major adoption (like Spark, Akka, Play, etc.), you still have to target the Java crowd too, which leads to a lowest-common denominator design for the API. Akka, Play, etc., may as well be written in 100% Java. If Spark were started today, the authors would not choose Scala (IMO), because Scala is not the best "Better Java" language anymore. If they didn't need the JVM (the JVM is experiencing some decline!), they'd choose Go, or maybe Rust. If they needed the JVM and could wait on a few features like pattern matching and data classes, they would probably choose Java, which has become tolerable and is getting better. If they couldn't choose Java, they'd probably choose Kotlin. _The unique circumstances that led to authors of these early libraries choosing Scala no longer exist._ In a world in which Kotlin is the Better Java (i.e. Java but with the mainstream FP features), or perhaps Java is itself the better Java, having accreted the features it was missing (which caused it to lose market share), the question is what is *unique* about Scala that can drive adoption in some new market. Because Scala is losing and will continue to lose the Better Java market. I have thought about that a long time and my own answer is that Scala is better at FP than the other JVM languages. I think focusing on FP will inspire FP developers to stay and contribute libraries that are much more powerful, principled, and type-safe than Spark, Kafka, and many other libraries that helped push Scala into industry so long ago. This strategy of sacrificing what got Scala where it is today, in order to take Scala where it must go tomorrow, may seem counterproductive, but it happens all the time in startupsâ€”it's called a pivot. When you take an evolutionary dead end, in this case caused by market evolution, you have to find out what you're uniquely best at, and find an adjacent space not too far from where you already are, and then pivot hard to get there, ignoring all distractions. Pursuing Kafka, Spark, etc., is a distraction. Recognizing that, in my opinion, is the key to success.