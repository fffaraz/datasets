Scalatra with Casbah/Salat/liftweb for scala to JSON. 
Whatever you do don't use Lift.
It seems like it'd be trivial to make a Scala version of Flask. I wonder why no one's done it.
I'd be interested to hear why they think it's a disaster. It has some rough patches that are fixable, but I really can't regard it as a disaster. Better than most any other framework I've used in other languages.
For a great ORM try Squeryl. 
i dont want to ve disrespectful but anorm is crap. 
Seconding wondering why it's a disaster. I know people got burned on 1.x-2.0 stuff, but it seems like a decent modern framework. Lift I like more, but I can't imagine teaching newbies to use it. Cool architecture, terrible docs. 
We're starting to use a lot of Play! 2.0 partly because we've already deployed an awful lot of Akka(which is awesome). To be fair, most of what my team works on is REST and asynchronous stuff like websockets/comet though so if you're looking for solid templating, I can't comment too much.
We use Play and Akka + swagger.
have you ever used one of sqlalchemy, django orm, activerecord or even gorm? again, i don't want to be disrespectful to the authors and underestimate the amount of the effort put into the library but then what the actual fuck is this? val populations:List[String~Int] = { SQL("select * from Country").as( str("name") ~&lt; int("population") * ) } or this? case class SpokenLanguages(country:String, languages:Seq[String]) def spokenLanguages(countryCode:String):Option[SpokenLanguages] = { SQL( """ select c.name, c.code, l.language from Country c join CountryLanguage l on l.CountryCode = c.Code where c.code = {code}; """ ) .on("code" -&gt; countryCode) .as( str("name") ~&lt; spanM(by=str("code"), str("language")) ^^ { case country~languages =&gt; SpokenLanguages(country, languages) } ? ) } 
squeryl seemed good. thanks for letting us know.
I am not sure if you are suggesting that that code is bad for some unstated reason or whether you actually don't understand it. Also, They have moved away from some of this syntax claiming it was too complex and suggesting that things like spanM should be handled with more standard operations on collections. There is room for argument there, but that's another story. I have three primary points of appreciation for Anorm: 1) It makes zero requirements on my domain objects. Every other data mapping/ORM/whatever framework I have seen always makes significant demands on my domain objects and never fails to be a pain in the ass especially if you are trying to maintain immutability - which you should probably be doing if you aren't. Squeryl may be an exception here, I should note. 2) It is simple. Fewer places for the framework to introduce bugs of its own or for users to create bugs with a lack of understanding of magical inner workings of the framework. 3) You never ever have to wonder how you're going to get anorm to do something wacky and every project worth doing that I have seen involved at least a few wacky queries. With Anorm, you just write whatever the hell query you want and then have decently powerful tools to parse it - simple, easy, satisfying. 
If you want to convince your boss, you need to make sure you present the downsides as well as the upsides, so this kind of claim: &gt; So, given the near lack of risk would raise an immediate red flag if you were trying to convince me. There are risks in picking up Scala: - Very slow compiler (a big deal, especially for front end development where template recompilation is expected to be near instantaneous -- looking at you, Play 2) - Immature tooling around it, especially IDE's. Whether you pick IDEA or Eclipse, you'll get bugs and a very small subset of the features you're used to with Java - Challenging recruiting. You will probably not be able to find Scala developers, so you'll have to hire Java developers and hope they can come up to speed. - The creation of Typesafe hasn't resulted in much acceleration to the time before there was a single organization before the language. This is preoccupying about the future. Especially since they tend to prefer to add features than fixing broken ones, allegedly to be able to file papers to conferences. - Mixed bag around the build. sbt is fast but very arcane, with very little documentation and very unclear directions for he future. Just to name a few. 
Good points. The bottom line is that the priority of the Play team seems to be... well, the Play team. They will take the framework in whatever direction they feel like with very little regards for existing users. As a developer, there is absolutely nothing wrong with that: scratch your own itch and all that. But as a user, it makes me very nervous about the maintenance, backward compatibility and future of Play. Everyone who picked Play 1 is pretty much dead in the water right now (even though they say they will keep supporting it, it's already clear that they are more interested in working on Play 2 than 1). Oh and the template recompilation went from sub-second in Play 1 to taking 8-10 seconds on Play 2. When you do this several times per minute, it's a huge deal and one reason why I feel I've run out of options to do web development in Scala and considering going back to Java. 
I was in the same board. Play 2.0 with just 10 or so models and associated controllers + 20 pages or so was taking 10s + per compile. Unacceptable.
ORMs are 90s technology. They're so limited it's insane. Sure they can be simple, each class is a table. Great. But what about if you're doing anything even slightly complicated? Writable common table expressions? Window functions? If your tables and results are so normative that you never do anything other than simple joins, then sure ORMs can be great. But in my experience they're a million times more hassle than they're worth.
Scala also supports captures of this kind, but the blog post is addressing a different topic (stable pattern identifiers). 
From what I understand the `match` operator was designed to match by class. I would never think of using it for equality of variables. (*Disclamer: I am in no way an expert of scala*)
Actually, my original point had been that Haskell also disallows using variables in placeholders to capture the value in the placeholder, which prevents the behavior observed by the author. But that was just me being silly because when I wrote up and ran a small test case I realized I was wrong and immediately remembered how often I had used this feature in the past, though in a different guise. Doh! :-) Anyway, part of the problem here is that Scala wants to (rightly, in my opinion) follow languages like Haskell and O'Caml by having upper-case mean that you are pattern matching on type constructors (or things like them at least), but unlike those languages it doesn't have the luxury of making it impossible for anything other than types and type constructors to start with an uppercase letter so to beginners and people unfamiliar with languages like Haskell/O'Caml/etc. it looks like an inconsistency.
i personally got convinced after i tried building a small web app with play! and then stress tested it with akka on
Match has many many many many uses.
It won't be fixed, it was a conscious decision.
For some personal experiments, I'm using FastCGI/StringTemplate/JBDC (with some lightweight, hand-coded wrappers around the former). We'll see how it scales, but for simple apps it's been very nice.
Well it would be imaginable to emit a warning of the shadowing, independent of what the IDEs are capable of. Then if you want to be nasty, add an `@unchecked` :0)
I started out using anorm, and I agree that it's crap. The main reason is it is not [DRY](http://en.wikipedia.org/wiki/Don't_repeat_yourself). I can only list out all of my database columns so many times before I scream, and look for something else to use. My case class lists my column, and my sql file list my columns. That's already two places. I don't like that, but I could live with that. But anon wants me to write select, insert and update methods by hand and list all the columns in each of those. I'm not a big fan of ORMs. When the Play docs said how they didn't like ORMs and were keeping it simple, I was cheering them on in my head. But I can't stand anorm. I did start using squeryl and I like it a little better.
Thanks for the suggestion, I was actually already using it. Honestly I'm not in love with it either. But it's a lot more [DRY](http://en.wikipedia.org/wiki/Don't_repeat_yourself) than anorm, so at least it pisses me off less. I don't really want a full blown ORM. For the most part I'm happy to write my own SQL statements, at least when they're select statements. But marshaling the results into objects should be handled for me. And I shouldn't have to write my own insert and update statements. I like type safety, but part of me thinks things were so much simpler back when I just had a getAll method that returned a List&lt;Map&lt;String,String&gt;&gt; for any query.
And parse, and parse it, and parse it again. Have the Anorm developers never heard of [DRY](http://en.wikipedia.org/wiki/Don't_repeat_yourself)? Because the examples I followed were anything but. It's more like, lets see how many times we can list out every column in the table! Boy, this is going to be fun if I need add a column later! Maybe you get satisfaction from writing parsers. But I do not. I get annoyed when I do a task that the computer should be doing for me. And I get really annoyed about the 10th time I do the same thing, and write the same code that really should have been autogenerated for me in the first place. I haven't touched anorm in about 2 months (I rewrote the code to use SQueryl pretty much the next day, and then haven't touched the project at all in a while), and I'm still mad about it.
I haven't actually done a production app in scala yet. I'm still trying out different stuff. I'm planning on using finagle with [querulous](https://github.com/nkallen/querulous/) if I can either find a port or port it myself to work with postgres.
But this doesn't seem to make use of any of the Scala collection features, like map or filter. A better test imo would have actually made use of common operations on Collections in Scala and the same applied in Java. Otherwise you're just testing the same collection with different syntax, which just proves the Java implementation is faster than the Scala one. But the performance benefits might disappear when making use of stuff specific to the Scala collections because (I assume) it has to convert the Java map to a Scala one? 
My guess would be that one of the reason is Scala.Net
Because it has a much richer API and integrates seamlessly with the immutable collection, to the point where you can effectively exchange them with almost no adaptation of the rest of the code. Mutable collections are also required with the builder factories, so it's only natural to provide 'end user' types as well. Cf. http://www.decodified.com/scala/collections-api.xml
immutable.Map 5-6x slower and mutable.Map 2-3x slower vs using the implicit conversions seems like a very heavy price to pay.
Do something smaller
Two things which are probably not at all what you ask for, but I take note of them anyway: * In a turing machine, the tape is what contains the data. You call the program "tape." * Why not make an infinitely long data tape? I always see these arbitrary restrictions on Brainfuck interpreters and wonder why. If you can implement all those other things, you could easily implement some kind of easily expandable data structure.
It is (or, at least, should be) convention to add parens to methods with side-effects, even if they don't take arguments: Wrong: def method { println("This is a side effect!") } method Right: def method() { println("This is a side effect!") } method()
You'll have a much better experience using IntelliJ community edition: http://www.jetbrains.com/idea/download/ Then file -&gt; settings -&gt; plugin manager Install Scala plugin.
Immediately the same response I have thought of. Odersky + Typesafe are developing the Eclipse plugin quite heavily at the moment (2.1 release looks promising) but as far as I can see, the JetBrains team have done a better job of making a Scala plugin, even if it's not going to be a bundled plugin in 12.
Hi Anth, this shouldn't be the case normally. Which exceptions did you experience? One of the reasons that it runs fine on your laptop but badly on your desktop could be that you forgot to adapt the eclipse.ini file on your desktop machine (that's the thing **I** always miss when setting up Eclpse :-)). Which Eclipse update sites did you use for which Eclipse version? Is it a vanilla Eclipse install or something like JBoss Tools or STS? Let me know how it works out!
Do you have the Groovy plugin installed? They are very much still not compatible.
Also, as a counterpoint to those made by the the IntelliJ fans, I've used Eclipse and IntelliJ for Scala quite a bit, and they both suck right now, just differently. I have nothing against IntelliJ, its preferred workflow just doesn't match how I like to work.
&gt; It's been a year now that a full team of Typesafe employees have been working on the Eclipse plug-in and to be honest, I don't see much progress compared to how things were before Typesafe :-( I wish the Eclipse plugin was better too (I use it all day at my job), and I'm not a Typesafe apologist by any means, but the Typesafe team *has* made progress on the Eclipse plugin. Semantic highlighting, implicit highlighting, kind-of rational incremental compilation, fairly-functional basic refactorings are all things that the Typesafe guys have produced in the last 6-12 months. The plugin is getting better, there's just a long way to go.
&gt; Agreed, but my point was that the plug-in was already progressing at that pace before Typesafe took over Maybe, maybe not. I remember the pre-Typesafe days, and it wasn't at all rosy. The plugin got basic refactorings around that time, but building was a mess on projects with more than a few classes; you could forget about incremental compilation. Back then, I almost never even got any completions when typing something like foo.&lt;crtl-space&gt; . There were also organizational problems. I remember the part-time maintainers seeming a bit out of their depth, plus a proliferation of branches for one-off fixes, config options that toggled fixes to fixes for fixes, partly-finished Summer of Code contributions, etc. This is not to say that things are great now, just that they're a whole lot less bad. &gt; if \#scala is any indication, the overall recommendation is that even today, IDEA is still a better Scala plug-in That's certainly what I hear, but my own experience with IDEA and that of my coworkers is much less positive. Scala IDEs are about where Java ones were in the early-to-mid-2000s. 
excuse my ignorance, but what is meant by not a bundled plugin in IntelliJ 12? The plugin is already installed separately and not bundled. Are you saying that it will no longer be available for free?
Very interesting. I've been playing around with Scalaz Iteratees, but those don't seem to be as powerful. I couldn't find anything like those Enumeratees or convenient operators for piping data through them, though I think they're adding something like that for version 7.
Streaming over HTTP… oh God why.
That is where video streaming is moving to.
It's the rename for ScalaQuery, with some ambitious plans to adopt the new macros feature in 2.10 for LINQ-like awesomeness.
Sure, thanks no problem. Reddit comment threads are just not the perfect venue to discuss that stuff. :-)
I think it does, but you need to specify the maximum, which is by default too low for the plugin, it seems.
Jazzy Akka 2.x Roadmap https://docs.google.com/document/d/18W9-fKs55wiFNjXL9q50PYOnR7-nnsImzJqHOPPbM4E/edit?hl=en_US&amp;pli=1
I'm really curious about how this paradigm will be adopted by the community: &gt; You can write your database queries in Scala instead of SQL"
WTF @ first two questions. I suppose if the interviewer ever interviews the president, he'll start by asking him which political party he belongs to, and what political office he holds. Edit: By that I mean, he could have found the answer to them on the project's website, they weren't questioned that required one to interview Martin to get the answer to, and there wasn't any useful insight that Martin could add. Look at the last question and answer. A lot of the things Martin said the in the answer are things that should have been questions.
It probably will, but I really enjoy using it. SQL is a very expressive language for writing queries with a very interesting paradigm. Anorm provides nice combinators for converting rows back to Scala object.
Sorry - I'd have carpal tunnel if I still used Maven. ;-)
Cut and paste, son. I'm not fond of Maven's verbosity either, but I *am* fond of the POM being strictly declarative, syntactically unsurprising (it's just XML), and not full of bizarre symbols like `&lt;-~` or irrelevant programming constructs like class and object declarations everywhere. Fuck that noise.
The declarative nature of maven is what makes it such a nightmare. It is all very well when you have a simple use case and don't deviate one iota from the happy path. As soon as you have to do something beyond the narrow imagination and philosophies of a typical maven developer, well - welcome to hell! I can't think of a single tool I hate more, or that has wasted more of my professional life, than fucking maven. Even ant is miles better than that maven pish. SBT is better still. It does things my convention, sure, but at least it gives you an escape route and doesn't expect you to write 17,000 lines of XML and twisted, bizarre plugins to acheive the simple. Anyone who actually prefers the typical obtuse pom.xml to a simple SBT build file is surely utterly doolally.
&gt; By default, build tasks that do not depend on one another execute in parallel. This also applies to your tests. Instead of sequentially executing your tests, Sbt will run them in parallel. ...something about parallel task execution… Informative. ;)
Because I dislike declarative-only. If you want some simple, non-standard behaviour, why can't you just do it, in the build file, instead of arsing about with plugins or torturing your pom in weird ways? Declarative is fine - for the most part. Most of a typical sbt build file is in fact declarative. However sbt lets you just say "and then do ABC and put it in XYZ" if you really want it. It's a build file. You should be able to tell it exactly and explicitly what steps you want it to perform in a procedural manner, when you really need to. It's not some terrible capital offence to do this, but maven treats it as one and that's why it's awful.
If writing plugins were easy, would that distinction still matter?
Yeh. Writing a plugin means maintain a separate project, ensuring the plugin is configured on every developer's instance, some mechanism to keep the plugin up to date when it is changed, like an internal maven dist site - a whole lot of infrastructural overhead. A plugin is fine for some major new behaviour you wish to add. It's not so great otherwise.
You can, yes. And that's really nice. I love maven, but after spending 4 days banging my head in anger against sbt, I finally had the conceptual breakthrough to "get it", and damn, it's amazing. A really nice compromise between declarative by default, and procedural on demand. It's really, really clever. For simple builds, sbt is a lot nicer than maven ... ~test is just awesome.
Yesterday in Cambridge, MA, USA
How different will the Future/Promise API in Scala 2.10 be from the AKKA 2.0 implementation? 
Black hole in Switzerland
* You can unit test controllers by using traits. Added an example [here](https://github.com/playframework/Play20/wiki/ScalaTest). * Uses specs2 and Mockito for testing, available out of the box. I'm using Subcut to provide dependency injection, and unit tests works perfectly. * IDEA 12 has [Play 2.0 template support](http://plugins.intellij.net/plugin/?idea&amp;pluginId=7080). * The build system is SBT with some additional plugins. This is the standard (Typesafe approved) Scala build system, and while SBT has been a pain in the butt historically, it's now somewhat decent. * Anorm is one possible database access layer. I'm using [Squeryl](http://squeryl.org) myself, and am very happy with it. * They really hate anything that has internal ThreadLocal storage, or keeps unit of work semantics around. It goes against the stateless async philosophy of Play.
&gt;I’ve stopped long time ago trying to parse the reasons behind why small percentage of Java folks utterly in love with Scala (me included) and much, much larger percentage is either indifferent and downright hostile towards it. My guess: it requires a more intelligent mind to grasp, but is very rewarding to those that can grasp it. The type system, for instance, is quite nuanced, and a lot of (less competent, IMO) programmers seem to dislike strong typing entirely.
Am I missing something? This link seems like a shallow restatement of www.warski.org/blog/2012/08/missing-oo-and-fp-bridge-in-scala/. Even though it's listed as a reference at the end, it isn't really a reference but a whole sale copy.
My blog is a partner site of JCG, and they republish the posts with my permission. Adam
It depends on Scala 2.10.0-M7, which is still not released officialy.
If I recall correctly, previous version was released for 2.10.0-M6.
I would love to see a scala logging API that actually returned one of it's parameters. That way, whenever I did: z = x+y I could naturally log that operation just by adding z = debug(x+y) or even z = debug("The result of x+y is {}", x+y) I actually created a little wrapper for slf4j that behaved like this and it was tremendously useful to me. 
I don't see why macros are necessary for this. It doesn't seem any different than to define `def log(message: =&gt; String)`. Real log erasure can also be achieved by annotating the log method with `@elidable`. When elided, not even the `isDebugEnabled` call is executed. Indeed I guess `@elidable` can be implemented in terms of macros.
I did a similar debug function in python that evaled strings.
As a manager of a dev team whos last project was in SCALA my main reason for not being sure if we will use it in our next project is that recruiting people is very very difficult!
I honestly think this is bad style, because your logic gets too mixed up with logging code. Moreover, if you want to comment or remove logging, you will have the same amount of trouble as you would have if you did both things separately from the start. However using some kind of pimp pattern you might be able to do z = (x+y).debug("The result of x+y is {}") Which seems easier to maintain. Abraço
A somewhat off topic question: Can anyone explain the advantages of slf4j over, say, plain log4j? Most of my experience with slf4j is fighting against transitive dependency conflicts involving multiple slf4j deps pulled in from somewhere in my project's dependency tree. This has always left me with a bad feeling about slf4j, but I realize that's a bad reason to dislike a lib.
Twitter4j and linkedIn are both medium sized companies. Twitter has 900 employees, linkedIn has 2400. Further, they are internet companies in silicon valley with access to some of the best technical people around. They were recently small startups seeking to be technically fluid and rapidly changing. They are not going to be typical. Big companies have tens or even hundreds of thousands of employees, often have long histories, and usually don't actually focus on the technical world. I work at one such (in finance) and though scala is certainly on the radar it isn't going to be en mass adopted anytime soon - though it may get some usage here and there. Internal technical lists have discussed it, but the gist is that scala is too protean.
I've been using scalaz.Validation. It's like Either, but better.
The real issue is that neither the Options nor Either classes are meant for "error handling" per se.
Me too. For me, it's semantic difference (both `Left` and `Right` are simply successful results, although of different types). `Validation`s are also more composable (they have `map`, `foreach`, you can treat them as applicatives, and so on) I've used `Either` exactly once: when I parsed HTTP responses and they could be either strings or XML nodes, depending on the status code. Long story short, I had something like `(Int, Either[String,Node])` there.
&gt; Either requires the immediate caller to do something about the problem Compose them using projections and handle the failure at any point you like. &gt; What if you could have something like catch, only it supplies whatever is needed to continue execution anyway? Again `getOrElse` on a projection will do that for you. 
&gt;Compose them using projections and handle the failure at any point you like. Requires all methods in the stack to return `Either`.
`scala.util.control.Exception` makes it rather easy to accomplish.
Ah, one for us maven users :)
…using the horrible, horrible `scala.xml` library. Noooooo thank you.
It's an interesting study, some notes: * The biggest difference between java &amp; scala is clearly tool support, making debugging harder. Scala doesn't have debugger support yet (although the latest scala-ide release has some). * Scala performance issues (mostly unnecessary object allocation) can be remedied but this cost more time debugging &amp; profiling. * They used students for this study, they probably already had a lot more experience with imperative langauges than functional languages. (the programming problems were quite hard, so they had to have been in the 3rd or 4th year of their studies) * They use actor based programming with Scala and java.util.concurrent in Java; imho both are very different. I would never use actors to implement a parallel merge sort, of course the new futures/promises api wasn't available yet for them. No mention of parallel collections.
Well, I only skimmed it and read the associated comment thread on proggit, but that's the gist of the study: it doesn't compare languages on equal footing, but checks if Java devs get immediate benefits by switching to Scala. And the result is that the benefits are not immediate. I had a little of Haskell background, and it still took me several months to raise my Scala skills to match Java. If those guys had no or little experience with FP, then they're not gonna crank out elegant Scala after only one month. 
There are a few interesting bits in the data dumps. Still I found this more useful as comparison: http://hammerprinciple.com/therighttool/items/scala/java
What's so horrible about it?
&gt; Given that we have escape analysis, I'm not sure this is really that big of a deal any more anyway. The modern JVM is very good at optimizing frequent, short-lived allocations. Yes it is *very* good, but far from enough. For example if you use for-comprehension with several generators: for( i &lt;- 0 until 100; j &lt;- 0 until 100; k &lt;- 0 until 100 ) yield (i,j,k) Will create one million closures... This was benchmarked several magnitudes slower than nested while loops...
Pretty interesting but I have to question the results if only because the co-author works for Larry Ellison.
It seems to me that the semantics Try _wants_ are closer to imprecise exceptions than `Either`. Turning `Try` into `Either` gets rid of why some people want `Try`. But changing the mental model of it/name scheme to capture computations lifted into an extended domain might clear things up. It would also provide those clamoring for a sound model and a set of laws some legitimate grounding: http://research.microsoft.com/en-us/um/people/simonpj/papers/imprecise-exn.htm
"Automatic object copying" Where does it happen ?
I would love to see scala succeed. As a java freelancer this would put back a lot of oomf in my day job.
&gt;Hi, author here - can I ask if you really didn't find the documentation site?. External documentation is not a substitute for good Scaladoc, which is, as I said, almost nonexistent. What little Scaladoc there is is written very poorly (not capitalized properly, not punctuated properly, etc). API documentation should not resemble a text message. &gt;Re fixmes- I don't have a single one in the code and less than 19 todos - including unreleased functionality that are documentation to me - the main dev. Documentation is where it belongs - again unless you find it actually lacking - actionable examples would again be appreciated. For examples, see the Scaladoc for: * trait `CData` * trait `Comment` * trait `SourceUser` * method `equals` on class `ElemKey` &gt;To answer the BaseToken comment the type explains what it is (an OptimisationToken) and generally the user will never see it in code. That could be a valid criticism - less visible implementation classes. Yes, exactly. If it's an implementation detail, it should not be in the API documentation. The public API should be clean, concise, and well-documented (in Scaladoc). Even if `OptimisationToken` must be public, its subtypes should probably be nested inside its companion object, rather than being at the top level. Keeping the set of top-level types small makes them easier to navigate.
By the way, when Scala 2.10 gets released, please consider (if you haven't already) using its macro and string interpolation facilities for writing XML inside Scala code, as opposed to the DSL you currently have. I find internal DSLs terribly ugly and the errors from them completely confusing, and the cool new stuff in 2.10 would seem to make them unnecessary since you can parse the XML at compile time.
&gt; which is, as I said, almost nonexistent. Actually you didn't write that, just documentation, but that clears it up nicely thanks. I'll state it - just for the record - that, in general, I often find scala/javadocs almost worthless, examples (executable ones at that) have far more worth for me. That and feedback from actual users has driven the focus on the other documentation. To your actual examples, CData and Comment are obvious for an xml library, to the point that I'm not even sure what comments could be there - perhaps a link to the DOM api for it? equals on ElemKey and SourceUser, both classes are actually good candidates to be brought out of the main package. Regards implementation detail there are two levels of api in Scales, the common use one (heavily documented with actual examples on the main documentation sites) and extension/modification of behaviour (documented in the details section for example). I'm more than happy to look at splitting these up into common (scales.xml.x) and derivable/re-usable (xml.x.impl or similar), but they'd still very much be public. If you have a look at the history of package layout, you'll see the last versions have headed this way and its a path I'll continue to go down, but incrementally. Some, more radical, attempts have met with grief from the limits of package objects and forwarding, but I'll get there. Its still good to know there are those who may appreciate further effort in this direction.
2.10 features are the focus of the 0.6 releases, 0.5 is focussed on asynchronous parsing via aalto-xml and iteratees. I've documented this in other places before, you'll see Scales in the release notes for M6 and M7 because of that interest. But I wouldn't disregard the dsl that is there based on string interpolation alone. The dsl is living code and subject to the entire freedom of Scala, there would not be much of a difference the second you move away from purely template driven (low re-use) style xmls (i.e. the kind that the Scala xml supports). Witness the number of stack overflow questions on modifying the scala.xml dom directly as indication of the inbuilt syntaxes limitations. Whilst I realise you may be commenting on internal dsls in general, I'm not sure what you mean by "errors from them". The Scales dsl is a very straight forward wrapper around common activities in an immutable model, no tricks there at all really. The need for the internal dsl won't go away from xml literals but it will help for quick "won't change xml" templates, essentially I'll be leveraging the dsl for it as far as possible anyway. There is already a project underway [smop-markup](https://github.com/bartschuller/smop-markup) that has been playing with these ideas.
I know this is an old comment, but I've seen this in a few places now, but I haven't seen reasons why people hate Anorm so much. I'm new to Scala (using play 2.0), and we're planning on moving toward slick when it's ready. What would you use today?
Can anyone summarize the 'scalaz faction' drama? I'm hoping it's funny.
Too rich for my blood, I'm afraid
&gt; - Target new platforms including Java 8 and Javascript Scala officially targeting Javascript would be awesome.
I can't help but wonder if they were prompted to try this in response to Red Hat's new language *Ceylon*, which does the same?
And there was much rejoicing. (Yayyy)
Because these metrics reflects the community dynamics by measuring how much are people are willing to share their code (via github) and their expertise (via stackoverflow).
Ah, there's a milestone build but not a nightly.
Cool. Will this work better with Maven?
Apparently reminder emails were supposed to be sent out 2 weeks before class starts, but neither myself nor a colleague of mine have received any. I figured /r/scala would be interested, hence the reminder. Also, this is the couse that Martin Odersky is teaching, so if you haven't signed up, I would strongly encourage you to. Edit: Seems the site is up and you can read the first "example" assignment to get up to speed for those new to Scala. For older hands, the first assignment is pretty simple.
Odersky sent me an email two days ago. Here are the contents: &gt;Thank you for signing up for Functional Programming Principles in Scala! Software is at the core of most of our products and services now, so programming is a pervasive activity. At the same time, we know that productivity of programmers can differ by more than one order of magnitude, much more than in most other disciplines. I hope that you will find this class useful for improving your programming skills by letting you concentrate on the essentials of abstraction and composition. I expect the class to be offered in September 2012. I'll notify you again when the class starts.
is there a subreddit for the class?
Nope. Perhaps we can create one? 
Interesting, I just checked and I still haven't received an email yet. Perhaps an issue with their email system?
If you go to the coursera website, log in, and click on the "go to class" button, you can start with the first assignment to install the tools we will use in class.
I remember reading somewhere that coursera was unavailable when GoDaddy.com's DNS servers were attacked. Perhaps some emails couldn't be delivered at that moment? Just taking a wild guess, here.
o'right cool, then we should add it to /r/OnlineEducation so everybody knows...
Does anyone know of any good books on Akka?
This is not to be taken as a harsh criticism of Scala's type system. It is widely understood that it has made different design choices and will therefore made some things harder, and some other things easier. In particular, if you don't care about powerful type systems and are happy knowing Scala without writing this kind of seemingly-unreadable code, it's also fine, you don't need to feel concerned -- but the library author down the road might be. The form of higher-kinded programming that is discussed here is very difficult to achieve in most programming language and, barring experimental type systems, Haskell is the only language to have widely developed these kind of techniques. I still think it's interesting to hear about the consequences of various design choices, in particular the way directional type inference affects usability. I would be interested in replies on how to do that kind of generic programming more effectively in Scala, or maybe in demonstration of other, unique points of Scala type system that are unmatched by Haskell and also provide interesting forms of genericity -- I'm thinking, for example, of the interesting mix of object and module system that allows some fairly innovative design patterns and, maybe, support interface abstraction barrier better than equivalent Haskell constructions.
As someone new to both Haskell and Scala, I don't know what's going on here. But it looks like this is all about type inference and if you write out your types none of this matters?
Is a lot of the complications coming from the fact that Scala supports full inheritance? To me that's where a lot of the ugliness comes from, but I don't read Haskell, so I'm not sure I understand the issue...
I have better examples... somewhere, but you can start with how Profs. Odersky and Leroy frame the problem: http://stackoverflow.com/questions/2807629/handling-incremental-data-modeling-changes-in-functional-programming http://stackoverflow.com/questions/2707171/generics-and-constrained-polymorphism-versus-subtyping https://groups.google.com/group/scala-debate/msg/f44a68f2f8a0667c?hl=en http://assets.en.oreilly.com/1/event/61/Structural%20Prototypes_%20Resolving%20the%20Statically-typed%20Object-functional%20Dichotomy%20Presentation.pdf
The [scala-debate discussion](https://groups.google.com/group/scala-debate/msg/f44a68f2f8a0667c?hl=en) is fairly interesting, thank you. It more or less goes into the direction of my previous comment, but doesn't go much into the details (of what Scala does well for "component-based programming"; path-dependent types?), though.
Am I the only one who is annoyed to spoil one of my e-mail addresses to be given a link to a PDF? The intro is not too promising: "There are some things in the Scala ecosystem that will seem like a foreign language to someone coming from Java." — hullo? 'There are some things in language B which seem foreign when you speak language A.' Plus a cook-up of the "deep end", "avoid sbt and scalaz" etc. Yawn. So can we get a direct link to the Martin Odersky interview, please?
Typesafe is not Scala, so Typesafe's growth might be 300%/yr so far. However, if you take out Java from the indeed.com graph you can see that Scala almost doubled from Jan 11 to Jan 12.
This post is a good example of my frustation with a lot of these scala sql libraries. I'm assuming this is a problem with the library and not the tutorial. But the columns are written out too many places. The code is not [DRY](http://en.wikipedia.org/wiki/Don't_repeat_yourself), not even close. How many places are all the columns written out? I counted around 6. How many lines of code would I need to change to add just 1 new column to one of the tables? Why do I have to tell the scala code about information that exists already in both the postgresql schema definition and the scala class/object definitions?
Pretty cool, but I wish there was a theme. Not just "submit any app".
This course just started if anyone's interested. I don't really know much about Scala but I figured it'd be a nice way to get back into programming a little bit(I was learning Ruby some months back but dropped off). Also, apparently I don't know much about Reddit because I wanted to put the link and a comment when I posted it.
Your sum method needs to return an Int (because you said the return type is Int with the ": Int"). Everything has a value now. So a block (some code in curly braces) has a value, it's value is the value of the last statement in it. "if" statements now have a value, and that value is that of whichever block is run. That value also has a type. So if both the "if" and "else" are "Int", then the if is also "Int". If the else returned a String, then the value of the "if" would be the superclass that Int and String have in common, which is the type "Any". But "sum" is declared to return "Int", not "Any", so doing that's an error. They don't want you to use return, but it still exists in Scala. So that code could also be written as: def sum(xs: List[Int]): Int = { var myvariable if (!xs.isEmpty) { myvariable = xs.head + sum(xs.tail) } else { myvariable = 0 } return myvariable } But that's not a functional style, and the course is about functional programming. 
You're doing fine it looks like. The functional approach to programming makes heavy use of recursion and pattern matching so it might get some getting used to but I assure you that the effort is definitely worth it.
Same here friend! I started watching the vids and doing coursework tomororw. Saturdays/Sundays are best for me. Good luck :)
Impressions: * Ah, they renamed `makro` to `macros`. Thank God. * Instead of `toList`, etc, we now have `to[List]`, etc? I love you, Scala developers! Thank you! Thank you!! * Those improvements to Scaladoc sound amazing. Omfg I cannot wait. * Pattern-matching against interpolated strings sounds boss.
The new standard library Scaladocs: http://www.scala-lang.org/archives/downloads/distrib/files/nightly/docs/library/index.html
&gt; Of course, this kind of result is usually useless and I'm pretty surprised that Scala compiler even bothers with that. Well to be perfectly honest, this was my reaction when I read your comment... I don't know Scala much but at first sight this looks pretty useless to me. &gt; val x=while(false){}, val x={class A}, val x={val y=5}, and even val x = while(false){class B} (yup, it compiles!) are all equivalent to val x = () Cue in Keany Reeves saying "Woah."
It does not matter whether the condition `something` yields `true` or `false`, the resulting type of the expression `if (something) {anything}` is always `Unit`. Example: `def test[A](foo: =&gt; A) : A = if (true) foo` error: type mismatch; found : Unit required: A def test[A](foo: =&gt; A) : A = if (true) foo ^ 
Here here Tony.
Cheers, hope it helps someone.
&gt; I totally agree with most of your points but I think you are missing a tiny detail - they are talking about "Scala adoption in your JAVA organization." Have you worked with many Java organizations? Yes, since 2006 I have worked in 5 Java organisations and all of them now use Scala. I also work closely with peers who do same. I have also been employed specifically and primarily to accomplish the task of helping out a Java organisation to move to superior languages (twice). As for the merits of what this report has to say on the overall matter of introduction of Scala, no I do not agree with it (and I should expect, neither do my peers who have experience on this subject). However, this particular disagreement would be a reasonable discussion. I have no problem with a disagreement on reasonable grounds. Indeed, I got to this point of understanding by having *lots* of disagreements with knowledgeable and insightful peers, winning some battles, losing others and adjusting my position accordingly. Unfortunately, I cannot have a disagreement on this particular subject with the author of this report, because the author is clearly under-qualified on many important points. For example, we'd have to first learn what algebraic data type means before we move on to the much harder subject of how to introduce the subject to the curious. Someone who is so utterly confused on such introductory subject matter, and so struggles to explain it to themselves, is going to have a hard time explaining it to others. I didn't miss the overall point. I chose not to address it. They have got it disastrously wrong anyway.
Use code s2040 for 40% off through 9/26
Note that Algebird is interesting not only as an abstract algebra library. It has a couple of peculiar monoids implementing data-stream algorithms (http://en.wikipedia.org/wiki/Streaming_algorithm) - e.g. HyperLogLog for estimating the number of distinct items and CountMinSketch for estimating frequencies (based on https://github.com/clearspring/stream-lib).
This doesn't seem like a very encouraging article. Not what I was expecting from the title. I only skimmed it though. "Thank God Scala doesn't support point-free style" doesn't really seem like it belongs. Hell, most of it doesn't seem like it belongs. It seems more like an article about what dude doesn't like about scala and/or the scala community, than an article targeted at someone's java organization considering using scala.
First, thank you for not taking my comments personally. It is a refreshing change from the usual. Second, let me get my personal motivations out in the air for all to see. This is a purely selfish exercise. I want to be surrounded by people smarter than me. I will work hard to make this the case. In particular, I don't mean people who are more knowledgeable than me -- this is easy and I take this for granted. I mean people who can use their quality of intellect to persuade me on a proposition that I might otherwise hold to strongly (with the footnote of a suspension of disbelief should it be required). Let me agree with you regarding attribution of authority. I retract. At the time, I was really thinking that attribution of authority may be granted by a reader, mistakenly or not. I expect you'd agree here with this revision. I do not think I am nitpicking on words. There is a critical difference between case classes and ADTs. They are completely unrelated. Not only this, I can point to existing confusion in blog posts and artices from beginners who are able to comprehend case classes (multiplication) but are severely confused when it comes to ADTs (summation). The difference is so immense as to be non-existent and the confusion already so prolific that repeating it is almost certain to mislead even further. It is not reasonable to use the two in the same context, except perhaps to say, "constructs that Scala permits." There is no other relationship. As for the point of "avoid category theory." Some will argue that it is taken out of context, because what you are really trying to say is, "when you are learning Scala, you should avoid directly learning the subject of category theory, leaving this for later." Now I happen to violently disagree with this statement, based on the collective experience of myself and my peers. I violently disagree because it is a position that I once held, but I have been convinced that it is far removed from my initial intuition (which I expect, is your current intuition). This would be a reasonable discussion to have -- in fact, now that I know what motivates this position and that I am also confident that it is wrong, I could challenge you with experiments that expose just how wrong it is. Regardless of the outcome, this would be progress. However, putting this aside, I also read "avoid category theory" in the context of your motivations. At this point, let me remind you of my personal motivations -- to take good ideas from smarter people. This "avoid category theory" proposition, when read in context, is very obviously fear-motivated rhetoric. It is exposed later when you admit to your motivations of fear and things that are "scary." The fact is, you have no idea whether or not to avoid category theory, whether that is taken to mean what I wrote earlier (an assumption that I am not so keen to leap to) or as the incoherent proposition that stands on its own. You simply do not know. Why not suspend belief or otherwise until this changes? If your personal thoughts are, "category theory is really confusing -- beginners should avoid this", you expose a large amount of information about your capacity to learn the subject, whether intentionally or not. I would argue that this attitude is very proactively *preventing you from learning the subject matter*. In other words, you are being unfair to yourself here (leaving aside the impact for others) by taking a guess at the difficulty of the unfamiliar subject. This is exactly what I meant when I said, "they [beginners] severely over-estimate the difficulty of the unfamiliar subject, conquer it, then have a laugh at themselves." You are *exactly* that beginner right now, misleading other beginners, intentionally or not. Trust me, there is a laugh in the future if you stick to your goals, and it is fun to have. Not only this prevention of learning for yourself, but as an example, Martin Odersky himself has made propositions of similar absurdity on this subject [citations omitted]. Good Lord, just what is a poor beginner to think now!!? I mean, just how on earth are they expected to learn this subject when they are bombarded with garbage!? In other words, I am sympathetic to your cause. You are confused and you want to change this, but you must also endure poorly-formed, incoherent nonsense in your efforts to overcome this. What to make of it? One camp will tell you, "oh don't listen to that angry guy on the internet who says your report is nonsense -- he is knowledgeable but he is arrogant and doesn't know how to appeal to an audience or beginner." I am not going to address that, but I am hoping to give you a taste of *just how much sympathy I have for the poor beginner*. A lot. Best wishes on your journey of learning. 
With respect, I think the perspective on how to learn a subject by someone who is still coming to terms with that subject cannot be used for serious teaching. You will notice that almost all those who have overcome these hurdles do not hold similar opinion. You will be one of these people some day. Keep at it.
Like this: http://doc.akka.io/docs/akka/snapshot/scala/actors.html#Actor_API
Is there a detailed list of new features/improvements/changes in Scala 2.10?
This was here a couple of days ago: http://www.slideshare.net/dcsobral/scala-210-english 
When I was building my parser, I looked around for other parser code to look at. I found the jgo code, which uses PackratParser. That was very helpful. You might also learn something from my parser efforts - the [Cypher parser](https://github.com/neo4j/community/tree/master/cypher/src/main/scala/org/neo4j/cypher/internal/parser/v1_9) is written using Scala's parser combinator. 
&gt; First, thank you for not taking my comments personally. It is a refreshing change from the usual. Since you must be Tony Morris, this will likely just make you angry, but I can't resist. If people take your comments personally, you should make them differently. You can't control how other people will react to your words (whether or not their reactions are reasonable is irrelevant), but you can control what you say.
Relax. I was parodying silly commentary the whole time. It is very effective at finding smart people; especially those who worked that out. It has lost its effectiveness since the pool has dwindled. I haven't done that in ages. I don't think anyone is stupid, except for two people on this planet, one of which has never written a computer program. I think some people say stupid things sometimes, including me. If you are on the mailing list for pleasantries, yeah keep me in the killfile, but just so you know, I surely am not there for that reason .
Will this be a hassle-free deployment like on Heroku? Nice to see alternatives!
&gt; If you are on the mailing list for pleasantries, yeah keep me in the killfile I certainly will. On scala-user, I don't want technical discussion that's pleasant, just not-obnoxious. That's setting the bar fairly low, and you still didn't clear it. I don't expect you to care, of course. Best wishes.
OK, how many people say SKKKK-AYE-LA instead of SKAHH-LAAA. It seems like fits better.
[Scala in Depth](http://www.manning.com/suereth/) is quite, well, in depth. Other than that most books are mostly for introduction, unfortunately.
Their version of the Java code with futures is quite bad, the correct way to do it is to use a CompletionExecutorService and retrieve each future as it comes back. No need for idle threads. When looked this way, the monadic composition of futures in Scala is much less attractive, which is probably why they didn't want to show the correct Java version. Furthermore, the Scala example is showing aggregation and not composition, so it's not showing any advantage of Scala's monadic futures over the standard Java way. 
Type in the name of any assignment into google and you'll see 20 github repos with solutions (some horrible). Perhaps I'm pessimistic, but in most college classes, more than 10% of the class is cheating in some way. In a class of 100K, I would suspect that there would be 10K cheaters. 
I'd assume the cheaters are wasting their time. They aren't being forced to take the course. And the certificates probably don't have much of a value anyway. I put up my assignments on GitHub. Not with the intention to cheat, or to help others cheat. But its just what I always do, put all my projects up there. Anyway, I took mine down after the email. I'll put it on a private repo soon.
Coursera really wants them to have value. They want companies to hire based on their certifications. Unfortunately they may find this is harder to do for programming than they realize.
I think programming is about the only skilled field where it could work. There are a ton of companies that don't particularly care what your GPA was and only care about whether or not you have passion in programming. The types of people that take courses on coursera for fun is their target workforce. 
What I've learnt is - it is more satisfying to learn from looking at other solutions, but only after reaching a solution myself, even if I had to drag my feet to reach that point. Ever since the third assignment, this has enabled me to look at existing problems functionally(although with very limited knowledge), and be more confident knowing that I'll be able to implement something, however obscene it be might be. As for the lectures, I found it more than sufficient to implement the solutions. Anything more is just flair.
Call me naive ~~niave~~, but what's the point of cheating. The assignments are fairly easy, if one can't get through the class without cheating they should start with a beginners programing class or find another line of work.
Agreed, private repos are pretty damn cheap.
Besides, in coursera, you get free, high quality courses. And the only thing they ask in return is your word you will abide by the honour code. It is very disrespectfull if you don't and you, and many other people, should be ashamed.
hi niave.
Completely agree, not only is it more satisfying, but I think you learn a lot more.
And a poor speller.
nope, see his post. he said "niave" at first. :)
He, being me.
For you, sure; for me the problems are not easy. And if I just can't get one done in time, fine I'll take the hit for it, but how will I EVER know how to solve that problem if I don't "cheat" by looking for someone else's answer? 
True, it is a artifact of traditional education where determining how much someone learned is more important than helping them to learn as much as possible. 
It's not the end of the world, just learn what you can. The certification is fairly meaningless if one gets the answers from someone else. 
Good points, one could start their own class with more flexible rules. I'm no fan of the "your on your own" style of traditional classes. But I'm left with a method trying to ascertain value. Peer grading? Number of useful additions to the effort? Karma points? I think something could work, anything from education research?
Well, you can ask - that's why there is a forum, I suppose...
One more tip, using "last" does what I was hoping it would, gives proper details for the last compile. No idea why "last compile" doesn't .... not that I really know how "last" works anyway.
What kind of syntax improvement do you expect ? 
The kind that doesn't have bizarre, subtle syntactic gotchas like having to have blank lines in certain places, nor syntactic noise like having `package` and `class` show up in the project description file. The project description should not be in a programming language. It should be in a data language like XML, and it should only describe top-level information about the project (what languages it's written in, who wrote it, where the SCM is, dependencies, etc). In this regard, Maven gets it right, and that's why I use it. However, while Maven's idea is quite solid, the implementation is severely flawed. The markup in the POM is horribly verbose, vastly more than it needs to be (apparently the developers are fatally allergic to attributes). The POM's schema also does not allow extension, so everything not defined by the POM itself has to get buried under `&lt;plugins&gt;`. The code is poorly-documented, inextensible, dependency-injected spaghetti, that takes "use interfaces everywhere" to a very unhealthy extreme yet still manages to not be extensible in some areas where it's needed. Still, if I were going to design a build system right now, it would look like Maven minus all the cruft, not SBT or Gradle.
It (hopefully) won't have the aforementioned syntactic gotchas and noise.
I usually end up being the build expert on my teams, though I never get to pick the build technologies. As such, I've been forced to deal with Maven along with several other build tools, and one thing I've learned without any doubt in my mind, is that data languages for build systems are the absolute wrong way to go.
There is the discussion forums in the course.
At work I've used Scala as a scripting language. What I did was auto-load some "framework" classes into the REPL when the user executes the startup .bat file. At that point you can feed commands in from a text file using ":load". Or you can just type them in - same thing. Does that count?
Uncle Ben to Peter Parker (aka ScalaMan) while teaching him Scala: with great power, comes great complexity. I don't think Scala is a great scripting language, in the sense that it is not often appropriate for those use cases where scripting languages are used today. It is a great language for getting things done by invested programmers; it has very powerful abstractions and a high ceiling to play with (even if the floor isn't that low). 
Answer: No.
If you go through the current lectures by Martin Odersky in the Coursera class, you will find that the answer is probably 'no'. At first I was surprised that he didn't make any difference between `def`s (methods) and functions, but then after a while I came to see that it really makes very little difference. There is a section somewhere where he contrasts object encapsulation and "free standing" functions. E.g. adding a `show` method to multiple types versus a `show` function matching types. Both are possible in Scala, and each variant is better suited for a particular scenario. Where non-local context is needed or types are closed and fully visible, use free standing functions; where the type hierarchy may potentially be extended and only local knowledge is needed, perhaps internally known things contribute to polymorphic behaviour, use object encapsulation.
I don't understand type classes, really, but according to [this article](http://blog.evilmonkeylabs.com/2012/06/11/Understanding_Scala_Type_Classes/), they're implemented in Scala with the pattern of a method taking an implicit parameter related to the type of one of its other parameters (or the object it belongs to), like the `sorted` method on `List[T]` needing an implicit `Ordering[T]` in the article's example. Is that all there is to it? `Ordering` is the type class in this case? This seems suspiciously straightforward, which I'm guessing means I'm missing something&amp;hellip;
You're right. I was confusing case classes and type classes. Not sure what I was thinking.
Are type classes really a fundamental feature of functional programming? If not, and if type class is the only complaint being raised against Scala, then the answer to the question as written is "no". 
Yeah, I was specifically talking about the lectures.
First of all you do not compare OOP versus functional programming, because as Martin correctly states, these issues are orthogonal. Even in functional programming you need some way to achieve polymorphism, and generics are not enough. So wether that is though OOP, type-classes, multi-methods, it doesn't really matter as far as functional programming is concerned, as long as it gets along with referential transparency. What I don't get from oppinions like yours is what makes type-classes better than OOP? Because in my view type-classes are not better, they are just an alternative. Sure type-classes are more like open interfaces to which you can add later. That's certainly something you can use in real life. However Scala does precisely that by means of implicits. If you take a look at the collections library, you'll find plenty of instances where types are extended ... for example lists can only be sorted if for the type T there is an implicit Ordering[T] defined. Ditto for map() - sometimes map cannot return the same type, but you can provide a CanBuildFrom that knows how to build a new type from your list and the given mapping function. And so on. When comparing Scala with Clojure or Haskell, you have to realize that Scala is somewhere in the middle. It is a static language, but you can drill holes in that static type system and do things Haskell programmers only dream about. But it also gives you a lot of static safety, while not having the overhead of Clojure. Also, the Scala course has been all about functional programming, with really few exceptions sprinkled. If you would read SICP you would understand just how badly a static functional language needs algebraic data types (versus a LISP in which you can build the whole language on top of higher-order functions). And because in Scala everything is an object, to model such types you must first have some knowledge about objects. And the course did exactly that - explain enough concepts for being able to implement immutable collections.
Structural typing works for some cases, however providing an Ordering[T] is much more general because not all types have an ordering defined and yet you may want to have ordering nonetheless in a certain scope. Also when using structural typing you rely on the fact that both the name and the signature of the method you want is the same on all types. But that's not the case. One type could implement cmp(b) that returns either -1, 0 or 1 and another type could implement lessThan and greaterThan that return booleans.
Well, let's see. Haskell: return 1 Scala: 1.point[({type l[a] = EitherT[Something, SomethingElse, a]})#l] I certainly find one of these easier to read.
The weird "layout" rules = the off-side rule? That's pretty much like Python. And you don't have to use it; you could roll curly braces and semi colons instead. If you'd like. The user-defined operators are not different to functions. That's part of the simple syntax. Just about everything is a function. There's no difference between an operator and a function. And I guess the thing about the parens is a valid point. With so much Python and Haskell, I've become used to not having to write parens so that might be one of the things that put me off with Scala.
&gt; Structural typing works for some cases, however providing an Ordering[T] is much more general because not all types have an ordering defined and yet you may want to have ordering nonetheless in a certain scope. I'd say they are about of equal generality. I forget the exact syntax for structural typing in Scala, but note that you can specify (via structural typing) that the compare method not necessarily be on T: def sorted(comparator: {def compare(a: T, b: T): int})(collection: Seq[T]) &gt; Also when using structural typing you rely on the fact that both the name and the signature of the method you want is the same on all types. But that's not the case. One type could implement cmp(b) that returns either -1, 0 or 1 and another type could implement lessThan and greaterThan that return booleans. Well, I claim this limitation exists also with `Ordering[T]`: You rely on your comparator to implement the Ordering trait (which specifies a fixed method name and signature). In the specific case of the `sorted`, it's probably more convenient to use the `Ordering[T]` technique because: 1. `sorted` is explicitly defined in terms of `Ordering[T]` 2. There is an already predefined `Ordered[T]` trait, and an already predefined implicit conversion between `Ordered[T]` and `Ordering[T]` I.e. the Scala standard library authors have already done all the work for you. But my point was that there are more ways than just traits to implement type classes in Scala, and so if you're question is "Is that all there is to type classes?" it probably pays to know alternative implementations.
Why play and not scalatra or some other option?
I would like to know about this as well.
http://en.wikipedia.org/w/index.php?title=Comparison_of_web_application_frameworks&amp;oldid=515190057#Scala
I have been using Play 2 for a while now. Before, I was a java developer using Play 1, and I quite enjoyed the clean approach of Play 1, especially compared to other java development frameworks. Once Play 2 came out, I decided to learn scala, and start messing around with it. Overall, it is really nice, a solid MVC framework that takes advantage of the power of scala. I don't know how much you know scala already, but I highly recommend you learn how scala works before developing with Play 2. Scala has a hard learning curve, but it is well worth it. Using the standard java programming techniques doesn't suite Play 2 well. Overall, I really enjoy using Play, and use it for my hobby projects. I cannot compare it to other frameworks ans I have never used them. But I can tell you Lift(http://liftweb.net/) is not an MVC framework
Not really sure if /r/scala is the right place for this discussion, but... &gt; The weird "layout" rules = the off-side rule? That's pretty much like Python. Not really. In Python you can only indent or not (or outdent to a previous indentation level). From what I remember the layout rules in Haskell there are frequently multiple places you can indent to that have different meanings. (I might be wrong on the specifics. I just remember that Haskell's indentation rules only had a misleading similarity to the Python rules.) It's also interesting to note that Python requires a colon before an indent *only for readability*. The language would still be unambiguous without the colon. Haskell (as usual) cares more about terseness than readability, and so has no obvious cues for where indents are allowed. &gt; And you don't have to use it; You need to understand it if you want to be able to read other people's Haskell code. Use of layout is pervasive in Haskell code. &gt; The user-defined operators are not different to functions. That's part of the simple syntax. Just about everything is a function. There's no difference between an operator and a function. There's simple for a compiler, and simple for a human. Haskell's rules may be the former, but they are not the latter because one cannot look at an arbitrary operator and tell what its precedence or associativity are. This means that in Haskell one unknown operator in an expression makes the entire thing unparseable. In Python, even if I don't know what behavior a certain operator has been given, I can still parse arbitrary expressions because the set of operators is finite and the precedences and associativities are fixed. (My understanding is that Scala also has rules for figuring out precedence just from an operator's name, making it possible to parse an expression without needing to look up an unknown operator's definition.)
&gt; Not really sure if /r/scala is the right place for this discussion, but... Pah. There are down vote arrows if people don't think a syntactical discussion is relevant. &gt; From what I remember the layout rules in Haskell there are frequently multiple places you can indent to that have different meanings. As far as I know, there are three ways to indent in Haskell: 1. Start the new expression further to the left than the previous expression: this ends a block. 2. Start the new expression at the same column as the previous expression: this continues a block. 3. Start the new expression further to the right than the previous expression: this starts a new block. And that's really it. I think your confusion stems in two facts: 1. It's never stated exactly by *how much* you're supposed to indent. This is pretty much up to the programmer, but after doing Haskell for a while, you will recognise how much it's common to indent for each construct. No code will break if you indent too much or too little, as long as you follow the off-side rule. 2. When outside the realm blocks, you may indent freely, or avoid indenting completely, because all you're doing is building an expression which can be rewritten on one line. Some people choose to align function arguments differently and such, so this could be seen as some kind of strange indentation, when in reality, it's just splitting up a function call over several lines. &gt; It's also interesting to note that Python requires a colon before an indent only for readability. The language would still be unambiguous without the colon. Haskell (as usual) cares more about terseness than readability, and so has no obvious cues for where indents are allowed. The same could be said for any language with a C-like syntax: There is no obvious cues for where you're supposed to put braces. It all depends on what you want to express. The elements in Haskell that require blocks are, however, few. Essentially only the special syntactic constructs require blocks: `let`, `do`, `where`, and `case … of`. That's it. The rest are expressions which can be broken up on different lines haphazardly. The rules are really simple; the problems you have had seem to be related to the fact that the rules are also very forgiving and allowing of artistic freedom. Whether it be good or bad. &gt; You need to understand it if you want to be able to read other people's Haskell code. Use of layout is pervasive in Haskell code. Very good point. &gt; Haskell's rules may be the former, but they are not the latter because one cannot look at an arbitrary operator and tell what its precedence or associativity are. Oh, right. That is true. I didn't consider it because I've never had to read code which I was also not supposed to understand, which includes knowing how an operator functions and its precedence and associativity, and therefore looking it up in some kind of documentation. Depending on your development environment, though, shouldn't looking up precedence and associativity be as easy as hovering over the operator?
Thanks. Good resources. I will have a look at both.
&gt; As far as I know, there are three ways to indent in Haskell: ... &gt;And that's really it. I think your confusion stems in two facts: Based on [this](http://echo.rsmw.net/n00bfaq.html#the-indentation-thing), it's a lot more complicated than that. Part of the weirdness is that the left-most position for an indent is not one space to the right of the indention of the preceding line (as it is in Python, modulo continued lines), but is instead based on the position of the first non-whitespace character after one of the layout-block keywords. Also, lines with exactly that indentation get semicolons prefixed onto them, while lines indented more than that don't. &gt;I think your confusion stems in two facts: &gt; &gt;`1`. It's never stated exactly by how much you're supposed to indent. Unlikely, as this is true in Python as well. &gt; `2`. When outside the realm blocks, you may indent freely, or avoid indenting completely, because all you're doing is building an expression which can be rewritten on one line. Yes, this is confusing. Some indentation is stylistic, and some actually has meaning for the compiler. Python has this problem too, but to a much smaller extent as the areas where indentation doesn't matter are delimited by special characters (parens, brackets, quotes) and the places where it does matter are delimited by a different special character (colon). In Haskell it's only indicated by keywords which look no different from any other identifier, and are typically sandwiched between other identifiers. &gt; The same could be said for any language with a C-like syntax: There is no obvious cues for where you're supposed to put braces. What you're saying is sort of true, but I feel like your conflating writability with readability. Figuring out "where you're supposed to put braces" is a writability thing, and in either language (well, I assume, in Haskell's case) is rarely a problem, because if you just wrote a keyword that expects a block, you know it expects a block. The problem is with *readability*. In C you know a pair of curly braces in a function body is virtually always a block. People don't put curly braces willy nilly in their code. In Python you know an indent after a colon is a block. In Haskell, indentation might be a block, an attempt to avoid semicolons, or purely stylistic, which makes figuring out what you're reading a lot more difficult. &gt; I didn't consider it because I've never had to read code which I was also not supposed to understand, which includes knowing how an operator functions and its precedence and associativity, and therefore looking it up in some kind of documentation. Do you ever have to read code that calls a function, but you don't know the precise implementation of the function? This is the same sort of thing. Being able to gloss over details is pretty much a requirement when working on code that's being developed by many people and/or over a long period of time. If you need to grok every single subexpression of a codebase in order to read it, then you can't build anything of significant complexity. The same sort of thing annoys me in other languages too, by the way. For example, in C++ not knowing whether an identifier is a class name or a function name can lead to certain code being syntactically ambiguous. This is almost an edge case in C++, though, while in Haskell it's pretty much the norm for expressions to be unparsable until you look up the definition of all of the constituent parts. I like to be able to: - tokenize code without parsing it. - parse code without knowing anything about the things it references. - use things (function/classes/modules) while knowing as little as possible about their implementation details. This sort of "hierarchy of comprehension" helps me navigate large bodies of code and get to the bit I'm interested in without having to understand every single line. &gt; Depending on your development environment, though, shouldn't looking up precedence and associativity be as easy as hovering over the operator? Yes, it's occurred to me in the past that with enough tooling, Haskell could be made readable. I'm not sure if this is a good thing or a bad thing. The same could be said of APL, after all. And this doesn't help when trying to read code snippets outside of my development environment. Assuming using tooling is the right approach, I'd like to be able to read code with just my eyes, not my fingers, so "hovering" isn't ideal. One way I was envisioning something like this working would be to have the editor insert "ghost parens" to disambiguate precedence and associativity. It could even have a configuration setting where one could tell it about the precedence rules known to the user (perhaps even just a partial ordering), so it could leave out ghost-parens in "obvious" cases like "3 + 5 * x". (Something similar could perhaps be done for layout, and maybe even sugar like do-notation, where it could show you the braced/de-sugared version of the code somehow.) Coming back to the real world, do you know of any way to get *any* kind of "precedence aware" functionality in Vim?
&gt; Part of the weirdness is that the left-most position for an indent is not one space to the right of the indention of the preceding line (as it is in Python, modulo continued lines) Not the preceding line -- the preceding *expression*. Haskell is a functional language and happens to deal with expressions, not lines of statements! &gt; Unlikely, as this is true in Python as well. I was under the impression that once you had started indenting by four spaces, the interpreter wants you to be consistent with that. &gt; In Haskell, indentation might be a block, an attempt to avoid semicolons, or purely stylistic, which makes figuring out what you're reading a lot more difficult. Could you show me a piece of Haskell code that you find confusing due to the indentation? I've never come across one, although I have been confused when writing indentation myself. &gt; Do you ever have to read code that calls a function, but you don't know the precise implementation of the function? This is the same sort of thing. Being able to gloss over details is pretty much a requirement when working on code that's being developed by many people and/or over a long period of time. If you need to grok every single subexpression of a codebase in order to read it, then you can't build anything of significant complexity. Now it sounds more like a problem of it being difficult to figure out what the operators do based on their name, and not as much a matter of parsing. And that, I would agree with. &gt; Coming back to the real world, do you know of any way to get any kind of "precedence aware" functionality in Vim? Unfortunately, because I've not had this problem, no. But as far as I've seen Vim being bent, it should definitely be possible.
It's less unfair than you think! EitherT is a monad too. An example that's a little less of a straw man: contrived :: Int -&gt; EitherT String Maybe Int contrived x = return $ x + 1 def contrived(x: Int): EitherT[Option, String, Int] = (x + 1).point[({type l[a] = EitherT[Option, String, a]})#l] Ouch. And yes, you can use a type alias instead of the type lambda, but then you have a) the visual clutter of named things lying around that don't really have the significance to deserve names and b) the stylistic difference of two expressions rather than one, and so braces. The first point is the real problem because, for instance, if you're using the function monad, for each function type you use you'll want a type alias lying around so you can easily refer to it. So for each 'Int =&gt; A', 'String =&gt; A' etc. you use, you soon end up with innumerable type aliases corresponding to them ('IntTo[A]', 'StringTo[A]') etc. Of course, things do improve somewhat if we use type parameters for the monad type: def mcontrived[M[_]](x: Int)(implicit M: Monad[M]): M[Int] = (x + 1).point[M] But note we still have to supply the type parameter for point, because Scala can't infer it. And with a *slightly* less contrived example, things get hairy fast: less_contrived :: (Monad m) =&gt; Int -&gt; m Int less_contrived = return . (1+) def less_contrived[M[_]](implicit M: Monad[M]): Int =&gt; M[Int] = ((x:Int) =&gt; x+1).map(M.point(_)) For symmetry, I spent some time trying to write the less_contrived Scala function using the compose method rather than map but wasn't able to get it to compile! Note as well that this doesn't solve the problem of using multi-argument type constructors - in less_contrived, we don't mention that nasty EitherT type lambda but the callers of less_contrived will still have to (or in turn be rewritten to use a generic monad type if appropriate). I understand why things are this way - why there's no partial application of type constructors, why the return type of a method doesn't contribute to inference of the expression fulfilling it - but (to tie this back to the OP) I think that without the OO concessions in Scala these warts would be either absent or at least pleasantly sugared.
It might be too late to enroll, but Martin Ordersky has an scala online class, https://class.coursera.org/progfun-2012-001/class/index. 
Your code is pretty off base. //no need to define the return type for such a short function.It's long, //but you're wedging a lot of type information into one line. def contrived(x: Int) = { type l[a] = EitherT[Option, String, a]; (x+1).point[l] } //This covers your less contrived example in haskell. def mcontrived[M[_]: Monad](x: Int) = (x+1).pure[M] //In case you insist on returning a lambda for some reason def less_contrived [M[_]: Monad]: = (x:Int) =&gt; (x+1).pure[M] //This does not work well and is pretty dumb def less_contrived2[M[_]](implicit M: Monad[M]) = ((_:Int) + 1) map {M.pure(_)} // Ditto. //syntax like this is required to use both less_contriveds. Attempting to use it causes an error. val f = less_contrived[List]; f(5) //Meanwhile our named method can be used in exactly the same way val f = mcontrived[List] _; f(5) //While working properly at the same time. mcontrived[Option](5) Do you not know how to write Scala code? Because your code is overly verbose for what it does.
What libraries are better at this? JVM or other.
I had hope that it would be obvious that stupid little functions with contrived in their name were contrived. I'd included the return types to try and make things more clear, not as some sort of weird chicanery :( Much of the other wackiness comes from stripping this stuff out its original context - of course if you're calling a function directly like that it'll barf when it discovers that 5 is not, in fact, a Monad object, but if you're doing for { blah &lt;- less_contrived[&lt;something&gt;] ... it means you don't have to scatter the partial application underscores hither and thither. It's just a stylistic choice for functions that aren't going to be called directly. This also is moving away from my original point, which is that the poor situation with type inference leads to having to choose between the fun syntax of type lambdas, cluttering the global namespace with type aliases, and duplicate local trivial type aliases, and I think this sucks! I really hadn't thought this was such a contentious issue. The local type aliases in particular really remind me of all the local defs that Python code ends up with in its effort to work around the limitations of Python's lambda keyword. Edit: it's entirely possible my Scala isn't the best. Below is some actual code that I've been wanting to improve for a while; if you could have suggestions for what can be bettered that would be completely awesome. // Assuming implicitly[Monad[Promise]] type EitherTError[A[+_], B] = EitherT[A, Error, B] def validateEmail(u: User): Error \/ String def validateName(u: User): Error \/ String def validateDomain(u: User): Error \/ String // I want to improve this function def userRecord(userP: Promise[User])(implicit details: Details) = for { user &lt;- userP.liftM[EitherTError] email &lt;- EitherT(validateEmail(user).point[Promise]) name &lt;- EitherT(validateName(user).point[Promise]) _ &lt;- EitherT(validateDomain(user.id, email, details.tenant)) } yield Record(details.tenant, user.id, email, name, details.path) In particular, I don't want to have to explicitly provide the type for point/liftM - this is the bit of Scala's syntax that's frustrating me. If you have a better suggestion for a name for the EitherTError type alias that would be awesome too - it doesn't make sense to have it as a local type alias called 'T' or something in this context because it's used throughout the code. Oh, and please ignore that this should really be a function User =&gt; Error \/ Record lifted rather than Promise[User] =&gt; EitherT[Promise, Error, Record] :)
Oh dear. I think we've been agreeing with each other &gt;&lt; I think the language is more than fine - it's managed to get me to stop using Lisps for playing around which is quite a coup. I just really hate this one corner of the language because I keep bumping into it.
Yeah, I hate the syntax for type classes. It is IMO the worst part of Scala.. I'm glad this ended amicably. So few arguments on reddit do. 
Any video to go along with this presentation?
I am not an expert on them but .... Apparently they don't :-( Optimizing Option/Some was the first thing I was hoping for when I saw it (and avoiding allocations in the proces). If it did work, there would still be the limitation that value classes don't work across method boundaries, as soon as something outside the function has to see it, it gets allocated as a regular class. I believe it's mainly targeted at implicit conversions/classes and pimping. Reading through the SIP. It's saying that value classes can't inherit from AnyRef, and for trait inheritance value classes need to use new "universal traits" that inherit directly from Any. I'm not aware of the full implications (though I'm guessing there are many), but this alone would require changing Option to inherit from AnyVal instead of AnyRef. I really hope I'm wrong.
Even if you made Option an AnyVal trait and Some and None subclasses of AnyVal, it would still box them. AnyVals are unboxed only when you know their actual class. Method signature contains Option[T]? Boxed. They're unboxed in methos signatures if you specify the exact type and then you get two methods in the bytecode: a specialized one with unwrapped parameter and a normal one with wrapped: class A(val i:Short) extends AnyVal def f(a:A) {} compiles to public static class A{ public A(short _i){i=_i;} private short i=0; public i(){return i;} public i_$eq(short _i) {i=_i;} } public void f(A a) { f$sp$A(a.i());} //not sure about the actual name mangling public void f$sp$A(short a) {} At least that's my experience from playing with milestone releases.
Makes sense ... Since it's compiler trickery it needs static dispatch at compile time ... so no dynamic dispatch/inheritance, and no escaping methods. Harsh limitations. 
That's where you bump into Maven's principal weaknesses: shitty API and mostly nonexistent API documentation. See, what you're supposed to do in Maven when you need special behavior (like your integration tests) is write a plugin to do it. This is well and good, but you need a good API to do it with or you're gonna have a bad time.
Fair enough. What about having Maven run a script (e.g. via the `maven-antrun-plugin` for an Ant script) as part of its build process?
I really liked his explanation of what "A monad" is: An instance of Monad class/trait/type. :-)
It was a single script. I was just laying out how simple the things were that we needed to do, and pointing out that instead of ~4 lines in some Scala/Groovy/Foo build-tool DSL, we had a ~4-line script wrapped in 130 lines of XML (I just checked the pom). That's the cost of data-only build configs, and the scripting/declarative impedance mismatch.
I don't suppose you'd be willing to show me said XML?
Thanks. When I figured that out suddenly monads seemed less like magic to me.
My only question left is, was adopting it 3 and a half years ago irresponsible or ahead of the curve?
I think Scala / TypeSafe has outgrown the need to receive 'endorsements' from ThoughtWorks.
If I understand you right then I mostly agree with you when considering this from the perspective of the maturity of Scala and TypeSafe. However, Scala is still relatively new and there are a lot of shops that are pretty settled in their ways. This kind of thing (the tech radar) can be used to counter the typical FUD you'll find around approaching new (for some arbitrary shop) technologies like Scala in places that are stuck in their ways.
If it helps...here's the blog post that finally helped me understand what a monad actually was. http://www.codecommit.com/blog/ruby/monads-are-not-metaphors
Very nice read, thank you.
Originated here https://github.com/lrytz/progfun-wiki/blob/gh-pages/CheatSheet.md
Hi, op here. What you didn't find satisfying?
One problem is that it only mentions the things that already exist in Haskell.
Not entirely true. Anything that helps grow the ecosystem is a positive. If it helps knock more conservative places off the fence on to the Scala side, that's hopefully more people paying Typesafe or other consultancies for support/development which benefits all of us. Hell, maybe one day in the distance future the Eclipse IDE won't suck. While I agree that it shouldn't need it, and that any forward thinking place wouldn't have been waiting on a Thoughtworks endorsement. Never underestimate the mind blowing amounts of relatively backwards tech houses, and while you might not have to deal or care about them, having hopefully some of their money flow through the Scala ecosystem is a positive for all of us. 
The "Please Enable JavaScript" page is amazing.
Welcome to the 21st century. Times have changed since 1994. Do you have Apple stock? If so you're in for a big surprise!
I didn't know what Spray was, so figured out it is [this](http://spray.io/).
This is a very good and detailed blog post. Thanks.
Great post. Subscribed
Scala for the Impatient is very good, esp. as in introductory text. There are links to various scala books at http://capecoder.wordpress.com/
I enrolled on it after the course finished though and until a few weeks ago all the lectures were still available.
I took this, did most of it but then lost interest - I was disappointed with most of the assignments except the sets implemented solely in terms of functions one, that was good. (It reminded me of the Church numerals and similar FP mind-fuckery). Most of my disappointment stems from having read the first few chapters of SICP already and recognising the same problems and exercises. I guess my expectations were somewhat wrong going in.
There's a lot of learning material online for free, for example the Coursera course https://www.coursera.org/course/progfun and many many books, if your evil you can bittorrent them, if your good you can buy them if you don't want to be evil or good but just lazy there is a whole book here! http://www.artima.com/pins1ed/ 
Scala's is worthwhile, its just when you get into functional and you hear words like covariant and contravariant and monad, it seems annoyingly like Math. However, some of these concepts are actually very simple but just with complex words. 
I actually completed Martin's online course. It was how I got started with Scala. Tons of fun!
OO is why how I got completely turned off to any kind of serious programming. Languages like Scala, Clojure, and Erlang have me seriously finding the time to learn. friggin' OO
What's wrong with OO? I really don't understand people who say they hate OO... Though I do understand people who don't like Java and it's AbstractSingletonNuggetFactoryFactory. For that matter, Scala is a hybrid OO/functional language. It's one of the things that attracted me to it, and that I didn't like about the brief overview I read of F#.
there is nothing wrong with it; the way it was taught to me (in secondary school, and poor books) turned me off to programming completely at the time.
I don't think co/contra variance is related to functional programming?
What are you looking for? Walkthru of the functor, applicative, monoid structures? I think best way to start is with Staircase book and Horstmann's Impatient Scala, and trying lots of things in the REPL. If you're through the Coursera class, then Suereth's "In Depth" book
Will give it a read, though my Haskell is not very good.
Cool! I've yet to install and try it, but was just wondering about how to improve my use of vim on Scala.
It's probably stuck in the overly paranoid spam filter. Message the moderators by clicking on the "message the moderators" link in the sidebar (it's in the upper right corner of the "moderators" box)
Not all OOP languages are created equal. Unfortunately people learn OOP as used in Java or C++, instead of being exposed to the more pure version of OOP as presented by Smalltalk or CLOS. I think that universities teaching Java as an introductory language are doing a great disservice to society.
other scala learning link collection - http://www.quora.com/Scala/Where-can-I-find-a-tutorial-to-learn-to-program-in-Scala/answer/Hasan-Ozgan
Don't read too deeply into this post; it's just an interesting approach to supporting arbitrary function composition into units of work to be executed by a contextual interpreter. Could you clarify how this post demonstrates cognitive dissonance? Specifically, what is the inconsistency between the philosophy and the approach? To address your points above: &gt; To me the value of dependency injection was always questionable. Even more so in a functional context where you can test pure functions more easily and completely than complex objects. Dependency injection is no more than passing an argument to a function, whether it is pure or not. Separating argument-passing from functional contexts would be a false dichotomy. &gt; So the whole argument of making it easier to mock disappears. No argument is made in this post regarding mock objects. &gt; Scala support side effects. So why not use them in the context of initializing dependencies, a reasonable use of side effects if there is one. Why resort to monads? For adaptability and portability. Units of work can easily be composed with different sets of dependencies, and can be executed under different environmental contexts. &gt; In fact, I am seeing more and more post and articles about Monads in Scala, yet they often fail to justify their use. This post is not those articles. &gt; In Haskel, they make sense, that's the only way to do certain things because of purity. But in Scala it's not clear. Is this some sort of purity envy? Some find this approach useful. I suggest you give it a try; you might find it interesting. If not, that's ok too!
Striking at 8:45 of the video: 71 students took the course from Afghanistan. Were these Afghans or foreigners?
Could someone give a link directly to the video on vimeo? The embed doesn't seem to work for me.
They could very well be Afghans. The ICT industry is becoming more and more important in the countries of the middle east. I work part-time for an IT consultant who works for an organisation responsible for holding IT courses for people from troubled regions all over the world and his experience is that there have been a fairly sudden influx in participants from the middle east the last few years.
Be sure to watch the last like 10 mins of the video, the questions+answer part is the most interesting (for those who already know about the things to come in Scala 2.10); some very interesting questions + replies
I tweeted to Martin Odersky, and he answered: "Afghanistan is the first country in the list. Maybe some people who were just too lazy to scroll down." I had a few hours good hope for that country. Back to reality.
Thanks for posting. As a recent "graduate" of Odersky's class, it was interesting to see the resulting statistics. Much of the talk was a little over my head, though. I'm still hacking on the basics.
Good talk, but I felt he went too quickly - would have helped to explain the code a little bit more.
TL;DR ORMs are really bad so here is my API for mapping objects to relational databases
What is the point of putting together such a vague and hand-waving list? &gt; Step 1: start using all those great resources on the internet! Actually, I'm stuck on this because he didn't tell me to turn on my computer first.
Does anyone recognize the windows console replacement he's using (with the M icon in the top left of the window)? I'm just looking for something with colour for ScalaTest without going the full cygwin route.
Thanks! 
Somewhat off-topic: Does anybody know anything about the fate of anti-xml in Scala 2.10? Last i checked (in August), Martin Odersky was talking to Daniel and the lead developer of ScalaXML about the possibility of integrating on of the two libraries. But i haven't heard anything in that regard ever since.
Actually, [here](http://www.infoq.com/news/2012/11/next-jvm-language) is a bit of background about the poll. Of course, "bias-free community-based insight into trends &amp; behaviors" is wishful thinking with this kind of polls; but perhaps there are some other interesting aspects to it, e.g. seeing the ballots of some more prominent exponents of the PL landscape, as well as how people pick or group multiple languages. It is a bit annoying that the table view is hidden unless you submit a vote yourself. Currently it looks like this, sorted by number of votes: Option Adoption % Code Votes ------------------------------- Scala 77% 71% 513 Clojure 76% 72% 438 Groovy 82% 72% 389 Java 8 54% 62% 388 JavaScript 82% 70% 332 JRuby 74% 63% 190 Erlang 61% 58% 116 Jython 65% 54% 103 Kotlin 54% 49% 92 Scheme 57% 52% 76 Xtend 65% 51% 75 Ceylon 52% 49% 73 Mirah 56% 41% 55 Fantom 49% 45% 50 Unsurprisingly, Scala is leading, followed by Clojure. Not sure, why JavaScript is so high in the list; are people really thinking Rhino or rather JavaScript outside-of-the-JVM (which is not the question asked)? Finally, there is a [heatmap](http://www.decidify.com/draggable/2/poll-radar/8/) for Scala, although the raw data set would be more interesting.
Looking at the latest heatmap Scala, Groovy and Clojure are the big names closes to the centre. Java 8 trails, and interestingly is scoring quite low on % of new code which will be written in it. An update on latest numbers (apologies for shoddy formatting): Option Adoption % of Code in New Language Votes Details Scala 77% 72% 551 Heatmap Clojure 75% 72% 461 Heatmap Java 8 54% 62% 414 Heatmap Groovy 82% 71% 406 Heatmap JavaScript 82% 70% 352 Heatmap JRuby 73% 63% 204 Heatmap Erlang 61% 57% 125 Heatmap Jython 64% 54% 110 Heatmap Kotlin 53% 47% 99 Heatmap Scheme 57% 53% 82 Heatmap Ceylon 50% 48% 81 Heatmap Xtend 65% 52% 81 Heatmap Mirah 54% 43% 62 Heatmap Fantom 48% 44% 54 Heatmap 
They should have included Java 7/6 as well since it will most likely be the only option for most people reading infoq.com. 
The first question for Martin Odersky in the [parkbench session](http://skillsmatter.com/podcast/scala/park-bench-discussion-3621) addresses the development post 2.10; the general answer seems to be that follow-up versions will mainly deal with stabilising and optimising existing features.
F-Bounded Polymorphism is amazingly convenient. https://github.com/BlueScale/BlueScale/blob/master/src/main/scala/org/bluescale/telco/api/Joinable.scala Is an example of how I've used it to allow multiple types of Joinable to interact with each other in a side affect free way. Wouldn't be possible otherwise to do (a, b):(A,B) = a.join[B](b) and have join be a member of the Joinable trait both A and B implement. (Joinable is implemented by a media stream or a sip endpoint(sipphone, etc) in my case)
Thanks again to the Jetbrains guys. I think the popularity of Scala has more to do with the IntelliJ Scala plugin than many realize. This plug-in is the main reason I started using IntelliJ in the first place.
Some insight about its reason. https://github.com/csenol/2.10.0-RC3-Benchmark
Thanks for this!
I guess this is one of the best ways to learn [Scala](https://www.coursera.org/course/progfun) The course just finished, but it will start again next year.
Yes, there is that. There are a lot of things I've often said, "If they ever ask me "X", the interview is done"... but I've never done it. I HAVE, though, being polite, decided that after the interview that I would never work there for one X or another.
Somehow that was WORSE than a powerpoint presentation.
I'd like to hope that, with Scala, we have no need for crap like Spring.
Going to have to agree there. Using Spring with Scala sounds about as useful as preheating a microwave. Even if you do need dependency injection that can be reconfigured at runtime (which you probably don't), use Guice or something.
Isn't this the same as Akka?
It gets worse. My company doesn't use it because it is too fancy. We use EJBs instead. My last day there is 31 Dec. I'm looking forward to Spring. 
Modern Spring with Java Config isn't too bad, actually. I agree with you w/regard to the XML config, but Java or Java/Annotation hybrid isn't horrific. I still prefer Guice though. 
Can we all be in agreement that if we use Scala in our workplaces that we simply revolt against anyone wanting to use Spring? I mean both Guice and SubCut are better alternatives than Spring IMHO.
I thought the most notable part of it was that they're trying. :) A lot of features in Spring are workarounds for the limitations of Java and simply aren't necessary in Scala. I've never liked using Spring as a framework, but I do find it has a lot of useful libraries buried with int, such as their [JdbcTemplate](http://static.springsource.org/spring/docs/2.0.x/reference/jdbc.html), wich makes working with JDBC actually nice.
Why all the Spring hate? I've just started embracing it. However, I've not used it with Scala as its just not the Scala way. 
Another [interpretation](http://jaxenter.com/spring-meets-scala-the-injection-spring-needs-45832.html) of the move. &gt; This is more an admission that Scala’s inexorable rise meant Spring had to reach out and create a project surrounding it, with demand so high amongst its community. In the past two years, more and more companies are switching to Scala, so its natural to see this happen. It’s just slightly strange to see it happen after Rod Johnson left to join Typesafe’s Board of Directors. Perhaps it was in the works beforehand?
Is there a way of executing the IO stuff without calling "unsafePerformIO"? In Haskell, I try to avoid (explicitly) calling functions that start with "unsafe" - because you know, they're not safe.
You could make a trait that extends App and calls unsafePerformIO on the value in its body, right? (Assuming Scalaz doesn't already have that.) This would make something somewhat analogous to the main function in Haskell.
I understand that this is what they are trying to do, but adhering to a convention only works so long as what you are doing fits into the category that the convention was designed for. In this case, "unsafePerformIO" has different semantics and use scenarios from Haskell's version of this function, so it is misleading to give it the same name.
You don't have to lecture me on the value of functional programming and how it allows you to create abstractions that allow you to compose bits and pieces together nicely; I am well aware of this. However, abstractions that make perfect sense in one language do not necessarily make sense in another language --- at least, if you intend on using them in the same way. In this case, the IO monad does not make sense for general side-effectful work in Scala because if you are going to do that, you may as well just write the code in plain imperative style because it will be cleaner. Having said that, you have convinced me that the IO monad makes sense in Scala for the case where you want to build up an IO action piece by piece before executing it so that if something goes wrong you can abort the entire action by never executing it in the first place; I agree that in this context it could make sense. Edit: Fixed typo
This blog entry has been tweeted and discussed on Scala mailing lists in the last days. It presents a technique for achieving the same goals as **method overloading**, but without some of its problems. As such probably many people have used this approach before (including myself), but the nice thing is to *name* this approach ("magnet") and to provide a thorough discussion of it. Instead of defining multiple overloaded versions of a method, a new type is introduced which wraps all possible method argument types. Like a type class, implicit conversions are provided for the possible underlying method arguments. That way problems are avoided: (a) impossible combinations due to **type erasure**: def foo(f: Future[Int]) : Unit def foo(f: Future[String]) : Unit // no! (b) lifting the overloaded method(s) into a **function**: def show(i: Int) : String def show(d: Double) : String show _ // no! The article also discusses implications such as having different method return types, and limitations such as added verbosity and loss of named arguments or empty parameter lists. In conclusion, the approach offers both advantages and disadvantages and appears "somewhat orthogonal to traditional overloading".
Agreed. I think a better example would have been what we are seeing in this blog post but interleaved with processing from other monads than IO. This way, the compositional benefit would be more apparent. 
Shameless plug: I wrote a post on how to easily parse JSON with dynamic methods - [Beautiful JSON Parsing in Scala](http://www.furidamu.org/blog/2012/09/18/beautiful-json-parsing-in-scala/)
What happened to RC4?
They realised it was broken as soon as they released it, so went straight to 5.
The paper is from spring 2011
Hmm, Play! 1 could not handle our growth unfortunately. We did a Play!2 migration (which can be a huge pain) right after launch and it has served us very well. Scala ftw. 
first! (how lame... :) In related news, I'll add that Futures and Promises have been used in one way or another in many Scala libraries. This new abstraction is supposed to unify existing use under a common API.
As much as I like Scala, it *is* too complex.
Just incase you don't follow any of the other places this has been posted. IntelliJ is, IMO, the best Scala IDE, and the paid edition has awesome Play 2.0 support.
I don't think anyone believes it's simple, or would ever make that claim with a straight face these days (perhaps 3 years ago Martin may have held on to that notion). The worthwhile discussion is trade offs. 
Not being simple and being *too* complex are completely different things.
Obviously calling something *too complex* is context-dependent. In the context of software development, I consider anything that is not simple to be too complex.
I think you are thinking at a syntactic level. I would not call Python or Coffeescript powerful languages. Syntactically you can accomplish a lot with each line, but as a design tool I think they fall flat.
Meh. Just because some monkeys pretending to be programmers wouldn't know an implicit view from a banana doesn't make it Scala's fault. Catering to stupids serves only to hinder those of us that aren't stupid.
So in other words, if something is at all complex then it is automatically *too* complex.
Christ, I'd hate to have you on my team.
Nothing wrong with being non-stupid. "Bluntly speaking your mind" is usually the same as being an arrogant asshole. There are different ways of voicing your opinion, and usually the most effective one (especially when working in teams) isn't calling others code monkeys because they don't understand some aspect of a language. You might be the world's best coder, but if you act as abrasively as you did in your previous comment it won't really matter since nobody will want to work with you.
Then it is fortunate that I made the comment anonymously on Reddit, and not in front of a team. :)
Well, that's true.
You are missing the point. The staging thing is not useful. It should not exist. It is unnecessary complexity. Even if some people do need it, they should have to turn the stupid thing *on,* rather than forcing me to turn it *off.*
"git commit -a" does not remove the staging area. It misses deletes and you still end up dealing with the staging area when resolving merge conflicts.
&gt;git encourages a workflow where you review what you want to be part of the commit before you make the commit, rather than blindly committing all changes without looking over them first. Blindly? What the hell kind of workflow involves committing changes you haven't even seen? Anyway, if there's a need for review of the changes, that's what diff and shelve is for. That still doesn't explain what Git's staging does that is so wonderful as to necessitate it being a core feature.
My bad, you're right. It's git add . that misses deleted files. git commit -a misses new/untracked files. The staging area still doesn't go away with git commit -a unfortunately.
You can compile Python into JavaScript so it suffers from the fact that it can be compiled to JavaScript. Kind of retard this argument when you think about it, isn't it?
I don't see what the big problem is .... Sometimes being able to hit a few tables, get them translated to case classes without involving a Java library might be deemed convenient, even useful.
It's somewhat closer (not having used it) to SQLalchemy's SQL Expression Language than a full on Hibernate-esque ORM. Still, ORMs with mutable state make me sad. 
The speedup would need to be pretty dramatic to make up the difference (immutable maps in Scala are only slightly faster than Ruby): http://capecoder.wordpress.com/2012/07/29/scalamapbenchmark/ Java 8 will be adding parallel support too... In a multithreaded backend env. Java collections are typically accessed from many threads using all the cores anyway...
They have a few commonalities and differences: LINQ basically consists of the syntax additions they added to C# to allow writing "SQL-like" code and the *lifting* infrastructure to get AST representations of these queries. For some implementations you don't need the lifting, like for their collection classes which received the appropriate implementations via bog-standard extension methods (`Select`, `Where`, ...). For others you need lifting (I'll get back to that later). Scala's for-comprehensions were in the language from quite the beginning and Scala's collection libraries support the required interface (`map`, `filter`, ...) natively. They are quite similar to Haskell's do-notation or C#'s LINQ. So while you look only at collections, they are both quite similar (although other details not related to your question make Scala's collection superior to C#'s collections). When working with external data-sources like databases (LINQ is not limited to working with databases) you have the issue that you need to convert the code you have written in your programming language into a query the database understands. C# got such functionality when they added LINQ: When you talk to a database in C#, the compiler returns a lifted representation of your LINQ code (basically a limited form of an AST) to the corresponding LINQ-to-SQL/-Entity/-XML adapter which knows how it can convert the compiler's representation of the code into a representation the external data-source understands. Scala basically didn't have lifting functionality until now. That's the core point why Slick was considered inferior in the past. The next version of Scala which will arrive in ~2 weeks (against which Slick is compiled) features macros which are way more general and have a lot more diverse use-cases than C#'s approach. What Slick basically does is adding an implementation of the for-comprehension "interface" backed by macros which let you do pretty much the same as in LINQ, although – like with collections – it improves on what LINQ does in some ways already. Additional improvements are Scala's type macros which completely eliminate the need to do any sort of mapping, code-generation, etc. So basically specifying the database connection string will be enough in future versions of Scala to talk to external data-sources in a statically typed fashion. Given a table like this: create table coffees(id int auto_increment, name varchar(255), supid int, price double); All you need to do in a future version (not 1.0.0) of Slick is something like this: object Db extends Macros.H2Db("coffees") val all = Db.Coffees.all val brazilian = Db.Coffees.insert("Brazilian", 99, 0) DB.Coffees.update(brazilian.copy(price = 10)) println(Db.Coffees.all) TL;DR: Querying techniques in Scala prior to 2.10 where inferior to LINQ, 2.10 closes the gap and adds a few improvements, 2.11 and future versions will be substantially superior to LINQ. To compare the approach to language design and evolution both languages take, I'd say that C# is mainly driven by a substantial number of ad-hoc additions to the language (LINQ, extension methods, properties, async, ...) with limited but focused use-cases, while Scala gains a very limited amount of more general abstraction capabilities (implicits, macros) with a wide range of possible applications.
Many thanks for raising this here, and thanks for the nice explanations. One thing I am curious about: LINQ has the interesting feature of being able to query not only IEnumerable and IQueryable, but also IObservable. [exciting feature](http://themechanicalbride.blogspot.co.il/2009/07/introducing-rx-linq-to-events.html) Does it have any parallel in Slick? That would be really exciting. 
Interesting. I'll probably give it a try on my next project. I'm not saying Slick is bad, just that I've never been really excited about having to use ANY ORM.
&gt;efficient SQL queries I could have written myself that way. This is the key point that a lot of the pro-ORM arguments miss. Sure, ORMs make abstraction and type safety work. But look at the queries that get generated when doing anything more complicated than a "select * from table" query in JPA. Not only is it sometimes atrocious, but it's totally hidden from you and you'll never know that you're hitting your database with 1000 queries instead of a single hand-written one until you're trying to scale your app up, which is usually too late.
I really wouldn't call Slick an ORM, most presentations of Slick's creators even start with "what's wrong with ORMs". Edit: Interesting point made on the Slick mailing list: https://groups.google.com/d/msg/scalaquery/Zqessupzc9M/bVWMONqPc7YJ
You misunderstand me. My problem is that it's non-constructive. So what if ORMs are bad? What would be better? "A fundamental redesign" is a nothing answer. You could just as well say "something else that I like better".
Thanks! I will look and try. Having a unified syntax, applicable to both databases and event streams, might be incredibly useful in the analysis of event streams. Typically, an initial statistical analysis of an event stream is performed in an offline manner with a database copy of the stream. Applying the conclusions in the online world usually involves some adaptation/duplication of code (together with bugs and incompatibilities). If one could represent the analysis by some kind of 'Query' objects, which apply transparently in both situations, it would be a very satisfying solution to that problem.
I favor cleverness over clarity.
None of what you said is true. You can select just several columns rather than the whole object "select c.name, c.order from Customer c" http://bwinterberg.blogspot.hk/2009/08/how-to-query-several-properties-with.html Since you write your queries in Hibernate Query language, you know what queries are going to execute on the database, you know exactly what is going to happen. Its not totally hidden from you, nothing is hidden from you - its your lack of understanding of it that is the problem.
There is no burdensome code generation, you write the code in Java with JPA annotations, this generate the database. You *can* go in the other direction if your crazy enough to, but thats not a good idea. What exactly is the ORM tax?
Give an example of what you cannot express in JPA which you can express in your database? Then tell me why you need it? In the majority of cases you don't need those feature of the database you cannot express with JPA, or you should be using stored procedure for those edge cases. Also I will tell you that now you are tied into a specific database and you cannot migrate to a new database vendor. So while your totally embedded with SQL Server, the competition using Hibernate/JPA has a larger choice of database vendors due to the standard JPA. We had to support Oracle AND SQL Server, JPA was a good choice and worked well. For edge cases we used stored procedures for very specific edge cases such as calculating tree data structure containment. I was a senior server developer and I can tell you with over 15 years experience of programming, JPA solves a lot of problems you face if you go standard JDBC. Why do you think they created it in the first place when we already had JDBC?
Seriously, think about what you said "Don't repeat yourself: All the necessary metadata, table and column information, data types already exist in the database. Use it, instead of trying to duplicate it into the code." If your code is dependent on the database structure and your queries are JDBC strings, when you change the database schema, you going to have a LOT of broken code. You are repeating yourself, your SQL code in strings is a repeat of the database structure. Once you change the database, all your SQL code breaks and has to be re-tested. Testing is hard due to databases being mutable. If you have the entire schema in one place, JPA annotations and classes then when you change the code the changes go to the database and the code is type checked. Imagine what happens when you rename a column in the database in your case, you have to search all SQL queries, and you un-typed code which gets that column will break and you don't know it at compile time. Imagine the problem if you do a major database change. Think! ... your crazy
&gt; Once you change the database, all your SQL code breaks and has to be re-tested. That's great, because my code base wouldn't have a single line of SQL code. &gt; If you have the entire schema in one place, JPA annotations and classes ... No, you have it in two places: In your code and in the database. &gt; ... then when you change the code the changes go to the database and the code is type checked. Just interested, could you show me how you magically manage to migrate your data in the database when you make changes in your code? &gt; Imagine what happens when you rename a column in the database in your case The IDE puts red squiggles under the effected parts of the code a few milliseconds after the change to the database occurs and (ideally) offers the appropriate refactoring? What you say makes no sense, at all. Do you see me anywhere suggesting to use strings? Using strings is even worse for type-safety. Did you even understand what Slick and/or type providers are supposed to do in the future? Did you read the comments in the rest of the thread?
&gt; In the majority of cases you don't need those feature of the database you cannot express with JPA I guess the database vendors just put them in for fun right? &gt; Also I will tell you that now you are tied into a specific database and you cannot migrate to a new database vendor. The current API already manages to cover sequential collections, parallel collections (`scala.collection`), Hadoop-based collections (Scoobi and friends) and multiple database vendors (Slick) with support for NoSQL databases planned for the near future. What was your point again? &gt; I was a senior server developer and I can tell you with over 15 years experience of programming Judging from what you write, I can tell you that probably every DBA in your last 15 years cringed when he saw your code talking to his database. &gt; JPA solves a lot of problems you face if you go standard JDBC. "Sucks slightly less" makes neither of them great, not even good. &gt; Why do you think they created it in the first place when we already had JDBC? They tried to build something better? (Hint: They pretty much failed doing that. The main difference between JDBC is not that JPA is *slightly* better, it is just that JPA is horrible in different ways.) 
When you use actors with Scala 2.10 you'll need to include the akka-actors JAR. Each Scala release will be bundled with a particular version of the JAR but it should be OK to use any 2.1.x version of the JAR (I think). More concretely here's how I think it would work: Scala 2.10.0 is bundled with akka-actors-2.1.0.jar. If you write a project with actors you'll need to have a dependency on Scala 2.10.0 and on akka-actors 2.1.0. Later, when Akka 2.1.1 is released, you can keep the dependency on Scala 2.10.0 and just update the akka-actors dependency to 2.1.1. (The [migration guide](http://docs.scala-lang.org/overviews/core/actors-migration-guide.html#step_5__moving_to_the_akka_backend) also talks a little about the dependency on Akka 2.1.)
I never criticized Slick, read my comments, I suggested that JPA/Hibernate/Toplink is good and people criticized that. I defended that because it works well and its a mature solution. People seem to think that ORM's are evil because they don't understand them.
I honestly prefer squeryl over slick. I'm running the git version of squeryl and the syntax is just much better. Sadly in both there are no implicit joins on foreign keys like there are in linq. (You always have to specify what you are joining on) Squeryl has this functionality sort of but it doesn't turn it into a join but a select within a select instead. 
Writing raw sql becomes a huge pain when your project ends up having 1000's of different web method calls which all run different sql queries. Then you have to manually convert the results into some other object. Especially when the dev team starts being retarded and doesn't write a general method to do so. (Which also does not work out well because it assumes the SQL you are writing will match all the time, and there is no compile time checking which introduces way more bugs) Most SQL queries should not complicated, and if you start writing ridiculous long and complex SQL statements to get data there is something wrong with your database design in the first place. A good project if it uses an ORM will code first using the ORM and grow their database that way instead of defining a database schema outside and then writing an ORM to suit it. 
Akka 2.1 has a dependency on Scala 2.10, which [imminent](https://groups.google.com/forum/#!msg/scala-internals/3R7xTJhcN0I/iXCcem0Ejp0J).
Have you ever used a ORM? There are so many cases of them being successful.
Yes, otherwise I wouldn't have an opinion about it.
You can take a look at the commits https://github.com/scala/scala/pull/1823/files . I am no expert but there is a recurring theme of @tailrec being used a lot. If some one could explain how / why this is better. I know the JVM does not support tailrec , but the scala compiler does. How does the scala compiler optimize this call ?
Awesome, I think that's a good route at this point
The github pull request has a lot of commits. The point doesn't APPEAR to be tailrec removal, but rather replacing for comprehensions and some other loops that create temporary anonymous inner classes (that's how scala implements closures) with simpler loops that don't need a memory allocation. This commit in particular has a bit more explanation: https://github.com/paulp/scala/commit/6a288b632e0e78a96f1298be9b4e8231728183af
I should think the scala compiler should be able to determine if a method is tail recursive without requiring the annotation. Maybe I'm being to optimistic though.
Why are we trying to make language creators into gods?
In short: The IntelliJ Scala plugin now uses an appoach very similar to [Zinc](http://blog.typesafe.com/zinc-and-incremental-compilation) (1) it fires up a compile server which keeps scalac "warm", using a tool called [Nailgun](http://www.martiansoftware.com/nailgun/). That basically does away with the need to use FSC which had various problems. (2) it uses the SBT incremental compiler API which uses source based heuristics instead of byte-code analysis as before (the blog outlines various advantages of source-code based analysis for Scala). I had been using the [idea-sbt-plugin](https://github.com/orfjackal/idea-sbt-plugin) before this new architecture, because it was much faster. I just tried to switch back to "built-in" IDEA compilation in one project. It compiled the whole project in 75 seconds (sbt from console took 67 seconds), and a successive incremental took 23 seconds (sbt in `~test:compile` took 27 seconds), so they are pretty much the same speed. The analysis in that case was not very accurate, as I made a change which did not affect any other class (I fixed something in a ScalaTest class), but the incremental compilation picked up 23 files (instead of just 1), so this is something that needs improvement on the SBT side. I found that with existing IDEA projects, in order for the new settings (called "external build") to take effect, the best is to wipe the `.idea` and `.idea_modules` directories, and re-create them with the [sbt-idea plugin](https://github.com/mpeltonen/sbt-idea) v1.2.0. IntelliJ IDEA seems to get confused when you do this while its running (even if that project is not open), so make sure you quit IDEA, wipe and re-create the project files, then re-launch IDEA. There are still advantages of using the sbt console from IDEA, e.g. configuring your build file, easy interface to run specific tests, etc.; on the other hand, IDEA's native compilation is now on par, and the formatting of compilation warnings and errors is better then through the sbt console.
Scala is huge for DSLs as well.
I use and like both. Groovy is obviously better for scripting, though. I also think that Scala is pretty good for DSLs.
The biggest competitor will always be just plain Java. Imagine if Java gained some decent syntax sugar for closures, tuples, and such. All eyes are on Oracle as stewards of Java and the JVM. (Personally, not loving how they're handling things so far.) &gt; the most dangerous enemy of a better solution is an existing codebase that is just good enough
I'd say it's more Clojure or Scala, but Groovy is cool too.
+1 for Scala. And it is quite good for multi-core programming using the Akka framework, I think Akka has the best documentation for any open-source library I have seen.
That's [James Strachan](http://macstrac.blogspot.com/2009/04/scala-as-long-term-replacement-for.html): &gt; Though my tip though for the long term replacement of javac is Scala. I'm very impressed with it! I can honestly say if someone had shown me the Programming in Scala book by by Martin Odersky, Lex Spoon &amp; Bill Venners back in 2003 I'd probably have never created Groovy. Note that James has moved on from Scala and he's now an [active committer](http://blog.jetbrains.com/kotlin/2012/04/kotlin-m1-is-out/) for the [Kotlin programming langage](http://confluence.jetbrains.net/display/Kotlin/Welcome). 
It seems to me that both Scala and Groovy had had their shot at being a replacement for Java and it hasn't happened (and they are both quite old (ten and nine years old respectively). The "Java.next() language" title should be awarded to languages that are more recent (e.g. Clojure) or maybe not even released yet (Kotlin or Ceylon). 
Scala, because **[Play](http://www.playframework.org/)** is awesome.
See also my awesome [blog post](http://blog.richdougherty.com/2009/04/tail-calls-tailrec-and-trampolines.html) on the topic. :)
I'm very excited for this release. Lots of great stuff, especially the Actor lib and Future/Promise standardization. 2013 will be the year of Scala.
My favourite new features are value and implicit classes (~-&gt; extension methods)! No more guilty conscience for using implicit conversions!
Love the "small" things, like implicit classes and `???`, making life so much easier and reducing boiler-plate. But above all, I'm excited to see what people will be doing with macros... And crazy things with string interpolation...
How do implicit classes ease your guilty conscience? They're just syntactical sugar for a class/implicit function pair.
You are right. It's the combination with the value classes that is in effect extension methods for Scala. Meaning that implicit methods will no longer cause the creation of a wrapper object.
If only they could wrap more than a single primitive :-(
I get that bit ... I'm guessing I don't understand the practical limitations of how you actually implement value classes. You'd still need to alloc/wrap at function boundaries and when you lose type info, and it's much more complex than the single primitive example, but I don't see any hard reasons why you can't do the following: Note: Disregard the purpose of the function etc., just trying to include a few types of operations you'd do on these strange struct like things. def doStuff : Vec2 = { val a = Vec2(1, 2) val b = Vec2(3, 4) val c = a * b val l = length(c) c } which decodes to def doStuff : Vec2 = { val ax = 1; val ay = 2 val bx = 3; val by = 4 val cx = ax * bx; val cy = ay * by val l = sqrt(cx*cx + cy*cy) Vec2(cx, cy) } On further inspection I guess wouldn't play nicely with anything that also wasn't a value class, as any interaction with anything that isn't a value class would involve an alloc. 
I hope that's not like the year of the Linux Desktop!
Can someone please explain like i'm 5: a practical use for value classes and implicit classes? I don't get it from the release and SIP documentation. Thanks in advance.
**Value Classes** allow you to 'tag' types without the runtime cost of allocating a wrapper class. A (rather stupid) example: class Frequency(val cps: Double) extends AnyVal { def toSeconds = new Seconds(1.0/cps) } class Seconds(val value: Double) extends AnyVal class Test { def waveLength(f: Frequency) = 340 * f.toSeconds.value } Now when you do this in the REPL and look at the byte code of class `Test` : &gt; :javap -v Test ... public double waveLength(double); Code: Stack=5, Locals=3, Args_size=2 0: sipush 340 3: i2d 4: getstatic #13; //Field Frequency$.MODULE$:LFrequency$; 7: dload_1 8: invokevirtual #16; //Method Frequency$.toSeconds$extension:(D)D 11: dmul 12: dreturn ...you see that only primitive doubles are passed around, there is no instantiation of either `Frequency` or `Seconds`. So wherever in your source code you instantiate `Frequency`, essentially "nothing happens". When a method belonging to `Frequency` is called, e.g. `toSeconds`, instead a static method is called which takes `Frequency`'s value (the underlying `Double`) directly. You get type safety (a frequency cannot be mixed up with a value in seconds) and type specific methods without any performance disadvantage. . ------ **Implicit Classes** reduce boiler plate when producing extension methods. Before you needed to write: implicit def RichDouble(d: Double) = new RichDouble(d) class RichDouble(d: Double) { def hertz = new Frequency(d) } This pattern was called "pimp my library", because you needed to write a conversion method (`def RichDouble`). Now you just write: implicit class RichDouble(d: Double) { def hertz = new Frequency(d) } 16.hertz.toSeconds.value // -&gt; 0.0625 So this class is really semantically easier to interpret as a container for extension methods. . ------ Finally, you can **combine them**, giving you extension methods with minimal performance costs: implicit class RichDouble(val d: Double) extends AnyVal { def hertz = new Frequency(d) } which should also eliminate the `RichDouble` instantiation. In the first case (no value class): class Test2 { val x = 440.hertz.cps } 8: ldc2_w #23; //double 440.0d 11: invokevirtual #28; //Method .RichDouble:(D)LRichDouble; -- this instantiates RichDouble 14: invokevirtual #33; //Method RichDouble.hertz:()D In the second case (value class): class Test3 { val x = 440.hertz.cps } 5: getstatic #22; //Field RichDouble$.MODULE$:LRichDouble$; 11: ldc2_w #28; //double 440.0d 14: invokevirtual #33; //Method .RichDouble:(D)D (*) 17: invokevirtual #36; //Method RichDouble$.hertz$extension:(D)D (*) This still seems to calls the enrichment method (`implicit def RichDouble(d: Double) = ...`), although returning straight a double, so that's probably a no-op(?).
**EDIT:** ninja'd by Mit_Taste_E, I started typing this when his answer was only about value classes. Consider this Scala 2.9 code: object QuerySupport { implicit def string2query(s:String) = new Query(s) class Query(val s:String) { def execute():Result = //something } } Now you can use your strings like this: import QuerySupport._ "some query".execute() Notice that the implicit conversion from one type to another (here from String to Query) is pretty long: implicit def string2query(s: String) = new Query(s) class Query(val s: String) { ... You prefer to write less code, don't you? So since Scala 2.10 you can simplify those two lines to: implicit class Query(val s: String) { ... You can still use `Query` class as a normal class everywhere else. Note though that this line: `"some query".execute()` is equivalent to this piece of Java: new Query("some query").execute(); While Hotspot most likely won't allocate the object on heap, still allocating it even on stack is a waste of time, especially since it probably won't be used after this. And I don't know where Dalvik would allocate it, so to be safe, you can declare your class as a value class: class Query(val s: String) extends AnyVal { ... While this class can no longer have any other fields, from now on if the compiler knows that a value is of type `Query`, it will store it as a reference to a string, without creating any objects of class `Query` (if the compiler tries to store a `Query` in a variable of type `Any`, or even in an array of `Query`s, it will wrap it anyway). Thanks to that, this lines: var q1 = new Query("some query") var q2 = new Query(null) "another query".execute() /* var q3: Query = null // won't compile, vals/vars of value types cannot be null */ compile now to an equivalent of this piece of Java: String q1 = "some query"; String q2 = null; Query$.MODULE$.extension$execute("another query"); Notice no allocations of any Query objects. Combine both for extreme awesomeness: implicit class Query(val s: String) extends AnyVal { ... 
&gt; This still seems to calls the enrichment method (implicit def RichDouble(d: Double) = ...), although returning straight a double, so that's probably a no-op(?). Adding `@inline` to `hertz` method and `-optimize` to compile flags removes even that, but I haven't tested it much.
Wow, thanks for the ellaborate reply. Will digest all of this in due time! Thank you.
Thanks for this incredible reply, all made sense to me. Truly appreciate your patience.
Since I'm on it, I'll tell you why value class arrays don't work well. `Array` is the only generic class that does not suffer from type erasure. That is, if you have a compile-time type `Array[T]`, you have also a runtime type `Array[T']`, where `T'` is an erased type of `T`. This has all to do with internals of JVM and history of Java. Therefore, if you make your custom value class for unsigned ints: class UInt(val toSigned: Int) extends AnyVal then arrays of these cannot be stored as `Array[Int] == int[]`, because they would lose type information. Therefore, Scala uses an array of *boxed* values: `Array[UInt] == UInt[]`. So creating a new array of custom value type leads to an array of nulls and every value stored in that array becomes boxed: scala&gt; class UInt(val toSigned: Int) extends AnyVal defined class UInt scala&gt; val a = new Array[UInt](3) a: Array[UInt] = Array(null, null, null) scala&gt; a(0) java.lang.NullPointerException Compare with an array of a built-in value type: scala&gt; val b = new Array[Int](3) b: Array[Int] = Array(0, 0, 0) scala&gt; b(0) res1: Int = 0 Fun fact: arrays of `Unit` have the same problem in older Scala versions, but not in 2.10. Scala 2.8 &amp; 2.9: scala&gt; new Array[Unit](3) res0: Array[Unit] = Array(null, null, null) Scala 2.10: scala&gt; new Array[Unit](3) res4: Array[Unit] = Array((), (), ()) For similar reasons, if you have a class that is specialized for `Int`s, it won't become automatically specialized to `UInt`s. Also, you can't specialize type parameters of generic classes for your custom value classes. 
This might be the absolute worst designed site I've ever seen.
I first thought that this was an ad for an upcoming course. I eventually realized that the thing on the right was an unloaded flash movie.
they should change their name from London Scala Users' Group to Scala London User's Group ;-)
In the SIP discussion, Martin Odersky writes why he thinks this is not a good idea: &gt; Allowing @implicit on toplevel classes would force the compiler to open every class on the classpath to check whether there's an implicit flag on the class. Clearly, that's impractical. Anyway, what would be the advantage to have a top-level implicit class? You also cannot declare top-level functions (hence no top level implicit functions). I find it always good to import implicits from a particular scope, otherwise not just the compiler but you yourself run into the risk of loosing track of them. The question is also what top-level means. With anything you are going t o share, you will have at least a package definition. You could also use a package object to contain your implicit classes: package object mystuff { implicit class RichInt(i: Int) { def isPrime = i &gt; 1 &amp;&amp; (i == 2 || (2 until i).forall(i % _ != 0)) } } Then package mystuff object MyApp extends App { (1 to 100).filter(_.isPrime).foreach(println) } 
&gt;Allowing @implicit on toplevel classes would force the compiler to open every class on the classpath to check whether there's an implicit flag on the class. Clearly, that's impractical. Yes, I read that. It seems incorrect; I would think it only has to open every class that's currently imported (including the implicit imports of the current package(s), `scala._`, `scala.Predef._`, and `java.lang._`). And it *does* have to open every non-top-level class that's currently imported. &gt;Anyway, what would be the advantage to have a top-level implicit class? If I'm writing a package with a bunch of them, this would let me put them in their own source files, instead of having to put them all in one big `package object`. &gt;You also cannot declare top-level functions (hence no top level implicit functions). Indeed. I don't much like that, either, but I can at least understand the reasoning&amp;mdash;you can't very well knit together a single JVM class from the top-level functions defined in any number of source files. In this case, `package object`s are a good compromise: they let you make what *looks* like a top-level function, but such functions in any given package must be collected into a single source file (or, more specifically, a `package object`) and compiled into a single JVM class (`package$`). But I don't understand why we can't have top-level `implicit object`s. If we could, then implicit class MyImplicit(x: String) could desugar to class MyImplicit(x: String) implicit object MyImplicit extends ((String) =&gt; Foo) which if I'm not mistaken would work just as well as a top-level `implicit def`. &gt;You could also use a package object to contain your implicit classes Indeed. And I'll have to. But it sucks, as I said.
Serialization &lt;-&gt; Deserialization of trusted data. ORM. Encryption &lt;-&gt; decryption. Compression &lt;-&gt; decompression. Any abstraction over a trusted protocol will do.
two questions: * why no student discounts? :-( * will there be vegetarian food options?
It's useful because they compose: if I have a bijection from A to B and another from B to C, I can compose them to get one from A to C. This allows you to build up bijections from smaller pieces. This also applies to *container* types, so if there's a generic way to for example deal with sequences and maps (there are), then that applies to any bijection: if I have a bijection from A to B, another from B to C then I can also, without any extra code, get a bijection from sequences of A to sequences of C, say. This ability to compose bijections is what makes this treatment of the idea so powerful.
Right, but if you replace "bijection" with "function", everything you said remains true. The benefit of this library is that you get the calculation of the composed/lifted inverse for free -- but how handy is that actually in practice?
Student discounts: because there's no budget for them. There might be a need for student volunteers, though. Vegetarian food: hell yes!
Sounds interesting, but when will the topics of the talks/workshops be announced?
https://github.com/twitter/bijection/issues/41 For "bijections that are bijective", yes, they can be very useful. They compose under a semigroupoid with an identity (category), they also provide a product operation (aka: zip) and there is a homomorphism to the Lens category. I could go on, but this alone is incredibly useful!
Tony, if you have a miserable life, why do you need to share it with others? Being socially impaired doesn't excuse for this style of "discourse". Have a look at some of the more constructive criticism, that even led to a successful pull request. We all agree that bijective is the wrong wording here, and that perhaps also some of the implemented "coercions" are bad. But being arrogant doesn't change anything. One of my favorite John Cage quotes: "How to improve the world (You will only make matters worse)".
SIP-14 (Futures &amp; Promises) is back ported in upcoming [Scala 2.9.3](http://www.scala-lang.org/node/26255) maintenance release.
It looks like SIP-14 is just a fix for the previous Futures, which is definitely something that was needed. Correct me if I'm wrong.
Are you fucking serious mate? You have no idea how much idiots like you crack me up! No I am having a fucking ball. PS For extra giggles, I would be super interested in knowing what style of "discourse" you refer to and that a miserable, socially impaired person like me cannot afford insight. 
SIP-14 *is* what is new in Scala 2.10 (and in the back port). Scala 2.9.2 had a Future type in the actors library (which is deprecated now), while other projects invented their own versions of Futures. This is from the SIP: &gt; This is particularly evident due to the fact that within the Scala ecosystem alone, several frameworks aiming to provide a full-featured implementation of futures and promises have arisen, including the futures available in the Scala Actors package [4], Akka [3], Finagle [2], and Scalaz [5]. &gt; The redesign of scala.concurrent provides a new Futures and Promises API, meant to act as a common foundation for multiple parallel frameworks and libraries to utilize both within Scala’s standard library, and externally. The limited [Future(s)](http://www.scala-lang.org/api/2.9.2/index.html#scala.actors.Futures$) type of Scala-Actors did not have Promises and [a lot of the API of scala.concurrent.Future](http://www.scala-lang.org/archives/downloads/distrib/files/nightly/docs/library/index.html#scala.concurrent.Future), including the configurable blocking handling (`Await`). Here are two more pointers - https://speakerdeck.com/heathermiller/futures-and-promises-in-scala-2-dot-10 - http://skillsmatter.com/podcast/scala/futures-and-promises-a-new-take-on-concurrency-in-scala-2-10
There's no excuse for people being confused about what monads are good for when clear, straightforward and accessible papers have existed on that for TWENTY YEARS. (Philip Wadler and many others)
They haven't been useless in your java work, you just didn't notice. Monads are used to some extent all day every day by every java programmer on the planet. Whether you choose to acknowledge and exploit this is a property of your motives, not any technical matter.
What I was trying to say was that making fundamental composition rules explicit is rarely a mistake. Are we on the same page?
&gt; Actually both bijections and functions do compose (form a semigroupoid), however, what we have here in this library is not bijective and for whatever you want to call it, does not compose. You seem to be saying that "compose" == "form a semigroupoid". You can form a category of injections or left invertible functions in exactly the same way, though...
I am just meaning the term "compose" as I understand the OP to say it. Yes there are other categories.
Not exactly. Yes Java programmers use monads all day, knowingly or not. Indeed, some instances are built right into the language. However, in some cases, it is the absence of insight into the utility of monads (insert X here, not just monads) that causes Java programmers to reach for inappropriate tools. In other words, there are practical consequences for ignorance of some basic structures of computability (note that "monad" is just one of many, that gets all the undeserved attention). Please note that monads are language-independent. They can be exploited in Java to some extent -- to which the language or type system itself hinders. Pushing the type system of Java (and implementing many monad instances) is the thesis of [Functional Java](http://functionaljava.org/). Failing to gain this insight has direct detrimental consequences for the Java programmer, whether it is known or not.
Is there a way to download Odersky's Coursera course as slides or videos instead of enrolling? It would be useful so that, you know, you can learn RIGHT NOW rather than on some arbitrary date selected by Coursera... 
The date is finished. You can do the course anytime now. It's now just a repository.
You need to be logged in, then there is a button to [class archive](https://class.coursera.org/progfun-2012-001/class/index) -- not sure though that you can access it with any login or just if you had signed up for the course. I guess the former should be fine?
Have you logged in and registered for the class? Working fine for me: http://imgur.com/FTzhJ
It seems it doesn't work with my newly created accounts. On the other hand, using the bugmenotme@mailinator.com/qwer1234 login found on bugmenot it works. It looks like you need to enroll before a course ends, and I guess someone enrolled the Bugmenot login. It sure takes real idiocy to design a system like this... 
Could you please tell me that login?
This was cute- I think it was pretty much the exact path I took as well (although I haven't gotten too much into Slick or Squeryl yet).
Glad you enjoyed it!
Seems pretty accurate so far. I'm at step 5 :)
i would :)
There is definitely interest, and some work already being done. Programming in Scala, written by the language creator is largely written in this manner. Atomic Scala, which is in beta, is trying to teach Scala as your first language.
Awesome, thanks. I'll take a look at Atomic Scala. I think I own Programming in Scala. (The Steps and the Flowers Book) Scala as a first language is quite a stretch, I'll be interested to see how it works out.
I think anything that brings more people into the community is going to be a good thing. I don't have a Java background so I feel like there is a lot of things, particularly from an 'enterprise' standpoint that I don't know and would be better served in my endeavors if I did.
I would be interested in such a book. More so, a Scala book for non-JVM developers would be best.
Is it just me, or the logo actually looks very much like Haskell logo? http://www.haskell.org/haskellwiki/Haskell (check favicon as well)
Looks like a Scala'ish Lambda to me, and since Haskell also chose to work with the Lambda symbol, they unavoidably share similarity. Perhaps using Scala's red colour will make it more distinct?
It would be good to put the original authors always at the beginning of the re-posts. I like to know who wrote the article before reading it or scrolling to the end. Perhaps also the original link.
Definitely. I learned Java (properly) after and because of Scala myself. A lot of the warts in Scala come from Java compatibility and history, so there's definitely room for explaining these idiosyncrasies to newcomers. Stuff like java vs scala collections, primitive types, etc. I do think developers approach the language differently though. In my experience, either the OOP aspects "click" first, like if you're coming from Python or C++, but seasoned Ruby devs first find common ground in closures and first-class functions. Completely non-scientific observation of course. I believe comparing to what is already familiar to the reader has value: "Know Python? Here's how Scala classes work, keyword args and default parameter values, imports and packages, etc etc". I've got some notes drawing up a simple cheat sheet of sorts comparing common Python idioms to Scala kicking around somwhere. I'll dig it up and post it. 
I'd like this both for learning the language itself, and learning how to run/compile Scala programs. I'm used to Python/Ruby (click the file) and C# (click Run in VS) on Windows. No experience with Java IDEs (Eclipse and IntelliJ), and there seem to be too many hoops to jump through on those environments, and so far guides assume I know how this Java stuff works.
The relevant git repo is here: https://github.com/stevan/moe
And the relevance (apart from general PL-ness) is that it's written in Scala.
Ah yes, apologies. I should have mentioned that. :)
More information on this would be awesome! Coming from a Java/Groovy/C# background my Scala code is ugly as sin. It's very easy to fall back into the more 'classic' OO style and write Java-with-Scala-syntax (which is a huge gain over straight Java, I feel I'm missing out on the real power of FP). If you haven't seen it http://twitter.github.com/scala_school/ was the first place I found that approached Scala from a non-Java POV. It me a bit.)
( ͡° ͜ʖ ͡°)
Hi, very nice article ! :) but font-faces sucks. I had to edit the css to read your article (on chrome 21 on windows). 
Introduction to the Art of Programming Using Scala by Mark C. Lewis is a very good approach which bypasses java entirely. In addition, the author has posted a lot of videos on YouTube. The web site for the book is www.programmingusingscala.net. I have purchased the book from amazon and am very happy with it.
Thanks! Downloading now
Thank you so much!
( ͡° ͜ʖ ͡°)
Huh...why on earth wouldn't they available for new users?
I'm really enjoying the author's articles on Futures, want to find an excuse to use them now
Thanks, very thoughtful of you.
Thank you, who knows when or if they will offer this again
Ah do you already use Scala 2.10 in your projects?
Yeah I'm quite lucky that my job lets us have quite a lot of autonomy in technology choices :) 
Could someone put the materials on some other file sharing service? For whatever reason, Dropbox just keeps giving me the finger.
What a great course. Thanks for sharing this.
Agreed. The font was really causing me to squint, and I gave up after a couple of paragraphs due to eye strain.
We *are* hiring so if you can work in London, pm me
Thanks!
oh, wasn't aware of this. I use FF with NoScript add-on. That gives me a boring but readable serif font for that page (JS disabled).
Fuck you. This is illegal.
did you try clicking thru link?
Um, no, using `Try` is not "usually preferred". It's a newly introduced, different approach to exception handling that is better behaved under some circumstances (like the given example of actor messages). Sometimes you need to have a single object represent either success or failure; sometimes you don't. Just like everything else in software, you should only use it where it makes sense. Trying to shoehorn it into every situation where you'd otherwise use exceptions, like making all of your methods return `Try` just because you think that is the Right Way To Handle Errors&amp;trade;, is just going to annoy me if I have to work with your code.
`Try` is particularly needed when exceptions cannot be immediately handled. That is the reason why they are prominently used by Scala 2.10's futures, and consequently in systems build on top of futures, such as Akka dataflow or actors.
I wonder why Hewitt is such a big deal. I tried to read his papers, looking for proper formalism behind actors, but they are such a horrible mess. Am i missing something?
My opinion of TomTom has just improved considerably ;)
Hope they let me take it again :)
And rightly it should be an uphill battle. It's a great language, much better than java, but the tools are immature, buggy and slow. I'm sure I'll get downvoted by misguided fan boys but these are cold hard facts.
Not sure if I agree with you but have an upvote for raising a good point. Tooling should definitely be considered when choosing a proglang. I did one year of scala professionally, using Idea as an IDE, and it was not that bad. Code completion, instantaneous compilation feedback, jump to definition, etc.. it seemed to work rather well and it's basically the only functional language to have a decent IDE support (with F# perhaps). 
Sounds interesting. I've sent you an email.
Just curious: Are you having trouble finding Scala engineers? Are you willing to import engineers from Europe?
I do hear good things about intellij but I am have been too dumb to get it running. I'll put some serious effort in at some point and see how I go.
You probably need to edit the startup script to point it to your JDK. Having trouble getting IntelliJ itself running or the Scala plugin?
It is kinda hard to give an objective answer to this type of question. I am certainly not an academic so I cannot say I run in those circles, but possibly more so than his framework it is the dialog created to help solve an inherently difficult problem. Also, I don't think that any of the major models in use today could be considered a canonical representation of Hewitt's Actors. I don't think any one can fault you if reading his papers didn't change your life. Are you looking for a secret sauce or more of a way to model actors on paper to reason about a system you are building?
This [website](http://www.42go.com/index.html) is awesome. I'm not sure if this is a real company or just a website parodying other tech startup websites. Either way it's got some classic elements. * Not immediately obvious what the company does. Even when you click the learn more button on the home page it starts telling you about who is working in the company without ever telling you what any of these people actually work on all day. They also spend quite a bit of time explaining what technologies they use, but what the fuck do they actually build with these technologies? Will you hire me to just perfect my own red/black tree implementation in scala? * Everybody's "accomplishments" include 1) the last thing they were working on, 2) they a wife and two kids and 3) some other random fact no one cares about. * Everything about [The Culture](http://www.42go.com/culture.html) page is classic, including the existence of a culture page. Complete with obligatory photos of engineers writing on a white board while laughing -- something about a camera just makes software developers draw hysterical math equations on white boards. One critique: they should have wrote a more complicated diagram. They've also got the standard "working while sitting on a lawn and giggling photo". And the picture where everyone's jumping... what can I say? lol * The [Benefits](http://www.42go.com/culture.html#benefits) page is also pretty boss. This is where we find obligatory photos of ping pong and frisbee. Honestly, these photos were too hard to find and not obvious enough. I am disappoint. Side note: no mention about salary or time off on the benefits page... * The [Join Us](http://www.42go.com/join_us.html) page says that prospective employees should "care deeply about providing value to customers and developing a service that can evolve and improve quickly"... uh, what service? Hard to care about your customers when you have absolutely no idea who they are. Yes I would like to work for your company because I am deeply passionate about vague ideas and doing work to solve unknown problems. * The CTO's blurb: "After exploring the vast tech galaxy, Eishay co-founded FortyTwo to change something that’s fundamentally wrong with the universe — **the Web.**" ... Damn this stupid internet! lol -- I'm sure there's plenty that can be fixed with web development, but the way that is worded is just classic. Sorry, I'm not trying to be mean, it's honestly a very professional web site and looks like a fun company, but one must admit the site is pretty cliche.
I started out with working through the exercises in [Scala for the Impatient](http://www.amazon.com/Scala-Impatient-Cay-S-Horstmann/dp/0321774094).
I have actually looked at Scala School, as well as a couple of other posts online. I haven't and perhaps should read a book. If I have to point to *one* thing that I find confusing, it is ready scala code. As for building a project any tips for frameworks or types of applications?
A great thing about Scala is its REPL, so you can try different things as if it's just a command line. Initially, the REPL and simple single-file projects is the way to go. Scala shines with its collections (Lists, Maps, etc, and functional additions onto those). Get comfortable with common Scala patterns (the book is great for this). My favorite web framework is Play!, but there are several to choose from. However, it will be overwhelming to try to learn Scala and Play! at the same time.
This is great. Thanks!
To start with, you have a huge head start knowing all about classpath, IDEA/eclipse, maven central, configuring hotspot GC, etc, but almost nobody learns scala in a week (Maybe if you're already really good at C++ and haskell). I saw this HN thread yesterday, was thinking of how to not get people to give up, I'm convinced this guy just didn't have enough of a support group (meetup/user groups, taking coursera, asking on stackoverflow and beginners list): http://news.ycombinator.com/item?id=5096523 -------- You need to read the source of some projects (the collections libs are good), learn the REPL and how to read type signatures thoroughly, learn common shortcuts (App trait, underscore wildcards, when periods, parens and braces are optional, upper/lower case for constants/variables, and "=" before method body is *not* optional). Then start porting/refactoring other people's spiders or analytic code, or your own sysadmin/logfile cutting code. I recommend 3 books, the Staircase (2nd edition), Horstmann's "Impatient" and Suereth "in Depth". In Depth is a pretty dense book, save that for later but read his 30 rules on the inside covers. Also flip through Impatient and read carefully the sidebars in "TIP", "NOTE" and "Caution". There's a huge amount of good advice on stackoverflow if you google on "learn scala", and twitter's effective Scala 
Oh, you're asking. Program a lot in Scala. 
Good tips. Thanks.
Cool! Is this your project or you just found it? 
Why have a username/password at all? Why not just have the author of a bug/comment/whatever be the author of the commit that created that bug/comment/whatever?
I'm a new graduate about to start another Scala job in another startup. I'll have the freedom to choose which aspects of the project to tackle. In your opinion, what sort of project parts would make me more attractive as a backend engineer in the future? I know this is a vague-ass question, but it's kind of hard to phrase. 
It's my own project. Thanks for the 'cool' :)
Well multiple users can login into your running server. So, a username is required so that the commits have the username as author name. I realized that a username is not required for a single user, but it's definitely needed for multiple-user support.
Oh, I thought each person would be running the server locally, just like they each run git locally.
Here are a few pointers in developing for open source. * Create a GitHub account, and start following some active projects. This gives you a feel of the workflow of open source projects. GitHub is very simple to use even for beginners. * Learn to effectively use git. Although GitHub is easy, git is NOT. I still get surprises with it even after 3ish years of working with it. * Most projects (even gitstick) have a contributing section with guidelines on how to contribute. It's really important that you follow these on a per-project basis. * Once you've cloned a project, check out the GitHub issues, and start working on them. You can also check in-code tasks which are essentially comments with a TODO or a FIXME (just do a `git grep TODO` or `git grep FIXME`). Try to fix or implement the issue. Don't worry too much about the quality of your code; as long as you follow the project guidelines, project maintainers will give you comments on what can be changed once you submit a pull request. [Here's](http://codeinthehole.com/writing/pull-requests-and-other-good-practices-for-teams-using-github/) an article on submitting good pull requests and good practices.
Ticgit is actually designed that. Users from different machines just can't connect to your server. This actually annoyed me, as people who don't know how to use git (like QA for example) simply couldn't work with Ticgit. I developed gitstick as a solution to this very problem.
Can you talk a bit about the pros/cons of using this vs. github's issue tracker, or maybe something like redmine or bugzilla? Or, maybe it's mostly that I don't know about distributed bug tracking, any resources you think are worth reading up on? 
Let's say you wanted to track bugs without using GitHub or BugZilla. This is usually the requirement for organizations that do not open source their code. One solution would be to host your bug tracker on a website internal to the company. This slows down the entire process of bug tracking, as you have to login and update the tracker. Also, you can't access the tracker when you're outside the company network or have no internet access. Gitstick solves this problem as the bugs are just part of the source code, but in a different branch. You don't even need a repository to track bugs using gitstick; just start it in an empty folder and it creates a repository that only contains bugs. Another interesting problem is that you can't see who changed what issue in GitHub (okay you can, but there's usually not enough information). Gitstick tracks every change to every bug as a commit in the repository, so you can use `git blame` or just view the log. There are actually quite a few distributed bug trackers out there. [Fossil](http://www.fossil-scm.org), which is a distributed SCM, actually integrates bug tracking with the SCM. [Ticgit](https://github.com/jeffWelling/ticgit) and [Bugs Everywhere](http://bugseverywhere.org/) are also similar tools. However, Gitstick is actually the only one that supports multiple users via a single web interface. Also, you don't need to know how to use git to use gitstick; just use the web interface to track bugs. 
Nice code. Just had a look at the majority of it. The Ticket class seems quite scary - lot of mutable state happening, or am i misreading it?
I think you can tell a lot about the culture of a company looking at these websites, even you don't think they are that sincere. In this case, it seems like they are an idealistic bunch who have a very niche view of the world. Since they are working with Scala, I'm guessing they are working on either financial (though better to be in the UK) or web backend problems.
Note: originally content was published at http://nurkiewicz.blogspot.gr/2012/11/becomeunbecome-discovering-akka.html
Would be helpful if you could provide some usage examples in the README
Yeah I am planning on doing that. This was pulled from another much larger project that I am working on and I just wanted to get it out there, and will work on getting the docs up to snuff later.
Hi all, I'm the author of the library and I'd love to hear your feedback, especially if you've found the library useful in your project. I'm also interested in any suggestions for additional boilerplate (in the standard library or otherwise) that you'd like to see eliminated with macros. These macros are compatible with 2.10.0, and I'm currently working on a version using type macros (for 2.11.0-SNAPSHOT) that entirely eliminates all of the boilerplate, here you can see a comparison of [before](https://github.com/dicarlo2/ScalaEquals/blob/master/core-test/src/main/scala/org/scalaequals/test/Point.scala) with def macros and [after](https://github.com/dicarlo2/ScalaEquals/blob/ScalaEquals-Paradise/core-test/src/main/scala/org/scalaequals/test/Point.scala) with type macros. (As a side note, the before uses both equal and equalAllVals macros to test their interoperability, in case anyone is wondering why only equal wasn't used.) Soon the type macros will emulate everything in case classes (namely, copy and product) with the exception of producing a companion object, as that isn't supported right now. Anyways, thanks for taking a look at the library!
On a related note, is there a better alternative for RMI-style connections (i.e. synchronous request-response)? Can Akka be used for this?
This offer is just for today so I have to choose tonight *gulp*
Too bad there isn't a part two of this course yet
Please, Bill, please take on SBT and "Make it obvious, guessable, or easy to remember". Please! Why does it have to use this weird config format that blows up when you don't leave and empty line, rather that the excellent typesafe config. Why everything is named %, %%, :=, &lt;&lt;=, ~=, &lt;+=, &lt;++=...
Returning Option[Collection[_]] is something I personally don't like ... how is None different from Some(Empty)? Just return the collection type, which may be empty.
This looks excellent! I love seeing projects that highlight the practical use of macros, and automatic generation of equality methods definitely fits this bill.
Took this course the first time around. Really recommend it.
we have some great people in the team, im kinda looking for maybe 1 more experienced, a medior and a couple of juniors, it was a battle for me to use it again this time round, mainly as its hard to recruit for!
You can always use a Java one: http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/collect/Multiset.html
I did not know the Guava libraries, they look interesting, thanks.
I feel ashamed that i did not think about using a HashMap[Int,Int] for counting (I was also given that advice elsewhere). I tested it and worked very well, in the machine i was testing it took only 9 seconds! (using a mutable one in a not very functional way). I tried the TreeSet also :) , i decided to settle with the BitSet because i thought it was awseome to store a set of non-negative integers like that :P I had not heard of Trove collections before, i will take a look at them. Another thing I noticed while doing this exercise is that recursion is more expensive than i thought so. I guess procedure callings is expensive after all. 
Very good introduction to Monads. This will save me hours from having to explain it to my friends trying to come up with examples on pastebin/github. :)
Is this a common theory on the matter? I was just made a decision without real logic behind it here and would like to hear peoples opinions on the matter.
This guy is a superb author and I'm thoroughly enjoying the content of these blog posts. Keep them coming Daniel! :)
Thanks for the kind words! Rest assured that I still have a couple of articles planned for this series. :)
I want that five minutes of my life back.
Of course I would share, :) (sorry for the delay in replying :S) [Here](https://gist.github.com/redoacs/4724082) is a gist of it. I think i could have used the get methods that return Option's to simplify the code. 
Congratulations, and thanks for all your hard work! So far my favorite new features in 2.1: * New Scala JSON API * New Filter API with built in CSRF protection * Scala concurrent Futures
Could you explain that. I used Play 1.5, which used JPA, so my example probably would be different for 2.x. For example in Play I might have a model Task. I have controller with a static method getAllTasks() that calls Tasks.findAll(). In order for this to work I have to have a JPA context initialized.
&gt; If your controllers interact with the DB, you don't understand MVC. Huh? I understand it pretty well, actually. *Something* needs to get data to put in the view, after all. I'm not saying controllers should contain low-level JDBC code; rather, mine always depended on some source-of-data abstraction. If the controllers don't manage getting data to display in views, what does?
Try implementing your controllers as traits. We have one WebsiteController object that extends traits for all of our individual controllers, allowing us to use DI on those. For testing, we have a TestWebsiteController that does the same thing. We inject each object differently depending on our testing vs production needs. 
I gave it a whirl and tried learning it for about year on and off. I got some stuff out of learning scala nothing crazy. Eventually, I move to Erlang (currently on it) and some of the Scala stuff made much more sense now. Pattern Matching and functional aspect of it. I feel like Erlang is easier as a language so I don't have to focus on OOP and the Type system. I believe after this I can move to Haskell and learn about type system. From there I guess I can move back to Scala and have a better view of it or learn Smalltalk (Squeak) for more OOP before going to Scala. To me, just me, not everybody elses, Scala have too much stuff in it that I tend to get lost in all the noises. Like OOP+Functional+Concurrency+Type system is a bit much to take in for me. You can do it many ways and it's not as rigid, I didn't fully understand this complaint when people complains about complexity until I started to learn Erlang (which is a much easier language). But Scala did help me appreciate type system more so now and its functional paradigm has help prepared me for Erlang.
Sounds good to me.
Aha, got it. The cake pattern more or less, right? It's been a while since I used Play (back in the 2.0-beta days), so could you explain how the "wiring" would work? I understand how you'd mix in test implementations of things at test-time, but how would you mix in the prod versions?
Thanks, that helps a lot. I can see how that would work now.
Wish this had been posted earlier where the discount codes haven't expired for the book I am actually interested in :/
That said, from the comments: Typesafe responded: @Paul- On Monday, February 11th, Manning will offer a 50% discount on all 14 books listed in the promotion! Stay tuned for the discount code...
Just refunded them to you ;)
The value of this without the text inbetween the bullets is rather limited...
That looks very useful, thanks! It would be interesting to have as a comparison for some examples the equivalent (?) code with plain Scala 2.10 reflection.
That is true, semantically they are different. Most of the time, in an API, there is no need to expose Option[Seq[_]] ... just exposing Seq[_] is enough, even if internally it's represented as an Option[Seq[_]]. My interpretation of what you were doing was that there wasn't any value to wrapping the Seq with Option, but of course YMMV.
I just stumbled on this too. Looking forward to Monday!
The sad state of our industry: Folklore. Huge claim: "A New Java Library for Amazing Productivity Posted on February 11, 2013" Folklore - No facts or numbers.
Did you read the article? It's a deliberately provocative title in order to emphasis the author's point that Java combine with various libraries &amp; frameworks isn't dissimilar to Scala when measured in terms of learning curve, technology risks etc. I don't think the title is intended to be taken literally, or seriously. 
Also, just the fact the different languages means syntactical differences is also kind of a "big deal" relative to libraries. (At least in Java,) learning a new library cannot change the syntax of the language you're working in. As someone with several years of Java experience, but still relatively new to Scala, I have never encountered a Java real world statement I was unable to parse regardless of what libraries were being used, but I've encountered many Scala statements I've had trouble with.
http://code.google.com/p/scalabeans/
Well, obviously... most companies don't like to pay people to learn new skills, since they are probably going to quit in a year.
A lot of people have been applying the same argument to Haskell, Lisp or OCaml. It doesn't exactly help a company to think in these terms. 
I don't know, if I found a company that let me program in Scala when I think it's the right choice, I don't think I'd be looking around for another job. 
That `sameElements` is broken on `Sets`. 
I tend to agree with the OP, but this is definitely a weak point of Scala (the hard-to-understand bit, not the richer-syntax bit). Take, for example `immutable.List[A]`'s `++:` operator: def ++:[B &gt;: A, That](that: collection.Traversable[B])(implicit bf: CanBuildFrom[List[A], B, That]): That In order to really understand this, you have to be aware of: * generic type constraints * the special role of the trailing : in operator names * multiple parameter lists / curried functions * implicit parameters * the role of implicit parameters in making code more generic 
Ah, thanks. Yeah, that does seem counter-intuitive. At least this works: scala&gt; Set(1,2) == Set(2,1) res0: Boolean = true I suppose sameElements is really only meaningful on ordered collections.
The whole "CanBuildFrom" trick for making the collections types turn out to be the right type is also a non-trivial concept to grasp.
On a language which makes such a big deal about very precise static typing, if an method doesn't make sense for a type, then that method shouldn't be present on that type.
To be fair, the CanBuildFrom issue is less of a language thing and more of a library thing. And the CanBuildFrom [documentation](http://www.scala-lang.org/api/current/index.html#scala.collection.generic.CanBuildFrom) is pretty minimal. If they beefed up that page, in part by adding rationale and examples, it would be much easier to understand the intent behind the signature. I'm not trying to excuse Scala's (needlessly?) complex library. I'm just saying that a complex library isn't a core language syntax issue. 
# **Fixed your link** I hope I didn't jump the gun, but you got your link syntax backward! Don't worry bro, I fixed it, have an upvote! - [documentation](http://www.scala-lang.org/api/current/index.html#scala.collection.generic.CanBuildFrom) ^Bot ^Comment ^- ^[ [^Stats ^&amp; ^Feeds](http://jordanthebrobot.com) ^] ^- ^[ [^Charts](http://jordanthebrobot.com/charts) ^] ^- ^[ [^Information ^for ^Moderators](http://jordanthebrobot.com/moderators) ^]
Schema generation is [planned](http://blog.typesafe.com/introducing-slick).
What do you mean exactly? The library explicitly restricts itself to the case of range iteration with `foreach` or in a for comprehension: for (i &lt;- 0 until 100000000 optimized) { ... } What is not "idiomatic" here? It might not be "functional" (in terms of yielding something), but certainly it is the way to write loops in Scala. Looking into my own code base, I have `while` all over the place because of the closure allocation penalty currently attached to `Range.foreach`. Sounds like a reasonable project to me, that probably at some point will be an automatic optimisation of scalac.
I'm (the author here) definitely no functional programming guru, but I'm glad if this is useful to other imperative heretics ;-) Oh, and yield / Range.map is next on my list of optimizations! (regarding more functional constructs, here's what my initial compiler plugin did in 2.9.x: https://code.google.com/p/scalacl/wiki/ScalaCLPlugin)
&gt; Looking into my own code base, I have while all over the place because of the closure allocation penalty currently attached to Range.foreach. This makes me incredibly sad. Is this what the future of JVM languages look like, a code base where you have to use `while` because `for` is too inefficient? Don't get me wrong, I love the monad compositional power of `for`, but I'm still dreaming I can have my cake (clean functional approach) and eat it too (performance) in the code I'll be writing in the coming years. 
I don't really see a problem here. The [documentation for sameElements](http://www.scala-lang.org/api/current/index.html#scala.collection.Iterable) says &gt; Checks if the other iterable collection contains the same elements in the same order as this iterable collection. The [documentation for Set](http://www.scala-lang.org/api/current/index.html#scala.collection.Set$) says &gt; The current default implementation of a Set is one of EmptySet, Set1, Set2, Set3, Set4 in class immutable.Set for sets of sizes up to 4, and a immutable.HashSet for sets of larger sizes. Sets can be ordered, and it looks like the implementation for the small sets (in your example `Set2`) are ordered, so `Set(1, 2)` and `Set(2, 1)` don't contain the same elements in the same order. I'll admit, it might be a little surprising the first time you see it, but I don't think it's a sign of immaturity. Edit: Forgot links
The difference is that Scala is much more similar to Java than any of those languages. It is quite accessible to any seasoned Java developer.
For small projects, the cake pattern works well. However, it can quickly grow out of control. I don't feel strongly that the cake pattern is *bad*, but it's a design decision that has some consequences (see link below). Guice has some really nice composability features, and modules give you a very clear look of what is happening. The cake pattern is more surface level, and doesn't let you handle Scala singletons like Guice can. This SO Q&amp;A might help: http://stackoverflow.com/questions/7860163/what-are-some-compelling-use-cases-for-dependent-method-types edit: For an explicit example, in addition to injecting database(s) / S3 / http clients / email clients, we also inject simple things like clocks. That way, in testing, we can play with the time and test things that use timeouts or time intervals. The tested class simply asks for the time, and we can put in specific times for each call (such as advancing a week, or even going back in time).
You're right. If you only want this sort of flexibility when testing, a framework like mockito does work. However, we use this outside of just testing. In fact, we can easily swap out implementations of classes in several different modes, with very little developer overhead (simply using `inject[Classname]`).
That sounds brilliant. Let me talk to my team!
 // Let's break down the following //val ids = A.data returning A.id insertAll ("foo", "bar") import scala.slick._ import scala.slick.driver.MySQLDriver.simple._ // this example uses MySQL // 'A.data' the type of A.data val dataColumn: lifted.Column[String] = A.data // 'A.data returning A.id' // there is an implicit conversion on A.data when we call returning on it val insertInvoker: driver.MySQLDriver.CountingInsertInvoker[String] = columnBaseToInsertInvoker(dataColumn) // 'A.data returning A.id' ; the signature of returning is // returning[RT, RU](value: RT)(implicit shape: lifted.Shape[RT, RU, _]): // driver.MySQLDriver.KeysInsertInvoker[String, RU] // so it needs an implicit Shape to convert from RT=Column[Int] to RU=Int // (easy in this case, probably crazy when we're dealing with projections) val keysInsertInvoker: driver.MySQLDriver.KeysInsertInvoker[String, Int] = insertInvoker returning A.id // 'A.data returning A.id insertAll ("foo", "bar")' // the signature of insertAll is // insertAll(values: String*)(implicit session.Session): keysInsertInvoker.RetMany val retMany: keysInsertInvoker.RetMany = keysInsertInvoker insertAll ("foo", "bar") // 'val ids = A.data returning A.id insertAll ("foo", "bar")' // obviously another implicit conversion, somewhere; // the class RetMany belongs to the object keysInsertInvoker // so it statically knows the type of the Seq it must produce val ids: Seq[Int] = retMany for (i &lt;- ids) println("Got id: " + i)
Aw shucks, indeed. No idea what happened, I hope github will fix the issue. In the mean time, here is the markdown interpolator: https://github.com/paradigmatic/interpol/blob/master/src/Markdown.scala An here is the usage: https://github.com/paradigmatic/interpol/blob/master/src/Main.scala The output will be: `&lt;p&gt;&lt;strong&gt;&lt;a href="http://en.wikipedia.org/wiki/Anchorage,_Alaska"&gt;Anchorage, AK&lt;/a&gt;:&lt;/strong&gt; &lt;em&gt;-3°C&lt;/em&gt; (26°F)&lt;/p&gt;`
Really? Scala 2.10 actors don't have mailboxes?
Should have said "durable mailboxes", sorry.
Please, please move this project off Eclipse. I love what you guys are doing, love the Scala worksheets especially, but friends don't let friends develop on Eclipse. It sucks that badly.
Looks amazing, but I can't tell - can it help parse binary files?
as in... sucks... computer resources? ;)
Operator overload abuse FTW...
What's this Twitter's offer/broker you speak of? Some sort of library?
Depends on what you mean by help, I imagine. The [docs](http://rapture.io/gettingStarted) certainly indicate you can "slurp" input into an Array[Byte] which is about what I'd expect an IO library to enable me to do with binary files... If you really mean "parse" as in turn a binary file into something meaningful, you'd need to specify what the data is (an image, a Word doc, what?) and have a library/code able to do the conversion in order to successfully parse it.
lol, no. I mean sucks in almost every way it is possible for an IDE to suck. IDEs are supposed to simplify development -- a task which both Netbeans and IntelliJ somehow seem able to manage. Eclipse used to do this, but somehow has managed to evolve into a beast that frustrates development at every turn.
My bad for not adding the link: [Offer/Broker](http://twitter.github.com/effectivescala/#Twitter%27s%20standard%20libraries-Offer/Broker) I'm not sure about the anchor in that link. Search of offer/broker on the page if the link doesn't take you to the right spot in the document. 
I've upvoted you because it's a valid concern, but I completely disagree. The overloaded operator usage in Rapture IO looks minimal and intuitive. THIS is operator abuse: http://www.flotsam.nl/dispatch-periodic-table.html This library looks useful and very much needed. I just hope the author is careful.
I was aware at what you are pointing but wantent to chip in my own issue with eclipse - I don't know what machine should I have to be able to run it in a way that it's not annoying...
I'm not sure the container approach to thinking/talking about monads is really very strong. As shachaf says, &gt; `getLine :: IO String` contains a `String` in the same way that /bin/ls contains a list of files And while you could argue that `Cont` contains a value of some sort, that's really not what makes it interesting/valuable. How about `State`, or `Reader`? We can get more esoteric and talk about [this weird search monad](http://math.andrej.com/2008/11/21/a-haskell-monad-for-infinite-search-in-finite-time/), too. Calling any of those types containers is really stretching the notion.
This is one infuriating web site, most links can't be clicked (tried Chrome and Safari) and I can't even shift-click to download the mp3. 
The author thinks Scala doesn't have pointers (just like Java, Scala has pointers, just not pointer arithmetics) and thinks that `map` is all that defines a monad (that would be a functor, not a monad). Terrible article, avoid. There are much, much better monad tutorials. 
Just getting rotating cogs from blogspot with Firefox. Scripts are enabled, so I don't know what's going on. Why are platforms screwing up browsers so much these days?
I see they finally have RSS for audio now, great!
[Direct YouTube link](http://www.youtube.com/watch?feature=player_embedded&amp;v=oW6c_INmzEs)
Sorry about the cogs. I'm not sure why it's doing that. I didn't do anything special, so it must be blogger.com. I guess I'll poke around at the "layouts" options and see if any one of them render the page directly.
His style is hilarious, enjoyed skimming through it despite knowing all those 'tricks' already.
I did read that in the [Haskell Weekly News](http://contemplatecode.blogspot.com/2012/02/haskell-weekly-news-issue-215.html). But I'm not sure I agree with it. HWN didn't give any more context, so I don't know if shachaf had a better way to think about monads or not. Or even whether shachaf was serious or making a joke. (Or any clue who shachaf is) I think of IO String as a box (the IO) that contains a String, but for type safety and purity reasons, I'm discouraged from opening the box (using unsafePerformIO), and instead encouraged to put functions in the box, which are then run from inside the box, and I'm given a new box that contains the result of all of this. (Or, Haskell being lazy and all, at least collapses to the result of all of this if I ever open the box.)
`flatMap` is the quintessential defining element of a monad; `map` defines a functor. All monads are functors, but not all functors are monads. 
I've never used, and don't really understand, a lot of the other monads you mentioned. I meant to mention that in my reply, but I got distracted and left that out, sorry. If anything I said in my blog post is outright wrong, point it out to me and I'll correct it. I understand that everything in Haskell in lazy by default, and nothing gets evaluated unless it's forced to, and that IO is actually building up a chain of callbacks to be called when the value is actually available. And even that even that isn't really true, and that GHC does a strictness optimization, and certain things cause things to be evaluated. 
Laziness in Haskell has nothing to do with `IO`'s behavior. `IO` quite simply does not contain a value. The analogy with ls is _exactly_ right. ls _really_ does not contain a list of files. It knows how to find out what the list of files is, when you run the program, but that's as far as it goes. `getLine :: IO String` doesn't know what you're about to type before you type it. `IO` values can produce a value on demand, but that's explicit demand, not laziness. And `unsafePerformIO` and strictness and all the other stuff are irrelevant to my point.
&gt; I'm guessing you wanted me to talk about the three laws of monads, or maybe the Haskell typeclass. But I didn't consider either of those appropriate for my tutorial. No, I wouldn't expect either to be part of a monad tutorial. However, your focus on `map` to describe a monad is incorrect. Like I said, `map` alone characterizes a functor. Maybe you should start by understanding this fact (and the relationship between functors, applicative functors and monads) and take the reader through this progression one step at a time, starting with the functor, which is the easiest to grasp. The fact that you downplayed the importance of `flatMap` shows that you don't really understand what a monad is. 
What editor is he using?
TextMate I guess
I doubt it's textmate; seems more like Emacs or Eclipse Scala workbook maybe? If it's textmate, then it's pretty badass. :)
would have to agree with you there. i would never develop large projects in scala+ecliplse; eclipse seems to keep on getting in the way rather than making your life easier. always get the "brain freeze", where it just hiccups and stays frozen for half a minute or so. switched to intellij, never looked back.
you can run your program and get the output at the cursor thats what he does
Actual 42go employee, or just continuing the parody? Are you a forward-thinking, shovel-ready, synergized startup looking for action-oriented people with strong personal brands? Tell me about your value propositions. [edit] Actually, let's get down to brass tacks: I'm too ugly to work for or invest in your company. ;-;
Just a minor error I saw, the EmployeeLabelMaker implementation is the same as MovieLabelMaker. Otherwise, I'm also an fp newbie as well I can't offer much more feedback other then it looks good and conforms to what I know about how you should use typeclasses. good job!
Thanks man.
I am on FF18 and had the same problem. I can click and expand details of the podcast, but I cannot click or select any of the text within the details. It isn't an image, it looks like it is intended to be clickable/selectable.
&gt;We're working on some really interesting problems Why are you guys making problems?! We want solutions!
I fixed some typos and fixed the mixed up label functions: https://gist.github.com/viktornordling/4981423
not terrible. He needs to specify that the monad magic happens because of flatMap, otherwise he'd just have a functor, but otherwise it's a good simple explanation. 
I agree that calling it a container might be confusing, but he's not *wrong*. State absolutely 'contains' a function that runs, along with with reader, etc. 
It doesn't contain the referenced type. `State s Int` does not "contain" an `Int`, but has a function that can produce an `Int` (and a new state) given a value of type `s`. If your criterion is that the type is implemented using some other type, that's pretty much a tautology for all but the most basic types.
http://i.imgur.com/RbbyixC.png As cool as this is, i wonder why anyone would ever seriously use this? 
The neckbeards are also "holier than thou", apparently. Meant to be irreverent and funny, is actually unfunny and does not inspire confidence. 
Pam Grier does kick serious arse. Good talk. The rules for parentheses in function calls are a bit more subtle than she describes it at the very beginning, but the rest of the thing is cool. lol @ the badass playa on the slide for "What is a Function". Also, good job on introducing monads without overcomplicating things.
I liked it.
Anyone still got the course materials?
Concur. Is it really necessary to insult a group of people to make functional programming look less intimidating? Programing conferences should be accepting towards everyone.
Oh, it's possible that it was a good talk! It's just an unnecessary title. I'm not a neckbeard but I despise the cliche.
It's a funny title.
i know how you feel
I can't take you seriously at all. You want to hire, stop talking marketing.
it's the first time I really find myself on 'this' side of a discussion. Not sure how this happened. &gt; Consider that the "neckbeard" can refer more to the perception of the code itself, rather than its writers, Can? Does it? This is much like the "brogrammer" thing that existed some time ago. It's trying to get people to bond by exclusion of others. It sucks. &gt; hygienic laziness wut? &gt; (Disclosure: I work alongside Kelsey, the presenter, and I'm sporting a 5-day neckbeard at current) "I have black friends, too!"
&gt; it's the first time I really find myself on 'this' side of a discussion. Not sure how this happened. Well, you started it. :) &gt; hygienic laziness Yeah. When most people grow a beard, they call it a beard, at least as far as I've known (and been one among) the bearded. A neckbeard is just what forms when you don't shave for days/weeks/etc, and usually tends to be rather unkempt. Once you begin trimming it, shaping it, and so on, it crosses the line into a beard, because you're actually taking steps to groom and clean it. That's my take on neckbeards vs beards, and I'd wager that most people have a similar take, if they've even bothered to think about beards this much in the first place. So I mean... if you (or whoever) want to get bent out of shape because someone called you out for having a scraggly-ass beard, that's your prerogative. /r/beards can probably help with that. ...similarly, I'm sure there's a relatively smaller sub devoted to unkempt neckbeard solidarity, all the same. I didn't really look for that one, though.
http://www.reddit.com/r/neckbeardrights Fight the power!
For the purpose of learning, there's an argument to be made for learning map/flatMap in the context of containers first, then moving on to Futures and other less "tangible" instances of Monads. And I guess by tangible I mean how accurately I can picture the monad. A container like a list or even an option is bookshelf or a line of cubbies with things in them. Later I learn that I can compose futures into something like sequential looking code, and my code won't need to hold onto a thread while it waits. Neat! This expands my mental model, but it doesn't invalidate the new "moves" I've learned for composition. 
The article of course already notes that this method uses reflection, so you might want to refrain from using it if you want good performance. Also, you should learn when using structural typing is appropriate. Quite often, what you really want is a trait.
Can you give an example of when this would be useful?
It provides bidirectional, symmetric stream processors. It lets you (eventually, when it's done) write code like this: val f: Message =&gt; ProxyBase[Message, Message, Message, Message, (Message, Message)] = x1 =&gt; for { y1 &lt;- someOperation(x1).request x2 &lt;- someOtherOperation(y1).respond replyU &lt;- StringMessage("have synced upstream and downstream").request replyD &lt;- StringMessage("have synced upstream and downstream").respond } yield (reply1, reply2) val g: Message =&gt; ProxyBase[Message, Message, Message, Message, (Message, Message)] = Proxy.mapDK { case StringMessage(m) =&gt; StringMessage(s"The string message is \"$m\"") case x =&gt; x } val h = f &gt;-&gt; g The types can be different in each of the four directions (combinations of upstream vs. downstream and input vs. output), too, and you'll remain completely type-safe.
When structural typing is actually appropriate? I actually haven't run into that situation. I wanted to use it for "+", but that's not possible because generics and structural types don't work together. I ended up doing that with an implicit Numeric.
I wasn't aware of generics and structural types not working together. Why is that? "not yet"? Or "they can't"?
It can be very useful to identify a category of classes satisfying a structural constraint, without defining a full-blown trait. Think about the java try-with-resource (loan pattern) that works on any Closeable object. With duck typing you can define a method that takes a closeable, where the latter is defined only by being of type [C &lt;: {def close(): Unit}], with no need to define a trait to inherit from.
For starters, [structural typing doesn't work with isInstanceOf](http://stackoverflow.com/a/4846042). 
What are bidirectional, symmetric stream processors?
Agreed that in a public API you will want either a common trait or a type class approach. But structural typing is useful for rapid prototyping in my experience. If you want to try out something quickly without getting side tracked by having to define a trait (that you may even have to delete at a later point), it's nice that you can define `def foo(): { def cancel() } = ...`
I would try to explain, but I couldn't possibly do a better job the the original [`pipes` tutorial for Haskell](http://hackage.haskell.org/packages/archive/pipes/3.1.0/doc/html/Control-Proxy-Tutorial.html) by it's creator, Gabriel Gonzalez.
&gt; How do Akka Futures differ from Java Futures? Is it that they can be non-blocking? That's a big way. Basically you can map/flatMap/filter over them, which aside from being nice in the usual Scala collections way, lets you use for comprehensions to express chains of async operations in a more "sequential" way. def remoteCallA(): Future[Foo] = ... def remoteCallB(foo: Foo): Future[Bar] = ... def remoteCallC(bar: Bar): Future[Baz] = ... val futureBaz = for { foo &lt;- remoteCallA() bar &lt;- remoteCallB(foo) baz &lt;- remoteCallC(baz) } yield baz Compare that with the callback hell a non-mappable API would lead you to. That's just one of many things. [This is a good intro.](https://speakerdeck.com/heathermiller/futures-and-promises-in-scala-2-dot-10)
The call val futureBaz:Future = for { foo &lt;- remoteCallA() bar &lt;- remoteCallB(foo) baz &lt;- remoteCallC(baz) } yield baz will return immediately with a future. It will only block when you try to get the result and the howl chain is not yet finished. 
Ok, so same thing as Java. Besides, that's not what the OP was saying: &gt; lets you use for comprehensions to express chains of async operations in a more "sequential" way So again, I am not seeing what is so different compared to how things are done in Java. 
The community made some summaries: [Scala 2.10.0](http://www.slideshare.net/dcsobral/scala-210-english) and [What's new in Scala 2.10](http://ochsenreither.posterous.com/whats-new-in-210)
Is it really the same thing as Java? Future.get is blocking as far as I can see, so the Java example would block at each call, while the Scala example will not block at all. The way that is enabled is through the for-expression in Scala, which is really syntactic sugar for various higher-order functions such as "map". Those higher-order functions can be used to avoid blocking. The advantage of using a for-expression instead of the higher-order functions is that it syntactically can look a lot nicer, including in the above example that looks sequential.
I am not certain that you are right about that example regarding it being synchronous (the syntax also looks wrong, I don't think you can put 'println("foo");' into the for-expression like that). In the following example, I believe the blocking is fully delayed, such that the following print statement is executed immediately after the for-expression: val futureBaz:Future = for { foo &lt;- remoteCallA() bar &lt;- remoteCallB(foo) baz &lt;- remoteCallC(bar) } yield baz println("foo") Since the thread never retrieves the value of futureBaz, it would never block. Once the for-expression is folded out internally in the compiler, I believe it would look similar to your example of asynchronism, just more nested and with a future as the final result.
&gt; Ok, so same thing as Java. Not really. You'll still need to wait on the results, either by blocking, or by doing something when the future completes (Futures have a foreach() method that effectively sets an onComplete callback), but that choice is yours. With Java you basically have to block. Additionally, the for-comprehension example returns immediately with a Future that represents the chained up computations. It's nice to be able to create objects representing chains of computations that you can pass around if needed. That would require a lot of boilerplate to do in Java.
&gt; The Scala example will block just the same. Not necessarily. You could block on the future: val baz = Await.result(futureBaz, 5.seconds) but you don't *have* to, if that's not what makes sense. With the Scala approach, you have a choice whether to block or not, which opens up a lot of new use cases and possibilities. You can always fall back to blocking with the methods from Await, if that's what you need. &gt; Make no mistake: these two examples do block, it's just more hidden in the first example. No, they don't. Leaving aside the for-comprehension syntax (I'm not sure you can put println there in that way, but I get your drift), as ecirptsrif pointed out, the for expression will "return" right away. You *can* block on the resulting Future if you want, but you don't *have* to. &gt; Blocking is a necessity for any concurrency to happen, whether it's synchronous or asynchronous. Not really. Blocking is convenient in some use cases, but it's not necessary. I've worked off-and-on on a distributed, event driven system at work for the past few years. In that context, blocking is a pain, and having the option to not block is very helpful. In other contexts, that may be different, of course.
&gt; But when you launch an asynchronous operation, somewhere, a thread will have to block and wait for the answer. Fair enough, but that seems a bit like hair-splitting to me. Things like loops and methods are just syntactic sugar for GOTOs, if you go down far enough, but that's not a distinction anyone feels compelled to make these days. So, duly noted.
Great post. However, I disagree with the comment regarding tooling. It has a long way to go.
i am desperately trying to figure out Lift in Eclipse IDE, many online article say it works, and i am sure it will but its a HUGE hassle compared to whats out there.
Play doesn't really require any extra tooling. I use eclipse for the java and scala bits but often just use vim or Geany for the templates. 
I take it he has seen the work by [Philipp Haller](http://lampwww.epfl.ch/~phaller/capabilities.html) and doesn't reinvent the whole thing.
IntelliJ IDEA has a Play2.0 plugin that can work with Play's templates, with Intellisense and whatnot.
How about Scala Cheap Shots?
Author here. Yeah, I've been given a link to that work in the comments. Should've googled before posting. Anyway, what's the state of it? Is it working for scala 2.10? Is it planned as an experimental feature someday, or was it a one-time project?
Modulus should really be a lazy definition. No need to compute it for every complex number, compute it only when required.
Yes, sorry I didn't see that comment before because I had javascript disabled. I honestly don't know if that project is still alive or further research is being done, but it may well be worth contacting the author.
For Emacs in particular, you can add a [File Variable](http://www.gnu.org/software/emacs/manual/html_node/emacs/Specifying-File-Variables.html) like this at the end of the file: /* Local Variables: */ /* mode: scala */ /* End: */
Does scalac reject it even with the closing '!#' ?
No, it's not syntactic sugar. I don't think you undestand what the word 'blocking' means. Blocking traditionally means an entire thread *pausing* and awaiting input. Futures/Actors use microthreading under the hood, and could very well use Netty or other non-blocking network code. Are you familiar with Netty? It is fully non blocking. Futures and map/flatmap syntax allow for the underlying network code to be purely asynchronous. 
Why are you trying to compile it with `scalac` ? The idea of a script is to run a piece of code without compiling it...
no, not even close. Akka has many, many more features. The goal here was small and focused. It has two features akka doesn't have though: 1) extends vs wraps (for 'this' reference leakage prevention and avoiding need for actor to know its an actor for identity reasons) 2) builtin typed actor router.
Yes. I opened this issue many moons ago and it still hasn't been addressed.
I often write my code as *modulinos*, little self-contained modules that double as both command line programs and importable libraries. Also, it's a completely unnecessary hassle to have to remove shebangs from Scala code that you later want to compile. The compiler should treat shebangs as comments, doy.
I think the main problem with such a study, like most studies of this kind, is selection bias: - Most people who tried Scala and then gave up will never know about it, let alone bother filling the survey. - People who love Scala will be more inclined to fill such a survey in an attempt to share their interest Second, to be really scientific about productivity, you need to cover a lot of scenarios, such as - Writing a project from scratch in Java and then in Scala. Compare. - Writing a project from scratch in Scala and then in Java. Compare. - Writing a project from scratch in both languages. You also need to do this with people with various level of competencies in both languages and compare what's comparable. Bottom line: productivity speaks for itself. If a technology makes people more productive, it will be used more and more to the point where you won't need a study to justify its existence (when was the last time you read a study asking if C or Java makes you more productive?). The simple fact that such studies exist about Scala is showing that Scala still hasn't met the burden of proof in that area just yet. I hope it does, one day. 
&gt; *The simple fact that such studies exist about Scala is showing that Scala still hasn't met the burden of proof in that area just yet* No, it just shows that some people have too much free time on their hands. I don't need studies to pick technologies anyway. I have no idea for whom these studies are for, especially since I've never seen one worth anything. Probably for clueless managers that make decisions based on brochures and lap dances. Scala is proven by the simple fact that it is being used in demanding domains, like finance or in thriving startups, in spite of the strong competition it has from the dozens of languages and platforms available. It also has a small, but very active and sustainable community of people and companies that *ship*. You don't need more proof than that.
Here's some utility code I carry around that utilizes structural typing: def using[A &lt;: { def close() }, B](stream: A)(f: A =&gt; B) : B = try { f(stream) } finally { stream.close() } The following classes/class groups all have `close` methods, but they don't inherit them from a common place: * `java.io.OutputStream` subclasses * `java.io.InputStream` subclasses * `scala.io.BufferedSource` So... when is structural typing better than implementing a trait? The answer is quite similar to that of "When are typeclasses better than implementing a trait?": when you *can't* implement a trait and want to do something elegant with code in a library.
Indexed monads are just categories in the monoidal category of endofunctors over whichever category you are working in.
Can you elaborate? A categorist friend of mine was looking into them a while back and said that although his initial intuition was what you said, if you work through the details they don't really work out to being the same thing. 
I'm assuming you know what a monoidal category is. A category in a monoidal category is a set, called its objects (for the indexed monad typeclass, this is the set of Haskell types), and given two objects A and B, an object of the original monoidal category Hom(A, B). There is a morphism `id' : I -&gt; Hom(A, A)` for all objects A, and a morphism `o : Hom(A, B) x Hom(B, C) -&gt; Hom(A, C)` for all objects A, B, C. These morphisms have the following properties: o . (id' x id) . lambda = id o . (id x id') . rho = id o . (o x id) = o . (id x o) . alpha This corresponds to the laws of indexed monads: join . return = id join . fmap return = id join . join = join . fmap join
Yeah, I do know what they are and know about the internal category construction. As I said, I think it looks okay on the surface but something goes wrong somewhere. I'll try getting ahold of my friend to see what his objections were to this interpretation. Thanks for elaborating!
What may be going wrong is that the indexed monad *typeclass* only describes *some* categories in the monoidal category of endofunctors over whichever category you're working in, to be exact, those whose objects are the same as the objects of whichever category you're working in.
It isn't scala at all.
I think in this case the biggest improvement would be to use a recursive [nested function](http://www.scala-lang.org/node/116) instead of a while loop. And then you should be able to move your vars into parameters of the nested function, so that they are immutable instead of mutable. Your goal should be to try to write this without any vars. 
Also keep in mind that you can return values from your if statements. For instance: val x = if (someBool) 5 else if (otherBool) 1 else 2
Yeah, to make this really scala-like you got to get rid of the vars. At cessationoftime suggested, a recursive call is good for this. Another common thing you can do is a fold over a closure, but that would probably be on the messier side for this situation. To do this you would put your mutable variables into a tuple. Then the function you're folding over will take these, do your computation, and return a new tuple that will be used in the next function call. My guess is that if you really think functionally you'll be able to write this in a much cleaner way.
This is a great start. A test suite will help a lot. Here's something that greatly improved my code. Open up a tab with the [Scala API](http://www.scala-lang.org/api/current/index.html), and try to, as cessationoftime said, write it with no vars. Perhaps this definition of the problem may send you on the right path: 0) You have a directory with some number of things inside of it. Its result set should be the following: 1) If the thing is a file and it matches the pattern, it's in the result set 2) If the thing is a directory, its (GOTO 0) is in the result set You may be surprised how concise it'll be. edit: I totally mis-understood your problem! Oops! A similar approach will likely help, though.
One thing to note. Usually you wouldn't append (:+) to a list, it is pretty awful performance wise the way they are implemented. Normally one would prepend to a list (::) and then possibly reverse the list. If you must append then you may want to use a different collection. Of course you probably dont care much in this situation, but it is good to know. [Here](http://www.scala-lang.org/docu/files/collections-api/collections_40.html) is a chart of the standard collections and their performance characteristics.
Once I started thinking like this, it's so, so painful to do java work.
Disclaimer: I'm still new to Scala. I know some Java, but I don't see myself as "Java guy". But I don't agree that your new version is better than your old version. The new version is more "functional". It avoids mutable local variables and uses recursion instead of loops. Maybe I just haven't "come around" yet, but I think recursion is almost always harder to understand, and I don't see the point of avoiding mutable local variables, especially in small functions. Java code has a habit of using overly verbose function names. But I think the names you used in your original code were fine. I think the names "g", "chM", "n", and "gi" are incompressible without comments, and you didn't include comments.
It took me almost 6 hours to turn the imperative method into a stateless function. If I stumbled upon the functional version it probably would have taken even longer to understand it. So I too am still questioning whether it is "better". Obviously if every small thing I have to write is a 6 hour academic exercise, I won't get anything done and the language is of no use. I am trying to see if I can "think functionally" and become good enough at it to actually write code more quickly.
I have seen the "case x :: xs =&gt;" syntax before, but I finally get it after seeing it applied to my already working function! I do like this a lot better, it makes the bounds checking more intuitive. Thanks!
Using that approach, the compiler must not only ignoe the sheband lines, but also deal with the code at the top level (main method equivalent). What should the compiler do ? Remove this code ? Wrap the code in a main method ?
Yeah, that's called a destructor (not to be confused with the same term from OOP), it takes the variable apart and creates new local variables. Internally, it calls unapply, and any case class you define gets an unapply method automatically (in it's companion object). It's intentionally the same syntax that you use to construct the object. I don't have time to play with it now, but two things I would still improve: * You might be able to match on both variables at once by wrapping them in a tuple: (name, glob) match { case (Nil, _) =&gt; true; /* ... */} * Come up with a way to make it tail recursive. Right now, if you put the attribute @tailrec on chM, it fails to compile. That might be more of a rewrite though. Right now you're basically using the stack to backtrack, to try several possibilities until one works.
I have though about the tail recursion considerably, but I don't think it is possible. Due to cases like *.js matching testFile.js.js , there will always be two possible routes to completion for any character. This means that one route must be evaluated in order to determine if the other should be tested. I'm not sure the algorithm is possible without backtracking. I am inclined to be concerned about head recursion, but I did a test against a 386 character long filename and it was fine. Also it's still 60% faster than my original method! 
Your original version didn't use recursion, and it didn't use some other growing data structure, so that makes me think a tail recursive version should be possible. Instead of backtracking, maybe you can skip over the store, then if there's more to the glob, search the name for something that matches the remaining nonwildcard part of the glob. I may not have thought this all the way through though. The danger with recursion is not being slower, it's using too much memory. Since these are lists though, you're probably only adding two pointers to the stack each time for the two arguments, and maybe 4 more pointers for the local variables if they can't be optimized away. (Plus return address, registers, whatever else is involved in a function call)
how about the whole video: http://mrkn.co/1tp7y
Treat shebang lines as comments. No more, no less.
It's not enough. For instance the script: #!/bin/sh exec scala "$0" "$@" !# object Greetings{ def apply( name: String ): String = s"Hello $name" } println( Greetings( "Alice") ) The script will run and work as expected. However, if you just ignore the comment line it's still not a compilable Scala code, because you cannot have statements (or expression) outside class/trait/object... So you will need to decide how to handle this code (drop it, wrap it in an object, wrap it in a object extendings `App`, etc.)
&gt; This is important because, today, scala minor version releases can contain breaking changes. Not anymore. :-)
I agree with the first point that you can't do much about the selection bias. However, even if people are as productive as before but feel more productive that has value in and out of itself. All things being equal, being able to enjoy your work more adds a lot of value.
Barney's one rule: New is always better. Java 8
The question is ill formulated to achieve the desired result. It actually goes: "Should Scala 2.11 drop support for Java 6 and the Android platform?" A year ago, 85% of user base wasn't at Java 7. http://java.dzone.com/polls/have-you-adopted-java-7-yet I for one am stuck to OS X 10.6 without Java 7. So f*** these plans.
Is it for dropping java 6 support? As far as I'm aware, both 6 and 7 are currently supported by scala, just 6 is the default. Maybe they're thinking of making java 7 the default target for compilation? 
You see, only the adepts get to know the motivation of this poll: http://permalink.gmane.org/gmane.comp.lang.scala.user/61462 Given the way it is presented, it is for /dev/null
The reasoning is also flawed: &gt; To keep things simple (for you and ourselves), we'd rather not (officially) support two incompatible class formats in one Scala release (i.e., Java 6 &amp; 7), as this would result in a fragmented eco system, where artifacts would have to indicate which Java version they're targeting in addition to the Scala version. The ecosystem will be fragmented anyway if the switch is made to Java 7, as long as Android is a viable platform.
&gt; You see, only the adepts get to know the motivation of this poll Good find. Posting to scala-user is a common tactic the elite use to hide their plans from the Scala community. Fortunately, their plot backfired, resulting in a healthy discussion of the pros and cons of continuing to target Java 6. I was able to "hack" the URL you provided to reveal the full discussion: http://comments.gmane.org/gmane.comp.lang.scala.user/61462 
&gt; Good find. Posting to scala-user is a common tactic the elite use to hide their plans from the Scala community. That doesn't make any sense.
And as long as people want to write Android applications in Scala.
Honestly I think it's worse to keep the language back to keep backwards support for Java 6 only to keep android developers happy. It's not like you can't still use 2.10 with android and gain amazing functionality over what Java offers. I'm also assuming keeping java 6 support has significant impact on things they want to do with the compiler and features they want to add. I don't know the specifics of what impact keeping support for 6 would have on the language, I'm just assuming it would be significant. Also, I feel it's really up to android/google to get the support needed to work with java 7 instead of forcing scala to keep it as a platform in mind. Scala initial target wasn't for mobile computing, it's something nice that resulted bc of Google's use of Java on Android. 
won't android catch up with time? its not like there is immense demand for scala on mobile today; though there probably will be in two years.
There's uncertainty about Java 7 on Android because of corporate politics between Oracle and Google. The rift dates back at least to Oracle's refusal to let Apache have a license to use the compatibility tests that are used to certify Java implementations. It's very complicated, and I can't attempt to explain it because that would require me understanding it in the first place. Personally, my take is that Google will have to support Java 7 eventually, because if they don't, they will split the Java community in two and end up with (by far) the smaller piece. Regardless of the exact nature of the political and legal problems involved, they are ultimately about money, and therefore it seems reasonable to assume that they can be solved by money, which Google has plenty of. That still leaves the problem of timing, though. The first RC of Scala 2.11 is targeted for this December, so presumably the official release of 2.11 will be in early 2014. Even if Google does announce Java 7 support for Android, how long will it be before Android developers can rely on enough users running a Java 7-capable version of Android? 
In that entire thread, and this entire discussion, I haven't seen any actual numbers for what switching to java 7 will do for performance. I want to see some actual numbers for how making a universal switch to invokeDynamic will increase performance.
Wait, what does dropping Java 6 support have to do with Android platform support? I have been using Java 7 for an Android project (using IDEA) just fine - so why would there be any problems? Here's a nice SO link: http://stackoverflow.com/questions/7153989/java-7-language-features-with-android In any case, Scala 2.11 isn't getting released or (I'm guessing) getting wide adoption any time soon, and if there indeed *are* any incompatibilities, I'm sure the Android SDK will support Java 7 by then. 
How did you manage to sneak your Java 7 class files through dex, which as far as I know supports class files up to version 6?
As always, awesome blog post by Daniel.
Well, at least [Red Hat believes](http://jaxenter.com/red-hat-take-openjdk-6-reins-from-oracle-46506.html) that Java 6 still "plays an important role". Perhaps it means people should be using Ceylon soon if they are not ready to migrate? Thanks.
Is it faster than the Scala compiler usually is?
Unfortunately, no, it is just a wrapper around the scala compiler API for the sole purpose of making that API accessible to simple use cases.
As in all things, it depends on your application, usage, and context. The library does check if the class is newer than the source in which case compilation is omitted. Since plugins/config files are often static for days/weeks/months you only pay the compile time once.
Thanks!
In 2.10 there is a default api that does that and it's called ToolBox. [Here is a good example of how can it be used](http://stackoverflow.com/a/12123609).
I'll add the definition of an assignment operator for those who don't want to load the PDF: &gt;6.12.4 Assignment Operators &gt;An assignment operator is an operator symbol (syntax category op in (1.1)) that ends in an equals character "=", with the exception of operators for which one of the following conditions holds: &gt;* the operator also starts with an equals character, or &gt;* the operator is one of (&lt;=), (&gt;=), (!=). So `+=`, `-=`, `&gt;&gt;=`, `+++*&amp;&amp;^%%^&amp;=` all have precedence 0, and `=!!!=`, `=/\/\/\=`, `!=`, `&gt;=`, `&lt;=` and `==` all have precedence 6. Also, Scala forbids mixing next to each other operators with the same precedence and different assiciativity, so for example this won't compile: 1 +: List(2,3,4) + 5 
How does that work? It looks like + has higher precedence than *?
So, &lt; and &gt; have higher precedence than exponentiation? That's odd.
They want to generate bytecode using the new method handles from Java 7. It won't run on Java 6.
The "replacing Command" section is totally dumb. The whole point of a Command class is that you can inspect it (e.g. figure out how much a purchase was for WITHOUT executing it), and can have multiple implementations of the execution function, if you don't put it inside the class as a virtual function. If you replace the class with just an uninspectable execution function, you might as well just use a normal method, and have the caller create the closure and store it if desired (with () =&gt; method(args...)). If the rest of the book is like this, it's shit. 
&gt; Beta eBook + Paper Book ($46.00) Er... seriously? 
Ruby: appeared in 1995, became popular around 2005 - http://en.wikipedia.org/wiki/Ruby_(programming_language)#Ruby_on_Rails Python: "Python was conceived in the late 1980s and its implementation was started in December 1989" - http://en.wikipedia.org/wiki/History_of_Python I did my first big Python project back in 2000, no one had heard of the language then. Paul Graham's "The Python Paradox" is from 2004 (http://www.paulgraham.com/pypar.html), 15 years after the language was created. Objective-C: created in 1983, only became popular 25 years later, in 2008, with the App Store. To become mainstream overnight, like Java, is a pretty rare exception, not the norm. Even C: the language was created in 1969, but the first edition of K&amp;R is from 1978! The second edition is from 1988 and the first C standards (ANSI C) appeared only in 1989/1990. And let's not even start talking about Lisp (1958), Haskell (1990), Erlang (1986)...
Except in the title, this article doesn't mention Scala anywhere. 
Correct. Those are binary operators. Binary operator means that the number isn't operated as whole but the single digits are operated with each other. So: 11001 XOR 01111 would result in 10110 ^ XOR, 0\^0=0; 0\^1=1; 1\^0=1; 1\^1=0 &amp; AND, 0&amp;0=0; 0&amp;1=0; 1&amp;0=0; 1&amp;1=1 | OR, 0|0=0; 0|1=1; 1|0=1; 1|1=1 ~ NEG, ~0=1, ~1=0 \&lt;&lt; LEFT-SHIFT \&gt;&gt; RIGHT SHIFT \&gt;&gt;&gt; RIGHT-SHIFT (ignoring leading 1s)
May be Scala is difficult but i mamaged to learnt, the problem is i cant use it, i went after Scala for getting on to Lift framework, but when i was ready to learn Lift, something bad came to realization, there was no option in eclipse to start a new lift project, just like GWT(now an failed framework) we need to download an arcane project and modify that. The most shocking thing is the downloaded project is so complex for a newbie that a person without assistance will never get it. but Fortunately, i have heard support for Scala in many other frameworks are being released, e.g. Vaadin and Wicket i will try those, Lift was an disappointment, i will never try Play since it has lot of Java noise, And i am a c# guy.
The problem with SBT is it thinks everyone has a GBps connection, here it downloads colossals thing for generating a simple Lift project, SBT suks big time.
I'm the author, so if you have any questions or feedback, I'd be glad to hear them.
Why do you think Lift should be left aside?
Thanks for your opinion - appreciated. I'm still on the fence. I'm finding Lift's security and snippet comet model attractive - the ability to have several snippets updating on a page without blocking the client. On the other hand I'm liking Play's popularity and general approach. Seems like it comes down to whether you like MVC or MVP?
Looks nice, but these sorts of problems are why I abandoned Play!
Is it worth migrating to Scala IDE from IntelliJ IDEA? It seems like some of the new features are nice, but I've always had problems with Eclipse like memory leaks and slowness. Thoughts anyone?
In my very humble yet biased opinion, IDEA = Scala IDE 30.0.0
i don't really understand. You are free to choose the persistence approach you want. Anorm is just a suggestion, nothing more. Play API are about Controller and Views and not about Model or Model persistence...
Wasn't comparing with Eclipse.
Kept crashing for me on 64bit Ubuntu when I did the Coursera Functional Scala course last year. If you have a massive code base, IDEA-Scala may get sluggish. But that's probably I'm on the nightly's anyway. If this happens, you still have SublimeText.
Wow, really really impressive release. I'm can only report good things about it!
Note that 5 and 6 may be [switched](https://issues.scala-lang.org/browse/SI-7283) in the language implementation. It seems to be an error in the spec.
&gt; Is it worth migrating to Scala IDE from IntelliJ IDEA? No
I'm a bit confused by this, how exactly is SBT bloated? I find it interesting to call another tool "bloated" in the context of discussing something like Eclipse, the most bloated IDE around and far more complex then SBT.
Like many of us that frequent this subreddit, I took this class. I can say that it is very worthwhile, even for experienced devs. He mirrors [SICP](http://mitpress.mit.edu/sicp/) for teaching functional programming and also pulls from his own book, [Programming in Scala](http://www.amazon.com/Programming-Scala-Comprehensive-Step-Step/dp/0981531644). Buy the book and read it alongside if you have the time. He and his students (and his wife) have created some exceptional videos that go beyond what I've seen from other Coursera classes in terms of production value. There is also an automated grading system that allows ~~unlimited~~ many commits so you can get immediate feedback without penalty.
I signed up for the course, looks like it could be a lot of fun. I'm hoping I can follow along. I'm no functional whiz, but I work with Java every day. So I'd like to believe I'm familiar enough w/ programming fundamentals and the JVM to follow along w/ this course. 
I'm new to that class(and to Scala), and I think (at least for this iteration), you can only commit an assignment five times, latter ones won't be graded.
I appreciate this isn't very revolutionary code, but my colleague and I thought it was a vast improvement over the old code and now try to take the approach of using small composable functions in the rest of our code now. So I thought it was worth sharing, what do you all think?
I thought modloader was being phased out (?). Is there any way to get a mod working using scala for forge instead?
Would anyone who was there or has watched all the videos give a top 3 list of their favorites and why they are good?
Seems rather new, and I hadn't heard about it before, so I thought this was interesting. The source is only published a week ago. There is also going to be [a presentation](http://www.meetup.com/ny-scala/events/106576152/).
I'm not sure how my question got lost. The image is pretty self-explanatory. I'm a beginner to scala and reading Oedersky's book. Typing this example into IDEA12 with the scala plug-in generates these type errors. Using fsc, it compiles fine. Is this just a limitation of IDEA's scala support?
It breaks some releases, gets fixed later. Give it a month and it will work.. though something else will break
sometimes weird things like this happen when your project doesn't have a valid JDK selected.
I'm was using an old version of Java7 on MacOS. Just upgraded to 7.17 and the problem is still there. It just might be a plug-in problem for the time being.
Using IDEA 12.1, and scala plugin 0.7.213 (both latest). It's working perfect for me, I use a terminal window with SBT to compile, but IDEA compiles/shows me the errors too, and there are none in this case. http://i.imgur.com/ZV31u9M.png It's not a limitation of IDEA's Scala support. Up until around 6 months ago, you weren't guaranteed a working plugin version for every version of IDEA, and it was dicey on new versions. But it's been completely solid for around 6 months now in my experience, every IDEA upgrade has had a properly working Scala plugin.
File -&gt; Invalidate Caches
I also upgrade to the latest versions yesterday. What OS and JVM are you using? I am using Mac OS 10.8.3 and JDK 7.u17. Have you found that the JVM matters?
Thanks. This is the first time that I submitted an image. I put the comment under the "text" tab.
Not unlimited commits! Grades don't count after the first 5 commits. I made a boo-boo, treating submit like a git repo and submitting work as I completed each step in the assignment.
Oops! The grades don't really matter, though. As long as you make something like a 60 or 65, you'll get a certificate. Though I'm sure you're not doing it purely for that. ;)
I got a 6.6 in week one, my 7th commit that week got a 10. I was going to try for perfect scores, but now I'll just bump along getting 9s. I'm doing it 3 reasons: * To learn a new language. * To use Eclipse and TDD in a context other than my normal work to compare to how I use it normally. * To understand what it is about FP that makes it good for concurrency, multi core or distributed processing.
I used Eclipse for the first couple of weeks, but switched back to my normal editor, IntelliJ IDEA. The [Scala IDE](http://scala-ide.org/) (fork of Eclipse) was just too buggy for my tastes. Some of the developers at The Gaurdian took the class last time and [posted a guide](http://www.guardian.co.uk/info/developer-blog/2012/sep/21/funtional-programming-principles-scala-setting-up-intellij) to using IDEA for the class. Note that it may be slightly outdated now that IDEA has changed their SBT integration and compilation strategy. It is still worth the effort to look into...
I hope someone applies for the constraints solver. That would be a fantastic contribution to Scala!
I've been thinking of (but currently not having any time to build) a programmer's CAD tool written in Scala and using Scala as the design language—i.e. something like OpenSCAD, but with a focus on object-oriented and functional programming, rather than the awkward mess I end up with trying to build anything complex in OpenSCAD's language. Having a basic constraint solver library available to me would be a great boost if I ever get around to that!
Did Intellij already have play2 support? Do they have a similar plugin? I'm not a scala developer yet, but I am considering diving in.
It looks like it does have play2 support, but it's not clear the differences between the plugins as far as features.
Scala is one of the coolest languages I've used. This looks like a great resource for learning how 'real' scala gets written. 
So I've heard, though I'm extremely familiar with Java so I find a lot of Scala to be intuitive and it lets me ease my way in to functional thinking. I plan on checking out haskell at some point though.
Haskell is really nice. The advantage of Scala, however, is that while you can have all that functional awesomeness (check out scalaz) you can still make use of the huge number of Java libraries and all the other advantages of the Java platform. Also you can easily fall back to imperative where necessary.
You should check out the haskell landscape. It's not a bare wasteland anymore. Batteries are already included. I use haskell for web development, internal web REST services, JSON in'n'out, batch processing, pdf creation. I send emails and encrypt files. &gt;Also you can easily fall back to imperative where necessary. Never was a problem for me in haskell. As someone said, haskell is the best imperative language on earth :) 
Yeah I wanted to get into haskell anyway. Just haven't got around to do it yet short of a little dabbling.
There's not nearly enough information here to determine. How is User defined? How are you accessing the database? But just looking at this, it looks WAY too complicated to really understand.
I'm also new to scala, so take what I have to say with a huge grain of salt,. It seems to me that you are programming a lot like java - vars, loops, very long repetitive calls like getUserByUsername(user.username), and lots of exceptions. I think maybe instead filter the iterable user to the ones that cannot be saved, and then you'll have two lists that you can work with, instead of returning failures and successes. 
I'm a Java programmer by trade, so that's very likely... As I understand things though, this isn't actually a for loop, it's a comprehension over a Try[User]. The idea being that every step of the chain is executed only if the previous step returned Success, and will itself return either Success or Failure. We then get out at the very end a Try[User] that is either Success if all of the tests passed, or Failure containing the first one that failed. 
The ultimate reason for this not working was because the directory was not configured under the source path. This is a bit strange because I created the directory and sources using the IDE. It turns out that you need to still mark it as source.
If you want the for comprehension to define a *Try* object, you should always wrap your user in the *Try*. So it must be a *Success(User)* or a *Failure(Exception)*, in each of your matching blocks. something like userWithId &lt;- user.identity match { case None =&gt; Failure(new IllegalArgumentException("No identity provided for user")) case _ =&gt; Success(user) } So that you get a *user:Try[User]* On the second match, you're not supposed to *get* the *identity* option, but to match on it, lest the identity is *None* and you get a pretty exception due to a missing value persistedUser &lt;- user.identity match { case None =&gt; Failure(new IllegalArgumentException(s"Missing user identity: ${user.username}")) case Some(i) =&gt; getUserById(i.id) match { case None =&gt; Failure(new IllegalArgumentException(s"Unknown user with id: ${i.id}")) case Some(u) if u.identity.map(_.lastModified.ne(id.lastModified)).getOrElse(false) =&gt; Failure(new IllegalArgumentException(s"Last modified date of user is wrong: ${i.id}")) case _ =&gt; userWithId } } once again this second check returns a *user: Try[User]*. We need to stress out a couple of fact in the code so far: - each new for-generator (the left hand side of the *&lt;-*) should have a different name. It's not a variable to modify. It's a sort of name binding to use in the following comprehensions. I know it sounds complex, but it makes sense if you look at the for comprehension desugaring as a *flatMap* call: (user.identity match {... returning a Try[User]}).flatMap(userWithId =&gt; (... second check).flatMap(... and so on)) So each nested *flatMap* (or generator in the *for* syntax) has visibility of the previous binding, and reusing the same identifier creates confusion. Think about val list: List[List[Int]] = ... for (i &lt;- list; j &lt;- i) yield {... here you have both i and j} - if you need to extract values from an option, the suggested way to avoid exceptions is to use *getOrElse*, which gives an appropriate fallback value, or to use a pattern match. When there's need to transform the value in the option, you have *map* as a friend Based on the second point, I would rewrite the third check as uniqueUser &lt;- getUserByUsername(userWithId.username) match { case Some(u) if u.identity.map(_.id.eq(user.identity.get.id)).getOrElse(false) =&gt; Failure(new IllegalArgumentException("Duplicate username")) case _ =&gt; userWithId } What we get from here is that since we're not really interested in some of the intermediate generator bindings, we can avoid to use any identifier for them, but just write: _ &lt;- doSomeCheck To put it all together we have rewritten the method as def canSaveUser(user: User): Try[User] = for { _ &lt;- user.identity match { case None =&gt; Failure(new IllegalArgumentException("No identity provided for user")) case Some(i) =&gt; getUserById(i.id) match { case None =&gt; Failure(new IllegalArgumentException(s"Unknown user with id: ${i.id}")) case Some(u) if u.identity.map(_.lastModified.ne(i.lastModified)).getOrElse(true) =&gt; Failure(new IllegalArgumentException(s"Last modified date of user is wrong: ${i.id}")) case _ =&gt; Success(user) } } verified &lt;- getUserByUsername(user.username) match { case Some(u) if u.identity.map(_.id.eq(user.identity.get.id)).getOrElse(true) =&gt; Failure(new IllegalArgumentException("Duplicate username")) case _ =&gt; Success(user) } } yield (verified) We've also merged the first two checks nesting option matches. This still is a bit messy; as you can see try comprehension is all mixed up with the option matches. We can put to use the *Try { ... }* syntax (which calls *apply* on the *Try* object) to automatically write our user checks and convert exceptions in a *Failures*. def canSaveUser(user: User): Try[User] = Try { user.identity match { case None =&gt; throw new IllegalArgumentException("No identity provided for user") case Some(i) =&gt; getUserById(i.id) match { case None =&gt; throw new IllegalArgumentException(s"Unknown user with id: ${i.id}") case Some(u) if u.identity.map(_.lastModified.ne(i.lastModified)).getOrElse(true) =&gt; throw new IllegalArgumentException(s"Last modified date of user is wrong: ${i.id}") case _ =&gt; user } } getUserByUsername(user.username) match { case Some(u) if u.identity.map(_.id.eq(user.identity.get.id)).getOrElse(true) =&gt; throw new IllegalArgumentException("Duplicate username") case _ =&gt; user } } Still not the optimal solution (you can have a look at Scalaz Validation type, if you dare...) Otherwise we can turn the problem upside-down and factor out major code duplication in a local method. Let me know if you can wrap around the following. https://gist.github.com/anonymous/5371134 I hope I didn't make mistakes, since I can't verify it on a test system.
Your last code block is a lot cleaner than what I had, which is great :) Would you consider this kind of code to actually be a good way of doing this kind of checks though? Or is there some better way of writing the code?
Which then brings me back to the original question. If this isn't a decent way of achieving this kind of checks in Scala, how would you do it instead?
Again, it's hard to say because you're limiting yourself to "this kind of checks". I probably wouldn't check like this. I would make sure that a User object is savable at any given time, ie I would validate it when I create the object instead of when I save it.
&gt;Doesn't that mean the user object needs to know how its being stored in the database Possibly. I'm not sure what kind of 'validity' you're checking for. If you're checking for if the object is valid in terms of relationships in your database or something, you should let your database handle that via the schema or constraints or whatever. If you're checking for business rules validity, you should check before/during construction of the object.
So you're suggesting that the creation of the user is a lot more than just "new User(...)"? Or that the constructor does database lookups to ensure the username is unique? And the setter would need to too, if the username is changed...
&gt;So you're suggesting that the creation of the user is a lot more than just "new User(...)"? Possibly, yeah. You could make a companion object and make creation happen there. 
A lot depends on context. If you'r working on a concurrent application, you can't but check for duplicates at save time, and you must ensure that you do it atomically, too. You can make asynchronous calls to some sanity check, though, to increase user experience by displaying possible failures before they happen. Too many variables and design choices are involved to give a definitive solution. I just tried to tidy up your code as I see fit, trying to stick on your premises. I wouldn't personally use Try objects unless exceptions are unavoidably introduced through library use or to signal some serious failure (This is how I interpret the Try design). I'd advice the canSave method to return a possibly-empty sequence of errors, or the first error found, or a simple boolean, depending on the level of information needed, and the checks be made concurrently by sequencing Future calls. But since in the original post we're talking about learning and making practice I'd leave the actual coding to you.
The real thing I was trying to get at was - in Scala, what would be considered the "best" way to write code that ensures the conditions I listed earlier are met? The way I wrote the code seems to me to make the most sense, but that's coming from an OOP Java background and not a Functional background, so I'm likely missing things that make it a lot easier to work with. The one thing that I'm really not keen on - but which seems to be how a lot of people do it these days - is to write into the User object knowledge of how it reads and writes from the data store. Again it might be my OOP background, but the serialization mechanism - in my mind - is not part of the data object but is something that acts on the data object, so that it can easily be switched out for some other form without the data object even knowing about it...
Hmm.... I wrote something similar in Scala for Gox. Then found the java xeiam-xchange package... 
Using the Scala IDE (as a plugin) got a much better experience for me with the 3.0 release.
hmm. Maybe I should revisit. Especially since they have pretty decent Play support as well, I've heard.
I've just came across this library when I was looking for rational numbers in Scala. It's amazing import spire.syntax._ r"1/4" * r"5/7" According to the video, the string interpolation of the literals happens at compile time, including possible simplifications of the numerator/denominator. It also allows to tweak rationals so that the numer/denom do not exceed a particular value. Good stuff in there.
**Core News** * Scala Days NYC * Scala 2.10.1 * sbt 0.13-M1 * sbt in Action MEAP * Emacs support **Community News** * New Dispatch version (standard futures, readable operators) * New Scalatra version * New Unfiltered? * New Subcut version (DI by Dick Wall) **Discussion** * Dependency Injection * sbt for Android * Scala on Android * Cake Pattern * Next podcast will be May 8th **Community** * LWJGL plugin for sbt (light weight Java OpenGL bindings) ---- **Cut - start new episode #5 (?)** **Discussion** * What is idiomatic Scala? * Best Practises, mutable vs immutable * JSON libraries * Nulls, Reflection * For comprehensions * Operators 
Very nice. So when can we expect all these cool macro functionality to end up in Scala proper? 2.10 only got def macros and none of the right, is that right?
Cool, thank you. I'm looking forward to more macro work in Scala. I think it opens many new doors, especially for library developers.
Actually, only type macros and macro annotations are missing from 2.10. The rest (def macros, dynamic macros, string interpolation macros, implicit macros) are there. The only thing is that there's an issue with implicit macros (SI-5923), which prevents them from being used for materialization, but it's fixed in master (2.11.0-SNAPSHOT), and I plan to backport it to 2.10 (maybe it'll even make it into 2.10.2). 
I wish the scala compiler could compile macros in the same compilation unit that they're used in. That's the only thing that keeps me from using them more widely. I'm not sure if this is technically possible, but it would definitely make life easier.
These are doc-macros, nothing to do with code macros, despite the name. They are placeholders you can use if you need to paste a particular snippet into multiple doc comments.
I realize that the blog is about doc macros. But the source code of the example uses macros. I was just tangentially commenting about macro compiler implementation.
Looks good mate!
[Link to the actual article](http://files.osmek.com/get/12632.pdf) 
Honestly, what do you you expect? The guardian (or any other Typesafe client) has nothing to gain with writing this whitepaper so why should they invest time &amp; energy into writing one? This kind of marketing is standard practice, if a company is looking to adopt Scala, Typesafe will probably suggest that they should talk to some manager at the Guardian (or another big custormer) to add legitimacy to their claims. In return the Guardian probably gets some discounts or better support...
The folks at foursquare, linkedin, twitter etc would like to have a word with you, if you think Typesafe can't find case studies of scala used in the industry. Check http://twitter.github.io/ and see how Typesafe is "having a hard time" coming up with scala case studies. But you already knew this. So why I am I typing this? So that I can politely ask you to fuck off this sub-reddit and go shit somewhere else. 
&gt; The folks at foursquare, linkedin, twitter etc would like to have a word with you, if you think Typesafe can't find case studies of scala used in the industry. Yes, these case studies date from 2010 and 2011, so you're basically confirming that Typesafe is having a hard time finding new case studies? 
Ooooooooooooooh, now it is "new" case studies that you want? Maybe you should go back and edit your earlier post and add "new" to it. I am confirming your bullshit, aint I? Very flexible with the truth aren't you. Or better still go here http://www.scala-lang.org/node/1658 and figure out why none of those examples apply, because they are too new, new but maybe old, too old, too much, too frothy or too irritating. Or maybe just go troll some other subreddit. Take your shit elsewhere. You don't like scala, don't use it. If they force it on you at work, go jump off some building. 
Hum, type safe in what sense? As in Slick?
[*cough](http://engineering.linkedin.com/incubator/technology-behind-eatin-android-apps-scala-ios-apps-and-play-framework-web-services)
Not necessarily. I definitely don't think it should be an ORM. But maybe using either named parameters instead of ordered ? replacement, possibly being able to type the parameters as well. I don't really have a good answer, but I have actually thought about this in the past. I just think this is 2013. Untyped string replacement just seems so dated.
This is exactly how this happened to me.
What part of "The full paper by our Head of Architecture Graham Tackley" do you need explained ? http://www.guardian.co.uk/profile/graham-tackley
src: https://news.ycombinator.com/item?id=5674510 scala-zeromq - thread-safe ZeroMQ sockets for Scala (github.com) ' z0r 42 minutes ago | link The 0mq extension included with Akka has serious design problems, so I'm happy that mDialog has let us open source this. (I didn't write it, but I've worked on issues we've had using the original Akka extension). The Akka actor wrapping each 0mq socket sends itself a message to trigger a poll, which blocks for a configurable period of time. Messages easily queue up both in the actor's mailbox and on the 0mq socket. The default settings for the extension leave you with very high latency and poor throughput, but even if you modify the polling frequency and timeout you end up trading heavy CPU usage for what ends up being increased but still capped latency and throughput improvements.' alt: http://doc.akka.io/docs/akka/snapshot/scala/zeromq.html
http://doc.akka.io/docs/akka/snapshot/scala/zeromq.html
That title sounds like you are trying to sell me something...
Please note that paradise builds exist both for 2.10.x and 2.11.x. The former can be used for production programming together with a vanilla 2.10 compiler: http://docs.scala-lang.org/overviews/macros/paradise.html#macro_paradise_for_210x.
That's an unsubstantiated claim that could be said of any language.
 [**@psnively**](http://twitter.com/psnively): &gt;[2013-05-13 18:01](https://twitter.com/psnively/status/334005416944095232) &gt;It's OK to believe [#scala](https://twitter.com/search?q=%23scala) is complex. The problem is believing [#java](https://twitter.com/search?q=%23java), [#csharp](https://twitter.com/search?q=%23csharp), [#ruby](https://twitter.com/search?q=%23ruby), [#python](https://twitter.com/search?q=%23python), [#php](https://twitter.com/search?q=%23php), [#java](https://twitter.com/search?q=%23java)script aren't. ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/1eav4a%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[Translate]](http://translate.google.com/#auto/en/It%27s%20OK%20to%20believe%20%23scala%20is%20complex.%20The%20problem%20is%20believing%20%23java%2C%20%23csharp%2C%20%23ruby%2C%20%23python%2C%20%23php%2C%20%23javascript%20aren%27t.) [^[FAQ]](http://www.reddit.com/r/TweetPoster/comments/13relk/) [^[Statistics]](https://www.stathat.com/decks/PJSe8OF5J44Y) 
Fair enough. Still, Scala is more complex than any of those, maybe with the exception of PHP.
Scala seems complex. But then I go back to writing C++ code and suddenly all the fold-case-match-recursion stuff looks really easy again, because I'm three templates deep into my code and trying to convert a string from UTF8 into some eastern ASCII set to use an ancient library which uses COM for interface design, and then a void* explodes somewhere on the heap, outside of any exception handler. Two weeks later I figure out that it's just an off-by-one error. Good times!
You could also put forward a case for Ruby as well. Unhygenic metaprogramming and some of the ways you can mess with (break imho) lexical scoping. But yeah .... Java/CSharp/Python clearly aren't as complex.
Python *is* complex, but hides it from beginners. I'm not just thinking of metaclasses and weird type hierarchy, but also performance characteristics and general behavior. Its innards are full of surprises.
Martin Odersky on the topic of complexity of Scala and programming languages: http://lampwww.epfl.ch/~odersky/blogs/isscalacomplex.html. Basically, when discussion the question whether Scala is complex, it is necessary to ask in regards to what perspective Scala is complex. For instance, Scala is definitely complex in terms of the depth of its features relative to other languages. But Scala is also relatively less complex in regards to features that are provided as libraries in Scala, that tend to be provided either as built-in features in other languages, as extensions, or with very verbose syntax (compare for instance Scala's actor libraries with actors built into Erlang).
I think Scala in Depth is the best of these. It moves quite quickly so it takes a lot of focus to keep up with it. 
the list at scala-lang.org needs some updates - Atomic Scala by Eckel, Marsh - Akka book by Wyatt - Akka in action, Roestenberg has about 1/2 of chapters in MEAP http://www.scala-lang.org/node/959
Assembly must be really simple then. ;)
It should probably be in a sufficiently synthetic language.
Well, it's complex in the sense that not a single one of the refactoring tools in the eclipse plugin can do their job right. Even simply renaming a variable is apparently so complex that it fails to do so correctly. That would be my definition of complex. So complex, the tools to manipulate scala code written by people who know scala extremely well, don't work.
The Scala language is necessarily more complex since it's multiparadigm, but the code may be simpler than Java/C# code because the Scala language is more expressive. The functional style suits some applications better than others.
Interesting article! Doesn't go into great technical depth, but gives a good overview of the benefits of akka.
Couldn't agree more, I don't really think I've ever had a Scala solution in my own code that was more complex than the equivalent Java/C# (as at worst case Scala can easily express the same concepts). 
Another definition of complex: so complex the makers of the best IDE around for Scala said to themselves, "fuck this bullshit, let's make a whole different language that's not so fucking complicated!"
My day job is c#/.Net. I'm not convinced scala is more complicated than it but maybe that's because I've not dove deeply into scala. C# has many, many niceties that I'd venture to say most c# programmers don't use. They've adopted many functional principals w/ c# using delegates and events, so the language itself partly satisfies the two paradigms oo and functional (similar to the flexibility you get in scala). Also there are asynchronous helpers w/ tasks in the newest versions that I've yet to explore. The one thing that I definitely think scala is more 'complicated' on is implicits. Using the Eclipse IDE, in some .scala files almost every line is using some sort of implicit! If I was to track all that back and realize what is actually going on, it would take some time. C# has extension methods which are similar (but not quite as dynamic), but they can easily be tracked back.
Does anyone use this library?
Looks like more than a handful http://code.google.com/p/factorie/
It's like seeing a cockroach walking across the floor. For every substantiated claim of a company getting significant gains out of a technology, there are 100 that aren't talking about it. There are a lot of languages that don't have any. 
No, I wouldn't say that. All the languages mentioned are vastly more complex than Scala.
Scala is definitely complex in the sense that it is easier to support languages such as Java with good tools than it is to support Scala with good tools. And good tools are very important when using programming languages. However, I believe the increased difficulty of supporting Scala is a trade-off for getting a language that is both more advanced than many others and still very pragmatic. Martin Odersky and Typesafe have been aware of the problems with the tool support for some time and have worked to improve it. In my experience, the tool support has gotten a lot better over the years; in 2010, the Eclipse plugin would frequently crash and hang and have other issues; in 2013, the stability and general performance have improved a lot. It will probably take some years before the tools get really good, but in my opinion, they are currently quite usable.
I've been using the plugin since those days of crashing. It is frustrating that the basic refactoring tools just don't work. I can understand a newly introduced option not being right, but when a year has gone by since it's original introduction, and many many more broken refactoring options have been introduced since, and still none of them have been made to work, I have to wonder what is going on. Do none of them use any of it?
I don't think it has to be more complex just because it is multiparadigm. OO and FP complement each other quite well. Compare Scala's lambdas to Java's AICs.
Having read most of these books I'd rank the best Scala books as follows: 1. Scala for the Impatient 2. Programming in Scala: A Comprehensive Step-by-Step Guide, 2nd Edition (be sure to read Chapter 1 for some intro/context to Scala) 3. Scala in Action Scala in Depth is more of a best practices book, but some of the content seems to be subjective / personal preference. The O'Reilly book on Scala isn't that great and neither is the pragmatic bookshelf one.
It's a matter of priorities and resourcing. Refactoring is 100% community driven. The Typesafe team has concentrated on getting the core functionality (building, completion, hyperlinking, debugging, etc) to work well and to create a framework where people can contribute easily. I have no doubts that with the proper effort refactoring could be improved quickly.
Good information! That is a good example on the weakness of extension methods. And as a side note, I wouldn't consider myself a critic if your tl;dr was addressing me. I'm actually a self-taught convert!
Good points. I'll bring it up with the IDE team.
I don't think it's even right to be comparing "complexity" of languages, at least not amongst the ones mentioned here. They can be complicated to think about and work with in different ways. Except PHP... oh, PHP... that's a language that I hope to never, ever touch again in my life.
Why won't this show?
There are always two parts of an equation. Watch a Kotlin talk, you'll see why people are sick of their FUD.
Because it's not out yet..
Something related to the number of... "primitives". The more primitive structures there are, the more complex it is. But also, the less there are (see assembly, as another poster mentioned), you get a different kind of complexity that arises out of it being too simple. So complexity is like a negative parabola as a function of primitive count. e: yes, "primitive", ty
*primitives But that's not complexity we're talking about now, that's pragmatism. The lambda calculus is simple, but not pragmatic. Scala is incredibly complex (minimal size of compiler: infinity, since the type system is Turing complete), but very pragmatic. Also, assembly isn't necessarily simpler than, say, lambda calculus, it just depends on the underlying system in this case.
Sick of their FUD? I haven't encountered anything like that, if anything, people are excited that new languages continue to be created. You should be too, the more competition Scala has, the better it will become. For example, there are already internal talks about adopting Kotlin's `?.` operator in some way. 
&gt; Sick of their FUD? I haven't encountered anything like that For instance claims like “there is no IDE support for Scala and it's pretty much impossible, too” or “the for loop is slow and it's not possible to fix”. There is just so much needless bashing, that I'm wondering why they don't manage to convince people by shipping working software instead. Really, just watch any talk by them and you have a high chance of encountering stuff like that.
Just bought it, I will hold you to that evaluation.
just an FYI, I did not read the book in a vaccum. It is good, but I needed to read about many of the concepts from various points of view to really grok them (this is an ongoing process). http://eed3si9n.com/category/tags/scala/scalaz and http://blog.tmorris.net/category/programming/index.html were invaluable. 
&gt;val it = x.run.run // wtf ? yeah... I know. :-/ More: I think Play is a weird web framework, but I don't have much experience with it. None the less, your code is fairly easy to follow. I don't think you need to assign a variable to the result of the for comprehension to return it in your 'listSkillsUserPicker' method, but that's probably an artifact of debugging/writing the code, and certainly not an egregious mistake. I'm probably not experienced enough in functional design/scalaz to say if this is *good* code, but it certainly doesn't look at all bad to me. 
https://github.com/lampepfl/scala-js/blob/master/examples/helloworld/HelloWorld.scala
Finagle and Scala is sounds pretty good. I heard Blake at Tumblr speak last year and it seemed they used every technology out there at some point. Glad to see they are pairing things down to a sane set of technologies. 
I'm sorry to hijack this thread, but I just spent a lot of time fixing a refactoring botched by the ScalaIDE and remembered this thread. 'Rename package' and 'rename type' have basically never worked for me. I'm using the latest stable ScalaIDE, and 'rename package' just left lots of errors I had to fix manually. I understand people-power constraints, and generally agree with the Typesafe team's priorities for the IDE. But I also agree with speek in this thread: refactorings that aren't going to work shouldn't be clickable options in the UI. IDE troubles or no, thanks for Scala! It's great!
We've been testing this out in our development environment. My main gripe is the web interface is balls slow. So while the information it sends is pretty thorough and definitely a step up over airbrake we don't really want to move use of this into production until the issues with site performance are addressed.
Takipi is in open beta, so it is currently free (we should remain in beta at least until the end of the year). The final model is not set yet, but pricing afterwards will probably be on a per-server basis.
&gt; It's sort of ok. You can imagine it's being like the price of oil in Norway, or something. :) Basically he introduces quickly former projects he did for quickly sketching graphics with Scala, like SPDE which is an adoption of the Processing IDE, and a browser based version of that (which I had never heard of). Then comes to Scala Notebook which is a REPL in the browser with the possibility to emit HTML elements to display results. He adds custom widgets for SVG, so you can easily draw graphical shapes from the REPL, and then goes as far as importing some fancy JavaScript library for data visualisation (D3), so you get like a reactive view to a data model, which does automatic interpolation / animation and so forth.
Great. A tool similar to the python notebook was on the top of my wishlist.
They most certainly made no such reference to coitus in regard to their support of Scala. Their plugin is brilliant, and getting better every day.
A lot of scala - everything FP related
Brony alert.
Our newest events seem to be from May 23rd, which is suspicious as that seems about when your deployment went out. I don't believe anyone would have disabled our integration in the development environment but I'll check. I'll hit you up on mail if I find an issue.
I know this is /r/scala, but I'll just chime in since no one else has. TBH, my favorite way to develop on GAE is either Java/GWT if I'm doing a single page app, or Python and jQuery. That's not to say that Scala webapp frameworks don't have their place, but the Eclipse tooling for GAE/J and the tooling in place for Python provide a significant advantage over the language benefits you gain by writing in Scala. I'll get some Scala code in some of my larger Java apps, but that's only when the benefit for whatever module or processing lends itself to being written in Scala. Sorry if that's not the answer you wanted to hear, but I'd be interested in how many people agree or disagree.
Python is definitely my backup as I have no interest in dealing with Java (especially GWT). Kind of disappointed about the crickets for Scala on GAE. You're experience is probably correct in that there is no streamlined experience on GAE with Scala. Which is a little dissapointing.
I did a Lift app on GAE a few years ago (2009-10ish). It was a pain in the ass to configure initially but once I got it running it went really well. I don't love Lift, but I looked at it again recently precisely because I was looking for a Scala solution for GAE and it seems to be the only game in town. It looks like the situation has improved re: getting it running on appengine, but I ended up going with Python because I really didn't want to go down the Lift rabbit hole again.
Perhaps you could make Play 2 work with [this](https://github.com/dlecan/play2-war-plugin/).
These slides are associated with a talk and workshop given at LambdaJam 2013 conference in Brisbane. Both of these were recorded so keep an eye out.
Play 1 with GAE plugin worked very fine for me.
Are there more resources about modules as Daniel talks about them in his key note. He spends a lot of time talking about how amazing they are, but I feel like I am missing something.
It was too painful to watch, I gave up.
I wanted to like it, but the speaker seemed really nervous and it was just too hard to watch.
I came across this morning: http://notes.implicit.ly/post/50957458017/sbt-appengine-0-5-0
Cool but... would be much more interesting if it was a command line app. Something with a better integration with sbt for instance.
I'm not sure that this view is any better than seeing the raw stack trace.
In what ways is it better than the default stack trace? 
it doesn't look like it improves much but it does at least collapse scala library errors. 
You read my mind. Glad I wasn't the only one.
Haha! Glad to see somebody else just jamming in the oh-my-zsh cookbook. I put that in all my Berksfiles in vagrant-using projects to get a decent, not home but it is a hotel, shell asap.
1. Hipster 2. Transsexual 3. Brony EDIT: Downvotes? Really?
hi OP, i would really really like to see an example usage (first of indexed state, then of indexed cont)
Functional hipster goodness.
Actually I think games would be a prefect place for scala. You normally have a rendering thread and one or more physics threads. The game state could be held in a immutable map. 
You may be interested about performance, especially in more critical code paths. For example, this will allocate dozens of short-living objects, even if `doSomething` doesn't do anything substantial: for (x&lt;-width; y&lt;-height) { doSomething(x,y) } Here's a talk about Scala optimization techniques: http://www.youtube.com/watch?v=IfLwuCVRQTU 
Are there specific questions you've run into that you don't know the answer too? Maybe I can help. I'm also planning on writing a blog on how to do a concurrent, multithreaded game engine in scala without mutable state. 
I'd like to emphasize how much better this pattern is than creating incredibly long inheritance hierarchies. 
Oh yeah, Type Classes are awesome that way. I'm not sure, but I think you incur a performance penalty for it in scala.
I think you're thinking of doing a type alias type toStringable = { def toString: String } I believe that does use reflection, but implicit conversions use the compiler to generate the proper bytecode without reflection. 
I'm glad to see I'm not the only person interested in game programming with Scala, avoiding mutation whenever possible. As a start, I've discovered that you can make a simple game loop function that takes state as its parameter(s) and calls itself recursively with tail-call optimization. I'm trying to expand toward the actor model and simulating state machines, I think it will be a promising way to structure everything. I'd love to see what other (more experienced) Scala programmers are doing with this subject.
I'm seeing a lot of advice here from people who seem to be much more familiar with Scala than with writing games, so allow me to offer some counter point. There is pretty much only one path on the JVM to write games, OpenGL (or more specifically, lwjgl). OpenGL is a very, very efficient library which, for better or for worse, relies heavily on side effects and global state. There are reasons for this: immutability comes at a cost that is simply incompatible with games with decent performances. If you're writing a 2D game, you might get away with turning the immutable knob to 10 and still see decent performances, but make no mistake: your game will most likely be unplayable on all but the fastest machines if you are not willing to make compromises with mutability for performance. I've been there, my first games were following standard type class/OO hierarchy, the code was clean (in my opinion anyway) and... they were dog slow, nearly unplayable. Once I gave up on the concept of "nice looking code" and started writing my code based on what the profiler was telling me, my source became much more ugly but my games suddenly got much, much better. Finally, a general word of advice before you embark on that long, painful and rewarding journey: when it comes to writing a game, language should be a secondary concern. Pick the best technology for your game and adapt your habits to it. Yes, even if it means Flash, ActionScript, C# or C++ with Unity. You'll be much happier with the end result, even if it's a bit painful at first (and to be honest, Scala would be at the bottom of my list for potential languages to write games in). 
First I should clarify that the game is in the roguelike fashion. The graphics are unicode and (right now) just being sent as 2d char arrays to JFrame components. Could you detail the performance issues with immutability? Also happy cakeday.
You can use the G1 collector options to get near-soft realtime guarantees. 
Why do you think creating short lived objects has an impact on the garbage collector? Are you not familiar with how generational collectors work, or G1?
I've spent approx 12 man months full time in to a game project written in Scala on top of LWJGL. It's 3D, and I feel I've pushed Scala/LWJGL quite far (core profile OpenGL), but haven't reached any meaningful limitations from them. I'm not going to have a popular opinion when it comes to Scala though as I sit in a middle ground, especially when it comes to games. Productivity is my goal above all else, Scala has been invaluable with allowing me to keep my code fast and maintainable and bug free (the quality of code is far and above other projects I've worked on), but I don't see pure immutable FP as the highest goal towards achieving this. Mutability/immutability/OO/FP are all tools I use to varying amounts. Scala's not strictly pure and it's not just haskell like FP, it's got a full set of mutable collections, and it's more than happy to get out of the way (as much as something on the JVM can) when performance is important (at it's worst it's just a less ugly java with type inference). On UML ... I have no idea, I've never seen virtue in UML. The most useful functional concepts I've found is mainly Scala's heavy use of higher order functions in addition to the richness of the in built immutable data structures and case classes. It's just a damn productive way to get stuff done. I use a mix of OO and FP (the OO stuff is mainly just for structuring state/data, classes and mixed in traits, no huge hierarchies), I've preferred functions over methods over time. I'm comfortable with FP, and a substantial portion of my code is FP (perhaps 40%), but nothing that touches any of the hot loops or anything that gets executed many times per frame. You're at times going to lose around an order of magnitude of performance if you do things religiously immutable, this wasn't something I was willing to give up. Mutating an array of integers is going to be insanely faster than repeatedly modifying a vector, or prepending to a list. In terms of awesome libraries (2 and a half of these are Java based): * Akka has been a valuable tool for coarse grained concurrency. * Kryo for serialization (with Twitter's Chill Library for some Scala specific serializers) * Netty for networking * LWJGL for OpenGL * Scalaxy loops for converting integer based for expressions to simple while loop bytecode. So I don't cry myself to sleep writing while loops. I'm happy to elaborate further or provide samples on just about anything, but I'm not an FP purist. Scala's an awesome language, and I honestly don't think I would have enjoyed myself, or been as productive, or as bug free had I not chosen Scala. On books: * Scala for the Impatient * Functional Programming in Scala (currently in MEAP). Awesome book, though not all that useful for my game dev. * Scala in Depth The thing you'll find is there are hundreds of different people with plenty of opinions on the *one true way* that Scala *should* be written. This is somewhat of a curse to leading to a somewhat fractured community ... you'll have to feel things out and make up your own mind. Most things are tradeoffs.
Implicits are costless (take a look at the byte code). The only cost you'll pay is due to the interface based dispatch (since type classes use traits/interfaces) and the invokeinterface call (assuming the JVM can't work it's magic on the call site, it usually can't).
There are *huge* rewards to be gained from moving to Scala from Java, even if you 100% ignored immutability (which in itself would be a big mistake). Type inference, case classes, much more productive collections, pattern matching, implicits, traits. On the topic of GC. I'm not that careful on my use of memory (though I'm not using a strictly immutable approach), and G1GC set to 5 millisecond pauses (and heaps from 2-8G depending on what I'm doing) , I've run in to no pause problems. Any pause problems I've run in to have been from unexpected alg weaknesses instead of GC.
Short lived objects do have an impact on the garbage collector, just not in the way people expect. The faster you generate garbage, the more often the minor collections run. The more often the garbage collections run, the faster surviving objects are shipped in to survivor spaces/old gen. So the more garbage you produce, the faster you're filling your old gen with objects that perhaps shouldn't be there (lets say they're garbage shortly after getting there), and wouldn't be there had you produced less garbage. The less garbage you produce overall, the higher the chance that an individual object will be collected by the new collection (since it won't be promoted out). Producing lots of garbage isn't free even if you don't mind the cost on the minor collections. Immaturely promoting objects to old gen isn't something that should be ignored. Old gen isn't free to collect. While I use G1GC, I've found no documentation for it out performing CMS in any meaningful sense, regardless of the nice theoretics.
Akka is awesome. While my main loop spins, my render/sound/persistence &amp; terrain generation are all Actor based (anything coarse). Their futures/promises (now core Scala really) are also the backbone of how I interface with my networking layer.
Nice, I'm glad that it's generally costless, now if we can just get better typeclass usage syntax then I can die happy.
Awesome response. 
This is why you have multiple generations. You don't pay that big of a penalty for the occasional short lived object being moved from Eden to survivor space if most of your collections are in Eden space (and you will have frequent collections that do clear a lot out). G1 doesn't even have this problem as it deals in regions, not generations
Xtend looks promising actually, I'll look into it.
&gt; If you don't use uml or diagramming, is there a particular way you plan your programs? Not the OP; but pen and paper with rough sketches of what you want works out well for me.
You should pm me when you start this blog.
Is anyone using Activate? Care to share some experiences?
Thanks for linking the paper. It was quite the enjoyable and approachable read. I'd still say immutability is a functional concept though. It's imho the simplest way to get things done within the constraint of referential transparency (without resorting to state monads and waving concurrency goodbye). I know it's comical to quote Wikipedia after you've linked a Peyton Jones paper, but it suggests FP "avoids state and mutable data". If it's the easiest way of maintaining referential transparency, is it really orthogonal? I get your point though, thanks for the education.
Hello, i'm using Activate since for over a year now, in a few different projects. My experience with Activate, since the beginning, was really positive. It had a few hiccups (i started with version 0.6) but has been getting better every relase. Flavio (Activate's developer) is always very helpful to questions and fixing bugs. But now on the technical side, the reason i like Activate are these: - Way fewer code and boilerplate for persistance, i just need to warp transactional around the code i want to persist, and that's it. No more saving, flushing, refreshing... I still worry this is gona bite me sometime, but has not happened yet; - It works great with Scala. Being able to use Traits, and even query using traits, makes it feel like you're using scala to its potential; - Never worry about what's in memory and what's in database, Activate takes care of this; - Great performance, Flavio worries a lot about this, so it's great that i have to less to worry. I could go on, but i probably already look biased. It's hard for me tell the problems because i already got used to it (there are some problems, one which i remember are the sometimes crypitc stacktraces). But all said, you should probably take it for a spin and see how you like it. For me, going Hibernate -&gt; Activate was like going Java -&gt; Scala, and i do not look back.
With play 2 around I am surprised anyone uses lift still.
Play war Builds a war file pretty good. So pretty sure the more powerful and better ajax statements are also not true.
Play 2.0 does not support war file deployment : http://play.lighthouseapp.com/projects/82401/tickets/8-war-packaging
Why is that?
Is there a reason for this...? I liked his book and blog....
Maybe dpp wasn't "selling".
Does this release support scala 2.10?
I'm not big on the Ajax support in lift. It feel like a kludge.
And yet we've done it...
Ajax itself is a kludge.
Who uses Lift anymore? It's ugly and overly complex!
Any better suggestion? 
This release announcement sucks. What's new in Lift 2.5? I'm someone who's looked at Lift before, but as I recall I thought the template system too ugly, and so I focused more on Play. But maybe Lift 2.5 has something new in it and I should give it a second look. I guess I'll never know. All that release announcement seems to do is assert Lift was awesome before 2.5, and continues to be awesome.
Stop trying to misuse the browser as an application platform.
Yes.
Change: WriterT[scalaz.Id.Id, List[String], A] Better: Writer[List[String], A] This looks deadly: // provide fake monoid to make it compile... i dont think it gets used implicit object monoid extends Monoid[Throwable] { I assume this function: DB.withConnection has this type: (Connection =&gt; A) =&gt; A Encode it in a data type: case class DBCont[A](f: (Connection =&gt; A) =&gt; A) Guess what? It is a monad. Write `map` and `flatMap` and all that. This data type will help. I see you are stacking on another monad (`EitherT`). You can write this too: case class DBContT[F[_], A](f: (Connection =&gt; F[A]) =&gt; F[A]) This too is a monad (if `F` is a monad) and allows you to stack arbitrary monads in the computation. You can create values of this type and the glue them all together. Without the need to stack: type DBCont[A] = DBContT[Id, A] Some library code has been repeated: case Failure(e) =&gt; \/.left(e) case Success(v) =&gt; \/.right(v) Just write: _.disjunction I am not a big fan of `String` for log messages. Consider using a data type instead. It is way more useful to integrate with libraries, I won't have to parse the String after the fact if I wish to use it algebraically and I can always convert it to a String if that is ultimately the use-case. HTH.
Do these go with a talk we can watch?
This is a ScalaDays talk, and as far as I know (from following ScalaDays tweets on twitter) the videos will be posted online, but I don't know when.
Very nice, and as a user of both, very balanced. Scala is a bit more challenging to learn, but there are definite benefits.
I had that awakening after using functional programming languages with Hindley–Milner based type inference. The only place I see an advantage on dynamic typing, based on my experience, is when doing data structures manipulation like XML,DB tables or method call delegation. Still on the type of projects I work on, dynamic languages only work in small scale, because hardly anyone writes unit tests in enterprise software.
I remember a few years back when I was starting haskell and I kept fighting the type system. I just wanted my code to run, damn it and I was interested in other parts of the language. But now after doing scala / haskell for a long time its the type systems that I desperately crave in other languages.
The problem with DB and XML is that their schema varies and keeping it in sync with code is a chore. For example, if you're reading a database table with an unknown schema, it's way easier to put everything into a `Map[String, Any]` than to try and create a mapping between the table and strongly typed classes. In dynamically typed languages all objects are `Map[String, Any]`, so it's easier to work with them. Of course if you want to write to the database, you need to have some mapping even in case of dynamically typed languages. The same goes for JSON and XML: Scala's `xml \ "a" \ "b"` would be `xml.a.b` if using dynamic typing. Shorter, more convenient, more idiomatic, and will blow up on runtime just like the Scala version would. For reading this kind of data, you can either: * go dynamic (using `Map[String, Any]` counts here too) * maintain a bunch of boilerplate code that maps it to your classes * use [macros](http://s3-eu-west-1.amazonaws.com/presentations2013/56_presentation.pdf)/[type providers](http://fsharp.github.io/FSharp.Data/library/JsonProvider.html) Scala is a language that gives you all three options.
The advantage of accessing a foreign data and manipulate it as if it was proper language data. Something like (consider it pseudo-code): db = open_db ('db connection') column = db.table_name.column open_db() generates on the fly all necessary magic to make this work. With a static language you need to generate this somehow ahead of time, which mostly requires tooling external to the language. The best thing so far for this type of scenarios in static languages are F# type providers, but F# use is still quite limited out there outside finance world.
This talk was amazing! The guy who wrote it is very smart and very nice. I had to ask some really basic questions about how compilers work and he did not talk down to me at all. I think people were confused about how much work this took to accomplish and were tacking on things like, when will there be IO with File API, when can we use Akka with web workers, etc. And all this, just in 4 months! Totally ambitious that he also wants this to bootstrap. Anyway, I wish the guy much success. He's awesome! Edit: He mentioned he used a JS concatonator and I kind of wish he didn't. I'm curious to see what the compiled class file looks like (the one that is not the standard library, obviously).
Its nice how the type system in Scala can now indicate even information like this thanks to macros.
[Use recover](https://groups.google.com/d/msg/play-framework/UylCl0mAa00/_QM-gHisstcJ).
I hope they're planning on making the syntax less ugly…
&gt; it's way easier to put everything into a Map[String, Any] than to try and create a mapping between the table and strongly typed classes. Want a bet? I'll show you how it is definitely not way easier, IRC?
Thanks for the kind words! | He mentioned he used a JS concatonator and I kind of wish he didn't. Oh, why so? Would you prefer having zillions of script tags in your HTML? | I'm curious to see what the compiled class file looks like (the one that is not the standard library, obviously). For example, you can can have a look at the generated file for the Reversi: (in semi pretty-printed form) http://lampwww.epfl.ch/~doeraene/scala-js/examples/reversi/target/reversi.js Btw, each block (function($) { ... })($ScalaJSEnvironment); corresponds to a class, a trait, or a top-level object, and was 1 file before concatenation.
I just got done trying this, and it seems very good. It throws compiler exceptions for most unsafe serializations (anonymous classes for example), and throws runtime exceptions in the other cases. Hopefully they can find a way to serialize anonymous classes and functions, but even if they don't this is a very nice step forward.
Type macros = syntactical expansion of types + codegeneration within an enclosing class: http://docs.scala-lang.org/overviews/macros/typemacros.html. All that is gone with type macros being abandoned, though we're looking into other ways to do codegen. Blackbox macros don't require to be expanded for the program to typecheck. At the current level of tooling, this simplifies tools.
Ok thanks. The generation or transformation of methods within an enclosing class I find a very intriguing scenario, so I hope there will be something like that. I think macros have greatly lowered the entry barrier for experiments which were just too messy and difficult to do with custom compiler plugins. I had tried a while ago to write a compiler plugin, and soon gave up. Def-macros I managed to understand in a day (well, perhaps my knowledge level was higher then, as I had already fiddled around with ASTs)
Very impressive performance numbers, faster than Kryo and less memory! Quick question... How portable is the default format between languages? What would be required for e.g. Go and Scala to talk to each other in a distributed system?
Obviously this is a specific crowd, so no surprise that most people use Scala in their day jobs.
Casual uml for casual people. Go write this book.
You can search SO or scalex.org for operator "&lt;++=" (scalex 0 hits tho http://stackoverflow.com/search?q=[scala]%22%3C%2B%2B%3D%22 http://scalex.org/?q=%3C%2B%2B%3D ------------------- I've asked github to work on this, maybe other people can ask too https://github.com/contact
&lt;++= is in sbt, and means "concatenate a value that depends on the value of one or more keys with this key's current value". It's usage is discussed in the sbt readme here: http://www.scala-sbt.org/release/docs/Getting-Started/More-About-Settings.html I don't know if you have it anywhere else, but it's not scala code that you'll run into often. Basically in sbt, you have tons of keys such as target or name or install. Some are setting keys and some are task keys. When you do name &lt;&lt;= organization that means that the value of name depends on whatever organization is at the moment. &lt;+= adds something that depends on key to a sequence. &lt;++= is useful for the libraryDependencies key, where you have a bunch of dependencies that depend on another key: libraryDependencies &lt;++= scalaVersion { version =&gt; Seq("org.scala-lang.whatever" % "scala-compiler" % version, "org.scala-lang.whatever" % "scala-reflect" % version) } This syntax is deprecated in sbt 0.13 for a much cleaner style: name := organization.value //name now depends on the value of organization libraryDependencies ++= Seq("org.scala-lang.whatever" % "scala-compiler" % scalaVersion.value) //libraryDependencies now has a library that depends on the value of scalaVersion added to it.
Had the pleasure of seeing this talk in person when MO redid it for the SF-Scala meetup last night. Was pretty inspiring, and I heartily second the recommendation to watch it when available. The west coast talk was recorded as well -- I've heard it will be available on Marakana at some point.
This abomination of over-engineering is still alive? 
Yeah I screwed that up. Going to remake this post with the proper link.
http://www.reddit.com/r/scala/comments/1gx53a/easy_to_use_type_classes_in_scala/
I noticed the Play &amp; Scala IDEA plugins were in conflict for the past week but it seems to have been fixed today.
I'm with you, but shouldn't your hatred be directed at IDEs and not scala? I've had just as much trouble with Java and eclipse. Despite the extra 'overhead' of using Vim, I'm still way more productive in it with scala than I was with java and eclipse. 
Yes, but even the typesafe offerings are extremely difficult to get running. So while the language isn't the culprit the community/infrastructure is. I love the language but want an IDE/environment that works. Sadly, the only thing close for all-in-one that I've used is C# with resharper. Also, its been my experience that anything is more productive than 'X and eclipse' :) I feel that this is a hangover from java/eclipse; JVM IDE are traditionally nigh-impossible to use/set-up so the bar is set a lot lower. 
IDEA is actually better, though not perfect. It hasn't crashed/stopped working for me, at least. It's at least worth trying to get working. What doesn't work? 
play and scala plugins don't work together, although there might be a hack to fix it...using a nightly build. Getting tests working with spec2 or scalatest has been a nightmare. I suspect thats due to round-trip issues with sbt and IDEA.
This matches my personal experience as well. And if you happen to hang out on irc on #scala, you realize that most of the questions there are also about sbt, Eclipse vs/ IDEA, using libraries that haven't been recompiled with the latest version of the compiler or some other environment problem. It makes me wish the #scala moderators were as strict as the #java ones and only allowed actual programming questions. My biggest disappointment has been the IDE plug-in situation. I was so excited when Typesafe took over and announced that they were actually paying a team to work on the Eclipse plug-in, which would no doubt become an industrial strength plug-in in a matter of months. It's been two years now and IDEA is still a better plug-in, albeit with plenty of holes as well. I can't count the number of times that Typesafe said that this time, they were taking tools very seriously and then proceeded to completely ignore this aspect, let bugs fester for years and then adding features and proposing additions to the language that either directly bypass the SIP process or that get scaled down (the recent type macros) because the compiler has become such a beast that even they can't modify it without compromising the whole edifice. Despite all that, Scala remains my #1 choice on the JVM but I'm getting increasingly bitter about it, and I'm hoping a language will come about that will fix it all (and no, Ceylon and Kotlin are not it). 
Is there any particular reason he brought in all of actors instead of doing some sort of `parMap` over the list of IDs? It feels like actors gave him the sort of boilerplate he wished to avoid.
Yeah the IDEA Play2 plugin is fucked up. I couldn't even create a project. Hopefully this will get fixed : http://youtrack.jetbrains.com/issue/SCL-5111
What does the Play plugin actually do? Can you get by with just the Scala plugin?
I haven't had many issues with IntelliJ Scala plugin. Been using it for ages. I wouldn't recommend Eclipse though.
Scala doesn't have a decent web framework yet anyways, so you are better off with C# for now. Of course, if you are happy with rails then I guess the "decent" qualifier isn't very important.
Yes, crappiest player ever. Doesn't work in either Opera, Firefox or Chromium (no video)
Scala has a fantastic web framework! It's called Vaadin. It's technically a java framework, but you can write all your code in scala and it works great.
what's your hardware? How much RAM do you give eclipse?
It works well enough for me, but the refactorings should really be removed from the releases until someone works on them. Not a single one is reliable and they should never be used.
The keynote was less controversial than I expected. It also genuinely made me think that I should use local vars more often for clarity.
I'm currently working on a behemoth Play+Scala project using IntelliJ, haven't had a problem so far. Pretty much install Play out of the box, ran the 'idea' sbt command, and was good to go. The Play plugin was out of date for a few days, but appears to be back in sync now. Turning off the Play support didn't seem to have any significant drawbacks for me. I've barely noticed.
This has been fixed (got it working just today after the same consternation you've been having). However, I agree whole-heatedly with you regarding Scala + IDEs. IntelliJ IDEA in particular is infuriating since I've paid for a license the last two major versions, and it seems like the product hasn't improved much (Darkula theme? Really, JetBrains? You can't fix import resolution of the 'tuple' function but you can change the hell out of some theme colors!). In any case, I'm considering just reverting back to using Sublime Text 2 for all Scala dev and just suck up the code completion and auto-optimize features I lose by doing so.
Which keynote?
Scala Days 2013: http://youtu.be/iPitDNUNyR0?t=32m34s
FWIW I don't want to encourage the division or engage in trolling. I have a foot in both "camps", if camps they be. I've slogged it out in the JEE mines (for which reason I'm not in a rush to take advice from the creator of Spring), and FP is a paradigm that suits me and solves many of the problems I'm interested in. The parody/mockery seems to go in one direction at the moment -- "is this a var I see before me" -- and I think it's an attempt to make new abstractions seem less intimidating.
I agree. Eclipse is an insult to people who have to use it. I have thrown a SSD, multi-digit amounts of RAM and a server-class CPU at it and the experience is still terrible. I'm kind of hoping that this Activator thing will involve into a real IDE.
I'm amazed how bad the player is ... It was always bad, buggy and bloated, but I don't remember it ever being completely broken like it is now.
Weird conclusion. As a web framework, Play2 is an asynchronous version of Rails. Lift is much terser, much more useful for specific needs (see, e.g., Comet), and is actually battle-tested. I would highly question anyone's advice to use Play in production today. Let me see a FourSquare-size installation run on it, we'll talk.
Yeah, listening Rod's presentation, I kept thinking to myself "I'm glad he's around to offer his insight, but I'm also glad he's not in charge.". Scala is on the verge of some amazing innovation (beyond what it's done already) and he seems to want to neuter that for the sake of stabilization.
I feel your pain. I have fallen back to using just sbt + vim.
Yes, renaming can mostly work if it's a situation where the rename effects don't leave the file. However, I don't need that, I need rename that changes other files. Organizing imports isn't a refactoring, but yes, it's another example that now and then really messes shit up and you have to go manually fix it. I have recently found situations (in files that use a lot of literal xml) where the formatter will also break your code - as in format it into a form that no longer compiles. I can live without the refactoring, though if they worked, that would be awesome. Much more valuable than whatever it is they're working on, I'm sure. Also, if they had the ctrl-1 shortcut working (to apply fixes, like creating methods that don't exist), that would awesome too.
&gt; I have recently found situations (in files that use a lot of literal xml) where the formatter will also break your code - as in format it into a form that no longer compiles. Erk. Have you got an example?
Same, having said that I do all my building in an independent sbt console. Intellij Scala plugin's been flawless for me for maybe 6-8 months now. I don't get how specs/play don't work out of the box ... but I also don't expect an IDE to do special things for libraries, so I guess I have different expectations.
Yes, I do. Essentially, if you build an xml literal: &lt;code&gt;blah blah blah ...&lt;/code&gt; And within, you have a complex block like a pattern match that uses more xml literals to create strings, so: &lt;code&gt;blah blah blah... {x match { case Y =&gt; &lt;code&gt;Some more text&lt;/code&gt;.text case Z =&gt; &lt;code&gt;And more text&lt;/code&gt;.text ....etc with potentially complex pieces in there... &lt;/code&gt; Then, when you ctrl-shift-F that, it will often collapse it all to one line, like so: &lt;code&gt;blah blah blah... {x match { case Y =&gt; &lt;code&gt;Some more text&lt;/code&gt;.textcase Z =&gt; &lt;code&gt;And more text&lt;/code&gt;.text &lt;/code&gt; Now you'll notice the lack of space between ".text" and "case" and that doesn't compile, not to mention being on one line is not good formatting! Solution is simple enough - put all such code blocks in a separate method and just call {yourPatternMatchMethod} in xml literal. But, there it is.
I'm on Juno, with scala plugin version: Scala IDE for Eclipse 3.0.1.rc01-2_10-201306070915-5fde194 org.scala-ide.sdt.feature.feature.group scala-ide.org From update url: http://download.scala-ide.org/sdk/e38/scala210/dev/site/ In the formatter, I turned off "format XML", and this apparently is what causes this problem. I turned it off because it was causing other problems. The code below demonstrates both problems (ie, with or without "format XML" turned off, the formatter ruins the code). You'll pardon, the code is nonsense, but you can probably see I'm using xml literals to assist with a code generation project. package com.test.format import scala.collection.mutable.ListBuffer import scala.xml.Elem object ShowFormatProblem { def print = { val buf = ListBuffer[Elem]() buf += &lt;code&gt;CREATE TABLE [dbo].[some_table] (&lt;/code&gt; (0 until 10).foreach(field =&gt; { buf += &lt;code&gt;field_name { field match { case 0 =&gt; &lt;code&gt;public void Test{field}Class(Param p) {{ this.myParam = p; }}&lt;/code&gt;.text case 1 =&gt; "[numeric](18,0) " + "NOT NULL" case 2 =&gt; "[int] " + "NOT NULL" case 3 =&gt; "[int] " + "NOT NULL" case 4 =&gt; "[decimal](" + 18 + "," + 6 + ") " + "NOT NULL" case 5 =&gt; &lt;code&gt;[nvarchar]({ field }) {field}DAO() &lt;/code&gt;.text case 6 =&gt; &lt;code&gt;[nvarchar](200) { "NOT NULL" }&lt;/code&gt;.text case 7 =&gt; "[datetime] " + "NOT NULL" case 8 =&gt; "[numeric](18,0) " + "NOT NULL" case 9 =&gt; "[numeric](18,0) " + "NOT NULL" } }&lt;/code&gt; }) buf.toString } }
One of the things that bothers me most when coming from *Scala or Haskell* to *Ruby or Smalltalk* is the following: I can define methods on my objects in Scala, say `parseString(s: String)`, and can then write `allMyStrings.map(parseString)`. In Smalltalk you'd have to write `allMyStrings collect: [:s | self parseString: s]`. This may not be that dramatic in that particular instance but overall it does add quite a bit of verbosity. Then again in a language without static typing and help of a compiler the verbose approach might actually be necessary. Especially when functions with more than one parameter are involved. Obviously functional programming wasn't ever of any concern for Smalltalk so there's also a lot of methods (tail, init etc.) missing that you have to implement first. But that's trivial of course.
Other new stuff is: Lazy values and call by name parameters. Also type class based polymorphism. I dunno if you can easily make infinite datastructures in smalltalk, but it's pretty easy in scala.
Akka was used in two main ways (now only the first one really): * For coarse level parallelism between components. Level generation actor, persistence actor (pinned to a thread), sound actor (pinned to a thread), rendering actor (pinned to a thread), out of main game loop terrain rasterization (flexible number behind a router). This is mainly as a convenient and consistent way to handle concurrent components, even if it isn't necessarily doing a heap here, or being tested to it's limits. But at least I don't have to hand code my own threads &amp; queues. It's only handling maybe a few hundred messages a second at peak. * For a long time it previously provided futures/promises and execution contexts for the network layer for req/reply style packets and handshaking, but after the unification of futures/promises in 2.10 it doesn't really play a role there. The game is both single and multi, Akka is used for both (it plays a bigger role in SP), as is Kryo (its main role before packet serialization was just saving stuff to disk). 
Great, thanks! I think I'll use that approach for my upcoming 2D game as well. As for serialization, have you considered Protocol Buffers and why have you chosen Kryo instead?
I briefly hand coded a BSON like serializer, then realized I'd taken a terrible approach. At that point I looked at protocol buffers alongside kryo, and well ... everything else out there. Basically coupled with Twitter's Chill library (https://github.com/twitter/chill) that provides kryo serializers for a bunch of scala data structures, I'm actually only writing serializers for my edge cases, as most structures are done automatically. Kryo performed at least as well as protocol buffers on the benchmarks, so performance wasn't a concern, and I haven't seen anything more productive than Kryo. 
I like the following pattern for state machines. However you could also do something similar using function types directly. abstract class State[T] { def next(): Either[T, State[T]]; final def run(): T = { var currentState: State[T] = this; while (true) { currentState = currentState.next() match { case Left(result) =&gt; return result case Right(nextState) =&gt; nextState } } // Will never happen throw null; } } class HelloState[T] extends State[T] { def next(): Either[T, State[T]] = { println("In the Hello World state."); return Right(this); } } new HelloState[Unit]().run() 
I didnt really like the akka FSM. Im looking to build one also. 
That's why I think as a community it's important now to voice (constructive) resistance to this idea of dissolving Scala in a Java culture. Java has always only been one door to Scala. There are many others, like Ruby, Haskell, and so forth. The Java culture is stagnant, what you call a "Java Shop", a brainless enterprisiness. For me, that's the opposite of innovation. We should care more about research on the one hand, and startups and creative businesses on the other, and not submit to a culture of boredom and mediocrity. Naturally, as my background is academia and digital arts, for me the computer science research and the creative aspect are the most important. Scala is in the sweet spot here. There is enough ongoing fundamental research—the upcoming Scala Workshop is a good example—, but other than Haskell, this stuff is translated into practical application, so it doesn't get stale on the paper without ever materialising. If Scala submits to this stabilising-over-innovation, it will loose this sweet spot. The community being inclusive is the most important point. This is where Rod Johnson's key note totally failed in my opinion. He was kind of alluding to this inclusiveness, but only to take a very particular side, achieving basically the oppositive effect—accusing the non-Javashop side of having the fault of everything, and then even in one of the last slides claiming that Scala should be split between an academic version and an enterprise version. With him being on the Typesafe board, that makes me feel really uncomfortable about Scala's future.
Hm.. I can look into using abstract class and Either, they might both be more useful. But I'm hoping to use as much immutability as possible, so I'll be using an external 'run' function more like this: def run(s: State[T]): Either[T, State[T]] = s.next() match { ... run(next state) } Although it might be cumbersome having to match the Either first, and then the resulting State.. Thanks for the suggestion though.
I briefly looked at Akka FSM, and I might take some influence from their syntax. It's not quite what I want though. I want to separate individual states more, rather than putting them all under a big single 'machine' class.
Let me see if I'm understanding you correctly: case class Waiting extends State case class Processing extends State case class Terminating extends State def next(s: State, i: Input): State = s match { case Waiting =&gt; handle i case Processing =&gt; handle i differently case Terminating =&gt; maybe more handling of i } I'm not sure how to pattern match on both the current state and the inputs, but you made it sound elegant. Care to give an example?
You can do some interesting things with Scala's "less flexible" types. You can statically state things about your types that you can't really state in other statically-typed languages. You can, for example, emulate Haskell's type classes, albeit with an ugly syntax. But you can do it. I know it's not popular with the kids these days, but I really like being able to lean on my compiler. Scala's type system allows me to express more complex compile-time relationships than I can express in more mainstream statically-typed languages, and so I can lean on my compiler even more. It's great! Finally, macros. I haven't played much with them yet in Scala, but I'm a firm believer in a good macro system being baked into a language.
You would write the pattern match this way: def next(s: State, i: Input): State = (s, i) match { case (Waiting, Trigger) =&gt; handle Trigger case (Processing, Interrupted) =&gt; handle Interrupted case (Terminating, Output) =&gt; handle Output } You can then use the `_` wildcard for cases where you don't care about one of the state or the input, such as an "all states on this input" or "all other states, whatever the input" or "this state but I don't care about the input".
*(Related to my question, so i am replying to my own post...)* *Thanks for all answers btw.* **How can I look at functions?** If I look at Scala functional code, I tend to visualize them as electrical components which can be plugged together. A function can implement a statemachine-component, returning the next state after certain input. A scanner can be a component that filters data from text-input. For me it seems that OO and FP can be combined easily. Is this a good way to look at functional programming? **Efficiency** There seems to be a trade-off between efficiency and purity in functional programming. Partly because we can not reuse the variables in FP we need new "variables". Some of it can be optimised away using tail-recursion and stuff, but I think not everything can be optimised. If I try to turn the Peg-Solitair solver as implemented on http://golang.org/ into FP, I would need to store each board on each stacklevel, while the go version only stores the moves and performs them on a variable board. If the board would be really large like in the [game go](http://en.wikipedia.org/wiki/Go_game), the fp solution would run out of memory fast. That makes FP-code less space efficient then code with data that gets modified. At least on the lowest level. What is a good trade-off, or is there some point that i am missing here? **Solve** What I expected to find in a FP language is that there is some kind of solve function, that solves the above simple problem by itself. Prolog has some capabilities that seem to do that (can't find the link). Is there something like that in Scala, or is it something easy to implement? **Parsers** It seems that FP makes parsers much easier to make. But there are also parsers like [Parsly in Python](http://www.youtube.com/watch?v=t5X3ljCOFSY) that are very good. I hope Scala would get a similar system too ;-) How hard is it now to get a good parser working in Scala? **What direction i want to go** I liked this speach: [Inventing on Principle](http://worrydream.com/#!/InventingOnPrinciple) . Which is about "modeless" programming with a clear visual feedback. Can Scala make this possible? I'll give it a try anyway. ;-) 
That basically gets into defining methods by cases, or even multimethods. I've got some notes I can try to find to write as a blog post about how to do multimethods of a kind in Scala.
i agree will a lot of comments above. it would be nice if all the videos were uploaded to something with better player quality. youtube, vimeo ?
Disclaimer: I write in Scala full-time at work. I appreciate Scala's features, its orthogonality, and its theoretical underpinnings. I don't want to become stagnant and intellectually-incurious like the Java world mostly is. That said, it might not have been what the Scala community *wanted* to hear, but Rod Johnson's talk was what the Scala community *needed* to hear. I heard him arguing for a sensible middle ground between the stagnant, intellectually-incurious hyper-stability of the Java world, and the disdainful-of-OOP, feature-churning, more-innovative Scala one. That's a very fair point. 
I'd appreciate that very much!
I know about that and it alleviates the pain to some degree but is still not exactly a perfect solution. Especially when you want to do something like `Seq("47", "58", "14").map(Integer.valueOf(_, radix))`.
He could have at least given credit to the original authors
Thanks, this is amazing.
The one thing I noticed is in your dog class, bark returns unit, but the type you gave it is string.
Here's memoization and an example of call-by-name parameters: https://gist.github.com/markehammons/5896043
I think you forgot to replace some instances of "Haskell" with Scala. 
Good catch
Yep, thanks. Was a bit of a rushed job.
That's what I like about scala, there's always something new to learn.
&gt; You can, for example, emulate Haskell's type classes, albeit with an ugly syntax. But you can do it. I made a blogpost [here](http://www.dzone.com/links/r/easy_to_use_type_classes_in_scala.html) about how to use more typical OO syntax with typeclasses. &gt; Finally, macros. I haven't played much with them yet in Scala, but I'm a firm believer in a good macro system being baked into a language. Macros are great, but they're hard to make unless you're familiar with Scala's AST style. They are extremely powerful though.
So, programming for 3 years and using Scala for 6 months and you are finding Scala is slowing you down? Are you compensating for the learning curve?
I was thinking the same thing. However, I do agree with some of the negative points he raised (IDE, implicit, too much op overloading) 
So, since it relies on Macro Paradise; does that mean I have to link to macro paradise to use this as a library, or does it boil down to a "standard Scala 2.10" dependency?
&gt;Unless you want to sink time into reimplementing this common stuff, you’re going to reach for a library that can help I've been programming in Scala for two years. Haven't yet felt any desire to use a third-party library written in scala, other than the scala standard library. I use Java libs exclusively, and I think it's been an excellent choice. 
[Current syntax](https://gist.github.com/soc/5737101)
It's a controversial post but even though I'm not convinced of the overall conclusion, I still find it an interesting description of a developer's experience with Scala.
&gt; I’ve been developing software professionally for a whopping 3 years Oh. 
Ah, wasn't aware of that. Why would you want to extend a case class with a normal class, though?!
For the operator overloading thing, why don't we just define a scaladoc thingy like @opname, that's what the method would be called if it wasn't a symbol. Then the IDE can give me a tooltip. Then at least I'll know how to pronounce the code when I read it in my head.
Don't be like that. I've been programming for much longer than that and have known some programmers at his # of years that were sharp.
Everyone that complains about Scala compile times should try to compile a C or C++ project developed by 50+ developers team and do a _make all_.
It does boil down to a standard Scala 2.10 dependency.