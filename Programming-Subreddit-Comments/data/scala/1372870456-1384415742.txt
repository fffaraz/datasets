When I first read the title, I thought it would be referencing the study comparing Java and Scala, which has been posted to [/r/programming before.](http://www.reddit.com/r/programming/comments/yxfz8/scala_vs_java_just_as_fast_less_code_harder_to/?already_submitted=true) I'm wondering if Java isn't as *un*productive as its made out to be, or if we've just found good ways of making it more productive.
Ok, so—we all know Scala is great—I'll just go through the "Bad Things" section. - **Compile Time**. Agreed, there is a magnitude between Java and Scala compile time. And the CPU runs pretty hot. Certainly not a strength of Scalac. I am somewhat hoping that in a future version, the compiler can use parallel processing (or does it already?), which would be one possibility to get significant boost. - **IDE**. That one I never understand. Yes, features might not be as good or stable as Java, but I find them more than good enough, and they certainly don't hinder my productivity. I am using IntelliJ, so I will answer that way: _Renaming_: Works good enough for me. Sometimes classes are not automatically renamed along with companion objects, ok, but you just need a second pass. I never found it messing up, in worst cases it missed some spots where the old name remained. Annoying, but not the common scenario. _Extracting_: Can't comment, I don't use that feature. _Finding references to a type_: Can't find that feature in IntelliJ? _Find implementations_: Rarely use it, but I just ran that over a dozen of random cases. It was 100% correct in each case. - **Operator overloading** (not even correct terminology). Yawn, the Rod Johnson moment. I use dozens of libraries daily, and I don't have that problem. Chewing over and over the same two or three libraries that use symbolic operators doesn't make the argument better ("Using %% is a slap in the face"—I mean, c'mon?! BTW sbt 0.13-RC is out) - **Implicits**. One of the most important features IMO. To be fair, when I started Scala I also had a rather cloudy understanding of them. My advise is, don't get intimidated by them. You might sometimes not "see" something, but that is not bad at all. Over time you will most certainly find that they are really fantastic tool, and all the fog will dissolve. There is a good read by Josh Suereth about where to expect implicits to be looked up. Once you grasp that, it is a fairly overseeable thing. - **People experiment with Scala**. Yes. that's good. Again, let them be. You can be perfectly using Scala without following those intricate experiments. In the beginning I was aware of Scalaz, later Shapeless, but I didn't have any direct use of them. I was curious, but it appeared too difficult for me. Now I occasionally use features of these libraries, and I have no problem understanding them. Just go with the flow, at any time pick the tools and libraries that are accessible to you, and put the other ones on "remote watch". I want to extend on the IDE topic: I found remarkable that the author did not bother to mention that already today the amount of help, warning highlights, refactoring suggestions etc. in IntelliJ/Scala is by far superior to what I was used to in Java (admitted that I don't use Java much since three or four years). The orange highlight is most of the time spot on, finding dead code, unused things, suggesting improvements (e.g. replacing an `.isInstanceOf` followed by `asInstanceOf` with a pattern match—I just had those coming up in some `equals` methods. One click, and it was correctly refactored!). So in my experience, the IDE really _boosts_ Scala productivity. A lot. The times where updates were going from terrible to a bit less terrible are over. We're not at 'fantastic', but we're at good to a bit better in each update. ----- My summary: The Scala developer team should try to improve compilation speed.
Hi, author of blog here. That is something I can't really win with. Either I don't mention my relative lack of experience, which feels... dishonest, or I fully disclose it, and receive ad hominems. I fully expect that gaining experience will shed new light on past thoughts, but I can only describe the experience I've been dealt, so to speak. FWIW I have colleagues with 10-15 years experience who agree with many of my points. Does that suddenly make them any more _right_? I hope not. :)
I have known programmers who have been at it for 20 years who stopped (actively) learning after their first year, and others who have been writing for only a few years but have grown exponentially each year. Obviously just being at it for 3 years means there is a whole lot more to learn, but I wouldn't say that makes you unseasoned or not worth listening to. I, for one, appreciated your post.
(blog author here) Hopefully :) I would be crazy to think there would be zero learning curve. Many aspects of learning still remain, for sure. For example, I can't just sit and type out a for comprehension correctly, I have to go borrow syntax/structure from existing examples. I still can't "think in monads". Part of the issue is that I don't feel passionate about Scala, so I rarely play with it in my spare time (I do have other programming interests), so 95% of learning is on the job only. Some of my problems cannot be attributed to learning curve though - compile times and tooling for instance. Another example is that our team has decided to migrate all our specs2 immutable, Given/When/Then tests to something else -- even when we knew how the library worked, and had internalised the API, we were just slower writing tests with it. I don't think saying it will taking 6 months to be as productive as you were in $CURRENT_LANG is really a problem if it pays off, just that I've heard/read on several occasions that the touted time span is 4-6 weeks. That's a tough billing to live up to :)
Hi Grundlefleck, excellent article. &gt; So… in conclusion. Scala will make you less productive, for some period of time, and if you do get more productive in it, it probably won’t matter that much anyway. This is the only sentence I object to. A lot of really talented software engineers feel *so* strongly that scala makes them *so* much more productive. Even if the boost isn't something you've experienced yourself quite yet, it doesn't make it wrong, and if you keep at it you'll probably see it someday too.
(OP here) With IDEs it seems YMMV. Completely accept that, but I stand by the description of my experience both with IntelliJ and the ScalaIDE plugin for Eclipse. Of course, it took Java IDEs a _long_ time to get to where they are both in features and not having bugs in refactoring/search. I'm sure Scala will get there, but reliability and accuracy is not what I see _today_. It seems I'm missing a meme. Could you explain what the "Rod Johnson" moment means? w.r.t. having no problems using libraries daily, that's kind of the point. Now I'm more used to sbt, ScalaQuery et al, I know what the symbols mean. Just because I learned them doesn't mean they weren't _surprising_ at the time. The point about %% was specifically about surprise - since there's no way you could look at source code and guess that it means what it means. FWIW I had hoped to be clear that I know it's not called Operator Overloading -- oh well. Glad we can agree on compilation time as an issue, because it's probably my A*, #1, 1st Class pet peeve with Scala. Thanks for the feedback. 
I've never really noticied a major difference in the compile time speed of scala vs java. That said, you don't have to sit around staring at your test waiting for it to finish. You should have a reasonable assumption when you start your test its gonna work, if your running tests and praying it works you don't understand your problem well enough. I kick off my test and go back to work, typically doing stuff like documentation or working on my next area, if it fails I jump back, fix it and move on. Even if the compiler is too slow for you there is other stuff you can do that's relevant to the code.
&gt; Could you explain what the "Rod Johnson" moment means? Well, the alleged abuse of symbolic method names is a repeated bashing point of Scala. But when you look at actually libraries that you commonly use, probably 98% of them make very careful use of it. So that means, if you want to make it look bad, you revert to the same three examples: SBT, the [old version](http://code.technically.us/post/54293186930/scala-in-2007-2013) of Dispatch, and perhaps Scalaz—although the latter is perhaps the most ridiculous, because you will anyway start to use it, when you totally know what you are doing, so that's not something that affects an average Scala developer. Rod Johnson—member of the Typesafe board—used (the old) Dispatch (and SBT?) as slides in his infamous Scala Days keynote, which also came with the tone that everything that wasn't familiar from Java must be somehow bad/ elitist/ ... I admit that when I was starting to use sbt, it took me a while, too, to understand the logic behind `:=`, `&lt;+=`, `&lt;&lt;=`, `&lt;++=` etc. They are not arbitrary, but unless you read a good article about it, they probably don't enter your brain straight away. But just like Dispatch got rectified, sbt is doing the same with the upcoming [version 0.13](http://www.scala-sbt.org/0.13.0/docs/Community/ChangeSummary_0.13.0.html), trying to minimise symbolic operators or at least giving you [alternative syntax](http://www.scala-sbt.org/0.13.0/docs/Detailed-Topics/Cross-Build.html) if you prefer not to use symbols. The problem with sbt symbol methods _was_ that the sbt documentation was not very good a while ago, but today it is much better. ----- Also I must say I find it a bit naive to pretend that when you look at new build tool, you immediately understand how everything works. Back in the days, I took me quite a while to understand how to achieve the most basic things with Ant, and even worse Maven.
External libraries that use runtime proxy class generation may need it. Examples: Spring, Hibernate. 
&gt;language has a theoretical limit in the improvement it can give to your overall productivity. &gt;How much of your time, as a software developer, do you spend doing stuff that is language agnostic? I spend a lot of time doing stuff that doesn’t go any faster when I wave the wand of a magic new programming language at it. I spend time figuring out: &gt;what a feature is supposed to do, understanding what the user needs, and exploring edge-cases that will have to be handled. which names and concepts will make it easier for the next developer to understand the business logic. how to iterate new features while maintaining backwards compatibility, both in a long-lived sense such as maintaining APIs, but also in a short-lived sense, such as how to deploy database schema migrations with no downtime. what the most appropriate logging, monitoring and metrics are needed to give us visibility into how our applications are used, and how well they perform. what the performance and scaling characteristics of a design are likely to be, and how to measure if I’m not confident. how to coordinate and integrate and deliver, and generally work, as part of a team. Ah, so I think you left something important out. Language can affect the *architecture* of your application, which absolutely doesn't have a 'theoretical limit' of how it affects your productivity. I'm going to guess that you and your team's code is more along the lines of the "java++" idiom than functional programming design. There isn't anything wrong with that, and if that's the case, you might be right that the lack of tooling and compile times end up negating the marginal language improvements you get from switching to Scala. In my case, switching to scala allowed me to go from a callback hell, state ridden server core to a monadic DSL that has been insanely easy to expand upon, reason about, and debug. I wouldn't have thought software could be this neat. It was humbling getting to the point where I could understand enough FP concepts to build it, and I'm still learning and do have times where I fight the compiler and feel like an utter idiot.... But every battle with the typechecker results in some of the most 'productive' code I've written in my 12+ years of being a programmer. 
Scala doesn't have operator overloading exactly. It just has methods that can be named anything so that they look like operators.
well I tend not to use libs I know absolutely nothing about 
I am sorry someone hurt his feelings. 
&gt;No one wants to join to a community whose members think that if you don’t get their point of view, you are not smart enough. It sounds like you felt there were people in the community were insinuating you weren't smart enough, hence I assumed your feelings got hurt and the need to write a post. You keep talking about one liners and then attempt to invoke the false dilemma contrasted against 'solving real world problems'. This is the same logical fallacy Rod Johnson failed to comprehend. I understand that it is important to be friendly and welcoming to newcomers. I support the idea of not insulting newcomers. I was corrected about some assumptions when I started interacting with the Scala community, but I never felt insulted. The typechecker made me feel I wasn't smart enough, but not the folks from #Scala or the mailing list. :-) Regardless, I want to solve problems the right way. If that means I have to expand my knowledge base and possibly feel lost while doing so, I'm happy to do so. &gt;We must remember that if our colleagues cannot understand our code, it is not their fault. It is our fault! I don't know objective-c. Does this mean if I look at something in objective-C and don't understand it, it's not my fault it is the authors? You seem to be confusing unfamiliarity with low code quality. I don't think this is fair to say at all. 
&gt;The only thing which I am saying is that FP attracts intelligent and arrogant people who cannot really understand why other people act like they do. What does that even mean? I am probably just graduating from the 'newcomer phase' and I never got the impression that the hardcore functional /purist/zealots of Scala were arrogant. If you got that impression, it may have a lot more to do with your perception of things than anything else. They have been helpful, enlightening, and actually write a lot of code that solve real world problems. It sounds like you think there is a dichotomy between functional purity and writing code that solves real world problems. 
Of course. But that does not make my opinion is bad. It is my view of the reality. You may have a different view and it is totally cool. By the way, the human behavior is not guided by reason. It is guided by feelings. I know, it is crazy but there is a shitload of evidence which proves this claim. 
Sure, I'm not saying that it is a bad thing. Just highlighting it. For me, the important point is the mistake in the title: &gt; Using Scala Will Make You Less Productive This guy cannot speak for anyone else so a more accurate title would have been "After 6 months I haven't figured out how to be more productive with Scala". Better yet, he should have asked "Why am I not more productive with Scala after 6 months" and people would have explained why to him. 
&gt; I fully expect that gaining experience will shed new light on past thoughts, but I can only describe the experience I've been dealt, so to speak. That statement is correct but your title is quite different. Your title makes an assertion about *my* capabilities. You are saying that *I* will be less productive if I use Scala. &gt; FWIW I have colleagues with 10-15 years experience who agree with many of my points. Does that suddenly make them any more right? I hope not. I have 30 years of programming experience and about 12 years with functional languages and I have figured out how to be much more productive with languages like Scala and I've proven it by building [a company](http://www.ffconsultancy.com/) that does exactly that. Does that suddenly make me much more right? Erm, yes. I think it does. :-) In case you're wondering, the secret to massively increased productivity is to change the way people work by building the tools that you've always wanted but couldn't have built before. For example, our last client had one (business) team writing specifications for mathematical code that another (technical) team would use the specs to write C++ code by hand that would be put into production. Changes typically involved dozens of people, took months and cost at least £1m. They started using F# a couple of years ago, rewriting the legacy mathematical code in a different language and trying to take advantage of the new features and refactor the code a bit and they saw some significant improvements (10x faster, 10x less code etc.) but they were still working in the same way. This year, I showed them how to build a tool (a bespoke graphical programming language) that allows the business to write executable specifications than are compiled and put directly into production. Instead of taking months and costing over £1m, an individual is now able to make changes from the comfort of their desktop with 24 hour turnaround and minimal cost. They wanted a new feature for this tool to apply a change that saves the company £200k each month and we were able to give them the new feature in 24 hours. The improvement in productivity is unprecedented within the (20,000 employees) company and they are keen to repeat the success elsewhere. That's how you use a tool like Scala to massively increase productivity. 
I can confirm this. I was playing around with the [Crystal Space game engine](http://www.crystalspace3d.org/main/Main_Page) to ascertain its viability in game development, and had to compile it from source since it was only rebuilt once every few days, and I wanted a recent bugfix. It took like 40 minutes to compile on a Core 2 Quad (or maybe it was a Pentium 4... It's been a while and I've changed computers twice). Also the [MaNGOS project](https://github.com/mangos/MaNGOS) (open source World of Warcraft private server) has to be built from source because you need to extract game data from the WoW client. Building Android APKs is very time-consuming as well, especially if you want/have to run Proguard. A moderately sized codebase usually only takes a few minutes at the most, but it can add up. In the latter scenario, I just use that time to make a Git commit, maybe get up and stretch, grab a drink, go to the bathroom, browse Reddit, etc. Compile time can be a blessing. It gives you an excuse (and a reminder) to take a break.
I think it was here on Reddit, the Firefox team was talking about why there wasn't a version for such-and-such an architecture, and it turned out it takes something ridiculous like 2 days to compile all the various versions when there's an update (hence their reluctance to add more).
After becoming reasonably adept at writing Scala, I've faced a pretty major issue when returning to work on older Java projects: I've frequently ran into impedance mismatches between an idea in my mind and the code Java is capable of expressing. My simple, concise idea gets turned into verbose boilerplate and design pattern soup. The increased "surface area" of the code is more error-prone. In the case of concurrency and/or mutability, the code is harder to grok. For example, compare the word count from this Scala based project: http://spark-project.org/examples/ with the word count in Java's Hadoop: http://wiki.apache.org/hadoop/WordCount . Now keep in mind that the combinators used in the Scala example (map, reduce, etc.) have a matching equivalent in Scala on normal collections, collections in parallel (e.g. list.par.map...), collections on terabytes of data across thousands of machines (see: [Scalding](https://github.com/twitter/scalding), [Scoobi](https://github.com/NICTA/scoobi)), and rows of a database (see: [SLICK](http://slick.typesafe.com/)). Learn some basic combinators once and you have access to all of that power. Yes, there are some people who overdo overloaded operators and implicits. But that expressiveness is an amazing productivity boost with the right libraries and mindset, and I'm more than willing to deal with some people abusing it if the overall community keeps creating beautiful things with it.
I agree 100%. I've frequently fell down the hole of refactoring my Scala code into a more elegant form. It's hard to hold myself back. I usually just give up on the equivalent Java code.
I use Vi when programming Scala. I really didn't think IDE could be something you could complain about. Moreover - Things like implicit is what makes awesome tools like Scalding possible.
The argument "Scala compiles faster than a 30 year old language" is not going to impress a lot of people. 
This is true, but it's easy to abuse them. The code may make sense to the author but look like hieroglyphics to others.
It looks like in the first time you have tried to post your beginner questions on lists like scala-language or scala-internals, which are in fact for advanced Scala users - expecting to get full help there for questions asked ten times a day is also a form of arrogance. During the last years in which I'm active in the Scala community, I have seen a Scala community which is everywhere as helpful as on Coursera, regardless if it is on StackOverflow or beginner Scala mailing lists. With your unconstructive and extremely subjective opinion, which seems to be based on _some_ questions you have seen and probably which are mainly asked by yourself, you are hurting the Scala community and insulting everyone trying hard to improve Scala and to make it easier to use for people like you, which just want to get their job done.
What about stuff like val needSomeInit = { ... use local variables and names here... myInitedValue } Would you suggest indent rules for multiline assignments like the above example or prefer named methods to do the init? Wouldn't you agree that braces are easier to spot out over a long code block, rather that indentation? Of course you could argue here that good programming advocates short methods, but I's just wondering. I must admit I'm not a fun of formal indentation rules for syntax parsing, it's one of the things that bothers me in haskell and it strongly reminds me of FORTRAN. I just feel like there's something about how we human reason that makes indentation reasoning unnatural and unintuitive, but this is just my gut feeling.
Perhaps it depends which $CURRENT_LANG is. I know multiple Java developers (including myself) who became productive within weeks, to the extent that nobody prefers using Java.
There are architectures (or maybe patterns) enforced in Play! that we were not experienced with on the JVM, so that was new, but I have no complaints about moving towards an asynchronous architecture in general. It's more like we were writing Scala--, back when we were in Java. By that I mean, we were using FP concepts in Java: immutability; side-effect-free code; the Maybe monad; stateless transformations of data, etc. We absolutely suffered from the mass of boilerplate, but I felt we also got the benefit of the paradigm. There also was that several-month experience of writing Clojure, where trying to write Java++ would be more of a battle than in Scala. I was really looking forward to having those FP concepts we liked in Java available easily, and having them being idiomatic, thus avoiding impedance mismatch between libraries. Like I say in the blog, these things are _definitely_ an improvement in Scala. When I look at a plain text file of some case classes and some filters and transforms, the code is obviously better, the point I am trying to make is that code does not exist in a vacuum, there is a myriad of other factors involved in productivity, and we neglect them in favour of language wars. Thanks!
&gt;That statement is correct but your title is quite different. Your title makes an assertion about my capabilities. &gt;You are saying that I will be less productive if I use Scala. The title of the blog post is pretty much the setup to a joke where the punchline in the opening sentence. It's a comment on how many blog posts around Scala (both pro and con) make unsubstantiated claims. Now, our senses of humour may differ, but was the writing really so unclear that it wasn't obvious I was being satirical? That is an honest question: if that wasn't clear, then my writing is bad in the same way that my code is bad if no one else can understand it. &gt; Does that suddenly make me much more right? Erm, yes. I think it does. :-) No, it does not. Your company, no matter how successful (congrats, btw) is not proof of how to be more productive with Scala. It is a data point. We are all subject to our own biases, and I can only imagine that when you build a company and have a successful career with a particular belief, the amount of confirmation bias you would suffer from is immense. How many founders of companies do you think I could find who would testify, and completely believe, their method or product is the best, and they are the most right? While I sense many people, myself included, could learn a lot from your insights and experiences, it doesn't mean you are more right than any other appeal to authority.
I have not posted to any Scala related mailing lists mainly because the response which I got to my questions in other forums was so disappointing that I decided to abandon Scala (A decision which I reverted later). Of course my opinion is subjective but I don't think that is unconstructive. Instead I would claim that it is provocative. These annoying newbies are in fact the potential new users of Scala. And like you said, &gt; expecting to get full help there for questions asked ten times a day is also a form of arrogance. Are you sure that it is newbie friendly? I would wonder how many of the newbies are alienated by this practice. I agree that asking the same questions from a wrong mailing list is annoying but if these people get arrogant responses, doesn't it make the Scala community look arrogant? Also, the second this which I liked about Rod's keynote was that he was advocating a pragmatic approach to software development. I wonder how this can be unconstructive? I agree that it might sound boring because it would mean things like backwards compatibility and slowing down the innovation. However, these things are important for enterprise. Of course, if you don't want to have enterprise developers as a part of your community, claiming that this is unconstructive makes sense. By the way, shouldn't you be wondering why people feel this way instead of accusing these people for hurting the Scala community?
Based on other comments made to this thread, someone might get an idea that the be friendly to newbies rule only applies when the newbies "know their place". I understand that the part of Rod's keynote which you mentioned upset people. The problem is that in order to grow, Scala have to look outside its core community. These people might value the boring stuff which Rod mentioned. But I think that it cannot surprise anyone that Rod wants bring Scala to the enterprise. I would assume that it is why he was hired in the first place.
I wouldn't say I expect to know everything looking at the configuration of a build. I like Bill Venners' metaphor. Where possible, your library should be like a rental car: don't expect people to read the manual for the basic features. I consider the semantics of %% to be a basic requirement (makes up about 50% of dependencies in my current project). I'm glad to see there is an attempt to provide alternative syntax for those who value 'guessability' over terseness, that smells like progress to me. In a way, libraries moving away from symbols for method names doesn't invalidate my argument, it vindicates it. sbt 13.0 doesn't appear to have been released yet, so I believe that example remains valid. Also, it's not like I plucked out some obscure library nobody ever uses so I could score points. sbt is the de facto build tool. Play!, the poster child, uses it, thus I couldn't avoid it. My observations are very experiential. Scalaz operators may be the most natural for Haskell programmers to understand, as many of the operators are borrowed from there (is that correct?). I'm not a Haskell dev, so unfortunately I struggle with them. It doesn't mean Scalaz made the wrong choice, just that I don't like it. 
Oh I don't know how to play violin. But I'm still gonna play it in the concert because I just bought it. I don't care if people came for a piano recital, because music is music. After the _concert_ ... Oh well, violin isn't a good instrument for music.
Please clarify your analogy, I'm not sure I understand how it relates.
&gt; Are you sure that it is newbie friendly? It depends on what 'newbie' means. For programming beginners it is not - for experienced programmers who know how to communicate with other developers it is not that bad. Knowing how to use a search engine, asking a well formatted question and to find out the right place to post a question have to be learned. I don't answer questions that don't fulfill these requirements and I know of a lot of guys on the mailing lists reacting similar. Being unfriendly to such askers is not the case I have seen - they just don't get responses or are advises to ask the question at a different place. &gt; doesn't it make the Scala community look arrogant? It does for some people, but this is not related to Scala, but for every community. It are beginners that help other beginners and experienced people that help other experienced people. The latter helping the former for a longer period of time is rarely the case. For this case Scala has the disadvantage that there are just little beginners. &gt; By the way, shouldn't you be wondering why people feel this way instead of accusing these people for hurting the Scala community? We are very well aware of this fact and we work hard to make it better. Posting content that names these guys stupid, arrogant, unhelpful or other things doesn't provide new understandings for us but unnecessarily preventing beginners from taking a look into Scala. If you tell me how I or others contributing to Scala should use your article to improve something, then do it but don't post content that looks more like an abreaction on former frustrations.
On Scalaz, the `|@|` you gave as an example is for applicative functors. This is a rather interesting example, because if you convert this to an alpha-numeric identifier, it still wouldn't make any sense - because it's not the operator that's *complicated*, but rather the underlying concept, being an issue of familiarity with functional programming. It's really not more complicated than OOP though, as nothing is more complicated than OOP, you just don't feel that OOP is complicated because of all the exposure you've had to it. It would also be more verbose for no good reason whatsoever. Also, I've never used Scalaz or seen much usage of it. Most Scala code is in fact quite boring, unless you have a rookie in your team that goes willy nilly on doing "smart" things, which can happen in Java too - but you should be doing code reviews and stuff, you know. The operators in Scala's standard library are quite sane and consistent. For example "++" is for concatenating collections, "+" works for adding an element to a Set or to a Map, but on the other hand for sequences you've got ":+" and "+:", mostly because sequences have ordering and in general you need to be aware if it's an append or a prepend. I've used IntelliJ IDEA Ultimate for about a year now and have stretched it to its limits. Sometimes it has problems with some experimental features. Like for example String interpolation from Scala 2.10 works, but Scala 2.10 also supports pattern matching by using String interpolation, which is pretty cool, but very experimental, so IntelliJ IDEA has problems with it. On the other hand I never had problems with IntelliSense, or with Refactoring, or with Debugging, or with Jumping around / navigating the code, only minor glitches that happen rarely and that get fixed fast. IntelliJ IDEA is also capable of things that Visual Studio by default isn't - like having really good integration with Git or having the ability to do code Coverage for your Scala code with nice highlighting of code that isn't well covered. It also has good integration with Play2 (only the Ultimate version). *Implicits* give you [type-classes](https://en.wikipedia.org/wiki/Type_class) and no, CanBuildFrom is not the full story (CanBuildFrom is in fact not a type-class). After experiencing the awesomeness of having type-classes in your language, I'll probably never again use a statically typed language that doesn't have type-classes. In fact, I also started having problems with dynamic languages that don't provide similar tools for solving the expression problem, like multiple dispatch or protocols ala Clojure. For-comprehensions are in fact quite simple and consistent. It would have taken less time to find out how they work, than writing your blog post. The compiler translates it (recursively) into calls to map, flatMap, filter and/or foreach. And monads / monadic types are just a design pattern. A monad is simply a container and operations such as map(), filter() and flatMap() allow you to operate on whatever the container holds while still keeping the context of that container. This is extremely useful - for example with Future[T], which is also a Monad, working with map/filter/flatMap allows you to operate on the result, even before the result is ready for consumption. There's a ton of other useful monadic types that save one from reinventing the wheel. 
In some Smalltalk dialects Symbol's `value:` method calls a method with the corresponding name on the passed object. Something like this should work (I tried it in Ideone but whatever they are using doesn't support it, works in Pharo). (Array with: 1 with: 2) collect: #asString
&gt; don't expect people to read the manual for the basic features I don't disagree here. But let's assume, it was `libraryDependencies.add(Artifact(group = ..., id = ..., version =, crossVersionType =)`. You would still have to look that up somewhere, just as you would have to look up `libraryDependencies += group %% id % version`. And that would be in any introductory text for sbt. &gt; sbt 13.0 doesn't appear to have been released yet, so I believe that example remains valid What I was saying is that it has been repeated for the past three or four or I don't know years. It is just annoying and redundant. You can read this in sbt's Wikipedia article, it's common knowledge. And you can already use sbt 0.13-RC today if you want. Otherwise wait one more week. &gt; Scalaz operators may be the most natural for Haskell programmers to understand, as many of the operators are borrowed from there (is that correct?). I'm not a Haskell dev, so unfortunately I struggle with them But who forces you to use Scalaz? If you don't know Haskell or come from functional background, how do you have the impression that you cannot happily develop Scala without using Scalaz functionality? I also "don't like" many many libraries. I tend to not use those that I don't like. And taste is different, I tend not to like interfaces which are Java'ish and not Scala'fied. So that boils down to a plain opinion statement.
&gt; The argument "Scala compiles faster than a 30 year old language" is not going to impress a lot of people. Age doesn't have much to do with how long it takes to compile C++. C is faster, and also older. 
&gt; You would still have to look that up somewhere I think the distinction is when working on a team, looking at what someone else has already put in Build.scala. I can make a reasonable guess what 'crossVersionType' does, and either it seems relevant to the task at hand or not. You could still argue I should read the documentation, or maybe I should have paired with someone who knew what they were talking about. I _still_ think there's just no need to start off with %% instead of something like the example you gave. &gt; What I was saying is that it has been repeated for the past three or four or I don't know years. It is just annoying and redundant. Possibly because it still affects newcomers like me. It's still in the latest release. It's still an issue. No matter how well tread the ground is. Similarly, criticisms of java.util.Date, or Java boilerplate aren't going away even though we could consider them redundant by the same standards. Realistically, if we only had such use of symbols in old, deprecated, unused libraries, I wouldn't have been introduced to them in the past six months, and they wouldn't have been mentioned in the blog. But they're still de facto standards. &gt; And you can already use sbt 0.13-RC today if you want. Otherwise wait one more week. The ship has sailed, I know what these things mean now. As mentioned, I'm glad for the progression that you described. &gt; But who forces you to use Scalaz? Nobody at all. In the blog I specifically gave Scalaz a pass on its usage of symbols, because it's clearly not for noobs like me. Pretty sure I've seen a core contributor, maybe Tony Morris, say exactly that, and that's completely fine. I mentioned Scalaz here just to show that I am not saying that their use of symbols is bad (quite the opposite) just that they're not the most accessible to me, so I don't like it. &gt; So that boils down to a plain opinion statement. I'm confused that you ever thought I was ever offering anything else besides my opinion :) (I am enjoying this discussion, thank you) 
w.r.t Scalaz, I mentioned in another comment, but I explicitly called their usage of symbols out as being A-ok with me. I understand there's a foundation of knowledge you need to know (computability theory, is it called?) and then Scalaz is trivial. Completely fine with not having that foundation at this moment in time, because I can avoid scalaz until if/when I do. I haven't experienced the awesomeness of type classes, as you put it. They do seem to fall further towards Odersky's library designer levels. I have refactored away from a colleagues attempt at that (which I don't think was done quite correctly) towards a more Java-y adapter, and felt better for it. w.r.t. for comprehensions, I know _how_ they work, a colleague explained them really well. What I don't have, however, is _fluency_. Similarly for monads, I understand them at a superficial level, but I don't "get" them yet, truly. I can see their purpose and usefulness. You can observe that the word 'monad' did not appear in the blog. I certainly can't complain about them, or my unfamiliarity with them, but I perhaps did them a disservice by not listing them in the Good Things. Thank you.
&gt; Possibly because it still affects newcomers like me. It's still in the latest release. It's still an issue. That's true. It's just to explain why people are allergic against it, because we're hearing it since years. But of course, everyone new to it has to grasp these things, no doubt. &gt; (I am enjoying this discussion, thank you) Cheers.
After spending some time thinking about this "part" of the discussion, I think that overreacted and I apologize for this. What I was meant to say was that people don't typically make decisions based on logic. We are driven by our emotions. It is true that often this kind of thinking is born from a random encounter with an individual who does not necessarily even belong to the core community. In other words, these feelings are highly subjective and often unfair (like mine first impression) but they can be powerful motivator behind person's actions and alienate potential developers (I leave it to you to decide if this is a good thing or a bad thing). That is why bad first impressions should be taken seriously (it seems that the official Scala community does just this). About the dichotomy between functional purity and solving real world problems. It is kind of easy to think that way because it seems that the discussions around functional purity often concentrates on concepts which seem very abstract at first sight. In other words, it is hard for a newbie to understand how these concepts can be used for solving real problems. This does not of course mean that it cannot be done. It is just one example how understanding the paradigm shift to FP can cause misunderstanding if you don't understand why it is better than for example OOP. Maybe simple examples are better than extremely abstract discussion?
I though that I already confessed in the end of my blog post that the Coursera's Scala course made me realize that I had been wrong about the Scala community. I updated to my blog post to highlight this point because I have no intention to attack the Scala community. I agree that my blog post was very provocative but I decided to write it that way because I wanted to highlight that the typical prejudices about the Scala community (or FP in general) are not fair or correct. I also wanted to support Rod because some of the things he said made sense to me (he made some mistakes too). Also, I am not sure if asking people to stop writing content (positive or critical) is a good way to deal with the situation. Doesn't it give an impression that you are cool with all people who agree with you? Although I agree that this the way communities tend to work but I think that education is a better way to deal with those negative and unfair feelings. I know this situation must feel like sh*t but imho asking people to stop feeling the way they feel just does not work. Of course, in the end you have to decide what battles are worth fighting. One good example of positive education is the Coursera's Scala course. I know a bunch of Java programmers who participated in this course and many of them had some prejudices about Scala. After the course, all developers wanted to try it out in their work. 
&gt; terrible idea - syntax should be visible. whitespace is for aesthetics only. It's better to share arguments, not opinions.
OK then, here's my counterargument: "Syntax doesn't have to be visible".
Old habits die hard? Here is the folder structure of a Play2 Scala app: . ├── app │ ├── controllers │ │ └── API │ ├── models │ ├── util │ └── views ├── conf ├── logs ├── project │ └── project ├── public │ ├── fonts │ ├── images │ ├── javascripts │ └── stylesheets └── test
Blog post going into some detail about what this is and how to use it: https://devblog.timgroup.com/2013/07/05/narrative-style-testing-with-bildungsroman/
The part part /src/main/scala/ comes [from Maven](http://maven.apache.org/guides/introduction/introduction-to-the-standard-directory-layout.html). I think it is mandatory to do it like this if you want to use Maven. The &lt;my&gt;/&lt;unique&gt;/&lt;package&gt;/ part is not really necessary with scala but I think most IDEs will create this folder structure for you. I hope you agree that unique package names are a good thing for public projects, especially for libraries. And having a convention on where to find a package in the folder structure also is a good thing in my opinion. The only problem I see here is that the github interface was not made for browsing deep folder structures. But your IDE and file browser can probably handle them well.
Regarding the /scala/ part, I agree that it doesn't make any sense to separate Java and Scala sources so in my sbt build files I always override the source directory to just /src/main (tests go in /src/test). 
Then there is no separation between source code and resources. The `/scala/` part exists for a reason.
I can perhaps see wanting to mingle java and scala in the same directory tree (even though I probably wouldn't do it personally) but jamming *everything* together seems like a bad practice to me. Where do you put your static resources and other build inputs?
/src/resources, of course. Test resources still go to src/test/resources. 
See above reply. 
That's inconsistent.
I still keep it in case I add other languages on top of java and scala, which does occasionally happen.
I didn't say *bad* habits, did I? But, IMHO, a unique package (and the folder structure it comes with) is useless for a monolithic application. In any case, one can use a single element as root package, *com/company/project* can be shortened to *project*.
Oh no, how all other non-JVM ecosystem can exist without such thing? I would even say that Python's, Ruby's, Node's open source ecosystems are much richer than JVM's one... and there was no trouble without reverse-DNS folder structure.
so wait - you set it up like * src/main - source files * src/resources - resources * src/test - test sources * src/test/resources This seems like a *very* bad idea to me - looks like your test resources are being included twice.
That's a very bold statement with no evidence to back it up. While Python, Ruby and Node have very active ecosystems, the JVM ecosystem continues to remain the largest by far. 
[Debate: Does Scala need to sell out?](http://jaxenter.com/debate-does-scala-need-to-sell-out-47708.html) by Chris Mayer
I like having the folders structured by package because it keeps from having one folder full of source files. A big project with many classes should be well organized to make it easier to navigate. And having informative package names will help *immensely*. The *src* folder is good if you have many other folders in a project, like a *build* or *target* folder. 
Lack of reverse-DNS folders is the least of what's wrong with those awful languages.
What a persuasive argument. I guess if it makes you feel good to insult people, go for it.
An even more difficult tast would be to find a citation for that story being even a little bit true.
Because comparing a worst-case scenario on the far right hand side of the "project size" bell curve to the every-day situation of many means what? This is just a "... if you think THAT'S bad, you should..." one-up remark that might get you karma but means zero.
"Dependency injection tries to invert it, one simple way of doing so is by non optional constructor argument, another way is an abstract def. " No it isn't. What it sounds like you're talking about is IoC and it drives me insane hearing people mixing up DI and IoC. DI = An object's dependencies are not generated inside, they are "injected" in. IoC = You are "inverting" control away from the code, usually into some kind of configuration file and this is usually done using a framework like Spring. You dont really explain why constructor argument is "sub optimal". I've been writing Scala for a few years now and tbh I dont use any kind of crazy frameworks to accomplish DI, I just do it with simple language features (i.e constructor). Quite honestly, the amount of mental overhead with the cake pattern is crazy for how little it actually gives you; I really am not a fan of it. 
Agreed. I find constructor based DI much more easier to understand, and actually more flexible than the cake pattern. I have written in detail about my view here: http://igstan.ro/posts/2013-06-08-dependencies-and-modules-in-scala.html
I'll give you that. The first few packages should be collapsed into a single folder, like `com.example.awesomeapp`, `com.example.awesomeapp/impl`, `com.example.awesomeapp/ui`, etc. Scala will let you do this, of course, though convincing IDEs to grok it is another matter.
Note: The post doesn't describe the Cake Pattern.
What improvements could be done to this small App to make more Scala-like?
Looks pretty good, but can be even more Scalaish: * You're using a mutable Map and ArrayBuffer. In most cases immutability is preferred in the Scala world. I bet you could rewrite this using folding or for-comprehensions. * If you use a mutable collection, it is typically recommended to prefix it with "mutable", so "mutable.Map" instead of just "Map", to make your sin explicit. * You're [using a var](http://i.imgur.com/ul917r8.png). Perhaps there is another way to count the nodes which does not require mutating state? * "def printFields": for zero-argument functions to Unit, meaning its purpose is to create a side-effect, the convention is to add an empty argument list, so "def printFields()". * "fields foreach { f: String =&gt; … }": My personal preference here is to leave out the type annotation (": String") since it doesn't really help make the code a lot more readable. Not sure everybody else would agree, however.
Thanks Haakon, I pushed some changes: * prefixed Map and ArrayBuffer with mutable. (should this apply to val names too?) * removed the var nc * add the empty argument list to printFields() * removed the type annotation (I agree with you). Can you give me a hint about folding or for-comprehensions?
&gt; Using it requires some boilerplate main method ceremony, but it's pretty concise in my opinion. You can write `object Main extends App` and spare the `main` method.
Another goodie: changed the main class to object Main extends App and removed the *main* method. The new class is [Main.scala](https://github.com/insideout10/ChargingStationsOSM/blob/master/src/Main.scala).
Of course, thanks, will fix the post
Great. I also noticed that you're using an Array; these are used mostly for Java interoperability; otherwise, Scala has a wide selection of collections that are preferred. In this case, since all the members are unique, I think I would go for a Set. Vector is another very cool and highly efficient collection. Folding (as in the foldLeft and foldRight functions on collections) essentially allow you to "fold" the elements of a list into each other - for example, sum them up. For-comprehensions can be read about [here](http://stackoverflow.com/questions/1052476/what-is-scalas-yield). In general, a good book is recommended.
Thanks! fixed now...
Its down now, here is an alternate link (DNS propagation slowness, sorry) http://outerdot.com/code/2013/07/10/why-scala-rocks/
what do you mean by "open source" ?
* removed array, * removed mutable collections. It looks better, although not so elegant. Especially this part: val fs = fields ++ ((nm.keySet -- ignoreFields) -- fields) Is there a better way to do that?
SVG images are indeed an XML file, so there is a source producing the image when interpreted (by your browser for example). In that case, the images are released with the MIT license which allows you to modify the source, redistribute it, etc.
Immutable collections are slower for many things
Fun little implementation, but this "baseless number system" is, unfortunately, not a baseless *counting* system, due to the definition of +. In particular, a counting system should have a unique way to represent the number N described by the successor function + as: N = 1+++++++... (for N +s). The result of BaselessInt(1)+++++++++... will simply be [N]. On the other hand, while I can add and multiply, I've never been able to count very well. So maybe we can live with this.
Here are the ones I can think of: - Usually slower, because you have to copy things around or implement more complicated structures (e.g. ropes). - Increase garbage collection pressure because it creates more objects. This can be mitigated by good (e.g. JVM's generational) GC's but sill something to keep in mind. - Not always as easy to reason about as code that mutates structures. 
AFAIK GC shall perform better with immutable objects: [Garbage collection and performance](http://www.ibm.com/developerworks/java/library/j-jtp01274/index.html#3.4) from IBM DeveloperWorks site. 
If I understand you correctly, you say multiple-digit baseless numbers will never be reached just by counting, which makes sense. The only argument I can take is that any baseless number can be reduced to a unique regular integer which is itself just a one-digit baseless number by definition, agreed not an interesting one, meaning it should be possible to reach all baseless numbers with a unique counting sequence using this little (!) conversion trick. While googling for *counting*, I also came up with [this](https://en.wikipedia.org/wiki/Numeral_system) which says: &gt; [Ideally, a numeral system will] Give every number represented a unique representation (or at least a standard representation) which is not the case for baseless numbers so I guess baseless numbers might not be a formal numeral system after all. You should come up with an interesting counting function for this, that might help you with your counting problem =P
*isomorphic And no, they are not uncountable, because the list is restricted to a finite size.
http://www.reddit.com/r/scala/comments/1i1cym/baseless_number_system_in_scala/cb0qnes
?
So, can you do a bijection to natural numbers? Hmm... I think I see a way. Use base 9 to represent each component in the baseless number and concatenate using "9" as a separator. It's a bit rough, but there should be a way to make that a reasonable mapping. Yep. I'm calling it countable.
I tail called you. Now it's all messed up! :)
I'm surprised to read this, I thought that these days, the Cake pattern was considered to be an anti-pattern and being slowly abandoned. Did I miss something? 
Like mercurialmaven, what you describe is not what I think of as IoC at all. My understanding of IoC is the sort of situation where you have a library / framework which manages the lifecycle of objects / requests and calls into your code through specified interfaces as appropriate. So, normal non-inverted control is when I use a library by instantiating objects and calling methods in the library from within my code. Inverted control is when I use a library without ever instantiating or making other lifecycle calls myself. Instead, the libraries wraps around and calls into the code that I write. 
If the list is finite, then it's countable. If the list isn't finite, then there's an obvious bijection between a "baseless number" and the power set of the natural numbers P(N): For S = {e1, e2, ... } in P(N), the e_i in increasing order, the corresponding baseless number is [e1,e2,...]. 
It's been 20 years since my advanced math courses, and programmers don't get to use them nearly enough. So, just to clarify, and refresh an old man's memory, the power set of the natural numbers is uncountable, right? 
[indeed](http://www.youtube.com/watch?v=xYnzZ2rczSo#t=13s)
Not that I am aware of. But I think it sucks that I can't download those videos so that I can watch them while I am offline. :(
I have downloadhelper for Firefox. Maybe that is usefull to you. It can download the .MP4 from parleys. http://www.downloadhelper.net/ Edit: One can download the sheets at parleys. (downright-&gt; "download pdf of this talk").
I enjoyed this a lot. I especially liked how this tutorial shows all of the so many different ways of doing things in scala, as I wasn't aware of all of them before. There are a couple of places wher it would be cool to show how Scala supports the pearly way, but has other more prefered alternatives. For instance, Scala regexen are much weaker than perl regex, but this is a very good thing. Perl regexen have grown a lot of features to liberate regexen from their limited power, but Scala has bigger guns. Sure, you can parse a recursive gramar, capture variables, and build up a datastructure with perl regex, but how readable is the result? The Scala answer would be to use Parser combinators, which give you granular ability to name sub-parsers, and a truely first-class way to build up ASTs. Many problems that are screaming for an exception in other languages are perfectly well suited to Option or Either in Scala. Thanks to for comprehensions you can have blocks of code which propigate Option and Either, but the type system can make sure you finally pattern match to pull a value out. val optNum = for { x &lt;- map get "key1" y &lt;- map get "key2" } yied (x + y) optNum match { case Some(n) =&gt; ... case None =&gt; ... } 
[](/flutalot)^(I’m so very sorry to have to tell you that you might be wrong in your spelling of “a lot” as “alot”. But I’m a bot and I’m most likely mistaken. Please don’t be upset, I’m only trying to notify people in case they don’t know they might have made a mistake.)
Functional Programming in Scala. 
The issue is that in Scala, often the best way to 'inject' something into a method is to return a function that takes a parameter. This is both inverting control (to some degree) and injection. 
Scala In Depth
Agreed. Also "Scala in Depth" by Josh Suereth.
[Programming in Scala](http://www.artima.com/shop/programming_in_scala_2ed), by Martin Odersky, is a pretty good start.
just buy the e-book. There are discounts all the time I believe too. I got an early access copy for ~ $25. 
Did the job for me, also a senior Java programmer.
Not a book but definitely check out these talks: http://www.youtube.com/watch?v=grvvKURwGNg http://www.youtube.com/watch?v=_qRYOayG9SM
Me too, now I'm a junior Scala programmer... :-/
[Scala for the Impatient](http://horstmann.com/scala/) This book is helping me make the switch from Java to Scala right now.
Same here. Love it despite the shitty IDE help/hindrance.
I don't know about this one. It's been in MEAP since February 2012, while most books only spend about six months there, then one of the authors dropped out about a year ago for no visible reason. I would withhold my money until it actually comes out. Until then, there are plenty of other good, production ready books. 
Seconded. This is a great book to get up to speed quickly.
Eclipse won't cope.
What are you using an IDE for again? (Ed: No seriously please tell me.)
I have mixed feeling about Scala in Depth, of the various Scala books I bought it was the most disappointing. Felt to me like a random collection of topics.
I'm guessing you're using Eclipse. Try IntelliJ (free) edition with Scala plugin, feels a lot like coding in Java. Spend most of my day coding in it.
Programming in Scala has an excellent introduction for background etc., but for getting up to speed learning the language Scala for the Impatient is far less long-winded (esp. when it comes to lengthy boring examples). Scala in Action isn't bad either, but perhaps as a second book.
A more relevant question would be why **wouldn't** you use an IDE It's a tool purpose-built for the specific purpose of writing and navigating code in your language.. * Auto import management * Automatic indentation/formatting fixing * Refactoring support (renaming a var in 40 different files etc.) * Keyboard shortcuts for every conceivable task from running unit tests to templates for common snippets and structures. * Automatically being taken directly to the appropriate line of code when there is a compile error. * Code completion with inline documentation popup, parameter type hinting * Finding usages of methods across hundreds of source files * etc. etc. The alternative seems to be to install dozens of VIM plugins to the point where you've basically built up your text editor until it's basically an IDE or to live in the stone age treating code as glorified text to be edited in a general purpose text editor. In my experience the only time that makes sense is if the language you are using has really poor IDE support e.g. Go or dynamically typed languages where IDEs typically do a poor job of doing code completion, refactoring etc. e.g. Ruby. The communities with the worst tools tend to be the biggest supporters of bare-bones text editors. 
Cause I like to be productive
Josh himself speaks of Scala in Depth as "the second Scala book you should read". It is meant as an intermediate bridge guide for those who've become familiar with more basic Scala. Source: I work for Typesafe, the Scala Company, along with the author of said book. 
Solid book, if you're going to buy only one book get this one.
What's "two-ways"? You can generate IntelliJ projects _from_ sbt, and build _in_ IntelliJ _using_ sbt. Does that qualify?
JetBrains just today announced an [SBT-plugin]( http://blog.jetbrains.com/scala/2013/07/17/sbt-plugin-nightly-builds/) for IntelliJ IDEA and started publishing nightly builds from it.
By two-ways I mean to keep the project synced between SBT and the IDE, i.e. changes made in the IDE are applied to the SBT file/project and viceversa. Until now I can see that you can only generate IDE project files from SBT.
I need to try this out!
Same here. Will revisit when I've had a bit more Scala exposure, but first pass was disappointing.
I respectfully disagree - on even a medium-sized project, the number of source files can get quite large. I personally prefer a nice hierarchical organization of my source, such that I can keep associated files around each other and improve clarity for the entire team working on the code. Of course, this implicitly shows up in most projects anyways - even if you didn't organize by package -&gt; directory, you'd likely have some sort of sub-organization of folders on your own, at which point you might as well organize by package. In any case, there are valid reasons to dislike Java, but this isn't one of them - in fact, I personally find the convention a strength.
Great question, was just thinking about it. SO indeed has a wonderful topic map, first time I see that, thanks. How about this: tags can map to the content, (e.g. Based on the SO topic map, I like your idea) and categories to level ( beginner, intermediate, advanced, expert / or Odersky's own A/L 1-3 levels (http://www.scala-lang.org/node/8610) This way the same topic can have posts for all levels etc... Not sure there is support for sub tags in Jekyll, will research. 
Wasn't aware it allowed submitting documents. Very interesting, sounds like exactly what I had in mind. Seems like I need to think of what added value this can add. Here are some areas / features I thought still justify another site targeted for tutorials . 1) ability for users to "save their progress" (I am working on it using firebase API) 2) ability for narration (page author can record narration on key points using an edit mode button that uses soundcloud API) 3) interactive tutorials a-la codecademy / try ruby. (E.g. Using an online REPL like scalakata.com) 4) send to kindle feature to allow reading on mobile devices easier 5) quizzes and challenges / leader boards / gamification etc The target is more on the teaching focus than per se documenting. I'm not planning implementing all of these of course, but I think it will be easier to experiment with those ideas on a site other than scala's official docs. Having that said, you make an excellent point, and it helps me focus on the direction. This is exactly the kind of feedback I was looking for, much appreciated!
Thanks I'll take a look at it
Hi eranation, Simon here. I raised the issue that it should be as easy to contribute to the website/documentation/... as it currently is for contributing code a few days a go. Martin's response was that the Scala team is currently working on the next generation of the website. It is planned that it will be published as work-in-progress soon, so that everyone can comment, file issues, fix bugs, add content, etc. before it goes live and replaces the old site. I'd be happy to see you around, especially the idea of having an online interactive tutorial/REPL is imho really important for a modern language. More info is here: https://groups.google.com/d/msg/scala-debate/CzlQg-TCKbA/TRNmIc-hK9QJ Bye, Simon
I've started using it ... till now looks great. And it's just an alpha.
I've only heard of it, not used it, but does sbt-eclipse only do one-way support (i.e. generating the project file, but not update it from eclipse?) And another question. What about using maven instead of sbt? Would m2eclipse-scala support the two-way integration?
I'm happy with a reasonable directory layout. I just find that being forced to use reverse dns package names never results in what I would consider a reasonable layout. It may just be the required prefixing. It seems like you always end up with project/src/com/company/project/actualcode.java when project/src/actualcode.java would have been fine. The subdirectories that java would force that come after the second "project/" are usually fine (though some of them end up being a little sparse). Now IDE's can find it by collapsing the empty directories in the GUI. But sometimes I use vim and have to cd to the code. Or sometimes I browse it on github. Or use Finder or Explorer. Or an svn web gui.
Thanks! will be in touch :)
This is just a draft, feedback welcome!
Bunch of extra steps which aren't really necessary. 1. Scala is not needed, sbt will fetch it for you. 2. Conscript and giter8 are useful, but not absolutely necessary, `mkdir -p src/main/scala` is what really needed, or just drop your sources right into the project directory.
Thanks, I'll add a "Quick setup" section
I'm probably being dense, but with downloadhelper, how do you download the video?
Download helper puts an icon next to my forward/back icons in firefox. If it finds a video that can be downloaded it rotates. Press on the down-arrow next to the icon and it shows a menu-item with the file(s) that can be downloaded. If i click on the Shadaj lecture, i can see a long-named .mp3 file in the menu that shows up on clicking the down-arrow. It just appears for a small time (a minute or so), usually only while the file is downloaded.
Why is the whole object locked? Wouldn't it be enough to just lock the variable that's being initialized (assuming the expression is pure)?
If you are writing code for the JVM and not using an IDE, you are either the single most productive coder in the world or haven't been exposed to highly skilled peers. If it's the first one, I argue that you could make yourself even more efficient by adopting the use of an IDE. If it's the second, unfortunately you do not have enough experience or context to be an authority on an opinion like this. The attitude of 'IDEs are for old people and wimps' is unfortunate, and sadly holds quite a few people back. It's perfectly understandable if you're working on a platform without good IDE support or if the platform itself doesn't lend itself well to this kind of tool. Any other case implies that you are just showing your lack of experience.
Is this the right way to send a chunked response from a custom Marshaller in Spray?
Mmmh... never a good sign when something that used to cost money is now given away. I'm guessing they haven't had much luck trying to sell it. 
Interesting post - I blogged about this myself recently, but with the opposite conclusion: http://www.janvsmachine.net/2013/07/on-custom-languages-for-unit-tests.html. At least for unit tests, I don't really see the benefit of DSLs. I guess the key question is: who will read the tests? If it is developers who know the language that the code is written in, it seems better to me to keep the tests in the same language. If it's business users or others, it may be a different matter.
I agree with your blog post's conclusions. DSLs make sense where there is a requirement for a formal language, such as for expressing grammars for parsers, but I don't see the relevance for unit tests. The above article seems like it is simply expressing unit tests with a contrived, and not particularly intuitive, natural language syntax.
Unit tests should always be readable, and easily understood. If the best way to make them readable is to use a DSL, I say you should use one! Obviously, there are tradeoffs. However, having been writing a lot of acceptance tests recently, I found using a DSL hugely beneficial. Even as the person writing and reading these tests (and implementing the code to make them pass), I found it easier to reason about when written in terms of people and things rather than calls to endpoints to set up a certain state. Admittedly, the example shown in the blog post isn't necessarily the best example of when to use a DSL as it is fairly small. However, I kept it short to encourage people to read it.
I just pushed a review to the code, thanks to a helpful review by @sprayio.
I would agree that DSLs for testing are useless, but that's not the only thing that Scala (and other functional languages) bring to the table regarding testing. Check out [ScalaCheck](https://github.com/rickynils/scalacheck) (as well as it's counterparts in other languages, like [QuickCheck](http://hackage.haskell.org/package/QuickCheck) and [FsCheck](https://github.com/fsharp/FsCheck)) to see what I mean. Property-based testing is miles above standard unit testing, and it's hard to see why until you try it. EDIT: added a closing parenthesis
Once in a while DSLs are nice. Not this time though.
I agree that unit tests should be easy to understand, and that DSLs can help with readability. However, is what you've implemented really a DSL - what's the actual grammar for the language? You've actually conflated two attempts at a DSL into one - one for tests and one for building graphs. Also, your argument for the use of natural languages is not particularly compelling. You argue that for the following: alice ~&gt; bob alice isFriendsWith bob `isFriendsWith` is more understandable than ~&gt;`. I would argue that the use of concise symbols actually improves readability when the meaning is well established (in a particular domain). In fact most DSLs take this route. An obvious counter-example to yours is the following: x + y x addTo y The former is abundantly clear, whereas when presented with the latter, the natural assumption would be that `addTo` does something that was in some way different to addition, as otherwise why would `+` not have been used. Perhaps `addTo` modifies `y`. It would be extremely cumbersome to use a DSL, say for vector operations, which used named operations rather than the usual mathematical symbols. The lack of operator overloading is one the main factors that makes DSLs impractical in Java. I think your own code provides a further counter-example to trying to use a natural language syntax to express unit tests: alice befriends bob alice isFriendsWith bob `isFriendsWith` is an ambiguous name - is it stating something declaratively or is it expressing something to be tested? If this were a DSL (for building a graph) I might expect the former, but here it's actually the latter, and I have to look at the implementation to find this out. "assert" (or "require") is part of the domain vocabulary for unit tests, and by avoiding it you have made it unclear which expressions are the actual tests. This isn't helped by the fact that your NL syntax relies on implicitly mutating state in `graph`. 
If there is already a DSL present, then that should be preferred. Using x addTo y is clearly a bad idea if the use of a + could be used. As I'm not aware of any existing DSL for a friends graph, I went for natural language. After reading feedback, I think you're correct about having conflated two DSLs into one. The first commenter on the post suggested that the DSL for the friends graph be refactored back into the main code - which I believe would then render the assertion DSL obsolete. Sadly, it would also make the title of the post inaccurate! Thanks for the feedback :)
I think friendship is a slightly tricky concept to model in FP languages - it's more suited to logic programming. I disagree with some of the commenters here that DSLs are pointless - they have their place. I'm just not convinced (yet) that that includes unit tests...
I guess the problem is that `synchronized` requires an object reference (`java.lang.Object`), so at least in this example, where the variable is a `Double`, you wouldn't be able to sync on it. In any case, a scenario where many threads are concurrently accessing different uninitialised lazy vals seems very esoteric to me, so this looks like a pragmatic solution. One could argue that it is safer to have a private object to lock on, but that would add another reference per object.
Java is a JVM language…
Yes, sbt-eclipse has only one way support.
Yes. See also http://en.wikipedia.org/wiki/JVM_languages
Including Java (the actual JVM language with the largest job market) [skews the graph a little bit.](http://www.indeed.com/jobtrends?q=java%2C+scala%2C+groovy%2C+clojure%2C+jruby%2C+jython&amp;l=)
The point is: Scala has caught up with Groovy, the formerly strongest contender as Java alternative on the JVM.
Yes sure. There is probably &gt;50 Java jobs for each Scala job. On the other hand, Java jobs are not exactly on the rise any more.
While very interesting, I think the unsaid consensus is that the title is misleading.
Well, as said, I took it for granted that we're not talking about Java. If anyone read the title as saying, there are more Scala jobs now than Java jobs, I'm sorry about that. Can't seem to be able to edit the title.
No need to apologize. I just came in all excited, and then was disappointed is all. Though I was a bit incredulous that Scala had surpassed Java itself. Maybe in 5 years. It's still a nice achievement for Scala. 
If you click the Relative link and look at the growth, it seems that Groovy looks a lot better than anything else (including Java), though Scala is still #2.
Unfortunately most of the hits - for all of these languages - are in sentences like "bonus if you know X, Y and Z (but we won't let you use it in production)". 
The "relative" mode is one of the most absurd things I have seen. Relative to what? Relative to previous number of jobs? They would have initially been zero or one, depending on your view. And probably at different times in the past. So what does 1 million percent growth mean? And what does a graph mean if you depict multiple "relative growths" which relate to different things?
I have no idea, I didn't make the graph, I was just looking at the pretty lines.
The main problem is the average skill level of the enterprise worker.
[now let me add job](http://www.indeed.com/jobtrends?q=java%2C+scala%2C+groovy%2C+clojure%2C+jruby%2C+jython%2C+job&amp;l=)
According to that same site, here are the number of jobs available: - [Scala: 1263](http://www.indeed.com/q-Scala-jobs.html) - [Groovy: 3450](http://www.indeed.com/jobs?q=groovy&amp;l=) Add this to the fact that it doesn't seem to be possible to get any graph past January 2013 and I really don't think this site is very serious. 
Hmm, that's odd indeed. If you use "Scala and Java, Groovy and Java", they level. Those phenomena exist in many sites. http://langpop.corger.nl/ (which now seems offline) was showing "Shell" way ahead of Scala on the Stackoverflow ranking, although if you use "Shell" as tag, the come up levelled in Stackoverflow search. On Github I am surprised since long time that "ASP" is in front of Scala. If you look at the activity, there is almost nothing going on. If you look up some of the highest ranking projects of ASP, there is isn't even any significant "ASP" sources involved. So, unless these site provide reproducible algorithms of generating the data and ranking, one needs to be very careful with conclusions. That also goes for Indeed.com which does not provide any background information about how the data is analysed.
R is a wide spread statistically environment used across difference sciences. It is an important competition for the commercial Matlab, although it has a different language and slightly different focus (statistics and plotting). It is very powerful, but the language honestly is one of the worst designed ones I have seen. There have been bindings for C, Python and Ruby before, so making it embeddable on the JVM is certainly a good thing for Scala in the sciences, which sadly is drowned in Python. (**Edit**: also attractive that running some algorithms through Scala from a R session gave &gt;10x speed increase) Running JFreeChart from Scala is fine, but with R there is another really well looking alternative now, without having to export/import the data.
I wonder what effects we might see on these graphs 6 months after the release of java 8. *note*: I love scala myself, and am aware that it brings much more to the table than just closures. Yet, a lot of people gravitate to it and groovy for those features, imo, at least initially. 
If you think bringing Scala into a Java shop is hard then imagine a .NET shop. This slidedeck reinforced a lot of great points, thanks.
Reading through the introduction, this seems very good. I like their approach of using Scala to teach functional programming style and paradigm. Learning Scala should be more than just learning new syntax, but completely changing how you think about programming (especially if you come from an OO background). 
But these numbers are so tiny that they are beyond the margin of error, so I don't really see the point. Besides, the graph ends in January and it doesn't seem possible to see it for July, why is that? 
How so? Even if you mostly ignore functional programming and just use "lambdas", the collection API and case classes you save a truck load of boilerplate.
What's wrong with Scalaz where you should avoid using it?
What good are these slides without the accompanying audio?
"Don't make Scala Perl-like" was an earlier slide.
The mark for Jan 13 is left of the right margin, which corresponds to July (half the distance from Jan 12 to 13). You can easily judge the amount of noise by looking at the curve. SNR isn't that bad.
I couldn't disagree more. Scala is a rather bad replacement for Haskell if what you want to do is make use of a highly expressive type system with optimally clear syntax, but easily lives up to the better Java claim. "Regular" programmers get it and I agree with the approach implied by the slides -- they can worry about monads later. 
Bloated in what way? Do you mean compiled .jar size? Because that's really a non-issue. &gt;If you're just scala-syntaxing java That's basically what every other JVM language is
pjmlp didn't suggest they use a 30 year old compiler.
&gt; they can worry about monads later As long as they use Option correctly, at the very least.
&gt; introducing ScalaZ too soon may frustrate or frighten developers Yes, that's it. The whole thing is about easing in Scala, initially as "Java but with cool custom for loops like maps and filters" and then taking it from there.
It is common for a speaker to upload their slides. It is less common for someone to make a quality recording of the entire talk. The result is that slides are often shared without any audio.
Apparently [another R + Scala project](https://github.com/TiarkRompf/Relite).
Scalaz introduces a lot (and I mean A LOT) of new abstractions, which: 1. need to be understood 2. are not supported by most 3rd-party libraries 3. often, are too abstract to be immediately applicable 4. or are simply syntactic sugar, which increases code style variability I think using only few features from Scalaz shouldn't hurt, but those features should be understood by the team and the feature restrictions should be enforced as adding a new library dependency would be. My candidates (in order of usefulness): - some() and none() - |+| and Monoids - Validation - NonEmptyList
Wait, some() and none() aren't in vanilla scala!? Are Applicatives in Scalaz? I can't imagine living without them in Haskell.
`some[T](t:T)` and `none[T]` are functions that have return type `Option[T]` instead of `Some[T]` and `None[Nothing]`. They're mostly useful in initialising vars or as the initial value for folds: xs.foldLeft(None)(f) // f has to be of type (None[Nothing], X)=&gt;None[Nothing] xs.foldLeft(none[Y])(f) // f has to be of type (Option[Y], X)=&gt;Option[Y] var x = Some(1) x = None //illegal, x is Some[Int] var y = some(1) y = None //legal, y is Option[Int] As for applicatives, they surely are in Scalaz. I don't feel like I need them that badly, usually a nice `for` is enough.
What about \/? Don't tell me you use the broken/awful Either from the standard library. How about transformers? They're a life saver. 
&gt; \\/ &gt; Either Their type doesn't convey any semantic information. Instead of using them, I prefer to either create a custom ADT, or just use Validation (which provides semantic information of "it's either a correct stuff or an error"). &gt; How about transformers? They're a life saver. You're exaggerating.
You really create a custom ADT with all the common typeclass instances instead of using \/? Why? \/ can more or less do what validation does (except it's a monad and Validation isn't). Transformers are a life saver. I write a lot of network code. If you're using futures without transformers, you're severely handicapping yourself. 
Ill have to admit now I'm more of Scalaz 6 guy, so I haven't had an opportunity to use \\/, but I wouldn't anyway. Is there any situation, where Validation doesn't fit and there no meaningful reason to define a new ADT? This ADT doesn't need all the functionality of \\/. I'm a guy who'd happily define `case class Email(override val toString: String)` to get some strongly-typed semantics and wouldn't mind that this new class has no toUppercase method. As for the transformers, I'd love to see some examples.
When working at startup that used play framework for Java, the older Java developers would always find something about Scala to nitpick as an reason to not use it (compile times, complexity, lack of hireable devs, etc). What I think they were really against was sacrificing their position as "Senior Java experts" and effectively make me (a younger Scala programmer nearly half their age) the in house expert. No way they were going to throw years of Java experience to adopt some new technology all the cool kids were using.
Ah. In Scalaz 6 Validation is a monad, so I think that's the issue. **As for Transformers, behold:** If you've ever wanted to return a Future[Option[A]], but didn't want to deal with val f2 = for { optA &lt;- Future{ Some("a) } } yield { for { concreteA &lt;- optA } yield { concreteA.toUpperCase } instead, you can use Transformers! Which have the type signature of Transformer[Monad[_], A...] val f2 = for { concreteA &lt;- OptionT[Future, String](Future { Some("a") } ) } yield concreteA.toUpperCase Here's a real world example from my [xmpp library I wrote](https://github.com/vmarquez/xmppz) : for { (conn, myjid) &lt;- ConnectionHelper.gchatConnect(conn, "xmppzExampleClient") (conn, presence) &lt;- conn.sendGet[Presence](Presence(from=Some(myjid), to=Some(tojid), presenceType=Some("probe"))) conn &lt;- conn.send(Message(body=Some(msgtext), to=tojid, from=Some(myjid))) conn &lt;- conn.send(StreamEnd()) } yield conn ConnectionHelper returns a Future[Writer[Either]] transformer stack. I'm using the writer monad to log what happens, if anything goes wrong comprehension *terminates* because of the Either, and it all happens asynchronously because of Future (and it's backed by netty so it's using NIO for max number of connections). 
I'd write that first example as val f2 = Future{Some("a")}.map(_.map(_.toUpperCase)) but that's me. I'll check out the transformers, maybe I'll find some use for them.
True. Just because Scala provides support for functional programming doesn't mean that Scala isn't a fantastic OO language.
Sometimes the best way to sneak Scala in the door is to write an awesome new system in Scala. The usefulness of said system will mute much of the criticism. I also had experience having a team member cite $RANDOM_BLOG criticizing Scala.
The first thing I wrote there was this sick analytics utility that parsed through our applications server logs and exported performance data in csv files. It was no sweat to build in Scala and run via sbt, but I know building in the same thing in Java would have been unpleasant. Even the Java devs had to show Scala some respect after seeing it in action.
Although, Scala does have *good* metaprogramming: reflection and macros. Though both APIs are still experimental in 2.10 (the reflection one has at least one thread-safety bug, in particular).
Indeed, I was just referring to Ruby's particular flavour, run time global modification of .... just about anything.
I'm in the same boat. I'm familiar with functors, monads and applicatives but I struggle to find an application in my code. I am slowly realizing that competent functional programmers are much better at explaining "how" these concepts should be used than "why". Whenever I have asked this question on the forums or irc, I get nothing. 
I assume you don't include Clojure, there.
You actually shouldn't need this anymore - as of a couple weeks ago, IDEA has first class sbt support. It'll read in your project definition and automatically sync your dependencies and such just like it does with maven. This really was my last blocker to switching to sbt from maven. http://blog.jetbrains.com/scala/2013/07/17/sbt-plugin-nightly-builds/
Yes? Clojure is just scheme-syntaxing java.
I think STM would be another scenario which could benefit from this syntax. You can have in-memory versus durable STM in the same application. That is almost exactly what the author describes as "multiple access spaces". I have no knowledge of Agda, perhaps someone can explain why this interleaving of type parameters, value parameters and implicit parameters is an idea that comes from Agda?
Agda is a statically-typed purely functional language, with syntax similar to Haskell or ML. It's main feature is dependent typing, which is what gives rise to (the general case of) the proposed Scala feature being discussed. Basically, in Agda, there is no seperate concept of "type parameters", just value parameters, and if you want to pass a type as a parameter to a function or a type constructor, then you can just do so as an ordinary value parameter, because types (and functions of types, like type constructors) are just values like any other in Agda. Totally unrelatedly on the language design level, but useful for similar reasons, Agda also has a notion of implicit parameters (two of them, actually, but the second one is not important here). Let me illustrate the difference for you: -- This is an implementation of sized vectors. data Vec : Nat -&gt; Set -&gt; Set where -- the curly braces mean to take the parameter implicitly nil : {A : Set} -&gt; Vec zero A cons : {A : Set} -&gt; {n : Nat} -&gt; A -&gt; Vec n A -&gt; Vec (suc n) A -- This version of sized-vector append takes all of its parameters explicitly. vAppendEx : (A : Set) -&gt; (m : Nat) -&gt; (n : Nat) -&gt; Vec m A -&gt; Vec n A -&gt; Vec (m + n) a vAppendEx A (suc m) n (cons x v1) v2 = Cons x (vAppendEx A m n v1 v2) vAppendEx A zero n nil v = v -- This, more usual, version of sized-vector append takes some of its parameters implicitly. vAppend : {A : Set} -&gt; {m : Nat} -&gt; {n : Nat} -&gt; Vec m A -&gt; Vec n A -&gt; Vec (m + n) a vAppend (cons x v1) v2 = Cons x (vAppend v1 v2) vAppend nil v = v -- If we want to, we can specify implicit parameters manually, and switch around which ones are implicit. -- Of course, this is not usually a good idea. vAppendIm : (A : Set) -&gt; {m : Nat} -&gt; (n : Nat) -&gt; {Vec m A} -&gt; Vec n A -&gt; Vec (m + n) a vAppendIm A {suc m} n {cons {A} {suc m} x v1} v2 = Cons {A} {suc (m + n)} x (vAppend A {m} n {v1} v2) vAppendIm A {zero} n {nil {A}} v = v Agda doesn't care which parameters you make implicit vs. explicit, as long as you either specify a given implicit parameter manually or it can figure it out by the normal process of type inference. The second kind of implicit parameter that I mentioned are called "instance parameters", and are indicated by double curly braces rather than single. An instance parameter gets a sort of second chance to be inferred if normal type inference can't figure it out, and will be filled in by a lone value in scope of the appropriate type. As usual, you can specify them explicitly if you want. Agda's instance parameters are somewhat closer to Scala's implicit parameters than Agda's implicit parameters are, but both implicit and instance parameters in Agda can be taken anywhere and can be either types or values. (Of course, this because in Agda there is no distinction between types and values; that's what makes it dependently typed. In Scala we need a distinction between type parameter lists and implicit parameter lists, and you (unfortunately) cannot force the user to pass type parameters explicitly.) EDIT: Corrected punctuation.
Website: http://oss.readytalk.com/avian/ Unfortunately there aren't any more detailed release notes
I'm curious how its performance fares in comparison to openjdk. Edit: i tried it with some benchmark code I had lying around. Avian had a 10x slowdown from openjdk, but that might be because of the way I built it. Dunno.
Also [on the ACM website](http://dl.acm.org/citation.cfm?id=2489837&amp;picked=prox&amp;CFID=236345446&amp;CFTOKEN=82511692)
oh fart, oldies still stuck in command line era
Scala is useful almost anywhere. Even if you mostly use it like you would Java, you can integrate bits and pieces of the conveniences Scala provides in your code. Scala is *not* useful in teams/projects that only know Java, unless everyone involved is prepared to learn. Besides, if you want to learn Java, learn Java. Learning something else alongside will not help you towards that end goal. The most efficient approach would be to first learn Java to desirable competency, and *then* tackling Scala afterwards, or vice versa. I could imagine learning Scala first and then transitioning to Java. Just not both at once. Especially if you're new to programming. So the question is, is it worth it to start by learning Scala first instead of Java? Sure! Why not? You gotta start somewhere, and it can be Scala just as well as Java. Scala is definitely a more convenient language to work with than Java, as it provides more abstractions and ways to deal with data and code. However it should be said that, if school requires you to learn Java, you need to learn Java. So wait with Scala unless you feel confident enough in your learning abilities that you will be able to learn both at once.
Learn from Martin Odersky himself: https://www.coursera.org/course/progfun Learn Java so you can read other people’s existing programs, and Scala so you can be happier and more productive.
I know a somewhat decent amount of Java. I understand basic GUI design and I can implement various basic data structures (BSTs, Linked Lists, etc). I understand the concepts behind recursion and can use it in my programs. I'm just worried about how far a long in Java I should be before I start to learn Scala alongside it. I feel as though one is never "done" learning a language, I'm just curious about when one should feel that they know enough of a language to move on and learn something else. Thanks for your response :)
Once you learn the cool bits of Scala, you might not want to go back to plain Java (I know I don't). It might be better to learn Java as-is to learn the basics of imperative-style programming (until J8, if they deliver), then use Scala to transition into more functional-style stuff. Odersky can be kinda dry and hard to understand sometimes (but that's just me), I read this book not long ago [http://pragprog.com/book/vspcon/programming-concurrency-on-the-jvm] and learned that the author actually teaches Scala, it seems for Java people...he definitely more entertaining. Once again, your results may vary... http://www.youtube.com/watch?v=LH75sJAR0hc
What exactly are the "cool-bits" of Scala? I hear that functional languages have some incredible benefits over strictly imperative languages? I've never quite understood why functional languages (particularly languages like Haskell) seem to gain, to use the phrase, "cult followings".
If the question is "should I learn programming language X" -- the answer is always yes. The more you learn, the stronger the core tenets become and the more the various language degrade into syntax and tooling (which is a good thing). http://norvig.com/21-days.html "Learn at least a half dozen programming languages. Include one language that supports class abstractions (like Java or C++), one that supports functional abstraction (like Lisp or ML), one that supports syntactic abstraction (like Lisp), one that supports declarative specifications (like Prolog or C++ templates), one that supports coroutines (like Icon or Scheme), and one that supports parallelism (like Sisal)" 
I just released a very experimental interactive "tour of Scala" (with code examples that you can run via the browser) and would love to hear feedback from people new to the language! http://scalatutorials.com/tour/01_tour_of_scala_scalculator.html (Note, it's still very early work in progress, and not complete, so if you find errors / typos, please forgive us and we'll appreciate if you click the link supplied to report it) Would love to hear feedback, e.g. did it help you get the language's basics? did it make you want more / less to continue learning it? did it make things more / less clear to you? etc... Thanks! p.s. it's a non for profit hobby project, 100% free forever. 
Scala has many "cool-bits". Some of the ones that are immediately cool to a Java programmer would be: * Collections Library - a great collection library that has a unified and consistent API, with support for many different data types. * Case classes - immutable classes, with a single constructor, a hashCode and == implementation, and more. * Singletons - you can generate a singleton object without the syntactic noise of Java. * Traits - traits are more powerful interfaces that can contain state, and full method implementations * Concurrency - the language supports better basic concurrency primitives, futures, actors, dataflow The functional features that us FP nuts enjoy are: * powerful type system (dependent method types, implicits, ect) * immutability (promotes code that is easy to reason about) * combinators in the stdlib * pattern matching * flexible syntax * macros * monad syntax * and more Many of these features also exist in Haskell, but Scala is a little more relaxed and by many's definitions less safe. Haskell has no mutable state (without some more advanced features), and has syntax inspired by ML, while Scala's remains closer to the C family of languages. On top of this Scala interoperates with Java which for most is a big win, as it opens up all of Java's massive code bases to be used. 
I find it hard to believe that anything useful could be learnt from Perl. It's also worth pointing out that learning a new language doesn't come without a cost - you could instead spend the time extending your knowledge of a language you already know. In the specific case of Scala, I think it is worth learning though, esp if you're already on the JVM ecosystem.
I entirely disagree. First of all, you might someday need to port a Perl application to something else. Also, Perl is useful from a command line via parameters, it might just be the most powerful command line tool you got. Beyond that, Perl has its own flavor and useful lessons to be learned. The idea of blessing structures to objects, stripping away a bit of the magic from objects. Very manual reference handling, etc. 
I'll definitely make a solid effort to learn the language. It seems like it can make a lot of tasks a lot more efficient. I've seen examples where entire Java classes can basically be reduced down to single line statements in Scala lol
Is there a particular reason why Haskell would be better suited? The reason I thought Scala would be the "best choice" is because it's a JVM language that mingles well with Java. Can you explain why you feel as though Haskell would be a better choice? Thanks for your reply :)
I personally don't see any advantage of Java over Scala, so if you have already basic Java skills, I don't think sticking longer to Java before trying to learn Scala helps you any. Many people report that after many years of Java, learning Scala requires quite a bit of 'unlearning Java'. I started Scala after many years of Java, so I had the same experience, starting with very Java'ish code. I think if I had picked up Scala earlier, my learning experience would not have been more difficult at all. Scala feels a natural transition from Java, because it is fully interoperable, shares many of the same concepts and has syntactic similarities. Nevertheless, you will find that Scala is quite different. While other posters have advised you that Haskell is more "educational" for you, I disagree with that it is necessarily a greater benefit. Don't feel intimidated when people try to tell you you only get smart from learning a pure functional language. Scala in the first place is great fun to work with, and staying on the JVM in my opinion opens you many doors.
But it is true that time resources are limited. I would love to learn many more languages, but I simply can't. The maximum I manage now is learn to read code in other languages. And I think that also goes for a period of relative wealth in time—when you study. So putting priorities is the right thing to do.
If you want to learn statically typed FP, Haskell enforces purity, is lazy, and doesn't have the warts of the JVM that Scala has, so it's an elegant (and pure) environment for learning fp. For learning and thinking functionally, it's probably a better choice. As Tpolecat mentioned, nearly everything you learn in Haskell is transferable anyway, and without Haskell, you're kind of missing part of the picture of why Scala is the way it is. Having said that, I'm not sure I completely agree you should do Haskell before Scala. There's nothing wrong with learning Scala, "getting shit done" and furthering yourself on the FP aspects later. I used Scala productively and had a grand old time for quite a while before properly jumping on the FP train of thought.
It is a question of time versus value. IMHO you are undervaluing what a little knowledge of Perl or Haskell or Erlang or X is worth... I am not saying become an expert, but you can become versed in languages quickly (days) and it gets faster and easier with every one (pick up idioms and orientations faster, have syntax become less and less jarring). By constantly learning languages, you are learning HOW to learn (your own personal process)... and in this field, I can't think of a single thing more valuable that the ability to pick up "whatever comes next". So I say time well spent! It seriously becomes much easier after the first 15 or so -- then you start bundling them together the same way people do in real life -- if you speak Portuguese, Spanish isn't like learning an entire new language. Romance languages can be somewhat lumped together. The same happens in programming, you start seeing a language as a functional language with roots in X, but the flavor of Y, and idioms of Z ... and rather than taking weeks to pick up, it takes hours. 
Best start is to start reading this: http://typesafe.com/resources/book/scala-for-the-impatient
In case you just want to learn things, then by all means go ahead and learn Scala. I was assuming you wanted to be able to construct programs, and in that case, make sure you are fully able to construct a program according to specification in Java before moving on to Scala.
Scala is easier to start writing a project in - you can fall back on your knowledge of Java. Haskell will teach you more in a shorter amount of time. It's essentially the difference between learning to swim by jumping in the deep end (assume you have those inflatable things on your arms so you don't drown) or in the shallow end. In the shallow end, you can still walk, so it's fairly easy to get from point A to point B, and you can even try a little bit of swimming on occasion. In the deep end, you can't fall back on walking and need to learn to swim to get anywhere, so it's harder to get from A to B. Functional languages use different idioms. If you're trying to learn some functional programming, it's probably best to learn a functional programming language instead of an object-oriented language with features that enable a functional style.
Very cool, I'm glad to see scala have something like tryruby.org. I only took a quick look, but so far... * The ordering on the [table of contents](http://scalatutorials.com/tour/toc.html) seems to be off. * It might be better to condense the pages covering the fundamentals that are similar across any number of languages (like "Method Definitions" 1 2 &amp; 3) to more quickly get to scala-specific stuff. Not sure what the specific audience for the interactive tour is though; that approach might be too dense if it's targeted at completely new programmers. Otherwise, looks awesome!
I'd suggest introducing `val` before `var`.
&gt; If the question is "should I learn programming language X" -- the answer is always yes If I know C#, Haskell, Scala, Scheme, and an ML, should I learn F#? I'd argue that the answer is probably 'no', unless there's a job I'm thinking of applying for that uses it. &gt; IMHO you are undervaluing what a little knowledge of Perl or Haskell or Erlang or X is worth... I am not saying become an expert, but you can become versed in languages quickly (days) and it gets faster and easier with every one (pick up idioms and orientations faster, have syntax become less and less jarring). There's also the issue of whether it's a better use of your time to become an X guru than to learn a tiny bit of X,Y and Z. There's a fairly big difference from "I learned a bit of Haskell, Prolog and Common Lisp in a class" to "I've used Haskell/Prolog/Lisp for a few years and have written several nontrivial projects in it". For an AI class I took over the summer, a few years back, I implemented a fairly simple expert system in [Mercury](https://en.wikipedia.org/wiki/Mercury_(programming_language\)). It wasn't that difficult because I essentially wrote a combination of Haskell and Prolog code in Mercury. However, I'm not certain how much Mercury taught me, because I don't think I was really thinking in Mercury.
Good news: Very small amount of JS and CSS in the markup, very attractive Meh: Front page with 1745 DOM elements (July 31), improved from initial launch. Bad news: ~~Front page with 3771 --&gt; 1764 --&gt; 1745 DOM elements~~, ~~over 1MB of images~~, some unfortunate class names (e.g."darkbluebar") Edit: the number of DOM elements is currently 1745, and the size of images is 669 KB. Either the site has been updated or I was greatly mistaken previously. In any case it's better than I originally thought.
Those who responded while I was sleeping explained my reasoning very well, thanks guys! If you know Java you probably understand how to write buggy programs. By learning Haskell you will learn how to write functional programs, and you will then be able to apply these skills in other languages (including Java btw, but Scala in particular) where writing functional code is a discipline rather than your only option. 
Glad I could help.
Thanks! removed the TOC link till it's fixed, thanks!
&gt; Once you learn the cool bits of Scala, you might not want to go back to plain Java (I know I don't). This is the one big downside to learning better languages - there tend to be fewer jobs for them (though they do exist), and writing blub can be painful once you understand more powerful languages.
A nice quick tour. Only a minor note: `getTypeTag` is a misnomer—it _needs_ an implicit type tag as parameter, but it returns actually a `Type`. Consequently, `typeTag.baseClasses` should actually be called `tpe.baseClasses`.
&gt; First of all, you might someday need to port a Perl application to something else. Also, Perl is useful from a command line via parameters, it might just be the most powerful command line tool you got. Neither of which has anything to do with learning something useful, which was my point. The only thing I learnt from my brief experience with Perl was how not to design a programming language. 
I'm working in Scala full time now, after many years of Java. I don't think I've had to "unlearn" anything (well, maybe the semicolons). In addition to the huge learning curve of Scala, there is the issue of learning to think functionally. Unless you buy into the functional religion, there is no need to unlearn imperative programming. Now I have another tool in the tool box.
I recently did a "Scala only" job hunt, and found a great job using Scala. In addition, the 3 companies I interviewed at that used Scala were all great. If you need a job ASAP, then maybe my approach isn't going to work...
False Choice. You are conflating very different things. Learning a bit about 3 languages is a far cry from becoming a Guru in one ... which takes years and requires outside investment generally and expertise (a job that uses that skill).
If you have an android phone you can see the videos in the scaladays app here: https://play.google.com/store/apps/details?id=com.parleys.android.scaladays2013 It has support for viewing the videos while offline as well.
Time is limited; there's only 24 hours a day. The opportunity cost of spending a weekend learning Forth could be understanding something you don't in your go-to language (say, grokking continuations, monad transformers or existential types), or just getting more experience by making something useful. Sometimes your time is better spent learning a new language. Sometimes it's better spent getting better at the ones you already know.
Bad news: not a single line of code on the front page. 
There's lots of code examples under the scala in a nutshell section.
Doesn't have right padding/margin on iPad.
Great job. Thanks.
You should learn at least a bit of Haskell not because you're going to need it in the future. To be frank, many people who know Haskell don't use it professionally. Instead, you should learn it to learn how to solve problems in a functional way. This skill translates into appropriate Scala skills and lets you make your code more concise, less error-prone and easier to parallelise.
Some pdf links lead to access denied errors.
~~true, after one downloads the 2 MB front page~~ Edit: seems to be down to 942KB, so that's awesome.
You've omitted a /s
Same here, on iOS 6 Safari and Chrome. Front page has the feel of starting off as an adobe rendering. The rest of the site is a bit better.
In what regard?
That's pretty unfortunate. Should we proof the site and verify links and send it along to TypeSafe? I'm a bit torn on this, I would love to help but the carelessness exhibited by the mistakes leads me to worry that I would simple be an enabler of bad practices.
I can't even read that without zooming in to at least 150%...
And what you are missing – more testable.
Can't you just infer it?
I'm slow
We don't. It's an EPFL project. That said, Typesafe does provide help, such as our in-house graphic design wizard.
Please file bugs or send pull requests: https://github.com/scala/scala-lang
[Interview with Dianne Marsh](http://typesafe.com/blog/dianne-marsh-sneaking-scala-through-the-back-door)
Sweet!
We're doing integration testing with…archaic home video media?
Yes, Typesafe help was very helpful. But indeed scala-lang.org remains in the hands of EPFL. And we have limited resources for this kind of testing. I did probe the site for some time to try and find all broken links, but obviously I missed some. As another comment says: please file bug reports (or even better, submit pull requests) in our issue tracker on GitHub: https://github.com/scala/scala-lang
I dropped out for health reasons and my inability to continue keeping up with the other two. It was only fair. They are going very strong.
Well, age isn't the reason I know what it was. I wasn't old enough to know about it when it was actually around. I only learned about it years after its demise.
Being able to find implicit calls is a requirement for maintaining any kind of Scala project. 
Scala *has* been gaining some traction (possibly surpassing Groovy by now?) so expect to see more of it in the future. Learning Scala will make you a better Java programmer in some ways (as well as a possibly frustrated one)...and if the job still requires Java, you can always try to push for the Guava libraries as least: https://code.google.com/p/guava-libraries/
Another thought (this might just be me): it seems like the Java language might be experiencing what is happening to JavaScript. There seem to be more (and more?) languages out there that target the *platform* and one only goes down to the 'C-level' to tweak the code for whatever reasons (C-level being Java &amp; JS, because *technically* Java bytecode would be the assembly equivalent). 
Hi, one of the authors here! The book has been in MEAP for a while, but all chapters are finished (and online if you subscribe to the MEAP) and we are in talks with the publisher right now about a final round of revisions. We should know a final publication date fairly soon. The book is still quite useful even in its current form - all chapters are available to MEAP subscribers, and there are exercises and answers for all the chapters in the [book's repo](https://github.com/pchiusano/fpinscala). Here in Boston, there is a [Meetup group](http://www.meetup.com/boston-scala/events/120128672/) of people who are working through the book's chapters and exercises together, which has been pretty cool! I've heard of other businesses that have been doing "reading groups" for the book as well. As Tony mentions below, he unfortunately had to drop out due to health reasons, but Runar and I are still going strong and will make sure the book gets out.
Hmmm, why do some reddit entries disappear? I tried to submit this right now, and reddit says "that link has already been submitted". But I guess like me no one has noticed?
Perhaps one should add [ScalaCheck](https://github.com/rickynils/scalacheck/wiki/User-Guide) which has generators based on random numbers, but (as far as I remember) also makes sure that some _boundary/edge cases are included_.
*Very* slow to load for me (Chromium 28) then started to hang after the first page. Needs more oomph in the backend?
[Here is an example project](https://github.com/scalamacros/sbt-example-paradise) using the new paradise version. `project/Build.scala` shows how to add the compiler plugin (needs a resolver and `addCompilerPlugin`). The example uses a macro annotation `@hello` which can map the annotated tree to another tree. Here it adds a synthetic `hello` method: @hello object Test extends App { println(this.hello) }
This isn't sandboxed very well, unless Kay Yan left a honeypot with his not-real sftp password in it.
Please open an issue on it, I'll send him a note as well, thanks!
Dropped a note on the forum. I'd be interested in seeing how they'll fix it. I can see how someone could compromise the forum pretty easily. A shame too, because the site is really cool - hope it sticks around.
Looks all blurry for me.
As long as the password is no longer used for anything else, you will be fine. .gitignore to the rescue. I've sent an email to your gmail account with additional details and a potential solution. 
Would you please tell me which broswer/OS used. And which Resolution of the screen. I would fix it.
But why does it need a host JVM? Is it simply incomplete?
I would conjecture that interpreting bytecodes is a lot easier than compiling them to native code for some platform.
Updated link: http://scalatutorials.com/tour/
Well, it could be statically compiled with GCJ. That would not require another JVM.
Came in to make this comment, glad someone beat me to it.
Hey sure. Here's a picture for reference: http://i.imgur.com/zxh394B.png It just doesn't look "sharp" to me. The buttons (Next) get kind of blurry too when I hover over them. What bothered me most was the code. Tried it in Firefox and it does definitely look better there. Anyway, as for the system: * Mac OSX 10.6.8 * Chrome 28.0.1500.95 * 1680x1050
Both the libraries and the languages (i.e. Scala). I don't expect to see any 3000 line JVM's written in C/Java any time soon.
yeah, and Validation integrates nicely with applicative functors by accumulating errors (look for "applicative builder" pattern)
I'm not sure what's supposed to work and what isn't. From the start, choosing 'next page' twice takes me to another view with 4 choices. Of those, 'basic' and practice have clickable buttons that zoom me in on those choices. If I click 'start' on either of those once zoomed in, I get taken to appropriate content. The 'concurrent' choice isn't clickable. The 'functional' choice zooms in like the others, but once zoomed, clicking 'start' doesn't do anything. FF 23 Ubuntu 12.04 LTS 1920x1080
I'm astonished just how differently programmers can end up seeing things! I genuinely feel scalaz is the *worst* thing about Scala, and would immediately veto its use for any project...
So the question is: does scalaz hinder readability due to unfamiliarity or does it hinder readability because of inconsistent APIs? The former is something you can work around, while the latter is unforgivable. The truth probably lies somewhere in the middle, but I've found it comes much closer to the latter as I've learned and read more code. It's developed by many different people, so there may be better/worse pieces. I've certainly not used the majority of it. 
I find the readability hit comes from operating at too high a level of abstraction -- as a consequence the names are unevocative, or worse, symbolic. For example, it's far easier to work out what "cartesianProduct" might do than &lt;|*|&gt;.
&gt;I find the readability hit comes from operating at too high a level of abstraction Operating at a higher abstraction should HELP readability! It's reducing code! Readability does not just apply to lines of code at a time, it can most definitely refer to aggregate lines of code. Abstractions help on this front. Is it harder to *think* about? Yes. For the same reason pointers trip up people (one of the most basic abstractions you encounter in programming), so do higher level abstractions such as the type classes (monad, applicative, etc.) Symbolic operators, eh, I'm kind of with you there. My main gripe with that is the difficulty in communication. 
Also worth mentioning is the GLL-combinators library https://github.com/djspiewak/gll-combinators which allows to use GLL parsing as easily as native scala parer-combinators.
The issus of start button is 'Functional' has been fixed.
&gt; Operating at a higher abstraction should HELP readability! Right, but it's trivially false that all abstractions always improve readability in every context. The question we always have to ask is, "does this abstraction do more do help or hinder readability"? And for me, scalaz abstractions are in the "hinder" camp. &gt; It's reducing code! The aim is readability, not code golf. I code a lot of Java, so believe me I am sympathetic to this impulse, but the reality is that sometimes conciseness helps, sometimes it hinders. &gt; Is it harder to think about? Yes. That's not a good quality, though. A good abstraction should make the code easier to think about and easier to reason about. 
Let's get concrete. Do you think higher kinded types hurt readability? They were certainly an unfamiliar way of thinking about code and I struggled with them for a while. However, the greatly improve readability for a *program*, while possibly hurting readability when talking about a single line at a time. Java is incredibly easy to reason about one line at a time. I've never thought "what does this line do" in java, while that happens regularly reading scala (and scalaz) code. However, Java **applications** are often difficult to reason about because the abstractions happen at a framework level rather than a type level. Instead of understanding function composition, (an abstraction), you have to understand an AOP *framework*. 
Looks awesome, thanks!
See also [PlayCLI](https://github.com/gre/playCLI), especially if you're already using Play! iteratees.
This is true.
Very useful library. Definitely going to be using this :)
&gt;&gt; In your position, your time is better spent learning Haskell. My comment on this, from my ca 1 month long experience in Haskell, where I coded some non-trivial algorithms and tried to dabble with "real world". For purely algorithmic problems, it's fantastic. I had no problem adapting to the way of thinking, as I have been experimenting with SML, Ocaml and LISP previously. However, as soon as I tried to coerce the language into "DO X" where X is not a pure computation, it got quickly ugly. (For example, trying to manually parse binary data [reinterpret_cast from C++], or using mutable Data.Vector.) I dislike Haskell's library documentation too. (as in, a lot of it is implicit, some is hard to find, and there's also stuff that people use but is not mentioned in the docs) It's a steep learning curve, and not only because the language in itself is different. I also struggled with casual/imprecise use of words, for example: - The difference between "value" and "action". After long discussion with people on #haskell, I came to the conclusion that there is no difference. You can think of an action as of a value+behavior where the behavior is added post-hoc by "interpreting" a one or more values in some special way. My problem is that the behavior is not intrinsic in the value, it comes to being only after being interpreted, and it can be implemented in multiple ways, so the distinction is not really clear, esp. since some values can also be used "uninterpreted" (e.g. for List). (Think of an "action" as a pointer to function in C: it's a value _until_ you "interpret" (execute) it. Rather bad analogy, but still.) - People tend to use the same word (for example, "functor") for three different concepts without any qualification. In particular, they use "functor" for any of the following three [capitals emphasize the concept]: 1) a Functor [it's how it's called] TYPE CLASS, 2) a TYPE (say, Maybe) that is an instance of Functor [the type class], 3) a VALUE of a type which belongs to the Functor type class (a value like, say, x :: Maybe Int). Mixing 1) and 2) isn't usually a problem, but, e.g., LYAH mixes 2) and 3) which made it way more difficult than necessary for me to understand it. Simple qualification (adding "value", "type", "class") would have made the text much more clearer [at least to me]. I found on the net Scala samples for the exact same problems I tried to do in Haskell, and the solution was way simpler, almost obvious. Sometimes the "cleanest" solution IS to do really do something dirty [or the problem is dirty in itself], and Scala gives you a simpler escape hatch than Haskell. Which is a double-edged sword, as many others have pointed out. On the upside, #haskell on freenode is a great place full of smart and helpful people. EDITS: minor clarifications and cleanups.
&gt; I find it hard to believe that anything useful could be learnt from Perl. Regular expressions. Functional abstraction (yes, lambda). Many flavors of OOP. At least.
Many other PLs have those and would be far better places to learn those concepts, bar reg-exes which I'm not convinced are a worthwhile language feature. What feature does Perl have that is best learnt in Perl, i.e. that would make Perl worth learning? 
&gt; What feature does Perl have that is best learnt in Perl, i.e. that would make Perl worth learning? This is a loaded question, IMO. Perl has hardly an original feature, and you can always claim that, for example, dynamic scoping (local construct in Perl) is better learned in Common Lisp, for example. Something I've seen only in Perl are typeglobs, which allow for direct symbol table manipulation and are used for many things, e.g., package mechanism.
Array types not being erased at runtime is a property of the JVM and has nothing to do with Scala. So if you use arrays with generic types, you'll have to keep information about that generic type at runtime, whether you write Java or Scala code. Scala allows to do this with manifests (formerly) and class-tags (from Scala 2.10 onwards). I don't even know if Java has any mechanism to do that (other than using reflection)? Then article goes on &gt; And then the quickSort method somehow does not work if invoked on a generic. I mean, some one blogged half a year ago about his or her problems getting something done. @logos01 what was your intention of posting this? To deliver this message &gt; Generics in Scala, while having a nice syntax, are just crazy. Sorry, this is utter none sense.
This is a bit weird. Why would you write your own SVD in C when you could use an existing one that was probably much better written? Did you check that the results are the same? How does the performance compare to properly optimized code like Intel's MKL? Can they be parallelized? 
parallelizing the svd and fairly comparing different implementations is nontrivial-- I think using single-threaded implementations makes sense for this type of benchmarking. It would have made sense for the author to pull some non-homebrew code for the c contender...
&gt;In Java one can just use Arrays.sort(points) if points is a T[]. And the method can work with a subclass of Point. Because Java made a mistake of making arrays covariant.
Labeling the 5 things as facts is really confusing. &gt;**Fact #3**. Another question is where is the reference to the locked object stored between the corresponding enter and exit calls. That's not a fact...
http://www.artima.com/insidejvm/ed2/threadsynch3.html (from co-author of Staircase book
I'm not saying that the article is wrong. I'm saying the sentence after the Fact #3 bullet isn't a fact. It's basically a question.
Do you have any better suggestion than the last comment on the blog? Instead of extending Ordered[Point], you can provide implicit Ordering of desired type in the companion object: object Point { implicit def pointOrdering[T &lt;: Point] = new Ordering[T] { def compare(t1: T, t2: T) { return math.signum(t1.value - t2.value).toInt } } } This should work. There is still a slight problem that a new ordering object will be created for every sort call, and I don't see a way to avoid it without a cast :(
Its a little hard to follow exactly what problem is trying to be solved but if you have this as your point class and you want it to be sorted. I ignore the isMiddle cause I don't understand what that is for now and simplify it a bit below case class Point(val value : Double) The following would sort it without even bothering with Ordering Array(Point(0.1), Point(0.01), Point(5), Point(2)).sortBy(_.value) To me this solution is far superior to any java solution and I don't even have to think about Generics. But it does properly return an Array[Point] which I believe is what the goal was.
Is this going to support redis sharding in the future?
The "for loop" suggests: &gt; There’s no direct equivalent to the low-level for loop; you would need to use while. Scala's equivalent is much better than this!: for (i &lt;- 0 until max) doStuff(i)
Also, for "Instance-of check", pattern matching reveals better options and potential: myvar match { case a: MyType =&gt; ... }
I guess he used `while` because of the equivalent performance. Is `Range.foreach` macro optimised to drop the closure allocation, yet?
+1. IntelliJ automatically suggests that when you do successive `isInstanceOf` and `asInstanceOf`, which happens typically in `equals` methods.
SBT project support? Edit: yes it is https://github.com/dcaoyuan/nbscala/wiki/SbtIntegrationInNetBeans
I really dislike this solution (Eiffel introduced it way back then, it was a mess too). Renaming classes on import is extremely confusing, I think that being forced to disambiguate by specifying the full package path is much clearer. 
It might be confusing if you are programming in a plain old text editor with minimum syntax highlighting but in case of my IDE, it just takes me a single click to find out what a particular class refers to. Plus since this is all statically typed, the changes of the confusion causing big issues is low. Though I agree having some sort of a visual cue for scope renamed classes would be nice.
Code is read in many more different tools than just IDE's: web browsers for code reviews or github repositories, command line shells, SourceTree/gitx/gitk/, email, diff tool, etc... Renaming classes on imports should be heavily discouraged, code is already hard enough to read as it is. 
I disagree. I think it naturally fits with the possibility to define _type aliases_ and the possibility to _import members_ of objects. Having looked over some sources, being able to abbreviate package names of often more than ten to twenty characters is a real breeze for readability. This is a really big eye pain in Java. You have to look up symbols in many cases, not just renaming. When I import `concurrent.stm.atomic` or `Swing.EmptyIcon`, and you find `atomic` or `EmptyIcon` in the body of the code, you will have to look it up, too. If you want to torture yourself by using NotePad instead of a proper IDE, well that's your business. In an example project of mine where around 110 files contain import statements, there are about 56 renamings, but they just affect around 10 to 20 individual symbols. The use cases: - "identity": for example I find `collection.immutable.{IndexedSeq =&gt; Vec}`. This makes it very short and readable, and by "identity" I mean that I can easily search for the use of this particular data structure across my sources. I could do a bulk renaming to change to another data structure. - shortening classes. `lucre.event.{DurableLike =&gt; DSys}` and `lucre.confluent.reactive.{ConfluentReactiveLike =&gt; KSys}`. Simple: DSys - durable system trait, KSys - confluent system trait. - shortening packages. `lucre.{event =&gt; evt}`. You'll see `evt.Node` a lot for example. Another good example is e.g. [this project](https://github.com/kenbot/ScalaSwingTreeWrapper/blob/master/src/main/scala/scala/swing/tree/Tree.scala): `js` = `javax.swing`, `jst` = `javax.swing.tree` - "scoping". e.g. I have multiple log methods. In a particular context I use `de.sciss.mellite.{logTimeline =&gt; log}`, so in that class I will write `log`. I can change the log method with one simple rename later if I want. Also specfiying implementation classes. `impl.{DocumentImpl =&gt; Impl}`. - name conflicts. E.g. `de.sciss.synth.proc.{ProcGroup =&gt; _ProcGroup, Artifact =&gt; _Artifact}` when I define `Element.ProcGroup` and `Element.Artifact` which have these as peers. Very useful. 
It only ever gets messy when you try to [cover arrays and strings](http://stackoverflow.com/questions/12204869/working-with-scala-collections-canbuildfrom-trouble/12216805#12216805).
I'm definitely going to be trying this out. Scala support is the reason I originally jumped ship from Netbeans to IntelliJ. Good to see Scala getting some Netbeans love!
The question is not whether it's possible to do sensible renamings but whether the people you work with find all these renamings that you do as sensible as you do. 
Are there any similar tutorial for Intelij Idea?
They could just as easily have used a fold; using mutability unnecessarily doesn't look very good in Scala.
[YouTube mirror](http://www.youtube.com/channel/UCVvLx6c90GSWVh_8-Ejdo2Q) (no slides, though)
At this point, I think an SSD should basically be a requirement at any workplace. They pay for themselves in no time at all in increased productivity. 
Remove duplicates and sort with this, assuming your equals and hash are well defined Set(Point(0.1), Point(0.1), Point(5), Point(2)).toArray.sortBy(_.value) I would say the conciseness of the Scala example alone is enough to make it superior to a large degree, but also the Scala line reads more like a sentence. 
Just watched "Scalaz: The Good Parts". While I like the type safe === and the validations, I don't fully understand the need for lenses. I also really don't get the obsession with operator overloading. The speaker complains about having to dig into documentation to get Hibernate to work because it is unintuitive, but splashing |@| or \\/ operators around in your code is perfectly fine. 
Yes using Array.sortWith solves the ugly casting (it's actually the first comment on the blog). But you still need the ClassTag because Arrays are invariant in Scala. And what if you really want to use a specific sorting algorithm (something else than the implementation of Array.sortWith), then you're back to the same issue of casting or implicit ordering.
Yes covariant Arrays are a bad idea. But have you ever encountered any bug or issue related to Arrays being covariant in Java in practice (not the usual silly example)? I have not. The Scala nicer invariant Arrays lead to worrying about invariance, covariance and ClassTags. Sorting on subclasses seems to be a relatively common question:http://stackoverflow.com/questions/12171138/elegant-way-to-sort-arrayb-for-a-subclass-b-a-when-a-extends-ordereda
Yes I agree that Scala in general is much easier to read (not so sure when it comes to ordering subclasses), also in the example, instantiating an implicit Ordering should not be an issue as many other objects are instantiated in that code.
There are 2 kind of issues raised on the blog: a) necessity of ClassTag because Arrays are invariant in Scala. It's nicer to have them invariant from a theoritical point of view, but then Scala developers need to know what Invariant/Covariant means and when to add a ClassTag. So they have to understand quite a bit more than Java developers. b) issue with Sorting.quickSort that requires an implicit ordering to work on subclasses. Obviously Array.sortWith is a work around, but then you lose control over the sorting algorithm. The implicit ordering is not really worse than a Java comparator. Yes it needs to be instantiated every method call, but many other objects are created there, so it should not be an issue. Still ordering does look quite a bit more convoluted than the Java equivalent.
The goal is to remove duplicates with a specific criteria (here there is a tolerance bound), so a Set would not work.
Been trying to look into delimited continuations recently, hopefully the macro stuff they're planning won't water them down. It seems like they're a rare feature.
My point was that you shouldn't code it exactly how you would code it in Java. While coding Scala like its Java works fine in some cases there are others where trying to code that way will give you a major headache. I let myself get a bit off topic trying to show exactly how to solve it.
I disagree. Those two examples are in my opinion misuses of the for loop and would be more readable and better performing as while loops given the option of post-loop testing.
This is really nice. I personally can't stand using XML as a configuration language. I think it's an anti-pattern where the actual data is overwhelmed by XML tags and all sorts of stupid rules based on the name of tag. 
I spent a significant bit of time implementing `IndexedContsT` for Scalaz 7, which should be a more than adequate replacement for the continutations plugin. Except for where speed is a concern, probably. :(
The equvalent of the second loop is rather common in C. It's basically a for each loop. So how is this a misuse of for.
I've been working with Ian recently on Swarm, which is based entirely on the continuations plugin, and I agree with his argument to keep maintaining it. While I definitely feel that the raw delimited continuations feature has a steep learning curve for the average developer, it is more than possible to build a friendly API over it (which is what Swarm aims to do). I'm not convinced that it's as inherently bug-ridden as Jason seems to imply. That said, I'm not the one maintaining the plugin or dealing with the side effects of it's implementation in other areas, so if there was a strong reason to deprecate it, I could understand - Jason's reasons just don't seem adequate to me though. EDIT: I should note also, that the proposed solution does nothing to replace the portable continuations feature (being able to serialize thread state and transport over the wire to another machine for execution - essentially sending computations to the data they operate on). scala-async seems to be a purely future/promise driven library, which isn't really any different than the usual "fetch data from where it's stored and do stuff with it" approach.
This is fantastic! Thank you for making/posting such a great resource. I work in NLP and am constantly looking for / re-implementing all sorts of string measurements for features. Its really refreshing to see something that is (1) available through a maven repo for sbt/maven/etc. (2) very well designed, and (3) not insane (why do so many people insist on making their own custom strings or numeric or collections for their NLP/ML libraries!?) I rather like the approach used, where parameters for each measure are passed as implicit parameters. This avoids the huge verbosity introduced by most similar-ish libraries (though I'm not aware of anything that goes even close to this level of breadth). Thank you!
Thanks! please do :) 
Downvoter - appreciate your feedback, but will you please consider also commenting on which part you didn't like about it? Is it the post / the library / both? :) Thanks!
The talk covers Futures, Promises, and Try. The presenter is very nervous and seems inexperienced, but if you bear with her, it's a worthwhile talk. She sticks close to the code and covers the basic concepts at a meaningful level of detail. If you're tired of talks that take the standard inverted approach to technical topics -- "you'll get lost and feel dumb if I tackle the easy parts in concrete detail, so instead I'll make you feel smart by waving my hands about the really advanced parts" -- this is the opposite kind of talk. I've used Futures extensively but learned a couple of new things that will improve code I'm already writing. 
You can take a look at the [open issues](https://issues.scala-lang.org/sr/jira.issueviews:searchrequest-printable/temp/SearchRequest.html?jqlQuery=project+%3D+SI+AND+resolution+%3D+Unresolved+AND+component+%3D+Continuations+ORDER+BY+created+DESC%2C+priority+DESC&amp;tempMax=1000). My own experience playing with the plugin is that it certainly not as polished as the rest of the library. For instance I could get an error, but simply adding an intermediate val assignment make it go away... So when you get an issue, you have to ponder whether you are doing it wrong or the compiler plugin is doing it wrong or it is just not implemented or it is not possible. On top of that there is no documentation and no specification. It would be terrific if a bunch of people jump in and support it or provide a better alternative (like akka actors were better actors than the original Scala actors for instance). It does seem like a gigantic task though. 
How does performance compare to the likes of Jackson, GSON and Jerkson?
I wonder what `final def` in an `object` gives you? And vice versa, if making the `val`s final (e.g. `TileDim`) and the case classes (e.g. `Room`) would change anything? 
I removed the finals from the defs in object since you're right, they're already implicitly final, and I marked the case classes final, which gave a small speed boost.
I'm not sure what balance of performance versus readability/LOC you're looking for, but for what it's worth, I rewrote the code inside the time block using ParVector for the parallelism, and it was only 10% slower, with dead simple code not too different from what you'd write for a single-threaded implementation. 
Yeah, ParVector works really well for what it is and was the original implementation I had. That being said I think the LOC sacrifice I take with Futures is fine. I separated the actual bench code from the metric calculation code, and scala weighs in at 99 SLOC, which is the shortest of any of the programs in the bench. You can see the latest changes I made here: https://github.com/markehammons/Levgen-Parallel-Benchmarks That being said, I was thinking about making another version of the benchmark that was fully functional and made use of everything scala has to reduce code size.
See also [JSON4S](https://github.com/json4s/json4s) and its Jackson implementation.
Another wrapper for Jackson: https://github.com/wg/jacks and another json lib: http://rapture.io/jsonSupport
I think the basic problem is that multiple JVMs use too much RAM. I have one JVM for Eclipse and one for each sbt instance for each project (or multi-project) I'm working on. Too many! If all the JVMs weren't using so much RAM we'd have more free RAM for ramdisks to use for compiling.
&gt; I don't fully understand the need for lenses. You have to remember that scalaz started off as, and still mainly is, Haskell-style Scala (but without the ubiquitous lazy evaluation that Haskell has). So lenses are good to do convenient imperative-style updates, especially of nested structures, in functional programming. If you don't see the point of functional programming, then of course you wouldn't see the point of lenses. &gt; The speaker complains about having to dig into documentation to get Hibernate to work because it is unintuitive, but splashing |@| or \/ operators around in your code is perfectly fine. Operators are actually quite easy to remember, I find. Until you come back to the same code 6 months later...
Thanks!
How so? def x() = while(true) {} // x: ()Unit
Another important aspect of `Nothing` and bottom type is type variance. `Option` is a good example. sealed trait Option[+A] { // covariant, i.e. `A` is a return type def get: A } case class Some[A](get: A) extends Option[A] case object None extends Option[Nothing] { def get = throw new NoSuchElementException } def sqrt(d: Double): Option[Double] = if (d &gt;= 0) Some(math.sqrt(d)) else None val opt: Option[Double] = sqrt(-1) opt.get // exception Similarly `List`: sealed trait List[+A] { def head: A def tail: List[A] } case class Cons[A](head: A, tail: List[A]) extends List[A] case object Nil extends List[Nothing] { def head = throw new NoSuchElementException def tail = throw new NoSuchElementException } Cons(1, Nil).head // 1 Cons(1, Nil).tail.head // exception
 @tailrec def f(): Nothing = f()
&gt; @tailrec def f(): Nothing = f() Well, you can define that with any type: @tailrec def f(): Any = f() That is to say, the type system doesn't have a particular concept of infinite recursion.
Of course, because `Nothing` is a subtype is any type. Essentially, `Nothing` means 'not reached'.
&gt; Unit- Type of method that doesn’t return a value of anys sort. No. Unit is a type inhabited by a single value.
Wouldn't a Tree zipper (implemented in Scalaz as a TreeLoc) suffice for this problem? Here's a good explanation of Zippers implemented in Haskell(no need for actual Haskell knowledge): http://learnyouahaskell.com/zippers
The article had a goal of doing a tree traversal with O(1) storage, which `TreeLoc` does not do. `TreeLoc` maintains a separate list of parent nodes during the tree traversal, which I believe means O(d) storage. Of course, the article cheats its way around the O(1) storage requirement by storing the parent reference in the tree nodes themselves, so that's really not an improvement. One way or another, you have to store a reference to each node's parent *somewhere* in order to traverse the tree—as part of the node (article's solution), in a separate variable (`TreeLoc`), or implicitly in the stack (the article's "first take").
And 'sys.exit'. Basically anything that "diverges" Here's an informative blog post: http://james-iry.blogspot.com/2009/08/getting-to-bottom-of-nothing-at-all.html
To further elaborate: methods that never return normally are of type Nothing: scala&gt; def a = throw new RuntimeException a: Nothing 
I just tried this plugin today (still sbt 0.12): https://github.com/jrudolph/sbt-dependency-graph Add to `project/plugins.sbt`: addSbtPlugin("net.virtual-void" % "sbt-dependency-graph" % "0.7.4") And to `build.sbt`: net.virtualvoid.sbt.graph.Plugin.graphSettings Now run `sbt dependency-dot` and open the result with GraphViz. If I was shown that I get this with two lines in my build file, I would be immediately convinced of sbt :) Lots of great plugins out there. 
&gt; I just started wrrriting the code to read the file, and this is one of the beautiful things that I really like about Scala, is that there is no cerrremony to deal with. He's always uplifting!
Let the backwards compatibility issues begin
[**@clementd**](https://twitter.com/clementd): &gt;[2013-08-27 15:49:01 UTC](https://twitter.com/clementd/status/372385270038945792) &gt;I couldn't find a [#scalaz](https://twitter.com/search?q=%23scalaz)-7 scaladoc, so I've hosted one on [@clever_cloud](https://twitter.com/clever_cloud) [*scalaz-seven-doc.cleverapps.io*](http://scalaz-seven-doc.cleverapps.io/index.html) Enjoy! ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/1l6zpc%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://www.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
I have discovered this same phenomenon. It's one reason working with dynamic languages and like MongoDB is so simple. It's all dictionaries in and out of a database with no schema to maintain in code.
I very much enjoyed the original ProgFun class, and the topics here seem applicable to some ideas I've been working on, so this is a no brainer! For those interested here is the [HN discussion](https://news.ycombinator.com/item?id=6285149). 
Already signed up!
I did the original progfun course but it's been a while now and I haven't worked on any projects with scala. Any recommendations for books to get back up to speed before this starts? 
Signed up. Did the progfun course twice. The first time I mistook it for a Scala intro course and had to drop it because I could not keep up with it and work. The second time I completed it with distinction. Really looking forward to this course.
The course webpage recommends Scala for the Impatient (as a quick book to read). There's also very good documentation at scala-lang.org (I've always liked the "Tour of Scala" section: http://docs.scala-lang.org/tutorials/)
Note that the prerequisite course (Functional Programming in Scala) starts Sep 16 (https://www.coursera.org/course/progfun), so you can take it before Principles of Reactive Programming starts. Some other quick introductions to Scala that might help if you can't take the prerequisite course http://www.scala-tour.com http://learnxinyminutes.com/docs/scala http://scalatutorials.com/tour 
I had the great pleasure of meeting Mark at an evening event after ScalaDays in NYC this year. He's brilliant—doesn't see how sbt has ever worked as especially hard to grok, as far as I can tell—but he cares a lot about the feedback and making good on the "s" in "sbt." I wanna be like Mark when I grow up.
Same thing happened to me. I've already signed up to take the progfun course this September so hopefully I'm able to keep up with it this time around. 
This is awesome, thanks for the tip! I've also been looking for an alternative to Maven's 'dependency:tree'; anyone know if this exists?
There are far more C or PHP jobs. Learn those instead. As far as the future, aliens invaded the earth and if you see this message sent through time portal, you. must. run.
Join LinkedIn if you haven't already, and join the Scala Enthusiasts group, you will find there have been about 20 discussions on these topics in the past, all of them positive about Scala. Also this will help you find Scala jobs wherever you are in the world.
Imho, as a programmer or engineer you should just enjoy learning new technologies regardless of whether they make you more employable. * Scala is a plus, it shows you are interested in learning new ideas: functional programming &amp; advanced type systems. There are also scala related technologies you may want to look at: akka (actors), programming with futures/promises, reactive web apps, ... Scala is currently the 2nd language on the JVM and it is growing quickly but that doesn't mean all big companies are now looking to adopt scala, they still have a long way to go. Scala is typically used when java is a complete pain because java lacks efficient immutable types, type classes, pattern matching, high-level concurrency libraries and (for now) closures. I work on a compiler, we did a rewrite in scala, using type classes &amp; pattern matching made the code much more readable and adding features is now much easier. * Knowing C shows you know something about manual memory management, beyond that it doesn't offer much over java, unless you develop very specific skills like C in embedded environments or HW driver development. If you want to learn how to write a proper native application, C++11 is the only way I'm afraid. The language is huge and the learning curve is steep but the payoff is huge. Modern C++ gave me a new perspective on how efficient manual memory management can be achieved. * Learning PHP shows you can take a great deal of pain. I could go on...
Unfortunately in my area no employers I know of are willing to make the leap to Scala. Learning Scala has still helped me though, my java code is less mutable and I've done a lot better around concurrency and testability. Its also helped in using libraries like Guava to their full potential. I've even written a few non-production scripts and internal webapps very quickly in Scala for work. So they have started to see benefit in me learning it. You'll also be ahead of the curve when Java 8 releases with Lambdas.
We're hiring: http://careers.ocado.com/VacancyInformation.aspx?VId=19851
Is it really about the number of jobs available? How many jobs are you planning to have? Most programmers just have one at a time. If you're looking for a single job, it makes sense you'd want to optimize for quality and pay. On average, Scala developers earn greater pay and work at higher quality firms than Java developers. This is because there is a self-selection effect: developers who want to rest on their laurels won't take the effort to learn a new language, and unambitious firms won't take the time to implement new technologies. My employer is currently seeking scala developers and I can vouch that there is definitely a greater demand than supply in the LA area.
Learning PHP is such bad advice.
We would love to hire some more Scala developers. (Full disclosure, I work there) http://jobs.wibidata.com/ tl;dr Yes, it's a worthwhile language to learn. Yes, there are jobs.
Weren't you listening?! RUN!!!
Thank you waxzce and xuwei-k for the links. I was looking for this yesterday and couldn't find it.
From what I hear, companies are having a hard time hiring Scala programmers, which suggests that Scala will be an asset for you. However, it may depend on what kind of job you're looking for. Most of the people hiring Scala programmers are looking for senior-level people who are capable of independently architecting and implementing complex applications. I would guess that there are more Scala opportunities open to good senior-level developers who are willing to learn Scala than there are for programmers who already know Scala but aren't ready to work at that level yet. There's another thing to consider, though, which is that learning Scala is an excellent entree into a lot of meaty programming topics: functional programming idioms and style, distributed systems, actors, and so on. You can do all of those things in other languages, but Scala has a lot of excellent work in those areas that makes it relatively easy to get self-study projects up and running. Not only that, the libraries that make Scala fun for playing with distributed programming are the same libraries that are being used to implement systems in the real world, which will make you that much more marketable. If you aren't one of those senior-level developers yet but are working on becoming one, Scala is a good language to work in. 
It's not that bad, as long as it's not your first language, and you don't use it outside of work. 
It depends how much you're willing to move. The jobs are very geographically limited to places that I at least find highly undesirable to live in. (SF/NYC/Boston) 
If you are in the UK - jobs@niceactimize.com, state "Java/Scala developer" in the subject. they are finding very hard time finding good Scala developers. They are making Scala a strategic technology.
I'm not sure the banner is diverse enough for me ;) All jokes aside, I'm always interested in hearing why scala and how it helps over just Java. If you don't mind, could you elaborate on that? 
What does Maven's dependency:tree that this sbt plugin doesn't? `dependency-dot` is just the task to output to .DOT format, but you can also use `dependency-graph` and `dependency-tree` to get console print outs.
Might I suggest that those are highly desirable places to live, the main problem being the cost of housing (because, you know, many people want to live there)? Or think of it this way: Silicon Valley / SF has a large share of the Scala jobs, because so much of the US software industry is located there. Places with few programming shops are highly unlikely to have any Scala jobs, since Scala is still a niche language.
People consider different things desirable. I wouldn't live in SF if the housing was free. It's just something to consider.
You left off an option: Free monad, which I would use. Ignoring that, you would use Reader as a consolation. You would definitely not use implicit here and I have had to fix a lot of code that makes this mistake (which is usually later realised). I will have to explain why when I get a chance. Sorry, it's detailed.
The absolute numbers are sobering. The [trend](http://www.indeed.com/jobtrends?q=Scala%2Cjava&amp;l=&amp;relative=1) is pretty good. 
Do you have a link to specific Scala jobs? I've been burned in my previous job where they advertised Scala and I ended up writing Java. 
I have been using implicit parameter for Connection with a combination of scala-arm delimited continuations-style resource management and string interpolation and I have been happy with it. I mostly do small data processing and analysis with data coming from Oracle. It goes something like this (from memory, I don't have the code handy right now): implicit class SqlStringContext(val sc: StringContext) extends AnyVal { def sql[C](args: Any*)(implicit conn:Connection, requestedType: RequestedType[C]): PreparedStatement@cps[C] = { val statement = ??? // create a statement here from conn, sc and args managed(statement).reflect[requestedType.ARM] } } The requestedType implicit is to help return the right transformed type for the delimited continuations plugin. So I have been trying to do something non-trivial involving resource management with cps and string interpolation and I haven't seen any issue where I regretted my decision to pass the connection as an implicit. 
live music from the scala community (people available at the event) live music to the scala community (professional musicians from the area) Scalaoke! (karaoke for all attendants, with prices for best performances) book discussion group (not limited to programming): online proposal of titles and voting for the most 3 interesting books to discuss countries showoff: attendants can present videos and pictures of their country/region/city of origin to present interesting sites, customs, and any other curiosity. Share your culture and your passions, giving others some idea for future holidays.
Anything that encourages/forces shy guys such as myself to mix, mingle and talk. For instance: Divide people into random teams. Each ticket has one of n [where 3 &lt; n &lt;= |Attendands| / 5] colours. People with the same colour belong to the same team. Then let the teams find each other and have them solve a problem / mystery. Maybe a little programming / hacking task or something entirely different (find things in town / the crypt?). P.S. fuck I just saw that the tickets cost a small fortune (for a student). Seems to be common for Scala conferences. I guess I'll have to go to Ruby conferences instead. ;)
Nice one! Would be great to get music involved, maybe a choir as we're in a church?! Scalaoke - great name :-) Love the book discussion idea too. I think the last idea might work in some capacity as we're going to have people coming from all corners of the world. Thanks! 
Nice try Scala-programming musician
Neither. I'd make it a constructor argument of the class, or an abstract val in a trait. If I was currently writing code in an object, I might change it into a class. If I wanted to use it in multiple classes, I might use inheritance, or (occassionally) nested classes. This makes the "wiring" explicit. I am aware of the various dependency injection frameworks available for Scala but I'm not using any of them at the moment. Need to look into them again.
I like your idea.
Having been a Java programmer for 15 years, I have now successfully brought Scala to two different employers. So, Scala positions may be easier to get into than a web search would reveal.
Depending on how complex you want to go, why not just do something like this: def withDB[A](action : java.sql.Connection =&gt; A) : A = { //setup your db connection here.. action(sqlConnection); } 
I agree on the explicit wiring, but don't you mean that you'd make a connection *factory* an argument of your class? The advantage of having your functions take a connection as an argument, like you would using Reader, would be that you can reuse a connection across several function calls. 
The biggest win for using Scala instead of Java is it is fun to program. Once you've used Java for years you can solve problems over and over in the same way - it gets very tedious and boring. Solving problems in Scala gives you many more pathways to solve the same problem. People who enjoy what they are doing are generally more productive and produce better results. That's my experience.
The question is about doing lots of work with a connection. There is no mention of multiple connections, or multiple threads (which is the only situation in which I think you might need multiple connections).
That's actually a new perspective to this for me. Thanks!
Wasn't there a compiler switch that makes scalac actually emit warnings with these cross referencing of `val`s?
You should x-post to r/vim
That's generally something you'll discuss and negotiate throughout the interview process. If you get an offer, it's definitely important to stress that you very strongly prefer working on a team doing Scala. Our hiring process usually just takes engineers and tries to place them after the interviews. You should try and find someone to refer you though, it will help a lot and the process can be slightly different. A random referral from someone on Reddit will not help you much though :( 
I took a brief look, does this support finding implicits? Jump to definitions or overrides? Edit: I used Scala at work for a about half a year and maintain a sizable Scala codebase. These features are imo essential for maintaining scala; bit less for writing it. 
I'm finding that vim isn't really good for large (more than a couple of files) projects, even with plugins. Currently for my [news reader project](http://newsrdr.us/) I'm using [Scala IDE for Eclipse](http://scala-ide.org) and it's working pretty well. I have to start the development server by hand from inside sbt-debug but I have full debugging and auto-complete support. :) Plus, since I'm using Slick, the app will pretty much work transparently on my local machine (using H2) and on the production AWS instance(s) (using MySQL). 
I was going between Eclipse and IntelliJ, now Scala is mostly IntelliJ for me. Neither were great with debugging support, I'd frequently have to rewrite my code as to not confuse the debugger or profiler. In the time since my heavy Scala use, I've seen a few scala-plugin update so maybe that's better now.
Now that you mention it, Eclipse does have a bit of a hard time with Slick queries sometimes. Mainly, it seems to be stopping on possible exceptions thrown deep within the Slick library that don't affect the final result. As a result I pretty much never break/single-step on anything Slick related, only the output.
&gt; "TL;DR - use def all the time, and things just work." This is a terrible summary of the rest of the article. &gt; it is not obvious which blocks of code are running at construction and which later. I'm surprised that `final val secondsOfWaiting` referencing a `val longEnough` (notice the missing final) in the very first snippet of code didn't ring any bells. &gt; I don't want to think about this! This smells of "I can't bother myself to actually *learn* the language I'm using, so I'll adopt a dubious rule (making sure to spread it to the world) and get on." Maybe the author should quit programming instead? Because today's "this" will be replaced by "that" tomorrow, and inevitably another blog post with dubious advice will be written. 
Bells or not, fact is that you will most inevitably run into NPEs with trait mixins and vals. I am very experienced in Scala and I _do_ share the author's statement: "I don't want to think about this!". I don't. Really. This is one of the few annoying parts of Scala which totally violates any principle of least surprise. Obviously, "use def all the time" is not the right advise, because you might have side effects—best example: instantiate a GUI widget. You could say of course "use lazy val all the time", and indeed that's how my code looks for composing GUI widgets. But it is an issue that the language should automatically solve, it shouldn't allow me to run into NPEs.
What's your pain point for performance? Our benchmarks show it as being close to Jackson for parsing, and we process a lot of JSON at my company with it without it being an issue. If I have something to work with then I can attempt to resolve any performance concerns (I'm one of the core contributors).
dependency-tree is exactly what I've been looking for, thanks! I should RTFM :-)
Having tried to hire engineers at a Scala startup previously, advertising for a specific language is a good way to lose applications, especially for an esoteric language. I/Others look for excellent engineers regardless of language. If you need to pick up Scala for a job, you will learn the syntax in a few weeks, idiomatic Scala in a few months. Not a single engineer at the startup I worked at previously was a Scala programmer coming into the job. 
Anyone using this, and want to talk about it? Neither the release notes, nor the github page give me a good idea of what this is, or what it's like in practice.
This was demystifying. :) The [source code of StringContext](https://github.com/scala/scala/blob/560b3728f364f3523a2bad202d41881f719b9fad/src/library/scala/StringContext.scala) is also useful, as it shows the implementation of `s` and `raw`.
[Here](http://parleys.com/play/51c387cae4b0ed8770356869/chapter0/about) is a talk about lenses that uses Shapeless. I don't know if that's all there is to it or if there's more.
This almost feels like an assault on proponents of readable Scala.
Now try implementing a string interpolator with a macro. Muahahaha.
String interpolation is one of the scala 2.10 features I use the most. It's just so handy and much nicer to read and write than the old way of constructing dynamic strings.
I do believe string interpolation is a boost to readability in Scala. ```s"Hello $user, how are you this fine $day"``` is much easier to read than ```"Hello " + user + ", how are you this fine " + day```. It's also less error prone.
Kudos, I discussed with my manager on feasibility of introducing scala in development, he replied if clients wants it, then only we will use it. 
Long since superseded by [IsTraversableLike](http://www.scala-lang.org/api/current/index.html#scala.collection.generic.IsTraversableLike).
Yeah, quasiquotes make macros 50x more readable, and much easier to create.
I think so, but it looks like it's not something I can just skim, so I'll have to read it after work. It looks like it introduces a lot of new vocabulary, and I caught the phrase "familiar from scalaz" in it. It looks like it's written for someone already at least somewhat familiar with the concepts it implements. But I'm only familiar with a few of those concepts, and I was hoping for something for someone unfamiliar with these thing, that would tell me why I care. I certainly couldn't send that to someone who only knows Java, or C++, and except a positive reaction to either that library or to Scala.
Hey there, Thanks for the input. We're certainly conscious to have a programme that reflects all the industries that are using Scala. Especially the cool ones. Hopefully, this year's event will bring that. We're also going to have 3 tracks with a couple of talks on different languages tackling similar problems, unlike last year's. We've had some really interesting talks come through on the CfP and they will be announced very soon. As I mentioned in the post, I'm also keen to have different stuff during the breaks and before and after the event which will be fun for the community. Hopefully we can implement a few of those ideas on the feed and also a few of ours. Thanks again, Theo 
Well, the standard library is very good example of very advanced Scala code (don't delve inside, unless you consider yourself a Scala advanced user).
Scala is useless for the web, once you learn , there are no tutorials for web site development, they instead will direct you to shit frameworks like Play, these are only good for the Java professionals, No proper IDEs , and that SBT bullshit Scala lives in the shadows of Java, sick sick sick 
DZone dont respect freedom of speech, please Ban Dzone from Reddit.
Thank you for your valuable contribution.
the language game code snippets impress me.
Great question. Advanced library code is very different from application code and has a much higher learning curve for someone new to the codebase. I'd like to see examples of good application code as well as good library code. 
I like Finagle. Probably the best example of a scala lib at the moment is argonaut's JSON parsing lib. I have an XMPP library with some sample apps (sending a message) that IMO are pretty nice...
I would avoid Scala standard library code (especially the collections). It contains a lot of hacks and compromises that few would consider beautiful. The typelevel.org libraries (shapeless, spire, and scalaz) are considered "advanced" but they are functionally pure, very well written, and include many examples. 
&gt;language game code snippets What is that?
Aww, could the troll not figure out sbt? Such a loss.
search for debian language game.
Well, for loops are just a very thin layer of sugar on top flatMap/map/foreach/filter. Each layer/line of the for loop allocates it's closure once per iteration of it's enclosing loop. It just makes it easy to write clean looping code that also allocates insane amounts of these closures and runs an order of magnitude or two slower than the imperative version. Heavily nested for loops can be both clean, but also heavily obscure their run time performance implications. It kind of relates to their point on Performance, how using high level collection operations and straying from imperative style can easily obscure how it will perform. 
Any thing that helps you have safer and better code is good, certainly a nice addition to normal tests.
And this folks, is the reason why static typing is good! :)
I am curious why on earth you would want to add syntactic ambiguity to scala.
Much appreciated comment. Thanks.
Here's a presentation on Slick: http://www.parleys.com/play/51c2e20de4b0d38b54f46243/chapter0/about
Thanks for sharing. I'm always amazed at how Slick code doesn't remind me of SQL at all. I haven't used it myself, but I feel that it must be hard to really predict the generated query due to Slick's inherent syntactic impedance mismatch What I'm talking about is this: https://groups.google.com/d/msg/scalaquery/_1EYCh6j79Y/Gvuntd2DKjQJ Nonetheless, it's an interesting alternative approach...
The example given is the a for expression with a return in it, with the rationale that since the "return" happens in a foreach(), it is non-local and thus has weird/unpredictable results. In this document, they are giving the advice of using "return" for clarification of intent, enhancing of readability. That's an absolutely awful advice - personally I would say "*don't ever, ever use the return keyword in Scala, even if you think you need it*". Skipping over the unintended consequences that happen because "return" inside closures is non-local, it's also a regression in terms of readability because it represents a short-circuit (like a jump, a GOTO). For example, it obfuscates the invariants and the exit conditions that you have inside a while-loop or a function - the more complex the code is, the bigger the problem. &gt; *Each layer/line of the for loop allocates it's closure once per iteration of it's enclosing loop. It just makes it easy to write clean looping code that also allocates insane amounts of these closures and runs an order of magnitude or two slower than the imperative version* This is not really accurate and shouldn't represent the basis for one's programming style. Yes, it's easy to write code that's inefficient, but this happens in general - sometimes it matters, sometimes it doesn't matter, sometimes the algorithm itself has awful complexity - what's the point of writing an imperative while-loop as optimization, when you could have optimized an O(n^2) algorithm to an O(n), or simply avoided the costly operation altogether. Calling foreach(), filter(), map() and flatMap() does have a performance cost. In my experience however, it does not reach an "order of magnitude" (in general the slowdown is somewhere between 2x and 8x, depending on what you do and is most certainly not 10x or more, to qualify for one "order of magnitude"). Of course, it could be an order of magnitude, but the JVM is pretty smart about inlining call sites and about allocations of memory for short-term objects. That's why one shouldn't make optimizations decisions, unless it's based on actual profiling of the code in question. Sure, if you've got some hotspot that's discovered to be a problem, go ahead and write the most efficient while-loop that you can. But other than that, readability trumps all other considerations, as (skipping over the maintenance costs) it does help you to understand what's going on, empowering one to make better architectural decisions. Also, when speaking of the imperative style versus FP in regards to while-loops, personally I prefer tail-recursions. The compiler optimizes tail-recursions into plain loops, with the same performance characteristics. Some people find while-loops more readable than tail-recursions, however for me tail-recursions are more readable, because they allow you to keep working with immutability and for me immutable functions are more readable because it makes it easier to reason about its effects, its exit points, its invariants and so on.
Seems to be down currently.
I use spark... Its a good system, but still a tad rough around the edges...
Besides their terrible documentation, one other place to learn spray is at their user groups. https://groups.google.com/forum/m/#!forum/spray-user
Could you give some examples of those "rough edges"? I'm considering using it in production.
Thank you
Feel free to open an issue on the GitHub page if you need any help.
What is the output of these hardware languages? How does what is written in code eventually get printed on a circuit board, or am I totally misunderstanding ?
I'm going to give it a go. Been tinkering with haskell for awhile, but Scala should be easier to squeeze in at work (testing a Groovy app maybe?) and it'll be fun to see a different approach to functional programming.
From the webpage: Generates high-speed C++-based cycle-accurate software simulator Generates low-level Verilog designed to pass on to standard ASIC or FPGA tools
It's the 16th today and still isn't opened. Can anyone else confirm this?
I took the previous iteration and would recommend the course, given that it doesn't require that much time, compared to some other courses. It's less difficult than Programming Languages by UW, goes less in depth theory-wise, but might give more of hands-on tool knowledge of some pillars of functional programming. With the caveat that Scala code doesn't need to be purely functional. People subscribed to this subreddit might not gain much from the lectures, but some of the problems, together with the discussions that arise in the forums around them, might be worth it nonetheless. There are always people taking these courses that are actually overqualified. Thus, little competitions are put up as to whom has found the most efficient algorithm for something. As soon as this one ends, the first iteration of Odersky's follow-up course starts, btw.
&gt; given that it doesn't require that much time How many hours on average did it require for you? Also, I'm enrolled in Programming Languages too, while I'm not interested in Ruby or ML I am interested in most of the stuff on the curriculum. Would you say it focuses too much on those languages, because if it did I'd rather not waste time. Last question, how many hours on average did you spend on it?
It depended on the week, I think I spent as much as 10 hours on one (second to last I think, the assignment was very challenging, but very satisfying as well), but most would probably be around 4 to 6.
Did you also read everything the wiki suggests? 
Look for openings on job boards and start applying! Where are you located? Are you willing to relocate?
In the midwest. Yup willing to relocate to wherever pretty much. I know applying is a no-brainer, I just don't know how to best present myself or show that I'm worth hiring considering my competition is people with work experience and/or education in this field already.
1. Study the classics. Your lack of knowledge of computer science core topics will be a problem, but one you can overcome. https://en.wikipedia.org/wiki/Structure_and_interpretation_of_computer_programs and https://en.wikipedia.org/wiki/Introduction_to_Algorithms are two useful books to look at. 2. Get some formal education. You may find that your abilities have already surpassed what you can find in night school, but Coursera has a Scala class starting today https://www.coursera.org/course/progfun 3. Consider a vocational software engineering program like Dev Bootcamp or similar. We recently hired someone who went that route to change careers. 4. Drop back and make a clean break with the IT side. You'll need to find a job as a software engineer. You could spend decades trying to ease into development and it won't happen (or maybe it will, but it will be up to luck, not your action). 5. Familiarize yourself with software engineering best practices. Unit testing using JUnit and jMock. Continuous integration with Jenkins. Source control with Git. _Effective Java_ is good, but slightly dated. I love _Growing Object Oriented Software Guided by Tests_. 6. Find an open source project that you like and contribute to it.
Amazing. This is exactly what I was looking for. Thanks so much - this gives me a ton of actionable items to get me started.
Probably 5-10 hours. I watched the lectures on 1.5x speed, lurked in the forums quite a bit and did some related additional reading. As phill0 said, the second to last assignment took quite a bit longer than the other ones (the first ones being essentially a go-through for me), because of a common performance bug that the grading system checked for. That being said, there were also people who have been struggling with the understanding of functional set definition already (assignment 1 or 2, I think). So they had to spend quite a bit more time on thinking/ research. But it's definitely been worth the effort, then.
I started reading "Programming in Scala, 2nd Ed." and got to chapter 15 by the time the course was over. I have to say that the book was extremely helpful, especially the early parts. I haven't read anything else, other than skimming through API docs while doing the assignments.
Go to local meetups. I got a job through people I met [here](http://www.meetup.com/boston-scala/).
It's a lot easier to get a programming job and turn it into a Scala job, than it is to "get a Scala job". For instance, where I work we sell a large J2EE application, and for various reasons Scala is pretty much off the table at this point. However, there are other projects at the company where it doesn't matter what language is used, as long as it gets done. Small projects that only need one developer with a clear beginning and end are easy sells. 
1. Try to get your foot in the door as soon as possible. It's only going to get harder. 2. Write code. Every day, if possible. 3. Get involved with an open-source project. That will get you familiar with the difficulties of working with other people and their code. Using source control, conforming to coding standards, reading and understanding an existing codebase, these are all practical skills that will make employers more likely to take a risk on you. 3. Start filling in your academic background. I would say there's a lot of academic background you can ignore at first; go for analysis of algorithms first and operating systems second. Those classes contain a lot of information that will be valuable day-to-day in an entry-level job. Basic analysis of algorithms is a must; it's considered common sense to be able to pick between common data structures and simple algorithms. Operating systems doesn't just include OS mechanics; it also includes an introduction to reasoning about concurrent and distributed systems. There are lots of other essential subjects, but they're irrelevant to landing the kind of job you're looking for. 4. Do Odersky's Scala course that is starting today: https://www.coursera.org/course/progfun Master your tools! It's common these days to take kind of a half-assed approach to learning languages. People treat languages like cell phones: they grab one and start using it, assuming that it will teach them everything they need to know about it. If they get confused by something, they either blame the design or decide they should avoid that aspect of the language until later. That doesn't really cut it with any language, but especially not with Scala. (Languages today really are better designed and easier to learn than fifteen or twenty years ago, but Scala is not one of the easy ones, and even with the easy ones, the half-assed approach is not very efficient.) Never stop reading books. If you're done with *The Scala Programming Language*, try *Scala In Depth.* Get an operating systems textbook, read a chapter occasionally, and do the exercises. Put a higher priority on learning things well and proving it with hands-on work, and a lower priority on covering a lot of different subjects. In computing, you learn the same lessons over and over in different contexts. The context doesn't matter; the depth does. 
&gt; obviously one person won't know about all of these and some are for mixed environments like C/C++/java/scala or rails front end, scala/java backend I'd like to repeat and expand on your disclaimer, because I think that list could intimidate someone who is just starting out. Someone looking to get their foot in the door at a first job should not be worried about any of the following: * specific technologies that nobody cares about except the companies using them (unless you're targeting a particular local company) * specialized skills that programmers pick up as the need arises, which may be never * skills that are basic for IT/ops but which programmers may never need to know With that in mind, I pared down your list and added my own comments about what you might need to demonstrate in an interview. * git or other version control. Have some experience and be able to explain how you use the tool and why. Experience working with other people, such as on an open-source project, is a major plus. * comments, style guide. code conventions, javadoc/scaladoc. This is more a matter of convincing people that you play well with others and can communicate well. Opinions about the value and appropriate use of comments vary so wildly that the only thing people care about is whether you are willing to conform to the standards of whatever project you are working on. * know one of vim/emacs and one of IDEA/eclipse. This is an excellent suggestion. "Do you prefer coding in an IDE or a text editor?" is a common interview question. There's no right answer, but having enough experience to discuss the pros and cons of each (meaning you've done a significant amount of real programming in each) is kind of a litmus test of whether you're serious about this programming thing.^1 * unit/integration testing, scalatest, Specs2. If you've written good unit tests for a project and can discuss why you did or didn't think it was worth the effort and can explain under what circumstances you would or wouldn't write unit tests in the future, that's a 100% in my book. * design/code review sessions: drawing flows on whiteboards is an important skill. This is part of the bigger category of communication. Verbal and written communication skills are most important, but I agree that whiteboard skills are important, too.^2 * modular code libraries for reusability w/nice APIs. I.e., software design at all levels. People will sometimes give you a hypothetical problem and ask you to solve it. It may be *very* high level, or it may be a low-level coding problem. At high and low levels design is the same and different. Just get as much programming experience as you can, read design classics^3, and use ideas from what you've read to think about the design choices you have to make. As for the rest, I would only expect a young programmer to have experience with the things they have needed to have experience with. What interviewers really want to know is not what you know now but whether you are capable of learning what you need to know to solve the problems you're faced with. If you go head-down on a challenging programming project and do whatever it takes to solve it, then I don't really care whether the techniques and technologies you learned are relevant to my business^4. What matters to me is that if I hire you, you'll apply the same approach to my problems. 1. Some programmers can be forgiven for not knowing much about IDEs. Java-only programmers can be forgiven for not having experience with text editors, but nobody can be forgiven for being a Java-only programmer. 2. Sometimes an interviewer will interrupt you while you're speaking and specifically ask you to draw on the whiteboard. This is partly to make sure you aren't a gifted bullshitter and partly because people really want to see how well you whiteboard, whether you draw understandable diagrams and choose an appropriate level of detail. 3. This is a subjective topic, and you should find books that appeal to your particular mindset, but don't learn about software design from Java-focused books. Avoid *Design Patterns* for now. Nobody cares about it any more except Java and C++ programmers. I like *On Lisp* (if you're willing to actually learn Lisp,) Richard Gabriel's *Patterns of Software*, Rich Hickey's talk "Simple Made Easy," and, if you can find it ([hey! we're in luck](http://www.itu.dk/courses/SASU/F2010/files/Naur%20from%20Cockburn.pdf)), an absolutely spectacular essay by Peter Naur called "Programming as Theory Building." Architecture is a common metaphor for programming, and one of my favorite books in that regard is *How Buildings Learn: What Happens After They're Built.* 4. Well, honestly, I have to admit that the faster you can become productive, the better. It's a secondary consideration, though, only worthy of a footnote. 
I got my current Scala job through going to a Clojure meetup. After graduating, I attended dozens of different meetups and made sure to rope some of the attendees into going to nearby bars afterward. That's where are the real networking happens. Apart from learning the technical stuff as mentioned in this thread, you also have to learn how to be approachable and warm with people. They have to work with you and they understand that your voice can alter their culture. Don't just wear the face that you think they want to see; actually work on yourself and improve your own empathy. 
From a maintainability perspective, please don't. Keep it simple. Don't use meta programming or make *one massive function*. It might seem like a good idea now, and feel clever. But, its not. Especially to the guy that comes after you that has to pick up your code and do something more, or fix a bug.
Thanks! I am a scientist first and a software engineer as a distant second-- so I openly admit that some of my library design might be quite janky in places... I really want to make this library easy to read and maintain, but the math it implements is sort of complicated... The problem is that I am trying to model a system which has these recursive function semantics... The functions themselves are numeric, but look like f(g(x)+h(j(Y)) |-&gt; z(phi) etc... and the topology isn't known before an instance of the system is instantiated with its desired structure... We need to maintain order of operations, etc. So yes, this really does sort of need to maintain its structure... I would prefer to use Scala lambda-type comprehensions, but I am not quite familiar with the language enough to leverage them in the best way. How would you recommend assembling this system in a way which is easiest to reason about and maintain? The parameter objects are nominally huge JBLAS matrices FYI... With a bit of metadata perhaps... The benefit for using this system is that all the behavior of this complex mess of nested functions is that they can all be accessed via the methods for the outermost function... So in the actual use case, the interface is quite simple... 
&gt;They have to work with you and they understand that your voice can alter their culture. This is an amazing piece of advice. When I read it, I actually stopped and read it out loud again - it's true of any employer, any company, any group.
I see a lot of good advice to get *a* job but not really a Scala job, which is what you were really asking (I think). Unfortunately, I don't have any good news for you. I've been trying to get a Scala job for the past two years (I live in Silicon Valley) and I've come up completely empty. First of all, even the big companies that are allegedly heavy Scala users such as LinkedIn and Twitter don't list any specific Scala job positions. I interviewed with both and asked about Scala during the interviews and all I got is some hand waving saying that I might one day write some Scala but that they couldn't promise anything and they were mostly hiring for Java. Most of the interviewers hardly knew any Scala anyway. I also looked up start ups and mid sized companies but there is pretty much zero Scala jobs around here. I've given up on this for now, I'll take my chances with a Java company which I feel might be open to allowing some Scala down the road, but I don't have high hopes. The Scala job market is pretty much dead in the Silicon Valley. 
Thank you, my company is using spray and I just joined a few weeks ago. 
I'm not entirely sure what you're trying to model here exactly, but I'm sure you could make better use of traits to model the tree you're trying to implement. First are you familiar with the Option class? I believe your Container is attempting to encapsulate what this class does already. trait Node[T] { def value: Option[T] } trait Branch[T] { def children: Traversable[Node[T]] } case class Tree[T](root:T) extends Node[T] with Branch[T] { def value = root.value def children = root.children } object EmptyNode extends Node[T] { def value: Option[T] = None } case class FatParameter(value: Option[Value], children: Traversable[Node[Value]) extends Node[Value] with Branch[Value] case class SkinnyParameter(value: Option[Value]) extends Node[Value] This way you can use pattern matching while traversing the tree, ie: val tree = //Some new Tree with values def mapValues(node: Node[T]) { node match { case branch:Branch =&gt; branch.children.map(child =&gt; mapValues(child)) ++ branch.value case node:Node =&gt; node.value } } mapValues(tree) EDIT: Formmatting 
These look much like `IndexedLens`es from the Haskell `lens` library.
Why is this important. How does annotating my code with effect types help in any way?
Purity implies referential transparency. Makes it easier to reason about your code, test it, optimize it. You can read more about it here: http://en.wikipedia.org/wiki/Functional_programming#Pure_functions
is there anything like umds findbugs for scala?
Sweet. I was hoping to see more macro goodness, though…
So did they decide not to drop support for java 6? Or was that planned for 2.12?
Is it binary compatible with 2.11 or we back in the dependency hell ?
2.11 is a new major version compared to 2.10, so when you switch to 2.11, which is [not to be released before next year](https://issues.scala-lang.org/browse/SI#selectedTab=com.atlassian.jira.plugin.system.project%3Aroadmap-panel), you will have to link to libraries compiled against 2.11. I don't think to speak of "dependency hell" is fair. The transition between 2.9 and 2.10 was very smooth in my experience. These versions were practically source code compatible (I cannot remember having a single compilation error, apart from some deprecation warnings), so most projects released new binaries straight away.
If you either read and understand Structure and interpretation of computer programs, or take the Coursera course - just one of those - (I'd recommend the latter because it's actually about Scala), you will already be ahead of a lot of candidates.
DOE feel that this 'reactive' thing is just an annoying marketing stunt to describe something quite common?
This 'reactive' thing is getting ridiculous. Outside of being async/not blocking, and preferring message passing, there doesn't seem to be a meaningful message. There are almost no specifics given in any talks/lectures. I have a solid grip on Async, Akka, Event sourcing, Play etc. etc. but I still see no significant meaning/message to the "reactive" push, it just seems vapid and relatively empty, just spin. Hell, I initially felt relieved when I found out their was a Jonas Boner talk on Javazone about going reactive. I thought finally I might get some questions answered. http://vimeo.com/74553108 Outside of "use async message passing", there was almost zero content in the talk. There really is no substance to the "reactive" push. On reflection, this could be because I've already been drinking the koolaid for a few years, and I see it as the normal way of doing things :-/ 
&gt; A template trait for indexed sequences of type IndexedSeq[A] which optimizes the implementation of several methods under the assumption of fast random access. &gt; &gt; Indexed sequences support constant-time or near constant-time element access and length computation. They are defined in terms of abstract methods apply for indexing and length. &gt; &gt; Indexed sequences do not add any new methods to Seq, but promise efficient implementations of random access patterns. I think you are a bit naive in assuming that because a trait is called "optimized", every particular operation and your particular use case is optimized. It's always best to sketch out which functions your algorithm is going to call and then look for a collection that performs particularly well on these. I give you an example. The code as you posted it takes 72019ms on my machine. If I make the following modification, it takes 501ms: // Vector pretty good with head and tail var left = leftArr.toVector var right = rightArr.toVector If I make the following modification it takes 253ms: // List optimal wrt head and tail var left = leftArr.toList var right = rightArr.toList ! Now if I call `arr.sorted` on the original array, it takes 43ms. Wooop. Probably that's as good as you can get.
I was toying around with the standard lib. &gt; I think you are a bit naive in assuming that because a trait is called "optimized", every particular operation and your particular use case is optimized. I believe that if the trait is labeled "optimized", then it should provide only optimized operations. Unoptimal operations should not derive from such a trait. If `IndexedSeqOptimized` only overrode methods from `IndexedSeq` that it actually meant to optimize, then I should have seen `IndexedSeq.tail()` instead. Though we both missed the possibility that `tail()` within that context was the most optimized implementation that was available. I haven't seen the source of `Vector` so I don't know the internals of its `tail` method. But `tail` in Vector has a different inheritance chain. But it makes sense that `List` would provide the fastest tail access because it is a linked list internally. It doesn't have to generate a new collection and subtract the head in the process. It just pops the head off the chain. I will definitely switch to List, at least for mergeSort. And I will make sure to pay attention to each class' strengths and weaknesses. Thank you.
Here's the source of `SeqLike.sorted()`: def sorted[B &gt;: A](implicit ord: Ordering[B]): Repr = { val len = this.length val arr = new ArraySeq[A](len) var i = 0 for (x &lt;- this.seq) { arr(i) = x i += 1 } java.util.Arrays.sort(arr.array, ord.asInstanceOf[Ordering[Object]]) val b = newBuilder b.sizeHint(len) for (x &lt;- arr) b += x b.result() } As you can see, it delegates to the Java array sorting method, which internally uses a highly optimized Dual-Pivot Quicksort with MergeSort fallback.
Depends on jdk for sort impl
That's another 50% gain right there. I also used `Array.copy` to copy the remainder in after the `while` loop exists. (`leftHead` and `rightHead` are now the indexes, `pos` is the index in `result`.) if(leftHead &lt; left.length) Array.copy(left, leftHead, result, pos, left.length - leftHead) else if (rightHead &lt; right.length) Array.copy(right, rightHead, result, pos, right.length - rightHead) &gt; Now if I call arr.sorted on the original array, it takes 43ms. Wooop. Probably that's as good as you can get. I just implemented Merge Sort and it can do the job in 36ms for the same count. A marginal gain at that point but it's just so cool how fast it can get. I'm looking into SmoothSort next.
I was looking at OpenJDK-7 on GrepCode, which is the standard implementation. It's the same across all Java SE 7 installs and I believe Android as well.
I've been educating myself about it all, but I have an uphill climb ahead of me in convincing management to trust in competent people and solutions like this over overpriced "enterprise" solutions. With that perspective, I have an appreciation for what they're doing even if it did reek of "web 2.0", "synergistic", and "responsive" hype. I get where you're coming from, though.
As a heads up, the signature for AuthenticationFailedRejection has changed for the next release to take a HttpAuthenticator instead of a string. I have no idea why, but maybe someone can explain or I should ask on the group. 
The documentation really is hit or miss.
Yes but not jdk6 or before.
JDK6: &gt; The sorting algorithm is a tuned quicksort, adapted from Jon L. Bentley and M. Douglas McIlroy's "Engineering a Sort Function", Software-Practice and Experience, Vol. 23(11) P. 1249-1265 (November 1993). This algorithm offers n*log(n) performance on many data sets that cause other quicksorts to degrade to quadratic performance. Both implementations are focused on keeping average time-complexity when others tended towards worst-case. I can't say for certain, but I know Android's Java is based on JDK 6, so it likely has this implementation. 
I'd like to be more help, and I'm sure more people here would like to as well, but I can't make heads or tails of what you're actually describing. &gt; "tree" (a fair description, though I think of it more like recursion...) A tree is a data structure. Recursion is a strategy in program control flow. You can use recursion to walk, navigate,transform, process, or otherwise manipulate a tree. The example I posted is recursive, so I don't understand where the example above doesn't match up with your model. &gt; Based on neural nets Neural Networks are modeled using abstract data structures known as graphs, similar to trees, though more complicated. &gt;It attempts to implement a sort of recursive-composable function structure. So I can be like: F(x) = g(h(x) + j(x+k(x))) or something like that The example you gave is a composition of functions though, no recursion is present in this example. &gt;which is decided when the class is created by its companion object Companion objects don't create classes, but I don't think you're referring to Scala's companion objects here and instead suspect you may be using the wrong word here. &gt;The big idea is that a rats nest of functions (neccesarily complicated, because they might be attempting to model some data-generating process) should have the same methods as each of the sub-functions Methods are functions, functions that belong to classes, so this doesn't make any sense &gt;we will also need to "deal out"... so to speak... parameters after they go through optimization... By parameters do you actually mean return values? Parameters by definition are values that serve as input to a function. If you want to return multiple values in a function in scala(assuming this is what you meant by "deal out") you just return the values in a Tuple. def multiValueFunction(): (String, Int) = { val aString = "abc" val aNumber = 42 (aString,aNumber) } val (stringResult,numberResult) = multiValueFunction() println(stringResult) println(numberResult) I am also unaware of what optimization you're revering to. I hope you can better articulate your problem so that I can better help you, a composable neural network does sound interesting. 
I'm taking [the Coursera course](https://www.coursera.org/course/reactive) in November. I hope to find out from that.
Okay, like I said, I am a researcher first, and a hack software engineer: perhaps I can clear this up a bit... First: regarding neural nets being graphs. This is absolutely true, however, in this case, the "graph-like" behavior of the net has already been implemented using an efficient matrix approach. You are exactly right to note that this is a composition of functions problem. That is what we are talking about here: Each densely-connected NN represents a function which takes parameters and arguments. The parameters change infrequently and are the very-large objects which are complicating this situation somewhat. In its simplest form, a single-layer NN can be thought of as a function which has n arguments, m outputs and m * n parameters. It must also be capable of performing a backpropagation operation, and be capable of computing its gradient. (this gradient, again, is m*n in size). in general, you can think of the inputs and outputs as order m or n vectors... but the dimensionality must be preserved. The library I am building should allow the composition of complex subnet architectures... and I am thinking that a fairly clear way to do this is using compositions of functions. Again, in this case, by function, I actually mean neural net, which requires a big parameter matrix. The idea of recursion comes in when you consider that your outermost NN-like object is actually a composition of arbitrarily many similar functions, nested within that outer object. (I sometimes use functions and arguments interchangeably here, because the NN itself is an object (err... class instance) in my program, which takes its parameters from its constructor, and optionally mutates them through the set operation) The design pattern here is that we want to be able to handle the entire composition through the outer object... that is: We pass the input argument to the outer layer, which passes its own output to its children, or inner functions (depending on your viewpoint)... and recurses, possibly with inner branches or other complexities, until we hit the output. Using the outer object, we also want to be able to run backpropagation and optimization... (in this case, using SGD or LBFGS... but the actual optimization approach is sort of irrelephant here) All we need to do is get the outer object to cough up something which is a representation of all the parameters (not the same as arguments in my nomenclature) of all its children, and similarly, gradient objects which are pretty much the same. This shing and the gradient matrix get passed to LBFGS, for instance, and optimized, and passed back into the model structure for further use. When I say companion object, what I mean is: object NNComposition{ def apply(desired topology): NNComposition } class NNComposition{ ... } Since my initial post, I have scaled back a bit, and rather than going full-recursive, I am composing nets using a more conventional "layer-by-layer" comprehension, and allowing layers, then, to be composed arbitrarily... noting that NNLayer extends NN. Layers communicate with eachother using callbacks. I am far from in love with this design pattern, and am still actively considering alternatives. Presently, I am going full mutable, non-functional-strict by implementing full access and update methods for the parameter objects (which are different from arguments, and live inside the NN objects, as we discussed above). I would much rather use a more functional approach, but am having difficulty seeing one which doesn't use those obnoxious nested parameter "Containers" I mention in my first post... which are begging to break themselves by not maintaining actual mappings between parameter objects and the subnets they go with, but instead, relying on sequence order, and proper nesting. Thanks for the input so far, btw! 
I am a fan of Scala and the Play Framework but I have to say this reactive manifesto makes me very uncomfortable. Why should there be an effort to get people to commit to something not on technical merit but on ideology? 
Yes, you cannot nest jars, they need to be unpacked to appear in the classpath. Use a tool such as [sbt-assembly](https://github.com/sbt/sbt-assembly) to create a self-contained jar file. Are you building your project with sbt? Then adding this is straight forward. Create a file `project/plugins.sbt` with the following content: addSbtPlugin("com.eed3si9n" % "sbt-assembly" % "0.9.2") Then you can run `sbt assembly` and get the ready made jar in the `target` folder.
Yeah, I thought about it a bit more after I wrote my question, and I take your point: maybe it's enough to say "Here's the [Typesafe Activator](http://typesafe.com/platform/getstarted). It provides benefits X, Y, and Z. Enjoy!" The problem I see is that there _are_ politics around tech choices and that being emphatic matters in gaining mindshare. Still, that said, I totally get why "Sign here!" can come across like it's followed by "or else!" and that can be off-putting. Hopefully the Coursera course also does a better job of communicating the stack's value constructively.
No C++ on the chart? Not sure where this would lead Scala to, but I see it would alienate the typical enterprise users to move to the language.
Got a PDF version of it? 
You will not find 'typical enterprise users' at StrangeLoop...
No, sorry. :S I thought it was worth posting anyway, since it's cooking up a bit of a storm in the more FP-minded corner of the Scala community, which in turn is because the proposal mentioned in the slides looks like it might end up reducing Scala's expressive power. See https://twitter.com/odersky for details.
https://docs.google.com/presentation/d/1sPshSx9Jgng9vMNXR99fBfyzlAW2542ZpH_maWVX2Pw/edit
Here's one with c++, but these 2 axis charts have the curse of dimensionality. You're trying to smash all the rules about primitives, homogeneous and heterogeneous data structures and higher level constructs, subtyping, type classes, ML modules, onto 2 dimensions, and you're trying to generalize about all the bultin casts/coercions in C++ vs the mechanisms that control when they're applicable http://james-iry.blogspot.com/2010/05/types-la-chart.html The lisp area has shen, clojure core.typed, typed racket etc. So every datapoint needs an asterisk justifying why it's in that quadrant http://shenlanguage.org/ http://docs.racket-lang.org/ts-guide/ (Iry's blog has a lot of great posts about generalizing about type systems http://james-iry.blogspot.com/search/label/types
I agree. [Message the moderators](http://www.reddit.com/message/compose?to=%2Fr%2Fscala)
Cool. Also, a [new logo](http://www.scala-lang.org/resources/img/scala-logo-white.png) would come handy. If you need some help about what to link we could open a new post to discuss details.
this is a good FAQ: http://stackoverflow.com/tags/scala/info
Agreed, just could use some love. Hopefully jeresig got my message. Let's do a little fall cleaning, haha.
So what happens to variance, I didn't quite get that...? PaulP's twitter comment suggests to me that this will eliminate declaration site variance and there will only be use site variance? That would be rather odd and introduce a lot of noise on the use site, no? Like how would `Option[+A]`, `Some[+A]` and `None` look like? def foo(bar: Option[Int]) = () foo(None) How would this be all written?
This would be great. Have a look at /r/clojure and /r/haskell for some inspiration.
Phil Trelford!
"The 'extra' flag on synced folders is now 'mount_options'"
Does anyone know if the videos of these presentations will be published?
he sounds like an ass. and isn't sitting right.
&gt; Functional programming combines the flexibility and power of abstract mathematics with the intuitive clarity of abstract mathematics. I guess if I'm not seeing the joke here, then the joke is on me. 
I think you picked the wrong site to criticize xkcd :-) If you're not familiar with the comic, have another look sometime. The artist, Randall Munroe, is generally beloved of computer scientists. I recently did a [Coursera](https://www.coursera.org/) online course in [Algorithms](https://www.coursera.org/course/algs4partIcourse/algs4partI) presented by [Robert Sedgewick](http://en.wikipedia.org/wiki/Robert_Sedgewick_\(computer_scientist\)) and he peppered the lectures with xkcd comics to illustrate concepts like [Depth-First Search](http://xkcd.com/761/).
You don't actually need a functional language to do tail recursion, you know.
I want to get into FP, it seems hard to me, guess that's why I don't get the joke
It's not too late to sign up for this excellent course: [Functional Programming Principles in Scala](https://www.coursera.org/course/progfun). (You've missed the deadline for the first assignment, but that doesn't matter unless you really want a "certificate".) I use Scala, but I'm not very strong in functional programming; the course is a lot less scary than I thought it would be, and provides a very good foundation.
Thanks for the suggestion, I tried that one before, I made it for the first couple of assignments, the I barely could keep up, I would like to try it again. You use scala in your job? you use it more in a OOP way?
hes making fun of functional programming fantards, not functional programming itself.
i wish there was a way to get xkcd as a twitter feed or rss or SOMETHING so I could easily see the newest comic everyday. I always like to read them but I always forget.
As far as I can tell, the OOP in Scala seems amazing.
This is really cool.
A neat exercise, but wouldn't it have been more useful to do this for, say, any other language which doesn't run Java natively. 
*Shhhhh*
i wouldn't consider tail recursion to be a mathematical abstraction that are unfamiliar to programmers. For example this is a feature that people have wanted in java for a long time (including me), which is going to be added in java 8. 
I was more referring to the tooltip (quoted above). Unfortunately just adding tail recursion and lambdas won't make Java as convenient as Scala for functional programming. In my opinion checked exceptions are fundamentally incompatible with convenient functional programming, and I think that's why Scala dropped them. Also, Scala's collections library is much nicer for FP.
I'm just trying to understand the motivation for writing a Java-&gt;Scala converter when the major selling point of scala is to *not* have to do exactly that. It's clear a lot of work went into it, but I don't get why.
If you are a Java programmer learning Scala, I think this is valuable. Many questions on Stackoverflow, for example, concern how a specific snippet of Java code would be written in Scala. I think this helps in those occasions.
Strangeloop presentations are always slowly released throughout the year as editing is completed by the people at Infoq. If you happen to know an attendee, you might talk them into letting you watch the unedited versions that were made available to attendees only. 
Tail recursion is functional programming no matter the language.
http://www.cs.uwm.edu/~boyland/fool2012/papers/fool2012_submission_3.pdf
Scala and clojure are considered to be heavily adopted mainstream languages at strangeloop. 
This looks like a nice tool to help people learn Scala. I'd just hope that people don't think they can paste their entire apps in there and say *"hey presto! My app is in Scala!"*. Among the most compelling reasons to use Scala are its expressiveness and type system. Having code already expressed "the Java way" simply ported to Scala doesn't give you a lot of the benefit that you would normally get. Just as C ported to C++ wouldn't show off the benefits of C++/OO. As long as you're aware of, and cool with that, I think this is a very helpful tool, especially for Scala beginners!
I used to feel the same way, but I got really big into f# after working in c# for a long time and now I do almost everything in functional languages. My point being, when it clicks it's amazing 
I'm not saying Scala and Clojure are mainstream. I'm saying they're considered mainstream at Strangeloop. This is the type of conference that has multiple Julia, Erlang, MiniKanren, and Elm talks while featuring a single Java talk, zero C of any kind (C, C++, C#, Objective C), zero Python, zero Ruby, etc... Enterprise adoption is just about the last thing on the agenda of anyone at Strangeloop, and Odersky's presentation reflected that. 
I know Strange Loop quite well, given my interest in compiler design, you just happen to use a different meaning for _mainstream_ than I do. :)
How about a C to java compiler!
I use Scala in my personal software projects. (I write software as a hobby, mostly.) Yeah, I've been using it in an OO way, but trying to be idiomatically Scala-like where I can (not just using it as a "better Java"). I just found myself reaching for `var` a bit too readily, I've been trying to write more of my stuff to be immutable where possible. Recently I've taken the time to learn about [Akka actors](http://akka.io/), which looks very promising for writing user-interfaces in a decoupled way, and handling [web services](http://spray.io/) without having to do the "threading" myself.
It also has some nice representation of types and functions, e.g. try the following case class Person(name: String, age: Int, spouse: Option[Person] = None) Or this: def squared(x: Int) = x * x On the other hand, it seems to be strict top-down, e.g. the following doesn't work: lazy val p1 = Person("alpha", age = 44, spouse = Some(p2)) lazy val p2 = Person("beta" , age = 55, spouse = Some(p1)) 
For me, it would be if I had five or six really useful classes from an old Java project and I want to incorporate them seamlessly into my new Scala project without re-writing them by hand. Yes, I could just stick them in `src/main/java`, but then they'd be sitting there annoying me, possibly requiring `JavaConversions` to play nicely with the rest of my project. And sure, the auto-generated classes would need some tweaking and refactoring before they're properly Scala-like, but it'd be a very helpful first step.
There is [cucumber-jvm](https://github.com/cucumber/cucumber-jvm), which allows you to run cucumber features in a native JVM environment, even with scala Step Definitions. So there is a cucumber for native JVM languages, unlike what the article says.
There is scalatest which is like J-Unit. Nothing too fancy. It does what you expect and it works well. There is SCCT for coverage. But in my opinion SCCT doesn't seem to be that mature at the moment, so you could just use any other java coverage tool instead. I would recommend JaCoCo. If you run both, JaCoCo and SCCT on your project, the results will differ. JaCoCo seems to be more accurate and generates nicer looking reports. Then there is Scalastyle which is like Checkstyle for Java and warns you about trivial things like tabs instead of spaces, methods that are too long, classes that are too full, cyclomatic complexities that are too high and similar problems. It probably needs to be tweaked to your personal preference, but i find it very helpful to ensure code quality. I also run FindBugs on my scala classes. But the interpretation of the report is a bit tricky because it warns you about things that are totally OK. It needs to be tweaked with a ruleset of checks to be excluded because many of them report false positives. Particularily with case classes. Edit: spelling.
Clear? Um, no. That compile error isn't even *remotely* clear. Clear would be implementing `csv` as a macro that does this check and gives a meaningful error message if you get it wrong.
Yea that compiler error could be clearer. The type system error reporting could use some love. 
Step back for a moment do you find abstract mathematics at all intuitive? I did a quick poll, most people here do not think that abstract mathematics belongs in the category of things that are intuitive.
The type system error reporting is fine. It tells you what type your expression has, and what type it's supposed to have. That's not the problem. The problem is that this is a misuse of the type system. The correct approach would be to have a class representing the rows of the table (e.g. `case class MyRow(date: Date, ratio: Int)`) and some function somewhere that generates CSV from a sequence of them.
Ok, show us the code. I think you'll find it a lot harder to do this with a macro than you think.
Nonsense. Types express properties of programs and compilers verify them. That's exactly what's happening here. Other languages (eg. Agda, Idris) are able to do this somewhat more elegantly, but the Scala equivalent is nevertheless very useful.
How is this more useful than having a class for the rows?
I didn't say implementing such a macro would be easy. I said its errors would be clearer. Macros can produce any error message they want.
Seems interesting. Any thoughts of this vs infinidb + R?
heard about this through scalawags first.. gg daniel
I can't speak for Miles, but Sized is expressing size constraints in a type system. In doing so it's moving a class of errors from run time to compile time. One could also argue it's removing boiler plate, but in this specific case I don't find that part particularly interesting. Your MyRow class isn't expressing it's "arity" in a type, sure case classes have the "def productArity: Int" method, but that's only accessible at run time to determine size. So you can only check that your case class MyRow has the same quantity of fields as your headers (let's say a Seq[String], but the problem would still apply if you had a special case class for this) at run time. Part of this problem is due to case classes inheriting only from the Product trait (and not something more specific), but that's another discussion. Sized allows you to ensure your code generates lists of arbitrary sizes, in this case it allows you to express that two lists are of some arbitrary equal size, which is quite handy for things like CSVs, tables etc. 
The key idea here is that we have two (or more) values of a variable length type which we want to be constrained at compile time to be of equal length so that we have a rectangular result. Wrapping those values in another won't solve that problem, it just moves it somewhere else. It's not clear to me how "a class for the rows" might help (example code would be useful), but a class for the columns is illustrative: with a column type that contains a heading and a list of values for each of the rows we are guaranteed that there won't be a mismatch between the number of header columns and the number of value columns because these are no longer separate. But notice that the exact same problem has returned wrt the rows: we can no longer guarantee that each of the columns has the same number of rows ... unless we use the same techniques that are illustrated in the presentation.
In the absence of even a sketch of an implementation that's hard to say. I'm skeptical, because the type mismatch that is being reported is saying exactly the right thing in exactly the right places, albeit not as fluently as one might like. Any macro replacement for this would also need to produce type mismatches, and has no additional resources to change the form of those messages, so would not be able to improve on the status quo. I'd be happy to be proved wrong, because if there were any such mechanism I could almost certainly make good use of it. But I don't believe there is currently ... can you show me otherwise?
Haven't tried either but the main difference is that Precog is built to analyze schema-less data whereas infinidb is used for normalized/sql data. I guess we'll have some feedback soon now that it is open source.
@milessabin is it possible to add an @implicitNotFound ?
Unfortunately that won't help here, at least not directly. The type mismatch is ... a type mismatch.
@milessabin what if something like this existed: @typeMismatch( error: (found: TypeTree, required: TypeTree) =&gt; String ) required - found =&gt; Eq( Eq, Diff(N) )
IMPORTANT: It's under the Affero GPL which means, unlike with many open source projects, you can't deploy the Community Edition on a web-facing platform to external customers without either paying for it, or publishing all your source code. You would have to purchase a commercial license if you didn't want to publish all your source code. Also, don't use Reddit comments for legal advice. ;)
I'll have some of that :-)
This isn't quite true, if the APIs *TO* precog are non-AGPL, it means that you can't MODIFY the Precog code without releasing the changes/source. It does *not* mean your own application cannot use it without releasing your proprietary source. This is a smart move by Precog (or the new owners?), because it means someone like Google or Accenture (hah) etc. can't take their engine code and modify it releasing changes or buying a license. 
I think a macro-based DSL would provide a simpler notation in this particular case. It would allow to drop Lists, double colons and Nil, which would be much easier on the eyes. Also, in my opinion, current difficulties with implementing macros in Scala should not be indicative of the strength or weakness of the concept of macros.
Type mismatches are exactly what we want in this case, however.
Oh, sure ... and if dreams and wishes are allowed I'll help myself to full-spectrum dependent types ;-)
[It's been done, actually](http://nestedvm.ibex.org/). However, the converse would be far more impressive.
I meant converse as in Java to C
Isn't that just Javac + jvm?
I think that persistent key-value stores can be very useful. There are several implementation. Currently I tend to favor [Twitter Storehaus](https://github.com/twitter/storehaus). Your implementation seems good, but I don't think it is a good idea to add it to slick. Slick is here to ease database access and query from Scala, not to provide the ultimate persistence layer. I prefer it to be as simple as possible, and let other devs (like you) build higher level persistence libraries. 
JVM doesn't convert to C. It JIT compiles to machine code. It also requires several other mechanisms unrelated to the code to be present (e.g. garbage collector, class loader). You might need the garbage collector in a hypothetical Java-&gt;C converter though, because I don't think there's any possible way to reliably statically determine when an object is due to expire. Class loading however could and would be dispensed with.
I'm not sure I understand why you refer to that as boilerplate (or why dependent types are relevant in that regard). List is the ordinary Scala List type and Sized plays an analogous role. The choice of ::/Nil vs. variadic constructor form is more stylistic than anything else. shapless's Sized has supported variadic constructor form from the outset.
Thanks for the feedback. Storehaus looks interesting, but I'd like to see them do automatic schema generation or use something like scala-pickling so it isn't necessary. 
Looks interesting, but I would like to know the actual performance gain. I'm pretty sure it would be only for large amount for data... 
Well anytime you're looking to improve performance by reducing the number of allocations then the assumption is that you're talking about a hotspot in your code....
You're totally right, if I have time, I'll try to make some benchmarks, and see how it goes :-)
So after years of claiming that `null` was evil and that `Option` was the path to salvation, this sounds strangely like "Okay, maybe it's fine to give up `Option` when performances are important". Seriously? Talk about sending mixed messages. And also, this gem: &gt; Of course, this adds quite a bit boilerplate compared to simply returning an Option. But the performance gain might be worth it. "Might be worth it"? Did anyone bother actually profiling this before making it a feature of the language? 
Screenshots?
Thanks. The screenshots give me a better impression of what features to expect and what the workflow would look like (indeed exactly like GitHub it seems). And although it's Java it seems certainly easier to deploy than [GitLab](https://github.com/gitlabhq/gitlabhq/blob/6-1-stable/doc/install/installation.md).
"Might be worth it" is not "this feature might be worth it for Scala" it's it "might be worth it for your use case". This feature allows you to continue using extractors without having an additional object allocation. Profiling it would be akin to profiling the creation of objects over time. There's nothing terribly interesting about that. We know deductively the improvements gained from it (i.e. lower memory overhead, fewer garbage collections).
Ask your company if you can moonlight or even move to a developer role as a junior. 
This talk is loaded with useful things that you have probably never actively explored. Here are a few things I picked up (these are OS X shortcuts, they may be different on other platforms): - Cmd-Shift-A: search for short cuts! - Smart Completion (Ctrl-Shift-Space): allows you to fill in anonymous function parameters, e.g. in a `list.foldLeft(...)(&lt;csr&gt;)` position - Global Completion (Ctrl-Space twice): allows you to import members from objects, for example to enable implicit conversions on a type - Ctrl-Shift-P: show type of current item, very useful when chaining collection transformations - Ctrl-J: quick documentation; Cmd-Shift-I: quick declaration (shows implementation source code in a small popup window) - Cmd-Shift-P: show implicit parameters New actions in IDEA 13: Introduce new field, companion object, hashCode/canEquals/equals, rearrange class members (e.g. based on visibility) The third part gives an intro to going into the actual plugin source code, with a demo of implementing a new inspection feature. Roadmap: Drop Zinc in favor of their own dependency analysis. Better sbt integration. Support (presentation?) compiler plugins.
Looks great upon first glance! "The table typechecking currently uses runtime reflection..." Is that expected to improve? I am not sure where exactly this is used, but "runtime" is a red flag. Also, is the store eagerly read into memory, or is it all lazy? In other words, what is the memory overhead?
So this stores the values as blobs! How would indexing work? 
This plugin is the reason I started using IntelliJ. Very impressive work!
* hint 1: 'f(y) == x' *is* ***Boolean*** * hint 2: http://stackoverflow.com/questions/9556579/finding-an-item-that-matches-predicate-in-scala 
Summary: it 'filters' Set s to a new set containing those elements of the original set for which f(element) is also in the Set. I think.
I think your confusion may be - and it was mine at well for a while, is the definition of exists def exists(s: Set, p: Int =&gt; Boolean) says exists is a function that takes two parameters, a set and *a function that takes an int and returns a boolean*. It does not say exists is a function that takes two parameters, a set and an int and that exists returns a boolean. in the call, s is the set and (y: Int) =&gt; f(y) == x) is the second parameter, an function that takes an int and returns a boolean Side note: I believe this is a closure because it is closing over the value of x, but someone please correct me if I am wrong.
Since the *Set* type analysed in the course corresponds to a predicate function^[1], *map* takes a *Set* and creates a new one whose elements are the values obtained by mapping *f* over the original elements. This works exactly as explained by **lm42**, the new function returned by *map* takes a *x* and returns *true* only if in *s* there was an element *y* such that *x* is the "mapping" of *f* over *y* f(y) == x ^[1] a function whose value on a input x is *true* or *false* depending on whether *x* belongs to the set p.s. I suggest that such questions be made on the corresponding coursera forum, where the context of the question is better known and you can get more informed answers
It is a closure, but I believe it is closing over s and f in the exists function. x is an input to the anonymous function which is assigned to the map function (I believe the set class is defined in this way). I can't remember the context though.
Guys, this is a gross violation of the honor code for the progfun course. Map is the most difficult problem in that homework set and you just gave away the answer. Personally I don't really care, but this is a for-credit course at EPFL and you should really try to respect the wishes of the instructors (especially since they're doing this for free).
This would replace github if you were in a situation where you wanted to host your own repo's (perhaps on a server at work...) but still maintain a github look-and-feel. Personally I think github is so inexpensive and has done so much for OSS that I don't mind the minimal monthly expense, but to each their own.
:( oops, didn't know that. You're absolutely right, will be more careful next time. I should have taken the time to check this before answering.
Did you get any reply? Or is the only mod just another subreddit-hogger?
Basic stuff..
No, I didn't. I imagine John is pretty busy. He is the mod of tons of subreddits. I'll ping him on twitter and see if he responds.
I found that surprising, too, FWIW.
We use gitlab internally but getting that up and running is actually a PITA. Hopefully this improves and we can switch.
[There is a new part 2](http://www.drdobbs.com/mobile/developing-android-apps-with-scala-and-s/240162204)
good job, the new page looks nice!
Thanks! It is still a work in progress. Please feel free to share any links or items to add to the sidebar.
this usage already has a name, called pimp my library. http://stackoverflow.com/questions/1913591/understanding-why-pimp-my-library-was-defined-that-way-in-scala If you are versed in scala from a book such as programming in scala, you'd discover three uses of implicits. Implicit classes, implicit conversions, and implicit parameters. Your usage is implicit conversion to another class, aka typeclass, pimp my library. edit: You are also extending AnyVal which provides serious compile-time optimization at the cost of restraints on the class.
Nice changes, i would add some tutoriales and books: http://www.tutorialspoint.com/scala/index.htm http://twitter.github.io/scala_school/ http://www.artima.com/pins1ed/
No answer? Perhaps you should start one and invite other /r/Scala redditors
What do you like to do, what are good at? I'd say not all projects are equally adequate to be your training ground, and picking up something you would enjoy and could usefuly contribute too is an essential criteria.
Please do not use this name any more. While it was [introduced](http://www.artima.com/weblogs/viewpost.jsp?thread=179766) by Martin Odersky many years ago, it has been generally agreed that the wording is problematic and has some sexist connotation. I don't find the old discussion anymore, but [the term was removed from the library in the beginning of 2013](http://thread.gmane.org/gmane.comp.lang.scala.internals/15662). The pattern is referred to as **enrich-my-library**.
Well the first question is, where is a list of projects in Scala?
You can start from here: https://github.com/search/advanced Edit: or here: http://mvnrepository.com/artifact/org.scala-lang/scala-library/2.10.2
This one is nice and useful https://github.com/sksamuel/elastic4s 
Thanks for the links! I added them to the sidebar. Let me know if you have any others.
I'm looking for contributors to scalatutorials.com email me at info@scalatutorials.com for details... 
A bunch of people I work with say they don't like Scala. It's because they don't know Scala, and when they try to read Scala code written by our Scala programmers, they can't. Well, duh. They say, Scala "encourages unreadable code," and they roll their eyes when I say it IS readable code (most of it, anyway) for people who know Scala. The idea that learning a language and spending a few weeks writing code in it would materially affect your ability to read code in that language is apparently crazy talk. The idea that a language might be hard to follow until you get used to some new ideas, and that the factors that make a language worthwhile might be the same factors that make it incomprehensible to noobs, well, that's obviously bullshit rationalization, because COBOL and Visual Basic and C programmers grokked Java code the first time they laid eyes on it and embraced OOP right away with no complaints. Right? That's what happened, right? 
Well done Derek, glad to have access to these slides outside the meetup. 
I am looking for contributions to these small OS projects: [sclicks](https://github.com/julior/sclicks) and [qantu](https://github.com/julior/qantu)
I'm sorry. I deleted my comment.
Nice! Pretty core to using Scala in many frameworks.
I am having luck with https://github.com/etaty/rediscala , did you try that?
- departure: Scala Async sits on top of Futures/Promises to allow non-blocking await calls inside a future body (implemented using macros) - "reactive" extension means not only can a future complete successfully or due to failure, but a stream of multiple events can be observed. - the interface is basically a typed publish-subscribe, with some niceties like `flatMap` combinator - the new contribution is putting the former two together, i.e. transitioning from `async { }` to `rasync { }` within which you can have non-blocking awaits for events and not just plain old futures. - internally, the `Promise` type is complemented by a non blocking queue called `FlowPool` - can be thought of as a macro (as opposed to CPS) version of Scala.React minus the `Signal` type (events only) 
One of the main strength of scala is compatibility with legacy java code. You can already use every web server you need. Actually many other scala web frameworks are already based on netty. New solutions/frameworks were developed taking into account the new paradigms offered by the scala language, trying to leverage its best features and simplify development. What's wrong with this? The swing framework was part of the standard java distribution, so it got special treatment at the time to streamline desktop gui development a bit. But the scala team didn't develop any web framework itself, those were the product of external contributors enjoying the language. As a last note, I'd expect that you can find some library on public repositories (github, bitbucket...) with contributions to ease up development in scala for your favourite web framework.
I think this is useful for people first coming to Scala from Java, though of course you eventually have to learn to "think in Scala". It's a little disappointing how break and continue in loops is handled though; they just get converted to comments that say "break" or "continue". I can see why the transformations of the code to are more difficult in this case, but I think it still leaves the beginning scratching their head.
The ADT link is wrong; it (in the relevant context) stands for Algebraic Data Type, not Abstract Data Type.
Thanks for sharing. I had the same problem a few days ago. What was really frustrating though, was that the two best examples I could find were either: * [Oversimplified](http://www.playframework.com/documentation/2.0.4/ScalaWebSockets): Doesn't really show you how to solve a problem with websockets that can't be solved with regular HTTP requests. -or- * [Too complicated](https://github.com/playframework/playframework/blob/master/samples/scala/websocket-chat/app/models/ChatRoom.scala): Hiding the essential parts inside a 144 LOC pub-sub system isn't really pedagogical. Your code is really the perfect example, that I wish I had last week. :) It would be cool if someone would update the official docs... I guess [this is the file](https://github.com/playframework/playframework/blob/9206bea8c9c88acdc6786ebb2554f081396e8f6a/documentation/manual/scalaGuide/main/async/ScalaWebSockets.md) that would need to be changed.
thanks! i'll submit a pull-request. I'm still trying to figure out how to unit test/functional test (i'll settle for any kind of automated test) this example without the aide of a html template printing out the message to the screen. Have you by any chance been able to test a websocket used this way?
Sorry if you came from a non-Java language and thought you would never have to get your hands dirty with Java. It isn't true and you should get over yourself.
I can tell you the exact situation which motivated this (at least, it pushed me to actually implement it) though there are many other applications. There are also commit messages, comments, and test cases. **case class TypeRef(pre: Type, sym: Symbol, args: List[Type])** The compiler allocates a metric bazillion of these. In approximately half of them, pre = NoPrefix. In approximately half of them, args = Nil. That means we're wasting a crazy number of fields on constant data. So we want to find a way to let those TypeRefs for which one or both of those fields are the common values not to pay for the field. Except to do that, TypeRef has to become an extractor, so pre/sym/args can be constant defs in some TypeRef subclasses and fields where necessary. When I implemented that, I found that although it reclaimed a ton of memory, performance was even worse. The reason: all those Somes being allocated during pattern matching. The change to TypeRef to take advantage of fast extractors isn't checked in yet because the policy is for the compiler not to depend on features which aren't in a release: so it can't go in until 2.11 is out.
&gt; Perhaps the intention is to support specialized Option classes that use the value space of the underlying type to represent the None state? Yes, this is among the uses. https://github.com/scala/scala/commit/8f05647ca5
You should see him live - he's a force of nature.
&gt; Do you even know who you're talkin' to?
This reminds me of Rich Hickey's quote [paraphrased]: "I can't read German, that doesn't make it unreadable."
&gt;and is interested in owning equity in an early stage startup. Yeah good luck with that
Sounds like you're looking for a cofounder, not an employee.
Sounds interesting,Please get in touch. Email: kapoor@capecode.in
really really love it, would just need(scala.Js) some tiny lib to give nice access to all the web stuff
booooo to the Lift sheeple
I had read that scala-js required a 19mb lib. I don't see it being loaded in the sample games. Was that article just wrong? I am way more interested now if its not the case.
Through the same interface as javascript does, as of now. There aren't any fancy scala-js ways of doing it
That was correct. What has changed is that the google closure compiler now works with scala-js, and in this case shrinks the normally 40mb standard library down to ~700kb with dead code elimination, renaming and other things.
That's awesome! Thanks for your examples, I'm totally fascinated.
Ah.. was hoping there'd be a close-to 1:1 between web workers and scala actors. That might get pretty hairy, though, as most browsers don't support workers spawning workers.
Why do we want/need inheritance at all for 'late bind' Design by Contract type stuff? 
It seems like this is just the simplest parts of Scalaz (`Eq`, `Validation`, `NonEmptyList`, etc.) plus BDD-esqe syntax. Not a positive for me.
Great idea! If that someone were to put Rod Johnson on a separate channel entirely so you could... 'adjust' his volume independently, that'd be great.
Do you even know who you're &gt; quoting?
Hmm. I wonder how the code merge is going to work. * What about spray json vs play framework json? * How are the spray packages going to get renamed? eg spray.client to akka.http.client ? spray.can to akka.http.can? * What's the timeline on the full merge?
I know who *I'm* quoting, although obviously /u/campbellm might be referring to someone or something else entirely. I'm not sure what your question is, unless it was rhetorical (in which case, I couldn't tell, so...).
Eh, hm. I'm confused now. Originally, my question was rhetorical, but in all sincerity: who *were* you quoting?
[Meet the Scout](https://www.youtube.com/watch?v=geNMz0J9TEQ).
Well, I'd just argue the combination of higher order functions along with the ability to do implicit conversions completely negate the need for inheritance as a way to do DbC, and by doing so you can bypass a lot of the unneeded complexity inheritance brings along. Eventually you'll end up using implicit conversion to get around an implementation not being aware (in the project sense) of the interface it's ostensibly acting as, so might as well go that route from the beginning. 
Just wondering whether you got my email yet ? My sent folder does not shows it...
Thats a framework dear, created by humans.
then fuck off
but legacy means Java and only retards ever moved to a VM, so whats the use of having compatibility with RETARDS ?
yeap sick RETARDS sheeple moved to Java some time back ans now they will reap the benefits, thats not good for the specie.
Well, conceptually, that's what you're doing even *with* inheritance: subtype coercions are just implicit conversions implemented as `identity`. :)
There's no need to insult Java programmers. There's nothing retarded about programming in Java.
Mathias has responded to a couple of these questions: https://groups.google.com/d/msg/spray-user/IEVLn2ixAMQ/jSI5mA7VwFMJ
Lost me at 'M$'. How old is the author? 12?
&gt; We have committed to releasing RC1 before the scala.io conference next week, so expect something soon. They're moving fast on this. Which is good to not let us sit in limbo about it.
12 years old troll...
Holy run-on sentences, Batman.
Really, is library size such an important issue?
then why comment here, you are a loser
Yes. Modularization is important. If I want type safe equals, I don't want to import a whole universe. For the same reason, Scala 2.11 tries to factor out independent packages.
I guess it depends on your time scale. Anthropologists would call agriculture "recent." On the other hand... Mosaic released 1993 Gmail launched 2004 Present day 2013 ... I have a hard time thinking of "almost half of history ago" as "recent."
It was discovered years before 2004. I picked the public beta of Gmail because Gmail was the first application used by millions of people that was clearly an application running in the browser rather than just pages on a web site. 
In internet time the practice certainly isin't recent and really took off in 2001 with the release of the MSXML component in IE allowing for script controlled background HTTP processing. What is recent IMO is the new trend of what I would call heavy JS frameworks to facilitate the development of the concept. When we just had plain JS and MSXML you had a number of issues particularly around feature compatibility across browsers. This set of problems evolved into a set of somewhat-lightweight solutions known as AJAX frameworks (primarily designed around making your back-end code more compatible across differing browsers). While very capable they lacked the programming concepts many web developers are comfortable with (ie client -&gt; server). This lacking has created the rise of Node.js and other frameworks which take the concept up to another level of abstraction allowing a developer to treat local js development in a very similar way they would do client-server development. This can make things easier to work with, code becomes more portable between client and server along with other benefits. The downside being that you are pushing quite a lot of code onto the client and chances are your application only uses 10-30% of the capabilities of your chosen framework. This trend, in internet time, I would call "recent" though with JS based HTTP servers maturing it's quickly just becoming another old thing we have in our tool boxes. 
relatively, fully formed HTTP servers running in JS are newish. Pushing code onto the client to relieve servers and push away non critical functions has been going on for quite a long time. 
I haven't spent enough time using the current OOB netty enough to be able to compare but what does spray offer outside of being written in the Scala language?
Fuzzing is subclass of negative testing. It usually involves sending malformed or unexpected inputs at an interface (socket, file parser, etc). It's one of the techniques bad guys use to find buffer overruns and other exploitable defects in software. My favorite book on the subject is this one: http://www.amazon.com/Fuzzing-Brute-Force-Vulnerability-Discovery/dp/0321446119 
&gt; Scala is an excellent language for fuzzing and writing fuzzing platforms. Props to the Scala community for such a versatile tool. I wouldn't have been able to do this nearly as quickly or as well with other options. Why not? 
The R-Tree is a classical spatial (multi dimensional) data structure. Like many classical structures, it was defined (1984) in terms of mutable cells. The article gives a brief introduction to how queries and updates in an R-Tree work, and how an existing mutable implementation (Java) can be taken and be made into an immutable structure (Scala), using the path-copying technique. It doesn't contain specific benchmarks or such, but from my understanding it should incur a quasi-linear overhead factor due to keeping the children at the various tree levels in instances of `Vector`. The code is published as open source.
with world moving to low powered Android devices and other smart phones, how do you think that will affect the future JS developments ?
for many years, these former Java Programmers had no problems with Scala not being able to do proper debugging in Eclipse , thats so low class from a C# programmers point of view. And when we mention it they point us to intelliJ, thats so stupid, these guys dont understand complete STACK.
The use case for this library is not apparent from the short description provided on github. Anyone using this for real work? What use case is this solving for you?
If I were to write .Net-code for any Android platform, I'd simply use [Xamarin](http://xamarin.com/). It worked great for me when I used it for iOS-development, and using it for Android is pretty much the same procedure. Not sure why you're trying to hate on .Net developers though.
Have you looked at the [Wiki](https://github.com/Netflix/RxJava/wiki)?
It doesn't strike as something promising enough performance to be taking up with something like [JH Labs Java Image Processing](http://www.jhlabs.com/ip/filters/), but perhaps we are underestimating the potential. At least it is an interesting and clean approach... [The GitHub repository](https://github.com/stephenjudkins/pureimage)
But why is it important at the level of ~ 8MB, right now? Are you writing an embedded system?
This is cool, have been looking for something similar and hit similar obstacles. 
It's an aesthetic question maybe. Also a perceived dependency. If I want a core functionality A, I prefer to depend on something that implements A + x, where x should be comparably small. Also a small module tells me that the functionality is not entangled with many other things. It becomes an exchangeable part. You know, think of the Unix shell philosophy.
&gt; expressiveness always comes at the cost of performance Not true for all languages, look for example at http://www.antigrain.com And using trait for pixel representation is very inefficient, especially when you have to process millions of pixels. C++ allows to abstract over pixel format and not to lose efficiency, far superior than Scala/Java for images processing.
Well, I guess using for example macros we can arrive at some very efficient representations for digital audio or digital image in Scala which are still expressive.
No video available yet as far as I'm aware.
I'm trying to work out how to get this kind of example working with JsonNode objects. Basically I need to take the input JsonNode from the websocket and manipulate it then return it back (or a new modified copy obviously). When I (obviously naively) replaced [String] with [JsonNode] it refused to work with errors that I didn't understand. Is there an easy way to do what I want? The reactive-stocks example (using a java front controller rather than scala one) works fine but I couldn't work out how to port it to scala. The second issue I have with "scalafying" that controller was that the template no longer rendered due to the lack of a http context. I've seen mention of adding implicit keywords and so forth to the template itself or the controller but I couldn't get anything to work. Could you point me to somewhere that has an example of what your code does that can use the route.application.wstest.webSocketUrl() call in the template? Sorry to be a nuisance :)
I've been using Scala for a few years, as the best practical language for my uses. It has a great community, tools, and of course Typesafe and Odersky to keep things moving. But the design of the language seems more academic than practical; a proof-by-construction that OOP and FP can coexist. But practically speaking, OOP was just a bad idea, a massive misstep in computer language design and engineering which is gradually being corrected. And it seems to have significantly complicated the language. I wish Odersky had put his considerable energies behind something purely functional.
LOL, what are you ? Why will anyone get that machine for dotNet platform ?
thanks "Visual Studio integration" wow, clearly veteran dotNet guys are super smart, i mean those who created this. "Native UI, Native Performance" is that Dalvik bytecode or the Linux underneath the Android ? 
I'd love to see the video for this. He seems angry but I can't tell what he's driving at from the slides alone. It sounds almost like he's becoming a Clojure convert.
Lets hope such posts are taken in good light and are used to FIX SCALA and make it right.
the problem is tools and lack of stepping in debugging, highly scalable reusable code need proper IDE integration. OOP is the reason many of us go to Scala, or else you can use "go or clojure"
There was a point where I was totally convinced Clojure was his next destination. The entire talk in fact just kept making me think about Common Lisp lol.
The only way to design a better Scala is to jump off the JVM sandbox and build a brand new cross-platform virtual machine from scratch. This is extremely complicated and I'm sure only a very large community with a strong commercial support can fulfill the goal. Google could have done this, but they, like Odersky, have chosen the JVM-way instead. So, Paul's new project, whatever it is, seems more like utopia.
Just wait a month or so for a new version of IntelliJ Scala plugin which promises a proper implementation of debugging Scala closures with correct variable resolution.
I look forward to this
The main pain point with `@specialized` for me was that it basically failed to work all the time, for example when you use nested classes and so forth, so you needed to design your API around the idea that it works correctly with `@specialized`. Are these problems shared with Mini-Boxing? My second question is, I know this is now in experimental state, but is there a plan that it will replace—eventually—the (from my perspective totally broken) specialization that is currently in place? Thanks for your work!
I very much doubt that. I haven't seen the talk, just the slides, but he has been talking about similar topics before. I can make out two things, one he doesn't like to compromise for seamless Java interop; second he has issues with the compiler design. There seems to be some cheering from the advocates of statically typed functional programming, so if he will ever be involved in compiler programming again, my guess is it will be anything but a dynamically typed language.
Indeed, one might agree with some of pain points he makes out, but from a pragmatic point of view the Java interfacing of Scala is done right. Perhaps in five or ten years, the ecosystem is such that we do not rely any more on a large amount of mature Java libraries, but right now we do, so making it straight forward to embed those libraries is essential. I understand that it can be very frustrating from a compiler programmer's point of view to deal with all the corner cases, but from a user's perspective Scala has done much more right than wrong. I think he is just burned out, and so it's probably best both for him and for the evolution of the Scala compiler to make a break and let some new people take up this Herculean task. One thing that must be addressed no matter what opinion you have about how it's done right, is to modularise the compiler and give it a proper concept of how to handle mutable state. The fact that it cannot run multi-threaded is a core performance issue. If that is solved, both overall as well as incremental compilation times will go down, and perhaps one can even convince the people who recently wrote they don't think the Scala compiler is suitable for "live programming" (e.g. turning the AST representation in the compiler into a reactive flow model). I have a good feeling about this, as the language is basically "complete", it doesn't really lack any particular functionality; in my optimistic future we will see in the next couple of years a refactored scalac that will incorporate a new dependent type model ("dotty"), and probably part of that refactoring will be exactly rethinking the concurrency model of the compiler.
At the moment, yes, miniboxing also leaves nested classes untouched. But it doesn't have to be that way -- if you file a ticket with a suggestion on how to soundly optimize nested classes for your usecase, I can make sure miniboxing does it. Regarding the experimental status -- yes, it's experimental, and there are things that still don't work properly. But if miniboxing matures well and gets enough traction, I can file a pull request to scala/scala (note: I don't decide what goes into trunk, so I can't guarantee it will get in!). Then again, in the meantime fixes taken from miniboxing can be backported into specialization. (I already backported a few fixes and filed some common bugs) I think the development of miniboxing should be driven by community -- if people post usecases where specialization should be improved, I know what to focus on, and I'll do my best to address them (the entire idea of miniboxing was motivated by PaulP and Erik Osheim's comments that specialization creates too much bytecode). Also, since miniboxing is a plugin, it also allows faster experimentation, as it doesn't need to adhere to the rigors of scala/scala.
What for? There are already purely functional languages.
Really hoping this isn't going to be IntelliJ 13 only. Edit: Because I've paid for v12
Can anyone explain that example where the Long MaxValue - the Int MaxValue equals the Int Max Value? I have a very rudimentary understanding of Scala and I am just getting started. That part hurt my head.
`Long.MaxValue == 9223372036854775807L`. `9223372036854775807L.toFloat == 9.223372E18f`. `Long.MaxValue - Int.Value == 9223372034707292160L`. `9223372034707292160L.toFloat == 9.223372E18f`. It's part of the PaulP drama of whining around properties of the JVM. No reason to be worried, as far as I'm concerned. Basically you can complain that you can assign an `Int` or even a `Long` to a `Float` and that conversion is lossy. I'd say write your own type-safe numeric types if that is a problem, or use `BigInt`, `BigDecimal`... ----- Note that this is no different from Java: float f = Long.MAX_VALUE;
Yeah, but none of them have things like subtyping. [I'll link my only blog post for the third time so far](https://pthariensflame.wordpress.com/2013/07/07/introducing-spellcode/), because unfortunately I have no more to say on this subject yet (won't be long now, though, hopefully).
in that case just dont use OOP features of Scala
I'll try to work on an example of this later...at work right now...but for your first question (taking the jsonnode in), you should be using [JsValue] instead of [String] or [JsonNode]. The [JsValue] will have your json node passed from the fronted javascript. def indexWS = WebSocket.using[JsValue] { request =&gt; //Concurernt.broadcast returns (Enumerator, Concurrent.Channel) val (out,channel) = Concurrent.broadcast[JsValue] //log the message to stdout and send response back to client val in = Iteratee.foreach[JsValue] { msg =&gt; println(msg) //the channel will push to the Enumerator channel push("RESPONSE: " + msg) } (in,out) } something like that should work. For your second question, are you seeing an error actually saying 'missing context' or something else. Sound like you might need to import &gt;import scala.concurrent.ExecutionContext in your controller if your missing context. But if your async request is timing out, you may need to do something like this in your controller: &gt;implicit val timeout = Timeout(Duration(3,"seconds")) Hope this helps unblock you.
Well, good, that wasn't necessarily the intent of the slides or my post. :) I agree some context would be useful tough, I'll try to provide some in the form of the video if it becomes available.
I think you're right wrt the statically typed languages. One of his other pain points, if the Scala mailing lists are anything to go by, appears to be that his quest for soundness and DRYness in the compiler codebase was rather Herculean, not to mention lonely. Edit: typo
&gt;I understand that it can be very frustrating from a compiler programmer's point of view to deal with all the corner cases, but from a user's perspective Scala has done much more right than wrong. I think he is just burned out I couldn't have said it better myself. Much respect to Paul P, but I've noticed this pattern with him recently: Telling us things are held together with hideous duct tape, presenting slides with a grab bag of language warts, taking relatively cryptic jabs at Scala (in an attempt to look magnanimous? I don't know), and generally philosophizing about how *perfect* things could be. This may be a classic example of someone losing the forest for the trees. Yes, Scala has many bad corner cases but 9 times out of 10, from the user's perspective, I'd rather use it than the alternatives. None are perfect (maybe LISP :P). Scala made the decision to sacrifice its purity in order to introduce a whole new swath of people to amazing programming techniques. And if Scala stops existing tomorrow I'll still say "thank you" (to Paul P, Ordersky, and others) because, frankly, learning it and its libraries has made me an all-around, better programmer. And, like I said, yes, there are many warts. But it's been relatively easy for me to avoid them, and still reap the amazing benefits of the language. He's been in the weeds too long (doing an amazing job) and may have lost the end user's perspective. Or, perhaps, like you said, he's just burnt out. Most people probably would be.
The sources will be on Github, as soon as I have more than just promises and speculation to show for it. :) As for where it will run, it will run wherever you like! I intend for the compiler to have a sort of pluggable backend system, which, in combination with the eventual goal of self-hosting, would mean that any Spellcode programs *including the compiler itself* would be available for any platform for which a backend (possibly third-party) exists. I plan on using a native backend via [epic](http://hackage.haskell.org/package/epic) for initial development, but I seriously doubt a JVM backend would be that hard to write after the relevant APIs are solidified. JVM-specific optimizations are another matter entirely, though, so I don't know how (in)efficient it would be. :/
Haskell is my favorite purely functional language, and while it has its own substantial problems, I prefer it to Scala. However, IMO the tools and libraries aren't up to par with Scala's (maybe FPComplete will save the day here), and ultimately I need those tools and libraries to get things done. 
That's well and good, but part of the whole point of Scala was Java interoperability, which implies OOP. Without that, Scala would have the same problem.
&gt; Putting Scala in the Java-community has helped the language to grow as it has Except that [Scala has barely grown at all](http://www.indeed.com/jobtrends?q=java%2C+scala&amp;l=) and that [Groovy seems to be outpacing Scala significantly in growth](http://www.eweek.com/developer/groovy-programming-language-sees-major-boost-in-popularity.html). 
I'm looking forward to this already. The last one was awesome. 
&gt; I think he is just burned out I promise I'm not burned out.
&gt; Perhaps the video makes more sense than the slides do. There wasn't anything in the slides that would make me not want to use Scala anymore. Do these sentences have some connection which you forgot to identify? The overall effect is akin to "are you still beating your wife?"
&gt; scala has nothing resembling seamless java interop I think the main problem with your presentation is what I called "drama" in my other post. Don't get me wrong, I appreciate all the work you put into Scala, but I think you are a bit out your mind in terms of "whirling round". Let me cite this from your goodbye letter &gt; I'm taking this step because my precipitate is whirling round and round without any more lead turning into gold, and as all good alchemists know, that means a severe shaking (or stirring, I'm not picky like 007) is in order. I'm starting to find myself annoying, and knowing what high tolerance I have for myself, I must be in the red zone. But instead of alpaca farming, we get sausage factories, war stories, everything is wrong, etc. Hmmm....
I recommend you to wait for the next TIOBE surprise regarding Groovy :-D Other than just astro-turfing, Scala is producing novel research output that is turned into productivity. Houses stand longer when they are built on a solid foundation.
I don't know what "Hmmm...." is intended to imply, but there is no contradiction except in your imagination. Also, when you neglect the lines between the lines, don't be surprised when you're surprised.
&gt; The only way to design a better Scala is to jump off the JVM sandbox and build a brand new cross-platform virtual machine from scratch. I dream of being able to generate a reality distortion field one tenth this strong. I don't, really: I'd like people to believe things because they're true, not because they are helpless to resist the neural wave tech I imported from the year 2550. But I can see how it would be convenient. Scala is literally perfect - the best language which can possibly be implemented on the jvm. That's what you're telling us. We can take as a given the minor backpedaling you would have to perform in any sane response, and it doesn't change any important aspect of this claim. And it's the top-rated comment! The absence of imagination is hard to bear. 
I have no experience with typed clojure, but that is a thing which sounds like it might interest you.
If you don't include "java" in the search terms (and I'm not sure why you did in the first place), Scala is looking quite healthy. http://www.indeed.com/jobtrends?q=scala
What exactly do you mean by a "best possible language"? I personally believe that there exists no such thing. At some point when designing a programming language, you need to make one trade-off or another. And while it is often a very good idea to push the boundaries as much as possible such that you trade off less and less (possibly even none), there are many cases where you are forced to trade off something. And that is why a better Scala is not the same as the best possible language. A better Scala would have to make many of the same trade-offs as Scala for it to be a strictly better Scala, including being statically typed, having an advanced type system, supporting multiple inheritance through traits or similar, some form of interoperability with Java, etc. Could it make sense to make different trade-offs? I believe so, at least for certain cases. But it wouldn't be a strictly better Scala, more like a language evolved from Scala. I recall some slides from a presentation Odersky made some time ago in which a theoretical new type system for Scala, somewhat more constrained, was presented. Adopting those changes would yield a considerable number of advantages, but it would (as far as I understood it) also create greater limits on the things that could be expressed in the type system. Could those trade-offs make sense? Possibly, but it likely depends on the perspective and in regards to what. And issues such as backwards compatibility also complicates things. If you don't care about backwards compatibility, then that definitely helps simplify things. But that is not a perspective shared by everyone, breaking compatibility will cause pain and work for a significant number of people, and I think you may agree that, at least in some not fully foolish perspectives, the argument that backwards compatibility should not be broken lightly may have some merit. Of course, even if we restrict ourselves to creating a strictly better Scala, there is still considerable room for improvement. But that room for improvement is limited by a number of factors, including resources and the current platform. And while Scala is being improved according to the available resources, there are some issues that can be difficult or impossible to deal with well while staying on the JVM. And I think this is where the OP of this comment line is coming from. I personally think that, while Scala has gotten a lot of stuff right, it has also gotten some significant things wrong, things that will not be easily or ever fixed. Some is what you touch upon in the slides, other things include stuff like (IMO) XML-literals being baked into the language. I don't think that Scala having faults is a big problem, because Scala is both practically useful and a marked improvement in many important ways upon several earlier languages, such as (IMO) Java. Just like Scala is in many ways much better than its predecessor Java, I think there will be languages in the future that will in many ways be better than Scala. I do believe it will take a considerable while (guessing about the future is perilous, but likely somewhere between 5 to 30 years) before we see a language that is both a marked improvement over (future) Scala and which has gotten sufficient traction and support. And I believe that that language will take advantage of the new boundaries that Scala and other languages has helped push out, and likely push the boundaries even further itself.
I don't recall seeing you in the quite long 'JVM situation' thread a while back. https://groups.google.com/forum/#!msg/scala-functional/kvbaE6cAzqM/RC1nmc-HUtYJ It sounds like there's a lot you might be able to add to it, and I'm certainly curious on your thoughts. I want a language on the JVM, but I honestly don't understand the insanity we have to go through for 'almost seamless' java interop. I'd rather java interop be five times more difficult if it would make the language 5% more pleasant. There's already a ton of hoops I have to jump through to handle nulls etc. going from a java library to scala, so a few more hurdles don't bother me. 
Thanks again for helping me with the code in my other reply. For reference (I posted this on the gist page too) I had to slightly modify the chrome console test code by wrapping the ws.send line in a function: ws.onopen = function() { ws.send("This is a test"); } I hope this helps.
Cool. Ok that makes more sense. I was curious because outside the JVM munging arithmetic, especially casting between different types, might not come as much of a surprise.
&gt;The only way to design a better Scala is to jump off the JVM sandbox and build a brand new cross-platform virtual machine from scratch. I'm sorry, this comes off as ignorant rambling for the sake of noise. Why do you think this? What are the current problems with scala that are caused by the *JVM*? Do you think it's other flaws are not important, or that they would be fixed by a new VM? What is it this new VM would do?
TIOBE is not THE metric: http://pastebin.com/DVPWnN2Z And Scala is growing much more than Java as mattparlane already said.
Designing programming languages, and creating tools like compilers and libraries is a hard job with lots of trade-offs. Odersky himself points out some trade-offs in his book "Programming in Scala". I think he has found good trade-offs to make the life of JVM programmers better. Don't shy away from using Scala because of these complaints from a compiler developer. It may be truth in Paul Phillips words, but Scala is a good language to use anyway.
IT'S HIM!!!
Apparently you don't, as that's exactly how I characterized your imagination.
Then you could have easily removed that byte code generation in the last couple of years. By the way, I use the widening from `Int` to `Float` quite a lot and find it useful :-O
Java interop may be the selling point for many people, but for me, the point of Scala is that it is a well supported functional language.
&gt; Then you could have easily removed that byte code generation in the last couple of years. Your imagination continues to drive your end of the conversation, and I prefer real work, so I will leave you to it. If I could easily - or at all - have made such changes, I'd still be working on scala.
I'm still figuring out how to use Scala in Android. Their website mentioned an eclipse plugin for it, but nothing about IntelliJ.
I have a strong background in Java building SOA and scalable messaging systems (5+ years). I took the course on coursera for Scala (passed 98.5%) and I've really wanted to know what sort of experience I would need before I could migrate, how much am I expected to know vs how much I'd learn on the job. I've really done very little outside of the course. What sort of salaries are Scala jobs paying for those new to the language. 
*hangs head in shame* To be fair I did the same to myself, this was a side-side project, believing it would be a quick and easy port. Some time later I'm still not 100% happy with the code, but at least its in a state now where I do not feel embarrassed to share it :) 
Like more or less expensive than San Francisco/New York City? Do you live/work in London?
This "well supported" thing - do you not realise that e.g. Play and sbt are built on Java foundations (Netty and Ivy)? Yes, that is slowly changing, but...
What are you thinking for "non string based"? Just brainstorming, doesn't have to be completely attainable just yet.
Isn't IntelliJ 13 the big Android Studio release? Perhaps you should check this [post on scala-on-android](https://groups.google.com/forum/#!topic/scala-on-android/yc_bozVYJG8).
Used to, left because of the cost. IMHO the overall standard of living is not great. If you loose your job and have to fall back on the state or you become the next Google London is great - just don't be middle class.
It would enable tail call optimizations, hopefully.
Have you decided to contribute to an existing language or are you considering creating your own? I want to say this. Even if you turn the page on Scala and move on, the language and tools have become better, faster and more usable thanks to your numerous contributions. 
Where do you live now? Doesn't London also have bigger wages to compensate for flat rent? What about food and enterntainment prices? Are other cities significantly cheaper in uk?
What I can recall quickly... type erasure doesn't allow method overloading for parameterized types, weak support of different variance types, no native support for closures, unsafe design of arrays, no proper way to encode full type signatures in class files, core concept of null, no plain functions, etc...
IMHO the wages do not scale with the cost of living. Food is similar for supermarkets, slightly more expensive as many of the supermarkets have smaller versions with slightly higher prices. Entertainment - hard to compare as London has far more. You can for example go to arty-house cinemas for a similar cost to watching a crappy hollywood blockbuster in Leeds. I loved the cinemas in London. The big one is the cost of accommodation. It depends. Rents are detached from house prices, so if you plan to come for 2 years for the experience, do it and rent. If you plan to try and settle save yourself. London is the place where you come to get the opportunity to get the experience to leave! A great city but being killed by housing costs.
En anglais, s'il vous plaît?
This might sound like heresy, but the .NET platform has a lot going for it. I just wish there was a cross-platform VM with .NET's capabilities. Yes I know there is mono, but everyone hates it.
Neat! I'll use that. 
instead pitching for fixing Eclipse these guys cry for intelliJ
Thanks. I have quite a few 'smallish' projects that might be interesting for a general audience. When I find time to extend their READMEs and include API docs, I am going to post maybe more here.
I guess that explains peak hours on trains from suburbs. I've stayed for a week in Guildford in summer and found it strange, that those trains are so full.
nice collection....
Percent of what? If you look at [JVM languages](http://www.indeed.com/jobtrends?q=scala%2C+groovy%2C+clojure%2C+jruby%2C+jython&amp;l=), you'll see that Groovy and Scala have largest share. Taken, for each Scala job there are like 50 Java jobs. But take a look at the wages and the profile of the jobs. (BTW: Groovy, how much is there if you don't want to spend your day with Grails?)
I don't have anything extremely concrete, but showing data in line in the file would be a nice start, I think Ipython does some of this. Basically more visualizations and less focus on how the code is structured in terms of files and folders. There is not really a good reason to have functions in an object ordered in a particular way, it would be very nice to have it represented more as a graph and the functions as nodes hanging off. If it was displayed like this then when you pull up a function all of the surrounding unused space could be filled with functions or objects that are called from said function. If you want more thought out stuff you should really check out Bret Vector's blog http://worrydream.com/
I like the article but I wonder why the shift away from RDMS/OLAP to NoSQL. Was there another goal here that was different from the topic of the article? This is nothing against Scala as I think it's a cool language but based on the article it seems like the company ditched RDBMS just for the sake of change.
Yes, there were many other reasons why we were considering a move away from our SQL Server infrastructure. It wasn't directly related to the Scala technology change, but I think the fact that we were able to make that change made other people in the organization comfortable with exploring non-Microsoft solutions. It was a project that sat on our back burner for awhile. The problem wasn't the RDBMS technology itself. I apologize if it comes across that we're anti-RDBMS, we're not, we were just exploring other options (relational or otherwise) to address some of our performance and high licensing costs we experienced with SQL Server clusters.
Why not Postgres?
Thanks for the article - enjoyed that.
A new VM would manage memory more economically. It would effectively do what the new [miniboxing compiler plugin](http://scala-miniboxing.org/index.html) does, and even a bit more. 
&gt; It was also becoming clear that Scala was being heavily adopted in the industry based on data from job sites like Indeed.com indeed.com is showing Scala at 0.04% job market share, "heavily adopted" is a bit of an exaggeration. Also, interestingly, the graph he's using to make his point doesn't show Java. [Here is the same graph with Java](http://www.indeed.com/jobtrends?q=scala%2C+groovy%2C+clojure%2C+jruby%2C+jython%2C+java&amp;l=). Quite sobering. There are good reasons to switch to Scala, but "heavy adoption" is certainly not one of them. 
&gt; I was referring to Scala in the context of JVM languages, not including Java. Why not? It's still the language used by about 99% of companies that use the JVM out there. Groovy is the #2 language on the JVM, Scala #3 and then you have all the others, why compare Scala with all these other minority languages? 
no but its more about existing industry thats being ignored for supporting RETARDS called JAVA programmers.
now I know you are trolling, thanks for clarifying. 
Because it's a more fair comparison to make across 2nd gen JVM languages vs Java.
That's great to hear. Good luck with your Play! app. I would recommend trying to get some of your colleagues onboard (if you haven't already) so you can get some support on the technology choice.
Thanks! A motivating factor was to move away from IIS (the older the existing web app got, the harder it has been to keep it functional on newer IIS revisions), and to be platform-independent, so moving to Play wasn't a hard sell. Fortunately a small dev team overall, but so far I'm the only one who has any Scala experience... We'll see if that can change.
You might want [np](https://github.com/softprops/np).
He seems preoccupied with others' imaginations.
Just watched your video. Can't speak to the compiler guts, but your criticisms of language design choices exactly match my pain points with Scala. What do we need to do to couple the paulp train to the ermine train?
I'll be taking a close look at ermine, but I'm going to drink things in for a while before the train gets going again. 
Interesting stuff from Paul. My only issue with this is that I'm not sure at all that it helps Scala itself, or the community.
Yeah, that would be nice to have. I've made a SBT skeleton project as a Git repository that I clone whenever I need a new project which works alright. 
Maybe they just wanted to try something new, for fun and learning, + something with static typing + not Haskell + on the JVM, but are shy about stating these criteria publicly because of just how much negative feedback it would attract? I don't see these criteria as a negative, but you may? 
I've been working on a project using Neo4j lately (in python, not scala), but I really don't like gremlin. Something about it, including its syntax, just doesn't feel right.
Might be nice to know that Cypher, the built in query language of Neo4j, is built with Scala. https://github.com/neo4j/neo4j/tree/master/community/cypher
Annnnnd, it's gone.
&gt; type erasure doesn't allow method overloading for parameterized types For one, for the sake of brevity and uniform principles, I'd prefer to be able to implement overloaded methods with the following signatures: def apply[A](it: ⇒ Iterable[A]) def apply[A](f: ⇒ Future[A]) def apply(any: ⇒ Any) which is not possible because of erasing the method parameter to Function1 in all the cases. &gt; weak support of different variance types I mostly meant reasons caused java.util.Map&lt;K,V&gt; to have get(Object key) rather than get(K key). &gt; no native support for closures Similar to Java, a synthetic wrapper capturing all referenced objects from outer scopes is created, while I suppose this could better be achieved if a VM supported this natively as dedicated bytecode instructions. &gt; &gt; no proper way to encode full type signatures in class files &gt; I don't want this at all. I actively want this not in a language. Really? You don't want the signature in a class file be Option[String] but simply Option?
Looks good, but I don't see myself migrating anytime soon. We have some work upon unfiltered/netty, that has a way more readable code than that. 
Care to elaborate a little bit what you mean with &gt; [...] way more readable code than that with an example or two for comparison?
There's a sex joke in there somewhere...
A really clear and above all pragmatic blog post. 
Klout is always looking for great Scala engineers (http://klout.com/corp/careers). 
&gt;For one, for the sake of brevity and uniform principles, I'd prefer to be able to implement overloaded methods with the following signatures: def apply[A](it: ⇒ Iterable[A]) def apply[A](f: ⇒ Future[A]) def apply(any: ⇒ Any) You can already do this but better: def apply[A,M[_]](f: =&gt; M[A]) &gt;I mostly meant reasons caused java.util.Map&lt;K,V&gt; to have get(Object key) rather than get(K key). I think this was for legacy reasons. I don't think if you rolled your own map you're constrained to the Object type. &gt;Really? You don't want the signature in a class file be Option[String] but simply Option? No, I think this encourages bad design/coding. Your method signature should be parametric, not specific to a type. I'm willing to hear arguments both ways though. 
Do you happen to know if the talk was recorded and will be, or, even better, already is released somewhere?
[Subcut](https://github.com/dickwall/subcut).
`Reader` is a neat monad but it doesn't scale as well as dependency injection the way it's done in Java. We're still using Guice a lot and I am still looking for something that makes this kind of simple construct: @Inject private MapService mapService easy in Scala. The requirements are very simple: whenever one of my Scala classes needs a dependency, I don't want to have to modify an entire flow of method call paths with that extra dependency (either explicitly or with implicits, like the `Reader` monad forces me to). The Cake pattern has way too much boiler plate over this simple approach, so it's a non-starter as well. Has anyone come across something similar? 
Twitter and Foursquare are both big Scala shops.
A well written blog post, I will try playing around with this pattern a bit.
Was recorded, as were all of the "big" talks, assume at some point should be available on scala.io site.
Interesting, got the same reply when I asked 2 developers at scala.io conf why they were using Play instead of Spray for their REST application backing an AngularJS frontend. Response was basically, Spray is not readable enough. I started out with Spray and Scalatra but moved to Play for full stack server-side (no Angular, Backbone, etc. frontend) development. If I go pure REST + JS client I'll give Spray another go -- lightweight, scalable and performant are nice-to-haves.
Well, you could use Guice. The Java DI patterns are still valid in Scala: @Inject private var mapService: MapService = _ This initializes `mapService` to `null` initially, with the expectation that it will be initialized by the DI system. Note that they won't understand some of the nuances of Scala's type system. For instance, they won't properly inject a dependency of type `X with Y` or `X { type Y &lt;: Z }` or of a value class, which Java's type system cannot represent, unless some sort of add-on is used to teach the DI system about Scala types. --- It would also be nice if systems like Guice could implement abstract `val`s. For instance, you'd have: abstract class MyAwesomeClass { @Inject val mapService: MapService } …and then Guice generates an implementation of `MyAwesomeClass` dynamically, complete with an implementation of `mapService`.
Tumblr and Social Print Studio both use Scala to a fairly large extent
Netflix
the talk was recorded, it will be available at infoq.com at some point (as should most of the talks made in english, conf was part in english, part in french)
After 41 minutes he says what he wants is a virtual machine that directly executes the abstract syntax tree. There have been VMs like this, and their performance is terrible. Maybe he was talking about the compiler rather than the machine. I think his complaint that compare() should return LT | EQ | GT instead of an integer is good.
I think he's talking about saving your programs as serialized AST &amp; compiling these to bytecode when you start executing your program. (basically add one extra layer of abstraction over bytecode) I can seen the benefits of this, I always wondered why Scala hasn't gone this way, a lot of scalas 'bytecode representation problems' can be solved at link time, this would be good for performance, binary compatibility &amp; compilation speed. The downside is application startup speed and you would probably need a properly standardized ast format. This execution model is very close to the way jruby works.
Has there been a reaction from Martin or anyone else at TypeSafe to this presentation?
How would this affect Java interop?
Using java from scala wouldn't be a problem. Using scala from java would be more problematic: to instantiate classes or access objects you would have to go through some special interop api. To satisfy javac class-files with interfaces of the classes/traits should be available. The current interop story with java isn't much better though. I've personally tried to access scala objects from java; the many '$'s in the name broke my IDE and I'm not sure if the next version of scala will use the same name mangling. You currently can't instantiate new objects with traits from java (as in new Foo with Bar). While I think this could be done with the system he proposes. (ScalaFactory.mixin(Foo.class).with(Bar.class); // the ScalaFactory hides all the ClassLoading &amp; bytecode manipulation) If you look at what dependency injection frameworks like guice do, this shouldn't be terribly difficult. The biggest problem is that if you use classloaders you exclude Android, unless you offer the option to compile your program to bytecode (sort-of compile the world to bytecode). There are other applications that don't allow classloaders, you can't use those either. Of course I'm dreaming out loud here ;)
&gt; For the record, I have a lot of respect for Clojure and if I ever give up on types it would be a language of interest. However it is unlikely I will ever give up on types. I, too, have a big respect for strong, static-typing. The three-value comparison you gave is a prime example: in a strong- &amp; static-typed system (assuming that it isn't making the classic C mistake of integer/enumeration equivalence) such a system can be perfectly expressed. (eg `Type Relation is (Less_Than, Equal_Value, Greater_Than);`) -- In such a system you simply don't have that problem of "it's an int" (assuming that the programmers aren't being "compatible" with C/C++ et al).
what's the problem with OOP?
The moment you pre-compile to bytecode, you can no longer keep binary compatibility. So you can do this for standalone applications but not for libraries.
&gt; what's the problem with OOP? One problem is that recent graduates seem to be lost as to the value of subtyping, that is restricting allowed values... even though we all used it a ton in math classes because of the [undue] emphasis placed on extensibility in teaching OOP. subtype Positive is Integer 1..Integer'Last; function Div( Numerator : Integer; Divisor: Positive) return float; The above, for example, needn't check for the divisor not to be zero. Another problem is that some problems *aren't* reflected by a class-hierarchy; sometimes there are more differences than commonalities in the types involved in a process. (Don't try forcing the square pegs into round holes.) Lastly is that you lose a lot of predictability, which is the whole point of a system where every object "knows how to print itself" and can implement their own print.
np is cool.
Martin and others have been aware of Paul's opinion for a long time...
Yeah, but the only people who would be worried about that are those who are using the libraries!
What you describe is somewhat counter to normal functional programming practices, where functions should be "pure" and all parameters passed in explicitly. This means that, more or less by design, you have to modify the "entire flow of method call paths" for an extra dependency, just like you would for any other parameter. Of course, Scala isn't a pure functional language, so if the trade-offs make sense for your project, you can use Guice, Spring, and other frameworks with Scala to add something like @Inject.
The list of mocking frameworks should contain [jmockit](https://code.google.com/p/jmockit/), which can mock everything, even static methods.
[Video from Pacific Northwest Scala Conference](https://www.youtube.com/watch?v=D3VBVGhZ1SE)
I've been surprised by how much trouble colleagues have had picking up spray-routing, too. I wonder if it has something to do with the gap between being aware of the existence of partial functions as a first-class concept in Scala, and being able to reason from that awareness to ramifications. The "Longer Example" at the spray-routing [documentation](http://spray.io/documentation/1.2-RC2/spray-routing/) is, I think, a good litmus test: if you're comfortable with functional programming, combinator libraries, and the notion of partial function chaining, it probably makes good sense. If you aren't, then yeah, it's probably some pretty tough sledding. The availability of PartialFunction and orElse/andThen almost makes me want to work up a presentation just on it, and the various things, like Option, that are actually PartialFunctions or have implicit conversions to them, so you can say stuff like myOption1 orElse myOption2...
Interesting. But shouldn't the compiler be able to optimize for this by converting the function call into a method call at the bytecode level?
None of it matters as long as they dont fix SBT and things that never work in Eclipse.
None of it matters as long as they dont fix SBT and things that never work in Eclipse.
Hello "logicallygenius", are you planning to be kicked out again?
Great write up. Clear, concise and to the point.
Interesting, but I bet comparing the bytecode for the two cases would be instructive.
I'm really digging this guy's kool aid. But couldn't his complaints about maintenance woes have been about any piece of software? Surprising that a brain farm like Typesafe is suffering from the same problems as random software developers.
[Slides](https://speakerdeck.com/pavelfatin/design-patterns-in-scala)
I am not sure about the use of `Symbol` though. Indeed, I wonder if there are ever any good cases where the `Symbol` type in Scala is useful? We have a special syntax, but it only saves one character opposed to `String`, and as far as I know, it can't do anything that `String` can't; if you put them into a set or map, string behaves totally correct w.r.t. equality. So why symbols?
Since when will `!=` perform a reference check—I thought that would be equivalent to `!(a equals b)`? Do you mean `a ne b`? Or is the `equals` method of `Symbol` defined to use ref checks? **EDIT**. Ok, I see… from `Symbol.scala`: override def equals(other: Any) = this eq other.asInstanceOf[AnyRef] So it might make some sense in the compiler which makes heavy use of symbols (right?).
Aye.
Pick any medium-size project from any of Scala's more single-paradigmatic influences (e.g., Java, C#, Haskell, OCaml, or Smalltalk, to name a few prominent ones) and demonstrate that porting the project over to idiomatic Scala, and thereby providing access to the previously missing other paradigms, is beneficial in some notable way to the project's internal structure.
Scala lets you build up Domain Specific Languages that you can intersperse with other Scala code. Maybe you could build a DSL for some particular area that interests you.
&gt;I think mostlywaiting was talking about the .NET VM, not the .NET languages. And there are many .NET languages -- since you say ".NET is not near as nice as scala" it seems like you're under the impression that .NET is a programming language, like Scala is Fair enough, precision in discussion is important and I can respect that. When I said .NET, I meant any of the .NET languages. C#/C#/VB, since I'm restricted to the platform (in the external, business requirement sense), not the languages.
Did anyone understand what happens when you have a type with sub-types, e.g. a sealed trait. From the [slides presentation](https://speakerdeck.com/heathermiller/instant-pickles-generating-object-oriented-pickler-combinators-for-fast-and-extensible-serialization) I gather that the automatic format generator will fall back to using reflection. Wouldn't it be better/possible to do this at compile time (using macros)? sealed trait Foo case class Bar(i: Int) extends Foo case object Baz extends Foo (Bar(33): Foo).pickle // what's it doing here exactly? 
I wrote an emulator in Scala. Was enjoyable.
UNTIL you can debug SBT web projects/ code in Eclipse, NOTHING CAN BE COOL IN SCALA LAND
Going a bit further with the Unix shell philosophy, you don't actually have a OS whose only commands are "cat" and "echo" (just an example) because those are the only ones you're regularly using. However, I understand the psychological component, that you **perceive** that library as being less entangled.
Thats all Fine but whats the use if our web projects dont work from Eclipse ?
but whats the use if our web projects dont work from Eclipse ?
Ah, I see, also [this](https://github.com/scala/pickling/blob/695e7d0e7737adda5b6303bb220bb8a2c0a493a7/core/src/main/scala/pickling/Tools.scala#L58), looks like you are right. That's good.
I took that course the first time around, and it was great. If you have the chance, I highly recommend [this](https://www.coursera.org/course/proglang) course as well. It uses Scheme, Standard ML and Ruby.
I don't understand the "Intuition" section. I know that 100 is bigger than 90, therefore, 100 cents is bigger than 90 cents. This is a standard lift (`A =&gt; B` to `F[A] =&gt; F[B]`), not a contravariant one. This is confirmed by the very code the blog author uses: def compare(x:T, y:T) = Ordering[S].compare(f(x), f(y)) What am I missing? Can someone show another example of "why" I should care about contravariant functors, as opposed to explaining "how" they work? (I'm quite familiar with the theory. I have a similar question on "why" vs "how" about comonads). 
http://www.reactivemanifesto.org/
You can convert any money amount to an integer. Thus you have a function `(Money)=&gt;Int`. Then suppose you have any integer ordering `Ordering[Int]`. It may be increasing or decreasing (or any weird ordering). Using the contravariant functor you can use the contravariant functor to produce an `Ordering[Money]`. To summarize: `(Money)=&gt;Int` gives you a function `Ordering[Int]=&gt;Ordering[Money]`. Is it more clear to you ? 
Oh please stop conning people into doing PLAY framework, MVC is for sheeple, oh wait you all are sheeple.
I didn't know Netflix used Scala. Is it *the* major language at Netflix, or just *a* major language?
Is this course of interesting outside of web development?
I don't know for sure if it's the dominant language at Netflix, but a quick search yields quite a few results and presentations about Scala at Netflix.
I'm taking it with the hope that eventually I'll be able to apply it for distributed computing.
From the first video, it doesn't sound like there will be a focus on web development, the "course contents" list below is from the first video. Course Contents (from the first video): * Review of functional programming * An important class of functional patterns: **monads** * Functional programs in a stateful world * Abstracting over events: **futures** * Abstracting over event streams: **observables** * Message passing architecture: **actors** * Handling failures: **supervisors** * Scaling out: **distributed actors**
It would a great if we could get access to the source code as the source in video is pretty much Illegible.
You need some time put aside. It also depends on your current expertise. For the previous course (on Functional Programming in Scala) I was investing about 1-2 hours per week in doing the homework. If you have problems grasping the concepts involved, then you'll definitely need more than 1-2 hours per week, but I don't think it's unsurmountable. 
Couldn't they try LLVM?
This is so foolish. Why test at all, there are better ways than wasting time writing tests. You sheeple follow what your masters tell you and you do that for like ETERNITY. without any improvements and NO SHAME.
Assuming you are a developer, you are the first I've known who sees _no_ value in testing. Can you elaborate?
I fear you've been had by the troll. If AAAplus isn't a troll, I'd also be curious to know what is better than testing.
Very timely, of course, to anyone doing the first homework for [Principles of Reactive Programming](https://www.coursera.org/course/reactive). (A little tricky, by the way.) In effect, ScalaCheck forces you to think about the contracts (post-conditions and invariants) your software provides. Then you write your contracts in ScalaCheck form, and it generates random data to test that they are indeed always satisfied. I'm sure, used well, it could get me to think more rigorously about my code and what it's supposed to guarantee.
[Source code on GitHub](https://github.com/tmiw/newsrdr)
So i guess you are a Java programmer.
Why do you say that?
I figured he was either a troll or completely unorthodox developer. I've known plenty and although a lot of them don't like testing, they'll usually admit its value in some fashion.
Are you using bootstrap? Also, what web framework are you using?
 Why would one test when one knows how to code perfectly.
Can't argue with that! :)
I'm doing the reactive MOOC as well. I'm certain OP is probably too! ScalaCheck seems like a fantastic tool. I think library developers would especially like it as you never know how some crazy kook is going to consume your API. The first reactive exercise was a great introduction to its capabilities.
Do you have any constructive feedback on how this could be done the Scala way? 
If you want to build a more idiomatic scala webapp I would recommend looking into Play2.x or Spray. Alternatively, Unfiltered provides lower level request-response handling with some nice pattern matching utilities. One low-level area where you could make this more idiomatic is validation: if (userId != null &amp;&amp; userId.length() &gt; 0) Instead of if statements, chain Options with map and filter. For a (hacky) example: Some("initial_user_id").filter(_ != null).filter(_.length &gt; 0) Try it out in the REPL! 
Yep, I'm using bootstrap for CSS and a few of the JS libraries and [Scalatra](http://scalatra.org) for the Web framework. I also handrolled a simple MVC library for the client side in CoffeeScript. :)
I like using _ in anonymous functions. That has to count for something, right? :)
Ideally the pattern matching would go all the way to what response to deliver. Like this : //Some(User) if user in db, else None def buildUserObject(id: String): Option[User] = { /*...*/ } def doWithUser(u: User): Option[Response] = { /*...*/ } val errorResponse: Response = { /*...*/ } resp: Response = Some("initial_user_id") .filter(_ != null).filter(_.length &gt; 0) .flatMap(buildUserObject(_)).flatMap(doWithUser(_)) resp.getOrElse(errorResponse) you can also dress it up with for expressions, which are just syntactic sugar over map, flatMap and filter calls. ie: resp: Response = for { s &lt;- Some("initial_user_id") if s != null if s.length != 0 u &lt;- buildUserObject(s) r &lt;- doWithUser(u) } yield r
Yes, I am. :)
Woah I'm not sure if I understand correctly, but aren't you just trying to do this? resp = for { s &lt;- Option("something") if s.length &gt; 0 u = buildUserObject(s) //need a = if it doesn't return an option r &lt;- doWithUser(u) //maybe this one returns an Option } yield r
That's right, Option(null) == None so there's no need for the first if statement, and you can put the if statement on the same line as Option("something"). I defined buildUserObject as returning an Option so it needs 's &lt;-' instead of "s =" but that's totally arbitrary. 
Do you find for-comprehension it more readable than using plain map/flatMap/filter ? val res = Some("initial_user_id") .filter(u =&gt; u != null &amp;&amp; u.length &gt; 0) .map(buildUserObject(_)) .etc... At work I regularly see large for-comp constructions and it is rather difficult to get what code is doing. So I usually break such constuctions into plain map/filter blocks and use intermediate variables for clarity. btw, you can use withFilter in such scenarios which is optimised not to create intermediate collection. To author: good job, keep improving! I would suggest avoiding "var"s and try to use val. "You must have a real reason to use var" - that's what my Scala teacher said to me. If you are new at FP it can look unnatural initially but later it will start to make sense. Say with val I am sure my variable is never changed/reinitialised down the code - it slightly improves code reading. Try to embrace things like Options, no nulls! I would advise you to go through Functional Programming in Scala book one day - I found it tremendously useful - it will teach you how to write more idiomatic Scala and how things work under the hood :) 
I prefer for comprehensions when the entire body of a function can be structured as a single for comprehension. As soon as you start chaining them together they get cumbersome.
Yep, I'm changing stuff to val wherever I have to modify/fix code. I'm thinking that [rebalanceJob](https://github.com/tmiw/newsrdr/blob/master/src/main/scala/us/newsrdr/tasks/ServerMaintenanceJob.scala#L17) could be rewritten as a foldLeft op, for example.
If you're using the Iterables/sequences as a functor, then yes, that's fine to chain them together. It's when you want use them as monad that makes things much more readable. For instance def handleReq(req: HttpServletRequest): Option[UserObj] = resp = for { name &lt;- Option(req.getParameter("name")) job &lt;- Option(req.getParameter("job")) pwd &lt;- Option(req.getParameter("pwd")) } yield UserObj(name, job, pwd)
The author seems to misunderstand what a Scala function actually is. Scala more-or-less defines "function" to mean an object extending one of the `Function*` traits. `apply` is a *method,* not a function. Functions in Scala are indeed objects; methods are not. Of course, the compiler will generate a function for you if you try to use a method as a function, but that doesn't mean they're equivalent.
&gt; There exists things that are not objects. Functions are not objects. &gt; [...] &gt; Python and Scala just kidnapped the functions, jailed them into “objects” That's plain stupid (pardon my &lt;someOtherLanguage&gt;). There is nothing wrong _treating_ a function as an object. Along that argumentation you can say OO is dumb because `true` and `false` certainly cannot be objects. Objects are just handles or references so things become tangible.
Instead of `Some(blah).filter(_ != null)`, why not `Option(blah)`?
It doesn't seem to keep me logged in if I go to a page outside of the loginwall. Seems nice otherwise though.
Yeah, I noted that mistake later in this thread. I was trying for a one-to-one equivalence between the if statement and the option chain.
I don't know what it is about this article but it strikes me as really... snooty? "I HAVE SEEN THE TRUTH AND ALL ABSTRACTIONS ARE LIES!" The tone and delivery of the ideas could use some work.
Super intelligent programmers dont worry about such issues, instead we try to focus on how to put any programming features to the best use and how to make most out of them regardless of who says what about them. And it means finding out which are the best and most useful features. For example , we will soon reach an Macros language era, only super intelligent ones will be able to use them, the rest should just bow down to us
You know you also don't have to concatenate manually in coffeescript... You can tell by looking at the code you are a confident developer and very proud of your work. Nice job!
&gt; OOP is wrong because of its definition of an “object” What the hell? OO programmers couldn't agree on the definition of "object" if you offered a keg of beer personally pissed in by James Gosling as their reward. Scheme was created as a way to [investigate message-passing actor-based OO](http://www-mips.unice.fr/~roy/JAOO-SchemeHistory-2006public.pdf), but most people don't even recognize it as OO, and of course many people have felt the need to add their own preferred flavor of object system to the language. Try to talk about the different styles of OO in C++ and Smalltalk, and you are guaranteed to get flamed by people who say C++ is not OO because ALL HAIL ALAN KAY, THE OBJECT-ORIENTED PROMETHEUS. Saying OO is wrong because its definition of object is wrong is like saying French cooking is bad because it uses the wrong vegetable. 
They are in Scala, too. What I wanted to say is that just because in your everyday experience you cannot touch a "true" or "false", since these are logical judgements, doesn't mean it is not useful to treat them as something that can be passed around and has an attached interface.
&gt;Some people claim that the value of monads is that they “delimit” the side-effects. But what’s the use of the delimiting if monads don’t really make your program easier to analyze or safer? In fact, they don’t. It is just as hard to analyze as if you use side-effects. There is no such thing monads can make easier which can’t be done by static analysis. Embarrassing that a PhD candidate studying PLT seems to be misinformed about Monads... 
He is a Scala hater/troll; look at his posting history.
Thanks! Can you explain a bit more about the concatenating?
Ah, good to know! :D
I have a fairly large Play app running on Cloudbees at the moment, pretty happy with the service. Deployments are easy, fast, and the deployment process integrates tightly with SBT. Only a closed beta at this point so I can't comment on scalability and performance but it handles benchmarking well. Was originally using Heroku, but had endless problems with build timeouts - The EC2 Micro instances they use for build servers just don't keep up with a large codebase, especially with lots of javascript minification. We eventually (after weeks) got through to support and had them upgrade us to a faster build server that didn't timeout, but it still took a good 10 minutes to deploy a build (vs 10 seconds on Cloudbees). 
This may not help you much given your licensing comment but I've had three (two for work and another that's a personal project) Scala Play applications on Heroku and I love it. Managing deployments is ridiculously easy (literally just a git push - and can effortlessly rollback to a previous deploy) and there's a wide variety of great addons (most of which have very reasonable pricing and nearly all have a free tier to experiment with). As for databases on Heroku I've used MySQL, MongoDB, and Postgres (including one project where I migrated from MySQL to Postgres), use whatever works best for your needs obviously but from my experience Heroku's (own) Postgres addon is a bit better than the (only) MySQL addon available.
Can I ask how long ago it was that you were on heroku? I've read in places that they had issues with slug size etc that they've since cleared up. Did that have anything to do with your problem?
About 2 months. Slug size wasn't the issue - it was the amount of time it took to compile the project. To my knowledge the issue still exists, as it's pretty much a fundamental part of their architecture. They don't allow binary deployments - you have to push source and let them compile it. We had a lot of Maven dependencies (Which seem to download very slowly on Heroku), a fairly big Scala codebase, and a large amount of Javascript and Coffeescript that needed to be minified. All this added up and it simply hit the 15 minute compilation timeout. They put us on a higher tier to improve compilation time (When we eventually got ahold of support), but it was still a 10 minute endeavor to get a release out. Compiling on our in-office build server and deploying a binary to Cloudbees takes ~1 minute. Which makes a big difference when you have a last-minute bug to fix 5 minutes before a demo to a potential customer. They also don't support private git submodules, which we use heavily.
Thanks for the clarification. Have you found cloudbee's support to be better or just never needed to use it yet?
&gt; Embarrassing that a PhD candidate studying PLT seems to be misinformed about Monads.. If you're going to criticize a PhD about the topic of his thesis, the least you could do is present arguments instead of just complaining. Who knows, maybe the ensuing discussion will lead you to think that you might know less about PLT than he does after all. 
You can try openshift.
Hm, it might be because the template for the non logged in pages doesn't take login status into account. Let me check on that and get back to you.
I have been inspired by your talks especially the flaws in Scala and the JVM. Looking forward to see if you come up with a solution for these. Possibly an alternative language and compiler and VM. Perhaps what you build can interop with Scala using Scala Virtualized? If you have any concrete plans let the community know also. BTW, what was the functional language with multiple layers of abstraction mentioned by a member of the audience towards the end 
Okay, should be fixed now.
Emacs support for scala is still a little "poor" and Eclipse is... Eclipse. :-/ I think I'll give IntelliJ a try very soon!
I'm still not satisfied with the Scala support in IDEA either, though. It still has a bunch of rough edges especially when you use more advanced features. Also it is slow and taxing on the CPU. Perhaps I should just get a proper work station for my Scala coding as opposed to just a laptop ...
Agree. The Eclipse Scala IDE has a lot of major issues. First of all (but this could be me) Eclipse occupies a lot of pixels, is slow... I mean, after spending some years coding just with Emacs (except for C# where I use VisualStudio which is light-years ahead of Eclipse) you cannot get back to a *slowing* IDE. But, I repeat: this could be just me, as a lot of people are happy with Eclipse (I suppose). But Eclipse has something great: code completion which if you are not that expert can help you a lot, and a good SBT project management capabilities. Anyway, I'm going to give IntelliJ a try ASAP.
I haven't had any issues with CPU, have a quad core i5. Maybe having a SSD helps too.
I cross-posted to /r/programming, but that seems to be getting downvoted: http://www.reddit.com/r/programming/comments/1qix5x/intellij_scala_plugin_has_been_downloaded_more/
IDEs have always been hard on the computer running them, especially when used with slow-to-compile languages like Scala or C++. So yes, getting a proper work machine will serve you well. It doesn't have to be a hugely expensive powerhouse, either. Even a Core 2 Duo will be fine. Do make sure you get enough RAM for it, though—6 GB should be good.
I don't know about SBT support (I loathe SBT anyway), but IntelliJ IDEA has damn fine completion. Most notably, auto-completion also shows methods added via implicit views.
Eclipse is fucking terrible. I'd sooner try to struggle with Vim than try to use that heap of junk again.
this just shows that scala is such a difficult language to use without an IDE.
Their Ruby and Python plugins are also popular...
150426 + 195916 &lt; 851196
good for you. you are a typical scala programmer. thank you for stepping out.
The Scala plugin is free, the Ruby one is paid (and so was the python one until very recently).
Probably because IntelliJ is (and has always been) the only usable IDE for Scala. In addition, it's also pretty good.
I'm not exactly sure why it is but I feel the same.
Seems like a nice lib, but nothing that couldn't be done in JUnit tests... I thought it was an interesting assignment though, I didn't cheat by looking at the impls. What I have a hard time getting around in Scala is this concept of extending the object for a test, doesn't that go against the substitution principle? What if you change the internals of an object (for example the name of the 'empty' parameter in the first assignment)? For that reason I still kind of am not sold on this whole trait extending for tests thing.
PLEASE switch to PostgreSQL... MySQL is so terribly broken that it has corrupted an entire generation of developers with horrible SQL habits. By default, MySQL is NOT ACID compliant (There really is no locking on MyISAM tables). When you DO convert to an ACID compliant store, it's slower than molasses! PostgreSQL is FULLY ACID compliant AND very fast AND extensible using PLSQL/PLPGSQL/Java/C.... It's basically just as capable as Oracle, but it costs NOTHING to deploy...
&gt;What brand is your toaster of a computer? It has an Intel Core 2 Duo E8400 (3.0 GHz) CPU and 4 GB of RAM. It's not a toaster. It runs IDEA just fine. There are many problems with Eclipse, of which my hardware is exactly none: * Terrible UX overall. * IDE is buggy as hell. The window for downloading and installing plugins is especially horrid. * Workspaces are an abomination. I'll keep my projects where *I* want to keep them, not where some shitty IDE thinks I should keep them. * There appears to be no real support for opening Maven projects. It can import them into its native project format, but requires me to establish mappings of Maven plugin goals to IDE actions. WTF? Just run the fucking Maven build! So yeah, take your shitty Eclipse and shove it where the sun don't shine. IDEA does what Eclipse does, *correctly.* IDEA even has the same worksheets feature. And no, I'm not going to use SBT. That thing is also horrid garbage that should never have seen the light of day. Mandatory blank lines, fucking seriously? I have been thinking about Gradle, though…
3 years? I've tried Eclipse occasionally for far longer than that. It's *always* been terrible.
I don't know. I've never used it. Since it's based on Eclipse, though, chances are pretty good that it is.
I meant it went from usable to some sort of abomination =)
Hmmm . . . . Tells me to be fair, then proceeds to back up my argument... I like it! :) I agree with you wholeheartedly!
Could be the mem size, I haven't had a comp less than 8 gigs for 4-5 years now. I typically give Eclipse a gig and then enable the heap monitor on it to show me what it uses. It typically hovers at 200mb and then up to 600 or so for when it does full workspace rebuilds (rare event usually change in jdk etc) My home comp also runs it fine with 1.9 processor, but also 8 gigs. A little slow to start up (20 seconds or so?) but after that runs smooth. Hm, I don't use Maven, but when I did previously it only seemed to do dependencies well. Sbt, blarg, I'm no fan definitely, its a weird little half-script half-declarative thing, but I've been able to use it build scala or even scala js projects with it with little fanfare, so it 'works'. I just have refresh project after adding sbt dependency and run it from the command line, but I don't mind using cli for tools that work well and I think sbt meets its goals of being simple and easy to use. Sounds like you're not going back, but workspaces can be pointed anywhere also, you just check or uncheck standard locations... anyway, good luck.
Only Walmart Canada and only an outside vendor. I am still working on getting the Walmart US Information System Division to allow the use of Scala by our internal development teams, but it hasn't been approved yet. Bureaucracy motto - "Yesterday's technology tomorrow!"
Note that I didn't say Eclipse is *slow* on my system, which it isn't. Speed isn't the problem.
Idea is great but if you try to use slick 2.0 it goes crazy with syntax errors. Supposedly some of it is fixed but most of it is not. I have actually transitioned to vim with ctags, neocomplcache, and ctrl-p, vim-scala, and the sbt plugin, and I am way more productive now.
I think we have now firmly established that he indeed knows more about this topic than you. Not that I'm surprised, though: people who criticize without any justification usually don't have much interesting to say. 
BOOOOOOOOOOOOOOOOOOOOOOOOOOOUUUUUUU! To corporate spammers
No I'm confident he doesn't. His main argument that you missed was that monads introduce a cognitive overhead that he can't escape from. You tell me that sounds like someone who is well versed in the subject? 
Funnily enough, I find Eclipse more intuitive to use than IntelliJ. For the life of me I couldn't figure out relationship between projects, modules, my source code and the resulting on-disk structure in IntelliJ. (Note: Being a c++ coder, I had little experience with both Eclipse and IntelliJ when starting to look at Scala.)
&gt; nothing that couldn't be done in JUnit tests But wouldn't you have to write the random generators yourself? And the framework to pipe the random data to your tests? As far as I know, JUnit doesn't provide that out-of-the-box. As with any test framework, ScalaCheck provides idioms to make it easy to test the things its designed to test. Running each test with a hundred combinations of random data, and then *automatically finding a minimal failing case* is definitely a feature ScalaCheck provides that JUnit doesn't. (Try changing one of the `checkBogus` calls to `check` in QuickCheckSuite.scala to see a minimal case.) And it allows you to do it in four lines of code. &gt; not sold on this whole trait extending for tests thing. When performing Unit Tests, you're sort of assumed to be "inside the walls" to some extent. (In Java, for instance, you're in the same package, which allows you to get sufficiently inside the system under test so that you can isolate it from the rest of the system.) In Scala, traits are used as *modules* for a stronger statement of the same thing. When you want to use a module, your client code mixes in to the module's trait to make the dependency explicit (and type-safe). In the homework, it's a little confusing at first because the traits are so abstract. We have Heap, which has a "heap" type H and element type A. Then IntHeap defines A to be Int, and BinomialHeap defines H to be List[BinomialHeap.Node]. Then we have five bogus sub-traits of BinomialHeap. None of these are concrete classes. Our test class is a QuickCheckHeap, an abstract ScalaCheck-Properties-subclass which mixes in IntHeap. The test suite then creates the actual concrete objects by mixing together enough traits and abstract classes to make a non-abstract result, which is then sent to be checked by ScalaCheck. This is how the "Cake Pattern" works. ([This talk on the Cake Pattern](http://www.youtube.com/watch?v=yLbdw06tKPQ) by Daniel Spiewak helped me understand what this pattern is for.) By the way, try overriding the `empty` method in QuickCheckHeap.scala. You simply can't; the type of H is not defined in QuickCheckHeap. You could only redefine it in BinomialHeap or one of its sub-traits - but that's the system under test, so that would be allowed anyway. You could (if you changed the definition of `empty` in BinomialHeap to specify its result type as `List[Node]`) write this: check(new QuickCheckHeap with BinomialHeap { override def empty = List(Node(1, 1, Nil)) }) Which would be very obvious to anyone reading your tests, and in some circumstances something like this would be very convenient in mocking away parts of the system under test.