I have to say that this is an argument that, while not unheard of, and has a lot of reasonable-sounding works, but is totally insane once you think about it a bit further. Factually, a huge majority of the Scala community is happily using Scala without using Cats or Scalaz, and in fact use the standard library. This includes large and important projects like Spark, Akka, Scala.js, and the Scala compiler itself. Philosophically, saying you have to use someone’s favorite library otherwise don’t use the language at all is an insane level of /r/gatekeeping. One programming language can host many different libraries, without issue Practically, saying you have to use the latest flavor-of-the-month effect systems to benefit from Scala (and these *literally* change every month!) means you have no time to acually do work for your customers or business. Migrations are hard when you have a big system, and you don’t have time to churn your entire system from IO to Free to Tagless back to IO again in the space of a year Empirically, it’s crazy for someone to tell me my code isn’t modular when they have never even seen it, let alone worked within it. Or to say my code doesn’t do what it says on the box, when more likely than not they are in fact using it (transitively or not) without issue. It’s even crazier to say my organization doesn’t value programmers and our code quality is devolving. I mean, what on earth? Lastly, there’s the claim that using Scala without scalaz makes people think you are an “ivory tower wonk”. Factually incorrect, and perhaps even anti-correlated. Nobody has a monopoly on virtue, and I’m not going to tell people not to use Scalaz or Cats if they like it. There’s plenty of reasons to like it. But there’s so much practical impossibilities and plain factual incorrectness in this post that I don’t think it should be your motivation for going Cats/Scalaz-style FP
https://www.youtube.com/watch?v=d6WWmia0BPM
From Scala you can drop into the javax midi package for generating midi files: https://docs.oracle.com/javase/7/docs/api/javax/sound/midi/package-summary.html The api style is 100% old-school java but it’s effective for the task
**Context** &gt; How big is your team? About 40 people in the product, and 20 people &gt;What backgrounds and levels of experience do your team members have, and how many had written Scala before working with Scala on your team? Backgrounds: All over the map. We have people that used to do embedded device work (C/C++), people who have specialized in live streaming data processing/data-analytics, people who have done CRUD Spring applications, people who have specialized in devops, junior devs straight out of college, and architects with 20+ years of building robust, maintainable software in a variety of languages. Of the forty, maybe five to ten people had production experience with scala, and only two or three had more than two years writing production scala code, including myself. We are a fairly small market so that isn't surprising. Nearly everyone who isn't a junior dev has some production experience with Java or C++ or C# or Python. Experience levels are fairly well distributed normally, with a mean five years of production application experience. The most experienced devs/engineers have 20+ years of experience, the least experienced have less than 6 months of experience, and we have at least one intern. We do not ONLY write Scala on my product team. There's a lot of Java and Javascript development as well. The part of the product that is most expensive to re-run batches in production if we screw up is implemented in Scala in a mostly referentially transparent way. The team in general is not sufficiently advanced enough in FP to push to a totally FP architecture, though we've pushed it as far as we could and are continually refactoring towards that goal. Most of the libraries we produce for re-use within the product are tagless final with an opinionated java wrapper so that we can get the best of both worlds -- modular internals and opinionated integrations for the Java parts of the application. **Practices** &gt;Do you use a publicly published style guide, an internal one, or no written style guide at all? We have a modified subset of the Twitter Style guide, with a link to [Li Haoyi's Principle of Least Power](http://www.lihaoyi.com/post/StrategicScalaStylePrincipleofLeastPower.html). Our modifications are that we use implicits for DI to avoid having to include Spring, and if a library, we code to the least powerful interface (Effect/ApplicativeError, usually) that we use to allow for callers in scala/java code to make the decision of what concrete implementation to use. We TDD all our code and try to wrap everything in an interface (either a trait or abstract class). This was all born out of experience trying to get inexperienced scala devs to produce common code. We tried the cake pattern, partially applied functions, manual constructor injection, limiting error handling to Try/Future, etc. The most sustainable/testable injection pattern we've found is to use implicits and typeclasses over some **F\[\_\]** type-constructor, and to limit the F to be Functor/Applicative/Monad/ApplicativeError/Effect as needed, or just straight up making everything a typeclass over IO so that we have an abstract class/trait to mock in our tests. People seem to be able to copy/paste this enough that we don't end up with huge stacks of monads and throws/try/catch everywhere. &gt;If you use a public one, do you have any internal tweaks that you apply? See above. &gt;There's a learning curve from "cleaner syntax for Java" to other styles that more fully exploit Scala's capabilities. There is a natural tension between engineers who are drawn to climbing up new hills in the language to expand their capabilities, and engineers who feel that this diverts critical intellectual energy away from other issues facing the engineering team. Often some of the most productive members of the team are focused on architectural, domain, and feature considerations and do not have an especially strong interest in learning new programming constructs, and managers are sensitive to anything that compromises their productivity. &gt; &gt;What are the most frequent issues of disagreement among engineers, and how have you (successfully or unsuccessfully) addressed them? IO vs Either vs Try vs Future vs Option. Dependency injection styles. Using map vs pattern matching. Even if something is expressed in the style guide, with a large team over many years it's hard to come to consensus on anything, even when citing sources or the style guide itself. Usually we try something different, wrapping older parts of applications that "work" in interfaces and implementations that leverage whatever the current team has come to consensus upon. My concern is that we develop things on time, and that are testable and correctly implemented. Parts of the product have been developed by other teams, either as a POC that made it into production or as part of externally contracted pieces that eventually came back in-house. We file tech-debt cards and work to make the codebase more uniform over time. Every time team-members change, the old style goes out the window, and a new one gets developed. This tends to happen about once a year because of the way rotations work on projects here to decrease knowledge silos within the company. **Overall assessment:** &gt;Is your team succeeding with Scala? What is the range of opinion about this question among individual contributors and also among managers? Coming from companies that were experienced in Scala and had a cohesive Scala educational training environment and company-wide style, I'd say no. From the perspective of managers, defect rates are low and we are still developing features and delivering, so yes. My opinion is that if the company isn't going to commit to one style and train developers to not throw or side-effect without calling it out in big, bold letters in the application that it isn't really worth the hassle of training new team members and that we should stick to Java and Spring when possible, and Flink or Spark with Java when we really need the power (which is in two places in the overall product), simply because framework development forces developers to solve the problem the same way. With such a large, rotating team, and many micro-application domains with differing requirements, consensus decision making is difficult and capricious, depending on which wheel is squeakier when the decisions are being made and the personalities involved. Largely, I'm agnostic except in the two applications in the product where we were prohibited from using Spark/Flink by architects at this client, and were forced to write custom distributed streaming applications instead.
Ive seen a lot of work on this in Haskell. There is a book, The Haskell School of Music; a mailing list called Haskell-art; and people who do live concerts call it livecoding. Good luck!
I know a couple of interesting projects written in Haskell if you're keen to explore: - https://github.com/tidalcycles/Tidal - https://github.com/DimaSamoz/mezzo There's also this interesting project by the Underscore guys written in Scala (uses `WebAudio`): - https://github.com/underscoreio/compose
Here’s an basic demo that will get you going http://automatic-pilot.com/midifile.html
I think the issue you're describing is a bug with webpack's sourcemap loader. Do the sourcemaps you're attempting to load have a http url?
`export` looks amazing. Opaque types are amazing. Finally `newtype`! However I see room for improvement. implied arrayOps { inline def (arr: IArray[T]) apply[T] (n: Int): T = (arr: Array[T]).apply(n) inline def (arr: IArray[T]) length[T] : Int = (arr: Array[T]).length } Having to repeat `inline def (arr: IArray[T])` isn't cool. And I understand that `IArray` methods must be implemented as statics to avoid boxing, but defining them in the companion object is cumbersome. There should be a way to add a bunch of methods at the same time. Also maybe take advantage of `export`? I'm thinking that since an instance of IArray must be an Array, define IArray's methods in the type declaration, and use `this` for the instance. opaque type IArray[T] = Array[T] { def apply[T](n: Int): T = this.apply(n) def length[T]: Int = this.length } or opaque type IArray[T] = Array[T] { export this.{apply, length} }
Thanks for the responses so far! To clarify, this was to be strictly offline, so no "live coding" (who knew this was a thing?) I also just realized I could generate MusicXML by hand so I have a GUI ready to ingest that in case I want to stare at the output.
&gt; Philosophically, saying you have to use someone’s favorite library otherwise don’t use the language at all is an insane level of [/r/gatekeeping](https://www.reddit.com/r/gatekeeping). One programming language can host many different libraries, without issue. It can, but I'm increasingly asking myself, why use Scala for X at work on this team. What does it buy me? I'm having a harder and harder time justifying it over Java when I'm not using typeclasses to enforce constraints. It gets harder and harder to maintain a codebase when people decide to use Try, and Either, and Future, and IO, and try to extract a value from it all over the place, and actively turn off any tooling we have in the build system to prevent this type of stuff. When people code concrete objects without any sort of trait or abstract class, so testing in isolation becomes difficult. Yeah, it's one company, but it's a lot of different developers in this market over 4 years, and was totally different at a company that enforced a highly coherent coding style. When you tell them not to throw, but they do instead of encoding it in Either. When you tell them not to use Future because it caches values, or they extract two futures with the same code in them to a value and don't understand why the behavior changes. Or you tell them not to exit a monad till the end of the world or you end up with Future\[Try\[Either\[Throwable, Option\[Int\]\]\]\] because they are gluing together a bunch of concrete implementations and aren't really paying attention to what the code they write in a particular method/class is supposed to be able to **do**. Or when you inherit a codebase that's been passed from team to team, all of which implemented a different part of the application and you end up with some constructor-based injection, some typeclasses, some cake pattern, some mutable vars, some rt code and some guava/spring glue. It's just a mess. And then you hand the same developers a Java Spring application and they produce cohesive, quality code that they all understand and agree to write the same way across consulting agencies and companies **without a governing style guide**. Because it's familiar and they have LOTS of examples. You could do the same thing in Scala with Spring, but they end up cutting themselves. &gt; Practically, saying you have to use the latest flavor-of-the-month effect systems to benefit from Scala (and these *literally* change every month!) Everybody hits upon this. You're correct. They do change every month. But binding to **F\[\_\]: Monad/ApplicativeError** doesn't really change over time, despite what you call the pattern enforcing it and the concrete implementation using it. But neither does find/replace Future with IO/Task/whatever, you just might have to go up a level and ensure that it eventually runs. The real problems begin when people start mixing IO and Future and Task and ignoring compiler warnings related to the style guide or randomly turning them off in builds because they didn't know any other way, or @SuppressWarnings and getting a consenting reviewer. FWIW, Tagless Final is almost as easy of a pattern to emulate as the decorator pattern. It is nice to be able to limit the ability of some random dev and reviewer on a large team to being able to call unsafeRunSync somewhere where it really shouldn't be. I'm most interested in getting developers not to do this, but our application is a really special case. If we were just doing some crud app that didn't have extraordinary performance and $$ runtime constraints and architectural history as to why it is developed in Scala instead of something more familiar, I don't think I'd care as much. &gt; Empirically, it’s crazy for someone to tell me my code isn’t modular when they have never even seen it But I have seen it. I see it every day. When I say "you," I mean inexperienced Scala teams. The very post about style guides and the complaints OP is making are what I hear from experienced Java devs that come into our legacy scala codebase. We universally want to rewrite it so that it will be uniform, but don't get the go-ahead to do so because the application works and is expensive to run if a rewrite would fail. It delivers core customer value, and I'm basically able to fix almost any issue that comes up with the application regardless of style, so there's no concrete reason to do so unless I get hit by a bus. &gt; Or to say my code doesn’t do what it says on the box Apache Avro tends to fail this way. DataFileWriter has a builder, but unless you read the implementation, there is no documentation telling you that the order of the set calls actually matters and that create writes all the headers to the file before data is appended. Or all the cases where some code in a java library throws a null pointer because some two classes passed in result in some edge case the devs didn't consider. Or because your credentials are not correct. Or it runs on a separate thread outside of your control and isn't thread safe. These things happen in Java libraries all the time, even popular ones like AWS or Avro or Elasticsearch or Testcontainers. When effect constraints are expressed, there's a certain built-in validation that at least the authors thought of those scenarios and are actively trying to prevent them in client code. &gt; It’s even crazier to say my organization doesn’t value programmers and our code quality is devolving I'm saying that if you started with an FP codebase, then booted the FP programmers because you didn't like the way the code looked, rather than worked, the new devs are unlikely to like it either. Companies are also unlikely to rewrite working code. So you end up with a half-and-half mess. That's why style guides are important. I'm not saying that OOP code isn't high-quality by definition. I'm saying that not knowing that asserting in an Akka actor will bring down the entire ActorSystem isn't common knowledge, and if it gets passed to a team that doesn't know the details of using Akka you can bring an entire production system to a halt by restoring persisted state in an actor that now doesn't exist as a message in the system, and you didn't catch that in integration tests because it was such a corner case. Yet it happened because it was possible. This happened in the company I worked for, and the new dev team looked for the error for days before I was called over to a different product unit to search for the needle in the haystack. I found it in one of their libraries, and made them take the assert out. But you had an entire product team that didn't understand the library/framework they were using, and they had inherited that code in a working state, then made changes to their own whims because they wanted to use assert instead of throwing an error and allowing for recovery. Risk happens with change, and change is constant. That dev team should have been trained, but wasn't. Cont below
&gt; Lastly, there’s the claim that using Scala without scalaz makes people think you are an “ivory tower wonk”. Factually incorrect, and perhaps even anti-correlated I said with scalaz. People think that using FP is complex. It's just different. But different depending upon the application of the language can certainly mean bad to people who are unfamiliar with it. &gt; Nobody has a monopoly on virtue, and I’m not going to tell people not to use Scalaz or Cats if they like it. There’s plenty of reasons to like it. But there’s so much practical impossibilities and plain factual incorrectness in this post that I don’t think it should be your motivation for going Cats/Scalaz-style FP There are lots of impossibilities. I am inferring a lot from OP. But I'm also speaking from experience with a large scala team made up of people who express these frustrations a lot. And I'm also having to maintain codebases from teams who didn't adopt a style/set of libraries/standards. The motivation for going cats style FP is that at least I have a library and a set of source documentation to point to when I say that the code is going to break in a code review. Even if I write a test, sometimes it has been disregarded as a corner case that won't happen. It's a real phenomenon. I have organized libraries where everything is written in one style, and disorganized applications that have been through several teams and are working currently, but sometimes have very expensive bugs to fix, and I have zero control other than influence in a meeting over what style the company as a whole codes in. ANY consistency would matter, and when I see the fact that the team members we are able to get in this market can code Java consistently across product teams and do not code Scala as consistently, and the compiler is able to enforce that better with one style over another, I'm definitely going to recommend either switching to Java or using the enforceable Scala style that removes some of the order of execution/undocumented assumptions. The fact is that if it is pure OOP, Java can do it, and Java developers are more plentiful, and there are fewer arguments over what is the right way to code it in Java.
its almost as if you're sherlock holmes in the digital flesh
No, I use "inline-source-map" in my webpack's config, though the sourcemap generated from [Scala.](https://Scala.sj)js is in a separated file. Could you explain more why it is a bug?
It isn't **wrong**, it just recommends some things that are problematic/common in nearly all other scala code that only has to worry about other scala code. It also promotes things that are absolutely necessary for Java interop, which that project REALLY needs, that your company pure scala project may not, and promotes some anti-patterns, like re-inventing pattern matches that are already implemented in the standard library. [https://github.com/databricks/scala-style-guide#apply-method](https://github.com/databricks/scala-style-guide#apply-method) Using apply methods for class constructors is pretty common. It is rare to see new MyClass all over. Even in Java code, you tend to have factory methods/builder patterns for things. [https://github.com/databricks/scala-style-guide#call-by-name](https://github.com/databricks/scala-style-guide#call-by-name) Necessary for caching some things, implementing tests, etc. I agree that it can be dangerous, but encoding the return value or input value as an effectful type (Future, IO, etc.) is a better signal. Using thunks is also verbose. It makes sense, sometimes. But call by name is really useful, too and is used all over the scala std lib. [https://github.com/databricks/scala-style-guide#multiple-parameter-lists](https://github.com/databricks/scala-style-guide#multiple-parameter-lists) Means that configuration can't be partially applied, leading to either lots of repeated parameters, nested configuration god classes, etc. Currying when you know you are always going to partially apply is useful, and you can crib from other implementations of common things in other languages. [https://github.com/databricks/scala-style-guide#recursion-and-tail-recursion](https://github.com/databricks/scala-style-guide#recursion-and-tail-recursion) Basically mandates using var for things where it is unnecessary, which can lead to hard to reason about code. You can't just substitute values, and have to keep a tabulation when reading through a case or resort to debugging. [https://github.com/databricks/scala-style-guide#implicits](https://github.com/databricks/scala-style-guide#implicits) I agree with their reasoning here, but sometimes its effect can be detrimental: &gt;When implicits are used, we must ensure that another engineer who did not author the code can understand the semantics of the usage without reading the implicit definition itself. Leads to lots of manually decorator classes on large codebases because it expressly prohibits the enhance my library pattern, and often will just result in developers violating open/closed OOP principle. They'll just change a class if they own it instead of using a pattern that leaves the class as-is, potentially resulting in large portions of a codebase being touched to make a simple change. Implicit conversions are easy to abuse, they are correct about that. Implicit classes are used all over the standard library, though, and are pretty common. It also encourages making dsls via implicits, which has wreaked havoc in the past (see dispatch, though that also violates symbolic method names). I think that implicits are useful for injection of configurations (like in the scala compiler), for typeclasses, and for typeclass syntax, and for adding behavior to classes that you do not own. Basically, you could iterate those reasons and not have to write the rest. Also restricting where implicits are defined (package objects for things you don't own, explicitly imported, and companion objects for everything else to allow for overriding injections in tests) greatly reduces the cognitive load they add to a program. Use judiciously, and only if everyone on your project understands what they are and how and where to declare them. It's doubly problematic when they forbid multiple parameter lists, as that's another way of baking in configuration without resorting to repeating yourself ad-nauseum or using runtime di container frameworks. [https://github.com/databricks/scala-style-guide#exception-handling-try-vs-try](https://github.com/databricks/scala-style-guide#exception-handling-try-vs-try) &gt; &gt; &gt;Do NOT use Try in APIs, that is, do NOT return Try in any methods. Instead, prefer explicitly throwing exceptions for abnormal execution and Java style try/catch for exception handling. &gt; &gt;Background information: Scala provides monadic error handling (through Try , Success , and Failure ) that facilitates chaining of actions. However, we found from our experience that the use of it often leads to more levels of nesting that are harder to read. In addition, it is often unclear what the semantics are for expected errors vs exceptions because those are not encoded in Try . As a result, we discourage the use of Try for error handling. Undeclared exceptions are the bane of existence, and having error handling code at many different nested levels in an application increases its complexity. Encoding as Try is problematic, too, but encoding as Either\[MyNonFatalExceptions, A\] or even Option\[A\] is better, as at least then you know if a method you call is going to possibly throw. [https://github.com/databricks/scala-style-guide#monadic-chaining](https://github.com/databricks/scala-style-guide#monadic-chaining) Just use var and try/catch. It's an anti-pattern and they are explicitly encouraging it. Yes, you should refactor large chains into separate private methods. But they actively encourage using pattern matching instead, which can result in missing a case, while the standard library already implements the pattern match inside that datatype's flatMap or fold. You are actively avoiding widely tested and re-usable code for your own, potentially buggy implementations and if you use guards or get your case statements wrong you can have pattern matches that don't throw warnings that a match is not exhaustive and have match errors at runtime. You should use better methods (getOrElse, exists, orElse, etc) if they are available, but the none match in their example good code is repeated twice, for example. [https://github.com/databricks/scala-style-guide#type-aliases](https://github.com/databricks/scala-style-guide#type-aliases) If you aren't doing java interop, type aliases often make your code easier to understand or result in fewer repetitions and thus fewer repeated bugs. [https://github.com/databricks/scala-style-guide#multiple-parameter-lists-1](https://github.com/databricks/scala-style-guide#multiple-parameter-lists-1) Ugh. [https://github.com/databricks/scala-style-guide#implicits-1](https://github.com/databricks/scala-style-guide#implicits-1) Again, makes sense for java interop, but NOT for scala only. [https://github.com/databricks/scala-style-guide#traversal-and-zipwithindex](https://github.com/databricks/scala-style-guide#traversal-and-zipwithindex) Most application transformations are not performance/memory sensitive, and it will be obvious when they are, and recursive method calls are referentially transparent and while loops with vars are not always. Use judgement here, but CALL OUT IF YOU ARE USING WHILE so someone doesn't do something dumb, like extract it to some other place, and don't use it in a global place, encapsulate the while in a method.
Put a top level thread for that.
John, I believe that used to be the case in scalaz's actor library, no?
Type providers rely on "whitebox macros", which are an experimental feature being discontinued. Moreover, if you really need to instantiate stuff from dynamically retrieved models, they wouldn't help you: type providers are expanded at compile-time, not runtime. Essentially they are equivalent to code generation, except that the source does not get dumped on disk. &amp;#x200B; This is a case of [XY problem](http://xyproblem.info/). If you elaborate on the problem you're facing, you'll have better chance of receiving useful pointers.
Don't get me wrong, I am not defending actors vs any library or anything, but I wish the points you are making would be more balanced than just throwing a line in the wild at the end of the conference. It would make your point clearer and everyone would benefit from it
&gt; All of these things TARGET JAVA because java is a bigger user base and because there are more Java devs in the world. This is 100% wrong. All of Play, Spark and Akka have audiences that use them mainly from Scala. All of them use ADTs, which alone absent any other feature are a reason enough to use Scala. All of them use typeclasses - Akka for HList processing in their DSL, Play has a functor hierarchy, and all 3 of them use typeclasses for codecs. Akka also uses quite a few implicit conversions, Play provides traits for usage with cake - which is a Scala-only pattern. &gt; I could be wrong. Ask yourself this question: if scalaz/cats/monix/shapeless ceased to exist, would you use Scala? Emphatically yes. Even if I didn't rewrite them and had to switch away from pure FP style, "better Ocaml on the JVM" is still a fantastic deal, far preferrable to struggling with Eta for example. The answer is the same for the 95% of the community who never even used or heard of these libraries and just write Play or Spark.
IMHO Java+Spring is never an option, because it's insane. I don't think any most awful Scala code can be as comparably insane as what goes for 'the usual' in Spring. &gt; Our modifications are that we use implicits for DI to avoid having to include Spring [distage](https://izumi.7mind.io/latest/release/doc/distage/basics.html#tagless-final-style) might suite as a better alternative to Spring for tagless final apps than implicits, esp. if you need to manage global resources or want to share modules between applications.
Whoops, first post on Reddit, something went wrong
Thanks for filling this in, I somehow screwed up with the upload
No, the Scalaz actor library was more or less equivalent in "transactionality power" to an actor, which is more or less equivalent to `Ref` + `Deferred` / `Promise` in Cats Effect / ZIO / Monix. These are all undeniably useful but their lack of composable transactionality means solutions have to be engineered _de novo_ for the problem at hand, rather than by reusing smaller, simpler building blocks that solve just part of the problem.
Thanks for your feedback. It's good to hear your perspective and I will keep it in mind for future talks! Many of the people I talk to around the world drank the actor cool-aid way back when and ended up with single-node actor subsystems that no one wants to touch. On the flip side, you have several large clustering deployments where actors are adding a lot of value. As with most things, there's no silver bullet (until Unison, maybe :smile: ), but for all the numerous shops out there who inherited single-node actor systems, it's time to explore what functional Scala is offering.
\&gt; As FP scala is the Haskallator (it's not, really, Java has too many good libraries to wrap for that to actually be true) &amp;#x200B; Java is not destiny. Golang has proved that not-Java ecosystems can thrive. Haskell is just as viable.
That's fair. Although I think that re-deploying the application (recompiling) to support a new field/type is acceptable.
SonicPi is cool.
It is. There are far more Java shops than go shops, though, and go has fewer features than Java. Other than Gradle, how many shops use Groovy now? How many JavaScript shops use Coffeescript? So far, nobody has articulated a reason to use Scala as a better Java at an enterprise shop instead of Kotlin / Groovy / Java, which have better compile times, better tooling, more familiar tooling, and almost no controversy on how to structure a program and don't require enterprise developers to learn all that much more than basic Java programming, a standard library, and just a little syntax. Can you give good technical reasons to use Scala over these languages?
My current team has about a dozen developers ranging from new grads to 10 years in industry. Only a couple had any Scala experience before we introduced it in the team. &amp;#x200B; We use an internal style guide, enforced by ScalaStyle, WartRemover, and scalafmt. We prohibit some libraries in our scalastyle config (the IllegalImportsChecker rule). We enforce unit testing with scoverage. We enforce usage of those tools across our monorepo with Gradle -- in the root project, we set up a hook to add all those checks for subprojects. &amp;#x200B; We wrapped some blessed libraries in our own gradle modules and we develop against that internal API. We use a bootstrap script to generate new projects, and the boilerplate code uses that internal API. The generated boilerplate also wires up the application with MacWire, encouraging that as the DI mechanism. &amp;#x200B; It's been about a year and a half since the switch from Java to Scala here. The team is mostly happy with it.
&gt; Modules can be polymorphic over arbitrary kinds - use TagKK to abstract over bifunctors That's nice! I wrote some of that by hand for a project where we had two runtime profiles. I agree that Java + Spring is insane, but it is the familiar way to do things, and I tire of explaining its insanity to devs who just want things to work the way they are used to instead of thinking about how to make them work better. The business case is not easy to make in small crud applications with no real runtime performance considerations, and it is easy to find Spring developers. Izumi-r2 - you seem to be making the case that Scala as a better Java is the way to go. Can you articulate why that is better technically than other alternatives, like Kotlin or Java? What features do you avoid using in Scala and what features do you use that aren't available in those alternatives?
Groovy is reflection city, so that one's out. List of things in Scala but not Kotlin: * macros * scala-logging library inserts isEnabled checks for you * compile-time DI with MacWire. * compile-time JSON codecs with Circe. * async/await with Monadless. * immutable collections that don't expose mutable APIs, unlike Guava immutable collections (which expose mutations and blow up at runtime). * Future and Task-like libraries that are easier to use than Java's CompletionStage in my opinion, and more precise about where things execute. * cheap custom types (AnyVal on a good day, com.softwaremill.tagging otherwise, and opaque types in Scala 3). * custom string interpolators (like sttp's uri"") * compile-time string interpolators. * expression-oriented syntax. * pattern matching. * safer way of dealing with Java nullables in my opinion (I trust Option(javaNullable) more than pinky-promise annotations) * Try and Either in the standard library * data in traits * tagless libraries like sttp, useful even if your in-house code uses concrete types None of that makes Kotlin a bad language. It's great that more people are shifting toward immutability. Scala's just a better fit for my team.
I think you're underestimating how quickly and widely Go is spreading. It's becoming the default language for Kubernetes-deployed services. Haskell being discounted because it's not on the JVM seems like a bad reason.
Have you tried [ScalaCollider](https://www.sciss.de/scalaCollider/)? Something OSC / Sonic Pi based may be your best bet.
Did you use Scala.js bundler?
In that case, you could let the build tool do the job for you through code-generation. With SBT you could create a task that looks at a static URI and parses the data into case classes. Then add this task to the `sourceGenerators` key: https://www.scala-sbt.org/release/docs/Howto-Generating-Files.html
if you are willing to recompile to pick up changes, then why not generate the source code for the classes defined by the metadata?
\&gt; Izumi-r2 - you seem to be making the case that Scala as a better Java is the way to go. We advocate a fusion of OO and FP styles, the classic Scala trademark of "FP for logic, OO for modularity". Although, opinions differ on what is OO and I prefer to think of it as "pure FP with first-class modules" ;) &amp;#x200B; \&gt; Can you articulate why that is better technically than other alternatives, like Kotlin or Java? &amp;#x200B; Pure FP style doesn't buy you anything except referential transparency. Every other feature of Scala also benefits the "better java" style as well, in order of importance for 'naive business code': &amp;#x200B; * Macros. Macros are a huge boilerplate saver, they allow safe, expressive, composable libraries to solve tasks for which Java/Kotlin/Spring would usually employ some stringly-typed unsafe non-understandable bullshit. Any Scala ORM - - is a reason enough to use Scala and they're only possible with macros. * Implicits. Implicits make Scala, I don't think I even have to explain why. All the reasons for why they're good in pure code, apply to 'better java' code – wrangling with effect wrappers is a very small part of their utility. * Better OO. Kotlin doesn't have inner/path-dependent types and doesn't have mixins. The former is vital for modularity, the latter for productivity (in OO style) * Type safety. GADTs, refinement types, singletons, type tagging and most importantly, simple ADTs all let you model data precisely and write robust code absent of noisy defensive programming. \&gt; What features do you avoid using in Scala and what features do you use that aren't available in those alternatives? &amp;#x200B; We avoid nothing in general – we're using and evolving pure FP Scala ecosystem with all that comes attached, but we're also not on a crusade to destroy unbelievers – imperative style is great for many tasks and we all benefit from more Scala users no matter how they write their Scala, I don't want to close my eyes and say that these 80% Play jobs in my city don't exist – even though we're using http4s ourselves, or that out of \~50 visitors to a local meetup only \~5 use cats in production and the rest don't know what is "type class".
To anyone interested in both programming and making music, I can highly recommend the talk Functional Composition by Chris Ford: https://vimeo.com/128467879 It uses Clojure, so sorry for being slightly OT, but it's a really nice talk.
No. I setup Scala.js with Webpack by myself. It isn't complex though. Webpack simply takes the output of Scala.js.
If you want to see good example of functional DDD in Scala, I would definitely look at Functional and Reactive Domain Modelling by Debasish Ghosh and Domain Modelling Made Functional by Scott Wlaschin
Thanks for the mention. From the perspective of more traditionally musical concepts, the embedding of ScalaCollider within [Mellite](https://www.sciss.de/mellite/) might be interesting, as the former is mainly a system for sound synthesis; in Mellite for example, you have a rudimentary [Patterns](https://peertube.social/videos/watch/46e65cde-b459-487a-9884-0f00725e1980) abstraction giving you a functionality similar to patterns in SuperCollider.
I once write a simple MIDI library for Scala: https://github.com/Sciss/ScalaMIDI/ - I don't remember, though, if you can do much more than read in standard MIDI file and play that using the default synthesizer.
Wix Accord does light validation
The directives are all about manipulating the HTTP-level data, the request/response methods, headers, codes, parameters and all that. So you extract the information you care about, validate it, then forward it to your application which can talk to databases or whatever. My only experience with akka-http is with proprietary code, so I can't link it, but making a `Route` is essentially just another function. def route(app: Application): Route = { path("whatever") { cookie("my-cookie") { cookie =&gt; validate(valid(cookie.value), "invalid my-cookie") { complete(app.whatever(cookie.value)) } } } } As just another function, anything the route needs access to can be passed in.
Finagle.
Woah. I think this is smart. I will try this.
I'm currently working on a [Docker client in Scala](https://github.com/bhuemer/docker4s). It's implemented with http4s, circe, cats, fs2, etc. (i.e. non-blocking and with effects) and inspired by the Python API. ```scala import cats.effect.IO import fs2.Stream import org.docker4s.api.Containers.LogParameter._ import org.docker4s.api.Containers.CreateParameter._ import org.docker4s.syntax._ for { _ &lt;- client.images.pull(name = "busybox").compile.drain built &lt;- client.images .build( Stream .emit(Compression.TarEntry( "Dockerfile", """ |FROM busybox:latest |CMD ["sh", "-c", "while true; do echo -n 'This is a test ';date ; sleep 5; done"] """.stripMargin.getBytes )) .through(Compression.tar()) .through(Compression.gzip())) .result // Create a container from the newly built image and run it container &lt;- client.containers.create(withImage(built.imageId.get)) _ &lt;- client.containers.start(container.id) // Follow all the logs from the container (stderr not actually used in this example ..) _ &lt;- client.containers .logs(container.id, stdout, stderr, follow) .evalTap[IO]({ case Containers.Log(Containers.Stream.StdOut, message) =&gt; IO(System.out.println(message)) case Containers.Log(Containers.Stream.StdErr, message) =&gt; IO(System.err.println(message)) }) .compile .drain } yield () ``` Let me know if it could be of any use to somebody and I'd flesh out features accordingly. :)
Looks neat and well done :)
It's possible, but finicky as usual with anything sbt related. Did you set `emitSourceMaps in fastOptJS := true`? ScalaJSPlugin.scala has a couple other source map related keys defined although I don't believe they are necessary.
In principle I agree with you. If I have our developers choose to read an Akka book from Oreilly or "Functional programming in Scala" I know what they will do. However, having a hard time learning Scala monads means spending hours in front of your IDE and starring at red squiggly underlines. Having a hard time learning Akka means lost updates in production with spurious data corruption that goes unnoticed for multiple weeks (e.g. because someone closed over actor state in a future). In my experience, Akka feels very easy and lightweight, which makes it fun but also dangerous to use.
Thanks for your suggestions. I have read the former book by Debasish Ghosh and I really liked the whole "domain models as algebras over immutable values" idea. I was not so keen on the "free monads" part, which appeared a bit too clumsy for something akin to "define a sequence of actions that may be interpreted later". I will definitely take a look into the other book.
&gt; I could be wrong. Ask yourself this question: if scalaz/cats/monix/shapeless ceased to exist, would you use Scala? Yes, yes, a thousand times, yes. It's what I and my teammates have been doing since ~2009. I've written Java off and on since then, and I very much prefer Scala, even without pure-FP libs.
Hi. I was wondering, are all the concepts found in Cats Effect, Monix and ZIO also found in Haskell? I mean, all the type classes like Concurrent, Effect, Async, ...? Thanks.
Hi. I was wondering, are all the concepts found in Cats Effect, Monix and ZIO also found in Haskell? I mean, all the type classes like Concurrent, Effect, Async, ...? Thanks.
Last I heard they may end up being supported after all
You want transform.
With transform, you have to pattern match on the Try. OP's version installs two callbacks, but each is simpler, so I prefer OP's.
As mentioned, you could use transform. But if you're using a lot of `Future[Either[A,B]]`, and really want to step it up, check out [`EitherT[Future, A, B]`](https://typelevel.org/cats/datatypes/eithert.html)
What you're doing is fine, you can make it into an extension method it you're using it often or want to increase clarity.
Not a direct solution but checkout \`attempt\` form cats: [https://github.com/typelevel/cats/blob/master/core/src/main/scala/cats/ApplicativeError.scala#L65](https://github.com/typelevel/cats/blob/master/core/src/main/scala/cats/ApplicativeError.scala#L65)
I view them as worthwhile for the same reason that `_` is: it's such a common case and it saves so much code on aggregate. I don't like special cases in general, but sometimes they're common enough to be worth the learning overhead.
I've built several (well, actually using the predecessor spray-http), but all proprietary. I'd say it's not only usable but the most practical way of building web APIs I've ever found. You can compose together existing directives to build your own, more complex or domain-specific directives. (You can even use `for`/`yield` if you stick to `Directive1`s). So e.g. you could write a set-cookie-if-doesn't-exist directive in terms of the lower-level set/get directives. It ends up being very compositional and amenable to writing all these tiny reusable/testable one-liners, and building the application up out of that.
Just to be aware, the benefit of using EitherT instead of Future[Either[.. is so you can more easily use them in for comprehensions.
I think this may be an anti-pattern. Future already encompass the chance of unexpected failures in its Try-result. What you're doing is effectively lifting that failure to an Either, but there is no way to tell the Future that all unexpected failures are handled so you now effectively have a Try[Either[X, Y]], which semantically expands to 1. Success(Success(y)) 2. Success(Failure(x)) 3. Failure(Unhandled exception)
I don't really think this is an anti-pattern. Cats IO has `attempt` for exactly this use case.
Have you considered using cats IO or monix Task? They have methods that can return a wrapped Either or Try for exactly this case.
\&gt; where a Left means expected errors The main advantage of Either\[Error, A\] is that throwing exceptions has some performance overhead. Throwing an exception should not be used as a way to communicate information up the stack. This is ofc still sometimes done, and you have to work around it, especially in code you have no control over. In those cases I think its completely fine to pass the information-exceptions into your Either by doing something like the snippet OP sent (or using some other library to do it for you). So yes and no, it definitely can be an anti-pattern.
 I need to execute JavaScript in HTML responses. I am using sttp version 1.5.12. According to the documentation I just need to include implicit val sttpBackend = FetchBackend() but it's not working. See documentation at : [https://sttp.readthedocs.io/en/latest/backends/javascript/fetch.html](https://sttp.readthedocs.io/en/latest/backends/javascript/fetch.html) Already included the dependency for Maven. &lt;!-- https://mvnrepository.com/artifact/com.softwaremill.sttp/core --&gt; &lt;dependency&gt; &lt;groupId&gt;com.softwaremill.sttp&lt;/groupId&gt; &lt;artifactId&gt;core_2.12&lt;/artifactId&gt; &lt;version&gt;1.5.12&lt;/version&gt; &lt;/dependency&gt; Example: import com.softwaremill.sttp._ implicit val sttpBackend = FetchBackend() I expected to use this like the other supported backends. Eclipse reports not found : value FetchBackend Any help is appreciated.
They are not equivalent. IO (with `.apply(…)` or `.delay(…)`) delays an expression which may or may not throw an exception as it runs. `Future.apply` on the other hand always reifies exceptions into a `Try` through the `transform` method: https://github.com/scala/scala/blob/v2.12.3/src/library/scala/concurrent/impl/Promise.scala#L27-L31 So a Future always wraps a `Try` value while an `IO` is simply a delayed expression of some type. IO needs `.attempt` to lift potential exceptions to the surface while you Future keeps them readily available as part of its state. The anti-pattern here is eagerly recovering a failed Future into a `Future[Either[Throwable, X]]`; expected errors in the form of exceptions can of course be recovered to a Left of some non-exceptional type.
Future already does that for you: It wouldn't be possible to recover from an exception if it was allowed to bubble up the stack. As an aside, the expensive part is **creating** the exception; recovering it into Left won't avoid the cost.
Yea, like i would not create an exception if i was not going to throw it. What I was trying to get at was that if you have Either\[X, Y\] as a result of some function, it would be better if X was not actually Throwable, because of the overheads. But if that function has to catch some exceptions, you are not left with anything else than somehow wrapping that exception in X.
.attemp on the cats thing. That works.
Can you try creating the case classes customertype and customertypenumber with one field, string and int respectively, and include that in the definition of Movie? Customers: Seq[(customertype, customertypenumber)]
It's definitely possible, but requires jumping through a couple hoops to get it to work while maintaining build performance. You can take a look at the config in [create-react-scala-app](https://github.com/shadaj/create-react-scala-app.g8/blob/master/src/main/g8/webpack/fastopt-loader.js), which has full source map support, for an example.
I tried this tonight and couldn't get it to work. &amp;#x200B; I can see that the kernel gets setup with coursier and defined by looking around with %%shell cells. I can also see that java is installed (I even ensured that it was by doing an !apt-get the way the [spark example notebook](https://colab.research.google.com/drive/1EcotODzgSnLozSH3hDuBfZr06gJXY8I0#scrollTo=fUhBhrGmyAvs) does). Then... I restarted the instance using the Management trick. Then... after waiting for the reconnect, I try making a cell with just a println in it, and it fails to run. Note: I didn't make a new notebook or anything, I just added a cell to the Scala Install notebook. &amp;#x200B; So, sorry for being dense, but what did I do wrong? &amp;#x200B; TIA!!!
Okay... the seque that I missed is that after you run the "install script", in that same tab/window I have to open a new notebook. In my case, I save your examples to my drive and then open them in colaboratory from there. Makes sense, the newly loaded notebooks specify the metadata/language\_info for scala; whereas the old ones were still python. &amp;#x200B; THANKS so much, I'm looking forward to working through the rest of the examples.
Thank you for a working example. This is what I need. I'll take a look and report back.
Looks good, thanks for sharing! &amp;#x200B; I'll give it a try with this template I've created sometime ago, it's been a PITA to maintain it. [https://github.com/gvolpe/typelevel-stack.g8](https://github.com/gvolpe/typelevel-stack.g8)
&gt; Your scala incremental builds take orders of magnitude longer than your java builds, and you aren't getting more compiler verified code than you would in Java, you aren't getting more modular code than you would in Java, and you aren't really reducing boilerplate any more than you could reduce it by using Java with vavr or Kotlin. Orders of magnitude longer than irrelevant is often still irrelevant. Code is read much more than it's written; even a small gain in conciseness/clarity is well worth any compilation time penalty. Case classes alone are ample reason to choose Scala over Java. Better libraries for basic validation (or heck, even stdlib `Either`) are ample reason to choose Scala over Kotlin, and while it's the higher-order FP abstractions that lead to those libraries being available, you don't have to be working at that level to be able to make use of its fruits. (And for what it's worth, I have less faith in Kotlin's ecosystem or maturity than Haskell or Eta; it certainly doesn't have "20 years of production code" to argue for it). Frankly I find attitudes like your post the most damaging part of modern programming culture. If you drive programmers away from using languages in which better things are possible because they don't understand or appreciate those better things today, how will anyone ever learn that those things are better (or even that they're possible)? To the extent that there are productivity problems we should certainly fix them (though I've never known the kind of codebase you're objecting to to have issues with Scala compilation times; on the contrary, it's those that make heavy use of Scalaz/Shapeless/... that tend to have the biggest complaints). But it's absurd to say that we should reject those who want to make their code a little more concise, a little more understandable, a little less defect-prone. Perfect is the enemy of good.
&gt; You could do the same thing in Scala with Spring, but they end up cutting themselves. I agree that this happens, but posts like yours are exactly why! If we as a community could stop telling people they have to use scalaz and final tagless and everything from day 0, and be helpful and supportive to those who want to write a basic Spring CRUD webapp using mostly the same techniques that they're familiar with, we'd have a Scala that was a straightforward improvement over Java in every use case. Too often we put the cart before the horse when promoting the fancy techniques. Scalaz, final tagless etc., are tools to make it easier to write clear, understandable code - plain old functions and values. Sometimes you hit a point where you need a complicated technique to achieve that, but the technique should always be seen as a means to an end, not an end in itself. Often with a little more thought and effort it's possible to achieve the actual goal - plain old code, simple values, single-purpose function - without needing the advanced technique at all. But the way we talk about these techniques leads to people cargo-culting them without understanding what they're intended for, and that's even more damaging in the long run. A complex layered interpreter structure being used to implement a straightforward function is a much bigger problem (in terms of the effect on readability/comprehensibility/maintainability) than an uncontrolled exception or mutable variable.
So I've been looking into this. I found [this GitHub repo](https://github.com/dmitriy-yefremov/scala-code-gen) that seems like it outlines a few different ways to do it. I'm not sure I understand once the code is generated...how do I actually *use it* in a program?
You should be able to work with the generated sources like if you'd written them yourself. If you're using IntelliJ you probably want to add the directory with the generated sources to your source path, so it discovers them, but everything should compile either way.
Where is the best place to land a remote work in scala?
I think this is a very important concern, and I learned a few things going through the answers so far. I'll try to add my two cents here. I worked on a few Scala-only teams, usually 4-5 people, out of which 1-2 would be senior Scala devs. We never had a formal style guide, but we had several discussions and never moved to one. Perhaps tooling is better now, but at the time scalastyle was not very good. I don't regret that decision. Code reviews were the best way to enforce a relatively common coding style across the team. Syntax is usually the easy part, while the level of abstraction indirection, choice of libraries is by far the biggest and hardest to get right. If there's an existing code base, people will usually try to follow the same conventions anyway, but code reviews can help make sure it doesn't strain too much. They are time consuming though, and can be taxing on both sides. There is no easy way out, and code reviews *have* to be taken very seriously by the reviewer. Less experienced engineers are more prone to "learning on the job" and need more guidance not to try to apply their new discovery for everything. I found that senior engineers, even without prior Scala experience, are very good at picking up the existing style and staying close to it. Scala may exacerbate an existing problem, but I'm pretty sure the same kind of "decisions for the sake of an indvidiual's intellectual development" can show up in other languages too, and is more a question of experience than anything else. Juniors will likely make more mistakes than senior devs, regardless of their Scala knowledge. What to do when there's no existing code-base? I would certainly set time aside for jotting down some high-level guidelines: - pure FP (referential transparency, effects tracking, etc)? - choice of technology. Akka? Slick? Play? Spark? http4s? etc. etc. They will likely steer you towards a coding style already - asynchronicity everywhere, at boundaries or nowhere? - mutability: never, encapsulated, YOLO? - a strategy for dealing with errors - a strategy for logging Probably the first choice will greatly reduce the scope of the other points. In my experience the biggest disagreements evolved around asynchronicity and mutability. There's a natural tendency in engineers who care about their job to learn new things and try them out in the wild. A good team lead will have to manage that, Scala or no Scala involved.
Metals really sucks right now. The language server crashes all the time, completions don't work for multiproject layouts (multiple repos with unique build.sbt and multiple builds in each project.). Also there are tons of asinine configuration that has to be done just to link one build.sbt. I'll stick with intellij that figures all this out in one click. Maybe in 7 years metals will be good enough to compete with intellij .
Nice presentation. How does the performance ZIO STM compare to other Java STM implementations (I believe there exists quite a few), and also how does the performance of your semaphore, promise and queue examples compare to other existing Java/Scala implementations?
Looks promising. I will give it a try tomorrow at work to see how it performs
Just to balance your view, I’ve really not had this negative experience - albeit with single project layouts. Personally I find IntelliJ has loads of extra bloat that I don’t want but perhaps you’re more accustomed to the full IDE thing.
Metals has been life changing for me. Works really well for me. It has got me doing proper scala development work on an ipad so totally life changing. &amp;#x200B; Also as a recommendation try it in conjunction with tabnine (even the free version) for the most awesome experience: &amp;#x200B; [https://tabnine.com/](https://tabnine.com/)
I imagine you can optimize for certain cases, eg. if you know you have a lot of calls to Show[Option[Xyz]] you might assign that specific insance to a val in an object. But I assume you have more than one case of such typeclasses, which makes the process of optimizing very tedious I assume. And obviously, it would be nicer to have a general solution. Other than that I don't have any ideas.
It's a very new project. It's unreasonable to expect the same feature set as IntelliJ. However, they seem to be moving really fast with new features
Is it possible you could give a Scastie example of how this would work? I couldn't make it compile. My use case is similar to: class Foo[A] { def convertToInt(a: A): Int = Convert.convert(a) } val listFoo = new Foo[Circle]() // How to summon Convert[Circle, Int]? listFoo.convertToInt(Circle(radius = 1.3))
I would love to move away from the bloat of IntelliJ, but there are still a few features not in metals yet that I can't live without. For example automatic imports. That's not much but having to add them manually (and so remembering all the namespaces) is kind of a pain.
Yeah that makes sense, I guess we have different use cases. For me metals has been really transparent to use - it largely just works (while recognising it’s still under a lot of development). Now for example it has hover types which isn’t a thing in IntelliJ (or at least not by default if it is possible). For me that’s a winner straight away! Also metals supports auto imports!
I don't think so, not in the nice bit of the language. You could write a wrapper which checks some internal mutable state for a list of pre-made instances. If it finds one, it returns it. If it doesn't, it creates one using your above method, and then adds it to the list, and then returns it. But doing that would require indexing the list somehow with 'B', so would involve class names and limited reflection. I don't think there's a way to filter a `List[Show[_]]` by the internal type due to reflection.
IntelliJ IDEA has a plugin for Bloop too: https://scalacenter.github.io/bloop/docs/ides/intellij
Could supporting this at the compiler level be something worth considering for Scala 3? As a human I know that these typeclass instances are constants, yet they are recomputed each time. I'm writing a game in scala and need every bit of performance I can squeeze, especially on basic stuff like using typeclasses for extensibility. The reallocations from redundant typeclass instances are so punitive for my use case that this language feature may as well not exist.
It is already fixed by the typeclass derivation support in Dotty. The infrastructure might change a bit until it gets frozen for Scala 3 but I do not expect that aspect go change.
Wow, I need to check that again.
How do you do auto imports?
https://scalameta.org/metals/docs/editors/overview.html Should just work - which editor are you using?
Try this: [https://scastie.scala-lang.org/isvZvvybQKGgQZibdaNpcg](https://scastie.scala-lang.org/isvZvvybQKGgQZibdaNpcg) Good luck :)
There is also [Scala STM](https://nbronson.github.io/scala-stm/) which doesn't aim to be a copy of Haskell syntax. It's quite performative and works very well, I have used it since many years and can highly recommend it.
I'm using VSCode. I'm actually not talking about build import, but the adding for example "import scala.util.Success" automatically. Typically if I use a symbol that is not imported, the editor will red-line it (because it's a compilation error), and when I hit a hotkey on the error the editor should show me a list of candidates within my build, and insert the "import \[...\]" line corresponding to my choice on the top of my file.
I've made the switch myself. I consider ensime to be superior featurewise, but it's not maintained and it has started crashing in my project, so I have had to switch to metals. Still, metals _is_ good, and it is getting better which is what matters.
Very interesting. What editor are you using on an iPad? I've thought about doing programming on a tablet but never tried.
Thank you!
If you don't have medium membership, please use the following link: https://itnext.io/functional-reactive-programming-in-scala-from-scratch-part-1-9f9db0c47478?source=friends_link&amp;sk=33c0d75a23418beb8df0c2ce90adbd4c
I too would like to know more about your iPad setup!
Right we are using EitherT[Future, A, B] a lot. Still with many libraries out there, they use Future so we have to map that into a Future[Either[...]] which can then be put into EitherTs
Scala is a very interesting programming language that fuses Object Oriented Programming with Functional Programming (where programming languages like Haskell are a clear influence). This fusion of styles, although powerful, can be a source of confusion. For me there were two reasons: 1) there's always the OOP and Functional way of doing this and 2) most of the Functional Programming concepts are disruptive in regards to my Java background (all I learn at University was LISP and Scala seems to be more influenced by Haskell). However, Functional Programming is gaining a lot of traction in our industry and Scala has a lot of commercial adoption and fairly decent tooling, which makes it a great language to learn. Moreover, Scala has a lot of interesting concepts, like Type Inference. Compared to Python, Java is very verbose, as you need to declare the type of every variable. This gives us type safety, but it's quite boring. Scala can infer the of a variable based on the value you give to it, so it kind of feels like Python when declaring variables. Another interesting thing about Scala is that it is fairly popular in the Data Science world. Possibly because of Apache Spark, but to be honest this is far from my area of expertise :) Anyway, I really, really like Scala and I wouldn't see myself going back to Java and the Spring framework again. It changed the way I approach my code, specially after reading (and doing the exercises) of the "Functional Programming in Scala" book. Obviously this is a very simplistic and very personal overview, so make sure you keep an eye on this thread for other opinions ;p
thank you so much for the in depth reply, this was a good explanation of it!
Yep, this increases productivity so much any time I try another editor I'm ugggghhhh without it because I've gotten to the point now where I \_expect\_ it Also love when you hit a certain import count on types intellij is just like you probably need \`import package.\_\` which you can toggle off if you're worried about namespace issues. Also the implicit support in 2019.1 is \_a lot\_ better now which gives me less reason to switch. We use gradle as well and not sbt, have yet to find anything that handles auto imports as well as Intellij for gradle. Not to mention on the paid version of Intellij you can create configs from gradle tasks. Literally 2 clicks + enter you can start debugging tests with your new run/debug configuration. Idk, Intellij provides so much "make my life easier shit" I could give fuck all about bloat. I guess part of that is im on Linux with a 2700x and 32gb of ram so bloat doesn't really matter to me. I guess if you're resource restricted on your hardware the bloat matters
Yes, I was aware of it. It doesn't seem to promote functional programming though. Most of the examples make extensive use of side-effects ([https://nbronson.github.io/scala-stm/syntax\_cheat\_sheet.html](https://nbronson.github.io/scala-stm/syntax_cheat_sheet.html)) including the creation of a \`Ref\` which should be encapsulated in an IO-like type.
That looks awesome!! I was just looking for a Scala docker client today! And on a side note how do you like using Gradle?
What does 100% remote mean to you? Are you looking for a remote company (w/o a central office) but would be willing to do non Scala work? Or would you want 100% Scala but not 100% remote?
Why? How can introducing a new keyword as common as given be a good idea? This will break people's code.
Very excited for this, although not having the ability to run the program through the IDE is a blocker for me. I don't need a debugger connected; just the ability to run the program through a warmed up a build server is enough. I could keep an sbt session running in a terminal and use that for running the program, but that will probably trigger a recompilation.
what pay range are u looking for?
&gt; It doesn't seem to promote functional programming though No &gt; the creation of a `Ref` which should be encapsulated Why? A `Ref` is transparent, there is no side effect in creating a `Ref` (other than a `new`).
My company's currently hiring. Ping me your CV and I'll send it through to HR.
We're working on adding the ability to run main and test from the editor, see https://github.com/scalameta/metals/issues/652. Feel free to share your thoughts on how this feature should work if you have specific ideas. For example, we have recently discussed in that issue how to handle System.in and cancellation.
If you're happy with IntelliJ then that's great! Metals is still missing a lot of common IDE features and we recommend IntelliJ in the linked post for people who rely on those features https://www.scala-lang.org/2019/04/16/metals.html#future-work &gt; completions don't work for multiproject layouts That sounds totally fixable and is tracked as a feature request in https://github.com/scalameta/metals-feature-requests/issues/14 &gt; tons of asinine configuration that has to be done just to link one build.sbt Can you elaborate on this? What editor are you using? For VS Code, the experience should be close to single-click to import an sbt build. We have made several design decisions to actively reduce user-facing configuration.
The "add missing import" refactoring is indeed missing and I'm hoping we can ship it with the next v0.6 release. We already have most of the components to implement the refactoring. A workaround until then is to trigger a completion on the compile error like here https://imgur.com/a/cWBFKNd
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/iet2Bhl.gifv** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme)^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20el95uxq)
That's what's working for me in VSCode (although annoyingly currently it imports them local to the import context (i.e. not at the top of the file). Maybe you have an old version of metals? And there's an issue to fix the local importing in the milestone for the next minor release: https://github.com/scalameta/metals/milestone/8
And a LOT, if not most tests as it's a part of one of the more common ScalaTest specs: http://www.scalatest.org/getting_started_with_feature_spec
Then comment on the proposal!
&gt; Why? A `Ref` is transparent, there is no side effect in creating a `Ref` (other than a `new`). This is where most people get it wrong :) You might wonder why the `Ref` implementations in both [cats-effect](https://github.com/typelevel/cats-effect/blob/master/core/shared/src/main/scala/cats/effect/concurrent/Ref.scala#L158) and [zio](https://github.com/scalaz/scalaz-zio/blob/master/core/shared/src/main/scala/scalaz/zio/Ref.scala#L142) return something like `F[Ref[A]]` instead (its creation is suspended in `F`). TL;DR the `Ref` needs to be suspended in `IO` so when you `flatMap` on it you create a region of sharing that is sealed and you can verify its behavior by performing substitution and check that referential transparency is preserved. Such is not the case if the creation is not suspended. Fabio Labella gave a great talk on the topic: - Video: https://vimeo.com/294736344 - Slides: http://systemfw.org/scala-italy-2018/#/ Happy FP coding! :)
I think that we're hiring here at Yoppworks currently, which is a mostly-remote company HQ'd in Ottawa, Canada, with clients across Canada and the USA. https://yoppworks.com/
Bottom of the article states this: &gt; Implementation Status and Timeline &gt; The Dotty implementation implements both old-style implicit parameters and new-style given parameters. In fact, support for Scala-2’s implicits is an essential part of the common language subset between 2.13/2.14 and Dotty. Migration to the new abstractions will be supported by making automatic rewritings available. &gt; &gt; It is planned to deprecate and phase out old-style implicit parameters in a version following Scala 3.0. The precise timeline will depend on adoption patterns. So it sounds like they have a plan to support both and slowly migrate people over to the new syntax.
This may be an implementation requirement of the STM library you are using, but I can assure you that in Scala STM, creating a Ref is transparent; it takes the initial data cell value and starts off with a meta of `0L`, and that's it.
Honestly, I would rather learn Haskell than Scala for a "pure functional programming" language. However, considering the job market in my country, and the fact that Scala can use many interesting libraries from Java for free, I decide that eventually I love Scala more
UPDATE- this was very helpful. Turns out my problem reduces to traits not taking parameters in Scala 2: https://dotty.epfl.ch/docs/reference/other-new-features/trait-parameters.html Problem: https://scastie.scala-lang.org/HJWijsm9TSqzqXkLBmsL3g Solution: was able to turn my trait into an abstract class and use your instance specialization examples. Thanks!
You're talking about two different things :) The `Ref` I linked has nothing to do with transactions but still the concept of sharing state applies. Same with `Deferred`, `MVar`, `HttpClient`, etc. For the transactional `Ref` there's this thing called `TVar` in Haskell's `stm` and `TRef` in `zio-stm` (the T stands for transactional). And again, look at how its creation is effectful and returns an [STM[Nothing, TRef[A]]](https://github.com/scalaz/scalaz-zio/blob/master/core/shared/src/main/scala/scalaz/zio/stm/TRef.scala#L118). That's because creation of mutable state *is a side-effect* and must be suspended. If you remained unconvinced after watching Fabio's talk I don't think I'd be able to explain it better. But probably watch it again knowing it's not talking about STM ;)
Nice! So what's the shortcut? \^Space is supposed to trigger completion but it doesn't do anything here.
Thanks! It's still all very much work in progress, but nonetheless already useful. I'm mainly using it in integration tests of other projects where I'd just like to dynamically create Docker containers for the various bits and pieces I'm testing and then seeing how they respond (in fact, a lot like how the library itself already uses integration tests to verify its own correctness: e.g. [ImagesBuildIntegrationTest.scala](https://github.com/bhuemer/docker4s/blob/master/docker-client/src/it/scala/org/docker4s/api/ImagesBuildIntegrationTest.scala)). Aiming to push a snapshot release to a Maven repository in the next few days so that it's easy to play around with it a little bit. On the Gradle question, I'm very happy with it for the time being, but at the same time I haven't really addressed / thought too much about cross-compilation for different Scala versions, etc. I might switch to SBT at some point, but at least in the beginning I was / am quite happy with Gradle, escpecially because it makes it so quick to resolve dependencies and re-generate projects. A few days before I started on this I also poured way too much time into trying to make SBT's integration test sources be aware of test sources (to re-use some test helper code) and that had probably left me primed to try something else .. anyway, not particularly wedded to either.
So my goal is to switch out the exception with my case object. It looks like attempt is close but I'd still have to left map to my case object.
My goal is actually to switch out the exception with my case object so while cats `attempt` is close, I'd have to still left map to my case object.
Looks nice but I'd have to still left map that Left(ex) into my case object (so Left(myCaseObject))
Would love to work in Sydney. Can I send my resume too?
&gt; How can introducing a new keyword as common as given be a good idea? Is your argument that common words shouldn't be keywords? &gt; This will break people's code. You can't make an omelette. Also Scalafix.
Ctrl+space is the default shortcut to trigger completions in VS Code. The cursor needs to be inside the identifier to get it working. Either way, "add import" code actions will be added soon enough...
The usual case is for backend programming and nowadays it's all about http and Rest stuff no matter the language you choose. Regarding the language itself it's very very big and it's surface and edge cases are too many. You can spend more than a few years on it and still keep learning new weird things to do with it. At least you can't be bored with scala in that aspect. But I'd say eventually at the end of the road one becomes so very frustrated with it since you will spend half of the time discussing and hqving to choose between the OO thing and FP. So it's an interesting journey until it isn't anymore. At least it's supposedly to be one of the more high paying languages you can be involved with. Not that has actually come for me yet.
Patiently waiting for the ELI5 version here in the reddit comments :D
We are actively hiring at my company. ([http://citrine.io](http://citrine.io) | [https://citrine.io/careers/#senior-backend-software-engineer](https://citrine.io/careers/#senior-backend-software-engineer)) &amp;#x200B; Though we usually don't care about specific language/framework experience, your experience could come in very handy as it fits right in. We are very remote-friendly (if not remote-first), barring me everyone on the team is remote within US/Canada. &amp;#x200B; In terms of business, we are building a platform that would empower scientists and engineers to discover, experiment with and create the materials and products of the future. Using our platform, scientists at Fortune 1000 companies have developed new materials that enable improvements from longer battery life to more efficient solar technology. &amp;#x200B; Feel free to DM if I could provide any more details.
I made a recoverToEither extension method for this that just does (with cats) .attempt.leftMap. I also did a recoverToLeft in case you already have a F[Either...] that we use internally.
This is a good idea. I'm surprised cats doesn't have something like this built in already!
I'm know I'm in the minority, but I personally think as long as the compiler can catch it, it's okay to have breaking changes... The build tools all let you lock down the version of scala you want to compile with.
We are hiring, the founders are based in SF, but engineering is remote. We have a small team, we do functional programming, and scalajs to boot. &amp;#x200B; dan AT goodcover dot com
I remember interviewing with John Snow Labs couple of months ago or so - they were looking for remote Scala developers to work on their NLP library: https://github.com/JohnSnowLabs/spark-nlp Maybe try them out?
Thanks for the pointer. I don't know enough protocol details to discuss implementation level ideas. But at a very high (and perhaps naive) level, I imagine that "run" could be treated like any other build task. As you mentioned, if std-in and cancellation are supported, supporting run (or any build task in general) should become feasible. I am not too concerned about the UI, especially since I am interested in the Vim frontend. All I need is an API and I can then bind it to a key. The only complexity would arise when a debugger needs to be connected to the task's process, but then, that's not a blocker for me.
Aside, can I use bloop cli to execute the project, without loosing speed due to warm-ups, recompilations, etc? If that works, that is good enough for me!
Make a RSS reader. It's not that complicated and allows you to work with different libraries and aspects, like network, DB.
Interesting, thanks for help
Hey, any interest in particular? Looking into FP? Actors? Web? An easy one is often grabbing a website, and building a copy. In your case, it could be creating the API. You could also consume APIs. GitHub has a good one. Build a client for it, and write a scoreboard for scala repositories. You could sort by PRs, issues, commits,... Based on the amount of data, you will need to be smart about it. You could build a game. Minecraft was/is built in Java. Start easy with snake, or pong, and move up. If nothing jumps at you, there is exercises.com (or similar). It has a bunch of coding challenges. Good luck
Thanks for your suggestions, it really helps me
If you install the Bloop cli and restart Metals then it will automatically connect to your running Bloop server. That allows you to run/test from the terminal using the same Bloop server that Metals uses for compilation/diagnostics. In the upcoming Bloop v2 release the deduplication of compile requests from Metals and the Bloop cli is greatly improved.
You should already be able to bind Vim shortcuts to run and test using the Bloop cli. The linked issue is on adding a “run” button above main function using LSP features to avoid the need for custom user configuration/shortcuts.
Cron is very, very mature, as are the practices for using it. What is it missing for you that airflow has? Airflow can invoke Scala and spark submit.
The DAG system in general and the UI. I do not think you can seamlessly establish dependencies between ETL jobs with Cron as you can with Airflow? Oh wow, do you have any guides on it? I genuinely cannot find on the documentation.
If you’re doing airflow right, there shouldn’t really be any business logic written in python. A lot of people really break separation of concerns pretty badly when they construct DAGs.
Airflow solves a lot of problems that cron does not (at least not vanilla cron). Dependency management is one of the most important for data workflows: “don’t run this job until these two other jobs have run successfully, and keep track of that on a per-hour basis”. It also provides “operators” for common tasks like “run this spark job” or “execute this Postgres query” (it kind of over-abstracts imho). The web ui is also pretty useful for users that aren’t systems-savvy. I.e., the engineer who has never used the command line (who does exist no matter how hard you want them not to or how hard you try to train people) can just click “rerun” and re-run a job without risking screwing something up. I’m not saying you should always use airflow instead of cron. Personally I have a lot of criticisms of airflow, but it’s widely adopted so it’s hard to avoid. They’re just different tools that solve different (though sometimes overlapping) jobs.
Yeah, to be clear; you'll write your _dags_ in python, but your spark jobs can be in whatever language you like. We use airflow to run spark jobs written in scala. As for writing airflow dags in scala, I haven't heard of anything like that; I think you'll just have to bite the bullet and use python.
And honestly you should probably become comfortable with using Python; a data scientist who hates python is going to have trouble enjoying her work, I'd think.
You can use a BashOperator to run spark-submit. Or anything really.
This is a library that was shared here a while ago. It might not be production ready and I don't know if it's maintained. I think the idea behind it was to keep a spark context between jobs. https://github.com/KenSuenobu/scattersphere
[Spark Submit operator](https://airflow.apache.org/_modules/airflow/contrib/operators/spark_submit_operator.html)
I have Linux VPS/Node with [Linode.com](https://Linode.com) where I am running ubuntu Linux. I use an app on the ipad called Blink Shell to connect to my ubuntu VPS where I just use neovim for all development. I have access to all tools like SBT etc of course as its a full Linux OS. &amp;#x200B; Blinkshell supports mosh so you session is not lost when you switch apps on your iPad or walk away for a while. &amp;#x200B; It works really well. Especially loving the fabulous battery life compared to any laptop I have ever used. &amp;#x200B; I also have a really nice feature rich git client app called working copy which i highly recommend also. I use it for cloning repos and reading code mostly but really useful. It has a simple editor for making changes to repo and committing too. &amp;#x200B; Let me know if you have any other questions. &amp;#x200B; Some links for reference: &amp;#x200B; [https://www.blink.sh/](https://www.blink.sh/) &amp;#x200B; [https://workingcopyapp.com/](https://workingcopyapp.com/) &amp;#x200B; [https://kapeli.com/dash\_ios](https://kapeli.com/dash_ios) (I use this for docs - IOS version is free) &amp;#x200B; [https://gocoedit.app/](https://gocoedit.app/) (I have this but never use it :-) Its like sublime text and has syntax highlighting for a lot of langs.) &amp;#x200B; [https://arslan.io/2019/01/07/using-the-ipad-pro-as-my-development-machine/](https://arslan.io/2019/01/07/using-the-ipad-pro-as-my-development-machine/) (my setup as simple as I outlined above ... this blog has a much more sophisticated setup than me :-) ) &amp;#x200B; Thanks!
I think that's quite a statement. There's nothing you can do in Python you can't do in R in a much seamless, streamlined and more concise way. You can look at that just by comparing the Tidyverse to whatever Frankenstein packages Python has.
My rule of thumb is that if the new function does not require access to any of the surrounding context (parameters of the outer function or previously declared local variables) then it should be its own separate function, not locally defined. Unless there are side-effects (like changing a local \`var\`), it's always possible to convert a locally defined function to a standalone one by passing as parameters anything that it would have otherwise captured, but sometimes relying on those captures makes for code that is more convenient to use or easier to read. So it's only at the point where I gain something that I prefer a locally defined function; the number of callers makes no difference to my decision. If I really only want it called by something locally, I'll make it private. There may be some more esoteric and rare reasons to use a locally defined function, like when you need some slightly different bytecode generated or have to influence an optimizing compiler (scalac or the JIT) to decide what should be inlined, but that is absolutely not something most people ever have to consider.
[removed]
I do it all the time
Your question doesn’t really make sense, what scheduling framework you use should have no effect on whether you use Spark through Scala or Python. Your business logic should be separated from your scheduling code. Unless there’s something I’m not seeing...
https://github.com/franklinchou/macro-fiddle/tree/first-cut ^ I took a crack at it here (based on the github/blog post credited above). It definitely parses the schema fields but it doesn't look like I can use the case class generated. Or at least the compiler is having trouble finding the generated case class?
No, BDD is about specifying behaviour as it brings value to a stakeholder. When you describe it from an infrastructure point (Kafka, a database or any other piece of infrastructure) of view or from a technical (the most common of this one is the “as a developer”) point of view you’re not doing BDD. These are anti-patterns which will end up driving your code from infrastructure or from technical decisions rather than behaviour. One of the biggest benefits of BDD is the abstraction you get from infrastructure, by using a piece of infrastructure as your actor, your architecture doesn’t become abstracted from it, quite the opposite, it leaks into your domain and becomes tightly coupled with your domain.
Do you have example code?
Yes, i also made a stackoverflow post: https://stackoverflow.com/questions/55779131/can-a-scala-type-class-have-abstract-type-members If that's not sufficient i can supply the full project, but it's not really much more than that.
Hm, so you basically need memoization (easy) but for types (uuuuh). Perhaps you could obtain a value for type `B` that you would use as a memoization key. Maybe you could make use of `ClassTag` / `TypeTag`, or alternatively require some kind of `MemoizationKey[B]` which would be an `implicit val` that you would share across multiple `implicit def foo[B: MemoizationKey]` methods. You'd need to create a val for every `B` that you need, but that's once per `B` for your project, not once per `B` per `implicit def foo[B]` method. And well, you'll need to implement memoization itself, but that should be easy now that you have values to use as keys. This is probably not exactly what you were looking for, just my 2 cents.
Odd, I pasted your code to Scastie with minor tweaks. Seems to compile fine: https://scastie.scala-lang.org/1ikTCUJPQrmO2Z80LeNriA Perhaps I missed something.
You can't test locally defined functions properly, right?
Could be that you are using the macro in the same project that defines it. Macros should be declared in their own "compilation run". If not, what errors do you get?
The point is that I dislike writing Python, but it's easier to manage the code if everything is written in one language. Especially if our "Data Science" team has only two people, which are absolutely overloaded with work, so any reduction in complexity would be great.
One of the reasons to prefer local functions is to make them unavailable in surrounding scopes. e.g. lihaoyi in ["Strategic Scala Style"](http://www.lihaoyi.com/post/StrategicScalaStylePrincipleofLeastPower.html#dont-over-engineer): &gt; If you're not sure whether a one-use-helper method will need to be re-used in future, nest it inside the method that uses it so it can't be immediately re-used. This extends to other areas as well - If you don't immediately reuse something, make it private. If you don't immediately extend, make it final. It will be much easier to read, refactor and delete code that's obviously inacessible outside, you wouldn't have to check "Find Usages" before you do something with it, and when you do want to reuse, you can just go back to it and unprivate it - making it obvious that it's used externally.
Here is a full example that gives the error: https://scastie.scala-lang.org/T2WqeiVEQziwn31xb5oOhQ
Commenting because I am also curious. Even just documentation help.
See if this helps - https://github.com/ashwinbhaskar/
I am not very well versed in path dependent types - more knowledgeable people will probably correct me on this, but the problem here is caused by `DbString.R` not necessarily being equal to `dbStringOps.R`. There needs to be "evidence" that they are the same type in all cases. I have managed to hack something together, take a look at this: https://scastie.scala-lang.org/lodgUzBBSfO9moBcSZKqxw This seems to be called "Aux pattern".
I find that nested functions are bad because you can’t easily independently test them. I use them sparingly.
Testing typically has two major problems: test case generation and oracle (the ability to check whether a given outcome is valid). Unit tests the way most people do has no oracle problem: you’re the oracle. It has terrible test case generation though - hard coded, biased test cases that represent an insignificant fraction of the input domain. PBT solves the test case generation problem - it’s still not exhaustive, but it’s eventually exhaustive, given enough executions. It makes the oracle problem much worse, though - you don’t know if an outcome is valid. So you have to sort of worry at your problem from the edges and confirm that outcomes look right. The trick to seeing its usefulness is to learn how to write properties. There are techniques that need to be learned. A trivial one is when you can provide an oracle - a working implementation, say, or if your algorithm has an inverse function, such as encoding / decoding. PBT is also pretty neat in scenarios where you don’t have an oracle - you can’t know whether an outcome is valid. Think of testing the spotify search api. How do you know the result is the right one, exhaustive and all? PBT lets you test that, because you don’t need to know the expected outcome. An interesting concept I’m playing with is: PBT doesn’t need an oracle. So why not evalute properties on production traffic? Instead of testing on random input, you’ll test on interesting input. You get to monitor application sanity! This is a subject I’ve been studying for a couple of weeks now, and I’m happy to talk about it further if you’re interested, or to provide relevant links and blog posts as soon as I’m in front of a proper computer.
Oh, and if you’re at all interested in any of what I’ve just written, I encourage you to look into metamorphic testing. Riveting stuff, if you’re into this type of things.
I don't know what defines beginner friendly, but this guy https://github.com/blackdoor/jose/issues/20 is pretty straightforward and I'm happy to help beginners to learn. Also check out [issues on github for scala projects that are marked as good for beginners and looking for help](https://github.com/search?utf8=%E2%9C%93&amp;q=label%3A%22good+first+issue%22+label%3A%22help+wanted%22+language%3AScala+state%3Aopen&amp;type=Issues&amp;ref=advsearch&amp;l=Scala&amp;l=)
Thanks a lot! that aux pattern was also mentioned on stackoverflow, but your answer did provide some clarity on how to use it!
What am I missing? This seems guaranteed to miss the edge cases you’d normally hand write tests for.
I agree with making things private, and _maybe_ even final, but I don't agree with prioritizing local definitions over private ones. I'd have to check the bytecode when I'm not on my phone but I believe local methods involve an allocation on every invocation of the outer method even if they don't capture anything. I'm not suggesting that is a big cost in the usual case, but it strikes me as an unnecessary one which is not sufficiently compensated by "I know this is only used in this method". I find that knowledge is not appreciably different from "I know this is only used in this class". Put another way, the class is the smallest scope I care about with respect to visibility, and prefer a clearer gain to use a local method.
It's actually more likely to be the opposite. The values generated by property based frameworks are not evenly distributed. They tend to be bias towards the common edge cases. For Ints these would be -1, 0, 1, MinValue and MaxValue. For Strings these are just the empty strings. For Chars these are uncommon Asian characters or characters for which the upper case version looks exactly like the lower case version, etc. Try it out!
You can look at [scopt](https://github.com/scopt/scopt). scopt is a little command line options parsing library. It is not very complex.
&gt;I’m starting university soon and will be required to learn scala &amp;#x200B; Lucky you. Really. &amp;#x200B; I decided to learn Scala after writing primarily JS for about 4 years and becoming more interested in FP. It quickly became my favorite language and I don't see that changing. I worked on a couple Scala projects at my last company, but now I'm writing primarily TS with some Python and Go. &amp;#x200B; It can seem overwhelming at first, but I learned it entirely on my own and didn't really have a clear path. I probably wasted a lot of time on things that didn't matter so much and could have become efficient in the language much more quickly than I did. It's great if you want to learn FP. After getting comfortable with the basics of the language, you can jump into something like [Scala with Cats](https://underscore.io/books/scala-with-cats/). A lot of people will recommend the [Red Book](https://www.manning.com/books/functional-programming-in-scala), but if you're not already comfortable with FP, it will be a long and frustrating experience. &amp;#x200B; A lot of people will disagree, but I generally find Scala to be more pleasant to work with than Haskell. I'm hoping that the next iteration of Scala is a little simpler, more stripped down. Things are moving in a more and more functional direction, but it doesn't seem to be affecting the popularity/usage of language. Maybe things will change with Scala 3, but I wouldn't count on it.
I started working on [firebase4s](https://github.com/firebase4s/firebase4s) last year, but haven't had much time since switching jobs. Most of the work revolves around wrapping the Java SDK and exposing a more Scala-friendly API. There's also some more challenging things like automatic conversion of case classes to/from JavaBean classes - something I still haven't worked out.
I think that's fine, however, you should IMO not convert any exception. Only handle exceptions explicitly. And if you have to handle exceptions generally then use [https://www.scala-lang.org/api/current/scala/util/control/NonFatal$.html](https://www.scala-lang.org/api/current/scala/util/control/NonFatal$.html) Because fatal exceptions should actually be allowed to crash your programm.
I have heard this before but didn't quiet understand the implications. Like what happens when you catch a Fatal exception but don't crash the program?
I'd recommend contributing to [ZIO](https://github.com/scalaz/scalaz-zio). A lot of first-time contributors chose to make ZIO their first contribution. It's 100% FP, I'm trying to make the contribution process clear and detailed, and I support new developers learning enough FP to contribute. :)
I am the author of better-files: [https://github.com/pathikrit/better-files](https://github.com/pathikrit/better-files) It's written in a "better Java" style Scala with zero external dependencies
&gt; I'd have to check the bytecode when I'm not on my phone but I believe local methods involve an allocation on every invocation of the outer method even if they don't capture anything. This does not seem to be the case, seems like they're compiled to simple methods: https://scastie.scala-lang.org/QyPHtGvDQ56Zj41JaHiWrw &gt; Put another way, the class is the smallest scope I care about with respect to visibility, and prefer a clearer gain to use a local method. Well, yeah, but it depends on how big your functions and classes are. With big classes, you can no longer see at a glance if a method is not being reused in multiple methods.
&gt; This does not seem to be the case, seems like they're compiled to simple methods: https://scastie.scala-lang.org/QyPHtGvDQ56Zj41JaHiWrw Nice! Glad to be wrong about that. Thanks for doing the work. Makes me slightly more likely to choose a local method. &gt; With big classes, you can no longer see at a glance if a method is not being reused in multiple methods. True, but big classes/functions are their own separate issue, and one I don't run into with any kind of frequency. In the end I guess I just don't care about knowing how many times a private method is invoked within a class. While I understand the philosophical benefit I can't say the difference between local and private has ever affected me in practice, and worst case it's maybe two key presses to get that information.
In that case, just use R’s more-seamless-and-streamlines version of Airflow! Problem solved :)
Aren't functional and reactive two totally different concerns? I don't know why companies and authors mix and match the two concepts as if they are the same thing.
I'm 80-90% Scala today. I'm looking to be remote from any office most of the time with the occasional travel being fine. I wouldn't want to be the only engineer 100% remote on a team though.
Your lib is awesome. Thanks for making it. Idk if you need help, but I wouldn’t mind doing my first OS “Scala” PR to it.
E.g. if you have an OutOfMemoryException, I would want my application to crash instead of doing I-don't-now-what. At that point correct behavior is not possible anymore, so just let it crash for good.
Plus, you'd write your edge cases yourself if needed, as normal tests :)
Nah, it's fine to use them when you need to when the benefits outweigh the cost. You should however be aware of the differences. For this reason I really appreciate that the default is immutable
I saw a lot of discutions about object orientation, even the course of Daniel Ciocîrlan on udemy has an entire section about OO in scala. It's object orientation largely used in scala? What is the most common paradigm of scala projects? Is it mixed? Another question: what is the point of libraries like cats and zio? Scala fails in being a trully functional language or it's just collections of syntax sugar?
you have an example where mutable collections can be better than immutable?
One use case for mutable collections are locally defined collections. For example, look at the standard library implementation of [distinct](https://github.com/scala/scala/blob/bf89d69885c1ecf6599c6d4b74d64ca06b3fbf56/src/library/scala/collection/SeqLike.scala#L509).
I think the obvious benefit of immutable data structure is concurrency. Since it can't be mutated, it's completely thread-safe. So unless you're writing multithreading code, it's justifiable to use mutable collections when you find it's too hard to do with immutable collections then.
Using them internally in a method is not too bad, since the mutability can then be reasoned about locally. Avoid taking in mutable collections as arguments or returning them from methods, since non-local mutability is generally hard to reason about.
&gt;It's object orientation largely used in scala? Scala is very capable of OO and often this paradigm is part of good solutions. Many problem domains can be modelled well in OO, so why wouldn't you? That's what's so great about Scala: You can choose the tools that fit your current situation best, without getting dragged into ideological arguments with either your compiler or other human beings. &gt;Scala fails in being a trully functional language or it's just collections of syntax sugar? What makes a language "truly functional"? I think just the fact that libraries like cats and scalaz exist is a testament to Scala's flexibility. When you design a language, you have to take care not to include too many features, especially in the standard library. So a library like cats can be many different things: An addition to Scala that evolves how the language is used, or maybe a neat toolkit that is used by a small percentage of Scala developers who think they need more functional structures. Maybe the language designers didn't think about such a library, or they purposefully omitted it because it's too niche. Whatever the case, it exists, so surely you can't use it as an argument for Scala's failure.
Implementing algorithms like heap sort would be more efficient when using mutable data structures
In some cases mutable collections may perform better than immutable collections. Depending on your business requirements you may want to opt for mutable collections in the hot-path of performance critical code, though I'd advise using benchmarking to determine if this is a worthwhile change.
Right. I will need to look into this. Going to start another thread...
Why would one use a **abstract type** in an abstract class instead of having the type as a **parameter** (generic abstract class) ? &amp;#x200B; I just finished the chapter on abstract members on the Programming in Scala book, and its not clear in which situation each is better.
Common misconception, the biggest benefit is local reasoning, which greatly increases ease of maintenance, which is by far the most costly part of software development.
The rule of thumb I use to determine whether a type should be an abstract type or a generic is by considering _who_ determines the type. If it's the _user_ of a library, then it should be a generic type parameter. If it's the _writer_ of the library, then it should be an abstract type member. For example, if we consider something like [Shapeless Generic](https://github.com/milessabin/shapeless/blob/master/core/src/main/scala/shapeless/generic.scala). Generic has both a type parameter, and an abstract member: trait Generic[T] extends Serializable { type Repr ... } The _user_ provides the type `T`, so it's a generic type parameter, then the _library_ gives you the type `Repr`, so it's an abstract type member.
&gt;should i try strive to not ~~ever~~ use them when writing scala code Probably. As others have said, there is definitely a time and place for usage of mutable collections, but it's rare. If you strive to keep everything immutable, it'll be obvious when the exception to that rule arises.
What's the misconception? They are both good benefits and basically outlining the same point - when something can change it is harder to reason about side effects. This just scales with concurrency.
Let's say two threads are working with the same collection. How are they cooperating? Each operation yields a new collection. If both threads are producing new collections all the time, how do you ensure none of the updates are lost? The data structure itself may not be mutated, but the reference to it will be. So the concurrency problem is still there.
Yes, this made me switch completely to neovim.
Thank you so much, Olafur!
Fire away
If anything is being “updated”, it’s not immutable :). As long all objects are immutable, concurrency problems are less of a problem.
&gt; scala-logging library inserts isEnabled checks for you Kotlin has inline functions that have the same effect. &gt; compile-time DI with MacWire. Java (and therefore Kotlin) already have compile time DI using Dagger. &gt; async/await with Monadless. Kotlin has `suspend` functions that do the same. &gt; immutable collections that don't expose mutable APIs Kotlin has a bunch of immutable collections in the standard lib. &gt; cheap custom types Kotlin has [inline classes](https://kotlinlang.org/docs/reference/inline-classes.html). Plus, when Java gets value types, all JVM languages will get them. &gt; expression-oriented syntax. Kotlin already has that. `if/else`, `when`, `try` are all expressions. &gt; pattern matching. It's also there, though not as the same extent as Scala. I read they might expand it, since now Java is getting that as well. &gt; safer way of dealing with Java nullables in my opinion (I trust Option(javaNullable) more than pinky-promise annotations) Kotlin doesn't use annotations for nullability (at least not explicitly). Nullable types are designated as `T?`, compared to `T` which are non-nullable. &gt; data in traits You can have [properties in interfaces](https://kotlinlang.org/docs/reference/interfaces.html#properties-in-interfaces) in Kotlin.
I haven't watched yet so let me know if this is covered, but my biggest challenge with property tests is coming up with good test cases that aren't just reimplementing the method under test. It feels like there aren't often nice clean properties to test like in the examples I see.
[Here](https://fsharpforfunandprofit.com/posts/property-based-testing-2/) is a nice guide for choosing properties.
I would say the issue is that while safe concurrency is _an_ advantage of immutability, it's not the only one, and not even the most important one (by far). By focusing on concurrency as the standard go-to example of why immutable data structures are important, readers might be left with the impression that if they're not doing concurrency, it's not something they need to worry about so much.
There seems to be a need for it in Akka actors to record state (prior to the newer typed Akka) or if you’re implementing some sort of cache but outside of that, once you written a few recursive functions you’ll find almost no reason to require mutable types in your app. So it’s not always “dirty”
While I was waiting for SBT assembly to run, I decided to write up a really simply explanation of how to manually compile Scala programs and run them using the java command, and ended up mostly talking about java. I only realised on reflection what a dry subject this is...
If your point is that code quality and concurrency are the same thing, they’re not. There’s no direct correlation between them. Code quality helps you reasoning with any type of code you’re reading/writing but that’s as far as the relationship goes. Before we go on, let’s establish the difference between parallelism and concurrency (I recommend reading the cats.effect documentation for a good summary on this), parallelism refers to two computations running in parallel, concurrency refers to two computations accessing the same resource at the same time. So, while immutability helps with non-concurrent parallelism because it removes the possibility that one thread changes the state that is shared with another one, it doesn’t really help with concurrency because by definition, the problem with concurrency is access to shared resources. So if those resources are accessed and new values generated concurrently, there will be reconciliation problems. An effect system does help with this and one common way to deal with this is by using `Ref` which allow for atomic modification of shared resources, interestingly enough since the modifications are atomic, from an concurrency perspective it doesn’t really matter if the ref is to a mutable or immutable structure(again, it does when it comes to understand what’s happening during the modification/replacement of te value referenced).
Myself being someone who can’t remember the last time they used a mutable data structure or even a mutable value in Scala, I would recommend you not to get to strung out about mutation. Just try to think and write code in a functional way, if you strive to use pure functions, for example, immutability will naturally emerge from it.
Not directly but if we're talking about really simple scenarios I don't find it matters too much as testing the function, would hopefully test the functions inside it too.
Ay, okay, that makes sense :)
It seems possible to do this: class Hello { def apply() = println("constructed!") } def x() { lazy val h = new Hello()(); h; } x Constructed! x Constructed! I can't find documentation on how "lazy val" should behave when used inside a method. Presumably this was a mistake and the lazy keyword is ignored?
It behaves the same as `lazy val` anywhere else: the val is constructed when it's used, but only once. ```` scala&gt; def x() = {val h = new Hello(); println("after declaration"); h.doThing(); h.doThing()}; x() constructed after declaration doing doing x: ()Unit scala&gt; def x() = {lazy val h = new Hello(); println("after declaration"); h.doThing(); h.doThing()}; x() after declaration constructed doing doing x: ()Unit scala&gt; def x() = {def h = new Hello(); println("after declaration"); h.doThing(); h.doThing()}; x() after declaration constructed doing constructed doing x: ()Unit ````
There's always a maintenance cost to using mutable collections. The smaller the scope of the mutability, the lower that cost, but it will never be zero. Occasionally a particular use case might be worth the cost, but make sure you know what you're getting out of it. I wouldn't say never use mutable collections, but I'd say always try solving the problem without them first.
Thanks for the write up!
Yes. Always **strive** not to use mutable collections.
In java I can use jaxb to generate an .xsd file from existing java classes (with annotations). What's the equivalent library that I could use in scala? scalaxb seems to generate scala code for a given .xsd but not the other way round.
May I ask what a DAG is? I only know of the term as "directed acyclic graph". I'm very new to Scala.
Scala classes can compile down to fully Java-compatible classes so you can use exactly the same tool as you use for Java. The main rules to follow would be basically: * define simple Scala classes at the top level (not nested inside objects) * use \`var\` instead of \`val\` for members * use \`Integer\` and not \`Int\` * you may need the **@Bean** annotation on class members * define enums using Java There's a maven tool for this: [https://stackoverflow.com/questions/7251458/generating-xsd-schemas-from-jaxb-types-in-maven](https://stackoverflow.com/questions/7251458/generating-xsd-schemas-from-jaxb-types-in-maven)
One good thing to have in your toolbox is a solid understanding of how to use tail-recursive helper functions. These typically can replace old-style **while** loops yet still remain stack-safe and non-mutative at the source code level: the **@tailrec** annotation tells the compiler to transform the calls appropriately. The SICP book explains the concept beautifully: [https://mitpress.mit.edu/sites/default/files/sicp/index.html](https://mitpress.mit.edu/sites/default/files/sicp/index.html) &amp;#x200B; And, needless to say, get familiar with the library-supplied collection methods, fold/reduce/scan/groupBy/partition etc.
Explain to me how two threads can build a single data structure simultaneously without fear of conflict. I have no confidence at all that you even understand what we're talking about.
They cannot - at least in a functional way.
So my original point stands. Given this I can't see that your comments added anything other than noise.
No need to be hostile:) You are saying "none of the updates are lost". The point of an immutable data structure/object is that there can be no updates. So no updates can be lost. &amp;#x200B; If you are updating a "mutable" data structure, then obviously you might have a concurrency problem. I'm not arguing that you can remove all "mutable" data structures. But, if you use immutable data structures in most places, then those structures are threadsafe. If you must have a mutable data structure, then you have to consider effects of concurency and use some methods ( locking, atomics, etc ) to make sure no updates are lost.
Generally speaking in terms of algorithmic complexity (and also performance in reality) its hard to find immutable data structures that "are very good in all operations". For example immutable `List` has constant prepend however lookup and append is O(n). If you want a dynamically expanding Array (or even just an array) with O(1) operations everywhere, there is no such immutable data structure. The closest thing is `Vector`, which is (at best) effectively constant on most operations and in reality the size of your collection would have to be &gt; than a non trivial amount (talking thousands) for the O(nLogN) lookup on `Vector` to be faster than the O(n) of the `List` (Li Haoyi made a really good analysis). The same deal is if you want an immutable map that has (at least) effectively constant lookup by key and maintains key ordering (such a collection doesn't actually exist, this problem is solved using composite data structures that combine either a `Vector` or `Map` along with another `Map` internally which is terribly memory inefficient). Mutable datastructures have the obvious downside of race conditions when being accessed in parallel, however languages such as Rust and the new multicore OCaml solves this issue with linear/effect types.
I just published a snapshot version to Sonatype OSS Snapshots, so if anybody would like to try it: \`\`\`scala resolvers += "Sonatype OSS Snapshots" at "https://oss.sonatype.org/content/repositories/snapshots" libraryDependencies ++= Seq( "org.docker4s" % "docker-client" % "0.9-SNAPSHOT", "io.netty" % "netty-transport-native-kqueue" % "4.1.33.Final" classifier "osx-x86\_64" // Or, if you want to use UNIX domain sockets on \`epoll\`-based systems like Linux: // "io.netty" % "netty-transport-native-epoll" % "4.1.33.Final" classifier "linux-x86\_64" ) \`\`\` It's only available for Scala 2.12 at the moment, but happy to make sure it works for Scala 2.11 as well.
&gt; The point of an immutable data structure/object is that there can be no updates. So no updates can be lost. So we've circled back to you maintaining the same point you earlier abandoned. OK. The rest of your comment is irrelevant. Let me ask again: how can two threads build a single datastructure with no locking/coordination, even if they are both fully functional? From the standpoint of practical engineering this is the only relevant question.
I think the point GP is trying to make is that simply using immutable structures in place of mutable ones does not fix concurrency. You can't just replace `val m: mutable.Map[...]` with `var m: Map[...]` and expect to solve concurrency that way. If you did that, you would miss updates when two threads concurrently say `m = m.updated(...)`, as one of them could be looking at an outdated version of `m`, and would thus produce an incorrect result. Of course you can have nice concurrency with immutable data structures if you only use them for reading ephemeral or static data. But if you need concurrent writes, e.g. to maintain any sort of shared state, immutability by itself is not enough to fix your concurrency problems.
 You can't just replace val m: mutable.Map[...] with var m: Map[...] and expect to solve concurrency that way. If you did that, you would miss updates when two threads concurrently say m = m.updated(...), as one of them could be looking at an outdated version of m, and would thus produce an incorrect result. I completely agree with the above. The problem I think I have with your comment, is that an updatable "shared state" object cannot be an immutable data structure. If you have an object that you need to "update", you don't have immutability, so you are running into concurrency problems. &amp;#x200B; The point is that if you design your code such that you only have immutable data structures, then you won't have concurrency problems. &amp;#x200B; In the real world, you might require a mutable data structure (in your example the shared state), in that case, you will have to to deal with concurrency on that object. &amp;#x200B; So, if you maximize objects that are immutable, then potentially a large part of your application will not have concurrency problems, and you will have to deal with concurrency only with the mutable objects. (which are hopefully few).
You're correct that a DAG is a directed acyclic graph. Airflow uses such graphs to represent processing pipelines (i.e. if B depends on A, then there is an edge A -&gt; B). The graphs are necessarily acyclic because otherwise they'd have a circular dependency and be impossible to run.
I say don't use mutable collections unless you need to. But if you need to, then use them. The order of preference is 1. `val x = Map(...)` 2. `var x = Map(...)` 3. `val x = mutable.Map(...)` 4. `var x = mutable.Map(...)` (1.) is best: if it doesn't need to change, don't let it. (2.) is preferable over (3.) from a principle-of-least-power perspective (in 2. you cannot aliase the mutable object to multiple locals, but in 3. you can) (3.) has better performance, e.g. mutable map/set lookup is ~4x faster than immutable map/set lookup, and constructing via `mutable.Set.add` is about ~2x faster than `immutable.Set#+` due to the underlying datastructure (http://www.lihaoyi.com/post/BenchmarkingScalaCollections.html) (4.) You should basically ~never need
Well, this is mostly semantics, but the concept of immutable data structures does not cover references, just the data structures that they contain. You can still have mutable references (var) to immutable data structures (immutable.Map). The design patterns you're describing is more than just "immutable data structures". You're also not explaining how exactly you're going to avoid the necessary mutable state if you need it for example to track socket connections or memoized instances or what not. Ultimately unless your application is pure math you'll have to deal with mutable state one way or another and whether you use vals of mutable structures or vars of immutable structures or ten layers of abstractions on top of either of those you will still need to deal with concurrent access by means of semaphores or other concurrency primitives.
I think we are saying the same things. &amp;#x200B; I agree with the last paragraph - real world applications have mutable state which needs to deal with concurrency. You will definitely need deal with concurrent access on those. &amp;#x200B; I think there is a lot of space between pure math and socket connections. Depending on your application, the majority of collections could be designed to be immutable. There might be some which need to be mutable. Some other comments: A data structure containing a var is mutable. An immutable data structure does not have "var"s &amp;#x200B; Of course, you can have "var"s to immutable data structures. There are the following things you can do with these "var"s 1. Use them locally in the function body in which case there is no concurrency problems because your changes are not visible. If you return this, it's a new data structure. 2. "use to create" or "store" them in a data structure -&gt; 1. Inside the data structure it is a val - in which case this data structure is immutable 2. inside the data structure it is a var -&gt; in this case the data structure is mutable and has concurrency concern.
I agree with the idea of keeping them internal inside a method so that the RT can be reasoned about. One example where they are super useful is in dealing with legacy Java code - for example, in at least one of my projects, we have to deal with JDBC and cursors and such, which sure, might be handled with an IO monad, but it is easier to simply iterate the cursor and add to a mutable list, and return an immutable version at the end of the function.
Ahh gotcha. I wasn't understanding the Airflow part at the time, that makes sense. Thanks for the response!
Threads are never a practical requirement. Presence or absence of locking is never a practical requirement. Practical requirements look more like "overall throughput of x, never pausing for longer than y", and I've yet to encounter one that couldn't be met with immutable data structures.
It looks like you just moved and renamed `build.sbt` to `project/build.scala` and then use those defs in a new `build.sbt`. Am I missing something?
Hi, let me know how it works for you when you try it.
Maybe it's just me but I find that the code surrounding immutable collections is more complicated, and that adds a maintenance cost too.
Slick assumes you have runtime access to a database. It creates a database model by querying via JDBC and wrapping the results in its internal meta-model. The code generator uses this to create another model, from which it generates the slick schemas. You could try creating models from the CSV at any of those layers, but it sounds like a lot of work. The quickest approach would be to run a local db instance with your schema and pass in the JDBC URI.
The only case where I find it easier to work with mutable collections is where the business/real-world process you want to model actually has a collection mutating. Even then I'd say it's harder to understand what's going to happen in the presence of a mutable collection, but sometimes knowing that your code is true-to-life is more important than knowing what your code is going to do, if that makes sense.
Thanks. That's what I thought.
The bean annotations can simplify writing things that require get/set methods.[https://www.scala-lang.org/api/current/scala/beans/index.html](https://www.scala-lang.org/api/current/scala/beans/index.html)
I'm using it quite often in my job, what would you like to know? How can I help?
Nice, so I’ve worked to get as much of the pre-existing syntax working to make the migration easier, but it should also support mockito-scala only features like mixing arguments and matchers. I copied all the tests in the original library and they’re working, but haven’t tried the same in a real project as we use scalatest where I work So basically if you can replace the specs2-mock by mockito-scala-specs2 and see what happens? Maybe report any bugs/issues you find? I’m working in the migration document so any stuff that doesn’t work (and can’t be fixed) would be really useful as well Many thanks in advance!
Also interested in the results, we're always behind when it comes time to update our templates
This a best attempt at best practice web service written using `cats` and `http4s`. The entire thing is pure and referentially transparent so all effects are suspended. https://github.com/pauljamescleary/scala-pet-store
This is still a bit of a "toy" example but it's a real system that uses http4s, circe, and the ZIO monad: https://github.com/mschuwalow/zio-todo-backend kind of a toy as well but also a good substantial example: https://github.com/spf3000/functional-hangman
The Slick DBIO class is an example of an IO Monad.
Isn't `DBIO` a free monad construct?
I head John De Goes is entirely made up of IO Monads. Definitely real-world and not a toy.
I wouldn't be so sure. Have you touched John De Goes? We have dead people coming back to life and people getting 40 years younger in movies these days, so just because you saw him live in a video doesn't mean he actually exists!
http4s is a good example.
Problem with questions like this is with functional programming, programming in the large is exactly like programming in small. One of the stated objective of functional programming to use composition to make big programs from smaller ones, and the compose even bigger programs from that. So you're not going to find a program that looks different because it using `IO` in the wild in a way that's materially different from some pedagogical examples. That said to answer your question directly, there's `doobie`, `http4s`, `fs2`, and pretty much anything built from those libraries.
I guess if you’re asking this question is because you’re not working in functional Scala. Several companies are using it, including the 1000+ employees one I’m currently working at. It’s common practice to use it in enterprise Scala environments. As some other people mentioned here, a lot of production OSS libraries use it, such as http4s, doobie, fs2, etc (cats.effect page has a small list of libraries using it). These libraries tend to abstract over a higher kinded F that can be set to a specific IO monad later (think of it kind of like an interface that allows you to choose IO, ZIO, Monix Task, or whatever other implementation is available).
All I know is no matter how many John De Goes I have in sequence the effect is best described as some kind of comprehension and at the end I still have a John De Goes to start the next sequence.
You can also configure the generator to introduce Edge case you have in mind
I would show you my last few projects but because they are commercial and NDA, I cannot. But there are some big projects released as OSS, like: * [https://github.com/slamdata/quasar](https://github.com/slamdata/quasar) - this one is cofounded by John De Goes * [https://github.com/rchain/rchain](https://github.com/rchain/rchain) - tagless final interpreted to some IO monad.
IO is a free monad over a universal algebra, so both correct kind of. But more strictly DBIO is not THE io monad.
This is an interesting explanation of the direction that Martin wants to take implicits in Scala 3, and there reasoning behind it. I still don't know if I agree with it or not, but I thought it might make for an interesting discussion.
i think changing implicits is a good idea and I agree with /u/modersky 's reasoning for what he's doing
a cubical type theory implemented in Scala https://github.com/molikto/mlang
I don't directly disagree with any of the points but I'd like to see a bit more acknowledgement that implicits have been a success story for many (though not all) people, and that current Scala has been vastly more successful than most designed languages ever are. The highest priority should be not breaking that, and I don't always get the sense that these proposals put as much value on that as I do. I do think post-Scala languages should find a better way to achieve what implicits do for us - or perhaps just a way to constrain their use away from the bad cases. I'm not at all convinced that segregating implicits into a second-class system is the right way to achieve that (a lot of Haskell's problems come from typeclass instances being second-class and not having everything that's available in the plain-old-value world). And I'm not sure where the idea that there should be only one way to declare implicits is coming from. To go back to the Forth/Pascal analogy, one thing Pascal does is use different keywords/constructs for different patterns of stack manipulations even though they are the same underlying thing (and would be exposed as the same thing in Forth). More concretely I think conflating implicit conversions and implicit parameters gives rise to a lot of the current hate, and even if the implementation continues to use a single underlying mechanism, we would be better off creating a clearer distinction between them at the syntactic level. Concretely that would mean things like different keywords for defining implicit conversions, different imports for implicit conversions. I think that's a much more promising direction than what's proposed here: the notion is to avoid emphasizing the low-level implementation, but by having a single construct that declares all kinds of implicits (and only declares implicits) we'd be doing exactly that.
[removed]
Try mine: [https://github.com/scf37/fpscala2](https://github.com/scf37/fpscala2) &amp;#x200B; It is kind of non-standard but quality rest api built on IO.
Interesting to see the thought process driving the new direction. For me personally the comment about compiler errors resonates most strongly. The biggest problems I've had with implicits when learning a library/framework have always been missing an import and needing to retreat to the documentation to find what I'm missing. If the complier could tell me the candidates for the missing import, that would be huge.
\&gt; The new syntax should *not* mirror the full range of choices of the other definitions in Scala, e.g. val vs def, lazy vs strict, concrete vs abstract. Instead one should construct these definitions in the normal world and then inject them separately into the implicit world. I'm not so sure this is the correct direction -- it actually makes declaring implicits more complex and introduces additional cognitive overhead when declaring implicits to have to always use two steps to create an implicit that is available for injection. It also implies (heh) that implicits are not a first-class citizen in the language, something that scala developers have lampooned about OCAML functors and everything is a runtime annotation in java. In addition, ridding the language of the implicit keyword and replacing it with a set of new keywords may mean that learners of the language now see the topic of implicit scope as a set of five or more unrelated concepts instead of a whole, unified concept. &amp;#x200B; \&gt; In fact it’s better not to think of them as parameters at all, but rather see them as *constraints* I agree that that is a good way to view typeclasses and generic implicits, for example, `Foo[A]`, but how does that apply towards implicit parameters like `ExecutionContext` and the `Context` example frequently cited in /u/odersky's previous implicit talks? What are those constraining -- the method they are declared in? &amp;#x200B; \&gt; Imports of implicits should be clearly differentiated from normal imports. What purpose does this actually serve? If I `import myPackage._` I currently get everything declared in `myPackage`. But now, if `myPackage` contains implicits, I have to do two import statements, one for the **regular** world and one for the **implicit** world. That seems odd and one more annoying impediment to actually using implicits. &amp;#x200B; I don't have any suggestions for making implicits better, other than by removing implicit conversions and replacing all instances of them with implicit classes providing extension methods or even collapsing that use case to all being typeclasses with extern statements. Surely there would be nothing wrong with requiring `ExecutionContext[Future]` or `Context[Compiler]`, right? &amp;#x200B; \&gt; The new syntax should be clear also to casual readers. No cryptic brackets or symbols are allowed. Why is this constrained to just implicits? Shouldn't this also apply to `&lt;:`, `&gt;:`, `=:=`, `Foo#myThing`, `A | B`, `A &amp; B`, and other type constraints, etc.? What makes the use of parameter bounds for implicits any more onerous than these symbols -- the syntax is even `MyType :Fooable`, which is pretty nice, currently, and seems to follow the idea of implicits being constraints more than `def f[A](a: A) given (executionContext: ExecutionContext): Future[A]`. &amp;#x200B; The purpose of the changes seems to be making implicit use more difficult. Making the usage of a feature more difficult is a way to discourage the use of the feature in a language. It encourages other usage patterns available that are true first-class citizens within the language, for example, writing manual decorators and proxies instead of extension methods, using the reader monad or currying and partial application instead for parameter injection. Which is strange, since /u/odersky has said in the past that implicits are Scala's differentiating feature. &amp;#x200B; I have no problem learning the new ways to use implicits and the new keywords. I'm not sure that they simplify the learning curve, nor am I sure that they make implicits more successful. If that's not what they achieve, and the true intent is to make implicits more difficult to use to discourage their usage because of their difficulty to learn and potential to abuse, then perhaps the feature would be best removed entirely and at the least the intent of the proposed changes should be more clearly expressed. Removing them will certainly simplify the language. The cost of doing so may be a high price to pay in that we are essentially removing Scala's defining feature. &amp;#x200B; Again, as always, I could be wrong.
Interesting approach solving an actual problem. Thanks for sharing !
Love it!
I like Scala Steward (https://github.com/fthomas/scala-steward). It's a "real world" project and its domain is easy to understand which make understanding the code a little easier.
Oh man I wasn't ready for that. Time to do some studying
Scala Steward. Here's the entrant code with the canonical IO for comprehension https://github.com/fthomas/scala-steward/blob/master/modules/core/src/main/scala/org/scalasteward/core/steward.scala
The light text on white background is really hard to read. Can you provide a higher contrast option?
I've tuned up the brightness, although the background on the site is black – a typo or may be your browser plugins are misconfigured? Alternatively, a repost should be available at [functional works](https://functional.works-hub.com/learn/no-more-orphans-8eb0b) at some point.
Don’t you need a package with jdk source code, something like openjdk 8 dev? For newer versions I think java home env variable has been deleted.
Substitute Scalaz \`Task\` for \`IO\`, and I suggest looking at [Funnel](https://github.com/Verizon/funnel), which is a complete distributed monitoring system with an initial target of AWS and several back-ends for gathering metrics. The API of the metrics themselves is not referentially transparent (to ease adoption, something we came to regret), but everything else is. I think it's also a good example of intermediate-level Scala software engineering generally, with some clever structure to keep types related to a particular platform (e.g. AWS) compatible with each other but incompatible with types for another platform, for example.
I just tried it and the background came up black. Thanks!
I am quite new to Scala, and what distracts me is the need to switch often between sbt command line and shell (yes, of course I can use different tmux panes, etc., but still). I'd like to achieve a workflow where I could start sbt in background somehow and transparently pass all sbt commands to it, while being able to run shell commands as well. I can think of a trivial implementation of the above in a form of a launcher that runs sbt and inserts into PATH another binary with the name "sbt", which deals with connecting to the "true sbt" and returning its output. Has this already been implemented?
Try Dark Reader extension
I really like the colour scheme for the syntax highlighting, is it based on an existing theme for some editor?
Better, and shorter version on cats typeclasses: &amp;#x200B; [https://scastie.scala-lang.org/5M5vERDZQLmZms9dFdnJIg](https://scastie.scala-lang.org/5M5vERDZQLmZms9dFdnJIg)
You should probably save yourself some trouble and use Metals instead.
Nice first post! Looking forward to reading more from you. Are you or your company on twitter?
My two favorite parts of that thread were the discussion of error messages, and the mention by mdedetrich of the fact that outsiders whine about implicits but then think guice or spring is perfectly fine. I remember while watching Martin's talk about Dotty last year, it felt like he was trying to fix the whole problem that DI attempted to address. I personally think DI was a huge failure. It entered promising cleaner, more powerful code, and at the height of its reign, it was just another form of mindless bloat: vast structureless masses being autoinjected into various cavities, resulting in amorphic tubs of jello. If you think about it, Structured Programming (coroutines and functions, a la C), stumbled on as the dominant language paradigm 2 years after the first OO language in part (Kuhnian) because it still worked, but when the Windows API dropped and quickly grew, collapse was at hand. Each call took 4 or 5 arguments and a lot of them were structs with 10 members. DI took us back to that same cliff, but the 2nd time around, we simply made it easier for the developer to move the mess around. &amp;#x200B; My feeling is that implicits are useful, but, that the entropy of a system is directly correlated with the degree to which shaped abstractions have to be augmented with contextual miscellany.
Yep, https://twitter.com/kaidaxofficial
If he's on a 2.11 project that won't help him.
Install the openjdk. Enter ls -la $(which java) in the terminal. You will see /usr/local/lib/openjdk.../bin/java The part before /bin/java is your jdk home. Open your .bashrc in an editor. Enter EXPORT JDK_HOME=your jdk home from above. Save. Kill the terminal. Start a new terminal. Run sbt. Always open your editor's from a terminal. Should work.
This program's success will enable us to pursue Cats ambitious [2019 roadmap](https://github.com/typelevel/cats/blob/master/ROADMAP_2019.md). Any amount will help us get closer to our goal. Thanks!
Maybe you can try Streamsets [https://streamsets.com/](https://streamsets.com/) if the nature of your data / bussines case have a stream aproach
I need to be able to refactor code, unfortunately so waiting for that to come in metals.
Hi, So this is where it is super odd. ``` $  ls -al $(which java) lrwxrwxrwx. 1 root root 22 Apr 25 22:32 /usr/bin/java -&gt; /etc/alternatives/java ``` I don't have a `/usr/local/lib/openjdk`. All of my java/openjdk installations are in `/usr/lib/jvm`. Which is bizarre because my previous openjdk-devel installation was in `/usr/lib/java` and I was able to point to it and make it work.
I have been manually setting it, sadly doesn't work :(
Ls -al /etc/alternatives/java
Looks like it indeed.
Nope. Did not work :/
What happens when you type java --version
java points to 1.8.0 while javac points to version 12. &amp;#x200B; For now I have uninstalled all the java versions on the system. &amp;#x200B; There are multiple variations of different java versions: src, headless, devel, &lt;plain&gt;. &amp;#x200B; Any idea which one is optimal to use with ensime?
2 looks wrong
Your java runtime (java) should be java 8, build 121 or higher. Your jdk (javac) needs to be java 8.
In a micro-services platform (services and spark), a big e-commerce company in Europe, we are using it for 10 new modules out of around 70, however the rest of are older than 1 year, almost all new ones make use of cats-effect and right now I am using ZIO to build another one. Pretty much all projects that use Doobie will make use of IO monad to some extent, and this is a very used library.
You could be using the databricks Community edition to run the code yourself: https://community.cloud.databricks.com/login.html
Will it just show the answer or how to arrive there?
I know all that. Like I said, I had it working on my previous linux install but it doesn't work on fresh install. &amp;#x200B; Anyway, I solved the problem by removing all versions of java and installing it from AdoptJDK.
I haven't been working with spark for quite some time now so I might be a bit off. **.fold(a)(b)** is basically **.aggregate(a)(b, b)**, meaning that it first folds the partition and then folds the results from the partition. 2. There was one partition and it was folded to 1 + 7 and once more to aggregate the partitions 1 + (1 + 7) 3. There were 4 partitions so it was 4 + 7 and then all of the partition results were aggregated using the same fold resulting in 1 + (4 + 7) 4. You can basically ignore partition calculations since at the end all of the results were basically counted - there were 4 partition results, which just means 4 (0 + 1 + 1 + 1 + 1) 7. **.coalesce** basically reduces the partition count to the amount specified, but probably because 4 &lt; 10, no repartition/reduction is being done 8. same as 4. there were 6 partitions and doing the last fold resulted in 1 + 6 (1 + 1 + 1 + 1 + 1 + 1 + 1) 11. to 15. I am too lazy to explain right now, but it's basically the same as my previous explanations but with keys
Awesome, thank you!! I understand now
If typeclasses are such a powerful, obvious, necessary part of Scala, why is there no Monoid in the standard library? It seems to me that by respecting the diversity of approaches to these core language features (eg. scalaz vs cats) we make Scala less approachable because newcomers must learn 1. the language, 2. the standard library, 3. the “standard” non-standard libraries (for which discovery is a huge issue for newcomers), and 4. the conventions to weave them all together. In golang a user need only learn (1) and (2) and I think this should be the case for Scala 3 as well. https://contributors.scala-lang.org/t/principles-for-implicits-in-scala-3/3072/51
&gt;high fructose syntax I'm totally adding this phrase to my engineering vocabulary!
It will show the answer but at least you'll see if the solution are correct since it seemed to be your major problem in your question. That the solution seemed wrong. Also, those method: foldLeft exist for Seq. So you can run the code with a Seq instead of a RDD and add a println in the loop so you'll see how the accumulator change at each loop.
There's experimental thin client mode in debt, I can't find docs other than in the changelog (https://www.scala-sbt.org/1.0/docs/sbt-1.2-Release-Notes.html) but in short, passing -client in the sbt command might do what you want.
So few donations...
Nice! I haven't checked the code yet. Just curious to know, you didn't use mutable arrays?
Every time I want to write a blog post on how I've done something in Laminar it ends up as documentation instead, so well I figured this might be interesting enough to post on its own. If you used React.js you know its [solution](https://reactjs.org/docs/lists-and-keys.html) to performantly rendering dynamic lists of children: for each virtual DOM element in the list, you need to specify a key identifying the "model" – the thing that this element renders, – so that React knows how to map a new version of a particular virtual element to an old one, so that it can update the old element belonging to the same model instead of re-creating it from scratch. Laminar doesn't use virtual DOM, so it doesn't need this mapping, because our element references are stable, not ephemeral. Even if the contents of a Laminar element are updated by some stream, it's still the same element in the API, because it's still the same element in the DOM. However, until today this meant that Laminar users needed to do one of these things to render dynamic lists of elements: - re-create elements on every update, sacrificing performance on large lists, and being unable to retain element state such as input focus on affected elements - use a very performant but a low level / imperative [children.command API](https://github.com/raquo/Laminar/blob/v0.7/docs/Documentation.md#performant-children-rendering--childrencommand) - figure out a manual memoization strategy to reuse existing elements instead of creating new ones The new API essentially takes all effort and guesswork out of that last option. You just need to provide a stream of List[Model], a function to render each model into an element, and a key to memoize a model, and you will get a stream of List[Element], but with a twist that every element will be reused as long as its associated model continues to exists in the provided list of models. Here's how you use it to render a list of users: // 1. What you need case class User(id: String, name: String, lastModified: String) val usersStream: EventStream[List[User]] = ??? // your logic generates this def renderUser(userId: String, initialUser: User, usersStream: EventStream[User]): Div = { div( p("user id: " + userId), p("name: ", child.text &lt;-- userStream.map(_.name)), p( "user was updated: ", child.text &lt;-- userStream.map(_.lastModified != initialUser.lastModified) ) ) } // 2. Render a stream of models into a stream of elements efficiently val userElementsStream: EventStream[List[Div]] = usersStream.split(_.id)(renderUser) // 3. Include the stream of elements in some parent element div("Magic list: ", children &lt;-- userElementsStream) And that's it. All mounting / unmounting / memoization / subscription / unsubscription for streams happens automatically, as always in Laminar. This is just a high level overview, the [docs](https://github.com/raquo/Laminar/blob/v0.7/docs/Documentation.md#performant-children-rendering--split) have more gritty details. Actually, now that I think of it I should probably adapt what I just wrote for the docs. Sigh, every time... Oh and implementation of the splitter is very simple, see [Airstream's SplitEventStream class](https://github.com/raquo/Airstream/blob/master/src/main/scala/com/raquo/airstream/eventstream/SplitEventStream.scala). Cheers. Join us on [gitter](https://gitter.im/Laminar_/Lobby) if you're into this kind of thing.
Nope :)
I wanna create web project, but don't know what is better solution: * write self wrapper for http, use akka http library * write raw self solution * get play framework or something same p.s. Project is social network.
the quote is such a great point.
This is a bit childish.
And nothing of value was lost
"the negative sentiment generated by a few very loud scalaz maintainers is damaging to the community." So Scalaz maintainers were harassing the Scala dev team? Or they are trying to silence their opinions made in articles and blog posts?
This is what I have a problem with. Making vague references to disagreements without context. Makes it very difficult for onlookers to understand what’s going on, which IMO is also damaging.
I thought scalaz got rid of the main jerk?
A lot of times we want to be the bigger person by hiding others mistakes. But in reality we fail to share their past character flaws, which, while aren't necessarily concrete evidence for future behavior they serve as a forewarning until flawed characteristics have been resolved and many times the sharing of misdeeds aid in that change because now the perpetrators know they can't get away with attacking others without repercussion. Yeah I don't grammar well
Their groupies are still hanging around.
[https://contributors.scala-lang.org/t/coc-compatible-community-builds/3097/6?u=onesupercoder](https://contributors.scala-lang.org/t/coc-compatible-community-builds/3097/6?u=onesupercoder)
I think that this move is a consequence of forking scalaz and creating cats. If creating Cats wasn't childish, then removing Scalaz isn't childish either.
I agree. While I can understand the motivation in not to call out specific incidents, as this can devolve into a flame war, but if they aren’t pointed out, no discussion can be had. Like you say, this leaves no room for change as what is being referred to could have happened years ago or yesterday. I suspect most people have little idea what is going on and just want popular libraries that they prefer to use be compatible with the compiler. Again, without being aware of what is going on how am I meant to make a value judgement on what library to use, other than what it does and how it does it? From the outside this looks like tribalism. Is this unfair? Maybe, there will definitely be more to it, but how am I meant to know what is going on?
*outcry* *rage* ---- they should have made this move much earlier. such a toxic project. and so much entitlement. run your own community build, the repo has instructions of how to do it.
The community build is a service provided by Lightbend which costs them a lot of time and effort. They're free to include or exclude whichever projects they like. It's true that Scalaz is now a self-contained island and that some of their maintainers like to bash Lightbend and the Scala community in general, so it seems understandable if the community build maintainers no longer want to invest time in that.
Imagine how damaging to the "community" these kind of political actions are. They drive people away, especially people focused on the technical who are bewildered when stuff like this happens.
In that case they should stop calling it a ‘community’ build, like someone pointed out in that thread. Call it what it is, the ‘Lightbend Scala Compatiblity Build’.
It's ridiculous. Childish and ridiculous. And it's why scala can't grow and why people are switching to different languages.
Out of the loop can someone explain the background here?
Everyone benefitted from Cats. Cats &amp; Typelevel are the reason FP features are making it in dotty. Progress has been stalled when Scalaz was the main FP project, that also actively antagonized Scala itself making cooperation impossible.
Not so much anymore, and personalities are not a cause for persecution anyway.
Was this because the scalaz maintainers were just spamming the dev list with messages consisting only of &gt;&gt;= |*| &lt;=&gt; ^* ~~&lt; &gt;&lt;?
I’m curious, what refactorings in particular do you rely most on? We’ll be working on adding “code actions” (LEP refactorings) in Metals over the coming weeks.
Where are the maintainers bashing lightbend? Or Scala? I don't think Scala the Infinity War talk had anything disrespectful in it. A much more inflammatory talk was Paul Phillip's Scala Collections Why Not back in the day, and that was coming from the top maintainer of scala/scala and a Lightbend employee. Nothing to do with scalaz. Now, it's certainly up to the scalaz maintainers to be proactive in trying out release candidates and milestones against their codebase. And the maintainers of the community build have the right to boot a project for any reason that doesn't involve technical dissent. The terms explicitly state there is often no one right way to do it. Their stated reasons are political, though. They could have said too few libraries depend on scalaz anymore to justify including it in the community build and nobody would be alarmed. They instead included a political statement. There is bound to be backlash when you make a political statement. But how can a codebase violate the code of conduct? What violations were there by the maintainers? Cite the violations. Who did what? Who have you seen bashing scala or Lightbend in a way that violates the COC?
You know the part of the COC that talks about microaggressions? This is what they're talking about.
You can start from here: [https://np.reddit.com/r/scala/comments/9a11p1/newbie\_wondering\_about\_the\_history\_of\_the/](https://www.reddit.com/r/scala/comments/9a11p1/newbie_wondering_about_the_history_of_the/)
In the past I've seen it happen on multiple occasions. I'm not going to make a list here. Recently I haven't been following all channels very closely and I'm very happy I missed whatever drama that preceded this thread. I also couldn't care less.
Then why comment and make the claim at all?
While I might not care what, if anything, happened this time I've grown very tired of the fact that every time certain people show up drama is bound to ensue.
After reading the thread, technically it doesn’t look like a big issue. Just being removed from a CI, right? But it’s definitely seems a disrespectful and childish action. Apparently those SIP guys are like, we do whatever we want, now get out of our sights and go to reddit, lol. I’m super interested to see how this turns out, such a drama.
Wow, this doesn't look welcoming at all. I am new to Scala and taking into account what I just read, I am wondering how welcoming the community would be to a new member.
That happened a lot of time ago. Now, all toxic elements of the community went somewhere else. I found the Scala community very welcoming and they helped me a lot in my first steps.
That's a lot of drama!
Now I remember why I stopped reading those. When did this happen?
It's a joke
You probably only need a source generator. https://www.scala-sbt.org/1.0/docs/Howto-Generating-Files.html See https://github.com/milessabin/shapeless/blob/master/project/Boilerplate.scala and https://github.com/milessabin/shapeless/blob/master/build.sbt#L145 for an example
Can confirm: Am new to Scala and I have no idea what this is about
You might consider scalameta. [https://scalameta.org/](https://scalameta.org/)
Okay. This is unrelated to Slick's source generator, right?
This looks great. How well can this plugin to Play! framework? Is there documentation on it (the process of getting the object creation to play nicely with a Play! webservice)?
I'd rather have proof than someone's interpretation. If there's a link to it and both parties identify themselves formally for their contributions to one another I'll believe every word. Otherwise I'm not going to listen to one half of an argument. Also your point doesn't make sense. People don't hide each other's mistakes.
I don't even know. I've been told in the past I'm one of those damaging members and I don't even know why.
I figured it out, scalaz peeps were harassing the Scala Center team. They've been on and off again as far as kindness goes. And they put up with it for a long while because scalaz was the only thing out there for a while. Now there are other choices and they are getting fed up with the harassment. Even in the discourse thread someone told Adriaan to go see a thereapist for his past trauma. :(
As a developer, Cats was a great help, simply because it provided Scalaz-like functionality along with good documentation. When Cats came around Scalaz had only some (really good) blog posts by Eugene Yokota. That's not enough for a core library. I just went to the Scalaz web and the docs are incomplete and broken.
To be honest I joined the scala train and just ignores the drama. There are a lot of amazing projects and projects around, i just focus on this. 99% of the community don’t care about this drama they are just here to build great stuff with a cool language
as far as I can see, this is not persecution in any sense. not every scalalibrary gets to be part of the community build process
in what way? apparently i missed all this drama, and it didn't effect me at all.
&gt; I have no idea what this is about Speaking as someone not-new to Scala… You're better off keeping it that way. Drama this large and over this span of time obviously has an effect on the ecosystem, but you honestly aren't missing anything about not participating or even understanding it. The history of cats and scalaz is an interesting one just from a "how did the ecosystem get here?" standpoint, and [this](https://www.reddit.com/r/scala/comments/9a11p1/newbie_wondering_about_the_history_of_the/) does a great job of summarizing it from a remarkably neutral perspective. To the extent that you want to understand the drama, you're best off looking there. Keep your head above the water, good sir, and welcome to the language.
It seems Scalaz 8 started a few years ago, but it never took off. On the other hand, Scalaz ZIO was a refocus and rebranding of Scalaz 8 from what I can tell. Scalaz 7 series had been in the Community Build since the inception of the Community Build. In 2014, Scalaz was still a significant dependency in the Scala ecosystem so it was an obvious addition. That was five years ago, now. Around 2014 and even before, maintainers and contributors left Scalaz. A lot of bad blood existed within that Scala sub-community of functional purists. The schism was one of the motivations for the creation of Typelevel, and was before either Scalaz or Scala had a code of conduct to help deal with the issue. Scalaz tried to adopt a CoC, but it was probably too little, too late. Regardless, the Community Build (and Scalaz maintainer Kenji Yoshida) helped keep Scalaz 7.2 current through major Scala releases over those five years. The benefits were mutual, since Scalaz 7.2 was both kept current but also helped expose a few regressions in either the compiler or other Scala libraries. Most major development in Scalaz had largely dwindled, though, as most people started migrating to Typelevel and Cats. It was charitable that Lightbend tried to voluntarily add the Scalaz 8 and Scala ZIO projects to their Community Build early on in Scalaz 8 and Scalaz ZIO's development. However, it didn't appear they ever took off. The Community Build even spent cycles trying to get Scala 7.3 working, but gave up. The Community Build may have mistaken the latest Scalaz projects for continuity of Scalaz 7. Scalaz 8 never took off. It's called Scalaz ZIO, but the only relation is that the artifacts have the `org.scalaz` branding in the organization. It doesn't appear to be compatible with Scalaz in any way, and even starts its version scheme from 1.0 and not 8. The "Scalaz" in the name may only be aspirational or a signifier of taking its design influences from Scalaz. Most software and libraries in FLOSS usually choose new names to avoid this confusion. Despite Scalaz being a single monolothic project for years (well, there were scalaz-concurrent and scalaz-effect artifacts), the Scalaz community blessed ZIO as a sub-project. Over the five years between 2014 and 2019 that Scala 7 was frozen and stable, a lot of mindshare had migrated to Typelevel projects and elsewhere. It took years for the Scala ecosystem to migrate away from Scalaz to Cats and friends. That time had come, and the Community Build can now cut the cord. It's probably a good sign that it's time to move on, and for Scala to do better as a community. Unfortunately, a lot of this background story is usually omitted from the discussions. I'm continuing to omit it here myself. Having followed it, I don't think it's worth re-hashing or re-litigating. People omit the history because they are just tired of the flame wars and are trying to move on. A lot of people are disappointed that Scalaz was disintegrated. There is a lot of hope in the Typelevel project as a path forward. Finally, these functionally pure libraries are useful and interesting, but it's important to point that they have mixed success in Scala. They do have their time and place, but some of the most popular Scala projects and companies that use Scala don't need to use these libraries. The FP evangelism has a tendency to go overboard to the point of not always being either practical or useful.
&gt; As a developer, :)
No idea. I’ve never used it.
I haven’t tried it, but a huge amount of that book is code. I don’t see how you’d be able to get much out of it by just listening to it. (Then again, there are blind programmers, so what do I know?)
That's good to know. The process of pushing toxic elements out of the community seems to be a rather natural process. I am wondering what defines "toxic" though. According to what I've read in the above-mentioned link, there are some people who disagree with certain steps and approaches that were taken. Ignoring their voices would only deepen the crack inside the community and possibly scare away potential contributors. Just expressing an opinion without intention to resurrect a topic that seems to be long gone. &amp;#x200B; Anyway, I am glad that there are some people with positive initial experience in the community.
What problem are you trying to solve exactly ?
I think there's no shortage of people who toxic still left, however I've avoided direct interaction with most of them. The only one who've I've had a negative interaction with is unfortunately a Lightbend employee as well.
I’ve been using Scala for nearly three years, and only came across this drama recently. It’s really just a small sub part of the community, and on top of that, just because you use Scala, doesn’t mean you’ll ever have to interact with these libraries to a big degree (although people like to pretend otherwise)
CSV is causes schema loss. I don't think its possible to create a proper case class (where all fields are not String or Any) just by sampling data of the CSV. Either your schema will be vague (everything is a string or any) or you will end up with run rime errors where the parsing will fail. Things like Avro were created for a reason. IMO, /r/Franklinwritescode will learn a lesson in pain because of abuse of Macros and runtime errors caused by autogenerated code.
I can confirm Jasper-M's observation.
ScalaZ 8 and ZIO are totally different projects
There's an audiobook? Unless you are very familiar with coding functionally, I'm not entirely sure how that would work.
There always will be in every community. It's part of humanity and always will be. I really hate the word toxic. I think the word itself is "toxic" and would prefer if people call it what it is, ill-mannered. I spent some time in the thread and from what I can gather the people in charge there (I guess mainly LB employees) are taking serious offense and are the ones currently violating the Scala CoC they put in the place themselves. It's disheartening really.
If you check out the [Scala FUD Guide for Newbies](https://kubuszok.com/2018/scala-fud-faq-for-newbies/), that's a good dispassionate discussion.
It's not tribalism. It's just a huge amount of work to deal with some people.
I agree.
No one said anything so I'll bite. I don't think there is any sizeable market for such low hour commitment, at least in North America. Generally such high skilled employment is intended to be the primary thing you do for a living, and so at least 30+ hours of work per week is expected. &amp;#x200B; You might be able to find short term contracts to fill up your availability – those clients are more likely to only care about getting things done on time. Best if you have a personal network where you could fish such contracts out of, but working through a freelancer platform is also an option. Personally this doesn't look appealing to me, but some people do that. &amp;#x200B; Another thing you could do is switch to a better paying primary job. I know, depending on your current deal that might be easier said than done, but presumably your current job offers a good work life balance, so as you're ok with working more hours, you might be able to find a different employer who requires 50+ hour work weeks but pays more.
If you are trying to *define* case classe types at the start of an application then you are (largely) out of luck. Case class definition is compile time and "start of application" is post compile. If you happened to mean instantiate (existing) case classes from csv data then that's easy enough. Generating the source for those case classes during the build is also fairly straight forward. Dynamically defining them during the application runtime is a whole different challenge. Which is why this question is odd. Do you really need the case classes types defined dynamically?
Could you at least hare the list of "certain people"? This phrase used here and at the linked thread 100s times and still everyone hesitate to name them.
[https://github.com/ashwinbhaskar/functional-way](https://github.com/ashwinbhaskar/functional-way) . A way to ease the barrier of starting off with Scala and functional programming.
I can understand ScalaZ, but not ZIO. ZIO is a totally different project.
Hey! It's totally unfair! There \*is\* a Prolog implementation in Scala type system!
Haha. Love it
In general changing variable/package names and moving files across packages.
Play framework is the easiest and most complete framework we have, so unless you're trying to learn Akka, I'd recommend it.
That hastily spoken definition of monad, the whole scene looks so realistic I may as well be actually hearing the german
It is perfect, pure gold
How many people here know off the top of their head what the community build is or particularly care about what goes in it? My feeling is very few “everyday” users of Scala (not the uber pro library makers or few companies that are heavily into it) are really involved in the community at all. And by far the biggest sect of users - those from Akka/Spark world, don’t really care about the community squabbles. I might be completely off base but that is my intuition. And it points to the true problem of the Scala community - 90% of users are not involved in the community at all. Googling stuff on Scala points to 5 year old pages half the time. Libraries dont have simple documentation for the 80% common case. Akka and Spark are the 2 big killer use cases and they have basicaly completely independent communities comprising everyday users. All the people in cats/scalaz land, arguing about monad transformers vs effects, or decades old drama are basically off in a world of their own... the world of the Scala celebrities.
I don't follow? When a community schisms, both parts are still communities afterwards.
True as far as it goes, but being unwilling to exclude people who are being unpleasant ends up being more damaging in the long run, IME.
You often write in a very direct/aggressive style that takes positions that are not yet mainstream as given. When the wider programming world/culture does not accept that e.g. impure functions are inherently bad, it can be counterproductive to write in a way that implies e.g. that impure functions are obviously inherently bad and no reasonable reader could ever doubt that they are. Not because that's a false statement but because if a reader who doesn't currently see impure functions as bad takes you to imply their current views are stupid/unreasonable then that's not likely to lead them to improve (even if it's true). Obviously it's vital not to lose sight of when certain programming practices really are objectively better than others, and I wouldn't want you (or anyone else) to have to justify functional programming from scratch every time you recommended a functional practice. But IMO it's best for the long-term health of the community to write as though mainstream views on programming style were - not right, per se, but within the spectrum where there are tradeoffs in both directions and reasonable people could disagree - even when that's not actually the case. Telling people outright that they're wrong may work when the majority agrees that they're wrong, but when 90% of the programming community is doing it wrong, effecting change is a subtler proposition.
Great insight actually. But what really grinds my gears are the reason why Scalaz ZIO was removed from the community build. Let’s face it, it looks as an immature behavior from my PoV best described as: “We don’t like those people”. Yes, they introduced CoC. And I’ve thought it is there to make community more welcoming for new people. My contributions are humble, and hardly that this behavior will empower me to contribute more.
nice:) Would you be interested in contributing to something similar that I have been doing? - [https://github.com/ashwinbhaskar/functional-way](https://github.com/ashwinbhaskar/functional-way)
Hey this is really cool, I spent all weekend playing with it trying to recreate some of the services we have at my place of employment and it's relatively intuitive even with only a basic, undergraduate cs theory level understanding of FSMs. Thanks for sharing!
&gt; I am wondering how welcoming Scala community would be to a new member... You should stop wondering. A) The word community is overloaded. There are many communities. B) People who would not be welcoming are the minority.
&gt; This is a bit childish. It's more like a lot childish.
&gt; microaggressions One person's microagression is another person's "well sorry not sorry you can't handle the truth". Hot take: sometimes software folk lack empathy.
No doubt people lack empathy. Adrian has an impossible job, he does well at it in general. He should publish who's been harassing him. He doesn't deserve the abuse. John and Emily don't either. Emily is understandably upset, as is Adrian. Nothing of value was lost is just not true any way you slice it, though. It isn't the truth, it's just being edgy to be edgy. If the discussions around Scala could stay technical we could avoid all this drama. But they can't for some reason. So let's not fan the flames with untrue statements meant to provoke anger. That's not got anything to do with empathy. That's just wrong. Scalaz was the proving ground for typeclasses in Scala. It pushed the type system to its limit before Shapeless took over that role. Good or bad, it was one of the driving forces that caused the cultural shift away from symbolic method names, and toward more documentation than less. It's absolutely an influential project with a lot of merit.
That merit doesn't excuse spicy drive-by's like "you should see a therapist". That's not rooted in any technical factors.
I have a model that is defined as entries in a CSV. For example (first row is header): ``` name, type, nullable, calculated id, string, false, false date, LocalDate, false, false date_plus_30, LocalDate, false, true ``` Some of those fields need to be calculated. For instance, the `date_plus_30` field is calculated by adding 30 days to the `date` field (that's just an example). Input data would be CSVs containing records with an `id` and a `date` and final `date_plus_30` column that is blank. The data would be pulled in (as CSV), conformed to the model, computed and then the output data would be sent back as the same CSV but with the `date_plus_30` column filled out.
Excluding scalaz doesn't just exclude a few jerks. It has like 4 thousand stars; it excludes all users there too
You missed the drama that preceded this thread because it wasn't actually public. No one actually knows what happened other than the person that took action. That is disheartening to say the least. As a user i see a great library suddenly being given the shaft by influential people, and im not sure what can be done because i have no idea what happened.
This infra that we’re talking about is maintained and paid for by Lightbend, and they have final say over what projects they support, correct? Ergo it’s not a ‘community’ build.
Not trying to _define_ case classes. Sorry. Edited the question.
Having a non-compliant CoC was a known issue for Scalaz. Some of these Scalaz people try to argue with Lighbend people about CoC issues. The disrespect over the years from a few Scalaz members is well known, [as evidence of Daniel Spiewak's post](https://contributors.scala-lang.org/t/coc-compatible-community-builds/3097/44).
I already said that Adrian doesn't deserve the abuse. Neither did Emily at the beginning - Adrian insinuated that she and John were abusing him prior to Emily's response. Neither of those actions are acceptable behaviors that are likely to defuse an emotional situation. I'm in agreement with their technical decision - there are other projects that exercise the parts of the scala compiler exercised by scalaz and argonaut and are more heavily relied upon in the public dependency graph. It could have been a simple email to the scalaz maintainers explaining that their project was taking an inordinate amount of time in maintenance for the return on investment in the community build so they are being removed. Then, if the Scalaz folks were offended and started emoting, Adrian could rightly point out they were being ridiculous and it wouldn't look like retaliatory censure by one of the most important people in the scala community for a decades old fued between the core scala team and people no longer involved in scala. Instead we get drama where people's intentions are being called into question unnecessarily.
Again, true as far as it goes. Equally, a handful of jerks can exclude thousands or millions from your community spaces if they make them unpleasant enough.
Any community build ultimately lives on someone's server and someone decides which projects are part of it; that was the case before and after this change. It builds a number of projects many of which are non-Lightbend; a name that suggests that it's just Lightbend projects would be more misleading.
&gt; Wow, this doesn't look good at all. I am wondering how welcoming Scala community would be to a new member... Very. Just write code. Stay away from Twitter.
But clearly the Scala community does not have a say in what projects are in Lightbend's build server. Not in the same way that, say, we do in Scala's SIP process. Also, the name I suggested does _not_ convey 'Lightbend projects only', it clearly conveys 'Lightbend Scala' compatibility i.e. these projects are compatible with Lightbend's version of Scala.
You talk to your mother that way? &gt; Ugh, it’s &gt;&gt;=, ma!
 But when someone feels like it’s a persecution, what can you do.
Hi, nice to hear you find it useful, I did some final touches today removing dependency on out internal http wrapper, try it again!
IMHO they gave themselves the shaft by turning this into a public crap-throwing contest. The community build is primarily a large collection of regression tests for the compiler. Being included in it or not does not say much about the value of a certain project. It depends on a lot of different factors: popularity, usage of exotic features in novel combinations, amount of other popular libraries which depend on it, ease of adding it to the build, ease of maintaining it in the build, amount of crap one has to endure when interacting with the project maintainers. Apparently some people thought the added value of having Scalaz in the community build no longer outweighed the downsides of having it... This is very unlikely to affect users of that library at all. Scalaz will no longer be tested against bleeding edge Scala versions on Lightbend CI infrastructure, but it's easy to test that yourself once in a while. This has been turned into something a lot bigger than it actually is. By the way there are lots of other valuable projects which are not included in the community build, e.g. Spark which if I may say so is a lot more important project to the Scala community as a whole.
These are the kinds of blog posts I love.
Laminar has been a game changer for me. I never felt comfortable with the available Scala wrappers around React. Enter Laminar, which is lightweight and feels much more natural than what React ever did even when writing it in JavaScript. &amp;#x200B; I can wholeheartedly recommend you try it out if you're a fan of functional programming and want to try something different.
Yes! That was the absolute highlight!
I absolutely will! Shared it at work, people are enjoying it!
:)
I've upgraded real apps through Play 2.3 to 2.6 and the changes are not minor. The guides are long and take weeks to execute: [1](https://www.playframework.com/documentation/2.7.x/Migration24), [2](https://www.playframework.com/documentation/2.7.x/Migration25), [3](https://www.playframework.com/documentation/2.7.x/Migration26). There are dozens of huge, system-wide changes that force you to touch every controller - e.g: [Having to pass a "messages" object to *every single page* generated](https://www.playframework.com/documentation/2.7.x/Migration24#I18n) in your app. It means you app has to pass around the request literally everywhere so it touches basically 90% of your critical paths. [Controllers have been massively overhauled](https://www.playframework.com/documentation/2.7.x/Migration26#Scala-Controller-changes). You cant use methods in objects any more which means controllers that depend on each other need large refactorings. Everything that was cake had to be untangled. [Important auth modules](https://github.com/t2v/play2-auth) are stuck in cake pattern](https://github.com/t2v/stackable-controller), creating these horrible cake/dependency injection issues. [Adding a CSRF protection line to every single form on your app](https://www.playframework.com/documentation/2.7.x/Migration25#CSRF-changes) Changes in Play Framework are large, random, often pointless, questionable re-implementations of already solved problems (e.g. i18n). It's taken so much work to keep my apps similar to the latest version of Play that I almost take offence to the article suggesting that Play has been this steady easy framework.
I think this article explains with accuracy why did that happened [http://james-iry.blogspot.com/2009/05/brief-incomplete-and-mostly-wrong.html](http://james-iry.blogspot.com/2009/05/brief-incomplete-and-mostly-wrong.html)
&gt; I almost take offence to the article suggesting that Play has been this steady easy framework. Maybe this is an unfortunate consequence of Play being different things to different people. E.g. if someone used very few of the features they had large changes, then they would be under the (albeit limited) impression that everything is easy breezy.
That's actually pretty funny.
In that case generating code source at build-time defining both the case-class and deserialisation logic for the non-header rows is probably your best bet. &amp;#x200B; You don't need that logic to be tied to the PlayFramework. However you need to write some build logic. The SBT docs and gitter can probably help you.
We could do everything with AbstractSingletonProxyFactoryBean!
I can't give up my job, I love my job! I have full freedom to use the language of my choice on all projects, my input is heeded when it comes to design choices(probably the most important), I work from home, and all of my co workers are smart. I do really appreciate the response and understand where you're coming from, I am definitely not averse to small contracts and the like - it would be nice to do something like refactoring a codebase from "Scala as a better Java" to "Scala - The Functional Beast" or writing tests or something along those lines where deadlines are not so much of an issue (Just started messing around with fs2 and would be awesome if anyone had a project involving that) Obviously it's a shot in the dark but I don't lose anything by posting! If you or anyone else needs someone for a smaller contract or anything really feel free to contact me.
\&gt; You just made those words up right now. So many times I've been reading about FP and though this exactly.
I don't know how that rises to the level of someone who should not be welcome in the community. I suspect that the people who do think that are projecting something on to me that isn't there. I however have never understood what or why.
Android is unfortunately not a prioritized feature in the Scala community, nor is iOS support for Scala Native. Sucks because I'd love to use Scala to write apps, but it's a lot of work and the potential user base is probably not that large.
&gt; I don't know how that rises to the level of someone who should not be welcome in the community. I suspect that the people who do think that are projecting something on to me that isn't there. I however have never understood what or why. Maybe this is a personal journey for you to figure out. Maybe they are wrong. Either way, we'll never know for sure. So you'll have to settle for imperfect heuristics and proxies. If someone tells you, the way in which you communicate does not foster a collaborative environment, what do you want to do with it? Is this a random data point? Is this person a trusted individual? Does this person have something against you personally? All personal questions that you need to answer. Maybe your answer will be different than the answer of others.
Debating whether to share this at my job lol. This is hilarious.
Lucid Software | Software Engineer in Application, Dev Tools, or Site Reliability Engineering | Salt Lake City, UT, USA | Onsite | Full Time Lucid Software is the creators of Lucidchart and Lucidpress - world-class web applications that push the boundaries of what is possible in the browser. The entire application back end is written in Scala. The frontend stack uses TypeScript, Angular, WebGL, and the Google Closure Compiler. The build system is Bazel. We are hosted in AWS. We are a ~500 person company outside of Salt Lake City Utah, that is growing like mad. We are looking for - Application engineers to help build applications that users love. - Development tools engineers to help build a development experience that engineers love. - Site reliability engineers to help build a scalable, reliable, and performant production system. More information and the application can be found here - [Application Engineer](https://www.golucid.co/careers/f9cb83be-e016-4be5-91dc-598e17e8d04c?team=Engineering) - [Development Tools Engineer](https://www.golucid.co/careers/c8de139c-6da7-44dc-a4af-95052aa2a086?team=Engineering) - [Site Reliability Engineer](https://www.golucid.co/careers/be16cacc-4cd3-4be0-9ec0-070646f9ec69?team=Engineering) Please DM me if you would like to chat about any of the positions. Please mention this Reddit thread if you apply :D
I always wondered what would be of the perception of the Scala community if leadership had just outright banned people around a decade (?) ago when all this drama began? I knew the perception of this community was particularly bad when even members of the silent majority of Scala programmers - those people I knew in school and work but who never tweeted or blogged - would casually mention to me how Scala's community is full of assholes. That perception stuck around longer than warranted. Were the contributions of some of these members - aggressively negative, yet technical smart - worth it in the end? And now the history is so long and complicated that a new generation of Scala members want explanations that would undoubtedly lead to more drama and grief. So leadership rightfully ignores their requests and gets attacked again. &amp;#x200B; I believe Scala leadership should just pull the trigger and if we lose some would-be brilliant members then so be it. I just want everyone to just be sane and happy and to move forward. And I wish that the people who keep promising to leave would just keep their promise.
You might want to try your luck on the sbt-android gitter room: https://gitter.im/scala-android/sbt-android?source=all-rooms-list
The post on relations is first-class: [https://kubuszok.com/2018/its-all-about-relations/](https://kubuszok.com/2018/its-all-about-relations/)
LKQD | Senior Software Engineer | Full-Time | Onsite | Austin, TX 78704 LKQD is a video advertising platform that handles hundreds of billions of events daily. We're a small division, fewer than 40 people, in a large public company (Nexstar Media Group, NASDAQ: NXST). You'd be working with me on the core adserver, written in Scala, with supporting microservices in Go. The deployment environment is Linux on Kubernetes. Need to have: \- Clear communication \- Experience in a language with a decent type system (Scala, Rust, Ocaml, F#) Nice to have: \- Ad industry background (OpenRTB, VAST, VPAID) Dm me for more info
Mosaic Inc. | Sr. Backend Scala Engineers (3) | Oakland, California | ONSITE | Full Time Hi All, I am a senior manager at Mosiac - We believe that financing for modern home improvements should be simple and worry-free for both contractors and homeowners. We work with leading solar and home improvement companies across the nation to offer financing for solar energy systems, batteries, and efficient home improvements. Our systems are all Scala with play and Lagom for Microservices and we are currently looking for 3 Sr. backend engineers to help us scale to the next level Microservices architecture. We are located at Oakland and do have near shore teams that we collaborate with. We are great about culture and are mission driven, plus we have a fun environment to work in. Open to questions. &amp;#x200B; [https://www.joinmosaic.com/careers/?gh\_jid=1623285](https://www.joinmosaic.com/careers/?gh_jid=1623285)
Rewards Network | Senior Scala Software Engineer (SDET positions also available) | Chicago, IL, USA | Onsite | Full Time &amp;#x200B; Rewards Network powers the leading dining rewards programs in North America including partnerships with major frequent flyer programs, several of the nation's largest bank card issuers, and dozens of national corporations. We are looking to grow our Scala developer teams to scale out and tackle creating the rewards platform of the future by rethinking our existing infrastructure using functional programming principles. &amp;#x200B; We are looking for people who: \* Have experience with Scala (2+ years preferred), or are eager to learn \* Have experience with Docker, Kubernetes, and/or DC/OS \* Have experience working with Akka, Play, Spark, or other Scala-focused frameworks \* Have experience with Spark SQL, Cassandra, Elasticsearch, and/or Kafka (strongly preferred) \* Are familiar with and passionate about functional programming and software testing (ScalaTest, Specs2, Gatling, BDD/TDD in general) \* Are familiar with functional reactive programming (Reactive Manifesto signers get bonus points) &amp;#x200B; We are primarily hiring for senior-level positions as software engineers as well as SDETs, but we encourage anyone with Scala/FP experience to apply. You can private message me for more details and contact information, or comment with general questions.
If anyone is looking for examples of styles of communication that others may find distasteful or vaguely threatening, I'll point some out right now. &gt; I’ll be the first one to say it: sorry. To me, this reads as villainizing Lightbend. Specifically, "I will be the first among us to do MORAL_ACTION because I am better than you." &gt; “people who get along with Seth” This is a reductive, inaccurate depiction of what was said. Why include it at all? &gt; You can find me on Twitter. Sounds similar to the phrase "you can find me outside" which is a veiled threat. Why go to Twitter when the discussion is here? Also, it oddly shirks the responsibility of the conflict to the maintainers. The OP was the one with the problem, why not stay and help fix it? I get the feeling (begin insertion of personal interpretations) that the OP isn't being as charitable about interpreting people's actions. Therefore one person's preference or action is interpreted as an attack to another. This immediately creates a hostile environment that makes collaboration difficult. Why not favor a less hostile interpretation? Why not take people at their word when they say things like "x was difficult to work with and I don't want to work with them anymore". Also, I get it. We're all software-folk, very "proof-oriented" (haha proofs). But people aren't software. People don't always need or want proof. If you cannot bend on this idea of communicating with people (especially volunteers of all people), then maybe communicating with these people isn't your forte. And maybe you aren't easy to collaborate with.
&gt; That's a lot of drama! It's not even good drama; there are no receipts. It's a lot of vague-booking. `DRAMA.BAS` if anything.
&gt; Now, all toxic elements of the community went somewhere else. Ehh this is debatable. You can witness a whole bunch of people being toxic right now!
This was superbly done
Exclude who from what?
Ytel | Software Engineer (mid/senior/lead level) | Lake Forest, CA USA | Onsite | Full Time Come work with me and about 20 other engineers in sunny, warm, Southern California, no Scala experience required, just a willingness to learn! Our team is doing about 60% Scala and 40% Java. Company is doing telco/sms APIs (similar to Twilio). Good pay and perks (free lunch/snacks/flex hours), relocation to SoCal included. Feel free to PM with any questions.
https://www.youtube.com/watch?v=9Emn2YQNDl0 haven't tried it yet but looks promising together with metals...
I don't think it is what you want but maybe consider databricks? It has python and scala support. The issue is that everything has to be a notebook and if you want to execute code remotely it always runs on a cluster.
[Theia](https://www.theia-ide.org/) is a VS Code-like cloud ide and it should work with [metals](https://github.com/scalameta/metals).
I really liked the part with hemmorhoids and monoids and how they were both a pain in the ass
https://www.eclipse.org/che/
I'm only learning Scala, but I like doing both on my main desktop PC which I use to do serious stuff on and on my laptop which I use in my bed exclusively for fun stuff. For my Scala MOOC I ended up using a Linux system on a flash drive. That's an old tech solution for sure, but it works great since I find things exactly where I left them. I occasionally overwrite a backup of what I'm doing on the residing HDs, frankly this is really hassle-free. And bandwidth-shortages-proof too, which is important in my case.
Thanks!
Also to note, ZIO is separating itself from Sccalaz org for now (see https://twitter.com/jdegoes/status/1122934173960785920)
I think any words slapped onto that video would make me laugh hysterically. I do prefer the GIT version one though. (*it's ok, Linus uses CVS at home...*)
It excludes Scalaz and ZIO users from having a code-base that is regression-tested against the Scala compiler.
&gt; Apparently some people thought the added value of having Scalaz in the community build no longer outweighed the downsides of having it I think many here would disagree, in particular with ZIO. ZIO is an excellent edge case for the scala compiler. Removing it from the compiler regression test suite lowers its value. It is hard for other library maintainers to predict what will cause such actions without proper examples of what caused them. Here we are completely left in the dark. That is a problem. Claiming a CoC violation is a sincere concern, and should not be thrown around lightly. These should be treated with transparency, which we have not been given.
So there doesn't seem to be an out-of-the-box answer to this, AFAICT. But you might be able to put something together with a long weekend's effort and a fair amount of elbow grease. Here's what I'd do: 1. Acquaint myself with [Eclipse Che](https://www.eclipse.org/che/). 2. Acquaint myself with [Language Server sidecars](https://www.eclipse.org/che/docs/che-6/language-servers.html#ls-sidecars). 3. Acquaint myself with [Metals](https://scalameta.org/metals/), specifically as a Language Server, ignoring other editor plugins. 4. Implement a Metals Language Server sidecar for Eclipse Che. I honestly don't think this would be very onerous, but again, it doesn't appear to exist in any OOB form.
Scalaz was already a part of the community build process though, and has been for a long, long time. To remove them is absolutely a persecution. It is different than simply saying "well not everyone can be in here", because Scalaz was included. It is only now that things have changed, and we have no clear reason as to why.
If you are comfortable with terminal-based editors like Vim, then you can try editing code on a server via mosh/ssh using Metals (https://scalameta.org/metals/). For a more GUI-friendly interface, I would look into https://www.theia-ide.org/ as recommended by /u/oelang
Actually, you might also be able to use VS Code Live Share to edit files on a remote computer with a full IDE experience including terminal access as long as the remote computer can run VS Code https://marketplace.visualstudio.com/items?itemName=MS-vsliveshare.vsliveshare-pack
I've been pair-programming with a colleague using VS Code Live Share and Metals and it's AWESOME. Thanks so much for your work.
I guess people don't want to pay for open source. I know I don't. If they want to become enterprise and have businesses pay they should just do that. Asking the normal users to pay seems backwards - it's only companies that will benefit after all.
I wonder why?
Who cares JDG is just as toxic as some of the old scalaz maintainers in the first place (look up the controversy around LambdaConf keynotes for an example). Though the project ZIO is promising, you might as well just use Cats IO for effects, which is well supported, documented, and not a one man show. ZIO seems to be a library meant to keep JDG relevant in the community so that he can make big dollars doling out consulting and training programs.
Twitter is a terrible medium for any kind of civilized discourse. She's just baiting people so she can mock them in front of her followers. It's like a kid get bullied in front of that bullies friends in a school yard.
It's not a one man show, he is actively looking for contributors and makes a point of highlighting their contributions (e.g. Itamar Ravid's work on ZIO Streams or Wiem Zine El Abidine's work on STM). Also, he could not earn any money from ZIO trainings if the software were bad, because no one would be interested in it. I can understand that some people don't like his style, but I am also convinced that cats-effect would be worse without the competition from ZIO.
&gt; ZIO seems to be a library meant to keep JDG relevant in the community so that he can get into conferences and make big dollars doling out consulting and training programs. `hot-take.scala`
&gt; I can understand that some people don't like his style That's a polite way to describe some of his more infamous blunders. &gt; It's not a one man show, he is actively looking for contributors and makes a point of highlighting their contributions That's nice. He's still the guy in charge though. If ZIO were a person I'd feel bad for them. He's already shown his true colours and I'm not optimistic he'll ever change. &gt; Also, he could not earn any money from ZIO trainings I'm speaking of his general training practice, not ZIO specific things. &gt; I am also convinced that cats-effect would be worse without the competition from ZIO. Perhaps, but there are other options available out there as well, such as Monix Task. ZIO is just a vehicle for JDG to remain relevant.
&gt; Perhaps, but there are other options available out there as well, such as Monix Task. That's almost the same as Cats IO, so what I said about cats-effect also applies to Monix. &gt; ZIO is just a vehicle for JDG to remain relevant. So what? "Man develops software and gives it away for free in hope that others use it" doesn't sound scandalous to me.
Please don't use Guice. Play does not require it. It's only the default DI that's documented for similarity to Java code.
Nothing wrong with developing open source software, or making some money from it, but it gives him a platform to continue to be shitty to other people.
HTTP servers tend to come with their own routing API (akka-http, http4s, play, finagle, finatra, finch, etc) and they're usually tightly coupled to the overall server API. &amp;#x200B; It's nice to see a standalone routing API decoupled from any framework or ecosystem.
Apparently, dibblego has been running things all along behind the scenes? [https://contributors.scala-lang.org/t/coc-compatible-community-builds/3097/164](https://contributors.scala-lang.org/t/coc-compatible-community-builds/3097/164) His words are somewhere between cryptic and indecipherable.
This.
Did you have success with the source maps? For me they do only work in Firefox. In Chrome and Edge the files "App.scala" and "Main.scala" are just empty.
&gt; Why not favor a less hostile interpretation? Why not take people at their word... Excellent questions. You are doing the same to Emily... to show examples of needless hostility, of course. I think it is an ancient tradition. The elders of the community disapprove of a woman's behavior, so now she is a witch and everything she does and says is rationalized as evidence of her wickedness. &gt; I get the feeling (begin insertion of personal interpretations) that the OP isn't being as charitable about interpreting people's actions. I can see where she is coming from, though. If you are going to call your regression test suite 'community build server', then you can't complain if some people mistakenly think the community has a say in what belongs in there. If Scalaz was thrown of the community build server for being incompatible with the CoC, then it should be let back on again if it somehow becomes compatible. A non-hostile interpretation of Emily's words is that she initially tried to figure out what to do and later got frustrated when instead of a way forward, she got a series of rejections. &gt; And maybe you aren't easy to collaborate with. This reminds me of a research that compared recommendation letters that tenured professors wrote for postdocs in their research groups. The men generally got praise for their research, while women got praise for being a pleasure to collaborate with. This dynamic should reduce women's career opportunities in science because the selection committees don't mind a top researcher that isn't especially easy to work with. I have no clue if that finding survived the replication crisis, however.
It seems Kenji Yoshida doesn't believe it's a big loss either: [https://twitter.com/not\_xuwei\_k/status/1122972408120524803](https://twitter.com/not_xuwei_k/status/1122972408120524803)
I'm really excited about all the Scala content this year. :) I'll be doing two sessions myself: * Concurrent and Asynchronous Programming in Scala (Leap workshop that focuses on building skills) * The Long Road to ZIO (advanced lessons learned session, useful for library authors)
That's because someone did make them up, albeit like 60 years ago.
Nice, Scala.js frontend libraries could definitely use some common ground like this. I will try it next time I touch routing for my project. &amp;#x200B; Side note, your gitter link in the docs appears to be broken.
LC is the best conference I’ve been to. Regretfully can’t attend this year, but I’ve attended thrice now and enjoyed it immensely every time. The content is both wide and deep and the “hallway tracks” are unbelievable. It’s also a lot of fun, with good food and social events organized as well. The fact that its not a mega conference makes it easier to start seeing the same folks here and there after a day or two and start talking and getting to know other attendees. I also know John goes out of his way to get a very diverse and interesting crowd which is so much fun seeing people from all over and different backgrounds get together to chat and learn about Functional Programming.
Interesting, this could end up being a nice way for servers to migrate backends. Move the route handling to trail, provide something like "trail-&gt;play" and "trail-&gt;akka" or "trail-&gt; http4s" backends and then people can switch around easily.
&gt; PLEASE NOTE: When you purchase this title, the accompanying PDF will be available in your Audible Library along with the audio.
Isn't it the other way round, Scala compiler regression tested against those libs? I mean, isn't it the responsibility of a lib maintainer to ensure there is no regression in it?
Scalaz and ZIO we're previously confirmed to be backwards compatible with new compiler releases. Scala worked w/ Scalaz and ZIO to improve its compiler. This benefits all scala users. ZIO in particular is an excellent test for the compiler, and Scalaz 8 does a lot of interesting things as well. Scalaz/ZIO users will now have a library that is not confirmed to have backwards compatibility, and will have to create tickets for changes if there are bugs in the compiler. That is a significant downgrade; Scalaz/ZIO may have a sincere lag-time before being compatible with new compiler releases.
I've never seen the subtitles more in sync with a Hitler video
**\*Update:\*** Apparently Eclipse Che 7, currently in beta, integrates the Theia editor others have mentioned, and supports [VS Code extensions](https://che.eclipse.org/eclipse-che-7-extending-developer-workspaces-to-run-vs-code-extensions-in-the-cloud-cbe97e11d4d4). For your 4-machine case, the easiest way to get going with Eclipse Che 7 beta would likely be to install [minishift](https://www.okd.io/minishift/) on one (which I highly recommend as your single-node Kubernetes solution anyway), then use the [che addon](https://github.com/minishift/minishift/tree/master/addons/che) with the `--addon-env CHE_IMAGE_TAG=...` argument to select one of the [Che 7 beta images](https://hub.docker.com/r/eclipse/che/tags). Che 7 beta will then be available on your network, and hypothetically at least, the Metals VS Code extension will be supported.
Live Share is super cool, especially with remote coworkers
I recently worked on creating a FREE course on Scala. It is available at [https://bonsaiilabs.thinkific.com/courses/first-steps-in-scala](https://bonsaiilabs.thinkific.com/courses/first-steps-in-scala). I am an author with Pluralsight and already published 2 courses on Scala with them. Hope new learners find it useful
When you have a public example of your play-fsm based design then pls share
Hi, yes, we are open to external contributions as well.
I haven’t used Metals and I know it’s quite new but ensime-vim plug-in for vim works incredibly well and is definitely viable for code bases you are already familiar with.
This is a crap answer but for csv files you could copy and paste the header into a Scala file and then replace , with :String, write ‘case class X()’ around it and you’re practically there are you not?
Thats cool, great work. I saw your struggle using `Partial` with some of the ScalablyTyped typings, which isn't strange considering it's a quite unique typescript feature which is difficult to provide in Scala. I'm working on it though, and think we'll have ```trait `PartialLayout``` sooner rather than later :)
might be of interest - functions can be curried at runtime: scala&gt; val add: (Int, Int) =&gt; Int = _ + _ add: (Int, Int) =&gt; Int = $$Lambda$1033/69160933@15f8701f scala&gt; add(3, 5) res0: Int = 8 scala&gt; val add3 = add.curried add3: Int =&gt; (Int =&gt; Int) = scala.Function2$$Lambda$1055/731870416@65c86db8 scala&gt; add3(5) res1: Int =&gt; Int = scala.Function2$$Lambda$1056/1431699407@6cfd9a54 scala&gt;
may be of interest - functions can be curried at runtime: &amp;#x200B; scala&gt; val add: (Int, Int) =&gt; Int = _ + _ add: (Int, Int) =&gt; Int = $$Lambda$1086/158995547@c386958 scala&gt; add(3,5) res4: Int = 8 scala&gt; val add3 = add.curried(3) add3: Int =&gt; Int = scala.Function2$$Lambda$1056/1431699407@63300c4b scala&gt; add3(5) res5: Int = 8 scala&gt;
Good point, they can also be uncurried
Do we really need all these different codes of conduct? What is so different about different groups' expectations of behavior that they each need to spend time writing their own?
I have several functions and I can pipeline them using the andThen. For example: val a = ( x: Int) =&gt; x + 2 val b = ( x: Int) =&gt; x + 4 val c = ( x: Int) =&gt; x + 5 &amp;#x200B; val pipeline = ( a andThen b andThen c ) &amp;#x200B; Now I try to add a new function but in this case with 2 parameters: def d ( x: Int) ( y: Int ) = x + y &amp;#x200B; How can I add them to the pipeline? I have the obvious answer of d( pipeline( x) )( y ) but I´m wondering if there is another way to add it simply to the pipeline. &amp;#x200B; This is a simplification from a case I have at work where we have many functions with spark dataframes as input and output plus in some cases additional parameters. &amp;#x200B; Thanks in advance
You're making the exact right point, Typelevel is deprecating the old Typelevel CoC in favor of the more ubiquitous Scala CoC. :)
Mostly looks good. Although - "Remarks that violate the above code of conduct, including hateful, hurtful, oppressive, or exclusionary remarks, are not allowed" Who decides if written remarks are as described? I am just afraid that criticising code can be hurtful to somebody and the community member can be punished for giving honest feedback without sugar coating. Some people are a lot more direct (Eastern Europe, Japan,...). I don't see anything preventing that.
The way I see it is, if you're invested in sharing your statement to other people, then it implies that you care about affecting change in others. And if you care about affecting change, then I think that means that you should care about where your audience is coming from. This means tailoring your message to your audience. If you don't do so, your message is less effective. But if you instead want to affect change, and \*don't\* care where your audience is coming from, then it can come across as dictatorial, which is counter to what community is about, causes additional resistance, and is overall counterproductive. So it becomes a question of whether you more want to share exactly what you're thinking, or do you more want to affect change? Because they often imply different behaviors.
&gt; A shared code of conduct means a shared standard of good behaviour. Except it's used as a way to exclude projects and people which they deem "not CoC Compatible" - not just communicate a "standard". See the "Scala Community" removal of scalaz, zio, argonaut... https://github.com/scala/community-builds/commit/be8d3f07832c78044a65d3840a9338dc05943af7
totally agree that migrating real apps is really a pain. But this is about creating a very beginners guide to Play+Slick on Play 2.7.0 (and in comparison with my original tutorial for Play 2.4.x). I remember to update a real app from Play 2.4 to Play 2.5 and it was so painful !
Yeah hopefully common sense takes over and people can just rule accordingly thanks to public discussion forums or chat logs etc.
Yeah when a project is maintained by a group of people who harass or bully you often and then ask for forgiveness, people don't have time for that. Life's too short to be treated like shit.
do what the COC says and exclude the people, not the code or the hundreds of contributors then
I'm pretty sure this particular Lightbend Employee doesn't care what I've posted on reddit, or even cares what I've had to say, I've never he had an interaction with them on here before.
I understand what you are saying. A lot of people who worked really hard on the project and did nothing wrong. Why punish an entire ecosystem because of a few people? The problem was that over the space of years they would ask people to help fix their builds to incorporate changes for new scala versions and work together to resolve issues. And during that time scalaz team members have been awful to work with as in abusve towards Seth and Adriaan etc. And some scalaz members have apologized, left or been replaced, but new ones just as toxic have arrived. In that very thread emilypi displayed many toxic behaviors, gaslighting, projection and strawman attacks. She would literally reframe what she said to make adrian appear as the abuser. There was just no winning. Which is why after years they are done trying to work with people of that nature.
so why is Emilypi still commenting but the code is banned? seems backwards
Is there anything going on Saturday June 8th?
You'll have to reread what i said. Because in order to get your code in the build, you have to have maintainers of the project to work with that aren't toxic.
Ooh scala&gt; Function.uncurried(add3)(3,5) res6: Int = 8 I didn't know that - thanks!
Ah, great, a new CoC for Typelevel to use against the 'out group' and ignore for the in group...
 [https://status.leagueoflegends.com/#na](https://status.leagueoflegends.com/#na) [http://status.github.com](http://status.github.com/) Currently planning out a status page that works for all my projects (and a project may have multiple services). I also want to make it send Discord messages to me when a service fails. Just want to practice more http4s + fs2 + circe stuffs :)
Except i've been harassed by someone in TL and they aren't banned or asked to stop contributing, because they're of the Miles/Lars gang.
Is that stated in the CoC? All I see is that you’ll be kicked temporarily, then excluded. Not that every project you’ve worked on will be blacklisted. What’s the point of a “standard” when it’s capricious and changes based on who’s upset at who?
Twitter | Senior Software Engineer | San Francisco | ONSITE &amp;#x200B; Working on infrastructure tools with Scala! &amp;#x200B; [https://careers.twitter.com/en/work-for-twitter/201904/senior-software-engineer-infrastructure-management-services0.html](https://careers.twitter.com/en/work-for-twitter/201904/senior-software-engineer-infrastructure-management-services0.html) &amp;#x200B; MP me for more information!
That's horrible were you able to share with the community what they said or do you have any links to it?
Yeah i don't know enough about it. All i'm saying is that if i were working on a project and someone was telling me how fucked up i was just because i disagreed on some form of project change and started vilifying me and making feel crazy. I wouldn't want to work with them or their project.. That's just me. I know some people like it rough :)
Maybe use currying? val pipelineD = pipeline andThen d(_: Int) pipelineD(1)(3) // 15 d(pipeline(1))(3) // 15
I'm working for Netflix and we are looking for 2 Data Engineers in the Bay Area. We pay way more than those numbers. Send me your CVs if you have experience with Scala and any of the data processing framework like Spark or Flink. [https://jobs.netflix.com/jobs/864557](https://jobs.netflix.com/jobs/864557)
Circe is amazing, I'm saying that it took a lot of pain to switch to circe and now we are very happy with Circe. jsoniter-scala is not really useful for Circe since it already support automatic codec derivation from case classes.
We are looking for someone for this one: [https://jobs.netflix.com/jobs/864557](https://jobs.netflix.com/jobs/864557) Drop me a message if you're interested.
Safespace
ScalablyTyped was actually one of my main motivation to check that out. And there was always a facade for every Javascript I wanted - really great! I actually struggled with 2 points: 1. as you mentioned `Partial` made me really think if Typescript would be the better fit;) 2. for each Library I had troubles relate to the Javascript documentation.For example: * In JS-Doc: `Plotly.newPlot('myDiv', data, layout);` * In ScalablyTyped: `typings.plotlyDotJsLib.plotlyDotJsMod.^.newPlot('myDiv', data, layout)` I started this pattern `import typings.plotlyDotJsLib.plotlyDotJsMod.{^ =&gt; Plotly}`so the code matches the docs. So I was wondering why not using`object Plotly`instead of`object ^`
I guess his point is why have so many CoC. Just like there are licenses , mit, apache etc good ones and gpl etc bad ones, we can have a standard list of CoC. Good license: Nobody is allowed to insult anybody. CoC_MIT You can punch anybody as long as you call them Nazi beforehand. CoC_GPL Everybody can punch everybody. ©All Rights Reserved
Yeah, It's not optimal. I'm doing exactly the same, and it's definitely an annoyance. I'll be tracking thoughts in https://github.com/oyvindberg/ScalablyTyped/issues/14
I find it ridiculous there is need for such thing, and any dispute over it. I guess I'm just too old, but if someone harasses me on internet I just block him. And by no mean I extrapolate community from behaviour of one person towards me. Like, in my life, my friend, a C++ is an ass to me frequently, I don't think all C++ devs are asses. And I still like him.
Then say that. If a human moderator judges that a particular person (or group) is bad for their project and excludes them, it's clear what's going on (and other people might agree or disagree with that moderator decision and that's fine). A project that already had a robust, trustworthy institutions for resolving these kinds of disputes (e.g. a moderation committee that the whole community respected) might eventually benefit from formalizing a code. But there are no such institutions in Scala. Trying to introduce a code without an institution that's trusted to apply it is putting the cart before the horse. Introducing these codes of conduct doesn't make those situations any better or easier to resolve - quite the opposite, as we saw in the above incident. "Has this person violated the CoC?" turns out not to be any easier to determine or demonstrate than "has this person behaved badly?" - indeed it seems harder. A code is supposed to clarify what behaviour is expected but we can see the Scala CoC has been a total failure on this front: all it's done is add more confusion than if there was no code at all.
You can use any Java library
Just curious, where can we see that toxic behavior by new Scalaz members?
Play framework ships with one if you’re using Play already.
I have enjoyed using **Scalingua** in the past. There is an sbt plugin for it that can do string extraction.
I believe most people can tell the difference between direct and respectful criticism and behaviors listed above. There are ways to correct individual mistakes by mods. What makes you think otherwise?
Lots of activities on both Saturday and Sunday. Saturday is the big hike and trip to a local brewery.
&gt; toxic behaviors, gaslighting, projection and strawman attacks. Toxic behaviours is vague, and the others aren't against the CoC. What exactly was the CoC violation?
That may be the case now, but I think that’s mostly because there wasn’t really a push in the past. But if you investigate the ScalaJs-libraries, then you see that there is a lot of support for React in Blogposts, because you can build Apps with it. And I think as ScalaJs gets more widespread there will be a higher demand for other type of front-end development within Scala. And that’s why I love the open-source nature of this language. If we as a community think it should be changed, then I dare to say we can! I researched some links to help the original poster of the GitHub-Issue and posted them on said issue. I know it’s not a lot, but I try to do at least a little. Who knows, maybe something comes of this and in half a year or so we can build Android Apps with modern Scala.
Sadly that seems pretty much dead too, maybe r/androiddev ? I don't know how much backlash that would get, though\^\^
Here's a sneak peek of /r/androiddev using the [top posts](https://np.reddit.com/r/androiddev/top/?sort=top&amp;t=year) of the year! \#1: [The future of Android Development](https://np.reddit.com/r/androiddev/comments/9n88wv/the_future_of_android_development/) \#2: [When you have only 8 gigs of RAM](https://i.redd.it/ktxfv4g857821.jpg) | [111 comments](https://np.reddit.com/r/androiddev/comments/ac509y/when_you_have_only_8_gigs_of_ram/) \#3: [When you change the code but forget to rebuild](https://v.redd.it/rq3argkri3411) | [25 comments](https://np.reddit.com/r/androiddev/comments/8r8ikt/when_you_change_the_code_but_forget_to_rebuild/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/afd0dd/blacklist/)
Have you read the CoC? It's not just about harassment. It's also about setting up a community where people feel welcomed.
Linus Torvalds
I have. And I don't think you can command someone to "show empathy" etc. I would prefer if we didn't have the ability to label someone based on CoC, but rather take person as is. Ok, this guy XY is not really emphahetic, who knows what he's been through in life, must have been pretty hard on him that he lashes out on me. I feel sorry for him, and I will not interact with him anymore. I just don't feel it's right to ban/remove/etc. someone from community just because that person is a jerk (or that we feel so). We should strive to be one community, with both good and bad that's with it. But maybe I am part of the problem as well - but it's the life I've lived that led me to these opinions (I've had friend being labeled as jerk when they were undergoing very rough patch in his life). And it seems to me the CoC discussions and fallouts are the toxiest. I do apologize if this post or parent post offended anyone.
There has been no xml talk that I know of, so no change.
[Dotty and xml-literals](https://dotty.epfl.ch/docs/reference/dropped-features/xml.html). So the support will probably not be in the current form.
XML literals will be supported in 3.0 but deprecated in favor of a string interpolator (prototype at https://github.com/allanrenucci/jsx-interpolator). See https://contributors.scala-lang.org/t/proposal-to-remove-xml-literals-from-the-language/2146.
There was a SIP meeting in November, where members reluctantly voted to keep XML literals until a suitable replacement appears. [https://gitter.im/scala/center?at=5bfc28b1fa7bbb3fe009f677](https://gitter.im/scala/center?at=5bfc28b1fa7bbb3fe009f677)
This is beautiful. You can literally click someone out of your life if you want, why does the community have to micromanage this? There are far better things to spend time on. BTW /u/fromscalatohaskell do you code professionally in Haskell? What's the biggest pro/con moving from Scala?
and the point of the above post is that the number of CoC just decreased by one.
Thanks for the info!
You'll have to ask them.
[removed]
Jon Pretty was doing some cool i18n stuff a few years back. Repo is here https://github.com/propensive/rapture but it's marked as archived. I don't know what state it's in, nor whether it's completely deprecated vs moved somewhere else though.
I think you'll get more answers if you give certain categories (e.g. web framework) and ask commenters to give what they perceive to be the best for each category
Please don't mischaracterize what happened. A project was removed from Lightbend's regression suite for testing community projects against the latest scala builds, because the Lightbend employees maintaining it felt it was too hard for them to continue doing so.
What IDE are you using currently? What differences are there between the environments? If it's just code changes and you want to sync more flexibly than via git, you can use something like Dropbox. If you frequently change IDE settings or add plugins, some IDEs allow you to synchronize those across multiple computers. If it's your broader development environment, like installing databases and so on, I would very strongly encourage you to get comfortable with docker-compose (if you aren't already) and use that. It will ultimately solve more problems.
Set up a poll where you can get people to vote on the ones they use. Then post the link here.
Wrote a website with the front-end in Lift and the back-end in Play, that let's you remotely interview potential candidates or practice coding problems for interviews if you're the interviewee. [https://hack4ever.org](https://hack4ever.org)
Look at https://github.com/projectfluent/fluent. There's no jvm implementation currently though probably
the stated reason was “CoC incompatibility”
[link](https://github.com/makkarpov/scalingua) (I suppose this is the one?)
&gt; if someone harasses me on internet I just block him It may be feasible for personal emails or IM. I guess it's not so easy to block someone out of a public community forum or open group chat, especially if it's central to some community. If you do, the person may resent you and find other ways of attacking you, disparage you on other media, etc. All the while, they may never realize that they have been dicks, and that their behavior has been reprehensible from the start, because nowhere did it say what a reprehensible behavior meant. I think you shouldn't underestimate how clueless some people are about how obnoxious they come off online, and how easy it is for them to take blocks and bans personally as some kind of holy war against them. Unfortunately, I'm not sure a CoC really solves any of these fundamental issues, but I hope it makes it slightly better. What's for certain is that things are not always as simple as "if someone harasses me on internet I just block him".
That's it!
What events led to this posting?
[This](https://contributors.scala-lang.org/t/coc-compatible-community-builds/3097), I believe.
I mean recent drama showed that at least part of community is not satisfied with actions of those organizations. Those orgs are what keeps Scala alive. Don't you think some changes are needed? Clearly for you to need to make such a statement somebody/something was done not right. Tip: Do a survey, Q &amp; A, figure out what happened, what can be improved from other parts of community - even that could help restore health of community
I wonder if they have considered banning Linux from the scala project
I read `Metals works only with Scala versions 2.12.8, 2.12.7 and 2.11.12` from their homepage.
no I don't code professionally in Haskell, only hobby
My bottom line is, CoC is bringing more problems than it claims to solve. At least that is the way it seems to me. I also hope it makes things better.
Linus Torvalds has [apoligized in 2018](https://lore.kernel.org/lkml/CA+55aFy+Hv9O5citAawS+mVZO+ywCKd9NQ2wxUmGsz9ZJzqgJQ@mail.gmail.com/) and since changed his style of communication.
Man this has been a ride reading into. Appeartly few scalaz maintainers are toxic. There is also a build of scala that includes a bunch of libraries from the community. This way you don't need to spend a bunch of time compiling those libraries. The maintainers of the scalar community build felt like it was not worth keeping scalaz include due to those toxic scalaz maintainers. However all this was wrapped up in watered down commits and remarks rather than being blunt about it. Then go on about how being in a scala community build is earned.... which just adds flames to a fire. It would have been enough to flat out say, we do not promote hate, so we've removed scalaz and sadly all projects that depend on scalaz. If you are one of those projects we are sorry, let's talk about possible inclusion down the line.
This might be relevant https://code.visualstudio.com/blogs/2019/05/02/remote-development
&gt; Scala is used in many different ways. There are the people who use it as a “better Java” with more powerful object-oriented features, and there are the people who use it as a “poor man’s Haskell”, concentrating on the purely functional language subset. And then there are the many in between who use it in a predominantly functional style with an object-oriented module structure, without being too dogmatic about it. &gt; I see this difference of approaches as a big opportunity. This resonates with me
Yes, and you can also read the follow-up thread. Which reason do you think is the real one?
Not sure if you’re saying the CoC was invoked in the commit message to imply authority to what was ultimately an ad-hoc personal decision.
Here here
The burden of all this ceremony is so sad and stupid. Such a waste of time. Caused by a minority of trolls.
I would say, depending on how you unpack it, the commit message was either a terribly worded explanation, or an excuse rather than the actual reason. The first way would be "behavior incompatible with Scala's CoC \[on the part of some individual\]." The second way would be "scalaz's CoC is incompatible with Scala's \[and therefore can't be included for unspecified reasons\]." Either way the commit message doesn't make a lot of sense. As for authority vs. personal decision, that isn't the question, since the people who made the decision are authorized to make it. It's their company's regression suite. &amp;#x200B; In any case I don't know exactly what happened but my more generous interpretation would be that maintenance related to keeping scalaz in the build tended to involve private communication (e.g., about progress on fixing a regression), and people on the Lightbend side felt repeatedly hurt or drained by that other party, and thus that it was costing too much emotionally to justify keeping it. Of course, there are a lot of less generous interpretations, and the generous one doesn't make them into perfect angels (then again, who is?), but I do think it's quite plausible.
The correct phrase is: Hear, hear! That is, unless someone is asking, “Who wants more wine?” Then you can say, “Here, here!” and pound your fists on the table. “Hear, hear!” simply means “hear him” or “hear her” and is a sign of approval of the previous speaker. English reference books mention here, here only to note that it’s wrong.
&gt;There is also a build of scala that includes a bunch of libraries from the community. This way you don't need to spend a bunch of time compiling those libraries. The community build is *not* a different distribution of Scala. It's a tool used by the compiler team to automatically test the compiler against a range of popular and demanding libraries.
&gt; There is also a build of scala that includes a bunch of libraries from the community. This way you don't need to spend a bunch of time compiling those libraries. The maintainers of the scalar community There are a number of errors here.
Good bot!
Is this about the scalaZ thing?
Who, exactly, are the trolls? Are you saying the scalaZ maintainers are trolls?
Don't know why you're being downvoted. The entire Scala community has been hurt on recent events and I consider myself part of it. It is sad but I hope we look forward to only look ahead and leave the past behind.
Tbf, I feel like this could have been a lot worse. Sure, there have been some "not-so-nice" things that have been said, but it still feels more like a civil discussion as opposed to the all out shit-storms that happen regularly in other language communities.
&gt; [–] GoAwayStupidAI 1 point 4 hours ago &gt; Good bot! User name does not check out!
It's a welcome respite mentally. Ordnung muß sein!
If you use `mill`, you just stay in the shell, and Mill does the start-in-background thing automatically for you. It works like this because I had exactly the same pain point that you are now facing. In general, it just works, so perhaps it's worth exploring
From what i have heard and read on internet , scala is most preferred for spark , is it so ?
Here we go again. "Scala wars". And always the same culprits. 🤨
There was a post from the last scaladays that had top libraries in each category.
Many people came to Scala because of spark but there is still a sizeable community using Scala without using spark.
So is it also safe to say scala with spark is much faster than scala with python ?
For me it is pretty simple. Community build uses computational resources and this costs money. The Scala warlords are wealthy Swisses and they intend to use their wealth to control the Scala community.
You're fanning the flames with comments like these
Who is this minority?
Take a look at Amazon Linux workspaces &amp;#x200B; [https://aws.amazon.com/blogs/aws/new-amazon-linux-workspaces/](https://aws.amazon.com/blogs/aws/new-amazon-linux-workspaces/)
Stop bringing gender into something that has nothing to do with it.
Mind your own business.
&gt; Would you have accused me of this if I had picked male examples? If so, who here is bringing gender into something that has nothing to do with it? Absolutely. This drama has nothing to do with anyone's gender but their behaviour. This is not an eternal struggle of certain genders. Some members of the community have been toxic towards the others. Someone finally decided that they didn't want to deal with it anymore.
You aren't really replying my questions, but I agree with the answer nonetheless. Maybe you tried to add to hyperforce's examples of needless negative spin. In that case, nice try!
&gt; Function.uncurried(add3)(3,5) not sure why i get an error ``` Function.uncurried(add3)(3,5) &lt;console&gt;:13: error: overloaded method value uncurried with alternatives: [a1, a2, a3, a4, a5, b](f: a1 =&gt; (a2 =&gt; (a3 =&gt; (a4 =&gt; (a5 =&gt; b)))))(a1, a2, a3, a4, a5) =&gt; b &lt;and&gt; [a1, a2, a3, a4, b](f: a1 =&gt; (a2 =&gt; (a3 =&gt; (a4 =&gt; b))))(a1, a2, a3, a4) =&gt; b &lt;and&gt; [a1, a2, a3, b](f: a1 =&gt; (a2 =&gt; (a3 =&gt; b)))(a1, a2, a3) =&gt; b &lt;and&gt; [a1, a2, b](f: a1 =&gt; (a2 =&gt; b))(a1, a2) =&gt; b cannot be applied to (Int =&gt; Int) Function.uncurried(add3)(3,5) ```
No, you can't literally click someone out of your life if you want, at least not in all cases. If Contributor A is consistently hostile to Contributors B, C, and D, how are they supposed to work together on a particular project if B, C, and D have all sent A to /dev/null? "Just block them" is nothing more than "suck it up, Francis" posturing.
"... I want to earn some extra income.... I have about 20 extra hours per week..." Build your own business
cats, cats.effect, cats-mtl, http4s, fs2, fs2-kafka, doobie, circe, pureconfig. I think that’s mostly it. We also use more occasionally refined for type refinement, and enumeratum. That’s what I can recall from the top of my head.
Take a look at polls done at each scalar conference, here is the most recent one: [https://blog.softwaremill.com/scalar-2019-whiteboard-voting-40b31e4f7f7](https://blog.softwaremill.com/scalar-2019-whiteboard-voting-40b31e4f7f7) &amp;#x200B; Over last two years my team migrated from python to scala+play+play-json+slick to akka-http+quill (with small stop for doobie)+circe+cats and we now consider adopting http4s.
&gt; who here is bringing gender into something that has nothing to do with it? You literally brought up a study about gender in the workplace. Would _you_ have brought this up if the person in question had been a male?
By order of importance in our codebase: zio, cats, http4s, refined, circe, monocle, scanamo, magnolia, akka (for sharding only), newtype, pureconfig
Absolutely. Hyperforce's remark about being easy to work with reminded me of that study.
Akka HTTP, Slick, Akka Streams and Enumeratum for me :)
Spark
In order of importance: Play, Akka Streams, Akka Typed, Cats.
Finch, finnagle, pureconfig, cats
zio, doobie, cats, play, play-json, akka-http, sttp, specs2, scalatest
Main ones: finch/finagle, doobie, cats (cats-effect, cats-tagless, cats-mtl, ...), scalaz, circe, treelog, knobs, kind projector, monocle
Zio, Spark, Akka HTTP, Circe, Pureconfig, Scallop, Sttp, Monocle, Scalatest, are the first that pop to mind (in no particular order)
Monadless, akka http, macwire, circe, sttp, guardrail, scalapb, elastic4s.
play(we got some useful libraries built for it -.-), cats, circe, sttp, doobie, scanamo, pure config, akka-streams-kafka, refined, Sangria, monocle, zio (getting started and liking it so far)
Any troubles with f2-kafka or is this just working?
It works well, and bugs are usually addressed quickly. There’s also a Gitter channel which is quite active. I started using it on version 0.16 IIRC, so must have been using it for about 6 months or so in prod.
Can I ask which fs2-kafka you use? Because when I search it, there are 2 repos showing up
This one: https://github.com/ovotech/fs2-kafka
You should edit to include where you are from as well! I'm curious how it shifts based in region.
You are describing something similar (but not exactly) to Monad. For example, I can define function myToString which works for any container F[_] ``` import cats.Monad def myToString[F[_]: Monad](fa: F[Int]): F[String] = Monad[F].map(fa)(_.toString) ``` Then it can be applied for options: ``` import cats.instances.option._ val option: Option[Int] = Some(123) val strOption: Option[String] = myToString(option) ``` or for Either's ``` import cats.instances.either._ val either: Either[Exception, Int] = Right(123) val strEither: Either[Exception, String] = myToString(either) ``` You want to use partial function instead of total function. Let's say that we have F[Int] and PartialFunction[Int, String] = { case i: Int if i % 2 == 0 =&gt; i.toString }. What will be result for applying this function to F[Int]? If Int is even then result is F[String] otherwise what?
Akka streams, akka http, some datatypes from cats, avro4s, elastic4s
I see quite a lot of ZIO here. For what you use it in yours project?
Play, quill, macwire, akka typed and streams
Akka, Akka HTTP, Akka streams, cats, slick
In no particular order: Akka http, play json, slick, cats, mill, alpakka mqtt, blackdoor jose, etc
Actually it does–'go away _stupid_ AI' being the key distinction :-)
My case: EPG import microservice (instead legacy java code). Import time down from ~2 hrs to less than 5 minutes + extra functions (rabbit, couchbase). Definitely, will use for future projects.
Spark is def #1 for us. Then play+slick. While we have some internal libraries that are more straight FP most of our scala stuff falls under the better java (and spark) category.
We really use a mix because we started off on the Lightbend stack and now use more and more TypeLevel stuff. &amp;#x200B; By order of importance: \- akka-http (server, and client libs) \- slick \- doobie (for newer stuff) \- akka-streams \- fs2 (for newer stuff) \- cats \- enumeratum \- some Shapeless and Scalacheck \- sbt
Yup
Spark, shapeless, cats, sttp.
Finagle, finatra, heron, scalding. Yes I work at twitter and yes I’m hiring (pm for details!)
Actually `handle` and `handleWith` in `MonadError` use `PartialFunction`, so this is perfectly the base for a `MonadError`.
scalatest, scalamock, scalafmt, wartremover, sbt-native-packager, better-files, and the usual play, scalatra, akka, akka-http
why not java kafka-streams?
This is my best attempt, based on Cats, which isn't perfect, since the behavior of mapping the value in `Some` is generally considered analogous to mapping the value in `Right`. To make it work right, you could right an entirely custom typeclass. import cats.Foldable import cats.Monad import cats.instances.either._ import cats.instances.option._ def unifiedErrorMatcher[F[_]: Foldable: Monad] = { object matcher { def unapply[T](value: F[T]): Option[T] = Foldable[F].collectFirst(value) { case x =&gt; x } } val f: PartialFunction[F[UglyError], F[PrettyError]] = { case matcher(error: VeryUglyError) =&gt; Monad[F].pure(VeryUglyButPrettyError()) } f } // We need apply because otherwise it tries to use Some(VeryUglyError()) as an implicit. println(unifiedErrorMatcher[Option].apply(Some(VeryUglyError()))) // Some(VeryUglyButPrettyError()) // Swaps are required here because Cats has right-biased either. println(unifiedErrorMatcher[Either[Model, ?]].apply(Left(VeryUglyError()).swap).swap) // Left(VeryUglyButPrettyError())
akka http, akka streams, alpakka, circe, quill, enumeratum, macwire. I guess that's mostly it.
I have written a blog post about using ZIO instead of Cats Effect with the 47Degs Fetch library http://justinhj.github.io/2019/05/05/using-47degs-fetch-with-zio.html I'm considering writing a project that uses Coursier in some way, possibly as a way to interactively add dependencies to scala build files.
Because it’s a functional codebase, we would end up having to write some wrapper, with code very similar to fs2-kafka to be able to control side effects and make the streams delayed in F, for every application.
Can you please share your experience of mixing akka with pure fp toolkit? There is no pure fp tools for clustering/balancing yet, so I don't think I can convince my team to abandon akka with its imperativeish style in favour of fp. I fell that it is very complicated to establish friendship between akka clustering utils which require you to define actors and stuff and fp ideas. This might come down to just wrapping *impure* akka code using some general techniques, but I would really like to know how you accomplished that
Sure: I created an abstract service (trait) for a type A that has a `send` method that takes an A, and building that service requires a function (we can call it behavior) from A to UIO[Unit] (or F[Unit] if you use TF). Then I created an interpreter for Akka, that creates the ActorSystem and setup the sharding when it's initialized (all effectful code being wrapped in IO), and in the created actor, when I receive an A I just call the behavior function with that A and run it using `unsafeRunSync`. The whole thing is about 50 lines of code. That way, the rest of the code doesn't see Akka at all, I could even build another interpreter if an alternative emerges. But this is okay because I only need the ability to send messages to a shard. A less radical approach if you have existing code using Akka heavily would be to keep the actor code as small as possible, write all the logic in pure FP and use `unsafeRunSync` in each actor's `receive` method to run your logic.
We are monitoring team focusing on cloud-native service monitoring. * For log infrastructure, we use: flink(scala api), akka stream, druid(with tranquility, which is written in scala), elastic4s. * For metric infrastructure(metric collection, metadata management), we use typelevel stack. * For user-end app, typelevel stack(new) and akka-http(old).
It looks like a case of the XY problem : [http://xyproblem.info/](http://xyproblem.info/) . Anyhow, I'm gonna assume that you're trying to find a construct that let you reason generically about errors, in which case you should look into [ApplicativeError](https://github.com/typelevel/cats/blob/master/core/src/main/scala/cats/ApplicativeError.scala) or the more powerful version : MonadError. This will not work for `Option` though : instances of these constructs do not exist for Options (the reason becomes obvious if you think 5 minutes about it). This is probably a sign that using Option as a wrapper to Error is not great, and if you control the modelling, you should probably switch to `Either[Error, Unit]` instead. You can also try coming up with an homemade abstraction as it was suggested in this thread, but sincerely, you're better off using some existing ones, they are likely to cover a lot more usecases than what you'd be coming up with.
You mean spark with python? And what's the point you are trying to make in the context of this post?
Wow, I never knew about http://yxproblem.info This is great! Right on par with https://0.30000000000000004.com
Hi there, maybe I should give more information about my problem and how I'm trying to solve it, my bad. I'm building a web-service that make requests to an external API. To make those requests I'm using STTP and CIRCE to parse responses and map them to case classes (ADT). My web-service has it own ADT for error states with relevant information, so I translate errors from the External API response -&gt; Internal Error ADT. I have different endpoints + operations implemented and quite a few of them share External API responses, so I would like to reuse the pattern matching Partial Functions I have. I have two important types of External API requests, with payload and without it. Responses with Payload are modeled as Either\[ErrorResponseADT, PayloadModel\] and the ones without we simply have Option\[ErrorResponseADT\], the absence of error is treated as success. &amp;#x200B; Regarding switching to something like Either\[Error, Unit\], I'm not the biggest fan of using Unit, I prefer to use a dummy case class to represent the response like Either\[Error, DeleteResponse\] , even without value. However I think it hides the fact the External API doesn't have a Payload in the response and In my opinion It's hiding details to the developers. &amp;#x200B; Now you know why I think I need to abstract over the container, I might be wrong and I'm open to all types of suggestions, you already made me question myself quite a few things! Hope this shed some light into the real problem I'm trying to solve. What do you think?? &amp;#x200B; Thanks!
Wow thanks this seems to be "what I'm looking for", however @Baccata64 made me question myself if I really need all this (as I replied to him to his answer). Could you explain me a little what does Foldable and Applicative imply in this context? Or share some information sources I could read to fully understand the need of them. As much I want to solve my problem, I would love to learn how you came up with this solution to do it myself next time! &amp;#x200B; I'm also trying to find a "simple" solution and I love how this ``` println(unifiedErrorMatcher\[Option\].apply(Some(VeryUglyError()))) println(unifiedErrorMatcher\[LeftEither\].apply(Left(VeryUglyError()))) ``` looks like, to get there... not sure how simple it is :D but awesome really! Thanks!
Getting budget to keep the project alive and 4 developers can have a job. Not good days.
I've been trying to do my pattern matching Partial Functions using this method. However I can't make it to compile: ``` import cats.Monad import cats.instances.option._ import cats.instances.either._ type ErrorOrModel[T] = Either[T, Any] //ERROR: abstract type pattern F[InvalidSessionError] is unchecked since it is eliminated by erasure //ERROR: abstract type pattern F[ResourceNotFound] is unchecked since it is eliminated by erasure //ERROR: abstract type pattern F[ResourceDuplicated] is unchecked since it is eliminated by erasure //ERROR: abstract type pattern F[ResourceValidationError] is unchecked since it is eliminated by erasure //ERROR: abstract type pattern F[UglyError] is unchecked since it is eliminated by erasure def deleteOrModifyErrorMatcherMonad[F[_] : Monad](fa: F[UglyError]) : PartialFunction[F[UglyError], F[PrettyError]] = { case _: F[InvalidSessionError] =&gt; Monad[F].map(fa)(_ =&gt; PrettyInvalidSessionError()) case _: F[ResourceNotFound] =&gt; Monad[F].map(fa)(_ =&gt; PrettyResourceNotFound()) case _: F[ResourceDuplicated] =&gt; Monad[F].map(fa)(_ =&gt; PrettyResourceDuplicated()) case _: F[ResourceValidationError] =&gt; Monad[F].map(fa)(error =&gt; PrettyResourceValidationError(error.msg)) case _: F[UglyError] =&gt; Monad[F].map(fa)(error =&gt; PrettyGenericError(Some(error.msg))) } private def test = { val eitherError = Left(InvalidSessionError("", 1)) val optionError = Some(InvalidSessionError("", 1)) deleteOrModifyErrorMatcherMonad[Option](optionError) deleteOrModifyErrorMatcherMonad[ErrorOrModel](eitherError) //ERROR: No implicits found for parameter 'mondad$f' : Monad[ErrorOrModel] } ``` I'm getting type erasure errors and when using the either, its missing some implicit :/
These [https://github.com/finagle/finch/tree/master/examples](https://github.com/finagle/finch/tree/master/examples) seem to be pretty useful
Basically you have 1 layer of wrappers/1 (or more) extra object per each `F[_]` in your type. So .e.g `EitherT[Task, E, A]`, requires creating `EitherT` instance which contains `Task` instance, which contains `Either[E, A]`. If you do `map` or `flatMap` you cannot reuse any of that instances - you have to alloacate new `EitherT`, `Task`, `Either`... And allocation is not free. Garbage collection neither. There was a presentation (I think quite recent one) comparing the cost of different approaches on JVM, but I cannot find it ATM. From what I remember from discussions overhead on monad transformers comparing to a "baseline" was 10x, but for now keep it as anecdotal until someone posts like to actual benchmark.
I did some benchmarks and according to my observations it is nowhere near that bad \*unless\* you do not use inliner. I will make a post out of it soon. What you should be worrying more about is the cost of effect wrapper, for instance if you use \`EitherT\[Future, ...\]\` you will be bleeding on thread pool submissions (you will have a lot of calls to \`map\`, \`flatMap\` etc induced by \`EitherT\` that cost a lot since every one of them, however small, will become a new thread pool task). If you switch to eg. \`IO\` the difference is, I'd say, negligible
Got it. What I found was one of John Degoe's [posts](http://degoes.net/articles/effects-without-transformers) about that. Also, I found [this](https://github.com/iravid/transformer-benchmarks), which is close to what I'm looking for. &amp;#x200B; If you come across the talk, I'll appreciate if you post the link, please :)
Quick question, do type classes for sorted collections already exist out in the wild?
How about cold vs warm?
I wrote something you might find useful, at least for the very beginning: https://github.com/slouc/finch-demo
I used JMH so all this - fork/warmup/iterate dance was done correctly, I assume
*Commenting just to get notified about answers*
Ok, so on warm JVM :+1:
Ah gotcha. I thought this was equivalent of 'kafka streams' but not really. Kafka streams is much more than what this libary is offering. Ktables, backing k/v stores, fault tolerance, exactly once ect. Looking at the docs for fs2, this is really bizzare to me ``` Instead, up-stream is asked to produce elements whenever down-stream is pulling. It's possible to run the consumer and producer independently, and use an asynchronous non-blocking queue for communication. The producer can then slow down when the consumer isn't fast enough. ``` Why would you possibly need to tell producer to slow down or a seperate queue when you have kafka already.
Hey, meowlicious99, just a quick heads-up: **bizzare** is actually spelled **bizarre**. You can remember it by **one z, double -r**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
Hey /u/CommonMisspellingBot, just a quick heads up: Your spelling hints are really shitty because they're all essentially "remember the fucking spelling of the fucking word". And your fucking delete function doesn't work. You're useless. Have a nice day! [^Save ^your ^breath, ^I'm ^a ^bot.](https://www.reddit.com/user/BooCMB/comments/9vnzpd/faq/)
Thank you for the explanation. I do have to treat with `EitherT[Future, ..., ...]`. Do you have a gist or a repo that you can share with this jmh benchmarks?
Put the Java file in your scala project and use it as is? Do you need the case-class generation of `equals`, `toString`, static constructor, etc?
Sure. `Foldable` is a typeclass for operations that can be done on types that act like ordered collections that can be iterated over. In this case, both `Option` and `Either` act as collections that can hold at most one object. Since `Either` is right-biased, if it is `Right`, it it considered to be holding an object. `Foldable` is used for the `collectFirst` operation, which gives you the first value in a collection that matches some partial function. The partial function used is the identity function, so it's basically `headOption`, which returns head if it exists as an `Option`. That's exactly the format we need to implement the `unapply` method that can be used to create a partial function matcher. But you also wanted to rewrap the value in the original container, which is what `Applicative` is used for. The purpose of `Applicative` is a bit harder to describe, but I'm just using it for the `pure` operation, which is the wrapping operation. So, `collectFirst` is needed for unwrapping a value and `pure` is used to wrap a value. With these, it's possible to instantiate approximately the partial function you wanted. As I think about it, I'm not entirely sure that their usage here is appropriate, because it allows this and I don't think that this makes sense: println(unifiedErrorMatcher[List].apply(List(VeryUglyError(), VeryUglyError()))) // List(VeryUglyButPrettyError()) If we want something that always makes sense, a new typeclass could implement exactly the wrap and unwrap operations that you want. That's more or less the second implementation. I mostly learned about the use of functional typeclasses from eed3si9n's [learning Scalaz](http://eed3si9n.com/learning-scalaz/) and [herdng cats](http://eed3si9n.com/herding-cats/), but I'm not sure they're the best material anymore. That all said, knowing more about the actual problem, I personally agree with /u/Baccata64.
I think I found it - [https://www.youtube.com/watch?v=d5OiukU26Mw](https://www.youtube.com/watch?v=d5OiukU26Mw) \- as /u/rzeznik said it is not that bad, though you have to pay some penalty. Of course, it matters only if your IO operations is not so much more expensive that you still notice some gains from IO monad improvements.
Thank you!
Thanks for the link! I'll watch it soon
Ah, I am in the middle of making a blog post about it :-) I don't have a repo yet, but I can make you a gist if you are still interested.
Absolutely, please!
Oh this looks great! Really look forward to reading through. &amp;#x200B; I developed the audio/video fingerprint database for IntoNow.... in C++... It was, something. Definitely something. Always wanted to implement a version in FP.
Thanks four your response, I will try something like that
I used to work on Spark a lot in Singapore, along with scalatest, doobie, and shapeless.
I just wanted to say I'm glad you asked. It's always good to be skeptical and learn the principles behind things rather than blindly accept heresay.
Apologies for the delay on the reply. \&gt; Regarding switching to something like Either\[Error, Unit\], I'm not the biggest fan of using Unit You should ask yourself why you're not a fan. If your API call doesn't return any payload, I assume it's because it mutates something in the remote system, in which case \`Unit\` is a perfectly valid type to reflect what the http call does. \`Unit\` (or \`void\`) doesn't express the fact that nothing happened, but rather that something happened but no data was returned. Having a unified contextual type for your responses in the form of \`Either\[Error, ?\]\` would also reduce the need for HKT abstractions, and you'd be able to prettify your errors via a mere Either#left#map\` call, which would reduce the puzzlement of our fellow developers.
I’m not an expert in streaming, but that just sounds like backpressure, the java library will have to implement something similar, even if you as a user of the library don’t see it, otherwise a chatty producer would bring consumers to a halt.
BTW, all contemporary JSON parsers for Scala have built-in (or extension) libraries for derivation. And yes, jsoniter-scala macros derive codecs only for its Core API. But Core API of jsoniter-scala would be useful if maintainers of circe will be interested in more efficient (and safe) parsing and serialization to/from their `Json` instances.
Yes, I would like to work with case class instead of Java class. Hence, would like to know if given a nested Java class and the nested Scala case class equivalent with possibly field renames, is there a lib which allows to perform boilerplate free transformation between the two.
Simple yet useful :) Thank you
If you already written both classes and want to convert between them try [https://scalalandio.github.io/chimney/](https://scalalandio.github.io/chimney/) \- one of its function is conversion between case classes and Java beans. (DISCLAIMER, I am co-author of this library).
I don't understand how thats even possible. Chatty producer will keep producing to kafka and consumer will just 'fall behind' , how would consumer possibly halt the producer, they have no knowledge of each other. Java library does not implement backpressure or any such thing.
I recommend you ask them on the library’s gitter channel if you want to know how it works, this is leveraging a Kafka feature, it’s really not doing anything that unusual.
But are you using that feature in your application? I want to know why as a user you need that feature. Like what use case warrants asking producer to stop.
Thanks raghar@. Can you point me to a relevant documentation for transformation between Java beans and case class? Also, I quickly checked that chimney uses macros underneath. With Scala 3 coming in next year, will it be possible for Chimney to upgrade?
It supports Java Beans - https://scalalandio.github.io/chimney/#ReadingfromJavabeans - but actually as long as you have getters, setters and default constructor POJO should work. Nobody believes that migration to Dotty happen overnight, and for a while Dotty will allows usage of Scala 2.x libraries AFAIR, so we will have some time to rewrite. Just like everyone else.
IntelliJ is the IDE with the best support for Scala currently.
I second this. Scala feels very "built in" to Intellij.
You can use Swing (if you're feeling masochistic).
but I don't want too
It is likely one of the few (if not the only) good options. You could also just use JavaFX, but there--AFAIK--aren't any Scala bindings.
I found swing to be utterly impenetrable, so I'd give it a wide berth for sure.
When people code gamein scala or java what do they use ?
Scala REPL (or Ammonite). I use it for processing files all the time.
Do people code games in Scala?
yes
&gt; there--AFAIK--aren't any Scala bindings. http://www.scalafx.org/
Thank you.
What about using OpenGL or some scala game engine. I do not have personal experience, but here is a list https://github.com/ScalaGameDev
hox much is it used ?
Sorry, not too sure about that.
Definitely check out ScalaFX
That's a hint that maybe you are not looking at the right tool for the job.
Hi, That's indeed interesting post. Thank you for making and sharing it. You might be interested in about following projects / demos. [https://gitlab.com/e257/proto/gitdb](https://gitlab.com/e257/proto/gitdb) That is Git based data storage demo for testing Git's writing performance. Scala + Java, Apache-2.0 Then there is tackler: [https://tackler.e257.fi/docs/performance/](https://tackler.e257.fi/docs/performance/) Tackler is plaintext accounting tool ([https://plaintextaccounting.org/](https://plaintextaccounting.org/)), which can use Git as data storage. It is performance tested (for reading) regularly with set of one million (1E6) transactions. These transactions are small files which are stored to git repository. Tackler is written in scala, and licensed under Apache-2.0. Source code is located here: [https://gitlab.com/e257/accounting/tackler](https://gitlab.com/e257/accounting/tackler) &amp;#x200B; I am very interested in about your plans to use git as data storage. It seems that it has some not-so-nice (exponential) performance characters when file count increases. This is true especially when writing many small files into repository.
JavaFX (ScalaFX) is supposed to be the successor to Swing. I am a full time Scala programmer with a decade of Java before that, and I gave up and learned Typescript and Vue because I need something that I can get working in a reasonable amount of time. The Java frameworks aren't quite good enough to fool you that they are native, and they have very large memory and install footprints.
You can use Scala in both iPython and Zeppelin notebooks if it has to be online. You just need a Scala Kernel for Jupyter.
Typescript is for front end right ?
Vscode with metals plugin is awesome combination. I’ve been using IntelliJ for years but after switching to vscode+metals I’m quite happy - it’s fast, highly customizable and not as bloated as IntelliJ idea. Metals provides you all basic ide functionality with scala such as code completion, imports, gotos and type inference. Moreover, try setting up scalafmt and scalafix for formating and linting
I'm afraid the JVM isn't used for desktop applications all that much these days. However, there are plenty of Scala options for web application development. If you want to go in that direction, check the side bar under "Web Front End".
How do you do refactors? Like extract variable or method, or rename variables?
Look up Electron
No, I want to do game.
Try Pixi JS with Scala JS
or react native depending on what you're developing
I know it's not scala, but in the interest of pragmatism, tornadofx in kotlin is pretty good for a javafx framework. Just as a thing to look into.
I haven't done anything fancy on scala desktop. But to just get straightforward things done I've never had issues with JFormDesigner in IDEA or WindowBuilder in Eclipse. They both use swing (which, yes, is old but works fine) so it's easy to make the UI feel native to the OS.
I used dire-swing. It took me a solid month to understand it, but I was glad that I put in the effort. The author is also very helpful last I checked. https://github.com/stefan-hoeck/dire
Here are the two online webpage Scala "script snippit runners" I use: https://scalafiddle.io https://scastie.scala-lang.org
I've been using this with vscode [https://github.com/scalameta/metals](https://github.com/scalameta/metals) works like charm . Would be more simlar to python experience for you instead of a heavyweight ide like idea.
The JVM is used for a lot of desktop applications. They just mostly happen to be ones used internally at corporations and not something most people ever see. The Java apps most people are familiar with would be the Java IDEs (Netbeans, Eclipse, and the suite of Jetbrains' stuff like Intellij, Webstorm, PyCharm, etc.). But there is also other ones like Aqua Data Studio and Matlab.
I've written a lot of Swing and JavaFX apps and both work fine with Scala. Swing is an old school API, and a bit on the ugly side. JavaFX is actually a very nice API to work with, is a pleasure to code, has very good performance, is easy to skin (with CSS) and built around a scene graph API. It also has a nice GUI builder, SceneBuilder, that's supported by Gluon.
You can use JavaFX. My last chess program is written in it: https://github.com/melvic-ybanez/Nostalgia.
I don't think there's a direct equivalent in http4s. As far as I understand (correct me if I'm wrong), Local is a ThreadLocal on steroids that works with a current request context instead of a thread. Try to take a look at [Kleisli](https://typelevel.org/cats/datatypes/kleisli.html). In http4s, the type of a request handler is `Request =&gt; F[Response]` and `F[_]` is a monadic effect. `Kleisli`, in turn, allows you to compose functions that return a monadic value. So a possible implementation may look like so (it's pretty much Scala-ish pseudocode) `val current: Kleisli[F, Request[F], Request[F]] = Kleisli.ask` `val handler[T]: Kleisli[F, Request[F], T] = for {` `request &lt;- current` `// do some magic` `} yield 42` `// ...` `case req @ GET -&gt; root / "foo" / IntVar(something) =&gt; for {` `_ &lt;- doSomeWork(something)` `result &lt;-` [`handler.run`](https://handler.run)`(req)` `response &lt;- Ok(result)` `} yield response` &amp;#x200B; The beauty of such approach is that you can pretty much create as many Kleisli as you want and compose them in any possible way for a monadic effect. They all have access to the Request variable and you won't have to create a globally visible varialbes
Monix Tasks have [locals](https://github.com/monix/monix/blob/master/monix-eval/shared/src/main/scala/monix/eval/TaskLocal.scala) that are very similar and, in fact, inspired by, Twitter Future locals. You can try pluging them in instead of [cats.effect.IO](https://cats.effect.IO).
I do it manually :) it’s not a big deal, comparing with idea which provides refactoring but freezes and eats ram and cpu when I import cats or scalaz.
Hi, you can check various ways of context propagation in this presentation [https://speakerdeck.com/yarhrn/scala-context-propagation](https://speakerdeck.com/yarhrn/scala-context-propagation) .TL:DR The best option from fp(and maintainability) perspective is ReaderT + Tagless Final.
My dude, I love Scala, but I can't name one game in Scala
Intellij works like a charm , it has a lot of options moreover debugging is much better in intellij than eclipse for scala
You may want to look at `cats-mtl`, possibly st ApplicativeAsk.
It does not matter, it is still a programming language, I think coding game is really good to get better at programming and I want to learn fictional programming also. I ask for a popular framework because I like to capitalize on what I use.
TDD with Scala + Swing: https://github.com/plokhotnyuk/calculator
Akka-http, akka-streams, plain akka for supervision, json4s. When I want something more hardcore, I can switch to Haskell; all this scalaz-cats-typelevel stuff looks hackish compared to Haskell anyway.
Kotlin port of imgui: https://github.com/kotlin-graphics/imgui/blob/master/README.md It’s in Kotlin, but you can use it from Scala.
No need! I also took my time.. I wanted to try all the proposed solutions! After all the talk I'm going for the Either\[Error, Unit\] solution, its the cleanest, easiest so far. &amp;#x200B; Thank you for sharing that important piece of knowledge!
Thank you for the explanation, its very clear and easy to follow. I'll make sure to study **Foldable** and **Applicative** in detail, they seem to be very handy. I totally understand, thank you for sharing those sources, specially "herding cats" as I'm using mostly Cats lib for some functional programming. &amp;#x200B; You are completely right, after thinking about it I'll go with [/u/Baccata64](https://www.reddit.com/u/Baccata64) solution, its simpler and easier to maintain.
What are you trying to do? Which source and target systems? Would you prefer native Scala or spark sql?
I would strongly consider combining [scalajs-react](https://github.com/japgolly/scalajs-react) with [Electron](https://electronjs.org/). [This post](https://medium.freecodecamp.org/building-an-electron-application-with-create-react-app-97945861647c) discusses combining Electron and React, and might be very helpful. These days, Scala.js, Electron, and the React ecosystem are all very, *very* good. I'd resist the temptation to say "it's not native!" For example, [Visual Studio Code](https://code.visualstudio.com/) is an Electron app.
In fact, I am using Monix tasks in my first attempt, but propagation didn't work for me. Just now I realized, that it is disabled by default.
I've seen this one, but the lack of examples made me look for other options. Do you happen to have any good examples or maybe you could explain how exactly this covers my case? Thanks!
I'm sorry if I'm missing something, but doesn't it mean, that all the functions that need to access the value have to be updated to have different signature?
Thanks for sharing this. I'm new to this, so maybe I'm missing something, but I frankly, do not see much benefit here. The bueaty of `Local` is that in any place of my code I can get the value without changing any signatures. So if I had ``` def businessOperation(input: String): F[Int] =&gt; { ??? } ``` I can do this ``` def businessOperation(input: String): F[Int] =&gt; { logger.log(MyData.local()) ??? } ``` And the rest of the code remains the same. No changes at all. With `ReaderT` approach every function that needs an access to `MyData` will need to updated for new signature. Same concern as here https://www.reddit.com/r/scala/comments/blzan6/equivalent_of_threadlocalfinagle_local_in_http4s/emu7eo3/
&gt;What are you trying to do? I'm writing ETL jobs and noticing that a lot of the code is just very ugly, hard to read, and lacks structure. I'm sort of piloting spark at my current job so there really isn't a senior scala developer to correct my mistakes. &gt;Which source and target systems? Pull parquet files from azure datalake, do some tranformations and write them to the datalake so that machine learning models can use them as inputs. I'm mostly just looking to see a good example of how a professional structures a project, how they write jobs, and how they break up things into different pieces.
If I understand your question correctly, then yes. A signature of function would always include Kleisli (ReaderT is essentially a Kleisli in cats). Let me provide you with an example that would hopefully give a little bit clarity. Please, consider this example as a little bit artificial and only intended show a real-world-ish scenario. import cats._ import cats.implicits._ // bunch of additional imports class SomeService[F[_]](implicit effect: Effect[F]) extends Http4sDsl[F] { private val current: Kleisli[F, Request[F], Request[F]] = Kleisli.ask def getHeader(name: String): Kleisli[F, Request[F], Option[String] = for { request &lt;- current header &lt;- request.getHeader(name) // I do not remember the exact API, however it gives the idea, I hope } yield header // notice that it's not a method val combineHeaders: Kleisli[F, Request[F], Option[String] = for { firstName &lt;- getHeader("first-name") lastName &lt;- getHeader("last-name) } yield firstName |+| lastName // https://typelevel.org/cats/typeclasses/semigroup.html def doSomeOtherWork: F[Int] = effect.delay { 42 } def rootRoutes: HttpRoutes[F] = HttpRoutes.of[F] { case req @ GET -&gt; Root / "combine" =&gt; for { someData &lt;- doSomeOtherWork headers &lt;- combineHeaders.run(req) output &lt;- headers.fold(BadRequest())(value =&gt; Ok(value)) } yield output }
You don't need to update your signatures thanks for tagless and F\[\_\]. In case reader your F can be equal to type F\[A\] = ReaderT\[IO,MyData,A\] . Then you can use typeclass from cats-mtl like ApplicativeAsk.
You’re gonna want to use Frameless my friend. Well maybe not, but I’m doing the same thing right now at work and typesafe spark jobs will save you a lot of headache down the road. [Here’s a good blog on readable spark jobs](https://developers.soundcloud.com/blog/creating-readable-spark-jobs) . It doesn’t go over the whole type safe thing, but it still is a very good example of how to keep things readable.
Though I'd still need to specify context bounds in my functions if I were to use `MyData`, currect? ``` type MyDataAware[F, A] = ReaderT[F,MyData,A] def businessOperation[F[_] : MyDataAware]: F[Int] =&gt; ??? ``` or whatever the syntax is (can't check right now). Because otherwise `F[A]` gives me no access to `MyData`.
You are right. But if inject it on class level, your signatures stay clean.
Also make sure to check out this blog post: https://olegpy.com/better-logging-monix-1/ demonstrating integration with MDC We've discovered few issues since then (mainly related to integration with Futures) but my hope is that we can release new version within a month or two. Though it is still usable in the current version, just mentioning in case someone was wondering about production-readiness
Agree FRP approach is very elegant.
Thanks a lot for the interesting feedback! Actually we are planning to implement a "Container Metadata Store" where a container can be a directory, a file, a record in a file, a table in a DB, a row in a table etc. Since we want to keep track of history and linage, the original idea was to model that in a graph DB, but then a college came up with the smart idea to "misuse" a version control system. As for the exponential performance characteristics of Git related to many small files: Can you elaborate on that a bit?
Right on time ! thanks! I have that red book as well. That was my plan. I will go through yours too
I was really hoping you had a fancy plugin/addon :)
Yikes I got a lot of downvotes on my other comment &gt; so much for the tolerant /r/scala I don't even know why people are upset, I didn't offer it as an answer to the op lol
Yikes I got a lot of downvotes on my other comment, so much for the tolerant r/scala hah I don't even know why people are upset, I didn't offer it as an answer to the op lol
Will the language of the book be Chinese or English? I think focusing on separate editions will help. Also, it might be easier to understand in smaller chunks/documents rather than just one long document. Good luck!
I’m optimistic rename symbol will be released for Metals within the next month. Other basic refactorings like “add missing import” are planned after that.
Great advice, it will be english first.
Let me know if you need any help. It will be fascinating during the journey.
I think readability is the main key. I deeply dislike Dataframe as they don't have types and you end up with column name as string everywhere in your code. It's hard to maintain and errors only show up at runtime. Use RDD or dataset. There are two teams I think you can join : 1. Write an object with all your source , one with all the transformation. I usually like that for project where there are a lot more sources than transformations. And when you mostly do joins. 2. Write case class and companion object where the transformation are leveraging 'copy' and the companion object will have the read from source methods. I like this model better but I can make it hard to understand what is going on when you have a lot of joins.
Hello! I'm attempting to use the scala toolbox in my java program to parse and then compile a scala source file, then cast and instantiate that file for use in my program. I've come up so far with the following: `return (Engine)toolBox.compile(toolBox.parse(content)).getClass().getDeclaredConstructors()[0].newInstance(0);` Content variable here is just the string representation of the scala source file (a scala class which extends class Engine). The rub is that I don't know how to get an instance of the ToolBox. Almost every single example I find is for using it inside scala using a mirror and mkToolBox(). Would anyone happen to know how to do this from java? TL:DR How to get ToolBox instance in Java source file to parse/compile/instantiate a class from a scala source file at runtime?
Awesome! Please take a look at this great book based on a series of blog posts. I did my second steps in Scala with those posts. https://leanpub.com/theneophytesguidetoscala
Metals' team moves very fast, they are releasing frequently and adding new features all the time. So I'm very optimistic regarding this plugin. But I must admit that for beginners IDEA is much mature and handy choice (yet slow and resource demanding), with all suggestions, implicits' search , better type inference and refactoring.
-5 isn't that much, don't understand why they would downvote that lol
Very useful post, already saved in my favorites. Thanks!
ZIO has [FiberLocal](https://scalaz.github.io/scalaz-zio/datatypes/fiberlocal.html), they always work and don't need to be enabled, unlike Monix.
`sbt ensimeConfig` should be pretty verbose on the first rub, and should populate that file with some elisp IIRC. There are no errors either?
If you are "starting to learn Scala out of curiosity" and don't have any preferences yet then I would recommend you to check [Metals](https://scalameta.org/metals). It is Scala language server which is supported by vim, emacs, atom and visual code. I'm not Emacs user but it works perfectly in vim for me. They did huge progress in past several months: autocompletion, auto import, go to definition, call hierarchy and so on.
Good timing. I am currently going through the arduous process of finishing all the exercises in the red book. Its been tough going so far :D. &amp;#x200B; I will read through your book in parallel and post any issues. thanks for posting it here.
Great work! Another excellent project from SoftwareMill. I'm looking forward to trying it out.
In cases like these I find it is often best to adjust the boundary between Scala and Java to make it easier. In this case, why not make a Scala class of your own that does the compile and parse? It could then use the Toolbox as you have seen. Your Java code then just has to figure out how to use your new class, which has a method that takes a string and returns the compiled Engine
This has kind of been my last resort, because that would add some extra complexity to the build steps of the main program itself. So there really is just no way to get an instance of toolbox into Java?
The first step is use it to finish daily work. Then im trying to ask why cats theory are helping us. Hope make it earlier.
I will definitely read it.
I'd appreciate if you point me to an example of how to wire this into http4s. I tried to implement this as http4s middleware, but my `TaskLocal` is cleared before handling of the request is completed.
Here's the output I get in the minibuffer: user-error: Current buffer has no process
Thank you. I may try it out. Although the more I read the more I understand that I should really get familiar with the kinks of sbt, and pay less attention to ensime itself.
Compile time evaluation is typically done using macros in scala. Have you tried those?
Quality post.
I tried understanding this approach, and either I failed or there's no benefit really vs feeding the value as parameter. Let's take this function ``` type Key = String type Value = String def getValue[F[_]](key: Key): F[Value] = ??? ``` Very simple. And it is used in 42 places like this ``` for { v &lt;- getValue[IO](key) ... result &lt;- computeResult(v, x, y, z) } yield result ``` Now we realize, that we need to add authentication information. What will happen when we add this as parameter? We'll have to update the function call code in all 42 places where it is used. What will happen when we change return type and return `Kleisli` isntead? We'll have to update the function call code in all 42 places. Again. Ok, assume, we already use `Kleisli[IO, UserAuth, Value]` as return type. And let's assume (for the sake of next example), `UserAuth` is stored as a property of some `VeryBroadContext`. ``` for { v &lt;- getValue[IO](key).local((ctx: VeryBroadContext) =&gt; ctx.userAuth) ... result &lt;- ... } yield result ``` And then we realize, that `UserAuth` is not enough and we need an entire context. We again end-up with a necessity to update the code in all 42 places to udpate that `Kleisli`. I as well could've just updated signature of `getValue`. At least, there's IDE refactoring for that. And compare this to `Local` approach ``` def getValue[F[_]](key: Key): F[Value] = for { userAuth &lt;- F.delay(UserAuth.local()) value &lt;- callBackend(value, userAuth) } yield value ``` and when we need to user entire context, we just change the code in a single place ``` def getValue[F[_]](key: Key): F[Value] = for { ctx &lt;- F.delay(VeryBroadContext.local()) value &lt;- callBackend(value, ctx.userAuth, ctx.somethingElse, ctx.anotherThing) } yield value ``` And all 42 call sites remain unchainged. Did I miss something? Is there a way to avoid this inconvenience?
Thanks a lot for the example. I tried undrestanding how will this look in a bigger application, and I don't see much benefit from passing context as parameter, perhaps I missed something. Asked on another comment thread. Would appreciate you taking a look and answering the question I have there. Thank you! https://www.reddit.com/r/scala/comments/blzan6/equivalent_of_threadlocalfinagle_local_in_http4s/emyksuh/
I don't have any example at hand but if you write to me at gitter (gitter.im/Avasil or gitter.im/monix/monix) we can figure it out
Yes, I tried that using `blackbox.Context.eval` function in [jsoniter-scala-macros](https://github.com/plokhotnyuk/jsoniter-scala/blob/8c5f427ab580fb877fc3c74560d2efa13fdfd544/jsoniter-scala-macros/src/main/scala/com/github/plokhotnyuk/jsoniter_scala/macros/JsonCodecMaker.scala#L282). But I think that it worth a separated library like [left-pad for SCala](https://github.com/stew/left-cats).
I mean errors in sbt when you run ensimeConfig in the console/shell. But, I would recommend you check out metals as pointed out by /u/Walen007 For casual (and even professional) use it's much quicker to set up and has just enough functionality
About performance of adding files to git: These comments are based on partially testing of git (cli) and JGit with in-memory based operations. I am especially suspious that my test code with jgit and memory based operations could be sub-optimal or somehow wrong. However, because native git demostrates similar traits, this isn't probably totally off. That said, it seems that time to add single file and time commit that single file increases as file count increases, which seems to be logical regarding how git's DirIndex works. For reading I haven't noticed similar phenomenon. Really rough ballpark is that when file count increases of 1E1 -&gt; 1E6, the add+commit time increase is about 1000-10000x. So it's not exponential, more like logarithmic, but it still could render insert times unusable. On the bright side, there is JGit Ketch, [https://www.eclipse.org/lists/jgit-dev/msg03073.html](https://www.eclipse.org/lists/jgit-dev/msg03073.html) and [https://github.com/eclipse/jgit/tree/master/org.eclipse.jgit/src/org/eclipse/jgit/internal/ketch](https://github.com/eclipse/jgit/tree/master/org.eclipse.jgit/src/org/eclipse/jgit/internal/ketch) which makes jgit very tempting. =) Happy Hacking!
Authentication in Akka is done using BasicHTTPCredentials sent via Authorization header, see [https://doc.akka.io/docs/akka-http/current/routing-dsl/directives/security-directives/authenticateBasic.html](https://doc.akka.io/docs/akka-http/current/routing-dsl/directives/security-directives/authenticateBasic.html). Using that you wouldn't have the email in the path of the URL the customer is POSTing to. See the tests in the link above. You could then check the id in Credentials.Provided(id) against your Customers. If you're looking up Customers from a database or an actor or similar, you should use [https://doc.akka.io/docs/akka-http/current/routing-dsl/directives/security-directives/authenticateBasicAsync.html](https://doc.akka.io/docs/akka-http/current/routing-dsl/directives/security-directives/authenticateBasicAsync.html) instead. &amp;#x200B; If you don't want to authenticate using a password (which I don't see in your Customer class), you could use a simple path("secured" / String) and compare the extracted String (the given email) against you Customers.
I too would be interested in a library that allowed `val e = arbitrary()` to be computed at compile time. Presumably one way to implement this is val e = eval(arbitrary()) // macro compilation fails if arbitrary is impure // after macro application, looks something like: val e = __Computed.computed123 ... final object __Computed { val computed123 = arbitraryLiteral() } As well if `arbitrary()` results in a primitive type then no `__Computed.computed123` is generated, the primitive is used directly. Working list of goals * if arbitrary() result is a primitive, just use primitive * if arbitrary() is reduced to a literal if possible (eg. similar to OP's [lookup tables](https://github.com/plokhotnyuk/jsoniter-scala/blob/fd661126cdd3c793b184873740d181629070b4f0/jsoniter-scala-core/src/main/scala/com/github/plokhotnyuk/jsoniter_scala/core/JsonWriter.scala#L2046-L2131)), eg. `Array(1,2,3).map(_+1)` would become `Array(2,3,4)` * arbitrary() definition is moved to singleton `__Computed` if non-primitive, which acts as a memoizer
What about using scala as a scripting enigne per the JSR223? Why do you need to use the toolbox?
I am really sorry to hear this. My condolences to his family.
My goal was to be able to compile a single scala class file at runtime, generating the `.class` file if I wanted it for class loading later. I went down the route of using the scripting engine eventually but that was entirely cumbersome and bot really what i want to do. I saw in many stack overflow pages and forums that the ToolBox was the way to dynamically parse, compile, and load classes at runtime. But only saw examples in scala. Since my project is in java I wanted to do it from there but couldn't figure it out. I eventually attempted to just make a hybrid java/scala project using a scala class to do all the toolbox stuff, but didn't figure out how to instantiate that into my java side of the code even though they shared a package and everything. So... I pretty much just plan to give up on scala and continue just supporting groovy. In groovy there is a simple single method of the GroovyClassLoader to do everything I want. So... easy way out.
Why not instantiate it from Scala? Once you have the instance there you can use it from Java.
Because I couldn't get my scala side of the project to talk to the Java side.
Ah. Maybe fix that, then. That's something that should work. What build tool are you using?
Gradle. It can see and compile both pieces just fine. But the java side can't see the scala side. I gave up for now though.
Oh gosh. Scaldi is one of my favorite libraries.
I am very sorry to learn about this. Sangria really is a great library. I’ve never had the chance to truly interact with Oleg but his work will remain a very important part of this ecosystem.
This was the second link when I googled, "sbt javafx": [http://francoiscabrol.github.io/blog/javafx8-with-sbt.html](http://francoiscabrol.github.io/blog/javafx8-with-sbt.html)
doesn't work unfortunately. I assume it is not meant for openJDK 11?
JavaFX isn't included with the JDK anymore, it is now it's own separate project and you have to add it as a dependency.
Can you explain to, like to retard, what do I need in my build.sbt to achieveve this?
 val os = "mac" //or "linux" or "win" val javafxVersion = "11-ea+25" val javafxModules = Seq( "javafx-base", "javafx-controls", "javafx-fxml", "javafx-graphics" ) libraryDependencies ++= javafxModules.map(mod =&gt; "org.openjfx" % mod % javafxVersion classifier os)
May be this will be of help. [https://www.reddit.com/r/scala/comments/9fbzbk/build\_file\_snippet\_for\_using\_javafx\_with\_java\_11/](https://www.reddit.com/r/scala/comments/9fbzbk/build_file_snippet_for_using_javafx_with_java_11/)
I thought so. Here's how you fix it. You make gradle have scalac handle everything. sourceSets.main.scala.srcDir 'src/main/java' sourceSets.main.java.srcDirs = [] sourceSets.test.scala.srcDir 'src/test/java' sourceSets.test.java.srcDirs = []
😢
This is incredibly sad, the only times I've interacted with Oleg he was very helpful and active :-( does anyone know what has happened ?
Oh my gosh I completely forgot this step! I did this when I had a mixed Groovy/Java project but completely spaced on doing this to set up the Scala/Java mix. Thank you!
Pardon my ignorance but what makes the Graal JIT so good?
It has a lot of new optimizations in it like escape analysis that can prevent object allocation in some situations. C2 (the second tier JITC it replaces) doesn't have these optimizations because it's very old and written in C++, making it difficult to enhance or maintain nowadays. The graal JITC is written in java, and can optimize itself as well as other bytecode.
Haaa ok cool. Thought Escape Analysis was a thing with C1/C2 since HotSpot 8 though?
I believe it is, but this approach allows a more powerful escape analysis than what was around before. Check out the abstract I've added to my post.
Would this work with GADTs that exhibit existential types? As in: sealed trait TestBase[A] case class Test[A](rest: TestBase[A]) extends TestBase[A =&gt; A] // other cases...
What's Jetbrain product's UI made of?
After OpenJ9 it seems hard for me to change the JVM again. I'd not change a possibility of 50% performance increase over a certain 66% less memory usage. Maybe it's still worth using it to compile the app tho.
graal's jitc seems to result in reduced memory allocation as well. in any case it all depends on what you're looking for in your app, and I'm glad we have so many jvm options now: speed/performance: openjdk w/ graal-jitc balanced: openj9 quick startup/low resource usage: graal aotc
Swing! https://github.com/JetBrains/intellij-community
That is true, indeed. It's so nice to see this many JVM implementations. And yes, OpenJ9 has a performance loss, but, mostly, using I/O, this performance loss is reduced a little bit. It's great for microservices, it ran my akka http apps using between 80~150mb. Besides that, the -Xquickstart flag is really nice for cloud environments to speed up start up time. I think it really depends on what you are trying to solve to choose the best JVM for it. ;)
Graalvm will be a game changer. I published a release of my CLI accounting tool yesterday [*](https://github.com/hrj/abandon/releases/tag/v0.5.1) and shipped a native image with it. The startup time for the regular jar was about 6 seconds. The native image has a startup time of 0.005 seconds, that is, virtually instant. Until recently, I was proud of the fact that Java apps don't need to be compiled for every target platform. However, the difference in startup times is large enough to warrant the extra effort in compiling native images. Note: things that don't work well yet: JavaFX and libraries that heavily use graphics capabilities, such as Apache FOP.
I dont know, I'll try it out when I get some time
Is there a video that goes with the slides by any chance ?
Waiting for the meetup organizers to publish
\&gt;How to create a modified 2D array for the recursion? what happens if you directly operate on array passed in. Wondering why you would need to do a clone.
We're hiring in Amsterdam, I'll keep an ear out for Portugal posts though.
It seems that the functions operated on the same array - so when I did map recurse(), I'd end up with an array that was a combination of several attempts, like a failure in DFS wasn't being reset.
I know of some companies in Portugal using Scala, but I'm not too sure if they use "Functional" Scala or "better Java". &amp;#x200B; First of all, one of the sites I used the most for programming related jobs was "ITJobs". Here's a link: [https://www.itjobs.pt/emprego?q=scala&amp;location=](https://www.itjobs.pt/emprego?q=scala&amp;location=). &amp;#x200B; In terms of companies using Scala: * e-near (their blog: [http://enear.github.io](http://enear.github.io)) * I think they are the organisers of the LX Scala conference * Codacy ([https://www.codacy.com/](https://www.codacy.com/)) * Zalando has offices in Lisbon ([https://jobs.zalando.com/tech/locations/?gh\_src=4n3gxh1#lisbon](https://jobs.zalando.com/tech/locations/?gh_src=4n3gxh1#lisbon)) but there aren't any vacancies right now... * I know of really smart people work at Feedzai and they use Scala ([https://feedzai.com/](https://feedzai.com/)) * I know that University of Minho used to be a Haskell lover ([https://www.uminho.pt/EN](https://www.uminho.pt/EN)). Might be worth it to look around the cities near that Uni, namely Braga and Guimarães. * Check the people and sponfors of the Scala Portugal meetup ([https://www.meetup.com/Scala-Portugal/](https://www.meetup.com/Scala-Portugal/)) * [Blip.pt](https://Blip.pt) is a good company as well and they seem to be using Scala ([https://blip.pt/jobs/?search=scala&amp;rolearea=](https://blip.pt/jobs/?search=scala&amp;rolearea=)) &amp;#x200B; &amp;#x200B; Hope this helps a little bit. Feel free to DM me if you need.
Thank you in advance for all the links. I’ll do a deeper research about Scala positions. I’ve mainly working with Java here after I left a professor position (I used to teach Haskell at a public university) but I’m missing thinking in functional style already :D
Good to know about Amsterdam. I’m planning to move to Portugal at first to be able to get my citizenship but I’m still studying the existing options related to getting my citizenship even living in others EU countries.
That is amazing!
Sangria is truly special. It was one of the first complete implementations of GraphQL, and I think it, and Oleg, are a big reason for GraphQL taking off in popularity. I never had a chance to meet Oleg, but in reading his interactions on the Sangria repo, it was clear that he exhibited a rare combination of technical genius and kindness. Learning to use Sangria taught me some interesting programming lessons, and for that, I'm thankful. Rest in peace.
Some Scala devs are really keen on transitioning to a more functional style, but are afraid to deep dive into a world that is unknown to them. Sometimes all it takes is having someone that has the experience and the intuition in FP for the change to happen :)
Awesome
I actually agree 100%, after working with IntelliJ IDEA and then switching to VS Code, thing become much faster and much more comfortable. I am 100% agree with you! VS Code /sbt command line is probably the best way to develop, I don't need a monster IDE, I need a light-weight editor and VS Code does this very well.
Thanks a lot for the information - I didn't know that there was a multiple master management system freely available. This is definitely one more reason to lean to git instead of subversion.
So Scala is not just about "being functional". The unique thing about Scala is that it allows you to pick the best suited approach for the use-case. Some parts of your program can be imperative (if fits the case better) while other parts can be functional. Scala is more about finding what is right for your use case.
Because he is trying to be functional.
Really is sad news.
&gt; How to create a modified 2D array for the recursion? If you really want a copy of an array then cloning is what you do. In this case you might actually be better off using a type like `Vector` which can do structural sharing. Generally you'd use arrays only when you wanted to modify something in-place. Alternatively, look to restructure your code or find a different representation such that you don't have to copy the full array every time. (Or, to be honest, don't worry about it; memory is cheap and computers are fast these days). &gt; WartRemover disallows the use of ==, so I defined the type-safe === operator they recommend - but isn't this built-in anywhere? It's not built into the language, but Cats and ScalaZ (popular libraries for programming in a pure/functional style) both offer implementations. &gt; I don't use sets to get the valid candidates for the empty position, but instead map the checking function across the list 1 to 9. Does Scala use lazy evaluation (so that it would know to not check the later conditions if the row condition is not met for example) or is this less efficient than getting the intersection of the sets that satisfy each separate condition (row unique, column unique, small square unique)? Scala evaluates strictly by default. In cases where you want lazy evaluation on collections you can use the `.view` method which forms a lazy view of the underlying collection, e.g. `someList.view.map(someFunction).find(somePredicate)` will find the first `someFunction(x)` that matches `somePredicate` without evaluating `someFunction` for the rest of the list. As for what's most efficient, my only advice is to profile your own use case; in my experience what is efficient on the JVM is very often counterintuitive so it's better to rely on measurements than try and reason about it.
As noted in the paper, the current JVM does have escape analysis however its very binary. It works well enough for "typical old style" Java code, however idiomatic Scala code often trips the current escape analyzer way too easily. The JVM escape analyzer is one of the primary reasons that the JVM is fast.
Thanks, this comment is exactly what I was looking for.
Rest in peace
Hello there, I work at enear full time. Yes we are organizers of the LxScala for the second year - [https://www.lxscala-reactive.com/](https://www.lxscala-reactive.com/) . We have a few projects that use Scala which is what I work in too. We are currently looking for a few positions - [https://www.enear.co/careers/](https://www.enear.co/careers/) If anything interests you, feel free to contact me or look into the site. About other companies there some others that are also nice that also work with Scala. Feedzai, last time I heard (I may be completly wrong) were reducing their usage of scala language. Nezasa ([https://www.nezasa.com/](https://www.nezasa.com/)) also works with scala and has a nice team.
Hey, vascorsd, just a quick heads-up: **completly** is actually spelled **completely**. You can remember it by **ends with -ely**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
***To add more detail:*** You will lead teams who build resilient systems to handle million requests per day without downtime, working closely with a host of functional languages (they're flexible)! They need someone to develop and execute a mid &amp; long-term technical vision and architectural direction in creating highly scalable solutions. This position offers sponsorship and is based in Germany, so if you have a strong understanding of core priorities, KPI's and underlying system architecture...plus experience leading and building cross-functional engineering teams, then this could be really interesting!
Cool! Has anyone used Graal to improve compilation times?
That’s actually one of the first things that was noticed to be reduced by graal
I'm currently trying to add code generation to tapir, so I can later describe my backend endpoints and generate fully featured clients for Kotlin, Swift and Typescript so frontend and apps have a better time integrating stuff and less bugs.
Could you elaborate? I don't see a difference when compiling my project with Graal compared to the latest Java 8/Hotspot, at least after each JVM gets warmed up. How should I configure SBT to make the most effective use of running on Graal?
I use emacs and sbt frequently for smaller scala projects. Assuming you have `addSbtPlugin("org.ensime" % "sbt-ensime" % "2.5.1")` in your `~/.sbt/1.0/plugins/plugins.sbt` file, running `sbt ensimeConfig` in a terminal window (not sbt console) should generate a verbose log and populate your .ensime file. Which OS are you on?
Video of the talk: https://youtube.com/watch?v=mGxcaQs3JWI
Video of the talk: https://youtube.com/watch?v=mGxcaQs3JWI
[removed]
I am literally puzzling this out for LDA clustering with Spark ML at this very moment. It's not TensorFlow, but it is a dispatcher for serving ML models.
MQTT broker, with AKKA, only as hobby work.
I haven't done this with Play specifically, but I get the feeling more people are just relying on dedicated js tooling for asset management, with webpack probably being the dominant choice. As JS build processes have gotten more and more complex, it's just not feasible for the "Asset Pipeline" implementations in all the various backend web frameworks to keep up, which I think is why you see more frameworks like Rails or Phoenix just delegating those responsibilities to a dedicated build tool like webpack. It's not without tradeoffs, since webpack can definitely be a pain in the butt in its own right, but a common approach is to keep a dedicated assets directory within your play/rails/phoenix/whatever project, and have a build step that copies the generated frontend files from there into the public directory of the main "backend" project when deploying. &amp;#x200B; Here's one example I found on github that seems to be doing roughly this with Play: [https://github.com/stuart-xyz/rate-my-area](https://github.com/stuart-xyz/rate-my-area). In that case, they split the ui webpack project into a separate repo and included it as a submodule: [https://github.com/stuart-xyz/rate-my-area-ui/tree/24c2f666da3c5933d6967c99cb1a8baacb5e0131#run](https://github.com/stuart-xyz/rate-my-area-ui/tree/24c2f666da3c5933d6967c99cb1a8baacb5e0131#run). &amp;#x200B; If you wanted to wire your webpack dev server to run automatically when starting play, this StackOverflow post describes how to do that: [https://stackoverflow.com/questions/34568008/how-do-i-run-webpack-from-sbt](https://stackoverflow.com/questions/34568008/how-do-i-run-webpack-from-sbt) &amp;#x200B; That said, it's definitely possible a good plugin for doing this in SBT does exist. Using something like webpack is a tradeoff...you're more likely to find up-to-date plugins, documentation, and support for all of the latest JS glitz, but it's one more tool you have to figure out and integrate.
I worked with akka but not tensor flow what is the project about
Awesome, thanks !
Tensorflow is an open-source machine learning library, mainly used to train neural network models. Tensorflow Serving is a project for deploying trained models and exposing them via HTTP or gRPC endpoints to be used in a production setting. From their README: *It deals with the inference aspect of machine learning, taking models after training and managing their lifetimes, providing clients with versioned access via a high-performance, reference-counted lookup table.*
Do you plan to serve the model within a Spark pipeline or in a different setting?
UPDATE: We've released v4.0.0: [https://twitter.com/oas\_generator/status/1128214723260850177](https://twitter.com/oas_generator/status/1128214723260850177) &amp;#x200B; Please check it out and let us know if you've any feedback.
Why on earth you wanna do that?
Is akka more suited for this than other streaming solutions such as fs2 and monix? Not a pointed question, I'm genuinely curious and I've never used akka streams.
I mentioned akka because I'm not familiar with fs2/monix and I'm thus not able to give a constructive reply to your question, but my guess is that fs2/monix should be as suitable as akka. What are your thoughts on that? What are the advantages/disadvantages of them?
I am interested in participating
I'm not entirely sure, but fs2 has a large focus on control, and it is pull based so that might not be a good tradeoff for ML
Pipelines all the way.
I'm not aware of any examples but I don't know why it would be any different from using powermock with anything else. What did you try and what problems did you have?
Can I suggest moving the static functions (object methods etc) into a class so it can be more easily tested / mocked. &amp;#x200B; Playframework already has good dependency injection. So I dont know why having functionality on objects would be an issue.
Why can't you use a multi-project build? Does it fail then?
Sounds great, feel free to use this for the discussion: [https://github.com/picnicml/doddle-serving/issues/1](https://github.com/picnicml/doddle-serving/issues/1). Thanks.
I use Akka Stream for [FScape](https://github.com/Sciss/FScape-next), a digital signal processing system. However, I don't use the high level stream API, but rather implement a graph stage logic per element and use my own internal chunking into `Array[Double]` objects that get passed around along with a use counter and a queue to reuse them and minimising instantiation. It's optimised for 1D signals now, but it could be interesting to understand how 2D and multi-dimensional signals (tensors) would be represented...
These instructions won’t make Sbt run using graal. You need to start Sbt with the graal compiler and libs on the upgrade module path and the other jvm options I listed
Here's mine: &lt;https://gist.github.com/pathikrit/a32e17832296befd6b94&gt; ``` val n = 9 val s = Math.sqrt(n).toInt type Board = IndexedSeq[IndexedSeq[Int]] def solve(board: Board, cell: Int = 0): Option[Board] = (cell%n, cell/n) match { case (r, `n`) =&gt; Some(board) case (r, c) if board(r)(c) &gt; 0 =&gt; solve(board, cell + 1) case (r, c) =&gt; def cells(i: Int) = Seq(board(r)(i), board(i)(c), board(s*(r/s) + i/s)(s*(c/s) + i%s)) def guess(x: Int) = solve(board.updated(r, board(r).updated(c, x)), cell + 1) val used = board.indices flatMap cells 1 to n diff used collectFirst Function.unlift(guess) } ////////////////////////////////////////////////////////////////// import scala.collection.{IndexedSeq =&gt; $} val board = $( //0s denote empty cells $(1, 0, 0, 0, 0, 7, 0, 9, 0), $(0, 3, 0, 0, 2, 0, 0, 0, 8), $(0, 0, 9, 6, 0, 0, 5, 0, 0), $(0, 0, 5, 3, 0, 0, 9, 0, 0), $(0, 1, 0, 0, 8, 0, 0, 0, 2), $(6, 0, 0, 0, 0, 4, 0, 0, 0), $(3, 0, 0, 0, 0, 0, 0, 1, 0), $(0, 4, 0, 0, 0, 0, 0, 0, 7), $(0, 0, 7, 0, 0, 0, 3, 0, 0) ) println(solve(board).get.map(_ mkString " ") mkString "\n") ```
Could your object implement a trait instead, and use the latter for DI specification &amp; mocking? Can sometimes clarify exactly what the responsibilities are...
Yes, I am interested too.
I’m interested.
Looking for an idiomatic way to perform a side-effect if `Option` is defined ``` def m[F[_]](out: Option[String], err: Option[String])(implicit F: Sync[F]): F[Unit] = { val outF = out.map(F.delay(System.out.println)).getOrElse(F.unit) val errF = err.map(F.delay(System.err.println)).getOrElse(F.unit) outF *&gt; errF *&gt; F.unit } ```
&gt; or use graalvm as your jvm Thanks! That's what I did. Both with and without the params from this post, SBT compiles my project just as fast as it did when my $JAVA_HOME pointed to the latest Oracle JDK8. :\
 ``` import cats.instances.option._ import cats.instances.unit._ import cats.syntax.foldable._ out.foldMapM(s =&gt; F.delay(System.out.println(s))) // gives you F[Unit] ```
have you actually given it time to warm up? I usually see results after 4-5 compilations
&gt;Would this work with GADTs that exhibit existential types? As in: It does work, but it makes the compiler unhappy with extractors-based patterns, so you have to default to type-based patterns, and accept the fact that you'll get compiler warnings about erased types : ``` def myFunction[A](testBase : testBase[A]) = testBase match { // case Test(rest) =&gt; doSomething(rest) // compiler is unhappy case t : Test[i] =&gt; doSomething(t.rest) } ```
import cats.implicits.\_ out.traverse\_(s =&gt; F.delay(System.out.println(s))) \*&gt; err.traverse\_(s =&gt; F.delay(System.out.println(s))) or List(out, err).flatten.traverse(s =&gt; F.delay(System.out.println(s)))
there are so many tools to use in nodejs, like babel.
If you have questions, please don't hesitate to ask them on the gitter room for FP Foundation: [https://gitter.im/julien-truffaut/fp-foundation](https://gitter.im/julien-truffaut/fp-foundation)
As far as I can tell ExecutionContext uses Java ThreadPools internally, but the idea is that you do not depend on Java's classes on Scala's API level - this way things like Scala.js or Scala Native can use ExecutionContext with the same API, just different implementation.
Sorry, I think maybe the question was misleading here: Yes, Scala uses Java ThreadPool (and the ForkJoinPool) implementation as of Scala 2.12. What I would like to know is more about the use of the two global Thread Pools that can exist in a running Scala program, namely the `scala.concurrent.ExecutionContext#global` and the `java.util.concurrent.ForkJoinPool#commonPool`. Both exist, seemingly to perform the same purposes. This looks really redundant to me. Specifically, why does [this line](https://github.com/scala/scala/blob/v2.12.8/src/library/scala/concurrent/impl/ExecutionContextImpl.scala#L127) not simply read `java.util.concurrent.ForkJoinPool#commonPool()` ?
Few things: * separating error reporting related to Scala from error reporting from other Java libraries (huge value on its own when it comes to debugging), * especially you would avoid issues like Scala hanging because some Java library uses things wrong, * setting up values yourself is just a common sense, because you can control things that otherwise could be changed by someone else without your knowledge. And nobody has the time to check internals of various things to check if across several versions of JVM things are stable, or change or whatever. For the same reason usage of `ExecutionContext.Implicits.global` is discouraged - create your own and tune it to your hearts desire, `global` EC is just for making testing and prototyping easier.
It's probably because the Scala `ForkJoinPool` is older than the Java one and no ones bothered to risk the change to see if switching to the common pool will break some applications.
Actually, the Scala ForkJoinPool has been ripped out completely with Scala 2.12. My question is about usage, not implementation.
I'm talking about usage. You never know if an application that uses both pools would suddenly be resource starved if they suddenly used the same pool.
The way both of these pools are intended to be used it's pretty much impossible to starve them or else you are already doing to wrong and haven't noticed because of sheer luck. I really hope Scala devs aren't basic decisions on such cases.
Victor Klang's series on [Futures in 2.12](https://viktorklang.com/blog/Futures-in-Scala-2.12-part-7.html) has some details about adjusting the pool size, which I think addresses your question -- you can't simply use commonPool, because commonPool isn't bounded and doesn't have a prefix declaring it as coming from `scala-execution-context`. The big problem in my mind about using the global thread pool at all is blocking rather than exhaustion -- it's far too easy to use a fork/join pool which should be CPU bound and work stealing instead of a thread pool that's tuned to your IO needs.
I always want to ask what happened, but then I see hundreds of people just saying their condolences and not asking anything, and then I don't want to be "that guy". I don't know why it's so frowned upon. One thing is to harass his family &amp; friends who need their privacy, but another thing to keep the veil of mystery around the whole thing. Simple "after a short disease" would be enough. I know I sound like some nosy asshole, but I have trouble coping with the fact that people just get removed from our lives without explanation. Player 2 has left the game. Fuck that. Anyways, definitely a terrible loss. I hope his closest ones realise what an important figure he was in our community.
&gt; have you actually given it time to warm up? I usually see results after 4-5 compilations Yeah, that's what I see too. In my (admittedly rudimentary) testing, I just ran `clean` and `compile` a bunch of times until the time reported by SBT changes. For my project, that takes 5-6 cycles, and stabilizes at the same amount of time for Graal and HotSpot. Thanks for the link, I'll read it over today. It's very possible that I'm doing something wrong, but I think I've got at least the basics right, since if I do the same process when running SBT on OpenJ9, it's much slower, which makes me think I really am varying the JVM environment the way I intend to. Perhaps scalac is not as amenable to optimization by Graal as other Scala code. Shrug.
I don't think you understood their point. Scala's ForkJoinPool is supposedly older than java's (is this true? no idea). Assuming that's true, then when java's `ForkJoinPool#commonPool` was introduced, scala's global pool already existed. This means that applications that are using both java's `commonPool` *and* scala's `global` pool are using two different thread pools. If Scala starts using java's `commonPool`, you cause those applications to now use the same pool instead, which could have a dramatic impact on the application's performance. Yes they are using the pools incorrectly in that case, but good open source software is reluctant to make breaking changes -- hence why they waited until 2.12 to make that change, which already has no expectations of backwards binary (or in some cases source) compatibility. It would have been very bad form to make that pool change during 2.11.
No, I do understand that, but my question is explicitly about 2.12 code on Java 1.8+, not Scala 2.11, not Java 1.7, not Scalas ForkJoinPool either because there is no such thing in Scala 2.12. I have literally LINKED the line of code I am asking about...
Thanks for sharing -- very useful.
I mean... it's probably the same answer, and apparently i was wrong -- they didn't make a change in 2.12, they only dropped their own FJP implementation, but scala's default global executor is still a different pool than java's, and i'm guessing this is why. The other reason i can see is because Java's commonPool is configured using a different set of system properties than scala's. You could theoretically use `System.setProperty` so the scala properties also applied to the java ones, but there'd be no way for them to know whether Java's commonPool had been initialized yet, so it would be folly to try that. Why are you so hung up on this?
this is awesome! simple to understand. The relationship between type and data constructors clicked for me finally. Cant wait for the next post in the series
Thanks, it’s always nice to get positive feedback. :)
&gt; en I don't want to be "that guy". I don't know why it's so frowned Hi, I'm Yann, one of the colleagues of Oleg. I can understand what you are feeling. We (the colleagues) cannot say anything just because we don't know. We would also like to know. But we don't. The family has chosen to not share more information with us at the moment. We have to respect their privacy in the matter. It's difficult, but we all have to accept that we may never know what happened.
\&gt; Why are you so hung up on this? When I stumble upon code that is baked into the environment I use an can have unseen implications (like lazy global thread pools) I want to understand the reasoning behind this. The reasoning behind the global Java pool is pretty simple: The Java language and ecosystem is not flexible enough to do it any differently, even though it feels like a bad idea. I cannot apply the same reasoning to Scala so I am looking for other explanations. That's it :)
What are you thoughts on [Kotlin Coroutine](https://youtu.be/_hfBv0a09Jc) to handle Future's callback hell? Instead of using an EitherT pattern to solve the problem, the opted to incorporate concurrency into the language with 'suspend'.
I think Kotlin as an entire language is unnecessary because it adds little to Scala. Also google sucks because they used Kotlin in place of Scala.
I think it probably makes it harder to know when the future will be resolved.
Coroutines have be implemented in a Scala library via macros : * [https://www.youtube.com/watch?v=B3hKOUtc4e0](https://www.youtube.com/watch?v=B3hKOUtc4e0) * [http://storm-enroute.com/coroutines/](http://storm-enroute.com/coroutines/) I'm buying way into functional programming so I have no use for them as I can pretty much solve the problems coroutines solve with monads. I do however understand that if you're used to a more imperative style, they're an important tool.
I find the control flow too hard to follow. Most of the time you can just ignore the suspend and read the straight-through code - but the times where you can't are precisely the most important times. People keep trying to find shortcuts to simplify monadic code, but IME they always end up with awkward corner cases that mean they end up causing more trouble than they're worth. (I'm sceptical about the proposed scala 3 effect system for exactly the same reason). Monadic style has the enormous advantage that everything is (or at least desugars very directly into) plain old functions and values that do what they say and can be reasoned about as normal functions and values. At this stage I'm not interested in any alternative proposal that can't preserve those aspects.
&gt;they always end up with awkward corner cases I think this is key because most language designers never tell others about these corner cases. By the time they find out, its already kind of late.
It's a bit rough on its own, but quite nice once you start using it with arrow-fx to group things all together nicely.
The corner cases are different each time, but they're always there. Listing the existing ones wouldn't work: every new approach avoids the specific problems that previous approaches had, but nevertheless introduces new ones. If you don't have a coherent underlying model to start with you're never going to come up with one by accident, but it will probably take a while for the specific incoherencies of your model to manifest themselves; it's very easy to come up with a design that looks sensible on the surface, while the problems only emerge with extensive use.
Coroutines are intersecting with monads but are neither less or more expressive/generic than monads/effects. What do i mean is that simple cases like chains of `await` with coroutines or `&lt;-`/`flatMap` with monads are very similar . Still they are inherently different because coroutines allow you to `await` for completion inside a loop etc, while in case of monadic approach you are required to use something like `traverse` from cats. I am personally a fan of the latter because it is much less powerful (but powerful enough to solve most of the problems). What's more monads can be swapped quite easily and are very good for library authors to make them as most generic as possible or for regular developers to make testing your code less of a chore (tagless final approach).
I think it's a bit disingenuous to reduce the suspend modifier to just Future[], since suspend is a lower level construct than that. Suspend doesn't necessarily mean asynchronous code (see generator functions, arrow). But I guess async is it's main use case. Kotlin doesn't have a lot of the features Scala has to be able to use a Future[] well: for comprehension and higher kinded types. Instead it uses its own compiler magic (continuation passing style). I find the end result a lot easier to use, since most of the time I can either ignore it or use an async/await style of programming. It does require some getting used to (same as EitherT I suppose). I think Scalas futures works well in a functional way, whereas kotlins concurrency can handle state better, with things like structured concurrency. A lot of Kotlin runs on Android, where this structured concurrency makes a lot of sense: Switching the activity means having to cancel all related work/futures. An area where Kotlin is still (coroutines are relatively new after all) behind Scala is the actor system. Akka is way more advanced than the current kotlin actors. Disclaimer: As you may have noticed I am more familiar with Kotlin than Scala, so if you I have mischaracterised something please correct me.
Do you you have an example of an awkward corner case? That would be interesting to know.
These kind of language features immediately raises the question: why only suspend instead of `Future` or similar types? What about `Option` \- oh wait, they have it. But what about `Either` or `Parser` or `Validation` or or or? &amp;#x200B; I think a great strength of Scala is, that it tries really hard to generalize things. It failed at that for some parts (like `TupleN`) and we all know the pain that came of it. Therefore, I agree with with m50d: is it possible to generate code with plain old functions out of this `suspend` syntax? Then do it and it will be fine. If it can't be easily done, that's the sign of problems that will come up in the future 100%.
With this kind of thing it's usually the interaction between two effects that's problematic - one effect on its own is fine since you can understand it just by reasoning about the program execution order. As a very concrete example, using a library/framework that relies on threadlocals will break, e.g. if you write some database access code using Spring JDBC template and want to call an async function from the row mapper this can't possibly ever work right (whereas with futures it's fine: your row mapper returns a future, so you get back a list of futures and then you can sequence those into a combined future outside the library call). Another example is if you're working with continuations / resumable exceptions (e.g. if you're using an iteratee library), it's very hard to reason about what's going to happen when you resume from within the middle of an async function. In the most general sense it's just hard to confidently refactor when replacing a function call with its result (or vice versa) or replacing two function calls with making one call and using the result twice is going to change where the suspend/yield points are; of course if it never matters where your program suspends/yields then it doesn't matter (though in that case I'd argue you might as well not have a keyword at all and just do it magically/invisibly like go does). Making `await f(x)` visibly different from `g(y)` does give you visibility into where the problems might be, but it's only half the battle if you can't actually pull out/store/reuse a *value* that's completely equivalent to `await f(x)`.
Thank you. I completely agree with respecting the privacy of the family, of course. I thought there's a wider circle of people (including his colleagues) who know what happened. My biggest regret is that I also do Scala and also live in Berlin, even visited commercetools office for a meetup, and I never got to know him personally. Seems like he was a genuinely nice guy, and really smart too. RIP
Simple and to the point. I am adding this to my bookmarks. Keep up the good work and I am looking forward to next posts :)
I've had to use Scala and Node at work and Kotlin for some personal mobile/server work. I'll give my perspective from these three. But essentially it comes down to having flexibility at the library level (Scala/Different implementations) vs simplicity and standard use of async/await at the language level (Kotlin/Node/C#). There is definitely a flexibility in having async functionality implemented at the library level via Future/Monadic style. And having the option to swap implementations. However, for new engineers to Scala the learning curve here will be steeper. Kotlins async/await is very much like Node/C# but IMO even simpler from my understanding. On a broader technology/trend level, async/await is becoming the norm. In Node/JavaScript, there was initially raw Promises. These got replaced by language level async/await. Now, from what I hear about upcoming features in Node, you don't even need the async keyword, and will just need to use await (much like Kotlin where you only need 1 keyword.. suspend). In Kotlin, where it's a significantly better Java and it's the ecosystem is not aiming to be functional (in an pure/extreme sense), Coroutiens serve the purpose of async quite well. Philosophically, it seems the goal of Coroutines was to explicitly make async code look sync and explicitly avoid callback/monadic flow. It does make majority of code easier to read (IMO).
I briefly worked with Sangria a few years ago, and was blown away by the project, the thoughtfulness of the code, and the thorough but approachable documentation. I was super impressed to find out it was mostly a one-person project. Oleg was clearly a very bright and motivated person. Rest in peace.
&gt; to make testing your code less of a chore Isn't this just theoretical? Any real life code relies on such combination of type classes, that instantiating your runtime and using real `IO` appears to be much easier than implementing some `FakeIO` specifically for tests
I know nothing about Kotlin. How does `suspend` compose? Being able to compose effects however needed is something I very much like about handling them using monads.
Thanks :)
Thank you and my condolences
I wonder (perhaps someone can answer this), if you require a special annotation `suspend`, if the thing still stays composable in the sense of suspend def first(in: A): B def second(in: A): B suspend third(in: A): B Would it be possible that `first` calls `second` and `second` calls `third`, and suspension works correctly? Or is this an "error" in Kotlin, because `second` is not instrumented to be suspendable? This is doable in SuperCollider (there are no special annotations), which I think has thus a great (universal) coroutines implementation.
 suspend fun first(i: A): B = second(i) fun second(i: A): B = third(i) // does not compile suspend fun third(i: A): B = TODO() The reason is, of course, that to call third you need to be in a coroutine or suspending yourself (under the hood suspend is translated into a continuation argument, a fancy callback and second does not have one have those to pass to third). Solutions are to either use runBlocking in second to call third in a blocking fashion, or to return a Future[B] (called Deferred in Kotlin). Or better yet reconsider making second a suspending function. Do you know how this works in SuperCollider? What would happen if you called second without calling first first? Does the compiler know the call hierarchy?
They compose like regular functions would (assuming you mean something like this: https://pl.kotl.in/HX2bJrjAf). However, most coroutine code I see is written in an imperative style
"Colored function" is a terrible terminology to describe different kind of effectful functions, because color is a single attribute while effects could be multidimensional attributes that are orthogonal and composable. In my library [Dsl.scala](https://github.com/ThoughtWorksInc/Dsl.scala), I have a better solution than Kotlin coroutines. There are two basic concepts in Dsl.scala: domain and keyword. Domain is the return type and keyword is the operation. For example, `async` / `await` in other languages can be considered as a special case in Dsl.scala, where the domain is `Future` and the keyword is `Await`: import scala.concurrent.Future import com.thoughtworks.dsl.keywords.Await def myFuture40 = Future { 40 } def myFuture42 = Future { !Await(myFuture40) + 2 } What is interesting is that the `Await` keyword is not only available in the `Future` domain, but also any curried functions that finally return `Future`s. For example, `Route` in Akka HTTP is a type alias of `RequestContext ⇒ Future[RouteResult]`, so you can use `Await` in functions that return `Route` as well. import akka.http.scaladsl.server._, Directives._ val myRoute: Route = { get { complete(!Await(myFuture42)) } } `Await` is not the only keyword that you can use in a `Route`. I just wrote an article [here](https://www.reddit.com/r/scala/comments/bpmdhc/improve_akka_http_dsl_with_the_help_of_dslscala/) about other keywords for resource management and performing Akka HTTP directive. I called this approach "domain derivation", since the domain `Route` is derived from the domain `Future`. The domain derivation approach is similar to `StateT` or `ReaderT` monad transformers, but more lightweight than those transformers. The keyword `suspend` and the terminology `colored` in Kotlin unfortunately excludes these interesting N keywords × M domains use cases, unless the Kotlin compiler provides N×M built-in keywords.
It's not a dual, but an extension of Monad, traditionally called MonadError. Libraries such as cats and scalaz provide that genetic construct, as well as specific implementations for Option, Either, Try, Future ... On my phone so I won't link but it's easy to find documentation around it.
Lots of really nice stuff, although the supershell doesn't work fine for me when running the scala console inside sbt (it basically eats all input I write deleting the line, prompt also becomes invisible due to this).
`MonadError`. I think there are built-in `MonadError[Future, Throwable]` and `MonadError[Try, Throwable]` instance in both scalaz and cats. IIRC, there is no built-in `MonadError` instance for `Option`, but you can create your own `MonadError[Option, Unit]` instance easily.
Thanks Baccatta and yang_bo. I'm thinking the method is a dual to flatMap, not that the type is a dual to monad. But why would you use a MonadError[Future, Throwable] given Future already contains the exception in case of error? And why make some nested effect for Option, when Option already has orElse? Just for uniformity, so that effects can be easily substituted if the need arises?
&gt; I'm thinking the method is a dual to flatMap, not that the type is a dual to monad. Technically that method would be `coflatMap`, which looks like `F[A] =&gt; (F[A] =&gt; B) =&gt; F[B]`. The dual of lifting is extracting. So it's completely different. &gt; But why would you use a MonadError[Future, Throwable] given Future already contains the exception in case of error? `MonadError[Future, Throwable]` simply says that "This monad called `Future` can handle errors of the type `Throwable` within its context". This means that for any `A`, a `Future[A]` can contain a `Throwable` inside of it. If you look at the type signature of the two basic operations of `MonadError`, `raiseError` (like `pure`, but for the error value), and `handleError` (like `flatMap`, but for the error value), things will start to get clearer. I hope that helps. :) Here's Cat's version of it for reference: https://typelevel.org/cats/api/cats/MonadError.html.
You don't need \`FakeIO\`. In a lot of cases, just use \`Id\` and you'll be fine!
&gt;Or better yet reconsider making second a suspending function. That's really really bad. If you do that, then soon all your code will end up as suspend functions. Essentially that would be the same as using Future as return type (or IO, ...) for all your methods in Scala. And then at some point when you want to use a function in blocking way (and don't need to suspend it) you have to do extra work.
My company app has thousands of lines of csv file building code for some reports. The code is rammed with .getOrElse("") and mkString(",") etc. I've just rewritten most of it to use a single file library that uses Typeclasses and it's fairly elegant. Just provide a list of A, and a function that given an A returns a Map[String, Encoded] where String is the column and CSvEncoded is any type (string, int, float,, option) that has an implicit conversation available and boom, done. Surprised I couldn't a find a library for this but it was just 100 lines of code.
Underrated opinion.
Thanks lol
This is exactly what the linked article discusses (and to an even greater extend the first link in that article). There is no way around it: Everything that calls a suspending function must be suspendable. But I agree with the you: Letting suspend proliferate freely through your code is a bad idea. At some point point you need to return back to normal functions. Now I don't think the extra work here is that bad: Blocking just means calling runBlocking (but remember blocking is usually not the goal) and launching it in a new coroutine, i. e. in the background, is simply calling launch. What you also get to decide at that point is where to run the asynchronous code: In a thread pool? In the same thread (blocking)? What about UI threads in Android, Swing, etc? This can all be neatly controlled at the top of the suspending in call hierarchy. This is is roughly equivalent to the choosing a ExecutionContext in Scala but with the potential benefit of the structural concurrency. In Frameworks, such as Scalas Play framework, this last step isn't even your responsibility: You return a Future from the controller.
Interesting approach. It definitely looks more powerful than Kotlins coroutines in that I don't know if things like the !Each macro would be possible to implement in Kotlin. For the simple Future case, it looks the [same as Kotlin](https://pl.kotl.in/-Z_W363C0), except that !Await is a macro instead of a normal function like in Kotlin. Of course with suspend you wouldn't write it with Future at all, you would just write: suspend fun my40() = 40 // stand-in for some asynchronous operation suspend fun my42() = my40() + 2 Things do break down in Kotlin with your second example though. But I would argue that is okay: It avoids the magic rewriting going on in your code. Where is the Future created? Is it inside the string? Probably not since that would yield the wrong result. Is it outside the string but inside the complete? Is it outside the complete? How far up can it go? If more than one is possible which one is chosen and why? Or am I missing something here? I had a look at your post and was intrigued by the TApply macro. I haven't come across something like it before, it does a really good job at eliminating the callback. In Kotlin this is not possible (I think) since the callback needs to return a value. You do this by rewriting the code so that the statements below are all part of the callback, right? Clever, but slightly too much magic for my liking. One question: Does your library support other Callbacks and Futures except for Scalas? There are quite a lot of them. How would support for them look like? In Kotlin that would a simple ~5 line function. As for colours: I would argue your functions are coloured too, those that return a Future and those that don't. Of course once you get to your NxM scenario colouring gets a bit trickier. As for the use cases: I find kotlin covers most of what I need: async/await, yield, and even some monad comprehensions. All of which are plain old functions you can implement yourself without macros (but are also in the standard coroutines library + arrow for monad comprehension).
 &gt; I'm thinking the method is a dual to flatMap, not that the type is a dual to monad. Those two things are related, in a category theoretic sense. If a Foo has methods bar, baz and quux, a Cofoo (the dual of Foo) has methods cobar, cobaz, and coquux that are dual to their regular versions. So part of being dual to monad is having something that is dual to flatmap.
Why have the same discussion in in PRs again and again if almost everything about style - formatting, allow/don't allow \`null\`s/mutability etc - when you can set it up once and for all and be consistent across whole project? This way it is easier to make PR about things that matter: whether the code is self-descriptive, whether abstractions are leaky, does it provide the actual business value... Basically it helps you focus on things that matter, because if you screw up less relevant things some automate will notify you, you fix it on the spot and move on. Unless you have a prototype, or other throwaway project where quality doesn't matter I see no downsides to having linters and a lot of gains.
There will always be parts of your program that need to be tested with a real `IO`. But you can push them to the edges ("functional core, imperative shell") and write most of the tricky business logic that needs lots of test coverage in a place that can be tested with a few simpler classes - it absolutely is practical. If every method requires a big combination of typeclasses you're doing it wrong - most of the logic should only need one or two, only the top-level coordination functions should need all of them.
To expand on what /u/NippleGame said every time you call recoverWith, rescue, and prepare, you are calling something with the exact same type that has a different name and is spread amongst several interfaces. For easier maintenance, it's nice for your program to program in terms of the common interface that provides a method with that type signature. That's MonadError/ApplicativeError. The same is true of flatMap/map/foldLeft/etc. If the instances (Option/Future/Either) for a given type change, but the interfaces methods don't, your program won't care.
`Id` is defined in Cats as ``` type Id[T] = T ``` Which means that if, for example, in your production code you have `F[String]` somewhere which is also used in for comprehension, then defining `F` as `Id` will give you an entirely different result than some other monads would (or am I using it wrong?). But in fact it is rarely possible to use `Id` in code that does something more than arithmetic operations. Even pure code that doesn't call external systems usually needs `ApplicativeError` if it's not some simplistic exemplary petstore project. At least from my very limited experience. // Sorry for mistakes if any, typing from phone
Depends on the application of course, but what you said holds true only for cases where, as you said yourself, there's a "tricky business logic that needs lots of test coverage". Most services I have to write are about calling multiple external systems and then doing joins aggregations and transformations on results. Thanks to Scala, aggregations, joins and transformations are usually a couple of oneliners. However the real complexity (and majority of code) is in error handling: graceful degradation, retries, etc.. And for me, so far, this is tightly coupled with `IO`, at least `Sync` is what my code expects. And I'm finding it more convenient to use real `IO` on such cases. // Typing from phone, sorry for mistakes
Well sure, a different context can definitely get you a different result (in your example the returned string), but usually it doesn't and if it does, then it might very well make you aware that your code is kind of flaky by design. If you use something error-like, you can very well use Either (or a validation type) instead of IO, which still makes testing more easy imho. You have a point though in that the more high level you go the more complex and constrained the effect type becomes. But the more lower or leaf-like parts of your code can still be tested like that.
&gt;Now I don't think the extra work here is that bad: Blocking just means calling runBlocking Well then, why would we not just make all function be suspendable by default? Because "the extra work is not that bad" right?
An even simpler example: someone’s IDE is set to tabs and another to 2 spaces. The linter can ensure consistency no matter what. Sure, you could futz around to have everyone’s settings match and there are other ways to ensure consistency but none as simple &amp; comprehensive as a linter.
In the embedding case, it's a combination of compile time dependency injection and websockets. Specifically, components are probably what you're interested in: https://www.playframework.com/documentation/2.7.x/JavaCompileTimeDependencyInjection#Using-other-components The documentation in the embedding Play page points you in this direction with overriding DefaultAkkaHttpServerComponents. ```scala import play.api.http.DefaultHttpErrorHandler import play.api.mvc._ import play.api.routing.Router import play.api.routing.sird._ import play.core.server.DefaultAkkaHttpServerComponents import scala.concurrent.Future val components = new DefaultAkkaHttpServerComponents { override lazy val router: Router = Router.from { case GET(p"/hello/$to") =&gt; Action { Results.Ok(s"Hello $to") } } override lazy val httpErrorHandler = new DefaultHttpErrorHandler( environment, configuration, devContext.map(_.sourceMapper), Some(router) ) { protected override def onNotFound(request: RequestHeader, message: String): Future[Result] = { Future.successful(Results.NotFound("Nothing was found!")) } } } val server = components.server ``` This lets you get the actor system: https://www.playframework.com/documentation/2.7.x/api/scala/play/core/server/DefaultAkkaHttpServerComponents.html#actorSystem:akka.actor.ActorSystem If you take a look at the sample for compile time dependency injection: https://developer.lightbend.com/start/?group=play&amp;project=play-samples-play-scala-compile-di-example and the one on websockets: https://developer.lightbend.com/start/?group=play&amp;project=play-samples-play-scala-websocket-example That should give you an idea.
If you want the reasoning by the author of coroutines himself read the article I linked in my first reply: https://medium.com/@elizarov/how-do-you-color-your-functions-a6bb423d936d
&gt; Things do break down in Kotlin with your second example though. But I would argue that is okay: It avoids the magic rewriting going on in your code. Where is the Future created? Is it inside the string? Probably not since that would yield the wrong result. Is it outside the string but inside the complete? Is it outside the complete? How far up can it go? If more than one is possible which one is chosen and why? Or am I missing something here? You can explicitly specify the boundary where the `Future` is created with [@reset](https://javadoc.io/page/com.thoughtworks.dsl/dsl_2.12/latest/com/thoughtworks/dsl/Dsl$$reset.html) annotation. def myRoute1: Route = { get { complete(s"The result of myFuture42 is ${!Await(myFuture42)}"): @reset } } The above code will be translated to: def myRoute1: Route = { get { Await(myFuture42).cpsApply { a =&gt; complete(s"The result of myFuture42 is $a") } } } If you move the the `@reset` annotation after the `get` directive as `myRoute2`: def myRoute2: Route = { get { complete(s"The result of myFuture42 is ${!Await(myFuture42)}") }: @reset } Then `myRoute2` will be translated to: def myRoute2: Route = { Await(myFuture42).cpsApply { a =&gt; get { complete(s"The result of myFuture42 is $a") } } }
&gt;Short answer: To clearly mark the function to ease reasoning about which functions may suspend and wait. Then, changing a function from non-suspendable to suspendable is kind of working against what the author himself encourages
In large teams it's better to lint.
I don't quite get where you're coming from. Only functions that can suspend should be marked as suspendable, obviously. In the original example `second` calls `third` and so it itself can suspend and should be marked as such.
Fuck linting
even better than linting, is auto format: https://scalameta.org/scalafmt/ Instead of getting warnings, get it fixed right away. It can't probably catch as many issues, but it seems a good complement at least
What do you mean by leaky abstractions?
Mind explaining with a little example? I'm probably facing something similar soon.
https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/
Hmm... that's interesting. It seems to work for me :-/ Could you open an issue with some environment details and capturing your reproduction steps, please? Thanks.
&gt;Lots of really nice stuff, although the supershell doesn't work fine for me when running the scala console inside sbt (it basically eats all input I write deleting the line, prompt also becomes invisible due to this). idk. `console` works for me. If you have repro steps, could you report it on GitHub issue plz?
That's what I thought as well, and I create [Dsl.scala](https://github.com/ThoughtWorksInc/Dsl.scala/) to answer the question. My solution is to move the real implementation of these language features from compiler to libraries. The compiler should only perform name-based CPS translation that are neutral from specific types, then it's the real implementation is provided by libraries. For example, in Dsl.scala, `Await` is a plain `case class`, and the actual implementation for the `Await` keyword goes in the `Dsl` type class. As a result, you can use `Await[A]` in function that returns a `Future[B]`, `Task[B]`, or even `akka.Route`, as long as type class instances of `Dsl[Await[A], Future[B], A]`, `Dsl[Await[A], Task[B], A]` , or `Dsl[Await[A], Route, A]` can be implicitly resolved, respectively. import com.thoughtworks.dsl.keywords._ import scala.concurrent.Future def myFuture40 = Future { 40 } // Use Await keyword in a Future def myFuture42 = Future { !Await(myFuture40) + 2 } // Use Await keyword in a Task import com.thoughtworks.dsl.domains.task.Task def myTask = Task { !Await(myFuture42) } // Use Await keyword in a Route import akka.http.scaladsl.server.Route import akka.http.scaladsl.server.Directives._ def myRoute: Route = get { complete(s"The result of myFuture42 is ${!Await(myFuture42)}") }
I don't see why not assuming you can express your test's expectation for the predefined failure combinations. Scalacheck is really good on finding issues with non-ASCII character sets, timestamps, that sort of thing, when encoded/decoded in JSON. Unfortunately quite often you will find an underlying library is broken, e.g. javax.time is riddled with edge case bugs.
I don't know what kind of environment details would help, just `env`?
[https://www.wartremover.org/](https://www.wartremover.org/) is useful; however some compiler issues can be annoying e.g. Product/Serializable on certain case classes.
&gt; most language designers never tell others Is this by malice? Or just forgetfulness?
This is way harder to read IMO. Keep in mind you can compose directives with `&amp;`. So your example can be simplified to `(get &amp; parameters('p1, 'p2)) { (p1, p2) =&gt; ... }`
Of course, you can use `&amp;` with `TApply`: def currentDirectoryRoute = { val glob = !TApply(get &amp; pathPrefix("current-directory") &amp; parameters("glob")) val currentDirectory = !Using(Files.newDirectoryStream(Paths.get(""), glob)) path("file-names") { complete(currentDirectory.iterator.asScala.map(_.toString).mkString(",")) } ~ path("number-of-files") { complete(currentDirectory.iterator.asScala.size.toString) } }